Hi there! [You can find SAS Tutorials here!](http://video.sas.com/#category/videos/how-to-tutorials) 
Seems a little silly to use SAS for a product registry. Maybe that's why the "SAS" person isn't responding. It's a weird request. Without knowing much, I'm really curious why not store the registry on some flavor of SQL server? Specifically if clients are searching for what they need in it, it's totally nonsensical to use SAS....unless SAS has some framework for that sort of thing I'm totally unaware of...but even still, SQL is the standard for those sorts of catalogs as far as I know.
Thank you. I'm not sure that the end goal is to use SAS for the product registry. He wants right now to: --Perform deep unstructured analytics --Concept/sentiment extraction --Correlation/causality/problem/solution How does he get there through our Indian statistician gatekeeper?
I really don't know. I'm in clinical so I take SAS for granted. Do you guys already have licensing for use? Otherwise, really, it might be worth looking at another language like R. I guess depending on what the catalog is stored in, I'm confused why you wouldn't just take a snapshot of it, get it out and analyze it however you see fit. If SAS isn't already readily available, use R. It's free and it's totally solid. I've been trying to get my department to skip out on SAS and switch to R for years now. It's just not feasible because all the clients also use SAS so all the data extraction comes in sas7bdat or their transfer format, and R's not completely reliable to translate it...so SAS has a bit of a stranglehold on the industry...Which is a damn shame really because it's not that amazing. The long and short being, if you don't already have SAS, don't get it. You'll just be locking up a chunk of the budget. If it's not completely necessary then avoid it. I can't think of one thing I can do in SAS that I can't do in R besides read in SAS files completely accurately. 
We're a huge company with thousands of licenses. So that train has left the station.
Then I have zero clue why they wouldn't just give you access to an instance. I'd just call them 3 times a day every day till they answered. That or look who his boss is and contact them if a week goes by.
I mean if he's familiar with SAS, there's no shortage of text analytics and data cleaning you can do with it. It should work fine for that. For actual storage once you get standardized definitions, I'm sure they'd use a SQL server, but talk to your IT people.
SAS is a tool which excels at data analytics. By definition, what you're asking about is *not* analytics. It's not really anything. You can accomplish what you're asking about with formulas in Excel, which is about as far from SAS as I think you can reasonably get while sharing some similarities. My best guess for why the company SAS person hasn't responded is that he, like me, doesn't understand why the request is being made in the first place. If you were a waiter at a restaurant and someone asked for a fork to eat his soup, what would you do?
He (my colleague) seems convinced that some kind of modification is necessary to accomplish the tasks listed above (deep unstructured analytics/concept sentiment extraction/correlation-causation-problem-solution). Obviously, I'm completely unfamiliar with SAS, but as a lay person whose company used Oracle, for example, if a guy the IT dept didn't know suddenly called a developer asking for something requiring a developer's time, the answer would be "Lol no. There's a process, find out what it is, and if you make a good enough case, MAYBE it will be included in the next release." I feel like that's where he's at, and/or he just doesn't have a grasp on what SAS's existing capabilities are,
The statement above is one I can get behind!
proc contents to get the names of the columns. proc sgplot to get a box plot of the column(s) you want.
So these phrases: &gt;(deep unstructured analytics/concept sentiment extraction/correlation-causation-problem-solution). ...are kind of corporate gobbledygook that don't say a lot. Deep unstructured analysis...well, SAS can do some of that. It's better with structured data, but it can be used *to* structure data. It kinda depends on what you specifically want. Sentiment extraction? That sounds like I'm trying to justify myself to a manager, or worse, a manager justifying to a higher manager. Maybe I'm out of the loop, but that means nothing to me. Correlation-causation-problem-solution? Are we writing a resume here? SAS has about a million and a half tools to find correlations and statistical significance, but it's not going to set up a natural experiment for you that proves causation. Problem-solution? That doesn't sound like something any programming language or database can solve. That's usually done by humans thinking. In short, he's using nebulous concepts that don't really get at the meat of what you/he want done. If it's just structuring unstructured data, then sure, SAS can do it. So can R, Python, C, etc. If it's solving all your problems with buzzwords, then no, SAS probably can't do it. Sorry we can't be more helpful, but it's practically impossible without specifics.
@fdsaf3 - OK, I feel like I'm getting somewhere now. Are you saying that "deep unstructured analytics/concept sentiment-extraction/blah blah are NOT analytics? Or are you talking about using SAS as a product registry? (Even I know the answer to the 2nd question, actually) Then I'm going to find out where he got the idea that they are. Btw, I told him this sounded like an Excel problem, so you made my day :)
OMG you hit the nail on the head. I'm sure I'm missing some specifics, which I will endeavor to get this AM, but you've all been exceedingly helpful in articulating why he's having these issues. My best answer was "Uh, I don't think that's how this works."
I reread your original problem. If you've got tens of thousands of custom categories, and you need to somehow concord them with an existing standard, that does NOT sound like an Excel problem to me. That sounds like something I would use SAS for, and yes, I would likely use a lot of text parsing and and analytics to try to automate recategorization. While yes, you could theoretically do it in Excel, Excel isn't designed for working with that many observations as efficiently as SAS is, particularly if you're developing many to many relations. Eventually, you want to store something in... not SAS datasets. Probably a SQL server, as mentioned elsewhere. But for getting from your ugly, nonstandard, current data to an existing standard, using SAS seems reasonable if he's already got a license and knows what he's doing. 
&gt;OMG you hit the nail on the head. I'm sure I'm missing some specifics, which I will endeavor to get this AM, but you've all been exceedingly helpful in articulating why he's having these issues. I might've missed something, but what issues is he having other than IT not responding? As I said elsewhere, using SAS to update a concordance is fine. Hell, I've used SAS to make webpages. If you're fast enough, and don't know other tools as well, it's pretty flexible. SAS doesn't have to only be used to run clustering algorithms. &gt;My best answer was "Uh, I don't think that's how this works." It's not that "that's not how this works," it's that those phrases are virtually meaningless. Again, without knowing more specifics it's hard to give specific advice. Is your concordance stored in a flat file somewhere? An excel workbook? What *exactly* is he trying to do that he's having trouble with? Just update your product registry? 
He can get a license - no problem. You defined the issue well. But I'm still not clear on whether these capabilities already exist in SAS, or whether a modification is necessary in this case. Is SAS typically modified?
There are different licenses you can get for SAS to add functionality (the most common/required being SAS Graph, SAS Stat, and SAS Access engine for whatever Databases you regularly work with), but all your basic data cleaning and text modification tools should be included in Base SAS.
Sorry, I didn't see your other responses when I wrote mine. I was responding to your original post where you said (or at least I interpreted) that you basically needed a tool to do some light classification of items. That's something you can do in a Microsoft product like Excel or Access. The other things you mentioned sound like things that SAS can do. I'm not personally knowledgeable about deep unstructured analysis, so I will refrain from comment on that piece of the question. I think I misunderstood the question, since it sounds like your colleague needs something more than Excel. At least for the deep analysis part. I can't help with that.
I'll try it out, thanks!
It's hard to give advice without knowing how this directory name is being stored; some example code might be in order. If it's a variable in a dataset, you can use the transtrn() function to remove 8 spaces in a row, something like this: data new; fileold="C:\example\of a filepath with 8 spaces\in the middle.txt"; length filenew $ 500; /* or whatever length you need */ filenew=transtrn(fileold," ",trimn("")); run; This replaces eight spaces with nothing (removing it). Here, trimn("") is what you use to say "a string of zero length". There are other string manipulation functions you could look into, like compress(), tranwrd(), translate(). This code will break your filepath if you ever have a folder or filename with legitimately 8 (or more) spaces in a row in it, but that seems unlikely.
There's faster sql code, but: Proc sort data=YourData; By Discount; Run; Data YourData; Set YourData; By Discount; Count+1; If first.Discount then count = 1; Run; Proc sort data=YourData; By Discount descending Count; Run; Proc sort data=YourData nodupkey; By Discount; Run; Or Proc Freq with output statement (Sorry on phone)
Sorry, should've been more clear about how the code actually looks: proc import datafile = "C:\a very\ long name for a\ directory" out = OutFile dbms = xlsx; run; The directory name is so long that those lines go up to 80 characters though, which is why I go to a new line and tab. My issue is that the resulting string includes those tabs, even though I've only put them there to keep things looking tidy. Do I need to use your method of writing the string, turning the tabs into nothing, and then doing the import? Or is there a simple solution to this that I haven't found
If you're using SAS EG or something similar, you may need to close it first and then put the open/close around the appropriate step. I assume you're also specifying the destination in the "ods rtf" statement.
yeah, you need to do the code I suggest on dataset OutFile after you import. 
Proc means data=yourdata nway noprint; Class discount; Var discount_count; Output out=summa sum=; Run;
Are you specifying an output file location? What version of SAS are you using? Are you closing the ODS statements? You should just need one ODS statement at the start, then one at the end. ODS RTF FILE="Location\Filename.rtf" ; All your code. . . ODS RTF Close ;
Think this is what you are looking for. I favor SQL over data steps so this approach uses the 'distinct' keyword inside the aggregate function: PROC SQL; CREATE TABLE want AS SELECT DISTINCT Discount ,COUNT(DISTINCT count_dis) AS distinct_count_disc FROM have GROUP BY discount; QUIT;
Yes (agreed). And use ODS EXCLUDE to omit proc output you don't want: ods exclude all; proc ... /* that I don't want in output; */ run; ods exclude none;
I was specifying an an output file location like you have there and closing at the end. I suppose a better way to put it would be I don't want to have the "All your code..." part I want to have a part of the code like "procedure A" then not some procedure "procedure B" and then have "procedure C" in the same document with procedure A
You only have to answer for "fido050amb". proc tabulate data= yourData (where=(discount eq "fido050amb")); var discount_count; table discount_count='Discount Count' * sum= ' '; run; 
You can find the **original** [post here](http://blogs.sas.com/content/sasdummy/2017/08/25/npp-with-sas/), complete with a preamble for why I use Notepad++ even when I have better SAS environments available. There are also many comments from readers on the post, sharing their own reasons and tricks for using Notepad++ and other editors.
Thank you for this!
Do you mind sharing that with me as well? I'd love to be able to supplement the prep book with some additional questions since (at least in the base prep book) the questions are way easier than the actual test.
Okay, thanks for your help!
Thanks for this. I did not understand from the post that /u/Cubsfan5ever wanted to omit output from the RTF. Hope that solved all your issues, OP. 
While most of these comments are correct, base SAS is not the go to product for "deep unstructured analytics/concept sentiment extraction", SAS add-ons have been created to handle these exact problems for example: https://www.sas.com/en_us/software/text-miner.html Ignoring the buzz words, the 3rd type of analysis "correlation-causation-problem-solution" can be done and is frequently done is SAS. To your larger question, SAS analytics can interface with SQL databases. You might have a normal database in the background (hopefully) but SAS is just tapping into it. Careful going in half-cocked with just internet comments supporting you. We are all making a lot of assumptions here.
No worries there. You all have been extremely helpful in that (sorry to generalize) you reinforced my argument that you need to be precise and know what you want in order to get what you want. And find the right people. This might be a slight exaggeration, but yesterday he claimed our 130,000 person organization had no discernable IT dept. Maybe it's super de-centralized, and probably is, but I'm quite sure one exists.
No problem! I'll PM you.
Are you saying that you're trying to figure out where that "entityVersion.xml" file is located?
No, we have a filepath in the error message, but we don't have direct access to that location. I was hoping that it might be possible to extract it through SAS... maybe?
If you have access to the path in SAS, you could always just input from that location and then use a list command to write it to the log. Or write it back out to another location. data _null_; infile "/mypath/entityVersion.xml" lrecl=500; input; list; run;
This interview with Catherine Truxillo, Ph.D, Senior Manager with the SAS Academy for Data Science, may give you some insights http://www.mastersindatascience.org/blog/sas-academy-for-data-science/
These papers might give you some insights: http://www2.sas.com/proceedings/sugi25/25/btu/25p053.pdf and http://www2.sas.com/proceedings/forum2008/166-2008.pdf
I use libname to point to a directory so I can pull data from multiple tables in that directory. 
okay, but does that mean that if you only need one table, you'll use infile instead?
okay i'll check those out, thank you
A libname with set statement is used to read in SAS data sets. Filename/input is used to read in text files.
If the file is already saved as a SAS dataset, I don't see why you wouldn't just use libname.
Libname statements allows add more information to the data, such as the sas engine 
try replacing "if" with "where"
Sorry, on mobile or I would post the example code. This link should help. You use the where statement on the dataset. http://support.sas.com/documentation/cdl/en/proc/65145/HTML/default/viewer.htm#n0qarv79909fdhn13c60hfubqwdq.htm
Can you explain the difference between if and where?
not really, i just know it makes a difference sometimes. If I had to guess, I think IF is for data steps and WHERE is for PROC steps. but it's definitely something to do with the order of operations within each step and at what point it processes the statements. did it work?
For you and /u/zezworkacc: "if" applies at the end of a data step, "where" applies to the reading of a dataset. That's why "where" works in procs while "if" doesn't. You can use either "if" or "where" in a data step, but they do different things. Let's say you have a dataset with 1000 records, 500 male and 500 female. If you use "if female=1", then anything you do in the data step will happen to all 1000 records first, then the output data will only have 500 records. But if you use "where female=1", only 500 records will be read in, then the code inside the data step will be done to only those 500 records and the output will have 500 records. This is particularly important when using first. and last. variables, if you want to preselect records to be considered - you may get very different output if you use "if" instead of "where". 
tagging /u/atomofconsumption too I tried changing "If" to "where," and got "Warning: No data sets qualify for WHERE processing." It then proceeded to produce the same output file, with all the male and female data, so it seems like it didn't do anything. Do you know why it would do that? Is my "where" in the wrong location in the program?
As /u/j-12 mentioned below you want to use where, but it's included in the data line proc export data=mksc2013.outmembermonths (where=(gender='Female')) dbms=xlxs outfile="Desktop\outmembermonths.xlsx" replace; run; You could ALSO use an IF statement in a previous data step data work.forexport; set mxsc2013.outmembermonths; if gender='Female'; run; proc export data=work.forexport dbms=xlxs outfile="Desktop\outmembermonths.xlsx" replace; run; 
Thanks /u/GooseTheGeek - this is much more clear than my explanation. 
Yea, but you included the support.sas.com link that gave the solution ;) I would have done the subset before the export, even though it's less efficient than using the where statement. OR used put statement in the data step. Lots of ways to skin a cat in SAS. 
It is standard to use a Libname for all SAS datasets. You use infile to create a sas dataset from a data FILE (TXT, CSV, XML etc...) Some types files also have libname engines, like XML and CSV. Typically it's easier to use a libname if your data accepts it. 
Interesting. This is very different from any other language I've seen...that's some strange syntax, with the "=" after the where. I wonder what the syntax would be if I wanted "ands" and "ors" with the where? Is there a site that has all that information?
`where` can go in 3 different places in a data step, and has different behaviour for each of them: * Within a `set` statement as a data set option for an input dataset - this is applied before any processing happens and affects only that dataset. * Within a `data` statement as a data set option for an output dataset - in this case all records are read from all input datasets and filtering only happens after processing has completed for each iteration. * As a `where` statement - this is applied to all input datasets on all set statements in the data step. Filtering happens as records are read in.
You don't ALWAYS use the = after where, but you do in this instance because it's an option to the data statement. This is called a "[Data Step Option](http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000131192.htm)" It's different than the typical "[Where Expression](https://support.sas.com/documentation/cdl/en/lrcon/62955/HTML/default/viewer.htm#a001000758.htm)" you are probably used to. There are no less than 3 ways to do anything in SAS. It's incredibly powerful, but you can easily trip over yourself with all the special syntax. Just wait until you discover Macro "Functions".
Good stuff! I've only ever used the third one.
Yes, I've had a similar problem myself. I don't have an exact answer for you, but I think what you want to google for is SAS encoding.
I have spent lots of time searching for answers. [here Wingdings 3 to Unicode](http://www.alanwood.net/demos/wingdings-3.html) I tried different Unicodes on the webpage. I noticed that if the Unicode displayed a square in Unicode column in the webpage it displays square in my output too. Some works like the triangle and slim arrows I mentioned in my post. 
Include (where=(gender=‘female’)) in the data statement 
Yep, that's why I mentioned encoding. I may be incorrect (not an expert on this), but the triangle and slim arrows are 4 hexidecimal = 2 byte (UTF-16), but the other character you mention is 3 bytes (and would fall into UTF-32). [See this link](https://blogs.sas.com/content/sgf/2014/09/26/encoding-helping-sas-speak-your-language/), if you click on "SBCS, DBCS, and Unicode Encoding Values for Transcoding Data" there you'll see that UTF-16 and UTF-32 have different values for the encoding option in SAS. Again, I may be incorrect in all of this, but I vaguely remember needing to change my encoding to get what I was trying to do to work. It is also possible you may simply be limited to UTF-16 for SAS ODS; I don't know what ODS's limits are. EDIT: All right, the more I read, the less I understand, so maybe I should bow out trying to help out on this one.
Thank you so much! I will try it at work on Monday have a nice weekend 
I often throw this code on the end of programs, right after closing the external log and listing: * Check log ; data checkerr ; infile "&amp;logDir\MyLog.log" truncover ; input @1 text $90. ; if (index(upcase(text),upcase("ERROR")) &gt; 0) or (index(upcase(text),upcase("WARNING")) &gt; 0) or (index(upcase(text),upcase("UNINITIALIZED")) &gt; 0); * If log contains ERROR or WARNING ; run ; proc print data=checkerr(obs=100) ; title "Problems in Log File &amp;logDir\MyLog.log" ; run ; If you want to do it for all the logs in a directory, you can use the pipe command to get the list of log files and loop through them: http://support.sas.com/kb/41/880.html
Why not just a shell script? That's what we do.
My department is moving towards a "closed" environment where we can't do shell scripting anymore. This is helpful. Thx!
Are you using SAS SQL? Are you using "select distinct"? This is a classic one to many join problem. Look at your data post merge, where do many of the additional rows come from? Does your inner join linking with the ON statement make sense? From what I can tell, you forgot to insure that iD=iD so basically every unit is getting every year of data.
Thank you for your reply. I've taken a look at the data and figured out where the new rows are coming from. My mortgage rate dataset has a Month column, so every row has splintered off into identical data for every month for that particular year. Safe to say, I don't want that. I only want the mortgage rate for the month in which the property was sold. And what do ya know, I went back and joined both month and year instead of just year... problem solved. Thank you for getting me thinking clearly.
Sweet! Good luck!
Don't know how to do that :)
Awesome! Thanks so much!
 grep ERROR sas.log &gt; sas.errors grep WARNING sas.log &gt; sas.warnings You can also trap issues like this that result from sloppy coding practices (note that the two arrows append to the file instead of starting a new one): grep 'issing values' &gt;&gt; sas.errors grep 'have been converted' &gt;&gt; sas.errors After you run a script with those commands, you will have a file called sas.errors and one called sas.warnings. We put the contents of these files in notification emails so that we can easily see why the program failed.
http://support.sas.com/techsup/notes/v8/19/861.html
Is the variance correlated with the response in a fairly consistent way? If so, look into using generalised linear models. SAS has various procs to help with this, including proc glm.
If I remember correctly, during install there is a screen that says configure unicode or something similar, by default i believe it was un-checked. There may be a way to enable it post install. not sure...
You used the caret as a "not" symbol, but reddit markup interprets the caret as "start superscript". Also, the caret isn't interpreted as "not" everywhere in SAS. It's often better to use the word NOT instead. Or mark it up as code, not text: if a and ^b You might be able to achieve something similar in SQL by summing the values of N of one each of a's and b's key columns. What SQL were you planning to use to duplicate the MERGE function? 
I was hoping something can be worked out with "full outer join"
 proc sql; create table out as (select a.id, b.id, case when a.id is null then 0 else 1 as ina, case when b.id is null then 0 else 1 as inb from input1 a full outer join input2 b on a.id = b.id); quit; Hope the syntax is right -- I'm on my phone.
You can get there using a nested query. First write the query to get the full list of IDs with flags for which input data set they belong to. Then wrap that query with an outer query which grabs all the distinct IDs and case logic which sums the individual flags. 
thank you. I think the CASE END script is what I'm looking for. But another question: what if there are multiple matching IDs? for example person ID and case ID, where there can be duplicates of one ID but the combination of the two IDs are unique? 
for those who are interested, I think I found the best solution: proc sql; create table out as select a.*,b.* from (select *, 1 as a_flag from temp1) as a full outer join (select *, 1 as b_flag from temp2) as b on a.id1 = b.id1 and a.id2 = b.id2 order by id1,id2; proc freq; table a_flag*b_flag; 
You might want to join on both if possible. Instead of a.id = b.id, it's a.id = b.id and a.caseid = b.caseid. You can also leave it as-is if you want, which will create a Cartesian product. In that case, if you had two occurrences of the same ID on one data set and three occurrences on the other, you would get six records -- one of each combination. This is an important difference between proc sql and the data step.
Came here to say this. Good work!
For reference, all the input variables were copied and pasted directly from the .csv so there are no errors in the letters. (I put this in a word file and made it red because that was the only code of mine I couldn't get to work). I'm super new to SAS so i might be overlooking something obvious.
What error message is it throwing?
Your DLM= should specify the delimiter eg: ',' for comma delimited.
I thought I heard my professor say that csv was its own delimiter for csv files, is that not the case? I definitely could have heard him wrong so I'll try that.
This is the error: NOTE: Invalid data for SEQN in line 609 1-38. (same error repeated for every variable) WARNING: Limit set by ERRORS= option reached. Further errors of this type will not be printed. 640 74481,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1 38 NOTE: Invalid data errors for file ''C:\Users\smecham\Desktop\nhanes\SMQ_H.csv'' occurred outside the printed range. NOTE: Increase available buffer lines with the INFILE n= option. SEQN=. SMQ020=. SMD030=. SMQ040=. SMQ050Q=. SMQ050U=. SMD055=. SMD057=. SMQ078=. SMD641=. SMD650=. SMD093=. SMDUPCA=. SMD100BR=74450,,, SMD100FL=. SMD100MN=. SMD100LN=. SMD100TR=. SMD100NI=. SMD100CO=. SMQ621=. SMD630=. SMQ661=. SMQ665A=. SMQ665B=. SMQ665C=. SMQ665D=. SMQ670=. SMQ848=. SMQ852Q=. SMQ852U=. SMAQUEX2=. _ERROR_=1 _N_=20 
It looks like it worked for the first 608 lines of the file. You might browse the file and see what happened in line 609. You could also try reading the file in to Excel to check it out.
Google is your friend for any SAS syntax ... I find the published SAS docs a bit terse, so I usually take the first result that someone has written as a paper or an example from sascommunities. A google of "SAS data DLM" links to a good PDF on the first result. SAS syntax is annoying because each PROC was often written by a different team resulting in slightly different syntax.
try proc import proc import out=work.smq datafile='c:\Users\smecham\Desktop\nhanes\SMQ_H.csv' dbms=csv replace ; getnames=yes; datarow=2; run; That way you pick up the variables from the first row of the CSV file.
Yes probably missing data values and commas at the end of the file. The $ tells SAS that SMD100BR is a character variable. In your log SMD100BR=74450,,, so something to check on there. Also your log shows C:\Users\smecham\Desktop\nhanes\\**SMQH.csv** but your code above says C:\Users\smecham\Desktop\nhanes\\**SMQ_H.csv**
OP was right, delimiter was supposed to be comma! Thanks for your help, both of you!
Unfortunately on my assignment our prof told us to use a data step instead of proc import. But I figured it out, hallelujah. Thanks!
Thanks for your help guys! I appreciate it!
Does that mean you have the formulas for calculating the mortality rate and its variance but don't know how to translate them into SAS code?
Here's an example of another possibility: %let p1=\Long descriptive name1\Long descriptive name2\Long descriptive name3\; %let p2=Long descriptive name4\Long descriptive name5\Long descriptive name6\; %let p3=Long descriptive name7\Long filename here; %let path=&amp;p1&amp;p2&amp;p3; data _test; infile "&amp;path"; input &lt;stuff&gt;; run; 
Hi all, I am trying to build a regression model on a data set using a mix of categorical, non categorical, data. The issue: my output is not showing me what I want to see. Correlation between variables (I included Corr) and I include CL for Confidence limits. Any help would be amazing. I caveat that I am a finance guy messing with statistics. 
where is the ; in the third row ?
I'm not familiar with the terms "cron" or "batch, but just had an idea: Perhaps Cron is being blocked by a firewall as it's trying to modify files. If there's a way to grant write-access to Cron that may be to do with it.
Ah sorry. This is on a unix server (SAS Grid, actually). CRON is a job-scheduler in UNIX. I've got a bunch of other scheduled jobs that work without issue, but this is the only hangup. I'm debating whether I should just modify the program and swap out this macro for an ODS CSV wrapped around PROC PRINT. Would be slower, but it doesn't really matter since this runs at 4 in the morning. 
If you go for that option I can help. That would work I think
you sir...are a genius. I have spent days looking at this and I can't believe I didn't see that. 
Can you use proc export? Something like this: proc export data=misc.gc_access outfile="/apps/sas/TFS/ProductDesign/Public/misc/basefile.csv" dbms=csv replace; run;
I'll test that out overnight. It works without issue in EG, but then again so does the other one. 
Well I am either an idiot or SAS is fortran, maybe both. Cl and corr are suppressed with lasso.
This actually looks more like an issue with how SAS is being invoked, than with the code itself. Can you paste the full command being used to call SAS? Interactive mode requires an x display, which is why I ask. Also, do you have other programs that work in batch mode?
Yeah I'll post the script when I'm back in the office on Monday. I've got 9 other scripts that all work without issue: this is the only one that fails, and it's the only one with this macro. I saw some documentation that says a "-noterminal " line could help me somewhere in the script. Not rally sure where to put that, though. I'll update Monday. 
It is almost ALWAYS a semi colon lmao
If you use the macro numb, you can do 1 to 12. Remember to get rid of the 20170, so you don't get 2017010.
Use -noterminal when you invoke SAS.
Looks like an ODS problem. Try to suppress ODS output (close all) and maybe use proc printto to reroute log output as well. Hope this helps
Yes, that's how I'd do it. But if you only want each record to output once, you need to set a variable after one of the values is found and check it in the do loop -- maybe use a "while" statement. Be sure to reinitialize it before the do loop, as well.
Thank you!
You're welcome!
I would create a macro that contains the values using a proc sql into. If you have a dataset data1 that contains all of these 150 values, and the var name is "value" the syntax to create a macro "vals" is as follows: Proc sql; Select values into: vals separated by " " From data1; Quit; Now you have a macro that is the text of all these values, just call it in your logic statement using if var1 in (&amp;vals.) then ...
To answer your question about whether SAS can work with star schema DBs, the answer is YES. If your data is in Teradata then you can use SAS to pull what you need, as you need it, via SAS/ACCESS to Teradata. When configured properly, SAS will push your join/filter directives to the database appliance and bring back only the results you need for processing in SAS. As to whether star schema is better than what are doing now...probably yes, in terms of database efficiency. But depending on the analytics you need to do in SAS, you might need a process that pulls the data you need to create analytical base tables that help assemble just the fields you need -- at the proper level of detail/aggregation -- to support your analytical and reporting process. You can accomplish that with SAS code or with discipline-specific tools like SAS Data Integration Studio (which can create jobs that you can schedule/monitor). I'm not sure about the one-table-per-month idea. If all of your reporting is bound by a monthly calendar, I guess that's okay. But if you want to work with more arbitrary time spans (like "past 30 days") or forecasts ("next 30 days"), that might be a hindrance. You can always pull/group data at month boundaries later, if needed. I'd prefer to keep all facts in one continuous table. You can use slowly changing dimensions (SCDs, supported easily in SAS DI Studio) to represent the most relevant version of "facts" for the timeframe you're reporting on. You can get more SAS-specific data management guidance from the [SAS Data Management community](https://communities.sas.com/t5/SAS-Data-Management/bd-p/data_management).
PROC EXPORT did successfully create the csv file, so looks like it's all good. 
I ended up switching from the ds2csv macro to a basic PROC EXPORT and that solved the problem. Just following up, though: this is the full command in my script when I call SAS: #!/usr/bin/ksh cd /apps/sas/TFS/Public/adhoc/Access_Numbers /apps/sas/Config/config_dir/sas IBM_host_query_v5.sas rc=$? if [ $rc -ne 0 ] ; then echo "IBM_host_query_v5.sas failed. Return code $rc" | /usr/bin/mailx my.name@company.com exit 1 else echo "IBM_host_query_v5.sas done" | /usr/bin/mailx my.name@company.com fi 
I agree with xmindallas. Use -noterminal. Here's the command we use. Most of the options won't apply to your issue though. sas -autoexec -work /saswork/ -noovp -memsize 6G -sortsize 6G -sumsize 6G -errorabend -unbuflog -noterminal -log log_file.log -sysin sas_program.sas
I posted up above also, but the -noterminal option is what you should add. I'm glad it worked with the proc export though. Also, as a note. A rc of 0 means no errors or warnings. A rc of 1 means no errors, but had warnings. A rc of greater than 1 means that there were errors. In our environment we don't care much about warnings, so we actually consider both a rc of 0 or 1 to be successful. Completely up to you though. Thanks, John
Thanks! I'll make these switches you mentioned here and in your other post.
https://imgur.com/akf4Z2Z
I can't imagine there being a date format for this format. It's just too rare. I would parse the string into three variables and then use the MDY function to concatenate them back into a single date type variable.
You could adapt the approach here: https://stackoverflow.com/questions/9300020/sas-format-full-month-name-to-integer Rearrange the day number, the first 3 characters and the year number using `substr` and then input using `date.`
This should work, try this: DATA want; SET have; month_char = STRIP(SCAN(fiscal_year_ended, 1,'1234567890')); day_char = SUBSTR(STRIP(TRANWRD(fiscal_year_ended, STRIP(month_char), '')), 1, 2); Year_char = SUBSTR(STRIP(TRANWRD(fiscal_year_ended, STRIP(month_char), '')), 3, 4); long_date_char = STRIP(day_char) || SUBSTR(STRIP(month_char), 1, 3) || STRIP(year_char); fiscal_year_ended_new = INPUT(long_date_char, DATE9.); RUN; 
If you have a SAS Profile, these E-Learnings are great SAS Tutorials https://login.sas.com/opensso/UI/Login?realm=/extweb&amp;goto=https%3A%2F%2Fsupport.sas.com%2Fedu%2Fviewmyelearn.html 
Disclaimer: There is almost certainly a better and/or more efficient way of doing this. What I would do is make a separate datastep to a temp tbl that filters your data down. Use the IF statement. &gt; &gt; Data work.outmembermonths; &gt; set mksc2013.outmembermonths; &gt; if YearMo = '201303'; &gt; if Gender = 'Male'; &gt; run; Then your Proc export statement. Your syntax errors could be related to datatypes. Numbers wouldn't have quotes around them, for example. Using a separate datastep with multiple if statements would also produce an error log that points out the lines that are bad. I hope this helps a little.
The where statement you have looks at the records you've read in (which is 1000 at a time) and looks for any that meet the criteria you've specified. If there are no records in the batch of 1000 that you are reading from your input data, the step will not run. I assume this is what you mean by "break". As for your other question, Boolean logic (and, or) can be used when you use if/where statements. The use of these can get a little trick and can require fairly advanced understanding of how SAS processes data. But for the most part, and/or work like you'd expect. 
&gt;Why does it work for some fields and not others Either the variable is misspelled/doesn't exist or you have a numeric field in quotes. 
Just to add on, the comparisons sas is making are case sensitive. This means gender=‘female’ will not pick up ‘Female’ so make sure to spot check the data and make sure you are using proper capitalization (also look into the functions upcase() and lowcase() 
&gt;The where statement you have looks at the records you've read in (which is 1000 at a time) and looks for any that meet the criteria you've specified. If there are no records in the batch of 1000 that you are reading from your input data, the step will not run. I assume this is what you mean by "break". I don't believe that part is true. As long as the records make it to that step (which they will in this case), SAS will keep running through the data step until it finds 1000 that meet the where= criteria. However, it would behave as you described in an if statement in a data step. One caveat -- I have not verified this with a where= statement in proc export. I have had issues with them in the past, so I try to avoid them. Or I could be thinking of using a where statement (as opposed to where=) in proc export.
Proc tabulate don't think so. Proc report maybe. Option to remove page breaks is ods start page option. Startpage= "never" On mobile please excuse formating. 
Thanks! I looked into proc report but couldn't find anything either. 
Conditional highlighting in Proc Report is very doable with a compute block. I don't think Proc Tabulate supports highlighting (though it has a lot of layout options).
You can use formats to conditionally format cells in TABULATE. http://www2.sas.com/proceedings/forum2007/095-2007.pdf 
Sorry I'm on my phone and can't open your link. I'm aware you can format cells, but it doesn't help in my case right? Essentially I need an if statement that says if column A or B are greater than column C then highlight the cell. Easily done with excel... Wondering if possible with sas. 
There's nothing in the link about that. I think you're going to be out of luck. The only way I can think to do it would be to pre-process the data in a data step or using data set output from proc freq or proc tabulate to set an indicator variable when you want that cell to be a certain color. Even then, I don't think it would work in proc tabulate -- maybe proc report. Edit: You could make an adjacent cell in proc report that performs the calculation, and then you could color code that cell. You could also make the text conditional on the value with proc format.
If you can calculate max(A, B)/C in a cell in tabulate you can use the format trick. Sometimes its impossible to do that because tabulate is very limited with how aggregates are calculated.
It seems to me that this is an example of why it's a bad idea to use a comma as a delimiter. Are you sure that isn't the point they're trying to make? I don't know how I'd read that file in as-is, other than maybe reading in the two parts of the salary separately and then multiply the first part by 1000 and add the second part.
I agree - this looks like a typo in the question. Comma delimiters are fine as long as any embedded commas are wrapped in double quotes - e.g. if you change the first line to 123,"Harold Wilson",Acct,01/15/1989,"$78,123" then SAS handles it correctly. If you assume a fixed number of commas in the last field then you can input it as multiple fields, but there is no consistent way of reading this sort of malformed data with a single input statement.
options obs = 1000 is the culprit. Even though you deleted it, it's still active in your session. You can either delete it and start a new session, or run the following prior to resubmitting your code: options obs = max; Once you set your system options, deleting the statement isn't sufficient to reset the option in your current session. 
This.
How are the variables named? 
Start1 end1 start2 end2...end16 - its a flatfile so that is per case. They are in ddmmyy format
I'm not at a SAS computer so I can't do any test coding, but this looks like a job for arrays. data dates; set dates; array starts (*) start:; array ends (*) end:; do index = 1 to dim(starts); do_some_operations with starts(i) and ends(i); end; run;
I'm yet to work with arrays so I am a bit confused by this. Could you elaborate a bit, I do appreciate it.
Arrays are just lists of existing variables. So: `array starts (*) start:;` I am declaring an array named `starts` of an indeterminate number of elements. The variables in the array are exactly `start:`, i.e., variables whose names in the dataset starts with the string "start". `do index = 1 to dim(starts);` Looping through all elements of the array... `do_some_operations with starts(i) and ends(i);` I do some operations, referring to the elements of the array using the index `i`. `starts(1)` is the first variable in the array, `starts(2)` is the second variable, etc. I believe the ordering would depend on the order of the columns in the dataset. So if your dataset is ordered as you typed out a couple of comments above, the array `starts` would consist of the variables `start1`, `start2`, `start3`, ... in that order, and you could refer to each variable via the index `i` in the loop. I'm not 100% clear on what you're trying to accomplish, but from your exponential calculation in the original post, you are probably going to do a double `do` loop over the `start` and `end` arrays.
That makes it a little clearer. I can give a better description of what I am trying to do now that I am at a pc. For the sake of this example let's pretend that it is 3 repeating variables, a start time when a pay period began and an end time, when a pay period ended: - start_1 end_1 start_2 end_2 start_3 end_3 What I am interested in doing is collapsing end dates and the subsequent start date when they are less than 30 days apart: **start_1:**Jan 1 **end_1:**Jan 15 **start_2:**Jan 31 **end_2:**Feb 16 **start_3:**May 1 **end_3:**May 12 This would become: **new_start_1:**Jan 1 **new_end_1:**Feb 16 **new_start_2:**May 1 **new_end_3:**May 12 Obviously there are many different combinations that could need to be collapsed and also the actual dataset has 16 series of start and end dates. Hopefully this clarifies a bit better.
Hm, as I said, I'm not a SAS computer so I can't fiddle around with code, but I think here you would want to declare `starts` and `ends` as I outlined above, and additionally declare `newstarts` and `newends` arrays to reference new, empty variables to do your updating. So you could check if `ends(i)` minus `starts(i-1)` is fewer than 30 days and conditionally write to the new arrays based on that test. 
Okay well I can see how it goes. The array stuff is a bit tricky to me, but I'll give it my best. Thank you
Is this what you had in mind: ░░░░data pay.dates1; ░░░░set pay.dates; ░░░░░░░░array starts (*) start:; ░░░░░░░░array ends (*) end:; ░░░░░░░░array new_starts (*) new_start:; ░░░░░░░░array new_ends (*) new_end:; ░░░░░░░░░░░░do index = 1 to dim(starts); ░░░░░░░░░░░░do index = 1 to dim(ends); ░░░░░░░░░░░░do if (starts(i)-ends(i-1)&lt;30) ░░░░░░░░░░░░░░░░░░░░then starts(i)=new_starts(i) ░░░░░░░░░░░░░░░░░░░░then ends(i+1)=new_ends(i) ░░░░end; ░░░░run; I must confess it gets tricky for me to comprehend the next sets of variables along the line cause it potentially be start_1 and end_7 being updated into new_start_1 and new_end_1
It looks like you did `do index = 1 to `... twice, which is going to cause problems because the two loops are going to overwrite `index`. The outer loop will initialise it to 1, but you loop over all the `ends` in the inner loop, incrementing it eventually to the maximum value. So all the `starts` strictly between 1 and the max will be skipped. To start off, you probably just want to copy `starts(1)` directly into `new_starts(1)`, since that is never overwritten (?). Then you would loop over all `ends(i)` and compare with `starts(i+1)`--this is comparing a given end date with the subsequent start date. I don't know if you also want to collapse start dates more than one index away--if so, you would have to handle that too, somehow. To top it all off, you probably need to keep track of a `new_index` separtely, so you know which of the new variables you populated last. Sorry if I'm not too much help. Getting late into the night and my brain is sorta fried...
Reading what you want, if I was you, I would use the arrays to output explicitly into a 'longer' format. var1name, var1value, v2name,var2value type of thing. Then hold the start date using retain and only change it to the next parameter index(parameter, "start") where end - start &gt;= 30 (or, I'd assume, if _N_ = 1). You can probably do it in one datastep by being real technical about it but it would probably be quicker-written to do it in 2 steps...marking the start dates and then similarly doing the end dates with a retain based off your new start date. First over 30, lock it, output the 'new' start and the new end.
That sounds much more feasible. Could you help me with writing the formula for that? Essentially my data would now be three columns: (id) (start) (end) What I would want to do, within each id, is check if the (observation n+1 start date) - (end date) is &lt;30 or GE 30. If it is GE 30 then (start date) (end date) line is kept and the process is rerun for (observation n+1 start date) by subtracting (observation n+2 start date) - (observation n+1 end date). If it is &lt;30, then (observation start date) and (observation end date n+1) replaces (observation end date). Of course it would need to check each subsequent (start date n+#) - (end date) until it does find one GE 30 and then all data in between would be removed and, for example, your new line might be (observation start date) with the end date that came from (observation end date n+5). How would you do this with the lag function? 
Lag function probably doesn't work well for this. If it's more than 2 steps away then you need another lag. Retain is probably what you want here. I messed with some test data and to be perfectly honest it's not working like I thought it would. I'd probably resort to making it long and then call macros on macros to read in and test each line. Doing that would let you read in data line by line and test, but might be a bit of a headache if you're not used to SAS. %macro test1(data=); /*get your table limits*/ %let id = %sysfunc(open(&amp;data)); %let fNobs = %sysfunc(attrn(&amp;id,NOBS)); %let id = %sysfunc(close(&amp;id)); /*loop your table till the end*/ %do i = 1 %to %fNobs; /*get the line you want to test (and only that line)*/ data current_test; obsnum = &amp;i; set &amp;data point = obsnum; output; stop; run; /*null step to run other macros on that line you just pulled*/ data _null_; /*do tests on current test*/ /*call other testing macro*/ /*call a macro to compile it, lock values with symputs from previous macro*/ run; %end; %mend; Probably not the most helpful answer. I can't think of a time I needed to do anything like this with smashing dates together or I'd give a snippet for it.
This is what someone else had suggested (in longfile format) - what do you think of this: data want; set have (rename=(start=_start end=_end)); /* rename start and end to get them out of the way */ by id; retain start; /* keep new start variable across observations */ format start end date9.; oldend = lag(_end); /* do this before everything else, so lag() is never called conditionally */ if first.id then start = _start; /* initialize */ else do; if _start - oldend &gt; 30 then do; end = oldend; /* take end from previous record */ output; start = _start; /* initialize again */ end; end; if last.id then do; /* cleanup at end of id group */ end = _end; output; end; drop _start _end oldend; /* get rid of old and intermediate variables */ run;
Eh, test it. If it works then it's a lot easier than dealing with macros calling macros. When I was checking it out with test data the retains weren't working quite like I expected and this might clear up that problem. To be fair, I purposefully shy away from retains. I'm in clinical, the only time I use retains is to carry swathes of visit info into another visit in window to gap fill. Finance and date data aren't things I'm super comfortable with, so it wouldn't surprise me to see a more knowledgeable solution than I would have thought of. There's always a lot of different ways to skin the cat in SAS (and most programming). 
First things first, if you click the "formatting help" button then you will notice that Reddit supports Markdown formatting. If you want people to help you, take the time to format your code so that it is more legible. I am not 100% sure of your intent, but it looks like you are confusing a few things. Here is a sample dataset to get started so that we are looking at the same thing: data Visitdate; informat _DATE_E1_C8 _DATE_E1_C10 date9.; format _DATE_E1_C8 _DATE_E1_C10 date9.; input _DATE_E1_C8 _DATE_E1_C10; dataline; 01JAN2000 01FEB2000 01JAN2001 01FEB2001 01JAN2002 . . 01FEB2003 . . ; Now, notice that I am assuming that your date fields are actual SAS dates, not character variable in a date format. This is important because you are testing those fields by comparing them to the numeric missing value ".", but then ScreeningALL is defined as a character value that you are assigning a string to. Despite that, you say that you want the *value* of those variables, so your code an statements are at odds with each other. If we assume that the date fields are actually numeric and you just want to check the values and get the first non missing value, then I think code like this using a SELECT statement is a little clearer than IF/THEN/ELSE. Given those assumptions, something like this will work: data Visitdate2; set Visitdate; format ScreeningALL date9.; select; when (_DATE_E1_C8 ne .) ScreeningALL = _DATE_E1_C8; when (_DATE_E1_C10 ne .) ScreeningALL = _DATE_E1_C10; otherwise ScreeningALL = .; end; run; proc print data=Visitdate2 noobs uniform; var ScreeningALL _DATE_E1_C8 _DATE_E1_C10; run;
You could try: ScreeningAll = COALESCE(DATE_E1_C8, DATE_E1_C10); The COALESCE function means 'use the first of the following variables that are not missing'. You also need to format ScreeningAll. If the value is stored as a numeric sas date you could use: FORMAT ScreeningAll DDMMYY10.; and if it is a date-time you could use: FORMAT ScreenningAll DATETIME20.;
If DOB is a SAS date, it'll want a numeric value. Try changing '7/15/1963' to '15JUL1963'd. The d is important too as it tells SAS to treat the contents of the quotation marks as a date and not a string. Hope that helps!
The "in (1:10)" construction is different from the "&lt;=" one. The "in" operator only includes integers. For example: data bleah; a=1.5; b=0; if a in (1:3) then b=1; run; Gives b=0, because 1.5 is not "in" 1:3. (integers only) Non-intuitive, I know.
That's not "in"'s fault, though, it's colon's fault. You can use in with a list of any sort, like if a in (1, 1.5, 2, 2.7, 3) then b=1; 
Good point, but it's also true that there's no way to make something equivalent to 1&lt;=x&lt;=10 using 'in', right? As the first is continuous, but 'in' will always require a discrete finite list
That is correct, yes. 
I cannot append or union this data because certain files come in with columns as numeric, as opposed to every other file as character. Any idea how I can force all to be formatted as character so I can at least do an input later....
Yes, this is more accurate! Thank you!
You cannot have fewer variables while keeping the same file structure. If you must keep that structure, you will have the same number of variables, but the later ones will have missing values. I suggest instead that you create a new file with one start and end date pair per record. This file will have fewer records for each case with more than 30 days between records of the same case. This code assumes that your dates are SAS dates: data newFile; set yourFile; array starts (*) start: ends (*) end:; case= _n_; * must have a case number because new file has multiple records per case; i= 1; * initialize array index; startDate= starts(1); * first start date; do while (i le hbound(starts)); if i eq lbound(starts) or (starts(i)- startDate) gt 30 then startDate= starts(i); else do until (i eq hbound(starts) or ((starts(i)- startDate) gt 30)); i= 1+ 1; end; endDate= ends(i); output; end; keep case startDate endDate; run; 
You cannot have fewer variables while keeping the same file structure. If you must keep that structure, you will have the same number of variables, but the later ones will have missing values. I suggest instead that you create a new file with one start and end date pair per record. This file will have fewer records for each case with more than 30 days between records of the same case. This code assumes that your dates are SAS dates: data newFile; set yourFile; array starts (*) start: ends (*) end:; case= _n_; * must have a case number because new file has multiple records per case; i= 1; * starts index; do while (i le hbound(starts)); startDate= starts(i); j= i; * ends index; if j lt hbound(starts) then do while ((starts(j+1)- startDate) le 30); j= j+1; end; endDate= ends(j); output; i=j+1; end; keep case startDate endDate; run; 
You can either preprocess the data to ensure consistent types, using Visual Basic in Excel or Python, if you know how to program in those languages. Or, if there are not too many files, manually ensure consistency. Alternatively, it does not look like there is any problem with the import itself--you're only complaining about appending conflicting data types? In that case, you can do intermediate processing in SAS. I would use PROC CONTENTS to extract variable names/types/lengths, and use the PUT()/INPUT() functions to change variable types as needed.
Yes this was my thought. I tried a macro and proc sql to input all variables as numeric. However, that input fails because some of the data tables are already numeric. I ended up using an infile on each csv. and informat and format to get the result I wanted. But that requires 31 infiles. Because I haven't figured out how to &amp;I within quotes (in the unfurl) 
https://communities.sas.com/t5/SAS-Procedures/PROC-IMPORT-EXPORT-forcing-column-to-be-character-or-numeric/td-p/132678
I had no idea about DBDSOPTS -- this is great
I don't have access to SAS during the weekend, but I would try this: data employ; infile 'c:\books\learning\employee.csv' dsd line=myline col=mycol; informat ID $3. Name $20. Depart $8. DateHire mmddyy10.; input ID Name Depart DateHire; infile 'c:\books\learning\employee.csv'; input #myline @mycol Salary comma8.; format DateHire date9.; run; 
Hmm, that doesn't seem to have worked :( Do you know what else it could be? The program just seems to never stop running, whether I write it the original way or your way
How big is your SAS dataset? Excel isn't great for big (10,000+ observation) datasets. Just to check syntax, try putting in data work.outclaims; set mksc2013.outclaims(where HCPCS='99396' and DOB='15JUL1963'd); if _N_ ge 100 then stop; run; proc export data=work.outclaims (where=(HCPCS='99396' and DOB='15JUL1963'd)) dbms=xlsx outfile="Desktop\outclaims.xlsx" replace; run; The first bit is just to create a 100-observation dataset which mimics your full one. If it runs, the syntax is sound and it'll probably be because you've got more data than Excel can handle effectively.
It's pretty huge, over a million files I think, but I have "Obs = 1000" to be able to run tests, and those usually run in under 5 minutes. Even when I run it at Obs=1000000, it only takes about 10 hours to run - this took the whole weekend and was still running Monday morning, and the file it was creating wasn't updating every second like it usually does, so I knew something was wrong. Hmmm, interesting. When I added in your code and ran it the first time it seemed to work. Then I made a slight change and ran it again, and this time it didn't work, and I get the additional warning "Data set WORK.OUTCLAIMS was not replaced because this step was stopped." I wonder what's going on with that
Sorry I didn't catch the Reddit auto format. That N should have an underscore either side of it. Not sure how to put literals in Reddit but it'll be underscore-N-underscore = 100
Ah, I got it to work! Interesting, so what does your addition do exactly, what is this "If N ge 100 then stop" doing?
There's a little theory behind it, but it's basically saying process 100 lines then give up and output them to the output dataset
Hi, I'm looking for a way to add a selection/drop down specifically to 'Crosstab 1' so that the users can narrow down displayed results. Is this possible? Thank you!
Drag it into the report pane rather than the section/report filters area, and then define an interaction just to the crosstab. 
I suspect one or both variables are character format and not numeric.
I also had trouble with this. And my variables were both numeric. Would there be another reason I would receive a warning or empty output like this? 
/u/Calach_ OH! Thank you, I was missing that Interaction component. Is there a way to move that drop down list in to the same pane as crosstab1 since I only want the interaction on crosstab1. The drop down list outside of the stack container is misleading because it appears as though you can filter the other tabs: 'Headcount', 'Open Reqs', etc.
Strange, please do post a summary of your data with a proc means output.
Both of my values are numeric, could it be anything else?
It's hard to say without seeing your code and at least the description of your variables. If you're using a by and class statement, then missing data can throw SAS off.
Unfortunately not. Stack containers can only show 1 object at a given time. 
Thank you very much. :) I come from heavy MicroStrategy dashboarding experience so I tend to gravitate towards those concepts. Could you tell me if I can complete the following in SAS VA? Within one container, have a button bar broken up into 4 parts (let's call it crosstab1-4). When I select a button on the bar I want it to display a specific crosstab. Button 1 displays crosstab1, button 2 displays crosstab2, etc. However, on button 3 I want to display a crosstab but also would like a list in that same 'pane'. Basically, I am interested in having the illusion of a stack container but still be able to add other components in there. We found that we cannot add a list/drop down list in stack container to just drive one crosstab only. When other objects in the stack container are selected we want the list/drop down list to disappear as well. I hope this makes sense.
Interested in the answers to this. I work for a large UK bank and use sas in my day job. Is it worthwhile doing the qualification in the first place? 
I read the SAS study guide. Then using their Content Guide, read through again and filled in the Content Guide with HOW to do each task/skill. I also used 2 videos on Udemy (SAS Programming on Data Manipulation and Preparation by Cheng) which I found super helpful. They're set up like my favorite type of lecture: she presents a concept, explains it and then shows it in use. Also, Practice! 
Is there any point doing the exam if you use sas coding all day everyday in your job? As far as I can tell nobody seems to care if you have it or not. 
I got a large raise for going and getting mine. My boss literally asked me to get it so I did. Company paid for the test. My job didn't change it all but I got a nice jump in pay.
That's my problem, nobody seems to care where I work. Do you feel like it improved your knowledge of sas, statistics or overall coding ability? 
No, it definitely didn't. It was pretty much a matter of memorizing syntax for a couple things I never use/need. I already knew everything else. Then I went to study for the advanced one and it was pretty much a book written 80% on proc sql and temporary views. I have zero need to know anything about that at this time so I didn't follow further into the path. Maybe one day...if someone asks...no one's asking though.
In my experience, there is actually a negative correlation between competence and SAS certificates. I become suspicious of candidates that have them. 
Currently studying SAS at Uni and I haven't worked in an industry using SAS, that's why I'm doing this certificate :P
I'm also really interested in this; hope someone comes along with an answer!
check out https://sasensei.com - the questions aren't certification specific (yet) but will give you a flavour of what's to come
The smallest 'length' an number can have is 3 bytes, capable of representing integers up to 8192. If you try to sum a number (eg PROC SUMMARY) and the sum exceeds the maximum representable number for the given length, results will be incorrect. 
Where were you at 8:30AM?
Base certification book. https://onlinecourses.science.psu.edu/stat480/ 481 &amp; 482. 
For me, it is one of the tie breakers if everything else is equal, but it's way down the list of tie breakers. I'd much rather have someone who has experience using SAS in an applied setting over someone who has a certificate. So as a college student, what would be more important is that if you worked with a professor who has you write SAS code for a research project.
If you want to try to save space by adjusting lengths of numeric variables, print this out: https://v8doc.sas.com/sashtml/unixc/z0344718.htm. Or just don't do it, because space is cheap nowadays.
There is an dbdsopts= option in proc import that helps with this. [There's an old thread about it here.](https://communities.sas.com/t5/SAS-Procedures/PROC-IMPORT-EXPORT-forcing-column-to-be-character-or-numeric/td-p/132678) I haven't tried it myself, usually guessingrows=max is good enough, and I can fix the few variables that are the wrong format.
Ooh thanks. I wondered whether there was a way to tweak things in PROC IMPORT. I'll give it a go.
My route would be to import each dataset and standardize the variable types/formats individually. Sounds like a pain but I don't think it would take you too long once you have the basics. Also just to be clear you are attempting to append these, not merge them, correct?
Yes, append, then sort by arrival time in the ER.
Macro that shiz and throw in a proc append to stack em all.
This idea came to me in a nightmare, actually. I woke up in a terror-drenched sweat. I attempted it but only managed to eke out a pile of bad macro code.
Once you have a job probably not. But I think it can help weed you through the slush pile if you're applying for jobs where SAS experience is required. I'm actually interviewing people right now for a very SAS heavy position and those that have Base certification stand out to me more than the resumes that just say they have used SAS before. **But,** you can't use the certification as an excuse to be lazy on your resume. My biggest pet peeve weeding through applications is that people will claim they use SAS/R/SQL/etc but don't give any kind of examples to hint to me their competency. So it's better to have a line like "Using SAS, was able to analyze XYZ doing ABC and got Final Result" or something like that as opposed to just having a line on the resume that says "4 years experience SAS" and then having nothing to back it up. 
I put the code together and got this warning: WARNING: The quoted string currently being processed has become more than 262 characters long. You might have unbalanced quotation marks. Here is my log with code and warning. 1380 PROC IMPORT OUT= WORK.lean11 1381 DATAFILE= "S:\2016.4 Detailed.xlsx" 1382 DBMS=EXCEL REPLACE; 1383 DBDSOPTS= "DBTYPE=( 1384 Name ='Char(40)' 1385 Arrival ='Num(8)' 1386 Depart ='Num(8)' 1387 AOCLast ='Char(5)' 1388 Disposition ='Char(40)' WARNING: The quoted string currently being processed has become more than 262 characters long. You might have unbalanced quotation marks. 1389 Age ='Char(9)' 
I find I have more control using INFILE in the DATA step, rather than IMPORT. For this particular problem, going about it this way will let you specify through INPUT and PUT which variables will be numeric or character. You can also use where clauses and such to filter the data before even loading it, which is quite helpful. These problems though are honestly why I’d use Python or R over SAS any day. They say SAS is a good program to use to wrangle data... it is not a good program to wrangle data.
What version of SAS are you using? Check out: [idea1](https://communities.sas.com/t5/Base-SAS-Programming/Using-PROC-IMPORT-to-Specify-Variable-Types-and-Formats/td-p/353268) or [idea2](https://communities.sas.com/t5/SAS-Procedures/Using-PROC-IMPORT-and-define-field-names-and-variable-types/td-p/202953)
If they're all the same, you only have to write the code once to fix the in port and then macro it around however many times. 
So I don't know much about SQL itself but there's sql in SAS itself and it just isn't able to do certain things that Base SAS (or even more so SAS in general and all of it's extensions) can. That being said I'll at least try to give you an idea of how powerful a tool SAS can be For example, in SAS you can transpose data relatively easily with arrays or even a transpose procedure. You can use macros within it. You can easily access different types of data and/or read in raw data. It has very powerful reporting tools that allow you to customise the reports or the graphs you want. It can process large amounts of data really quickly. There's a reason for why it is so expensive however there is a free university edition or you could get Enterprise Guide which is a cheaper alternative (point and click way of coding). If you're struggling to learn SAS there are some great video tutorials out there. I am learning SAS right now (almost done with my course) and I amazed with it's capabilities so far! I struggled tenfold with learning Java
I had the same issue - I'm a db guy than walked into a SAS job. The best question to answer is (and this seems dumb) what are you going to do with it? Are you expected to be a statistics guy, or are you just putting things into a basic format that the BI people can use? If it's the former, SAS will get you there easier once you get beyond the basic sums/averages/etc.. If you're just pulling and formatting data for BI people, look at PROC SQL in SAS - that command is an ANSI-compliant SQL engine that can do many of the basic operations that SAS does (and some that it can't). If you go that route, you can use SQL inside of SAS and gradually pick up the syntax as you go. SAS will let you do some great stuff when paired with a DB. For example, you can download a result set and save it locally to work on the data rather than having to task the database with extraction each time. And with PROC SQL, you can still query it when it's a local file. I think the toughest part of learning any language is to internalize the syntax so you don't have to look everything up all the time, and it's tougher to find that motivation when you already know the ins and outs of other languages. To me, they solve different problems - SQL is about CRUD operations and (normally) relatively simple analysis, and SAS is for heavier duty statistical operations. Your mileage may vary.
Figured it out. Had to chop the DBDSOPTS block into multiple DBDSOPTS.
I'm writing a macro to repeat PROC APPEND 21 times. Let's see how this goes...
Think of SAS as a complement to SQL Server database. SAS can actually communicate directly with database via direct pass through queries or indirectly through SAS libraries (pointers to database containers) Learning SAS is pretty simple since you already know SQL. You can run Proc SQL commands that let you carry out sql commands on SAS datasets )tables). SAS’s power is that it can help build automation via macros. You can schedule jobs and automate report generation. I generally use SAS for automation , importing/processing files and building reports. I use the database primarily for quick advice pulls and lookups. 
One use case that is sometimes worthwhile is setting date variables to length 4. Datetimes still need to be length 8 though.
Say you have a list (50,000 rows) of annual incomes of loan applicants from different states. Assuming you want to find the average income per state, would you do it using proc sql/proc means in SAS or pivot the data in excel? 
My preference - if I present data to business users I throw into a pivot table in excel. Just easier to manipulate. 
I would agree. I downloaded sample mortgage data and have been answering similar questions to practice. I'm interested in business analytics and data visualization, my background is MIS. What sorts of day to day SAS tasks would you suggest I have down pat?
For reporting: Understanding how to import from a variety of data sources, data cleansing (you will spend about 80% time doing this), summarizing the data, create report and presenting your findings by telling a compelling story. For advanced analytics, If you are looking to forecast or make predictions you will have to understand stats modelling. 
All of the SQL you can write in your SQL SERVER DB can be written in the SQL SERVER dialect (and executed on the database) within proc SQL (using a pass through) else you can use the standard proc SQL syntax and take advantage of SAS functions within your SELECT statement. That's all just one procedure in SAS and there are many procedures. 
Yes, setting dates to 4 is pretty safe for the time being.
I'm assuming you have the data sets named something with a suffix you can iterate on, i.e. dataset1 - dataset22. Step 1 - create your base table. This will have all the columns/formats of the columns you want but no observations. I will refer to this as "base" in the code down below. Step 2 - write your macro. This will change slightly depending on the specifics of what you're doing, but I'm guessing it will look something like this: %macro macroname; %do i=1 %to 22; proc append base=base data=dataset&amp;i; run; %end; %mend; On the first pass, the empty data set BASE gets overwritten by the contents of dataset1. Then on the 2-22nd iteration, the append procedure tacks on the data sets as you'd expect. If you're at all worried about columns not matching (which I highly recommend you clean up before you append), you can add the FORCE option to the proc append. But again, I'd recommend against this. Hope this helps. 
If you run all code upto the proc freq, do you get no error and all runs as it should, with dataset a outputting correctly? 
Yes, the only issue is with the output of proc freq. 
Does it underline the problematic where clause in the log output?
Are you using any ODS statements or anything funky to control how the output of your procedures is getting printed in the results viewer? 
No it does not
No, I’m not. In my preferences, it’s just directed to HMTL in the internal browser. 
Proc freq data=a; Table b*c / list missing; Run; 
Is the a data set a view by chance,
How about if you output dataset a to a permanent location, ie library.a then open up a completely new sas session and run the proc freq in there? 
Fyi, that's just a dumb 'warning' telling you the quoted string is more than 262 characters, which happens because you have a quoted string that is more than 262 characters. There's nothing inherently wrong with long strings, it's just the parser thinking it looks kind of long and guessing maybe you could have unbalanced quotation marks and throwing a warning. You can turn off that warning with the statement options noquotelenmax;
Why do you use two ampersands before dsn? I assume that's text and not a variable.
You have to add one more period so SAS knows correctly what the macro variable it needs to resolve. Use this: DATA&amp;YEAR..&amp;&amp;DSN&amp;I..MST_TBL Note that there are now two periods following &amp;I :)
OP is doing something like this: http://www2.sas.com/proceedings/sugi22/CODERS/PAPER77.PDF
Use colon modifier for all of the text variables in the input statement: ... input ID :$3. Name :$20. Depart :$8. DateHire mmddyy10. Salary dollar8. ; format DateHire mmddyy10.; format Salary dollar8.; ...
Wouldn't you use proc glm or proc reg? 
If I understand you correctly, you create 84 variables? Wouldn't two be enough? I would define the individual data variables as month (1 to 12) and type (1 to 7). I would then create a table of frequencies by month and type, copy it to Excel and create a chart with 7 frequency lines with month as the horizontal axis. Not a fancy Sankey diagram, but doesn't this do the same job?
As bad as this sounds, there's a test answer bank out there that has about 30-40 questions that will be on the actual exam, so memorizing the test bank and then some logic for how nitpicky SAS can be is how about most my peers passed the exam. 
This is really very easy. You should think a little bit before you say you have no clue. I'm not gonna write you your program because for one, I'm on phone and mostly importantly you should try this yourself. But here is something to get you started. Since this is a comma separated file, use list input method with DLM option. Use sequential names for your numeric variables. DAY1, DAY2,...,DAY100 in your input statement. STD function is what you are looking for. The standard deviation.. STD(DAY1,DAY2,...,DAY100)... Instead of typing the 100 variables, use a variable list preceded by OF. This can be done in a single DATA step. Let me know if you need more help. Good luck!
And you can easily do the categories with a proc format.
Your Enterprise Guide sessions should be distinct. 
Are you running something else that's resource-intensive on the same machine when your SAS job runs? It might be that SAS is only getting to make use of the CPU a fraction of the time, and another program is stealing lots of CPU cycles.
This may not be your problem, but I've noticed that Real Time can be much greater than CPU time when you need to read/write large datasets. The hard drive / network activity of reading/writing the file can be more intensive than the actual PROC you're running. Dropping non-relevant variables from your working temporary dataset might help. Also OPTIONS COMPRESS=BINARY; (compressing your datasets) can help.
Yes, that is true. You can confirm by right clicking the "WORK" library under "Server List" and selecting "Properties." The Path should be different for the two EG sessions.
Dataflux is data quality and data management software. https://www.sas.com/store/books/categories/usage-and-reference/practical-time-series-analysis-using-sas-/prodBK_63980_en.html 
THANK YOU. My current project requires a butt load of indicator variables, and this will likely cut my code in half when I get there.
I have seen high real time with low CPU time when you push code to run in database with the SAS In Database code Accelerator. although usually the CPU time is much smaller than the 5:10 OP is seeing, usually the few seconds it takes to send all the instructions to the DB.
Seconding this - SAS is almost always bottlenecked by I/O rather than CPU limitations, unless you're working with a file small enough to fit completely in cache or some other sort of high-speed storage.
It should be underscore-n-underscore if you want the step to stop after x records, unless you're counting N some other way. 
You can tell OP meant to type underscore N underscore since the N is italicized in the post.
Yes, sessions are distinct, but two programs within a single session are not. 
Focus more on SAS server administration or data management if you're not into stats. Also, it might be worth paying for the web courses or looking for free tutorials online.
If you create a free account on the sas website there are a bunch of videos they made. I personally feel it helps to learn if you’re using it hands on vs reading from a book. 
If your data looks like '8:00 PM', then use time8. informat. If it looks like '8PM' or '8 PM' or '8AM', read it as text, compress, use tranwrd function to replace 'P' with ' :00 P'. Note the space before colon. That's why it's important to compress before. Do the same for 'A'. Change to ' :00 A'. Then use input function on the modified character with time8. informat and store the numeric value in a separate variable which you can use for sorting. You can use a time8. format on the newly created variable for better readability.
What exam are you trying to take, basic SAS programming or statistics? If you're focused on the programming side, just jump in and start experimenting. That's the quickest way to learn.
As you said ... It depends. Rule of thumb: pack as much as you can in one step. If you do joins or filter+sort, then use SQL. You can't easily combine two tables using data step when join conditions between tables differ. Use data step for classification (and ensure that every row is classified), nested ifs, read one table and write to many, running data quality during import to staging and all of those you can do using one step. If you have a simple join like a value lookup, you can use data step with formats (key value pair) or hash objects if a table is huge. Everything said are my experiences/use cases. For the mentioned example, did you index the tables properly? How about using where clause in dataset options? 
Thanks. That clears up a lot for me.
Forget SAS and learn R or Python instead. I only use SAS because I absolutely have to at work. Python and R have a much better career outlook and when you get more advanced they can frankly do more than SAS anyway. 
I personally use data steps when I want to edit my table on a row by row basis, and SQL when I want to change the table as a whole. e.g. joins and large filters with SQL, then simple transformations and more complex if-then-else statements in data step. For the problem you shared, have you tried splitting the above into multiple SQL steps, I had a similar experience before joining 3 datasets of around 60 million rows, but splitting each join into its own proc SQL step cut run time down by 1/3. Experiment with various different techniques, until you have something that you are happy with.
The other way to avoid sorting is using a hash merge within a data step, I generally use this method when only taking a few variables from another dataset to add to the main one. 
If your datasets are already sorted by the join key, make sure you use the `sortedby` data set option, otherwise proc sql will assume that they're not sorted and sort them again, slowing things down. You can check whether this is happening by using the `_method` and `_tree` options in the proc sql statement to display the query plan in the log. There are a few advantages of using data steps: * Arrays * It's much easier to implement logic that depends on the row order of your dataset, particularly if you want to refer back to previous rows. * When merging datasets in a data step, worst-case performance is O(m+n), vs O(m*n) for proc sql if you accidentally trigger a cartesian join. * If you want to manipulate or import external files, create output files, or execute OS commands, proc sql does not have that capability, but data steps do.
Did you mean to say 'you can't easily combine *more than* two tables with different join conditions using a data step'? I would agree that proc sql lets you do this with much more concise syntax, but this is sometimes at the expense of performance. The query planner is very conservative about memory usage and tends to shy away from hash joins except for really tiny tables, which leads to a lot of unnecessary sorting.
You'll find you can do the same things in data steps that you can do in proc sql and vice versa. You'll have to just find out what you're comfortable with. I don't think I've ever joined tables using a data step. I learned SQL first and have refused to use data steps for joining since I learned SAS. I use data steps when I want to work on rows. I like to structure my data horizontally: loan_id|bal_1|bal_2|...|bal_40|loss_1|...|loss_40 So I just use a data step if I want to work on arrays like that. But in proc sql it's still possible to work on that way by leveraging SAS macros to create %do loops in the middle of your proc sql to work with those arrays. Just a little more clumsy. Proc Sql has the added benefit of being so easy to sum down columns and grouping. I prefer proc sql over some of the other sas procs for sums, counts, and weighted averages. I also frequently reference the dictionary tables to get and store variable names into macro variable(s), which is easy with sql. You can blend proc sql and data set options: select tb1.a, tb1.b, tb2.c, tb2.oldname, tb1.newname from mydata (where=(b&gt;100) rename=(oldname=newname) drop=...) as tb1 inner join mydata2 as tb2... Data steps can be very powerful too - some people can do a lot with data steps. Like if you wanted to break up data easily then in a data step you can output based on certain conditions to multiple tables in one step. You can use lags. Thousands of other things that no one could possibly list here. But I'd say if I had to choose just one I'd choose proc sql.
Really? I thought SAS was used by 70% of companies around the world and is the most used software. 
Please elaborate!
Basic SAS I suppose. For the software analysis side of things. Im good with computers and do music production, also have a degree in business and figured it would be a good blend of things. 
I imagine this isn't cheap, but if you're trying to get into the SAS/big data world it might be worth exploring : [SAS Data Science](https://www.sas.com/en_us/certification/credentials/advanced-analytics/data-scientist.html#par_styledcontainer_6a95)
Great answer! To add to this, I basically ask myself, "am I working across rows or inside rows?" Across is SQL, within is data. Or if I need to retain a variable, data step. Not all encompassing, but a good rule of thumb.
I'd recommend that you just download the University Edition and start playing with it. As others have said, there are lots of online resources to get you started. If you're curious about something, just try it. You won't break anything. Good luck!
I'd never discourage you from learning anything (even R and Python), but it's foolish to say that there aren't opportunities in SAS. There have always been people (especially IT people) bashing SAS, but it continues to be a very popular, powerful solution.
Yes, I meant more than 2 tables. The example query has 4. If properly indexed, it should work decently. Typing all this from phone... 
&gt;Did you mean to say 'you can't easily combine more than two tables with different join conditions using a data step'? That would be a true statement. When you get into hash joins, you're way beyond easy. Of course it's possible, but it's way easier to write a proc sql step. And unless you're trying to ensure your own indispensability (which ultimately won't work anyway), your code will be impossible for 90% of people to understand. 
The one thing that usually makes me choose proc sql is when I want the Cartesian product of two tables. The data step is usually the wrong tool when multiple data sets have duplicates on the join key.
There are lots of resources yes, just looking for the most learning friendly ones
I'd recommend the SAS Online Documentation. Just browsing through informationon the data step, functions, and formats would give you a really good start. Then I would start going through the procs, starting with proc print, proc freq, and proc means; and then moving to proc tabulate and proc report.
You can change the column in Excel to text, or you can convert the variable to a string in SAS after loading it from Excel. It would be something like: charvar = put(numvar, z10.);
Not many of us are running university edition, would you maybe post which is the error you're getting in the log so we can understand if it is related with the code or a missing functionality in your system?
 ERROR: Procedure GPLOT not found. ERROR 180-322: Statement is not valid or it is used out of proper order. (5 times, referring to the SYMBOLx commands).
If you want to test yourself on SAS skills you can use https://sasensei.com. It's a great way to learn SAS as well..
it's probably related with your sas version. Can I have the complete sports dataset (datalines input) in order to run your code with my machine?
Not sure if this applies to you, but the way the data is accessed and stored also makes a difference in whether or not Proc sql will run faster. So for example, if your data is stored sing regular ol *.sas7bdat files then I have found that proc sql will sometimes save you time over the data step on big complex joins, batch calculated fields, sorting etc. However, if you store your tables in an actual sql database and do stuff like indexing and what not, then I find that proc sql can cut processing time in half especially when joining more than two tables or when you're using subqueries or whatever.
I'm not perfectly sure of some pieces of your code: &gt; I am attempting to generate 100 data sets with these assumptions you are working on a single dataset creation (with name *one*), which will have one record for each iteration of the deepest do loop, so 100*3*7=2100 observations. &gt;"Illegal reference to the array trtvar." for sure you are getting this error, an array is a simple container of values, hence when you are multiplying by trtvar you should reference in which position of the trtvar array you want to find your value, e.g. trtvar[1] will look at the physical variable vartrt1, initialised as numeric with value 1. My suggestion for you is to think a bit, and then write here, which should be a dummy structure of your dataset. Then I'll be able to help you out with some code. Also, please remember to format the code properly, the asterisk of the array unknown dimension is translated with italic font on reddit.
rsubmit will run the code after it until it finds endsubmit on the host your code signs on to. The documentation is here: http://documentation.sas.com/?docsetId=connref&amp;docsetTarget=p1eyablk3vvdlkn1h5euyczvt585.htm&amp;docsetVersion=9.4&amp;locale=en
You need a SAS/GRAPH license which I suppose isn't included in SAS University Edition. You may be able to use PROC SGPLOT instead. 
You have a PM
I'm not sure it's suitable for time series analysis, it's Data Quality software..
Review of the event - https://www.linkedin.com/pulse/sas-london-user-group-allan-bowe 
It looks like you've been recommended a lot of great resources to learn SAS. If you're new, for a one stop shop on where to find it all this link http://support.sas.com/training/us/sp1.html may help. It has links to the 200+ tutorials, Ask the Experts Webinar series, University Edition download as well as recommended Learning Paths based on job role: http://support.sas.com/training/us/paths/ The Academy for Data Science option mentioned is also available on that link. The SAS Communities is a great place to post programming / content related questions if you have any: https://communities.sas.com/t5/Learn-SAS/ct-p/learn and for the recent Money and Payscale.com article on SAS skills, this may be of interest: https://blogs.sas.com/content/sascom/2016/05/19/need-a-job-in-todays-job-market-learn-sas/ 
You can use views to pre-define any and sub-queries your SQL step is doing to avoid reading and writing the dataset 5 times. An example: proc sql ; create view trp_2 as select a.SKU, a.Date, sum(b.u_spend) as Spend_90, count(distinct b.date as N_rec90), calculated spend_90 / calculated N_rec90 as Mean90 from trp_1 as a left join trp_1 as b on a.SKU = b.SKU and a.date &gt;= b.date &gt;= a.date - 89 group by a.SKU, a.date ; create view trp_3 as select a.SKU, a.Date, sum(b.u_spend) as Spend_30, count(distinct b.date as N_rec30), calculated spend_30 / calculated N_rec30 as Mean30 from trp_1 as a left join trp_1 as b on a.SKU = b.SKU and a.date &gt;= b.date &gt;= a.date - 29 group by a.SKU, a.date ; create table trp_4 as select * from trp_2 as a left join trp_3 as b on a.SKU = b.SKU and a.date = b.date ; quit ; That code above calculates 30 and 90 day moving averages for spend against SKUs.
It's difficult to tell if your smaller queries are correct without having a look at the original query. You may want to check your join conditions and see if they make sense. Did your results from both the methods match? You've got 4 tables with around 10 million rows in each. If these are sas datasets, then it shouldn't take long as sas can process these without breaking a sweat. If these are external database tables sitting in a different server, I'd suggest sql passthrough instead of using libname method. What about your cpu/real time? How do they look?
Did any of you guys to the SAS UK forum in Birmingham a few weeks ago? 
Im sure the Original (one Program, several joins, one proc sql) and the current (several program, limit up to 1 join, one proc sql per program) are the same output. I created the later using the former. The Join criteria's are all the same as well. As for real time / cpu time, the former would be over 3 hours real and cpu time (i cant actually remember because the execution never finished) The later has no particular pattern, ill try to relay this information so you can understand. I should mention that I altered the later project with a PROGRAM that GROUP BY and turn the 21 million records to about 100,000 to join to a small table of 1000 records (i felt this was a good way to 'save time') but I am convinced this wasnt the reason why the process isnt hanging anymore. RT,CT; lets call this TB1 4:22.00,1:47.00; INNER JOIN 2 tables, both of 22 million records ea Lets call this TB2 1:59.00,1:02.00; Select concatenated Vars from 1 table Lets call this TB3 2:15.00, 38.53; Select * from (select max from tb1) inner join (select distinct from tb2) 9:33.00, 12:19.00; Select *various vars* from TB1 left join tb2, left join tb3 on some criteria such that i should probably just use an inner join. 1:45.00; 4:06.00; GROUP everything from previous program 0.44,0.09; select * from the previous program left join small 2000 row table. 
How can we help you with these few information? Please, post: 1- what the log is telling you 2- the xlsx file - if you are allowed to share it 3- some info about the file - if you are not allowed to share it I would suggest you to give a try with the libname rather than the proc import which helped me more than once.
Thanks for the feedback. I hope I have provided sufficient information now. Boardgameguy123
Which SAS version are you using? Is this xlsx file available somewhere? How long are the variable names? 
NOTE: Copyright (c) 2002-2012 by SAS Institute Inc., Cary, NC, USA. NOTE: SAS (r) Proprietary Software 9.4 (TS1M4) Licensed to BRD OF REGENTS-NV SYS OF HIGHER ED - T&amp;R, Site 70206917. NOTE: This session is executing on the X64_SR12R2 platform. No, unfortunately not. I created it. The variables listed are: Date Year TotalAdmissions CVTotal CVChild CVAdult CVElder RESTotal ResChild RESAdult RESElder OtherAdmissions MaxTemp MinTemp AvgTemp Precipitation Snowfall SnowDepth CoolingDegree HeatingDegree GrowingDegree AirQuality PopulationSize County AirNumber AirContent Weekday DummyHeat390 DummyHeat395 DummyHeat397 DummyHeat399 DummyHeat490 DummyHeat495 DummyHeat497 DummyHeat499 DummyHeat590 DummyHeat595 DummyHeat597 DummyHeat599 DummyHeat690 DummyHeat695 DummyHeat697 DummyHeat699 DummyHeat790 DummyHeat795 DummyHeat797 DummyHeat799 isWeekend isWeekday 
let's proceed with some debug. please try adding the following to the proc import: datarow=2; getnames=no; Trying to exclude invalid variable names here.
Unfortunately, still only getting the first 24 columns of the 49 total columns. 
please try with the libname libname xxx xlsx 'Yourfilepath.xlsx'; and look at the libname you have created. Then kill the libname with libname xxx clear; Also, please try to create a clone of your dataset, leave only 1 record, remove all the other records, and try to import it. Also, please make sure that with this latest import you don't have missing data in all the variables.
You could try specifying the range you want to import as part of the sheet option in proc import (ex. sheet = 'Clark$A1:AW100). I also typically run PROC CONTENTS after importing a dataset to confirm that everything is named correctly and is in the correct format.
Hmm still looks like it is an issue. Is there a way I can send you a part of the excel file?
Sure, just upload it on whatever cloud platform (mega? wetransfer?)
When I tried this statement: proc import datafile = '\\tsclient\F\Graduate Thesis\EDdata2.XLSX' dbms = XLSX replace out = clark; /*sheet = "Clark";*/ sheet = 'Clark$A1:CW4000'; run; It unfortunately, said it couldn't find sheet in spreadsheet.
https://we.tl/brRbDsOHNS
It should look something like this (with only 1 sheet statement): proc import out = clark datafile = '\tsclient\F\Graduate Thesis\EDdata2.xlsx' dbms = xlsx replace; get names = yes; sheet = 'Clark$A1:CW4000'; run; proc contents data = clark; Looking at the range you want to import, there could very well be a limit to the amount of data proc import is able to read in from an Excel file.
Oddly, it keeps giving me the following error. ERROR: File WORK.CLARK.DATA does not exist. 
Import works for me. filename yyy '//FILEPATH/EDdata2Post.xlsx'; proc import datafile = yyy dbms = XLSX out = clark replace; sheet = "Clark"; run; https://imgur.com/a/pszsh Please note that some variables were imported as text, please copy paste the column format on excel from the numeric, it should work. 
Where do I put the column format at? Just in the first column of my excel data?
You should use the excel tool, but this is not the solution. I mean, I didn't do it but import still works anyway. What I can see is that some variables were imported as text, therefore I would say that something odd is happening in your excel file. Are you sure, as an example, that there aren't strange values in the variables? I'll give a deeper look at home in a pair of hours and will let you know.
I am not sure. It is still not working on my end. The only strings/character columns should be the air quality, county, and aircontent. I am trying to run my code, and print out my results, but it again just says the dummyheat variables don't exist in the file. I will be unavailable most of today, but I will try to get back and figure it out. I have the code necessary to run as well, but am unsure if it will work.
Hmm. It still isn't working for me. Do I need to convert the format as you are saying? I am just not sure why it won't work on my computer. 
Use cURL for the initial download - it is much more capable than SAS.
I did something similar in R without an API key, just have to be patient... Write a program that loops through your API calls, and at every 2500 calls, wait 24 hours. Then continue for the next 2500 calls, and so on.
Did it still work for you with the different system? 
Google API rate limits you to 2500, even with a free tier API key. Though that doesn't look like an error for their rate limit. What does your request URL look like? It should look like this: https://maps.googleapis.com/maps/api/geocode/json?address=1600+Amphitheatre+Parkway,+Mountain+View,+CA&amp;key=YOUR_API_KEY 
yep - except that i'm requesting xml, so it's xml?address= have you been able to execute that without error? i.e. using a key and httpS:/ 
ahhk - yes i can do it without the key and over http: rather than https:/, but am trying to solve for more daily calls and with key. 
cheers - ive seen this mentioned in a couple of the sug papers - i'll have a look today. 
All my requests URLs + key are HTTPS. Seems to work fine. Removing the "S" actually gives me a request denial status. 'error_message': 'Requests to this API must be over SSL. Load the API with "https://" instead of "http://".' Are you sure your request URL to the API is correct and you are not just using a general web URL? 
Hi Just to let you know that I have it on my schedule for losing time during the weekend. Busy days lately. Let me know if you've already fixed.
Oh my gosh. My apologies, I am so so sorry. I appreciate all of your help. I am just trying to run a poisson régression analysis on the data and since I am not really proficient in SAS I have been quite frustrated. Again appreciate all of your help and feedback. Boardgameguy123 
filename xxx "&amp;filepath.\Crimes_-_2001_to_present.csv"; proc import datafile=xxx out=mydata dbms=csv replace; getnames=yes; delimiter=';'; guessingrows=10000; run; data MyData01; set MyData(rename=(Date=Datetime)); date=datepart(datetime); /* Season Derivation */ if ( month(Date)&lt;3 ) or ( month(Date)=3 and day(Date)&lt;=19 ) or ( month(Date)=12 and day(Date)&gt;=21 ) then d_Winter=1; else d_Winter=0; if ( month(Date)=3 and day(Date)&gt;=20 ) or ( month(Date)&gt;3 and month(Date)&lt;6 ) or ( month(Date)=6 and day(Date)&lt;=20 ) then d_Spring=1; else d_Spring=0; if ( month(Date)=6 and day(Date)&gt;=21 ) or ( month(Date)&gt;6 and month(Date)&lt;9 ) or ( month(Date)=9 and day(Date)&lt;=21 ) then d_Summer=1; else d_Summer=0; if ( month(Date)=9 and day(Date)&gt;=22 ) or ( month(Date)&gt;9 and month(Date)&lt;12 ) or ( month(Date)=12 and day(Date)&lt;=20 ) then d_Fall=1; else d_Fall=0; /* Violent Derivation */ if primary_type in ('ARSON', 'ASSAULT', 'BATTERY', 'CRIM SEXUAL ASSAULT', 'DOMESTIC VIOLENCE', 'HOMICIDE', 'KIDNAPPING', 'OFFENSE INVOLVING CHILDREN', 'ROBBERY', 'SEX OFFENSE') then d_ViolentCrime=1; else d_ViolentCrime=0; /* Arrest Derivation*/ if arrest='false' then d_Arrest=0; else d_Arrest=1; /* Domestic Derivation*/ if domestic='false' then d_Domestic=0; else d_Domestic=1; run;
* read in EXCEL dataset YourName; PROC IMPORT OUT = YourName DATAFILE = "&lt;insert file path&gt;" DBMS= EXCEL REPLACE; RANGE="&lt;insert sheet name&gt;"; GETNAMES=YES; MIXED=NO; SCANTEXT=YES; USEDATE=YES; SCANTIME=YES; RUN; QUIT; * create permanent SAS library - reddit; LIBNAME reddit.'&lt;insert directory path&gt;'; * create permanent SAS data set; DATA reddit.NewName; * read in EXCEL data to permanent SAS data set; SET work.YourName; RUN; QUIT; * temporary SAS data set; PROC CONTENTS data = YourName RUN; QUIT; * permanent SAS data set; PROC CONTENTS data = reddit.NewName; RUN; QUIT; This should read in the Excel data to a temporary SAS library. Example work.YourName Then, it should create a permanent SAS library. Example: reddit Next, it should create a permanent data set for the Excel file. Example reddit.NewName For more help check out SAS Help &amp; Documentation in Base SAS (purple book in menu). Hope this was of some help. 
I would suggest you with the starting gem: The Little SAS Book: A Primer, Fifth Edition 
You can find some helpful tips including free e-learning and software to help you learn SAS in these blog posts https://blogs.sas.com/content/academic/2016/10/20/learn-sas-on-your-own-time-with-these-simple-steps/ and https://blogs.sas.com/content/sgf/2016/04/12/let-help-sas-technical-resource-guide/ Good luck!
I don’t like the material from SAS. It’s needlessly long but leaves you not really knowing how to get things done. Penn State’s STAT 480 course is really good. https://onlinecourses.science.psu.edu/stat480/
I've given this a quick look over and it looks like exactly what I need. Thanks!
I'd get a solid foundation in SQL first, makes the uptake of SAS a bit easier. All of the courses and training usually load you up on a bunch of stuff that you don't really use in the real world.
Is that doable in about a 4 month timeframe?
Basics are doable in a day. Understanding types of joins maybe a weekend
Install SAS University Edition if you don't have access to Base SAS. You will need to install a VM which they walk you through on their website (if you haven't done so before it is simple - so don't get discouraged). On the SAS website take the Base Programming Course (it's free), it's under e-learning I believe. That with the PSU course and you should be set! Hope this helped.
Need this advice or regret it. I have been a SAS programmer for over 20 years. I tell everyone who gets into thus to buy that book....yesterday 
I honestly disagree with this. I see *Proc SQL* as something built in SAS just for making happy some recycled programmers. I would rather suggest to just learn the DataStep programming, with huge focus on the PDV. Which is completely different from SQL, but we can of course say that is the real SAS. But I completely agree with you that on advanced level, the SQL knowledge is a huge help both for wider understanding and useful tricks.
I agree with this 100%. I'm fairly young, but I learned "old school" SAS by doing exactly what you've described. I started by learning the data step and PDV, then added PROC SQL later. I have consistently felt like I have a better understanding and grasp of SAS because of this. This isn't to say that one is better or worse than the other. Both are powerful approaches which can perform very well in the right circumstances. 
Agreed, The PDV is one of the more important aspects of SAS. 
Awesome. Thank you everybody for your help. It seems that I got it mostly working, however, my only current issue is that when I attempt to run a poisson regression analysis I receive this error for one county. ERROR: Non-numeric response variables are valid only with the multinomial distribution or the binomial distribution for binary data. I was thinking it was an issue with my excel data, but I changed the data to numeric so I am unaware as to why this is an issue for one county specifically, but not the other. If anyone knows the reason as to why I am receiving this error it would be much appreciated. 
If you are looking for lists of distinct values for all of the fields in a dataset, then I suspect PROC FREQ might be a good place to start: data example; do x = 1 to 10; y = mod(x, 2); z = mod(x, 3); output; end; run; proc freq data=example nlevels; tables _all_ / nofreq nocum nopercent; run; Note that the 'nlevels' option will produce a table showing how many distinct values each field has, and the tables statement will generate lists of each unique value, plus the number of times that it appeared in the dataset.
Thanks a lot for the reply. Yeah this is almost exactly what i need. Can I out that in one data set without interaction? So basically can I join all those tables to each other and output as one dataset?
No. The OUT= option in PROC FREQ only generates an output table for the last variable in the TABLES statement. I despise the code that I am about to paste, and I am sure there is a much more elegant approach, but this is my brain addled solution: proc contents data=example out=vlist(keep=name) noprint; run; proc sql noprint; select distinct name into: fields separated by ' ' from vlist; quit; %macro alldistinct; %local i next_field; %let i=1; %do %while (%scan(&amp;fields, &amp;i) ne ); %let next_field = %scan(&amp;fields, &amp;i); proc freq data=example noprint; tables &amp;next_field / out=freq(keep=&amp;next_field); run; data freq(keep=field value); length field $20; set freq; field = "&amp;next_field"; value = &amp;next_field; run; proc append base=allvariables data=freq; run; %let i = %eval(&amp;i + 1); %end; %mend; %alldistinct; proc print data=allvariables; run;
Thanks EMACS, really appreciate your time! I'm new to SAS so looks elegant to me anyway.
To give you a rundown on the logic, this is what the code does: * Use PROC CONTENTS to generate a list of all of the variable names in the dataset. * Use SQL to create a macro variable called *fields* which is a space delimited list of the distinct variable names from PROC CONTENTS. * Write a loop in macro language using the %SCAN function to get each field in order, then run a frequency for that field and output it to a dataset. * Append that new dataset to a master list of variables.
If descriptive is all you are going for, that you can do what you need to do with excel. Aside from frequency counts, the only thing I can think of is to assign points to the ranking (3 points for 1st, 2 points for second, 1 point for third) and then giving each motivator a score. But you don't need sas to do that and quite frankly, creating the graphic to show this is a lot easier in excel. I mean, use SAS if you have to, but given the research question as it is presented here, SAS is the long way to do this.
How would you do that in Excel? If the data is laid out like I described above? I would need to transpose the data it seems.
 ID | 1st choice | 2nd choice | 3rd Choice | option1 | option2 | option3 | option4 | option5 | option6 ---|---|----|----|----|----|----|----|----|---- 1 | option1 | option3 | option5| formula | formula| formula| formula| formula| formula Each formula is simple nested IF formulas that assigns points based on whether the options are in column 1,2,3 i.e. if(B2 = "Option1",3,if(C2 = "Option1",2,(if D2 = "Option1",1,0)))) And then at the bottom of each option column, just add up the points so you know how many points each option got and then you can transpose that if you want to, but just cut and paste into another table and make that the basis of a graphic or whatever. You can tally the number of times each option got 1st, 2nd, or 3rd in excel or SAS, but to me proc freq is not any faster than pivot tables 
Thank you! I'll try this out. 
Do your own fuckin homework
I get to the step on the left, click next, and then it stays at 0% on the summary page indefinitely.
I had this, ring up SAS support and they'll help you
I would do it with SAS. IF your Dataset is like: ID OPT1 OPT2 OPT3 1 A B C 2 C A B ... ... ... ... And you would like to proceed with this thing of fixed weight assignment (which has absolutely no meaning): you simply could do: data a; length CHC $20 WGT 8.; set b; array OPTS[*] OPT3 OPT2 OPT1; do k=1 to dim(OPTS); CHC=OPTS[k]; WGT=k; output; end; keep ID CHC WGT; run; The sort (proc sort) and sum the WGT (proc means) by the CHC variable.
Not sure if this would be too simplistic but why not just put some counters on there. Could see which motivator was chosen as first place most times etc etc. After that you could use data step reporting to list these numbers. If you have sas/graph it's then easy to produce some bar charts (with or without counting them). Good luck!
Another option: put all your categorical variables into a `class` statement within your `proc summary` and then use a `ways 1` statement. That will give you a table containing a 1-way summary of your dataset over each variable in your `class` statement.
So this output shows, choice 2 was the most reported followed by choice 3, correct? Analysis Variable : WGT CHC N Obs Sum . 45 90.0000000 1 59 84.0000000 2 62 131.0000000 3 40 106.0000000 4 3 5.0000000 5 8 15.0000000 6 31 61.0000000 7 4 12.0000000 
unreadable. can you please format it or screenshot it?
Yes, technical support may be the best resource for you. You can contact them directly or create a track here http://support.sas.com/ctx/supportform/createForm
Don't you know? SAS is the Hotel California. You can install anytime you like but you can never uninstall!
Did you press "Start"?
If you don't get an answer here, you can also try SAS Communities https://communities.sas.com/t5/SAS-Analytics-U/bd-p/sas_analytics_u to connect with other SAS users. 
Hey, was wondering where I could find this test bank of 30-40 questions for the actual exam? :)
Things that don't work: Removing missover in an infile statement does nothing. end statements don't seem to help i'm keeping firstobs as 2 as the variable names are at the top of each dataset 
Can you please provide us with a sample, if you don't want to post the document, at least please try to write the first observations in a table here. I am not sure I've understood properly.
Is it something like: Dataset 1 X1 X2 X3 first sec first second th Dataset 2 X4 X5 X6 ond third fourth ird fourth 
Please post some text resembling the files that you're trying to import.
I think you could load them as separate tables and then union the 2 filtering out the incomplete record on the 2nd. Then find the max observation record I'd in the first table. Then join the incomplete data back in by saying record id = max record id in table 1 and record id is missing in table 2, coalescing all the observation columns to restore the split record into 1 row. Or just ask what the impact of disgarding 1 record is and drop that row if it doesn't really matter. 
You could sort the data by patient name and admission date. Then use a by statement (by patient_name admission_date;) Then you can use condition: If first.patient_name and first.admission_date then Output; The only problem with this is using patient name as you might have two people with same name but this can be fixed by using patientID or any other unique key given to each patient to identify them. Hope this helps, pm me if you need anymore help!
Thanks! In the data step, could I separate the If-then-output statements based on DISCHARGE STATUS, since I might not automatically want the first admission date if discharge status is 2?
Absolutely! So if I understand this correctly then all you would need to do is add another if condition so just add: AND discharge_status eq 2. So in the case i wrote here you would get an observation for each patients first admission where discharge equals 2. Let me know if you need any other help
If your data has a primary key, you could use the UPDATE statement - http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000202975.htm
close it's like this Dataset 1 X1 X2 X3 X4 X5 X6 X7 1 1 2 2 3 3 4 1 1 2 2 Dataset 2 X1 X2 X3 X4 X5 X6 X7 3 3 4 1 1 2 2 3 3 4 
Thanks for everyone trying to help the data looks like this Dataset1 X1|X2|X3|X4|X5|X6|X7| :-:|:-:|:-:|:-:|:-:|:-:|:-:| 1|1|2|2|3|3|4| 1|1|2| Dataset2 Dataset1 X1|X2|X3|X4|X5|X6|X7 :-:|:-:|:-:|:-:|:-:|:-:|:-: 2|3|3|4| | | 1|1|2|2|3|3|4| 
repeated in reddit format above
Replied above. Cheers
posted above. thank you.
Eh, that is an exeedingly weird result. You're saying dataset 2's first row should overwrite dataset 1's last row's nulls? So your combined dataset would look like: 1 1 2 2 3 3 4 1 1 2 2 3 3 4 1 1 2 2 3 3 4 I'm not at a SAS computer, so I can only sketch out some keywords for you to look up. * I would use the `end = ` `set` option in dataset 1 to figure out when I hit the last row of it. E.g., split dataset 1 into two datasets: a bunch of good records and the single bad record. * You can use _n_ = 1 to similarly split up dataset 2: data ds2_first ds2_rest; set ds2; if _n_ = 1 then output ds2_first; else output ds2_rest; run; * Now you have good records from both datasets and the broken record. For the ds2_first, you can drop x5--x7 and then do a rename of x1--x4, and then do a merge with no by with the broken part of dataset 1. * *Voilà!* You can now set all three pieces together properly.
I've never been a huge fan of SAS when it came time to manage output layout. However , I suggest you take a deeper look at ODS layout options 
There is quite a lot of flexibility with ODS and templates, everything you describe sounds achievable, given time. I would argue that there are several other methods outside of SAS that will produce cleaner, more professional graphs a lot more quickly. Even Excel would be a simpler option. In my opinion this is one of SAS' major weaknesses. 
My suggestion which always worked as a gem in years of career, is to create 2 different images, and include both of them in the same page using a proc report on a dataset with 1 variable and 2 observations, let's say first obs a=1, second obs a=2. then you create a format myimg. with 1='\\file\path\first.png' 2='\\file\path\second.png'. and in the proc report code you compute the variable on the format like define mycomp / computed style(column)=[postimage=myimg. ]; and compute it with compute mycomp; mycomp=a; endcomp; 
https://pastebin.com/U0pr8UHP
Looks like the simplest solution I've come across so far, I'll give it a try shortly
let me know if you will need some more complete code.
A few of us were there, yes!
holey moley, thanks for this, I'm going to see if I can apply this strategy. I'll let you know :)
This might be a good starting point: https://support.sas.com/rnd/base/ods/odsmarkup/latex.html
It can be done but it's super painful by comparison to Stata and R.
What the hell are you talking about?
What? Which bit?
Just typo into your google search box: "SAS Certification Prep Guide pdf". I have the complete pdf in the first 4 results. I spent 2 days for the base exam preparation (I was on a VERY low level at that time but already had some few basics and I already had a programmer's mindset).
[removed]
OP answered but for some reason his comment was deleted. &gt; Hey, thanks for your response. I've studied coding and have a lot of programming experience as well. Also, the book seems nearly to be 800 pages long. Is it necessary to go through the entire book for the exam? Is it then realistically possible to fully prep for the exam in 2 days( or even a week) ? It is 800pgs long because it is explaining you in a very detailed way some concepts you just don't need, if you are a programmer already. I prepared it with a SAS instructor in 2 days, the course was offered by the university. There was this friend of mine, student like me in the same year/university who didn't take the course but took a look at the slides provided by the instructor, we had the same statistics/programming knowledge at that time, he tried the exam and passed. My test was almost perfect (2 errors?) with these 2 days of preparation, my friend's test was within the passing range but not as good as mine, obviously. Focus on the PDV to get started with SAS and understand how it works. Then learn the basic functions for data manipulations like merge, the basic procs for data manipulation like transpose, the basic function for strings management, and the basic procs for data analysis like freq/univ, understand to discriminate when sas works on rows and when sas works on columns, then you are done. Take special attention to details during the exam, as some question are supersimple but they could be tricky (a misleading missing semicolon could make you think a lot on the expected result of a datastep, while the answer is ERROR).
The book is on Safari books if you don't mind paying for a subscription. Not sure if you can find it for free. If you google ' base sas bi exam academy' there's a guy who created some free practice questions, I am using them in addition to my book and its quizzes. Good luck!
Hey, I managed to find a free copy of the book ( the link for which is mentioned in the comments above). Thanks, anyway. :) How long is it taking for you to prep? And how do you find the difficulty level?
I was taken on an intensive 8 weeks course but it covered base sas and advanced. If you have some experience in SAS and have base or enterprise to fiddle with I feel like it shouldn't take you too long to know enough to pass. At the moment I have less than a month to prepare I'm trying to cover 5 chapters a week then I'm just going to keep practicing questions. I am close to passing but i am still lacking the confidence as the questions are really tricky. Best advice is just make sure you do as many quizzes and practice questions, that way it will be easier to spot trick questions :) 
That was a really detailed response. I'll first study the topics you mentioned and work from there. Thanks. :) Also, do you still have those slides that you used to prepare for the test. If yes, can you share it with me?
Sorry but I don't think so. It was long time ago.
My advice as someone who hires SAS programmers (we are hiring now, actually) is to be a little careful paying money out of pocket for SAS certification exams and/or practice materials. This is especially true of the base certification exam. In my opinion, the SAS base certification doesn't really provide much insight into how good of a programmer or analyst the person is. The advanced certification is better, but there's still a skill set that I'm looking for which is outside of what SAS covers in the certification exam. I don't think the exams are useless or worthless by any means. But if your goal is to make yourself more marketable, I'd be cautious paying out of pocket for an exam. You might not find it provides a great return on your investment. If your company pays for the exam, on the other hand, then there's no reason not to go for it.
Perhaps these resources help: https://support.sas.com/resources/papers/proceedings12/324-2012.pdf https://support.sas.com/rnd/base/ods/odsmarkup/latex.html 
From the perspective of someone who hires talent with SAS skills, make sure you are getting any SAS certs for the right reasons. My department has turned down multiple candidates that have Base/Advanced SAS certs, but then when we provide pratical scenarios that cover the material they fail. When we question them, they say they studied and passed the exam but don't use SAS, or only use point and click of EG or EMiner platforms. Our most successful SAS coders don't have any certifications or only got them after joining the team as we have a small budget for exams and licensing.
More than a month is best. 
Thanks. Will reconsider my decision then. On a side note, are you in India?
Yeah I moved a lot of repetitive graphing to SAS, which is working fine, but controlling the way the graphs behave and output via ODS is something I just can't get a handle on. When the complexity increases, I dump my data into Excel. In this case, I'd either graph in Excel or I'd run sgplot and then screen capture the graphs to a word doc, shoving them onto one page. Not being comfortable with ODS, it's just too much of a time suck to stay in SAS sometimes.
A small but valuable change to this for anyone who stumbles across the post in the future is to modify the macro call to include the data set name as an input. That way if you need to summarize fields from different data sets, you can change the data set name in the macro call without changing it in the code and rerunning the macro code itself. Good solution, I'm just trying to help make it a tiny bit better.
I know I'm answering old post but could you send me the link as well? I'm studying for advanced exam but all I have is prep guide.
No problem. :)
which is the dimension of the dataset? The error you get about the estimated G matrix not positive defined, is because you are dealing with sparse data, you could gain some info about this running a proc freq outcome*year, did you consider binning the outcomes to high/low? 
It took me about a month to prepare for mine and I used the certification prep guide. It was expensive but very good. If you want a free resource for practice questions, I highly recommend https://sasensei.com Hundreds of questions, hundreds of happy users!
There doesn't seem to be any sparse data. There are 932 people. There are 3 years and 4 levels within the outcome variable. The lowest box is 30 people in the 3 x 4 table, the highest being 125, but no errors when running a chi-square test. I did it run it as a binary outcome, I got the same note: Estimated G matrix is not positive definite.
Sounds quite strange to me. Can you share the data or are they private?
Here is the univariate model: &gt;proc glimmix data=data; &gt;model outcome=year/s dist=multinomial LINK=CUMLOGIT or; &gt;random year; &gt;run; Full model with interaction term (which I still don't know how to present in a table etc): &gt;proc glimmix data=data; &gt;class sex(ref='1') education(ref='1') race_ethn(ref='1') age covariate covariate1 covariate2 covariate3; &gt;model outcome=year sex education race_ethn age covariate covariate1 covariate2 covariate3 covariate*year/s dist=multinomial &gt;LINK=CUMLOGIT or; &gt;run; &gt;Proc freq: &gt;tables outcome*year; year1 2 3 1 50 57 66 2 39 46 34 3 101 98 120 4 125 115 90 &gt;proc contents; outcome Num 8 Year Num 8 BEST. Year age Char 1 $1. $1. age race_ethn Char 1 $1. $1. race_ethn education Char 1 $1. $1. education covariate Char 3 $3. $3. covariate sex Char 1 $1. $1. sex I am really appreciating your help. Thank you! 
&gt; year1 2 3 &gt;1 50 57 66 &gt;2 39 46 34 &gt;3 101 98 120 &gt;4 125 115 90 &gt;outcome Num 8 &gt;Year Num 8 BEST. Year &gt;age Char 1 $1. $1. age &gt; race_ethn Char 1 $1. $1. race_ethn &gt;education Char 1 $1. $1. education &gt; covariate Char 3 $3. $3. covariate &gt;sex Char 1 $1. $1. sex 
 year1 2 3 1 50 57 66 2 39 46 34 3 101 98 120 4 125 115 90 &gt;race_ethn Char 1 $1. $1. race_ethn &gt;education Char 1 $1. $1. education &gt;covariate Char 3 $3. $3. covariate &gt;sex Char 1 $1. $1. sex Sorry, I'm having trouble getting the proc freq table to work for you. The 1 is the first level of the outcome variable, 2 is the second, etc etc. Then the numbers after that correspond to the year 1, 2, and 3. Let me know if this makes sense. 
I am not very sure what is your questions but if you want to display the three columns: cola colb colc in the same date format (ddmmmyyy), use: FORMAT cola colb colc date 9.; 
you know how in excel you can copy paste the formatting from one cell or column onto other cells and columns? same here. i want to "copy paste" the format of a column containing onto other columns " so all dates in my datasets are the same format
If you add the **Format** statement that i mentioned in your **Data** step and you essentially doing that.
thank. I will try it. 
Your code won't be working, you allowed a blank between "date" and "9.", therefore "date" will be initialised as a numeric variable, with length 8 and format 9. . 
Good catch.
I am in the United States. My current employer has contractors in India, and my prior employer has both contractors and employees in India. I guess the point of my post was to say that it's perfectly fine to get a certification like Base SAS. However, your future employer will want you to "hit the ground running" with work, and if you are displaying these certifications on LinkedIn/resume, they are going to expect you to be able to do that level of work when you start your job.
Where would people learn sas without any background. If he were to get certified or not, where would he go to put it in practice? I have been looking into SAS for a bit but don’t understand where I would get comfortable using it to where I could earn a job working with it unless it’s all theoretical in a classroom setting .
it seems like the code is not pasting correctly... basically, even though I have the labels (highest, high, low, lowest) grouped, it seems to be grouping them based on the salary. So the word "highest" repeats multiple times for each state, and only shows a blank if one of the salaries is repeated, instead of only displaying the words "highest," "high," "lowest," etc., once.
I can send a screen shot to someone's email if you are willing to help and if that would be easier! thank you!
I know you got your answer already but for a general solution see the last post here https://communities.sas.com/t5/Base-SAS-Programming/Assign-format-to-new-variables-by-copy-the-existing-variable/td-p/165425 
I don't believe that There is a Built in function just for that . You could use macro language to create macro that Loop over all distinct value of the desired variable
Yep, that's what I'd do. Either populate a single macro variable with space-separated values of all the locations, or create a mock macro array and loop over however many of them there are.
Do you have a sample code of what this would look like?
It would look something like this: %let locations = /* list of locations - NOT A STRING */ %macro export(locations); %local i location; %let i = 1; %do %while (%scan(&amp;locations, &amp;i) ne ); %let location = %scan(&amp;locations, &amp;i); proc export data = xyz (where LOCATION = &amp;location) outfile = &amp;location..csv /* The two periods are not a typo*/ dbms = csv replace %let i = %eval(&amp;i + 1); %end; %mend; 
Wonderful thank you! 
Good stuff. Once in a while I still like to kick it old school, so I have been using a technique like this for decades: proc sort data=xyz(keep=location) out=locations nodupkey; by location; run; data _null_; set locations; file "call_macro.sas"; put '25'x "report(" %trim(location) +(-1) ");"; run; %macro report(location); proc export data=xyz(where=(location="&amp;location")) outfile="&amp;location..csv" dbms=csv replace; %mend; %include "call_macro.sas"; Basically what I am doing is writing a simple macro (called 'report' in this instance) and then writing some code to generate a file that looks like this: %report(Boston); %report(Chicago); %report(Dallas); %report(New York); %report(San Francisco); %report(Seattle); So why would I ever do something like this? Two reasons: * I think it is a little simpler. It breaks the task down into pieces that I can look at step by step and check as I go. * There are many times when I need to look at the list that I used to run the macro, re-run certain cases, etc., so it is nice to have a ready to run program that I can edit to generate partial updates as need. Ugly. Old school. But I think there is some utility to the approach once in a while.
this. learning how to use data *_null_; put stuff;* for data-driven code, is like the gem that would save you an insane amount of time forever.
Looks like you're on a wrong subreddit
I would run options LowSetting; proc tombraider; var laracroft; by gt610; run;
It’s funny because of the way it is
This worked, except it doesn't want to export my last location. The final location does show up on the %report(location) list, however it exports the CSV files up until the last location, when SAS just gets stuck on 'PROC EXPORT RUNNING'. Any ideas? Thanks
Could be laziness on my part. Try adding a RUN statement to macro, e.g.: %macro report(location); proc export data=xyz(where=(location="&amp;location")) outfile="&amp;location..csv" dbms=csv replace; run; %mend;
That worked, thanks. Do you know if it is possible to export these files using a specified Excel Template (.xltx) format? (i.e. if I point SAS to a saved template file, and tell SAS to start filling cells at a particular cell [e.g. B7]), can I do this in this step as well? Or if there is some other process (even if it is brute force converting the outputted .csv files into the template format structure), I would be curious if you have any strategies for that.
Sorry, I do not have anything to suggest in that regard. If I have to deal with Office then I generally switch over to either python or VBA. 
please, explain your problem in a proper way. no way we can help you with these information.
Like a title?.... /*Make a dataset named DEFAULT*/ ods tagsets.excelxp options(sheet_interval='none' sheet_name='whatever_you_want' embedded_titles='yes'); title '2014 Data'; pric print data=DEFAULT width=uniform noobs label; run; I'm not sure why your data starts at A7 though. Showing some of your code might be helpful to understand what you're doing. If you're not using tagsets and instead using DDE to get it more granular, maybe just make a 1 value datasets with cards and print that in A1 while printing the data in A7.
Assuming you have a template that you are trying to fit to, check out [this white paper](http://www.sascommunity.org/mwiki/images/d/d6/2444-2018.pdf)
This is brilliant! Perfect to practice for my upcoming exam! Will be sharing this with exam buddies :)
use the referral link - then you both get extra tokens! https://sasensei.com/user_profile#referrals
Brilliant thank you!
Wow I'm am apparently terrible at SAS.
Do I really need to sign in with social media to try this?
Yeah, looks like it cuz I can't see anything either. 
Yes - we took the decision that we weren't going to store any passwords on the site. Signups are necessary though in order to track scores, and so that we can give accurate difficulty ratings to the questions. 
It's impossible to know it all! The nature of 'community submitted' questions is that it tends to be those with more experience who submit the questions, hence they tend to be harder. The algorithm starts off though with questions that have a 75% plus pass rate. After 5 questions, they get progressively harder (based on previous pass rates). There is still a shortage of easy questions though, am working on this!
did they give you this code? It's not accurate and would not run
Yes, it was provided to me... I am not sure if it is worth downloading the SAS demo to play with this code, since I do not have the dataset it refers to anyway... what part of the code is wrong?
There are so many mistakes in this code. It seems that the programmer, never programmed SAS before as it is completely missing the basics. Missing semicolons, missing data statement, numeric date compared with a string without the d modifier, missing lib definition from the second out statement, typo in summary, ...
Maybe its part of the "test" to see if I notice... I will look into the syntax more to see if I can make a comment that is accurate about what is missing like the missing data statement, etc. Thank you for the feedback, it helps considerably!
&gt; Signon Using one of the platforms below Hard pass
I'm not sure what that means? 
Hm. Something is missing. Well, a lot is missing, in the way of instructions, I think. So I signed in, looked around, answered one question correctly, which turned 2 of my tokens into 2 experience points, and was asked if I wanted to spend 2 more tokens to play again. I had assumed it was something like I had to 'pay' if I got a question wrong but could at least continue answering as long as I got them right. No obvious way I would get thousands upon thousands of tokens if I wanted to try every question. Nothing I could see at first glance that would make me want to try. Now, if there is something good hidden here -- a substantial bank of questions, and a game with some actual incentive or reward for correct answers -- put up a help page that says what it is. Otherwise I'm out of here.
That's great feedback and you're right, we need instructions / help page, that's actually number one on my to do list. To clarify, the way it works is as follows: * you start with 8 tokens * RUN cards costs 2 tokens to play * RUN cards ends when you get one wrong * If you get a streak (more than 2 in a row correct) you EARN tokens To unlock the later levels (best ones being submit, short exams/sessions, or multiplayer) you can use tokens or Reputation You earn 2 points Reputation for getting an answer right (first time) You earn 1 Rep for voting (ensuring the quality of the question bank) You earn 10 rep for submitting a card that gets 2 votes or more You earn 20 rep for passing a timed exam There IS a substantial bank of questions, and being community submitted (and verified) it's good quality and growing. In terms of incentive - it depends who you are. If you're a student, you can learn SAS whilst testing your knowledge. If you're experienced, you can prove your SAS (get on the leaderboards) and learn even more by submitting more questions (teaching a topic is a great way to learn it). If you're an actual teacher of SAS (a Sensei) then the final level will let you create your own SAS tests, and let you see the scores from all your students with analytics to show the pass rates / question difficulty etc etc. 
Means 'no.' For a lot of people, having to sign on via social media is a deal-breaker.
[removed]
I played a bit and enjoyed it. I'm wondering, for submitted questions, how will you make sure that people don't copy or slightly modify preexisting cards, especially once you've introduced real incentives?
The system will prevent exact duplicates, but for slightly modified it's obviously a bit harder to flag up. We would rely on the community to downvote until our algorithms got better! 
I see your point. We're going to look at auth0 (auth0.com) to enable username/password signups in the future.
This guy. Just started myself. Bought “the little sas book” while beginning the online videos and I wish I would have saved the money for now. Sas’ online tutorials and practice samples really help more than a book for beginners. Though it’ll be a fine reference later, start with the free things online and see how you like it. 
I'm sorry but the goal of your analysis is not totally clear to me. Can you please try to give a proper description of the analysis case, so we will be able to help you with suggestion about statistics and the relative sas code? I'm not sure if you want a predictive or descriptive model, if you simply want the maximisation of a defined function, why are you looking to binomials, which of these variables are considered outcome and which one are actually included in your dataset. 
Thanks for the response! The 5 variables listed are inputs and revenue should be the output. The basis of the project is to find the number of booked seats that would maximize revenue. I am not sure which model would be most appropriate for this, but I’m open to any suggestion. Hope this clears my issue up a bit - Thank you again! 
Thanks.
Coming soon to SAS version 9.6 aka SAS/STAT version 16.2!
[removed]
I keep a couple copies of [The Little SAS Book](https://www.amazon.com/Little-SAS-Book-Primer-Fifth/dp/1612903436) around my office to hand out to people that are just learning. It is a pretty well organized, step-by-step introduction to SAS programming.
Thanks very much.. 
I would avoid DDE if at all possible as it is very flaky these days. Define a named range for the cell in question in your template and then use libname excel / xlsx to populate it.
This is inappropriate for this sub 
My girlfriend says to use stata if you have access it's much better at cluster analysis. I'm a morons I don't know I don't know anything so keep that in mind
Here are a few resources you may find useful to help you get started with SAS: http://support.sas.com/training/us/sp1.html Note there are also 200+ free tutorials and some free eLearnings you might want to check out. 
What issues are you having with University Edition? You could also try the cloud offering, SAS OnDemand for Academics. See here for different software options: https://www.sas.com/en_us/learn/academic-programs/students.html
Every time there is an update, the virtual box seems to not allow the download, or something gets screwed up along the way. I decided to go directly to SAS to download the latest version, but my virtual box does not allow me to open another SAS file, even though I removed the old engine from the virtual box.
Uninstall virtualbox completely, install the latest version, then try launching the latest SAS university edition image. A commercial alternative to SAS is WPS, but that one isn't free - just slightly less expensive: https://www.worldprogramming.com/products/wps
R...the little brother to SAS imo. No need for virtual box and you can even run a server version on amazon AWS to access it remotely. Its free and if you can learn R you can dodge a wrench. But seriously anyone who knows anything about this field will be like ok..he knows R so he can learn SAS so let's hire him. Source: Learned R in college, got a job programming in VBA because of R and now learning SAS at this job. Also if you are a veteran...EVERY SAS e-learning course and cert exams are free.
Turns out there are ancillary files in virtual box, had to find them to uninstall 
I used [Learning SAS by Example](https://www.amazon.com/Learning-SAS-Example-Programmers-Guide/dp/1599941651) in a SAS course to prep for the BASE exam and I found it to be pretty helpful. It's a little outdated, but starting from scratch it has some pretty solid examples to get you started on the basic concepts.
I'm hiring contractors to program in SAS right now. No way would I hire someone who has only used R. R might be a nice additional skill, but not by itself. 
If you needed someone to step in and program from day 1 yeah I get that but honestly R was harder to learn. SAS EG has some point and click function that you can study code. So if i needed a long term guy that we could let learn id hire someone with alot of r exp. R is free and SAS cost you your first born. 
Thanks a lot
He may well have been using WPS - a SAS language processor. Lets you run (most) SAS code, minus metadata and more advanced stuff (like fcmp and various specialist procs).
yes - you need SAS/Connect licensed, and you can use the `rsubmit;` statement to submit your remote code. Local libraries can reference remote ones using `library x server=remote;` type syntax.
Upvote for the dogeball reference.
Thanks! I don't even need to submit remote code - I just need to run code on the server and save SAS data sets to local/network hard drives (rather than on the SAS server). 
A better way to represent it would be to use an offset across the top, rather than actual months/dates. Let's say you simply had a dataset containing the intake &amp; month end records for each account in a single table, by Account &amp; Date. e.g. Account | Date ---|--- 1 | 20MAR2017 1 | 31MAR2017 1 | 30APR2017 2 | 04JAN2017 2 | 31JAN2017 2 | 28FEB2017 2 | 31MAR2017 Solution: ARRAYS! Will be worth viewing each dataset in turn to see how this works. I'm doing this blind (not literally, but without a SAS client to hand), so apologies if it's not quite right, PM me if you get stuck. /* Step one, calculate offset between end-of-month and intake date */ data step1 ; set have ; by Account ; retain intake . ; if first.Account then intake_date = Date ; /* hold onto date from first record per account */ else do ; offset = intck('month',intake,Date) ; if last.Account then max_offset = offset ; end ; format intake_date date9. ; run ; /* Now find max offset over all accounts */ proc sql ; select max(max_offset) into :MAX from step1 ; quit ; /* Now process into buckets */ data step2 ; set step1 ; array month{&amp;MAX} ; /* enough buckets to cover zero to &amp;MAX offsets */ retain month . ; if offset then month{offset} + 1 ; /* if we have an offset value, increment that bucket by 1 */ run ; /* And summarize */ proc summary data=step2 nway ; class intake_date ; var month: ; /* wildcard all month columns */ output out=vintage1 (rename=(_FREQ_=Intake_Count) drop=_TYPE_) sum= ; format intake_date monyy7. ; /* Group intake_date by month */ run ;
hmmm. i will give this a try. thank you
I think we've got this answer covered in this [discussion thread](https://communities.sas.com/t5/SAS-Enterprise-Guide/Running-code-on-EG-server-also-need-to-save-SAS-data-sets-to/m-p/422807#M27258), but post back if not. To copy data sets from your remote SAS server, you can use the Download SAS Data Sets task for SAS data sets only, and the Copy Files task for any file type. The Copy Files task handles wildcards and macro variables, so it's quite flexible.
if you google the error there are a bunch of results: http://support.sas.com/kb/44/047.html 
If you work (or are going to work for) a SAS partner, they are like $ in the bank. They are required to have a specific number of people certified to maintain status. The s actual practicality is less than desired but they do have their purpose.
If you are paying then hell no! It is not with it.
Too bad the test is all about nitpicky syntactical issues. Imagine a test written by a know it all douchecanoe that is a bar trivia nerd and likes stats software and hates people...you then have an idea if what a SAS cert exam is like
Too true. The test would be great if SAS studio didn't exist, if you didn't have software looking after you to make sure you close your parentheses, end lines with semi colons, put stuff in the right place, etc. I feel the way we use SAS has changed, but the test really hasn't.
Totally agree. The test is like: could you program SAS if you had to use the most brain dead text editor on the planet. It is not much more than "where is the typo" and "what screwy thing will SAS do if you code it like an idiot"
SAS also offers books, training courses, sample questions and practice exams! See what is recommended under each certification by clicking "Exam Preparation" https://www.sas.com/en_us/certification/training-exam-preparation.html
I took mine twice, obviously failed the first time. The first time I took it I went in blind (did not study for it at all). I was taking a SAS programming class at university at the time and the professor gave us the option of using the SAS Base Programmer cert score to replace our final exam. He said we should be 'fine' because the materials taught in that class should suffice for the cert exam. Boy, did I disagree. I got a 53. The base cert exam is extremely anal about syntax, small things like proper use of quotations, and ';' at the end of every line, also logic (output), etc. That's why I failed the first time, I simply just didn't pay attention to it. The second time I took it, I only studied 1 old exam that I found online (they're widely available). It had something like 150 questions, I spend a week studying for it. That's when I realized the exam very much focuses on those small things. It made me pay very close attention to literally every single word of every single line, and it made me very critical of all the answer choices. They will all look extremely similar to each other (I absolutely hate that, I think it's another reason why I failed: carelessness). And you have to pick the *best* answer choice. When I was studying, whenever I picked an answer, I would give logical reason why I think it's correct, and where in my lectures did this concept came from, before revealing the answer key. The first time I did the old exam and scored myself, I think I have about ~50% (failed). Whenever I picked a wrong answer, I would go back to lecture notes and sometime online to find out why my answer was wrong, and then make notes. I was still nervous as hell the second time because of how badly I failed the first attempt. I got an 82. You have 2 hours to take the exam, take all of the time. Don't be afraid to question your first choice, but very careful to not psych yourself out because of self-doubt. I'll be happy to answer any questions you have! 
I scanned the questions at the back of the book and made a test simulation app in shinyR. It's just a multiple choice question app with scans of pages and the answers written in an excel for comparison. Worked. Helped that I'd been using SAS for like 2 years at work though. Probably. 
Wow thank you for all the info! I have taken several classes that used SAS but unfortunately they did not cover SAS programming, only point and click features, so I'm a little behind in that aspect and I'll definitely be looking for old exams 
I'm assuming the classes that you took are stats classes that uses SAS to perform analysis? The class that I took didn't focus on stats, but more on programming (import, export, clean up data, manipulation, etc.). We would use SAS to perform those functions every week, and continually build up our skills (ie: performing more and more complex tasks in very *efficient* manners), using real data over the semester. We only perform simple stats analysis in the last month of the course, and even then, we complied codes to perform those tasks. Using 'point and click features' were strictly prohibited. We did not use it at all. I don't remember being taught or tested on anything that has to do with those features. PS: ask as many questions as you want, I passed the cert exam like 1 month ago lol. 
I used the prep guide only and had some prior experience with SAS from uni. The test focuses as much on specific tasks as it does in the minutiae of typos, syntax, subtle variations of reading data.
Use lag or retain + by-group processing + arrays + as much macro code as necessary to avoid repeating yourself. Without ETS I suspect that's your best option.
Yes exactly, it was a stats class that used enterprise guide and miner to analyze data (seems like that doesn't help me much here). So it sounds like the base certification focuses mainly on syntax and programming, and less on any type of statistical analysis? I have also found a PDF to The Little SAS Book, would you happen to know if that is applicable to base certification? Thanks again for the help 
I quickly scanned over the contents of this book (~350 pages). The contents are pretty much exactly what is covered in my programming course; it is almost identical all the powerpoints made by SAS themself. I think it's an awesome guideline/reference for a SAS programmer. This exam is very much an aptitude test of your practical skills using SAS to solve real 'business scenarios.' See [here](https://www.sas.com/en_us/certification/exam-content-guides/base-programming.html) for details about each category. It is very important that you know how to perform each and every one of those tasks by programming (ie: compiling codes) with absolutely zero error. I don't know how much time you have to prep for this exam, but I would not use this book to cram for it. Try to find old exams/dumps and study it well enough that you can select the correct answer without looking it up first, and be able to justify your choice with conviction because that's what will help you navigate your way through this exam. It not only test you on knowing what you have to do, but how to do it as well, and in the most efficient manner at that. 
I used prep guide, but if I was starting now I'd be a serial user (and contributor) to https://sasensei.com
This sounds amazing! Mind sharing/providing a git link?
Yea, sorta. OP pm'd me asking the same thing. This is the message I sent him: Yep, shinyR webapp. I don't really want to draw attention to my github because I may be breaking a copyright law and I only intended it for personal use but didn't want to pay for a private github. It's literally the only thing I've written in shinyR and only webapp I've ever tried to write so I'm sure it's full of nonsense and not meant to be taken as an example for anything. It was solely for personal use. It had a folder at root/www/testmats. testmats contained the xlsx and png files. the png shows the full question and the multiple choice answers, then you select a,b,c,d and submit...grades you after you completed as many questions as you wanted to do. the /www folder contained a little simple cs. The bulk of the program is below. I used RStudio when throwing it all together (free). Example of what was in ANSWERS.xlsx: QNO ANSWER 1 a 2 b 3 a ui.R goes like this: library(rJava) library(xlsx) library(shiny) library(XLConnect) library(shiny) library(DT) shinyUI(fluidPage( sidebarLayout( sidebarPanel( "Test Options", #MAKE ALL BELOW: #RenderUI's off a start button #SLIDER SHOULD PROBABLY BE REACTIVE ON HOW MANY ARE READ FROM ANSWERS.XLSX #UNRENDER IT WHEN TEST COMPLETES AND RERENDER THE BUTTON #OR CAN THESE RENDER ON LOAD OF PAGE? (FOR EASY UNRENDERING) sliderInput( "how_many_questions", "How many questions?", min = 1, max = 208, value = 1, step = 1, round = 0 ), actionButton("startTest", "Start"), actionButton("refreshTest", "Refresh") #TO HERE:# ), sidebarPanel( "Answer Options", uiOutput("aOptions"), uiOutput("subButton"), h6("Correct Counter:"), textOutput("Corrects"), h6("Incorrect Counter:"), textOutput("Incorrects"), h6("Final Score:"), textOutput("corPerct") #could add a timer... ) ), mainPanel( "Question Info", imageOutput("question"), uiOutput("fResHd"), tableOutput("feedback"), uiOutput("prevIFB"), uiOutput("nextIFB"), br(), tableOutput("currIC"), br(), imageOutput("fQuestion") ) )) server.R goes like this: library(rJava) library(xlsx) library(shiny) library(XLConnect) library(shiny) shinyServer(function(input, output, session) { observeEvent(input$refreshTest,{ session$reload() }) out1 &lt;- reactiveValues() out2 &lt;- reactiveValues() out3 &lt;- reactiveValues() GenRand &lt;- function(x) { return(sample(1:x, 1)) } turnCtr &lt;- function(x) { if (is.na(x)) { return(0) } else { return(x + 1) } } ##################TEST START OBSERVATION################# observeEvent(input$startTest,{ TurnMax &lt;&lt;- as.numeric(input$how_many_questions) if (input$startTest == 1) { turn &lt;&lt;- 0 } turn &lt;&lt;- turnCtr(turn) if (turn &lt;= TurnMax &amp; turn &gt; 0) { tSample &lt;&lt;- read.xlsx("www/testmats/ANSWERS.xlsx",1) tSample &lt;&lt;- subset(tSample, tSample[,1] != "NA") ansMax &lt;&lt;- length(tSample[,1]) hld&lt;-NA obslst&lt;-NA xlen&lt;-0 while(xlen &lt; TurnMax){ obs&lt;- GenRand(length(tSample[,2])) suppressWarnings(if(is.na(hld)){ hld&lt;-subset(tSample, tSample[,1] == as.character(obs)) } else { if(obs %in% obslst){ xlen&lt;-xlen-1 } else { hld&lt;-rbind(hld, subset(tSample, tSample[,1] == as.character(obs))) } } ) xlen&lt;-xlen+1 obslst&lt;-c(obslst, obs) } tSample&lt;&lt;-hld out1$nOrd &lt;- sample(seq_len(length(tSample[,1])),replace = FALSE) tSample &lt;&lt;- cbind(out1$nOrd,tSample) tSample &lt;&lt;- tSample[order(tSample[,1],tSample[,1]),] tSample &lt;&lt;- subset(tSample, tSample[,2] != "NA") out1$ansRow &lt;- subset(tSample, tSample[,1] == turn) out1$sQno &lt;- out1$ansRow[,2] out1$corAns &lt;- out1$ansRow[,3] output$aOptions &lt;- renderUI({ radioButtons("aOptions", "Options", c("a","b","c","d")) }) output$subButton &lt;- renderUI({ actionButton("submitAnswer","Submit") }) out1$out &lt;- list(src = paste0("www/testmats/q", out1$sQno,".png")) output$question &lt;- renderImage({ out1$out },deleteFile = FALSE) } }) ##################ANSWER SUBMISSION OBSERVATION################# observeEvent(input$submitAnswer,{ if (as.character(out1$corAns) == input$aOptions) { out2$newline &lt;- c(out1$sQno, as.character(out1$corAns), input$aOptions, "CORRECT") out2$feedback &lt;- rbind(out2$feedback, out2$newline) } else { out2$newline &lt;- c(out1$sQno, as.character(out1$corAns), input$aOptions, "WRONG") out2$feedback &lt;- rbind(out2$feedback, out2$newline) } turn &lt;&lt;- turnCtr(turn) if (turn &lt;= TurnMax &amp; turn != 0) { out1$ansRow &lt;- subset(tSample, tSample[,1] == turn) out1$sQno &lt;- out1$ansRow[,2] out1$corAns &lt;- out1$ansRow[,3] out1$out &lt;- list(src = paste0("www/testmats/q", out1$sQno,".png")) output$question &lt;- renderImage({ out1$out },deleteFile = FALSE) out2$corCt &lt;- subset(out2$feedback , out2$feedback[,4] == "CORRECT") out2$badCt &lt;- subset(out2$feedback , out2$feedback[,4] != "CORRECT") output$Corrects &lt;- renderText({ paste(length(out2$corCt[,1]), "/", TurnMax, sep = "") }) output$Incorrects &lt;- renderText({ paste(length(out2$badCt[,1]), "/", TurnMax, sep = "") }) } else if (turn &gt; TurnMax) { output$aOptions &lt;- renderUI({ }) output$subButton &lt;- renderUI({ }) out1$out &lt;- list(src = paste0("www/testmats/finished.png")) output$question &lt;- renderImage({ out1$out },deleteFile = FALSE) out2$corCt &lt;- subset(out2$feedback , out2$feedback[,4] == "CORRECT") out2$badCt &lt;- subset(out2$feedback , out2$feedback[,4] != "CORRECT") output$Corrects &lt;- renderText({ paste(length(out2$corCt[,1]), "/", TurnMax, sep = "") }) output$Incorrects &lt;- renderText({ paste(length(out2$badCt[,1]), "/", TurnMax, sep = "") }) out2$fct &lt;- as.numeric(length(out2$corCt[,1])) / as.numeric(TurnMax) output$corPerct &lt;- renderText({ as.character(out2$fct) }) if (length(out2$badCt[,1]) &gt; 0) { colnames(out2$badCt) &lt;- c("QUESTION REPO #","ANSWER","RESPONSE","STATUS") output$fResHd &lt;- renderUI({ h3("Final Results:") }) output$nextIFB &lt;- renderUI({ actionButton("nextIFB", label = "Next Incorrect Feedback") }) output$feedback &lt;- renderTable({ out2$badCt },include.rownames = FALSE) out3$currow &lt;- as.matrix(out2$badCt[1,1:3]) output$currIC &lt;- renderTable({ out3$currow },include.colnames = FALSE) out3$curobs &lt;- out2$badCt[1,1] out3$img2 &lt;- list(src = paste0("www/testmats/fq", out3$curobs,".png")) output$fQuestion &lt;- renderImage({ out3$img2 },deleteFile = FALSE) } else { output$fResHd &lt;- renderUI({ h3("NAILED IT!") }) } turn &lt;&lt;- 1 } }) ##################FEEDBACK OBSERVATIONS################# ########NEXT###### observeEvent(input$nextIFB,{ output$prevIFB &lt;- renderUI({ actionButton("prevIFB", label = "Previous Incorrect Feedback") }) TurnMax &lt;&lt;- as.numeric(length(out2$badCt[,1])) turn &lt;&lt;- turnCtr(turn) if (turn &lt;= TurnMax &amp; turn &gt; 0) { out3$currow &lt;- as.matrix(out2$badCt[turn,1:3]) output$currIC &lt;- renderTable({ out3$currow },include.colnames = FALSE) out3$curobs &lt;- out2$badCt[turn,1] out3$img2 &lt;- list(src = paste0("www/testmats/fq", out3$curobs,".png")) output$fQuestion &lt;- renderImage({ out3$img2 },deleteFile = FALSE) } }) ########PREVIOUS###### observeEvent(input$prevIFB,{ if (turn &gt; 1) { turn &lt;&lt;- turn - 1 } if (turn &lt;= TurnMax &amp; turn &gt; 0) { out3$currow &lt;- as.matrix(out2$badCt[turn,1:3]) output$currIC &lt;- renderTable({ out3$currow },include.colnames = FALSE) out3$curobs &lt;- out2$badCt[turn,1] out3$img2 &lt;- list(src = paste0("www/testmats/fq", out3$curobs,".png")) output$fQuestion &lt;- renderImage({ out3$img2 },deleteFile = FALSE) } if(turn == 1){ output$prevIFB &lt;- renderUI({ }) } }) }) Feel free to recreate it for personal use.
I'd probably go about it by using arrays and a loop to move along them
The base exam is focused almost exclusively on concepts of how SAS processes data. There is zero statistical content. The base exam is written in such a way that is meant to show you are competent reading in and processing data. Expect questions on syntax to read in delimited text files, set and merge statements, and other data manipulation concepts. You don't need to be an expert at everything. If you're going to study for the base certification exam (which I don't necessarily suggest, depending on what you want the certification for), I'd focus on getting a high enough score to pass and move on. The concepts covered in the exam are archaic and, in my opinion, not particularly relevant in today's SAS programming world.
Many thanks for sharing this.
I think that that depends on how you're using SAS. In academia for instance cleaning fairly small, double entered data is fairly common. Yes the end result is statistical testing so not really applicable to the thread but digging into the data itself is absolutely necessary as using import functionality in SAS can have some weird outcomes such as truncated data and missing observations based on how it was entered. This exam sounds interesting but geared toward uses of SAS that I've never encountered. For instance I've never performed a point and click analysis of anything and I've used SAS most every work day since 1997. What's the context for base certification? 
Pretty!!
While there will always be exceptions, my opinion based on daily working with SAS as well is that the topics which are the bulk of the base certification exam are not particularly relevant for today's modern SAS use. For example, I'm guessing a significant chunk of users would import data using the Enterprise Guide point and click wizard rather than writing a data step. I appreciate the need for understanding the program data vector and all the components of reading data into SAS. These are among the fundamental concepts covered in the base certification exam. But I don't think these are really the essential skills of a SAS programmer in 2018. Note that this is simply my opinion; disagree with me all you want, that's ok with me.
Set up SAS university edition in the AWS cloud and connect to it through your device's web browser. https://support.sas.com/software/products/university-edition/faq/AWS_runvApp.htm
I tend to agree with you. I definitely want to learn the fundamentals but want to understand the statistical theory more. Do you have any recommendations to refreshing or learning those statistics again? I graduated over a year ago and had 3 statistics classes (which I performed well in). However, that whole "if you don't use it, you loose it" saying is starting to creep in. I recently received a promotion at work and would really like to show my interest in and build expertise in statistical analysis. 
Nothing specific comes to mind. But I know there are plenty of videos of college courses you can watch through the MIT open course web series. I'm sure something in here will scratch the itch you're looking for. https://ocw.mit.edu/courses/find-by-topic/#cat=mathematics&amp;subcat=probabilityandstatistics
Totally forgot about their video lectures and classes! Thanks
Arrays and loops! DATA myHospData (DROP=i testICD); SET HospData; DiabetesFlag = 0; ARRAY icdlist{3} icdvar1 icdvar2 icdvar3; DO i = 1 TO 3; testICD = icdlist{i}; IF testICD ne '' THEN testICD = SUBSTR(testICD,1,3); * First three chars; IF testICD = '250' THEN DiabetesFlag = 1; END; RUN;
Or more concisely, using your example. 2 fewer assignments, no if/then's, no substr() function call. do i = 1 to 3 ; DiabetesFlag = (icdlist{i} =: '250') ; /* does array element begin with '250', 1 = yes, 0 = no */ end ; If you were specifically looking for the '250' and nothing else, you can make it even more efficient by not continuing the loop once it's found : do i = 1 to 3 until (DiabetesFlag) ; DiabetesFlag = (icdlist{i} =: '250') ; end ; 
This seems do-able with input statements alone. Please could you post a few lines of raw sample data and the corresponding output you're trying to produce?
Input records: D04BH_ITEM 1412 79001141278BH_STORE PUPPY $100 D04BH_ITEM 1452 79001145212BH_STORE PUPPY $25 BH_Store Puppy $25 D04BH_ITEM 1453 79001145312BH_STORE PUPPY $50 BH_Store Puppy $50 D04B_0304 79001030413B_COLORED BOWS Results I want: 790-01-1412, BH_STORE PUPPY $100 790-01-1452 BH_STORE PUPPY $25 790-01-1453 BH_STORE PUPPY $50 790-01-0304 B_COLORED BOWS
That 4th input record makes this a little more awkward, but I'll play around with it for a bit. Does the item description always start with a B?
Your initial post suggests that there's a double space before the item description repeats, but you haven't included this in your sample data. Which is correct?
No, not always. In fact it's much more common to not begin with a prefix at all. I did modify the code to just run this in one data step, so at least that's something. data item_qry; infile GETFTP PAD lrecl=277 missover PAD; input @1 string $80. ; start=find(string,'79001'); if start=0 then delete; old_ITEM=substr(string,start,9); ITEM=(substr(old_ITEM,1,3))||'-'||(substr(old_ITEM,4,2))||'-'||(substr(old_ITEM,6,4)); marketing_code=substr(string,start+9,2); description=substr(string,start+11); new_field=tranwrd(description,' ','?'); stop_pnt=find(new_field,'??'); string_i_want=substr(new_field,1,stop_pnt-1); ITEM_DESC_T=tranwrd(string_i_want,'?',' '); keep ITEM ITEM_DESC_T; run; 
There should be a lot of spaces of inconsistent length between the descriptions in records 2 and 3. Can't figure out how to get that formatting to copy over. 
Try this - it should work as long as there are always at least 2 spaces between the duplicated descriptions and no consecutive spaces within a single description. data want; infile cards missover; input @'79001' +(-5) T_ITEM $11. ITEM_DESC_T &amp;$32. @1 @'$' PRICE :8.; length ITEM $13; ITEM = catx('-',substr(T_ITEM,1,3),substr(T_ITEM,4,2),substr(T_ITEM,6,4)); drop T_ITEM; cards; D04BH_ITEM 1412 79001141278BH_STORE PUPPY $100 D04BH_ITEM 1452 79001145212BH_STORE PUPPY $25 BH_Store Puppy $25 D04BH_ITEM 1453 79001145312BH_STORE PUPPY $50 BH_Store Puppy $50 D04B_0304 79001030413B_COLORED BOWS ; run;
Damn that is slick! Totally worked! Thank you! I had no idea you could use @ and a string as a starting point. That's a neat trick. 
One last thing - make sure you set `missover` on your `infile` statement when using doing that, or else your input statement will carry on searching past the end of the line. It's also occasionally a useful technique for importing json files, as long as the structure isn't too complex.
It looks like you've already gotten a solution, but for completeness, I always like plugging regular expressions. I'm not at a SAS machine, so I'll have to illustrate for you in Python (SAS does support regexps, so similar methods should be possible): import re Items = """D04BH_ITEM 1412 79001141278BH_STORE PUPPY $100 D04BH_ITEM 1452 79001145212BH_STORE PUPPY $25 BH_Store Puppy $25 D04BH_ITEM 1453 79001145312BH_STORE PUPPY $50 BH_Store Puppy $50 D04B_0304 79001030413B_COLORED BOWS""".split("\n") print(Items) Pattern = re.compile(r"\s(7\d+)\s*(?=(.+)\s*\2|(.+))", re.I) for Item in Items: match = Pattern.search(Item) print(match.groups()) yields: ['D04BH_ITEM 1412 79001141278BH_STORE PUPPY $100', 'D04BH_ITEM 1452 79001145212BH_STORE PUPPY $25 BH_Store Puppy $25', 'D04BH_ITEM 1453 79001145312BH_STORE PUPPY $50 BH_Store Puppy $50', 'D04B_0304 79001030413B_COLORED BOWS'] ('79001141278', None, 'BH_STORE PUPPY $100') ('79001145212', 'BH_STORE PUPPY $25', None) ('79001145312', 'BH_STORE PUPPY $50', None) ('79001030413', None, 'B_COLORED BOWS') You might have to tweak the ID number a bit to fit and concatenate the second/third return values in SAS to get the desired output. The magic here is the pattern: `"\s(7\d+)\s*(?=(.+)\s*\2|(.+))` * `\s(7\d+)`: find the first occurrence of digit 7 after whitespace and capture all the digits after * `(?=(.+)\s*\2|(.+))`: conditionally return capture groups depending on if you see a repeated substring in the rest of the input (`(.+)\s*\2`) or the rest of the string itself `(.+)` It looks like complete gibberish if you haven't done regexps before, but it's very handy for pattern-matching with uncertain lengths. 
Thank you! I’ve used these before but it’s a major blind spot still, so I appreciate all additional exposure! And it’s always nice having more than one solution to a problem 
Thanks!
Thanks! 
I've worked a lot with SAS/VA in the past. Despite the very good good features of the system, unfortunately I found the report creation tool very limited. I simply wasn't able to create what I wanted to create, explain what I wanted to explain. Would consider it again in the future with the relative patches and improvements, for the moment I just can't recommend using it. 
Look at the dataset structure. You are doing something like this: ONE TWO X . X . X . . X . X . X . X 
Right. I personally prefer tableau as well. 
Tableau is good to fork over to the BUS end, but it has its limits too. SASVA is more for heavy statistical analysis IMO not reporting to Director / C level or higher, plus the dashboards are easy to adjust for additional requests aka scope creep.
I mean it all depends on what the project is, right? When I was working health insurance tableau was the goto, now in academia there is less emphasis on the enhanced visualizations. And when there is a need then it is usually a random MIT fellow who does it from scratch in python.
Yes on the project base, cant really speak on the MIT fellow.
SOLVED: I had to add those -emailhost &amp; -emailsys components to an additional sasv9.cfg file saved in a subdirectory. I also changed single-quotes to double-quotes on the IP address host name, if that mattered. 
Hey thanks alot for the help man! You really saved me. I do have a few questions though It's been awhile since I've used sas so what exactly does "Infile datalines" do? Second "if index(upcase(_from),'ONE') then FROM=1; else FROM=2; " What exactly is going on in that statement. I know with it I know longer get the "the class has more than 2 variables" error that I was getting but aside from that I'm just trying to clarify that I know what it is going on for future reference. 
[removed]
&gt; SASVA is more for heavy statistical analysis IMO I personally disagree with this.
You are welcome. *datalines* is just another code for inputting values manually in a datasets, very similar to *cards* which you used in your code. I'm simply more familiar with this, nothing strange. -I wanted to create the classes. What I did was using the *indsname=* function in the set statement. This is creating an hidden variable named *_from* (the name after the equal) which will take the 2 level name of the dataset from which the observation is coming (since with *set* you are simply stacking observations). For the observations coming from the dataset ONE, the variable _from will have value WORK.ONE, from the dataset TWO the variable _from will have value WORK.TWO. The function *index(_from,'ONE')* will resolve with boolean (logic) positive (1) if the string of _from contains the substring 'ONE' - the observations coming from the first dataset, assigning with the *then* the value 1 to the grouping variable FROM. 0 otherwise. 
Shows how to get SAS University Edition installed.
This is definitely what I can see in the real world. Maybe it could be true, I mean, if you have skills in data science and data programming such as R or Python, I could hire you and spend some time training you, but on a junior level. And I'm quite sure OP doesn't want to start back from his junior role. 
Speak with the IT dept of your university, I'm quite sure they will sort this out. We had a CITRIX remote access to our profile on a windows machine, basically a big streaming window which includes what you would see logging on the university's computer - with SAS and other stuff installed. 
I'm not at my machine yet, but this looks like it would display the entire contents of a each column as approve or disapprove, but I've got a combination of both in each column. I'll check it out in an hour.
Are you selecting specific person id's or all? I find it tiresome to be maintaining the where clause on repeatable tasks like this...for example using: where person_id in (123,456,789) I tend to make it into a 2 step process. Step 1 - create a macro variable which has the list of person id's Proc sql noprint; Select distinct person_id into :varname separated by ',' From tablename Where...criteria etc; Quit; Now select the record ids using something like this: Select record_ids from table name Where person_id in (&amp;varname); Quit; 
I have around 200 or so specific ones to select. I'll try this out, thank you muchísimo!
The prep guide is your best resource. Go chapter by chapter, read and take the quizzes. It will tell you what you don’t know and give you a lot of practice answering the style of questions asked. Good luck!
I'm biased as I built the site, but the best resource for SAS questions is - https://sasensei.com! If you have questions on the site itself you can also post them on https://www.reddit.com/r/sasensei/
Thanks - I actually visited the site last night through a suggestion from another post. Really like the format. Good work setting that up. 
thanks! it's still under development.. happy to receive any feedback / ideas for improvement.
There's a source far better than the book. This website is exactly the same as the book, the text is identical, but interactive, step by step, with examinations and exercises on each topic, and it saves the progress you are doing. I found it far better to follow than the book which usually get superboring in few chapter. https://jpsmonline.umd.edu/SASOnlineTutor/sot12/en/60477/index.htm I enjoy sasensei very much, it's a very good website, I love it. But honestly I would disagree on the fact that is a good source to prepare the exam :(
Analytics related to finance/revenue. Ideally, I would like to review assessing model performance in regards to linear and logistic regression, clustering, ARIMA, etc.
Analytics related to finance/revenue. Ideally, I would like to review assessing model performance in regards to linear and logistic regression, clustering, ARIMA, etc. 
[removed]
If I was you, I'd create a table of unique IDs. Then I'd join that with the other table with the records to get all the records for the IDs you want.
If the strings are equally formatted (every variable has exactly the same number of digits), then a very basic substring function repeated could seem the best approach: String example: AAAABBCC Data a; Set B; Var1=substr(oldvar,1,4); VAR2=substr(oldvar,5,2); Var3=substr(oldvar,7,2); Run; Substr(par1,par2,par3) Par1 is the starting variable Par2 starting digit for the actual variable Par3 how many digits in the variable Sorry for the shape of the answer I'm on mobile 
Thank you very much. I’m on mobile at the moment as well, but this looks like it will likely do what I need. 
I am starting from plain text, can you explain a little more? Sorry I’m new to SAS. 
I recommend you be very open and honest not only about your current abilities, but your expectations about how you will pick things back up. If they can't live with this, you may not be the right candidate. 
Ok. R squared will be big. That's what most financial regressions will be evaluated on. That and whether or not they make sense. It's going to be regression so you need to understand autocorrelation with lags. The annual cycles will be a part of that. Then there's principle component analysis to reduce dimensionality. Think all subsets and picking the best model if you're familiar with R. That gives you the strongest variables for prediction. You'll be doing ARIMAX models to be more specific, so go read about them and look up some SAS info on it. Idiosyncratic models are something you should be familiar with. Depending on what you're looking at and what the goals of the analysis are (stress testing, revenue driver understanding, equities/capital markets) the you will change you how you develop the model. You'll have a boss and some business line people and you want them to know that whatever you find you'll run by them to make sure the variables make sense. Sometimes they'll have you change it to something completely wrong, but that's how the world works. Good luck!
[Documentation: SAS input statement](http://support.sas.com/documentation/cdl/en/imlug/64248/HTML/default/viewer.htm#imlug_langref_sect159.htm) The input statement is incredibly flexible and reading in fixed width data is really one of its strengths. For example, you can just specify a variable name and the columns that it is in: data example; length country $8; input country 1-8 year 10-13; datalines; US 2014 US 2015 US 2016 Canada 2014 Canada 2015 ; run; An equally correct way might be to just specify the starting column (if necessary) and the length. There really are dozens of ways to do this in SAS. data example; input country $8. @10 year 4.; datalines; US 2014 US 2015 US 2016 Canada 2014 Canada 2015 ; run;
Here's one I wrote a few days ago in response to a similar sort of query: https://www.reddit.com/r/sas/comments/7qvepk/alternative_to_multiple_tranwrds_when_scan/dss8rg8/
Were you able to pass the Base and Advanced exam using only this SAS Online tutor? https://jpsmonline.umd.edu/SASOnlineTutor/sot12/en/60477/index.htm 
Were you able to pass the exam using only these resources? 
I've passed the base with &gt;95% with no study, but I was programming sas on a daily base since 2 months, I was on my internship and the exam was free cause I was a student working on my master thesis. After 2yrs I've passed the advanced with &gt;85%, I was working in the same company and programming sas on a daily base on a hardcore level. But still, I had to study, advanced is not easy, don't underestimate it. Advanced includes some topic which I've never covered on my job related task like prg3 (indexes and similar). With SQL I was not superskilled but I was definitely able to use it for standard tasks, therefore i just had to add something like subqueries usage and similar. For macro I only had to refresh some of the stuff you will almost never use in your life. Yes, I've prepared the advanced with the tutor linked, it is a sas official course, it's there cause I suppose some university is using it and forgot to protect it. It includes everything in the book word by word (not joking, it is mostly a copy paste thing from the prep book) but it is far better cause it will keep trace of the modules already done, propose more exercises than the book, remember the errors in the tests. And believe me, pressing next after reading a subchapter when fully understood it will make this far less boring than reading that kilogram of book (which I bought original). I don't know about the base tutor if one exists, I've never looked at it. Tldr: yes, it prepares you the same way as the book because it actually IS the book.
Thanks a lot. I found one for the base as well and I plan to take both exams in the next few months. 
Ok. Good luck. Take your time with the advanced, believe me.
I had used Base SAS certification book and Q&amp;A dump from a friend. I found this recently and it does cover base SAS certification material. 
I'm not at a SAS computer to check, but I would approach this using proc means or summary. proc means data = yourdataset print min max; var listofyourvariables; run; This possibly will have issues if your variables are character.
First of all you need to find a definition of *invalid value*. If we are speaking about univariate outliers, then you could consider giving a look at the k-sigma rule, where usually k=3, or the famous boxplot rule according the distribution of your variable. Both the rules are pretty easy to be applied in SAS, probably easier with a proc sql than datasteps due to the column-wise calculation of mean, sd and subsequent derivation of critical points for the first case or median, quartiles and subsequent derivation of critical points for the second case.
Do you mind taking a look at the code I tried? I'm successfully importing the data and creating the HMDA.HMDA2000 SAS file. When I open the HMDA.HMDAyear file I get a "Note: Data set has 0 observations" message. If I open the HMDA.HMDA2000 file, there is one variable and each observation is a unique string. I'm trying to break the string into variables which works correctly with a dataline argument. Why isn't sas finding the observation in HMDA.HMDA2000? proc import datafile="C:\Users\gwh13\Desktop\HMDA\HMDA2000.LARS" out=hmda.hmda2000 dbms=csv replace; getnames=no; run; data hmda.hmdayear; infile hmda.hmda2000 dbms=csv replace; input @1 Year $4. @5 Respondent $10. @15 Agency $1. @16 Type $1. @17 Purpose $1. @18 Occupancy $1. @19 Amount $5. @24 Action_Taken $1. @25 MSA $4. @29 State $2. @31 County $3. @34 Census_Tract $7. @41 Race $1. @42 Co_Applicant_Race $1. @43 Sex $1. @44 Co_Applicant Sex $1. @45 Income $4. @49 Purchaser_Type $1. @50 Denial_1 $1. @51 Denial_2 $1. @52 Denial_3 $1. @53 Status $1. @54 Sequence_Number $7. ; run; 
Thank you! I tried this and i'm still getting the "Data set has 0 observations' message. [Here](https://imgur.com/a/JznnY) is a link to what the hmda2000 file looks like. 
I got it working! Thank you. 
What kind of jacked up class forces one to use SAS with a caveat of no previous coding skills needed. That is like putting a 14 year old behind the wheel on the freeway at rush hour and saying "now this is the gas and this is the break....."
Here are a few training resources that may help if you're new to SAS. They range in 'How To' tutorials, webinars, documentation and free e-Learning: https://www.sas.com/en_us/learn.html &amp; http://support.sas.com/training/us/sp1.html I saw you had the box plot documentation, perhaps this one may, may not help: http://support.sas.com/documentation/cdl/en/procstat/67528/HTML/default/viewer.htm#procstat_univariate_examples05.htm I'd also suggest in addition to posting here, the SAS Communities https://communities.sas.com/t5/Learn-SAS/ct-p/learn is great for posting programming / content related questions. SAS users and technical folks can help you there.
Just use a long length initially if you're not sure, and trim down to a shorter length on a second pass once you know what the longest value is. 
[proc import example](http://support.sas.com/documentation/cdl/en/proc/61895/HTML/default/viewer.htm#a000314361.htm)
I poop out of my butt.
I'd like to add that proc import tends to use a hilariously low number of rows to guess how long a string field should be. It's 20 observations by default. So if you're importing a dataset and the first 20 string fields are blank or short, later observations will be truncated anyway. I add the option guessingrows=32000. There's a theoretical performance hit but I haven't noticed it. If you're worried about performance you should use the autogenerated data step anyway.
The Little SAS Book by Delwich &amp; Slaughter is my go-to. Also the Ron Cody book.
I second The Little SAS Book.
Here are a few options for new SAS users: https://www.sas.com/store/books/categories/getting-started/cBooks-cbooks_categories-cbooks_categories_3-p1.html Here are some Visual Analytics recommendations and data manipulation titles you may be interested in as well: https://www.sas.com/store/search.ep?keyWords=visual+analytics&amp;action=Search and https://www.sas.com/store/search.ep?keyWords=data+manipulation&amp;action=Search
Also has a workbook. Let’s you apply more of what you learn
Whats the biggest difference between the Little SAS book and the EG one? I've ordered the EG version from SAS as I am using point and click. I am looking for books to recommend work to possibly buy.
Seems to get the job done, thanks!
I agree with all of that! The Little SAS Book "signature" format is to describe the most useful tasks in a simple 2-page format. The EG version is mostly about the point-and-click approach. The SAS edition is all about the coding approach. The coding approaches work in EG too, so your preference might depend on how much programming you want to learn/apply. Both editions have recent updates: the SAS edition covers SAS 9.4, and the EG edition covers v7.1. 
no
As with anything, learning the skill is very different to executing it in the job. However, an entry level analyst job seems like it would be a good fit for you. 
Hello, thank you for your reply. If I do not have years of experience in SAS programming, but have experience with other programming languages (R, Python, etc), will employers consider those “other programming experience” as relevant experience? There are not a lot of entry level Statistical Programmer jobs - how can I gain experience when no one wants to hire me?
It depends. From what I've seen many job postings require analytical/programming experience and list SAS as a plus; which means that they trust that somebody with a good track record as a programmer could pick up SAS on the job if necessary. If they specifically say that they require a number of years experience in SAS they may be less flexible. I work in a "SAS shop" that has hired R programmers in the past who demonstrated an ability to pick things up quickly in interviews. &gt;There are not a lot of entry level Statistical Programmer jobs - how can I gain experience when no one wants to hire me? It's a conundrum; my solution was to get a Master's degree. Alternatively you could try to build a portfolio by doing freelance work or projects using publicly available data. Good luck!
Do you have any experience in SQL? Most data operations can be done using SQL within SAS.
No, sorry to say. SAS, in the real world, is not really a programming language, it is an entirely different way of doing things in surreal unexpected ways. Nothing any of the trainings do will make you anything other than a entry level ready. SAS and all of its BS not working as expected or the way any other rational piece of software works has to be learned through experience. Sure you could probably pull a query or two or even get some basic report, but without hands on, there is little way you are going to grasp the load of crap you have to do to get a real data set (not a perectly set up clean data set custom built as an optimal case for training) from multiple databases into LASR server to generate a neural net model to implement in real time decisioning engine then feed the output back into SAS VA for interactive report generation. That, my friend, needs battle scars.
Hello, Yes, I know how to manipulate dataset by using SQL commands. 
Hello, interesting. what did you mean by SAS (the eco system)? To me, SAS stands for Statistical Analysis System. 
review of the event: https://www.linkedin.com/pulse/slug-vanquis-bank-plans-march-vasilij-nevlev/
Ya that’s what we’re doing. Didn’t know if there was a quick answer. 
I started my career as an analyst/programmer working for research firm that had contracts with a mix of public and private clients. It was a challenging place to be as a novice because there was always some pressure to be as efficient as possible, but I did not always know the shortcuts that would get me there. This firm had a pretty good mix of contracts, but there were definitely times when I had to walk around and try and sell myself to different groups as one contract ended and another one started up. Looking back I would say it was a bit of a burnout position, but I learned a lot from it, met some great people, and ended up working on some international contracts around the world, which was interesting. It prepared me well for the next phases of my career.
It can be work that is very demanding depending on the CRO. Clients will want results, and quickly, and that usually depends on your data being clean first, which is another whole section of the industry. So often you are waiting and then rushing to deliver analysis in a very structured way. Depending on the type of programming (statistical, if you see mentions of Adam and SDTM), you will also spend time validating the work of other programmers. If you can find a spot as programmer in the data management side of things (which seems to be more rare, as they usually get looped into other more wide ranging positions) you might end up with a little more freedom to program things as you please as long as they deliver the information that is needed. However, I'm pretty certain that statistical programmers will get paid a bit more. I personally think you only stand to benefit by being local if at all possible because then training, especially being new to the industry, can make things a lot easier. However, if you are at a very large CRO, your work life balance can start to fall on the wayside.
Yeah, would need to look at the logs 
Thanks. It turned out to be a licensing issue. SAS was able to fix it for us. 
Huh, I wouldn't think SID problems would cause that. Glad it got fixed! Do you have different expiration dates on the same license/ 
Yes! That was the issue I believe. It was our developer that called them. 
Thanks for the response. That is interesting. I'm a SAS programmer in my current job, but the concept of proactively moving between contracts in this way is new to me. The CRO roles I have been looking at are mostly home based as well, which mightn't lend itself to that brand of networking. Did it feel like a burnout position because of the lack of opportunity to progress, or was it a workload/pressure kind of thing?
Thanks for taking the time to respond. The jobs I have seen, that seem to suit my background, lean towards statistical programming. Plenty of references to Adam and SDTM in the descriptions. I can see the value of your point about being local, and that is one of my concerns. I don't want to start into a remote job and force myself up a learning curve that is too steep.
Ah! That makes sense. :)
Thank you for the response - it is helpful. I have been using SAS for about 3.5 years in a bank, largely focused on data/reporting with some modelling. My degree is Maths and Statistics. It definitely seems from jobs boards and vacancy listings that there is a demand for programmers. My main concerns are about the practicalities of home based work, since I know so little about the specifics of it in this industry. I don't want to start into a new job and find myself unemployed two weeks later! Presumably it varies by CRO, but in your experience is there enough initial training/induction for a programmer new to the industry? What is a typical home based setup regarding hardware/software/SAS licensing? Again - thanks for the response!
It was a burnout position for me because the deadlines were often very tight. There were a couple of projects where I was working seven days a week, 14 hours a day, for months on end. It was also a challenging because sometimes we would win contracts, and other times we would lose them, so there was always a need to be looking ahead to next week's time sheet and making sure that you had projects to charge. Your opportunities to progress are really going to depend on your managers. I worked for one group that gave me a lot of recognition and promotion and allowed me to move up and take more senior roles. Other managers actively stood in my way because they needed someone who could get the code written in a certain period of time and at a certain rate. That is when I started telling recruiters I was available.
I got hired with SAS experience, but no clinical experience. Then again, it's not the statistical part. Metrics, etc has been my forte, and that's what I focus on. I'm local, and got to learn that aspect on the job. I don't have certifications or anything like that.
Are you on a fully homebased solution?
I'm local, so I'm mostly in office, but I have the choice to move more home based at least part time. I won't though, as I'll go insane. I work from home one day a week, but that's it
Thanks, it was just to followup on the request by op of being hired fully homebased from day1 with no experience in clinical programmind. I don't think there will be many opportunities of these sort.
You are using an invalid option, try commenting it out?
commented the first one out and got this error. ERROR: Physical file does not exist, /opt/sasinside/SASConfig/Lev1/SASApp/C:\users\**********\desktop\myfolders\dat_files\limitedip16.DAT.
Now you’re referencing a file that can’t be found...adjust the file path.
well obviously it's trying to jam two filepaths together: /opt/sasinside/SASConfig/Lev1/SASApp**/C:\**users**********\desktop\myfolders\dat_files\limitedip16.DAT. figure out where the actual file is and specify it in quotes. or it might be using a libname location that you didn't change. hard to know without the rest of the code.
I couldn’t find either of those file paths in the sas file. 
Couldn’t find either of those paths in the sas file though. 
Does it say libname anywhere
ill have to check tomorrow left for the day
Beamer...once you go Beamer you will never touch PowerPoint again. But there is a 89° learning slope, unfortunately.
Did you follow the step in the setup instructions for SAS University Edition about setting up a shared folder that the VM can access? Read them again, follow them very carefully, and put your .dat files in there (from the Windows side). Then within SAS, you should find them in `/folders/myfolders`
I work in government...so have to use it lol
 here is the code i was sent https://www.health.ny.gov/statistics/sparcs/docs/ip_v2.sas replaced all the file paths with /folders/myfolders/dat_files/
it does not, but if you are curious what the file looks like its on the web at https://www.health.ny.gov/statistics/sparcs/docs/ip_v2.sas replaced all the file paths with /folders/myfolders/dat_files/
That is the same point I would have with Beamer, just re render, it pulls in the new data and whamo. But I get it, sometimes you can't escape the MS beast. My current job I can't get them off MS Word despite how frustrating it is.
I learn SAS because my job requires me to use it. But I would swap for Python in a blink because it's an all-purpose language, unlike SAS or even R. And the sources for help in SAS are _very_ scarce.
 /opt/sasinside/SASConfig/Lev1/SASApp/ This is a Linux file path leading to (what looks like) the configuration directory for a SAS server. C:\users**********\desktop\myfolders\dat_files\limitedip16.DAT. This is a Windows file path from what appears to be your local machine, going to the .DAT file. Not sure where your code source is, but there's no reason for both of these paths to be together. They're going to entirely different things.
The above comment. But don't sweat the scorecards in particular, a scorecard is just a regression model to predict how good a bank thinks the customer will be. Get familiar with the idea of regression, and then apply that to a scorecard. Also if you're interested in retail credit risk, get familiar with the ideas of capital (money banks keep in reserves) and impairment (loss) - and how you can model these with pd, ead, and lgd. If you know the theory behind that you'll know far more than most of the people who work in rcr. 
Look into books by this guy: https://support.sas.com/en/books/authors/naeem-siddiqi.html
What is your filename statement for file EIUM? Also, this is not valid: infile eium truncover lrecl=2500 /PAD ignoredoseof /obs=10000*/ ; You might want: infile eium truncover lrecl=2500 PAD /*ignoredoseof*/ obs=10000; The directory "/opt/sasinside/SASConfig/Lev1/SASApp/" is in the University Edition virtual machine. The other file name, "C:\users**********\desktop\myfolders\dat_files\limitedip16.DAT", looks like it might be the result of an invalid comment statement. 
Why do you say the sources for help are scarce? All of the SAS documentation is online, and Google typically yields a useful result.
But creating a new table is so easy, why not do it that way? Then if you screw up you won’t ruin your data
I won't ruin the data, I'm just trying to add a new variable. If I don't get the variable correct the first time I can just drop it. Plus if I make a new dataset every time I add a variable, I have to come up and remember a new name.
Data datasetname; Set datasetname; Format newvar $20.; Do someshit Run: That will add a var to the end
The problem is that sometimes adding the new variable causes unintended consequences. For example, if you're merging to another data set to add the variable, there could be duplicates in that data set. That would create duplicates in the resulting data set.
Overwriting datasets is not good practice when doing data analysis in SAS. Besides, if these datasets are stored in the work library, they will automatically be deleted when you terminate your session. If you have them saved in a permanent library, then you can use the: proc datasets lib=yourlib nodetails nolist; delete &lt;datasets separated by spaces&gt;; run; 
Just do dataset2 then dataset3 etc in your work folder each time you change it until you have what you want, then put that in your permanent folder with whatever name
Yeah it does. I use this all the time on temp data I'm working with.
I second the google. I google the shit out of SAS questions daily. Their Communtiy pages are helpful for ideas on solutions imo
I wouldn't say necessary as its language is really only useful if using it i think. I would learn R and Python over SAS unless you needed to learn it. They are open source and alot of resources for learning that are free. SAS has only a handful of free online classes. If you are a Veteran then I'd learn SAS. They offer ALOT. All E-learning classes(same thing as in class) free, 50% of class room and web classes, 50% of sas book store, free exam vouchers and some other stuff. If you can learn R, you can learn SAS lol.
I'm going to leave it for you hahaha 
I started to type an answer but I'm not sure my output would be on track with what you are looking for. Can you mock up the output?
Unfortunately, I do not know how to type out things in a table format on reddit. but , consider columns /var Day 30 ,day60, day90, return a count or sum of occurrence of individual report_strat variable. 
Put 4 spaces at the beginning of each line. Then it will look like this.
Ok. Will do when I return to cpu 
ok here goes. Create a SQL table or sas dataset. 3 columns of variables for which I want to find sum in functions of events in the rows (in the rows there are 11 unique events that occur over 18 millions time in my original dataset. In the orig dataset, each time DLQ var is occurs in Day 30,60,90 , there is a 1 for count) DAY_30 DAY_60 DAY_90 DLQ_1 count count count DLQ_2 DLQ_3 ... DLQ11 
add fake rows into your data with corresponding zeroes. Tabulate cant tabulate data it doesnt see. (I hate sas)
Great a time series as your Have based on year as the ID and count as the var. I think the code to change all . To 0 is something like Data want; Set have; Array change all_numeric; If change = . Then DO; change = 0; End; Run; Proc tabulate stuff I'm sure this has some errors as I'm free thinking it.
Try using the /printmiss misstext=‘0’ in the table options. Table $clas_var /printmiss misstext=‘0’; 
I still think SUGI (SAS Users Groups International) is a better name. It had a different spirit when the focus was on bringing together users from different local groups to share tips, etc. Since I'm feeling nostalgic, I will also mention that I miss the glory days of comp.soft-sys.sas (the Usenet interface to SAS-L). That was an online community that really influenced many features in SAS, e.g. hash tables and perl regular expressions.
I hate to be that guy but SAS feels like a dying language and the global forum feels like a veterans reunion club. As a somewhat younger statistician, I am almost embarrassed by knowing and using SAS more than R or Python. In my organization, I am even outcasted for being "the SAS guy."
I feel your pain. I was "the perl guy" at my last job. They pelted me with rocks and garbage.
The prep guide is your best bet. Read the chapters and take the chapter quizzes to find out what you need to focus on. You will rarely get 100% of the questions right - they are really tricky! I think it’s mostly multiple choice, there may be fill in the blank but I can’t remember right now.
Yes, it's mostly multiple choice with some questions where you are expected to type out the answer. The exam generally doesn't ask you to write multiple lines of code at a time but rather fill in missing code in procedure or a data step.
Study the behavior of what happens when you leave off or add an unnecessary ; most of the questions deal with behavior when you code wrong.
Please post an example of the sort of data you've got already and what sort of IDs you're trying to generate. Text rather than images please.
Depends on how you're identifying a person. Unique first/last name sufficient? Or would you have to include date of birth or other fields in case of duplicates? Once you have decided which fields uniquely identify a person, you can sort the dataset with the nodupkey option into a new dataset to get a unique universe of keys. Keep only those keys (you will be merging this back into the original dataset and don't want to overwrite existing values). For this new dataset, you can do `NewID = _n_` to get a unique numbering from 1 to whatever per person. Then you sort the original dataset and merge the new IDs in.
I think you have the right idea. For example your code could be %let id=A1; proc sql; create table TABLE2 as SELECT * FROM TABLE WHERE Column="&amp;id."; quit;
It would be based on last name, first name, and DOB. Thank you for he guidance, I appreciate it!
Can you give an example of your SQL query? Not exactly sure what you mean.
If the %let is blank, then do you want the query to return no results, or not perform any filtering?
Not filter it. 
Why don't you just do one %let, and let the users code the whole statement: %let criteria= A1 = '21'; Or %let criteria = A1 in ('alpha','charlie','bravo'); Proc SQL; Select * from blah where &amp;criteria ;Quit;
There is about 6 lets that can be used in combination. 
Ok. you can do something like this. I don't have SAS right now to test, but I think it should work. If the length("&amp;id.")=0 doesn't work you can look up some other methods to test if a macro variable is empty. %let id=A1; /**this can be empty or not **/ proc sql; create table TABLE2 as SELECT * FROM TABLE WHERE (Column="&amp;id." or length("&amp;id.")=0); quit; 
I'll test that Tuesday when back to work tuesday. This is the last part to making this damn thing fully automated. 
The test is less about testing your ability to write SAS code and much more about testing your understanding of how SAS works “under the hood”. The trick questions, and there are quite a few, are rarely about pure syntax. If you understand the PDV and understand why it works the way it does, the tricks are a little easier to spot. Knowing the syntax is still important, but knowing SAS syntax just scratches the surface on the base exam. 
Other options I use to ignore blank variables are: where &amp;id. ne "" or where &amp;id. is not null
On my thinking throne so can’t test, but something akin to the following maybe? WHERE id = COALESCE(&amp;id., id) Somewhere where populated and non-populated value for your %LET id= would both perform without checking to see which scenario?
There probably is some function, but surely writing the function takes longer than your solution? Your way seems optimal, unless I'm missing something.
I found the end-of-chapter quizzes in the prep guide most useful. They were largely in line with the actual exam in terms of questions structure and difficulty.
Well I was hoping that when I was using the input statement that there would be an option to tell it the data was in thousands. Otherwise I have to type all the variable names back out or come up with a loop to multiply them all. 
I'm not aware of a function, but a loop might be your best bet. Create a macro var list using a proc contents/proc sql into statement combo. Then cycle through the vars, feeding into a if/then/else statement assessing the length of values and multiplying accordingly. Shouldn't take long to code. Let me know if you need help on that, I'm unaware of your experience level.
First off, I'd say you should be concatenating fields to create a KEY variable. I've done that with concatenating LastName, FirstName, and DOB (which I assume is not a string but doesn't really matter). data create_key; set yourdataset; new_key=cat(compress(LastName),compress(FirstName),compress(DOB)); run; 
Ok not a problem. Let me just tinker around with my code a bit and I’ll post a solution. 
Appreciate that. 
I’m surprised about this—SAS is super expensive unless you can get the SAS student access, which I’ve heard is somewhat different. Seems more relevant for a position as a programmer than grad school entry?
I have mentioned this on here before, but I used [passgaurenteed](https://www.pass-guaranteed.com/A00-211.htm) and it had a bank of ~ 140 test questions, which are updated to reflect the content of the exam. When I took my exam last spring, there were hardly any questions (if any at all) that I had not seen in the test bank. Mind you, I took a SAS programming course in college, and missed passing the exam on my first try by 1 question. I'm not sure that it's the cheapest option at $70, but it is cheaper than paying to retake the exam (take my word for it on that).
It’s not that I need this specific one. It’s just one of the credentials I can use to get into the program and it just happens to be the cheapest exam. 
Yea I have the SAS university edition that was free. 
How are you reading it in? Csv? Text file? 
I think that exactly what i need. I'll report back tomarrow at work. 
Someome asked this question last month. I provided insight about my experience [here](https://www.reddit.com/r/sas/comments/7nvozx/how_did_you_study_for_base_certification/). I passed the base cert about 2 months ago and now am studying for the advance cert. 
You can do this with a PICTURE FORMAT and using the multiplier option. Here's a sample code that would multiply by 1000. data test_data; input thsnds ; cards; 1.2345 222.302 0.857 45.309 15.30 ; run; proc format; picture thsnd low-high='0000000000000000' (mult=1000); run; data multipled_by_1000; set test_data; format _all_ thsnd. ; put (_all_)(=best.); put (_all_)(=thsnd.); run; You don't need those last two PUT statements, but I included them so that you can see in the log file how it converts the fields when you are ready to attempt this to your own code. You can read more about picture format in the [documentation](http://support.sas.com/documentation/cdl/en/proc/61895/HTML/default/viewer.htm#a002473467.htm). I have no clue what your data looks like so I just messed around with the input data. Regardless, the low-high of 16 zeroes should have you covered regardless of what the data looks like as it comes in. 
Interesting how often this kind of question comes up. Here is my obligatory plug for https://sasensei.com - a free site for practicing questions on SAS topics.
check out https://sasensei.com - it's full of original questions on SAS topics.
I’m reading it in as a csv 
I'd recommend using _numeric_ instead of _all_. That's going to blow up if there are character variables in the data set.
If you want to change all of the numeric variables in the data set, you can use this: array change _numeric_; do over change; if change=. then change=0; end;
The only way I could see to shorten your code would be to create an array and loop through each element but still multiply by one thousand. Not aware of any informats that do what you need. 
Please don't take this the wrong way, but I find it very dubious that you are making this suggestion without disclosing that you are the owner of the website. 
This actually gave me a idea. I made a marco that looped through the let statements and if it has a length greater than 0 it added it to the where statement. At the end i took off the last AND. Then passed that to the sql code. Thanks for the help
Sorry for responding to an old answer, but shouldn't it just be if by patient_name admission_date; first.admission_date; That should give one record per patient with the highest ranked admission_date ascending.
fair point, comment updated
would you happen to still have that pdf? I would love to avoid paying the 60 dollars if possible :)
Unfortunately not, I actually had the training module and it was on my old laptop that died, sorry!
[removed]
Sas itself sells a practice exam if youd like to buy it. i personally downloaded a revision app literally just typed base sas exam prep and got one for free. Its really good for revision but has a couple mistakes and the free version has lots of popup ads. Theres also sasensei
Wouldn't just having the questions to study be sufficient? If you can't figure out the answers on your own, maybe you're not ready to take the exam.
See here for exam prep + training info for the Base SAS9 certification: https://www.sas.com/en_us/certification/credentials/foundation-tools/base-programmer.html Exam Content Guide: https://www.sas.com/en_us/certification/exam-content-guides/base-programming.html Sample Questions: https://www.sas.com/content/dam/SAS/en_us/doc/other1/certification/samples/base-programming.pdf Practice Exam Info: https://www.sas.com/en_us/certification/resources/sas-practice-exams.html
Maybe you should just learn it and not cheat
It won’t really help to memorize the questions...they are different every time you take it.
maybe you should gargle my balls and mind your own damn business 
thank you - i realize that, but they are very similar from what i understand.
My experience with %include is that it runs everything in the program file you call. Not sure how you would tell it which lines/sections of the specified program you do or do not want to run. Perhaps it makes sense to split up the data steps into multiple files depending on which groups you want to run?
Thanks! The import file in question gets spit out from one of my software vendors and I am trying to semi-automate some data processing that I have to run for every project I work on. The import sas will always be different depending on the the project, but the data steps I would like skipped will be in every one. I am hoping I could have something like: %INCLUDE 'import.sas' / *dontRun X Y Z;*
There are some apps to study. Check SASs pre exam, I think it’s $50 last I looked. I used a friends for free. Maybe ask around
The SAS doc seems to indicate that you can use include to reference specific lines of code in the current program, but I'm not sure that that feature is available when calling an external file. http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000214504.htm
You could set up macro variables that are either equal to blank or *, then put those macro variables in front of the lines of code you may or may not want to run. Setting those macro variables to * before running will comment out those data steps. %let exclude=*; &amp;exclude data indata; &amp;exclude set mylib.data; &amp;exclude run;
&gt; run Thanks! I am starting to feel like this belongs in /r/ChoosingBeggars I am trying to set up this program so that people with very little SaS experience can go in and change the Path to where the text files and import SaS is located and run it without having to do anything else. I am starting to think that this is not possible. More job security for me I guess.... :)
a steady stream of new SAS questions can be found here: https://sasensei.com disclaimer - I'm the site owner
Does https://sasensei.com/ count?
thanks!
I actually enjoy trying this. Sometimes I get really stumped. But I am looking for something closer to real-world use. Like “here is ‘X’ data set, you can download it, and the client wants to compare ‘blank’ and ‘blank’ or generate a report that shows ‘a,b,c,d,etc’ I’m not even really sure how to ask what I want either.
You could look at some of the projects on Kaggel (competitions) but the projects are not SAS specific. However you can definitely use SAS to solve them. For the completed ones you could look at the results as well. Not sure if that would help
Initiate two macro variables before you run the include statement, where one variable contains a string of sections you want to run, and the other contains a string of sections you don't want to run. %let do_run= a b c; %let dont_run = x y z; Within the input file, include macro logic that skips the steps in &amp;dont_run, and doesn't skip the steps in &amp;do_run. Apologies if I've missed the point of the question!
Instead of using `%include` statements, write a macro, and specify the path to the text file as one of the parameters, with further parameters for the steps you want to include/exclude. This is pretty much exactly what SAS macros are for - selective and dynamic re-use of code. E.g. %macro import_stuff(file=,run_part_1=Y,run_part_2=N); /*Always run this section*/ data output_dataset; infile "&amp;file"; input a b c; run; /*Run this section only if requested - default yes*/ %if &amp;run_part_1 = Y %then %do; /*Conditional data step and proc logic goes here*/ %put Logic for part 1; %end; /*Run this section only if requested - default no*/ %if &amp;run_part_2 = Y %then %do; %put Logic for part 2; %end; %mend; Then to run it: /*With default parameters*/ %import_stuff(file=/tmp/myfile.txt); /*Skipping one section*/ %import_stuff(file=/tmp/myfile.txt, run_step_1 = N);
Stolen: https://blogs.sas.com/content/sgf/2018/02/16/efficiency-at-your-fingertips-keyboard-macros-and-function-keys/
Or if you have an suggestions for where I can find someone to take on the project I'd appreciate it!
Have you practiced writing programs, running them, and then checking the log? That will accomplish a lot more than just studying.
And vague, too. It's 5:00 somewhere.
If you want to practice parsing demographic data, give this a shot: https://www.treasury.gov/ofac/downloads/sdnlist.txt.
Tight deadline, depends on amount of work.. PM me for a quote.
Oh of course. Sorry about that. 5pm Monday EST. 
PM sent. 
I'd offer, but I'm away for a long weekend. This seems like a nice, easy way to make a little cash. If you don't find someone to do it by Tuesday I can have it to you then for 75$. 
Welcome to SAS certification exams. I warn everyone that I talk to and on here when I can that the best way to study for them is take perfectly good working code, have a coworker add a few random ;s and delete a character or two. Then predict how the remainder will behave. 
I failed my first attempt too. I posted about it [here](https://www.reddit.com/r/sas/comments/7nvozx/how_did_you_study_for_base_certification/). I an also try to answer any specific question you have. I passed it on my second try about 2 months ago. Now I'm studying for the advance one. 
You could set up the program to reference an Excel file (or text file) that has the correct file path. If the path changes, refer who ever is running the code to the workbook and have them change it there. This way the Excel file is tracking the changes and you don't have to worry about some one messing with the program.
Hmm. I brought it up on mobile without any issues. Sorry, I would have posted a warning if I knew it would cause trouble.
No you’re fine. Doesn’t cause trouble. Just didn’t expect so much 
I can assure you that the exam does not necessarily reflect the knowledge that a sas programmer has. You must have misunderstood my answer. I'm not saying memorise the answers but I'm saying that in order to not be caught out by the exam the person should prepare by knowing what the exam will try to catch them out on. What does it matter if I don't remember the exact options, I can google their syntax but what is truly important is knowing how to use them. Now after acing my exam if you ask me to recite the syntax of substr function i would have to think about it but I understand what it does and how it works. By brute forcing it I don't mean cram answers to exams (I'm not sure if you've ever taken the exam yourself but knowledge has to be there to be able to answer any of the questions at all). I meant that in order to be prepared for that certification the person who already has studied and read the book and played around with the code should test himself thoroughly with online materials available before going to the exam. I personally found the exam extremely difficult as have many of my coworkers. Apologies for not communicating what I intended to say, hopefully this clarifies what I meant. 
However, unfortunately we live in a world where everyone at some point must start out as "entry-level". I don't personally know anyone who has passed the certification without having some kind of hands on training within SAS(I'm sure there are others who find cheap ways around it). Regarding myself though, I assist tier 2 programmers at my job (CRO) with QC and producing TFL's. I don't have a ton of experience professionally working in the system, but I know my way around and am learning more everyday. Getting the certification for me is a stepping stone in showing my manager I am willing to learn and I'm getting better with time. Ultimately hoping to start a career using SAS rather then being the assistant. 
Unless the subject material from the base certification exam has changed significantly from when I got the certification in 2008 or 2009, I don't think the material covered in the exam reflects what modern programmers/analysts do on a daily basis. From what I remember, it's a lot of questions about reading data in using infile statements from text files with some questions about the program data vector mixed in. This is easy to say as someone solidly in their career, but I personally don't give applicants who have base SAS certification that much "extra credit" in terms of reviewing their application. As a hiring manager, I'd much rather have someone who is able to talk about some cool project they worked on or some cool piece of code they wrote than have someone point to a line on their resume that says they are certified. But this is just my opinion, so take it for what it's worth.
I completely agree with you. However, to the point I was trying to make in my comment above, a lot of people can use the certification as a stepping stone in their career (especially just starting out in SAS). Just like with most programming opportunities in the industry. Hiring managers want to see what you can do and have done, but having something like this on your resume can only positively effect your chances of at least getting an interview. For someone like myself who hasn't had optimal experience working in the software to create and manage projects, the least it shows is that you have an understanding of basic concepts in SAS and also have a will to learn (good characteristics for an entry-level position).
In order to learn from failed questions, it's important to have an explanation that can be reviewed. That is one of the reasons I started https://sasensei.com - so that you can learn from the SAS questions you get wrong (as well as the ones you get right). Not only that, writing new questions is also a great way to learn SAS!
I really enjoy your website. Did you develop it yourself? I'm a nooby there and just got my yellow belt lmao! But it's a great idea and can see it developing into somewhat of a codefights SAS version! Keep up the good work.
If I understand correctly, have you tried adding: dlm="","" to the infile statement?
Data step and proc sort to prep your data first... Proc sort data=army; By army_id effective_date; Run; Data dsn; Set army; By army_id; If last.army_id then output; Run; Or something similar...the last. Keyword will out the final observation in the by group which in this case would be the army id sorted by effective date You could add your effective dates to the data step also and produce multiple output datasets then run proc freq on this and proc means very simply... Nb - above syntax will be wrong but you should get the basic idea... 
I'm using dlm ="," not dlm="","" Do I need a pair of double quotes on each side? 
If you do, it should treat "," as the delimiter rather than just , 
Most fields don't have double quotes around them. For example, a row of data could be: 2,1-Strongly disagree,2,N/A,""This is an open-ended text response, like, from a survey"",2,3-Disagree,4 
It’s self funded.. glad you like it! You may be a noob there but I checked your results and you clearly aren’t a noob to sas. So that yellow belt was deserved 😊
Those are not just double quotes - they are *double* double quotes! This is not a standard format for a csv file. If your value is supposed to be we invited the strippers, JFK and Stalin then it should look like this in the file: ,"we invited the strippers, JFK and Stalin", If your value is supposed to look like this: "we invited the strippers, JFK and Stalin" Then your file should look like this: ,"""we invited the strippers, JFK and Stalin""", If you can massage the data into this sort of format, with text surrounded by a single set of double quotes, and any double quote characters that are part of your values doubled up, you can then set the `dsd` option on your `infile` statement, and SAS will import everything correctly, removing the outermost set of double quotes and undoing the doubling for you automatically. 
Sort by effective date and pay descending. Data step by date and pay if first.pay; Proc Freqdata=army; table effective_date*x; run; Something like that
Yes, double quote pairs on each side! I've never seen this before, but this is how data comes out of a vendor's system... My infile statement is as follow, but it does not work. When SAS hits a comma in the text that is contained inside the double-double quotes it treats the comma as a delimiter rather than as part of the text. Thus, SAS places the remainder of the text following the comma in the next var/field. infile "c:\temp\file.csv" dlm=',' dsd missover firstobs = 2 lrecl=32767 ;
Try reading in the file first without changing anything and then do a data step where your 'format x1 best12.' is before the set. Then just do x1 = input(weight,best12.);. I'm not sure why that wouldn't work accurately. What's the properties for this 'weight' variable? If it's character and that doesn't work then maybe use a scan and take positions of the series of alphanumeric characters and use put into a character variable and then input that character variable into a numeric. Something like that, basically removing the $ in character first then converting. 
Hahahaha hi classmate 
Ok, so I just opened my csv file in excel and did a find and replace. I replaced all "NULL" values with blanks. I was able to import the file into SAS afterwards, and it generated SAS missing values "." for the blanks. However, this can't be the right way to do this. It worked, but it was the most ridiculous work around. 
instead of running it on your dinky laptop it will use a whole stack of processors and memory. so yes, it's much faster and won't freeze your computer if you're running steps on a large database. 
If the field has text in it, you should input it as a character field. That may require you to list each field in an input statement if you're not already. Then you can conditionally read the data into a numeric variable after you read it in.
 FYI, you can format your code like this by putting 4 spaces at the beginning of each line.
Thank you!!
That's what I assumed... Gosh darnit! I bet that shit is expensive :S 
What a *darn* shame.. *** ^^Darn ^^Counter: ^^470756
You're welcome!
Thanks for your help! 1. I'm using base SAS 2. I used the import wizard 3. The data looks right in excel. Every "invalid data" error I had in my log corresponded to a value of **NULL** in my excel file. This is a large table of employees and their workstation names, manager names etc. All variables would be character except for login date which is a date variable. Sorry if this doesn't make any sense. I'm at whatever level comes before beginner. That's a great point to do a proc freq on my missing values. Thanks!
That made sense! It seems like you did everything right. My only guess could be is that SAS doesnt like the word null. Some words in SAS are key words and it might get confused when reading an observation as null. For example I cant name a macro "merge". To keep things simple just leave missing values blank. Base SAS is my prefernce as well, the import wizard is way better then enterprise guide's. 
Thank you for your help! I understand some of that lol. All my variables are character format except for my login date variable which is a date format. The login is always populated. What is sometimes showing up as null is manager name or workstation etc. I'm using the import wizard. Would you recommend doing a data infile or proc import? Sorry if I'm not explaining this well... I'm not confident in my SAS knowledge at all... compounded by how it seems like there are a million and one ways to do each step and everyone does it differently. 
Hmm. You're welcome. You're explaining it fine -- I've used the import wizard quite a bit, and I don't think I've encountered that before. Can you double check the import wizard and make sure the actual variable is coming in as character and not just the format/informat? It sounds like it's trying to read the fields in as numeric. If it's character, a value of "NULL" shouldn't be handled any differently from any other character string.
SAS can load data sets bigger than RAM, but this means switching with a virtual drive. So, get lots of RAM, a fast processor and a fast SSD for the hard drive. SAS graphics kind of suck. And I'd like to read someone else's comments on if you can get a GPU to help. I haven't....
Hello. So previously I was working somewhere where all of this was set up. I'm currently the only analyst and I have no idea how to get started (i.e. getting things in order in order to do my job). What do you mean by virtual drive? Previously at my other job, we used a server and terminals to run SAS jobs due to size.
Well, the first question is what are you doing with SAS? Are you running locally or off a server? Relate set or full set? Being updated constantly or as a batch? But to echo /u/dugorama and to paraphrase Neo, you want Ram. Lots of Ram. Fast processor and the fastest SSD you can stick in there.
[removed]
It means it creates a file on your hard drive that emulates RAM that it reads and writes to. Therefore faster is better and do get a SSD rather than a traditional hard drive
You want lots of everything: Hard disk, hard disk speed, ram and processor speed. Most SAS procedures don't use multiple cores, so you're usually better off having a small number of fast cores, than a larger number of slower cores. If you're doing (relatively) simple computational stuff, like tables of summaries and data manipulation of large datasets, then focus on disk speed and ram more. If you're doing computationally complex stuff on smaller datasets (proc mixed, proc genmod spring to mind, but there must be others), then don't compromise on processor speed. But at some point you'll wish you had a faster hard disk, other times you'll want more RAM, and others you'll want a faster processor. Try not to compromise anything. Also, I'd avoid a laptop. When you discover that your hard disk is painfully slow and too small, or you don't have enough RAM, you go to newegg or crucial (or wherever) get some new ram and 10 minutes later you are back to work. With a laptop, you're stuck. (My solution: Desktop with nice SSD, lots of processors and RAM + cheap chromebook. Run Chrome Remote Desktop on both, and access desktop when you aren't there. If you don't have decent internet connection you're screwed though.)
Don't use sas
Sounds like you're going to be running it locally, so id make sure you get a large hard drive internally (especially if you dont have access to USB hard drives) 
FYI. Reddit doesn't like link shorteners, they can easily lead you to a malicious website. Your comment got auto-removed. Use the "Formatting Help" button at the bottom of your comment field for instructions on how to hyper link text.
Add a px after thr 30. My intial thought.
Create a new variable with something like the following: Data work; Set YOURDATA; If gender = 'male' then gender2 = 1; Else if gender = 'female' then gender2 = 0; Run; Then go check that it worked properly using a frequency: Proc freq data=work; table gender*gender2 / list missing; Run; Also check out the Little Book of Sas! It has lots of good guidance on the software.
How large is the data set? 
Or, just create a format.
Try using a retain statement. If you show a sample of your data I can try to help more.
Try the [geomean] (http://documentation.sas.com/?docsetId=lefunctionsref&amp;docsetTarget=p0ywq67uqarnnen135hhs9gcsuv0.htm&amp;docsetVersion=9.4&amp;locale=en) function or the [geomeanz] (http://documentation.sas.com/?docsetId=lefunctionsref&amp;docsetTarget=p0ifv10vdogsesn158x2il0diaaw.htm&amp;docsetVersion=9.4&amp;locale=en) function.
Here is what have so far PROC IMPORT out= work.reddit DATAFILE="C:Users\example.CSV" Dbms=csv replace; getnames=yes ; RUN; What would I type exactly after imported file given I want the geomean for columns named AA and BB on my doc. Keep in mind columns AA and BB have over a thousand data points each. Thanks a million
Hey, so you could try doing this: Proc sql; Create table geomean as Select exp(sum(log(AA))/count(AA)) as geo_AA, exp(sum(log(BB))/count(BB)) as geo_BB From Reddit; Quit; ^that would be equivalent to doing a geometric mean
Handy if he want's to do this across multiple pieces of codes.
Thank you! Will definitely check it out
There isn't a simple percent agreement option to proc freq, but why not make a macro to calculate this for you?
If this exam is an entry requirement for an MSc program, I would strongly question the quality of the school in general and the program in particular. This is a very strange requirement.
I tried looking up SAS macros for this, but I couldn't find one. The ones I found were for Kappa. Do you know of one?
Not off hand. I meant that you could program your own.
Here's an [example that uses PROC FREQ](https://communities.sas.com/t5/SAS-Procedures/Kappa-and-percent-agreement-for-multiple-variables/m-p/250491#M56590) and ODS to output a data set with Kappa Statistics, then uses PROC SQL to express as percent-agreement.
This is great, but I have 200+ variables with different names, is there an easy way to rename variables?
What is your budget? Lets start there
You could do this with proc sql: Proc sql; Create table output as select * from input a where exists (Select * from input b where a.person=b.person and a.date=b.date and b.readmission_claim=1); Quit;
Thank you for the assistance! unfortunately, it only kept the lines where readmission_claim=1 and not all the other rows on that same day for some reason. I'm trying to keep all rows for that person, on the same day, where at least one row (on the day) has readmission_claim=1. 
Hmmm I thought the code I posted should've done that. Could you post a screenshot of your code?
Ok on other solution: Proc sql; Create table temp as select distinct a.person, a.date From input where readmission_claim=1; Create table output as select * from input a join temp b on a.person=b.person and a.date=b.date; Quit;
Nope, never mind. That worked. I failed to rename the input b. Thank you very much! 
Sorry, j was what I used to simply readmission_claim=1
Person Date code readmission 1 1/1/2013 11111 0 1 1/1/2013 11111 0 1 1/1/2013 g9310 1 1 2/7/2013 11111 0 1 2/7/2013 11111 0 1 2/7/2013 11111 0 1 2/7/2013 g9310 1 1 3/2/2013 11111 0 1 3/2/2013 11111 0 1 5/1/2013 g9310 1 1 5/23/2013 g9310 1 2 1/14/2013 11111 2 1/14/2013 g9310 1 3 2/5/2013 11111 0 3 2/6/2013 11111 0 3 5/5/2013 11111 0 3 5/5/2013 11111 0 3 5/5/2013 g9310 1 4 8/7/2013 g9310 1 
https://imgur.com/o7qtL0k 
I'll take a look tomorrow am and get back to you
Thanks! Two comments: 1. The input data set is all one so I’m just using t for both instances (a and b). 2. Lines 16 and 17 remain when those should be removed (example). 
If you wanted to do it in one step: proc sql; create table output as select ORIG.* from input as ORIG inner join (select person, date from input where readmission = 1) as SUB on ORIG.person = SUB.person and ORIG.date = SUB.date ; quit;
I figured it out: proc sql; create table output as select * from input t group by t.person, t.date having max(t.readmission_claim) = 1 ; quit;
It's something you could also use the double dow loop for. Basically, data set loops through the data one time, creating the keep flag. Then it runs through it again to assign that flag back to the data. data testdata; informat date DATE9.; input subject date claim; format date DATE9.; datalines; 1 01MAR2017 0 1 01MAR2017 0 1 01MAR2017 0 1 27APR2017 0 1 27APR2017 1 1 27APR2017 0 2 30DEC2016 0 2 30DEC2016 0 2 30DEC2016 1 2 05JAN2017 0 2 05JAN2017 0 2 05JAN2017 0 2 21FEB2017 1 2 21FEB2017 0 2 21FEB2017 0 3 06APR2017 0 3 06APR2017 0 3 06APR2017 0 3 15JUN2017 0 3 15JUN2017 1 3 15JUN2017 0 ; run; proc sort data=testdata; by subject date; run; data testdata2(where=(keepfl=1)); do _N_=1 by 1 until(last.date); set testdata; by subject date; if first.date then keepfl=0; if claim=1 then keepfl=1; end; do _N_=1 by 1 until(last.date); set testdata; by subject date; output; end; run; 
 data readm; set original; where readmission=1; run; proc sort nodupkey; by id date; run; data original_readm; merge original readm(in=in1); by id date; if in1; run;
Assuming you want to solve this using PROC SQL, it's really easy. All you need to do is do a subquery where you are selecting all the distinct values of person and date where readmission_claim = 1 and then inner join that back to your bigger table on person and date. Here's some pseudo code: proc sql; select t1.* from base_table t1 inner join (select distinct person, date from base_table where readmission_claim = 1) t2 on t1.person = t2.person and t1.date = t2.date; quit; 
Sorry :( Not good with formatting Hope you have a happy day
It's hard to tell what you're asking here. Could you please rephrase?
1) make the sure that the overall_place variable is named the same in both input data sets and is of the same type (numeric or character). 2) sort both sets by this variable. proc sort data = selectedsample; by overall_place; proc sort data = runnerdata; by overall_place; 3) create new data set from the two with this logic: data selectedrunners; merge selectedsample (in= s) runnerdata (in=r); by overall_place; if s; run; then you'll have only the selected runners with their data.
You could point your log to an external file beforehand and revert it to default afterwards: proc printto log='C:/log.txt'; run; %PUT _ALL_; proc printto; run; 
Might help: http://support.sas.com/documentation/cdl/en/sqlproc/63043/HTML/default/viewer.htm#n02s19q65mw08gn140bwfdh7spx7.htm
Thanks a million 
Yes it worked and saved my wifes dissertation. You are awesome and I thank you so much. Yah random kindness
Thought you might find some insights in these resources http://support.sas.com/resources/papers/proceedings12/155-2012.pdf or http://www2.sas.com/proceedings/sugi30/196-30.pdf You can also view some discussion on these topics in SAS Communities if you don't get an answer here https://communities.sas.com/t5/forums/searchpage/tab/message?advanced=false&amp;allow_punctuation=false&amp;q=chi+square+%2Bglimmix
For the user, the syntax is the same.
Can you look into using AWS? (Amazon Web Services)
The only drawback I've heard of is that some of the coding in SAS Studio is different than PC SAS. Sometimes they can't do certain functions, but all in all I think there's not a big difference.
If those certs are worth having is an entire debate in itself! 
They're not. End of debate. 
Especially if they have an EG one. Seriously that is like getting certified for breathing, if you have even two months experience you can pretty much master EG. Especially compared to other SAS products.
The basic one got me a 15k raise. A lot of that was based on merit and justified to senior management by the cert...but still...
The certification credentials SAS offers are more programming-focused, but [here are the Enterprise Guide training courses available](http://support.sas.com/training/us/paths/eg.html) 
For basic things there should be no difference. Are you installing on like a laptop or something? SAS Studio is a web application. It uses 2 workspace servers (which are essentially base sas sessions) per session, which will be more taxing than just SPRE. 
I would caution against this, personally. In my opinion, messing around with formats is a surefire way to get confused and create unnecessary complexity. Might as well create a separate numeric column, especially since that's what OP asked. 
I'm coming at this from a Systems Administrators viewpoint - I know very little about SAS (inherited this system) and am trying to learn about administering it. The best I can tell, this is just base sas and that is it.
Run PROC SETINIT; Run; From the sas prompt and let me know what you get 
Operating System: LIN X64 . Product expiration dates: ---Base SAS Software ---SAS/STAT ---SAS/GRAPH ---SAS/ETS ---SAS/FSP ---SAS/OR ---SAS/AF ---SAS/IML ---SAS/QC ---SAS/SHARE ---SAS/ASSIST ---SAS/CONNECT ---SAS/EIS ---SAS/GIS ---SAS/SHARE*NET ---MDDB Server common products ---SAS Integration Technologies ---SAS/Secure 168-bit ---SAS/Genetics ---SAS Enterprise Guide ---SAS Bridge for ESRI ---OR OPT ---OR PRS ---OR IVS ---OR LSO ---SAS/ACCESS Interface to DB2 ---SAS/ACCESS Interface to Oracle ---SAS/ACCESS Interface to Sybase ---SAS/ACCESS Interface to PC Files ---SAS/ACCESS Interface to ODBC ---SAS/ACCESS Interface to INFORMIX ---SAS/ACCESS Interface to Teradata ---SAS/ACCESS Interface to Microsoft SQL Server ---SAS/ACCESS Interface to MySQL ---SAS/IML Studio ---SAS Workspace Server for Local Access ---SAS Workspace Server for Enterprise Access ---SAS/ACCESS Interface to Netezza ---SAS/ACCESS Interface to Aster nCluster ---SAS/ACCESS Interface to Greenplum ---SAS/ACCESS Interface to Sybase IQ ---SAS/ACCESS to Hadoop ---SAS/ACCESS to Vertica ---SAS/ACCESS to Postgres ---SAS/ACCESS Reserved Slot 565 ---SAS/ACCESS Reserved Slot 567 ---SAS/ACCESS Reserved Slot 568 ---High Performance Suite ---SAS/ACCESS to SAP HANA ---PRODNUM964 
Studio is actually not installed. The plan is to start a new server with a fresh install of SAS + SAS Studio. That was run on the server - I just SSH'd to it, then ran SAS with X11 windows forwarding to my local computer.
I should have the sas program but I can’t seem to get it to work. 
Have you gotten it to run? If so, what does the log say?
well i attempted this a month or so ago, and was in the proccess of setting it up again but i cant get the stupid myfolders thing to work at the moment, but i kept getting errors that said ignoredosof.
I guess the university edidtion does not like virtualbox 5.2.8 the program i was given when ran i get 12 errors ERROR 23-2: Invalid option name IGNOREDOSEOF and the code that it goes with is this. infile eium truncover lrecl=2500 PAD ignoredoseof /*obs=10000*/ ;
Maybe try it without the IGNOREDOSEOF option and see if it works.
secondary question in the file i was given there were a bunch of file paths, since im using the university edition and share folders how should that path be just K:\Identifying Data Element Files\Inpatient\ENC_IDNumbers\IP_ENC_IDnumbers&amp;yr..dat"/ should it be /myfolders/dat_files/IP_ENC_IDnumbers&amp;yr..dat
I commented out IGNOREDOSOF and the first error i got was ERROR: No logical assign for filename EIUM. and the rest were ERROR: No logical assign for filename EIUM.
It sounds like EIUM was never defined with a FILENAME statement. Looking at the code you linked, EIUM is referenced in a file statement but there is no FILENAME statement to define what EIUM is. You can either write a FILENAME statement (there are several examples lower down in the program) or replace EIUM in the file statement with the filepath in quotes.
Yes you will need to put the file somewhere that University Edition can read from and then reference it either with the filepath directly in the FILE statement or indirectly through a FILENAME statement.
But I guess the question is how would I know what file I should put there though to correspond with the header columns. 
Wow! That's awesome I got.... $50 hahah
Wow, that program makes me irrationally angry. You see what they do there? Don't do that.
As someone who has never used sas would it least be a good framework to google how to use sas and get what I need. 
It should get the job done. They just go to a lot of unnecessary work. For example, the load of the first file would have been a lot easier if they had checked the record type and then used a trailing @ sign to conditionally read as type 1 or type 2. There was no need for 2 data steps full of substr statements. That's a decent beginner problem overall, and you'll have lots of data to play with after you get it loaded. I would recommend just going through all of the SAS functions and trying them out one by one. That will be a big help as far as understanding everything SAS will do. It might also be worthwhile to play with proc sql, especially if you have used SQL before. You could try the same merge in the program, but with proc sql instead. Also, try some procs like freq and means, and if you're feeling brave, tabulate and report.
You aren't supplying login information. Supply the code used for both users
You can code in EG just the same as PC SAS or Studio.
Right, but you can't use the drag and drop modules in SPRE or Studio. EG has more features. If his users want that then EG is their only option. 
Yes, this is usually when trying to access a file the is already in use (or sas thinks it is already in use) 
Big data is one of the things it can do pretty well, actually
No to be too facetious, but in the SAS realm, 50,000 rows might be considered an insignificant outlier subset. As for SAS being hard, the language SAS is pretty easy, however SAS, the ecosphere of additional products, can get to be quite daunting. 
I use both SAS and Excel for work. I only use Excel for quick analysis, prototypes that I will eventually build in SAS or creating MS Word friendly charts. For *everything* else, I use SAS.
SAS was originally made to handle data larger than other statistical software packages could at the time. This is no longer true as software like R and Python have come into the mix. (SAS is also expensive while the others are free.) If you are coming from no background in programming / coding I could see SAS being a bit difficult to pick up as the syntax is often not intuitive. SAS will be easier to pickup if you have experience in STATA/R/Python. My opinion would be that it depends on your work environment, but it may be more worth while to try and learn R or python, but if you find yourself ok with SAS then yes, it is totally fine, and you are doing yourself a service by picking up some non-excel analytics experience. Also just as heads up, 50,000 rows is not generally considered "big data". People who do data analysis for a living will not take you seriously if you refer to 50,000 rows as "big data". Where does "big data" start? Definitely depends on who you ask, but I would say it tends to start in the hundreds of million of observations, but some may define it as billions.
Does R handle large datasets as well as SAS? I was under the impression it doesn’t. 
We run regression models that have over 22m data points on a server set up that takes about 20 hours. Yes it can handle big data. 
Actually yea there is a term as big data but i wanted to mention my data is kinda big which excel cant handle. Thank you so much for answer. I will start to learn
SAS definitely has a leg up, but other programs go head to head with it until you start hitting tens of millions rows, in my limited experience.
I am learning python as well for machine learning. Maybe i can use python for data analysis too. With excel i can control cells easily can write formulas etc. But with python i need to write codes it scares me a little bit.Thank you very much for your answer. 
I use sas for billions of rows of data and it handles it fine.
On our team we use SAS on datasets into the millions of observations, and a few data sets in the billions of observations. Excel can even handle 50K rows with formulas if your computer or laptop has the horsepower. R can also handle datasets that size. Similar to other posters, 50K in analytics and data science is a small dataset.
Awesome! I’ll have to check this out. 
Study the prep guide! Each chapter has quizzes with questions exactly like the exam. Good luck!
I know the most common answer is too read the exam prep guide, but there is a reason for it. Practice exams will only get you so far and you will only be memorizing a few questions and answers that you may or may not see on the actual exam. It's true the exam plays tricks on you and you have to watch out for small details in the syntax. I failed my first attempt after only using practice exams and video tutorials. I got angry and just sucked it up, bought that big ass book and studied the shit out of it for a few weeks. Once you understand logical errors and how SAS handles them, you will have no problem passing. Especially focus on formatted input variables, generating reports and handling errors.
Might be a good and fun way to test your knowledge. Good Luck! https://sasensei.com/
I use Entetprise Guide at work, but I finally decided to give Studio a try. The dinosaur in me was resistant at first because I found the address bar to be offensive due to it taking away from the screen estate. The good news is that with Google Chrome, there is an option to save the link to your desktop as a webapp, and upon open, it looks like a legit app rather than a browser site. (I did the same thing with RStudio Server) I'm tempted to say that I'm liking it better now, and the drag and drop features in visual programming is very different when compared to Enterprise Guide, but doing sub process flows is a win. SAS code is 100% compatible as far as I can tell, but I'm not sure about how well migrating a process flow works. From an IT prospective, not having to support installations is also a win, so I do not see why not try it. 
There is an "Enterprise Guide" tag on Sasensei (https://sasensei.com/questions/filter?tags_any=[5]), which may be helpful
Thought this was spam, Went to read it before clicking report. Pleasantly surprised. Essentially it's proc format code to get the Bitcoin BTC symbol to show up in your reports. 
*Download SAS 9.4 BY USING TORRENT
Are you reading in numeric variables as character?
And there you have it, thank you very much! Of course, the error gave me no indication that this was the problem...
You're welcome! Yeah, the errors can be arcane sometimes.
Thanks, I am new to Reddit so maybe I don't know the lingo, but I have a lot to share.
I’m a little rusty in stats, but can’t you just estimate the predicated average of the response variable using the parameter estimates? Y= mx + b So SAS will give you the estimates for m and b, your prof asks you to calculate the predicted Y for a given value of x, which you can do with a calculator. 
Likely yes! Your best bet is the University edition. https://www.sas.com/en_gb/software/university-edition.html It's free for non commercial use.
The prep guide appears to be wrong, as b is the correct answer. These kind of issues are what drove me to create https://sasensei.com - a source of peer reviewed SAS questions with corresponding explanations. I also find that adding questions to the question bank on sasensei is a great way to revise / update my SAS knowledge.
I used to work in psychometric analytics and most of what we used specific to that kind of analysis was in SAS/STAT. That should be your focus.
I don't think B is a very good answer either. OUTPUT still writes observations to output. "DELETE statement" would be a much better answer.
let's say this is your table: data myTable; input country $ x y @@; datalines; Italy 20 15.4 Italy 30 20.2 Italy 40 25.7 Italy 50 26.2 Italy 50 26.6 Italy 50 27.4 Italy 55 . Italy 60 24.8 France 20 12.1 France 30 19.4 France 40 23.5 France 50 28.8 France 50 29.9 France 50 30.1 France 55 . France 60 31.3 ; run; you would use the GLM procedure like this: data all; set myTable; ods graphics on; proc glm; model y=x x*x / p clm; run; ods graphics off; now let's say you just want to use rows for Italy: data italy; set myTable(where=(country="Italy")); ods graphics on; proc glm; model y=x x*x / p clm; run; ods graphics off; does that help?
I don't think the wording's bad, an OUTPUT in a non-trivial reachable do loop (or conditional for that matter), will likely be changing the default behaviour of the data step. Indeed, even a bare "OUTPUT;" changes it, as the writing out happens at the point of execution of the OUTPUT statement rather than at the end of that iteration of the data step (you can argue it's irrelevant if there's only one OUTPUT and it's the last statement, but you're arguing from a very specialised case in that instance). I think the wording is okay for a multiple choice test. I'm not thrilled the language is such that the functionality is invoked in such an odd way, but given SAS's famous commitment to backward compatibility, I doubt that'll change.
Here's the update for the 4th edition that is available on the SAS bookstore website: [Content Update for SAS Certification Base Prep Guide](https://support.sas.com/en/books/content-updates-base-prep-guide-4th-edition.html)
Ah, I used that! Nice one
Unless rutgerswhat was terrible at his job 
I’ve got multiple sets of analyses that prove that you are a class 1 jerkasaurus
Proc sort data=have; by var1 var2 var3 date; data want; set have; by var1 var2 var3 date; if first.date; run; Where the var1 x var2 x var3 x date combination defines your defined set.
Well....in the sick logic that is SAS cert exams, c is the right answer. B is incorrect because there is an implicit OUTPUT by default, the fact you made one explict doesn't stop it from attempting write an observation for EVERY iteration, is just won't do it until you tell it. It still WILL write observationS. While answer c, prevents it from writing at all until it hits the last observation. So the best answer of "override the DATA step default behaviour that writes observations to output" (those last four words are critical) is c. It is nuanced bull manure like this being tested that makes me hate SAS cert exams. 
Thanx! Unfortunately this Errata is quite meagre and not all typos seem to be there. And it's funny how they mention this very quiz question in their Errata (This question is indeed Question 9 on page 539). But they repeat yet again that the correct answer is "c"!
Thanx! Unfortunately this Errata is quite meagre and not all typos are there. And it's funny how this very quiz question is mentioned in the Errata (this quetsion is indeed Question 9 on page 539). But they repeat that the correct answer is "c"!
We need more information. What date/variable format is "date" in currently? If it's currently character and like '201803', the quotes aren't needed around the elements in the "in" statement. If the date variable already has yyyymm format, there's no need for the input statement at all. Just use numeric or character format in the "in" statement, as appropriate. Also, you have a typo in the first element of the "in" statement should be a period instead of comma.
The inverse of the male OR (or whatever your reference group is) would be the OR of the other group. 
Good point, the question is borked.
Kind of depends what you are trying to measure. I worked in educational testing measurement, so PROC IRT (Item Response Theory) was fat and away the most appropriate, though we did use some of the other procedures in that linked article. The SAS/Stat [User Guide](https://support.sas.com/documentation/cdl/en/statug/63962/HTML/default/viewer.htm#titlepage.htm) is a great reference. As far as training, you can get started with Statistics 1 at the [free trainjng](https://www.sas.com/en_us/learn/academic-programs/resources/free-sas-e-learning.html) depot. [These](https://support.sas.com/training/us/paths/stat.html) are the trainings laid out currently for full statistical training options. These aren’t going to be free, though. 
I do a lot of analyses on surveys and use proc factor to create scales, mostly on attitudes and behaviors, but I've never had any formal training. I have done IRT before as well. I am looking for a general overview of when to do this or apply this, etc.
Obviously there are other covariates besides sex. You need to run your proc logistic with a "by sex;" statement and compare the ORs for the other covariates between the sex strata.
There are several practice guides out there that are incredibly well built. Search around eBay if you're willing to spend a few bucks.
Umm, Africa isn't a country? Did they say to find records where the country name *contains* 'africa'?
SAS publishes a prep guide for the exam which is going to be your best bet.
 proc export data=DATASET1 outfile="PATH TO FILE YOU'RE SAVING.xls" dbms=xlsx replace; sheet="My First Tab"; run; proc export data=DATASET2 outfile="PATH TO FILE YOU'RE SAVING.xls" dbms=xlsx replace; sheet="My Second Tab"; run; 
I'd do this: https://v8doc.sas.com/sashtml/proc/z0313909.htm. You'll need a separate proc import step for each sheet.
This. I'd probably embed in a macro and just set the macro variable to the sheet name, executing the macro however many times I need to capture all sheets.
Yes, good point on the output data set names. The macro example is also a good idea as long as OP is comfortable with it. If not, this might be a good opportunity to start working with macros.
Awesome, thanks!
Good call, will definitely use a macro (this is a take home exercise for a job interview--so really want to be as efficient as possible). Thanks for the tip!
The prep guide is a great way to prepare, and there are also practice exams available. The one that you can purchase through SAS you have unlimited attempts on, whereas the one you can buy through Pearson VUE you just get one attempt on an extended time limit. It is supposed to more accurately simulate the actual exam. Here's info on both: [practice exams](https://www.sas.com/en_us/certification/resources/sas-practice-exams.html)
You're welcome!
With the xlsx libname engine the workbook is like a library and the sheets are the datasets, very easy https://blogs.sas.com/content/sasdummy/2015/05/20/using-libname-xlsx-to-read-and-write-excel-files/ 
Sometimes the best way to learn, is to teach! If you can make it to Green Belt on https://sasensei.com, you can submit new questions to the question bank. I'd say this (plus the prep guide) are the two best resources for prepping your certification - but then I am quite biased, being the site founder!
It's quite easy really. Get a copy of SAS, like the free university edition or whatnot, and a copy of the base programming prep guide from SAS. Then, sit down and study, pausing often to implement code. Deliberately try to break your code and learn from what you've done.
Proc expand might be the easiest. I haven't worked much with it because I didn't have ETS installed until recently, but below is an example of a trailing moving average. &lt;pre&gt;&lt;code&gt; data test; input id $; datalines; A B C D E F ;run; DATA test2; SET test; by id; format sales percent7.2; do year = 1 to 20; sales=rand('normal',.05,.05); output; end; RUN cancel; proc expand data=test2 out=test3(drop=time) METHOD=NONE; by id; CONVERT sales = MA_sales / TRANSFORM=( MOVAVE 3 ); run; &lt;/code&gt;&lt;/pre&gt; If you or your organization doesn't have ETS, what I used to do would be one of two things: [a] use lags to manually calculate moving avg or [b] use proc transpose to convert a vertical sales column to a horizontal array (sales1-sales20). Define my sales array, then use a do loop to calculate the moving average.
Read the excel files into python and export them as csv files. The read the csv file into sas with dlm=','; If you have addresses or something you might need to take some extra steps.
Thank you! Going to give that a go. 
I agree with the /u/Everyday_Analyst, Proc Import is simple and the way to go in this case. I would like to throw out one recommendation to the group though in case you find yourself constantly translating data from one format to another (e.g. a lot of my colleagues use Stata or R): [Stat/Transfer](https://stattransfer.com/). I think I have had a license for Stat/Transfer on almost every machine that I have ever had for about 15 years. It is relatively inexpensive (more so if you are an academic user like I am), but it is one of those pieces of software that pays for itself in just a few uses in terms of time saved. For example, I have been working with two other researchers on a long term study over the past eight years or so. I do most of my analysis and data work in SAS, but they prefer to have Stata files for statistics and Excel files for browsing subsets of the data. From the Stat/Transfer command line I can issue a copy command to copy an entire directory of SAS files into another directory of Stata files, and then do the same thing for Excel. I upload those files to the web server and I am done. I have only had to call their tech support once, but they were helpful. The licensing people were also helpful when I lost an email with a license code.
wait I thought this was shit American's say
There is no way to remove a variable from an array. Do you have SAS/CONNECT or the option of using the SPDE libname engine? With either of those you could take advantage of parallel processing to some degree. You could perhaps use a hash object plus hash iterator to keep track of which variables have missing values, but I suspect that the CPU overhead would outweigh the benefits of skipping the occasional column. A third option would be to use your array to keep track of the array indexes that need to be checked, but then you'd need to keep bumping everything along by one every time you found a non-missing value. 
I will look into your first point. But I've never this before. I'm really interested in the hash method you suggested. Something I'm familiar with. Of the 1000 variables, 999 variables have at least one non-missing value each within the first 100K rows. There is only that 1 variable that is 100% missing and that's what I need to find. So my goal is that, SAS scans only that one variable after the 100000th observation. Progressively stop scanning variables once a non-missing value is found. Your third point is valid and I had thought about it. But it is very CPU intensive because for every row, it needs to check all 1000 array indexes...
Yes, I tried the exact same method earlier. Using proc format with proc frequency. Excellent technique. But like you mentioned, it doesn't scale well with 1000 variables and 200 million observations.
Interesting problem... [Here's](http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000148379.htm) a page I found describing how to use macro functions to directly access datasets by row number and character variable. I have no idea about the efficiency of this compared to a regular datastep, so you probably want to test this out on a small subset of your live data to see if it compares well to your existing method. I would go about trying this by initialising a space-separated list of variable names of interest, then extract their position in the dataset vector as in the example. Then, you can loop over the dataset in a macro and check if each variable is populated in another loop. If so--remove it from your list of variables to check. The stopping condition would be if the dataset is finished or you have an empty list of variables to check. Possibly, you could pick up some more time efficiency by dropping variables from the dataset (working copy, obviously, not the original) once they have been identified as having at least one populated cell, but with such a huge table, who knows... 
Thank you for your detailed suggestion. It looks like a promising and an interesting approach. I will try this out... and let you know...
Can you share an example of what the data you have looks like? The Excel table.
Also consider proc tabulate, it's more flexible in displaying data
Just a quick few that come to mind from my experience: Proc sql; Proc means; proc print; proc varclus; proc logistic; proc lifetest; proc univariate
Proc means is by far the most useful. Proc freq is also necessary. Everything else is great but specific to a task. 
TABULATE (you can compute and summarize stats in purdy tables); ODS (output = ; to Excel, pdf). SQL.
I would split the conditional IF statement into something like this: data _want_; set _have_; by date; current = 0; if first.date then do; if year(date) in (x y z) then current = 1; end; run; This way the code is explicitly creating and initializing the value of current. I'm also assuming the data is sorted by date.
Personally I see proc IML, opt model, and proc ds2 for when performance starts to really matter. Depends on business group the team is solving a problem for. The most common though is proc sql for easy data querying. 
TABULATE something like: proc tabulate; class site county pol s w; table site*county, pol*(s w); run;
I'd just calculate two models and a difference variable, but there may be an easier way 
Thank you! 
Usually in SAS, disk I/O is the dominating factor. You have to load a whole row into memory in order to check even a single variable out of your 1000. Keep statements usually help to mitigate this, but they won't help here as you need all 1000 variables to start with and you can't drop a variable after a data step has started executing. Once you've loaded a row into memory to process it, I suspect it's unlikely that the number of columns you have to check makes much of a difference. The only option that I think is likely to give you a particuarly noticeable performance improvement is throwing more disk I/O at the problem by using some form of parallel processing, and even then that will only help if you have more I/O available than a single process can keep up with.
Adding to your list since the most common have been covered by others. PROC TRANSPOSE is another is toss into the mix. For charting, PROC SGPLOT. And for simple random sampling, PROC SURVEYSELECT
I doubt there are any closed form mathematical formulas to compute power (except maybe for some extremely simple and limited scenarios). Power in this case must be done by simulation and especially under a range of expected scenarios. To do this, you should have access to a dataset from a similar study population, under a similar design. You should probably consult a statistician.
I'd have to check the documentation, but the stepwise option might do that in the output depending on what variables are used in the model.
This sub doesn't get a ton of traffic, and someone like me, who works in SAS every day, but isn't quite immersed in the community (I'm a programer in clinical trials, but NOT doing SDTM/ADAM) stuff like this is fantastic Thank you!
Are you familiar with [regular expressions](http://jkorpela.fi/perl/regexp.html)? Generally, they are a form of matching patterns in character strings and they are usable in SAS through a selection of [PRX functions](http://www2.sas.com/proceedings/sugi30/138-30.pdf&amp;ved=2ahUKEwjt5ra_6K_aAhUKLsAKHTuDBsEQFjACegQICBAB&amp;usg=AOvVaw13t2SuwvFqeDjbwm6Pvqwg) The prxchange function is applicable here: Data new; set old; array chars{*} _character_; do i = 1 to dim(chars); chars{i} = prxchange("s/[^A-z]|[^0-9]//",-1,chars{i}; end; run; The data step above (assuming I haven't made any silly syntax errors, I'm posting from mobile) should delete all the characters NOT between A-z or 0-9 (based on ascii values) 
Strip...compress...etc
Maybe this: [SAS 24716: Deleting unprintable characters from character variables](http://support.sas.com/kb/24/716.html) (click on the "Full Code" tab)
Thank you! for reminding me of regex and helping me solve an unrelated problem!
myVar=Compress(myVar,’ ‘,’kad’);
This one! Compress removes characters. The 'k' modifier means keep, 'a'&amp;'d' mean alphabet and digits respectively. So it will keep all alphanumeric characters and remove the rest.
&gt; SAS &gt; Nicely formatted
https://blogs.sas.com/content/graphicallyspeaking/ I'm sure there are a couple others out there but I think you want to be more specific. If you're trying to make a specific type of chart, search for papers on that on lexjansen.com. 
Thanks
&gt; SAS &gt; Nicely formatted
Thanks
Are people coming here from r/cobol, just to troll?
Here's a sneak peek of /r/cobol using the [top posts](https://np.reddit.com/r/cobol/top/?sort=top&amp;t=year) of the year! \#1: [Don't hate COBOL until you've tried it](https://opensource.com/article/17/8/what-about-cobol) | [0 comments](https://np.reddit.com/r/cobol/comments/6vygzr/dont_hate_cobol_until_youve_tried_it/) \#2: [High level overview of COBOL for those interested in starting to learn COBOL](https://devops.com/the-beauty-of-the-cobol-programming-language-v2/) | [0 comments](https://np.reddit.com/r/cobol/comments/7z6qg5/high_level_overview_of_cobol_for_those_interested/) \#3: [COBOL Is Everywhere. Who Will Maintain It? - The New Stack](https://thenewstack.io/cobol-everywhere-will-maintain/) | [11 comments](https://np.reddit.com/r/cobol/comments/6b76u4/cobol_is_everywhere_who_will_maintain_it_the_new/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/7o7jnj/blacklist/)
The little SAS book is a great resource for beginners to SAS. There is also a UCLA statistics website that has great examples of analyses in SAS (I’m on mobile and I can’t find it right now). I don’t think QBASIC will help you at this point, but it’s good you have some experience writing code. 
/u/Run_nerd has a great rundown if you know that you will be using base SAS However you may be using one of the newer SAS tools like SAS Visual Analytics on SAS Viya which can change the recomendation a bit. Do you know if you will be using base SAS, or Enterprise Guide, or something new like SAS Visual Analytics?
My coworker said they will be updating to 9.4 and with our agency, I'm going to just assume Base, no bells or whistles for the government.
Learn SQL. It will make your life so much easier as it is highly complementary 
This. Honestly there's very little actual SAS coding you need to learn. Just throw your SQL code in between a PROC SQL; and RUN; and you're pretty much golden.
Unless you actually want to do statistics...
What sort of work will you be doing with it?
https://stats.idre.ucla.edu/sas/ Love this resource!
I work in Vital Records, so I'm going to be running birth, death, icd10, and other health related reports.
Seconded on the Little SAS Book; it's great.
Yes this is it! Thanks for posting it.
The current version of base SAS is 9.4, so it sounds like it is Base.
True but 99% of the work in SAS is getting your data ready to be fed into a statistic proc, and knowing SQL will help most with that 99% of effort
Depends on what your agency bought. Ours dumped some serious cash into it. Once we get it fully setup it will be awesome.
SQL, and proc Freq will be your best friends.
The incredible power of SAS is the ability to write to any existing type of storage, be it a flatfile on a hard drive or a mainframe-driven database. As long you got access to the storage SAS provides sophisticated interfaces for reading and writing to it. And I did some crazy shit like writing SAS-Datasets into IBM Message Queus during my nearly 10 years of experience as a SAS-Consultant. I know no other tools capable doing this with a comparable low codingeffort.
Since others have already told you good reference texts and to learn proc SQL, which are the best advice, I'll give you the second best advice. Whenever you're learning to do something new, just Google the basic idea and add SAS to the search terms. There is a massive community and a ton of forum posts and code examples. The official SAS documentation, lex Jansen, sugi blogs, pretty much anything you'll ever do is demonstrated well online. Don't kill yourself reinventing any wheels, leverage the community.
Thanks for that, I feel I'll be doing a lot more report running than anything else. 
I'm not super familiar with PSMATCH, but could you add a year (or decade) variable to the model to force it to select a more current year?
Are they asking for experience with specific data sources (like Medicare claims)? If not I would just apply because it sounds like you are qualified. They probably are asking for this experience because then the applicant would be experienced with types of codes associated with health care data. (Icd-9 and 10 codes, CPT codes, etc.). 
Honestly just start applying. Start with the government sector, places like the MACs or UPICs, as they tend to pay a little less and so are a lot more willing to train people up. After a couple years there you'll pretty much have your pick of the healthcare sector.
Don't let not having experience in a specific industry keep you from applying. You can sell your marketing background as having experience with demographic data, which should transfer into knowing how to handle member data. If you fit half of the requirements of what a job is looking for - apply. Anecdotally, I moved from manufacturing to health care and got the job on my SAS and technical background.
Too much this. I moved into a senior sas role within banking with no sas background, just SQL and programming. The most important thing is how you relate experiences in your interview. Of they ask you a question about how you handled a tough decision, talk about analytics and make it somewhat relatable to how they'd use data in healthcare.
I've worked in healthcare/claims data analysis for my entire career. For an entry level analyst, I'd expect very little in the way of procedural or content knowledge. Knowing SAS would be extremely helpful. SQL would be an OK tradeoff for my team since I'm fluent in both SQL and SAS, but this would differ depending on the team you're applying to. Demonstrating an aptitude for learning SAS if you don't already know it (since you mention SQL and R) would be good. The base certification is, in my opinion, next to worthless for determining if a candidate actually knows SAS. It sounds to me like you have sufficient experience to apply to an entry level position. The only thing that might be a hangup is if you're applying to a claims data analyst position. Working with claims data is a different beast altogether than other types of healthcare data. Even so, I would imagine you should be able to get an interview given your background and qualifications.
I disagree wholeheartedly. The data step is an incredibly powerful tool. Granted, I cut my teeth on the data step, so I'm pretty biased. But while PROC SQL is powerful, there are things the data step can do that can't be done (or at least done easily) using it. 
Thanks, to be honest, I only know that we run reports, I'm not one of our statisticians, and frankly my math is not my strong suit. I do intend to soak in the information and hopefully use it in future projects. 
Perfect! Thanks!
Never used that site but I passed the base and advanced programmer exams. I used the SAS prep books for each test and they worked well, mostly because the practice questions were very similar to the actual exam questions. Good luck! 
The one at my desk has "bic" written on top. [Photos](https://imgur.com/a/VOI1s)
Please cut your nail.
Employees don't get those pens. We get old school bic pens and number 2 pencils.
It looks like they might be these: https://www.amazon.com/dp/B0000AQPTO/ref=cm_sw_r_sms_apa_NfR1AbT6JDRKZ.
Thanks! And I'm an idiot for not actually looking at the pen itself all that closely. Thanks again. 
Indeed it does. Gonna have to order a bunch. Thanks!
Humblebrag. Congrats on the job. 
You're welcome.
I'd recommend also, as you build your own plots, to save your work in your own library. I reuse the same sgplot code for nearly everything, changing the plot types and messing around with proc and ods options by googling things and reviewing the sgplot documentation on the SAS website to keep refining with each further iteration. 
Good idea, thanks.
Wow. This is an incredible resource!
SQL generates a Cartesian product which saves a lot of data step programming if you are doing combinatorics.
Or as simple as count distinct
Of all the procs/data steps in my programs, 95% are proc sql. There are few things you can't do with it.
I use proc SQL for most data manipulation, unless I need to use arrays and the like.
Summarizations, joins, Unions (my favorite is outer union corresponding for similar data sets in different orders with some unshared columns). 
I mean the article is pretty interesting. It suggests building out HTML5 interfaces that use SAS Stored Processes as a back-end data store. Likely getting rid of most of the reason's people don't like SAS. It has the advantage of being able to switch from Stored Processes in SAS 9.4 to CAS Rest API programs in Viya. 
I have several, very successful enterprise apps running in this manner. SAS datasets act as the backend "database". Development and deployment is much easier than any other platform I'm familiar with. 