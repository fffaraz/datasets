Just pay attention to some functions that won‚Äôt work interchangeably and missing values are also being used differently.
The variables in the .txt file are separated by spaces. I put a $ after the date variable in my input step - which I‚Äôm assuming means it reading it as a character. But when I try running it without the $, or with a mmddyyyy10., or making the lrecl = 20 in my infile statement, the dates keep showing as blank in my created table. I‚Äôm new so it may be some obvious issue I‚Äôm missing. I appreciate your help guys!
Ahh, this worked! Thanks so much for the help - you explained this perfectly.
The Little SAS book is a great book, and cheap as SAS books go.
I work for a university and have awesome benefits and i think the pay is just fine. I know what other sas programmers make in the university and we're all around the same area. I'm a senior programmer and i'm at $83k. But i didn't start there. I learned sas on the job at $50k in a data manager position and moved up from there.
I‚Äôve learned both languages in different contexts. Data management in SAS and object oriented programming in python. I don‚Äôt think they could be ore different, but my object was different soooo I may not be the best source...BUT if you have more questions...I‚Äôm here!
It sounds like the 9.1 is coming from the class. And if it's an intro class, they probably won't be focusing on much more than basics anyway.
You can drag the tab to the bottom or the side. If you have more than one tab, this will tile them.
I use both at work (and Python at home a lot). They're nothing alike. Certain things in SAS are 'easier' like retains and lags and just generally how the PDV works...but you can replicate it all in python. SAS will probably be faster in most cases if that matters to you a lot. I'd rather write in Python than SAS if it's an option though.
It‚Äôs bizarre to me that they would mandate you use SAS if it‚Äôs not for regulatory reasons. I would recommend just making sure what they‚Äôre reasoning is. Are these programs they want other SAS people to use? Some other reason? If it‚Äôs purely code that is for you and just to give some output then yeah go nuts. I fairly certain there‚Äôs a way to call r code in SAS though it escapes me at the moment.
In SAS you can do most all data manipulation in proc sql and then only have to learn a limited number of output procedures. The main benefit here is that proc sql is an integrated and validated part of the SAS environment. So it would be transferable to other SAS programmers and usable for programs that were working on regulatory filings.
Thank you kindly!
If you know SQL, you basically know SAS. The two languages have many similarities, and SAS has a PROC SQL function that literally uses the same SQL syntax that you're used to. Or you could try and use SAS studio or enterprise guide, which have somewhat of a GUI drag-and-drop interface.
Since a couple of people have mentioned being able to submit R code from SAS, but not explained how, I thought I'd point you at the relevant [documentation](https://documentation.sas.com/?cdcId=pgmsascdc&amp;cdcVersion=9.4_3.4&amp;docsetId=imlug&amp;docsetTarget=imlug_r_toc.htm&amp;locale=en). Basically, you have SAS and R on the same machine, launch SAS with the RLANG option, and then you can submit R code from PROC IML.
Just tried this, thank you so much!!
IML can call R
One thing you need to keep in mind. SAS processes data line by line. Python and R do not, they primarily use in memory. Your computer may not be able to handle the datasets you need to be working with. For example, working with a 10 million record drug records dataset in R, 8GB RAM, ran out of memory four times. SAS May take two minutes but it doesn‚Äôt stop.
Yup. [https://www.youtube.com/watch?v=UXzjyf5oz2Y](https://www.youtube.com/watch?v=UXzjyf5oz2Y)
You're going to want to get VERY familiar with what's called the Program Data Vector (PDV). This is the mechanics of how SAS processes through the data step. The data step is a very powerful tool for processing data. Getting used to how SAS processes data (what values get compiled at which stage of the data step, how to take advantage of internal processing flags, etc.) will be very useful. I don't care if snooty people now look down on "old school" processing, but in my opinion having a rock solid understanding of the data manipulation side of SAS guarantees that your code will be mostly bulletproof. SAS documentation for this kind of thing is pretty good. I'd say default to looking things up online if you need examples or explanations. Start learning about sorting and merging data. Or, if are more familiar, joining data using PROC SQL.
I remember that happening to me once. I thought I had done something wrong. Turns out I'm not crazy.
This is great advice. Thank you stranger.
Make a new variable that maps 85-90, 90-95, and 95+ into a 85+ group then add using the new variable.
Do you have a numeric age group? You could do that 85+. If not with the working dataset you can create another variable. If age_group in (‚Äògroup 1‚Äô ‚Äògroup 2‚Äô etc) then age_group (if you want to use same variable, but I highly do not suggest this, just make a new variable) = ‚Äò85+‚Äô From there you can do your analysis with the values by the new variable.
I¬¥m exploring that way, like u/Seemseasy said, but, correct me if I am wrong, would that not leave two missing spaces? I was more into something like combining the observations.
I think what /u/Zkck0517 is asking is, do you have the actual age as a numeric variable in the data set, as opposed to just the groups as character variables? If you do then you can just use PROC FORMAT to generate a new format to re-group all of the observations: proc format; value age_groups 15 - 29 = '15 - 29' 30 - 39 = '30 - 39' 40 - 49 = '30 - 39' 50 - 59 = '50 - 59' 60 - 69 = '60 - 69' 70 - 80 = '70 - 80' 81 - 84 = '81 - 84' 85 - high = '85+' ; run; data test; do age = 15 to 100; age_group = put(age, age_groups.); output; end; proc print; run; If you do not have a numeric age value then in your very specific case you could just do some string comparisons and get the correct responses: data example; length age_group new_group $8; input age_group $8. @+1 deaths; if (substr(age_group, 1, 2) &gt;= "85") then new_group = "85+"; else new_group = age_group; datalines; 15 to 29 3 30 to 39 43 50 to 59 32 60 to 69 21 70 to 80 21 81 to 84 4 85 to 90 5 90 to 95 2 95+ 2 ; proc sort data=example; by new_group; run; proc means data=example sum; by new_group; var deaths; run; As a general rule though, in many recoding situations you want to consider using PROC FORMAT: proc format; value $age_fmt '85 to 90','90 to 95','95+' = '85+' other = [$8.]; data example; length age_group new_group $8; input age_group $8. @+1 deaths; new_group = put(age_group, $age_fmt.); datalines; 15 to 29 3 30 to 39 43 50 to 59 32 60 to 69 21 70 to 80 21 81 to 84 4 85 to 90 5 90 to 95 2 95+ 2 ; proc sort data=example; by new_group; run; proc means data=example sum; by new_group; var deaths; run;
Nope, you'd now have three records as "85+" and then you can sum the three together like your second example. I'm on mobile so please excuse the formatting but, like Zkck mentioned, doing something like: if age_group in ('85 to 90', '90 to 95', '95+') then new_var = '85+'; else new_var = age_group; should yield 3 rows with 85+ for new_var.
Hahahahaha. Guilty.
 [MRW](https://m.imgur.com/CHZfvp3)
LOL. I once typed in "SAS Guide" on Amazon, and it brought up "SAS Survival Guide" and "Survival Analysis Using SAS: A Practical Guide" right next to each other.
It does :)
Actuaries and mercenaries...I guess it's all connected.
Loll but it‚Äôs fun now, because we have our own little group now that has its own SAS meaning.
I totally did, took a screenshot and sent it to my work colleagues. Haha.
AFAIK views are only for single tables and cannot join tables. But is this option faster for getting data from a single table than a "create table" statement - or have I misunderstood the purpose?
I don't think CPU resources are a problem in my case.. It is something like this solution, that I am looking for. My biggest problem is, that SAS pre-allocates resources to queries. Upon meeting a character variable of length 3200, even if all observations are blank, SAS will treat them as if they were 3200 characters long anyways. Using the compress binary/char will resolve problems like this?
You can create views from joins. If this is something that the tables or the query isnt changed alot then it can cut down on some space. But the data is accessed and the new table is made each.time the view is made.
He has really good books.
Try double quotes (‚Äú ‚Äú) instead of single.
Hmm, did not work, kinda managed with several tranwrd, which do work, but meh.
thanks - I'll give this a try! :)
Your code has a space at the end of each series of letters, was that intentional?
Works just fine as written on my SAS 9.2 install
Not sure I have an answer, but there is a thread about this topic here... [https://communities.sas.com/t5/SAS-Enterprise-Guide/Changing-accented-letters-to-the-normal-26/td-p/347521](https://communities.sas.com/t5/SAS-Enterprise-Guide/Changing-accented-letters-to-the-normal-26/td-p/347521)
I would think you would want something a little more flexible. For example, what about long weekends, vacations, or shutdowns? It sounds like you want a program that runs for each day since the last time that the program was run. I think the easiest thing to do in this case might be to have a program write the current date stamp to a file at the end of the program, and then read it back when it runs again. You will need to specific a standard location where the date is set, but then you can just run a loop from the day after the last date until today. This is loading lastreport date from macro variable, but it could just as easily be from a file: %let lastreport = %sysevalf("13APR2019"d); data test; do dt = &amp;lastreport + 1 to today(); /* code to process events for date = dt */ put dt date9.; end; run;
Thanks for the answer. It makes super sense. I will try and implement it. :-).
Qucik question: I get an error: Variable DT is not on file Work.have My code: data want; set have; do dt=&amp;lastrun + 1 to today(); where date=dt; put dt date9.; end; run;
Where statements can't be executed conditionally. You need to use if instead. Also, please, in the name of all that's holy, don't use SAS keywords (like date) as variable names.
Okay! I did not know that. Thanks for the answer. My variable name is not date. I just used it for easy understanding. but thanks for the heads up :-).
I could not get it to work. But i found another way. In the end of my dataset i create a new dataset with variable "today()". I load this in the start and create &amp;lastrun with this and then do: "where date between &amp;lastrun and &amp;yesterday". It seems to Work. Thanks for all the help and please tell me if something is wrong :-).
You would need to recode each response option into their own variables using a string search function (in this example "index" returns the position of a matching string anything greater than zero means the string is found) In your data step statement: if index(VAR, "1")&gt;0 then VAR_1 = 1; if index(VAR, "2")&gt;0 then VAR_2 = 2; if index(VAR, "3")&gt;0 then VAR_3 = 3; if index(VAR, "4")&gt;0 then VAR_4 = 4; Then you run frequencies for each variable.
Separate the values out: create variable one, two, three And if there is a 1 in var then it‚Äôs 1 in one. Var one two three 1,3 1 0 1 And then you run a regular proc freq on one, two, three. I would suggest to become a member of stackoverflow.
Sounds like a good plan. Well done.
Yeah I was able to create a new variable corresponding to 1,2,3,4. However this then creates multiple tables for proc freq. and if I try to create a frequency plot using the option in proc freq, they are not all on one plot. Is there anyway around that?
As far as I know the only way to do that is to output each individual proc freq table into a dataset using the output statement, then stack each dataset for each variable together into one dataset. From there you can clean up the rows based on what values you want to display.
Create your data data one; input x $; cards; 1 2 1,2 1,3,4 ; run; Count values using SQL and CONTAINS proc sql noprint; select count(x) into :count1 from one where x contains "1"; proc sql noprint; select count(x) into :count2 from one where x contains "2"; proc sql noprint; select count(x) into :count3 from one where x contains "3"; View your counts in the LOG %put &amp;count1 &amp;count2 &amp;count3;
The SAS documentation on PROC SQL is not bad. You might also consider a more general SQL book, not SAS-specific. (But SAS has some additional tools available in data steps that SQL doesn't; I find that most of my data manipulations are "2/3rds proc sql steps and 1/3 data steps."
I could be missing something, but I think the easiest way is just to split each observation into multiple observations. Building on /u/ButIwasThere wrote, I came up with something like this: data multiple; input x $; n = countw(x, ","); do i = 1 to n; value = scan(x, i, ","); output; end; datalines; 1 2 1,2 1,3,4 ; run; proc freq data=multiple order=internal; tables value; run;
Yes, good solution.
I would use index and create 4 binary flags to show if the participant selected the corresponding field. Then just do a proc freq with the /list option. The field itself will indicate if the response was present or not. Next I would ask find whoever designed the data and tell them off.
Yeah that‚Äôs what I originally had done. It just made it a lot more tedious to make a frequency graph along with the table. The crazy part is the people who I got the data from are survey methodologists üò¨...
I was on a project a long time ago and there was data gathered in a check-box like what you have. The person said they wanted it reported in a pie-chart showing each of the (1,2,3) , (1,3), (2,4) etc combinations as each slice. I could not talk them out of it and it was not understandable at all. I mean even if there were 4 options there would be too many combinations for an understandable chart. Maybe your data's frequency is different but, it just makes for an absolute nightmare when it came to understanding the data. Looking back at it, I would now just report the top-5 combinations along with the ranking of each individual choice.
If you want to call macro run time, not compile time (like in normal circumstances), you should check on the documentation of **call execute.** &amp;#x200B; Within the macro you can use call symputx, and store the macro variable in the global symbol table, so you can acces them on the whole session, therefore in your original datastep. &amp;#x200B; However, my best guess is whatever the task is, you are unnecessarily overcomplicate it. You should never use the macro facilites this way
Is it possible to post the code? I'm trying to visualize what you're saying, but i'm having trouble. I've pulled macro values into a macro within a datastep before, but i can't come up with a quick one off the top of my head. Seeing it would help.
This makes no sense to be honest. Can you please expand in detail what you‚Äôre trying to do and what your question is? To call a macro from a data step use call execute or dosubl.
Take the two free SAS e-course. For any topic you want to learn in depth search for papers on lexjansen.com
I would use the command "call symput" when using macros to name variables.
Scan function + do-loop
Scan in a DO WHILE loop and then transpose the resulting dataset
This set WORK.COMBINED; if factor1=1 &amp; factor2=1 then group=1; if factor1=1 &amp; factor2=2 then group=2; if factor1=1 &amp; factor2=3 then group=3; if factor1=1 &amp; factor2=4 then group=4; if factor1=2 &amp; factor2=1 then group=5; if factor1=2 &amp; factor2=2 then group=6; if factor1=2 &amp; factor2=3 then group=7; if factor1=2 &amp; factor2=4 then group=8; if factor1=3 &amp; factor2=1 then group=9; if factor1=3 &amp; factor2=2 then group=10; if factor1=3 &amp; factor2=3 then group=11; if factor1=3 &amp; factor2=4 then group=12; Can be rewritten as: set WORK.COMBINED; group = ((factor1)-1)*4+factor2; Now, that being said, nowhere in your code does this `residuals1` ever get created
Thank you! I am working from examples given in old class notes and I don't really know much beyond that -- how can I create "residuals1"?
Piggybacking on above: data WORK.residuals1; set WORK.COMBINED; group = ((factor1)-1)*4+factor2; run; data work.group1; set work.residuals1; where group=1; run; data work.group2; set work.residuals1; where group=2; run; etc etc.
You have a couple of good options so far, but here is a more fleshed out example: data namepets(keep=id name pet); length pets $20; id = _N_; input name $ pets $; n = countw(pets, ","); do i = 1 to n; pet = scan(pets, i, ","); output; end; datalines; Bob Spot Susan Milo,Rover,Shadow Jill Mittens,Chance ; run; proc transpose data=namepets out=tranxpets(drop=id _:) prefix=pet; by id name; var pet; run; proc print data=tranxpets noobs uniform; run;
Alternatively, I also tried out SASMarkdown in r to run chunks of SAS code, but that only works well using listing. What I really want to do is just output tables and narrative in the same way that I use rmarkdown, so if someone has a workflow in TeX that works for them, please share. I've come across a few resources here http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/MyPrograms/SASTricks/output-to-LaTeX.sas http://people.stat.sfu.ca/~cschwarz/Stat-650/Notes/PDF/ChapterSASTricks.pdf But I'm still searching for something that's a template for just writing up a short report with some quick tables and output.
"WORK.COMBINED.residg1" doesn't exist because SAS is reading two libraries. WORK and COMBINED. You can't use a period in a dataset name. COMBINED apparently exists, but residg1 does not. And COMBINED.residg1 tells SAS to look in a libname named COMBINED for a dataset called residg1. Also, try not to program into an existing dataset. output out=WORK.COMBINED r=rx1 rx2; This combined is overwriting the input version of combined. I'd name the output out as something else.
CountW to determine the number of words. Scan to separate into parts. If you know you‚Äôll have at most three use a loop and scan. If you‚Äôre not sure how many you‚Äôll have use scan + transpose for a dynamic approach. You may also want to consider keeping it in the long format. Makes it easier to work with in the long run.
It's kinda key to automating reports. You can get by just dragging and dropping for adhoc work but it's worth learning for bigger mi pieces
Definitely want to learn to code it. Use filename or let statements for file or folder paths. Point and click gets you by but the real stuff is in the code.
it's ok if you just need to import or export once, but it's faster to have the code if you need to do it repeatedly. You can save the code that sas generates when you use the import/export guided procedure, and then use that code for the next imports/exports. If you want to learn to code it, just start with that code, and apply options as needed. you can easily find them on SAS website or on dedicated papers
Thanks
Knowing both can be important. I too work in some environments where for whatever reason they don't let you just put the file location in code, but the import works. On the other hand, when import/export does work then automation becomes easier/cleaner.
gender = substr(bigvar,1,1); condomuse = substr(bigvar,2,1); etc. you just substr the combo var using the above code with (varname,position,startinglocation)
Infile is really important, too, compared to proc import, if you‚Äôll ever be importing the same cumulative file with incremental changes made over time. Proc import will assume lengths and formats that may not work with the intention of your data. For instance if a field has potential values of 1, 2, 3, and N/A but none of the records in the initial import have a value of N/A, proc import will read the records and make it a numeric variable. Once an N/A is added, it will read as character and may be incompatible with later code that calls that variable. It all depends on intended usage, but infile allows you to actively declare your structure based on your understanding of the data contents rather than relying on SAS to assume what they should be.
I got it! I ended up doing a double transpose to get my 4 columns into 1 column. The I just the substrings from the big column. Your solution looks more efficient though.
You are in the log tab of sas studio. go to the code tab and try again
I'm actually in the Code tab. Still doesn't work for some reason.
So this happened to me for the first time ever after I did an update the other day. I eventually got so fed up, I copied the code, placed it into text edit, then logged out of UE without saving. I powered off virtual box and restarted my computer. I was annoyed af, but now it works ü§∑‚Äç‚ôÄÔ∏è
sgplot doesn't support group and subgroup. You can however do this in gplot, or get something similar with panels. https://communities.sas.com/t5/Graphics-Programming/How-to-produce-stacked-bar-charts-with-GROUP-and-SUBGROUP-in/td-p/180072
It happens sometimes... no idea why. Make sure you‚Äôre hitting save from the code tab, and if all else fails, save as .log and then reopen it and save as .sas Fortunately both log and sas files are all plain text. https://communities.sas.com/t5/SAS-Programming/unable-to-save-libname/m-p/527025/highlight/true#M143619
This is why the first time I work with a dataset I do a proc import with guessingrows=all, wait 10-20 minutes, copy the log with all the formats into a new data step with infile, remove the proc import code. I know, I'm lazy, but seriously you'd think SAS would have a sensible way to import data without silently truncating characters.
You need to reformat your data but this is very much doable, and I highly recommend using sgplot. Here‚Äôs a blog post on it. Newer versions look better and can be customized more, this is about 5 years old. https://blogs.sas.com/content/graphicallyspeaking/2013/09/07/bar-charts-with-stacked-and-cluster-groups/
I‚Äôm guessing your original data is likely in what‚Äôs known as a fixed width format text file.
This. If you have a text file, you should be using infile to read it in always.
You failed to heed rule 0 of SAS coding 0. Never do your coding in SAS Studio...copy into but do not create code
Xlsx
Is it University edition? It happened for me . Just try again nd again.
Just fyi, the final example with both stacks/clusters actually uses sgpanel. The sas community response I posted links to this blog article
Thanks everyone! Glad it's not just my ignorance. I'll keep messing with it.
OP wants the second graph.
Read the docs, it only applies to specific output types, like listing.
Oh ok
Ah gotcha, thanks -- missed that. I myself wanted to do stacked/clustered groups a few weeks ago and was very annoyed that it's not implemented yet in sgplot!
Are you taking the free SAS e-course or the Coursera one?
Can they not update from EG?
I mean I could do them all manually; we are far too locked down to have admin rights for the local users. I was just curious if it had a halfway decent solution for deployment scenarios... And apparently they don't. But appreciate the feedback.
No none of em, I'm learning from SAS base prep guide.
I was about to ask if they the user had any sort of admin rights. My work I get granted temp admin rights then update it through EG myself to save the help desk some. Far as I know local EG updatea have to be done on the PC side. Only thing I can think of is a software management tool. We use one for common crap.
1 Z q,^::^:""#/%/=%%'fish Hp ggp bhyyy thi uhura hi jjjjowovghvg TV hbk nnjjhhhhh
I'm not 100% sure that I understand the issue so I apologize if my reply isn't helpful. From what I'm seeing, you have a macro that makes several datasets given a yearmonth input (%month). And after various sections of your macro, you need to call it for each of the values 201903,201902,201901,201812,....,201608? One thing you could do is to create a wrapper macro that wraps all the %month calls into a larger macro and then you only have to call that after each section. %macro monthall; %month(201903); %month(201902); %month(201901); %month(201812); ***Rest of calls here; %month(201608); %mend monthall; If you don't want those all written out and would rather have SAS generate the yearmonth values you could do somehting like this: %macro monthall2; %local i j ij; %do i=2016 %to 2019; %do j=1 %to 12; %if (&amp;i = 2016 AND &amp;j &gt;= 8) OR (&amp;i = 2017 OR &amp;i = 2018) OR (&amp;i = 2019 AND &amp;j &lt;= 3) %then %do; %if &amp;j &lt; 10 %then %do; %let ij=&amp;i.0&amp;j; %end; %else %do; %let ij=&amp;i.&amp;j; %end; %month(&amp;ij); %end; %end; %end; %mend monthall2;
Thank you. I will try this and report
I‚Äôve never used MATLAB so I can‚Äôt give you a comparison of the two, however, I can speak to some benefits of SAS. Probably one of the biggest benefits for the work I do is SAS‚Äôs ability to handle a large volume of data. Analysis that would cause Excel or R to grind to a halt can be done in SAS because it doesn‚Äôt solely rely on in memory processing. You‚Äôve also touched on another big benefit when you mentioned data cleaning. Very useful for this, often much easier than trying to clean data using SQL or an ETL tool. Then of course there are the many procs. Think of them like Pandas in Python. They are pre-built programs that automate complex analysis for you rather than having to build your own. Part of the rigidity and weirdness you‚Äôve mentioned comes from the fact that SAS has been around since the 1960‚Äôs. Part of it is also how SAS handles data. Specifically, it reads a record, manipulates that record and then writes it out. So, in essence, a data step in SAS is a do loop. And then part of it is that while the core language has remained the same, new functionalities have been added that sometimes required a different syntax (macro‚Äôs and the Graph Template Language are two that come to mind). Don‚Äôt give up trying to learn it. Go out to Amazon and get ‚ÄúThe Little SAS Book‚Äù. It is a great introduction and once you get the basics down the language really starts to come together. Also, the community is great. Lex Jansen has a website with tons of papers on how to do various things in SAS; many times the questions posted on the SAS community pages are answered by SAS employees themselves and the list goes on.
Really understanding the advantages of SAS you need to get a handle on the PDV \[Program Data Vector\] and how it is created and used.
SAS DQS does this, but if recall right it an't cheap
I'm not sure if I follow, but you can use a %include to bring the code into the program and then use the NOSOURCE2 option. That will run the code, but it won't show up in the log.
You could start by building some proc formats with the acceptable USPS abbreviations for street, drive, lane, etc. You may be able to use those in conjunction with a north/south/east/west proc format to determine (for example) whether a particular word is a predirectional (N. Main St.), a street name, or a postdirectional (Main St. N.). Once you've determined what each word represents, you can change the words to their corresponding abbreviations. Then you can merge by the list of address parts. This process will work better if the ZIP-Plus 4 is well populated in your data. That will make it less likely that you'll have similar addresses on the same block.
There's a typo in your proc print. What does the log say? Your plot statement should probably have an asterisk in it, and it's also missing a semicolon.
ERROR 22-322: Syntax error, expecting one of the following: \*, :. ERROR 76-322: Syntax error, statement will be ignored.
 PROC PRINTDATA=OUT2; RUN; Should be: PROC PRINT DATA=OUT2; RUN;
Yes, that looks like the error on your plot statement. It should be like this: plot prin1 \* prin2;
Is your link an accurate representation of the real data file? What i mean is, is the ATLANTIC variable (specifically the AL* values) always on the header rows you're talking about? Do the header rows always have AL* atlantic values?
I don‚Äôt understand. I‚Äôm just trying to read in that html file so that it has the variables Atlantic, name, and row followed by the variables for each row below that until it gets to the next header line.
Ok, this will get it all in, but you're going to share a couple of columns with those UNNAMED rows. But in the next steps you can create a counter to get the row count you want a few different ways. Data weather; infile "K:\Shared\mturf\temp\Edit1.txt" dlm=',' lrecl=75 truncover firstobs=1 dsd; length atlantic time rows status lat long $10 wind pressure x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 8. ; input atlantic $ time $ rows $ status $ lat $ long $ wind pressure x1 x2 x3 x4 x5 x6 x7 x8 x9 x10 x11 x12 ; obs=_n_; run; data weather3; set weather ; by obs; if time="UNNAMED" then catcount+1; retain catcount; run; proc print data=weather3 (obs=20); var atlantic time rows catcount; run; proc freq data=weather3 noprint; tables catcount / out=count; where time ne "UNNAMED"; run; proc sql; create table weather5 as select a.*, b.count from weather3 a, count b where a.catcount=b.catcount order by obs; quit;
Sorry for the crap reddit formatting.
Oh, and i probably got one or more of your headers wrong, so be aware of that.
I've been dealing with this a lot over the past few months. The "proper" way to do this is to pay money to run it through a CASS system (we use Satori) which will standardized the addresses in the USPS preferred format. A cheaper way to do this is tap into google map's API and feed these address into google and have them standardize it for you. Once standardized, it should be a simple merge by addresses. If you want to stay in SAS, you can (with mixed results) use the "COMPGED" fuzzy matching function and do a full join to match every record against every other record and select the record with the most similarity. (I have a program written in R that does something very similar: https://github.com/Adamishere/Fuzzymatching)
The important thing to understand about scope in SAS, is that besides global statements like OPTIONS or TITLE, most statements are local to the step (DATA or PROC) they are used in. If you're a fan of MATLAB you might consider learning PROC IML. SAS/IML is the product that was intended to directly compete with MATLAB.
If you lose the 'K' in your wk_char, you might be able to use a week informat to get a date? http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a002604509.htm
Create a suma=sum(rowa) and a sumb=sum(rowb) variable using proc sql. Merge this onto your original table so the sum value is populated for all rows. Then create the percentages eg apct = a/suma, bpct=b/sumb. You may want to macro this step to save lots of lines of code. Then drop all variables except the pct ones out of your dataset.
Hello pleas try this [pandas columns in percentage ](https://stackoverflow.com/q/33985509/8333806) If you doesn‚Äôt understand let me explain you.
Do you want that all values [i] bi converted into percentage??
But this means I have to hard code the name of all columns, which is not practical in my case. I am looking for a method that allows to me to batch convert *all* numeric variables to column-percentages.
Well I am trying to do this in SAS not in Python.
yes, as the percentage of the sum of their column.
This may at least solve a sub-problem: you can use proc summary to (easily) get a sum for all the numeric variables https://communities.sas.com/t5/General-SAS-Programming/Sum-all-numeric-variables/td-p/228238
If your columns are ordered like col1, col2, col3... You can easily read them into an array with another array retaining the sums. Then if end of file, do math
Well a good text editor could do it 30 seconds, Alternatively look into using _numeric_ combined with a proc SQL.
I think it would also work by using PCTSUM in a PROC TABULATE and creating an output data set.
Macro language might be good here; how about this: (might not be exact code) %macro loopreg; %let var1=a7; %let var2=a11; %let var3=a20; ...(etc.)... %let var87=a601; %do i=1 %to 86; %do j=%eval(&amp;i.+1) %to 87; proc reg data=bleah; model &amp;&amp;var&amp;i..=&amp;&amp;var&amp;j..; run; %end; %end; %mend; %loopreg;
Here you go (probably could be cleaned up, but hey you got it for free): &amp;#x200B; proc means data=work.datatest; var _NUMERIC_; output out=work.sumstats(drop=_type_ _freq_) Sum=/autoname; run; proc sql; create table work.new as SELECT * FROM Datatest, Sumstats; quit; proc sql; select name into: vars separated by ' ' from dictionary.columns where libname='WORK' and memname='DATATEST' quit; %put &amp;vars; %macro getit(); data work.final(KEEP=&amp;vars); set new; %do i=2 %to %sysfunc(countw(&amp;vars)); %let var=%scan(&amp;vars, &amp;i, ' '); &amp;var = &amp;var/&amp;var._SUM; %end; run; %mend; %getit();
Only point I'd add here is to output the model performance as a separate data set with the identifying &amp;i._&amp;j. tag, so that you can sort through as actually figure out which set of &amp;i._&amp;j. models give you performance beyond your expected threshold, if you have one.
You could generate the user-defined format from the data itself! :) https://support.sas.com/resources/papers/proceedings/proceedings/forum2007/068-2007.pdf
Perhaps you could run both sets of addresses through proc geocode, and then see which ones end up with the same lat/long.
If you open developer tools in your browser, click on the network tab, and try to save again is there any helpful output?
thanx, this looks good. I think this is the best we can get in the absence of out of the box solutions, so I am going to implement this.
yeah I had hoped there would be an option in PROC TABULATE or PROC REPORT to do just this, the same way PROC FREQ outputs row and column percentage.
This would be more like it but I have no idea how to write this code. can you elaborate? thank you
Just save your macro month to a different file. Then bring it into your program where you plan to use it with a %include. Include the OPTIONS statement NOSOURCE2 before the %include in your code. Then the macro code that you included will not appear in the log, and it also won't clutter up your SAS program.
So I reread you your solutions and I do not get the second part. I applied the first solution. %macro month; %month(201903); %month(201902); %mend month;
Here is what the macro looks like in my code. %macro month(yrmth); data Accounts2B_&amp;yrmth; set Accounts2A_&amp;yrmth; other things; run; %mend; %month(201903); %month(201902); what is the macro code supposed to look like in the separate file to call in with %include? %macro month(yrmth); %mend; %month(201903); %month(201902); %month(201901); %month(201812); %month(201811); %month(201810); %month(201809); %month(201808); %month(201807); %month(201806); %month(201805); %month(201804); %month(201803); %month(201802); %month(201801); %month(201712); %month(201711); %month(201710); %month(201709); %month(201708); %month(201707); %month(201706); %month(201705); %month(201704); %month(201703); %month(201702); %month(201701); %month(201612); %month(201611); %month(201610); %month(201609); %month(201608); then what would be the right way to call it the macro value from the main code?
Just save everything between %macro and %mend in the separate file.
another question. Is there not a way to write up all the macro values once inside the program under a name (say macroname), then use that name to each time i need to run the macro? like data accounts2c_&amp;macroname ?
I haven't done it myself, but you should be able to do something like this: http://support.sas.com/documentation/cdl/en/mcrolref/62978/HTML/default/viewer.htm#n1o5fkxq0gqdpcn1xs3ksdks69tf.htm.
Real basic ideas: Time of day vs day of week vs genre. What genres get you through work? Random: Match your tracks against their BPM / Tempo (not sure what site would have that) and investigate if you did a speed through all genres
I just saw your other reply with your macro code in it: &gt; %macro month(yrmth); &gt; &gt; data Accounts2B_&amp;yrmth; &gt; &gt; set Accounts2A_&amp;yrmth; &gt; &gt; other things; &gt; &gt; run; &gt; &gt; %mend; To run the code you want, you need to do the following: 1) Declare your macro 2) Declare the wrapper macro (the macro that calls all the iterations of your macro. 3) Call the wrapper macro. So it would look like this: ***Declare your macro; %macro month(yrmth); data Accounts2B_&amp;yrmth; set Accounts2A_&amp;yrmth; ***other things; run; %mend; ***Declare wrapping macro; %macro monthall; %month(201903); %month(201902); %month(201901); %month(201812); ***Rest of calls here; %month(201608); %mend monthall; ***Call wrapping macro; %monthall; Concerning your other question: how my second macro worked. It was just a way to simplify the creation of the year month variables. The idea is that instead of calling %month(yearmonth) for each year month combination, we use 2 for loops to create them for us. Below I've reposted the code with some comments to help explain the flow: %macro monthall2; /************************************** This is just to ensure that these macro variables only exist locally (i.e. inside the macro) **************************************/ %local i j ij; /************************************** The overall idea here is to create a variable ij that will contain the yearmonth value we want the month macro to call. So here i is given the year values (2016 through 2019) and j is given the month values (1 to 12). **************************************/ %do i=2016 %to 2019; %do j=1 %to 12; /************************************** Note that the loops for i and j will create all combinations of years and months from 201601 up to 201912. Based on your inital post, I assume you want nothing before 201608 and nothing after 201903. This "if" statement is being used to removing anything in 2016 before August and anything in 2019 after March. **************************************/ %if (&amp;i = 2016 AND &amp;j &gt;= 8) OR (&amp;i = 2017 OR &amp;i = 2018) OR (&amp;i = 2019 AND &amp;j &lt;= 3) %then %do; /************************************** This if else statement looks at the value for j. If it is less than 10, we add a leading zero. Otherwise we don't. This ensures we get values like 201608 instead of 20168. After these statements run we will have values for the ij macro variable **************************************/ %if &amp;j &lt; 10 %then %do; %let ij=&amp;i.0&amp;j; %end; %else %do; %let ij=&amp;i.&amp;j; %end; /************************************** Finally we call your macro for the value of ij. As we loop through the values, it will run your macro for all values 201608 up to 201903. If you want to verify that the macro is correctly creating ij properly, replace %month(&amp;ij) with %put &amp;ij. It will print all the created values of ij to the log. **************************************/ %month(&amp;ij); %end; %end; %end; %mend monthall2;
Transpose the data and then run proc freq on it and be done.
Thank you! It worked
Wrong sub dude.
Which one then?
r/Finland
Here's a sneak peek of /r/Finland using the [top posts](https://np.reddit.com/r/Finland/top/?sort=top&amp;t=year) of the year! \#1: [Finnish guy trying to see what the swedes are up to across the border.](https://i.redd.it/syujqoaqhdh21.png) | [32 comments](https://np.reddit.com/r/Finland/comments/as0ies/finnish_guy_trying_to_see_what_the_swedes_are_up/) \#2: [Even finnish cats needs the personal space](https://i.redd.it/mh8tjd8cadi21.jpg) | [21 comments](https://np.reddit.com/r/Finland/comments/atyvep/even_finnish_cats_needs_the_personal_space/) \#3: [finland](https://i.redd.it/t8fauotuou121.png) | [85 comments](https://np.reddit.com/r/Finland/comments/a2cju0/finland/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
LOL but it did make my morning.
Hello could you give more exemples for your input data. I don‚Äôt understand.
data one ; set have ; n = countw(var,","); /\* no. 'words' delimited with comma \*/ do i = 1 to n ; do j = 1 to n ; var1 = scan(var,i,",") ; var2 = scan(var,j,",") ; output ; end ; end ; run ;
Halfway down the page is the link to joint certificates or masters programs. https://www.sas.com/en_us/learn/academic-programs/resources/student-university-programs.html Queens is my recommendation but they‚Äôre Canadian. I think Texas is supposed to have some good programs but don‚Äôt recall specifics. Hopefully someone else is more helpful with personal recommendations.
[https://business.okstate.edu/analytics/certificate/grad-data-mining/index.html](https://business.okstate.edu/analytics/certificate/grad-data-mining/index.html)
Thank you ! Really appreciate your help on this one.
What kind of competitions?
Something like this should work: data want; set have; count1 = 1; count2 = 1; do while (scan(var, count1, ",") ne ""); var1 = scan(var, count1, ","); do while (scan(var, count2, ",") ne ""); var2 = scan(var, count2, ","); output; count2 = count2 + 1; end; count1 = count1 + 1; end; drop count1 count2; run;
I added a missing line to the code, so make sure you refresh before copying.
UNCG in NC has a partnership with SAS. Check the ERM department.
NCSU offers a course that got me through the certification exam. It‚Äôs tough but you learn through brute force.
Your posting the same question in a few places?
Didn't realize it was posted somewhere else. I didn't see it on the SAS forums. Not a real friendly community here. Jfc.
WGU has it under MSDA program, you'll gain 2 SAS certificates. https://www.wgu.edu/online-it-degrees/data-analytics-masters-program.html
&gt; The **total cost** estimate for each Graduate Statistics Certificate online program for 2018-2019 (12 total credit hours) is $5434.56 for North Carolina residents and $15,130.56 for nonresidents. &amp;#x200B; Thanks for the rec but the cost is too high for non NC residents
I'm going thru the list but it appears most of those programs are only open to students already attending the university, like a SAS certificate awarded with a Masters degree that a student is already working toward. I'm not necessarily looking for a degree - just a set of courses focused on SAS. I'll reply back if I find something
I gave their graduate admissions office a call and they said they don't have anything available to out of state students who aren't working toward a degree. They referred me to the undergrad office but no one picked up. I'll try calling again later.
This looks promising - thank you!
Are SAS courses recognized directly?
Oh sorry I was suggesting the one course - ST555. I didn‚Äôt realize you were looking for a certificate program.
The stipulation has to be that the courses has to work toward a degree or certificate. I'm looking for program that is focused just on SAS. UCSD's SAS cert program is something that fits that bill: [https://extension.ucsd.edu/courses-and-programs/sas-programming](https://extension.ucsd.edu/courses-and-programs/sas-programming) . It's just unfortunate that it hasn't been updated in awhile. I think they last updated it about 10 years ago. &amp;#x200B; Courses by the SAS institute aren't recognized either because it's not administered by an organization accredited by the US Dept of Education.
Yeah, unfortunately I have to show that I'm working toward either a degree or certificate to get reimbursed by my employer.
Rename XYZ YYZ as one common variable name before transposing. Or you can transpose each file separately and have the transposed variable called Date, and then set the datasets.
There will be several such variables and I would not know their names before hand.
You cannot control the input when you use proc import and if you use someone else‚Äôs code at least leave their credits in it.
Do you have an example of what you want and of what you are trying to get to? You may want to look at the `CALL vname()` routine. [vname sas documentation](http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000127866.htm)
Unfortunately, I don't think there is an easy way. I use Proc Sql to determine which country names are in my data that aren't in the map, and vice versa. I then use a data step to change the names, such as ... data foo; set foo; if name='Russia' then name='Russian Federation'; /* and so on ... */ run; Note also that the country names GfK uses in their maps can change from release to release.
More specifically, here's some sql I used to check for name mismatches in one of my examples: proc sql noprint; select unique idname from my_data where idname not in (select unique idname from my_map); select unique idname from my_map where idname not in (select unique idname from my_data); quit; run; And here's the code I used to change the names in the map, to match the names in the data, once I had scrutinized the mismatches: data my_map; set my_map; if idname='United States' then idname='USA'; if idname='China' then idname='China Mainland'; if idname='Russian Federation' then idname='Russia'; if idname='South Korea' then idname='Korea Rep.'; if idname='China/Taiwan_POC' then idname='Taiwan'; if idname='United Arab Emirates' then idname='UAE'; if idname='Slovakia' then idname='Slovak Republic'; if idname='Venezuela, Bolivarian Republic of' then idname='Venezuela'; run; (Note that this is a very manual process, for each new map and dataset.)
If the mismatches are consistent (i.e. it always says "Russia"), then you could make a concordance dataset with the old/new names and merge it onto each dataset you need to change. It can include just the 27 mismatched values, and you just do something like this: data newnames; merge oldnames(in = in_data) countryfix(in = in_fix); by oldname; if (in_fix) then fixname = newname else fixname = oldname; if (in_data); run;
Thank you so much! :)
Thank you!! :)
It sounds like for question 1 the professor only wants you to analyze one variable, then for question 2 add in sex and age, and then finally in question 3 use all the variables provided in the model. Could you post the exact questions? &amp;#x200B; If you're including all of the same variables in question 2 and 3, and you're not changing the model statement then you're going to get the same outcome. I believe the MEANS and LSMEANS statements only provide additional information.
If outcome is dichotomous then you should be using logistic throughout. GLM is a linear model so you'd want a continuous outcome.
If I used proc logistic throughout, how could I adjust for age and sex? and then for all the other variables? i see how that would be correct, I'm just not sure how to get there
Agreed, provided that the "exposure" variable is one of the predictors. Model 1: outcome = exposure Model 2: outcome = exposure age sex /*This controls (adjusts) the effect of exposure for sex and age */ Model 3: outcome = exposure age (all other predictors) /*This controls (adjusts) the effect of exposure for sex, age, and all other predictors */ Models 2 and 3 also allow you to test the effect of age, sex, etc. on the outcome. To what extent does being female/male increase/decrease the (log) odds of having the outcome? But in this case, it sounds as if you are primarily interested in the effect of exposure. Good luck.
We were just having this conversation in a faculty meeting yesterday. The question was; at what point does it stop being "asking for help" and become "having someone else do your work for you"? The consensus was that farming out your analysis online or from other students crosses the line when you actually send your data to someone and ask for the results. So asking questions in the way you have is at the line but not over it. It's close enough though that if I were your instructor or TA I'd ask you, in person, why you aren't at office hours instead of asking these questions on an internet forum specific to the software you're using. The reason I'd ask that is that your question isn't SAS specific, it suggests that you're not getting the point of logistic regression and how it relates to the modeling and interpretation you're being asked to do. Seriously, talk to your TA about WHY you're using logistic, when it's appropriate to apply logistic and don't get lost in the SAS coding that you're using to actually perform the modeling. The point is to apply the appropriate statistical technique and interpret the results correctly.
I am sorry, you are right about mentioning the source of the code. I added to the question the link to the github repo. Thank you.
I'd love to see something about musical tastes changing over time. If you could categorize each song/artist into a genre, then graphically display the proportion of top genres over a period of time (years would be sweet, but I don't know if you have that much data), it would be really cool.
.srx is a report template in XML that contain SAS Report Object Model (ROM) definitions. Depending on the how the file was generated and what the source of data was, there maybe no data in the report definition. You can rename the file with .xml file extension. Open the file with a text editor that handles XML. If the files were generated to include HTML and the report data then you may have an HTML report embedded in the file. Also, SAS makes a Universal Viewer that may help https://support.sas.com/downloads/package.htm?pid=2173
you should be able to import into R using [this package](https://cran.r-project.org/web/packages/sas7bdat/sas7bdat.pdf)
It‚Äôs not the actual data set though, it‚Äôs the report associated.. with the .srx file type. But thank you this is great once we do get the data sets...
I'm sure you can and I can only guess but I'd guess that the "size = 11" is interacting with the "size = 9" coupled with the "position" statement to make a figure that is 20 units wide that treats the inset, not as an overlay like you wanted but as a unique object that's next to the visualization on the left. I find sgplot completely inscrutable personally, I had to build a forest plot for my dissertation and I literally screwed around with every single aspect of it at random to finally get it to look like I wanted. Good luck and please post the successful set of parameters!
 Let me try and answer your question based on the above parameters. Being a Computer Engineer, Or having any programming knowledge it would certainly help. SAS is very SQL like and with easy to use commands it becomes very easy to program using SAS.I f you do not have any prior programming knowledge you would still be able to learn SAS easily. However, it is important you know why do you want to use it. SAS stands for Statistical Analytics System. It is a software suite with various Analytical and programming capabilities. So, if you wish to use SAS for analytics then it would be nice to have some knowledge of: * SQL * Statistics These two topics will form a base for you to get started with SAS and you can easily analyze data using SAS. SAS has many components which serve different purposes. Well, SAS certification is definitely a plus on the resume, it gives a stamp that you know the language to do simple data manipulations. Some companies even pay for your SAS certifications. I would like to recommend you the [Best SAS Training Institute in Noida](http://pythonandmltrainingcourses.com/courses/best-sas-training-institute-in-noida/) for certification and Placement assistance guarantee in SAS.
Sgplot is good for easy plots. The more customs things you want the more GTL is for you.
Yeah so you were right, but the conflict was in the data labels next to the bubbles. I tried to set them on a different size and weight, but with no success, so I just removed them and added a legend, that seems to have solved it. Case closed, thank you all.
Create a variable in a data step for the number of days ago that the item was created like this: age_days = today() - create_date; Then create a proc format for the appropriate ranges: proc format; value agefmt 0-15 = '0 - 15 days' 16-30 = '16-30 days' 31-high = '31+ days'; run; Then you can use it like this: proc freq data= dsetname; table age_days/missing; format age_days agefmt.; run;
If I'm understanding correctly it's pretty simple in a data step.... Data new; Set old; If date1 - date2 ge 0 and date1 - date1 le 15 then '0-15 days'n = '0-15 days' ; /*And so on...*/ Run;
Thank you but I got the ans...more easy by using New calculated data item and categories to create lables
They're using Visual Analytics though so that wouldn't work
I guess I skipped over that part. Looks like a really good reason not to use Visual Analytics if it can't do something so simple intuitively. The same applies to the GUI tools in EG, as far as I'm concerned.
Why are you doing this? There‚Äôs often much easier ways. Here‚Äôs a couple of different ways to create dummy variables. https://communities.sas.com/t5/Statistical-Procedures/How-to-create-dummy-variables-Categorical-Variables/m-p/258702/highlight/true#M13685
And to add to this - you can use data step in the background to create custom formats, but it won't be generally available unless you have loaded into VAs format catalogue. Also, if you have Autoload running, depending on how that is configured, it might fail to load tables with custom formats. I've successfully created a custom format for the Australian Financial Year in a dataset then loaded it manually into the LASR table and used it within VA 7.1. I didn't have access to the format catalogue, but as long as it was in the dataset before loading to the LASR table it was working. See this too: http://support.sas.com/kb/47/100.html
Wow. I had considered looking into VA, just so I could easily share results with non-technical people, but you've talked me out of that. Excel, it is.
in a data step array aa{i} z1-z99; run; end; &amp;#x200B; Then write some stuff to define them or set their values. It's something like that anyway, you're using a property of arrays that allows you to define sequences on the fly and it's probably in that link that DataSciGeek posted.
Why would you do this to yourself with manual if/thens? Arrays!
More specifically, create your set of new vars using an array and then write a simple macro to loop through them ad infinitum. As long as everything is numbered it should be relatively painless.
Haha...that's the way the dataset has to be produced. I'm doing some googling now but have you got any quick links to how to create arrays?
\[SUGI is your friend here.\]( [https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/242-30.pdf](https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/242-30.pdf) ) &amp;#x200B; In your case, it would be something like (done within a DATA step): &amp;#x200B; array type\_dummy\_vars {\*} type1-type100 (100\*0); type\_dummy\_vars(type) = 1;
Visual Analytics should be used in conjunction with other sad programs. Once you have your data set cleaned up and ready in the format you want you can do some pretty amazing things in visual analytics and make it easily usable.and dynamic for the users (i.e. they can do clever filtering of the data to only see what they want). I wouldn't dismiss it just yet unless you had a play with it. The VA on Viya is the one that will incorporate everything together hence you should look at potentially getting that
What do you mean "has to be produced". You mean the final product has to look like the picture?
Ok i've read that, but don't understand what my final code should be based on the examples.
The former, has to be like the picture. Can use other than sql!
So you can't do it in a PROC SQL statement. Instead, you need to use a SAS DATA step and it will look something like this: DATA output_data_set_name_goes_here; SET input_data_set_name_goes_here; /* The following creates an array within the DATA step that holds the 100 typen indicator variables, and sets them all to equal 0. */ ARRAY type_dummy_vars {*} type1-type100 (100*0); /* The following looks at the value of type, your categorical variable, and sets the value of the corresponding indicator variable to 1. */ type_dummy_vars(type) = 1; RUN; Arrays in SAS are just references to blocks of variables (so the type_dummy_vars array doesn't exist in any form outside the above code block, but inside the DATA step it's a way to point at 100 variables at once.
 Hi, sounds like you are learner like me, so I am sharing my learning approach with the following experiments to understand operations, iterations, and explicit output or you can visit Best SAS Training Institute in Noida /* using infinite increments with support from break and continue structures*/ data w; do i= 1 by 1; output; if i=90 then leave; end; run; /*while expression*/ data w1; do while(i&lt;90); i+1; output; end; run; /*until expression*/ data w2; do until(i=90); i+1; output; end; run; /* start and stop with constant operands*/ data w3; do i=1 to 90; output; end; run; /* using operands*/ data w4; start=1; increment=1; stop=90; do i=start by increment to stop; output; end; keep i; run; ;
It all depends on what version of VA you have ... it certainly would be easy to share results with non-technical people, but using an older enterprise tool comes with it's own issues. If it was a current version, then you'd probably just drag and drop (ie: VA 8.3).
Basic plan...\[Don't have SAS access at the moment\] * Sort by Start Date * Get First Record * HStart = Start, HEnd=End * Get next record * If Start &gt; HEnd * Output * HStart = Start, HEnd = End * Else * HEnd = MAX (End , HEnd) * Loop Back to Step 4 * Output &amp;#x200B; Note, REALLY bad idea to name variables the same a key words \[i.e. end\]
What's the size for the windows? Looks like buckets of year? Could find min start date max end date for each year? Could try and sort by start date end date and use first. Last. Functionality?
How are those defined? I assumed no overlap but your first set overlaps with the second so not sure why it‚Äôs excluded. How big is the data? There‚Äôs a simple way, but it‚Äôs space intensive.
On the off chance you haven't figured it out since yesterday... I would approach this using SQL, provided your dataset isn't ridiculously large. I'm not at a SAS computer to test, but the gist is: proc sql; create table iter2 as select distinct min(left.start, right.start) as start, max(left.end, right.end) as end from initial left, initial right where right.start &lt;= left.start &lt;= right.end or right.start &lt;= left.end &lt;= right.end; quit; run; You would have to iterate the proc until you don't see a change in the resultant dataset.
Hey thanks for the links. i've tried some of these methods e.g. GLMMOD &amp; SAS ends up crashing/can't run the code of my whole data set (approx 2 million rows), however the "case when" code works fine...Are the dummy variable methods supposed to be faster/ can you point to any literature about processing speed of creating dummy variables?
1) I‚Äôm not too clear as to what you want to compare each quarter sales to. To 0 sales, to the overall average of sales, something else? Significance differences is always a good way to go for easy to grasp summaries as long as you have a good basis. I think a box and whisker plot might help out. 2) this you can do with a [proc report and/or proc tabulate](https://support.sas.com/resources/papers/stylesinprocs.pdf). If this is going to be an ongoing project that needs to be automated look up proc format. You can create your own custom format which helps when automating a report. I‚Äôve done this a handful of times so I am by no means an expert but I hope this helps.
I would like to determine whether there exists a significant difference in sales of one Quarter vs. the sales of another quarter. Thanks for the paper you cite!
Happy to help, if you've got a specific question. What have you done so far, and where are you stuck?
I‚Äôve done q1 and q2 but I‚Äôm not sure how to do it in SAS. Also, this is more of the math, less of SAS, but for q3 I‚Äôm not sure how to show the 3% increase every 20 years in the transition matrix
So, where's the tutorial?
Thanks for this, but you're missing one key piece of information here. The actual tutorial.
Don't you find Cary a little humid?
try ``` %let strata=V1; %let strata=V3; %let strata=ID; proc sql; select &amp;strata., mean(V2) from test group by &amp;strata; quit; ```
Sure, you can do it. You'd just set by id, v1, and v3. Then set a counter and sum within each by group, initializing to zero on first.v3. When you get to the last.v3, calculate the mean and output. Tip: if you use the syntax "ctr + 1;" and "sumvar + v2;" you don't need a retain statement. The ctr and sumvar variables are retained automatically. Having said all that, I'd probably go with PROC MEANS. Edit: If there are multiple v2 variables, it would be a good candidate for some arrays -- possibly even the special \_numeric\_ array if you want the calculation across all of the numeric variables in the data set.
Look into Proc Summary - it's what you want.
Just wanted to respond and thank everyone for the feedback! /u/pzs913 /u/xmindallas /u/metagloria I'm working through these now. I circled back to PROC MEANS, but for whatever reasons, it was flooding my memory and crashing, or at least, I wasn't prepared to let it run all day. Going to make a smaller proof of concept with some of your tips and see what runs the best. Muchas gracias
Means and summary are virtually the same, other than the default of printing the output or not.
You can also do a proc report and compute. It‚Äôs intense to write but you have it of options design wise if this is going to be presented anywhere.
2 million records with how many variables? That shouldn‚Äôt be problematic unless you‚Äôre using SAS UE. And if you are, try increasing the Cores and Ram in the VM, you can go up to 2 cores and I recommend no more than half your machines RAM. Mine has 16gb so easy enough to process.
You‚Äôd have to be working with a huge dataset (100 million for that to happen) or you didn‚Äôt turn off the display output which massively slows everything down for big calculations.
Here‚Äôs a full example of PROC MEANS https://github.com/statgeek/SAS-Tutorials/blob/master/proc_means_basic.sas
let's see your proc means. there's no way it should take more than a few mins based on what appears to be a normal dataset.
Fun fact - SAS is no longer an acronym.
I use this proc regularly but it's been a while since I loaded it but I followed these instructions and it works fine [https://www.methodology.psu.edu/files/2019/03/PROC-LCA-M5-and-higher-4-2e6c2om.pdf](https://www.methodology.psu.edu/files/2019/03/PROC-LCA-M5-and-higher-4-2e6c2om.pdf) The point is that the DLL files have to be int he correct location so that when you initiate the proc the SAS engine tries to execute a file that actually exists, the engine is fine if the dll exists so put the files in the correct location and call the proc and i should give you a note that says that the proc you are using is from Methodology.psu.edu.
Thanks for your reply. I think some of my terminology is incorrect, I am sure the program works fine what I am struggling with is how to use it in SAS Studio rather than SAS Entreprise.
SAS studio is a web application that is running code on a SAS server, you'd have to have Proc LCA installed on that server in order to run it. You could try to make that argument to your SAS administrator but I have no idea if this specific app can even work in that environment. I'd give the developer at PSU a call and ask and then pass on whatever instructions you get to your SAS administrator. Or buy a SAS license of your own, or an MPlus license, MPLus does a better job and produces better graphical results I'm told.
Thank you again for your helpful reply. I will contact the SAS adminstrator and PSU.
If you‚Äôre trying this on SAS University Edition, the free one, you can‚Äôt. You don‚Äôt have access rights to it.
Thanks for your reply! I'm not on SAS university edition but this is good to know.
Hello! Have you tried findw or index? Happy to chat more via PM!
1. Create a temporary character array with the diagnoses you want to look up 2. Create an array that has all your med variables you need to search 3. Write a do loop to go through the terms and use WHICHC() to identify them Another approach is to transpose your data to a long format and then use a single where statement which is more efficient in the long run. You data would look like ID Med_Number Med 1 1 Fentanyl 1 2 Lyrica 1 3 Tapentadol Hyrdochloride
If this thread is still alive tomorrow when I get to my office I'll be happy send the code I use to mine medications fields. I use one of the "clay tight looping" macros I found a while back to compare sets of strings to the text field. You'd have to catenate all of your med strings but I've used it on 25000 or so fields for maybe 600 medications with no problems.
This is a good question... I'll play around with it in the am and let you know what I come up with. My first instinct is to just do it in a datastep using the point= and nobs= dataset options and the randuni() function. Probably need to retain the random values for each of the 3 columns to multiply together. Not quite sure yet. May be able to set the table 3x keeping only col1 the first time, col2 the second and col3 the third, resetting the pointer to a random row each time then multiplying the 3 numbers together. Do you want with or without replacement?
Don't do it with columns of a dataset. Create three arrays of ten elements, then randomly select an element. Dump result to a fourth array and then keep the fourth as a dataset.
With
That would be great - thanks! I'm playing around with a few options just to get the hang of working with these data. I'll post my resolved code once I have it working too.
Okay I sent you a PM with the code and instructions, if you don't get it PM me an email address that works and I'll send it that way.
Try this. Sorry for the delay http://imgur.com/XGLphNp
My general approach would be something like this: - Do a recursive listing of all files (including folder name) with a dir command, and pipe it into a file. Something like this: options xwait; x "dir /s /b C:/scanlocation &gt; C:/output/mydirlist.txt"; - Have SAS read in this text file, and look for rows with ".sas7bdat" - For each of these rows: (1) Parse this field, putting the path into a macro variable (call symput), to generate the libname statement you need. (2) Do a Proc contents on the sas7bdat file, output that to a dataset. (3) Open the contents dataset, and look for the variables you need in the NAME column.
I wrote code that does EXACTLY this at my old job. I'll see if I can dig it out for you!! Yay for no longer lurking
That would be awesome! Thanks!
I could use this lol
Got your PM! Toying around with some different options today, so I will post updates to the post. Thanks for your help!
Like I said, it's a kludge but it functions if you have a list of names and your search target has only correctly spelled medications. I have similar programs for all hypertension, lipid lowering, psych, HIV, gout and other meds but it's really an inefficient approach to this problem.
This is what i do. Use the pipe function on the upper folder location with /s to search subdirectories. Then pull out the directory path and fill out a new variable and then subset for all .sas7bdat files. Create macro vars of all directions to build libname macro vars and run a count do loop macro to assign each libname, run dictionary table code, unassign the library. Stack all datasets together.
VALUES= ( values-list ) options in xaxis statement specifies the values for the ticks on an axis.
Not sure if this is it, but try putting all the xaxis statements on one line Xaxis abel= "Age years" values= (50 TO 90 by 5) ranges=(50-90);
That actually sounds like I will want to do. Unfortunately, there are a lot of steps in there. Do you have any resources that have code examples of anything like that?
Please take a look as **sashelp.vcolumn** and **sashelp.vtable**. In fact, take a look all the vXXXXX datasets views in sashelp.
Offhand creating separate tables and setting them together is the only thing i can think of.
Can they select more than one of the same type of animal?
Not in a single column, but they could select "dog" for pet1 and "bird" for pet2.
Yes but could they select dog for pet1 and dog again for pet3?
Oh! Yes, they could technically.
They could all be output into one data set with an array and an output statement in one pass. do i = 1 to 5; gender = gender{i}; output; end;
They could all be output into one data set with an array and an output statement in one pass. do i = 1 to 5; gender = gender{i}; output; end;
They could all be output into one data set with an array and an output statement in one pass. do i = 1 to 5; gender = gender{i}; output; end;
Yup, spot on. I figures since i'm asking for those ticks the sgplot would provide all of them in the plot, essentially providing the range I was after.
Yup, spot on. I figures since i'm asking for those ticks the sgplot would provide all of them in the plot, essentially providing the range I was after.
Yup, spot on. I figures since i'm asking for those ticks the sgplot would provide all of them in the plot, essentially providing the range I was after.
Yup, spot on. I figures since i'm asking for those ticks the sgplot would provide all of them in the plot, essentially providing the range I was after.
Yup, spot on. I figured since i'm asking for those ticks sgplot would provide all of them in the plot, essentially providing the range I was after.
Yup, spot on. I figured since i'm asking for those ticks sgplot would provide all of them in the plot, essentially providing the range I was after.
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
Why not transpose into one record per person per pet with a data step and then use SQL to select the variables you want and count (*) group by your variables. Proc export to excel and make a pivot table from it
fftt
You could even do it in one pass like this: array gender{5} $ gender1 - gender5; do i = 1 to 5; gender = gender{i}; output; end;
Can you post a sample set and how you want the end result to look like, this often helps. A proc summary might work but you‚Äôd have to list out all the columns or maybes do an array. You can also write a macro and loop this stuff together as a bunch of difference tables at the end, this might be the easiest way.
Agree with this. Its more a data structure problem than a sas problem.
Once you transpose you can use proc freq. You would want to a data step transpose though. Sorry about formatting, probably best to copy and paste into EG or Studio and autoformat it. Data long; Set wide; Array anim(*) firstAnimal - - lastAnimal; Array sx(*) firstsex - - lastSex; Do I = 1 to dim(anim); Animal = anim(i); Sex = sx(i); Output; End; Run; Proc freq data = long; *number of animals across everyone; table anim; *sex distribution of animals; table sex; *animals by sex; table anim*sex; run;
Hi, any luck on the answers?
Thank you, you the man.
Yup, spot on. I figured since i'm asking for those ticks sgplot would provide all of them in the plot, essentially providing the range I was after.
It depends on what a company licensed. It comes with Base, Stat, IML, ETS, SAS Studio, and Access to PC files. Most companies will have these...maybe not IML, but they will have Graph too which university edition doesn't. Probably the biggest downfall.
It would depend on exactly what products you had licensed, but here's some info on the limitations of SAS University Edition: [https://support.sas.com/software/products/university-edition/faq/limitations.htm](https://support.sas.com/software/products/university-edition/faq/limitations.htm)
S-A-S L-O-L.
What type of statistics do you need? Hierarchical modeling? SEM? Basic regression and hypothesis testing? If you need stats expertise you need someone who can program and is a statistician. If you need just programming you have a wider pool. I will mention the first two SAS courses are free online from SAS, in case you weren‚Äôt aware.
SAS UE is limited to two cores. A full version would not be. Depending on what type of calculations you‚Äôre doing this could or couldn‚Äôt make a difference. Honestly, you‚Äôll need some significant work arounds while using UE - the temp space on the VM is limited to 10 or 20gb for one. If you have access to both, take the full version. That being said, some clever usages of indexes, macros and redirecting your temp space can let you do a lot on SAS UE if you‚Äôre limited.
It doesn‚Äôt need graph because Base supports SG procedures including SGmap now.
Looks like AT occurs 3 times. Am I missing something? here is some easy code with a dummy dataset &amp;#x200B; data original\_data; input cards Ev1 $ Ev2 $; cards; 1001 AB AT 1001 AT MY 1002 AB AT ; run; &amp;#x200B; &amp;#x200B; data unique\_ev(keep=ID EV); set original\_data; EV = EV1;output; EV = EV2;output;run; &amp;#x200B; proc freq data= unique\_ev; table EV / out=COUNT\_of\_EV; run;
SAS also has some built in functions for this with the x command. Look up DOPEN AND DREAD (Directory Open and Directory Read)
A proc sql should do the trick. Google 'sql select distinct'.
Yes. I want to know how many times AT AB or MY occurs overall in the data set but I don't want the sum of everything. I guess I want to know the unique number of IDS that used AT AB or MY. So, AT appeared twice once with 1001 then 1002.
then you would dedupe before the proc freq. proc sort data =unique\_ev nodupkey; by id ev; run; &amp;#x200B; If I understand what you want.
Instead of proc freq, try this: Create table counts as Select ev, count(distinct Id) from EV_unique group by EV;
depending the size and width of your table i would use sql to create a union between to "new" tables. data original\_data; input ID Ev1 $ Ev2 $; cards; 1001 AB AT 1001 AT MY 1002 AB AT ; run; &amp;#x200B; proc sql; create table work.EV\_tot as select EV, count(\*) as n from ( select \* from ( select ID, ev1 as EV from work.original\_data ) union select \* from ( select ID, ev2 as EV from work.original\_data ) ) group by EV; quit;
Proc sql; Create table my_counts as Select Id, field, field, count(*) From your_table Group by 1, 2, 3; Quit;
You need CATX for this data _null_; var1 = 'Drug1'; var2 = 'Drug3'; length var3 $ 11; var3 = catx(' ', var1, var2); put _all_; run;
I cant even tell on how many levels this answer is wrong
I would do a proc sort nodupkey by subject and drug Id, using the dupout option to get the deleted observations. Then merge these back in and create the new variable
Thats not gonna work when you need more then 2 drug in the same var
 %let key = patient_id drug_id; /*just to create your example data*/ data input_test_data; input &amp;key. drug $; datalines; 9900001 1 vinorel 9900001 2 carbo 9900001 2 pacli 9900003 1 fluor 9900005 1 5fu 9900005 1 leucov 9900005 1 test3row 9900005 2 fluor ; run; /*This solution works easily if you need more then 2 drugs in your result variable*/ proc sort data=input_test_data; by &amp;key.; run; proc transpose data=input_test_data out=input_test_data_tp prefix=drugname_; by &amp;key.; var drug; run; data result(keep=patient_id drug_id drug_combo); set input_test_data_tp; length drug_combo $100.; array drugs[*] drugname_:; drug_combo = ''; do i=1 to dim(drugs); drug_combo = strip(drug_combo) || ' ' || drugs[i]; end; run;
&amp;#x200B; &amp;#x200B; %let key = patient\_id drug\_id; &amp;#x200B; **/\*just to create your example data\*/** data input\_test\_data; input &amp;key. drug $; datalines; 9900001 1 vinorel 9900001 2 carbo 9900001 2 pacli 9900003 1 fluor 9900005 1 5fu 9900005 1 leucov 9900005 1 test3row 9900005 2 fluor ; run; &amp;#x200B; &amp;#x200B; **/\*This solution works easily if you need more then 2 drugs in your result variable\*/** &amp;#x200B; proc sort data=input\_test\_data; by &amp;key.; run; &amp;#x200B; proc transpose data=input\_test\_data out=input\_test\_data\_tp prefix=drugname\_; by &amp;key.; var drug; run; &amp;#x200B; data result(keep=patient\_id drug\_id drug\_combo); set input\_test\_data\_tp; length drug\_combo $100.; array drugs\[\*\] drugname\_:; drug\_combo = ''; do i=1 to dim(drugs); drug\_combo = strip(drug\_combo) || ' ' || drugs\[i\]; end; run;
 %let key = patient_id drug_id; /*just to create your example data*/ data input_test_data; input &amp;key. drug $; datalines; 9900001 1 vinorel 9900001 2 carbo 9900001 2 pacli 9900003 1 fluor 9900005 1 5fu 9900005 1 leucov 9900005 1 test3row 9900005 2 fluor ; run; /*This solution works easily if you need more then 2 drugs in your result variable*/ proc sort data=input_test_data; by &amp;key.; run; proc transpose data=input_test_data out=input_test_data_tp prefix=drugname_; by &amp;key.; var drug; run; data result(keep=patient_id drug_id drug_combo); set input_test_data_tp; length drug_combo $100.; array drugs[*] drugname_:; drug_combo = ''; do i=1 to dim(drugs); drug_combo = strip(drug_combo) || ' ' || drugs[i]; end; run;
If you have any questions about how does it work, feel free to ask
&gt; data result(keep=patient_id drug_id drug_combo); &gt; set input_test_data_tp; &gt; length drug_combo $100.; &gt; array drugs[*] drugname_:; &gt; &gt; drug_combo = ''; &gt; do i=1 to dim(drugs); &gt; drug_combo = strip(drug_combo) || ' ' || drugs[i]; &gt; end; &gt; run; This was working for me until I got to this part. I got this message. Nothing appears in the last column.
Do you even understand what the are the code doing, or you just ctrl c ctrl v it out and run, like a madman?
If I'm understanding what you're wanting to do correctly, here's one way to do it... input patient_id drug_id drug; datalines; 9900001 1 vinorelbine 9900001 2 carboplatin 9900001 2 paclitaxel 9900003 1 fluorouracil 9900005 1 5-FU 9900005 1 leucovorin 9900005 2 fluorouracil ; run; proc sort data=original_data out=original_data; by patient_id drug_id; run; data modified_data (drop=drug); set original_data; by patient_id drug_id; length drug_combo $100; retain drug_combo; if first.drug_id then drug_combo=trim(left(drug)); else drug_combo=trim(left(drug_combo))||' '||trim(left(drug)); if last.drug_id then output; run;
input patient_id drug_id drug; datalines; 9900001 1 vinorelbine 9900001 2 carboplatin 9900001 2 paclitaxel 9900003 1 fluorouracil 9900005 1 5-FU 9900005 1 leucovorin 9900005 2 fluorouracil ; run; proc sort data=original_data out=original_data; by patient_id drug_id; run; data modified_data (drop=drug); set original_data; by patient_id drug_id; length drug_combo $100; retain drug_combo; if first.drug_id then drug_combo=trim(left(drug)); else drug_combo=trim(left(drug_combo))||' '||trim(left(drug)); if last.drug_id then output; run;
input patient_id drug_id drug; datalines; 9900001 1 vinorelbine 9900001 2 carboplatin 9900001 2 paclitaxel 9900003 1 fluorouracil 9900005 1 5-FU 9900005 1 leucovorin 9900005 2 fluorouracil ; run; proc sort data=original_data out=original_data; by patient_id drug_id; run; data modified_data (drop=drug); set original_data; by patient_id drug_id; length drug_combo $100; retain drug_combo; if first.drug_id then drug_combo=trim(left(drug)); else drug_combo=trim(left(drug_combo))||' '||trim(left(drug)); if last.drug_id then output; run;
Here's one 'brute force' way to do it... input patient_id drug_id drug; datalines; 9900001 1 vinorelbine 9900001 2 carboplatin 9900001 2 paclitaxel 9900003 1 fluorouracil 9900005 1 5-FU 9900005 1 leucovorin 9900005 2 fluorouracil ; run; proc sort data=original_data out=original_data; by patient_id drug_id; run; data modified_data (drop=drug); set original_data; by patient_id drug_id; length drug_combo $100; retain drug_combo; if first.drug_id then drug_combo=trim(left(drug)); else drug_combo=trim(left(drug_combo))||' '||trim(left(drug)); if last.drug_id then output; run;
r/spss
Wow...I have not seen SPSS code for a really long time.
Just remember that two simple processes in series that are 80% correct are way easier to implement than one process that is 96% correct, yet both are just as effective.
Can you elaborate on this point a bit? I am not sure I follow.
I think the point is that you can have one process that pulls out some "Almost certainly businesses" (e.g. anything with "LLC" in it) and is about 80% effective on that, then another process that takes the remainder and pulls out some "Almost certainly people" (e.g. anything where the first word is in a list of common first names) and is about 80% effective on that. Together, those processes should leave about 4% of names unsorted, which you'll need to check manually. By comparison, you could create a single ruleset that tries to do both at once, but it's likely to be very messy because of a bunch of inclusion-exclusion combinations and uncertainty about the order the logic gets resolved. And that ruleset is still potentially only going to catch 96% of all names in it.
Unless you pull in another list like a list of names and cross reference it‚Äôs probably pretty inaccurate. I would simply scrape a website with baby names. Or just make it a csv. Then compare the list and unless obviously corporation then cross reference the first name with name list if on it then person. Just a suggestion
This is correct. When you have multiple axis statements for the same axis the last one overwrites the first one, they do not accumulate.
What you are describing is called [named-entity recognition](https://en.wikipedia.org/wiki/Named-entity_recognition) and you are right, it is a tricky problem. You have a couple of good suggestions already for approaches, but there may be more options if you have a license for [SAS Visual Text Analytics](https://www.sas.com/en_us/software/visual-text-analytics.html). Unfortunately that is not something that I have a license for or any experience with. When faced with similar problems I have generally turned to non-SAS solutions such as [spaCy](https://spacy.io/usage/linguistic-features#named-entities) and the [Stanford Named Entity Recognizer (NER)](https://nlp.stanford.edu/software/CRF-NER.shtml).
**Named-entity recognition** Named-entity recognition (NER) (also known as entity identification, entity chunking and entity extraction) is a subtask of information extraction that seeks to locate and classify named entity mentions in unstructured text into pre-defined categories such as the person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc. Most research on NER systems has been structured as taking an unannotated block of text, such as this one: Jim bought 300 shares of Acme Corp. in 2006. And producing an annotated block of text that highlights the names of entities: [Jim]Person bought 300 shares of [Acme Corp.]Organization in [2006]Time. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/sas/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
^ this. The Natural Language Toolkit (NLTK) python library has NER built in, and you should be able to find examples on feeding in a csv and identifying names. If you're using SAS, python is another great tool to have available.
You might want to use the COMPGED function in your matching to pick up variations on names. This function does a fuzzy string comparison and returns a similarity score between two strings. You could also pull from SSA.gov's list of baby names to help with identifying customer names.
You could also spend (even more) buku-bucks and buy SAS Data Quality Server. It works but it is a serious PITA to calibrate, so would not advise this unless this is going to be an ongoing cleaning exercise.
Thanks for the explanation. This definitely seems like the most sensible approach to take. I also want it to be very explicit that when I'm not sure if something is a name or not then it won't be counted as a name. Better to miss a name than get one wrong in this case. My aim is to minimize the names I have to throw away.
Awesome. I will look into this. I don't thinky employer is going to pay for more expensive SAS licenses for this task but I have python available.
Thanks! I will check out these resources.
I think the list has about 90,000,000 entries so I'm not sure that it's feasible to manually cross check much. But I do like the idea of comparing lists of names.
Can you describe how you would use compged to find variation in similar names? I'm using it in another part of this project where I need to match customer names with another set of names, but I'm not super familiar with the function.
Unfortunately this is a one-off task I've been given, so no chance of getting new licenses or getting time to calibrate/test radically new approaches.
Not cross checking manually but using something like compged
What are the trends of companies using R though? I am noticing a lot more companies are wanting R programming or SAS + R. I have never done R and I hope I don‚Äôt have to, but if the market trend is slowly going to R, might have to learn.
This youtube channel also has a video called "How to reference your statistics ass".
R is free
Also Python...
Most companies are using SAS also use R/Python as needed.
Python is rapidly stealing market share from both SAS and R. If I were new to analytics or data science and wanted to prioritize learning these languages / software my list would be Python &gt; R &gt; SAS, and I'd stop before hitting SAS. There just aren't really new SAS shops forming, they're maintaining contracts with institutions that have been using their expensive bloat for the past 20 years, but it's weird for an established group to bring it in.
Ironic that the video bragging about R forums to help users is posted on a SAS forum to help users. Also, please have someone who speaks English help proof your work.
That is my exact experience. At the company where I work (financial services), some of our data storage is moving to Hadoop. But we're still accessing it in SAS for many of our jobs, which also use data stored in SAS data sets and Teradata. It's still useful to have R/Python skills to be able to query Hadoop directly.
SAS is common in a few industries like banking, government, and pharma. Its really an enterprise tool so it's mostly used in big organizations. But even where SAS is prevalent, other tools like R and python are used as well, and this trend is definitely accelerating lately. SAS is a clunky language and its output and reports look pretty dated but it's fantastic for ETL type work on larger datasets. That said, there's still plenty of money to be made writing SAS code and will be for a while. Python and R are complementary tools and they're working towards interoperability for data science with things like the Apache Arrow project to provide a common data frame standard and libraries like reticulate which let you call functions from one in the other. Bottom line is the Python vs R debate is likely to just be "learn both and use whichever is best suited to your current task" sometime soon.
I did not watch video but now working in an org without an enterprise tool and a few hundred analysts querying via Excel I‚Äôm really seeing the need for a tool like SAS. I would love an alternative but haven‚Äôt seen one that seems as robust with the same suite of features. The amount of extra management R or Python at Enterprise take is astronomical. And RStudio costs for a server are in line with what SAS costs but not nearly the same level of features yet. The RStudio IDE is one of the best development environments I‚Äôve worked in, though R errors need a lot of work.
Do you have anything in mind that would be much easier or better to do in R instead of Python? Not trying to argue, just trying to learn. I'm pretty content with Python and haven't really considered learning R.
Sure! R generally has better statistical libraries so you'll find things like time series forecasting are better in R due to functions like auto.arima() and all the model evaluation methods readily available. Also the data.table package performs a bit better on big datasets than pandas which tends make a lot of copies and can crash if your dataset gets over 20GB or so. I really like both languages. They both do 90% of the data science workflow well, it's mostly edge cases where one outperforms the other by a significant margin. If your workflow is mostly in Python and your organization has good support for it then you're good to go! But time spent learning R is definitely not wasted so if you have time it's worth a look. Knowing both languages will make you a better analyst overall. Especially as they move towards a common data standard you'll find more integration of the languages for data science work.
I'd recommend trying to find a pattern with the names and code around that. Start wide and refine as you analyze the results. You can build some fairly good data step filtering after a few iterations using simple functions like prxmatch() or find() and index() variants.
I didn't not know Rstudio cost so much on an enterprise level.
Looks like they‚Äôve changed they‚Äôre pricing but used to be $1000/yr/seat. We have several hundred power users.
It use to be that way but they have a more enterprise approach now too. 120k a year for 100 pro seats with the enterprise suite. They are definitely stepping up the game. 1000 was the standard commercial user. I thought this was all that they had.
One server though - we have more than that.
You compare VAR1 with VAR2 and it returns the string distance between the two variables. From there you can either do a giant SQL Cartesian join to review every match between your two datasets and select the smallest distance for each record. Or a giant DO LOOP cycling each record to your matching list, returning the smallest match for you.
It is always good when you're doing this kind of exercise to acknowledge not just what kind of error rate you want to accept, but what kind of errors you'd rather have. So you're doing the right thing by stating that you'd rather miscode a person as a business than vice versa, and you can build your coding around that.
Note that Teradata volatile tables cannot be fastloaded - if the Excel file is large, the creation of the volatile table will take some time. The MUTLISTMT=YES will help a little since the inserts are buffered. Note the creation of the volatile table primary index using the dbcreate\_table\_opts dataset option ( choosing a well distributed PI is vital in Teradata, using join column(s) is a good idea if well distributed ) `libname td teradata user=abc pass="xyz" server=td_server connection=global dbmstemp=yes;` data td.vol_table ( multistmt=yes tpt=no dbcreate_table_opts='primary index ( key_col )' ); set sas_data_set_import_from_excel; run; proc sql; connect to teradata ( user=abc pass="xyz" server=td_server connection=global ); select * from connection to teradata ( select a.*, b.* from schema.table a, abc.vol_table b where a.key = b.key_col ); quit;
It creates versions of the same data set, usually for different time periods. You would age the existing data sets before adding a new one for the current day. Here is an example from a SAS Global Forum 2007 paper: AGE STATEMENT IN PROC DATASETS The AGE statement renames a group of related SAS members in a library. The code below will add day1 to the library and delete day7. PROC DATASETS LIBRARY=DAILY NOLIST; AGE TODAY DAY1-DAY7; QUIT; LOG LISTING NOTE: Deleting DAILY.DAY7 (memtype=DATA). NOTE: Ageing the name DAILY.DAY6 to DAILY.DAY7 (memtype=DATA). NOTE: Ageing the name DAILY.DAY5 to DAILY.DAY6 (memtype=DATA). NOTE: Ageing the name DAILY.DAY4 to DAILY.DAY5 (memtype=DATA). NOTE: Ageing the name DAILY.DAY3 to DAILY.DAY4 (memtype=DATA). NOTE: Ageing the name DAILY.DAY2 to DAILY.DAY3 (memtype=DATA). NOTE: Ageing the name DAILY.DAY1 to DAILY.DAY2 (memtype=DATA). NOTE: Ageing the name DAILY.TODAY to DAILY.DAY1 (memtype=DATA).
It‚Äôs big in banking. I‚Äôm a data analyst working in Risk, and it‚Äôs still heavily used in retail and treasury modelling, portfolio management, market risk, etc. There‚Äôs slow movement towards open source tools but... it‚Äôs slow. SAS has the advantage of being closed source, so companies have been building large infrastructures heavily dependent on SAS. It‚Äôs like taking a large vein out from your body and replacing it with a new one. I‚Äôd say it‚Äôs popular in corporate, though. Don‚Äôt let the tech market skew your perception of data analysis - yes, python and R are being used, but in my experience in the UK, they‚Äôre used at universities or at companies that won‚Äôt or can‚Äôt afford to buy SAS yet.
I have been using SAS for over 30 years in academia, government, and industry (management consulting and finance). The one thing that rings true to what you said is that about 95% of the code that I have ever written uses the exact same PROCs that you are using. There are occasional times that we need something from SAS/STAT or another package, but most of my time has been spent organizing, reshaping, and summarizing data rather than doing complicated statistics. It has been my experience as a consultant that firms tend to really know their most used PROCs well and feel strongly that their use is *what SAS Is for* while being a little blind about other applications. I am no different unfortunately.
I work in insurance and we use it to predict injury. We use it for some basic modelling, lots of people use R and Python, and we hope to combine that all once we get Viya! We have lots of one off models and a few more persistent ones.
I work in the Pharmaceutical industry in the CRO side. We do the CDISC and SDTM variable mapping, some more complicated data cleanliness checks (what I do), and our statistical analysis in SAS. Typically the checks that make it through to me can get pretty complicated for the systems that are in use so that take and while and for some studies need to be done over thousands of observations and hundreds of variables even. I have programs that were just checking data for blatant issues that are thousands of lines just checking that start dates are before end dates, that no visits occur before informed consent was signed, or that the subject returned the correct amount of administered drugs. I typically have a few programs to alternate through at a time and have the type I mentioned above and checks regarding external provider data files. I‚Äôll make macros to get those into sas if they weren‚Äôt sent as sas7bdat. I enjoy what I do as data cleanliness and data insights is actually one of my favorite parts of Stats and mathematics.
Academic research, I use SAS daily for data management and analysis and I've been doing that since 1998 or so!
Credit Risk Modeling at a bank. I honestly haven't seen much R in my dept, but have seen a lot of python for model development, some data viz in python and Tableau. Ultimately we use SAS the most. Our data is a mess and there is a need to productionalize not only the statistical model, but also the data integration. SAS is the preferred tool because it's a good data management tool in addition to having the statistical tools we need. I use macros, data steps, data transformation procs like transpose and expand, data summarization procs, proc sql, statistical procs, and some graphing. Most code sits in macro containers, loaded via %include statements, and are are called in succession in a driver script. I usually set up the code in SAS EG and then the production run occurs using python utilities calling together numerous parameters, other processes, the sas code via unix gridsubmit, and finishing up with several qc checks. The production process is setup by me referencing technical specs provided by our tech team. The execution is done using a web portal. One thing I just dislike about SAS is the data visualizations. Sgplot is fine, and I use it a lot, but my boss creates a lot of visualizations in python and they just blow my stuff out of the water. Wrestling with the graphical output in SAS gets old. At this point, I use SAS graphing more for documentation and internal review rather than for external presentations. I've actually never seen a demo on viya, but I've heard about it. I wonder if that would improve my work with SAS. A lot of my job isn't just writing code, it's reviewing data quality, working with tech partners to get more/better data, documenting code changes, and structuring the series of code so that it runs quickly and is compatible with the execution environment. However a lot of my job is navigating the bank's bloated project management structure and bureaucracy. I like what I do but I'm still struggling to figure out what I want to do in the next phase of my career. I've been looking for something that isn't quite so driven by regulatory requirements and doesn't have such oppressive regulatory/audit scrutiny.
It's big in healthcare data analysis. That's what I've been doing for my entire career, and what I'll likely do for the rest of it. Technically I'm managing a team of analysts at this point, but I still spend a fair amount of time coding/analyzing. SAS is a huge product. The data step is, in my opinion, the fundamental aspect of SAS which sets it apart from other programming languages and data manipulation tools. SAS can do advanced statistical calculations, but so can other tools. SAS can make graphs and visualize data, but so can other tools. In both of these use cases, SAS is either on par with other tools (statistical analysis) or sub-par (graphing/visualization) . I wouldn't expect modern users of SAS to use more than a fraction of what it's capable. of. Most people don't use SAS on a mainframe any more. There are vestigial PROCs and artifacts in the logic that apply to outdated modes for using the language.
I worked at big and small banks, I've mostly worked in Credit Risk with a few years of Strategy sprinkled in there. Strategy was mostly using SQL. Credit Risk was more modeling defaults on different retail products. People are talking a lot about Python here, but senior management prefers to stay with SAS at this point.
Primarily Base SAS, ODS, Macro, SQL for a finance company. Dealing with large data (Oracle), efficiency and optimisation of code, self-serve reporting (using ODS HTML and a webserver), web apps (PHP/SQL Server) with connections through to SAS &amp; Oracle, process automation. &amp;#x200B; Other functions use it for modelling, statistical analysis, reporting as you'd expect.
Need more info. What's the business question? What type of analysis are you expected to do? What is your experience with healthcare claims in general? If you are new to SAS, what types of analytical work have you done in other apps?
Fraud Detection, Marketing Optimization, Credit Modeling
I'm an epidemiologist at a large teaching hospital. I use SAS to analyse patient data and hospital performance metrics. I assist doctors with their research and use SAS to analyze their trial results. I'm getting comfortable with SAS Visual Analytics to present our data in more palatable forms. Didn't think I'd like this kind of work (used to do epidemiologic field investigations), but I really enjoy my job.
 Not sure about the business question yet. It don't know the details of the project yet. Also, I am not sure about the type of analysis yet. I have done a survival analysis before in R with SEER data. The work would be for a Health Policy Institute.
I've been doing architecture for the SEER data for the last few months. Department is about to finish up so we can actually start getting insights from it. We ended up building an entire dimensional model to query the data as a lot of our questions are going to need to have a lot of prep work before the analyses will even be done. First thing I recommend is making sure you understand the various levels of grain in the data itself. It is not immediately obvious based on what they give you what a column applies to. For example, in the outpatient table, you have patient_id, link_num, daily_dt, from_dt, seg_num, and rec_count as the primary key of the table. But *some* columns are dependent on only patient_id, link_num, daily_dt, and from_dt. We found that separating those tables into claims, segments, and lines was the best approach. Good luck with the data, feel free to DM me if you have any questions about the data itself, particularly once you start to ask the questions.
Classic
Read the description
You might as well forget it, they only want people who will pay attention to details, and you are not one of those people. Look at the side bar about this SAS group and you will quickly realize that you would die of dysentery from eating the wrong bug in the Congoian jungle on your first mission.
This group is for discussing Scandinavian Airlines.
Best post ever In order to join the SAS, you‚Äôll need to first be a cook in the British army for 15 years. After that, you MIGHT get an invitation from Hogwarts School of Witchcraft and Wizardry. If you do not get an invitation, your only option is...you guessed it...to be a RESERVE
Take the SAS free e courses. SAS has been used in the medical field since 1970s and health care is one of the biggest uses. You can find many books and user written papers on lexjansen.com which will cover almost all of what you‚Äôll likely be doing.
Not necessarily. SAS offers some things no current other analytics systems offer. 1. Enterprise level control with full lockdown abilities. For banks and health care with regulatory requirements this is huge. 2. Tools for all skill levels - they have GUI based tools for business users and super users can program in R/Python or SAS if they want 3. Pricing is competitive at the enterprise level - compared to RStudio which was $1000/seat/user. RStudio has changed their pricing model very recently 3. Subject specific tools - they‚Äôve taken their base tools and built a lot of custom tools to help people solve problems. For a startup, SAS is not the way to go. For someone who has several hundred analysts and must be locked down, I‚Äôm wishing we had SAS. PS. If you know of other tools that do all of this, please comment. I‚Äôm actively looking for a new Enterprise tool for our org and I‚Äôm finding it very hard to find ones that meet these basic requirements. Coding is great and I hate GUI tools, but they‚Äôre not going away any time soon.
This is the SAS programming language not the military.
We separated ours into claims, details, and diagnosis info. One to many, one to many.
The structure of the claims might vary depending on the source but a good source of information are the videos you can find at https://www.resdac.org/workshops/intro-medicare. Check out the rest of the resdac website as well. This [book](https://www.amazon.com/SAS-Programming-Medicare-Administrative-Data-ebook/dp/B00QMSGRJM/ref=sr_1_fkmr0_1?keywords=medicare+data+analysis+in+sas&amp;qid=1559266945&amp;s=gateway&amp;sr=8-1-fkmr0) is pretty good but might not match your claims exactly if you work with a contractor as opposed to a research organization. There are lots of nuances using Medicare claims data that you will have to learn. Hopefully you have someone with experience to guide you. The learning curve is rather steep but not insurmountable. If you come across specific questions please post them here.
I work in healthcare and what you describe is about 90% of what I use with the addition of hash tables. I also make heavy use of sgplot, which is very good. I originally used R and learned ggplot2 as it was developed but sgplot works just as well for me. Also I use glimmix less commonly and found it very flexible.
do you conduct data mining on SEER data ? It will be great to share some experience.
You‚Äôre going to love Viya!
That‚Äôs interesting. The org I‚Äôm working for is trying to move away from SAS because they‚Äôre trying to emulate the big tech firms as much as possible. Nobody‚Äôs thought about whether Google‚Äôs data problems are the same as ours, but who cares - it‚Äôs happening anyway. Our production code which used to be scheduled using SAS DI and SAS management console is now scheduled through a series of batch scripts. The requirement for good metadata has reduced so much that the production team simply write everything out in a single .sas file. I agree that lineage and the other tools that SAS provide are useful, but from what I‚Äôve seen it doesn‚Äôt seem to be enough to keep business. I do agree that SAS is the best tool for enterprise level analysis though - pretty sure my current org has no idea what they‚Äôre getting into when trying to move over to python. Couldn‚Äôt you offer similar functionality using python and team city? You don‚Äôt get fancy GUI like in DI Studio but you get a scheduling mechanism at least.
I'm looking at your comment history... you might feel over your head, but thats kind of normal with anyone using SAS. Organizing your old tasks so that you can find code in them is super important. A friend of mine who has a finance degree was kind of just tossed SAS and absolutely could not cut the mustard. She is a smart cookie, literally top of her class but I don't think she knew enough SAS to ask google the right things. My first real SAS job would be difficult for me now, after I have multiple SAS certifications, because of how the data was warehoused (which I did not realize at the time). SAS books are great for outputs, almost everything else can be done with proc SQL. The structure of files you have really dictate everything. If the enrollment file is monthly, you can count distinct year-months per member and figure out how long someone has been enrolled for. If its a FROM-TO format, I wouldnt simply INTCK because the person might exist in 2 lines with some overlap for some unholy reason. Don't believe in your code and QA everything, don't check if its true, check if the any impossible combinations are there, and flat out open the data vs creating a query to see it.
SAS has scheduling mechanisms, unfortunately most orgs lock it down. Can you get similar functionality elsewhere, yes, but with significantly more overhead, manual work and management required. Those tech companies are having trouble scaling for this reason and end with thousands of more analysts than needed. If you can burn cash it‚Äôs great and Google, Amazon and Netflix have money to burn. To be fair thought they‚Äôre dealing with real-time business and most orgs don‚Äôt. If you‚Äôre real-time I don‚Äôt think SAS has quite the same allure at all.
I dunno y'all...those special forces guys really kick ass at survival analysis. Nobody makes Kaplan-Meier figures like the British Special Air Service. But for a quick and dirty chi-square you cannot beat the Legionnaires of the L√©gion √©trang√®re. And then there is the famous Kolmogorov unit of the Spetsnaz in Russia.
I‚Äôm interested and will message you once I send you my resume. Thanks for posting this.
Viya is awesome!!
Good idea to post here! Our gov .org would not allow this but I like the approach! Good luck!!
Are you using 9.4 or Studio?
Thanks! You couldn't even refer someone from your network for an open position? Bummer!
I'm on SAS 9.4, we also have linux SAS for batch processing as well.
Anything remote or is it all on site?
Sorry, it is all onsite at our office.
Actually, I guess I could do that, basically post a link to the official job position. I just couldn‚Äôt receive people contacts via Reddit.
Classify it as category, what version are you on?
I have used aggregate cell function. But for cross tab it's coming as measure. Not at the start
Version 8.3.1
Ok think I miss understood. Do you mean like a row number?
Ok think I miss understood. Do you mean like a row number?
Yes right
I got a nice row number with this. At first the I had a 1 with a missing category, but when I uncheck the include missing in the filter options it worked fine. AggregateCells(\_Sum\_, 1, default, CellIndex(start, 0), CellIndex( current, 0))
But this comes under 'Measure' and Measure always comes at the end of Cross tab. If I'm using List tab then this option is valid but not for Cross tab
Depending on a couple of different factors, you might be able to bring the data back into SAS to do the join. Usually it is more efficient to do as much processing on the Teradata side as possible, but occasionally it is a better/easier solution to bring data back to SAS and work on it there.
SAS only allows conditional program flow control in macros and data steps. Depending on how complicated what you're trying to do is, you'll almost definitely want to just use a macro.
You could use a data step to create the data set (with one or zero observations) and then delete the data set in a subsequent step if it has zero observations.
You could just omit the else statement. I am not sure what the end goal here is.
Okay. I was hoping i could avoid macro since im not strong at it. Well. Time for learning. (Its not complicated at all)
I see what you mean. But im not sure if it will work. I Will never get zero obs. I Will performe A+B and it should = 0.
It is a check. If A+B=0 then all is good and SAS can take a break till Tomorrow. But if it is not =0 i want to make a datastep and print out where the error could be.
If Budget and Cost are not guaranteed to be integers I would suggest not doing a = comparison. Do something like ABS(Budget+Cost)&lt;(some small insignificant number). If you do not know why not, then be VERY careful in coding anything until you realize why you should never do equality conditions with floating numbers.
Oh I see, well then you do want a macro.
Just output to the data set conditionally. If a+b=0 then delete; else output; Am I missing something?
Reason #6567 why SAS VA is not yet ready for serious work
I'd recommend you look at macros. Wouldn't be difficult to build a macrovar that you can run a macro against. Sing out if you want a coding example
This looks to be the right way to go, but he says he wants to run code if else. So else do; [whatever]; end; run;
If you only have 1 obs then what do you mean "where the data may be".
Nope, not true any more. You can use %if/%then in open code as of 9.4M5 I think.
Put the other code in a different program, called myProgram.sas and use call execute with a %include statement. You‚Äôll need to figure out the quotes but the idea is sketched below. Data want; Set have; If sum(a,b) &gt; 1000 then call execute(‚Äò%include(‚Äú‚Äùpath to sas file.sas‚Äù‚Äù)‚Äô); Run;
That is a *major* improvement in the language. I'm surprised it wasn't more widely announced. You're right, though, my answer is outdated.
This is the non-macro answer here. Thing is, even if he WAS able to do proc print within an if-then statement, it'd "proc print" once for every error, not a single proc print output with all errors. The most logical method is to output to a dataset, then proc print the dataset once.
You're going to want to output errors into a new dataset then run proc print once. Even if you could if-then proc print statements, your logic will create a proc print output for every single data point. 100 errors would equal 100 separate proc print outputs. The code below would proc print 100 errors into a single report: data error_report; set have; if A+B NE 0 then output error_report; run; proc print data=error_report: run;
yes that's what i was trying to say as well--proc print at the end (not in the data step).
I was under the impression they would be offering both as options, the traditional multiple choice and the new practical version.
Thank you for your response. For an entry-level data analytics position, which version do you think would be more attractive to employers
Sorry for the late reply. I will try and look into this. Based on all of your answers i think i have something that will do the job. To clarify i want to do a daily check on some numbers that should equel 0 and if its not 0 that means something is wrong. If something is wrong i want SAS to get some data and print it. If i do "if a+b=0 then delete; and then a macro that only proceed if the dataset has observations. That i think would work. Again thanks.
To clarify i want to do a daily check on some numbers that should equel 0 and if its not 0 that means something is wrong. If something is wrong i want SAS to get some data and print it. Does it makes sense now?
Budget and cost will always be numbers and i use a format-step before comparison. But it sounds like i need to read on this topic. Thanks for the advise.
They won't care at all. Not even a little bit.
I think i got a solution. But i will be happy to be shown some code example. Maybe i could learn something :-).
Do i need to do a include step? Could i just "call execute(proc sql; select * from abc;quit;)?
Yes they will. The newer version is better. The old version is all multiple choice. In the new one you have to write programs.
The old version will be gone by the end of June and you‚Äôll only be able to take the new one after.
I manage and hire SAS devs for a fortune 5 healthcare company. I work alongside several other managers that do the same for various parts of the business. The very slight difference in exam quality here will not move the needle compared to various other factors. They both tell me that you can program in SAS. That is one of like a hundred things I need to know. The fact that one may tell me that very slightly more than another doesn't matter.
I don‚Äôt think so, but there are other ways. However given how you explained the problem that seems like the simplest solution. If you explain your problem in more detail perhaps I can offer other options. Specifically, where does your data some from, a data set or macro variables and what type of code are you trying to conditionally execute n
And I manage an Analytics team at a very large health insurance company. The old multiple choice exam has too many questions and answers on the internet and doesn‚Äôt hold much value for me. I‚Äôve had people pass both with flying colours yet not know when to run a Proc freq. The newer exam will help with that. Either way, I have them do a take home test as part of the hiring process. That method hasn‚Äôt failed me so far for hiring any programmers. It‚Äôs usually a relational data set so they have to do some basic joins and then do some basic summaries, like top ten beers based on survey data. And it‚Äôs over a million rows so they can‚Äôt do it in Excel. I look at the code for style, completeness and what level their programming is at. And if they comment their code, that‚Äôll get someone tossed most likely.
We aren't allowed to do anything like that take home exam you mentioned (I also manage a team of SAS and data analysts for a healthcare company). Going back to the original question: in my opinion, as someone who was once SAS certified, the base SAS exam is not really a factor. When I'm hiring for an entry level position, I expect the person not to know SAS and need to learn. When I'm hiring for a more senior level, I expect the person to have knowledge of SAS. Having passed the exam is superfluous - your experience and skills should shine through and illustrate that you have the knowledge to pass the exam if you took it. I can count the number of times SAS certification has mattered on an application in my history of reviewing resumes on one hand.
Why can‚Äôt you give candidates a take home exam? The data I always use is public open source data and has no relation to the actual job. And it‚Äôs not work that can used for the company so perfectly legal.
I took the beta in December. It was 2x the length of the production exam. I would take the new one as a personal challenge, but entry level work either is going to be fine.
I‚Äôm a SAS dev and this is extremely interesting. What style do you prefer? Data step or proc sql? I‚Äôve always found proc sql tends to be easier with merges and summary functions...etc
Legal has told us that it opens doors to discrimination issues. I don't know, I'm not a lawyer. I've taken SAS tests for jobs before, but my current employer won't let us give one. \*shrug\*
I don‚Äôt care about that :) Either works.
I'd go with Proc Report; [https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/259-30.pdf](https://support.sas.com/resources/papers/proceedings/proceedings/sugi30/259-30.pdf) given that you want to run this report on a frequent basis with data that is updated and identical each time. If this is for a paper then the best Sas Proc to this in is Excel or R Markdown possibly.
there is not really an easy way is the right answer. for the () you can do a format, but to get the standard error youll need to produce it in another table and output it, then i'd just toss it all back together ina SQL step and color it in excel. Why excel and not a SAS template? This nice looking graphic requirement might change depending on the journal you are submitting it to, so its not worth the time. You also might want to make the ## (#) into a text of one cell to avoid excel turning () into negatives, which is hell.
I didn't realize this, thanks for correcting me.
It's best to use the right tool for the job. For example, if you want to create a Cartesian product, use proc sql. If you want to output to multiple data sets, use a data step. I want applicants to be familiar with both.
I have hired quite a few SAS contractors in the past year and a half. I like the idea of the test, but I've done pretty well just by asking basic SAS questions verbally. They are mostly open-ended questions about efficiencies, a few procs, and data step programming. If someone has programmed extensively, they'll be able to answer them easily. If not, they're pretty much always stumped, and it's obvious that they haven't actually programmed.
https://go.documentation.sas.com/?docsetId=casml&amp;docsetTarget=casml_forest_details14.htm&amp;docsetVersion=8.3&amp;locale=en
As soon as you start saying separate data into multiple data sets I start getting twitchy. Almost never a reason to do that....pet peeve :p
There are lots of reasons to do it. Maybe I only want to keep a few variables in that data set so I can do some validation on it. Maybe I want to create multiple data sets for different purposes, which each have different variable sets or different populations. During the years when I executed marketing programs, this came in handy frequently.
I did the base 9 last year, and was looking to do the advanced this year. Anyone know if I will have to do the 'delta' exam to upgrade my base 9 to base 9.4 before I can do the advanced 9.4 cert? I was thinking of doing it anyway, but it would be good to know what the requirements are.
Thank you. I couldn't see this tree for the forest (it's buried in the methods for which one has a target). Unfortunately, I don't have SAS Viya, only EG.
Why not just practice programming in SAS to prepare for the exam? That's what the exam is trying to test in the first place. That way, you'll actually know the material and be prepared when you get a programming job.
yep yep... Before june is over, i have the option to do either-or right?
It sounds that way based on a recent post. So are you going to choose the one that lets you demonstrate your programming expertise?
I'm going to choose the one that i've been studying the best for.
The older version of the base programmer exam is still valid and the credential doesn't expire, you just can't take it after June 30th. So you don't have to take the delta exam to sit for the advanced exam, it's just if you want to have the newer credential. [https://www.sas.com/en\_us/certification/resources/base-programming-specialist-faqs.html](https://www.sas.com/en_us/certification/resources/base-programming-specialist-faqs.html)
Both versions of the base exam cover SAS Programming 1 and SAS Programming 2 content, it's just the format that is different. The e-learnings are a good way to prepare, and have exercises that you can practice with. There are also practice exams you can take through Pearson VUE: [https://www.sas.com/en\_us/certification/resources/sas-practice-exams.html](https://www.sas.com/en_us/certification/resources/sas-practice-exams.html)
Just take working SAS code...have someone randomly add or take away a few ;s If you can perfectly describe what will happen if you were to attempt to run the modified code, you will be ready for the SAS Base Exam. No kidding, that is pretty much what the exam is like.
The material at analytics exam is often wrong or out of date. I would recommend SASsensei and the certification prep guide and of course, practice. A good method to practice is try answering basic questions here or on communities.sas.com
thanks, i'll look into it
I bought the book. I am preparing for the base and the advanced and both seem adequate
What are the pros and cons of analytics exam and sas sensei
Thanks, that was exactly what I wanted to know. :)
Sorry for the late reply. My data come from a simple datastep. Proc sql; CREATE TABLE total AS SELECT distinct(sum(a.saldo) as budget format commax12.2, b.saldo as cost format commax12.2 FROM table1 a, table2,b WHERE some conditions ;quit; And now i got all my data. I just need to see if Cost+budget=0 and if it is not i need to run a few more datasteps. Does it make sense?
Use two dataset names in the data step: data meet\_criteria have2; set have; if career\_field in ("job a","job b","job c") then output meet\_criteria; else output have2; run;
This makes the most sense. When you have essentially unlimited work. tables deleting rows seems dangerous
That's been how I usually approach this, but I'm running into instances where a subsequent if/then statement might also apply to a job already output into "meet_criteria." So for example, I want to output jobs a, b, and c regardless of location. Then I want to output all jobs based in Atlanta (that are not jobs a, b, c). There are instances of jobs a, b, and c being in Atlanta, and I want to avoid outputting those observations into the new data set twice. Thinking about it, would multiple else-if statements address this? data meet_criteria fail_criteria; set have; if career_field in ("job a","job b","job c") then output meet_criteria; else if location = ""Atlanta" then output meet_criteria; else output fail criteria; run; Does the above code prevent jobs a, b, c who also happen to be in Atlanta from being output a second time due to the else-if statement?
It should work. I don't see no logical issues
You need something like this data have meet; if (conditions for have) then do: output have; end; if (conditions for meet) then do; output meet; end; run;
If anyone reads this and need help. https://www.pharmasug.org/proceedings/2014/CC/PharmaSUG-2014-CC50.pdf This helped me alot. :-).
For taking the Base Exams, absolutely your best resource is the SAS Certification Prep Guide (book). This will cover the entire syllabus, as well as give you a thorough grounding in key principles. Presuming you are studying outside of your main job, expect this to take around 1-3 months of study. &amp;#x200B; Sasensei is a question based learning system that will open your eyes to tools, tips and techniques that are well outside the core SAS curriculums. It is a 'real world' resource, for which an existing understanding of the core principles of SAS will be helpful. &amp;#x200B; That said there are many Beginner questions on Sasensei. Also, every question comes with an explanation, so you can learn something whether you answer right or wrong. &amp;#x200B; Submitting questions on Sasensei is also a great way to learn! Writing high quality, well explained questions involves a bit of research and proper understanding of the topic in hand. &amp;#x200B; If you are new to Sasensei, join up with this link for a 4 token bonus: &amp;#x200B; https://sasensei.com?code=39b1c086
what is 'analytics exam'?
Yes, the "else if" will only trigger for a given observation if the previous "if" does not. You could use an "or" condition to achieve the same effect: &amp;#x200B; if career\_field in ("job a","job b","job c") or location = "Atlanta" then output meet\_criteria;
Get rid of do, put output there use proc sql statement to cleanse the dataset afterward...
Then I think the approach I outlined above is exactly correct.
Why are you separating these in the first place?
Thanks for your response. &amp;#x200B; By any chance do you know if the advanced analytics SAS programmer certification test will be switched to the new format? Or will it still be multiple choice? Do you know what the timeline for when it's going to change is?
i meant [examanalytics.com](https://examanalytics.com)
Okay. Thank you for your time and help:-)
I'm afraid I don't know about that.
It looks like you have worked out your own question. I'm wondering if you also still wanted to delete from the original dataset? I'd guess that it would simply be using the 'have' dataset name instead of making a 'fail_criteria' dataset in your code. *data meet_criteria* **have** *; set have; if career_field in ("job a","job b","job c") then output meet_criteria; else if location = ""Atlanta" then output meet_criteria; else output* **have;** *run;*
The programming 1 and programming 2 content was updated not that long ago, and I think it was at different times in different parts of the world. From looking at the SAS website I think that the base 9 exam is based on the older curriculum, and the base 9.4 is based on the newer one. I guess it would pay to confirm this if you are looking at doing one or the other.
I agree, that is a great improvement, and I am likewise surprised it wasn't announced more widely. I told a few of my fellow coders at work, and they were all in agreement that: a) it was very cool b) it's a damn shame we are still stuck on M2.
1) Kinda but that‚Äôs really oversimplifying the idea of it. Hadoop is distributing data across a cluster but the relationships between all of your nodes and how MapReduce works is really complex. In my experience, working with Hadoop means you‚Äôll be using HDFS to store your data and depending on your Hadoop environment, you may use other tools like Hive, Impala, Spark, etc to analyze the data. 2) This is a big challenge with people starting out in Hadoop. There are some Udemy courses that make a solid attempt at teaching the skills needed, but setting up a Hadoop environment for learning is very involved. There are a lot of components to a Hadoop environment, so I‚Äôd narrow it down to 2 or 3 things that what you want to learn then go from there. If you‚Äôre really serious about learning Hadoop, there are some pretty good books on subjects like Hadoop, Hive, Sqoop, Oozie, and Spark
Awesome! Thanks for the detailed response brotha/sista! I think I might take a look at the Udemy course first. I feel like they do a decent job of ELI5-ing complex stuff. Then ill decide if I want to go any further into it.
SAS has a parallel processing solution they call their SPD engine so if you're already in a SAS environment you might have access to this already. Here's the link: https://support.sas.com/documentation/cdl/en/engspde/61887/HTML/default/viewer.htm#a002562355.htm In my experience working with SAS, they've got a lot of sophisticated data tools available but they all cost extra.
Oh cool, I‚Äôll definitely check if I have access to that too! Thanks for the heads up
Sure thing. Another thing to consider is adding some smart indexes to your datasets. SAS is pretty good at handling medium to large data on its own. Managing your data more efficiently within the regular SAS ecosystem and maybe adding some additional memory to your server will likely hold you over until your data gets past the 100 million records threshold. And even then you might not have to scan your entire dataset every time if you can partition your data and pre-process it in chunks.
Check out Sas grid manager for parallel processing across multiple hosts. Or go to viya and use CAS.
Somewhat related.. Has anyone heard of connecting SAS to a preexisting hadoop environment?
So thats product family is the older version. its called SAS EBI. the paid training is located here http://support.sas.com/training/us/paths/bi.html a good book to buy used would be this one https://www.amazon.com/Building-Business-Intelligence-Using-SAS/dp/1607649888 In general: use EG to do all major development, Create SAS Tables. Derive variables. Use Information maps to connect tables. Use WRS to create and show reports.
Thank you so much
Thank you so much
I'm not clear on what you're trying to do, but at a minimum you may want to remove the "=" from %put &amp;=sessnum; Try using %put \&amp;sessnum; instead.
Hi not clear on what you're trying to do, but at a minimum you may want to remove the "=" from %put &amp;=sessnum; try using %put \&amp;sessnum; instead., I'm dad.
Thanks for your reply. The = in there makes it show up in the log as "SESSNUM= 4" instead of just "4". I am sorry if my example code was unclear, I narrowed it down as much as I could to illustrate the problem, without overloading with irrelevant details. In my actual problem, "session" is but one of several columns in the dataset and I want to call a macro for each first occurrence of a session value, and passing that value to that macro. The macro is then supposed to create a new session using the session number as part of the name. That macro then fails with messages of "SESSSESSNUM" being an invalid name for a SAS session, when I actually want the macro to use "SESS" !! session, so for example SESS1 or SESS4 as a name. But I am already puzzled why the code in this example is not just assigning the values 1, 2, 3, and 4 to the variable SESSNUM as I'd like it to.
You need to leave the data step before the value is assigned, either through an explicit or implicit (start another data step or proc) run statement. &amp;#x200B; 42 data input; 43 input session; 44 datalines; &amp;#x200B; NOTE: Compression was disabled for data set WORK.INPUT because compression overhead would increase the size of the data set. NOTE: The data set WORK.INPUT has 5 observations and 1 variables. NOTE: DATA statement used (Total process time): real time 0.00 seconds user cpu time 0.01 seconds system cpu time 0.00 seconds memory 406.37k OS Memory 43316.00k Timestamp 06/11/2019 11:28:19 AM Step Count 1982 Switch Count 2 Page Faults 0 2 The SAS System Friday, June 7, 2019 03:56:00 PM &amp;#x200B; Page Reclaims 60 Page Swaps 0 Voluntary Context Switches 41 Involuntary Context Switches 0 Block Input Operations 0 Block Output Operations 136 50 ; &amp;#x200B; 51 run; 52 53 data output; 54 set input; 55 by session; 56 57 if first.session then do; 58 call symput('sessnum', session); 59 /\* %put &amp;=sessnum;\*/ 60 end; 61 run; &amp;#x200B; NOTE: Numeric values have been converted to character values at the places given by: (Line):(Column). 58:26 NOTE: Compression was disabled for data set WORK.OUTPUT because compression overhead would increase the size of the data set. NOTE: There were 5 observations read from the data set WORK.INPUT. NOTE: The data set WORK.OUTPUT has 5 observations and 1 variables. NOTE: DATA statement used (Total process time): real time 0.00 seconds user cpu time 0.00 seconds system cpu time 0.00 seconds memory 647.65k OS Memory 43316.00k Timestamp 06/11/2019 11:28:19 AM Step Count 1983 Switch Count 2 Page Faults 0 Page Reclaims 49 Page Swaps 0 Voluntary Context Switches 14 Involuntary Context Switches 0 Block Input Operations 0 Block Output Operations 136 &amp;#x200B; 62 63 %put &amp;=sessnum; SESSNUM= 4 64 65 data output; 66 set input; 67 by session; 68 69 if first.session then do; 70 call symput('sessnum', session); 71 /\* %put &amp;=sessnum;\*/ 72 end; 73 run; &amp;#x200B; NOTE: Numeric values have been converted to character values at the places given by: (Line):(Column). 3 The SAS System Friday, June 7, 2019 03:56:00 PM &amp;#x200B; 70:26 NOTE: Compression was disabled for data set WORK.OUTPUT because compression overhead would increase the size of the data set. NOTE: There were 5 observations read from the data set WORK.INPUT. NOTE: The data set WORK.OUTPUT has 5 observations and 1 variables. NOTE: DATA statement used (Total process time): real time 0.00 seconds user cpu time 0.01 seconds system cpu time 0.00 seconds memory 646.03k OS Memory 43316.00k Timestamp 06/11/2019 11:28:19 AM Step Count 1984 Switch Count 2 Page Faults 0 Page Reclaims 18 Page Swaps 0 Voluntary Context Switches 15 Involuntary Context Switches 0 Block Input Operations 0 Block Output Operations 136 &amp;#x200B; 74 %put &amp;=sessnum; SESSNUM= 4
Thanks Grandpa! Having to do it outside of the datastep is the piece I was missing!
try proc transreg maybe. if i understand what you want
if you want it to print 1,2,3,4 youll need to change your if to if first.sessnum then do; if "&amp;sessnum" ne "" then do; call symputx('sessnum',catx(',',"&amp;sessnum",sessnum); end; else do; call symputx('sessnum',sessnum); end; end;
in your example it is assigning 1 2 3 4 to sessnum, it's just over writing each number it's time so it assigns 1, then it overwrite 1 with 2, then it overwrites 2 with 3 Etc...
If you want to use a macro variable in the same data step you create it, you need to use SYMGET to get the value and be able to use it. Or use it outside of that data step. You used to not be able to use it in the same step and then that changed.
You don‚Äôt have SAS VA? That‚Äôs a lot more like Tableau. I‚Äôm surprised companies are still on WRS. I would ask your IT area what tools are available.
Proc univariate with the Pareto option on the cdfplot statement. The documentation has an example, second last one I think.
Have you tried: 1) Adding the server in ODBC as a user DSN 2) use the following libname structure in SAS: LIBNAME mydata ODBC noprompt = "[server=myseverpath.myhost.com](https://server=bbdbhr-prd.wesleyan.edu); DRIVER=SQL Server;Trusted Connection=yes"; The PROC SQL: &amp;#x200B; PROC SQL; CREATE TABLE mydata AS SELECT \* FROM mydata.sql\_server\_table\_name; &amp;#x200B; Good luck.
My guess is that you are connecting to a metadata server and running EG on a compute server (Typically SASApp) in that case you need to contact your SAS Administrator to modify the odbc.ini file on the compute tier.
yes. SAS Access to Hadoop and SAS Access to Hive both exist as products. In addition some versions of Visual Analytics shipped with hadoop or even older versions required a hadoop presence. The real question is what are you trying to do? read individual files on hadoop, that's easy, it's when you want to productionalize a process that uses hadoop data that it gets more complicated
What‚Äôs the specific error message? Is the SAS server windows or linux? Do you license SAS/ACCESS to SQL or just access to ODBC? You probably just need the DSN added.
Is this with a CRO or a pharmaceutical company directly?
Just edited my post, it is with a CRO.
I‚Äôd bet on this being the issue as well.
Then you‚Äôre likely working long hours, boring work, with no guarantees or job certainty. Obviously varies by company but in general, CROs are great for learning quickly but not a good long term role for most people. Some people do want those types of jobs though so it‚Äôs a very personal decision.
Thank you for your honesty, fortunately I am okay with that because I am looking for an opportunity where I can learn a lot quickly and get my foot in industry. I know this will very by company, but from your experience are CROs willing to train individuals who have SAS experience but who are new to the clinical aspect? I assumed there were a ton of SAS programmers with industry experience who were applying for these jobs, so I was a little surprised to get an interview honestly. I'm confident in my programming abilities but I thought the lack of industry experience would disqualify me.
You're going to want to read up on CDISC, SDTM, and ADAM. They'll probably have you spending all your time doing work on those, and on tables figures and listings
Thank you so much!
Do you mean the default mouse-over text, that is showing in your screen capture? ... I think you can probably get rid of it by specifying des='' after the /. (Alternatively, you might get rid of it by using "goptions noaltdesc;")
So the end goal is to use SAS to analyze data that is stored within Hive/HDFS. I don‚Äôt think we‚Äôd want to read individual files cause we need to analyze the data set as a whole. Does that help clarify?
Depends on what they‚Äôre paying and many factors. It can be hard to find anyone with SAS experience and someone with junior skills may be harder to find. Not all companies train or have training programs so ask about that at the interview - how they do staff development? How do they prioritize it? Dedicated time or up to you? Do they have a formal mentor ship program or will you have to learn on your own. But hiring a junior programmer is cheaper so they may be a company that can‚Äôt afford more expertise.
I have been in a Clinical SAS programmer for 8 years in multiple CROs. You are probably going to want to have a general idea of what CDISC, ADaM, and SDTM are. But I would just be honest with the company and try and use your research experience to your advantage. Like doing research means you have to be quick on your feet and be a fast learner. Those are skills they can't teach, standards can be learned on the job. Also play up you stats and figure experience. Those two skills are not as common and CRO companies are always looking for people who can them. Good luck!!!
I've worked in CROs pretty much my entire adult life. Something like 8 years solely programming. If they only want 2 years SAS experience, I doubt they expect very much. You sound like you'll be fine. Focus on your strengths, be willing to admit your weaknesses. You could read up on SDTM and what not but I think it would be totally ok to admit you do not know much about them if you don't. Their expectations cannot be that high if they're requesting 2 years general SAS experience. Also, if it seems toxic, it's probably toxic. CROs get a bad rap, somewhat rightfully so. Some of them are ran really poorly. If it's a small CRO particularly, take any red flag as a siren.
I have done a bunch of these phone screens for CROs over the years, here is my take... They should know from your resume that you do not have industry experience, so don't try to fake a bunch of knowledge. That being said it would be good to demonstrate that you have done enough research to know the basics of clinical trials and that you know what CDISC standards are in the general sense (i.e.- you know why SDTM and ADaM exist, even if you don't know the details of the standards). What is really more important is demonstrating a basic competence in SAS and the ability to learn more programming skills. Most programming work in a CRO really does not require much stats knowledge. Most of the programming work is about structuring the data and presenting results. Sure, mention and advanced statistics work you have done, but keep it brief. Even when doing stat tables for the clinical study report (CSR) 95% of the statistics will just be frequencies and univariate results. If I were interviewing someone for a junior programmer position I would look for a solid understanding in these areas: how a data step works (if you don't know what the PDV is, look it up), proc report, and proc import (particularly importing in excel files). Emphasize any past experience that you have that highlights these areas. A caveat to everything above: is if you have a fair amount of experience programming figures/graphs definitely mention it. Most CROs only have a handful of people on staff that are really good at these, so that could be a selling point.
&gt;The position is not remote if that makes any difference, as there appear to be more remote positions hiring currently. I am hopeful there will be more opportunities for training because I would be going to an office, and that is partially the reason they only require two years of experience. Being in-house as a junior programmer is a good thing. Hopefully, this will provide opportunities for more experienced programmers to mentor and teach you. That being said, don't be surprised if the most experienced programmers in a CRO are remote. So, if you really want to learn from them you will have to figure out a way to do that over e-mail/IM/phone. The culture in this area can vary quite a bit from company to company. Honestly, I would actually be wary of any job for a junior programmer that was remote. I have been remote for a long time, but I cannot imagine how hard it would have been to learn the industry culture if I have been remote in the beginning.
For multiple survey years, you just calculate a new weight variable divided on how many cycles of data you are stacking. Refer to the analytic manual for the specific calculation under "Combining Cycles". For multivariate statistics, usually try turning your analysis into a regression, so potentially an option under PROC SURVEYLOGISTIC will get you close to what you need. Maybe LSMEANS?
Thanks for your insight. I've got all of the code for my weighted and adjusted logistic reg. setup and I've run it so I have all the odds ratios I could want but my supervisor is pushing me to find a way to calculate prevalence ratios instead as odds ratios. I'll have to look into using LSMEANS with a SURVEYLOGISTIC and see what it gives me.
I did 1, but it didn't help. I did 2, and got the libname to work but the length of the table name is apparently too long. At least it is a step in the right direction. Now I just need to find a way to solve this new problem. :)
I have to be honest here and say that I have no idea what your answer means. Can you tell me how this would manifest, error-wise?
 I feel I am making progress but my understanding of the actual connection process is on the level of "it works because magic". I have learned that there is a 32 char limit on table names in sas. I switched to another table to test if that is the problem. I then found out I have to add the database in the libref which I did using database = &lt;database name&gt;. Then I learned what a schema is (I think) so I added that to thr libref too. The entire string being server.db.schema.tablename. Then i refer to mydata.tablename. Still not working. I thought I needed to add rsubmit and endrsubmit but that seems to refer to a previous setup-script used to connect to a teradata dbms where all other data is fetched from. Should I setup the connection to the odbc sql server? How? Should I use rsubmit/endrsubmit? Still very lost, as is probably apparent from my reply.
1) create a library pointing to your server (just like previous post) LIBNAME mydata ODBC noprompt = "[server=myseverpath.myhost.com](https://server%3Dbbdbhr-prd.wesleyan.edu/); DRIVER=SQL Server;Trusted Connection=yes"; &amp;#x200B; 2) if table name is &gt; 32 characters, use sql pass through. This runs the code on the server, where &gt; 32 chars are allowed: &amp;#x200B; proc sql; connect to odbc (dsn=MYDATA prompt = yes); create table mysasdataset as select \* from connection to odbc (select \* from SCHEMA.DatabaseTableNameThatIsLongerThanThirtyTwoCharacters); disconnect from odbc; &amp;#x200B; For tables &lt; 32 you can use the standard method, but it sounds like you need to refer to the schema too. SAS won't allow for using the "Database.Schema.Table" structure, but does allow you to point to schema this way: PROC SQL; CREATE TABLE mysasdata AS SELECT \* FROM mydata.sql\_server\_table\_name (SCHEMA = SchemaNameHere; &amp;#x200B; That is, remove the schema from the LIBNAME and add it in the SQL statements. Go get that data!
 have a series of data displayed in a dual-axis bar/line chart. If I have a user assigned to an numeric ID, I need their bar to be a slightly different color than the other bars. The ID assignment would be controlled in SAS VA Administrator. How do I do this in SAS Visual Analytics 7.4? See image below for details. We've tried using the indicator column, which can be dynamically assigned based on a parameter value that is associated with a drop-down list or other control object. The data source for the control object could have row-level security applied so that only the user's bank is displayed. This allows the user to change which bar is highlighted, but this is not the solution we need. I need to be able to control how the bars are highlighted on the admin side only. Sample data: ID Fig1a GA_Fig1a 1 0.650829 0.648538 2 0.01499 0.648538 3 0.955438 0.648538 4 0.480039 0.648538 5 0.060806 0.648538
The easiest way to get rid of wonky Excel formatting is to save the file as a CSV and import the CSV. It basic gets rid of any and all formatting. PROC IMPORT will code your CSV columns in basic formats, but you'll probably have to follow it up with your own formatting step.
If you have a lot of missing SAS is likely to interpret the column as character. I agree with other poster about converting to CSV and reading it in, except I suspect if you don‚Äôt fix the column types the CSV won‚Äôt be created properly. Excel doesn‚Äôt enforce types which is why it‚Äôs so flexible but also a disaster for storing data. SAS does not have a good method to control the types of variable while importing from an Excel file, but you can control it from a csv file.
Thanks for the tip, I'll give that a try!
Thank you for your patience in this, I feel like I am so close yet I cannot get it working. I am now getting a "CLI error trying to establish connection. Microwoft odbc driver manager. Data source name not found and no default driver specified: [Microsoft] [odbc driver manager] Invalid connection string attribute. Does passthrough require something else to work?
Which part are you having trouble implementing?
Perhapos replace this: connect to odbc (dsn=MYDATA prompt = yes); with this: connect to odbc (dsn=MYDATA noprompt = "[server=myseverpath.myhost.com](https://server%3Dbbdbhr-prd.wesleyan.edu/); DRIVER=SQL Server;Trusted Connection=yes");
I am not sure how to work around this specific proc code in the SAS environment. The logic of how to create a clean and scalable code, honestly
Or even if the methods I suggested are appropriate for what I described
Use a macro loop to generate the left joins and the table quarterly table names.
Let us know if it works yeah?
Assuming the names of the files are all the same, I'd append the quarterly tables together first and then join. You could macro-itize this, but I don't really know if it's necessary. Something like: data qtr; set dataset201801 (rename=(code = b\_code)) dataset201802 (rename=(code = c\_code)) ... dataset201903 (rename = (code = z\_code)); run; &amp;#x200B; proc sql; create table WANT as select a.acct , b.b\_code , b.c\_code ... b.z\_code from TEMPLATE as a left join qtr as b on a.acct = b.acct; quit; This should work, assuming there aren't any duplicate rows in the TEMPLATE or QTR tables. Otherwise this should be fine. You're going to have missing values of the individual \_code values where there is a mismatch between the TEMPLATE and QTR tables, but I'm assuming that's intentional (otherwise why would you do a left join in the first place?).
Bad data design. Why are you adding a column each time? It‚Äôs much easier to add rows. I would probably refactor my code to support a long data set and for final results that need to be in a wide format, reports and such, use proc tabulate or report to generate that structure. If you really need the wide structure, still more efficient to append all the tables together (stack, append, union) and then make your desired dataset using a transpose instead. This will be fully dynamic and doesn‚Äôt matter how many columns you‚Äôll have.
For help you‚Äôll need to show us how your initial data is structured. I suspect you‚Äôre facing a problem because you want a cumulative measure so need to either duplicate measures somehow or create cumulative summaries automatically. Show what you have as input data, what you need as output (data table plus graph) that ideally go together, which means the sample data should generate the expected output. Show what you‚Äôre tried/attempted and you‚Äôll get help from there.
Yeah it's the way the person downstream needs it. It's quarterly performance data and I think their code pulls it into some sort of template report. I'm going to try to append all the tables initially and see how that goes, my only concern is each of these tables are about 15MM rows and I have data going back to 2007, so it'll be huge.
Then you likely should build a process to summarize or process each month and then just append the results.
Yeah that's the goal in a perfect world. The datasets are still updated after that specific quarter, they're recording loss recoveries so it takes a long time for the various collection units to record and upload to our data. But this dataset I need to create is just a one time ad-hoc request...hopefully :)
Then I‚Äôd do a view that stacks it and a transpose. May take a bit of time but should work.
The method seems reasonable enough from the info you‚Äôve given. It‚Äôs unclear what trouble you‚Äôre having with the code though.
Post your data as text, not an image.
Why not just sum each of the categories of dummy variables? Then you could just do more simple if/then logic using =0 and &gt;0. The longer if/then logic using each variable should be possible, but I‚Äôm on my phone right now and can‚Äôt read your code well enough to find where you‚Äôre going wrong. An array isn‚Äôt going to work the way you‚Äôre trying to use it.
In the first code snippet, I believe the second "sub_PODcat =2" should be "sub_PODcat =3".
Haha. That‚Äôs a great idea! Thank you. :)
You need to edit your if-then statements for logic and they will work. Parentheses are necessary here. You need to tell SAS that categories 1 to 3 possibly include something instead of your current code which says only what to exclude. I like the suggestion /u/RagingClitGasm makes to sum each of the categories of dummy variables. Create a sum variable for each category then the code would be * 0 = no opiate &amp; no non-narcotics; if sum_opioid = 0 and sum_ace = 0 and sum_iv = 0 and sum_keto = 0 and sum_ibu =0; then sub_PODcat =0; *1 = no opioids on POD2 - POD5, but includes ANY non narcotics; else if sum_opioid = 0 AND (sum_ace &gt; 0 OR sum_iv &gt; 0 OR sum_keto &gt; 0 OR sum_ibu &gt; 0) ; then sub_PODcat =1; *2 = opioids on POD2 - POD5, and includes non-narcotics; else if sum_opioid &gt;0 AND (sum_ace &gt; 0 OR sum_iv &gt; 0 OR sum_keto &gt; 0 OR sum_ibu &gt; 0); then sub_PODcat = 2; *3 = opiates alone without non-narcotics included; else if sum_opioid &gt; 0 AND ( sum_ace = 0 and sum_iv = 0 and sum_keto = 0 and sum_ibu = 0) ; then sub_PODcat = 3; Then finally don't forget to take care of missing data too.
YES! It works! I had almost given up. Select Thanks From TheBottomOfMyHeart :D
Gold! You're too kind. Never give up!
Thanks for that nudge, my brain was not working at the end of yesterday. Summing worked like a charm. I updated my original post.
Derp. Thank you for the suggestions and tips. I ended up using [/u/RagingClitGasm](https://www.reddit.com/u/RagingClitGasm/) comment about summing. :)
Glad I could help! One last note, in case missing data is a concern: adding variables using + signs will return a missing value if any of the variables are missing, while using a sum() function will add all non-missing values and ignore the missing ones. Whether or not you want to categorize people with missing data is a judgement call.
I'd use a combination of [FIRST.ID](https://FIRST.ID) and the LAG() function. Assuming your data is sorted by ID, the following (or some close approximation) should work: &amp;#x200B; data \_WANT\_; set \_have\_; by id; if [first.id](https://first.id) then do; lag\_id = .; end; if id = lag\_id then do; fruit\_new = fruit||' &amp; '||lag(fruit); end; run;
Use proc sort with a nodupkey to remove duplicate fruits by ID. Then you can follow either approach here to concatenate the values. https://gist.github.com/statgeek/d583cfa992bf56da51d435165b07e96a
Alright, I've figured it out. I hate when people get a solution and never post it, so here is my solution. Shout out to /r/fdsaf3 for the help with the LAG function: data want; set have; by ID; LAG_FRUIT=LAG(FRUIT); if first.ID then LAG_FRUIT=""; else if first.ID = last.ID then LAG_FRUIT=LAG_FRUIT; LAG_FRUIT=LAG_FRUIT; if ANYALPHA(LAG_FRUIT) GT 0 then FRUIT_COMB = cat(cats(FRUIT)," AND ",cats(LAG_FRUIT)); else FRUIT_COMB = FRUIT; FRUIT = FRUIT_COMB; if first.ID then ID_ORDER = 2; else ID_ORDER=1; run; proc sort data=want out=want_1; by ID ID_ORDER; run; proc sort data=want_1 out=want_2 dupout=duplicates nodupkey; by ID; run; So in the above I used LAG to retrieve the previous entry for FRUIT. Then used first.var and last.var to put a blank if it's the only observation for ID or the previous FRUIT if the observation for ID appears twice. Then used ANYALPHA to concatenate a FRUIT_COMB variable if LAG_FRUIT had any characters in it and if not made FRUIT_COMB = FRUIT. Then I wanted to get rid of the duplicate entries for IDs who don't have a concatenated FRUIT entry. So I did first.var and last.var to number all second ID entries as 1 and all other entries as 2. Then I sorted by ID and ID_ORDER (which preserves ID order but switches entries with concatenated FRUIT variables to first position) followed by a PROC SORT NODUPKEY by ID. This dropped all duplicate ID entries with an ID_ORDER of 2 or greater.
FYI, posted my solution in the thread. Your advice with LAG was extremely helpful!
Sounds interesting.. I‚Äôm gonna try to work on it tonight.. Sorry at work now with a ton of programming to do. Will keep you posted on a solution.
I don't SQL, but I data step so I'll share that: Proc sort data= masterlist; by id; Proc sort data= sublist; by id; run; data mergedlist; merge masterlist(in=A) sublist; by id; if a; run; You always have to sort before performing a [BY] statement. The [IF A;] clause subsets the output only to those observations on the "masterlist". The [in=A] is a meta variable that only exists in the datastep.
I believe this would give a side-to-side join, and wouldn't actually add observations to the final dataset (if anything, for records linked on ID, it might simply overwrite the NAME values).
Oh, I think I've misunderstood you. You want to bring them all to the same level, but only if the ID is on the masterlist? I would run a PROC FREQ with a table out statement on the Master list ID's to get a table with just those ID's in the master list. Merge it onto the sublist to subset out those values that aren't on the masterlist and then just stack the two tables with the set statment. Something like: PROC FREQ data=masterlist; table ID/ output out = idlist; run; Proc sort data= idlist; by id; Proc sort data= sublist; by id; run; *This is now a table of the sublist with only those ID's in the masterlist; data merged_ID_list; merge idlist(in=A) sublist; by id; if a; run; data stacked_data; set masterlist merged_ID_list; run;
Try this out, it seems to do what you're looking for: data masterlist; input name $ 1-9 id 11; datalines; Coca Cola 1 Pepsi 2 NFL 3 Unilever 4 ; run; data sublist; input name $ 1-8 id 10; datalines; Aquafina 2 Sears 5 Macys 6 Degree 4 Mt Dew 2 ; run; proc sql noprint; create table want AS select name, id from masterlist outer union corr select name, id from sublist where id in (select distinct id from masterlist) order by id,name; quit;
proc sort data=brands ; by ID ; run ; proc sort data=subbrands ; by ID ; run ; &amp;#x200B; data want ; set brands (in=a) subbrands (in=b) ; by ID ; if ([first.ID](https://first.ID) and a) or (not [first.ID](https://first.ID) and b) ; run ;
Union the datasets to stack them on top of each other in a sub query, then do a select distinct on the fields. Sorry, on mobile and it's tough to write.
I agree, I think it would require a look at how the data is structured. My first thought was that it would be a matter of using first/last processing, but I'm pretty unsure about what the scenario and desired outcome is.
Instead of lag, you should be using two variables in your BY statement. &amp;#x200B; *Remove duplicate fruits from all ID; proc sort data=have out=fruit_nodups nodupkey; by id fruit; run; data want; set fruit_nodups; *two by variables; by id fruit; *set length long enough to hold all values and retain over values; length final_fruit $200.; retain final_fruit; *set missing on first of each ID to restart process fresh; if first.id then call missing(final_fruit); *append fruit name; final_fruit = catx(" &amp; ", final_fruit, fruit ); *output for last record of each ID; if last.id;*output only on last record per ID; run; &amp;#x200B; Generates this: Obs ID Fruit final_fruit 1 1 Oranges Apples &amp; Oranges 2 2 Pears Pears 3 3 Pears Apples &amp; Pears 4 4 Grapes Bananas &amp; Grapes 5 5 Apples Apples
Some reasons 1. Some variables have missing data. When using GLMSELECT only cases with all data will be used. However when you then use GLM, only variables being used with missing data will be excluded so you likely have more data. Easy to check the N used here. 2. Class variables are not parameterized the same method or specified the same. 3. You made a mistake in your code. Post your code.
Tried this out as well and it worked perfectly. This was closer to what I recall having done at some point in the past. Thanks!
Learning SAS doesn‚Äôt translate to anything. I.e. python helps you learn R and vice versa. Learning SAS is cementing yourself in a dying skill. It is killing your future potential. Unless you are old, entrenched in SAS, and in a senior role in an entrenched SAS company, where you are stuck there but you‚Äôve also sort of made it. In that case, you might as well hold on as long as you can while working to prolong your reign through pro sas propaganda.
Get hired for python or R skill. Subtlety refuse to learn SAS while demonstrating undeniable value in python or R. That‚Äôs the only way.
Learn to rstudio server with more RAM and then eventually use R with spark. Or the python version of that. Lol disc processing wtf.
Use a RETAIN variable: data herewego; set originaldata; by A; retain BFlag; if first.A then BFlag = 0; if B = condition\_you\_want\_to\_flag\_for then BFlag =1; if last.A and BFlag = 0; run;
Thanks alot! solved my issue
That is just a twisted view of what programming is all about. Learning one language, whether old or "dying" or not, does not "lock" you into anything. That is like saying that traveling to France locks you out of Spain. It doesn't. After you learn a few programming languages, the next one is just syntax.
Can you sell people movies? Check. - blockbuster logic
Imagine wanting to use SAS syntax in rstudio lmao üòÇ/wrists
Can you solve math problems? Check. - displaced time traveler abacus üßÆ expert logic
Can you pay the country club the SwimmingPayment with pennies? Check. - passive aggressive SAS user knowing deep down he is becoming obsolete logic
I didn‚Äôt mean to be passive aggressive SAS user. You seem to have a strong opinion on the subject. Tell me then, what can I do to get better?
The only people who believe that all languages are just a few syntactic differences away from each other are too biased to convince otherwise . But sure, no one is preventing you from unlearning sas thinking patterns and learning r/python from scratch.
Here's a sneak peek of /r/Python using the [top posts](https://np.reddit.com/r/Python/top/?sort=top&amp;t=year) of the year! \#1: [The entire MIT Intro Computer Science class using Python is available for free, with course materials.](https://www.youtube.com/watch?v=ytpJdnlu9ug&amp;list=PLUl4u3cNGP63WbdFxL8giv4yhgdMGaZNA) | [83 comments](https://np.reddit.com/r/Python/comments/a81mg3/the_entire_mit_intro_computer_science_class_using/) \#2: [These two books changed my life in 2018!](https://i.redd.it/dramdluyhu721.jpg) | [185 comments](https://np.reddit.com/r/Python/comments/abjuw4/these_two_books_changed_my_life_in_2018/) \#3: [Lil cheatsheet](https://i.redd.it/e9he5yt327h21.jpg) | [142 comments](https://np.reddit.com/r/Python/comments/arp3z9/lil_cheatsheet/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
Since it doesn‚Äôt matter what tool you use to transition to a language that doesn‚Äôt suck, there is nothing to optimize here. Just pick anything that gets you there eventually, no matter how efficient or elegant the process. Sometimes you may even need to reinvent entire wheels and perform miracles to get to this finish line, but it will always be the same wheels and miracles since all ways are equivalent because the tools don‚Äôt matter.
Try meetup.com? They must have a SAS user group there.
What‚Äôs a VBA set up? I sud SAS EG daily with both prof sql and sad data steps and haven‚Äôt needed anything. Maybe I just call it something else though
If you are using EG, you can schedule batch jobs with VB script. You just go to File -&gt; Schedule Project, then make sure the script is correctly scheduled in Windows Task Scheduler.
VBA is the coding language used directly in excel and other Microsoft products. It allows me to click a button on an Excel Workbook, have the computer go into the SAS server and run SAS code without opening enterprise guide or clicking any other buttons.
This wouldn't quite work because I have Excel Reports that run on the click of a button, and within the VBA Module I want in to go communicate with the SAS server and run Data steps. But I don't know the code for setting it up to run anything more than PROC SQL procedures. Thanks for the reply tho!
Oh that‚Äôs really cool! But unfortunately I‚Äôve never done that. Sorry I can‚Äôt help!
I'd like to team up, Not located in DC!
You can probably do this with SAS Stored Processes and Office Analytics. You would register the code that runs Proc SQL and Data Step Code as a "Stored Process". &amp;#x200B; Then using the Add-In for Microsoft Office, you could run the code you wrote in EG, or use a Stored Process to do the code using VBA in excel, however, VBA itself can't really call SAS Code directly.
Yes I understand VBA can‚Äôt do it directly. I use the SAS Object Manager and SAS Integrated Object Model references in VBA among a couple others. But I‚Äôm not sure they‚Äôre exact uses and limitations. As mentioned it works perfectly for Proc SQL but errors on Data Steps. I believe it‚Äôs coded in a way that sort of wraps the VBA functions (copy and pasted SAS code) in ‚ÄúPROC SQL;‚Äù and ‚ÄúQUIT;‚Äù but i don‚Äôt really know.
Huh, if the VBA wrapper adds PROC SQL; at the top of the code and quit; kind of like this. quit; data DSNAME; /* code goes here */ run; Basically you can't initiate a data step inside a PROC SQL Statement so you need to exit the PROC SQL statement using quit, likewise you can't initiate more Create or insert, etc statements without another PROC SQL before it.
Would the ‚Äúwrapped‚Äù quit; statement after the run; make a difference you think?
Im interested in the code to run proc sql from excel vba! Can you share an example?
It shouldn't. &amp;#x200B; If you use EG check the log, after each job EG adds a bunch of stuff to ensure that all statements to the server get ended. quit; is part of that;
I'm oversimplifying here a bit, but you should get the gist from the rest of this comment. Setup-wise I'll assume you have an Excel macro-enabled workbook set up with at least one button used to trigger execution. I will also assume that you have a plain-text SAS program that you will dump into a cell or range somewhere in that workbook (in the example code below it will be a named range called "SAS\_PROGRAM") or that you will be adding VBA code somewhere to read a SAS program in from an external file or database. Lastly I will assume that you have a sheet or range of cells that contain the names of the datasets you want to retrieve from the SAS session that you can iterate through (in the example code below it will be the first column of a sheet named "sas\_datasets"). That said, provided that you have included the required References in your macro workbook, you could use the following to execute a SAS program using VBA and pull the final dataset(s) into Excel. Public sasWorkspaceManager As New sasWorkspaceManager.WorkspaceManager Public sasWorkspace As SAS.Workspace Public sasWorkspaceFlag As Integer Sub runProgram() Dim errorString As String Dim dataset As String, itemCount As Integer, loopCounter As Integer Call deleteSheets Application.ScreenUpdating = False sasWorkspaceFlag = 0 If sasWorkspaceFlag = 0 Then Set sasWorkspace = sasWorkspaceManager.Workspaces.CreateWorkspaceByServer("Local", VisibilityProcess, Nothing, "", "", errorString) sasWorkspaceFlag = 1 End If sasWorkspace.LanguageService.Submit Range("SAS_PROGRAM").Value itemCount = WorksheetFunction.CountA(Sheets("sas_datasets").Columns(1)) For i = 2 To itemCount dataset = Sheets("sas_datasets").Cells(i, 1).Value Call createOutput(dataset) Next If Not (sasWorkspace Is Nothing) Then sasWorkspaceManager.Workspaces.RemoveWorkspace sasWorkspace sasWorkspace.Close End If Application.ScreenUpdating = True End Sub Sub createOutput(sheetName As String) Application.ScreenUpdating = False ThisWorkbook.Sheets.Add After:=ThisWorkbook.Sheets(ThisWorkbook.Sheets.Count) ActiveSheet.Name = sheetName retrieveDataset (sheetName) End Sub Sub retrieveDataset(sasDatasetName As String) Dim adoDbConnection As New ADODB.Connection Dim adoDbRecordset As New ADODB.Recordset Dim errorString As String Dim colNum As Integer Application.ScreenUpdating = False If sasWorkspaceFlag = 0 Then Set sasWorkspace = sasWorkspaceManager.Workspaces.CreateWorkspaceByServer("Local", VisibilityProcess, Nothing, "", "", errorString) sasWorkspaceFlag = 1 End If adoDbConnection.Open "provider=sas.iomprovider.1; SAS Workspace ID=" + sasWorkspace.UniqueIdentifier adoDbRecordset.Open sasDatasetName, adoDbConnection, adOpenStatic, adLockReadOnly, adCmdTableDirect Sheets(sasDatasetName).Activate colNum = 1 For Each fld In adoDbRecordset.Fields Cells(1, colNum).Value = fld.Name colNum = colNum + 1 Next R = 2 C = 1 Cells(R, C).CopyFromRecordset adoDbRecordset Cells(R - 1, C).Select adoDbRecordset.Close adoDbConnection.Close End Sub Sub deleteSheets() Dim dataset As String, sheetExists As String, itemCount As Integer, loopCounter As Integer Application.ScreenUpdating = False Application.DisplayAlerts = False itemCount = WorksheetFunction.CountA(Sheets("sas_datasets").Columns(1)) For i = 2 To itemCount dataset = Sheets("sas_datasets").Cells(i, 1).Value sheetExists = Evaluate("ISREF('" &amp; dataset &amp; "'!A1)") If sheetExists Then ThisWorkbook.Sheets(dataset).Delete Next Application.DisplayAlerts = True Application.ScreenUpdating = True End Sub
I should also mention that due to the difference between reference dates in SAS and Excel you will need to adjust and date, time, or datetime fields in order to have them display correctly. I do this in my SAS programs. You can check out the guide linked below for further info. [https://communities.sas.com/t5/SAS-Tips-from-the-Community/SAS-Tip-Conversion-from-Excel-Date-to-SAS-Date/td-p/475824](https://communities.sas.com/t5/SAS-Tips-from-the-Community/SAS-Tip-Conversion-from-Excel-Date-to-SAS-Date/td-p/475824)
Have you tried a maximum amount for the xaxis? For example: xaxis max = 3000; I've used this when I've had extreme outliers that I didn't need to display. If I didn't have it there, the graph would have been visually useless. I've never tried this with data labels though.
Not quite that easy in regulated environments. I can‚Äôt just load my data to AWS and RAM takes weeks to months to get approved. And we have massive data sets. Our transactional systems are phenomenal.
Offsetmax/min options on the Xaxis statement lets you control the extra space.
Do you have SAS Add on for Office? That would do what you need, but otherwise, I would suggest looking up some of Chris Hemidingers posts, blog and books. He‚Äôs the guru on the topic.
Perhaps this: [http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245893.htm](http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245893.htm) This example uses FDELETE to delete an empty directory to which you have write access. If the directory is not empty, the optional SYSMSG function returns an error message stating that SAS is unable to delete the file. &amp;#x200B; filename testdir '*physical-filename*'; data \_null\_; rc=fdelete('testdir'); put rc=; msg=sysmsg(); put msg=; run;
Thank you for this reply! I have very similar code but it's not quite the same. Here is an example of what I work with. I Connect to the SAS Server then call SAS procedures through VBA Functions. Then execute all the necessary functions and when I want to output the resulting table, I use a RecordSet to copy and paste into the workbook. Option Explicit Public obConnection As New ADODB.Connection Public StrPass As String Public StrUser As String Sub Connect() Set obObjectFactory = CreateObject("SASObjectManager.ObjectFactory") Set obObjectKeeper = CreateObject("SASObjectManager.ObjectKeeper") Set obServer = CreateObject("SASObjectManager.ServerDef") On Error GoTo ErrorFix Application.StatusBar = "Initializing SAS Connection..." StrUser = InputBox("Please enter your SAS UserName", "UserName", Environ("UserName")) If StrUser = "" Then Exit Sub StrUser = StrConv(StrUser, vbLowerCase) StrPass = InputBox("Please enter the SAS Password for " &amp; StrUser, "PASSWORD") If StrPass = "" Then Exit Sub 'Set properties of server defintion obServer.MachineDNSName = "INSERT DNS NAME HERE" 'obServer.Protocol = ProtocolBridge obServer.Protocol = 2 '2 = ProtocolBridge obServer.Port = "8591" 'Create SAS Workspace 'Set obSAS = obWorkspaceManager.Workspaces.CreateWorkspaceByServer("SASApp", VisibilityProcess, obServerdef, StrUser, StrPass, "") Set obSAS = obObjectFactory.CreateObjectByServer("sas1", True, obServer, StrUser, StrPass) 'Set obObjectKeeper = New SASObjectManager.ObjectKeeper obObjectKeeper.AddObject 1, "sas1", obSAS obConnection.Open "provider=sas.iomprovider.1; SAS Workspace ID=" + obSAS.UniqueIdentifier Exit Sub ErrorFix: Application.ScreenUpdating = True MsgBox ("Error in Connection") End Sub
This works perfectly for PROC SQL; in SAS Enterprise Guide but will error out on Data Steps. The Errors that VBA outputs are almost trying to read SAS errors so the errors look ugly. Heres the one you get when you try to run a Data Step. Run-time error '-2147217900 (80040e14)':
DBMS = XLSX should work. My log: &amp;#x200B; 98 PROC EXPORT DATA= x 99 OUTFILE= "c:\\temp\\x.xlsx" 100 DBMS=XLSX REPLACE ; 101 SHEET="volume"; 102 RUN; &amp;#x200B; NOTE: The export data set has 3 observations and 1 variables. NOTE: "c:\\temp\\x.xlsx" file was successfully created. NOTE: PROCEDURE EXPORT used (Total process time): real time 0.04 seconds cpu time 0.04 seconds
Do you have the appropriate license? Can you run PROC setinit;run; and check to see if you have "SAS/ACCESS Interface to PC Files"?
Here's what it gave me: &amp;#x200B; 1 proc setinit;run; &amp;#x200B; NOTE: PROCEDURE SETINIT used (Total process time): real time 0.01 seconds cpu time 0.01 seconds &amp;#x200B; Original site validation data Current version: 9.04.01M6P110718 Site name: 'AZ DEPARTMENT OF HEALTH SERVICES'. Site number: 70067355. CPU A: Model name='' model number='' serial=''. Expiration: 29SEP2057. Grace Period: 45 days (ending 13NOV2057). Warning Period: 55 days (ending 07JAN2058). System birthday: 29MAR2019. Operating System: W32\_WKS . Product expiration dates: \---Base SAS Software 29SEP2057 (CPU A) \---SAS/STAT 29SEP2057 (CPU A) \---SAS/GRAPH 29SEP2057 (CPU A) \---SAS/Secure 168-bit 29SEP2057 (CPU A) \---SAS/Secure Windows 29SEP2057 (CPU A) \---SAS Enterprise Guide 29SEP2057 (CPU A) \---SAS/ACCESS Interface to DB2 30DEC2061 (CPU A) \---SAS/ACCESS Interface to Oracle 30DEC2061 (CPU A) \---SAS/ACCESS Interface to OLE DB 30DEC2061 (CPU A) \---SAS Workspace Server for Local Access 29SEP2057 (CPU A) \---High Performance Suite 29SEP2057 (CPU A)
That is a much better answer than my "it should work..."
What license do you have? You can see it if you execute "proc setinit; run; " &amp;#x200B; If you have the right license, does DBMS=CSV work? &amp;#x200B; You can also try ODS EXCEL as detailed here: [https://blogs.sas.com/content/sasdummy/2014/08/29/experimenting-with-ods-excel-to-create-spreadsheets-from-sas/](https://blogs.sas.com/content/sasdummy/2014/08/29/experimenting-with-ods-excel-to-create-spreadsheets-from-sas/)
HERE BELOW IS FROM THE LITTLE SAS BOOK. There are several DBMS identifiers you can use to create Excel files. Three commonly used identifiers are EXCEL, XLS, and XLSX. The EXCEL identifier is available only on Windows. The XLS identifier creates older style files (.xls extension) and is available on Windows and UNIX. The XLSX\[1\] identifier creates newer style files (.xlsx extension) and is available on both Windows and UNIX. Not all of these identifiers may work for you if your Windows computer has a mixture of 64-bit and 32-bit applications.
Try proc tabulate maybe?
There are better free resources out there, start with the free SAS and the one on Coursera. The book list is correct. Affiliate links marketing?
It‚Äôs very possible to do. Can you do it? Depends on your skill set or budget.
A quick way I can think of off hand (if you only care about counting the yes values) would make new variables Cap1n to Cap6n. With it defined as 1=yes 0=no then get the sum of Cap1n to Cap6n. There might be a different way that counts values but I am unaware of it.
I don't have sas installed on this machine but what I would do is use a datastep, define an array with cap1 - cap6 in it, and 'do over' that array icrementing the numcap counter. Here is a link to an example of using arrays and the 'do over' loop: [http://staff.washington.edu/glynn/array.pdf](http://staff.washington.edu/glynn/array.pdf) &amp;#x200B; so in your case it would look something like this: data want; set have; retain capnum; capnum = 0; array caps cap1 - cap6; do over caps; if caps = 'yes' then do; capnum = capnum + 1; end; end; run; &amp;#x200B; Again, I don't have SAS on this computer to test it, but this is probably the method I would use as it would most flexible if in the future you had more than 6 cap variables. &amp;#x200B; Let me know if this works for you.
Holy guacamole!!! It worked! Thanks much!
You could concatenate the 'cap' variables and then count the number of 'yes' in that string Something like count(cat(of cap:),"yes")
this sounds like the coolest way to do it.
A date and a datetime are two different formats and will not match as you expect them to. The way it displays is actually of no consequence here, it is the format "under water" that has to be the same. A date value in SAS is the number of days since Jan 1, 1960. A datetime value is the number of seconds since Jan 1, 1960. This explains why you see the value of 01JAN1960:05:26:04 in your example. One thing you can try to make it work is to strip off the time part in your join: proc sql; select a.bla, b.foo, b.bar from a left join b on a.ID = b.ID and datepart(a.datetime) = input(b.date, MMDDYYN8.); quit;
As the other response said, a date =/= a datetime. However, you can extract only the date from a datetime by using [the datepart function](http://support.sas.com/documentation/cdl/en/lrdict/64316/HTML/default/viewer.htm#a000245883.htm). I believe once you extract the datepart you can match formats and join.
Repalce input with inputn
Thanks. That worked. I really need to go over the date tutorials again.
This looks like it may do the trick, will experiment around and see what works. Thank you!
Dates always used to bother me in SAS until I started storing them as numeric and not date related formats. If your data comes in as datetime use datepart. Store it as numeric. When you go to output, format a character variable and use put(x, date9.) or whatever format you need. 01JAN1960 is the start date for a SAS numeric date. That means it didn't read the number you passed it as a date. If you just datepart and then store as numeric, you won't have any issue.
to convert your datetime to a date, you can divide by 86400 (the number of seconds in a day), use datepart() or a datetime format
I'm a little unclear on what you want to do exactly, but if you always want to copy specific files from directory A to directory B, then I think you can use a macro? libname folder_a '&lt;directory location&gt;'; libname folder_b '&lt;directory location&gt;'; %macro copy(filename); data folder_b.&amp;filename; set folder_a.&amp;filename; run; %mend; %copy(ID1); %copy(ID2); %copy(ID3); %copy(ID9); You can add more file names or change them easily this way.
depending on your sas set up you can use the X command to pass commands out of sas. i often have to use it to move, unzip, and unencrypt files.
Sure - but be warned, the juice might not be worth the squeeze, if you know what I mean. This is one of my new favorite sayings. You can do this a few different ways. One approach would be to macro-itize and generate a list of files from a given folder/directory. This approach is described here: [https://www.mwsug.org/proceedings/2014/SA/MWSUG-2014-SA11.pdf](https://www.mwsug.org/proceedings/2014/SA/MWSUG-2014-SA11.pdf) So you'd have a list of macro variables from 1 to whatever (in your example, 3). The final step would be to check if any of those exist in the folder you want to copy them to. I am fairly sure, but not positive, that SAS has an EXIST function. So you'd have to embed this into a macro with a %DO loop: %if %sysfunc(exist(&amp;DSN.)) %then %do; data out.\&amp;dsn; set &amp;dsn.; run; %mend; There are other ways to do this that I can think of, but this is the approach I'd try first if I were in your shoes. And again, be warned that unless this is something that you need to automate, my sense is there are better or more efficient ways to get the same result. But it's totally possible.
You can PIPE windows commands in a FILENAME statement. I use the DIR command with various options in order to get a list of files in directory (and subdirectories). If the information from this PIPE'd statement is parsed correctly using a DATA step, you can lot of the Windows file attributes--e.g., name, extension, directory, size, owner, last modified date, created date, etc.--depending on the options you use in the command. From here, you can very easily use a WHERE clause to get what you're looking for and generate macro variable arrays or a DATA _NULL_/CALL EXECUTE step for carrying out your task.
yea all the time if you using active directory. https://documentation.sas.com/?docsetId=bisecag&amp;docsetTarget=n0l2hp5m00a1z2n1b598q4pknfih.htm&amp;docsetVersion=9.4&amp;locale=en
Can this be used to create ACTs, folder structure, and libraries?
you can programmatically do all the above as well but not with the predefined macros you would need to extend with proc metadata and proc metalib. you could get the users and groups(departments) from AD then use https://support.sas.com/documentation/cdl/en/lrmeta/60739/HTML/default/viewer.htm#a003105518.htm to programmatically create ACTs, and folders. I'm not sure about libraries defined in metadata. I'm leaning yes but no experience in that.
Thanks for the direction. Any chance you have bulk deleted users out of SMC? W/o altering other users?
Use a macro %if along with proc datasets to copy.
I'm pretty sure you can do bulk removals. It's going to be the same macro for bulk inserts / sync. I personally never had a task of bulk removals tho
Here's a really good resource for that: [https://communities.sas.com/t5/SAS-Communities-Library/Working-with-Dates-and-Times-in-SAS-Tutorial/ta-p/424354](https://communities.sas.com/t5/SAS-Communities-Library/Working-with-Dates-and-Times-in-SAS-Tutorial/ta-p/424354)
Do over is deprecated as of version 7, it really shouldn't be used in production code anymore. If it's just for homework that's fine then.
Yeah, it's pretty trivial. &amp;#x200B; First get a list of files somehow, there's many examples of that on the internet - there's one in the SAS documentation, under the macro appendix. Then use that as an input to a data step and use FCOPY() to move the files. Assuming you're on SAS 9.4 FCOPY() doesn't require OS commands. This method would then work on any system.
It‚Äôs a hw. Thanks!
Online? I don't understand. This means you can google while takinf the exam?
No, it‚Äôs online proctored. So there is someone watching you over webcam and you do everything over a VM. You download software that allows them to monitor you. But, while you are doing the coding part you do have access to SAS documentation through internet explorer.
Thoughts? I took the beta last December and contemplated the Advanced beta but after the 3 hour beta in was like I'll wait for the production advanced exam lol. I like the new exam style.
When I took it a few months ago, I didn‚Äôt have any access to anything- the VM would quit if I so much as had task manager open. I had to change my Chrome settings to not run in the background.
What's the complexity of the exam compared to the previous one?
What is the best way to prepare for the new exam?
The newer version of the exam still covers the same training as the older version, SAS Programming 1 and SAS Programming 2. There is an updated version of the practice exam and prep guide that's designed more for the new format: [https://www.sas.com/en\_us/certification/credentials/foundation-tools/base-programming-specialist.html](https://www.sas.com/en_us/certification/credentials/foundation-tools/base-programming-specialist.html)
Wasn‚Äôt any more complex, you just need to be careful on the coding part because you will use one piece of code to answer multiple questions. But if you use sas often it should be easier and more familiar than the multiple choice.
The experience is very dependent on your connection unfortunately. And probably whatever computer you are using. But here‚Äôs hoping the have optimized the VM software. Was not TOO bad for me. Just moments of lag every so often that would bug me.
Now that I think back, I didn‚Äôt even have a VM...I didn‚Äôt have any sort of coding environment- just ‚Äúwhat does this code do‚Äù sort of questions with a few places to fill in code. And also a proctor that would bother me if I so much as looked the wrong direction.
Lol the proctor got on me for putting my hand on my chin.
Did you use Studio or Enterprise Guide?
Enterprise guide. I‚Äôm not a big fan of studio personally. But I‚Äôve been using EG for 6 years so it‚Äôs what I‚Äôm most familiar with.
I definitely like Enterprise Guide better. Were you able to use the query builder during the programming part of the exam?
Didn‚Äôt try. I barely use it as it is. Part of me thinks they would force you to write the code, but maybe they would allow it. I‚Äôm not sure.
What range of topics did it cover? Proc merge? Proc sql? Etc?
Anything in the guide is fair game. Won‚Äôt have SQL in the base test, but you will in the advanced. The coding part was a lot of data manipulation and analysis. So sort, merge, means, freq we‚Äôre all used. But you can use whatever you want so long as you get to the right answer.
Good to know. Thanks.
You'll need to find the controlled terminology for each specific instrument. Some will be in the main CT file, but you can find many others in the [CDISC QRS supplement](https://www.cdisc.org/foundational/qrs). If it's a newer instrument, you may need to construct your own terminology.
Is this what you are after? http://support.sas.com/kb/37/109.html
Proc freq data=sashelp.cars; Tables type*origin; Run;
proc freq data=[dataset]; tables [case_status]*[year]; ods output CrossTabFreqs=dataset2; dataset3(keep=year volume); dataset2; if Frequency&lt;20 then volume=0;else if Frequency &gt;=20 then volume=1; run; proc sort data=[dataset]; by [year]; run; proc sort data=dataset2; by year; run; data dataset3; merge [dataset] dataset2; by year; run;
Example code requires example data.
This very much depends on the data structure.
Not a question so don‚Äôt use a question mark. Your post should include a few more things if you want readers and for it to be useful. 1. Reduce the amount of ads - unless that‚Äôs your focus here, making money off basic tutorials. 2. Add a table of content to the top that lets you jump to specific sections 3. Indicate the problem you‚Äôre trying to solve or problems that can be solved. You have some conceptual mistakes there, could be due to language or not fully understanding what a cross tab is versus a contingency table. And when posting here make sure to include more details about what it is and don‚Äôt try and hide that it‚Äôs a blog post - then people stop reading.
true. gave it my best guess considering op said it was a patient level dataset
The Beta followed the exam content pdf to a T. The last part of the content guide was the old style questions.
thanks for your suggestion.
Interesting I was actaully on the verge of making a post about the new test myself, you may just have saved me the trouble ;) . I've been studying SAS 1 and 2 these past two months and am on the verge of taking said test. My father is an epidiemiologist who uses sas with pharmacogenomics. He has been training me and I'm prepping to take the exam. Is there anything you'd recommend particularly buffing up on? I have just a few days left before I take it, and I'm rather nervous truth be told.
The prep guide is the best way to go in my experience. You need to know everything in the book because it‚Äôs all fair game for the test. Take special note of default settings (i.e. does proc sort use descending or ascending order by default) and overall syntax. If you have the 9.4 prep book, there will be sample code assignments to do in the book, so make sure you can do all of them without issue (assuming you have access to SAS). That‚Äôs what I have our new hires do and we have a pretty good pass rate with the test. If you fail it, it‚Äôs not the end of the world. Just write down what you need to study more and try again. You have to wait 2 weeks between attempts, but I wouldn‚Äôt wait much longer than that otherwise the info might not be as fresh. Other than that, Good luck! Let us know how it goes!
Proc Tabulate - quick easy way
Proc sort data=have; By merchant; Run; Data want; Set have; By merchant; If first.merchant then total=transaction_total; Else if first.merchant NE 1 the total + transaction_total; If last.merchant then output; Run;
There are a variety of ways to do it (if I understand the issue correctly). My personal preference would be proc sql. data have; input company $ money; datalines; Walmart 19.54 Walmart 102.00 Walmart 3.23 Walmart 23.10 Target 1000.20 Target 1.44 Target 8.99 Starbucks 3.54 Starbucks 3.54 Starbucks 3.54 Starbucks 7.23 Starbucks 3.54 Starbucks 7.23 Starbucks 3.54 Starbucks 3.54 Starbucks 4.23 ; run; proc sql noprint; create table want AS select company,sum(money) as total from have group by company; quit;
There are a ton of ways to do this. Other than the great options already posted, you can use proc means to sum the data and output a data set. proc means data=\_have\_ sum n; var dollars; class company; output out=\_out\_; run;
data Centers; input PUF\_CASE\_ID $ PUF\_FACILITY\_ID $ YEAR\_OF\_DIAGNOSIS; datalines; D3bf9934a-eb34-42e5-934a-d13a527a39e9 AANHJQQSOI 2012 D6b290370-876f-48e5-bca8-fd430bb2cd6f AANHJQQSOI 2012 D7b09299b-1196-4611-8c37-e013a1e772ec AANHJQQSOI 2012 D72edda19-ed82-4279-842e-dfd7c3088bc8 ABEDXVDLVS 2012 D611bedc7-5ce1-4773-9f24-a0401f587c1f ABYOOAIYLM 2013 D152e15f8-121f-4728-9881-451dcdd4ec00 ABYOOAIYLM 2012 Dc41ae9ef-5721-4d88-970c-485e07a63af6 ABYOOAIYLM 2014 D61aaafff-5d83-4730-a5b1-b143becd837a ABYOOAIYLM 2015 Dfd357d34-06cd-4c99-ad39-32bf29c26b66 ACGPUVKPET 2015 D30af9988-11b8-42a4-8aca-2a14c93b5aa2 ACGPUVKPET 2014 D7ec3084e-703c-41d7-944a-19f01ff6411f ACGPUVKPET 2015 D8e730f20-f768-4ed7-bda4-a4f40b189c33 ACGPUVKPET 2013 D06155fd6-e9f0-4f0a-8b8a-d9550e131a3a ACGPUVKPET 2013 ;
Just did, I updated the question as well. Thanks
 I hope this is not too much simplistic data Centers; input PUF\_CASE\_ID $ PUF\_FACILITY\_ID $ YEAR\_OF\_DIAGNOSIS; datalines; D3bf9934a-eb34-42e5-934a-d13a527a39e9 AANHJQQSOI 2012 D6b290370-876f-48e5-bca8-fd430bb2cd6f AANHJQQSOI 2012 D7b09299b-1196-4611-8c37-e013a1e772ec AANHJQQSOI 2012 D72edda19-ed82-4279-842e-dfd7c3088bc8 ABEDXVDLVS 2012 D611bedc7-5ce1-4773-9f24-a0401f587c1f ABYOOAIYLM 2013 D152e15f8-121f-4728-9881-451dcdd4ec00 ABYOOAIYLM 2012 Dc41ae9ef-5721-4d88-970c-485e07a63af6 ABYOOAIYLM 2014 D61aaafff-5d83-4730-a5b1-b143becd837a ABYOOAIYLM 2015 Dfd357d34-06cd-4c99-ad39-32bf29c26b66 ACGPUVKPET 2015 D30af9988-11b8-42a4-8aca-2a14c93b5aa2 ACGPUVKPET 2014 D7ec3084e-703c-41d7-944a-19f01ff6411f ACGPUVKPET 2015 D8e730f20-f768-4ed7-bda4-a4f40b189c33 ACGPUVKPET 2013 D06155fd6-e9f0-4f0a-8b8a-d9550e131a3a ACGPUVKPET 2013 ;
&gt;dataset3(keep=year **volume**); dataset2; if Frequency&lt;20 then volume=0;else if Frequency &gt;=20 then volume=1; run; How do we creat the variable Volume?
Proc sql; Create table my_totals as Select transaction, count(*) as total From my_raw_data Group by transaction; Quit;
You can do the sas programming 1 course for free online from the sas training website. You can also do sas statistics 1 for Free if that is your need. I'd recommend both.
Are you reading in the data originally via datelines or from a text file. You do not need periods to indicate missing. You need to go back to your input data to fix this, not after the fact. Usually you just need to add TRUNCOVER to the INFILE statement.
Hi, thanks for replying! &amp;#x200B; Uh, when I added TRUNCOVER to the infile statement, SAS took a really long time to generate an output so I stopped the system. &amp;#x200B; I got a WARNING message that my history data set is incomplete and that when the step was stopped there were "16739722 observations" when I only have \~450. I dunno what causes that so xD haha. Thanks for your help! &amp;#x200B; I'll tell my PI I tried \^\^;
My morning coffee hasn't kicked in yet, so fair warning. :) It sounds to me like you have a data set with multiple rows per person ID. If that's the case, can you transpose the data using PROC TRANSPOSE? I know for a fact that will create null values if the person didn't have that many weight values... Otherwise, can you provide some dummy data which looks like the data you have so we can better answer your question?
I don't understand why you're using SAS if you don't need to do data manipulations. Frankly, SAS is cumbersome and not the best statistical reporting software package. If you're already an average R user, I'm not sure why you'd want to switch to SAS if you are only interested in statistical programming. The strength of SAS comes from its data manipulation and data step programming. This post is quite curious.
I do not need SAS data manipulation at that moment (but need in future). Now I only need to recheck calculations done in R.
Now I'm really confused -- your original post says "no calculations," but now you say you need to check calculations. How does one check calculations without doing, well, calculations? And what type of "calculations?"
Ok, so what I meant is the brief tutorial about SAS that includes some basic syntax and some general language specific things. "no calculations" means that I do not need tutorials that explain how to perform specific type of calculation in SAS. I need only quick general introduction and after completing which depending what I want to calculate I will find specific tutorial for that particular type of calculation.
Perhaps the Little SAS Book. Longer than you want but good primer.
Post your code to read the file. You should be using TRUNCOVER but you likely set something up incorrectly then.
So if A is missing, you want B to be 'X', otherwise you want it to equal A? Then you can just do: &gt; if (not missing(A)) then B = A; &gt; else B = 'X';
Not to be dramatic but I think I could cry. Do you need anything? A virtual hug, a recommendation letter, my life savings? &amp;#x200B; Thank you so much!
That's definitely not necessary! It's always good to ask for help in these kinds of things, and when the question is "Is there an easier way to do this?" the answer is almost always yes.
There‚Äôs a function for that, X = coalescec(a,b); Coalescec for characters, coalesce for numbers.
You may just be giving the general schema for coalesce, but since you used OP's letters I'll clarify that the usage in this case would be b=coalescec(a,"X") Other fun little functions people forget about are ifn/ifc
One tangential suggestion I'd make is to make analysis/flag variables numeric rather than character. So in this case, use 1 and 0 as yes/no respectively. If you want, you can use a format to display yes/no, but the underlying data will be 1s and 0s.
When I studied for the 9.4 exam I bought the book they released as prep for the exam and read all the chapters &amp; did the practice quizzes. You will also want to try to implement some stuff yourself to learn more of the small details of SAS. Knowing SQL will help you more for the advanced exam as that's where they test on proc sql.
SAS is different than other programming languages. It's not harder, but because a lot of the logic for data step programming was developed in the 70s it's just...different. I'd suggest just reading SAS study guides and materials to study. Knowing SQL won't help for the base exam. &amp;#x200B; Note: this is feedback based on the base exam from like 2008. I think I heard recently that they changed the structure of the exam recently - if not the content. So this advice might be a bit antiquated. Take it with a grain of salt.
Awesome! I am already enrolled in a course through the VA at Syracuse State. Fortunately, getting the prep stuff for the exam knocked out for me will be fairly easy and inexpensive. I guess why I was wondering was if I should brush up on my Stats or Calc or anything like that? At any rate, thanks for the response!
Thanks for the response! It seems like the base exam is a look at entry level skills. I have never taken an exam like this previously. Wasn‚Äôt too sure what to expect or how difficult it would end up being.
You can find some recommended resources to help you prepare for SAS Certifications here [https://www.sas.com/en\_us/certification/training-exam-preparation.html](https://www.sas.com/en_us/certification/training-exam-preparation.html) For the BASE Programming Specialist certification, SAS Programming 1 [https://support.sas.com/edu/schedules.html?crs=PROG1&amp;ctry=us](https://support.sas.com/edu/schedules.html?crs=PROG1&amp;ctry=us) and SAS Programming 2 courses are recommended [https://support.sas.com/edu/schedules.html?crs=PROG2&amp;ctry=us](https://support.sas.com/edu/schedules.html?crs=PROG2&amp;ctry=us) Also see other support resources here to help you along the way [https://www.sas.com/content/dam/SAS/en\_us/doc/infographic/sas-cares-107449.pdf](https://www.sas.com/content/dam/SAS/en_us/doc/infographic/sas-cares-107449.pdf) Good luck!
Awesome! Thanks for the resources. I‚Äôve created an account on the SAS website. Excited!
I started with The Little SAS Book: A Primer by Delwiche &amp; Slaughter. This provided me with the basic fundamentals and logic of SAS. I then looked up free materials online (practice tests, etc)
Yes, that was a generic example, the OP can apply as needed.
Hey, me too. üëç
I work for a large bank and we use it for statistical analysis on our lending products. Getting my certifications to solidify my base salary requirements.
No, its primarily a programming test, nothing about statistics or math. You'll need to brush up on logic but that's pretty straightforward. In fact, the test right now is programming, so they give you a question and you'll actually have to program.
First course is free and you can get SAS for free via SAS UE.
Where did you find the practice tests?
As a full time SAS programmer, I sincerely think the first step would be to learn python instead. A major trend I‚Äôve noticed is organizations dropping SAS for python because it‚Äôs more powerful, less expensive, more customizable, etc.
What‚Äôs the homework?
It‚Äôs a free program through the VA that I go into. It‚Äôs the only programming language being offered. I understand R would be more ideal BUT with SAS the only thing being offered, I was curious if it was more regimented and had prerequisites. I don‚Äôt necessarily think I am even going to get a position using SAS, I‚Äôm doing it for the programming foundation. Not sure why you are being downvoted, thank you for your honesty and response!
You mean like this? proc freq data=example; tables a * b / out=freq; run;
Might as well just post it here like everyone else does.
They're being downvoted because lots of large companies use SAS and will continue to do so for the foreseeable future. If you have some experience and certifications, you could certainly get a SAS job if you want one. The key is practice. Just start writing your own programs and doing practice exercises online. I'd never discourage you from learning SAS, Python, SQL, or any other language. The more tools you can use, the better. Versatility is the key, no matter where you end up.
Nah, that would cross tabulate. I just want the frequencies of a and b separately, but in the same dataset. /u/xmindallas
It doesn't look like you can do that without setting them together in a separate data step. Or you could use proc append if you prefer.
I took the Base Exam yesterday. No analysis on it but it will ask you to find the mean of some things. For this test focus more on syntax. Since you will be programming some make sure you know the basics of all your procs (including proc import and proc datasets) and brush up on BY Processing. It's all very basic stuff so if you know how to do the basics, just follow the study guide and you'll be fine.
You can use proc tabulate with ODS: &amp;#x200B; ods output Table = NewData; proc tabulate missing data = example; class var1 var2; table var1 var2; run; &amp;#x200B; ods quit; &amp;#x200B; The resulting data set will be a bit messy. There are ways to tweak it in tabulate using a dummy var, or you can do the clean up in data steps. As @xmindallas said, another approach would to use FREQ one var at a time and append. Good luck.
(I expected to be downvoted) If it's free it can't really hurt you. SAS will develop some programming skills like understand program flow, constructing conditional statements, data management, debugging, using documentation/google to problem solve... That being said there is sort of a catch 22 involved: SAS is a programming language of a certain age and it has a very distinct way of doing things that is different from every other programming language I've worked in. For instance when you squint C# and Java look sort of the same, and if you know one you can probably at least read the other to figure out what's going on and probably get up to speed with a little research. From my experience the key concepts from the SAS (data step processing, controlling the PDV, etc) aren't really skills that transfer to other languages because the way SAS handles stuff is so unique. I don't want to give you the impression that SAS is bad, it's just not a general purpose tool. It was built to do one thing really well (work with data in a time where data was stored on punch cards and RAM wasn't large enough to hold more than one record at a time). Because of this lots of the other more modern functionality of SAS feels like its being contorted to fit into the programming paradigm organized around that function... In the grand scheme of things SAS is often a very good tool for the jobs it was designed to do, but can be cumbersome when you're not trying to do that specific thing. On the other hand something like python may not always be the best tool but it's usually going to sit in the top 3 because of its versatility. I'm a big advocate of knowing multiple languages so you can pick the one that suits your needs the best, but if I were to only have 1 language to work with I'd rather have the versatility of python over SAS.
Don't ask for other people to do your homework. If you are struggling, show an honest effort at what you are trying to do, and ask specific questions that are tripping you up.
You cand find some sample questions that are free for practices test under the Exam Prep site [https://www.sas.com/en\_us/certification/training-exam-preparation.html](https://www.sas.com/en_us/certification/training-exam-preparation.html) Just click on the exam that interest you to get more information. There is also information there if you would like to purchase a practice exam.
SAS doesn‚Äôt really have an object such as arrays unless you‚Äôre in IML. What are you trying to do and what have tried - code or gui?
Code. So the thing is I have a column. I want to put talk the values into an array? Anyway I can achieve this?
Arrays do nothing in SAS, it‚Äôs a shortcut to reference variables, that‚Äôs all.
Exactly. I want to reference variables in my loops. So how do you suggest I do this?
What does your code look like now? An array is just a declaration. https://stats.idre.ucla.edu/sas/seminars/sas-arrays/
I've attached my code in the above comment. Kindly have a look. Also thanks for replying. It's 1am here and I'm stuck. :'(((
Unfortunately without knowing what you're trying to do, it's impossible to help. What are you trying to figure out here? What do you want as output?
The book Predictive Analytics with EM is very good and I highly recommend it.
I want to run a do loop on one of the datasets column. So in the loop I want to reference the variables. How do I achieve this?
Make sure that the data is fully prepped before you do anything. You will spend the bulk of your time doing data prep.
A data step loops automatically, you don't need to loop it. &amp;#x200B; Run this and check it, it will operate on every row in the data set by default. &amp;#x200B; data class; set sashelp.class; length s_desc $20.; if sex='F' then s_desc = 'Female'; else if sex='M' then s_desc = 'Male'; run;
I'm on mobile but Something like: `proc SQL;` `create table want as select census, max(case when 0&lt;EXPOSURE&lt;9) then 1 elso 0 end) as valid from want group by 1; Quit;`
thanks! the code isn't working and unfortunately I don't know sql so I can't troubleshoot it. I appreciate your reply though!
 proc sql; create table want as select census ,max(exposure not in (.,9)) as valid from have group by census order by census ;quit;
thank you thank you thank you :)
data cash\_flow; input account\_num account\_desc $ trans\_key amount tran\_status $ ; cards; 1 P 23 200 SUCCESS 2 P 45 205 SUCCESS 3 P 22 409 FAILURE 4 P 34 343 SUCCESS 1 P 23 343 SUCCESS 1 P 45 506 SUCCESS ; RUN; /\* -------------------------------------------------------------------- Creating a table with required parameters \-------------------------------------------------------------------- \*/ PROC SQl; create table dat1 as select \* from cash\_flow where account\_desc='P' and tran\_status='SUCCESS' and account\_num=1; quit; proc sql; create table want as select amount from dat1; data arraysss; set want; array try\[\*\] \_numeric\_; sum1=0; do i=1 to dim(try); c=0;sum2=0; do j=1 to dim(try); put try\[i\]=; put try\[j\]=; a=abs((try\[i\]-try\[j\])/try\[i\])\*100; if a&lt;5 then sum2=sum2+try\[j\]; put a=; c=sum2; if c&gt;sum1 then sum1=c; &amp;#x200B; end; end; drop i j; threshold=100; if sum1&gt;threshold then alert=1; run;
can you tell me why this isn't working?
Without sql: Data want; set existing; If x = 1-8 then valid = 1; Else valid = 0; Run;
You're going to have a few options. Probably the most likely is clinical trial research or healthcare claims analysis. Starting salary will be $50k-$80k. That'll climb with experience. You'll probably start at a scrappy CRO or very junior at a manufacturer or insurer. You'll be able to climb up into the $125k range with 7-10 years of experience and 1-2 company moves. That's what I've observed anyway. Your mileage may vary
Worked for banks in the UK my whole career (10+years) and SAS has been the tool for all of that time. Its used pretty much universally for all stages of the data/analytics pipeline, from wrangling and feature engineering to simple analysis and more complex model building. I don't do too much coding anymore but still pick it up when I need to. That said we have taken the decision strategically to move everything to one of the big cloud providers, and as such we're all scrambling to pick up the open source tooling such as R or Python - bit of a change for me personally as SAS was the first language I ever learnt and its pretty instinctive now.
Banking is the alternative to Health Care. At a high level it's either modeling or ETL/reporting. Salaries can be all over depending on experience. I'd say starting at $50K+ and going up from there. Whatever the career path, you'll invariably get exposed to other technologies/softwares which help increase your value (domo, tableau, ssrs, etc...) if you learn and incorporate them into your work.
Government Contracting, DoD, City/Local. Private Government Contractors (stock gainz). Healthcare &amp; Research
I love SAS, but you'll need more than SAS to get your career moving. Make sure you also learn either R or Python as well as some basic HTML and JavaScript. &amp;#x200B; That would move you into any data science roles, data science roles that are SAS only are in short supply. However, there's many traditional data analyst/BI roles in banks and insurance companies and health care. Basically, regulated companies that have been working with data for a very, very long time.
You can use substr() to create a new column from characters in a string. SUBSTR(string, start, length ) 12,14,80 substr(email_type_extra,1,2) = 12 substr(email_type_extra,4,2) = 14 substr(email_type_extra,7,2) = 80 If they were all two digit numbers, then that would work well. But some of the email types are three digits. So it will depend on the structure of those numbers in the email_type_extra column. I don't know how many email types there are, but if it wasn't too many, then you could do a brute force method with a long 'case when' statement.
I would suggest using countw(var, ','). Substring games are not fun.
You could also use the scan function if the length of the email type is unknown. It will get you the values between the delimiters.
I may be entirely wrong but my first guess is that those scores which have 0 frequencies may actually be labeled as missing instead of 0. To see if this is true put the option /missing at the end of the TABLES statement in PROC FREQ. if you want to convert the missing into ‚Äò0‚Äô you can use an if-then statement in a DATA step.
I would use a proc tabulate and if necessary specify missing to display as zero. Or if you really want to use a proc freq create a temp variable where you replace missing values with zeros.
You want to use the CROSSLIST option. proc freq data=\_HAVE\_; table \_VAR\_ / crosslist; run;
Thanks. I tried this, but it did not work.
Thanks. The values are actually missing, as in left blank. I believe that if someone selected an answer, it would be included as a level. I ran the missing option as well.
The proc freq is used based on what you have in the dataset. If there is no option in the dataset, there will be no level of the item displayed in the output. You can make empty dummy in the dataset, but the percentage will be wrong. The best way is you adding the option item with 0 result and appending to the frequency output.
Thanks. Is there a data step that I can use to do that? Would you be willing to provide an example. I am not so concerned about the percentage, just the frequency.
Tabulate with a value format will work: &amp;#x200B; proc format; value labls 1=1 2=2 3=3 4=4 5=5 ; &amp;#x200B; proc tabulate missing; class rating/preloadfmt ; format rating labls. ; tables rating, N/printmiss; run;
Sorry, I didn't write out my thought completely enough. I should know better than to respond before my morning coffee. &amp;#x200B; The crosslist option will display counts of all combinations of whatever variables you include in your TABLE statement. So for example (and you can try this code in your SAS session), the following code produces a table with a count of 0 observations from the [SASHELP.CARS](https://SASHELP.CARS) table with a make of Audi and a Model of Hybrid (for example). &amp;#x200B; proc freq [data=sashelp.cars](https://data=sashelp.cars); table make \* type / crosslist; run; &amp;#x200B; For your data, without knowing the structure it's hard to say what you need to do. But what I would do if you want to stick with PROC FREQ is modify your data so that you can have two fields - one for the Likert Question, and maybe one for "Yes" (kind of a dummy variable). Then use the CROSSLIST option as mentioned before. You might need to modify your data a bit, but I think that should work.
Here are some free Enterprise Miner tutorials: [https://video.sas.com/category/videos/sas-enterprise-miner](https://video.sas.com/category/videos/sas-enterprise-miner)
IF you want my two cents, I think the buzz around "data science" is much ado about nothing. In my experience, data scientists are good at making pretty pictures but lack fundamental business knowledge and data manipulation tools. In the vast majority of cases, especially when reviewing applications for analytical positions on my team, I'd prefer someone who has more advanced business or technical knowledge vs someone who has more of a data science background. I work in healthcare claims analysis, if it matters.
SAS ignores anything that's blank on the bottom of the frequency table you might notice his missing equals and a number
Have you a proc report after establishing a counter (i.e., if var1=x then var1tick=1) to count them that way? You could then label each VarTicker in the "define" step.
Thanks !
At [allhomeworkassignments.com](http://allhomeworkassignments.com/index.html), we have a team of online SAS tutors who are highly experienced since they have been in the teaching fraternity for over some decades as well in the research sector. Students usually pay attention to the theory in the technical field and forget that practical aspect which also plays a very intricate part. SAS is mostly a practical course. We can assist both in your practical and theory. Our writing assignment is unique when compared to others since we offer online teaching services to students. We enable them to have direct interaction with our experts. At [allhomeworkassignments.com](http://allhomeworkassignments.com/index.html) you can get the necessary [SAS assignment help](http://allhomeworkassignments.com/statistical-analysis-software/sas-assignment-help.html) that you need to pass and get top grades. We are always here to provide expert and professional help.
ok thanks, using this I can split the columns up :) How do i now count each new value on the same row? Like in this picture (fwiw there is about 90 different email types) https://imgur.com/o1fRuw6
So are you trying to get the count of different email types for each email or the number of emails for a given email type?
It is the difference between effect coding and dummy coding.