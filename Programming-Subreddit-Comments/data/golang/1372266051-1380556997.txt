Yes. I was making a small gamble with this little side project and I wasn't sure until recently whether or not I would be taking a loss. Now that I've got enough orders, I would be open to the idea of doing some sort of split with a non-profit. Any ideas?
This is impressive, and the guarantee of no false positives makes it worth paying attention to. I hope they eventually add some kind of profiling tool called "Go Gadget" so that the command line will be "go gogadget".
I would say giving money to the golang project but it's well backed by Google. Maybe the FSF or similar organization?
Why do you wrap up a string in a struct for Rot13? Instead, why not just type Rot13 string In fact, it's not clear why making a type (at all) and defining Encode as a method on it is preferable to just making func Rot13(string) string. It also seems strange that later you do r13.Str = r13.Encode() This is a slightly jarring mix of direct struct access with method call.
I see what you mean, I think I wanted to reuse the Go tour so much that I mix it up. In the Go tour it is a reader inside the struct so it makes more sense: [Go Tour 60](https://github.com/santiaago/go-samples/blob/master/gotour/gotour_60_rot13/rot13.go) I agree with you I will try to simplify this and let you know, Thanks for the feedback! :)
Very interesting. Thanks for putting this up. Will definitely be following this. Thanks
Probably Tick for regular repeats of work. After/Sleep is a one-off, so your func would have to call itself to repeat this indefinitely, which could after a few weeks or decades result in a stack overflow.
You probably mean an out of memory, or a leak. There is no such thing as a stack overflow in Go, the stack is virtually infinite :) Concerning the question, if your case is running the main program every 15 minutes, cron is probably more adapted to the job (Since it's his main job). I'd probably justify using a Tick if the program already does some other job, like a Http server, and there is some kind of save related thing that run every X time.
 t := time.NewTicker(15 * time.Minute) // or just use the usual for { select {} } idiom of receiving from a channel for now := range t.C { DOWHATEVERTHEFUCK }
Why do you use the Go IsEmailValid method with the if else instead of just returning r.MatchString(email)? func IsEmailValid(email string) bool{ r := regexp.MustCompile(`^[\S]+@[\S]+\.[\S]+$`) return r.MatchString(email) }
You are right, I will update those valid functions, it will be cleaner, thanks!
That makes a certain amount of sense.
Pretty good talk for that amount of time.
Cool, only one thing to say though: go fmt your code ;)
I'd imagine most people there would be interested and welcoming because it is a "conference for curious Rails developers" and not a conference about all things Ruby after all.
I see advantages and disadvantages to both methods. Tick: - Pro: Don't have to wait for program to startup or allocate new memory. - Con: If you have a memory leak somewhere, it will eventually eat all your RAM (and HD thanks to virtual memory!). Cron: - Pro: Don't have to worry about subtle memory leaks; don't have to set up a relauncher in case it crashes. - Con: Have to worry about accidentally launching it twice (if one takes too long to finish); separates the logic into two separate things to keep track of. My advice would be to try both and see which you prefer. Ticking and cronning are both really simple, so it shouldn't be too much trouble to experiment.
Cron is exactly where *NIX users expect to find the "when are things run?" information, which provides clean separation from 'what the running thing does' logic. If it is a straightforward application that runs, does stuff and closes, I would absolutely use cron to manage the timing. That nicely simplifies the program into "doing X" and lets cron manage "when to do X". My rule of thumb is: use cron for any job that doesn't require special management, and will be run once every 5 minutes or less. Examples of "special management" I mean, is expected to be long-running, is reactive (a server), needs process management (monit, god, etc), needs fine grained control over run-times, need to manage channels and/or threads, or want to launch jobs conditionally or dynamically.
Looks really cool Couldn't get this to work on Raring Ringtail, with Go 1.0.3 installed. I get this error go get. package go/format: unrecognized import path "go/format" 
Mirate esto Daniel https://gist.github.com/DrummerHead/5735442
Silent error dropping (calling method with not initialized value) is the last thing I would like to see. Unless, for some very strange reason, you want to implement method both as method and a function. But then, why implement it also as a method anyway? fmt.Println("There's no unicorns around :/") Not *there're no unicorns*?
Personally I prefer a process manager that will start and auto-restart the program, so I would use a tick or sleep, especially because I already have a process manager running... but I think that's more about personal preferences in this case. If you do decide on having the program run forever instead of via cron. The most important thing to consider is difference between `sleep` and `tick`. If you want to make sure that `N` operations are done, but separated by at least `15` minutes, then `time.Sleep(15 * time.Minute)` . On the other hand, if you want to say, make sure a cache is updated at most `once` every `15` minutes, then `time.Ticker`. The ticker will adjust to your responsiveness which will come in handy when your work takes more time than desired.
Btw, it's also useful for debugging: https://code.google.com/p/go/source/browse/src/pkg/bytes/buffer.go?r=fb49e2bb674abda4c1d7ead716bbabee1202dc10#47
So now your "failure" or "error state" is occuring INSIDE ride_the_rainbow() even though it's a failure because you gave it bad data. And it's "silent" in code, effectively. Things like this make me lust for rust and pattern matching and non-nullable types. And in the meantime, I'll use something usable, like Go. :P
Thanks . That makes it clearer
That "About" section is awesome.
Agreed. The linked post seems like a horrible way to mimic what already exists in languages with option types and pattern matching, like Scala and Rust.
Anyone have a chance to try this out?
I mean, the usual go pattern works better than this article's suggestion (But I prefer Rust's)... because you can ignore the error. I guess it just depends on whether the author is suggesting this for internal usage for for other API design...
I would use cron, but my phrasing may have been unclear. Cron for 5 minute or longer intervals, and more likely in-program timing for increments less than that.
I wouldn't call Rust's approach "ignoring the error". It is just deferring it until you need the resulting value, as opposed to checking at each step. The latter makes it much more verbose (what Go does).
Well, I mean, its impossible to ignore the error because its impossible to get into such an error state because of the Option type mechanics. Versus in Go, you can ignore it, or even code around it in such a way that it's suppressed, like with what the authors doing from my perspective.
Try using something like this: ``` map[string]interface{}{ "reasons": []map[string]string{ {"reason": "I Like to Program"}, {"reason": "I like learning how to program"}, }, } ``` Now you can do: ``` {{#reasons}} Because {{reason}} {{/reasons}} ``` If you want, I have written a non-trivial and a quasi-trivial webapp in Go using [mandira](http://jmoiron.github.io/mandira), a fork of mustache that still sorta feels a bit like mustache: * [monet](http://github.com/jmoiron/monet), which is basically [my blog](http://jmoiron.net) * [gowiki](http://github.com/jmoiron/gowiki), a single file wiki i wrote this weekend 
thanks for sharing that, seems useful and I don't know of another way to do this than replicating messages (I'd be glad to know if there is, too). a couple of comments: 1. you should add an example function and a bit of documentation. 2. why limit this to string channels? why not make it *chan interface{}*? 3. spawning a new goroutine for each broadcast message might be problematic in high loads and lots of consumers. I get why you did this, but perhaps you should consider using *select* and buffered channels?
Android and Go are also two of my favorite technologies, but I can't help but feel at some time along the road of using Go to write an Android app one would encounter bumps in the road that wouldn't be there going with straight Java. Having said that, Go working well with Android is one of my tech dreams.
Thanks! Number one and two, I can definitely do. As for number three I don't know how to solve the broadcasting issue 'correctly'. A few competing factors in this are that I want to ensure that every channel gets every message, so skipping channels that are full would break that. I want channels that are able to consume, to not be blocked by a full channel elsewhere in the system. (subject to change) I would like the order of items coming in to be the order the receiving channels get them. &gt; This one I don't believe I currently have because of multiple go routines waiting to put data into a full channel, when something is consumed it's not defined which waiting go routine would wake up first. Perhaps a better solution for this would be to let everything get held up by a blocked channel? I say that as it's the extension of the concept that putting something into a full channel will block. That would also solve the ordering problem. If you (or anyone reading this comment) have some ideas of ways to solve the broadcasting to a slice/array of channels I'd love to hear it!
I like the look of this mandira I'm going to have to play with it. I've been maintaing a fork of mustache w/ some extensions for lambda sections for my own projects. The 'filters' concept might actually be able to replicate what I'm using lambda for though.
If you want to use mustache and pass in a struct, you need to make the variables inside of it public. Change name to Name and reasons to Reasons. If they are not accessible outside of the struct itself there is no way for mustache to pull the data. An alternative if you do want to keep them private is to define a function on the myMustache struct that acts as a getter to the name and reasons variables. (idiomatically the name of the getter should be Name() in this case) Mustache will call the function automatically and get the value to be used in the template.
Author here, happy to answer any questions. One of the features of ngrok that I thought was pretty cool while building it is that it runs a real-time web application completely locally on a user's machine, thanks to net/http and go-websocket. I'm not sure any other language or framework could make that work so easily. I have a bunch of other thoughts on things learned while building it that I'll share in a future blog post.
This is quite handy if you want some quick feedback on your ongoing work. Thanks!
I'd love for it to get some more use. When I wrote it I was intent on maintaining a mustache feel, and I wanted to write a JavaScript version as well. But client-side scripting has really moved on from this in the meantime, and Go could use a template language with a bit more flexibility (something more like Jinja), so I'm open to extending or altering it; namely, when writing the afore mentioned gowiki recently, I was having second thoughts about not adding dot or [] notation for accessing sub-namespaces without having to open up a block. Once you have conditional logic `{{?if ...}}`, it's nice to be able to do like: `{{?if user.LoggedIn }}...{{/if}}` rather than: `{{#user}}{{?if LoggedIn}} ... {{/if}}{{/#user}}` If you do end up trying out Mandira please let me know what you think of it!
This is totally possible. Especially since Android has been build with a Java environment, and Go is so radically different. I did see however that their is a Mirror API (Google Glass) for Go.
Haha thanks
Mandira looks a lot like Jinja2. Its nice. For the moment, I'm sticking with Mustache, because I have some experience with it. I'm trying to keep things simple by not having to learn to many thing at the same time. Still, very nice project. Now, I took the code you suggested, and other stuff to get it to work. Here is the resulting code: type Me struct { Name map[string]string Reasons map[string]interface{} } func main() { me := &amp;Me{} me.Name = map[string]string{"name" : "phpnoob"} me.Reasons = map[string]interface{}{ "reasons": []map[string]string{ {"reason": "I Like to Program"}, {"reason": "I like learning how to program"}, }, } template := mustache.RenderFile("practice.html.mustache", me.Name, me.Reasons) fmt.Println(template) } It works, but it created some questions in my head. 1. I cannot figure out the *interface{}* in the *map[string]interface{}* part. What does that do? 2. Given how I'm using MySQL as the DB for the simple project, how do I pass the results from the DB to the struct? As in how do I put the resulting rows in the me.Reasons part. Also, can I PM with questions? Thanks a lot!
I did not know I had to have them start with a capital letter. I'm new to structs (and Go in general) so that flew over my head. Thanks.
I can't really comment on usage, but I spent like 20 minutes reading the code. Loved every minute of it. (:
You're essentially talking messaging patterns. I don't know if there are any libraries out that do this in Go. Your one to many is usually referred to as 'publish-subscribe', the AddOutputChan function being the subscribe. Your many to one is less common but often referred to as 'fan-in'. Enterprise Integration Patterns discusses a lot of messaging patterns. It's a bit heavy weight though. Reading the table of contents is interesting. http://www.eaipatterns.com/toc.html I really like ZeroMQ when it comes to designing messaging systems. It pulls together some simple components to allow you to build really quite complex architectures. Check out 0mq messaging patterns. http://fireinside.me/post/3551747763/zeromq-messaging-patterns 
This is so amazingly cool. Are there other alternatives you have seen or is this something new? How long did this take you to create? It is very well done.
...and consts, types and methods ;)
I just tried it and it's pretty cool. It's a bit slow though. From here (Copenhagen, Denmark) it adds about two seconds per request. 
camlistore.org has been updated with a video.
1. Read "Effective Go", particularly the part [on interfaces](http://golang.org/doc/effective_go.html#interfaces_and_types). The short story is that an `interface` is a way of describing what methods are defined on a type (sometimes these are structs, but you can do for instance `type ZipCode int` and define methods on that). A struct *implements* that interface if it defines all the methods in that interface. `interface{}` is called the *empty interface*; every type satisfies that interface, since it doesn't specify any methods to implement. So it's a way of accepting any type. 2. I [wrote a blog post](http://jmoiron.net/blog/gos-database-sql/) about `database/sql` which covers this. If you're new to go and using DBs I highly suggest you read it, it's sort of the "missing manual" and covers memory &amp; connection allocation in some detail. Most DB interfaces won't scan into `map[string]interface{}`, but for instance if you had this: type Person struct { Id int Name string Email string } You could scan into it like this: db := sql.Open(...) rows, err := db.Query("SELECT id, name, email FROM user") if err != nil { log.Fatal(err) } person := Person{} for rows.Next() { rows.Scan(&amp;person.Id, &amp;person.Name, &amp;person.Email) // now `person` has those fields } You can use other libraries, like (shameless plug) [sqlx](http://github.com/jmoiron/sqlx) to achieve this pattern much more simply: db := sqlx.Open(...) // pre-allocate some people people := make([]Person, 0, 10) db.Select(&amp;people, "SELECT * FROM user") Feel free to PM me questions or ask them on IRC in #go-nuts.
Great! This clarified a lot of points I had, mainly the "why" ones :P
Note: currently only supports setting the desktop wallpaper on OSX. Linux support requires more research as there are a gazillion different ways to do it
I have put some work towards getting egl and glfw3 working with Go. http://github.com/mortdeus/egles 
Thanks for the feedback. Strangely enough, I hadn't even considered that. Perhaps I will find a cheap way to host other copies around the world to minimize latency.
Thanks! There are a few alternatives that have different subsets of ngrok's featureset. I've been working on an off on this for a few months, it's hard to estimate the exact amount of time since it's mostly been a side project.
I'm pretty sure there is no way to do it that would work across the board, but you may want to look into [wmsetbg](http://linux.die.net/man/1/wmsetbg) and [X11-Wallpaper](https://github.com/richardjharris/X11-Wallpaper).
&gt; MAYBE cut Some of them I plan a little bit more in advance and have nice slides for. Other ones, it was just kind of like, “Well, we need someone to talk tonight.” I’m like, “All right, well I can blabber on about this for 20 minutes,” and I make some notes in a text file and I go with that. But when I do that I make it clear like, “Hey, I just these 20 minutes ago, so let’s not be too critical.” Is "Maybe cut" a leftover editing note that should have been removed?
Okay, I merged in remogatto's changes into egles. 
...on a mac.
especially since it's the editor that has the default set to 8, not the language. You could have single space tabs if you really want.
Neat project! Though I don't see why Set needs to be a struct instead of directly aliasing the map type (which would slightly simplify your Set methods) but that's just cosmetics, the way it is currently certainly doesn't pose a real problem per-se.
For a general-purpose set, you want to use a map[X]struct{} rather than a map[X]bool, because an empty struct takes up 0 bytes while a bool takes up 1 byte. I often do use a map[X]bool where the size doesn't really matter, because it's convenient to be able to say: if s["blah"] { // do something if "blah" is in the set s } (this works because the default value for bool is false, so if an item is not in the map then you get false) -- but you aren't actually making use of this shortcut anyway (you do if _, found := s[x]). Additionally, there's no reason you need a 1-element struct -- you can simply make a type alias: type Set map[interface{}]bool Finally, your String() method can be greatly simplified: items := make([]string, 0, len(set.set)) for key := range set.set { items = append(items, fmt.Sprintf("%v", key)) } return fmt.Sprintf("Set{%s}", strings.Join(items, ", ")) Hope this helps.
Really lazy handling of the response body. Not impressed. Also Mac only. 
Yeah, but I really don't like tabs...
Is there a project like this for a simple but flexible dict (aka associative array or hash table)? map[string]interface{} is a pain in the ass in every way possible.
This is exactly the kind of feedback I can appreciate. Thank your recommendations. I already modified the String() method, which I previously did try to make work similarly, but for some reason I couldn't get it to cooperate across types. Also, I like the idea of using a map[X]struct{} instead, but what I'm not yet quite convinced of is the aliasing like: type Set map[X]struct{} and the reason being is that I like having the internal implementation of my Set be flexible. For example, if in the future, I implement it internally using something other than a map[X]struct{} it's now harder to change it. Coming from other languages such as C# and even Python I have a tendency to think this way but I understand it may not be the Go way. I'm still open. :)
Hey, no problem. Why would using a type alias make the internal implementation less flexible? You could still change the implementation completely without affecting the public API, naturally.
I updated the code to reflect this. Thanks for pointing this out, I'm all for saving some CPU cycles and making the world a little greener. :)
Rob Pike has a good talk about concurrency patterns in Go, which discusses one fan-in method: http://talks.golang.org/2012/concurrency.slide#26 
http://godoc.org/github.com/deckarep/golang-set Empty godoc but pretty intuitive anyway.
You could change difference to only a single iteration if I'm not mistaken: func (set *Set) Difference(other *Set) *Set { if set != nil &amp;&amp; other != nil { differencedSet := NewSet() for key, _ := range set.set { if !other.Contains(key) { differencedSet.Add(key) } } return differencedSet } return nil }
I have written something very similar a year ago: https://github.com/agonopol/goset/blob/master/set.go 
What do you recommend ? Is there a more idiomatic way of handling this ?
Good catch. The code's been updated to reflect this.
The response body should be streamed to the destination file using io.Copy. If an error occurs, the destination file is closed and removed.
Awesome, I made the code change to reflect this. Keep it coming.
This is largely dependent on the web framework that you are going to use with go isn't it? Are you using Google App Engine? web.go? Gorilla? etc.
Hmm I'm not completely sure I see the use-case .. in python you certainly can put anything in the dict but it's just as painful to do anything with the values if they're of different types . And if they're not different types then we're back to square one: why is there a need for interface 
Any good guides on integrating with Go?
Shameless plug: I wrote a mini package and an example: https://github.com/sauerbraten/persona
For completeness' sake, I tried out my weird storing-id-with-object approach: http://play.golang.org/p/Fn1XJTrvBv as well as the interface{} approach: http://play.golang.org/p/_Y1dTSJM1g . I was sleepy when I wrote my last comment; unsafe isn't necessary to recover the types from the stored type id approach...but that approach ends up looking like a messier, buggier interface{} approach anyway. Maybe I'm missing something, but switching on the interface's type doesn't seem too painful.
I wrote this a while back. It currently only works with postgres, but it shouldn't be hard to support other drivers given golang's sql package. Feel free to contribute: https://github.com/golibs/um
I'll definitely be checking this out for a command line app I had in mind. I wonder though. Why no binaries. Seems like it would be easy: http://dave.cheney.net/2012/09/08/an-introduction-to-cross-compilation-with-go
Depends... I could just copy and paste two files (user_management.go and cookie_handling.go) from that example, copy the routes in server.go, and copy the js directory to get a working prototype with a new project. But then again, it was both my code... In case you have questions you can always hit me up in #go-nuts on freenode, I'm sauerbraten.
There's no reason for using pointers to Set. A map already is a reference type. Then you probably want to rename NewSet to MakeSet - or simply Make, so it can be used as mapset.Make(). It could take initial items as varargs. With that you could also write table-driven tests. The String method with the extra allocated string slice and the Join call is short, but inefficient for large sets. I'd fmt.Fprint the items to a bytes.Buffer and call String() at the end.
I think there might be some mis-understanding. I didn't mean storing a type id. I meant using `map[string]MyType` .. I cleaned up your interface example a little http://play.golang.org/p/Qq5tGduGeU . If you're switching on a single type, you can use `v := var.(type)` and inside the relevant block, v will be a variable with that type. So you don't need to do a type assertion. Taking this example, I identified the goal is to print the area of different shapes. For that I see the common function as `Area` so I define my type `interface { Area() float32 }`. Now my dict is simply: `map[string]Shape`. I chose the name shape for simplicity (it makes more sense than Areaerererer). Now you don't even need to know anything about a rectangle or circle to be able to print its area. For all you know, the value is actually a `WobblyBicycleWeel` that just embeds Circle. You could go a step further and add a `Name() string` method if the name is important edit: and the link http://play.golang.org/p/Zn7TjiFQik
That's a good update on the switching thing, thanks. Yeah, I was trying to think of ways that having multiple non-homogeneous types would be useful. As I was writing it, especially using the word "interface" so many times, it felt wrong! It seems like the only time it'd be useful was when the stored types would be so different it wouldn't make sense to define a common interface between everything that it's storing. Maybe if you wanted to store every bit of state data for a game in a single dictionary. In here are images, sounds, structs defining various game entities, etc. This seems like a bad way to do things, but even then you'd presumably know what you were pulling out each time and could type assert it without issue. Heh, I give up. map[string]interface{} seems pretty good to me. :)
Note that neither the Gorilla toolkit (it's not really a framework) nor web.go have any auth built in. Both are more like "shims" on top of net/http and friends. 
This is actually a really great project. Since Go doesn't need a centralized clearing house like NPM or Maven, all it really needs is a great search engine. I am a little nervous that it is a one man shop / tool right now. But it has a great licence, and once he sets up the ability to mirror and sync, it could become a staple of the go community with lots of little mirrors running all over the place. 
Thank god for this, the only profiling I could find through Google was a 2011 blog post that was still using make files.
Profiling is all done in the standard libraries, this is only a convenience wrapper around it to simplify turning on and off certain functionalities. It looks useful if you've been using the standard library directly and find yourself writing a lot of the same code for multiple binaries.
When I was researching this, I found https://github.com/jmcvetta/o2pro and https://github.com/evalgo/evoauth . Not sure of actual state of either of them, though, and since this wasn't required for what I needed I moved on to other things and didn't investigate further.
cmd.ProcessState.Success()
Spectacular. :) I love this style of discovery/education.
Works great for me.
There isn't a portable way for all operating systems, so it wasn't included in the standard library. Using reflect like you did for Unix &amp; Windows works. 
that routes config format gave me goosebumps
It made me feel awkward for a second, too but then again, what else do you want for the basics? I think, it's also possible to define new routes at runtime through the [api](http://robfig.github.io/revel/docs/godoc/router.html#NewRoute) and [modules](http://robfig.github.io/revel/manual/modules.html) can include their own rules for more DRY.
Hmmm.... So I do the "go get" command to get revel and go tells me I need mercurial? []-&gt; go get github.com/robfig/revel go: missing Mercurial command. See http://golang.org/s/gogetcmd package code.google.com/p/go.net/websocket: exec: "hg": executable file not found in $PATH Edit: I missed this part: Both Git and Mercurial are required to allow go get to clone various dependencies. Why in the world?!? Both?
Goosebumps can be a good thing too. It is unclear how the op meant it.
Because like you can read on the message you posted, one of the dependencies - code.google.com/p/go.net/websocket - uses mercurial, and go get needs hg to grab it.
Yes because I want to install every DCVS. Brilliant.
goosebumps good. cringing bad.
I've messed with Revel before. It really like a lot of thing. I don't like that there isn't a standard (for lack of a better term) ORM, like ActiveRecord for Rails. Has anyone worked on hooking gorp into revel?
I think the creators have taken a lot of good ideas from mature frameworks like play and rails. Has me excited
Yep. If you look at the booking sample, it uses gorp. Check it out for how it's done.
You need the latest version of Go. Use 1.1 or later. They included several fixes and improvements that affects RPI. Arch Linux ARM has the latest versions of everything. 
I'm still not sure if a deeply integrated ORM/db binding is a good thing. Don't you loose a lot of database features if you abstract them away? [gosexy](https://github.com/gosexy/db) for instance abstracts over sql and nosql together.. i'm really not sure why one would want that.. [revmgo](https://github.com/jgraham909/revmgo/) seems like a much clearer approach (towards mongo/nosql in this case), forcing you to think in the way the db works that you use, but that's just me.
_ = fmt.Printf or similar. It's not described anywhere, but lets you avoid having to clean up the import temporarily.
It's never a big deal for me. I like this aspect of the compiler. If it's a big deal for you, you might want to check out [goimports](https://github.com/bradfitz/goimports), which is a tool from bradfitz which is a fork of `go fmt` but also attempts to comment/uncomment used/unused imports.
I agree that Document Based and SQLike databases are so different that they should different database abstractions. I think I'd be able to handle the integration now, it was just a barrier to entry for an innaguaral project I had in mind. 
Totally. I immediately think of something like rails admin. Where standard routes are created based on what models exist and what members they have. Obviously it'll have to be reimagined, but I think the concept has proven successful.
Just going to throw this tip out there in case it helps someone: If you are running Sublime Text 2 with GoSublime, you can press ctrl+. followed by ctrl+p (or cmd on mac) and it will bring up a helper that add/removes imports. No scrolling or cursor movement required. And of course like anything in SB2 you can re-bind those keys to something else if desired.
I introduced a bug in it recently and need to fix it up, but so far I'm loving it. I don't really think about imports anymore. I just write code and on save it does the right thing.
This can be solved by tooling. Have your editor correctly configured to remove unused imports (and gofmt) on save. Have a shortcut to add imports. Use some kind of fly make. Emacs: http://honnef.co/posts/2013/03/writing_go_in_emacs/ Vim...maybe look around. I use vim somewhat and don't know what the state of the art is.
The only time I've needed to leave an "unused" import, was for a database driver. And I supressed the warning like import { _ "github.com/mattn/go-sqlite3" }
I just found this through a Google search. I've been thinking about starting a project like this myself. Thanks for posting!
I noticed you're generating the name of the struct in plural (i.e. Users instead of User). Is this intentional?
Any plans of including this feature on the core tooling?
Yeah, I have some experience w/ both as well but naming the structs in plural feels weird, since each struct allocation will represent one record :) I'd rename the table to singular and change the ActiveRecord class, manually setting the table name there or even configuring AR using the pluralize_table_names option. Anyway, just some constructive feedback. The project looks interesting.
I see your point. Naming is kind of a dilemma. I will try to add a feature Singularize option. Thanks for the kind words.
Have you looked at Go-again?
&gt; I'm used to leaving things temporarily as I build new features, debug, and generally proceed with building my application Stop doing that. Think, then write.
Hmmm. All of my models in Rails apps are singular (ie User). It's true that the table name is plural, but the model name is not and I would expect the struct to match.
The only problem of Google Go is its name :( Could you please provide a link? Googling shows lots of irrelevant results.
https://github.com/rcrowley/goagain?source=cc
Thank you. It looks like thats what I'm looking for.
This looks very promising, good documentation. Same guy that made vagrant.
Blog author here. Thanks for the feedback! More content like this will definitely be coming down the pipe. Lots of great discovery lately happening in my time with Go
Thanks for the slides. Sample project would be great! Is the "helpers.Context" concept something Microco.sm built internally or from a public package?
Some lines in blue in the slides look like links, should be links, but aren't links (at least they aren't clickable). Can we see the URL somehow ?
The links don't work in the embedded version, but if you download the PDF (link on the right) they're fine.
Thanks, it works. As I spent long seconds looking for the link : it's on the right of the page, grey over grey.
Apart from being related to logging. I have no idea what this does.
I noticed this project the other day. It appears to be an internal Google logging standard.
It's a logging package with more features than the builtin log package in Go. Specifically it has various verbosity logging levels. It's interesting because it uses booleans cleverly to avoid the cost of evaluating the args to a logging function if that verbosity level is not triggered. In C++ this would be accomplished with a macro. In Go you have to do it differently. If you want to see how it works look at the Verbose type in https://github.com/golang/glog/blob/master/glog.go#L871
Interesting. You know what they say: every programmer has to write a Lisp interpreter at some point. In C, I've integrated with CPython before to script actors in a toy game engine. Since cgo can interop with CPython one might get some mileage out of the same approach under Go. Would be a cool idea as well, unless calling into Go from C is still as difficult as it was when I tried it the last time.
See also Paren: A Lisp for C++ https://bitbucket.org/ktg/paren
&gt; every programmer has to write a Lisp interpreter at some point. Nope, just the beginners.
This is a really clean little implementation. If you're ever wondered what a simple interpreter looks like, this is a great example. My guess is the performance probably isn't what you want for real-world usage, but it's a cool learning experience.
[Lua](http://www.lua.org) is my current favorite scripting language, and it was designed for and works well with C. I was discussing with a friend that it would be nice to have a scripting language designed specifically for Go that integrates as tightly. Support for channels and goroutines would be a high priority. The use of channels would be a primary means of communicating with the statically compiled parts of the Go application. We concluded the best approach would be to just write a Go interpereter. There's been a couple preliminary efforts in this direction, but nothing really usable yet. Go is not a huge language (compared to some) but writing a full interpereter is definitely not a weekend project. One of these days...
&gt; This is a really clean little implementation. In my experience, Gustavo Niemeyer's projects tend to be [great examples of clean, readable code](http://bazaar.launchpad.net/+branch/pipe/v2/view/head:/pipe.go). At least I find them very pleasing to read.
I chose to write an awk interpreter instead. Lisp gives me the creeps. 
Your Jedi mind tricks won't work on me. Sometimes you do want some kind of dynamic language. Something that doesn't need to be compiled. One of the original uses for Lua was for configuration files. It is nice using a programming language for that. For Go, I can imagine uses, such as a game engine (scripting events), plugin architecture (like wireshark protocol interpreters), etc.. Lua works well for that kind of stuff because it is easy to sandbox too. A Go intepreter would be similar, for example, you might only have fmt.Sprint and not fmt.Print because you want to disallow IO from the script.
Did you actually post to the mailing list about your concerns? One dude on twitter hardly a consensus makes.
Be sure to read the comments. The Go devs respond with a detailed explanation.
Hah, no.
There's something wonderfully apropos about the first program in a new language being a piece of a Lisp implementation.
[Greenspun's tenth rule](http://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule)
every programming language evolves to the point where it can implement scheme.
Hey, I'm the author of this package. When I work on a Go project I spend many time on things that really don't matter, like the README file, the license, the right and most idiomatic files organization... This is why I thought I'd love to have a way to bring all this work by default and focus only on coding. I hope people here could use it and enjoy it, reviews or comments would be really appreciated, since I know there're TONES of things to improve in this code, beside typical things to do. I'll take all criticism, but please be kind!
great idea. I wish I would have seen this before I started working on my current project.
so, what's your current project? we might exchange some ideas :)
My project is a simple command line utility (time tracker). It's the first non trivial go code I've written, so there were a lot of growing pains I think this tool could have saved me. https://github.com/rharriso/waid
you can still try it, gobi can do the job on existing projects as long as the endpoint does not exist, you just run, for instance, $ gobi pkg waid/entry_copy and all files you don't have yet will be created, then you can just delete the entry_copy folder.
I created https://github.com/tanema/gob for GoPath and Go project management with some tools for faster development. I like a lot of the things you are doing here that I might pull into my own project. I like the idea of creating boilerplate templates. I don't know how I would handle pkg development with the GoPath Management though. Any ways, good job I really like it!
I'll give it a shot, Thanks!
Ha, 41368 lines of "C" code (from the distributed headers) and 8598 lines of Go code. That royally throws off Github's language statistics (90% &amp; 9.8% respectively.) 
Sooo what are we doing now? Still suffering? That said, I'm surprised noone has mentioned npm, which is exactly what most propositions in this document are.
Blog author here. Had a ton of headaches distributing command line apps in Ruby, so far I am loving Go for CLI. Feedback is definitely welcome! Remember to star https://github.com/codegangsta/cli :) 
Thanks for posting this. I especially enjoy the License templates!
My packaging works like this: * I create a directory (say 'ext') for all my go language dependencies for an app. * I clone or copy all dependencies into subfolders of that 'ext' directory. Whenever I want to update that dependency, I can do a 'git pull' or the hg, svn, bzr equivalent. * Under 'ext', I make a .gitignore so all hg, git, svn, etc repo data is ignored. Then I make that whole 'ext' a git repo and push it to github. Now in my app I refer to any dependency as github.com/foo/ext/... This allows me to have complete control of the versions of each dependency. It also lets me use just one distributed version control like git on additional computers instead of always having to install hg, git, bzr, or whatever dvcs are used by dependencies. 
This looks like an awesome solution for command line apps, I'll have to try it out ;)
Another thing which I think strengthens your point even more is that go binaries are [statically linked](http://golang.org/doc/faq#Why_is_my_trivial_program_such_a_large_binary). It can sometimes be tricky to distribute dynamically-linked binaries for almost the same reason that Ruby can be difficult to distribute, you have to distribute other files. Go binaries are really standalone.
One of the biggest things I love about it. I've actually replaced several hacktastic bash scripts with small go applications. This definitely looks like something I may try out for my next one.
It's like Java's dream, write once, run anywhere lol
I'm actually pretty satisfied with the standard lib implementation of flags, but the documentation aspect looks interesting I'll have to use it on my cli util, and see if it saves me some space/time. 
You can use "gracehttp" from https://github.com/daaku/go.grace/ to get the same graceful restart.
Often, you test whether a set != nil. This seems to always be true, as even the empty set != nil. Why do you do that?
Great summary - and it pretty much matches my experiences using Go at my own startup. I think Go is a great language already but I'm definitely looking forward to seeing some improvements around the messy edges which still aren't quite right. Incidentally I think one of his complaints has already been addressed: the new glog package provides a more capable logging system than the default one. I'm finding it very good. 
I can see that. But that's mostly because x86 is almost the same as "everywhere" nowadays.
My main beef with Go is the lack of inheritance. I've found that 95+% of the time, interfaces are a much better fit, but those few times when it really fits I really miss it. I haven't really felt the need for generic types though, which really surprises me, especially since I love the template system in D. I've also found the standard lib more than sufficient, but maybe I don't use RB-Trees as often as the author.
You can use embedding instead of inheritance sometimes. 
Same as the JVM, run's on any platform with an implementation. Point taken though. There is an arm implementation, however the go site isn't as confident. http://golang.org/doc/install/source
I do that where possible, but sometimes it doesn't work. [example](http://play.golang.org/p/tHAI-dfyvl). The intent here is to override "DoMoreStuff". With polymorphism, I can override virtual functions, but in Go, the closest approximation would be function pointers, but those don't satisfy interfaces, which is completely lame. In my particular case, DoStuff is relatively complex, and DoMoreStuff isn't always overridden. The idea here is to make a pluggable system. I've achieved this by embedding the child in the parent and chaining function calls. To each child function call, I pass the parent, so the child can call back into the parent. Pretty lame, but it gets the job done.
I contributed a few small fixes for Go, most notably making the random number generation avoid mutexes.
Alright, I'll bite. How is (or will) Sparkle (be) different than... [Revel](http://robfig.github.io/revel/) [Goshire](https://github.com/trendrr/goshire) [Falcore](https://github.com/ngmoco/falcore) [WebGo](https://github.com/hoisie/web) [Go-Start](https://github.com/ungerik/go-start)
For your first point what should he have done there? make([]*Room, 0, 100) instead? Or use the index to get the room?
Apparently, it will be the preferred web framework for gay vampires. :)
This comment was unexpected, and I'm embarrassed to say it made me laugh out loud.
I was profiling it and noticed that the range was slow, but I couldn't figure out why. Thanks for that.
Well that readme is just excellent.
An array of objects plus pointers uses more memory. Taking the address is better.
Don't the bang patterns make it more strict?
Even made me laugh :)
As of yet, it may not be all that different. It seems I didn't research web Go web frameworks very well before I started my website, as I only learnt of some of these this last week. As to why Sparkle exists it was just born of me packaging some common abstractions I had come up with. So far it's extremely light weight by itself, but that's because I'm only implementing features as the website I'm building with it dictates them.
I love the fact this is a small package that does one thing well. More Go packages should be designed like this instead of swinging for the fence.
You definitely need a couple of examples of how to implement handlers/etc. - otherwise it's hard to compare to what's out there. 
"One thing well" is definitely a skill I've been trying to work on. It's hard to keep myself from wanting to take every cool extension idea and edge case and try to pack it in to a tool from the get-go.
This is reasonable. It doesn't let your dependencies declare their dependent versions which avoids the whole 'solve for this vague graph' problem. 
The only example I have at the moment is the Hello World example: https://github.com/sekhat/sparkle/wiki/Hello-World
you see it a lot from people coming from a rails background and it's more common in languages/platforms (looking at node here too) still in their infancy. it's easy to look at rails as one huge package that does everything for you when really it just ties a plethora of smaller, more manageable packages together.
I wrote and I am still working on https://github.com/tanema/gob as a project management/gopath management it is not perfect but I am trying to figure out the best way
Dear god, there's stuff out there still using CVS?
This was written as part of a web scraper that makes 100s of requests per second. All the connection pooling and other options of the default library's transport class were tending to get a bit bogged down. Thought it could be useful to someone else. I'm really impressed with how easy it was to swap out this part of the standard library with my own code, while still using all the other parts of the http library.
Nice. I don't think most people who are just playing with Go will have any idea how important this is unless they've tried to write some sort of spider/fetcher. I've been using Matt Reiferson's httpclient library: https://github.com/mreiferson/go-httpclient but yours seems a bit more straight forward (which I prefer) - I can't wait to try it out.
Looks sexy. Lord knows that the original http library gave me headaches with all its HTTP proxy stuff.
I didn't fully get the reasoning behind needing local disk time in the C++ version. I think Brad Fitzpatrick assumed some familiarity with the caching mechanisms in use?
I may be wrong but I believe it was just an old server that hadn't been updated to use the cluster file system. My assumption would be that the old standard was to use disk. But, because "cluster file systems own disk time on your machine, not you" that was no longer an option. Feel free to correct me if I'm wrong.
A lot of what you might otherwise do with mocks in a different language, you can do with interfaces.
Is it possible to check for parameters called on the interface? Can you run the comparison inside the interface as long as the test function is in the stack?
Essentially yes, and yes. You can write your own object to implement any interface you want and track whatever information you want to. A hasty example: type mockWriteSeeker struct { history [][]interface{} t *testing.T } func (m *mockWriteSeeker) Seek(offset int64, whence int) (int64, error) { if whence != 0 { m.t.Fatal("Unexpected whence (!= 0): ", whence) } m.history = append(m.history, []interface{}{"Seek", offset, whence}) return offset, nil } func (m *mockWriteSeeker) Write(p []byte) (int, error) { dup := make([]byte, len(p)) copy(dup, p) m.history = append(m.history, []interface{}{"Write", dup}) return len(p), nil } func TestMyFuncCallsSeekThenWrite(t *testing.T) { m := mockWriteSeeker{t: t} MyFunc(&amp;m, 123, "foo") expected := [][]interface{}{ {"Seek", int64(123), 0}, {"Write", []byte("foo")}} if !reflect.DeepEqual(expected, m.history) { t.Errorf("MyFunc failed to make expected calls: %#v != %#v", m.history, expected) } } I certainly don't mean for this to be a general pattern to follow, though. I feel too much reliance on the mocking model makes for confusing tests which often don't help anybody very much. So, generally, if you can find a more succinct way of determining that the end result happened, you shouldn't worry quite as much about exactly how you get there. I've seen too many unit tests that essentially ensure, line-by-line, that exactly the current version of the function written executes as it surely will. It's not very interesting, and might actually hide bugs if you're too busy testing the code you've written than the desired output. But, there are certainly times when something like this might be helpful. edit: formatting
I just realized that https://github.com/golang/groupcache is written by the person who wrote memcached (bradfitz).
See [this article](http://norvig.com/ngrams/ch14.pdf) for the original.
It may be a little better to accept io.Reader instead of doing your own Open()s
I did write this. Excellent catch on the request object. I will put a fix in today. Thanks for bringing that to my attention. As for the keeping track of the incoming/outgoing requests, I typically pass in a "reqId" that is generated on the client side, and then included it with the response. I left this out so anyone could roll their own implementation, though I could include this methodology. Do you have another approach?
[good idea](https://github.com/llimllib/segment/commit/2102356bb6374ed8c5f73f772019e00c512cadb3), many thanks
~~I think you are mistaken~~. He wrote gomemcache (https://github.com/bradfitz/gomemcache), a popular library for go / memcached bindings, ~~but not memcache itself.~~ Edit: no, nevermind. I am wrong, he's also a creator of memcached.
Written by the guy who wrote memcached (the original non c one)
If you're sorting your outputs at a higher level, that'll get you part of the way there. The net/rpc library does essentially that by tracking the sequence number for each request and response. However, I'd be concerned about having multiple goroutines attempting to "Write" to the same Conn at the same time. There are no guarantees that large, concurrent writes to an outside resource like a file or socket might not get mixed together.
You could bounce all your app servers to clear *all* the caches, but what if you want to clear just one particular item? You're right, networking errors complicate things. A broadcast message would likely be implemented as an RPC call to each and every peer - if one peer fails to acknowledge, we would have to report that the cache-clear failed (maybe after a short wait and a retry for the bad peer). If we are only doing this occasionally / by-hand as needed, such overhead is entirely acceptable.
I ran it through a space profiler. It's definitely generating all those ints into a vector and then accessing them in a rather strange way in genRooms. This could have been done better with a State monad (which I'm playing around with right now). 
I put in a fix for the client race condition. Take look if you have a moment. I'm going to add the reqId strategy next. What suggestions do you have for handling concurrent writes to net.Conn? A queuing system?
&gt; you need to purge old / invalid cache entries that were created by the buggy code Groupcache is a library that lives in your program binary, so if you push out a bug fix you're also going to restart your groupcache nodes.
Unfortunately...
ah good point. :/
This doesn't make sense. A function's private- or public-ness is orthogonal to its suitability for unit testing. You can test unexported functions if you keep your foo_test.go files in the same package.
net.Conn, at least, is goroutine-safe.
Currently second of "Trending Repos" on github.com/explore. Pretty cool to see a Go library there.
Why not use the flag package, have the user be able to provide those values on invocation?
This is really nifty. For other beginners like myself wanting a more in-depth explanation of how refer, recover, and panic can be used to pull this off, check out: http://blog.golang.org/defer-panic-and-recover
Would be nice to see field tag access and though maybe controversial, the way you get an unexported fields.
Author here. I specifically did not include field tags as the scope of this document is "thing you can do in Go" → "how to do it with reflect" and you can only get struct tags with reflect (well, or go/ast) You get unexported fields exactly the same way you get exported fields, you just can't set them.
 Agreed. Flag is quite useful for handling arguments. Here's a sample from one of my projects: https://github.com/dmuth/cat-crawler/blob/master/args.go 
Alternatively, use JSON, create a type Config struct { } with the values you want and unmarshal your config file into the struct inside init().
I've always felt that the flags are a one off invocation. Writing to a config file each time you run the application based on the flags you provide seems like a side effect for me. Or I suppose you could add an additional flag for persisting the settings you've provided, at least to make it expicit i.e. program -h myhost -p 3948 -savesettings
&gt; Odd that they make no mention of this explicitly in the docs. http://golang.org/pkg/net/#Conn &gt; Multiple goroutines may invoke methods on a Conn simultaneously.
 debug_level := flag.String("debug-level", "info", "Set the debug level") debug_level _ ಠ_ಠ
Thanks. I was sure I had tried this exact solution before, but apparently not then! Works as intended.
@ptrb: Really good to know. Thanks for following up. @flambasted, thanks for bringing to my attention os.File not being goroutine safe as well. 
I see, just not where I was looking. Thanks. :)
Scratching my own itch. Maybe someone will find it useful too.
This is the method I use, it's nice because sometimes I need to run multiple instances of the same app, and I can config the port in the .json file easily along with any other info I need to pass to the program.
 It's my own variation of [JavaDoc](http://en.wikipedia.org/wiki/Javadoc). Probably not 100% machine-readable, but I use the same format across all code that I write in all languages for consistency and sanity reasons. (The only exception is that if an employer requires a different format) 
I use the flag package only to specify which config you wish to edit, because the program does more than reads and writes configs, so I felt it's more convenient to use this way :)
I had just started learning Go about a week ago. So, mayhaps I'm wrong but his reasoning behind dependencies seems completely false to me? I thought go get magically fetches all the imported packages? It seems like perhaps there wasn't enough research on Go on the authors part? I just can't buy some of the complaints here.
My general methodology is provide a setting hierarchy. If flags are provided, use those, fall through to config then fall through to reasonable defaults where appropriate.
I would think you would need a Lua / Javascript plugin system too, or something similar. Average joe/jane programmers wouldn't write all those plugins in Go. But I think an embedded V8 engine would work very nicely
I recently used otto for a piece of software that need some scripting capabilities because mere configuration wasn't enough. It integrates really well. https://github.com/robertkrimen/otto
I know I will get flamed for this, but I will say it anyway: I see the GC as a drawback. In a good system that tracks memory and leaks, I have never found it hard to get the cleanup right. But on the other hand, in a GC app that grows over time, I have found it really hard to figure out why. In my 20+ years programming, I have found GC pain &gt; malloc pain.
&gt; Why the fuck would you put the workspace itself in version control. That makes absolutely no sense at all. So that, when I tell my coworker to clone the repo, he gets the exact versions of the libraries that I've got in the repo, and can rebuild the app reliably. Go's current method of expecting all APIs to stay the same is insane, and needs to be fixed. I need a way to peg a library to a version or range of versions. (I'm not the author of the article, btw, just for clarity) edit: [here](https://www.youtube.com/watch?v=p9VUCp98ay4&amp;feature=player_detailpage&amp;t=2197) is somebody on the go team recommending that you do keep the whole workspace in source control.
Gotcha, I guess I didn't understand what the meant, I had something else in mind. Several prominent Go projects have a local copy of their deps too, I think that's common as you point out.
I like TOML for this. https://github.com/BurntSushi/toml
Interesting - I use almost the same method. I didn't look much as it really didn't take that long to implement! I'm actually using the same intermediary library 'fsnotify'. That library is slightly more complete I believe (tests!) but has a few differences- namely it uses a global mutex for synchronization whereas mines uses channels. The library at that link also makes better reuse of the standard implementation of http.FileServe. 
I suppose that using a popular language like JavaScript instead of some other small DSL would be better... and if you already have a JIT engine for JS that performs really well, why not V8? A huge part of Wordpress' success is the amount of plugins it has, so language popularity (both core and plugins) would play a bit part in its success had it been written in Go and supported V8/LuaJIT plugins. Plus, performance never hurts!
Assuming that your fileserver is faster/better, why won't you just try to get a patch into the standard Go FileServer? 
Apart from this currently doesn't have good tests or benchmarks, there are very different use cases. You wouldn't want to use this library (or similar) if you are hosting a static directory with large files, or a large number of files as everything is loaded into memory. For those situations, you are always going to still want to load from disk on request.
&gt; Average joe/jane programmers wouldn't write all those plugins in Go. Incidentally, it seems that Go was designed to be used by the average joe/jane.
&gt; and if you already have a JIT engine for JS that performs really well, why not V8? Complexity plus C++ equals bugs equals exploits. But I suppose that V8 could be reasonably safe.
curious if you know how it compares to https://github.com/ranveerkunal/memfs? New to go so I'm not the quickest to spot differences.
I'm curious if os level caching mitigates any expected performance gains. Are there benchmarks?
Just added a test file with benchmarks. Interestingly this method (using channels for synchronization seems faster than using a mutex such as memfs, although this is a very synthetic benchmark.) On the benchmark provided, my library comes in at around ~33% of the time of the standard method, and around 85% of the time of memfs. Timings on my laptop are reasonably consistent e.g. BenchmarkOriginal 5000 761922 ns/op BenchmarkCached 10000 229925 ns/op BenchmarkMemfs 10000 369328 ns/op *BenchmarkCached* being my library. But it a different usage pattern might see different results! 
How do you do the preprocessing of files? Could you post a small example? I learned a lot by reading over your code so thanks!
Any language or system is "hell" if you don't use it with structure and planning in mind. Just because a language gives you a capability does not mean one should use it.
Go 1.2 will contain a gif encoder.
He didn't really, what he did was find a project which wasn't laid out in the way he liked and put it under his name whilst mostly rearranging the project.
Neat. Do you know if there are any plans for APNG as well? 
The language is named "Go". 
golang is fine, though the way he cases it bugs me. 
You're 1-2 years too late to the party brah' - we already had this discussion ... next you're gonna tell me the Gopher's name isn't Gordon :p
Wait, he's called Gordon?
There are some who will tell you that he has no name - don't listen to them
I've added a minimal example- [Preprocessing in-place](https://github.com/blaxill/static/blob/master/example/preprocessInPlace/example.go)
Why does a static site generator need to be fast? Hugo looks pretty cool, but I'm not seeing how speed is a selling point.
Thanks! Really cool feature
&gt; The language is named "Go". Yes, but Google (the Search Engine that Could) has problems with searching for it (so perthaps it's the Search Engine that Couldn't?)
I've just transplanted his face onto the face of Gary Oldman in my mind. Priceless.
Reducing the time for each developer cycle is always good.
Kinda surprised the tool isn't named "HuGoLang" ;-) Interesting that the language is hard enough to search for that users now write apps with docs that never refer to the language by its real name... The Hugo doc consistently uses "GoLang".
Ah, that's reasonable. I haven't used Jekyll myself, so I haven't experienced that.
No plans. I never hear of apng. What is it? 
Animated PNG files. Supported by Firefox for a long while, and the other major browsers too, I think.
I'd have to lean towards it being the new Chinese engines. Seriously, do a trends search of 'golang'. Still, I can't help but feel it isn't overly accurate. At the top it seems to do well enough, but I rarely see Pascal jobs, and have never seen someone wanting D. That may be my own narrow exposure, though.
That people write the language in docs tells me they're focusing on that instead of better solutions to the problem. As the community grows this will probably become less common. I'm wracking my brain to think of projects that would do something different than a knockoff of another language's solutions.
Tiobe isn't accurate about anything. People need to stop linking to it as if it were an authority on anything.
I stuck a comment in on HN and x-posted it into the article. It's probably some buffering magic being done since the values aren't read. I'd want a system call trace to prove otherwise.
Far less exotic than many other formats, judging by the number of people that can readily use APNG files, without installing additional software. It's not even proprietary. 
A fair comparison, as an HN commenter pointed out, would be to use the same client for both 'server' tests. I read nothing from this. 
Don't sweat it: there are anti-patterns in the Scala code, too. Examples like this don't prove anything. Go's scheduling for go routines adds some overhead that would actually be beneficial in real world environments and uses syscalls directly rather than letting the JVM buffer syscalls. According to some benchs in the comments on HN, using the Scala client with the Go server gets pretty much the exact performance of Scala/Scala. You can tell it's BS when people are going "Scala is using 200MB of memory! What a monster!" Well yeah, it has to spin up a JVM.
Yeah, if you have the time to write up a quick analysis of the Go code, I'd be really interested in reading your thoughts and improvements. 
It's possible to write slow code in both, and make either one slower than the other quite unwittingly. It just sucks when people benchmark unidiomatic vs idiomatic code, because it's usually not helpful whatsoever in terms of evaluation of languages' performance.
I started a job earlier this summer doing C++ on a production project after only doing mostly C/Java stuff. Let's just say I attribute all of C++'s increase to me.
care to post your code ... i'll run it on my OSX Quad i7 @ 2 Ghz
First of all run the original benchmark code (with the scala vs go combos too) to get a baseline compared to mine. the modified go client is here: http://pastebin.com/MBK9DHCm
This is a bit old, the upcoming changes they discuss there have been introduced in Go 1.1 AFAIK. 
The Linux Go networking stack is better than on OS X. Because more people use Linux for real servers, so it gets more attention.
Sure seems like it. 
All the methods mutating with value receivers scare me: func (h fileHandler) It seems like you're just getting lucky that the struct fields are reference types (maps). Those should really be pointer receivers. Why is ContentType a type? It has no methods. Or docs. Actually, the package and everything has no docs. addDir never closes f. What is an ExtensionHandler? Rather than, if d.IsDir() { name += "/" } Just define a suffix string and set it to "/" and use that in the Printf pattern below. Avoids allocating a new string each time to append "/" to it. No need for: var buff = &amp;bytes.Buffer{} Just say: var buf bytes.Buffer etc 
The plot thickens - I ran the benchmarks between 2 separate machines on a LAN, both Ubuntu 64 boxes. The results are even weirder: 1. Go client vs Go server - ~5us per call. 2. Scala client vs Go server - 0.4us per call (WAT?) 2. Scala client vs Scala server - 0.8us per call. 3. Go client vs Scala server - 1.0us per call. 4. tweaked Go client vs both servers - 0.4us per call. So again, it seems like this is something to do with socket options, or some under-the-hood buffering in scala (since only a buffered async version of the go client manages to be on par with it).
This shows how random the TIOBE index is. Also: http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html *"Apart from the confidence, sometimes also exceptions or mandatory additions are used to weed out false positives."* The table entry for Go: "Grouping: Go (**Addition: Google**), golang" This means that a hit for Go is only counted if the page contains the word Google as well, but a hit for C is counted, even if AT&amp;T isn't mentioned. I understand the motivation for this, but it also makes the rankings incomparable with each other.
Any pull requests are more than welcome. There are (currently?) no docs, as it was just something put together in a couple of hours. &gt;All the methods mutating with value receivers scare me: You're right, I will change this. &gt;Why is ContentType a type? Content Type maps directly to http content-type header. &gt; What is an ExtensionHandler? Check the examples for an idea of what an ExtensionHandler is. Basically it allows preprocessing by file extension. &gt; Rather than ... The line(s) if d.IsDir() { are actually almost straight from net/http/fs.go, but sure that could be changed. &gt; No need for... These are not equal var buff = &amp;bytes.Buffer{} var buf bytes.Buffer I've seen the first in use before, do you suggest against that?
Interesting thanks, maybe just DRY it up a bit.
(change the name) &gt; You see too many Go packages relying on rake I've never seen one but maybe it's because I'm not familiar with this * what's a Task? (and why do we need a manger for it) * what's a Task Manager? $ go get -u github.com/chuckpreslar/gofer $ cd $GOPATH/src/github.com/chuckpreslar/gofer $ go build ./bin/gofer.go &amp;&amp; mv ./gofer /usr/local/bin/gofer that last step doesn't work... but i wonder, why not give the command a proper name and replace those 3 lines with `go get github.com/chuckpreslar/gofer/gopher-bin-or-something`
Might be looking for solutions before appropriately determining problems here. What packages use rake? Why the non-go-get instructions? 
A task is a simple concept. If you've ever used a Makefile, [rake] (https://github.com/jimweirich/rake) for Ruby or [Grunt] (https://github.com/gruntjs/grunt) for Node, then you've used a task manager. Say you have a command that you execute over and over again. The command is simple at first. But what if your command gets more complex, requiring multiple steps to complete? Why would you want to take the time to write it out over and over again? If you take a look at the [Hood](https://github.com/eaigner/hood) project, you can see [here](https://github.com/eaigner/hood#migrations) the maintainer has implemented the basics of a task manager by following Rails' rake task as an example for generating migrations. Yes, this is useful to the project, but not to the Go community as a whole. The benefit of having a task manager is to allow a user to install your package, run a single command (ex. to generate default configuration files) and be up and running in no time. As far as the installation goes, it is a two part process. You'll need the binary installed in order to run commands registered from packages using Gofer. You'll also need the package in order to write your own tasks. If you'll provide what error you're seeing, I'll be able to provide you a little assistance in fixing it ;) Lastly, `go get github.com/chuckpreslar/gofer/gopher-bin-or-something` - it doesn't work that way ;)
Quick reply, take a glance at my previous follow up and it should explain why this is necessary. Maybe I need a more detailed README after all o.O. 
&gt; Lastly, go get github.com/chuckpreslar/gofer/gopher-bin-or-something - it doesn't work that way ;) That's his point -- your repo is broken until it (or something like it) works.
* **The 'const' block at line 16**: You can omit the repetitive instances of `1 &lt;&lt; iota`. Only the first line needs it. it is automatically copied to the other constants, by the compiler. * **'func NewExpression() *Expression' at line 32**: You have only 1 type constructor in your package. The accepted custom is that you just call it `func New() *Expression` in this case. * **The 'HasXXX(bool)' methods**: Getters and setters have the following accepted format: func (*T) EndOfLine() bool func (*T) SetEndOfLine(bool) You can therefore omit the `Has` part of the method names in your setters. This will conflict with your parameterless version of `StartOfLine` at line 77. But that one has a bit of an ambiguous name. it is not clear from the name that it will explicitly set EndofLine to true. So consider renaming it, or removing it. * **Repository/package names**: Your package is called *verbal*, while your repository is named *GoVerbalExpressions*. When using `go get` to install your code, the package is installed in the *GoVerbalExpressions* directory, which also becomes its import path (*github.com/maurodec/GoVerbalExpressions*). It is a little confusing that the package name itself is *verbal*. While not a deal breaker, it is cleaner to keep the repository and packages names the same. * **Package documentation**: It is useful to put a short (1-line) description comment directly above the *package verbal* statement. This makes sure that tools like *godoc* pick it up and use it as a helpful description of what it does. * **Compile error at line 195**: There is an undefined reference to variable *source* at line 195. The package fails to compile because of this. I presume this should be *e.source* instead. This may have just been a fluke that slipped through, but it is advised to write some unit tests and ensure the code both compiles and all tests pass, before committing anything into the repository. Info on writing unit tests: http://golang.org/doc/code.html#Testing
Thanks a lot for the comments! I will definitely take them into account.
No problem. I would like to add that, while tedious, it is really helpful to add comments to each public API element. Godoc uses these to auto-generate documentation. The accepted custom for this is something like: // Add adds the values of a and b and returns the result. func Add(a, b int) int { .... } There is an online version of godoc, which automatically generates documentation from repos like github: http://godoc.org/github.com/maurodec/GoVerbalExpressions Oh: and another point: Constants in Go are usually CamelCased, instead of ALL_CAPS. This is a matter of taste, but I think that it pays off in the long run, to stick with established Go conventions.
I have not done any documentation or unit tests yet since it's far from usable, but it's what I was planning on doing next.
A thorough README is never unwelcome or wasted.
retyping 'cos I accidentally closed the tab... I guess the explanation of what a task is, makes sense... but that's probably because I already know what a Makefile is. &gt; As far as the installation goes, it is a two part process. You'll need the binary installed in order to run commands registered from packages using Gofer. You'll also need the package in order to write your own tasks. It's not a two-step process though. observe that `go get`tting the command automatically fetches the package: [ `go get -v github.com/chuckpreslar/gofer/bin` | done: 3.280475819s ] github.com/chuckpreslar/gofer (download) github.com/chuckpreslar/gofer github.com/chuckpreslar/gofer/bin if the command was named `gofer` instead of `bin` then all I'd need to do is run `go get ...` and I can immediately start working with the `gofer` command. btw, you can replace that `cd`'ing and `mv`'ing dance by referring to the pkg path and specifying the output file e.g. `go build -o /tmp/gofer github.com/chuckpreslar/gofer/bin` &gt; If you'll provide what error you're seeing, I'll be able to provide you a little assistance in fixing it ;) Sorry I don't know what the actual error message is, because I didn't run the command. What I *do* know however, is that I can't write to `/usr/*` and I tend to uninstall anything that requires me to use `sudo`, regardless of how useful it is. &gt; Lastly, go get github.com/chuckpreslar/gofer/gopher-bin-or-something - it doesn't work that way ;) how does it work?
Also, to the coward that downvoted [ptrb](http://www.reddit.com/r/golang/comments/1jzl86/gofer_a_proposal_for_a_task_manager_for_go/cbk3tsp): Let your voice be heard! 
the `go build -o` is a valid point. EDIT: I hope you're not assuming you import the binary which is to be compiled and moved to you `PATH` for convenience.
absolutely nothing assuming the task is language-agnostic.
I think there may be some confusion here. I will use `#` in place of `github.com/chuckpreslar` to hide the noise * Users will import the `#/gofer` *package* * As I understand, they will run the tasks using the `gofer` *command* *for demonstration i first setup my env as such:* ~ # export GOPATH=/tmp/gofer-path ~ # export PATH=$PATH:$GOPATH/bin * To install the `gofer` *command*, they must do the following. keep an eye on the last command ~ # go get -u github.com/chuckpreslar/gofer ~ # cd $GOPATH/src/github.com/chuckpreslar/gofer /tmp/gofer-path/src/github.com/chuckpreslar/gofer # go build -o /usr/local/bin/gofer ./bin/gofer.go # command-line-arguments cannot create /usr/local/bin/gofer: Permission denied what I'm proposing is that you give the command a proper name like `gofer` such that it resides at `#/gofer/gofer` ... so `#gofer` is the *package* and `#/gofer/gofer` is the *command*. this means that all i need to do is run *one* command and have it work: first i do my setup ~ # export GOPATH=/tmp/gofer-path2 ~ # export PATH=$PATH:$GOPATH/bin run the one command ~ # go get -u github.com/chuckpreslar/gofer/bin check the packages that installed from github... not that `#gofer` has been downloaded ~ # go list github.com/... github.com/chuckpreslar/gofer github.com/chuckpreslar/gofer/bin and to run the command ~ # bin version 0.0.3 if the command were named `gofer` instead of `bin` then all I'd have to do is run that one `go get #/gofer/gofer` command and instantly be able to use the `gofer` command
thanks for the clarification, you may have taught me something about Go's get today that I honestly didn't fully understand. I'll try to take a look at this tonight, but in the mean time, it seems you know exactly what I'm trying to accomplish here - maybe make a pull request for me to look at?
You could also look at their actual go implementation. https://github.com/VerbalExpressions/GoVerbalExpressions 
I started mine before that repo was created. Actually, the owner of that repo marked some of my code today into it. 
pull request sent
As I've said elsewhere before: If you need to use sudo to do it then you're doing it wrong. Personally, I've seen this nonsense from things that are built with nodejs and ruby... long story short: If your installation process needs `sudo` then I'm not going to be installing it
Interesting results: client vs server - output 1. Go client vs Go server - 14.8568. 2. Scala client vs Go server - 5.461. 3. Scala client vs Scala server - 2.223. 4. Go client vs Scala server - 55.741. 5. tweeked Go client vs Scala server - 15.178. 6. tweeked Go client vs Go server - 54.339. (only time all cpus were maxed at 100%) To be fair I have a billion things open, maybe I'll repeat the test later on a fresh restart with nothing open. I'm also interested to see what happens on my little ubuntu hp 2760. The results combined with /usr/dvirsky do seem to indicate that the OSX go socket implementation isn't as optimized in some way. Edit: tried on a fresh restart and minimal running programs with the same result
Placing this here to clear up anyone else that is potentially confused: https://github.com/chuckpreslar/gofer/pull/3#issuecomment-22443140
Wow, I would never have guessed that the differences will be so big. Notice that even the fastest test you did is almost as slow as the slowest on mine. My machine is not that much stronger than yours (Lenovo W530, it's high end but a year old), even Scala is almost x2 slower on your machine. I had a full desktop running when I ran the benchmarks, including tons of browser tabs and 4-5 IDEs. Nothing was hard at work but I didn't test on a "sterile" environment.
Maybe it's just OSX sockets? Or I've jacked something on my machine? Maybe ill try and convince a friend to run then on his lap top
Awesome library! I wish the standard library already had those helpers built-in, it would've saved me a lot of headache!
To get a nice `verbalexpression` package name, put the directory `verbalexpression` in your github source dir, and your import path would look like: go get github.com/deepestbluedn/GoVerbalExpression/verbalexpression
Ok ran it on Ubuntu on a HP 2760p client vs server - output go vs go - 6.75353 go_mod vs go - 1.58089 scala vs go - 1.884 go vs scala - 3.19203 go_mod vs scala - 1.86875 scala vs scala - 3.787 Intel(R) Core(TM) i7-2640M CPU @ 2.80GHz
No big company uses just one technology, and generally, many don't share these details because it's not that interesting. That said, I think Cloudflare uses go in some regard.
Bitly has published a number of interesting Go libraries. A tour of them will give you an idea of what role Go plays in their infrastructure. https://github.com/bitly
&gt; Google has also said that they are using it for 'serious projects' but with no mention of which services in particular. Google uses Go for [YouTube (vitess)](https://github.com/youtube/vitess) and their [download servers](http://talks.golang.org/2013/oscon-dl.slide#1). Edit: added correct vitess link
[organizations using go](http://go-lang.cat-v.org/organizations-using-go) under the community heading in the sidebar. Keep in mind this is "no longer maintained", but I imagine the list is longer, not shorter. Also, regarding google using go internally, check the top posts for this reddit, notably one for [this link](https://groups.google.com/forum/?fromgroups=#!topic/golang-nuts/BNUNbKSypE0)
I used Go for a game backend 2 years ago while language was in flux. It sounds scary but it wasn't really, since it didn't have many issues, and when there was issue usually got fixed pretty quickly. Nowadays the language is just rock solid, popularity doesn't really matter there... dl.google.com is running on Go: http://talks.golang.org/2013/oscon-dl.slide#1 Here is list of other organizations using Go (it might be outdated): http://go-lang.cat-v.org/organizations-using-go1
&gt; I was wondering if anyone knew how popular it is becoming as a web backend. One metric is Github. That's obviously biased towards open source code, which may not accurately represent all usage, but it does give you some data. Go is the 24th most popular language on github right now. For comparison, that [puts it above Clojure, Erlang, and all of the lisps (except Elisp)](https://gist.github.com/munificent/6136198).
http://www.moovweb.com
Everything below Prolog should feel bad :)
This is a very good starting point. But this only covers a fraction of the parts of the reflect package which would benefit from a high-level abstraction (think: Function calls, working with pointer-types etc). Are you planning to extend this library in the future? (As a nitpick sidenote: I dont find the naming of the functions very idiomatic, although I do understand their origin.)
As of today the library covers only the abstractions I was in need of when I developped it. I'm aware it's not totally complete, and I'm definelty willing to fulfill it along the way :) The github issues page (https://github.com/oleiade/reflections/issues) have a "feature request" and a "suggestions" label for such requests. I'd really like you to fulfill detailed (with expected usage examples) features request for those you'd like the library to expose. And suggestions about the functions naming would be welcome to! I look forward to ear from you on the projects issue page ;) Best,
Actually, we've recently moved to GitHub: http://github.com/youtube/vitess. We are planning an announcement in the next few days.
Glad to see you moving to GitHub. They have made the barrier to contribute far lower than most other services.
And this is why we need generics. 
Cool, thanks!
ELI5 - what is it about not having generics that makes it so necessary? Can't you just "do it the go way" and have it still work? (not trolling, really just want to know)
If Go had generics, this set implementation could have been easily coded so that a set would accept only values of certain types or interfaces, like Go's own map does. As it is, the programmer of this library had no choice but to make his set accept all types. type Set struct { m map[interface{}]struct{} l sync.RWMutex // we name it because we don't want to expose it } ... func New(items ...interface{}) *Set func (s *Set) Add(items ...interface{}) func (s *Set) Remove(items ...interface{}) func (s *Set) Has(items ...interface{}) bool etc. Sure, it can be used, but it's not very safe. I don't *think* that's the go way. Unless somebody was clever in ways I cannot imagine, you can see the same design in every other data structure library written in Go. I would sorta be ok with this if at least the native map datatype could be threadsafe, since a decent map is good enough a datastructure for 99% of programs anyway.
I don't know what generics do, but I wouldn't mind having type variables like in Haskell. In that case, that would allow restricting the domain of the values of the sets without having to rewrite it all. But the way it is now, I like it. Very pythony. I always wondered what type to give to the values of a map when I care only about the keys. struct{} makes sense as it's sort of a Null type that can't even have methods, I'll remember this trick.
I don't think that you have to have an access_token for Instagram - I believe you can get away with just a client_id. What about Imgur? I would also be careful with image licenses - perhaps these could be saved in a database/CSV with the file names?
I will definitely look at it. Thanks for the suggestions.
Love it. How is Revel to work with, is it mature yet or still in heavy development / change?
I wrote up a quick proof-of-concept in my [fork](https://github.com/dradtke/goset), though I didn't take it as far as I'd hoped. It'll need some weird juggling between types and kinds to get it to work with proper runtime enforcement and not just a quick typecheck method.
It's more idiomatic to just use map[MyKey]bool. If you really care about memory performance then struct{} is nice, but it makes the code less readable. Using a bool lets you check existence like: if set["abc"] { ... } instead of: if _, found := set["abc"]; found { ... }. On the note of generics, the primary benefit is that they would enable compile-time type-checking (and perhaps performance benefits). You can recreate much of the functionality of generics with Go's reflect package, but the type-checking would all be done at runtime.
Then Generics are pretty much equivalent to Haskell's variable types. I'd declare *S* to be a *set of int*, *set of Writer* or *set of interface{}* and have it checked at compile time. Yes, I'd love that.
Thank you that you like it. It had some bugs that are also fixed now. I appreciate it.
The Go community seems kind of split on this issue. On one hand, you technically don't *need* (in the hunter-gatherer sense of the word) generics, you can just use interface{} and reflection, on the other hand - why not just make it a dynamically/duck-typed language then? You technically don't *need* compile-time type safety either, I write Python/Javascript/Clojure just fine without generics as well. What's worse is, Go in a way "cheats" by having built-in generic types (maps, slices, channels), you just can't create your *own*. IMO, if you have a C-style language with compile-time type safety in the 21st century, you need generics - Java, C#, C++ all have them and *nobody* in those communities waxes poetic about the "good old pre-generics days". That, or don't even bother with compile-time type safety. Go is in this weird limbo state of being 95% type-safe at compile time, except for the 5% where you're forced to either copy-paste code or get creative with reflection, both of which I hate. 
In my experience, Revel is great to work with. It's been around for a while, but 1.0 has not yet been released, so it should be considered as still under development. I wouldn't quite recommend building your enterprise app on this just yet, but otherwise it's awesome. Mostly getting the blog up and running was ridiculously easy. Revel has everything you need for a blog with basic functionality. I had to plug in a separate library to connect to MongoDB, because Revel is still Bring Your Own ORM, but that's due to change some time. Even so, I didn't really experience the lack of built-in ORM as a problem in any way.
I should add that my fear is that their problems with Java have caused Google to fall victim to the 'not invented here' mentality. That they are pushing Go largely because they own it. I can understand the need for Dart which appears to really address the issue they are pushing it for (I haven't used Dart either, just read about it) . But I'm baffled by their pushing of Go for stuff it wasn't designed for.
I switched from SublimeText2 to Vim as well. For Go, I highly recommend these 2 plugins as well: Bundle "scrooloose/syntastic.git" Bundle "dgryski/vim-godef" Syntastic is sort of a linter, it compiles your code and shows you errors (sort of like Visual Studio where it underline-highlights your errors in code). It allows for faster iteration, as you will never have to run 'go run/build' to find out compiler errors yourself. The second one, vim-godef allows for jumping into library definitions. So if my cursor is on fmt.Println, when I press `gd` it opens Go's implementation of Println function in my buffer. So you can see how things work under the hood. (jumping back to original buffer is as easy as C-o or use of BufferExplorer).
As I understand, the Go authors want generics, they just can't find a nice enough way to implement it. 
That was a really good summary. It's really cool to be able to read something condensed like that and have an idea what's going on with a relatively young language that I have an interest in. Please keep doing these!
Agreed! 
Seconded. the new encoding interfaces is something I've been wanting for some time now. Very nicely covered. 
Nice write-up, it's going to help many people get setup quickly.
I'm looking forward to the next post.
Thanks, the folding was a great thing. Using that right now!
Thanks, you're the second person to recommend these two, I'll definitely try this!
Will do, good idea.
This looks fantastic! The last time I needed a set, I ended up using the keys in a map. It'll be nice to really to have a real set to utilize next time. I wanted to ask: How did you like working on thread safe code in Go? 
Just chiming in to second the recommendation for `syntastic`. It's bloody amazing and really speeds things up.
One of my favourite podcasts, look forward to listening to this one.
Are there transcripts of those podcasts somewhere ?
awww yis, thanks so much for this!
Syntastic is great for overall go coding except that it doesn't recognize any appengine related syntax, like import. Any suggestion on that?
Great work! Please keep doing this :)
Also, https://github.com/jingweno/octokat and the project it was extracted from https://github.com/jingweno/gh .
I heard: blah blah blah, go to GopherCon. :)
Ah, this explains why people have been starring vim-godef recently :) Thanks for the mention. This was my first vimscript plugin, so it may still have some issues (although I haven't encountered any in a while). Don't hesitate to file a bug report (or a pull request ;) for any missing features.
Not major, But we have been developing a team collaboration platform in Go called Qortex: http://qortex.com 
What useful information does this actually convey?
That serving JSON from a simple webserver is 10x as fast in Go than Python. The point of the article is that if you have a bottleneck in your system from requests/second on a Python webserver it might be worth investigating if you can fix it with a Go implementation.
If *that's* the point, your test is utterly worthless. Serving JSON is a massively specific microbenchmark (when compared to an entire webserver) that has near no relevancy to the performance of a webserver as a whole. (Unless your website primarily serves json, which doesn't seem to me a particularly common use case) Your interpretation isn't supported by the evidence.
A big pet peeve of mine is when people who (by their own admission) don't know a language write an article comparing it to another language.
To me (also a long time python user) it simply conveys that for this simple case, coded up pretty much how I'd do it in either language (close enough), go is much much faster. You can dissect it a million ways. I don't know if the numbers are even important. But it does tell me that a naive implementation of some http and some json serialization in Go and in Python end up with Go being much, much faster. Kicking dirt, or even hinting at kick dirt, on someone's favorite language always ends up like this. Let the benchmark argument begin. P.S. Benchmarks have only one practical function: sales.
I think this points out something interesting the article missed. The go implementation is all standard library. The python implementation is not. And he didn't even touch deployment.
Add at least support for *tags* and you got yourself a product!
I have to agree with marky1991 here. I think that there are probably huge numbers of cases where Go would be faster than Python, but I don't think this does a good job of demonstrating it.
Congratulations on your achievement. I personally don't really care for a bookmarking site, but I felt the need to comment on your point #4: &gt; Database support is horrible. Coming from java land the orm side of go really scares me. Most of the libraries out there don't seem to be very mature and lack fundamental features. It doesn't even seem like connection pooling is supported in most libraries. Yikes! First of all, connection pooling is taken care of by the go sql package itself, so libraries should *not* do that themselves: &gt; The sql package creates and frees connections automatically; it also maintains a free pool of idle connections. [...] The pool size can be controlled with SetMaxIdleConns. [source](http://golang.org/pkg/database/sql/#DB) The idea is that you include a [relevant driver](https://code.google.com/p/go-wiki/wiki/SQLDrivers) and do everything through the sql package -- my (limited experience) with this use case did not show any "lack of fundamental features". Finally, the go sql interface is much easier to use than e.g. JDBC, so why would you need an ORM at all? 
I've just logged with google account but I don't think that the authentication is working: Request URL:http://link.zz.pe/api/1/login?token=whatever Request Method:GET Status Code:500 Internal Server Error No record found
So, how did you end up going with #4? I'm currently doing a project, trying to use Hood to the fullest. Not really an ORM (well, there are no real ORMs for Go yet, are there) but, I suppose, I can do most of the stuff with it.
Pretty cool! I like the simple interface. I'll try using this for a while see if it sticks.
I cannot thank you enough for pointing that out! This is still very alpha and I am still learning. It should be fixed now.
&gt;The idea is that you include a relevant driver and do everything through the sql package -- my (limited experience) with this use case did not show any "lack of fundamental features". In java spring-orm with hibernate is the predominate data stack. The features it provides developers out of the box: * sql result to pojo mapping * api abstraction (hql, criteria) over sql querying * service method level transactional boundaries * transparent caching layers * automatic transactional rollback on errors. * configurable connection pooling ([still missing from the go sql package] (https://code.google.com/p/go/issues/detail?id=4805)) * transparent lazy loading of collection subtrees * optimistic database locking support I'm just thinking about about features I have used in previous projects. Its an unfair comparison. It seems like ORMs in golang are just the first bullet. They provide a mapping layer from sql results to structs. I was just saying its scary moving from a world where so much is taken care of for me to a world where I am manually starting up and closing transactions. 
&gt; well, there are no real ORMs for Go yet, are there Agreed. I originally went with gorp then switched to beedb. Who knows maybe I'll switch to hood now that I am looking at that. My only recommendation is hide your data implementation behind methods. Like I have GetLinker(linkerId) GetLinks(linkerId) etc etc. so when a more mature product comes along I can switch out the implementation without affecting my business logic.
[Github repo](https://github.com/mjibson/goread) in case you're interested in looking at code, or hosting your own. The author also wrote a [go implementation of some DSP tools](https://github.com/mjibson/go-dsp)
There's also an Android app in development: https://github.com/mjibson/goread-android
I think were me and you disagree is on "free". Configuration and complexity are costs, huge costs! Terror inducing costs when debugging. Large costs when bringing in new people. It is all about how much of the framework you use... too often people bring in massive stacks and use 1% of the features -- that they could have done with vanilla language X and a bit of custom code -- and it never comes close to paying back it configuration, customization and debugging costs. 
Finally I can abandon feedly.
I was going to explain how I don't consider most of your bullets 'fundamental features', until I read this: &gt; I was just saying its scary moving from a world where so much is taken care of for me to a world where I am manually starting up and closing transactions. And here, I totally understand where you're coming from - during the day I develop Spring/JPA enterprise applications that run on fat application servers and I remember the first time I touched Go's net/http. Where's my session? Where are my out of the box filters? How do I etc. etc. etc.? The reality is, I didn't really need them. For me, one of the joys of programming Go is the feeling of empowerment when you realize how much you can do with so little. And when you start to realize the cost of all this 'taking care of'. Don't forget: your app runs in ~10Mb. A fresh Spring/JPA WAR file usually starts at that size on the file system, only to be deployed in a container that will have a hard time at anything less then 256Mb of memory. Anyway, good luck with your project. And just try it: use the sql package without any abstracting framework -- when the fear is gone, you'll know what I mean :)
This. So much.
https://github.com/mmcgrana/gobyexample
View Go documentation locally: godoc -http=:8080 To include documentation for local packages you install, try `-ex=true` as an option.
[Go Tour](https://code.google.com/p/go-tour/) is a great resource too, of course. You can install it locally instead of visiting tour.golang.org.
This will be very useful, thanks!
Awesome thanks, bookmarking these :).
http://miek.nl/projects/learninggo/ has a PDF you can grab for offline use.
In the spirit of Go, I am putting up comprehensive tutorials on all the important aspects of Go, all of which are just two minutes long!
Concepts on concurrency (More advanced but hey you have 6 hours) http://talks.golang.org/2012/concurrency.slide#1 http://www.slideshare.net/jgrahamc/go-oncurrency Also http://talks.golang.org/2013/bestpractices.slide#1
http://golangtutorials.blogspot.com/2011/05/table-of-contents.html This is where I started, and it was really helpful.
And Go plugins for text editor of choice.
... of which many are listed here: https://code.google.com/p/go-wiki/wiki/IDEsAndTextEditorPlugins
Yeah, everything on talks.golang.org is worth looking at.
I wonder if there is a nice easy way to pull all the talks down for those wonderful trips without decent internet.
that's actually already included with the language. If you run `godoc -http=:6060`, it's served at http://localhost:6060/ref/spec
No worries, buddy. These helped me out immensely. I'm sure you'll enjoy working with Go.
Here is my list of stuff for new gophers Learning * Background on Go’s design: http://talks.golang.org/2012/splash.article * Do the tour: http://tour.golang.org * Best practices: http://talks.golang.org/2013/bestpractices.slide (Slides 1-23) * 10 things you didn’t know about Go - http://nf.wh3rd.net/10things/ * How data structures are represented in memory: http://research.swtch.com/godata * Go koans (exercises) - https://github.com/cdarwin/go-koans Howtos * http://dave.cheney.net/2013/06/09/writing-table-driven-tests-in-go - How to write a test * http://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go - How to write a benchmark * http://dave.cheney.net/2013/07/07/introducing-profile-super-simple-profiling-for-go-programs - How to profile your code * https://code.google.com/p/go-wiki/wiki/MethodSets - How method sets are computed * https://code.google.com/p/go-wiki/wiki/SliceTricks - How do vector-style operations with slices (slice tricks) Bookmarks / Reference * http://golang.org/doc/effective_go.html - Effective Go, general usage tips * http://golang.org/ref/spec - Language Spec, good reference for control structures and builtins * http://golang.org/doc/articles/godoc_documenting_go_code.html - Documentation guidelines * http://golang.org/doc/faq - Frequently asked questions * http://golang.org/pkg/ - Standard library documentation * http://mercurial.office.yext.com:8080/pkg/yext/ - Godoc for yext code 
The spec is wonderful: very clear and easy to read.
Link for the lazy http://golang.org/doc/effective_go.html
Especially if he is just starting, he may find it good enough or even beneficial to learning if he just has a syntax highlighter, like the default gedit go mode
I am trying to use language that is easy to understand for someone who is new to Go, and probably doesn't know about slices yet.
Strings in Go are (usually) UTF-8 encoded, which is all nice when your 'characters' are one byte long. Your examples of using slicing for substrings fail miserably when dealing with characters that need more than one byte, e.g. the string "世", which needs *three* bytes: http://play.golang.org/p/OUxj8rNK3U 
I would interested to know which ones you ended up using and what you thought of them.
Code and slides [here](http://code.google.com/p/biogo/source/browse/illumination/?repo=talks).
Glad to hear! I see a lot of people on the mailing list having trouble with method sets: http://golang.org/doc/faq#different_method_sets Also, people trying to do traditional Simula-style inheritance in Go (and butchering the language in the process), vs doing it "the Go way". Unicode is a big, hairy, ugly, giant beast. I'm interested to see how you address it, most stuff on the web about it is pretty poor. Code points, glyphs, runes, characters.....all those terms are used interchangeably and confusion reigns supreme. Still, regarding your existing example, if you want "more accurate" "character" sub-string operations using slices, like in your example, you might want to convert a string to a []rune and *then* do slicing. Even then, since the strings aren't canonicalized, you won't always get accurate results (but it's still better than slicing on bytes). What I mean by not accurate: http://play.golang.org/p/rvFz3mCL5e Combining characters are a bitch, even runes won't help you there. 
Yeah, unfortunately play snippets won't run there because they have non-std-lib dependencies. If you want to see those, go get code.google.com/p/biogo.talks/illumination and it will get the talk and the deps.
I believe under Windows only system level environment variable requires reboot. Try using user level to set GOPATH, which I think requires re-login. Or just set the GOPATH when you are at a command prompt with no reboot or relogin required. Have not been using Windows for few years so I might be wrong.
I haven't used Go for very long, so maybe I'm missing some details. I've only ever used one gopath. Here's what it looks like on my Windows computer: C:\users\alec&gt; set GOPATH GOPATH=c:\users\alec\documents\go Basically, `go` is where all my Go projects are. Inside of `go`, these are my directories: go bin pkg src project1 project2 The idea is you put all your projects in `src`. For instance, `project1` might be a directory that looks like project1 main.go stuff.go more.go Inside of `project1`, if you run `go build`, it should just work, and produce `project1.exe` in the same directory. `bin` is for compiled binaries from your projects. For instance, if I run c:\users\alec\documents\go\src\project1&gt; go install Then `project1.exe` will appear in `go\bin`. You can then use this project from other projects as an import. I've also added `c:\users\alec\documents\go\bin` to my PATH variable so that I can run the binaries from anywhere in my command line. `pkg` is for packages you install from other places with `go get`. So basically `c:\users\alec\documents\go` is where I know all my Go code is, and it helps the go tools work a little better together. At first it seemed really weird to have a global code directory, but it works pretty well. Also, I've never had to reboot my computer to change my system variables. I'm on Windows 7, so to change variables, I just search in the lower-left start menu "system environment," and then use the "Edit system environment variables" tool that pops up to change the variables. I don't have to reboot my computer, but if I had a command line open, it will still use the old variables, so you just need to open a new command line window.
I am guessing you are working in Windows? In Windows you don't need to reboot for applications to read your new environment variables set under system. You should only have to restart the application or terminal session. Programs in general get a copy of the environment when they are started. In Linux and MacOSX there are several places to set environment variables but for the most part, environment variables are set at the time you start working in a terminal or application that requires it. I know it does not translate well to Windows. GOPATH is going to be project specific, not necessarily global. You may have some common packages you always use but think of GOATH as a project specific setting. In the Linux/Mac world the concept works very well both for development and deployments. It is how things are done. Use the windows version of LiteIDE. It is an excellent IDE for Go. It will manage the GOPATH for you and life will be good again.
I don't think it is. Python have virtualenv and pip, ruby and node.js can install packages locally per project, and it is very convenient. I don't like how it is done in Golang. But probably you need to compare with C/CPP, I think then it can be excusably. Aslo, you don't need to reboot Windows, you can set different env variables per each command.com window (or how it named now, didn't use windows for more then 10 years).
API seems clean and quick... look like express
I don't think you even need to work within your own GOPATH, but then importing your own packages will need to be done via relative paths: ~/test/go% cat main.go package main import ( "fmt" "./mypkg" ) func main() { fmt.Println(mypkg.Greeting()) } ~/test/go% cat mypkg/main.go package mypkg func Greeting() string { return "Hello, World!" } ~/test/go% go run main.go Hello, World!
OK. Trust an ide on windows. When I'm on linux, how do I set these environment variables in several places? 
At my company, we have several Go workspaces (projects, basically). So for each of these we have a top-level Bash script that you have to source which sets the Go path and other environment variables for your current terminal window.
On Windows you use set but in Linux you use export. export GOPATH=~\dir\dir That will set the variable for that current session. You could always create a makefile or shell script to do this for you. It all depends on how you are working or building the app for your environment.
I was in the same boat you were a few months ago. Moving from Windows to Linux/MacOSX can be a frustrating experience until you begin to understand how things work. Then you begin to appreciate Linux over Windows. Check out my blog, goinggo.net. It has a lot of articles for people just starting out in the language. You could said it is my notebook.
Go has GOPATH python has PYTHON_PATH node has NODE_PATH java has CLASSPATH ruby has RUBYPATH This concept isn't unique to Go at all. The only difference is that the 'go tool' doesn't do package relative imports. It only does imports relative to GOPATH. This greatly simplifiers the question "what am I importing and where is it located?" and also makes sharing packages between projects trivial. Languages have come up with an array of ridiculously complicated solutions to a problem that it made trivial by having a common root for all package imports.
True. They still fuck things up a bit not by having package versioning and therefore the ability to have more than one version for a given package, but I've come to like GOPATH, I would hope more people understood that only your packages need to be there and you are intended to keep your projects wherever.
Versioning is an entirely unrelated topic. GOPATH works whether you have some kind of versioning or not. You can put the versions of packages you want in a directory. Point GOPATH at that directory and run the compile with those versions. https://github.com/vividcortex/johnny-deps does exactly that. Python, Ruby etc. have a much worse versioning problem due to the need for runtime package versioning.
Nope, just need to close and open the command line (or what ever application you are using) again to load the latest system and user environment variables.
Why don't more people use go-restful? It's the only one that offers additional feature on top of net/http and it's the only one that has a *meaningfully* BETTER API for REST services. I say this after having tried literally every rest api for golang I could find. gorest, goweb, net/http, combo of various gorilla pieces, ripple, web.go, revel, etc, etc. go-restful is still easily my favorite. Best API hands down. haven't tried these yet: http://godoc.org/github.com/ant0ine/go-json-rest, example of go-restful : https://github.com/emicklei/go-restful/blob/master/examples/restful-user-service.go
Oh my god, you just made my day, I wrote johnny_deps, nothing makes me happier than somebody recommending it on reddit :) No, you're right, versioning is entirely unrelated to GOPATH, I was just empathizing about GOPATH being actually a pretty good idea and venting some frustration at some of the limitations of Go versioning, they are mostly fixed by johnny_deps, but there are some gotchas that can't be supported. I mostly agree though, most other versioning systems are pretty overengineered, but they also have a little more flexibility for some things.
GOPATH just describes where your personal libraries are going to live. You don't need a different GOPATH for every project, just use one. It exists for a number of reasons. First, the Go team reserves a directory on your machine for the standard library, and you are not supposed to put anything in there. That way, if they make a new package, they can just write new files, and they don't have to worry about clobbering any of your stuff. What if you made some package `stanley`, and then a `stanley` package got added to the standard library, and you updated the language? If you didn't have your stuff separate from the standard library, that would get pretty messy pretty quick. On a shared system, GOPATH can be set per-user, so that users don't interfere with one another projects, and also don't need shared privileges. Or the inverse: if you want users to share a GOPATH, then explicitly do so (along with all the standard shared file permissions rigmarole). Want to temporarily see what will happen on a clean install, for a user that has *no* packages, to test how some thing works when downloading a package fresh? Point GOPATH at some new, temporary dir, and then just blow it away when you're done. There's a handful of reasons that GOPATH exists. I don't understand why GOPATH is controversial. I don't know that I ever will.
I can't convince you because I don't think it's a good idea. Lots of people obviously agree because it's a constant topic of discussion. Frankly, I think a lot could be learned from Rubygems and Bundler in this regard. While these things aren't perfect, I find them to be considerably more useful than Go's scheme of setting a single path and pretending like everything can happily live in one big directory. The first person who writes GoBundler will be a hero to many!
That kind of teaching/learning only leads to duplicate efforts. Once to learn the wrong way, then the right way. Possibly triplicate if he asks someone else for help using the wrong way.
This is the sort of thing that should be documented somewhere. 
I am loving these articles, keep it up man! I'm not sure I like the new syntax over a setCap method, but I'll follow what happens.
I agree these articles are awesome. I don't necessarily have time to always read the mailing lists or issue tracker, so I'm only vaguely aware of most of these changes. Getting the all details in one place is incredibly useful.
And you learn a lot about what thoughts go into each release.. And shit, I didn't even know that appending to a subslice would grow into the underlying slice.. Learning these boundary cases are great.
This is very useful, thanks. I do not have time to keep track of the dev mailing list myself. A coherent recap like this is tremendously helpful.
Install CGDB (available in ubunu repos). It will make debugging on the command line much easier. 4 min demo video available here: www.youtube.com/watch?v=OKLR6rrsBmI
I agree in general, but there are some cases where you might want to switch GOPATHs too, think about maybe bundling your application along with all its dependencies for example.
You are confusing versioning with GOPATH. Those are two entirely different things. GOPATH just tells you where your packages, source, and binaries "go". Almost all interpreters have something like this, but they have sensible defaults backed in. Go does not. It is not absolutely required for building simple one file test programs. You can just 'go build hello.go' and you will get a 'hello' binary in your current directory. If you have other files or are using packages. You need a GOPATH. This is simple to set on both *nix and Windows. From your console on Windows type: set GOPATH=%CD%. On *nix: export GOPATH=`pwd`. Now structure your go like this: $GOPATH/src $GOPATH/pkg $GOPATH/bin Also note that now hello.go should be located here: $GOPATH/src/hello/hello.go You can have multiple projects all in this structure. Or you can put projects in different directory trees altogether. You can have each tree in your path (i.e GOPATH=dir1:dir2:dir3). Or just set it in your shell each time you switch projects. As others have pointed out - there is not need to reboot on Windows. There is nothing complicated or difficult about this, and it has nothing to do with which version of a package you use or how you are going to get your packages from remote repositories.
There's no such thing as an "underlying slice", only underlying arrays. A slice is a window to an underlying array. Multiple slices can share the same array.
Woot! Thanks for listening :)
 go get code.google.com/p/go.talks/present present
It's partly the point of the syntax, yes. There are probably other use cases, but the custom allocator is the most accessible one. I can't comment on Rust. Never used it, not even looked into it. The work that goes into avoiding Go's GC, *where needed*, however is far outweighed by the benefits of the GC. Chances are that most of your code will never have to worry about avoiding the GC in ways as elaborate as designing your own allocator. The places that really matter, like net/http, are taken care of for you. And a lot of the ways of avoiding the GC would equally apply in languages without GCs. A ton of mallocs+frees will be slower than reusing a buffer, and it's kind of the same in Go, just that the free is implied. Many of the changes that I talked about in this article are exactly that: Replacing working but not optimal code with better code. That's a natural development process, no matter if your language is C, Go or Rust. The important thing, however, is that net/http has been working incredibly well for a lot of people for a long time, and it just became better. There was no huge initial cost of thinking around the GC. The package was written, it worked, it was incrementally improved.
For some reason, I suspect this version of the specs wouldn't work very well with gofmt.
Sure, I may have come across more negative than I meant to. Please don't take this as a put down against Go or against it's progress. I'm very serious about tinkering with Rust in one window while writing lots of Go in the other. And thus far, GC is a very minimal (non) issue for me, but I don't have to worry about scale beyond a fixed size. I think I should've considered that in places "remove garbage" was written which doesn't necessarily mean special precautions taken to avoid GC so much as it is cleanup and obviously optimizations that cause less GC.
Useful, thanks!
I am the author of the library and i made it mostly to get better acquainted with go. The benchmarks found in the repository show that is is very fast (10x slower than encoding/json but i never expected it to be nearly as fast because of the increased feature set and parsing needed). I recently got a 15x speedboost by adding caching :) All feedback is greatly appreciated!
glad you like it! spread the word and report bugs too make me even happier ;)
What a great idea and really nice, simple interface too. It also highlights how over saturated the web has become with these services....so it's great to see them all combined into one place.
"Brick, do you really make(Lamp), or are you just saying types that you see in the package?" "I make ... Lamp. I make(Lamp)."
Is that a movie? Do you have a YouTube video with the context?
ha! glad you like it! Never checked out the go package, will do! The faster the better ;)
Linux Apache MySQL PHP -&gt; LAMP
hmm, you can use [iota](http://golang.org/ref/spec#Iota) [here](https://github.com/emilsjolander/goson/blob/master/goson.go#L12), it's a bit easier that way.
 var name *uint16 // ... var lpData *byte // ... fmt.Println(win.RegEnumValue(root, zero_uint, name, &amp;name_length, nil, &amp;key_type, lpData, &amp;lpDataLength)) That's passing null pointers for the name/data parameters. Not sure it makes sense to fetch a registry value without passing in buffers to hold the output. (That is also why you had to make up the `72` when passing in the buffer length; you should instead pass the length of the buffer.)
Aha, got it! The syntax for passing in `&amp;name[0]` feels a little weird, but it does make sense. Thank you!
Why not have a git repo for each project and check them all out under $GOPATH/src instead? 
did not know this existed. Caught quite a bit of inconsistencies ;) thanks!
You're doing it wrong, FYI.
Thank you for taking the time to carefully analyze our software development environment needs and providing your extensive and insightful commentary.
Is it really a "static site" when you're parsing and evaluating templates on every request?
There is absolutely nothing interesting about a static web server...
Definitely. Caching of the evaluated templates, and also setting caching headers, is the obvious next step : ) I sat on the fence about whether to include it or not in the tutorial, but it was already getting quite long so I left it out for the sake of focus!
says you ... i find it fascinating ... when and how much to cache ... ram or disk ... gc languae or not ... if the static files are generated first then served and if they are lazy generated ... the list goes on and on ;)
 -P --public Make this Gist public. -p --private Make this Gist private. (default) nice touch
Next up: Printing information with `fmt.Println`.
Poor word choice, aeronotix said it better and snarkier :-) 
I don't get it. If all you after is serving static files then why not use Apache, nginx or lighttpd or something similar?
First of all, great! Just started reading, one nit: exemptPaths: make([]string, 0), exemptGlobs: make([]string, 0), exemptRegexps: make([]*regexp.Regexp, 0), You can usually just omit list members in struct initialization, since their zero value is "nil" and both "range" and "append" do the right thing with that.
The `math/rand` package does not provide a CSPRNG, so you should read the tokens from `crypto/rand` directly (and then base64). Also, this is likely vulnerable to the [BREACH attack](http://breachattack.com/) if the response is gzipped. The masking approach in [breach-mitigation-rails](https://github.com/meldium/breach-mitigation-rails) might be a good start to mitigate.
This is precisely the type of condescending comment that destroys community and prevents newcomers and the less skilled amongst us from feeling welcome. The go community should try it's best to prevent this type of attitude from becoming socially acceptable.
The thing is: The only thing Go-related in this is essentially a four line main function which is calling `FileServer`. I'm all for helping the newcomers, but programmers aren't babies and their first steps in a new language should not be lauded as interesting nor thought-provoking. Hell, I even think the code in the article is *from the docs*.
`fmt.Print("Please specify a valid file with -f or --file")` I think you meant to use fmt.Println() ?! It's ugly when the shell prompt is on the same line as the print. Also here `fmt.Printf("Gist URL: %s", string(*gist.HTMLURL))` a \n after %s should do it. It's annoying. Actually looking around, it seems newlines are not very popular in your code.
Thank you for the elaboration, and I completely understand that, but my point was that I hadn't actually found myself in a situation where I was appending to a slice of a slice, so I hadn't actually thought about what would happen on an append, copy and extend or runtime error. It was just an interesting thing have brought to my attention.
I can think of a few reasons but really it seemed that the author wanted to use go and tell everyone how he/she did ... you don't always need a name brand server to send out static files or perhaps the authors has other one off use cases to program into his static server and found it easier to use go. As a side note is be interested in some "comparisons" to a name brand servers (used quotes because they normally aren't that indicative of common use or helpful in determining a specific use case)
I felt keeping it private by default was a sound idea.
You can actually parse them when the application start, like: var templates = template.Must(template.ParseFiles("templates/layout.html")) And then just evaluate the template on the requests: err := templates.ExecuteTemplate(w, "layout.html", nil) which is more elegant and the prefered way to do (this was explained in to go docs: http://golang.org/doc/articles/wiki/)
sbditto85 is right - the whole point of the post was to do it specifically with Go (mainly as a learning exercise). Apache, nginx (or Github Pages or S3 if you don't want to worry about hosting) may well be the better choice for most static sites.
2300 req/s all my wat
If you're looking for a go framework that's more similar to django, see [Revel](http://robfig.github.io/revel/).
_ doesn't work anything like a trashcan! You can not restore values that have not been assigned to anything!
I meant like an IRL trash can, aka the place you throw away things that you don't want.
I'm not a web developer but recently I laid my eyes upon Revel and reading the title of this article I was asking myself, why would I use Gorilla over Revel?! From what I understand, Gorilla is not aiming to be a web framework whereas Revel aims to be a framework as feature rich as Rails. I hope it goes beyond that.
That's not how _ work either. You are not throwing anything away you are just not creating it in the first place. Declaration vs definition is an important distinction, IMO, and the trashcan metaphor mixes them up. 
Would you also consider adding the Length Hiding protection for BREACH? In the rails app it added it as a comment in the HTML, which doesn't seem general enough to me (what if we are serving JSON). Perhaps instead we should add a `X-BREACH-Protection` header with a variable length random set of data.
Yeah, I agree it's not a good example of how to do servers, but I was doing it manually to demonstrate the use of web.GzipResponseWriter and web.Cache.
See for yourself, it's simply neither assigned nor used in the resulting code: Comparison: http://i.imgur.com/fwRbiEB.png Program "a": * Go source code: http://play.golang.org/p/WZCtnwqcK9 * Resulting assembly output from gccgo -S: http://ix.io/7BI Program "b": * Go source code: http://play.golang.org/p/kFZeWtOSBd * Resulting assembly output from gccgo -S: http://ix.io/7BJ I used [meld](http://meldmerge.org/) for comparing the output.
I'm not quite sure what it is you think you're arguing about. If a value is returned from a function an is immediately discard through whatever means(implementation detail) then for all intents and purposes, it was `thrown away`. (rhetorical question): what happens when you change that silly proof to use a `test()` function that actually does something that cannot be optimized away.
It's okay that you both don't understand what I'm writing and that you also think I'm arguing. Listen to the audio from about 1:30 in the video. He says: "Instead of putting it into a variable, you can assign it to underscore, which is sort of treated like a trashcan in Go". This is somewhere on the scale from highly inaccurate to moronic. Values are assigned to variables. Underscore is nothing like a trashcan. Let me explain how a trashcan works for you. With a trashcan, you take an object that you wish to throw away, put it in the trashcan and, if applicable, close the lid. It's also possible to open the lid again and fetch the object that was previously thrown away, for a short period of time, until the trash is emptied. This is how trashcans works. With the use of underscore, you don't have an object to throw away, as what could have been something you wish to throw away, simply isn't there. The value that could have been assigned to a variable is never given a name. Of course, if you explicitly give a value a name in a function, and then uses underscore further down in the code, it will not optimize away the use of the variable in the function. This still does not mean that underscore works like a thrashcan. Clearer now?
Thanks for doing the legwork, that makes sense really.
It might be a cultural difference. In our household, we think its kind of gross to remove things from the trash can and discourage it pretty heavily.
A similar project that came out recently: https://github.com/joho/godotenv
I think your imagination is running away with you, but I'm glad that you can confirm that objects are not naively "gone" when placed in a trashcan. 
Go needs more of these success stories imho. Thanks for sharing.
On the up side, it's based on work involving DJB. On the down side, it's based on work involving DJB. 
Here's my big list of Go stories. Most of them are thoughts and experiences w/ Go. http://amattn.com/2013/06/01/big_list_of_go_articles.html
Yes, you're right. Basically both have same purpose for loading env file but differ on implementation. Mine is using regexp, like dotenv did, while godotenv parser using sort of standard golang package. Both are good choices, so I think we can choose one, and stick with that :D
Frameworks and libraries. Different philosophies.
Darn you. You're several days late. I could have used this article a few days ago writing an application that consumes both XML and JSON feeds. I never knew about those libraries. I had to create structs of doom :(
If you are looking for numerical stuff, see https://groups.google.com/forum/#!forum/gonum-dev https://github.com/gonum
Some time ago I had the same problem. My task was a platform for machine learning. After several months I have some info for sharing. Go is fast and memory effecient. We compared our old implementation in python + nltk and nltk-trainer and our custom classifier in go on big corpora. So go version was about 15 times faster mainly because python version eats all memory and swap. We wrote all what we need by ourselvs because now there are not many libs for machine learning and math. Best list for libs in golang is here https://code.google.com/p/go-wiki/wiki/Projects. About coding: golang doesnt have generics and good data collections/transformation library. So you need to write a lot of boilerplate code to convert your data from one shape to another. if you like LINQ or something like that ithen think twice before going to golang.
Done! It took me awhile to figure out how I wanted to do them. In the name field if you type a word with # it figures out you wanted a tag and displays it as such. Example: CNN #news That way I don't add another field and you can quickly tag links just by typing. Search works over tags now too. So if you type news in the search field CNN would come up. 
I have been looking for some way to daemonize some of my go-based servers/scripts. The solution I came up with was to just created the file /etc/init/goip.conf (I'm running Ubuntu 12.04) with the following contents: # goip - quick ip resolve tool description "quick ip resolve tool" # Make sure we start before an interface receives traffic start on net-device-up exec /var/www/goip/ip Now I can use _service goip start_ (or stop) to start or stop my script. I have literally no idea what happens behind the scenes but for me, it doesn't matter because my script runs just the way I wanted it to. (and I no longer need a tmux session where the first 5 windows are go/python scripts that just keep on running)
Have you thought about learning [Julia](http://julialang.org/)? Though you could make a lot of worse choices, data science isn't something Go is specifically good at.
What does it provide over pgpool? http://www.pgpool.net/mediawiki/index.php/Main_Page
&gt; repetizzle
Golang has the primitives to build an easy to read hadoop / storm / spark which is important but the analytics libraries are no where near the maturity and offerings of python and the jvm. It has always and will always comedown to useing the right tool for the job; most jobs require more than one tool.
It's a method implemented in that file, line 105. It loops forever receiving on the channel until it gets closed or throws an error.
Can you explain why it loops for ever? Is it due to the below line? If yes, why would it loop forever? for msg := range ch { } or due to the function argument (ch &lt;-chan string) ? I believe the argument just mentions the type of ch there 
it loops for ever because that is how its defined ranging over a channel will loop for ever or until the channel is closed, returning one element from the channel and blocking until another item is available
Thanks, didn't know 'ranging over a channel' had such an effect.
http://golang.org/ref/spec#For_statements 
I don't understand what's my problem with Go. I really like the language and like all the differences it has to C, yet I cannot make myself prefer it over C.
Looks great! Thanks for sharing.
Hey there exec! Longtime no see (I'm sunderphon from GoT) I'll be checking this out, didn't know you worked on anything in Go :)
Of course, Go's my favourite language now. It's what happens when C and Python have a night of passion. Fast, beautiful code that's easy to write. Rosella's code is still messier than I'd like, I plan to clean it up a bit more over the coming days.
&gt; It's also possible to open the lid again and fetch the object that was previously thrown away, for a short period of time, until the trash is emptied. Not if that trash can had a built in compactor ;)
Don't judge a package by its blog post.
Very cool, I'm going to try this lib vs elastic and sphinx. One issue is other search engine/fulltext indexers named ferret (tho I'm pretty sure nobody uses the ruby one anymore) http://www.webferret.com/ http://shop.oreilly.com/product/9780596527853.do 
I have implemented Google's keyczar crypto library in Go: https://github.com/dgryski/dkeyczar . It has good cross language support. There are compatible C++/Java/Python/Perl/C# implementations too.
Got me there :)
it's not a full fledged fulltext search engine, mind you. it's just an "auto suggest" engine.
if it's an interface you're dealing with you may want to do something like [this](https://gist.github.com/chuckpreslar/6389988) to avoid potential panics in case it isn't actually a MapContainer.
Hey Harry, Tom here. Pleasant surprise to see you pop up over here. Glad to see you're enjoying Go :-)
[first thing I searched for on the demo page](https://files.app.net/htm9FZXo.png)
Very nice! I've been pondering how to do A/B testing for my current project, and this looks like a very slick solution. I love that it's not boxed into any one language, too.
I'm seeking for some help to implement the commands described in issue #1 or to implement some new commands that will blow gophers mind.
No, I just read RFC1459 and RFC2811, and viewed some raw IRC traffic. Architecture wise it's inspired by nginx. Central event processing goroutine, and then io on outer goroutines.
Nice. You should put some javascript restriction for like 300 ms for the user to type in. Else its going to bombard your server for no reasons. 
Here is a pretty good wrap up of setting up a go vim environment http://0value.com/my-Go-centric-Vim-setup
I thought I had a good Go/Vim setup until I read this--lots of good stuff. Though OP was looking specifically to merge the history so auto fmt-ing doesn't have an extra history item. The answer on SO seems to work fine for that.
That's possible if you were to integrate lua. The way I'd do it is to do some code cleaning/refactoring and load lua scripts that can register themselves as commands and have them call golang functions to send messages to channels, join/part users, etc. It's not too difficult to achieve, you could actually replace the entire switch statement in handleEvent with a map lookup for string → lua function, and the lua function would do all the logic. It'd still be pretty fast too.
got penis?
Good stuff! Thanks.
:!go fmt %
My main shock was that the LeapMotion exposes JSON through websockets in the first place.
I've been working on bindings to my lightweight cross-platform C library called Dynamic Windows... all the GUI functions are currently bound, but not the thread/event/mutex ones which I am not sure I need or not yet... Haven't really used it for anything except porting the test application (minus the thread test) but it works on Unix with GTK2/3, Mac and Windows... the library also supports OS/2 but Go does not support OS/2 currently. Source code for the Go bindings: http://bitbucket.org/dbsoft/godwindows Source code for the C library: http://bitbucket.org/dbsoft/dwindows Input is welcome.
Maybe Gustavo's [twik](http://blog.labix.org/2013/07/16/twik-a-tiny-language-for-go) would fit.
But where's Dick?
Add to your .vimrc: " Add Go plugins to the runtime path filetype off filetype plugin indent off set runtimepath+=$GOROOT/misc/vim filetype plugin indent on " Automatically format Go code on save autocmd BufWritePre *.go Fmt 
Ah... I think that clarifies things. Your initial post here made it look like you had something working, but that you were wondering if there was a "better way". What you really meant is that it wasn't working, right? You just get panics, right? First, to get code, indent all lines by four spaces. Second, I'm going to respond in runnable Go code, which you can get at [on the playground](http://play.golang.org/p/ghaYeP3llx). For Reddit-friendliness, I'll also inline a copy here: package main import "encoding/json" import "fmt" type MapContainer struct { M map[string]string } func main () { j := []byte(`{"a": "b", "c": "d"}`) var interfaceVal interface{} json.Unmarshal(j, &amp;interfaceVal) // At this point, you have an interface{} whose true type is // map[string]interface{}. Note fmt.Printf "reads through" // the interface{} to the underlying value, using the reflection // capabilities: fmt.Printf("interfaceVal's type: %T\n", interfaceVal) strings := interfaceVal.(map[string]interface{}) // but the values are still interface{}: valueA := strings["a"] // this panics with // "invalid operation: valueA + "\n" (mismatched types interface {} and string)" // fmt.Printf(valueA + "\n") // you would need: fmt.Printf(valueA.(string) + "\n") // which printed b // Now what you're looking for is a map[string]string, but we can not // go straight there from here: // s2 := interfaceVal.(map[string]string) // yields a run-time panic of // "panic: interface conversion: interface is map[string]interface {}, not map[string]string" // I'm not 100% sure, but I believe Go is entirely invariant in computer // science terminology (see // http://en.wikipedia.org/wiki/Covariance_and_contravariance_%28computer_science%29 ), // so for a type assertion to succeed, you need an exact match. // This is actually the easiest case to understand, which is probably why it is // what Go uses. Suppose my JSON was instead {"a": "b", "c": 1}... what would // asserting it as map[string]string _do_ with c? Silently discard? Error? // There isn't really a right answer, AT THE LANGUAGE LEVEL. In a moment, we're // going to observe that the JSON library has made a different choice, but at // a different abstraction level. // All that said, you now have a couple of choices. You could: var stringMap map[string]string json.Unmarshal(j, &amp;stringMap) fmt.Printf("String map: %#v\n", stringMap) // or var mapContainer MapContainer json.Unmarshal(j, &amp;mapContainer.M) fmt.Printf("mapContainer: %#v\n", mapContainer) // Two more notes. To directly get the map container, you need: var mapContainer2 MapContainer json.Unmarshal([]byte(`{"m": {"a": "b", "c": "d"}}`), &amp;mapContainer2) fmt.Printf("mapContainer2: %#v\n", mapContainer2) // Note I had to change to a capital M for that, to make it public. // And finally, note the JSON library WILL just discard things: var mapContainer3 MapContainer json.Unmarshal([]byte(`{"m": {"a": "b", "c": "d", "e": 3.2}}`), &amp;mapContainer3) fmt.Printf("mapContainer3: %#v\n", mapContainer3) // but that is a choice made by the JSON library, rather than the language. } 
Can you push out another link to say /r/linux about this? I'm interested if dwindows will allow me to use just C and not Objective-C on MacOS X. Also, how does it look? I'd love to see this.
thanks. That's really helpful. for future reference: The reason why interface{} cant type assert to map[string]string even if the json byte string seems ok is that "javascript object is loosely typed". it is ok to map both string, int, or even function in js. That's why golang chooses to use map[string]interface{}
Very cool. As someone who is interested in building search engines and using relevant algorithms, can you suggest any good resources? As of now I'm having a hard time understanding how you're doing index creation let alone queries.
From reading the description it seems like it's going to be a local email client written in Go with encrypted SQLite storage. I assume the UI is browser-based (JS is mentioned) although this is not specified. Not something I'd use, but I wish them luck.
anyone using docker for golang? I'm trying it
I still meet people that have never heard of it and so adding the name Google helps to give them a point of reference.
Great @DavidScone. Going to implement that +1
Nice! Just a small note that maps are not threadsafe. 
Maybe if you're intimately familiar with the domain space it would be passable, but if someone I worked with created a method with a signature like this, I might murder them. func TopocentricEcliptical(λ, β, s, φ, h, ε, θ, π float64) (λʹ, βʹ, sʹ float64) You shouldn't need several paragraphs to explain what the variables are. Descriptive variable names trump 1:1 notation parity with the book IMO. &gt;TopocentricEcliptical returns topocentric ecliptical coordinates including parallax. &gt; Arguments λ, β are geocentric ecliptical longitude and latitude of a body, s is its geocentric semidiameter. φ, h are the observer's latitude and and height above the ellipsoid in meters. ε is the obliquity of the ecliptic, θ is local sidereal time, π is equatorial horizontal parallax of the body (see Horizonal()). &gt; All angular parameters and results are in radians. &gt; Results are observed topocentric coordinates and semidiameter. Other than that, interesting library.
I get what you are saying and in my own coding I generally agree, but those names really ARE descriptive and well suited to the function for that domain. I think if each variable is well described then it gets a pass. Unicode code is a good thing.
Indeed, but they are only ever accessed by the same core thread, the client-specific ones never touch them.
A good program shouldn't be generally readable, but highly-readable within the domain that it's situated. As you point out, it even has great documentation for those who are not so familiar.
Exactly! Your browser, no plugins, can attach itself and go... the JSON is really simple and comes in fast (sometimes over 30 fps)... There are lower level API/SDK but why bother going that low as the data coming in is as fast as it's gonna get.
Oh wow, this is so awesome. Thanks! BTW: Another method would be really cool, where you have an int of the thing, and let it pick method automatically: inflector.FromNumber("People", 1) // =&gt; Person inflector.FromNumber("Person", 10) // =&gt; People
What about words that have different plural forms? Person =&gt; persons or people depending on context, fish =&gt; fish or fishes etc.
Yeah. Go has no way to statically know that every field will be a `string`, since the types of the fields are determined at runtime, so it has to use `interface{}` to represent the values of the fields.
Oh boy. Really?
If they ever come out with a way to develop Android in Go rather than Java, I'd be ecstatic.
Would like to see the performance of a standard package MUX and see how it performance in this benchmark.
While it's possible Go will have a lot of ground to cover before it can be a viable replacement. Java's utility doesn't just lie in the language but the libraries around it. It will take many years for that mound of software to be replaced. However, I'm a long time java developer, and the first language to interest me other than java is go, so I'd be perfectly happy if it were to happen. :)
I love go but its no where close to mature enough to replace Java. Need to get Go going on Android first. 
Two things need to happen for Go to replace Java: 1. Go for Android 2. Enterprise software adopting Go.
I'm deeply sorry for being so offensive but FUCK ENTERPRISE SOFTWARE
It's kind of hard to have mobile software without enterprise software to back it up...
I've programmed in Java since the first days of the beta. I don't see any library I'll be missing.
This article is horribly bad. I guess it was submitted to BI by the guys of iron.io.
Or 'canon' which has a different plural depending on whether it refers to the ordinance or the ordained. OTOH, in the absence of good localisation, this library is better than nowt.
iText would be useful. Also, a go-native SQL Server driver would be fantastic.
I don't understand the hate of enterprise software? I mean I'll be the first to go to open source, but enterprise software is just that. Enterprise. Companies have enough money to pay for it and they get what they pay for. They get very responsive bug fixes and support because they pay a lot of money for it. When people start marketing enterprise level software at non enterprise markets then you'll get problems but as long as it stays enterprise I don't see why there would be a problem? Companies need solutions that work for them. Just my two cents.
Absolutely terrible article. Go was created as a systems language, not as a replacement for Java to shut Oracle out of Android. The title of the article is inflammatory and incorrect. The content is just an advertisement for Iron.io. Reported as spam. 
as much as I like Go (and I actually love it), I think that Dart would make a better programming language for replacing Java within Android. Go really shines for system level software. 
&gt; Go was created as a systems language I'm with you on the other points but Go **is** replacing java as a web application server language for many of us. 
It really isn't.
&gt; Do folks find a simple url/pattern -&gt; handler func sufficient? Method + Pattern =&gt; Handler, yes, absolutely.
It's not what the dictionary definition of that term is, but what it implies in 90% of the cases: huge, ever-growing unmaintained software suites that allow -- even encourage -- business-driven shit to be piled upon it endlessly. Then again, it's hard to top the feeling of professional pride when you replace a multi-tier software package spanning millions of lines of code and several servers with a hundred line python script that actually works. Yes, I exaggarate a bit. But just a bit.
We wanted to support OAuth2 in Go and it was tricky to do in a TDD way, so we built Gomniauth. Today it supports Google and Github, but it's VERY easy to add providers. It's also general enough to support beyond OAuth2, so it'll likely grow as the community uses it and decide what they need. It also plays very nicely with our Goweb package - http://github.com/stretchr/goweb, and we've included an example app that you can copy to get going. We'd love any feedback, issues, pull requests etc. and think this is a step towards making web development in Go a realistic option.
Equivalent packages that have been tested for years and are stable/reliable?
"Business driven shit" makes money, enabling you to have a job. :)
Would love to see some twitter/facebook support. Reminds me of omniauth for ruby, very easy to work with!
Iron.io is the first company that openly expressed they were using Go. I know a certain company that is using GO for HL7 translations... And its a rather huge code base. 
There is one thing I am slightly confused about. Where do put the git (bzr, etc) repository you are currently iterating on? Do you put it e.g. into src/myproject.org/projectx/? If so: do you ever check in the root (which contains ./bin ./src ./pkg)? Also, but unrelated: where do you keep assets such as icons or data files?
Pretty sure I've been seeing loads more companies writing articles about them replacing key parts of their systems with stuff written in Go long before Iron.io. Granted, I don't sit at reddit every waking minute of my life so I may have missed some articles talking about it, but even then, the first one I seen on them using it was quite some time after others had come out saying they were. [Incomplete list of companies who have openly stated they use Go](http://go-lang.cat-v.org/organizations-using-go)
&gt; regexp uses []byte For every function in the regexp package there is an equivalent function operating on and returning strings. &gt; Different assignment operator is used depending on whether you are inside &amp; outside of function ie. = vs := More correctly, `var =` vs `:=`. You can use `=` in functions all you want, it's simply something different than `:=`. &gt; Type casting Go has no type casting, only conversions.
&gt;Else (or else if) has to be formatted properly, where the else is on the same line as the curly bracket from the if clause. Weird. Semicolon insertion, woo! &gt;Different assignment operator is used depending on whether you are inside &amp; outside of function ie. = vs := Uhh, isn't `:=` just shorthand for declaration and assignment in one? I suppose the complaint here is that Go is statically typed. &gt;If you’re using JSON and your JSON is a mix of types, goooooood luck. You’ll have to create a custom struct that matches the format of your JSON blob, and then Unmarshall the raw json into an instance of your custom struct. Much more work than just obj = json.loads(json_blob) like we’re used to in Python land. Well, technically, you can unmarshall to an `interface{}`, can't you? 
This is quite nice but although I'm very new to Go I feel like this should use the built-in `log` package. Or at least have the same features (prefix, flags, ...).
What bit me for a full day is the non-existence of KeyErrors. In Python: my_dict = {} print my_dict["hi"] results in a KeyError. In Golang: my_map := make(map[string]string) fmt.Println(my_map["hi"]) prints an empty string! ~~Workaround:~~ How it's done properly: my_map := make(map[string]string) value, ok := my_map["hi"] if ok { fmt.Println(value) } else { // Complain }
Yes, I agree. This is a 0.1.0 version and although the usage/interface won't change I'm planning on expanding the implementation to provide those things as well. Whether it's gonna be built on top of the stdlib's log pkg or not, I'm still undecided. 
I'm afraid I'm on my phone, so can't just PR this for a while, but a few comments: - Always use defer if you can when unlocking Mutexs, as it stands a panic (say in the String() method of something passed to Fprintf) could leave that mutex locked. - It's often useful to provide a utility function like func (l *Log) IsDebugEnabled() bool {return l.level == DEBUG}, which can be used to guard calls to Debug methods if there is significant work involved in constructing the arguments. - This is more personal preference, but I wouldn't return errors from the logging methods. 
&gt; * It's often useful to provide a utility function like func (l *Log) IsDebugEnabled() bool {return l.level == DEBUG}, which can be used to guard calls to Debug methods if there is significant work involved in constructing the arguments. Or maybe just make the level public: `Log.Level` instead of `Log.level`.
His current way makes chaining operations less verbose: goset.Subtract(goset.Union(foo, bar), baz) vs. foo.Union(bar).Subtract(baz) 
It is less verbose, but I'd argue that performing one operation per line is clearer. With the chained version the syntax doesn't give an immediate and clear indication of what is happening to what in what order, you have to look at it for several seconds. With the unchained version all it takes is a quick glance. I'd also argue that my proposal is more idiomatic. It treats sets as almost a basic type (add, remove and clear obviously remain methods) but operations over them are standalone functions, like with strings. 
Hey nomorepassword! Did you know an anagram for your user name is 'worn sparse mood'?
&gt; With the chained version the syntax doesn't give an immediate and clear indication of what is happening to what in what order, you have to look at it for several seconds. With the unchained version all it takes is a quick glance. You think so? I find the chaining easier to mentally parse - operations occur in order from left-to-right. With nesting, you have to find the innermost statement and start working your way outwards.
There's also https://github.com/golang/glog, written by Rob Pike himself and used as the logging library within Google. It's leveled, writes to different files according to level (files for more verbose levels include the less verbose messages too), and optionally outputs to stderr too.
Let's be concrete : what package precisely do you think might be missing or not strong enough in go ?
Its the unknown unknowns that bite you. Time and heavy usage is about the only thing that mitigates that.
Yeah. I'll plan to look it into it and add external methods just for those operations. As you said it is possible.
Precisely. Also a fair amount of timing information for statistics.
Also, another way of doing this kind of work is layering handlers, like https://github.com/streadway/handy advocates.
A panic cannot be caught though. So it really can't be used as an exception
You can "catch" a panic via a `recover` in a `defer`red function. http://play.golang.org/p/bSxW9RFCpF But that doesn't mean it's "easy" or a good idea to use panic/recover as error flow control.
Nifty! I'm a fan already. 
Maybe it's worth mentioning that switch is more flexible in Go than people coming from C (for example) might expect: http://golang.org/doc/effective_go.html#switch
glog takes a different approach on how to do levels, I wanted something that is more common and similar to other well known logging libraries. IMO, It's easier to use and specially useful for whoever is coming from other languages.
If only the attribute was public, it would be a pain cause the caller would have to know how to compare the level of intended logging vs the log level. For example: if log.Level &lt;= llog.DEBUG Since we do have a method for each level for logging it does make sense to following the same approach for checking for them.
 $ go help gopath This explains it all.
I love me some Go. Really do. But it's not going to be replacing Java, not anytime soon. First we need to get the tooling in place to even begin taking this statement seriously. I'm sorry, but just because I'm ok with Emacs/VIM and configuring a dozen other plugins and scripts to get auto-complete going doesn't mean the legions of Java developers are. Eclipse/Netbeans are pretty feature-full productive development *environments*. Go has text editor plugins sure, but they just don't compete with the tools Java devs are used to. Let's try this again once I can click a "play" button and step-through Go code in a real graphical debugger or can get syntax highlighting + auto-complete seamlessly working. It took me days to setup my Vim to be a decent (not great) Go environment, almost no Java devs would be that patient from what I've seen.
Very nicely done. I like the sequence in which things were laid out.
im programming java in vim for years, i hate oracle and getting kinda bored of enterprisy java environment, need fresh meat , go sounds cool even if another industry giant is behind it
I've added functions for Union and Difference. I'll add Intersection too in the following days: https://github.com/fatih/goset#multiple-set-operations Thanks all for feedback! :)
I've add additional functions for those, you can see here (Intersection is coming soon): https://github.com/fatih/goset#multiple-set-operations Thanks for the feedback! :)
I'm sorry, but this is just silly. If you know you can't handle an empty string then you should be checking the value. This is no different than in python. The fact that the key exists doesn't mean anything if what you care about is the value. There's nothing stopping me accidentally or otherwise, putting an empty string in your map/dict.
Not familiar with the term package testing, but trying to design this library to be very extensible and flexible so it can be combined with other libraries to perform more advance integration or black box testing. Tests created with this framework should be designed to last the lifetime of the product being tested (and expect to be updated and maintained continuously). So the advantage is only if you are looking for a powerful extensible test framework that is written in Go. The framework does little until compined with other testing libraries. For instance, a selenium Go plug to make a GUI test framework or RESTFUL library to test APIs. The test manager and each suite also have Setup() and Teardown() functions that make it easy to setup an environment and cleanup when finished.
The different states are useful to show clearly when a failure condition for running the test has been meet and let user determine what to do. It's usual in the Setup of a test or suite that the conditions needed to run cannot be met. The test should properly fail and have the choice to continue running the test/suite or if it's critical error and the run should be aborted at that time. 
There's a testing package in the Go standard library - ie `import "testing"`
There are also other third party test libraries for Go, but there is always room for yet another test framework the same as there is even room for another IDE to be written. Just can't get enough of that stuff. The "testing" in standard library I believe is more suited to white box unit testing of code while goQA is meant to be used on the integration side of testing. 
Downvoted because I dislike this pattern of learning a new language and then immediately publishing performance data about it, before you know how to write idiomatic or performant code in it.
So you get a bunch of images and output a single large .CSS file with their base64 content?
We actually output as part of the json return when the mobile application makes an API request: { "success": true, "message": [ { "id": "", "date": "", "title": "", "author": "", "thumbnail": "&lt;img src=\"data:image/jpg;base64, ...\"&gt;" "description": "" } ] }
Any plans for a server? :)
Fantastic!!! Just what I was looking for.
Upvoting for you describing your downvote and making a good point.
Upvoting *you* for explaining your upvote of Brad and reinforcing Reddiquette. Bugger - this could be turtles all the way down...
&gt; Mouse over for explanation... I'm hovering my finger, but nothing's happening... :p
I think he means business-driven as in "We're not going to refactor the codebase because we don't see the financial advantage in paying you to build something that already works. Here's fifteen pages of new requirements that need to be implemented by next quarter." And that's how the worst monstrosities grow.
On mobile Safari you can tap in place of mouseover and get the same result. 
Monstrosities grow for all sorts of reasons. I've seen them grow even when the best technical minds had complete control of the direction of development.
The first step of the quick start guide is to pipe the output of some wget command to your shell. The URL in question 404s. It's not exactly the best way to build trust.
I was gonna say before I opened this that I just read a really good article that actually works annnnd this is that article.
Is there any reason NOT to use 4096-bit RSA with SHA512? Computation is getting cheaper by the moment. The use of SHA1 concerns me.
So it basically just negotiate websockets?
I hardly think publishing metrics is a bad thing, as it allows you to understand what's going on. The author even pointed out where he might be doing things wrong or slowly in the bullet points before the benchmarks. This didn't strike me as trying to be definitive.
I replied with some comments.
Just want to say thank you for this series of posts. They are flippin fantastic!
Loving these posts!
We don't need to use .goc files anymore?
elseif in templates &lt;3
+1
Why not return filled slice instead of filled buffered channel? Slice also have support for range iteration, and you have index for free (though, you ought to mark it by '_' if you don't need it). I suppose, it still will be much slower than callback cause of memory allocation, but much faster than channel cause no need to call synchronization primitives.
What I want to know is *why* you need an iterator. From experience, there are usually only 2.5 cases where you need iterators. 1) When the *collection* is actually already a map, slice, array, string itself, 1.5) when it's e.g. a struct that wraps one of these or 2) it's something to be computed, in which case the following is clear and is already the common idiom. for i.Next() { v := i.Value() } It's doesn't even put any burden on the implementer because it's as simple as: `.Next()` does the calculation and stores the value somewhere and `.Value` simply returns it.
Reading data sequentially from disk is also a very valid use case. i.e. http://godoc.org/github.com/jmhodges/levigo#Iterator
That falls under `2`. i.e it's doing more than simply returning a stored value. Also, that api could easily be simplified to one call instead of two by changing `.Next()` to do the `.Valid()` check and returning a bool
 import ( . "gist.github.com/5286084.git" . "gist.github.com/5639599.git" . "gist.github.com/6433744.git" . "gist.github.com/6445065.git" .... Please let's not make a practice of this. Gists are intended to be self contained and easy to read. Here's a self contained version of the linked code. https://gist.github.com/eikenb/6487209 
ewencp.org thanks for the article. I appreciate the code samples and your thoughts about the code. Who would have thought when I shared your article in G+ it would create such a discussion. LOL Keep Writing !!
It should have been 120 seconds. If you try and run all 155 stations at the same time you will get DNS lookup errors. NOAA does not like you slamming their servers. The number of simultaneous requests need to be managed. The work pool provides two things. First it lets you manage how many requests are being made at any given time. Second, you can performance tune the application. Less is always more when it comes to multi-threaded/routine applications. Read this article for more insight. http://www.goinggo.net/2013/05/thread-pooling-in-go-programming.html 
What is your use case for this?
I agree with the goal you're trying to accomplish by creating that all-inclusive version - thank you for doing that btw. I disagree with the method. I mean, it's fine here as a one-off thing, but I wouldn't want to keep doing this every time. :) You did it manually. That doesn't scale. I'm working on a tool that will accomplish the same goal, but automatically, and without creating duplicated code. (It will let you easily browse imports of the current package, see what imports it, and effortlessly tell where each type/func is declared, etc.) I actually use the code in those gists inside my personal projects. By keeping each gist a separate reusable module, it makes it easy to import only what you need, and more importantly, avoids code duplication, making it easier to make improvements.
You can read about it at https://groups.google.com/forum/#!topic/golang-nuts/psZ_WrfCEqY. Or just look at this screenshot. http://img600.imageshack.us/img600/9470/u0qk.png Essentially, I had a small unlabelled button that I was using for testing purposes, but I had a thought "oh, it'd be nice if a tooltip showed me the source code of the button's action func, so I wouldn't forget what it does". Then I realized it wasn't trivial, but potentially possible. I took up the challenge and a few days later I was thrilled to see it working! :D
It's cool to see go's reflection is that powerful, thanks for showing us the code. Regarding the use of gists &gt; By keeping each gist a separate reusable module... I have no clue what "gist.github.com/5286084.git" is unless I clone it or view the gist in a browser. That's way too much work before I even start reading your code. Make a repository with descriptively-named go packages for each helper. It's the same benefit, plus readers of your code have some of idea of the intent up front: "github.com/shurcooL/utils/check_error". http://golang.org/doc/code.html#Organization
This is my first project in Go and I would love some feedback. It's a very simple HTTP-based message queue inspired by Amazon SQS and Bitly's simplequeue (https://github.com/bitly/simplehttp/tree/master/simplequeue). It was written mostly as a toy/learning experiment but it seems pretty solid so far and I could foresee using it in production somewhere. Feedback would be great.
Stupid Question: what is the use case for this? I have seen several of these services popping and am wondering what this can be used for. 
Message queues represent a big level of abstraction that you can use in a spectrum of ways. As a *simple* usage, imagine you are copying Google. You have daemons crawling the Web but you also need daemons to process the results of the crawl, and you want to be able to scale your "crawl" fleet and your "process" fleet independently. A message queue is one way to tackle that problem. Your crawler processes can shove the results in a big queue, and then the processing workers sit in (basically) this loop: while True: item = message_queue.get(wait=True) do_work(item) Your crawler software and your processing software can be on different machines using the OP's system, or any system like it, as an intermediary. Cool side effect: you can upgrade your processing fleet or even completely turn it off, and the results will just back up in the queue a bit and continue processing when they come back online. One of my duties as a site reliability guy is keeping an eye on queues throughout a system during peak traffic. On the *complex* end, you can build your entire system around a message queue and think of it as a bus for passing RPCs and data around. There are models in AMQP, a widely-implemented standard, for RPCs of this nature. RabbitMQ is widely used, and has a [tutorial that might help](http://www.rabbitmq.com/tutorials/tutorial-one-python.html). Message queues are one of the keys to scaling a big systems architecture (particularly web; delayed work is really useful in many products), but if not administered well a message queue can rapidly become the bottleneck of an entire system. I've done a lot of work in this area, so I can name a few more names than OP already did: RabbitMQ (and the AMQP spec), ActiveMQ, beanstalkd, ghetto queues with Redis, and so on. Happy Googling! **Edit:** Just thought of something: you know how thumbnails take a while to show up on Reddit posts? There's a message queue behind that. Fetching and resizing an image takes a while, and you don't want to block the story submission on the process so there's a message queue of "thumbnails to fetch" sitting in the middle. When the thumbnail is downloaded and resized, the story is updated in the database with the thumbnail.
NSQ looks pretty neat but seems orders of magnitude more complex to me. Aside from both being written in Golang I think they're fairly dissimilar as far as message queues go. At their core, all message queues are trying to achieve the same goal of asynchronous interprocess communication but there's so many out there that the differences become very subtle. i.e. HTTP vs custom TCP protocol, durability, message delivery guarantees, etc.
Is there concurrency in this queue system? I know it sounds oxymoronic but just asking.
Thanks! beanstalkd looks interesting- very similar semantics to queued. I'd be curious to hear folks' opinions about the pros and cons of an HTTP interface vs. a custom TCP protocol. Personally, I'm a fan of the HTTP interface because it is well understood and does not really require a client library to be written.
Yes. It supports multiple writers and multiple readers on the same queue.
When you Unmarshal a json string into a struct you'll get most of the data validation for free. (ie. what field is what type). Your struct is basically your schema. You could use tags to further validate/constrain the fields. Though, the length of arrays, range of values should be a simple if statement so it might be easier to just do that depending on how flexible you want to be Here is a few ideas how to do it: https://groups.google.com/forum/#!topic/golang-nuts/UVJ5Gr48RVY
What I do, and it seems like other people as well, is this: a) If the fork is supposed to be a new implementation that will deviate from the original repository, rewrite the import paths and use as a separate pkg; b) if it's a fork with changes that are meant to be merged back into the original repos, simply add your fork as a remote on the repository path, keeping the import path as the original. Hope this help.
Is it de facto to write the queue to disk for each request? Wouldn't you see a boost in performance if you only wrote to disk upon exit, or even in a Go routine?
Ok, I'm just a programmer so this might seem weird to ask BUT. Why the fuck are you doing all that bullshit when you know it's an int? I mean you make the slice in the first place. Why are you going round-about when you already know what it is? It's not just you asking though, I've seen this kinda question a lot. I just don't see why you are working so hard to not write a for-range loop.
Go is not a functional language, and these will perform very poorly compared to simple for loops. This isn't a knock against you or what you're trying to do; I did the same thing learning Go. But this kind of thing fits poorly with the language, and I think it's worth embracing the things Go does well and seeing where that takes you. Reflection is generally not used as a replacement for generics; take a look at [sort](http://golang.org/pkg/sort/), for instance, which uses interfaces instead.
Per-message persistence/non-persistence seems a little overkill to me. I do plan on implementing an in-memory store as an alternative to the current LevelDB store. It might also be nice to have third option that is the combination of both: messages stored in memory with a Goroutine asynchronously writing them to disk.
[More details in the mailing list](https://groups.google.com/forum/#!topic/golang-nuts/3cqoCCstuac).
&gt; auto-complete seamlessly working. You mean something like gocode. 
I'm not asking about them in go. I'm asking why are the looked at as much more powerful than just a range loop.
&gt; Even Python, whose Benevolent Dictator for Life views those idioms with disdain, is friendlier than Go To be fair, while Guido dislikes reduce I don't think he minds map or filter. He does prefer list comprehensions to map and filter for syntax reasons.
Map and filter are expressions, whereas a for-range loop requires declaration and mutation of a collection. It's not the biggest deal in the world, but transformations are so common that it's nice to have a short-hand for it (both for writing and reading code). It's sort of the same reason why people might want a ternary expression instead of a declare-variable-if-else-mutation thing. Go notably does not support this either. Since in practice Go does not cater for map/filter in an idiomatic way I would personally do as you say and just use a for-range loop.
Not a fan of functional programming, am I correct? The true power of map/filter/reduce and first-class functions in general comes from their composability. You take this function X, you take this function Y and you can create function Z that is X * Y and you can pass Z around , or partially apply it, whatever. It's all about how you combine them. Look at this - http://clojure.org/sequences or http://msdn.microsoft.com/en-us/library/ckzcawb8.aspx. When you have side-effect free functions that you can combine freely, programming in many ways becomes a sort of exercise of figuring out which lego pieces you need and then just snapping them together. It's a very powerful (but also very difficult) way to write software. You could potentially implement most of these with channels and range, but it wouldn't be pretty (or type safe). 
One does not simply write hardware.
Fuck everything about PayPal.
Bit of shameless self promotion but I wrote a blog post a few months ago about this very topic: http://mattyjwilliams.blogspot.co.uk/2013/06/why-im-happy-to-live-without-generics.html
with `type Basket []BasketItem` you can just say `Basket{{"Apples", 5}, {"Oranges", 6}}`. You could also define your total function as a method on the Basket type. `func (b Basket) Total() int { ... }`
Nice blog post :) Yeah, if the language contributors haven't implemented it, it may not be particularly sane in go.
The reflection in my implementation has way too much overhead compared to a simple for-range loop to be useful for large computation. More importantly you can use type inferencing on a slice of interface{}s in a for-range loop, so you can avoid the typecasting. Not too mention the ridiculous amount of verbosity.
Maybe a little bit off-topic here but I'll ask anyway: how do users get identified? I mean, you can't just go in a store, grab some stuff an leave. How does the staff know that you paid already?
Have you run `strip` on them both?
The binaries that you are complaining about being different sizes, of course. Run `strip test` on both binaries and see what happens to their sizes. I do rather hope that you are not the one who downmodded my perfectly cromulent question, if you don't even know what it is.
strip would have been run on the resulting binary. It removes debugging and other symbols from the binary. I am not familiar with the distributed compiler for Go, but it might be possible that the compiler does this step while the standard go build does not. Again, only conjecture. 
`go build` certainly does not on my machine on "go1.1.1 linux/amd64", which is why I ask. This is not the "base" project, but I just compiled one of my real projects here. go build generated a binary of 3,909,944 before strip and 2,776,080 after.
Thanks, I will try that at home. I don't have the setup on this PC here. &gt; I do rather hope that you are not the one who downmodded [...] I did not. I rarely downvote anything.
Is the binary distribution 32bits? Also, try building your app w/: go build -ldflags "-s"
Go binaries are statically compiled, which basically means that all of the library dependencies are compiled into and included with the final executable. This increases size but has the arguably more important benefit of being much more portable across systems.
That's an interesting approach. But at my company we just use git submodules instead. And we clone all the remote repos locally, and then clone from the local mirror. It is definitely a hassle to first set up (as opposed to just running 'go get'), but it is then easily reproducible. Git submodules also has its own caveats, but I'm satisfied with our current setup. I reserve the right to change my mind in 6 months though.
Isn't strip reliably unreliable on Go binaries?
With a source compiled Go, I get a 1.5M binary. ArchLinux 64 bits Go 1.1.2
How do you manage external dependencies?
&gt; Is the binary distribution 32bits? No, both compilers are for 64bit. I'm not trying to get smaller binaries. I'm just wondering why there's such a difference in size when using one or the other.
I use Manjaro which is based on Arch. What do you get when you use the binary distribution? 
How does this deal with someone deleting their git repo?
Also, separate your ops to interfaces... e.g. http://play.golang.org/p/OPN9vDS0tF You can easily store the operations in a map and make the calculator cleaner.
I know that ;)
It uses the local copy you have. Which you obviously have because it would be insane to have your important software depend on third party hosted code. 
With the package (go) from the ArchLinux repository, I get a 1.5M binary.
We do clone all the external dependencies. So we'll use 'git clone --mirror' to our own git server. Then we'll set up the git submodule to clone from that for each developer's working directory. For projects that we don't expect to need extensive modification (maybe just bug fixes), we'll keep that under the original path (like 'src/github.com/somebody/someproject'). If we're planning on changes that may not be accepted by the original maintainer, then we'll clone it and put under another path (like 'src/github.com/mycompany/someproject'). And any proprietary software that won't be released will be under 'src/mycompany.com/internalcode'. If I want to publish changes for 'someproject', I'll go into that directory and add a new remote for github.com/mycompany/someproject, and push to that as well as our own git server. 
Not really, I wrote Johnny-deps for Vivid Cortex (the company I work for) and maintained it for a while, but the CEO took over decision making on johnny-deps itself so I decided to continue my work on it on a fork I can control. johnny-deps is still maintained under that name on [their repo](https://github.com/vividcortex/johnny-deps).
[Even more information](https://groups.google.com/forum/#!topic/golang-nuts/CwdIJZs6Tfc).
Right. But I thought managing third party hosted code was the point of this app? Maybe I'm thinking of it wrong and that you would keep a fork of the repos you use as normal but instead of only updating the code in the repo when you wanted to upgrade, you kept it updated all the time and used this to specify the version to use. Not sure if that really buys you much, but I can see how you'd use it that way.
Would love to try it but it needs go tip currently. I will wait until it works with a release (1.2 I hope :) because I don't want to blow up my dev machine with a 2nd version of go installed. 
"You don't need this lock file to compile your package"..I dont get this. Then how do you track third party applications if they change because I did something like "go get -u .. ". Does this create those hashes based on the .go file contents? Or that hash value is git, hg commit from the remote side?
Dondur basically helps you to save your current go environment/dependencies into a file. And then on a different machine, when you do `go get` from scratch to get the dependencies, you can regenerate the lock file and make sure that the hashes are still the same. These are the git and mercurial revision hashes of each packages that are in your current go env.
Apparently, dondur just lists all dependencies, it still doesn't provide any command to make sure that you install the right versions (something like ``dondur build``).
Thank you!
From what I've seen, NSQ is actually at a good balance point between simplicity and complexity, when compared with other options.
You could use [gpm](https://github.com/pote/gpm) which does exactly that. It'd be awesome if the file generated by Dondur was on the [Godeps file](https://github.com/pote/gpm#the-godeps-file) format.
Does this mean gpm might support other DVCSs? https://github.com/VividCortex/johnny-deps/issues/30
That could be in the roadmap if there is enough interest on the feature. I'm opening a [github issue](https://github.com/pote/gpm/issues/6) on the topic, any feedback is more than welcome. :)
Not anymore. Strip was patched. 
Only for old versions of strip. 
The idea behind dondur is, It does not try to replace go tools, It complements go tools by generating a file which might be useful if your build fails in the future because of the package versions. Thats is why there is no dondur build command. 
For parsing XML, you may wanna check out https://github.com/moovweb/gokogiri
Looks very good. Just what I would need. Unfortunately, I'm not sure if I can use it. It appears to have c source code files, and I'm not sure if Google App Engine will correctly build and run that source. Thanks for the help regardless!
Simple content management system with files as Go templates. Maybe a web editor to edit and create the template files (aka pages). A template may contain simple things like {{define "title"}}, "content", "author" etc. but it can easily be extended by other users to suit their personal needs for smaller websites.
Something like [Sphinx](http://sphinxsearch.com/) with built-in support for replication and sharding... although I don't think one month is enough, but consider yourself challenged! EDIT: just noticed that someone else posted [this](https://github.com/EricR/phrase_search) today, somewhat related! EDIT: Sphinx is a pure C++ full-text search engine (like Lucene) based on fixed-schema documents that has a pretty flexible query syntax (includes stemming built-in so searches for "house" or "houses" or "housing" would return the same matches) but lacks built-in support for replication/sharding/distributed searches (currently done through hacks like delta-reindexing). It can read documents right off MySQL/Pgsql, from the output of a program (using XML) or via an API. It also exposes a daemon that understands the MySQL protocol for querying (so as long as your language of choice has a MySQL client library, it can also work with Sphinx). Having a flexible (schemaless documents like MongoDB), scalable (grow capacity horizontally by just adding new machines on-the-fly), distributed (sharding managed internally by the servers themselves), fault-tolerant (n-replicas per document) and FAST full-text search engine written in Go would be a great showcase for the language as well as an awesome tool to have! EDIT: It seems that the latest beta version of Sphinx now has support for [distributed indexes](http://sphinxsearch.com/docs/2.1.1/conf-agent.html), so that should serve as a good reference on how to implement it on the search engine.
How about porting http://sphinxsearch.com/ to Go and include built-in support for replication and sharding?
Interesting idea, but where would the content/data (variables for the templates) come from? json files?
Text files in the Go template format. The defines happen in these text files (one for each page) and they are parsed into the general layout via Go. So it would be a less ugly version of the same thing in PHP, where you have HTML and &lt;?php ?&gt; parts mixed in the same files.
Oh yeah, in the long run, I don't doubt that it would end up being pretty awesome! If you get a nice, useful prototype up and running in a month and plan ahead for replication/sharding/etc in the code, that should be a good start! Basically you have "documents", where each document has a unique ID (in Sphinx it has to be a number, but maybe you can be more flexible) and fields. The fields can be "searchable text", timestamps, or MVAs (multiple-value) fields like "[134,222,123]" or "['USA','Florida','Broward','Fort Lauderdale']". So let's say I have a document like this: ID: 1 text(Title): "Java J2EE Developer" text(Desc): "We're looking for a Java Developer with ..." number(MinExperience): 5 mva(Location): ['USA','Florida','Broward','Fort Lauderdale'] Then you query the engine to match "(Title:Java) AND (Location IN ('Fort Lauderdale','Pompano Beach'))" for example and that document would be returned. You can also make it as a standalone library (for applications that would like to embed a fulltext search engine) and a standalone daemon that uses the library to expose a networked search engine. If you decide to go this route, it would be nice to read Sphinx's documentation so you can have an idea of what features people need/use and plan ahead during the development to accommodate for their future implementation.
I have created a repo, to see if we can get enough support to build something this. https://github.com/oguzbilgic/better-sphinx
clones/ports of [bottle](https://pypi.python.org/pypi/bottle) and/or [feedparser](https://pypi.python.org/pypi/feedparser)?
Seems like there are many rss libraries for go http://godoc.org/?q=rss ? is bottle something like sinatra? simple web framework.
Is sphinx like a document db with support of full text index?
Just FYI: http://www.reddit.com/r/golang/comments/1ld1x5/building_our_fast_search_engine_in_go/
There is no kerberos support in Go, which is good to have for AD authentication.
I have created a repo for that too.
cool, will take a look! 
Single Sign-on lib/helpers. Maybe wrapping goauth2, and others, for Google, FB, Twitter etc.
Cool! lemme know if you've got any questions. Sorry, I never really created any documentation/how-to =S
That might be really useful, there is nothinf that already does that?
Soap library :) Edit: Soap Client* Not a soap server.
It's too bad there isn't a standard for that that works between Squid, Varnish, nginx, and so forth. It'd be nice to broadcast one signed UDP packet (or some other broadcast mechanism) and invalidate every cache that can hear the command, regardless of make and model.
https://github.com/skelterjohn/go.uik -- and start here and read this post: https://groups.google.com/forum/#!searchin/golang-nuts/gui%7Csort:date/golang-nuts/ijzMYMxSX4w/pFJbdRJ8WSUJ I honestly really like the way Go handles XML (marshall and unmarshall) and I am working with terabytes of XML files of about 500MB each. 
I have created a repo for that :) lets see how it goes.
There are already few packages doing that including a package from Google
Sphinx is a full-text search engine that pulls the documents to be indexed out of a database (MySQL/Pgsql) or reads them from the output of a program (XML) or that you can feed documents via an API (realtime indexes).
Where?? Been looking all over the place.. I've seen several starts but nothing that is maintained or even works anymore.
Oh, so does user make rules (for example, user is interested in the text after "location" and text after "title"), and then give Sphinx free form text to index into desired document structure? Or is the input already semi-structured data (in your example), and Sphinx indexes certain document elements, with full text index support?
I looked a while back (Github, and Google) and most of the ones I found wrap oauth 1.1 things (Twitter, and others) or oauth 2 (Google, FB, etc.) I haven't really seen anything that seamlessly wrap both.
No, when configuring Sphinx, you define an "index" (like a MySQL table) and then you define the columns of that index (like the columns in a MySQL table), then you insert documents (like MySQL rows) into the index, then you can use Sphinx to query the columns (kinda like "SELECT ... FROM ... WHERE (Title like '%Java%')" but WAY faster), but you can also filter your query not just by the matching text but also by other kinds of fields. So, for example, if you associate a latitude and longitude to a document, you can have Sphinx query all documents that have the word "Java" in the 'Title' and that are within X miles of a certain lat/long (by providing as filter a formula that calculates the distance of the two sets of coordinates).
These are really helpful, thanks for keeping them rolling!
As always, a nice, quick read that keeps me up to date with the most recent changes to the language. Thanks again for putting in the effort so the rest of us don't have to.
What's the difference between your project and Gorilla mux/pat?
Keep it coming. These go great with my morning coffee.
Where did you get this piece of information?
a little lack luster this week but still do love these.
Magnificent head of hair you have there Dominik ;-) Thanks for this!
Still fresh in Go but here are two things that bother me in your project: * Before filters should rather apply to individual routes than for the whole thing .. or both. * Personally I don't like that you are implicitly fiddling with the original request object/instance(?).
Well, unless you are a firm believer in the singularity, I don't think we should expect drastic changes/improvements to a programming language every week, right? Don't forget that this is discussing just the developments of core language plus code that (hopefully eventually) will be part of the standard library - not the full Go ecosystem.
This is my second project written in Go. It helps you to download manga from websites (online readers). Currently, only 2 websites are supported, but I plan to add more. I decided to write this tools, because the other programs are slow, buggy, closed source and full of ads...
Gorilla is a toolkit you could use to build some sort of template editing framework with. My project is more of a micro framework with very very basic template editing built in. It could be re-written on top of Gorilla (I probably would have done this if it was around when I was learning Go).
:)
I love seeing functional applications written in Go. There really isn't that much existing code to learn from yet. Thanks for posting this!
I see this going places
Could anyone explain why one would choose something like this over something like redis? Serious question. Or is this a mental exercise sort of thing?
I have to admit that I only skimmed the last quarter of your post. However, I had one big question: Are you sure that this saves resources when the tasks are strictly computational and not database-bound? If your tasks are hitting a database like MongoDB, I would think that it makes more sense to just have a DB connection pool that goroutines wait on. Have you profiled the app to see if it's actually maxing out your CPU? Have you looked at memory usage with the worker pool vs. without? I'd guess that this program is IO-bound, not CPU-bound. Perhaps try hosting the DB on a separate machine to eliminate CPU burden from the DB as a confounding variable in your test? That said, I like this post, and I like the idea of your blog. Keep it up!
The project offers basic redis functions implemented in a small amount of go code, could be useful for both embedded usage and learning go features (channels).
Everything is concurrent except situations where two goroutines should not act at the same time (like trying to write the same data at the same moment in time). How would you solve it instead? 
I've found that I seldom need to map over more than one data type in an application (say strings). For these situations, just writing a map, filter and reduce function that handles strings solves the situation for me. It's pretty quick and easy to write these in Go, as opposed to C, for instance. 
Oh I wouldn't. But the only thing that is concurrent here is reads. I wouldn't label it as a 'concurrent' key-value store!
"it's concurrent" can both mean "everything is concurrent" and "some of it is concurrent"
It's a pretty lame point. But whatever, if being intentionally vague about what your project is gets people excited then I'm out.
The description is that it is concurrent. It is concurrent. *you* are a pretty lame point.
This is a weekend project I started on as a way to learn Go that I quickly realized would be something worth sharing. It lets you queue jobs from Rails that are processed in Go, which can speed things up considerably. I would appreciate all kinds of feedback, and for anyone who wants to try goworker out, if you give me your email at the bottom of the page, I'll send you my contact info for some free one-on-one help getting started.
Please read the whole post just because I answer a few of your concerns that I knew readers would have. The MongoDB is being hosted by MongoLab in one of the Google data centers. Download the code and you can see for yourself. I made that database public. The profiling was very simple but I believe the simple profiling for this task proved the pattern is useful in some scenarios. Thanks for taking the time to read the post and write the comment. I appreciate your support.
Instead of `return spares` it is possible to just `return` on https://github.com/nathany/go-poodr/blob/master/chapter8/parts3.go#L28 :)
Definitely one of my favorite features of the language.
Cool, thanks!
I was going through the source, maniacally looking for uses of reduce, functors, monads and what have we and then I realized; functional applications. Oh, right ಠ_ಠ
Briefly looking at the code I found two issues (issues filled). 
It does seem to me sometimes that with Go's compiler actively supporting "just grab some stuff off of Github and see if it runs" that Go could use a stronger culture of labeling the code on Github. I don't want to rip into someone's "let's learn Go!" project for having numerous massive faults rendering unsuitable for production, ever, and on the flip side, I'd really rather not see a lot of people grabbing said projects and slapping them on to production willy-nilly. That will eventually come back to bite Go's reputation itself.
This was 95% learning exercise and 5% "I wish I had something like this back when I was working in trading". Not trying to kick Redis off the mountain; I love Redis.
If I add in persistence, it will be very manual (SAVE, RELOAD). Pub/Sub was fun to write. Still need to clean up a few things...
Could not agree more. I tried to get that point across when I put "v0.01" in the readme. I wouldn't change the current system one bit. It is up to the individual to realize the risk of relying on a library with a low version number. You only need to learn that lesson once.
&gt; It is up to the individual to realize the risk of relying on a library with a low version number. I agree... but there's a tendency for people to blame the language/community for such things, even though that is irrational. Then word gets out that language X has "low quality libraries". Haskell is currently working through this problem (especially for the particular type of low quality called "bad or missing documentation"). It has a package hub called Hackage, and on the current version, there's no distinction between "This is a core library supported by the best and the brightest and used by hundreds of packages" and "This is what some guy put up one day because he wrote a couple of lines of code after a few weeks of hacking around in Haskell". There's a new version coming out which is intended to directly address the problem, but it isn't out yet.
Operations on the map are subject to synchronization. At the application scale, work (including client I/O) is being distributed beyond a single thread.
Some suggestions: 1) move the allocation of the buffer on https://github.com/tristanwietsma/jackdb/blob/master/jackdb.go#L168 before the label NEXTMESSAGE so that you can reuse it (avoiding the cost of allocating memory for every new request); 2) instead of creating your own proto, reuse Redis' binary protocol as much as possible so others can reuse the client APIs - alternatively, you can use MessagePack to encode/decode the requests instead of plaintext, for performance; 3) Possibly split the Store's dataMap into n buckets for finer lock granularity (each bucket has its own lock and a hashmap of objects, instead of a single global lock for a single hashmap) - then you use [some hashing function](http://golang.org/pkg/hash/fnv/) to determine the bucket_id for a given key. If n-buckets is 1000, for example, there will be just one chance in a 1000 that a write operation would have to wait for a lock. EDIT: 4) Add support for key namespacing, so you can use the same server for different services and keys won't collide (Redis' SELECT) EDIT: 5) When creating a namespace, the user might define whether the store should be optimized for reads or writes. If it should be optimized for reads then you don't split into buckets. So you end up with two Stores, one ReadOptimizedStore and one WriteOptimizedStore.
Thanks! Excellent suggestions. Corrected #1.
This seems interesting too: https://github.com/mocchira/golfhash
If you get a chance to re-run your benchmarks, let me know, I'm interested in seeing how much of a difference that made!
I did a quick eyeball; not significant enough to show up (and fairly wild from trial to trial). I need to build a more comprehensive test suite.
I wish I could attend, but I'm a 15 years old from Central Europe. fml. It already sounds so fun.
if we get enough sponsors, we'll tape all the talks. Next best thing to attending.
The compiler forces you to be explicit in some cases in order to prevent certain classes of errors where the return variables are shadowed.
In original loop you wish to keep value, not the reference. Change theAnswer before returning, and defer will use new value. So that, all those defers you set up in the loop will use last value of variable (and remember, that defer runs on function exit, but you use it as if it runs on scope exit).
I would love to see some performance benchmarks :P please!
(author of the project here) Since it's not 1 to 1 redis compliant you can't run all benchmarks. SET/GET/PING are implemented for the sake of benchmarking. Testing GET (no pipelining): &gt; Boiler: redis-benchmark -t get -p 2000 -q -n 1000000 &gt; GET: 115890.25 requests per second &gt; &gt; Redis: redis-benchmark -t get -q -n 1000000 &gt; GET: 173280.20 requests per second Testing PING (no pipelining): &gt; Boiler: redis-benchmark -t ping -q -n 1000000 -p 2000 &gt; PING_INLINE: 112650.80 requests per second &gt; &gt; Redis: redis-benchmark -t ping -q -n 1000000 &gt; PING_INLINE: 170171.00 requests per second Testing GET *with* pipelining: &gt; Boiler: redis-benchmark -t get -q -n 1000000 -p 2000 -P 1000 &gt; GET: 881,057.25 requests per second &gt; &gt; Redis: redis-benchmark -t get -q -n 1000000 -P 1000 &gt; GET: 1,605,136.38 requests per second Of course it's slower than redis, but: a. not by a lot (without pipelining of course) b. you can save a lot of time by implementing logic that would require several roundtrips in redis inside the database. c. since Boiler is not single threaded, it enables you better concurrency, allowing you to do stuff you can't with redis, like operations lasting seconds. (Edit: Formatting) 
You mention wanting to find contributors. So why on earth post it on bitbucket?
I, for one, quite enjoy bitbucket.
never said I didn't, its simply not the place for finding random contributors 
You make a very valid point. I just grew to love it for private repos, as I don't feel like forking out money to github to keep my dotfiles and pet projects in sync, then quite enjoyed the system as a whole. I wish more people used it, there's nothing from github I'm really missing there.
You are absolutely correct. Silly mistake. I'm now passing the channel as a argument.
Nice video. I recommend using https://github.com/davecheney/golang-crosscompile for cross compilation. It handles everything for you.
You're right, this one is more in line with the *looser* language, allowing for different language constructs so that it differentiates enough from Go to find its place. I agree it will take a context switch to go back and forth, but then so does the dynamic features of the language.
Very nice! Thanks for the info!
No problem! Hopefully it makes your life easier the same way it did mine.
basing objects on maps is a bad idea in my opinion
why?
Sorry yeah I should have clarified. maps are slow and take up loads of memory. You can get the same level of flexibility with associative array with few items. Really a more structured approach is better in my opinion,having more of an object system. Though it is more work. 
That was the quick and easy solution to get started, as stated in the docs, performance was not a concern at this early stage. I know that I want to optimize for array-like objects down the road (using a slice when keys are dense integers), but for free-form objects, maps are nice for O(1) access. I'm not sure at the moment how else I could do this without giving up the purely dynamic form of objects.
It's quite a large 1 though. I recommend you experiment,but I've found that below 100 entries an associative array is quicker in go. 
Something like this type assocItem struct { k, v interface{} } type Assoc []assocItem func(a *Assoc) Lookup(key interface{}) interface{} { for _, item := range a { if item.k == key { return item.v } } return nil } Very basic. 
I've never flown into Denver, but the hotel chosen is 26 miles from the airport. There is no shuttle service and a taxi is estimated to cost $65. That seems like an odd choice to have a conference.
Oh neat, this looks very nice.
Nice!
I implore you to do some actual benchmark in the context of what you're doing. What you're talking about is essentially common knowledge/phenomena but there's no reason the map implementation can't be optimized for certain cases, and in fact I believe it is.
Question: Why do we need to use make if go hast "go install", am I wrong?
This is pretty cool! I've been wanting a lightweight, Go-native, (not(LISP)) scripting language.
run: go run ./cmd/mop.go build: go build ./cmd/mop.go install: go install github.com/michaeldv/cmd/mop Boring make file. You can tell it is completely unnecessary. Perhaps the developer has a background that included heavy use of makefiles and was feeling itchy not having one. edit: teedubu brought up a good point, which seems the makefile is necessary. However, I still don't like the makefile solution. It would probably be best, to separate the CMD project into another repo.
This is very cool. are there any benchmarks?
I'm not arguing there's some optimization to gain here, but this seems like a really odd thing to do. You're basically implementing maps again. I haven't seen this before. Is this common in other languages?
Not really. I am new to golang so that was a learning project for me. 
maps have to at least do what associative arrays do, but in order to scale they do a lot more. For a small number of elements it's frequently not worth it. 
Yes. You should experiment. all this is contextual.
Hi, this looks like a nice little project! A few things: * check for errors after Rows iteration (Rows.Err()) * I'm sure you're aware of this - not every schema has tables with id named 'id'
looks good!
I don't think you understood my point from before. So here's a couple tests that attempt to demonstrate. Save them as a_test.go, b_test.go, whatever and play around with them. Each one benchmarks your `Assoc`, a generic `map[interface{}]interface{}` and a specialized map based on the knowlege you have of the data e.g. `map[byte]interface{}`. http://play.golang.org/p/6wxb-0XXJs this one centers around the case where you have an integer array with &lt;= 256 elements. i.e the keys are bytes. http://play.golang.org/p/Y43kzty1uJ this one is essentially the same as before but using string keys. It's just to demonstrate a point but I'd hope that you or anyone else might point out any obvious flaws in there. With maps you also have the benefit of specializing without much effort on your part. By that I mean, you can store data in separate maps based on the type of the key so for integer keys you store it in an int map, string keys in a string map... if you want to go further you can even keep track of the keys and until you go above 255, you use a byte map. as soon as you go over, you simply create an int map and copy the other one.
Have you seen the README file? which explains everything by giving examples. It is almost longer than the package itself. https://github.com/oguzbilgic/vivom/blob/master/README.md If you still believe that documentation is necessary in this case, please send a Pull request.
He has a point, though. Godoc.org is the first place I go to for documentation, and examples like those in your readme belong into there as well. You know that Go documentation has support for examples, right?
It doesn't seem to actually handle the relational part very well. For instance, I can't really use a single query to load more than one struct. It assumes that records have one key and that the first column is the key?
You wouldn't be doing specialised maps like that in this context. Your point is fine though. 
Very cool!
Documentation *is* helpful. Don't let others complaints about it deter you though-- this looks really cool!
golang is a funny sounding word
Sounds like cross platform. Right?
I'm not entirely sure what this is, is it an alternative 2D rendering library to say...openGL? 
Throw package main into the root. This will work for both go install and go get. edit: Tested this, turns out that won't work. It's almost as if Go wants you to create two repos, one for the CLI and one for the library. The CLI would just need to reference the library, but they would need to be downloaded separately.
QML is (mostly) declarative language in qt for making fancy interfaces.
I think you're right regarding multiple repos being the intended structure. I'm not a fan; Makefile it is.
It's (imo) the simplest way to make nice cross platform GUIs.
As in, user interfaces? Does it have cross platform look and feel built in? I.e. widgets look and feel like their native counterparts? Is there a widget library? 
...What?
Hey I recently got introduced to http://berlin-ai.com/ in a hacknight for Ruby enthusiasts in Montreal - it was mostly around getting up-and-running quickly using the provided ruby client ( https://github.com/thirdside/berlin-ai/ ) I decided it would be a good time to convert my theoretical Go reading so far to some code, so I wrote an equivalent framework in Go to write AI bots for Berlin. If you've been itching to get started in Go, as well as at the same time have fun and compete in writing better algorithms to play other bots, you might enjoy Berlingo. 
Well... that's... silly. Kudos. Now, the next step is to go to the compiler team and claim they should recognize this pattern at compile time and optimize away the goroutines entirely... :) For... you know... performance... &amp; stuff.
The language offers no guarantee that you wont actually at some point have up to k-1 SneakyFact goroutines running at the same time, making this exercise somewhat moot. But, Go happens to handle that just as gracefully as it does as many recursive calls in the naive solution. Though, if you find yourself relying on tail call elimination, you should realize you are just writing a loop. Recursion is an interesting academic exercise, and obviously required for some class of problems, but ought to be avoided when possible for serious applications.
Interesting. Are you saying that if I spin off a goroutine and return from the caller, Go doesn't guarantee the caller will be removed from the stack? Could you elaborate on that? I'm sure that for reasonable k, Fact and TailFact will outperform SneakyFact, so this isn't an efficiency argument per se (it isn't really an argument at all -- really just an observation). For large k, however, SneakyFact will complete while the other two outgrow memory. As for tail call elimination boiling down to a loop, I did allude to that ("admit defeat and use a loop"). Sometimes recursion is convenient though (like in the root finding examples at the bottom).
Supposedly, there are cases where [tail optimization](http://stackoverflow.com/questions/12102675/tail-call-optimization-in-go) occurs. It isn't really an issue for me, though I would like to have a more thorough understanding of what those cases are. (#997 on my to-do list)
What I mean is, when you call "go SneakyFact(...)" within SneakyFact, the goroutine you spawn off might run immediately and call "go SneakyFact(...)" again, and so on, before the first or any subsequent goroutine hits "return". Thus, your goroutines may pile up in the goroutine queue similar to how stack frames of Fact() would pile up in your stack. The difference being a goroutine stack frame requires a minimum of 4k, whereas the memory overhead of an individual recursive call is pretty small.
Fair argument. Just to be clear, factorial was intended as just a trivial example; I didn't even use big.Int (which I'm willing to bet introduces enough overhead to pop the caller). I'd also be interested in seeing how the scenario you describe plays out on multicore. For example, at what critical volume of work does the spawning process outpace the completion process...
I'll grant it's an interesting exercise you put together. I had to think about it for a second. And, because you "go" right before you return, it is likely that even in a multicore/multithread runtime that your function returns before the goroutine starts. Of course, when you get into the nitty gritty of it, tail call optimization isn't usually a _language_ feature, but a compiler or interpreter feature. Just the same as the language doesn't precisely define the run order of goroutines. You can only ever hope for the worst!
Reimplementing a familiar problem is a great way to learn a new language. To that end, I hope some notes can help propel you even further. Your "List" type could be simply: type List []interface{} EmptyListError and OutOfRangeError ought to be const. Assuming you change your type definition, you could simplify New to: func New(items ...interface{}) List { return List(items) } Otherwise, just: func New(items ...interface{}) List { return List{items} } (That is, a "List" composite literal, vs casting []interface{} to List). You can shorten Extend to be similar to what you've done in Append: func (l *List) Extend(src List) { l.data = append(l.data, src.data...) } For Insert, you can leverage the built-in "copy". It's probably also reasonable to panic if the index is invalid: func (l *List) Insert(i int, v interface{}) { if i &lt; 0 || i &gt; len(l.data) { panic("Index out of bounds") } res := append(l.data, nil) copy(res[i+1:], l.data[i:]) res[i] = v l.data = res } Edit: formatting
i like the word golang, it sounds funny
thank you! :) 
Hey, I've been looking for a programming game involving AI for awhile now but the biggest thing I see missing for a lot (most?) of them is that there's no way to easily test or simulate the game without deploying something "in the wild". I've glanced at the Berlin documentation but I don't see anything about that. Is it possible from what you're aware of?
I dare you to x-post it to /r/cpp :)
done
As a ruby dev who is having an affair with Go, this all sounds just about right. I'm used to the kind of flimsy, often overly abstracted way that Ruby can get on large projects, and was relieved to have that ability taken away from me, in exchange for other more concise features. Also, strong typing was such a relief. No more `object.is_a?` for me. Basically, Go is in a way solving all of my frustrations with Ruby, while forcing me to sacrifice very little, if anything. I could see how a C++ programmer might be less excited about those things. Their language is already strong typed, and pretty explicit.
I started using Go after ~8 years with Python, which was preceded by ~8 years in Java. I've never really been able to commit to C++ (though I really like C). I never liked Java (I don't think OOP is the end-all-be-all of paradigms; very cult-like following among the academics who taught me back college). I agree with Pike's assessment that Go is an appropriate tool for those dissatisfied with "sophisticated" languages, like Java. Of course, you can write Java (or C++, for that matter) in less sophisticated (i.e. "responsible") ways. In fact, some of the best projects I've used were C++, but written more like C. I'd argue the problem that he's actually addressing isn't the language (I'm talking about C++), but bad programmers. I'm hesitant to label it "C++ culture"...
The ruby gem comes with a "test" mode that pits your AI against other dumb (random-movement) AIs in a single built-in map. Berlingo does not have that. On the berlin-ai.com site however you can create a new game and enable "practice" mode which doesn't affect your standings. Both examples are a manual one-run-at-a-time. They don't provide a quick repeating loop to gather statistically significant wins/losses. 
And likewise you can code python or ruby equally irresponsibly. However, a language will lend itself to certain practices; some good and some bad. I think it comes down to "the right tool for the job". I'm finding that Go really lends itself to solving certain problems really well, that I could see other languages fumbling with. That said, there are some scenarios where I could see Go fumbling with solving the problem.
"Desktop Components"
Ahh, practice mode sounds like something helpful. Thanks for the follow-up!
Where does Go fumble in your opinion? I hear this sentiment a lot. I don't disagree; I just haven't heard a concrete example.
[implements](https://github.com/dominikh/implements) is one tool that could help you. &gt;implements is a command line tool that will tell you which types implement which interfaces, or which interfaces are implemented by which types. 
My first recommendation is to trust your intuition. If at any point when starting to write something you think "surely there is a standard way to do X" - you are probably right. Although young, Go had some wise progenitors and a nice standard library. Second is to just search by verb instead of noun. Because Go uses composition and interfaces rather than inheritance it is true that common ways to manipulate stuff won't always be found in the type's package, but it is usually still sanely placed in something like the "sort", "net" or other more-verb-like packages. Third (and finally) You generally want to target your functions against interfaces rather than types, since your types will automatically implement those interfaces if it has the functions you need. This will make it easier to spot when you are only using a few functions for an interface (and thus it may already BE a commonly used interface), as well as enabling easier refactoring.
It was actually more interesting to read what cpp people say about go than what go people say about go.
Who said it?
Well, yes and no. I expected the kind of response it has got and I don't think the community is going to change its mind, short of an implementation of any other language (other than C) that will match the performance of hand-tuned C++ code. I am a recovering C++ programmer. Not a casual "C with classes" programmer, but rather a full-blown C++11/standardese/template meta-programming/let's-squeeze-every-last-CPU-cycle programmer with HFT background. Time away from C++ made me realise that it's an incredibly ugly and unwieldy language. It's tedious to maintain, slow to compile, and easy to fuck up, especially in large teams and aging codebase. C++ community has one of the biggest case of Stockholm Syndrome and are willing to put up with its numerous flaws because of the performance.
Interesting to see that sudden spike around March/April this year, I wonder if it was because of the release of Go 1.1? 
I'm so glad its getting more and more traction, I'd really love it to become a major web dev language, and have ton of high quality libraries and frameworks.
At work, I recently met a guy who has done 15 to 20 yrs C++ programming. Then he had to work with C#. After some startup problems, he was convinced that with C# he was at least 30% faster in completing the program. I am convinced that with Go the lack of Makefiles, super fast compilation, the lack of classes with sometimes 4 or more constructors and destructors and the lack of operator overloading will speed up the overall design proces, significantly. Note that you often write more code in Go than in C++ but it's just way better understandable. (me, a hobbyist Go programmer)
Note that since Go 1.2 has not been released, these are not truly "release notes", only a draft thereof.
&gt; \[C++ is\] tedious to maintain C++11 and C++14 make maintenance much easier. Projects written using C++98 are more challenging to maintain and projects using pre-standard C++ are a nightmare to maintain. &gt; slow to compile, and easy to fuck up, especially in large teams and aging codebase. Absolutely true! &gt; C++ community has one of the biggest case of Stockholm Syndrome and are willing to put up with its numerous flaws because of the performance. The movers and shakers in C++ don't really exhibit this behavior. Herb Sutter is quick to point out that every computer language has its own problem domain it is good at solving and that C++ shouldn't be used everywhere. Andrei Alexandrescu and Walter Bright are pushing D quite heavily despite both of them still being quite active in the evolution of C++. The list goes on and on. But as you point out, performance is pretty key to C++. And one other reason a lot of projects use C++ is for compatibility with old C and C++ code bases.
&gt; C++11 and C++14 make maintenance much easier. Projects written using C++98 are more challenging to maintain and projects using pre-standard C++ are a nightmare to maintain. That's true. At my previous job I was evangelising C++11, because it was simplifying a lot of things. But then, I tried to avoid bringing up things like rvalue references (or, worse, universal references, implicit move constructors) to avoid putting people off and let them ease into it. C++11 does make code terser, although it adds new classes of bugs, e.g. I got bitten by memory corruption when trying to implicitly capturing a `shared_ptr` member, when it actually captures `this`, so lambda will access deleted object. I guess that was one of the wake up calls that C++11 is not a holy grail and idiomatic C++ development will remain a minefield.
Nice, but a socks proxy would probably be more useful. I threw together a really rough one the other month, which works, but could do with some love: https://github.com/eXeC64/gator
the official tool is http://godoc.org/code.google.com/p/go.tools/cmd/oracle 
Nice project! You might want to check out my project ngrok for handling this as well: https://ngrok.com You could even run it directly on the Raspberry Pi (I know of others that do) with a linux/arm build at: https://dl.ngrok.com/linux_arm/ngrok.zip Run it in tcp mode if you're trying to forward non-HTTP services: ngrok -proto="tcp" 192.168.0.1:8080 On a completely unrelated note, it appears you and I have similar interests as I'm also the author of this long-paused project: http://jsrogue.com
I have been contributing to an old rougelike in C++ and have desperately wanted to move to C++11 almost only for the proper constructor paradigm. The maintainer wants as many people to be able to contribute as possible though, so no upgrading...
https://medium.com/war-is-boring/5c95d45f86a5
faster is better. We programmer don't want to wait, it kills effectiveness :3 
Why allow `GET` requests to change/modify the server's state? Example: if one were to build a website, they wouldn't allow a form to add or remove something from a database on `GET` request. 
I totally agree. Tiedot uses 'FormValue' to get parameter value from request. FormValue will find parameter value in URL, post or put body. Therefore it does not enforce user to use a specific method, makes testing and experiments a lot easier, although it may make a lot more sense to restrict http methods.
In the last code section: &amp;Subsriber
Odd, I can't install it &gt; src/code.google.com/p/go.tools/importer/source.go:434: n.Lparen undefined (type *ast.TypeAssertExpr has no field or method Lparen) &gt; src/code.google.com/p/go.tools/importer/source.go:435: n.Lparen undefined (type *ast.TypeAssertExpr has no field or method Lparen) &gt; src/code.google.com/p/go.tools/importer/source.go:436: n.Rparen undefined (type *ast.TypeAssertExpr has no field or method Rparen)
maybe it requires the current tip version of go? dunno
Just checked, I'm with 1.1.2... I'd rather not install the rc just yet (I'm in the middle of a small project and I'd rather not land in an issue)
Just checked again, requires tip. I could not find it in the manual, but it is in the first post of the mailing list submission. Oh well, I have to think about tipping or not tipping :)
This definitely looks better than some of the other extension managers I've seen for Go. Has anyone seen anything still better? I'm a ruby guy and used to my bundler.
To avoid the "last value is the value used always", you can take the address of the thing that your iterator points to so you aren't storing the value of the iterator : `&amp;(*ptr)`. Additionally, you can declare a new variable with the same name as your iterator within the for loop to make another copy of it `ptr := ptr`. 
we just have a GOPATH per project with all deps committed along with our app code. With golang's robust stdlib, there are few external deps and this way it is easy to version everything together. Updating from upstream is painful, but that is a relatively rare event.
On a log scale it's pretty linear. That is exponential growth iirc. There may have been a boost by a new release, the someone else has suggested, but it's probably the culmination of word of mouth and other stuff like that. 
Another way to say it is "improved data durability control". In Alpha release, buffer management was fully automatic; later on, buffer management is still automatic, but manual buffer management support is added in, therefore you can ask for immediate data durability (like commit in sql) by calling API.
It's a great deal more efficient to rewrite your recursive function as an explicit loop. If you're relying on tail call optimization, you're essentially letting your compiler to do this for you. It's a trick more useful in a functional language where it might not be possible to express your result any other way. While the Go runtime may in practice limit the number of actual goroutines in your run queue using this method, the language itself offers no guarantee that this be the case. That is, "go ..." may start work immediately, and recursive "go ..." calls may pile up goroutines taking up more memory than the same number of traditional stack frames. See http://golang.org/ref/mem
There’s also [https://github.com/mattn/gom](https://github.com/mattn/gom)
In his example, the bug is when he's iterating over a slice of objects, not a slice of pointers, so his loop variable is not a pointer, but an object that gets overwritten every loop iteration.
&gt; Or at least I think I am storing the address of each Dog object. As you found out, you're not taking the address of each element in `dogs`. You're simply appending the same variable over and over. See http://golang.org/ref/spec#For_statements , specifically: &gt; The iteration variables may be declared by the "range" clause using a form of short variable declaration (:=). In this case their types are set to the types of the respective iteration values and their scope ends at the end of the "for" statement; **they are re-used in each iteration.** If you intend to interact with the original slice, then use the index given to you. e.g. for i, dog := range dogs { dogs[i] } See also: http://golang.org/doc/faq#closures_and_goroutines
 wow much wanna wow check 
"I was looking at a code sample that showed a recursive function in Go and the writer was very quick to state how Go does not optimize for recursion, even if tail calls are explicit." I think I may know exactly who that writer is... 
Thanks for your article. It inspired this one and I learned a few things.
You from Miami originally, William?
No, I moved to Miami back in '94 from Long Island. I love Miami and would never dream of moving back to NY. The culture and people here are awesome. Oh Yea, Go Dolphins !!
Looks nice, would I have your permission to follow to colour scheme for a Vim highlighting file?
Consider the file public domain.
As I had it explained to be a few months ago, your build process (as it seems to me) is unnecessary. Change the import `"./goem"` to `"github.com/adeven/goem/goem"` and `go get -u github.com/adeven/goem` will automatically build the binary in put it in the `bin` directory within your `$GOPATH` environment variable.
Care to share your result for vim?
~~Working on it now, give me an hour or so? Vodka has its influence~~ It will be tomorrow now, my brain needs to sleep :) I'll post when it's complete. 
Thanks, no worries :)
TIL: Nano has syntax highlighting! 
You don't like the official Go Vim files? 
I do like them but they're not my favourite example of highlighting. Hell, I may try this colour scheme and hate it, but it's worth a shot right?
Ahh, you don't like your colortheme with Go! As the bundler of the theme-pack, I recommend you get it and try out a bunch of good themes: http://www.vim.org/scripts/script.php?script_id=625 EDIT: What my vim looks like doing go edits: http://i.imgur.com/QcZB8uR.png
Go needs CPAN.
No. Go needs nothing. It has been said over and over again that the versioning dependencies within 3rd-party packages is a problem that can't be solved. So don't solve it! Use git (or others) with version numbers and note in the readme that your package requires package B with at least version X.Y.Z.
&gt; versioning dependencies within 3rd-party packages is a problem that can't be solved. Au contraire, good sir! CPAN, PyPI/Cheeseshop, `npm`, Maven, even PEAR have solved it for years. **A versioned, curated repository is crucial for Go's long-term growth.** Here's what I've had in mind for a long time (I just haven't had the time to implement it): nut install [--global] webservice/sendgrid/newsletter Then: import ( "webservice/sendgrid/newsletter" ) func SendNewsletter() { newsletter.Send(...) } `webservice/sendgrid/newsletter` being an example pulled from CPAN, which has a `WebService::SendGrid::Newsletter`. The CPAN hierarchy works well in the context of how imports work in Go, so you'd just need to carefully organize packages as a benevolent editor. Kills the discovery bird -- don't forget, discovering Go packages is completely worthless today and yes, I am aware of the dashboard -- as well as the dependency bird with one stone. You could then write a project file that freezes dependencies, a la PyPI: dependencies: - webservice/sendgrid/newsletter: ==1.0 Redistributing your own package? Register a public key with the repository, sign your releases (just a tarball of the source tree at the given version), upload, distribute. Reuse the same project file to describe metadata of the package. Done. CPAN has the luxury of building an entire trove of infrastructure around their setup, including distributing testing on a wide range of platforms via volunteers that install the packages. Go has most of the infrastructure there already -- a documentation sorta-standard, for example. Here's why this is key: `go get` is tremendous for testing and getting something going. It is a complete blocker to me committing to maintain a system in production, because `go get` requires me to carefully manage git trees that I have no control over. This inevitably means mirroring them, at which point what is the point of `go get`? Things to consider: - Integration with distribution package managers (Python and Perl are good examples to study for this, how they got it wrong/right, and so forth). - Developer identity. PyPI and CPAN maintain identities; does `nut` use GitHub SSO? Maintain its own identities? - Strategies for resolving conflict. What if two libraries require different versions of a dependency? - Should be optimized for local mirroring off the bat. Nothing kills developer workflow more than the remote end going down for dependencies. PyPI going down was a complete day killer, hence the blog posts on working around a busted mirror. There is more, but this is a rough idea I've had in my head for a while which would solve three *huge* problems with Go: - Discovering a package. - Carefully maintaining dependencies in a production tree. - The assumption that I want to tie myself to the *master branch* of all of my dependencies.
Believe me, you think it can be solved. When you read the document of Nathan Youngman http://nathany.com/go-packages you will find out that it can't. Just use git with version numbers and when you have conflicting packages within the current GOPATH, define a new one.
Why are you so convinced that it cannot be solved? I arrived at the comment I left independently and a lot of its thrust is echoed in the document you linked. Not to mention that document you linked draws out a request and plan for how to solve the problem, and I fleshed out a basic, dumb spec for how to solve the problem. The problem is solved as best as we can, with a few (rare) cases that are unsolvable, in numerous examples in practice. Package management has been solved countless times, by countless people, doing countless things. Lay out an abstract concept: "manage dependencies, their versions, and relationships between the two." Now imagine all the things that have solved that in a practical way. Every single bloody Linux distribution has their own. CPAN, in particular, is a huge driving force of organization and productivity in the Perl ecosystem. That code is helpfully centralized, and a Perl developer can sit down and think "has someone parsed this arcane format? I bet it's in CPAN." Her homepage is search.cpan.org, not google.com. My personal opinion is that Go is already badly fragmented -- infinite alpha-level projects made in a vacuum in various states of repair, precisely because there isn't a central place to find work that provides a lot of value. Nathan says the same thing: &gt; The problem is, we don't have a "Go Packaging Authority" providing guidance, so every newcomer is left to find their own way. CPAN is considered "authoritative" by Perl developers, and that comes with a lot of (necessary) value. There has to be at least one central authority in chaos. One place to start looking. Imagine if you heard you need a Linux kernel, but have no notion of kernel.org. Where do you get the source to build? How can you *trust* where you're receiving the Linux kernel from? Is this the right one? The only answers to those questions involve de facto authority: Torvalds's authority and the community stewardship of kernel.org. There's no easy way to describe how that works. It just is. So it is with CPAN; when you're grabbing a package, you have the assurance that this package is a lego block that fits your standard assemble-a-project set. It's in CPAN, so it's *probably* an okay tool for the job. The authors are aware of how the Perl community *just is* (there it is again) and contribute to that community, rather than marketing their package independently and with no consideration for "the norm." This package is in a high-traffic, closely-examined compendium of prior art, and it's public credentials for the authors; the authors have an incentive to make the package function well and avoid rotting. That de facto blessing that *just exists as a given* goes a long way toward organizing and rallying the work being done across the world into a powerful toolbag for every developer. That's what I was getting at -- I just spent too much time on the how in my comment -- and I'm glad you linked me to Nathan's essay because I share a lot of thoughts with that. There are a few exceptions which I didn't even consider, like keeping the `.git` directory in a package for the ease of contribution. That's brilliant. To take another point, I resent being told something cannot be solved. Everything can be solved unless it is mathematically impossible. I tend to get motivated to prove someone who tells me something cannot be done wrong.
&gt; To take another point, I resent being told something cannot be solved. Everything can be solved unless it is mathematically impossible. I tend to get motivated to prove someone who tells me something cannot be done wrong. This problem is mathematically impossible.
For perfection, not adequacy.
Note, I didn't write this emulator.
That's because I did :) The project is on hold right now as I've been busy with work, but I'm hoping to get audio implemented by the end of the year, turns out it has been the most difficult part of the whole thing! A few weeks ago I was kindly invited to do a talk on my emulator at the [Go London user Group](http://www.meetup.com/Go-London-User-Group/), slides are [available here](https://docs.google.com/presentation/d/1EaY3HSAl3Tf4BE9BjZT3E82bwqiNBokQOjTUUaTVzzI/edit?usp=sharing) 
Wow, amazing. And its cross platform.
You're welcome.
I watched it with interest, hoping it would take off.
This is awesome. I'll probably look through your repo later. It made me very curious on the subject of emus :D
What did you do to handle drawing in a cross platform way?
The slides he linked to say he used a Go binding for OpenGL, found [here.](http://github.com/go-gl/gl)
As thegunn mentions, the drawing is done using go-gl https://github.com/go-gl/gl The windowing/keyboard input is achieved by using go-gl/glfw, the Go binding for the cross platform library [GLFW](http://www.glfw.org/) https://github.com/go-gl/glfw 
So it might look a bit clearer [in this version](https://github.com/BonkaBonka/sseredis/blob/e3c1bba33dacdf0acc0bf3a6fb7847f63b680383/sseredis.go) before I add the CLI option to control the keep-alive time. I can't lay my hands on the exact links I used to figure it out last night, but there is [a decent presentation by Rob Pike about Go's concurrency bits](http://talks.golang.org/2012/concurrency.slide#1) over on the the Go site (in particular - [this slide](http://talks.golang.org/2012/concurrency.slide#35) talks about using select for timing-out I/O operations). This code is also my very first attempt to use Go for anything more than the samples in their sandbox so it's probably not very idiomatic. =)
http://golang.org/doc/effective_go.html#channels http://golang.org/pkg/time/#After
Ah, as it turned out I didn't really understand what `select` does and that `time.After` returns a channel. Now it's all clear :)
Thanks. (see my reply to /u/bonkabonka)
What are some use case for having this bridge? Pardon my noob.
I hope you'll only spam these over the various programming subreddits once..
So, in my page I pull down a bunch of data and merge it into a template. With this, I can update data in Redis and then publish the key through the bridge and then any connected clients will update themselves. I had been using a Websocket to do the notifications in dev but the crummy load-balancer at work doesn't support them so I had to figure out an alternative. Necessity is the mother of invention and all that. =)
Yes, Go does have those atomic operations. It did not make sense to use those in the end of the article. If this was production level code then absolutely that is the right way to go.
I couldn't find them via Google, and had apparently overlooked them on the package list earlier. For anyone else looking: [sync/atomic](http://golang.org/pkg/sync/atomic/)
The results are slightly wrong. You should remove gamma correction (convert to linear RGB), do the math and apply gamma correction back. Check it with http://www.zagura.com/jbili/gamma_dalai_lama_gray.jpg
I just looked through the PRs as I've remembered seeing it being discussed https://github.com/nfnt/resize/pull/2 - so pretty much what you say. Note I'm not the author.
That's awesome, glad it's working well! :-)
You should probably now take a look at the QML bindings for GO: https://github.com/niemeyer/qml 
The best part is that it is enlightening in a way that isn't limited to Go.
I'm around chapter 14 of Michael Abrash's 3D programming book where he introduces the Pentium U and V pipes, so I couldn't help but try to go have some fun... http://play.golang.org/p/EOx7orQ3r_ 
You might be interested in reading this wiki entry: http://golang.org/doc/articles/wiki/ (writing web applications). Not sure why the URL is just the top level wiki?
&gt; Not sure why the URL is just the top level wiki? Because it's an article about writing a wiki, not actually a wiki. As someone just recently messing around with net/http this is an interesting article, thanks. 
It reminds me strongly of the "Automata via Macros" paper: http://cs.brown.edu/~sk/Publications/Papers/Published/sk-automata-macros/ The big idea being that we can use function calls to represent state transition. States are function pointers. All the transitions are, essentially, tail calls: the continuation is precisely just the next transition we're in. The difference in the presentations is that the approach in Rob Pike's presentation is basically a trampoline to simulate tail calls. Direct call threading vs subroutine threading.
The short answer is "no" the way you use Go for a web application is very different than with PHP. Think of it more as the Go will emit your HTML, and then the form submission will be returned to your Go application, rather than mixing them together as with PHP. The formal name for what you probably want to do is "templating", and you can find lots of additional information on templating HTML with Go. Good luck!
This is exactly what i was looking for. Will try this. Thank you!!
http://www.alexedwards.net/blog/serving-static-sites-with-go and templates in Go is like your own written web server with large parts of the PHP functionality.
http://golang.org/doc/articles/wiki/ (Already linked in this thread) is a good place to start. Most of the quick go web tutorials(including this one) are based around using go as its own webserver. In many cases this is undesirable as it doesn't cooperate well with other things hosted on the same IP. Fortunately the go standard library includes fastcgi support, which allows it to be easily connected to your regular webserver. While it's almost identical to using go as its own webserver, here is a good example of how to use it: http://mwholt.blogspot.com/2013/05/writing-go-golang-web-app-with-nginx.html Here is one that shows how to use the gorilla mux, and how to deploy using apache instead of nginx: http://www.dav-muz.net/blog/2013/09/how-to-use-go-and-fastcgi/ 
Nice. This is an excellent idea and piece of code to have around.
&gt;Volume float64 &gt; &gt;Price float64 Whomp whomp.
You can use go framework e.g. http://robfig.github.io/revel/
I wonder why everyone introduce webgo. http://webgo.io/ webgo is easily to use, but it's possible to do most of things.
Nathan's contribution to the Go community is just outstanding, thanks a lot and keep it up.
Ah, okay. Thank you for explaining.
Or you may consider using Go to expose a JSON API that powers something on the front-end like Angular. I wish more frameworks generated less HTML and let client-side frameworks do that. 