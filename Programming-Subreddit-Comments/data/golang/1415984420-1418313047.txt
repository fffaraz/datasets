you're right, I just find goquery to be less painful for scraping 
Formam not give you any control to the client (at least no more than other packages such as gorilla/schema or ajg/form). Is strictly necessary put a name to input in a form separate for a separator for access to a field, key or slice (in my case, I use the operator "." for fields of struct and keys of map, and "[]" for slice/array. Gorilla/schema and ajg/form uses "." both for structs/maps and slice/array).
Hmmmm. That must be new. I'll check it out. Edit: nice. You're right as long as it's fewer than 5 users. 
According to the [Plans &amp; Billing help page](https://confluence.atlassian.com/display/BITBUCKET/Plans+and+billing), public repositories allow unlimited users. Although small-to-mid open source projects usually have only one person with push access and everyone else sends pull requests.
`range` only works over arrays, slices, strings, maps, and channels. The relevant portion of the spec is here: http://golang.org/ref/spec#For_statements Otherwise, the expression in the `for` loop needs to return a boolean, and that's all `iter.Next()` does. It moves to the next item underlying it and returns true if there is one and false if not. It's the call to `iter.Node()` that actually fetches the item. This is a really common pattern in Go for iteration. You'll see it all over the place, including XML and `database/sql`.
Ya, it has little to do with Git vs Mercurial and everything to do with Google Code vs GitHub. I prefer Google Code's bug tracking system more than Githubs, but that's about it. Google Code at this point is dying. The haven't added anything to it in the last 2 years, only removal of features (see their [WhatsNew](https://code.google.com/p/support/wiki/WhatsNew) page). Google has decided it's dead. I think Go only went on Google Code originally because there was a mandate that open source projects from google to be hosted there. It looks like that mandate has since changed and they are moving now. I personally like Mercurial more, but the battle has basically been lost at this point.
Yeah. All the less does this make me want to use any Google tech whatsoever - although I'm currently making an exception for Golang which seems to have great community and maintenance cycle going for it with focus on pragmatic stability above all which I absolutely love. 
that's not what I intended at all. both projects were released around the same time and I think one would assume both were in stealth development for a significant period, no suggestion at all that bosun others didn't do research. how could the have known, or mperham have known Still no one's answered the question how the applications differ
Take a look at the Content-Type header from the server that's sending the data. In this particular case, it's: Content-Type: text/html; charset=ISO-8859-1 So you'll need to convert from ISO-8859-1 to UTF-8. You can use the `golang.org/x/text/encoding` package for this. See https://godoc.org/golang.org/x/text/encoding
One thing I am curious about is how the `go` tool deals with a substantial change to the `content` field there. Like, when the repo format changes from `hg` to `git`. Probably a `go get -u` will simply nuke the old repo and replace it with a git checkout. I guess we'll see in a couple of weeks.
Don't forget emacs moved to github too.
You mean the library that's packaged into the go runtime even if you only compile a simple "hello, world" program? I agree it isn't technically free (as it increases the size of the binary), but it's already a part of every single compiled Go program, so it *is* free in a practical sense. Try this yourself...compile a simple Go program and look at the disproportionate size of the output binary.
Sure, but that doesn't make it free, there is always a tradeoff.
The size of the binary is usually irrelevant, the cost I'm talking about is the time it would take to develop using one library or another.
Thanks, one more to collection. (e.g. https://github.com/go-validator/validator) What would work, however, is nice implementation for JSON schema or any other service description mechanism. It could replace dozens of struct-validate, form-validate and service-validate libraries that are already reinvented, are being reinvented or are going to be reinvented.
I suggest that “not have to worry about recompiling source code during minor or patch releases.” should be changed to “not have to worry about *rewriting* source code during minor or patch releases.”
I've used svn, git, and hg for years depending on project. I think the reason for git winning is github, plain and simple. Everything I can do in git I can do in hg. There's so much FUD against hg if you google 'git versus hg' that it's ludicrous. Sure, in 2008 git has more features. hg's rebase extension is so much easier to use in my opinion. It's also smart enough to not let you rebase commits you've pushed upstream. hg's lightweight branching is incredible and their named branches lets you easily have persistent branches. The named branches can be closed too as well. You just checkout a closed branch and then commit to reopen. A problem is how many times the hg people recommend cloning to branch (which I hate); this is no longer necessary or good hg practice imnsho. And I find myself resolving merge conflicts practically never with hg; it just plain works. I also hate in git that if I merge --squash to stable branch from dev, I then have to turn right around and merge stable back into dev for the correct ancestry to kick in or I'll have a shit time with merge conflicts in the future. The git commands are a joke in how they're logically organized. If the unstoppable ego that is Linus wasn't behind it I think someone would've fixed the shit out of the commands ages ago. (I love Linus's contribution to open source and he gave me my favorite OS; but, he loves getting flame wars over his preferred software). Steve Losh some git koans that are humorous on his blog that really point out its shortcomings. The final funny thing to me is that hg is actually a superset of git yet everyone thinks it has fewer features. :) Git's marketing sure won out over hg's. But github is incredible and bitbucket just doesn't compare. I've used both sites extensively and github just pile drives bitbucket into the ground with the social features. If the github people started doing hg repos I think the choice between DVCSs wouldn't be so clear cut. 
Meh, just write the code. If you want foo to be positive after importing from json... if foo &lt; 0 { return nil, fmt.Errorf("Foo should be positive!") } 
Nice. Just one nitpick - "Marshaling" isn't the Go term for "parsing JSON". It's a standard term in most languages for ordering raw data into a structure of some kind - for example, the XML package also has a [Marshaler interface](http://golang.org/pkg/encoding/xml/#Marshal).
Hey all, anyone still reading this, the is a new CrossPlatform UI Library written with Blink/V8 to achieve simple cross platform ui applications using HTML/JS/CSS https://github.com/miketheprogrammer/go-thrust Its gaining popularity after its release to the community, its going through alot of changes, because it was a rush to prototype and is now stabilizing as we add more committers.
Is modl good enough for production? He hasn't stamped his approval on modl yet. I use sqlx from the same author. 
I just tested. The first time you run "go get -u golang.org/x/net/context" it requests http://golang.org/x/net and clones the repo that appears in the go-import meta field. The next time you run that command it just updates the hg repo - it doesn't seem to make a request to http://golang.org/x/net.
I like the idea of just a Validator interface however it can get tedious to write validation logic on large structs. Struct tags are also great for readability (obviously you lose compile time safety). I wanted to play around with this idea and created a struct validation library as well: https://github.com/SyntropyDev/val I'm not sold on it however. Using a validation interface feels way more idiomatic. 
Self-advertisment: https://github.com/mccoyst/validate I wrote this in response to some thread in this subreddit a while ago; people seem to like it. Although I think I like jerf's idea a little more, since it avoids reflection.
I was considering working in go. This post kind of scared me off a little. Why do you even need to explain this? Shouldn't the use case: "working out of source control with go " be so trivial as to beg comment?
Very cool! I'll check it out 
Great write up on a common oversight for beginners! Small edit if this is your article, adding an upstream source should be, git remote add rather than git add.
it's the same use case in other languages that have namespaces. If you fork org.javax.SomeThing but don't want to change the import statements, you should fork in place.
Nice benchmark. Performance is important!
Oh, Thanks!
NotNil is really the only one I need. I just threw in the others for good measure. Also, I'm using this with a json schema that has heavily nested structs. Validating that with if statements creates a giant mess of boilerplate.
Just wondering, your AddRoute method is chaining middlewares inorder from right to left instead of the other way around! Why is that?
&gt;goodness knows I've never seen a validation library that doesn't need to be augmented by tons of custom code anyhow, since in the real world validation is rarely as easy as simply "must be positive" but usually includes something like "must be less than current account balance" too. But you still need to do basic software engineering. I haven't added it to the overview yet, but that's why the map of check names -&gt; functions is an exported symbol. Custom checks can be added to that global or ValidateWithCheckSet can be used to avoid non-obvious statefulness.
The json schema libs that I found via google-fu aren't particularly idiomatic in their usage patterns. I'd really like to have a schema lib that looks like: s, err := schema.Unmarshal(r1) var j MyJson err = s.NewDecoder(r2).Decode(&amp;j) The schema libs I found use the post-decode validation pattern, making them only marginally different from any other validator lib.
I found the valueQueue implementation interesting, although it doesn't seem to be used in your code? You should use map[type]struct{} for sets instead of map[type]interface{} - interface{} requires 8 bytes while struct{} requires 0*. I personally prefer a more declarative approach e.g. write a validator per dto to clarify the intention of why something is being validated in the first place. Looks like you had some fun writing this. Did you encounter anything worthwhile mentioning in your experience writing this package?
FWIW, one feature my system has that the other libs posted here are missing is error aggregation. Rather than tossing an error on the first failed check, it runs all checks and returns a single error that prints all the failures in a nice column-aligned format.
I didnt know duck typing is also idiomatic!
The valueQueue is used in the Validate() function. Since it handles cycle detection/loop prevention internally, the Validate function can use a dead-simple breadth first search algorithm. I hadn't considered using map[key]struct{} for my set types. That provides an interesting tradeoff: you save a few bytes and make your intentions clearer at the cost of making your add operations uglier (uses struct{}{} instead of nil). The thing I was most surprised by when implementing this is that interfaces don't maintain a history. Upgrading a struct to an interface creates a new level of indirection; upgrading an interface to another interface is effectively a typecast. It makes sense from a performance perspective, but has significant implications upon reflection. Edit: also, I am still a bit confused by reflect.Value's Interface{} method. The godoc mentions that it will panic if the value can't be upgraded/converted to interface{}. What type(s) would cause such a panic?
I add HTTP method declaration to AddRoute. ex: " server.AddRoute("/", Handler, middleware).Get() "
duck typing? I doubt I used it here.
I've been doing Go for about a year or so now and I really like it, so I thought I'd share a HTTP router I made with you guys. I tried to keep it all relatively simple, let me know what you think.
You can just create a `var Unit struct{}` and use that value.
Great write up. Thanks for this!
Is that in reference to the use of interfaces for vertices and edges? How else would you create a generic implementation?
channel is a way to establish ownership. So does mutex. channel is essentially Mutex; in "sharing data by communication", channel "locks" both RW access. This is slightly less efficient than RWMutex. BTW, the code still could have another revision.
You could simplify your TokenStore.StartRefreshing method: http://play.golang.org/p/1wRdYsbQ0j Channel implementation for kicks: http://play.golang.org/p/mDWZeiODE0
Emacs moved to git but still hosted on savannah. 
There's one on [Pluralsight](http://pluralsight.com/training/Courses/TableOfContents/go) that's pretty good. But honestly, the [How to write Go code](http://golang.org/doc/code.html) and the [Effective Go](http://golang.org/doc/effective_go.html) pages on the Golang website are all you need ...
There's [GopherCasts](https://gophercasts.io/). It's only a few videos, but they're pretty good. 
Very clean. Nice job on not over engineering this thing. 
It is not well tested: * Does not grab "/user/:id" and "/user/:id/" on to the same handler * "/:id1/:id2" or "/:id" also does not work * How to add static route for "/"? * How to add single panic handler for all routes?
The **id** in the pattern is not the same as **id** from the url.Values. 
http://www.metacasts.tv/ Requires payment, but in my opinion people deserve to be paid for doing good work. Maybe throw the guy (who is not me btw) a few bucks and see how you like them.
I didn't know of this one. I like his other things from around the internet. Have you watching this series? How'd you like it?
Exactly.. I think its nice to share but even nicer to do a bit of the hard leg work to make corner cases work before doing so :)
Hey, thanks for bringing some of these issues to light. I've updated it, now trailing slash URL's are redirected (/users/2/ -&gt; /users/2). I opted out of a panic handler, I felt it would be better to leave that up to the user to handle with some form of middleware. I didn't want to make too many assumptions, but if it's something you think could be a great benefit, I'm not totally against it.
Hi fiellas, this is my first ever golang library. Just my take on the i18n, and basically it is made how would I like to use it. It's very simple, nothing fancy, and gets the job done. I am very open for comments since I am gopher n00b, been hacking around the language for a month or two. Lemme know what you think.
Considering compile time duck typing is a fundamental language feature, I'd say it's idiomatic. Emphasis on compile time though because that differentiates it from Python.
how faster is this compared to juliensmidth httprouter? Would love to see a benchmark.
hmm, this one looks interesting :D
Your conclusions are WRONG! The problem you 're describing has a *very elegant* solution with channels (as most concurrency problems do). Your first and second efforts were *VERY* convoluted, for no reason. Take a look at this (I've added, maybe, too many print statements to make tracing the operation easy): http://play.golang.org/p/NGCkOFv_3L 
We really need something like a good and established i18n/i10n pure Go library/format for Go. Would love to see more w.r.t. this topic. So thanks for tinkering with it.
I'm mobile so did not look at your code to see if you've already thought of this but it would be neat if we could return a whole sub-node as JSON. Just thinking of APIs where the server can return a translation set to the client. 
Looks like an awesome start! Would be cool if it supported https://en.wikipedia.org/wiki/Gettext file formats (.po, .pot, .mo)
Never thought of that, I will definitely look into it. :) Thanks for the feedback!
I don't think you can you can't use a value as an argument to a map, but you can `type void struct{}`
I didn't watch it, but am a fan of his work in general as well.
Not sure whether you're responding to the wrong comment, but .po files are commonly used across many different frameworks (ex: wordpress, django, KDE)...
I'm talking about this part: set["value"] = struct{}{} Not this part var set map[string] struct{} They were saying it wasn't nice having to write "struct{}{}" instead of "nil".
Does it/will it support encoding.BinaryMarshaller, Unmarshaller and encoding/gob.GobEncoder, GobDecoder? If it does/will it will be the new prime choice when serializing App Engine entities (where *datastore.Key usually creates serialization problems due to it being a struct type without exported fields, and only (IIRC) implementing the GobEncoder/Decoder interfaces).
Well, there are instances where global mutable state is a good thing, but in App Engine it is even trickier than normal.
Ah, but I think you misunderstand. What I mean is not to use msgp to implement gob-encoding, but to encode types defined in third party packages using msgp. The problem with these types is that they have no exported fields, and won't serialize prettily with most encoders. To alleviate this they sometimes implement encoding.BinaryMarshaller, or encoding.TextMarshaller, or in some odd cases encoding/gob.GobEncoder. Since they are third party it's impossible to add functions to them, and since they are used in very strict ways in OTHER third party packages I can't just alias them to another type and add functions to them that way. This sort of requires that the encoder I use detects and honours any GobEncoder or BinaryMarshaller it finds..
This looks nice. Anyone know if there's plans to add an in-memory option (a.k.a. suitable for autocomplete)?
You're right; I misunderstood. [This](http://github.com/philhofer/msgp/wiki/Using-Extensions) is sort of what you want, but you'll still need a shim.
 One of the unique features of this package is the implementation of *Reader and *Writer, which are both buffered. *Reader and *Writer aren't interfaces, they're pointers.
Yup. I'll post a github issue, to let you consider things properly :)
I noticed that you didn't include the license information. Is it licensed under the same terms as Go? 
wait, `go generate`, a go 1.4 feature, wat?!! This was a big piece of news that passed me by...
maybe it's just me but it kinda made me cringe. 
if it would have been awful, I would agree but it was awesome and nerdy and cute 
I just updated it. It is licensed under the MIT license.
it's awesome, I smiled so hard
Oh yeah, it's one of the most interesting things in 1.4. It's a pre-compile step that must be manually run (go generate ./...) and you put special comments in your code that it reads and runs. It's not super powerful, it basically just runs other executables based on the commands in your code, but it's nice to have a standard way to run that stuff.
Great stuff, I enjoyed it!
We can add this to the catalog of nerdy music - https://www.youtube.com/watch?v=1S1fISh-pag and https://www.youtube.com/watch?v=Fow7iUaKrq4 I love both of those, nice to have another piece of tongue in cheek humorful music to think about during our short lines.
There aren't any Go fights yet, but this seems like a perfect place to compare performances of different approaches to the same problem. We should crank it up!
Thanks for your feedback.
I don't care for the dictionary they are using. The words are so obscure that the phrases don't seem easy to remember at all.
Glad they're gonna make the december 1 release on time. Go generate alone is enough for me to be excited. Lots of good changes here.
And for all of us who didn't already know, atom is a text editor.
Thanks Joe!
Log in with Twitter?
Awesome!
Release notes here: http://tip.golang.org/doc/go1.4
Please, _please_, **please**, test this rc with your applications. This will most likely be _the final release candidate_, unless issues are found. If you want til 1.4 final to test, then you'll be stuck with those bugs for up to 6 months. Please test and report feedback to https://groups.google.com/forum/#!msg/golang-nuts/mP5sSNwezVc/dM44xFd9L4IJ or log an issue, https://golang.org/issue/new
Introducing a new addition to the go toolchain: go fix it later
gore turns 
"or dive into something more productive and easy to develop with" I don't understand this question. If something is more productive and easy to develop with, wouldn't you prefer to use it? For me, go IS the more productive and easy to develop with.
Takeaway: you cannot override a method from an embedded struct.
How long do we have?
I'm not sure I understand. Do you mind explaining why?
Good stuff
Awesome tool. Thanks for sharing! I wonder though, shouldn't we have a more modular solution here instead of just explicity chaining your tool on top of go-imports. What if someone else makes another cool tool and also bases it on go-imports? If I wanna run both, then I'm doing a whole bunch of stuff twice for no reason. It makes me think maybe go fmt should have some kind of plugin setup that lets the user pick which 3rd party modules they want to incorporate. Maybe it would be more unixy to just have each tool just do only whatever little thing it does and let the user pipe them together with other tools via stdin/stdout. Seems like that'd still be a bunch of duplicated parsing logic/CPU cycles. I'd rather see gofmt parse once and then let other tools tweak the parse tree before it gets written out. 
Go 1.4 is scheduled to be released on 1 Dec 2014
Please test the release candidate with your application to catch any regressions or bugs before they make it into the final release.
But why 6 months? Once 1.4 is released, nothing else will get fixed?
 t := time.NewTicker(time.Hour) for { DoStuff() &lt;-t.C }
is there a way to configure autocomplete-plus to only take completions from gocode? i get all kinds of stuff in the suggestions but most of them are useless repetions from other locations, not context sensitive at all.
Thanks, this works and I think it should be t.C Still not exactly sure how it works though, does this mean that we are sending the current Time (t.C) over some channel, but there is no channel to receive it?
Channels are not only means of communication, but are also means of *synchronisation.* `&lt;-t.C` blocks until `t.C` receives. When `t.C` receives (in an hour in this case), the loop goes for the next iteration, does stuff, and blocks until `t.C` receives again in another hour.
Perfect. Thanks so much.
Here's a complete example, showing how to break out when you've had enough: http://play.golang.org/p/m2AMSyXWK6
http://play.golang.org/p/WvtSdjLBV_ 
Small nitpick, but if you don't actually care about the value in the channel, you should use the empty struct instead of bool. It's slightly more efficient, and it is the idiomatic way to indicate that the value isn't meaningful. See http://dave.cheney.net/2014/03/25/the-empty-struct
The provider is registered as an exclusive provider, so you shouldn't be seeing suggestions from anything other than gocode. Is it possible you have atom-ctags installed? It would be great if you could create an issue at the repo (https://github.com/joefitzgerald/go-plus) with steps to reproduce. Happy to look into this and make it right (I have commit rights to autocomplete-plus also).
You don't really need a library for this. I wrote a sitemap parser using just encoding/xml. This is really straight forward, and works with the situation you describe. I'm away from my machine right now but if you like I can post a snippet for you tomorrow .
Still a work in progress. Appreciate pointers, recommendations, feedback, etc. Started learning Go a few days ago.
I can already think of a project where this would be useful. Fantastic.
I have been playing with the encoding/xml package these few days and while its frustrating for a novice like me to understand from the package godocs, it just works eventually.
That's cool - I'm actually working on a Go app that is a HTTP/MySQL proxy that people can use for debugging/profiling purposes - it exposes a web app where you can see MySQL and external API calls happening in real time, search them, etc. For example, you can configure a Wordpress installation to use the proxy as DB server and it will show you a breakdown of the MySQL queries being issued by Wordpress - the proxy will 'EXPLAIN' queries in the background and build a report of bad queries that need to be optimized, etc - with some help from the application (DB queries must be annotated at the end, so "SELECT * FROM Users" becomes "SELECT * FROM Users -- {"file":"foo/bar.php","line":55,"method":"GET","URL":"/admin/users.php","sid":"uniquerequestid","anythingelse":"goeshere"} " As for the HTTP part, you change your API requests' hostname to the proxy and it forwards the request to the actual service, while logging the conversation, that also becomes searchable in a time series DB. Might be nice to add support for DVR files. My intention is to eventually make it a complete suite to profile the entire web stack, tracing web requests (API calls or regular pages) throughout the stack and showing a graph of everything that happens to fulfill a request - while tracking, storing and correlating related performance stats (everything that 'dstat' would output).
I'm pretty sure you need to do type assertion to get that to work. Alternatively, create an interface like so: type Nexter interface { Next() interface{}, error } type myStruct struct { a []int count int } func (m *myStruct) Next() (out int, err error) { if m.count &gt;= len(m.a) { err = Error{"nope"} // can't be arsed to look up the exact syntax } else { out = m.a[m.count] count++ } return } func tryfunc(in Nexter) { for n,err := in.Next(); err == nil { // do stuff with n } } 
The reason your code doesn't work is because you cannot apply the range clause to an interface{} type. According to the documentation ([1], see For Statements), "The expression on the right in the 'range' clause is called the range expression, which may be an array, pointer to an array, slice, string, map, or channel permitting receive operations." Go is very strictly typed so that, for example, in the following type Widget struct{} var i interface{} i = new(Widget) the interface{} is a different type from *Widget, even though i behaves basically like a pointer to a Widget. For that same reason, map[string]int is not assignable to/from a map[interface{}]interface{}. Go requires explicit conversions. The more "idiomatic" Go solution would probably be to write separate loops for processing each individual type. If you have a case where you have multiple types you need to process, you can do an iterator interface approach as suggested on this thread. However, I am willing to bet no concrete problem would ever actually need to be modeled that way... [1] https://golang.org/ref/spec
I've used this before when I don't care about cancelling the goroutine and just want it to run periodically. http://play.golang.org/p/3wus3r0P6a func periodic() { fmt.Println("Hello") // schedule the next call time.AfterFunc(time.Second*1, periodic) }
You can also try [xmlpath](https://github.com/go-xmlpath/xmlpath). I successfully use it in many projects.
Go really not need any framework. Go has all necessary for setup a webapp. You can do what you ask here ;) You can start for here: https://golang.org/doc/articles/wiki/ And if you want do the webapp without needing to refresh the web browser (single page app), you can write a function for render a template like this: func renderTemplate( w http.ResponseWriter, r *http.Request) error { // check if the request is ajax or normal if r.Header.Get("X-Requested-With") == "XMLHttpRequest" { var tmpl bytes.Buffer app.Templates["index.html"].ExecuteTemplate(tmpl, "tmpl", ctx) // encode to json j := struct{ Content string `json:"content"`}{ tmpl.String() } json, _ := json.Marshal(j) w.Header().Set("Content-Type", "application/json") w.Header().Set("Content-Length", strconv.Itoa(len(json))) w.Write(json) } else { var tmpl bytes.Buffer app.Templates["index.html"].ExecuteTemplate(tmpl, "tmpl", ctx) w.Header().Set("Content-Type", "text/html") w.Header().Set("Content-Length", strconv.Itoa(tmpl.Len())) w.Write(tmpl.Bytes()) } return nil } 
You perfectly demonstrated why people use frameworks. 
While I have no experience with Flask, from what I understand it a web framework. As such there are several available in go, biggest that I know are Revel and Beego. Depending on complexity you can (and should) understand how net package works. You can get away with just serving static files trough go's http server, and then implement routes that you need for ajax requests. Net/http and encoding/json are easy to work with. Gorrila/mux is worth looking into if you need more of a flexibility with routing.
I'm working with Flask for a while now, and with Go, I feel martini is really close. If you really on to something more idomatic Go, maybe look for Negroni or just Gorrila/*. If you knew about Play, Revel is a good alternative. People generally say "don't use framework with Go", for me, honestly, I think you shouldn't do that. Framework is not a set of library, it's a complete new language based on the original language, and you choose to use it or not.
I can help you with anything you need with mgo and MongoDB. @goinggodotnet
Ok, Thanks.
Oh, thanks!
net/http is a framework. Giving up control for convenience might be in the interest of your project if you think that writing these kinds of wrappers (or, more likely, using parts of `gorilla` that do these things already) is going to be a significant percentage of your time spent on it, but in all likelihood it won't be. The code above looks very straightforward and you can be sure that net/http isn't making too many of its own decisions about how to deliver responses.
Sorry to say, but I see zero reduction in repetition. You are simply repeating your own code while adding a layer of indirection.
now this on the other hand /u/dvirsky crosses that cringy line :)
I don't think anyone claimed the Java collections are bloated. I've only heard praise of them. See the video of Guava (formerly google-collections) explains why having Multimap and histograms aided readability and prevented bugs.
okay, must have been an issue with my atom installation. couldn't reproduce on another box and clean install fixed it on the other one. atom-ctags was not involved. now i just need to figure out how to configure my keybindings properly. `tab` for confirm is overruled by indent somehow. ps: so glad this finally landed. biig kudos!
Hm. Firefox 33 on Kubuntu here. `network.http.spdy.enabled.http2draft` is set to `true` but https://http2.golang.org/reqinfo still says that I use HTTP/1.1. Either FF 33 doesn't support HTTP/2 to the fullest yet, or there are other settings I need to enable. I can't use Nightly right now. If there is anyone who's using it, does it work for you? **EDIT:** Same for Chromium 38 with `chrome://flags/#enable-spdy4` enabled.
Same here, FF 32.0, Gentoo. network.http.spdy.enabled.http2draft = true. Chrome 36 doesn't work either.
ERR_SPDY_INADEQUATE_TRANSPORT_SECURITY (Chrome beta on Linux)
The Signature algorithm of the cert is sha1RSA which was meant to throw warnings in the newer version of chrome this requires I believe ? Looks like brad has been adding lots of fixes and tests for this recently https://github.com/bradfitz/http2/commits/master is this a sign your trying to get this to a production ready state for inclusion in the Go standard http package? 
Actually, I believe it was made optional (even though some choose to only implement encrypted HTTP/2).
Shows green lightning for Gmail, doesn't for http2.golang.org.
Looks interesting? Do you have a video?
For mistake number 6, "use more io.Reader and io.Writer", you can sharpen that even more. saveSourceAs would be even better implemented as func (page *page) saveSource(w io.Writer) (int64, error) { return io.Copy(w, page.Source.Content) } and at that point, arguably even _better_ written simply to expose the `io.Reader` in `page.Source.Content` in an official manner and call it a day, at which point all the referenced functions simply melt away, the sign that you're _really_ doing something right in the API. (It appears that the page.Source.Content is already public, based on the capitalization, though it's possible it's buried in some other private layer before it is publicly exposed. I'm not going and digging through the original source code.) It can be nice to provide "Write to a file" as a convenience function, just because it's ~5-line boilerplate of frequent use, but it is definitely an antipattern to take something that is an `io.Reader` internally and make it only publicly accessible via dumping it to a file. (Which, again, probably isn't being done here, but I've seen it... moreso in other languages that don't have an official "bytestream" abstraction so there's no easy way to export a "reader".)
I was initially using xmlpath, but it didn't seem to be able to do what I wanted with namespaces in the xpath queries.
I've always wondered - is there an advantage to using http.ListenAndServeTLS() in your application as opposed to using http.ListenAndServe() and having a reverse proxy like pound handle TLS?
I didn't actually try the encoding/xml route -- probably part of being new and lazy, but I figured the easiest way to get what I wanted was to run an xpath query against the parsed document and then iterate over the returned text nodes. However, it would be interested to see how encoding/xml deals with the document in question; I'll give it a shot.
If you have time to post this, I'd love to see some working code. Thanks!
Is not having a reverse proxy like pound handle TLS not advantage enough?
Seconding this!
+1! At 68, with just a couple of months of Go under my belt, this interview expresses my excitement about the language perfectly.
Probably too old. I think you need Chrome 41+.
Yes, that's the plan. It will eventually move to the Go standard library and be included by default. 
Either way works. Fewer moving parts if you do it from Go, at least, and I happen to trust Go's implementation and runtime more than other systems, even though Go's probably not as fast as some. Also, if you see the real remote address, you don't have to deal with things like X-Forwarded-For headers. 
You must have meant only implementing HTTP/2 for HTTPS. I guess this makes sense as long as https://letsencrypt.org/ actually works out. If not though...
The typography and colors on the slides are very uncomfortable and hard to read.
Yeah, I'm planning a little fix to the pooling for that reason and a couple others, after a talk I heard at Gotham Go this weekend.
Because there is no rfc for HTTP/2 yet. It's still in drafting status at the IETF. The RFC is planned to release at Feb 2015. You also didn't link to the RFC draft in the first place, which can be found here: http://tools.ietf.org/html/draft-ietf-httpbis-http2-14
Slides suck. Also, these "mistakes" are hard for me to grasp as a Go novice. Plain anglish plaese.
What about the risk of intruducing a second software component into your system, which itself can introduce a vulnerability and leak your cert? I'm not sold by the argument "let's make it more complex, so it get more secure!". And yes, I trust a GO programm much more then a reverse proxy written in C/C++.
Last time I researched the math/big package was the biggest performance killer for TLS in go. But that was one year ago and I don't know if things got better yet.
With how easy it is Go (with batteries included for web), and people using frameworks... an unnecessary layer which reduces performance and simplicity of language ... If Go was Python then I understand the use of a framework but it is Go.
The theory is that the reverse proxy will be more secure because lots of companies use it in production and it should have less moving parts than an application. But that's not necessarily the case (\*cough\* OpenSSL \*cough\*). If you trust Go more than a reverse proxy then there's no reason you can't just write a 10-line reverse proxy in Go and use that.
Yeah, I agree. I hate it when people release slides from a talk... it's almost never a useful exercise to read through them. Post commentary *with* the slides, then it becomes interesting.
@shelaki, I recommend starting a new discussion or raising a bug. 
I would also be interested in this. Then maybe I could get through checkout for that elusive Nexus 6 before it evaporates from my cart.
@davecheney, thanks for getting back to me. I don't consider this a bug, but more of a feature request. Would starting a discussion on golang-nuts have sufficient weight for the Go team to possibly consider this request?
It sounds like you're looking for something like this: https://github.com/headzoo/surf https://godoc.org/bitbucket.org/tebeka/selenium But if literally all you want to do is submit a form [http.PostForm()](https://golang.org/pkg/net/http/#PostForm) should work fine.
Wow, interestingly! 
&gt; I guess this makes sense as long as https://letsencrypt.org/ actually works out. Aren't there other places to get free SSL certs?
So, posting a form from a webpage is pretty trivial.... you shouldn't actually be looking at javascript/html stuff at all. You're not actually going to be interacting with the webpage in a browser. Instead, you'll be emulating what the browser does when you click the button. Clicking on the button in the browser just causes the browser to make an HTTP POST message that gets sent to the server with specific information from the form. You can replicate this in Go code or almost any other language that exists. This takes a little bit of knowledge about how HTTP works and how the data in forms is represented... as gladpaper mentioned, http.PostForm should do the trick, you just have to give it the right information about the URL and the form data. The tricky parts will be figuring out all the right data to give it, and probably working out how to authenticate (if the site you're submitting to requires authentication). There are tools in Chrome that can help you watch what data gets sent to the server for a specific action, so you can replicate it in code.
You should probably consider using "github.com/moovweb/gokogiri/xml" directly. The xml.StrictParseOption will give you an actual error message (the liberal xml.DefaultParseOption used by default suppresses all errors and warnings, leading to the head-scratching you're currently facing). import "github.com/moovweb/gokogiri/xml" doc, err := xml.Parse(content, xml.DefaultEncodingBytes, nil, xml.StrictParseOption, xml.DefaultEncodingBytes) Once you know what the actual error is, you can decide how you want to handle it - whether that's to reparse it with some recovery options turned on (look at the documentation for xml.ParseOption), flag it as broken and ignore it, specify a different encoding, etc... It won't be the lack of a return - more likely it's a harder to spot error like an undeclared entity or incorrectly declared encoding.
You're right, but it gets tricky when you have to start maintaining state like sessions, and dealing with CSRF protections, DOM interactions, etc., and it looks like packages like surf take care of that for you.
Ok, I'm going to use Negroni plus Gorilla/mux (and maybe Gorilla/context but I'm not sure yet). I'll use bootstrap, Golang have a template system, right? or there is something more *convenient*? **EDIT:** I better did a new post [here](https://www.reddit.com/r/golang/comments/2mq6ey/any_python_flasklike_web_framework_for_go/) for this question :)
StartSSL
I really like the render package https://github.com/unrolled/render It takes away some of the pain involved with HTML templates in Go. and it works great with pretty much anything that supports net/http
Whoops, indeed. Fixed.
This has immediately replaced a shell script I had that does something similar. Very excellent discovery 
Very nice. I like your style for multi-file templates. 
I have high hopes for letsencrypt. They seem to be doing everything correctly and it should work in all browsers. When it's ready I intended to make it as automatic as possible with Go.
For automation golang might not be the best option. I would recommend using something like auto it and its ie automation library, both are easy to learn and use
Why going trough the trouble of hosting it yourself while Freebase.com already has a well documented API (https://developers.google.com/freebase/v1/search-overview) ?
Yes, use tags + struct. http://golang.org/pkg/encoding/xml/#Marshal Add \`xml:",attr"\` to your struct To define attribute. Then marshal struct into xml. Sorry I'm on the phone and can't really give extended answer. But that's what you most likely need.
Hmm. Are you sure we're talking about the same thing here? I'm not talking about attributes, I'm talking about XML processing instructions like this sort of thing (note the question marks): &lt;?xml-stylesheet type="text/css" href="/style.css"?&gt;
You are correct we are talking about different things, all those things have completely escaped me, I will just excuse myself and head back to sleep. 
That is only for non-commercial stuff, and "non-commercial" in the way they mean it. You have to renew certificate every year, and revoking requires $$$.
Source code is tiny. `rm -rf $GOPATH/pkg` will remove any compiled packages, `go install` will put what is needed back again.
It could be that he needs to maintain control of the data for some reason, like correlating data from public sources like freebase.com with personally identifiable information from another source. There are a number of reasons why a company or individual might not want to share data and it's linkage with a service that does not have the same duty of care as they do.
What exactly does it do? not very clear from the readme. Does it set environment variables if it's not set?
Yes, you could use the same tools for freebase. The Freebase ntriples dump can be found under: http://commondatastorage.googleapis.com/freebase-public/rdf/freebase-rdf-latest.gz However, unpacked, the dump is over 300G IIRC, so it will take a (very) long time to load the triples. One optimization we tried was to shrink dumps by replacing common prefixes with shortcuts. [ntto](https://github.com/miku/ntto), which is just a thin wrapper around [replace](http://dev.mysql.com/doc/refman/5.7/en/replace-utility.html), will cut the typical ntriple dump filesize in half.
Yes, that is exactly it. Plus, I need to use Cayley and one can't do that with the search api.. Any advice or help on how to load the compressed data into Cayley and query it in Golang using Cayley?
True, but I need the data. For one reason being Cayley. So how do I load the compressed dump into Cayley and query it in Golang?
Shouldn't I just be able to add the compressed dump? And then how do I query it in golang
I think making a web server in go is already at its simplest version. Writing a library to make it simpler will only make it more complex. Here is a great talk about it: http://nicolasmerouze.com/build-web-framework-golang/
Maybe the sources are tiny but still there. I came to this running https://github.com/shurcooL/Go-Package-Store#go-package-store. It reports on all sources found, which can a while. Weeding out all that are not used any more would save some time.
Kind of embedded: https://github.com/robertkrimen/otto &gt; Package otto is a JavaScript parser and interpreter written natively in Go.
https://github.com/nf/deadleaves
Yes, since [0.3.1](https://github.com/google/cayley/issues/57) you can load triples from gz files. Internally, the archives are of course expanded, but it might be faster to read less from disk. With leveldb backend, you can have another compression in the storage layer: &gt; Google’s Snappy compression library is an optional dependency that can decrease the on-disk size of LevelDB stores with minimal sacrifice of speed. Snappy is highly optimized for fast compression and therefore does not provide particularly high compression ratios on common data. (http://leveldb.org/) That said, we haven't benchmarked the various cases. Also, we did the prefix compression to type less in the repl.
My results are (on average from 1000 requests): python: 242.2 ms golang: 142.2 ms This isnt news to anyone. I was just curious. Im sure these numbers can be better in both scenarios. both the servers were running in different amazon t2 microservers with ubuntu 14.04 Regardless of language I do not enjoy working with XML.
I think the difference here is that Go mandates the workspace that you must be working in (through GOPATH). For any other language, it was simple a matter of cloning / checking out in any location, then building from there. This was one of my biggest dislikes when I was getting started with Go, the fact that it wanted to force my workflow and that when I was modifying other projects (or my own) it would be applying to all dependents. I come from a Java background and (as much as people hate it) like the way that dependency management was done through maven with immutable deps (usually) in terms of being able to repeatedly build a project. It still feels (to me) pretty risky to be building against master of deps and things like [gopack](https://github.com/d2fn/gopack) seem to be addressing that.
Why use gokogiri? Why not use native Go XML? Setting the concurrency to -1 doesn't set it to use all cores. Code looks nothing like Go (use gofmt, follow Go standards of naming and variable formatting). You might be able to gain additional speed by streaming both input and output. Also, how much of that time is simply waiting for the data from the upstream xml provider? But a decent start to get Going!
Please correct me if I'm wrong, but you don't need to build and execute in two lines, just use `go run /path/to/project/Py-Go-xml-parse/src/xml_parse.go`.
while -&gt; for
Thanks for the input. I really appreciate it. Here are the explanations I have for doing what I did. - I've used gokogiri mainly because I didnt know the exact response data, so I couldnt define the struct for it. Also from the responses I got there is a comment bit on the bottom which I cannot remove (I've read that when unmarshalling this is removed) but I didnt have the struct of the received data from response so I couldn't use it. The questions I asked on the irc channel told me to make my own custom unmarshaller and honestly I dont have the knowledge to even know where to start doing that. - I didnt even know I could set the number of cores and again on the irc channel they were talking about it so I wanted to use it. - I had no idea what gofmt was. The standards were also unknown to me; Are you referring to these? https://golang.org/doc/effective_go.html - I dont know the upstream time of the request, I'll look into it later tomorrow. Again its the first time I've used Golang. I honestly didnt even think I would get this far but felt proud nevertheless. Thank you for your evaluation I really needed it!
Okay, I have snappy. Now, how can I use it while using os.Open to stream a file so that the streamed file is compressed internally? And, also, the issue, if you don't mind helping me, that I'd greatly appreciate help with also is how to query the graph.
Oops. Too much python.
* I suspect if you just want to transform a little bit, it might be better to do it with some form of stream processing... right now you are doing a ton of allocations that are not required, and buffer the entire contents over and over again. * You aren't setting the number of cores currently. -1 does absolutely nothing (changes nothing). If you want to set to available cores, then set it to runtime.NumCPU(). * http://blog.golang.org/go-fmt-your-code ... and you found https://golang.org/doc/effective_go.html which is a great resource to follow as well. * I would be very curious how much of the Go time is spent fetching that data, https://coderwall.com/p/cp5fya/measuring-execution-time-in-go around the http call would let you know. 
This thumbnail creature looks like a tweaked out juggalo.
I find that the Go standard library is very close to working with Flask. I have used Flask in the past and now that I have some experience with Go, I think that you should start with the standard library. I find that everything I expect is in those libraries.
Sorry, I only used the JS query language so far.
okay, thanks for the help, though! Wait, how do you use the js query language from a .js file and not from the web app, then?
Frameworks allow us to reason about the behaviour at a higher level and do more with less boilerplate code. It's a common design pattern that applies even to Go.
This reminds me: I read in the documentation about `{{range pipeline}} T1 {{end}}` I guess that it is the equivalent of Django template's for-loop, but I don't understand exactly what `T1` should be, and how could I use such action to create the &lt;li&gt; for a &lt;ul&gt; tag. 
Thanks, after doing additional research it seems like surf is the thing I needed all along! :)
Generally, there has been a consensus (read: convention) *against* defining "big" interfaces. I haven't used GAE, but isn't there a way to simulate the environment locally?
It won't be feature-complete w/o [enneff's streaming poop handler](http://github.com/bradfitz/http2/pull/10).
I guess you could use the [HTTP API](https://github.com/google/cayley/blob/master/docs/HTTP.md).
Thanks.
There is, but not inside a unit testing framework, which makes things annoying. (Disclaimer: I haven't seriously used appengine in a couple of years, so there's a small chance things have improved since I was last vexed by it.)
That's what the aetest package is for. It simulates the environment in that it runs the dev appserver in a certain way. This seems to cause siniec's main problem, which is that it's slow to start up.
The book is available at 50% off with code mlnickoloff 
Yes, I know that is a framework, but Go not require any framework for purpose of creation of a webapp. net/http + libraries is sufficient!
In your Go main method, you print out that the server is up and running before it actually is. Just something minor. But I am going to test this out when I get home! 
I use a similar approach, haven't had any problems at least as of yet. Personally I pass the [encoded string](https://cloud.google.com/appengine/docs/go/datastore/reference#Key.Encode) of the key. An added bonus is that using an interface to GAE makes it easier to switch to something else if needed.
Here an example for understand the range pipeline: http://play.golang.org/p/HvdxanOZTd I suggest you to read the links of the above comment, You will learn clearly the usage of templates in Go!
Ah, yeah, that postdates my attempts to use appengine. Thanks for the pointer!
Correct. Having the aetest package that allows us to test that the code works against the actual app engine API is great -- for *integration testing*. Verifying that the objects stored is compliant with the API, that keys are valid etc is very useful. However, when I in my unit test simply want to verify that an audit object is stored when my user is changed, I don't need that integrity checking at the cost of a multi-second setup/teardown process.
Ok, thanks! I think I'd like to keep it as close to the original API as possible, ie passing keys instead of strings. Minimize the difference to make it more familiar to developers that know the original library.
In terms of go, yes, the interfaces would be big. 8+ methods per interface. It is... frustrating that the reason I'm hesitant of doing this is because it goes against conventions, yet there is no real alternative of achieving what I want. As /u/durin42 pointed out, there is aetest, which does what you ask. But I still stand on my view that pulling in a simulated environment makes the test an integration test and not a unit test.
appreciate it nevertheless, I honestly just put it there for myself. forgot all about it! Sorry
I get the idea, but I don't quite think the execution is right here. I've got a slightly different method of preparing SQL queries that results in them being prepared and named at startup, which works really well. Here's a small sample: https://gist.github.com/anonymous/cd8e42ac2329d1695941 From there, you can refer to the `stmts` variable for all of your prepared query. 
fmt.Sprintf.
Obviously he does. Or, you know, someone without unlimited space. But thanks for your insightful contribution, I guess? 
My pleasure.
This. Though, fmt.Sprint() also works if you only want a string of the float itself.
Thank you! Is there a similarly simple way to convert a string to a float?
I don't believe that encoding/xml has anything that handles &lt;? ?&gt; wrapped xml declarations. Like with the const xml.Header, I think you'll have to simply write the stylesheet declaration before marshalling the rest of your data.
As long as the package contains a single file.
I've started using this recently and the overall it's been great so far. A few minor hangups, like private repos not being go-gettable, but I'm not even sure that's a problem with Gogs. 
FINALLY! FUCK RUBY! I want GitLab to be great, but Ruby makes it a nightmare!
I was prepared to roll my eyes. I've read so many Go/JSON posts that go through contrived examples to show you that you can decode a struct. But I really liked this one. I came out of it learning a few new things including skipable fields and deferred decoding. And it was generally well-written.
Go doesn't have a good enough story for resource file installation, so bringing another resource file into the fold seems like a bad idea. You're probably better off defining your queries in a map in a single go source file (assuming you expect your queries to be unchanging).
He can always use one of the numerous packages that allow you to embed resources in the executable, like [go-bindata](https://github.com/jteeuwen/go-bindata) or [go.rice](https://github.com/GeertJohan/go.rice). That is, if dotsql had supported it.
I thought that might be the case. Thanks.
&gt; Here an example for understand the range pipeline: http://play.golang.org/p/HvdxanOZTd Or http://play.golang.org/p/oB-vl_zDgG
Could you elaborate on your scenario and reasoning for hosting 2+ http servers in a single assembly? It's unlikely you will receive useful advice without providing context. To answer your question, you would use goroutines to launch the http servers wrapping it in a sync.WaitGroup - [see here](https://play.golang.org/p/7YCtzq-7at).
I have edited the post.
I have edited the post.
It is possible. You have full access to the system, and you might even be able to get something that is somewhat performant. However, it would probably not be a good use of time, except as a learning experience. And it would be many months before you had something very usable. If you want to write client software in Go, it would be better to not plague yourself with everything that is involved in a web browser.
Wow, looks really useful. Is there any articles on this approach? Any non-obvious pitfalls?
Read rationale section on https://github.com/krisajenkins/yesql The key points are: * Don't write sql directly in your code (it's kind of horrible to have large sql strings on your code) * Why create a DSL (query builder), SQL is already one * Having separate .sql files allows you to reuse them
Most Go guis just serve a webpage, so I guess you could do that.
Serve a webpage as the GUI of a browser? So... you browse inside your current browser using as browser the go code? As much as I like inception-esque coding, this doesn't seem specially neat.
In general, ideas are not important. Everyone feel they have great ideas, but only setting them into life will reveal if they were any good. Yes, a good idea is a good fundament, but execution is what matters. Execution, experiments, gathering feedback and iterating. So yeah, making a browser, good idea, whatever. Is it hard? No. Nothing is hard, it's only a matter of persistence and time (could take a million years, but it is only time-consuming, not hard). Is it realistic that someone, if they wanted, could build a browser in Go, within a reasonable timespan? Yes! Follow your dreams, but iterate. Just go for it.
Feature requests are best address with a bug report on the issue tracker, https://golang.org/issue/new
Really neat idea. Would be awesome to have some kind of integration with sqlx. Another neat idea would be to generate code using the new go generate in go 1.4 and allow strong typed functions being generated. e.g. dot.CreateUser("Archer S", "foo@gm.com") dot.FindOneUserByEmail("foo@gm.com")
Haha i just pictured the Inception trailer with a browser folding over on itself. Not as exiting to be honest!!!
It's.... browsers! All the way down!!
:D specially when all turns out to be Internet Explorer 4!
I think the people who have written [those routers](https://github.com/julienschmidt/go-http-routing-benchmark) have done a fantastic job. I had an idea for a router implementation the other day I would like to work on (based on a patricia trie with typed parameters and ordered route parts). I'll probably start work on it in a week or two once I'm done with the tests, benchmarks and other administrative tasks to make GA an ioc package I'm writing.
Is this an option? https://github.com/koding/kite Or have a look at the plugin system of HashiCorp's packer... 
Looking forward to see your work.
The Chromium codebase is about 5M SLOC, and much of that code resembles ancient and powerful incantations that could make the dead walk amongst the living. I think I could write 5 *different* Go compilers in the time it would take me to write a web browser from scratch.
I think I have to disagree with some of the posters here. Yes, it's "possible" to make a modern web browser by yourself, but realistically this is a major undertaking that requires hundreds of person years of effort. It's one of the most difficult projects in all of software engineering. That said, if you scale your expectations back to making something like lynx (i.e., text mode browsing), I think it's something you could reasonably pull off, although you never mentioned your programming experience level.
LiteIde is awesome as it has all features to make programming in Go really easy but after almost 10 years of using Vim, I cannot live without a Vim plugin. IntelliJ is heavy and for Go is really but really bad Vim + vim-go is a good alternative but it laks of things like "jump to definition" so if you are working on a big project and not all the code is yours, it is hard to find where a structure or method is defined
I don't think it matters if he decides to do it or not. Id say the only thing that matters is having a reason to do it, what will his/her browser do that the others wont. If your not implementing something close to home, then I have to say what is the point.
Stop refering to a go source file or a go program as a "script". It's not a god damn script! You want to be a programmer but you're ignorant enough to not care to know what a compiled binary is as opposed to an interpreted script.
I use [Djinn](https://github.com/thrisp/djinn), which solves issues I've had with using the standard library templating in html/template.
Extremely interesting. I would like to do this for my projects, but I am mostly interested in third party dependencies. I think I would be fine omitting standard library packages altogether, but it might be nice to see the top level packages used by github packages. I considered using dot/graphviz for such a thing, but never got around to it.
Also, your example is a bit silly. You are overriding method you are not calling. I understand that you are trying to emulate "OO" behavior of Python. To me, it just shows the subtleties of the "OO" approach other languages taken which are not straight forward and obscure. So, the question is why would you want to replicate this style in Go it if you don't have to?
the project will soon move to https://bitbucket.org/idsl/idsl It will offer generics that act like a slice for go
I was expecting to see goroutines and channels in action.
I don't see what the problems are. I run a GitLab instance and all that was needed was install Ruby, then install the GitLab omnibus package. Took forever to install but once it's up it's up. Gogs looks nice, but for something like a code repository that stores so much important data I would rather stick with something more mature like GitLab. Edit: I accidentally a word 
[Flotilla](https://github.com/thrisp/flotilla/tree/develop) is being developed as 'Flask-like'. The Go standard library is flask-like in itself as others have mentioned, but you still need to go a bit further to get a micro framework similar to flask, and Flotilla is an ongoing attempt at that. 
You could take a look at godepgraph (https://github.com/kisielk/godepgraph) for something similar, albeit a lot simpler. 
One final tip: because JSON only has a numeric type, not a specific integer type, and because you may be interacting with JavaScript code which only has integer precision to approximately 53 bits, `int64` values should be encoded into strings rather than numbers. Go will handle this for you automatically if you tag it: type Foo struct { ID int64 `json:"id,string"` } The `string` there instructs the JSON encoder and decoder to automatically, transparently format and parse between `string` and `int64`. I believe this was added in 1.3.
Nice write-up. Thanks for the detailed instructions.
The Decoder/Encoder section is a little misleading. The decoding isn't a SAX-like streaming parser of a JSON document. It simply reads JSON values one at a time, in its entirety, and parses it and returns a value. So if you are passing a massive JSON object over the wire, there's no difference between calling `json.Unmarshal()` on a `[]byte` of it versus `dec.Decode()` on an `io.Reader`. The underlying implementation of `Decode()` simply calls `Unmarshal()` -- see here: http://golang.org/src/pkg/encoding/json/stream.go?s=989:1036#L29 There's no real standard for JSON streaming. The Encoder just writes out JSON values separately on an `io.Writer`, one per line. If you want to write out a huge object, just as with the decoder it first serializes it to a `[]byte` and writes that out on the writer. The tl;dr here is that if you have only a single value to encode or decode, there's no difference from a memory performance standpoint if you use `json.Encoder`/`json.Decoder` types or the `json.Marshal`/`json.Unmarshal` functions. Use whichever one is more convenient for the type (`io.Writer`/`io.Reader` or `[]byte`) you're given.
Consider that the Chromium code is actually the same source for a few different platforms, including Chromium OS, and Chromecast. But yes, I never said building a web browser from scratch would be easy. I don't think I'd actually be doing it either (not if it's just me anyways). The post was mostly to get a thought off my mind, and see what others thought.
I had no idea. Thanks!
with firefox you could already do that, open chrome://browser/content/browser.xul
Might possibly be able to get a more useful visualization using hive plots. http://bost.ocks.org/mike/hive/ http://bl.ocks.org/RichMorin/raw/2117857/ http://egweb.bcgsc.ca/ Takes a bit to understand what is going on but feels useful after you get gist...
Ditto - or at least more than function signatures. A little light. 
Is the link broken for anyone else?
why not use memc-nginx-module? https://github.com/openresty/memc-nginx-module#readme 1. No additional process to maintain 2. It is very easy to implement (see the example) 3. Amazingly fast It is part of http://openresty.org/ which is one of the top performing web service frameworks as per bench http://www.techempower.com/benchmarks/ Infact it is used by cloudflare.com which you mentioned in your blog.
Kite seems interesting, but I really don't need that much communication, I think that my bigger problem is to precisely find on which port is running the launched plug-in since I delegated that to the OS, the main web app just need to know that information in order to redirect the user, that's all.
This was my first impression when I was reading this article. The embedded Lua for nginx was made to solve problems like this, so you don't have the overhead of external processes. OP, any interest in exploring that as an option?
I'm a little surprised no one has posted the token "{{insert language}} is Turing-complete, so anything is possible." Go would be great for the i/o bits of the browser, but GUI interfacing is still more painful than in C, IMO.
Realistically, no, I don't think Go would be a good language for a web browser. At least, all the current browsers and javascript engines are written in C++, [see here for a summary](http://www.quora.com/What-programming-languages-are-web-browsers-like-Google-Chrome-Opera-and-Mozilla-Firefox-written-in?share=1). I'd have to assume that's because browsers try to eek out every bit of performance possible, and memory management, lack of GC, etc, are all important for that. That's part of what makes Servo so interesting - to see if a new language can fit that role and make a web browser from the ground up - but it remains to be seen if that experiment will pan out. Servo is also a team of many people, some even salaried, who have been working on it for months already. So I don't think, short of some institutional backing, a web browser would be feasible. That said, if you want a poke in the right direction, maybe you'd be interested in going through the [let's build a browser engine](http://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html) guide, but in Go? It's written by someone getting their feet wet to contribute to Servo and is quite interesting. I think I've seen ports of it to Haskell already.
Provided a reasonably smart person, could he or she be able to defeat complexity given enough time? 
Try running it with tons of code, everyday, with a 10 man team. It crashes literally every few hours. Why do I blame Ruby? Because it's usually due to type errors and timeouts. This is after running the Enterprise version for a year and updating every "stable" release, so don't lie to me and tell me you've used it and everything is fine. I'll say it again; Fuck Ruby and Fuck GitLab!
I use Otto in a similar fashion, but only when the data size is small. Otherwise, the length of your computation in JS is quite noticeable when repeating n-line times... even for evaluating a simple expression tree. 
Use x/net/websocket.
i want to use websocket but haven't gotten to that point yet. it might help if you look at the source and see how they're implemented. that usually helps when i'm deciding on a package/lib/framework.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Trivial File Transfer Protocol**](https://en.wikipedia.org/wiki/Trivial%20File%20Transfer%20Protocol): [](#sfw) --- &gt; &gt;__Trivial File Transfer Protocol__ (__TFTP__) is a simple, lock-step, [file](https://en.wikipedia.org/wiki/Computer_file) transfer protocol which allows a client to get or put a file onto a remote host. One of its primary uses is in the early stages of nodes booting from a Local Area Network. TFTP has been used for this application because it is very simple to implement. &gt;==== &gt;[**Image**](https://i.imgur.com/vaz4n4u.png) [^(i)](https://commons.wikimedia.org/wiki/File:Tftp-wrq.svg) --- ^Interesting: [^Cisco ^Network ^Registrar](https://en.wikipedia.org/wiki/Cisco_Network_Registrar) ^| [^List ^of ^file ^transfer ^protocols](https://en.wikipedia.org/wiki/List_of_file_transfer_protocols) ^| [^Cable ^Internet ^access](https://en.wikipedia.org/wiki/Cable_Internet_access) ^| [^EFTP](https://en.wikipedia.org/wiki/EFTP) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cm9orvo) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cm9orvo)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I didn't have a chance to look at the code or try it, but being able to easily make something that makes a custom TFTP server is pretty fun. It's easy to see how it could be useful in pxe boot environments.
Wow that's really cool. Is this intentional, or is it just how the ordinary browser chrome is implemented?
I rather like x/net/websocket. It seems simpler and more Go idiomatic to me.
This was great; I found myself nodding a lot reading through it. Though I'm not sure the slides alone will be helpful unless you already are at least pretty close to having realized these mistakes on your own.
This is integrated into vim-go to with the command `:GoRename`. Check out a quick demo of it: http://quick.as/dgof2p7
is this saved so i can watch it later? don't really have time right now
Pretty sure most do exist (Stripe for example), there was even a lifst of plugins which exist in Go, but i cannot find it right now sorry.
If the Go packages for the APIs you seek to interact with aren't adequate enough for you and you don't want to write your own, one approach might be to develop a Node.js/Go hybrid application. You can communicate between both using either HTTP or Zeromq for example.
it's because of magic https://i.imgur.com/sg017lt.gif
edit: Uploading VODs to YT
Currently uploading VODs to youtube, if they work i'll shout you a link my friend!
Any chance of a write up? 
thanks
gorilla uses x/net/websocket. It just add more features to it.
link to your channel?
Yeah, probably. Might be a few more days though.
http://twitch.tv/paked The stream is over now, but I plan to do another one in about 20 hours, and on a regular basis after that. So probably a good idea to follow :)
and youtube? i can't always be live due to timezones, youtube channel would be pretty good.
hey, your video would be taken down from youtube as well because of the copyrighted music in the background or something. :(
Are you sure? The x/net/websocket package is not in the [list of goriilla's imports](http://godoc.org/github.com/gorilla/websocket?imports).
In the future you may want to locally record for upload to other platforms, it's not a lot of disk space, even at twitch's maximum recommended bitrates of 3660 kbps ( 3500 video, 160 audio ), and it prevents the near total loss of audio content ( since exporting muted content from Twitch to YouTube does not unmute it )
Hi. I wrote the blog post. * We considered the memc-nginx module. I wasn't confortable with bloating our load-balancer's Nginx with modules and functionality that are not really its main concern. I'd rather write smaller network services that do fewer things. * The Go daemon does a couple more things, like logging recs. per second and emitting events to our stats collector. I could've done that as a Lua extension I guess by I have 0 experience with that. * I'd rather unit test Go than Nginx. * The Go program is easy to scale horizontally by running it in more machines. I don't need to rebuild it in every machine, just once and then rsync it to all target machines. * While probably less performant than the Nginx+Memcache combo, what we built gave us enough perf. That we won't need to worry about it for a while. It did the job. * I only had a couple of days to solve this. I used the tools that I know best and the patterns that I thought would scale better. * It worked. Thanks for reading!
Unfortunately, the Gorilla websocket comparison linked to by arvtno is pretty devestating. "More idiomatic" can't fix "incorrect". I've got a couple of projects that use the x/net/websocket, and I got away with it since I wasn't torturing it very hard, but I'm planning on using the gorilla one in the future, because I _will_ eventually hit the problems gorilla describes. This message is caveated on the assumption the x/net/websocket has not fixed some of the issues in the comparison. Some are baked into the API, but some could be corrected in future code. The ones baked into the API are still pretty bad, though.
I was looking through the code as suggested by bmo111. The x/net code [uses the factory pattern](https://code.google.com/p/go/source/browse/websocket/websocket.go?repo=net#126). As far as I can tell, there's only one implementation of the factory. I am somewhat new to Go, but I am pretty sure that's not very idiomatic. 
Did it work?
the project has moved to: https://bitbucket.org/idos/idos/ It's now called Insert Delete Ordered Slice
That's another possibility. Do you have any pointers to examples for a hybrid solution?
e.g. for Passbook I found a post from the golang mailing list that said, sorry, no crypto module for that available and none on the roadmap, so just shell out to openssl.
Nice! Maybe someday I can use this instead of my ruby script.
oO nevermind then. must have dreamt it ^^. sorry.
If you wanted to put this on a website, like a flash game, how would you go about it?
You're letting your german show :P
I've been using beego and am really enjoying it. You can replace your PHP backend with Go. I love being able to compile my app and deploy it as a single binary. You can use nginx as a proxy or use Go's own HTTP server alone. There's loads of cool stuff to do with Go in the realm of webdev/networking/infrastructure. It's only getting better as the ecosystem and language matures. Go is great for writing various services. For instance, I was able to write a simple SMTP mailer service that listens for mail requests from beanstalkd. It works great, was simple to write, and again deploys as a single binary. Use something like systemd or supervisord to manage your services and you're set.
Try if you need insert delete ordered slice bitbucket.org/idos/idos
Nope as you might have seen audio messed up. 
I think I would still have the copyrighted music issue, and I really like listening to music. Might try and come up with a scheme to get some music. 
Actually, I am able to transpile to JavasScript and host it like that :) I'll try and get some things written up soon
We use Go as a backend, as a Restful API server. Then, we use AngularJS or whatever as frontend. Go is fast, is its own webserver, has built in testing packages, and handles data well. It does it all very well without external libraries, although an number of libraries and web frameworks exist that are helpful. It is my favorite server-side language. 
That's too bad, sorry to hear it.
&gt; It's advisable to use go http server for big projects? The go http server is intended for large scale production use. dl.google.com for example uses it.
Im going to start doing regular streams soon hopefully so look out for that
* Could use the Compile() method to pre-compile the source before the worker loop and pass the compiled script to Run() * Buffering stdout will help when writing thousands of lines * bufio.NewScanner is a simpler way to process line input
&gt; I love being able to compile my app and deploy it as a single binary. People keep saying that, but are people compiling their templates and static assets into the binary too? If so how?
gorename also updates all the callers of the function across your entire workspace to use the new name.
Thanks for the review. Indeed, [Compile()](https://github.com/miku/ottily/commit/78b761ce9cfb7260f645ae75e507b0c906ca0571) and [buffered stdout](https://github.com/miku/ottily/commit/9abf8b511e2b98058caa2d62eee0395b4134997f) help. I didn't want to use bufio.NewScanner, because I occasionally ran into some too long tokens, that Scanner does not handle, due to [MaxScanTokenSize](http://golang.org/src/pkg/bufio/scan.go?s=1184:1667#L69): &gt; Scanning stops unrecoverably at EOF, the first I/O error, or a token too large to fit in the buffer. 
Depends what you need. It could benefit from functional approach if it was meant to be flexible, e.g. http://play.golang.org/p/yU6KUS1y5w.
I changed the filter and slice methods to operate on a pointer. Returning a collection didn't seem go-like. I'm not to happy with the naming of the files and structs/interfaces. I feel like it could be a lot better.
Right, but I was more curious as to why they chose that design? Is the api feeding other front-ends or did they decide to just use angular instead of backend templates. I was looking for more context on why they chose their setup the way they did. 
Verdammt, what gives it away?
&gt; Returning a collection didn't seem go-like I assume you talk about this: func (c Collection) Filter(fn FilterFunc) Collection c.Filter(ByUser("A")).Map(RenameUser("A", "C")) It's hard for me to say whether immutable vs mutable operations has something to do with being Go-like. To get rid of boxing you could create a single template and go-generate collections for your data structures. Just an idea.
&gt; Go oder Node Assuming you're not joking :P
Stripe has official support for Go https://stripe.com/blog/official-go-support
Hi rjik, thanks for thinking along :) I was actually talking about [this change](https://github.com/LeonB/stest/commit/ed6c027b8d04c35df0797db312fee0c63995a403#diff-126bf1c4d3082cd978ae6e9a5f17e3cf) in my own code. A map/filter function returning a Collection seems totally acceptable to me.
If you're interested look up gopherjs, that's the transpiler itself
Hi (author of Azul3D here), # The graphics core Azul3D has a graphics core which does most of what you want, but not anything special for 2D. The graphics core ([github here](http://github.com/azul3d/gfx)) right now has three parts: The `gfx` package, which is a nice generic Go interface to modern rendering API's like OpenGL, WebGL, Direct3D, etc. Basically it gives you near-full power of these API's but through Go instead of messing with CGO/OpenGL code. The `gfx/window` package, which can open a window and set up a renderer for you. It uses GLFW3 internally. The `gfx/gl2` package, which provides a `gfx.Renderer` using an OpenGL 2 context (the `gfx/window` package uses this). Today it supports Windows+Linux+OS X, but I plan on having Android and hopefully WebGL/GopherJS support coming soon (around December). Take note that the `gfx` package _is a graphics API, not a game engine_. It tries really hard to not restrict what you can do. # 2D capabilities Azul3D doesn't have anything special graphics wise for 2D stuff right now. Basically, it's no different than if you wanted to do 2D directly with OpenGL itself. You can create models, textured cards, etc and render them with an orthographic camera and you're all set. There is an interim text package for rendering 2D pre-rasterized text: http://azul3d.org/more-packages.html#ztext I'd also look into using [draw2d](https://code.google.com/p/draw2d/) which renders vector graphics to images (you could then display these on textured cards through the `gfx` package, if you choose to use it). In the future I imagine having a package for Azul3D that can evaluate quadratic bezier curves in a fragment shader (i.e. resolution-independent text and vector graphics), but no ETA on that yet. Cool to see you're gonna do game stuff with Go! I am really excited to see what you come up with, regardless of what you end up using =)
Discussion on HN: https://news.ycombinator.com/item?id=8649857 Some 18 days ago [I asked if anyone knew of a mature IOC container for Go](http://www.reddit.com/r/golang/comments/2lcxza/ioc_container/). The general response was "Please don't do that". So to appease my curiosity and to test the consensus, that's just what I did. After about 4 rewrites and learning a lot about Go's type system and constraints, I managed to create package ioc in the Spirit of Go: Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. The performance is not that bad considering and is suitable for general programming. I'd go out on a limb and say that it's about the same speed as Autofac - reflect.ValueOf()/reflect.Value.Elem() takes about 30 ns per call. I would love to hear your feedback, especially if you have ideas to improve the performance. P.S. I would appreciate help if anyone knows how to sort out the Travis CI build error.
Why have we converged on 'IOC Container' as the name for /dependency injection framework/ ? All frameworks invert control flow (framework calls you). Why do DI frameworks think they own The IOC moniker? And as for ''container' ... I have no idea.
[Wikipedia](http://en.wikipedia.org/wiki/Inversion_of_control): In software engineering, inversion of control (IoC) describes a design in which custom-written portions of a computer program receive the flow of control from a generic, reusable library. Dependency injection can happen without inversion of control - such in the case where ready built instances or singletons are injected. Example: [facebookgo/inject](https://github.com/facebookgo/inject). Inversion of control is about defining a function to build an instance, based on other instances that can be built without needing to know how they are constructed. E.g. Given "A" can be built by the IOC container, you define a function to build "B" that takes a dependency on "A"; so you ask the IOC container for an instance of "A" so that you can build "B". This is called inversion of control because "B" doesn't need to know the dependencies of or how to build "A" to create an instance of "B". Inversion of control is a declarative approach to dependency management, rather than a requirement for dependency injection. The "container" moniker is at play because 1. it stores a registry of how to construct instances and 2. because it stores instances based on their declared lifetime characteristics e.g. singletons or instances that should only be created (lazily) once per container or scope or for every request.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Inversion of control**](https://en.wikipedia.org/wiki/Inversion%20of%20control): [](#sfw) --- &gt;In [software engineering](https://en.wikipedia.org/wiki/Software_engineering), __inversion of control__ (__IoC__) describes a design in which custom-written portions of a [computer program](https://en.wikipedia.org/wiki/Computer_program) receive the [flow of control](https://en.wikipedia.org/wiki/Control_flow) from a generic, [reusable library](https://en.wikipedia.org/wiki/Reusable_library). A [software architecture](https://en.wikipedia.org/wiki/Software_architecture) with this design inverts control as compared to traditional [procedural programming](https://en.wikipedia.org/wiki/Procedural_programming): in traditional programming, the custom code that expresses the purpose of the program [calls into](https://en.wikipedia.org/wiki/Function_call#Main_concepts) reusable libraries to take care of generic tasks, but with inversion of control, it is the reusable code that calls into the custom, or task-specific, code. &gt; --- ^Interesting: [^Apache ^Excalibur](https://en.wikipedia.org/wiki/Apache_Excalibur) ^| [^ColdSpring ^Framework](https://en.wikipedia.org/wiki/ColdSpring_Framework) ^| [^Reasonable ^Server ^Faces](https://en.wikipedia.org/wiki/Reasonable_Server_Faces) ^| [^Apache ^HiveMind](https://en.wikipedia.org/wiki/Apache_HiveMind) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cmazcsz) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cmazcsz)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I chose to use rockdb for storage, but from the benchmarks on ledis' wiki, it looks on-par with leveldb, of which look to be the best options. My instruments are showing ~500 operations / second.. not crazy. We use https://github.com/garyburd/redigo for the client.
Hi @denmaradi , I have used LedisDB in my company from v0.1, and some people also told me that they have used it in production too. You can see the benchmark in wiki compared with Redis. Hope it can fit your performance need. I am not familiar with cockroachdb, but @pkieltyka has given a detailed explanation. later I will add [codis](https://github.com/wandoulabs/codis) to support distribution. LedisDB supplies the APIs like Redis, so I don't think we need a query lib on top of it. Just try using it as an advanced KV storage. Btw, I suggest using rocksdb as the backend storage, it is very fast, but if you want to use pure go, goleveldb is good too. 
btw, as an aside, I've also heard really good things about https://github.com/aerospike
Many awesome NoSQLs every day!!!
Web 2.0, you know.
Yo dawg so we herd you like browsers so we put a browser in your browser so you can browse while you browse.
I think I'm more a fan of SOA than microservices, as all micro-service implementations I see tend to have heavy library dependencies with fairly complex communications. This leads to language lock-in which increases the tendency towards tighter integration and a decrease in the exact flexibility you wanted when you adopted the architecture. IMO a simple system using standard protocols, like HTTP, with well defined APIs would be better. Maybe there is a happy middle ground of a handful of microservices encapsulated inside an HTTP based service. Or maybe an alternative protocol that is fairly standard like protocol buffers would work.
&gt; codis codis looks pretty bloated to me.. I hope ledis can stay light and a clustering option would be layered on top.. I'm not sure what the options would be, most are consistent hashing based, and sounds like cockroachdb thought of the idea to use raft to coordinate the range of data sets, which is a neat idea
I don't think Go is for you.
My point is that prior to DI, IOC already had a well defined meaning. It is ridiculous to assume that the only control inversion in software is dependency resolution. Any system that uses callbacks is inverting control flow. 
Perhaps not. I've removed my Github Go repos and I won't be around anymore. Ciao
hi @pkieltyka, 500 iops is the benchmark result? It seems a little slow. The benchmark may not mean leveldb is better than rocksdb, and the result may be out of date, I will update later. LedisDB adds many configurations for rocksdb, you can tune it by yourself, so I think it is better than leveldb now. 
Duh, totally didn't notice, even when re-reading.
Slices are "reference types" anyway: they contain only 3 words (12 or 24 bytes for 32/64-bit systems): a pointer to the array backing the slice, slice's length and capacity. If you are worried about performance hit when returning slices "by value", you should probably not.
Don't worry mate, more streams coming. :-) As to what I use to make games in Go, I am currently modifying and expanding upon [Ajhager's Engi](https://github.com/ajhager/engi) (ie. making it geared towards games rather than it being a multimedia platform). You can find my version over at https://github.com/paked/engi. FYI The engine is based on the Entity Component System design. If you feel you have anything to add towards the project, open a pull request :) *Didn't mean for this to become a comment that shamelessly plugged my library, so please don't take it that way* 
Thanks a lot. 
Thanks for awesome work. Yes, rocksdb for production is what I am looking for. On top of that there is a project called Linq that I will using for querying. I prefer that over set operation provided by redis client.
For simple HTTP - absolutely, but if you need HTTPS/SSL - run an nginx/apache2 reverse proxy in front of it, the SSL implementation of Go is sensitive to timing attacks (and due to the nature of Go, this will be very hard or even impossible to fix) and not as well reviewed.
and btw, the 500 iops was just a sample on a Sunday late afternoon of one of our services 
On github search for go linq. Author is, I guess, named Balkan. (Replying through phone)
Golang is web searchable. Go is not. Lighten up. 
Don't you think that you could implement Kite in a SOA fashion as well? I'd think it would just make it easier to break up the application later as the system evolves without having to worry about routing at all. Yes it would introduce some dependancies, but I guess if this was mapped into standard protocols it would be desirable as well. Imagine the same interface, but using http/json? Not too sure though.. Making some big decisions about this at my new job I started, building out a whole web application...
Fair enough, I'll concede to that. I only have a 4 man team with 3 projects (each at about 100,000 LOC) so you have requirements above my own. I hope you find Gogs.io better than GitLab, and if I ever run into issues when I reach your scale I will bare it in mind and switch.
[This article](http://blog.gopheracademy.com/birthday-bash-2014/kite-microservice-library/) was recently published, describing how to build microservices in Golang. The idea behind microservices is to have lots of discrete services, usually running across HTTP, communicating together to get work done. Since everything communicates via HTTP, you could actually write each service in whichever language suits it (or you) best. See if it suits you!
ew
Indeed, many of the optimizations that make the "official" JVM fast (in spite of the language model) are the aggressive optimizations to reduce allocations in places they'd seem to be dictated by the language.
I agree. I've always thought that HTTP/JSON is not the ideal transport for internal microservices. ZeroMQ with some binary encoding (Thrift, PB, etc) should have less latency and overhead.
That's a lot of source files in one directory haha
Yes! but being a project approached in a one thing (in this case, elasticasearch), not should be no problem of structure. If this package were a client for mongodb, elasticsearch and other one more then it should be separate in different directory (I'm not the author of this package but at least, I'm doing it of this way in my projects too)
Makes sense! Just a comment.
A good writeup that covers the basics of the subject without getting bogged down in caveats. That said, it's odd that the author doesn't mention that slices are more idiomatic than pointers to arrays — maybe a little redundant to do, given the link to “Go Slices: usage and internals” in the reference section.
I was sort of hoping to find actual zookeepers. This is cool too, though.
Unfortunately you don't always know the architecture you're deploying to. :/
It's simple enough to set up builds for all permutations of GOOS/GOARCH that you expect to see, though.
Thanks demetreh, I will implement your suggestions.
The kites are going to reconnect automatically until it's up again. Any kite that that was fetched before and is in process of talking with each other will be not affected (because the token and url is already fetched). So the kites will be not down, however you are not able to discover any new kites. Also the token has a a expire duration (which is configurable). So this means if you have a token with a low expire duration, after the expiration you are not able to talk with others anymore.
 cmd.Stdout = os.Stdout cmd.Stdin = os.Stdin cmd.Stderr = os.Stderr cmd.Run()
Nice that this got here! I'm relatively new to Go lang, so please any tip will be appreciated. Anyway just a quick Sunday afternoon hack :-)
&gt; On the other hand, I want to stick to the http.Handler interface. Out of curiosity, what does that buy you?
I can use [alice](https://github.com/justinas/alice) middleware chaining. I will also be able to use the same handlers with other routers, if I decide to switch to another one later on.
That is one awesome hack :)
&gt; People keep saying that, but are people compiling their templates and static assets into the binary too? If so how? We use https://github.com/jteeuwen/go-bindata Works great.
serve data, not presentation .. same backend works for mobile, html, desktop, etc
You can wrap http.Handler interface with httprouter where you need to: https://github.com/julienschmidt/httprouter/blob/master/router.go#L210
I know this. If you wrap them anywhere, you simply cannot access route params.
Anyway, I have already rewritten the httprouter with gorilla/context. The new router is only 1.5 - 3 times slower.
It's nice to know, but I wouldn't call simply opening a subprocess a "hack".
Wooh, this was my first question, should've realized it wouldn't be to difficult.
Alice is actually very simple to rewrite for any type of handler function you want to use. I wrote a small wrapper around httprouter and functions to chain handlers for my handler type func(context, http.ResponseWriter, *http.Response). You can store the route params in the context and make a function to access it. Here's an example of what I did: https://github.com/janicduplessis/resultscrawler/tree/master/lib/ws
I updated the post to reflect this and your other comment, thanks joeshaw.
Thanks, I'll look into that.
&gt; (and due to the nature of Go, this will be very hard or even impossible to fix) Really? Couldn't the next version of Go simply contain a fix, or is there some deeper issue at play here? Thanks for flagging this up though, one of the main reasons for me to make the choice for Go is its stack integration (i.e. avoidance of nginx/apache frontend server installs) but I certainly also need a functional https setup! 
I needed a basic version of this to have a user edit some text and compare the differences afterwards: https://github.com/kioopi/extedit
It's nice that this is doable, but the overhead of running an executable every time you hit your lambda stack may be too costly in comparison to just using node as it is.
I choose olvere/elastic because is the more complete of all, and really easy to use. And also because it is made by a german (they are very perfectionist) haha. Also there is this [mattbaird/elastigo](https://github.com/mattbaird/elastigo) (I think that it is the most popular client in go).
I actually made something similar a few weeks ago, check it out :) https://github.com/Rubyss/gosub
If Lambda is spinning up a node instance each time a request comes in, then spinning up a go executable too may not really add that much. If Lambda persists instances (which seems more sensible), then you could easily run a Go process and communicate to it over a socket; you wouldn't have to spin up once per process. A thin little Lambda shim for each event would probably work great. It isn't clear to me from reading whether or not you can get these events from other sources. For someone already developing in Go, merely running a Node runtime in the cloud isn't that interesting (the Go runtime is technically superior in almost every way, if not every way; I don't mean this as pandering, it really is), so the only interesting thing about Lambda would be those events. If this _is_ the only way to get those events, then running a parallel Go handler to do the "real" work is completely sensible, especially if you've already got Go code that integrates with your other resources or something.
This helped me much - http://nicolasmerouze.com/build-web-framework-golang Ultimately, using Gin would save some time and complexity since it provides every common tool I need for my projects, but I've been using Alice/httprouter/gorilla-context as a matter of exercise and in order to be certain that response times are extremely fast. Routing wrapper: package router import ( "github.com/gorilla/context" "github.com/julienschmidt/httprouter" "net/http" ) type router struct { *httprouter.Router } func New() *router { return &amp;router{httprouter.New()} } func (r *router) OPTIONS(path string, h http.Handler) { r.Handle("OPTIONS", path, wrapHandler(h)) } func (r *router) GET(path string, h http.Handler) { r.Handle("GET", path, wrapHandler(h)) } func (r *router) POST(path string, h http.Handler) { r.Handle("POST", path, wrapHandler(h)) } func (r *router) PUT(path string, h http.Handler) { r.Handle("PUT", path, wrapHandler(h)) } func (r *router) PATCH(path string, h http.Handler) { r.Handle("PATCH", path, wrapHandler(h)) } func (r *router) DELETE(path string, h http.Handler) { r.Handle("DELETE", path, wrapHandler(h)) } func (r *router) HEAD(path string, h http.Handler) { r.Handle("HEAD", path, wrapHandler(h)) } func wrapHandler(h http.Handler) httprouter.Handle { return func(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { context.Set(r, "params", ps) h.ServeHTTP(w, r) } } Keep in mind that you will want to include this in your chain somewhat early-on: func contextHandler(next http.Handler) http.Handler { fn := func(w http.ResponseWriter, r *http.Request) { next.ServeHTTP(w, r) context.Clear(r) } return http.HandlerFunc(fn) } Here is my secured api chain initialization (for now) where cApi is the context struct: mApiSec := alice.New(loggingHandler, recoveryHandler, contextHandler, corsHandler, cApi.authVerifyHandler) Edit to add - For the sake of clarity, here is some more code: rApi.GET("/api/datas", mApiPub.ThenFunc(cApi.DataGetsHandler)) rApi.POST("/api/datas", mApiSec.ThenFunc(cApi.DataPostHandler)) graceful.Run(":7357", 13*time.Second, rApi)
Well, to prevent timing attacks, your encryption/decryption should happen in a constant time, regardless of the validity of the input and errors that might occur. This is a LOT harder than it seems, certainly if there are factors in your runtime you do not control - like the garbage collector, which might kick in more or less depending on the validity of the input data - which can be abused. Last time I checked - the Go SSL implementation was theoretically vulnerable. I have to add though that I doubt there currently are any timing attacks in the wild or even as a proof-of-concept for the Go SSL libraries.
The readme is not perfectly clear, but after going over it a few times, I think I understand it. The configuration library reads a file, and produces a map of values. The configuration file may defer to specific environment variables, with an optional default as fallback.
That's what he was asking. Did they choose to do that because they are feeding other clients? 
It should be very easy (almost trivial) to change the Go to a simple HTTP server that listens on some nonstandard port (4000), with nodejs running as a proxy. 
This is a *very* fast resizer (~2.25x faster than ImageMagick). The resulting image loses a lot of data (IPTC, EXIF, ColorSync profile, etc.), but for thumbnail creation this would be blazing fast. Is is thread-safe?
Yes it is EDIT: if you check bench folder you'll see the script (multithreads)
~~I'm not sure of the details, but I'm pretty sure the persistence of the lambda instances are less than a minute, iirc like 10 seconds.~~ The max is 60 seconds.
[This](https://github.com/julienschmidt/go-http-routing-benchmark).
I note your routes don't contain any parameters, like /api/datas/:id
From my tests, the node.js hello world consumes a 100ms time slot. This fork to Golang consumes 3x100ms slot. And I think that's just fork() time. After that Go lang would quick in full speed. Anyway it seems there's no execve() equivalent on node.js, which I think could help.
[About 3x for simple cases, according to another reddit user.](https://www.reddit.com/r/golang/comments/2nd4b3/aws_lambda_functions_in_go/cmd0zo5) Perhaps a more useful metric is that it seems to add 200ms of latency. What hasn't been performance-tested, yet, is the alternate approach proposed in the comments here: spin up a long-lived Go process, and then persistently proxy it for the lifetime of the Lambda instance. When I say long-lived, I'm probably talking about [10-60 seconds](https://www.reddit.com/r/golang/comments/2nd4b3/aws_lambda_functions_in_go/cmcyqas), but it might still amortize nicely during traffic spikes. Obviously it would be much better to have native Go support in AWS Lambda, and hopefully that's coming. It's not unfeasible to proxy everything through node, but it's awkward and ugly and latent (since you're not even starting the Go process until the node process is pretty well established).
Indeed, reading jpegs and png (even worse) currently is super slow on native go (with high memory usage). If you need something that is multiprocess, cheap and fast I wasn't able to figure out anything better. I have tried mostly any libraries out there.
I just needed a package like this! Thanks!
you should try opening different images for a real test and not perform the same operation on the same image. Maybe using data that is testable by others with other tools for a better comparison.
What changes the result (there is no cache) is the image size and the output size among other options like compressions. This is just to give an idea of how it performs. Anyway, of course better bench will come pretty soon so stay tuned.
maybe try to repeat some test following something like https://stackoverflow.com/questions/11727860/imagemagick-batch-resizing-performance
I believe the upper limit a Lambda function can run is 60 seconds.
httprouter is finicky eg you can't have these two routes at same time /users/:id /users/count goji's router is better option for my needs 
I've wanted something like this for a while, but unfortunately it doesn't seem like the stdlib left room in the `*http.Request` for anything context-specific to be stuffed. That is, I'd like to have `auth` middleware that checks an HTTP header, looks to see who's logged in, and stuffs the corresponding user's `*User` into somewhere that the handler func can access it. If this were possible with the stdlib, I'd use that, but it appears not to be. For that reason, I've lately been using https://github.com/gin-gonic/gin and I like it.
I tested it across a production server and actually is much more than ~2.5, where on image magick I have a peek of 100/s on this lib I got: ``` mean: 34.377864ms, min: 20.395457ms, max: 61.757311ms, %99: 55.475588ms, stdDev: 4.781191ms, rate: 700.16, count: 14005 ``` so 7 times faster
First of all, you can handle both in a handler for /users/:id and branch if value of :id parameter is "count". Not elegant but works if you have legacy URLs. Second, you can modify routes to avoid ambiguity. While /users/count makes sense, the other one should probably be /user/:id (notice singular "user"). Finally, a separate route for count does not seem optimal. httprouter likes clean RESTful routes, invest some time into designing appropriate API. I do agree that one can build almost any route structure with goji. Personally, I am looking at denco router at this time.
Not surprised that jpegs are slow compared to assembly optimized versions like libjpegturbo, but is Go really that slow compared to something like libpng, which to my knowledge does not use assembly ?
Exactly. I know functionally why you would use angular, I wanted to know more details of that particular design decision.
Yes, libpng is the slowest library both on go and c. I tested go jpeg vs libjpeg (the one written only in c). I can came back with more details but the go version was 4x (at best) slower than the c one. More importantly a quite higher memory usage.
Cause it's been also used within Browsers (with the Kite.js library). So you need something that is easy to decode. Our goal was simplicity over performant on certain things. So this one of the reasons. But as said in the end of the blog post, other protocols will be supported to in the future. 
Please refer to the language as "Go" and not "Google Go". I have seen many of them do it. It is important to uphold its unique identity.
so glad to hear it!
This was Samsung's winning entry to the Sort Benchmark Competition 2014. It sorted 3.7T of 100-byte records in 1 minute.
yes, you have reason. Sorry, I copied the same title that appears in the repository in github.
Thanks for helping transparency on this issue. This is currently too hypothetical an issue for me to worry about - would definitely be different story if I was running payment gateway or similar though!
libjpeg/png and turbo have like decades of development and thousand of contributors they have a very deep expertise in one single thing so yeah I think is quite normal
rez if of course the fastest resizer in the go-land, IIRC uses go asm, however the problem isn't really with resizing itself but reading images.
Why use docker at all? Why not just deploy the go binary for the target platform?
Awesome - a couple of new packages for me to go try out :D Thanks!
Looks like an interesting take on it. I have often wondered how this might be implemented in Go without horrible type assertions littering your code.
You can turn off the GC in Go. It's also possible to allocate a big blob of memory that will eventually be garbage collected, but manage it yourself while the program is running. The performance in Go in general is good (and getting better for each version), the profiling tools are excellent and linking with C or assembly is possible if there should be critical paths that are hard to optimize. As an example, look at the performance of "the platinum searcher" vs "the silver searcher". Both are ack replacements, where the former is written in Go and the latter in C. Go performs very well.
Cool.
Best api example i've seen for go
I have been experimenting with libchan (https://github.com/docker/libchan) to do this very thing.
Case in point, nr 1 at /r/golang right now is [Making a RESTful JSON API in Go](http://thenewstack.io/make-a-restful-json-api-go/) Quote from that page: &gt;Clearly if we are going to create a RESTful api, we would need &gt;somewhere to store and retrieve data. However, that is beyond the &gt;scope of this article, so we will simply create a very crude (and not &gt;thread safe) mock database.
If you call a function from a goroutine, that function is running in the same concurrent manner. I've never worked on a game before, but from what I understand, there's a main game loop responsible for timing and updating the display. It might be a good idea to have that main loop listening on one or several channels for instructions to execute one at a time. You could have several goroutines each working on providing their own type of data for the main loop's channel. 
Yeah, I think the good programmers need to spend a couple of years pitching high level ideas at each other in mailing lists, then it will trickle down to weaker programmers like myself :D. I mean, just ONE example of a top to bottom application that inexperienced devs can use as a crutch, that would've gotten me started real quick! I don't want to whine to much, I've had lots of fun puzzling together the "app" in OP, but I'm feeling insecure about it!
Go concurrency is all about CSP! Communicating Sequential Processes, a programming model discussed way back: http://spinroot.com/courses/summer/Papers/hoare_1978.pdf The idea is to use a set of self contained sequential execution unit (in our case a goroutine, or a gopher doing work in a factory) to transform a piece of data, which is then passed to another unit via a communication channel (the chan construct in go, a gopher sprinting with a letter or wheelbarrow). The composition / mapping of these pieces are just one way to solve computation problems, with the idea that it works well in a concurrent computing environment (multiple cores, hyperthreading, networked systems). The challenge is splitting a problem into its basic independent components (e.g. collect a mouse click, decide what it clicked on, decide to highlight it, etc) and designing the components to be as independent as possible. The goal of the independence is additional concurrency - the holy grail is for work to never have to wait on other work. Use all resources as much as possible to solve a problem in the most efficient way. This is all very similar to how processor hardware is designed. You are basically becoming a custom processor designer by jumping into CSP. Check out this document on Go pipelining: http://blog.golang.org/pipelines To me this is the big reason to investigate Go for game development, as my guess is that this leads to the most flexible, maintainable, expandable, and performant code. Nothing is free, the cost here is up front in the design in a big way, and in those community dead ends where others have not explored yet (which for sure have been explored in C++). My impression is that you do not understand CSP yet - it's a challenge and a wildly different mode of thinking (such as from standard threaded shared object concurrency), and not a well trodden path for game development (nor many other things). If you choose Go for your game you are joining an experiment, with no guarantees of help nor success. Be sure to understand CSP before deciding it is for you. If not using CSP then my guess is that this would be a better path: &gt; I wouldn't dare to try writing a multithreaded game in C++ at my current level. C++ is excellent and well understood, you can and will be able to do anything in it. With Go you might have to become a researcher and push the edge of human knowledge, which is perhaps not the best approach for getting a product to market. If C++ is not in your comfort zone then Go may be even further from it.
Yep!
To be fair, there's plenty of great stuff on Github. It's just often intimidating at first. 
I knew about GOMAXPROCS, but I was under the impression that the runtime handled OS threads as it saw fit.
It does, with GOMAXPROCS as the upper limit. Edit: the runtime will use additional threads no matter what. GOMAXPROCS is for how many threads your code will use. 
"JavaScript and Processing are poorly-designed languages that support weak ways of thinking..." That should pique your interest enough to read [this](http://worrydream.com/LearnableProgramming/).
Steve from his grave "There is one more thing" .... This is huge.
Hell yeah! 
In JavaScript, keys are equivalent with or without the quotation marks. Quotation marks are only required if a key contains characters not legal in a variable name, but it never hurts to include them. 
Why do you need this?
Why not a transpiler for Swift?
Have you actually considered the relative difficulty of both approaches?
I went through the process of using Go for a MMORPG ( https://github.com/larspensjo/ephenation-server). Some highlights: * The game was separated into a client and server, where the server was created in Go. Client was in C++, which was easier as it used OpenGL. * I was worried about Garbage Collection, which could have a negative impact on real-time performance. But I couldn't really see any issues (when running with 1000 simulated players). But I don't have any measurements to prove it. * The concept of sharing by communicating, instead of communicating by sharing, is powerful. However, I frequently encountered cases with single writer and multiple readers. This forced me to use classical semaphores instead. * The server used a list of GoRoutines for various administrative tasks, and one for each client (player). So the total amount could exceed several thousands in the simulations, I never had that many real players active. I really enjoyed using Go. My feeling is that I am much more efficient when designing in Go compared to C++. For more info, see http://ephenationopengl.blogspot.se/2013/02/ephenation-evaluation-report.html or the source code on GitHub. 
&gt; There are a few things that are unclear to me ... Have you studied [The Go Memory Model](http://golang.org/ref/mem)? &gt; I wouldn't dare to try writing a multithreaded game in C++ at my current level. Okay. But why choose Go over C# and [Unity](http://unity3d.com/)?
OP's example (and JSON in general) *is* legal JavaScript: http://imgur.com/IByc89m JSON is another data format, but it's also a subset of JavaScript. Put another way, `JSON.parse()` and `eval()` work equivalently for JSON strings. The biggest reason to favor `JSON.parse()` is due to it's behavior with non-JSON input. In particular, `eval()` will happily execute `(function() { /* nefarious things */ })()` – since that's a legal JavaScript expression – while `JSON.parse()` will throw an exception since it's illegal JSON.
I was poking at runtime-gdb.py the other day hoping to make it work again, and got pretty far (i.e. I got as far as loading the goroutine structs, stack pointers, etc.). The real core problem is that Go does not follow UNIX conventions for program memory layout. The calling convention is different, for one, and gdb has very very strong assumptions baked in that the traced binary uses the C calling convention. The stack layout is a bit different too; I couldn't get it to locate the variables correctly. I'm sure someone that knows Go's internals better than I do could make it work, but it's an uphill battle, you'll constantly be fighting gdb's assumptions about how a program's memory should be laid out. A debugger purpose-built for Go does not have these particular issues to face.
Only tradeoff is perhaps affecting performance of other processes on the system, there is no clear and present danger to the NumCPU approach.
I'd suggest [Go Bootcamp](http://www.golangbootcamp.com/).
Mark Summerfield's "Programming in Go" is probably the best book out there on Go. Detailed, very clear, and very attentive to using idiomatic Go, which is really key to grok'ing its benefits.
Do you not worry about the flexible state created by the concurrency in the sense that the gameplay with vary for each individual player based on hardware..etc.?
To avoid confusion, all goroutines (and the main routine) share the same memory space. So, the object updated in a goroutine is updated everywhere. You don't *need* channels for the changes to be reflected outside the goroutine updating it. You just need them or something from the sync package to make sure you're avoiding race conditions. 
You can also run [Go Tour](https://code.google.com/p/go-tour/) offline. Many people prefer to start with it. Official [documents](http://golang.org/doc/), like the spec or "Effective Go" should also be easily downloadable by "Save as..." in a browser ([or a hg checkout](https://code.google.com/p/go/source/browse?repo=default#hg%2Fdoc)).
Like /u/neutronbob, I would suggest *Programming in Go*. It is a good, well-written introduction to Go, and it works well as a reference book too. Its release was intentionally delayed until after Go 1.0, so it is every bit as valid as it was in 2012 when it was released. When you've read through it just have a look at the changelogs for the 1.x releases, so you're fully up to date.
One thing that was really great for me while flying, was an OS X App called "Dash". Basically lets you download documentation for whatever language/framework you are interested in and work with offline. IMO it is a little pricey, but it works well!
Thanks man, I'll check it out. Your talk on dotGo was awesome :)
Interesting. I wonder if the difference is due to creating multiple copies of the strings vs. only creating one set of strings, or due to an "under-the-hood" difference between how arrays are created vs. how slices are created? Maybe the compiler is optimizing the allocation of strings literals in one case, but not the other? I don't know much about pointer stuff, but would it be possible to repeat the first example (array creation), but using references to the strings, instead of allocating a new string for each one? In order to separate the two aspects of the runtime/compiler, and compare it to the other two examples. Something like: var ( body = []byte("hello world!") headerbucket = []string{"12", "public,age=30", "text/plain"} ) func mediumHandler(writer http.ResponseWriter, req *http.Request) { header := writer.Header() header["Content-Length"] = []string{reference to headerbucket[0]} header["Cache-Control"] = []string{reference to headerbucket[1]} header["Content-Type"] = []string{reference to headerbucket[2]} writer.WriteHeader(200) writer.Write(body) } 
&gt; one of my first thoughts was that it would be absolutely great for making video games. I think so too. I have a small game port that I work on occasionally to back up that claim, which can be seen at https://github.com/shurcooL/Hover. It's very simple at this time, but I have no trouble having steady 60 FPS despite any GC concerns.
Thank you, that's great advice! These last days I've been annoyed with having to import my model into my controller, it feels like they're only separated by name. Must be PHP-shame pushing me to overcomplicate things... I'll try it the way you suggest, thanks again!
 BenchmarkFat 1000000 1298 ns/op 544 B/op 4 allocs/op BenchmarkSlim 1000000 1293 ns/op 544 B/op 4 allocs/op I know benchmem doesn't catch everything, but huh?
Very interesting. Can you post a gist of the code ?
If you want private key encryption, nacl/secretbox isn't a bad way to go. [This won't run in your browser, but it should help](http://play.golang.org/p/m3MKFw7_EK). The nonce is a "number used once" - it's not secret information, it just can't be reused for the same message without losing some of the guarantees of the system. You could, say, append it to the encrypted file when writing, and read the first 24 bytes to recover it when reading.
Stream. 
Ahh, much simpler. Thanks!
Just checked it out, it looks awesome. The way you use utils (go/gists/...) is interesting and might confuse new folks :). A quick win would be to send gzipped content, it would reduce the response a lot. I'll keep an eye on on gotools.org
Dave has done a ton for Go, for a very long time.
Thanks! &gt; The way you use utils (go/gists/...) is interesting and might confuse new folks :). Do you mean for those trying to understand the source code of gtdo? Yeah, I'm slowly trying to refactor those packages to have better names and structure. &gt; A quick win would be to send gzipped content, it would reduce the response a lot. I already do for some things, but not all. I can do it for more. Thanks for feedback!
Yeah the naming of the gists confused me a little :)
Understandably so, given they're effectively nameless at this time. I will try to improve it.
Why do generics require subtyping and inheritance? 
APIs should act on many things, not individual things. There is rarely just one of something. This is generally more cache friendly, makes concurrency easier, and helps steer you away from the "everything is an object" trap which definitely grinds against concurrent designs. Most game engines fall into this trap. Edit: Of course, this doesn't apply to absolutely everything and is oversimplified, but I find it useful to think about. 
When you create a new slice based on an existing array, the slice is just a reference to a particular part of this array. Nothing gets allocated, nothing gets copied. So the solution from the blog post does exactly what you propose.
As an aside, you don't have to manually break up files to encrypt them with block ciphers, because your block size is going to be pretty small relative to the data, and because the data is processed into blocks differently depending on the mode (for example, CFB encrypts the blocks serially because the output of the current block depends on the previous block as well.) and padding scheme used. Plus, the last block needs to be padded appropriately depending on the mode and padding scheme to avoid leaking information, and to allow the decrypter to properly decrypt your file later on. None of the crypto libraries I have used so far have required me to manually break plaintexts into blocks before they get encrypted.
Briefly, if you have generics with inheritance, you can say `[]T` where `T` is some class or its children. If you don't have inheritance then there's no way to restrict what `T` is, so you essentially just have dynamic type. You can already do that now with `interface{}`. The kind of generics people keep asking for is the kind with inheritance.
What about a function with type `[]T -&gt; T`? I don't see how inheritance is needed. I just want the return type to be the same as T.
More or less. For the simple case of only one element, it is the same thing. However, what if you want the new slice/array to contain more than one element, in an order that's different from the order in the preexisting array? Is there a way to create arbitrary slices or arrays without creating new copies of the strings? Bear in mind, I'm coming from Java and C#, where the VM keeps just one instance of each unique string and references it every time it's used. Every time you create an array from pre-existing strings, you're just creating a small array of pointers to memory. Basically, I'm wondering if there's a way to do the same in Go. Honestly, I'm surprised because I thought that (since both cases use literals) a compiler would optimize both of the blog's examples to pretty much the same compiled code.
What is the difference between the two ciphers?
Is the code provided by the internal library being audited? Reference to OpenSSLGate
Here's my suggestion: fork it. The open source community loves results. Show that generics are useful and powerful and don't nuke performance. Just a proof of concept like a generic add would be enough to pick up some serious steam. I'd love to see go brought into the 21st century. Just my two cents. Whether you want generics or not really depends on what you're doing with go. Anything with math? Absolutely. A middleman between an http server and a database? Could care less. Fork it and then we'll find out how hard it is. 
"couldn't care less"
If you like C#, use C#. I'm not sure the majority of Gophers want Go to be C# (or Java or C++, etc).
So, go has 100% original parts? There is nothing wrong from incorporating good parts from other programming languages. We (the go community) should deflate our egos a little. The majority of gophers like go in spite of its lack of generics, that doesn't mean it can't be improved. If we want to find out what the go community wants, we should create polls not just assume stuff.
I was about to say something like T implements X, but then I realized that is just a function argument of type X. I think you could do a lot of things with no type constraints at all though. Like collections. 
But you can, with `[]interface{}` etc. If you're not going to have type restrictions then you can already achieve that with Go's interfaces
The root of the problem is a human one. Folks expect to find their favorite features in every language they encounter. It is an indication of their conservativism: their unwillingness to learn a new language. The best example I can think of off is the abuse of the JavaScript object model by C++ and Java fans. They failed to understand and accept that JavaScript featured a different object model than C++ and Java. In an effort to bolt on the features they are unwilling to leave behind, they modify the JavaScript environment to the extant that legal and valid JavaScript which uses the native object model will fail. It is nice that you could leverage your knowledge and skills with C to quickly get up to speed with C++, and likewise transition to Java and C#. But now, it is time for you to really learn a new language. Suck it up.
Filtering arrays is the most irritating thing in go. In C# or Ruby you would do: customers.Select(x =&gt; x.City == "Philly") However, in go this needs 6 lines of code filtered := make(Customer, 0, 10) for i := range customers { if customers[i].City == "Philly" { filtered = append(filtered, customers[i]) } } You tell me which one is easier to read and write. Sure, you can do without them, but it is a major convenience. The cognitive load (or the cyclomatic complexity) of the shorter version is much lesser.
You could write some code to encapsulate that filtering logic package main import "fmt" import "strings" type Customer struct { Name string City string Age int } func main() { customers := []Customer{ Customer{Name: "Bob", City: "Philly", Age: 21}, Customer{Name: "Alice", City: "New York", Age: 25}, Customer{Name: "Jane", City: "London", Age: 30}, Customer{Name: "Beatrice", City: "Moscow", Age: 19}, } fmt.Println(filter(customers, func(c Customer) bool { return c.City == "Philly" })) fmt.Println(filter(customers, func(c Customer) bool { return c.Age &gt; 24 })) fmt.Println(filter(customers, func(c Customer) bool { return strings.HasPrefix(c.Name, "B") })) } func filter(customers []Customer, predicate func(Customer) bool) []Customer { filtered := make([]Customer, 0) for _, customer := range customers { if predicate(customer) { filtered = append(filtered, customer) } } return filtered }
I like this for the fact that it only pulls out the go code. 
God dammit. 
You can also access all Go talks (http://talks.golang.org) offline. $ go get golang.org/x/tools/cmd/present $ go get -d golang.org/x/talks $ cd $GOPATH/src/golang.org/x/talks $ present
&gt; Show that generics are useful and powerful and don't nuke performance. I believe this is precisely the reason why they're not here. :D To be specific: people who know how to do it, won't do it, because of how ugly it is, or how extensive the change would be. People who would like to do it, don't know how to do it. Or at least, that's my impression.
Rust has generics and, like Go, lacks inheritance/subtyping as well as function overloading. 
I agree. Which is why forking it is kind of a "put up or shut up" kind of deal. The only way to truly stop this discission is for someone to try it and see what happens. 
There are a lot of problems with the discussion. 1. *"People who expect X feature they've used in another language should just suck it up."* Yes, Go doesn't need every feature from every language. However, that doesn't meant there isn't potential benefit to be had by adding certain features. 2. *"Go can never have generics because I want to do X with them, which any generics proposal for Go is unlikely to satisfy."* Perhaps your use case is unlikely to be satisfied, but that doesn't mean there isn't benefit to be derived anyways. 3. *"In order for Go to have generics, it needs to work just like it does in X language, which wouldn't work in Go."* Expand your mind a bit, you silly person. 4. *"Go has no way to figure out the type of this expression!"* Then don't make that a legal expression... The first step to adding generics to Go is simply to allow people to express relationships between the dynamic types of interface values. One problem you encounter when doing this, though, is that interfaces can be nil, and finding a way to eliminate this possibility, especially in the presence of generic types, can be non-trivial since the zero value is so important in Go. Something you can add on top of that would be a monomorphization tool (`go morph`, perhaps) which would allow you to generate more efficient versions of polymorphic code without adding this overhead to the ordinary build sequence. A problem here is in ensuring that the same generic datastructure isn't being viewed from both monomorphized code and polymorphic code, since otherwise the representations would have to be the same, significantly reducing any benefit you might derive from monomorphizing.
Working on it. :)
Then all your types are gone, which is like the whole point of Generics. Sure, you can keep programming in Java with Object/raw types (that's that `interface`), but there is a reason why everyone abandoned that years ago.
What do you mean by "all your types are gone"? At least here you can use type switches to handle different types.
On the other hand, the go version allows you to re-use memory if filtered already exists, or never need a slice at all if what you want to do is on the fly. You could do that with ruby as well, of course, but this is one of the ways Go encourages efficient code. The other thing to keep in mind is that the Go code is simpler. Naively, a new reader doesn't need to know what the "=&gt;" operator is, and doesn't need to know what the select method does. Much more importantly, how many methods does Customers have? I don't know Ruby, but I'm guessing there are a lot of things it can do. In go, []Customer has no methods. If you see a "type Customers []Customer", it is clear there are special properties that occur with a collection of customers. In Ruby, I would imagine that's less discoverable. I at least find similar things less discoverable in Python than in Go. Also, just fyi, your select code can be cleaner by using "i, v := range customers", and swapping customers[i] for v. 
If you're thinking about it in terms of a single-parameter function, then generics won't seem worthwhile. The point of generics is to describe relationships between the types of separate values. For example, if you want to call a method T.LessThan(T), you need to know that the receiver and the argument have the same type, which would require generics. You also need to know that T implements the LessThan method, which is where a constraint comes in. The constraint could take the form of an interface.
This was created as my "final project" in the online CS50 course. Despite just taking and intro to computer science class, I have a lot of programming experience... from early '80s Turbo Pascal to mid 2000's Delphi. After 8 years of retirement, I decided to learn something new. After learning a lot in the course, Go and web development were selected as more new things to learn. I'm likely doing a lot wrong. Critical feedback is appreciated. 
Like you said, you could do the same in Ruby, C# using `customers.Each(x =&gt; ...)` if you don't want to do something over the array. The 'simplicity' argument is wrong too. Go has concurrency primitives which are definitely harder than grokking generics. Go is definitely not a simple language, there are lots of ways to screw up if you write non trivial code. Even with something like `for`, if you have `i, v := range customers` and you have a method `go foo(&amp;v)`, you are screwed. You won't know what you did wrong. A new reader will pull his hair out before he learns that the `for` creates a copy of the value from the customers array. Programming languages should be easy to learn, but that is definitely not a desirable end goal.
http://www.alexedwards.net/blog/serving-static-sites-with-go
There aren't any libraries that allow the use of webrtc in go currently (I've looked, maybe I missed something? ). coreOS has it on their todo list I'm pretty sure, but as far as I know, they haven't started.
http://go-search.org/search?q=webrtc
You need to http://blog.golang.org/profiling-go-programs profile your application to find out where the memory allocations are actually going, instead of guessing. fwiw I doubt the problem is how you write to the file. More likely is that your `current_topic` map gets massive. Profile it and let us know the results.
Your code is quite long. Have you tried making an [SSCCE](http://sscce.org/) by trimming away things until all further trimmings cause the problem to go away?
My argument was about your comment on re-using memory. You are not re-using memory when you make a copy of an element in an array. For all intents and purposes, the go version and the ruby version use the same amount of memory. My other point was about: &gt;The other thing to keep in mind is that the Go code is simpler. Naively, a new reader doesn't need to know what the "=&gt;" operator is, and doesn't need to know what the select method does. You are not going to stop using a database in your application and start using flat files to store stuff because a 'naive new reader' might not understand SQL. If a new reader really wants to know what the code `..Select` does, he just has to go to the definition and check it out. Allowing developers to create abstractions and powerful libraries goes a long way in increasing the productivity in a language. Finally, []Customer having zero methods and ruby having 94 methods doesn't give you anything. What do you say to a C programmer who says, I don't even have a string type, it is just an array of characters, nothing special. I don't have a `strings` package with 40 methods, I don't have any bloat. I don't even have garbage collection why would you want that, it just decreases performance. Well, I am just ranting here, but that line of argument doesn't seem sensible to me :)
Do you looking for some signaling component examples?
I shamelessly plug mine whenever someone asks for more examples of web projects in Go. I created "a single binary" blog with JSON API. No need for database, SQLite has you covered. It is called [Vertigo](https://github.com/9uuso/vertigo). About the OP's project, it looks like very solid code. It seems like my and his project a lot of same kind of traits, like stripping out all possible JS. I also find it nice that you have commented a lot of the codebase.
An interesting approach. I like the approach to making versions available at runtime, and have used ldflags to set the main app version, but never dependency versions. Have you considered trying to add a flag to godep to do this automatically for vendored packages? I am not sure if they would take it or not, but i would love to see them work together. 
Looking over the code, it all looks good. But, looking over the style of the site... well it's bad :). * On the front page the beta signup takes up most of the space and the content has very little room. In short, a web page should have only one scrollbar. (This happens if the screen width is less than 1000px.) * At fullscreen, even if there is room, the footer isn't visible. I know CSS is tricky to get right - here are some of the best tutorials I know [1](http://learnlayout.com/) [2](http://learn.shayhowe.com/html-css/) [3](http://learn.shayhowe.com/advanced-html-css/). * The colors - use some program like [Color Scheme Designer](http://colorschemedesigner.com/csd-3.5/) to create nice color schemes or pick one from [ColourLovers](http://www.colourlovers.com/). Read up on color theory e.g. [1](http://webdesign.tutsplus.com/articles/an-introduction-to-color-theory-for-web-designers--webdesign-1437) [2](http://www.smashingmagazine.com/2010/01/28/color-theory-for-designers-part-1-the-meaning-of-color/) [3](http://www.smashingmagazine.com/2010/02/02/color-theory-for-designers-part-2-understanding-concepts-and-terminology/) [4](http://www.smashingmagazine.com/2010/02/08/color-theory-for-designer-part-3-creating-your-own-color-palettes/). The main problem is the front page sign-up + boxes on top of boxes. * Design [1](http://stopdesign.com/archive/2003/06/02/design-process.html) * The menu - don't animate unless you want attention. When you hover over the menu item, all the items on the right move, which means they attract attention and distract. Ensure that the item hover doesn't move the other items. The best way to learn is to learn from the best - one great site is [CSS Zen Garden](http://www.csszengarden.com/).
Many people who know how to do type casting would rather not do it, and use generics instead. I don't think it's a matter of not wanting to *learn*. Or do you feel generic programming in Go goes beyond type casting?
If you find that the `current_topic` map is huge, you could only store the predicates you actually need and ignore the rest. allowedPredicates := map[string]struct{}{ // hash set "/whatever": struct{}{}, } if _, ok := allowedPredicates[predicate]; ok { // actually use predicate }
Glad to see this being talked about. I find the idea of "just use head of tree" to be hopelessly naive, and it dismays me that this is SOP for go projects.
I did some experiments with Go and WebRTC some time ago... You can see it on my GitHub: https://github.com/andrielfn/bronnection. The code is a mess, I know, but it is working for 1-1 peer connections.
@egonelbre Thanks for the feedback. My total lack of design sensibility shows. Special thanks for the links. I'll learn as much as I can. If this site shows enough interest to proceed with the actual website, professional help will likely be in order.
Question about this point: &gt; go run is the exception to this rule. It is intended only to be a local version of the go playground. Avoid using it for anything more trivial than a program you would otherwise run in the playground. I usually keep a `main.go` or `server.go` in the main package in my projects, and I develop by continuously running "go run main.go". Is this improper? [Here's an example of what I mean](https://github.com/tyler-sommer/squircy2/blob/master/main.go). You can see I struggle to write idiomatic go, so any pointers are greatly appreciated.
They use the same amount of memory, unless filtered already exists. The Go version is easier to modify to use less memory / identify that there is an opportunity for memory saving. This particular example is not a convincing example of the argument, but I think it's a generally true point about Go. Any time you call a function, you need to know what it does. However, the syntax of the ruby code is different. It's different from the SQL statement (syntax wise), and it doesn't even look like a function as in Go. The Go implentation (even with generics) would have to have something like func Select(x []T, func(t T) bool) []T There is an input slice, and a comparison function. Both of those parts are there in Ruby, but they aren't "passed" to select, there's some magic happening with the combination of "=&gt;" and Select. It seems to me like you can't just 'read' the implementation of select, because the parser has to deal with the entire statement at once. 
I'd be interested on writing a simple signalling server for videochat. any pointers ? reading the node.js server code but cant tell if all is needed... 
When you use `interface{}` you lose all static information about the relationships between the types of various values in your program, relationships which are necessary preconditions for performing certain operations. You can use a type assertion in order to establish that relationship dynamically, but you've lost static type safety.
Very well done :D
Not OP. Can you expand on why? What does go run do differently?
Yes, absolutely, but as I said earlier, having generics means either having inheritance or having no restrictions on `T`, since you have a flat type system, not a hierarchy. Since Go has no inheritance (and no intention to add it), you are left with no restrictions on `T` in the hypothetical generics system, in which case `interface{}` gives you the same effect (apart from `[]T` -&gt; `T` etc). My view is that either you don't add generics, or you change the language significantly. I am of the opinion that if you really want generics, use a language designed with generics in mind.
@curiousAl Here are two that I used as references. When I started the [WeTalk](https://github.com/beego/wetalk) site was active (mostly in Chinese). It was a chat site (bbs) targeting Go and Beego users in China. I see that the website is no longer running and no code updates for a while. Issues: The code has been refactored and optimized into total obscurity. I learned a bit, but a lot remains inscrutable. More recently, code for the main beego website [beego.me](https://github.com/beego/beeweb) was made available. Issues: There is no login (user auth). It takes full advantage of the framework in ways that may not be obvious without digging into the source. Unlike WeTalk the source can be deciphered given a decent grasp of Go. Having source code for the site proved to be very helpful. As an added plus, before beego.me came online, Beego documentation was scattered, with some parts poorly translated to English. It's still not perfect, but what is now consolidated in the *Documentation* tab is a huge improvement. Finally, I just discovered a [bunch of GitHub projects](https://github.com/beego) that look to be useful. The Beego author and a number of contributors seem to be intent on delivering a web framework the likes of Rails or Django... but written in Go. As others have said, learning a "full stack" web framework is like **learning** another language. I fully agree. On the other hand, I decided to go this way because the alternative would require using Go to **write** another language. One could write a simpler language, but it would be simpler mainly as a result of leaving out features. There are a lot of features in Beego that I didn't use. E.g. validation, internationalization and complex routing. Still, it's nice to know those features are there should I need them in the future. All in all I consider the time spent learning the fundamentals of Beego to be time well spent. FYI, I did research other frameworks including Revel and Martini. I chose Beego because (even when I started) a lot of high volume commercial websites were using it. Most are not familiar because they serve the Chinese market. For whatever reason, Go is super popular China. 
Insightful post, thanks. Two things: &gt; Note: There is no concept of sub packages in Go. This is why the ioutils package is called ioutils, not utils, with an import path of io/utils. This avoids local namespace collisions. My documentation says this: &gt; import "io/ioutil" Also, this sounds like a typo: &gt; A multiple packages
Why do you recommend go build over go install? Go install will handle libraries and put the binary in the right place. From anywhere on your system you can do "go install github.com/tyler-sommer/squircy2" and then if you have $GOPATH/bin in your path run with with "squircy2". I see people often recommend go build over go install and I don't understand why. 
Cool. Just as a side note can anyone please explain to me why there is so much fragmentation in the AWS libraries for Go? There seems to be loads of different forks for the same package all moving at their own pace of development https://github.com/mitchellh/goamz &gt; This is a fork of https://launchpad.net/goamz that adds some missing API calls to certain packages. https://github.com/goamz/goamz &gt; This is a fork of the version developed within Canonical with additional functionality and services from a number of contributors! https://github.com/crowdmob/goamz &gt; This is a fork of the version developed within Canonical with additional functionality and services from a number of contributors! https://wiki.ubuntu.com/goamz I know the canonical version is hosted in their own weird repo thing, but come on, can't we get some coordination here? It seems all these different forks (each one with a healthy amount of stars from github users) are all going down the same path but it's confusing. If I was a new user to Go and was looking for "the" AWS package (a.k.a. like Python Boto), I'd have no fucking clue what was the one to back. 
Blog posts are in Markdown format. 
My confusion about why "go build" seems to be the go-to recommendation remains. It seems like "go install" should be the basic operating unit. 
Thanks for catching those, I've updated the post.
&gt; Go install will handle libraries Which can easily cause trouble because it will download directly from source code repositories which can suddenly introduce backwards-incompatible changes or breaking bugs. You can do it, of course, but whenever you import a new library, it's probably a good idea to check what version you're using and back it up. This is why I also don't recommend rushing head first into "go install". &gt; From anywhere on your system you can do "go install github.com/tyler-sommer/squircy2" Don't know about other people, but I usually set $GOPATH per project rather than have one $GOPATH for the whole system. It seems strange to group programs by programming language.
Go install won't update library versions~~, just pull in missing ones~~. Additionally multiple gopaths are generally not recommended.
&gt; Additionally multiple gopaths are generally not recommended. Why? I have seen a few explanations, but they don't sit right with me. Single GOPATH approach presumes that I should put all my Go binaries and code into one directory for no other reason than because they are written in go. I usually use one directory/workspace per project.
I'm interested in this also.
Were you, by chance, running the CloudToButt extension when you posted this?
Does it need to be third party, or are std lib packages fair game too?
Sorry, I wasn't trying to explain why it's a go-to. I don't think of it as a go-to, I use go install.
I recommend them. for me, GOPATH=$HOME/gopath:$HOME/Dropbox/gopath, so that when I "go get" something it ends up in $HOME/gopath, but the stuff I work on can go on dropbox and be on all my machines.
&gt; just pull in missing ones Not even, that's 'go get' (without -u). 
Because I want people to know about it, I'll plug [s3gof3r](https://github.com/rlmcpherson/s3gof3r) which "provides fast, parallelized, pipelined streaming access to Amazon S3" both as a command line application and via the `io.Reader` and `io.Writer` interface.
It uses type parameters constrained by traits, which are similar to interfaces in Go. There are a few differences: 1. Types have to explicitly implement traits. 2. Method names are namespaced by the relevant trait, so you can get around naming conflicts by being explicit about which trait the method comes from. This also means you can create a new trait and implement it for types defined in other packages, since there's no risk of conflict. This makes up much of the ad-hocness lost relative to Go interfaces due to (1). 3. Traits can provide default implementations for their methods if desired.
Go-GST will do what you need extremely easily.
[Here](http://www.reddit.com/r/golang/comments/2nttz1/webrtc_and_golang/cmhr1oi)
Please build a CMS in Go. 
If you mean for machine to machine connections... no not yet. You will need to create bindings for libjingle peer connection and possibly libsctp as Go has no userspace sctp libs yet... it has talked about on the mailing list however... I think CoreOS started a project but then it stalled as the primitives are just available in pure Go at this time.... If enough people got togeather it could be done though... and one hell of a feature for webdevs.
That is what I've been reading, webrtc libraries would be a great asset for the language. There are some github webrtc channels for simple chat I'll checkout in the mean time. 
We do something similar but just toss it out to statsd and have dashboards built on graphite. Then we can slice and dice how we need it, look at single nodes or aggregate across nodes, etc.
That happens when the original author is sluggish with updates or accepting merge requests. Usually at some point some other package will come to dominate but that can take some time. If the other authors happen to be listening, you can accelerate that process by coordinating to pick a "real" branch to merge together on to, or if someone is feeling particularly feisty, just unilaterally start merging if the license permits.
404 not found
The first post, by our own /u/dgryski, is up! http://blog.gopheracademy.com/advent-2014/go-probably/ If you'd like to be involved and write about one of your favourite Go packages, please send us a PR.
Not really, it's just a part of the app. It's just a goroutine that gets the memstats and dumps them to statsd using github.com/technoweenie/grohl
I don't know why some websites disable fullscreen-mode for Youtube videos but it instantly drives me away from their website. And I really wish the speaker would keep his face towards the microphone instead of turning away every five seconds. Other than that it was brief, entertaining, and informative.
Looks nice. It doesn't look like you are clearing the token out of the context after the request ends?
 func Init(failRequest bool) { failRequest = failRequest once.Do(generateKeys) } You're assigning the failRequest argument to itself. Also, split imports into two groups, separated by an empty line, stdlib first. Also, the user might want to return some content after the 401 header. 
&gt; Slides can be found [here](https://speakerdeck.com/ashish/core) They cannot. The server doesn't respond.
This is related to the DNS Simple outage, it should be fixed soon.
All good calls. Committed a fix to rename the failRequest argument so it's clear it's setting a package scoped variable. Unfortunately GoSublime autoformat reorders my imports. I'll have to look in to turning that off. If you set alwaysFailRequest to false, you can check for a valid token in the request and respond with whatever content you like.
Nice talk. PS: If I were his keyboard/mouse/trackpad, I'd have a severe headache.
I have a newbish question - is there only difference in preference in using time.Time instead of duration? 
Wow I've never heard of this framework (tough to hear of all of then since there are so many) but I'm very impressed! Will look more at it later. Anyone have any experience ?
Is there a YouTube link for this?
Just hit the youtube logo at the bottom right in the video. But yes - it's annoying.
It's embedded in the linked page: https://www.youtube.com/watch?v=JkgQJrodSpI
Thanks, my reddit client didn't want to load the page.
Would really love to be able to downvote the first three replies.
In theory strong communities will self-heal themselves. In practice I would restrict posting in golang-dev to contributors only.
Enthusiasm got the better of them, is one way to look at it.
Getting an error message when starting qtcreator after I have installed goplugin. It seems internally it runs go env from my GOROOT/bin, which gives the error "unknown GOARCH 'unknown'". When I run go env as my user or root I do not get the same error. Seems like the plugin is setting the variables it self.
I would, not that they should. Or at least moderate unrelated messages. I hate going through e.g. go generate thread with each second post being about generics. I exaggerate, but you got the point.
So 1.5 is slated to have a 100% self-hosted compiler toolchain? That's really amazing, and in only 5 years. 
ben johnson for president
Rather than put a "vendorInfo.go" file in every package I vendor, it would be preferable to just serve up my "godep.json" file at an appropriate route. That seems like a bit simpler of an approach.
Yes, I am. It would be great it this data was available via API, not just via STDERR.
Checkout Kite: Library for writing distributed microservices http://blog.gopheracademy.com/birthday-bash-2014/kite-microservice-library/
NSQ is a realtime distributed messaging platform designed to operate at scale, handling billions of messages per day. http://nsq.io/
Redis is pretty dead-simple to use -- both for queuing and pub/sub. Yeah you won't have trouble finding plenty of message buses that span the full spectrum of languages (eg: tightly coupled with Java, stand-alone, etc), integrated (roll your own instead of running a dedicated daemon), performance constraints (disk bound vs CPU bound vs memory bound vs network bound), however if you're looking for something that requires minimal setup and maintenance then Redis is certainly the way to go.
Howdy, author here. A data sketch will be smaller than doing the same calculations exactly, since you have only an approximate summary of the data stream rather than an exact representations. This generally comes at the cost of having to do slightly more work that what you'd do in the exact case. For example, if you're tracking IP addresses, in the exact case you just add or increment an element in a hash. For a count-min sketch, you have to hash it 5 times and update 5 arrays. There are other approximate algorithms that are designed to reduce both space and CPU. For example, streaming quantiles. If your data stream is large enough, the space and CPU required to compute them is prohibitive, but Greenwald-Khanna streaming quantiles uses less space *and* less CPU.
Weird. I wrote a mysql parser and lexer not one month ago: https://github.com/jadekler/git-go-logictree
&gt; So I need a background worker. I guess I could have this integrated in same program as the webserver, but for simplicity What did you have in mind? I can't quite see how introducing RPC would be simple. When you introduce RPC, you now need to introduce process management for yet another program, etc. &gt; and stability reasons, I think a separate program would be better. Can you elaborate on that? I imagine that whatever instability might cause you problems here would very likely also apply to the web serving program itself and you must therefore already be prepared to handle that. &gt; So, the question is, how would you implement this? My ideas so far are: Without more, convincing details, I'd just do `go worker()`
Please don't.
Don't..what?
&gt; Installation and Usage &gt; &gt; npm install noooope I'm pretty sure there's some Go applications that already exist to do this.... that don't require that I install node and npm and grunt.
Go has such beautiful toolchain, please don't pollute it with nodejs. Yes, I'm being ignorant and biased, but please stop.
This is intended for people using grunt as part of their process, not converting go folks to node. Why the hate? It's just a POC. :)
I'd glad you liked the talk. I should buy my keyboard/mouse/trackpad a drink. (Maybe not.) It was interesting to see the mic amplify my (possibly not the most gentle) tapping though.
As mentioned before, this is intended as a POC for folks already using grunt as part of their process, not to convert non-users to using grunt. It's just a POC. :) Also, what other tools auto-restart your go programs on save? I know of none but would love to see them.
Thanks for the response. However I feel I am diving into the rabbit hole. I am sure if I have more time, I would definitely look more deeper into this. Thanks.
Don't worry about line length. Wrap your lines when they feel too long. That applies to comments too. https://code.google.com/p/go-wiki/wiki/CodeReviewComments#Line_Length
Kind of a hack, but: http://play.golang.org/p/x2PUK5uJSg
Some of the things you pointed out regarding string manipulation and other stuff are easy to overlook and can make a huge difference if done correctly. I always appreciate when someone takes the time to share their experience and gold nuggets :)
It was not intended :) Thanks for pointing out. https://github.com/antonholmquist/jason/commit/1566ce9bab17f0dec7fd47afedef7ac32b838d96
Rename the struct Jason to Value, it makes more sense that way, also code using it will look better i.e. `*jason.Jason` vs `*jason.Value`. Any particular reason for not using [simplejson](https://github.com/bitly/go-simplejson)? 
Do you need the client to be able to check on the progress of the job? Send back a status when the job is complete? Cancel a running job? Do jobs need to be reliable and/or persist in the face of a process restart?
No, the job can be totally independent. The request on the front end is just a trigger. Yes, jobs need to be reliable, and restart (I'm thinking about doing this via stateful DB like Mongo or Postgres).
There's this one specifically for web apps: https://github.com/codegangsta/gin I'm sure I've seen more general applications, though.
Yes, I will consider changing the struct name. Possibly to Object, but I am not sure. Edit: Actually Value is not that bad. It's part of the official grammar and would be more correct than Object. I used simplejson but it has some quirks that I didn't like, and they seem unwilling to change anything that would break the current API. Example: https://github.com/bitly/go-simplejson/issues/25 
Thanks a lot for your feedback. I appreciate it and will look into it all and see how it fits the standards and my use cases. The API is subject to change this month so I will break it if in benefits the lib.
Why?
* Adding MarshalJSON and UnmarshalJSON makes sense * I will probably rename the struct the Value in line with your and egonlbre's recommendations. Value is part of the official JSON grammar. * .. so that would make NewValueFromString * Regarding the type methods. I do like the simplicity of String(), but maybe AsString() would be expressive and it would remove the log gotcha. Also, I would like to return (s, ok) like the standard type assertions since it gives me a bool that I can feed directly into sql.NullString{str, ok}, but I realize there would be risk of confusion. * Haven't considered the last item on the list yet.
That's pretty neat - I hadn't seen that before. However, I think the case for a grunt module still is valid. If I'm using the grunt ecosystem for my css/js/coffeescript/sass linting, compiling, and auto-reloading, it's handy to have my go tools inline with that, as opposed to using another tool separately.
Why not use YAML?
Sounds like you want a job queue with a persistent store. Workers acquire a job (only one worker can get a particular job from the queue at once) and the job returns to the queue after a timeout if the worker fails to ACK "job done" or if the worker dies. You can - of course - build a job queue on top of any persistent store, but it's actually quite a pain to get the locking right and also have it scale well. (It *looks* easy in SQL, but I've seen it bog down badly under load on top of mysql with a couple of different attempts at getting it right.) Something like gearmand (dedicated job system) or an AMQP-like system (e.g. rabbitmq) might meet your needs. They might be overkill and more trouble than they're worth, but I think it's something like that or you're rolling your own over whatever atomic primitives your persistent store gives you. A bunch of queue systems here: http://queues.io/ Anyone know of a particularly golang-friendly system? (there are amqp bindings for golang, but amqp isn't my most favourite thing). Good luck :-)
Sorry to be The One Who Knocks this, but I'm still not convinced. So far there have been several attempts to *simplify* the use of `encoding/json`, but I've yet to see a good example of where they help, apart from maybe less typing. In *all* cases I've seen so far, the problem could be solved with delayed decoding e.g. you first decode into a `struct {Type string; Value json.RawMessage}`, inspect `Type` and then decode `Value`. Or brute-force: attempt to decode into one of multiple expected types. If the argument is that you get to type less, I don't really buy that either, because you can always write a function/type to take care of that. e.g. a quick, probably buggy hack to demonstrate path traversal http://play.golang.org/p/ejZKvrxehh with a couple methods that ignore errors and just return the value. The `unmarshal` method also just calls `json.Unmarsal` so anything I could pass to that function will just work i.e. I can unmarshal a deeply nested object into a `json.Unmarshaler`.
&gt;Whitespace indentation is used to denote structure; however tab characters are never allowed as indentation. Caring about whitespace pretty much ruins YAML's human editability. DevA opens it in vim and adds some fields, :wq, surprise! Now the indentation is all messed up because his vimrc is different. &gt;Why not X? Because not everything should be shoehorned. JSON is already widely embraced and could use a few of these nice features.
I come from a Ruby background and Sidekiq has always been my goto. I recently saw this Go library that's Sidekiq compatible (https://github.com/jrallison/go-workers). It seems to have all the pieces to not need the Ruby part at all which would reduce the dependencies down to just Redis. I haven't used it, so I can't speak to it's reliability, but it's definitely something I'm going to check out to make both sides work together.
Yes, that's great if you're baked into the grunt ecosystem. But it would be far better if you could make a tool in Go that does the same thing, that is compatible with grunt, but doesn't require it. That way it could be used both with and without grunt. I have no idea if that's possible, since I know almost nothing about grunt other than the one or two times I've followed some instructions that use it.
I wrap comments at 80 unless there's compelling reason not to (urls, etc). As the note from the go wiki mentions, humans are better at reading more narrow columns of text than super wide ones, and it helps out if you end up having to use a side by side diff tool that doesn't wrap lines (some of the online ones don't). 
Why not [Toml](https://github.com/toml-lang/toml) for configuration? It's designed for just that, is familiar and easy to parse. Using JSON (data transfer format) for configuration feels like using XML (markup language) for data transfer or configuration. Many people I know that use JSON do it because XML is so hard to work with in code because it doesn't map to common programming structures. JSON doesn't need to be fixed to be more ergonomic for configuration, it needs to be replaced in that space.
Are there any benchmarks compared to encoding/json?
I'm excited about this! Especially from a contribution standpoint of things. I am a lot more willing to delve into the internals of the tool-chain when they're written in Go, as compared to C. I would bet a lot of others feel this way too.
Feel free to checkout my dev branch where I am experimenting with quite a few of the changes you proposed. Jason struct renamed to Value, String-method removed and replaced by AsString-method that return two values. Log method no longer really needed. https://github.com/antonholmquist/jason/tree/dev
Update: I resolved the issue of getting out of raw mode in the terminal by using github.com/klass/term to adjust terminal modes.
Sure, so here's a couple memory related ones from the dashboard: http://imgur.com/a/LB09j We also have graphs that monitor memory from the OS's point of view, just for consistency. The internal view from Go, however, is more detailed and useful. In graphite the node name is part of the key name (e.g. sys.node1.memory.heap_in_use) so you can look at single nodes or sum/avg across all the nodes for a set of keys. Also, I apparently totally lied above. The memory stats collection code is part of a separate package, which is public but we're probably the only ones using it. It's [here](https://github.com/github/go-opstocat/blob/6b01d29319d3fd98c5da09365f07bbfaed0d6489/grohl.go#L117).
Have you [scrolled through the YAML spec](http://yaml.org/spec/1.2/spec.html)? YAML's table of contents is longer than [the entire JSON grammar](https://tools.ietf.org/html/rfc4627#section-2). Pass.
This is pretty cool, I was actually thinking of building something like this. I understand that some people may not like node, or may note see the point, but hear me out. This looks like it fills a niche. If you are building a JavaScript application of a certain size, you are going to need some tooling to make your life easier. For example, any JavaScript project I work on I want to run at the very least; a linter (jshint), a style checker (jscs), a test runner (karma, tape, whatever). In reality I'll also want a module loader (browserify or require.js), some way compile templates to JavaScript (handlebars), and a minifier (uglify). To manage all of these tools, a task runner like Grunt is very helpful. All of these tools are fantastic and happen to be written in JavaScript. Why do we care? One of the reasons I like Go is that it produces a single binary that can be deployed. I really like the idea of, with Go 1.4, running `go generate` to generate Go files that contain the compiled and tested JavaScript. If I'm already using Grunt to run all these other tasks, why not just let Grunt do the build step also? The generated Go files should be checked into source control, so the project is still `go get`-able.
Yessssss...!!
Sure, but you get the idea: rApi.GET("/api/datas/:id", mApiPub.ThenFunc(cApi.DataGetHandler)) Just to note, I've found httprouter great for API work, but am using httptreemux for front end needs where routes may overlap and require prioritization. I've created an httptreemux router wrapper for ease of use. package treemux import ( "github.com/gorilla/context" "github.com/dimfeld/httptreemux" "net/http" ) type treemux struct { *httptreemux.TreeMux } func New() *treemux { return &amp;treemux{httptreemux.New()} } func (tm *treemux) OPTIONS(path string, h http.Handler) { tm.Handle("OPTIONS", path, wrapHandler(h)) } func (tm *treemux) GET(path string, h http.Handler) { tm.Handle("GET", path, wrapHandler(h)) } func (tm *treemux) POST(path string, h http.Handler) { tm.Handle("POST", path, wrapHandler(h)) } func (tm *treemux) PUT(path string, h http.Handler) { tm.Handle("PUT", path, wrapHandler(h)) } func (tm *treemux) PATCH(path string, h http.Handler) { tm.Handle("PATCH", path, wrapHandler(h)) } func (tm *treemux) DELETE(path string, h http.Handler) { tm.Handle("DELETE", path, wrapHandler(h)) } func (tm *treemux) HEAD(path string, h http.Handler) { tm.Handle("HEAD", path, wrapHandler(h)) } func wrapHandler(h http.Handler) httptreemux.HandlerFunc { return func(w http.ResponseWriter, r *http.Request, ps map[string]string) { context.Set(r, "params", Params{ps}) h.ServeHTTP(w, r) } } type Params [1]map[string]string // ByName returns the value of the first Param which key matches the given name. // If no matching Param is found, an empty string is returned. func (ps Params) ByName(name string) string { for k, v := range ps[0] { if k == name { return v } } return "" } This allows me to simply change the type casting in the handlers: f := context.Get(r, "params").(treemux.Params).ByName("file") vs: f := context.Get(r, "params").(httprouter.Params).ByName("file") However, httptreemux can also be used the standard way (I might be mistaken since I'm writing this from memory): f := context.Get(r, "params").(map[string]string)["file"] If you see any improvements that can be made, please let me know.
Wow, simply wow. This post should be made sticky.
This seems to have an incredible amount of complexity that inotify and a small shell script could eliminate. I wrote and use [this small program](https://github.com/tmc/watcher) to re-run scripts to deal with rebuild/rerunning etc. (there are many similar tools)
Is there a package to automatically create stub test functions for all the funcs in the code? Something like go generate but without having to specify directives. Thanks
This feels kind of hacky, but seems to work as you want it to: http://play.golang.org/p/O7RL2lyU6x (The `json:"version"` part is only necessary if you need to alter the names/capitalisation)
Nowadays configuration is more and more often not written by humans directly, but by programs. And they can easily serialize into XML or JSON, but JSON is better at representing data structures that are common in configuration. As for Toml, I see that: &gt;Latest tagged version: v0.3.1. &gt;Be warned, this spec is still changing a lot. Until it's marked as 1.0, you should assume that it is unstable and act accordingly. Whatever deficiencies you see in JSON, they hardly outweigh this instability. &gt;Because we need a decent human-readable format that unambiguously maps to a hash table and the YAML spec is like 80 pages long and gives me rage. No, JSON doesn't count. You know why. No, I don't know why. OK, it may not be the best language for human-editable configuration. But someone else will say that Toml isn't the best either. And the YAML spec, which gives Tom rage, was also written by people trying to make an ideal language for configuration (and not only configuration).
It's not going to be any faster. It's a wrapper for `encoding/json` which allows you to check/grab key/values easily and of the proper type (if they're native types).
Why not?
I came here to post exactly egonelbre's comment. Yes, *json.Value is so much better, and idiomatic. You also need docs on that type. I got turned off the package immediately when I thought "what is a jason.Jason?", clicked it, and it didn't tell me. 
&gt;&gt; Latest tagged version: v0.3.1. Be warned, this spec is still changing a lot. Until it's marked as 1.0, you should assume that it is unstable and act accordingly. &gt; Whatever deficiencies you see in JSON, they hardly outweigh this instability. I suppose, but it seems to be good enough for [cargo](https://crates.io/), and they're making a pretty long-term bet on it. &gt; No, I don't know why. OK, it may not be the best language for human-editable configuration. But someone else will say that Toml isn't the best either The reason I like Toml is because it looks very similar (ini-style) to what many programs already use, but it provides the same feature-set as JSON in terms of mapping directly to data structures. Like Markdown, it's much more likely to be adopted if it's familiar and intuitive. YAML is far too magic and flexible that I frequently run into issues where a corner-case causes my config to have a syntax error. Toml, like JSON, has a simple, strict set of rules, so once you understand them, it's easy to avoid mistakes. &gt; And the YAML spec, which gives Tom rage, was also written by people trying to make an ideal language for configuration (and not only configuration). YAML is a case of over-engineering and feature-creep. It tries to do too much and ends up not being good at anything. For complicated configs with inclusions and whatnot, I'll just use Lua. For simple configs, I'll use Toml. I've tried to use YAML (and still do on some legacy projects), but it's just not a good fit anywhere. I understand where the JSON5 developer is coming from, but it's trying to make JSON into something it's not. I understand the desire for comments, relaxed commas and more complete `Number` handling, but since it's incompatible with existing JSON parsers, you might as well switch to a format that's designed for the problems you're trying to solve.
Why does the user care how difficult is to implement a parser?
Complex grammars are difficult to remember and therefore difficult for humans to use. I can immediately tell how a JSON document will be parsed, or what type a given section will evaluate to -- just like I can with a Go program. YAML, not so much. I think [these are valid questions](http://stackoverflow.com/questions/18385685/clarifications-on-yaml-syntax-and-ruby-parsing), and I would rather not have to ask them. I can't tell you which unquoted series of characters are treated as strings and which are other types of values without having to check. (Does YAML support octal integers, or is it just decimal and hex? Which aliases for true/false does it use again? Are these tokens case sensitive or not? Is this a YAML thing or a quirk of my parser?) I also can't tell you how various YAML features map to my language, or which will be lost by re-serializing. Will these objects turn into backreferences again? Do default values for unspecified keys work? Will this order-preserving hash be written as an ordered map or a standard map, and what will it be when I try to read it back again? JSON is refreshing by comparison.
Here is your example with a minimal custom marshaler: http://play.golang.org/p/TC0VPogB2M I am sure it will be more complicated with real data though.
Good feedback. Thank you!
Thanks. If you restrict yourself to using getter and setter functions (like [this example](https://github.com/alexedwards/stack#getting-and-setting-context)) then the vast majority of type issues should get picked up at compile time. In that example, the the compiler should still throw an error if your getter logic tries to return anything that isn't a string, even though the type assertion itself happens at runtime. func Token(ctx stack.Context) string { if token, ok := ctx["token"].(string); ok { return token } return "" } You're right though - there is the possibility that you made a mistake so that your getter and setter don't use the same type in their signatures. Which unfortantely won't be picked up until runtime. I'll reword the documentation to make this clearer. 
Are you writing mysql?
For the context have you had a look at https://blog.golang.org/context I find their implementation of Value to be quite elegant, the package specific type to identify the value is a very nice touch.
For web servers I would suggest: https://github.com/codegangsta/gin works like a charm
I'm not aware of any, but it'd be really easy to create one. The standard library has [truly great and easy to use packages](http://golang.org/pkg/go/) for parsing and representing the structure of Go programs, so don't let the thought scare you off. For this, I think you'd get an AST from `parser.ParseDir` or `parser.ParseFile`, trim out non-exported identifiers with `ast.PackageExports`, and then `ast.Walk` across and write out test stubs for any `ast.FuncDecl` you encountered. And I think that's really all there is to it.
Awesome. /u/siddontang you rock. I've been meaning to switch some projects from redis to ledis, but I've been too lazy to run the migration script. Thanks again for your work /u/siddontang. Edit: also, do you have a recommended backend for ledis? I don't really care, I just want one that isn't in memory. I don't really need full ACID transactions, as long as INCR remains atomic.
Me? No. But I'm also a different person.
So what do you plan to use it for?
Again, I'm not OP... But I have written things just for fun many times. And Go is fun to write. So why not? I've often reinvented the wheel as a learning exercise.
So, after 14 hours of work yesterday, I finally produced my first Golang library. I'm still wanting to beef up the documentation a bit, and add examples of configuration options and their use cases, but the code is all working. Any and all feedback is welcome :) It's designed to implement the HMAC signature scheme [in use by Amazon for their AWS products](http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html), with a bit of added flexibility for looking up secret keys and changing the hashing algorithm, as well as allowing configuration of which custom headers are to be included when calculating a signature.
&gt; Suppose I have a simple net/http + gorilla mux frontend that takes a request. But processing that request in real time could easily take over 10min, so its not appropriate to do it in the request handler. Why? Go processes are extremely lightweight, you could output status slowly over an open connection. There is no specific reason that a web request is invalid for this task, except that it is unusual. I would say get version 1.0 working in a slightly ugly way (running in a web process) -- then let your needs drive you. The nice thing about ultra lightweight go routines is you CAN do things like this. The next step might be creating a status URL and a separate go-routine that you can reattach to -- then maybe a queue... then a complex queue like NSQ. 
Thx /u/zxo0oxz, you can use Rocksdb, or if you only like pure go, goleveldb is another choice. 
gorilla/context uses the same technique. With go.net/context you still need to devise a way to share context between middleware and handler.
Very cool; I was just thinking that HMAC support would be nice. Are you aware of the [x/crypto](https://godoc.org/golang.org/x/crypto) libraries, in particular [hkdf](https://godoc.org/golang.org/x/crypto/hkdf)? It looks like [your code](https://github.com/auroratechnologies/vangoh/blob/abd34f70a584925cbc4edd95fb1abdc22ff64a6a/vangoh.go#L6) is using [cypto/hmac](https://godoc.org/crypto/hmac) but not hkdf. &gt; Package hkdf implements the HMAC-based Extract-and-Expand Key Derivation Function (HKDF) as defined in RFC 5869. A semi-related package that might also be of interest: [gorilla/securecookie](http://www.gorillatoolkit.org/pkg/securecookie)
I didn't know about the x/crypto package, I'll have to look into that! (I'm really new to Go) I did come across gorilla/securecookie while I was planning the auth scheme of our server, but I wasn't sold on using cookies as the main authentication scheme. Amazon has done a ton of work in the API space, and has arguably one of the most used APIs to exist currently, so I wanted to try to replicate their methodology as closely as possible.
While this is a cool company, I'd rather not see this turn into a job posting sub-reddit. There's /r/jobbit - a job posting subreddit with a focus on programming for that.
^
Unfortunately the new page does not work at all for me :( It's mostly blank with some JavaScript errors. https://i.imgur.com/7Hyu9oS.png And I was half way through the tour... =/
Realistically, the only thing you can do is try to not keep a reference to the `[]byte` or `string` that was holding the private key. There's no guarantees that Go won't leave a copy lying around RAM, nor can it guarantee that your OS didn't swap that RAM to disk and thus leave a copy written somewhere there. There might be some whacky OS-specific system calls that could inhibit the latter, but it almost definitely won't be worth it.
Please report this issue with all details here: https://code.google.com/p/go-tour/issues/entry
Submitted an issue. Thanks for a link to the issues page :)
Okay, but I guess, in that case, it's still better to at least zero any byte slices and set any bigInts to zero when they are not used anymore. It sounds like this would decrease the risk of them remaining in memory, even though it is not guaranteed.
Here are the results, http://dave.cheney.net/2014/12/05/minimum-one-liner-followup
I was like, `min = 314`. Too bad, Gustavo Niemeyer has already suggested this.
[At first I felt really smart](http://play.golang.org/p/GAvqg6dBNV), but then I pressed "Format" :(
Instead of writing a wall-o-text (but someone else probably will), I'll just redirect you here -&gt; https://www.youtube.com/watch?v=f6kdp27TYZs Watch it and everything will be much clearer. Don't worry if title is misleading, the talk is very thorough and starts from the beginning.
Second solution from Gary will fail if the numbers are same!
That's what I do (and for the same reasons). Can't think of anything better. That and "go build -gcflags=-m" to inspect the Escape Analysis and get a clue what escapes to heap and why.
Zeroing the []byte buffer, and if you're using structs setting them to nil if possible can't hurt. Most of the code I've seen when dealing with keys tend to use arrays when possible, and pass pointers to them. Also I believe avoiding strings is a good idea if at all possible. Also if you're encoding your raw keys to base64 then it's very likely you'll have a copy of the keys lying around in ram or swap. This is not only hard to do properly in languages like Go, but it's also hard to do it correctly in C. 
The best choice depends on the size of your data values. http://www.reddit.com/r/Database/comments/2o5xcq/strengths_weaknesses_of_embedded_keyvalue_stores/
Depends on your scaling requirements, honestly. If you just want it to work and fast &gt; go worker(). If you have the time to invest in it/anticipate needing the scaling - go for the disk-backed queue solution, seeing as you need the jobs to be persistent, asynchronous and concurrent, which is pretty much the ideal use case for a queue broker.
Small wall of text. Goroutines are not necessarily equivalent to an operating system thread. Instead, they are a thread within the go "runtime"... basically an application that runs the compiled code. So, these goroutines _might_ turn into an os thread, but usually not. This is why they're more lightweight for the os than a normal thread. Concurrency is a large topic with tons of nuance. It does not necessarily mean parallel (As Rob's famous talk covers). On general, Go hides many of these details from you. That's one of its most powerful features, actually you don't have to know the exact specific of the interaction with the operating system because the go virtual machine will sort those details out. Obviously this is a general case, and sometimes you will want to know, but you have time to learn all that some other day.
Others addressed the first part of you post so I'll jump to the end. Concurrency is the idea of handling tasks independently without regard for what happened previously or what will happen next. Concurrent design enables tasks to be run in parallel on systems that support parallel execution (multi core processors etc). Multi threading is just one way of implementing parallelism in a concurrent design. Go's innovation is that it makes concurrent design easier and the compiler (and the runtime it creates) handles the dirty details of parallelism by deciding how many threads to spawn and doing all the extra book keeping required to create and close threads. As for the code snippet at the end. By saying 'go' you are signaling that order no longer matters, you are basically saying "hey compiler, make sure this happens, but don't wait around doing nothing if it's slow". The say function is invoked and begins waiting 100 ms, meanwhile the main() function confines to execute and begins the say "hello" function. Now you have two things running but you haven't controlled their concurrent execution with any primitives like channels so basically they will behave unpredictably. Finish the tutorial to learn about channels and how to control concurrent execution.
What has been updated?
Go routines say that things are able to happen independently from one another (concurrent). If they are running on multiple processors, then they're parallel. If they run on one processor, then it's concurrent but not parallel.
Just because you design using concurrent patterns doesn't mean that you can't just run those routines sequentially. To make parallel execution work you must 1) have concurrent design, and 2) manage parallel execution. You cannot do step 2 without step 1, and step 1 does not automatically lead to step 2. Now reread that sentence, &gt;Multi threading is just one way of implementing parallelism in a concurrent design. Hopefully it makes more sense now Google about the difference between concurrency and parallelism for high quality explanation on this topic
haha, good point. "One line" according to gofmt is different than one line of legal Go code :)
http://golang.org/pkg/runtime/#GOMAXPROCS
6. Goto 3.
&gt; some whacky OS-specific system calls that could inhibit \[swapping\] [`mlock` or `mlockall`](http://linux.die.net/man/2/mlock). &gt; but it almost definitely won't be worth it Here's a [page about that](https://www.securecoding.cert.org/confluence/display/seccode/MEM06-C.+Ensure+that+sensitive+data+is+not+written+out+to+disk). For that matter, here's [actual attacks](https://www.schneier.com/blog/archives/2008/02/cold_boot_attac.html) resulting from keys just *lingering in RAM* across boots.
&gt; Which means that it will be executed eventually. Maybe - https://golang.org/ref/mem#tmp_5 &gt; the assignment to a is not followed by any synchronization event, so it is not guaranteed to be observed by any other goroutine. In fact, an aggressive compiler might delete the entire go statement.
That url in the title is an eye sore.
I came up with this: `min = map[bool]int{true: a, false: b}[a &lt; b]`
That's why the quiz rules state "correctly formatted". 
I'm having trouble understanding the mod one. It clearly doesn't work for a == b, and it doesn't work for a close to b (try with 314 and 318 for example), but it seems to work with the two very different. Why does it work?
Oh, I get it. Cool!
"Click the "next" button or type PageDown to continue." I don't see a next button. Do they mean the "&gt;" clickable arrow at the bottom? Also "type PageDown" should probably say "click the "PageDown key of your keyboard". Cheers.
It'd be awesome if they extended that to include [SFTP](http://en.wikipedia.org/wiki/SSH_File_Transfer_Protocol).
I don't understand why the go team chose to implement a suboptimal algorithm to build suffix arrays. The best and practical linear time algorithm to sort suffixes has existed for a long time. For long strings (with long substring repeats), it makes a big difference. I've used it and I've experienced its inefficiency.
You can use the runtime package to set GOMAXPROCS and the go routines will expand to multiple cores. But, sometimes fewer cores will actually be faster than multiple cores of the go routines are short lived. (Someone more knowledgeable than me can explain why more cores might be slower for certain kinds of concurrency.)
Submit an improved implementation then?
Basically the http.Dir handler...
Damn, I'm always too late to these things. Mine was going to be min = b + (((a - b) &gt;&gt; 31) &amp; 0x1) * (a - b) http://play.golang.org/p/PgeRfX2dCt Ah well, next time :-)
http://zhen.org/blog/surgemq-mqtt-message-queue-750k-mps/ Link in the OP doesn't work for me, www.zhen.org doesn't resolve but removing the www subdomain appered to go to the correct blog post.
Question was whether a tool that does static analysis of Contexts exist and is free to use or is this thing internal to Google (or just a concept). It's hard for me to comment on use-cases or functionality since I've not seen such tool and I've no idea what it's capable of. /u/seriousguy420 out of curiosity, which exact part of original question was misleading to you?
There is also github.com/hgfischer/http-here with CORS support.
I would have said "gofmt formatted". Correctly formatted IMO is slightly vague. But maybe I'm the only one who thought so.
If anybody is interested, the current state-of-the-art appears to be the (MIT licensed) implementation at https://sites.google.com/site/yuta256/sais . It's ~500-lines of pretty dense code, but shouldn't be "too hard" with some sort of mechanical translation aid.
That is a whole other discussion though.
Understand how escape analysis works and try to model your dataflow in a way that the escape analysis can detect that your object won't leak out of the function.
Profile! Profile profile profile. Profile? Profile profile! Seriously, it answers two questions. First, does it even matter? If GC isn't a large line item in the profile, then stop worrying. Second, if it is a problem, it'll point you right at it.
What is the use case for this product?
Wrappers, wrappers everywhere. // struct to pass along handlers type MyContext struct{ io.ReadCloser UID string } // in first handler in chain r.Body = &amp;MyContext{ ReadCloser: r.Body, UID: rand.Int(), } // in handlers further along the chain ctx := r.Body.(*MyContext) Thus no need to use anything else than the http.Handler Actual implementation example: [https://play.golang.org/p/WLU1oYLd6p](https://play.golang.org/p/WLU1oYLd6p) (oops, went a bit far :P)
https://mobile.twitter.com/Sajma/status/494161985219465217 is an answer to your question.
Agreed it's a different discussion. However while there is no guarantee that this will have the expected effect. If done correctly it's still better than nothing. 
SSH != TLS
/u/dyoo: &gt; https://mobile.twitter.com/Sajma/status/494161985219465217 is an answer to your question. Thank you sir! TL;DR &gt; Q: Any chance those static analysis tools are going to be open sourced? &gt; &gt; A: That's the plan, once they're ready. Alan Donovan (author of ssa and oracle) is on it.
gorilla/context is not quite the same, it does not create a new context to avoid using locks if multiple go-routines want to add a value to the context. Also I don't think it has support for the ability to stop processing via the context. The golang blog version is nice because you can construct a tree of values without having to explicitly synchronize them. I Agree that you need a way to still share the context. Personally I created an interface that defines a handler that takes a context as the first parameter to the handler, and then middleware can update / generate a new context and pass it along.
Is there a video for this anywhere?
This sideshow format is not suitable for mobile. 
I personally use it for scripting related tasks. Since Go's compilation is so fast using the "go run" command is often speedier than the amount of time it takes to spin up a python or ruby VM; and of course executing a compiled binary is faster than running a dynamically interpreted language. The only downside is that you have to write more Go code than you would in another language. For example interacting with the shell and calling commands requires using the "os/exec" api in Go. You obviously don't have this kind of restriction in a bash script. With regards for interviews. Its a great language to use in a company, but if people aren't used to using the language there is a bit of a steep learning curve. Somebody can learn how to use the language in a short amount of time, but it takes awhile for people to really develop enough idiomatic "taste" and familiarity with the language features to fully exploit the orthogonality of the language. Considering the language is still so new, you might find it difficult to fully judge and discover somebody's raw programming abilities with Go if its not their everyday "go to" language. Learn the full standard library. Every package has its specific purpose. 
thanks, it was typo
If you aren't closing these connections, you could be running into max open file descriptors as enforced by your OS.
This is a useful article: [Recycling memory buffers in Go](http://blog.cloudflare.com/recycling-memory-buffers-in-go/)
don't keep seeding random number generators https://gist.github.com/anonymous/e7ac7c34e7dd4d32a1af
Now there's a tidy little package.
Can you also provide the sites.json file you are using? Could it be that it has some sites that don't exist or are slow?
Learning about readability on a horizontal-scrolling website... 
It's from GoCon. I'm not sure if the talks were recorded, and the original presentation may have actually been in Japanese. 
These are slides from [the present program](https://talks.golang.org/2012/insidepresent.slide#1).
I have that [file](https://gist.github.com/anonymous/3054c05db83e6fd83cf1) in the original post, but you are right. The sites that it was failing at were `googleusercontent.com` and `akamaihd.net`, both of which do not resolve (at least with `dig`). Thanks!
Thanks Dave. Using values instead of pointers would have an impact on performance due to memory copy, correct?
One deficiency I see from a cursory glance is it does not support cases like [Section1] variable1=value [Section2] variable1=value2 which seems to be used fairly often in a lot of INI files. Edit: oops, looks like it does. Sorry!
Yes, the presentation was in Japanese.
This is the go present tool. I'm sure the team would be open to a contribution to make the css a bit more mobile friendly. I would certainly be grateful. 
I'd ask the homebrew folks. You're probably right that, if it works from the command line, it should work in Brew.
That would be a fairly glaring deficiency...
`index/suffixarray` supports serialization. It wouldn't be too hard to write a package that takes the data from gasaca and creates the binary data needed by the suffixarray unmarshaler. Alternatively, you can just take at(), lookupAll(), Bytes(), Lookup() from suffixarray.go and drop them into a file with a constructor that calls gasaca instead of qsufsort(). 
Looks like it lives [here](https://code.google.com/p/go/source/browse/?repo=tools#hg%2Fpresent), I hope this one gets migrated to Github as well.
You may want to have a look at [this](https://github.com/drbig/simpleini). Or not. Edit: if for nothing else, it actually does support sections.
It's an interesting approach. I've not seen this before.
one great place to start is to write more documentation, including sample code. check out http://godoc.org/github.com/opennota/lexer to see how you're doing. right now there's not much there, but godoc.org makes it really simple to see your improvements
Slides #12-13 &gt; time.Duation Not passed.
Learning go and I just can't make myself use a spaghetti templating solution for HTML. Was looking for a HAML port, but honestly this looks even better. Thank you for this, I intend to try it out.
Again, using Mlock doesn't guarantee that Go hasn't copies of the key all around the RAM or that it can't copy the mlocked memory.
It does support sections: v, ok = ini.SectionGet("sss", "aa") https://github.com/zieckey/goini/blob/master/examples/inifileparsing/main.go
Yes, it will be migrated to github.
Is there a sync/pool example for byte slices?
I presented at GoCon... they told me weren't recording the presentations, so as far as I know there are none. Maybe someone recorded them with their phone! 
https://github.com/golang/go
This package _does_ support sections: // Get looks up a value for a key in a section // and returns that value, along with a boolean result similar to a map lookup. func (ini *INI) SectionGet(section, key string) (value string, ok bool) (Unfortunately, the comment uses the wrong name for the function, which is confusing.) There's also `SectionGetInt()`, `SectionGetFloat()`, and `SectionGetBool()`, as well as this convenient little thing: func (ini *INI) GetKvmap(section string) (kvmap Kvmap, ok bool) Edit: Created pull request to fix these issues.
Thanks.
Specialising based on the dynamic type of one or more function arguments... Sounds like a poor mans multimethods. But a nice non-breaking optimisation all the same.
I don't think there's a need for convenience functions/methods in libraries (like ParseFile in this case) especially in Go where you really should make use of interfaces. Besides that I'll probably check it out to write a simple CLI tool to edit INI files because we actually need that ;)
...yeah?
Go is migrating to Github as the official source repository. 
Ah, great news! I thought they already use GitHub. Haha. :D
it's up again
Not that I'm aware of, but using byte slices in the pool shouldn't be any different from using other objects.
Actually https://github.com/golang/go is a mirror, the canonical repo is https://go.googlesource.com/go
Guess I didn't look hard enough!
Not being a native english speaker I find naming harder in Go than in Java, it's difficult finding a concise name which still gives the same information as the long-ass descriptive names I use when coding in Java. I don't really agree with the part about testing, I'd rather have a assert function to check expected value with return values. 
Mirin' all the *_test.go -files. I should write longer tests.
As egonelbre said, no, not true. As well, they don't accept pull requests on Github. You still need to to sign the Google contributor license agreement, and must still use [gerrit](https://go-review.googlesource.com/) for code review process.
Flotilla required something similar: [store.go](https://github.com/thrisp/flotilla/blob/develop/store.go)
What's the point if it's not the canonical repo?
Why does it need an official mirror on GitHub?
Why not? ;)
Are you seriously claiming that this is done for backup purposes?
Just because they don't accept pull requests and will use gerrit for code-review they can still use github for git hosting and issue management. 
Thanks for your suggestions. I am pretty new to Go. I just tried to understand `interface` but I don't get what you mean by `a function called New which returns a interface` and how that `interface` will look alike. Anyway, I've added a few test to check if the generated names are identical or not. The tests are starting to fail when I generate around 300 names. But it's pretty random though. Do you think, letting user to specify a seed would be more helpful ? 
We found also this kind of solution, which we think to be rather "elegant" :) min = []int{a,b}[((a-b) | int((^uint(0) &gt;&gt; 1))) / int((^uint(0) &gt;&gt; 1))] https://play.golang.org/p/KTZe6afBlY
Problem is that Github is too easy to use and we can expect having troll Pull Request from all those Java jealous kids. 
For now.
It was a nice exercise in using Go, but you should not use it. Your 17-line example of using the library in the readme appears to translate to: for var i := len(slice) - 1; i &gt;= 0; i-- { if slice[i] % 2 == 0 &amp;&amp; slice[i] % 4 == 0 { return val } } And really you ought to just do that. Also I'm not sure how you're using the term "lazy", but it's not in a way I recognize; everything here seems to be strict. If you mean that the filters stop when asked to match an item the first time they see an item, that would be "short circuiting", and people generally expect a "find in array" function to stop once it finds what it is looking for, so even calling it "short circuiting" might be a bit much. But let me both begin and end with saying it was a nice exercise in learning Go. It takes courage to ask the question you asked. I regret that this is the review you end up with, but I encourage you to look at this as a good learning exercise.
&gt; For the simple case of only one element, it is the same thing. It is the same for any slice length. A slice just represents one particular part of an array, no matter how long. No copying required. This is why the solution in the blog post is so much faster. &gt; what if you want the new slice/array to contain more than one element, in an order that's different from the order in the preexisting array? Depending on what you need this for, an array of slices would be one way of doing it. BTW, when changing the headerbucket into a slice of string slices, the [resulting code](http://play.golang.org/p/COmSshz33y) looks quite similar to what you suggested above. (Sorry for the late reply, I am still not used to checking my reddit inbox regularly... Would be great if the inbox had its own RSS feed URL.)
Agreed. Go is very much about implementing things the obvious way: if you want to loop over a slice backwards and return the first value matching some condition, then write some code that does exactly that. It's neither necessary nor desirable to wrap that in layers and abstractions.
Have a look quick - https://play.golang.org/p/RS-_-TeBo5 Go has a concept of interfaces - http://golangtutorials.blogspot.com.au/2011/06/interfaces-in-go.html &gt; The tests are starting to fail when I generate around 300 names. But it's pretty random though. Thats because 2 things the number of names and random number generators will return duplicates. &gt; Do you think, letting user to specify a seed would be more helpful ? Its more testable. It also allows you to have two different random name generators with different seeds. Check out this guide for writing testable code (Its written from a c++/java point of view) - http://misko.hevery.com/attachments/Guide-Writing%20Testable%20Code.pdf 
&gt; Would be great if the inbox had its own RSS feed URL. Stupid me. It's in the preferences &gt; RSS Feeds.
Saying that is misleading. The only real difference is that you don't do pull requests on github. In git all different repositories are equal. Saying this is a mirror implies that any one repository is better than another. Github is being used for the wiki, and for issue tracker. The only difference is if you want to contribute something back to the main project, you have to go through Gerrit instead of using github's pull request features, which doesn't have the right feature set for the purposes of the Go project. Even if you're contributing to the project, I think you'll still want to fork this repository on github and push your changes to that.
we are using the GitHub issue tracker. 
It's equivalent to var handler http.Handler = Logger(route.HandlerFunc, route.Name) `handler`'s old value is used in the second assignment. If it weren't, the first assignment would've been useless, and you'd be right to be confused. 
Thanks - that helped a lot!
Thank you very much. Lazy loaded filter in a sense that .Filter(f) doesn't return filtered results, it builds up filter chain and runs through them when results are explicitly retrieved. I liked how [sort.Search](https://godoc.org/sort#Search) works and tried to see if its method could be used for general purpose array/slice filtering and mapping. Good learning exercise :) 
I stated using go a while ago personally and just recently started using it in a large scale enterprise application at work. One thing I've noticed is that people who tend to come from more dynamic languages end up fighting with go more when they first start using it. This includes myself. The go way is to use more interfaces that define polymorphic functions than to try to make the code dynamic using type switches and reflection. This feels dirty to people coming from dynamic languages, where DRY principles are touted very highly. It gives the code a bad feel when you aren't used to it. In practice, however, the boilerplate code for these interfaces turns out to be not as much of a hindrance as one might think. Once you code it using those principles, and work with the language instead of fighting against it, it really makes for a nicely formatted, easy to understand codebase. I was skeptical at first, but it made me realize that DRY doesn't necessarily mean to not duplicate any single line of code ever, just that common patterns that can be readily abstracted away should. Now when I look back at some of my untenable highly dynamic python code I wrote, I giggle to myselg and think of the original south park towelie episode. "Do you know what it's like to be way way too dry? I don't know and you don't want to know." LOL Please forgive typos and such, typing on phone on the bus ride home. Hope you're enjoying go! NOTE: A small tip I've noticed - go is such a simple language that if it feels like you're fighting it, you probably are not doing things idiomatically. It's my favorite feature of go, actually. 
&gt; The go way is to use more interfaces that define polymorphic functions Or to define separate functions, accepting non-interface types. [Regexp](http://golang.org/pkg/regexp/) package has plenty of these.
The cleanest way is to make This and That share a dummy ThisOrThater interface. If you can't do that (because you don't control the source for those structs) then embed each one in a new struct that you do control.
I wrote a [discussion on this a while ago](http://www.jerf.org/iri/post/2917). While I agree that this is not something you use all the time, there are use cases for this.
There's also https://github.com/1l0/identicon
[JSONGen](https://github.com/bemasher/JSONGen) does (atleast the json part) what you are looking for. However its Affero GPL licensed.
Just make two functions, one that takes this, and I've that takes that. If they really share no methods (or at least, nothing significant), the code handling them is probably significantly different anyway. It would probably help a lot of you have us more information on what exactly you're trying to do. There is likely an easier, better way.
I would definitely use it for interviews. It's simplicity means you're far less likely to make dumb mistakes, and most anyone can read it even if they don't know it.
Variadics are really awesome to have in Go (coming from C). This is also useful in os/exec and database/sql.
What are the missing features?
wow, thanks!
See this discussion on Hacker News back when the move was announced: https://news.ycombinator.com/item?id=8605293
welcome to the present!
You know, this is one of the bigger head scratchers I have when I am working on surgemq. I still haven't figured out the best way to pass in the config options yet. So thanks for sharing this post. I've read this one, Dave Cheney's functional API post, and now Rob Pike's post. Hopefully I'll figure something out.
Is there a reason why the GH repo haven't been designated as the official repo then? It seems like it would be a bit inconvenient to have issues in one place, the official repo in another, and code review in a third place.
Code review is not in a third place. The official repo and the code review system are in the same place. That's why it's the official repo. So there are two places: go.googlesource.com for the canonical repo and code review, and github.com/golang for issue tracking and wiki. And we must mirror the repo on GitHub for the issue tracker integration to work. 
If there were a better way, I guess Go itself would be using it for the JSON module. It was cases like that that inspired the question: where you have to package or encode or decode something that isn't known to the function ahead of time, but which is possible to handle anyway provided if it is of a set of types. In standard go JSON accepts `interface{}`, meaning static analysis won't catch you shipping an unencodeable value to JSON. I don't have a precise use case myself and haven't hit a roadblock yet, but there have been plenty of occasions when overloading a function would yield the cleanest code, but where using `interface{}` would have cost me static checks and undermined the self-documentation of the function signature.
The Go codebase seems to use `interface{}` a lot, which indicates that overloading is OK by them. It's just that, to me, making args "dynamic" in this way undermines the value of static analysis. So yes, I come from Python, but I'm one of the pythonistas happy to see optional typechecks in functions. I'm also dabbling in Rust, and it was more Rust's enums that I was thinking of with this post: ways to get the dynamic-ish benefits of overloading while retaining strong safety/type safety. Rust is great at that, Go not so much unless you can define an interface the potential arguments share.
Only that it can be anything at all, by using `interface{}`; this seems to me like a purist omission that actually encourages a worse style of coding, because I see empty interfaces all over the place in function sigs, including in the built-in libs. Coming from dabbling in Rust I'd prefer more precision.
Yea, I was afraid it would be this way. It's unfortunate that you can say "take anything" with the empty interface, but not "take either this or this", which is cleaner, more precise, and type-safer.
That's cool! Thanks for the link. I've specifically set out to clone some popular icons *without* looking for any hints, especially code - just to see what my own approach would yield 'artistically'. Now I can compare the guts :)
I have used the second solution in some code. I try not to use the first solution because I consider it some kind of workaround but it's usable. You retain type safety this way (re. solution 2). You will need an indirection (pointers) each timeyou want to deal with multiple types simultaneously. It's the after effect of wanting genericity with type safety. (it's not necessarily just a Go thing, it's just something that Go exposes so you have the choice). In C++, that would be a *void pointer.
That seems to do kind of the opposite of what I want my tool to do actually. That makes go objects grin a JSON doc, mine just populates struct tags of an existing go file. But it's interesting nonetheless.
+1 internets if you make it `go generate`-able.
Instead of writing func myFunc(t ThisOrThat) { ... } You could write func myFuncThis(t this) { ... } func myFuncThat(t that) { ... } 
I'm not looking for client code to process a POST, rather, the code that would exist in the Handler on the server to receive the POST request. 
&gt; It's the after effect of wanting genericity with type safety. (it's not necessarily just a Go thing, it's just something that Go exposes so you have the choice). In C++, that would be a *void pointer. C++ would let you write [`boost::variant&lt;this, that&gt;`](http://www.boost.org/doc/libs/1_55_0/doc/html/variant/tutorial.html). Similarly, Java would let you write [`fj.data.Either&lt;this, that&gt;`](http://functionaljava.googlecode.com/svn/artifacts/3.0/javadoc/fj/data/Either.html). This can be implemented in [C#](http://siliconcoding.wordpress.com/2012/10/26/either_in_csharp/). It's baked into [Rust](http://rustbyexample.com/enum.html) and [Swift](https://developer.apple.com/library/mac/documentation/Swift/Conceptual/Swift_Programming_Language/Enumerations.html)'s enumeration types. It's one of the [Scala](http://www.scala-lang.org/api/2.9.3/scala/Either.html) core types. The Go solution can be implemented in any of the above languages. The other constructs cannot, however, be implemented in Go.
Yeah, that's what I thought too, but was wondering if there was something that was more idiomatic to go...
Certainly: functions per-type, with `switch` dispatch, is an option. There are plenty if options. But I would love if there were a cleaner option that didn't clutter my "higher" code with the limitations of my "lower" code.
The request has a **Body** field. package main import ( "fmt" "net/http" "io/ioutil") func handler(w http.ResponseWriter, req *http.Request) { buf, _ := ioutil.ReadAll(req.Body) fmt.Println(buf) }
I am talking about the language intrinsics. Boost is a library that uses template metaprogramming, i.e. a kind of language on top of regular C++. Basically just a convoluted way to tell your compiler to write things for you. I do not consider this here. Other than that, Java uses type erasure which is clearly not ideal when you need to manipulate things at runtime. The C# generics involve some kind of indirection with virtual calls etc. Haskell does use indirections too, to my knowledge. (well Haskell does many types of generic programming) Can't speak for the other languages but if they have a generic datatype, I would bet there is indirection involved. It's maybe masked from you but you can't have a safe generic datatype without it. Types do not all have the same size. So you have to point to a memory location of a certain size. Just logic. (and that's even more important wrt multithreading) Go is no different in that regard : you can do all of the above with some work.. Having to do some work for these rare occasions you need enums forces you to keep your code simple and to the point. That's pretty strong.
More idiomatic? req.Body is an io.ReadCloser, so you can use it anywhere an io.Reader is expected. Very simple and idiomatic. In fact, I would probably not use ioutil.ReadAll, if it makes sense not to. There's usually a better way. (Using the body as a reader instead of reading the whole thing into a buffer immediately.) For example, to save the request body to a file: file, err := os.Create("somefile.bin") // check err _, err = io.Copy(file, req.Body) // check err 
IMHO encoding/decoding is a very poor example of where this would be useful. The whole point of using `interface{}` here is that you can pass it *anything*. You could argue that the set of inputs that an encoder can take is finite, but beyond the basic types like `int`, `string`, etc. there's no guarantee that marshalling won't fail... even if you pass in a perfectly valid type. The same applies to decoding, perhaps even more because in most cases you'll be dealing with user input. In both cases you *must* check that the function succeeds, so it's not like you get to type less code or are actually making anything safer.
That's my thoughts as well. Actually, I think most people don't want generic programming. What they want is a way to have code written for them. Because otherwise, we have interfaces in Go which are some kind of constrained *void with more type information. Here comes your generic datatype. :)
Yes, this is the "generics would be useful in this circumstance" / "Go doesn't need generics" argument. I just wanted to point out that many other languages have a way to express OP's intent – directly or indirectly – while Go does not. I don't see this as Go giving me choices, except in the sense that Go doesn't let me do what I want and thus forces me to choose something else. I'm pleased `go generate` is a thing, and I don't have anything constructive to add to the generics argument, so I accept the status quo. At the same time, however, I can't help but see this as a limitation, since Go *can't* do something that other languages can. --- To your specific reply: &gt; I am talking about the language intrinsics. Boost is a library that uses template metaprogramming, i.e. a language on top of C++. Yes, but the C++ language allows people to write things like `boost::variant&lt;&gt;`. Go does not. That is my point. &gt; Basically just a convoluted way to tell your compiler to write things for you. I do not consider this when I'm talking about generic programming. I think it's worth considering. Code generation is a viable alternative to having the user write specialized instances of generic code. If the Go compiler supported it, people wouldn't be [inventing things like this](http://bouk.co/blog/idiomatic-generics-in-go/). Go 1.4 brings `go generate`, so clearly code generation is seen as a solution to some problems. Why not here? &gt; you can't have a type safe generic datatype without [indirection] … Types do not all have the same size. So you have to point to a memory location of a certain size. Just logic. Alternately, one could use a data structure sized to hold the largest element it can contain (a `union` in C terms), prefixed by a tag indicating which type it contains. Bam: type safety without indirection. (This doesn't really apply to the topic since Go interface values are [`{ itable, data }` tuples](https://github.com/golang/go/blob/439b32936367c3efd0dadab48dd51202e1a510f1/src/runtime/runtime2.go#L80-L83) anyway, so everything's already indirect. I just wanted to show how it's possible to do this without pointers.)
Re. OP's question: as much as it is true that other languages provide some facilities : * they hide some costs * these are things that are not needed too often, or can be done in Go with not too much additional work. The philosophy of Go is to have the features that matter it seems. It makes people more efficient paradoxically (or not so paradoxically). Some people will insist on fighting the language but it seems they are first time users most often. --- Re. your reply to my previous reply. :) I think we agree here and the people at the helm of Go do too. Raison d'etre for go generate. The aim is probably to have something simpler than template metaprogramming which does not impact compilation speed. (so the code generation process would not be included within compilation). It is even more generic of a tool. And it will keep the language semantics simple. Compilation speed is important for the future goals of Go in my understanding. And re. your last point, that's an idea that I had too, it would require either to generate the type (with go generate) before compilation or once the reflection package is finished, perhaps the type could be created at runtime. Currently `embedding structs` is the way to have unions. So it's already there albeit you have to do it manually. I've done it while authoring libraries. I don't know if it's a strong occurence/need in user code. But for generic collections I'm definitely thinking about it via `go generate`. But at some point, if the type gets too big, an indirection will probably be better suited although we have somewhat infinite stacks in Go :). Something good will be coming at some point, I'm sure. People just have to think a bit about what they already have and what is the best way about doing what they can't yet. :) And aim at simpler code too.
Oh when my friends ask me how I like go, my response is. "I really like the runtime and the overall concept, but that it has it is own special type casting hell going on." Because anyone whose been looking at long enough is well aware of the generics argument. 
A few quick things: 1. I like the notion of comparing cards, but some games have odd rules. Are aces high or low? What about wild cards? Perhaps a comparer interface would allow swapping of rules. 2. Your implementation takes 16 bytes per card on a 64 bit machine. You could define card as a byte, use 2 bits for suit and 4 bits for value and still have 2 bits left over. 
I disagree, there are things you just can't do with interfaces. You write functions for code reuse and, IMO, generics provide reuse on the type level. Generics allow abstraction over commonly used patterns; one of the things I think C++ does really well is the `algorithm` library from STL. As a personal anecdote, I recently wrote a function to remove an element from a slice without needing to preserve order. It's just three lines but I had to copy and paste those lines where ever I wanted to use them. Later, I found a bug in the code and finding and updating all uses was much more cumbersome than it would have been if I could have written a generic function.
One thing I would expect from generics is type checking at compile time rather than at runtime. This is where Go is rather pythonic, and not C++. And for this you don't have to write example code I think.
I am surprised this isn't mentioned more. Two major benefits of generics are: - No runtime performance penalty compared to interfaces. - Type safety at compile time rather than runtime. For me the first one is a big problem -- interfaces have a significant overhead for small things like math algorithms (hence why the `math` package is not written using interfaces, I imagine, among other reasons). Personally, I don't think the second one is a _major problem_ because you can always write tests. But it would certainly be _nice_ to have.
Why are you disagreeing lol ? C++ template metaprogramming == one of the ways people can have code written for them. Even though not the best in terms of simplicity I think. I do not disagree that genericity is attractive. But most people make the amalgam that generics/generic programming == C++ templates. No please :) And someone has to explain to me how do you create a generic datastructure that is guaranteed to fit nicely in the cache while only being able to modify the types it operates onto. (wrt types having various sizes). I don't know too many cache oblivious datastructures. You could kind of compose templates but then again, that's how you get those awful error messages and even the template code gets difficult to understand. I find that C++ templates are a bit passe besides being not so good to look at. We need a better way than that. 
The language is, sure.
You might find this competition on Kaggle interesting. http://www.kaggle.com/c/poker-rule-induction
Glad we agree on something
Oh, thanks for clarifying. I misread your comment. I think C++ design goals resulted in the templates that the language has; TMP can be rather useful when absolute speed is necessary. That being said, I would have to agree and hope that Go doesn't get generics as full-featured as found in C++. Hopefully the syntax can be cleaned up some too. I think Rust does composable generics pretty well while not producing indecipherable compiler errors; they are more limited than C++ templates, but, AFAIK, that was actually a design goal for Rust.
&gt; But most people make the amalgam that generics/generic programming == C++ templates. I think that's because it seems that every language that gets generic types / templates (real ones, not Java-ish type erasure ones) ends up attracting the kind of people who love generic metaprogramming and before long start transliterating C++ STL/Boost to that language. (See example: D.) And then once you have STL-ish containers and algorithms implemented those same people start whining because the rest of C++ isn't around and so the language starts morphing into a different syntax to articulate the same ideas as C++. And before long people say "Why aren't we just using C++ if we are thinking in C++ anyway?" (See same example: D.) IMHO the value of generics is still unproven for the kinds of industrial big-team-oriented user-facing application stuff that is Go's target. Compile-time generics seem great for library writers, and runtime generics are great for dynamically-typed languages (e.g. Lisp). But once you have basic containers (lists, maps) that will take anything, and interfaces with virtual functions that generic algorithms can call (e.g. sort/min/max), how much more do you really need? 
Exactly. Well I wouldn't mind some kind of more elaborate generic programming still. But assuredly not a translation of what exists elsewhere. And the more I code in Go, the less I miss generics actually. There is a class of user-created, somewhat adhoc generic containers, that could benefit from simple code generation. Useful also if someone is too lazy/ wary to copy paste function implementations etc. But no need to inject templating directly in the semantics of an otherwise pretty nimble language such as Go. 
One will argue that all you need is mostly float64 and complex128 in math. The other numeric types do not support the complete set of mathematical operators (without thinking about conversions/coercions). And Complex numbers can't be compared unless they have a null imaginary part etc. So is there really a need for generics to do math ? Not too sure about that. (this is actually a question)
But that *cannot* happen in 1.x, for keeping compatilibty... https://golang.org/doc/faq#generics We could just fork Go.. are you up to it? I propose Go channels and goroutines, Rust safety, C++ generic algorithms, Java style packages... all with memory usage of Lua! Lets do it!
I was mainly wondering because byte slices are not only a really common example of memory you might want to reuse, but even more importantly, they're a type of object with *variable size*. So any example would have to take into account cases where: * The retrieved pooled []byte is dramatically bigger than you need * The retrieved pooled []byte is even a single byte smaller than you need
Yes. You need a float32 that adheres to IEEE behaviour for most graphics work or you get funny artifacts. There is also a case to be made in many domains for int-based (or at the very least fixed-point) maths that isn't subject to the rounding issues of working with float64.
I don't understand why people think generics are just for writing libraries, or widely reusable general functions. I want generics so that I can have compile time type safety through all of my code.
That's just equivalent to #2. (Also, Card# would be 1 + val / 4)
He suggested looking at bits; I'm talking about looking at a number. Yes, a byte is an aliased uint8 but the context was different. (Ah, yes /4)
I think this article is really missing the point. Any point in time that I can use existing, generically written code, then **I am using generics frequently**. I think in this case time saved == time using generics. Also the even bigger issue is that by encouraging using interface{}, Go is actively reducing the value of its own type safety. If the "answer" to a problem is "subvert the type system" or "repeat yourself", then there is a fundamental flaw with the language.
Oh ok, yes indeed I guess for cuda etc. That's a good use case. Shouldn't be too hard to have code generation handle this. Especially since I guess it is mostly library level code. I suppose once an arithmetic precision is chosen, there is no switching usually right ?
&gt; but I didn't see anything to suggest that. Well, he did call out 2 main things that made the xarg approach philosophically troubling. * Error handling. * dig's unstructured output style. Go handles both problems in a way that's potentially much faster and more rigorous than spawning a bunch of OS-level processes. Bickering aside, though, we strongly agree on that last point: &gt; all I REALLY wanted to see was how long it would actually take with parallelized xargs. Abso-fucking-lutely. As I implied above, I don't expect xargs to win, since it does a lot more work - more memory allocation, more text processing/filtering, etc. But I'm not a psychic, I don't *know* how big the speed difference would be, or even that it would swing the direction I'm expecting! Hard numbers are awesome.
You don't have to break compatibility to add generics AFAIK there is no technical reason not to have it in a 1.x release. That said, having generics would probably mean major changes to the stdlib to improve ergonomics when using generics that it may break backwards compatibility.
&gt; There is no reward; this is more of a thought experiment for the general programming community. The general community? The only language community (restricting to static languages, here) that are sceptical of generics, seems to be Go. So I don't really think that the general community is interested in that debate. 
Well, that depends on your analysis needs, but it's probably uncommon enough to warrant explicit conversions. I think a lot of the people requesting generics are actually maintainers of third-party libraries that are never going to be in the standard library because they're of interest to a limited domain. For example, most AI learning techniques, motion planning, specialized graph structures - you want the compiler to enforce type safety but you don't want to go down the C route of having 10 times the number of methods that vary only by type.
Very interested to get involved on this subreddit, Go has a LOT of potential for games and needs to be tapped.
Go killed Node.js, generics in Go will kill Java.
Go contribute to Hugo, it's a great project with a lot of good bite-sized work that can be done on it: https://github.com/spf13/hugo
Told you I had a proof of concept :)
In scientific computing, it's fairly common to run into cases where you have enough values sitting in memory at once that deciding to store all your floats as float32s can prevent you from hitting an individual core's memory limit. Even if that's not the case, choosing to store them as float32s also gives you fewer cache misses (*a lot* fewer for certain lattice operations), faster I/O, etc, etc, so float32s fill a very necessary niche. Of course, there's nothing *that* awful about writing xs[i] = float32(math.Sqrt(float64(xs[i]))) instead of xs[i] = math.Sqrt(xs[i]) (or whatever), but it's also pretty annoying.
Not relevant to your code, which looks like a great start for a poker hand evaluator, when you post on reddit you get more points (whatever they are) for posting a link as opposed to posting a comment. E.g, in this case you could have posted the link that is included in the comment. As an added plus, readers go straight to what you've linked to when the title is clicked. 
Amen !
I see, thank you.
Anyone interested in building a Cryptocoin Exchange in Go? 
&gt; somewhere between an educational toy and a useful black-box remote monitoring app Ah yes, the elusive education/NSA market... :)
&gt; If it caused an extra 2% to uptake go wouldn't it be worth it? The goals of Go are focused on creating a language that solves certain kinds of problems, not attracting users.
I have been working on a package for poker hand evaluation and had to accomplish similar things. I didn't end up separating out the card and deck functionality (a bunch of small packages can increase the overall size of the API) but I was definitely tempted too. It might be a good resource: https://github.com/SyntropyDev/joker/tree/master/hand At a glance: * 1 - NewDeck() should just be New() that way callers can call deck.New() * 2 - Constants shouldn’t be all caps. Change ACE to Ace etc. * 3 - I went to card.go to look for Ace, King, etc and was surprised that they were in const.go. I would consider just putting them into card.go. * 4. Consider table driven tests. I use them in my library and they save a lot of code. https://code.google.com/p/go-wiki/wiki/TableDrivenTests * 5. Shorter names are better. Consider Len() to NumberOfCards() if you feel the caller would understand. * 6 - Functional options for the New() constructor eliminating the need for NewSpecificDeck(). * 7 - I believe Rank is the official term for Face, but that doesn’t have to do with go :) Here is what 6 would like roughly like: func New(options ...func(*Options)) *Deck type Options struct { shuffled bool faces []Face suits []Suit } func Unshuffled(o *Options) { o.shuffled = false } func Pinochle(o *Options) { o.faces = []Face{ACE, KING, QUEEN, JACK, TEN, NINE} } func Empty(o *Options) { o.faces = []Face{} o.suites = []Suit{} } func Suits(suits []Suit) func(*Options) { return func(o *Options){ o.suites = suits } } This allows callers to do any of the following: deck.New() // default all suits, ranks, shuffled deck.New(Pinochle) // A,K,Q,J,10,9 shuffled deck.New(Pinochle, Unshuffled) // A,K,Q,J,10,9 unshuffled deck.New(Empty) // Empty deck deck.New(Suits([]Suit{DIAMOND, HEART})) // red cards only For more on Functional options read: http://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis If you go any further with this keep me in the loop - https://github.com/loganjspears
I don't work on the Go team. Among **853,303,287** function calls in all public Go packages, **102,396,394** ignore returned error and continue execution. I think that show paranoic error handling is not users may want to do. ^(I just made it up but the point stands.)
Why wouldn't you fork NSQ and add it in to NSQ itself? Is this even scalable?
I think, the idea is rather that you don't need the genericity in most cases. It's really more of a code writing convenience most of the time. They are aware of this themselves I bet. I mean, they did write the standard library after all. Point being that if the need for generics is insufferable, that copying code is not doable, then at the very very least you can use an interface. (but sometimes, I agree that it is not optimal a fallback either). Sometimes, an interface can be the best option though.
What? Those numbers don't make sense in absolute or in proportion. Your point is neither obvious nor does it "stand".
There are packages in the standard library itself that are generic containers that force you to use interface{}, which in turn forces you to do type casting and lose some of your type safety. e.g. http://golang.org/pkg/container/ring/ There are so many things in programming that can be satisfied with generic implementations, and it's hard to satisfy all of those cases with interfaces. However, while I think that while container-of-type style generics would be nice, there are other methods of generic programming that I think can solve some of the issues people are having.
I ~~totally~~ agree. (Well, with the little caveat that often, when it's only "the best solution currently available", it means that you could probably have foregone the desire for genericity and followed the cut &amp; paste route but I understand it can be an annoyance at times.) *[edit]: and actually with the big caveat that no big change to the type system should be needed. I guess I do not agree "totally" but to some extent only.*
Needs more docs. I find code harder to review when there are no docstrings explaining what the developer expects it to do.
Yes using interfaces like that is not a panacea. Typically that's where you would want to replace the types etc. The case for generics as a code writing thing. I do agree as well. It did bite me too (never too hard though).
Is the ORM they talk about available anywhere?
I think I like the idea of that "black box" better... I just mean that you do not have to install any software on the remote machine unlike most monitoring tools. This makes no assumptions about what you want to monitor, you just give gopoke a URL endpoint.
Maybe.....I think there are most likely other edge cases that we're not thinking of there that returning true would be problematic for. I think the best approach might be to add a *ImportSpec to the type switch.
Reflex looks good. But isn't it similar to [fswatch](https://github.com/emcrisostomo/fswatch)? Advantages of reflex a very much like fswatch. 
If you have anything to add to this snippet, please give details in comments.
Yeah, I haven't seen it either. Perhaps reach out to them twitter?
Friendly Editor: "Aslo" is misspelled in paragraph 2
Cool, Go is for sure lacking really good config tools. One of the biggest issues I've found when evaluating these tools is what happens when you nest deeper than one level? I shouldn't have to write a ton of marshalling logic to get the data out that I need unless that data is super complex or I want it to go straight into a struct. I use [Confer](https://github.com/jacobstr/confer), which is an offshoot of [Viper](https://github.com/spf13/viper) because it can handle multiple different configs at the same time, and because you can nest and access configurations nicely: config.GetString("server.logger.file_path") Unfortunately it only handles YML files at the moment, but YML works just fine for my purposes. That being said, nice work on this!
I've used [github.com/stathat/jconfig](https://github.com/stathat/jconfig) for years successfully.
Thanks for the links. jsonconfig doesn't handle multiple levels as nicely as Confer does but I think the way I would use multiple levels, I would prefer the way I handle it in jsonconfig. Supporting the merger of multiple config files would be quite easy by renaming and exposing applyDefaults in configBuilder.go as a public func. For the sake of conversation, I don't think I would ever use more than 2 levels unless I didn't know beforehand what the deeper levels would contain. This would mean I would have to do a certain amount of checking what exists anyway.
Mine doesn't do much more than that except allow for //comments. I just think it's useful to be able to explain things within a configuration file. Edit: mine also allows you to more easily handle deeper levels of data.
Not enough over engineering.
There isn't really a disadvantage when the configuration is small/simple. It's the approach I would use for simple configurations, see Load in configBuilder.go. Once your configuration starts getting more complex the boilerplate required to correctly read it starts to get large. I think this is probably more my personal preference though.
Why preprocess the JSON to remove comments when [JSON5](http://json5.org/) exists?
JSON is terrible for configuration. I've been using https://github.com/BurntSushi/toml instead. I've also used https://github.com/go-yaml/yaml in the past. Why do you call it JSON when you clearly deviate from the JSON spec?
&gt; would still work if I wanted go to arbitrary nested levels? In practice, you probably wouldn't nest that deeply, but it is nice to know that you can go deeper: I'm not sure if it would or not. I don't think that's an unreasonable desire. I wouldn't be surprised if that was feasible with the standard library, though I'm not sure. At any rate, thanks for posting this clarification--I understand your use case much better now (and it definitely seems like a reasonable one).
I think JSON is fine, you are entitled to your opinion though :) Thanks for the links, TOML looks like a nice addition to the typical ini file format. This code handles JSON just as well as it does the alteration made to it, if not better. I didn't try to mislead and I don't really see the problem.
Cool, if not, this is still really nice. If it is, you should really advertise that feature because it is really valuable and as I mentioned, is one of the things that few config libraries do well!
You can have compile time type safety throughout your code without generics. You might, sometimes, occasionally, once in a while, have to duplicate some similar code to support a couple types. But honestly, that should be rare. There are lots of ways to write generic code without needing "generics".
Adding such feature to NSQ means altering the server to keep and deliver messages based on timestamps and also adding the support for each client lib.. Why won't it scale? All it does is receive messages, persist them and publish later. You can run as many nsqdelay as you want to handle large amount of messages if the queue becomes large. 
hear hear!
If it doesn't work then it's a bug and I will fix it :) Thanks for the kind words, I think I'll add some more complex examples to the end of the readme and documentation examples.
I guess because I would have to implement JSON5 to use it. There's [this](https://github.com/yosuke-furukawa/json5) library but it doesn't look ready yet and I only want the one feature from JSON5.
It is -- but then it isn't really json anymore. Only parsable by your tool... we picked yaml because of this single issue (comments). 
That's a fair point but I don't personally think it's a problem for configuration files since it's unlikely that an external tool will be handling them.
Hi, i have a few questions. First, why are you advocating testify/mock and gocheck instead of standard library for testing? Introducing a Ruby dependecy via Rakefile isn't what i would qualify as simple. it's a dependency that can be avoided by writing a proper makefile. In my opinion, a good starter projet for cli with go would be: git init and standard library. 
Mainly that JSON isn't human friendly and doesn't support comments.
Nope. You don't have to (for servers, only for clients). It's an unfortunate mistake in the original design of the net/http package. The docs say: http://golang.org/pkg/net/http/#Request // Body is the request's body. // // For client requests a nil body means the request has no // body, such as a GET request. The HTTP Client's Transport // is responsible for calling the Close method. // // For server requests the Request Body is always non-nil // but will return EOF immediately when no body is present. // The Server will close the request body. The ServeHTTP // Handler does not need to. Body io.ReadCloser 
This is correct, but you probably want to use an [`io.LimitReader`](http://golang.org/pkg/io/#LimitReader) so that you aren't reading the entire body into RAM. A size of something like 2147483648 or whatever seems reasonable.
Okay, so what does the workflow look like? Do you just version control your templates and your content (together? Separately?) and then execute the templates before you ship?
Yep, exactly. Generally people put the templates and content in one repo, and the output in another repo. So, you update / add content, then run hugo, which updates your HTML output. You check both sets of changes in. For example, my blog http://npf.io - the templates and content are at http://github.com/natefinch/npf and the html is checked into https://github.com/natefinch/natefinch.github.io - which is what gets displayed by github pages (and I use cloudflare to forward npf.io to github pages).
Go team!
Yes?
yes?
Yes?
&gt;The most notable new feature in this release is official support for Android. Do this mean we can see Android completely moving to Go in 2-3 years? or is it too early to say
No.
Yes?
It means that in 2 to 3 years, writting Android apps in Go might be nice. Maybe.
This is all champagne!??! https://twitter.com/NWSBayArea/status/542881707012014080 
Thanks Go team, congratulations on the release and can't wait to move all our code to 1.4. Also, will Go 1.5 have generics? (Just kidding.)
Does "No." means ? It isn't too early to say that we can see Android completely moving to Go in 2-3 years. :)
Maybe in cases like this... vals := []string{"foo, bar"} // various operations that may append to vals var keys []string for range vals { keys = append(keys,"key=?") } where := strings.Join(keys," or ") db.Select(&amp;result, "select * from table where "+where, vals...) Cleaner than "for i:=0; i &lt; len(vals); i++" I think.
[The release notes][1]. [1]:https://golang.org/doc/go1.4
That would be cool! Instead of just writing code you can spend hours configuring your IDE. I feel soooo much more productive after I convinced maven/gradle/whatever to produce an Eclipse configuration which actually works, both for building the software _and_ for testing it. Especially as I no longer need that strange thing with letters you type on but can use the mouse! I admit that debugger support is bad, but any halfway decent editor is enough.
Hopefully jetbrains will make one
In most cases you configure it once and it works, at least this was for me with vim, Sublime, IntelliJ Idea. None of them was complex to set up. I started checking IntelliJ just recently and it looks promising.
I use latest unstable releases of IntelliJ plugin, can be rocky sometimes but still faaaaar better than the last stable one. https://github.com/go-lang-plugin-org/go-lang-idea-plugin
Yep, thats pretty much the idea. I wanted to hold of on more features and docs until I was sure about the main approach. My main concern was whether it is enough to check for the existence of a value in the session if I uses store that is encrypted and signed.
I know but it still sucks big time, I'm hoping for a dedicated Go IDE
``` for range time.Tick(time.Second) { log.Println("hello") } ```
why not join the go generics project? https://github.com/golang-collections
If I already know the slice size I prefer to allocate it directly: keys := make([]string, len(vals)) for i := range vals { keys[i] = "key=?" }
IDEs are useless, Go has go-mode.el and debugger is coming.
Nobody would be forcing you to use an IDE or use a working debugger. You can keep plugging away in your favorite text editor. I think you've probably been burned one too many times by Eclipse. There are other IDEs and they're not all as painful to work with as Eclipse. 
I'm glad I'm not the only one. 
Renaming a method and updating every reference to it. Building out and updating the struts when working with SOAP. Maybe an Integrated ORM. There are a lot of things I would like to see in an IDE. If you don't like it nobody would force you to use it.
I and many other people disagree.
&gt; Renaming a method and updating every reference to it. Isn't there something called `go rename` (or some such) that does this?
yes there is. I understand everything can be done in command line. I don't think it should be necessary to call another program to update my code after I rename a method. 
&gt; Not necessarily true. It depends on how the generics is implemented. Agreed, but this could be said about a lot of things. In fact I don't see any reason why static analysis could not determine that an `interface` type parameter is only used as a single type (through an type assertion) and thus optimized away. &gt; There is trade-off among expressiveness, performance, verboseness, and the complexity of the underlying model(and the implied ramifications). Don't misunderstand me, I agree largely with what you are saying here. I for one am actually fine without having generics, and hope that _if they come_ they are not in the traditional sense. I think the problem that they try to solve is a notable one: _generic programming_. Eventually Go will solve the problem of generic programming, I personally think. How it will look I do not know but I imagine it will not be as it's traditionally implemented but rather in a Go-esque form.
One use I can immediately think of that hasn't been mentioned yet is combining it with [github.com/bradfitz/iter](http://godoc.org/github.com/bradfitz/iter)
It means that Go might become a reasonable alternative when writing NDK parts of Android apps. Replacing Java on Android is not in the Go team's hands.
Cross platform debugger, YES. IDE, not so much.
Is it "it sucks because it sucks" or do you anything particular in mind? I'm not opinionated, just tried it, and for me it's the best available environment at this time.
&gt;Instead of just writing code you can spend hours configuring your IDE. Most users of serious text editors (Vim, Emacs, Sublime Text, etc.) have probably spent plenty of hours configuring their editors (I know I have). &gt;I feel soooo much more productive after I convinced maven/gradle/whatever to produce an Eclipse configuration which actually works, both for building the software and for testing it. Simply having an IDE won't turn Go into Java. I see no reason why a Go IDE couldn't just use the Go tool as its build system. &gt;Especially as I no longer need that strange thing with letters you type on but can use the mouse! [Acme](https://en.wikipedia.org/wiki/Acme_%28text_editor%29)
These tools are command-line based to integrate most freely with the maximum number of editors, not because they intend you to directly use them. Running a command-line program is the only interface shared by all these editors and IDEs.
Go generate would be nice. I could myself using it all the time. Something like: //go:generate jsongen -type=Struct1,Struct2
So have I for multiple projects, it works more than fine. Just be prepared to click away IDE exceptions every once a while. The only thing I really miss in that plugin is when hovering over a Function it showing the related documentation.
Yes?
Yes?
Debugger ok.. I don't think anybody can argue with that. But I really like working with LiteIDE and I honestly wonder what people find so bad about it. 
Yes?
No.
Indeed. IDEA, WebStorm and PhpStorm have increased my production so much. Out of the box, without almost zero configuration.
^ this. For a "starter project", going off writing a make file at all is promoting bad practices. If you want to write tests, great, use `testing`, if you want to check if something equals another, great, use `==`. Keeping things simple is what Go is all about. The fact that you can build using `go build`, test using `go test` is what's so great about Go.
I recommend no one goes over to the thread in /r/programming about this, unless you enjoy the usual "herp derp no generics" circlejerk. Seriously though, 1.4 looks great. 
I'll definitely have gogenerate support (I don't think I'll actually have to do much of anything to support it). Being able to specify the types you want to generate tags for is a good feature I hadn't thought of (I was just thinking whole-file).