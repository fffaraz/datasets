I already forwarded this to them.
Think he is meaning, have the frontend in one go app, and the functional backend in another go app, interface with api requests.
Huh, I just tried it and the 123 ball clock is taking 32 seconds on my na√Øve implementation. Guess it is time to learn how to profile Go code. I am betting the problem is either in my cycle detection test (which is really na√Øve) or my drain function (which isn't much better). I also used channels to represent the tracks. It might be better to use a data structure for them that can do the whole reverse order thing without having to slop them into a slice first.
I shared your fears, and now I ride unicorns over rainbows and fart pixie dust. It took me all of 20 minutes to make the switch.
I'm not sure I'm willing to make the switch from my current OS to emacs.
I'm using go in production as a windows service without issues, so i don't see what is your problem. Go has evolved so why don't you give it a try and make new conclusions.
I don't understand why ppl downvoted this comment.
So GitHub coined that branching model "GitHub Flow". "Master means it's deployable" is part of [Trunk-Based Development](https://trunkbaseddevelopment.com). I hoped you'd say what you said, but still it seems odd to call out 824 branches and not give context. Maybe you did in the video. By contrast, the MS Windows team is coming down from many thousands of branches towards trunk based development. It's going to take them some time to complete. Theirs are not [short-lived feature branches](https://trunkbaseddevelopment.com/short-lived-feature-branches/) of some definition (although a small percentage might be), they are long-lived valuable branches - that shouldn't be deleted for some reason. They also should **not** be merged back to trunk/master ASAP for some reason, because they are not release ready. There were a few article earlier this year around [GitVFS](https://github.com/Microsoft/GVFS) and they didn't dwell on the thousands because it wasn't the focus, even if it's important to many of us as we contrast to Google's Trunk-Based Development. Yup, Google's 25,000 developer monorepo IS one branch (and an un-numbered amount of patch-sets is the style of short-lived feature branches). Thus many of us think that effective monorepo does dictate branching models.
&gt; The only thing that comes to my mind about problems on Windows is that the plugin system won't work (it is a WIP after all) and the installer won't set GOPATH or GOBIN for you (and it won't give you the option). This is not true (anymore). GOPATH defaults to %USERPROFILE%\go. In VS Code I set two options: "go.inferGopath": true // autodetect GOPATH from src folder path "go.toolsGopath": "c:\\gotools" // do not clutter GOPATH with Go extension tools 
It is a lot better now. Give it a try.
Author here. Thanks for sharing this! If anyone has feedback or questions about the project, I'd be happy to answer.
Apart from some pointer assignments I guess you were pretty close? https://play.golang.org/p/pcykcguK9T 1. new(big.Int) returns a `*big.Int` (a pointer to a `big.Int`), 2. big.NewInt(value) returns a `*big.Int` (a pointer to a `big.Int`) I'm going to assume that this is correct, and that you should always use NetInt notation to create a bigint value. As such, I changed the parameters of GCD to accept a poiner. Functions like b.Cmp and t.Rem expect pointer values. Since zero, a and b variables are already pointers, you don't need to add `&amp;` in front of them. Having `&amp;a` produces a pointer to a pointer to big.Int (or `**big.Int`) and is incompatible with those functions. Finally, in order to return a `big.Int`, I changed the final return to `return *a`. This "reads" the `big.Int` value from the pointer and returns that, instead of the pointer. I think the big.Int test for zero is correct, godoc verifies: &gt; Cmp compares x and y and returns: &gt; &gt; -1 if x &lt; y &gt; 0 if x == y &gt; +1 if x &gt; y
&gt; Cross-compiling available on all platforms One of my personal favorites!
Hi guys, I want to share this simple logger I made for my servers, mostly game servers and realtime apps, it's really simple but useful for me. Maybe could be useful for anyone here. Regards!
Thank guys... Part 3 doesn't have screen =((( 
Cool project, but it's a bit weird that a static page takes up 50-100% of a CPU core on my machine. I'm quite sure it's the moving dot's not liking Linux chrome.
Disabled for now. It's just using particle.js. Will check, what's going on there. What Linux, Chrome version and CPU?
Bummer, was hoping s/he was going to end up with a faster implementation, by taking more steps to optimize. Any immediate thoughts from anyone on optimizing this further? Aside from benchmark/trace the bottleneck and focus optimizations there, I mean.
I'm not keen on the way that the waitgroup stuff is presented - it doesn't wrap lsFiles in a closure, and doesn't show a signature change, so it never addresses how he waits on it. Since the file system operations can also return errors (which are currently dealt with using `log.Fatal`) it would also have been a nice use for errgroup (to catch and handle errors), and potentially replacing the recursive nature of it with some "list workers" and avoiding the need for lots of waitgroups on each function. Also notice that the semaphore channel magically shows up in lsFiles without being a member of a receiver or parameter, which means that lsFiles is probably a closure itself, which is never mentioned. I just wish it showed off better practices.
Thanks, yeah that was the issue. It's Arch Linux, with Chrome 62.0.3202.75 and an Intel(R) Core(TM) i7-6600U CPU
For all that Go by _convention_ uses relatively safe concurrency abstractions, you are, technically, still using old-school threading, and that can get complicated. The simplicity of the language means that you take a hit in the code. In the worst case, you're duplicating code to be "generic", but there are other places where you're going to be writing several lines of code to do something that other languages can do much more quickly. Though, that said, I find that egregious code expansion happens less often than critics claim, most of whom have never used the language, and most of the rest of whom used it in some way I would recommend against. (Specifically, high-performance mathematical code, where you want to write things generic to int64/int32/uint32/float64, and matrices of difference sizes, etc.) I'd also defend that a bit by pointing out that the simpler code ends up being more broadly understandable. More programmers understand newArray := []int{} for i := 0; i &lt; len(arr); i++ { if arr[i] &gt; threshold { newArray = append(newArray, arr[i]) } } than understand newArray := [elem for elem in arr if elem &gt; threshold] And while as someone who does understand the latter, it does sometimes hurt to have to write the former, I've also learned that it is often _more professional_ to use the former in a context where the code may end up in anybody's hands.
Sounds like you are asking the right questions. Remove everything that isn't necessary. If it is necessary, find the fastest way. That is the whole point. But try not to give away too much publicly :) 
You are now my favorite person in the whole wide world.
If dealing with standard int, couldn't you just implement the same logic? https://play.golang.org/p/GVPWXGjKj_ func gcd(x, y int) int { for y != 0 { fmt.Println(x, y) x, y = y, x%y } return x }
I use `import gm "github.com/onsi/gingko"` and then use `gm.Expect(ACTUAL).Should(gm.Equal(EXPECTED))` which reads better to me. The repeated use of `gm` is a bit annoying, but makes it easier to know which pieces come from Ginkgo or Gomega or whatever else. I prefer it over manually doing: `if e, a := EXPECTED, ACTUAL; e != a { t.Failf("expected %v, got %v", e, a) }` which seems to be the other common way to do things, because this requires more lines and can easily lead to missing data in the failure message, or incorrectly printed data (depending which format parameters are used)
Apparently not on my mobile app there isn't :-(
Thank you, that's exactly what I needed to read!
I just wanted to try to implement full Python equivalent.
There seems to be a typo in the setup instructions for Single repository import. &gt; pkg.txtdirect.org 86000 IN CNAME gopkg.link. &gt; _redirect.org.txtdirect.org 86000 IN TXT "v=txtv0;to=https://github.com/txtdirect/txtdirect;type=gometa" Should probably read *_redirect.***pkg***.txtdirect.org* in the second line.
Thanks. Fixed.
Honestly, the meta tag seems easier to set up than this..
Heya. Today we flip the switch to make our presto client open source. We've been using it for a while and obviously wanted to contribute back to the community by making it publicly available. Feedback and comments are welcome.
Buffer is a struct type, not an interface type, and so it actually must be implemented by a byte slice by definition. There might be a more general buffer interface somewhere else, but I can't recall one offhand.
If you want to maintain the certificates, a webserver and a global infrastructure etc.
Letsencrypt and any old webserver in teh cloud. At least for me, a project that deserves a vanity import deserves a website anyway.
Possible sure. But not everyone is running their own webserver or CDN or general infrastructure. Differences in the approach. There is also https://caddyserver.com/docs/http.gopkg, which is a more static approach tailored to your approach.
One big thing is that ReadDir does an lstat() on each directory entry to get the FileInfo data, find doesn't need to do this.
Just about any kind of website hosting will let you put in the meta tags, including just using a GCS/S3 bucket.
&gt; Duck-typing - one doesn't need to explicitly define class hierarchies, as interfaces are implicitly satisfied. It's actually [structural typing](https://en.wikipedia.org/wiki/Structural_type_system), not duck typing.
Buffer is an idea that has existed long before Go.
If you use a static file on S3 + Cloudfront, then AWS will handle maintenance of the certificates, webserver, global infrastructure, etc.
True, but OP used the capitalized and monospaced "Buffer" to refer to bytes.Buffer, and that's what I was referring to as well. Buffers as an idea are definitely older :)
your demo-tools repo appears to be private. Only wrapany and demo-grpc are public.
Be a hero and learn how to crush it by coming up with awesome headlines like a boss. Paradigm. Synergy.
Version 2.0 adds more features useful for API load testing scenarios. The payload can now include template functions to inject random data into the requests, and you may simply omit the data field to run until interrupted rather than load a CSV... Also the status updates are much improved... Each time you interactively change the sending rate, a new column is created so you can monitor the latency at each rate... Each type or status response from the API gets a row. The results look something like this: Metrics ======= Concurrency: 1999 / 2000 workers in use Desired rate: (all) 10000 1000 100 Actual rate: 2112 5354 989 100 Avg concurrency: 1733 1976 367 37 Duration: 00:40 00:12 00:14 00:12 Total ----- Started: 84525 69004 14249 1272 Finished: 82525 67004 14249 1272 Mean: 376.0 ms 374.8 ms 379.3 ms 377.9 ms 95th: 491.1 ms 488.1 ms 488.2 ms 489.6 ms 200 --- Count: 79208 (96%) 64320 (96%) 13663 (96%) 1225 (96%) Mean: 376.2 ms 381.9 ms 374.7 ms 378.1 ms 95th: 487.6 ms 489.0 ms 487.2 ms 490.5 ms 404 --- Count: 2467 (3%) 2002 (3%) 430 (3%) 35 (3%) Mean: 371.4 ms 371.0 ms 377.2 ms 358.9 ms 95th: 487.1 ms 487.1 ms 486.0 ms 480.4 ms 500 --- Count: 853 (1%) 685 (1%) 156 (1%) 12 (1%) Mean: 371.2 ms 370.4 ms 374.5 ms 374.3 ms 95th: 487.6 ms 487.1 ms 488.2 ms 466.3 ms Current rate is 10000 requests / second. Enter a new rate or press enter to view status. Rate? 
My JS/CSS/images are typically in $GOHOME/src/$YourGitHost/$YourProjectName/static/js, $GOHOME/src/$YourGitHost/$YourProjectName/static/css, $GOHOME/src/$YourGitHost/$YourProjectName/static/images and map `static` folder as static in application router or intercept and serve (in production) directly in reverse proxy. I keep templates in $GOHOME/src/$YourGitHost/$YourProjectName/views/ 
Weird, the project visibility is set to Public in GitLab. What error are you getting?
Personally, I find the 12 factor approach to logging very useful. Your entire use case for async logging gets automatically taken care of. Just print your logs to stdout. And have another application listen to the output from stdin. I have written [funnel](https://github.com/agnivade/funnel) exactly for this purpose. 
True, but OP also said ‚ÄúAre buffers just a fancy array?‚Äù There‚Äôs definitely room for multiple interpretations of OP‚Äôs question, so by no means do I mean to call you wrong. I just judged that OP was asking about a higher level idea rather than asking about the API/implementation of a particular type in the standard lib.
I can see the project as public
It is open now, I‚Äôm able to see it. Weird.
netlify does letsencrypt with built-in support for hugo, it's what I use for gnorm.org and npf.io, both of which serve vanity imports. I wrote about it here: https://npf.io/2016/10/vanity-imports-with-hugo/ Aliases are a nice fix because they auto-generate all the associated subdirectories that you need. I keep the alias list up to date for gnorm.org with some code generation that runs on go generate: https://raw.githubusercontent.com/gnormal/gnorm/master/site/content/gnorm.md
Fair enough! Between us I think we've covered all of OP's possible bases ;)
I don't need to have profiled the program to understand that the explanation provided by `nagai` is insufficient, given the other GC implementations.
We suffer from be same thing at fb. Cannot use goimports at all cuz it hangs forever. We‚Äôve been discussing a fork that supports caching somehow.
I was forced to read The Goal in a business class. What does that book have to do with coding?
https://github.com/golang/tools/blob/master/imports/fastwalk.go for an example from goimports. You can check the test files for examples from the top level dir.
For me: from vim to visual studio code and back to vim
&gt; WHAT IS PRESTO? &gt; Presto is an open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes. &gt; Presto was designed and written from the ground up for interactive analytics and approaches the speed of commercial data warehouses while scaling to the size of organizations like Facebook. For those of us who hadn't ever heard of Presto (like me)
ended up writing my own parser.
Nice! We tried using https://github.com/avct/prestgo but it sucks balls.
That‚Äôs where we started too. Then it evolved over time and we ended up making so many changes that it wasn‚Äôt worth forking it and a new client was born. If you look at the code you‚Äôll find copyrights to that repo because we used some of their data type definitions in the early days.
Coding has nothing to do with business, it exists entirely within a bubble! The reason you had to read it in Business class is because the Theory of Constraints is universal, the concepts apply to coding and factories. The Phoenix Project was heavily influenced by The Goal.
As an engineer at Avocet (the avct in question), I have to say I wasn't aware of that specific function of the prestgo library, but then I've not been around that long. Still, it doesn't seem related to our core functions - are you sure it was prestgo doing this? 
Anyone else get a server error?
I'm getting 500 error but I found this: https://github.com/golang/talks/blob/master/2012/10things.slide
Still not 100% on Presto. I found the below page on the different connectors available. One question: can I use Presto to create a 'virtual table/view' over two different Postgre servers? https://prestodb.io/docs/current/connector.html
I know Facebook didn't have a lot of Go after Parse closed. I'm curious how the usage is growing and what areas it's being used in (if you're able to talk about it..)
10 things OP doesn‚Äôt know about HTTP?
So is there a way to actually make this calculation without using Pow?
My comment only applied to "modern" apps where the frontend was all Javascript. The other suggestions here are fine if you have to have templates that need to be accessible from your backend.
As per /u/ibishvintilli's response; Use `math/cmplx`. fmt.Println(cmplx.Pow(-2910.579503363819, 0.2)) I'm not sure of how it would be done otherwise.
Thanks
üôá‚Äç‚ôÇÔ∏è
Very useful. Thanks for sharing.
There‚Äôs a dedicated group of gophers, from various teams, working towards making it a first class language. This group has been growing, and general support for our systems is quite good. There‚Äôs really no restrictions on what you use in your projects so long your peers are willing to review your code.
Yes, Presto can query and combine data from multiple sources. Not only you can query multiple Postgres but also do joins between data from Postgres and other sources, eg Redis.
I added initial support to `usql` (the universal SQL command line client): go get -u -tags presto github.com/xo/usql Took me an extremely long time to get a cluster up and operational for testing. Will finish / clean up the integration over the next couple days. At least for now, you don't need to use a Java :) client for testing/development purposes. If you temporarily need to connect to a server with https and not plain http, one can do the following from within `usql`: (not connected)=&gt; \c presto https://host:port/?params Cheers!
I'm quite certain, yes.
That‚Äôs cool. Wondering why it took you so long to set it up. In the integration_tests directory of our repo there‚Äôs a Dockerfile that sets up an operational node with sample tpc-h data. For https, it‚Äôd be nice to support passing x509 key and cert files for client authentication.
Here's a quick gist for GitLab/Go projects: https://gist.github.com/everdev/b02486489fce6ac970e6a7d1dd42ec2e
It took so long because I had never used Presto previously. Went down the path of a couple of bad units. `usql` just passes the credentials on to the underlying Go driver. I would suggest adding x509 key/certs as parameters interpreted by the underlying driver. I realize you have the ability register a custom client, but that's not really possible / feasible with `usql`. I'd also like to note that it breaks the "standard" Go way of providing database connectivity.
I updated the `dburl` package to support `prestos://` URLs, which will change it to https, as well as recognizing `&lt;url&gt;/catalogname/schema` style URLs (so this is consistent with all the other databases supported by `dburl` and in turn by `usql`).
I've used Presto at the petabyte scale outside of Facebook. It's absolutely incredible if you have the compute to scale it -- it's crazy fast and easy to setup.
Can presto "push down" filters?
Depends on the connector! Check the docs, :)
With Go1.9 you no longer need to do go list ./... | grep -v /vendor/ just go list ./...
Great answer, thanks
Just looked at "Preparing for the Next Wave". For the love of god, please don't let this take off (except the logging interface).
I did not know the "12 factor" approach, anyway having two apps it's not so simple like one app saving his logs, but it seems like a good way to learn for future projects. Thanks
This framework has been around for a number of years. Any particular reason for a post about it today? 
Just sharing and to get some random opinions on it
[removed]
It's a decent list, but this is 5 years old, and go has some *much* cooler "unknown" features than these. These are pretty standard now.
I expected snowflake-style platitudes, and was pleasantly surprised. tl;dr: context matters, there's always a tradeoff, and engineering is about making choices. There's quote by Ralph Waldo Emerson circulating in the [Python community](http://legacy.python.org/dev/peps/pep-0008/#a-foolish-consistency-is-the-hobgoblin-of-little-minds), which I like very much: *A foolish consistency is the hobgoblin of little minds*.
you're right, thanks for pointing that out.
Yep, bad practice becomes good in a specific context. Maybe that context isn't always "I'm building a prototype and I don't need unit tests" I'm reminded of a quote more along these lines: "Not all good software has tests, and not all tested software is good". It's worth taking note of best practices, but you should enforce them when they need to be enforced. Knowing the difference is important tho.
He mentioned DNS rebinding attack, but I thought it applies only to badly implemented web pages like routers with simple default passwords...?
please don't let any of my coworkers read this. 
Interesting you mention game servers and realtime apps. Do you reckon something like this open-source project, [Nakama](https://github.com/heroiclabs/nakama) can be useful for you guys? Hoping that you guys wouldn't need to re-invent the wheel. ^I'm one of the devs behind Nakama
Yes, this seems to be about the ability of nginx to simply not serve requests with invalid Host headers (by using a catch-all). Not sure why that is nginx specific or even the default, but I am probably missing something...
I agree that context is important, but I don't follow through to the point of there not being such a thing as good or bad code. You really have to stretch quite a lot to come up with an excuse for code that's difficult to understand and maintain, even the "it's just a prototype" or "I'm going to throw it away" have come up as excuses various times for some hideous systems that have persisted for years precisely because they couldn't be easily understood and replaced. Write code under the assumption that it has to last 5 years and be maintained by someone else who isn't interested in how clever you're feeling, and might know your next boss. At the very least, it's good practice for the 80% of code where it could potentially be true.
Didn't know about Gin, and am shopping around for a web framework his week. Looks solid!
Hi u/Bloze! I've been working on [Orbit](https://github.com/gulien/orbit), which looks alike :) I love the way Tusk handles options, great work!
Please read thoroughly [the explanation page that benchmarks shootout site provides](https://benchmarksgame.alioth.debian.org/why-measure-toy-benchmark-programs.html); it also contains links to useful resources related to benchmarking in general.
This project is over 4 years old..
‚Ä¶on a more serious note, do you really write production code which spends 99% of the program wall clock time doing regexp matches and binary tree searching? Two points to consider: - It's not only the CPU time that matters. Programmer's productivity and [code maintainability](http://jimplush.com/talk/2015/12/19/moving-a-team-from-scala-to-golang/) typically far outweigh raw speed of the resulting program. - When raw speed matters [Go allows you to go as low-level as practically possible](https://github.com/klauspost/compress/blob/master/flate/crc32_amd64.s). - More often than not [benchmarks comparing different languages are useless](https://www.reddit.com/r/golang/comments/7as4f7/why_is_go_so_slow/dpd0pqx/). - In real production code, only profiling can tell where the program is slow and yes, you never know where the bottleneck is until you profile.
This project is still incredibly useful
Is there any reason to use a "framework?"
No reason to not have the option of someone doing that for you, though. I like, that someone is simplifying vanity-domains and thus counters some of the FUD around them :)
Oh neat! Can you aggregate across sources? Is there a way to do incremental, only recalc on new entries?
You have clearly never been to /r/badcode
Nice! The next iteration could be a re-write in Go (= cross-platform)... (Or does someone have a powershell-to-fish converter around?)
https://www.reddit.com/r/golang/comments/7bcf8l/after_reading_about_go_list_i_made_a_small/ Here's a potentially useful project that could do with a go rewrite :)
!redditsilver
###[Here's your Reddit Silver, icholy!](http://i.imgur.com/x0jw93q.png "Reddit Silver") *** /u/icholy has received silver 1 time. (given by /u/titpetric) __[info](http://reddit.com/r/RedditSilverRobot)__
sweet
https://en.wikipedia.org/wiki/Therac-25
**Therac-25** The Therac-25 was a radiation therapy machine produced by Atomic Energy of Canada Limited (AECL) in 1982 after the Therac-6 and Therac-20 units (the earlier units had been produced in partnership with CGR of France). It was involved in at least six accidents between 1985 and 1987, in which patients were given massive overdoses of radiation. Because of concurrent programming errors, it sometimes gave its patients radiation doses that were hundreds of times greater than normal, resulting in death or serious injury. These accidents highlighted the dangers of software control of safety-critical systems, and they have become a standard case study in health informatics and software engineering. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
For a parallel `find` replacement that's actually faster than `find` you should check out `fd`: https://github.com/sharkdp/fd
Sure. One simple approach to this is by cutting partitions per hour or whatever from your original data and then running these mapreduce jobs on these partitions.
I think it is very reasonable for most people to settle on using the standard library and assorted libraries to meet specific needs in the end. Nevertheless, I personally found Gin very helpful to get started quickly about 4 years ago. At the time, I had minimal experience developing webservers in Perl and no experience in Go. My colleagues, who had minimal web experience, had developed a Drupal (PHP) site that took seconds to load. I rewrote it in two weeks using Gin and got &lt;50ms response times with minimal effort.
my question now is, is there any performance sacrifice made by using a framework like Gin compared to standard lib?
LB +Docker Containers for me 
I'm not sure I'd call go-yaml abandoned per se... but it definitely needs maintainers that have the time to go through every PR and issue.
Exactly my thoughts. I would even offer my help maintaining the package, but I couldn't find any info related to that being a possibility.
I actually lolled and then "oh that's terrible". Not the intended point of the article however.
a comment or question alongside your link would be helpful to unterstand your intentions. you're posting old stuff all over this subreddit and never comment on it or ask something. looks like karma fishing to me 
[removed]
in a docker swarm
Easy password is to gain access to the web pages and reconfigure automatically the router. This is a risk indeed. Biggest flaw is when these webpages listens on the wan interface to allow the attavk to occur.
Never comment on anything? Maybe check again
We package them as RPM‚Äôs ( we‚Äôre ) on RHEL based OS.
Currently Papas. More specifically - Heroku. 
I use it on almost all my projects. If there's an alternative I'm happy to hear it.
The newest PowerShell is cross-platform and afaik open source. The script above works just as well on my Arch Linux.
... almost never ‚óî_‚óî at least in your five latest threads on /r/golang you didn't provide a question or comment without explicit request (this thread) 
Nginx - never docker I hate it for production
In Docker, using http://rancher.com/rancher-os/. Behind Caddy, mostly to get letsencrypt and static files serving.
So do we (on CentOS) (well, for our only application we wrote ourselves :).
Is it necessary? The whole point of Reddit is to share stuff you find interesting. I came across most of these tools recently and given that they haven't been posted before why not submit them, no? I'm guessing you're a seasoned Golang user who is familiar with all these tools?
[removed]
[removed]
As a self contained binary inside a Docker Swarm Service (FROM SCRATCH) and behind Traefik.
On an alpine image running in a kubernetes cluster
How so?
[removed]
Wow, didn't know that. But it [appears to be true](https://github.com/PowerShell/PowerShell)... Guess I'll have to check this out...
I know the maintainers well, I'm pinging them, and we'll see what we can do. Since this is basically the canonical (heh) yaml library for Go, it needs to be well-maintained.
If Reddit doesn't say it's a repost, I submit it. That's what I go with. But yes you're right, I should slow down a bit
I think the question is why anyone would want to read or write powershell by choice. I've provisioned machines with it, but I really hate using it due to the way that it's more a shell script than a programming language (in error handling and string manipulation etc)
Talking about the link itself
[removed]
could you elaborate why you've chosen rancher over coreOS?
[removed]
[removed]
Reddit has an automatic repost detector?! If so it's not working :D So a quick search on your hand before posting would be favorable 
&gt; I want to build my package on a different machine, I would run into that machine not having my patched version of the package You can put the package in the vendor sub-directory at the top-level directory structure of your own package.
I could be wrong, but as I understand it, rancher has a nice UI and scheduler and can use kubernetes or other back ends. 
Yes it does. If this was a repost you'd see an "other discussions" button on the link toolbar
Yeah okay... so it didn't trigger on your end because last time the gin homepage was posted - not the github repo directly advise still applies (or even more so now): please do a quick search before posting. there are tons of posts about gin. so if your intentions are as stated (to get opinions) searching existing discussions is far more effective than waiting for comments
Honestly, being written for go but using powershell is just kinda head scratching.
Don't forget the sharing part. Could be good as a reminder. I know I'm going come across as stubborn, but I'd rather post it and it gets downvoted than search by keyword everytime I want to post something. No one has time for that. That's what the downvote is for. The community decides what gets to the frontpage and what gets buried
sticking with the stubborn theme: - sharing is not needed as it already has been shared - so no developer needs a reminder for a lib or a tool in this case. you either know it or you look for something helping your case (maybe via search ;) ) 
Scratch docker images behind nginx. Mostly that setup is because I run other apps written in Python/Django and Elixir as well, so a standardized docker setup is useful just to keep things simple (and moving towards Kubernetes). I don't feel like nginx is necessary for Go apps but again, it's nice to keep that part of the stack standardized (common letsencrypt setups, common logs, etc.) I also run some stuff on GAE. That's been nice for small stuff.
Thanks for the answer! I am actually doing that at the moment but I wanted to use a fork of the original package, which would have a different path. To try to solve this I used dep and added a source property to the package which points to my patched version, though because I did not directly depend on go-yaml, but gin did, it didn't do the magic for me. It seems that it's only doing a shallow dependency management and does not really take care of chains as much.
hahaha this is getting ridiculous. You persistent bastard I'm sure the submission is useful for lurkers who are considering their options when it comes to go tools. I was a lurker some few months ago and if I had seen a post like this, I'd have noted it down and gotten the general consensus on tools like this from the replies if any Please let's end here ;)
For a junior development my advice would be to learn "meta" things, so that learning go will be much easier. I'd suggest learning ANTLR, for example (https://pragprog.com/book/tpantlr2/the-definitive-antlr-4-reference). Learn that and you'll have a solid understanding of the concepts of syntax, semantics, abstract syntax trees, and start to understand some of the *why* and *how* behind Go. Learn enough language meta concepts like the ones ANTLR would teach you and then learning a new language like Go will take you a week or less instead of months. That's just my 2 cents. I took a stab at learning go when it first came out but struggled. Years later after learning more about programming language design and theory it was quite easy to learn. I also then could *appreciate* why things are the way they are in go.
Go, like any other language, is a tool. It has places it is useful and places its not. When I picked it up, I'd been using backend JS for work (not Node, but I knew Node). Go suited my needs for a side project in that it was fast and worked at a much lower level than Node. I have never used Go at work. There aren't a lot of Go jobs near me and because Go has some controversial aspects I consistently get asked by people who haven't used it questions like &gt; bro why use Go Google doesn't even do it (not true) Or &gt; bro it's statically typed why use it Or &gt; bro it's so verbose why do you use it My point isn't anything about Go itself, but that it fits into more niche areas of development and so a lot of people have confused or incorrect opinions about It, and some just don't know much about it. If you're looking to learn a language deeply, i'd continue with Python for now. Google has a python-to-go transpiler called Grumpy. That would be a good way to integrate your python Knowledge Into the Go space. Your job prospects will more immediately improve with Python knowledge. Once you're more comfortable with any single language, you could start to pick up Go. You seem early on on your career and IMO the best thing to try to do is to master something. You already have python exp, so I'd focus on that. Again, not bashing the Go language or saying it's not worth learning, just saying that it seems to me your best choice right now is to hold off and focus on expanding what you already know. Another point to consider is that Go takes some unique approaches to things and lacks what you're probably most familiar with regarding OOP. Not that those are bad things, but the knowledge you gain from learning Go doesn't map 1-1 with many other languages. If you know another language really well, you may have an easier time understanding the motivations of the Go lsnguhe
although i'm enjoying a good discussion i'll keep it shut for now. have a good night (or whatever your timezone currenty has to offer)
I half agree with this, but i'd suspect that learning a language well enough to understand design choices and flaws in it lends itself to the same kind of understanding. If he focuses on what he already has skills in, he'll improve his existing skills as well as gain a foundation to be able to utilize Go well.
That's nice of you. It's a great package in general imo.
&gt; I'm not that great at any language and I feel like i keep succumbing to the problem of switching languages without actually learning one language in depth enough. I thought so as well when I was a beginner, but that's only because I had no clear picture of which language I really wanted to use in the end, nor where I wanted my career to go. Now I think back on this as a really great time where I learned a lot of different things, and broadened my perspective on things. &gt; Would it still be worth it to learn go? It's always worth it learning something new! &gt; people love it Irrelevant. Are you interested in learning it? &gt; I feel like because I'm such a junior developer, almost anything I learn will be beneficial I couldn't agree more. Learn as much as you can, keep your head spinning! As for point c: Go is just another tool, it depends what you apply it too. I tend to think that APIs/ backends written in go are more manageable and more focused, but there's a lot of personal bias in that. However, it is factually true that Go is very well suited to this kind of task, so in the end, if you do choose to learn it, I think it won't be a loss anyway! 
[removed]
What kind lf backend js was that?
behind nginx, regular scp of binary. Runs as an upstart service, use https://github.com/jpillora/overseer for graceful restarts. If you get into docker because "others do", please really see if it will make your life easier
That is why I've said you datastructure is not HAMT. But I didn't say it contains bugs. Most probably, it works. It is just not HAMT.
Single binary on CoreOS
&gt; If you get into docker because "others do", please really see if it will make your life easier Very good advice. Furthermore, be careful of what you're using if you don't understand the concepts well. Ie, I don't understand the low level implications and most importantly debugging of containers. I've seen plenty of issues regarding Docker, and while this may not be a "problem" with Docker, it's a problem for me. I can't debug the issues, and more importantly fix them. Or rather, I can't afford the time to spend debugging that type of thing. So if it's for learning, by all means go nuts. But if this is production, take great care in the known-unknowns, as they're likely to haunt you at one stage or another.
Go is a pretty simple language. With a little experience in other languages you should be able to pick it up and start being productive in it pretty quickly. It's not the investment something like, say, C++ is. And you'll learn new things from it - what is different in statically-typed compiled languages as opposed to interpreted / scripting languages for one. That sort of thing makes you a better developer, whatever language you're using.
Learning Go has made me a better programmer. You have to pay attention to types and you have to really think about what to do with errors. Using concurrency requires thinking in a new dimension.
If only channels could work with the fabulous G type ;)
Behind nginx. Nginx acts as SSL termination, static assets server and reverse proxy to * Go API servers * Node/React server-side rendering
Platform called Service now, it's their modified version of the Rhino is engine, and Java if you need faster/more advanced functionality in some places.
same
https://github.com/tockins/realize
You probably shouldn't choose your strategy based on a popularity contest. I have binaries copied with ansible, binaries copied with Makefile's, deployments with rpm, containers (Alpine Linux based) running in Kubernetes, containers "just" running under Docker. All serve a purpose and fit the particular environment.
Go is not essential for a front-end developer or mobile developer, but it is pretty much becoming the standard for cloud (Docker and Kubernetes are written in Go, for starters) and much serious backend work. I think it will usurp Python for many workloads, it certainly has at my company.
docker image built and pushed by jenkins to k8s
Binary directly on OS, but migrating to alpine on kubernetes.
This is a poor article with bad examples. The first example fails to communicate errors into the exit status of the process. It outputs the error message on stdout, not stderr. A little further down, an example type asserts to `*net.DNSError`, completely oblivious of `net.Error`. Next up, the glob example fails to handle errors that aren't `ErrBadPattern`.
We do the same at work (CentOS). Mostly this lets us put some config and the like on disk and init scripts know how to leverage this.
Similar for my personal stuff. SCP to a digital ocean instance and have it behind nginx and use upstart. 
&gt; fastest response (JSON, JSONP, XML, YAML, HTML, File) rendering ... it calls the underlying libraries just like everyone else, ain't any faster. This seems to be literally a collection of helper functions, each under 10 lines, of which you will likely only need one. It's better to write that helper function than to use this library.
some services are deployed as an RPM, but most are packaged Docker containers
I don't think RLIMIT_RTTIME does what you think it does. What are you actually trying to do?
Multi stage builds remove most of the reasons for building outside the container
üáπüá∑üáπüá∑
Why Alpine instead of scratch, out of curiosity?
So, at first I was a bit confused because I'm so used to naming my http request `r`, and it took me a minute to realize that in your example you were naming yours `req`. Not sure which is more common, but if it's `r`, you may want to consider renaming the renderer to `rndr` or something. My second thought was that this could be really handy...I often respond with atleast two content types: binary (protobufs) and json (for humans to easily enough poke at a service). I also tend to use html/template to provide a shitty web ui for services to expose some of the internals to humans. My third thought was the realization of what you _lose_ when using this: composition. For example, it really gets in the way of something like computing an etag from the response body for caching (Maybe i shouldn't be doing that? io.MultiWriter to a bytes.Buffer &amp; md5.Hash is pretty handy for that). Maybe not always a problem, but it's a real trade off. I suppose it's still possible to use something like a http.ResponseRecorder to capture the headers and body and have an opportunity to augment them...not particularly desirable though. Doing a quick peek through the code itself: - `Render.File` reads in the entire file in order to call `http.DetectContentType`, which only uses the first 512b at most. Probably better to use an io.LimitReader to get the first 512b, and seek back to position 0 on the file. Materializing the whole file in memory is gonna be a bad time on larger files. Hope you find those thoughts useful, and have some fun hacking on it.
You can add go-yaml to your project explicitly with this in your Gopkg.toml: required = ["gopkg.in/yaml.v2"] I'd presume that that directive, in addition to your source property, would take care of you.
Very nice 
I wanna fuck with the website. So hot.
Main reason: Damn small images. If you build your go application inside the container that shall run the application, the final image contains the whole Go toolchain. This is unnecessary bloat. If you build outside the container, you save hundreds of MB of image size. Depending on the circumstances, you even might not need alpine (or any other minimal Linux env) as the base image, `scratch` is often enough. You still can build within a container, using a multi-stage build, as /u/Justinsaccount already pointed out. For any extra stuff your build creates, you can use COPY to move all you need from the build image to the final image. [Here](https://medium.com/travis-on-docker/multi-stage-docker-builds-for-creating-tiny-go-images-e0e1867efe5a) is a good introduction to using multi-stage builds with Go. 
Not the parent, but primarily because not all go binaries can be statically compiled. Most take a dependency on libc/musl and sometimes you have cgo deps.
In Docker, behind a load balancer
Be aware that there is Rancher the management platform and Rancher OS the host operating system. Both are independent of each other. [Rancher OS](https://rancher.com/rancher-os/) is based on a rather cool idea: Everything, even system services, runs in containers. Because why would you need more than that when the only purpose is to run containers? Fewer moving parts to manage, less stuff to learn, smaller footprint. I like that concept a lot.
Hi, You came have both stage using docker multistage building! Let‚Äôs check my repo : https://github.com/itwars/Docker-multi-stage-build BR
These examples are contrived to show the different ways by which errors can be inspected. Even articles from the official golang blog write to stdout as the point is to show how that an error has occured and not to be pedantic. Let me know if you need links for this, I will be happy to share. As a side note, glob does not return any error other than ErrBadPattern.
Start off with what you think is fun. If that (for this week or hour) is Go, do it! By trying out a lot of different languages, you'll learn to program, not language specific quirks.
That all seems like a pretty weird false dichotomy, I have no idea how to answer. My most common setup is "directly on the OS", but in a VM, *and* behind an HTTP load balancer.
Anything serious should be behind load balancer, it's not that the go/server would be too slow. But you need a tool to block, limit or classify traffic that does not need recompilation of main binary. 
How easy is it to replace the API request in this tool? For instance, I'd be interested in measuring zeromq/nanomsg/grpc calls instead of HTTP requests.
Map (ok) and range (_) please ?
Do you run Kubernetes with GKE or self deployed? 
[removed]
Private Flynn-Cluster: https://flynn.io/
This is full of bad examples for: switch, lambda, concurrency (whole section). Please ask for help before publishing such articles, pages or websites. People like me would always be happy to do at least a quick review and make sure fundamental issues don't get promoted as good practices.
[removed]
It's a very pretty site. Some nice examples overall, but there are some incomplete examples, and examples with poor formatting. * Hello world: You only have one return type, no need to wrap it in brackets. * Variable declaration: you can also do `var msg string = "Hello"` * Multiple return types: you're using named returned types here too, not sure if that's intentional? * Importing: maybe suggest here that you should use the grouped up option if you have more than one? Overall, this looks nice, and is a really cool cheat sheet.
While good advice, I would argue that Docker is worth learning - just in case people are reading this and thinking "well, I was thinking about learning it, but maybe I shouldn't bother". It's a fantastic tool, and if you know it well, you'll be a valuable asset.
To add to what /u/yackob03 has said, it can also make it easier to debug what's going on in an image if you need to, if you have a shell, and some tools in there. Alpine is small enough to not have much of an impact while being useful enough to justify using it.
why 24 up ?
Self deployed
[removed]
Cool. Enjoy, then :) 
No need to thank me :) 
Thanks for your compliment. 
But for newbies and getting started this is awesome. :) 
Could you share your experience pre/past Flynn with us, how does it perform and overall what do you like about this PaaS ? Thanks
What about required? I would make required ‚â° not a pointer, while the pointer field means optional value.
Behind a Google Cloud load balancer, which takes care of SSL termination before sending the request to the servers running docker containers. The containers themselves are alpine images with go binaries. I've also used nginx, caddy, and other combinations before settling on the current approach.
[removed]
You can not, in current implementation, nested structs(pointer or not) will be parsed how required and exclude other structs. But if you are interested this, i could do it.
The way I've solved a similar problem is by making html templates that render the content I want, then printing them to PDF using [SebastiaanKlippert/go-wkhtmltopdf](https://github.com/SebastiaanKlippert/go-wkhtmltopdf) This makes the actual PDF generation code quite small, and it lets you work with regular html templates and css for crafting your document, which in my opinion is much easier (and in my case, let our front end devs take care of all the CSS stuff). 
Hi there, We use PrinceXML as external utility to generate PDFs from a html source https://www.princexml.com. This works really well and the PrinceXML system has some great additions especially in respect to hyphenation and block text layout. It can also render svg and execute javascript when creating the pdf. So it is really easy to create awesome reports with charts using a javascript library. Unfortunately it is rather expensive. But depending on your budget, it might be a very good option (it was also used by Google for quite some time). We have ben using it in production for about 2.5 years and had no problems at all. Another free option would be https://wkhtmltopdf.org, which is open source. We are currently looking into this, but did not yet have the time to properly evaluate the capabilities.
Good luck! May I ask what you intend to do once you found one? Publically shame the author? Please don't.
Less moving parts. In RancherOS, docker is pid 1 and everything is container (even userspace docker runs in a docker container). There is no systemd, no etcd, no fleetctl, etc. You just write docker-compose* file, stuff it into the system and voila! In think of it somewhat as taking the CoreOS idea and pushing it even further. In fact, one of the services that now runs on RancherOS was migrated from CoreOS and with the latter there were several outages caused by one of the above (etcd, fleetctl, ...) somehow deciding to stop work, nobody knows why (full restart usually helped, until next time). *) But mind that they do not fully support the current format. One major caveat is that you cannot specify networks for containers to join to. It's on the roadmap of course, but it's something to keep in mind.
This would be great. Most such libraries and tools in Go (I didn't try Cobra though) doesn't support "required" field while it is actually needed in some circumstances.
True. Rancher itself looks nice, too, but I do not have large enough deployments (in Go, and in the company we have vastly different setups) that would justify using it. I just use the OS.
This genuinely made me to click :-].
Hey, nice pkg. One question, what's the point of Logger being returned by SetLevel function?
I would argue that if your code is missing tests, you're not following conventions, it's messy, maybe a little buggy, etc. then no matter the context, that is still bad code. The thing that changes is how much you care about how bad your code is. I'd go as far as to say that most code, if not all code is bad code, just to varying degrees. If you're making a prototype, then who does care if the code is bad? If you're writing some code to take humans into space, and their lives depend on it, then your tolerance for bad code will be much lower...
Nothing wrong with dependency injection to invert / abstract dependencies - Go's interfaces generally make it lovely. If you use mocking, you might deserve it though ;)
Yea, agreed. I know it well enough to use it, just not well enough to debug low level horror stories I've read many times. Which, is not something I want to deal with in production haha.
Rather, I want to learn from it and use the ideas in my own projects.
wrote a tool that generates a directory tree of HTML files with the meta tags for a GitHub repository: https://github.com/nishanths/metaimport
I always forget in for-range loops, which comes first, the index or the element. You might want to add that.
[A nicely written testing framework.](https://golang.org/pkg/testing/)
Personally, I find the 2 app approach to be very simple. In my dev environment, I just do `./app` and in prod, `./app | funnel`. That's it. Nothing much to it. The advantage ? I just have to log to stdout from my app. No more messing around with global file handles, rotating them, removing old logs, gzipping them etc etc. Its all boilerplate stuff. I don't have to write it every time I write a new app.
I can recommend http://prawnpdf.org/ It's ruby, but there's no better alternative for it.
Replace that pointer example, it's a bad practice. You're basically returning the address of a variable that goes out of the scope and at the end you're left with a dangling pointer...
This post is two years old and it strikes me as written by someone that has barely used the language. There's one straight out wrong assertion - that go has pointer arithmetic. That's false to the point of absurdity.... go specifically does *not* have pointer arithmetic (i.e. incrementing a pointer's value to move the pointer to another location in memory), in order to avoid unsafe memory access. In addition, one of the other cons is pretty patently false, at least in 2017... the con of not having a strong ecosystem. The ecosystem is a pro these days, if you're doing the kinds of things that go is made for, i.e. CLI tools, networked servers, or APIs. 
I remember it as matching what you see in an assignment: m[key] = value a[idx] = value for key, value := range m or a I see the logic, even though in general I'm more likely to want to range over values than indexes, especially for arrays.
Thanks! Handling options in a way that was flexible and language agnostic was one of the biggest motivators for the project, since I haven't found anything I really liked out there. Orbit looks really cool. Definitely a great way to leverage Go templates to get something user friendly.
No, it's not. Because Go is garbage collected, it is perfectly valid in every way to allocate something in a function and return a pointer to it. The technical detail is that the compiler will observe during the escape analysis phase that the value escapes, and will allocate it on the heap, but that is an implementation-level detail, not a language-level detail. The [language specification](https://golang.org/ref/spec) doesn't include a concept of "stack" or "heap" at all. I recommend completely forgetting everything you know about C pointers when it comes to Go pointers, as the differences are so big that C will do nothing but trip you up. Go pointers are much closer to C++ references than C pointers, and that's not 100% accurate either, but it's closer.
It seems to ignore the constraint when I specify the package as required. I'm not too familiar with dep yet, sadly.
Yeah but, This created in mind of beginner proof :)
I tend avoid direct pdf generation from my code since it's usually a pain. What about generating something in one of the input formats supported by [pandoc](https://pandoc.org/)? You could write your data into a markdown file (or LaTeX if you need fancy stuff) and then convert everything to pdf.
I recently tried Prometheus, and I was really disappointed. It's not exactly clear what its intended use-case is--it has an odd model of collecting data--the client libraries make decisions about the presentation of the data (whether it's histogram, summary, etc); it supports *some* plotting/dashboarding, but very complex and limited; it also supports alerting. The limitations leave me feeling like it's really just a timeseries database and you're really supposed to use other tools for plotting, data collection, alerting, etc. If anyone has other experiences, I'm happy to be corrected.
Sure. It's super easy to setup and most of our applications just work with it as they already were mostly Heroku compatible. It offers us HA for the applications and for the buildin data appliances: Postgresql, MySQL, Redis And that for basically zero administration costs. Drawbacks: Sometimes it just kills itself. We remedy that with hourly full cluster backups. It is one command to make a backup of the whole cluster including all data. Features I would love to see and which are anounced: - Automatic HTTPS via Letsencrypt - User and rights management In the last weeks, the development of Flynn seems a bit stalled though. :(
Thanks for your answer. I'm give a closer look for personal projects. Out of curiosity, do you use anything else than govendor for your go apps, as it seems the default in Flynn.
&gt; the client libraries make decisions about the presentation of the data The developer of the instrumentation makes this choice, the client library merely provides the APIs to allow them to do so. &gt; it supports some plotting/dashboarding, but very complex and limited Grafana is recommended for dashboards. The in-built expression browser is more for ad-hoc/debugging work. Where exactly are you running into problems? 
&gt; Google has a python-to-go transpiler called Grumpy. That would be a good way to integrate your python Knowledge Into the Go space. Your job prospects will more immediately improve with Python knowledge. Once you're more comfortable with any single language, you could start to pick up Go. &gt; I actually really like what your saying about mastering one language first so i think I'll do that for now and maybe come back to GO a year from now. Thanks!
Yes, we mostly use glide.
Mostly I just want a fast/easy way to collect performance metrics and build dashboards/reports. I'm not sure if my use case is poorly suited to Prometheus, or if Prometheus just has a steeper learning curve than I was expecting.
It definitely isn't a looker. The way to go, as bbrazil says, is to use Grafana. It's much the same as an ELK stack--Grafana isn't the interface, it's the data layer.
&gt; Grafana isn't the interface, it's the data layer. Pretty sure Grafana is the interface and Prometheus is the data layer...
Ah yes, sorry fumbled my wordybits. 
Yeah, the wordybits are the worst. It sounds like I misunderstood the marketing then. :( So for my use case, should I pick Prometheus + Grafana or Influx's Tick stack? I'm not remotely concerned about performance yet--ease of installation and ease of use are my priorities. Specifically it's important that I'm able to rapidly add instrumentation and build out graphing/reporting facilities, preferably with minimal learning curve.
I don't think it's a good fit for that, as you discovered. In my experience with it, you dive in and set up a bunch of open source exporters (programs to get data from other software, like Apache or Postgres, into prom), maybe some custom instrumenting , then you import some pre-built grafana graphs and copy them to make your own. When you're done it is two months later and you have a useful mess. Then you figure out what worked and start from scratch with just parts that worked for you. It was worth the trouble for me and my company, but it takes time.
So uh.. can't really see shit captain. https://i.imgur.com/Tf0Qc0r.png
Can I ask what we're poking fun at here? I don't understand go enough to know exactly what you're saying is wrong. Sorry just really confused
Prometheus + Grafana. Skip Influx, it would be redundant alongside Prometheus (though you can add it into the mix later if you start collecting other stuff). Just wire up Prometheus as a backend for Grafana--once you have that set up getting dashboards built is straightforward.
I wouldn't do it alongside Prometheus; I would use it *instead of* Prometheus. The differentiators I care about are ease of install, ease of graphing/reporting, ease of instrumentation. I'm very interested in comparisons between these two stacks in this regard.
Just to summarize some of the other comments: Don't use actual PDFs as templates, use some intermediary instead. *(HTML seems like a reasonable choice)* I recently spent 4 months writing a layer on top of a PDF rendering library in order to extract and recycle all of the data within (with enough fidelity that you really could use a PDF as a template). It was a monumental effort, and that was just for the bare-bones feature set. The reality is that nobody except Adobe fully supports the 1.7 spec with all extensions. Foxit, iText and pdfbox are fairly close, but they are neither Go, nor easy to use, nor free (with the exception of pdfbox). *Oh, and pdfium (a fork of Foxit maintained by Chrome) is free, but extremely difficult to use. Depending on your licensing requirements, PoDoFo and Poppler (both open-source) could also be used to read and understand template PDFs, but their feature set is more restricted. Plus, I'm advising you not to use template PDFs, so you should probably ignore all the stuff about library support other than to know that it's daunting.
&gt; As a side note, glob does not return any error other than ErrBadPattern. Do you think that makes this a *good example*?
Escape analysis in the compiler automatically allocates any pointer that escapes the local scope on the heap.
[removed]
Browser problem? https://imgur.com/pLFUTWP
I didn't say it's not going to work.. it's just that authors shouldn't use bad practices in examples..tbh I stopped reading the cheatsheet after seeing that example... Best of luck ;)
Please edit that example or use something like this func getPointer (int a) (myPointer *int) { return &amp;a }
Has Prince's accuracy improved lately? I recall testing it out like 6 years ago and HTML looked not at all accurate. I eventually fell on EvoPDF to go from HTML to PDF and have had nearly no issues ever with it looking bad.
Yeah, you are right. I've got Chrome blacked out (so new tab bgs are black too) but that means sites that don't set an explicit background color have a bg of black. Sorry for the noise, cheers :)
Prometheus is absolutely a time-series database. It's just one that is able to poll from multiple sources, and which supports alerting. Prometheus is specifically targeted at monitoring from the ground up, which is why it's poor general-purpose time-series database. For example, there's no way to partition a Prometheus database into multiple "collections" (it's all one big namespace), and there's no way (last I checked) to programmatically push data into it. As other points out, Prometheus isn't really a UI. It comes with a UI, but it's completely perfunctory, and not intended to be the main UI. There used to be an official UI called Promdash, but it's been abandoned in favour of Grafana. It's absolutely fantastic at what it does. Grafana not so much, and the integration leaves a lot to be desired, but it's not outright terrible, and it's probably the best we've got right now. 
Yeah, it's called scripting. E.g. bash, makefile etc.
Ah, got you. I'm kind of torn on how strict a cheat sheet for people learning basic syntax should be. Anyone who has already learned a couple languages can get their basic syntax from the "Effective Go" doc and the language spec. I'm guessing this cheatsheet is aimed at people who just want to learn enough to get started without a programming background. You don't want such newbies to learn terrible habits, but you also don't want to info-dump a ton of stuff that is just going to be confusing.
Well summed up
I don't think that dependency injection is a bad thing in Go, in fact, the interfaces, closures and other things make it particularly easy and effective. Decent built in unit testing support means that you really ought to be doing something to make a package testable in isolation, and inversion of control techniques and DI are good for that. The flip side to this is that you really shouldn't need mocking - your interfaces should be small, and ideally lend themselves to being replaced with relatively simple stubs. If you feel you need mocking, it might be a sign of problems with the code design that make it hard.
This looks great. As far as i saw i should be able to 1. Generate the template to a buffer 2. Use that buffer as stdin for wkhtmltopdf 3. Let wkhtml2pdf save the pdf to file 4. Serve the pdf What i like here is, that wkhtmltopdf does not need to make a https request to the application, so no authentication etc needs to be done. Also the application (more specific the it infrastructure) does not allow to make https calls from inside the server to the server (big company with big restrictions)
Thank you all for the responses. I will have a close look to all hints( Õ°¬∞ Õú ñ Õ°¬∞)
If you're wiling to pay just use Datadog.
Correct. I just keep the binary of wkhtmltopdf in a `bin` folder, and call it on the fly when necessary, all communication is strictly between this binary and the application itself, nothing over the wire. What I do personally I generate a temporary, final HTML file, and use that as input, because in my case, I also use the produced HTML for emailing purposes. I think you've figured out the same basic strategy that I went for! Good luck with this, if you run into issues, shoot me a message and I'll be happy to share whatever knowledge I may have!
&gt; or example, there's no way to partition a Prometheus database into multiple "collections" (it's all one big namespace), and there's no way (last I checked) to programmatically push data into it. The usual way to approach this would be with labels. In such a setup you'd likely have each "collection" as a Prometheus, which would each have different `external_labels`. Doing it inside a Prometheus is also possible, but more fragile.
There's a [comparison of Prometheus to InfluxDB](https://prometheus.io/docs/introduction/comparison/#prometheus-vs.-influxdb) on the Prometheus website. Which is better really depends on the use case.
Indeed, but the commingling means that Prometheus also doesn't have a way to create collections (there's just one big bucket and it always exists), delete them, manage separate settings for each of them, manage permissions for them, and so on ‚Äî everything that a "database" would have. For example, in InfluxDB you have to create a database with `CREATE DATABASE`, and you have things like `DROP SERIES`. This is not a criticism, just an observation. Prometheus is less general-purpose than other databases. 
&gt; Prometheus is less general-purpose than other databases. Very much so. It's intended to do one thing, and do it well.
From a "jam things into a time series database and make graphs" influx and grafana have been pretty nice for me. I'm mostly using telegraf to get things into influx though.
That's a library, not a [framework](https://en.wikipedia.org/wiki/Software_framework). Specifically: &gt; Frameworks have key distinguishing features that separate them from normal libraries: &gt; *inversion of control*: In a framework, unlike in libraries or in standard user applications, the overall program's flow of control is not dictated by the caller, but by the framework. &gt; *extensibility*: A user can extend the framework - usually by selective overriding; or programmers can add specialized user code to provide specific functionality. &gt; *non-modifiable framework code*: The framework code, in general, is not supposed to be modified, while accepting user-implemented extensions. In other words, users can extend the framework, but should not modify its code. I'd say the `testing` package fails both #1 and #2.
**Software framework** In computer programming, a software framework is an abstraction in which software providing generic functionality can be selectively changed by additional user-written code, thus providing application-specific software. A software framework provides a standard way to build and deploy applications. A software framework is a universal, reusable software environment that provides particular functionality as part of a larger software platform to facilitate development of software applications, products and solutions. Software frameworks may include support programs, compilers, code libraries, tool sets, and application programming interfaces (APIs) that bring together all the different components to enable development of a project or system. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Yes, you can specify `GOOS` and `GOARCH` in your [run configuration](https://i.imgur.com/2k5yDsH.png) to target different platforms.
How does that answer OP's question? They specifically asked for a way to do it inside the IDE *with a similar experience to Android Studio*.
https://github.com/sirupsen/logrus
I can't agree more. I'm dealing with a system now that is absolutely awful to develop for because the dev environment spins up four different Vagrant VMs, each VM runs anywhere from 4-10 containers, and shit just stops working constantly. And by stop working I mean literally all or some of the services just stop working. The solution to this problem is to just run `vagrant destroy` and `vagrant up` again, which takes a half hour. There is absolutely no reason for this thing to even be using Vagrant. I was told using 4 Vagrant VMs to run Docker containers was the "perfect abstraction" for this situation because it gives them the isolation they want/need. I inquired more about the isolation, they meant network isolation. I don't think they even bothered to read any documentation about how networking works in Docker. There is no reason to use Vagrant. If you're not going to bother actually learning how to properly use a tool, if you're planning on using brand new technology while clinging to your old ways, maybe consider not doing it at all.
I'm writing a GopherJS bindings for most popular Cordova plugins, adapting the asynchronous javascript api calls to Golang synchronous style. Some documentation is missing, but it can serve as a reference to make idiomatic GopherJS bindings. https://github.com/jaracil/goco https://godoc.org/github.com/jaracil/goco 
thanks. im definitely missing some things like error handling too - i'm just not sure what other errors i can check for yet (one i can think of is if the length of any of the values in datasets is not equal to the length of the labels)
For the x-axis labels why not just use strings? Just convert numbers to strings.
&gt; go has some much cooler "unknown" features than these This comment would be much more helpful if you shared same of those :)
The testing package calls functions that you give it... isn't that inversion of control? 
Is this really bad practice though? It's even used in a the standard library, and well documented. https://golang.org/src/bytes/buffer.go?s=14336:14370#L443
yeah i decided to use str labels now while providing a helper to convert int labels to strings
Mhmm, I decided to use string labels now while providing a helper to convert int arrays to str arrays for people who would prefer to pass in an array of years by int.
Well, that's not the same case. The struct is kept globally and it's not going out of scope anytime soon..
Not if it teaches them the wrong thing.
I think it can be quite a bit more simple than that -- and thinking about it, the seek should be albe to be skipped ``` b, err := ioutil.ReadAll(io.LimitReader(file, 512)) // read upto 512b from file if err != nil { // handle error } mime := http.DetectContentType(b) // set mime headers // ... // send the content to the response reader := io.MultiReader( bytes.NewReader(r), // reuse the bytes that have already been read // read the rest of the file, no need to touch its current position. // If the whole file's already been read, it should just be returning io.EOF file, ) _, err := io.Copy(w, reader) ```
IMHO, of all pdf rendering possibilities, only LaTeX does its job well. As starting point I would suggest you my small [latex-to-pdf ¬µService](https://hub.docker.com/r/dim13/gotex/).
Unless I'm missing something, the only difference is using an intermediate variable. It's the exact same case.
We have been using prometheus in production for over a year to monitor our online service and i have to say its really great. We love discovery system (inventory), that alerts use same queries as graphs and that its fast and reliable. A bit slow to understand completely but once you get it and have that aha! moment you see its modular approach and data collection methods are really worth the time. But again if you just want to monitor few things like cpu load on 10 servers there are easier plug and play alternatives.
Wow tnx for overseer!
What exactly are you trying to achieve? What's the purpose of the website and the back end for it?
It is a torrent downloader with a single page webui frontend. The back end sends an update on progress every few seconds and also handles user input from the frontend.
 The first one returns the address of a local variable and the second one returns the address of a global variable. In the first case you'll have the address of a variable that will get cleared out the stack at the end of the function, in the second case the structure won't get cleared out because it's global and will last during the entire program. Am I missing something?
Really good read, well done! Now it's the time for gophers to do something about those issues.
Actually this site sets neither a background not foreground colour; so looks like your Chrome extension thingy should set more explicit colours.
Are you saying After the function you won‚Äôt be able to access the value of the first one anymore because it was cleared by the stack...?
If you're building something to run in the browser, JS is really your best bet. GopherJS, while interesting, is going to have some issues. My brief play around with it produced massive, unreadable JS files. Kind of reminded me of CoffeeScript all over again. You can basically Google your way through building a JS app. You might have a harder time doing that with GopherJS. I'm not being mean to GopherJS here. I'm sure it suits some people just fine. I find using the *right* tool for the job at hand is easier. As much as I really love Go, using it to generate the right bit of JS just seems like hard work.
It goes to off-topic, please take a look here and feel free to google https://stackoverflow.com/questions/17997228/what-is-a-dangling-pointer
What's wrong with these specifically?
Why is it bad practice? It's [used a lot in the standard library](https://golang.org/src/bytes/buffer.go?s=14336:14370#L443) and is the default way of returning a reference.
Sounds like those "database" things were not considered essential for getting a monitoring product working. &gt; manage permissions for them https://prometheus.io/docs/operating/security/#authentication/authorisation/encryption &gt; Prometheus and its components do not provide any server-side authentication, authorisation or encryption. If you require this, it is recommended to use a reverse proxy. 
This is a really interesting article. For a business that cares about performance per watt I expect the pressure to switch platforms is building to the point where it can't be ignored. The next few years could be relatively bad for Intel unless they have a response stored away somewhere. (But they would never hold back technology just because they were already sitting pretty with 98% of the server market, surely.)
Instead of type switching, have them all implement stringer or something
Actually, i was trying to limit the execution time of the process that will be run with cmd.Run(). Am i missing something ?
Go isn't C++. The example in the standard library isn't returning "the address of a global variable". It's returning a pointer of a compound literal. Returning a pointer to a local variable is safe and idiomatic Go. If you don't believe me, and the other people who have said so, please feel free to look at the language spec, the standard library, Stack Overflow, and the mountains of extant code that use this idiom.
&gt; b) I feel like because I'm such a junior developer, almost anything I learn will be beneficial and a lot of the tutorials that I've seen on go require you to create things from scratch which makes it a good learning experience exactly, after about a week, you'll find a lot of uses for golang, give it a week, and you'll answer it yourself.
&gt; I would prefer something as simple as websockets to implement. Then... Implement websockets? It's literally as easy as websockets. And it does fit your use case of updating every so often. I know it's a crappy answer, but to be honest, Javascript just is the most direct answer here.
There are countless examples I‚Äôve seen of constructors being used where the returning object is built as a local variable then returned at the end of the function rather than inline.
Maybe it's not obvious from this example, but those structs can be anything. Stringer wouldn't be of use if you have 10 different values to configure.
It couldn‚Äôt be easier, IMO, once you understand the patterns. I have a GitHub repo for my Prometheus configs, and a drone CI job in that repo to deploy on commit. 
The http lib news up an instance of each type of error it will return and returns those. You can see [here](https://golang.org/src/net/http/request.go?s=12816:12870#L359) that the Cookie func will return the ErrNoCookie instance in the http package. So you can check if it's a the cookie not present error by doing if err == http.ErrNoCookie { // handle this specific error } 
Hey, It is not me the owner. So if you really feel there is something wrong then you can contact to the owner.
Wow, that was like a punch to the gut, when the Golang numbers showed up. But its good to hear its just about missing optimization on the ARM side.
The return value of the `Error() string` method is purely informative and should never be used for flow control. Errors come in a number of flavors and good libraries document the errors they return. The first flavor is errors like `http.ErrNoCookie`, `io.EOF` or `bufio.ErrBufferFull`. Such errors are effectively constants and are usually named `ErrSomething`. You check for them with simple equality, `if err == http.ErrNoCookie { // do something }`. Another flavor is like `net.OpError`, `os.PathError`, or `strconv.NumError`, which represent a type of error rather than an exact error. These usually wrap an inner error with additional information. Such error types are usually named `SomethingError`. You check for such errors using a type assertion, like so: `if perr, ok := err.(*os.PathError); ok { // use concrete information in perr }`. Finally, you have interfaces like `net.Error`, which are desirable over concretely typed errors, because they reduce potential coupling between packages. Think of the `net.Error` interface as being a piece of documentation for optional methods the errors returned by package `net` may have. If a type which implements `error` also implements a `Timeout() bool` method, the caller need not know about the package the error came from or its concrete type. A check like this is sufficient: ``` type timeouter interface { error Timeout() bool } if terr, ok := err.(timeouter); ok { // check terr.Timeout() } ```
Could try elm and websockets if you wanna dip into FP.
Don't call me Shirley. 
Very cool. Any thoughts on SQLite vs Postgres? I very much appreciate the simplicity and capability - and as such, the extensibility. Fun to be able to so easily "read" the code.
Yea, coming from a Python background, you will miss those list comprehensions. But it gets ok over time. And makes the code slightly more readable. Same reason why Go doesn't have ternary operators.
They had some cpu/fpga combo somewhere, that could potentially be a winner for power/performance. There is also Xeon Phi
I wonder if using GCC backend would make it any bettet
What exactly was Lips used for? My point was that GC languages can't be used for real time tasks and they consume more resources. Based on that article it seems that NASA ultimately ditched it in favour of Java due productivity reasons. Does that mean Java is the new shinny thing and we should all use on embedded development? I really doubt it.
The syntax is awful compared with Swift(i.e. semicolons, C++ like namespace :: , import syntax...not to mention the syntax complexity) and yeah two memory models would help both with the productivity and performance(where needed).
&gt; dedicated to perform certain functions efficiently The keyword is "efficiently". In my book that means optimised to death and that means no GC(most of the time). Otherwise there would be no difference between embedded and general purpose programming. Based on your definitions all the android developers are embedded developers.
I am not involved in that project, just found it on Hackernews. My personal opinion is that SQLite should be sufficient for low-traffic forums, but connecting to Postgres [does not seem to be too compilcated either](https://github.com/s-gv/orangeforum#options).
Ours support Stackdriver out of the box, logrus needs a hook and the only one available works by sending requests to the Stackdriver API, we simply send the logs to STDOUT and let fluentd take care of the rest. Our library is custom made to work on GCP. Other than that, we always try to minimize the amount of third party dependencies and the TelTech logger doesn‚Äôt use anything outside of the standard library, that is intentional and we would like to keep it that way.
Scratch Docker containers deployed via CloudFormation and ECS.
Excellent write up. I completely agree about comprehensions. I'm very used to comprehensions in Python and functional array methods in JS so when I have to write an old-school for-loop-with-accumulator in Go I die a little inside.
Go is in front so it can terminate SSL and use HTTP/2, running as a systemd service.
Goland (Intellij customized and slimmed-down for Go) is great.
go is not C
Intellij/Goland user here. I just took a quick run at VSCode and even after installing the recommended plugins it does not handle navigation as well as Goland. e.g.: click on a func that implements an interface and try "Find References"; it does not get calls to the interface func. To be fair I only spent about 30 mins with it, so maybe I missed something. Is this functionality in present VSCode?
Richer tooltips and help in general. The biggest one for me is that in vim-go, the function signature help is disappearing as soon as one starts typing in the arguments, while it shows continuously, which makes a big difference for funcs with many arguments. Also, the "go to definition" seems to work a bit more robustly. It has started to happen that go-vim won't find definitions in the current package but a different file (maybe something temporary, but I never had this problem in vscode). Furthermore: Seeing the docstring on anything by hovering over it with the mouse , and the "Peek definition" function, to peek at the definition inline, without leaving the current file. Etc.
As a supplement, you may enjoy my dotGo talk from last year which dives into this subject in a little more detail: https://www.youtube.com/watch?v=KdX51QJWQTA
In addition to GoSublime, try GoGuru. It's awesome.
You might want to learn from the standard library first. It is an excellent reference on how to test various things.
That's a great talk! Thanks for sharing, I've add to the post :)
I'm on linux, so AFAIK, VS itself is out of question for me. Otherwise, I like how VSCode is able to open a directory as a workspace (with fast file-finding etc) without the need to set up project settings.
Is this gonna be simpler for my mini personal app than auth via Github? 
To cite [the `setrlimit(2)` manual page](http://man7.org/linux/man-pages/man2/setrlimit.2.html): ``` RLIMIT_RTTIME (since Linux 2.6.25) This is a limit (in microseconds) on the amount of CPU time that a process scheduled under a real-time scheduling policy may consume without making a blocking system call. For the purpose of this limit, each time a process makes a blocking system call, the count of its consumed CPU time is reset to zero. The CPU time count is not reset if the process contin‚Äê ues trying to use the CPU but is preempted, its time slice expires, or it calls sched_yield(2). Upon reaching the soft limit, the process is sent a SIGXCPU signal. If the process catches or ignores this signal and continues consuming CPU time, then SIGXCPU will be generated once each second until the hard limit is reached, at which point the process is sent a SIGKILL signal. The intended use of this limit is to stop a runaway real-time process from locking up the system. For further details on real-time scheduling policies, see sched(7) ```
I think what you can do instead is 1. Spawning your external process, save a reference to its process into. 1. Have a goroutine monitor the process (say, using `Wait()` on it). 1. Schedule a timer event. 1. When it fires, terminate the process (via `Kill()`). If it already exited, the last step will fail, so be prepared for that.
No Eclipse fans here...
This seemed cool until I saw that it's all kicked off by a large-ish bash file. Why isn't that a go file that we can go run, at the very least? It eliminates 50% of the dev population by not working on Windows. 
Roger.
ARM is such a weird market. I'm excited for better optimization on ARM but it may be quite soe time before it trickles down to meaning anything on consumer boards like the Raspberry Pi. Even thought he Pi technically supports AARCH64 it is an early version and left out most of the more interesting extensions (like crypto acceleration!) 
Depends on some factors like your framework and available options, but at this stage of development AuthN expects you to build out basic signup and login forms. Auth via Github does not.
Interesting, but I would suggest including a couple of screenshots to whet the appetite. Needing to install something like this just to see it at all is a big ask. This is not a complaint; this is a suggestion in how to better market the project.
I believe its set up the same as as gradle/maven wrappers in java land. The script downloads and executes the go binary so that its not a requirement of the project itself, and will download/execute the proper binary for the given platform. Gradle/maven also have a windows version of the script which would be nice to see here as well, but it wouldn't be that difficult to add.
Just seems like, if this is aimed at Go projects, and simply wraps the go tool (thus requiring it).. just make the base script in go. I guess typing `go run godelw.go` is longer than `./godelw` But then again, if all the script is doing is bootstrapping the right binary, I could just as easily download the binary directly.
I was interested until I saw the node.js requirement. 
Lisp was used for the operating software the entire probe ran on. It allowed the software to be patched while it was running, remotely. The fact that it was ditched for Java doesn't really support your position either, because Java is also garbage collected.
Just commenting in here so I can read this later
Just wanted to give a heads-up after one year. I just now merged the `performance` branch I was working on that uses a different buffer in the back. Previously every character look-up involved checking if we are at `io.EOF`, which is slow. The fact that I implemented a circular buffer so that extremely large files could be parsed as well, caused the character look-up function not to be inlinable. Now I believe the circular buffer is not needed, all web files (should) fit in memory anyways! The current implementation appends a NULL at the end of the buffer, so that we don't need to check if we're at `io.EOF` yet. This caused a massive performance increase, as this was a bottleneck for most minifiers. Specifically JSON got twice as fast. HTML about 25%. Also checkout the roadmap in the readme, I plan to add a couple more features in the future. Additionally, I've created https://www.patreon.com/tdewolff so that I can increase my time working on the project and the new features. And as always, feedback is appreciated ;-)
I've used Python and Go on a daily basis for 5 years--I don't know that I miss list comprehensions, but I certainly would like some way to represent conditionals or operations on lists as expressions. I think I'd prefer `map()` and friends to list comprehensions, but I would prefer list comprehensions to nothing. I don't want to overstate the problem--it's a minor annoyance, but I generally prefer fewer minor annoyances.
I remember reading in some GitHub discussions that folks from ARM are going to be contributing various SIMD optimized assembly routines to take advantage of ARMv8 in the crypto and runtime space. I've seen a few commits to Go already for the 1.10 release cycle, hopefully even more to come!
You can see your own upvotes...
I think go makes you explore types really well. I mean []bytes ... Really? But you learn that everything has a cost. Even encoding and decoding strings so that they are UTF8 correct characters. Try reversing a string in go. You will soon see how little you know about mutating data. Then try to understand []interface{} and trying to really get a grip on types. This is all knowledge you would definitely not pick up in js or python, let alone js frameworks. You really have to understand your data. If you don't, then you need to stop what you are doing. However this takes a lot of time. You also don't get the quick return you get from a dynamic framework, but you get in-depth knowledge. Another one is initializers in for loops in go. Try to reuse those.
Uses YAML. Nope. #savedyouaclick 
vs code w/ extensions is rather helpful as well
Yes, I agree! The fact the it even underline things is also really great! I've mentioned it in the conclusion. However, I don't know the extent of integrated checkers in VSCode and I mainly wrote this article in order to make some visibility on tools which are unknown to some Go developers.
&gt; g√∂del‚Äôs architecture is similar to Gradle‚Äôs I had a terrible experience with Gradle the first and only time I used it. This gets a resounding **nope** from me. &gt; When teams started new projects, they would copy scripts from other projects and make slight modifications. This process was prone to errors and made it hard to push out updates globally at a later time. That can be a real problem, but if I encountered it, I would rather solve it in my own organization than adopt someone else's solution.
Did not know that
They're not SSL certificates. Let's Encrypt does not call them SSL Certificates anywhere on their site.
You‚Äôre right, I should have called it TLS. I still didn‚Äôt get use to it. But hey, have a second look at let‚Äôs encrypt page title :)
Well if you want to get super technical it's not a TLS certificate either. It's an X.509 certificate with specific extensions to make it usable for TLS (or SSL if you like running insecure protocols on your servers)
I was using goose. https://getgophish.com/blog/post/database-migrations-in-go/ I didn't like it as much as how knex handles migrations in node but it was ok. You should deff be using a migration manager. 
I'm currently working on better support for this in github.com/rbastic/dyndao - already there exists a layer where Go Schema structures can be determined using either an information_schema parser, or an Oracle metadata parser.
https://povilasv.me/go-schema-migration-tools/
I've recently started using github.com/mattes/migrate as a library, within my programs, and using github.com/jteeuwen/ go-bindata to bundle the migration scripts up.
I currently have a home-baked information_schema parser that generates table structs (to use with sqlx), where each table column is a type and implements, along with Valuer and Scanner, these interfaces (to facilitate custom queries, i.e., with squirrel): type Named interface { Name() string } type Column interface { Named Type() string NonNull() bool PK() bool FK() (Column, bool) Table() Table Validate() error } type Table interface { Named Columns() []Column } I made some squirrel CRUD helpers, but when trying to select from the database, I don't want to receive an `interface{}`, nor want to use `reflect`. After a while I just rolled with hand-made queries and copy-paste squirrel CRUD code.
The number of dependencies is huge and the project structure is unconventional. Besides that, I kind of like [mage](https://github.com/magefile/mage) approach more. However, some of the built-in tasks in `g√∂del` look useful.
I'm confused about your squirrel comment. I use squirrel and I never "receive" an `interface{}`. I pass my structs in to squirrel and squirrel fills things out for me. Squirrel _accepts_ `interface{}`, but that just means squirrel doesn't require any particular methods to be declared on the structs you pass in.
&gt; I would advice you to use staticcheck instead, as it is the same things but with many more rules tested. I'm definitely in the process of adding `vet` checks to staticcheck, but right now, you should run both tools.
&gt; Java doesn't really support your position either, because Java is also garbage collected. Well my point is that if Java is now the language to use for embedded development then embedded development doesn't exist anymore. It's just something that people used to do 30 years ago. From now on I will refer to that past thing that used to be embedded development as "real time" development to avoid "Java is used at NASA/SpaceX.etc"-like arguments. 
is this handling equivalent of try-catch statements in Java?
Ha! Nice to read. I've updated the sentence to be clearer that both tools are complementary, thanks for the feedback. Also, I take this opportunity to thank you for all the tools you made available!
What's wrong with yaml?
Or install something like Pocket
The `interface{}` comment was when making generic struct CRUD functions, like `getOne(c Table) interface{}` not squirrel.
OMG just had the sick as fuck idea of mapping copy/paste or something to foot pedals... time the get the arduinos out...
The best gets better. 
Dude. You're awesome. Thanks for working on this!! I hope that Caddy users will benefit shortly. I'll ping Hacdias.
Ah I see, my mistake.
heh; note that Emacs foot pedals *are* actually a thing already. See e.g. https://www.emacswiki.org/emacs/FootSwitches
[`mage`](https://github.com/magefile/mage) might come in handy here.
This is really nice. I just tried this out using Docker for Mac and it worked a treat - posted notes on how I did that here: https://simonwillison.net/2017/Nov/5/golang-docker-for-mac/#Running_commands_against_files_83
thats when I pass as well ha
Wow, Blizzard uses Go.
Game development has to be conservative about tooling because they rely on existing ecosystem more than anyone else - they usually have relatively small time to develop one feature, and unlike web developers the resulting functionality is extremely tightly coupled. That and the job market in which it's extremely hard to find competent game developer. That being said I personally hold quite a low view about game developers. Their solutions is usually sub par, they usually don't understand why things work that way or another if it doesn't have a direct connection with game development, their error handling patterns are bizarre (yes that's coming from Go developer), and their resulting skills are likely to be unnecessary anywhere but game dev. There are a few exceptions to this rule (Blizzard being one among them, tho not entirely) or even people who defy this (Carmack you rock!) but overall game dev code is bad even by our current "we need us much functionality as we can, will care about code later" startup oriented mindset. Than again it's mostly my opinion. 
Thanks for the explanation.
I am using it as well, i didn't pick it, just stuck at it. I think its a problem using git with it, because the versions are sequential. So if two programmers do migrations and runs them without pushing it could become out of sync. I was thinking about using https://github.com/syncthing/syncthing for fixing it, just a tip. 
@kostix Appreciate your answer.
I wouldn't be surprised--Go seems like it would be ideal for game servers.
Is this serious? A book for parsing JSON in Go? For $30-50?
tl;dw Summarizing the video, these people are aware of Rust, and they would love to try it, but they've each personally been too busy to do anything but keep churning out more C++ code. They mention that some smaller teams who are working on less critical infrastructure have had the opportunity to dip their toes in new languages, and they mention that one of these teams is trying out Go for a small, greenfield project.
Or press the save link on the post.
My favorite approach is the connection management per request. On the beginning of the request you open a connection, on the end back connection to the pool. 
Depressing graphs but &gt; Even a very minor change, such as implementing the function addMulVVW in assembly, lead to an over tenfold improvement in RSA performance, putting Falkor ahead of both Broadwell and Skylake, with 8,009 signatures/second. ... and it looks like that change will be in Go 1.11
test
Use the context method variants of sql.DB, pass in a request scoped context, and they will return when the request is done. 
Yeah, dyndao offers methods to cast / convert for your preferred type. It tries to hide away the interface{}s underneath the hood, but they're there if you need them. Reflect is only minimally used. I see the value in all approaches to Go and databases, there's no one size fits all. Is your code open source? Would love to take a look through it.
The Rust Evangelism Strike Force in full effect :)
I love that this minifier exists but aren't you competing against JavaScript build packs? Have you tried to see if you could get this integrated somehow?
You are close. This is what I'd do: https://play.golang.org/p/HaHIXPSo9K 
Ok, so you have to separate it out by defining the inner struct. I witnessed this in the documentation, but did not know if it was a requirement. This simple example you provided me helps out so much. Thank you!
It isn't required. But to my sensibilities it is cleaner. Sure thing, glad I could help!
I took your example and [added an additional disk](https://play.golang.org/p/3MWjij4ZMT), just to make sure I understood the structure. I realize I need to use ints, I was just trying to wrap my head around the concept, and this was the easiest example I could toss together for my purposes that did not involve fruit. :P
From the last time: https://www.reddit.com/r/golang/comments/77v3hi/a_golang_web_application_development_tool_it_aims/
The only thing that you're missing (if I see right) is that the `Storage` field is a slice of structs, but you're only assigning it a single value. Plus, you're not really assigning it, because you're missing the `:` symbol there. So, you need to properly assign a slice to a slice, and that will require you to duplicate the type definition. That can be worked out by defining the inner struct outside of the outer struct as shown in the other answer.
I will have to look into what your describing and see if I can make it work from your answer as well. Thank you kind sir!
Sounds good! :) I just didn't want to leave that part out. 
Especially instancing - short lasting game regions where a party does a dungeon, quest, scenario, or whatever. Go's concurrency would really help with that (not that I know this is what they actually use it for). 
Interesting. So if I understand this, the grada package collects data in-memory for some period of time, and presents an api that grafana can read directly? An interesting approach. I have wanted something similar, for maybe a slightly different use case. Some of my apps have a `/metrics` endpoint with prometheus metrics I have added around my code. But not all users, or all environments, have a full prometheus setup and dashboards and things. It would be cool if there was a mode I could switch on in that case that would store some kind of in-memory history of my prometheus counters, and present them to a little self-hosted dashboard thing.
I could feel the guy's soul leaving his body as soon as the dev mentioned using Go (and not rust) in Blizzard project(s)
Could you explain more about why DiskType and Size need to use another type instead of string and int?
If anyone is interested in go https://youtu.be/Az5F4lwSljI
If anyone is interested in go. https://youtu.be/cN_DpYBzKso https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Or bookmark it.
Rust dosen't solve any problems for them, that's the reason they don't use it. There is no "memory safety" problem in game dev. Rust would only get in the way in gamedev because AAA game engines are full of "magic" everywhere, magic that would require using Rust unsafe keyword in so many places and fight with compiler/borrow checker/type system. There is no tooling for AAA game dev in Rust, it's niche language etc. 
Imagine you have a slice (let's say the type is `[]item`) containing 5 `item` structs. It would be weird if `len(items)` returned `"5"` (a string) instead of `5` (an integer) wouldn't it? I find it useful to use strings, numbers, times etc as you would expect them to be used. So if size is a number, use an int or a float. In the case of size, what if you wanted to find the disk with the largest storage? You would have to convert your string to numbers. With size as a string, I could enter "I have the biggest disk in the world" and it would be valid. By using a number type for numeric values you gain a lot for free. 
Sure thing! I didn't say they needed to -- I said I might consider other types. For example: A disk's size *is* a number.. why not store it as a number? By storing it as a string to lose the ability to do math against it without making conversions (that's a pain). Another reason you might want to use a different type is to make your code more intelligible by using custom types that describe the type a little better. Here's an example: https://play.golang.org/p/uXG3d2reD7
Thanks. But looks like the question I asked was not clear. Let me ask again. My question is that for example, in case of Size, what is the benefit of using another type (with same underlying type), say `type size int`, and use like `type Size size`, instead of `type Size int`.
Thanks. My question should be "What is the benefit of using custom type?". Could you tell me more which cases can be used by a custom type? 
One reason is a cleaner more expressive API. If I were to see a field on a struct labeled "size" that doesn't tell me a whole lot. Whereas, a Size type that is clearly measured in bytes tells me everything I need to know. It also allows for custom `String() string` methods. (see the Size type in the example). I also use custom types to act as Enums. (see DiskType in the example).
They do not use Go for game servers AFAIK, but it might be in use for other backend infrastructure.
You aren't wrong, however, but I wouldn't recommend this. I tend to prefer concrete types instead of anonymous structs. It doesn't make sense to re-define the `Storage` field every time you wanted to use it. (See here: https://play.golang.org/p/HRWe6NKlQu). It makes more sense to me to break it out into a separate type. You end up with a cleaner instantiation of `config` and a re-useable type (`Store`).
&gt; Sadly, Go manages to do worse than other languages, especially when it comes to parsing time and dates. I have to strongly disagree on this. It is quite likely that the author needs more time with `time` to appreciate it. That package gets a lot of hate because it is so vastly different than any other language. Yes, Go is resistant to change but so is the author in this case. And if the author actually created that issue to change `time` and got rejected, would he then blame the Go community for being unwelcome? He has been unwelcome of `time` himself first. On a similar note, the last part about the Go community (while there's some truth in it), it reads to me more like "I can't get *my* way, therefore I feel unwelcome". Finally the author "doesn't lead by example" either. Instead of approaching the author of Mage to ask for a change or opening an issue or do a PR, he decided to call it out on Twitter in a not so nice way. Otherwise, this is a very good article with many useful resources in the links. I highly recommend a read. üëç
While I agree rust isn‚Äôt ready for AAA games yet. I‚Äôm far more bullish on it than you for several reasons. First I think rust is closer than you think. The Kronos tutorials for vulkan mention the rust wrapper vulkano as a recommended tool. The developers of starbound announced that their next game is entirely written in rust and supports all three major consoles. I frequently hear the claim that safety doesn‚Äôt matter in games. Yet there‚Äôs little data to back this assertion. The fact that people are developing embedded OSes (tock) with little unsafe code is proof positive that you don‚Äôt need unsafe everywhere. The number of bugs that ship in games and the fact that virtually every modern game, even single player ones, is connected to the internet it some way. Maybe we *should* care more about safety. In the future the optimizations permitted by rust‚Äôs alias analysis give rust a much higher optimization ceiling than C or C++. Move by default semantics, better reference analysis and tools like Send and Sync make it easier to write the optimized version first and avoid some hard to spot performance pitfalls that are common in C++. That said rust is missing a few key features for game dev. Stable simd, more compile time code execution, constexpr generics to name a few. Self referential lifetimes and better tools for working with struct of array data would be nice too. 
Ah, that's totally different. You'll need to decide how you want to represent your `Size` struct fields in that case. I'm not sure what the `size` type gets you. Maybe you're thinking about storing the unit in there as well ("mb", "gb" etc), but that would seem like complicating it. I'm guessing at your intentions here though.
Thanks for this, I have been playing around with this for far too long.
Really, just competing with the PostCSS plugin [CSSNano](http://cssnano.co/).
This post and the comments on it are a perfect example of why the Go community is considered dismissive and intolerant. Go and Rust are both just programming languages - tools, nothing more. Is it really necessary to criticize someone for asking a question?
I like it. :) I think it would also be really helpful to have a tool that detects unnecessary preallocations.
I'm a little confused by your terminology - what are you referring to when you say "connection"? You should not ever really be managing database connections yourself. If you're talking about the `sql.DB`, you should only be initializing that object once, near the start of the program after you've loaded configuration. Then Go will take care of managing actual SQL database connections for you. You should not manage them yourself unless you have a very special case or a database driver bug. You probably don't even need to close the connection yourself (although it is good housekeeping). If you're talking about database transactions, most people will open one at the start of a request handler and commit or rollback at the end, but it really depends on how you want to do isolation. (If you don't completely know what that means, it's okay, but you should do some more research on relational database basics until you do understand, because it's important.)
&gt; This workflow is the most relaxed I experienced so far. When discussing Go features, I like to say: I came to Go for the go keywords and channels, I stayed because of interfaces and a lack of features. +1
&gt; Is it really necessary to criticize someone for asking a question? Huh? When did I do that?
A large portion of Riot Games' infrastructure tooling and several back-end and player facing services are written in Go.
The advent series is one of my favorite events in the Go community!
Not you, read some of the other comments.
Saying *"I like this and think it could be a nice fit for you guys, you should check it out"* is zealotry now?
While it's nice that Blizzard uses Go, please let's keep the Rust-talk productive and friendly.
&gt; The developers of starbound announced that their next game is entirely written in rust and supports all three major consoles. I've read their reddit thread on /r/Rust and it was very interesting but starbound is an indie game, why are you comparing that too AAA engines and their workflow? There is a difference in a indie game that 3 people work on and AAA game that hundreds of people work on. Different scale, different problems. &gt; I frequently hear the claim that safety doesn‚Äôt matter in games. Yet there‚Äôs little data to back this assertion. Ask anyone that worked on AAA games you will get your data. 99% of AAA games are just patched when someone reads out of bounds, you heard about any security exploits in Witcher? Call of duty? Assasins creed? Tomb raider? GTA V? How many CVEs? I didn't hear about any. &gt; The number of bugs that ship in games and the fact that virtually every modern game, even single player ones But most of those bugs are business logic bugs not memory safety ones, read log changes of AAA games and see for yourself. &gt; Maybe we should care more about safety. Of course we should worry about safety but game industry doesn't care about safety because they don't have problems with memory safety that will make them lose money of it. In game dev studios care about shipping fast and making games fast without any overhead and in this case Rust is the overhead and risk. &gt; In the future the optimizations permitted by rust‚Äôs alias analysis give rust a much higher optimization ceiling than C or C++ I am hearing that from everyone for almost 3 years now and to this day there isn't even one LLVM optimization pass done by Rust developers that I am aware of, why is that? Or maybe I missed something? You know that you can do custom optimizations in LLVM right? Is anyone even working on that? Isn't that the reason why LLVM developers are not working on that because most of the languages that use LLVM as backend have aliasing pointers? &gt; Move by default semantics, better reference analysis and tools like Send and Sync make it easier to write the optimized version first and avoid some hard to spot performance pitfalls that are common in C++. You know that game dev have different flow than normal C++ developing? Most use data oriented design (watch Mike Acton talk on cppcon if you are interested) and they will not benefit from Send/Sync because this would imply that they are already following rust borrow checker rules which they don't. They look at cache lines, and look at every microsecond in hot paths because they only have 16.7 ms (for 60 FPS) between every frame, most of the AAA engines allocate all the memory in front and have their custom memory allocators. This are not your typical C++/Rust users. And they don't want initializing variables by default, they don't want bound checking by default, they don't want any additional instructions generated to their stack frames, they don't want UTF-8 checking in strings by default etc. There are decades of experience writing efficient 3d games AAA engines, tons of C++ programmers and people that have expertise in creating AAA games in C++, amazing tooling and IDEs that were developed for years. None of the AAA studio will risk with Rust because they just don't see any benefit in doing that.
Here's a sneak peek of /r/rust using the [top posts](https://np.reddit.com/r/rust/top/?sort=top&amp;t=year) of the year! \#1: [Hey, this is kyren from Chucklefish, we make and publish cool video games. One of our two next projects is currently being written in rust, and I'd like to talk to you about it!](https://np.reddit.com/r/rust/comments/78bowa/hey_this_is_kyren_from_chucklefish_we_make_and/) \#2: [Rust is now an official part of Stanford's Programming Languages course](https://stanford-cs242.github.io/assignments/assign6/) | [84 comments](https://np.reddit.com/r/rust/comments/7a9w1c/rust_is_now_an_official_part_of_stanfords/) \#3: [me_irl](https://i.redd.it/oemt4qm7no6y.jpg) | [40 comments](https://np.reddit.com/r/rust/comments/5l2uc6/me_irl/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Couldn't agree more. In the world of microservices - the modern web with its distributed systems, there's a lot of opportunity to run on different build systems, compilers, languages etc. as long as you conform to an API and some other conventions. When everything is compiled together and called synchronously, I imagine it being more of a burden to build a single module in a different language, since the overhead of dealing with language bindings etc is relatively high. That in turn makes for a status quo feedback loop, where popular conventions, frameworks and languages tend to grow, and the less popular ones have a hard time getting traction. I'm very much speculating here.
&gt; So if I understand this, the grada package collects data in-memory for some period of time, and presents an api that grafana can read directly? Yes, that's basically how the package works. Grafana's SimpleJson plugin sends queries in regular intervals and update the dashboard from the responses. `grada`'s task is to buffer data between the queries and generate responses. I don't know how Prometheus data looks like, but I guess it should be fairly easy to build something similar to `grada` for this use case. You could try changing the `metrics.go` part to meet your needs, or you could start from scratch using the [SimpleJson docs](https://github.com/grafana/simple-json-datasource) as a starting point.
&gt;so you have to separate it out by defining the inner struct [here's](https://play.golang.org/p/HRWe6NKlQu) how to do it your way if you're curious. Make sure you understand Go's syntax for literals and anonymous structs.
[removed]
Nice work. This should be part of the compiler/optimizer if it always yields improvements in benchmarks.
[removed]
I believe people hate it because whitespace has meaning and the array/object notation can be ambiguous. I think yml is fine.
What's the advantage over https://github.com/facebookgo/grace? Why did you reimplement http.Server and did not use context.Context with http.Server.Shutdown instead?
I think it is differs from facebook's `grace`‚Äì `graceful` is kinda generic tool that just can send/receive file descriptors and that is all. It does not wraps any objects from standard library such as `net/http.Server`, nor listening the OS signals ‚Äì it allows user to decide when and how actually his application must restart. Sorry I do not understand your question about `context.Context`...? There is an example which seems doing the things you are talking about: https://github.com/gobwas/graceful/blob/master/example/main.go#L100 
Oh, get it, I thought it replaces http.Server, instead it's layer below. You could make a comparison of your project to the other existing ones in your README.md.
That this type of tool can be written in this manner with so little code makes me happy about the bright present and future of tooling in go. 
Don't be dramatic, I don't get that sentiment at all, but people somehow keep bringing it up...
Don't be dramatic, I don't get that sentiment at all, but people somehow keep bringing it up...
Parent poster was already mocking ;)
This is displaying in r/golang so... 
Recommending rust to hardcore C++ Blizzard devs is like going to a barbecue and recommending veganism to the host. You're either naive, a zealot, or both.
The code is very messy, so I didn't share it.
To me, it sounds like recommending a low level language to programmers who are using another low level language.
Yes, it would be interesting and certainly something to look into. However, I feel like the main advantage on the library is that it is written in Go so that it integrates really well with Go applications but also as a separate command-line tool. You don't need to do the NPM dance, and it is _much_much_ faster than the JS implementations (think 100x faster or more in some cases). How would you integrate a Go code with the NPM ecosystem? GopherJS could be an option but I fear the performance would be suboptimal...
Sure, but for DI?
&gt; Another nice tool is go-bindata, a small utility that generates Go code to embed files from a disk in the output binary. I‚Äôm using it to embed the React application into the binary, it‚Äôs easy to use. Unfortunately, it seems completely abandoned right now, so I‚Äôm looking for a replacement. Check out https://github.com/GeertJohan/go.rice
&gt; unnecessary preallocations Can you give an example of what you're thinking of there?
A linter can be 95% right. The compiler has to be 100% right. I'm not sure this optimization is impossible but it's going to be a lot harder than writing a linter that does it. (On that note, one of the interesting things I'm keeping an eye out on in the Go community is this continued bubbling up of linters from the community. I'm not aware of any other language that has this going on. I think it's an intriguing study in keeping a language simple, yet recovering the 95% sort of things via external linters on the side. Slowly but surely the Go community is crowdsourcing a static code analysis suite. I'm wondering if some other language could deliberately invoke this as a design pattern in the future.)
&gt; Ask anyone that worked on AAA games you will get your data. 99% of AAA games are just patched when someone reads out of bounds, you heard about any security exploits in Witcher? Call of duty? Assasins creed? Tomb raider? GTA V? How many CVEs? I didn't hear about any. I‚Äôd prefer my games ship with fewer bugs. Debugging out of bounds memory has a non-zero cost (as do rust‚Äôs safety guarantees ‚Äî but IMO the trade off is well in rusts favor). I have heard of them: www.csoonline.com/article/2133453/data-protection/researchers-find-critical-vulnerabilities-in-popular-game-engines.html https://www.cvedetails.com/vulnerability-list/vendor_id-1613/Epic-Games.html Also these companies have to willingly report to the cve database given the extreme non presence of games from it, I‚Äôm guessing that these companies are keeping their vulnerabilities close to the chest. No one in 2017 is writing millions of lines of big free netcode, least of all in C++. &gt; I've read their reddit thread on /r/Rust couple of days ago and it was very interesting but starbound in an indie game, why are you comparing that to AAA engines and their workflow? There is a difference in a indie game that 3 people work on and AAA game that hundreds of people work on. Different scale, different problems. Agreed the point was that a team of three people can get rust running on all major gaming platforms. I wouldn‚Äôt expect AAA studios to care about it until it‚Äôs an official part of the platform SDKs or higher level kits like unity or unreal, neither of which is happening anytime soon. &gt; I am hearing that from everyone for almost 3 years now and to this day there isn't even one LLVM optimization pass done by Rust developers that I am aware of, why is that? Or maybe I missed something (is there any now?)? Is anyone even working on that? Isn't that the reason why LLVM developers are not working on that because most of the languages that use LLVM as backend have aliasing pointers? You‚Äôve hit the nail on the head these are mostly llvm optimizations. The rust developers do contribute fixes for some rust specific issues, but they aren‚Äôt really upstreaming new passes. Though the `noalias` LLVMIR qualifier is finally usable by rust in the next llvm release. &gt; between every frame, most of the AAA engines allocate all the memory in front and have their custom memory allocators, they have cycles all over the place and in lot of cases their custom allocators allocate/deallocate memory (freeing to their user space pool) in arena style. This are not your typical C++/Rust users. Embedded folks have many of the same requirements and they are getting by just fine with rust. You can use arenas in stable rust today and they work just fine to create cycles. Custom allocators are an accepted feature, I believe swapping out the global allocator is nearing stabilization. Moreover these days game devs are using ECS libraries for this type of work and there‚Äôs already a high quality (though probably not AAA ready yet) one called specs. &gt; And they don't want initializing variables by default, they don't want bound checking by default, they don't want any additional instructions generated to their stack frames, they don't want UTF-8 checking in strings by default etc. They also don‚Äôt want copy construction by default. Move constructors have a cost because you can‚Äôt just memcpy. Rust has true zero sized types etc. I agree that these will be factors for blocking adoption of rust in game dev, these complaints tend to be more FUD than anything else. It‚Äôs pretty easy to shoot you self on the foot performance wise in C++ too. Reading these two game dev war story articles, a common theme emerges: they spent hours debugging and ultimately had to get creative to work around issues caused by memory unsafety. Maybe the game dev community should re-examine some of their assumptions about development practices? It‚Äôs definitely going to be an uphill battle, look you have the guy who turned off const... *shudder* https://www.gamasutra.com/view/feature/132212/debugging_memory_corruption_in_.php https://www.gamasutra.com/view/news/249475/More_dirty_coding_tricks_from_game_developers.php
I hear what your saying and agree with it. My thought is right now front end developers, which is 90% of the people who use a minifier are your target audience for this. So although I agree with what your saying and LOVE the fact it's so fast it's biggest benefit would be to get integrated somehow into a front end build process like webpack.
Technically anything that's a make()/new() call and doesn't get modified in the scope, because the compiler would optimize static arrays "away" by pushing them onto the stack instead of heap. * I might be wrong on that one, but seeing some zero alloc benchmarks leads me to believe that make/new wouldn't be optimized away and force a heap alloc.
That is right! Of course, the optimization can not be done for all code snippets that follow this pattern. However, it looks like for certain code patterns this optimization can always be done (no break/continue, no side-effects from function calls, etc.)
I don't follow your first comments, what do you mean by the linter or compiler being arbitrary % right? Using `defer` is a known performance caveat for example which is based on how the compiler implements this behaviour. And [this behaviour has improved in Go 1.8](https://github.com/golang/go/issues/14939), and is slated for further improvement in 1.10. I wouldn't call the compiler not 100% right, but the implementation left a gap which could be improved, just as OPs linter would detect a different gap, which the compiler currently doesn't optimize away (but might in the future).
[removed]
The linter is using a "heuristic" to decide if a prealloc should be recommended. Depending on this heuristic there might be cases in which the semantic of the program changes. However, a compiler/optimizer must ensure that this never occurs. An example (did not test it with prealloc) could be to introduce a break or continue statement inside the "for ranged loop". To do the optimization the compiler/optimizer needs to proof that this break/continue statements are never executed for all inputs. For many cases this is undecidable and such a program could not be optimized by the compiler/optimizer.
Also https://github.com/UnnoTed/fileb0x
"Game Server" covers a very wide range of things. If you're running a C++ game client (largely because of speed, available expertise, existing code-base, numerous C++ bindings for libraries and SDKs) then a backend that has the same physics libraries etc available is often going to be easier. If you don't need that, and you're mainly dealing with "game/business logic" then Go is more applicable. Where there exists a good reason to have part of your backend in C++, there's always the temptation to use that and expand on it to reduce the number of languages that are needed and have fewer reasons that make it difficult to move engineers between one and the other. In terms of game logic, you often have engineers on cross functional teams building features, so having two different languages for client and server can be seen as an impediment. You've also got the issue of game data, which is frequently large, and which very frequently ends up built into forms that are not easily read without the associated libraries. There is a strong force pushing towards monolithic codebases. You're more likely to see other languages outside of the core. It's not unusual for things like an SSO to be implemented by a different team, and they're more likely to pick languages that have libraries and strong support for http/oauth etc. It's also not unusual to pick other languages &amp; solutions for relatively isolated systems like large scale chat (erlang / ejabberd). Using other languages tends to be something that comes along with maturity and success - you've got a product, you know where the boundaries are and you've found some systems that don't map well to the language you originally picked. Maybe you've got some performance / scalability issues, maintenance costs or pain integrating your non-standard solution with other clients. I've previously seen various Python implementations that were hard to scale and expensive to run, usually because they ended up being computational bottlenecks that were not easily scaled horizontally. It's the point that you're considering fighting tornado and python function dispatch overhead that you really have to wonder if something else might be better. It's tempting to consider putting something like that behind an MQ, and slowly work on a properly distributed solution, but it's a big investment and you can't break what you have (plus you're potentially playing continuous feature catch-up, which is dangerous).
Its very hard to do this kind of analysis in a dynamic language like JS or Python. C++ rolls features like this into compiler optimisation. Java and C# already have a bucketload of analysis tools you can pay for.
&gt; I guess we could look at those and compare the foss linter community. The term "linter" originally comes from an open source program for C called "lint" from before the term open source even has meaning, so monolithic linters are not new. What I've never seen before is this distributed generation of a linter via a whole bunch of little projects, tied together more or less by gometalinter. &gt; C++ tries to roll features like this into compiler generated optimisations so the linter doesn't have to. Which is one of the reasons I contrasted linting accuracy vs. compiler accuracy. The bar is much lower for writing a linter, so you can get a lot more of them. I don't have any conclusions. :) It's just something I've been watching with interest because so far as I know it's unique to the Go community, and I find myself wondering how far it can be taken.
It's funny that in many cases, the amount of "Golang"s in an article, can be used as a quality indicator.
I was going to suggest that you simply make a new interface and then add a couple methods to common loggers so they could implement it. I thought method definitions worked the same way as extensions in Swift, allowing you to add methods to types you didn't define. But alas, I read the Go spec and that is not permitted; methods have to be defined in the same package as their receiver types. Good luck finding another solution. :)
For me, not doing a lot of Go, the "notable" thing about Go linting is how widespread gofmt is. Look at 100 different Java projects and you'll see 100 different styles. Out of the mainstream languages I think only Ruby comes close with rubocop?
Thanks for writing this. It's a great look into someone's experience with Go, and that's a good thing. I agree with many of your points, but I have to say that I have felt welcomed by the community. I've only interacted with this subreddit, but the culture I see on GitHub is friendly, too. I do see the "Go √ºber alles" and "JavaScript sucks" attitude you called out, but [it goes the other way](https://npf.io/2014/10/why-everyone-hates-go/) a lot, too. I think it's a bit of a defense mechanism to push back against the Go hate that's out there (which you also called out in your article). So I don't see it as a widespread culture problem, just a symptom of people who sometimes have slightly-too-strong opinions about programming languages. Besides, I've used JS on the server, and Go is much much nicer in my opinion. It's fine in the browser, but if I'm being honest, I wouldn't want to touch Node again, either. :)
ORM code is messy by definition, but I understand :)
Nice article. Would have been complete if "go tool addr2line" was used to extract details from the program counter (pc). 
Seconded. I love seeing and writing reference times instead of looking up the parts of an incomprehensible, ad-hoc string format every time.
Something I need to implement on every project. I suppose that's fair to have it ready. Consider extending it to support Template function ```go func Template(w http.ResponseWriter, code int, html string, data interface{}) ```
"System automation" is quite unclear. "Desktop automation" is much clearer. &gt; Golang Desktop Automation. Control the mouse, keyboard, bitmap, read the screen, Window Handle and global event listener. 
As long as you provide an interface that others can implement, provide a default implementation and allow the user to specify their own implementation via dependency injection, I see no issues with your approach. I believe this is the layer [supertype](https://martinfowler.com/eaaCatalog/layerSupertype.html) pattern.
I am all for project based source trees, and better solutions to the vendor folder. I continue to have a deep distrust for the reasoning behind "dep ensure" and the subsequent unavoidable consequences. 
&gt; It is quite likely that the author needs more time with time to appreciate it. That package gets a lot of hate because it is so vastly different than any other language. Yes, Go is resistant to change but so is the author in this case. Honestly? I'm soo tired of seeing this "*[You are holding it wrong](https://www.urbandictionary.com/define.php?term=You%27re%20Holding%20It%20Wrong)*" response to every single criticism of Go. Not every decision the Go team makes is the right one. Rob Pike's words are not gospel. Not every single line of stdlib is just pure and shiny and perfect. Even among the Go community, this subreddit has a reputation of being condesending, dissmive and generally unwelcoming to those who are new to the language. So can we *please* stop with the zealotry and admit that it is *perfectly fine* for someone to not like something about Go? I've been using Go since 1.1. That's *5 years* ago! In your opinion, do I also "need more time with `time` to appreciate it"? Or am I now beyond some threshold and therefore allowed to not like it? Go is a good language. In my opinion, it gets more things right than wrong. That doesn't mean it's perfect. There are many, many bad things about it I can and do complain about and you know? *That's OK*.
I definitely recommend a logging abstraction and not hard-wiring one, because you really limit your appeal if you hardcode what will be "the wrong choice" for 80%+ of your users. Part of the problem is that the Go library didn't declare a standard, and a part of the problem is that right now it's not even clear what that standard would or should be. `(string, ...interface{})` is popular, but it hard codes some expensive operations in to the interface (somehow converting interface{} into strings). And there's an increasing trend towards structured logging, as logrus demonstrates, but it's far from a sure thing. And you simply _can't_ square the circle between those two things, because a struct is not a string, so there's absolutely no way to match it. One of my libraries provides the ability to pass in a logging function for each of the limited sets of things that the library can log, each of which are passed all the information about the logged incident as a function. A default implementation which uses the built-in logger is provided. This is maximally flexible, but only works because I have two core things that can be logged; obviously this fails for a package with dozens of possible messages. So beyond that, the only thing I've got is, provide yourself an interface that you like and tell people they have to wrap. And that still leaves you with the decision as to whether you treat log events as objects or strings, for which I've just got nothing good. I mean, I could write things that could deal with it, but they wouldn't be pretty, involving type switches at a minimum and possibly requiring full-on reflection.
https://godoc.org/golang.org/x/crypto/acme/autocert
If you figure it out, let me know. I'll do the same. :)
Let me guess, inversely proportional?
Congrats to everybody! üéÇüéÇüéâüéâüéÅüéÅ I see Go on the track to became a mainstream language soon. How do you see Go in the next 8 years? Go is a such awesome language! Minimalistic, a huge advance on getting things done ‚Ñ¢ compared to classic languages like Java. Thanks for all the contributors!
Eight years of go, and still no generics. 
At the moment `dep` its main power is having easy reproducible dependencies. If you are interested in another take on project based source trees, check out virtualgo (which I wrote): https://github.com/GetStream/vg It integrates very well with `dep` to get dependencies, but instead of the vendor directory it places them in a project specific `GOPATH` and extends `PATH` authomatically with this `GOPATH` its `GOBIN`. It changes these environment variables automatically when cd-ing into the project directory, so there's no mental overhead in using it. If you've used Python before, the idea is similar to `virtualenv` for Python, but much more user friendly. And because Go compiles into self contained binaries the main problem of `virtualenv` is not there, which is distributing the final code.
I appreciate static code analysis a lot, but this particular tool feels like it'll cause an explosion of premature optimizations. Basically, this should be done at a time when a profile says some specific bit of code causes so many allocations it's slowing down something important. Outside of that scenario, *write the simplest possible code*, and prefer readability over micro-optimizations.
To see that in only 8 small years, Go is breathing C# in the neck is fantastic. The growth rate is astounding. And there is a reason for it, besides being the best thing since sliced bread. Congrats, and here's for the future! üçª
I did not know about this tool! Very neat, I will play around with it and maybe update the post or write a follow-up. Thank you.
Well, the thing is that you failing to take into account the significant reasons why they don't care to adopt Rust is legitimate naivety. These people have lives, job responsibilities, priorities, and probably family. 9/10 of the devs you talk to will have little to no influence on the programming language of choice for their current project. And if you really want to make change, you need to think about who it is you can reach who actually has the power to make that change, *as well as* what you can provide for them to give a shit about what you have to say. Otherwise, you may as well be just another zealot prancing around and making the same arguments all of the other zealots are doing.
Hard to answer this from the outside. I'd figure out what the metrics for success are then demonstrate how Go helps you meet those faster, better and/or cheaper. Get a few "wins" under your belt and converting others will become easier. For most people, change is the scary part. Once it becomes less scary - through your winning uses - change is easier.
The source code is available on Github: https://github.com/code-tutorials/golang-webapp/releases It starts off slow with simple short videos and moves on to more in-depth videos as the project progresses.
I first learned about this while watching this terrifying talk: https://www.youtube.com/watch?v=iffTJ1vPCSo
IMO, it's already a mainstream language. At least I can say that the majority of new back-end projects in my company are started in Go, and there is no stopping this trend.
Yeah, and?
If anything, the "fixed" code is self documenting and more readable. You can look at it and know exactly how many operations are expected. If I see a naked slice var, I assume that there's an unknowable quantity.
[removed]
There are many factors, and some of it is whether you have the right time full stop. If people aren't willing to learn, no matter what, then you're not going to get anywhere. * Present reasons to switch, with things to back up those reasons - facts. * Try get people interested in it, talk about interesting things you've seen or written in Go. * Invite people to work on projects of your own with you. * Find a genuine problem you're having with PHP, and do it better with Go. That last one is important. If PHP is actually solving problems adequately for the team, then why would they switch? Even if it's "wrong", or if Go would arguably be better, then why should they care? That's what you have to convince them of.
https://blog.golang.com/8years The actual post.
maybe something like: xs := []int{1, 2, 3, 4, 5} filtered := make([]int, 0, len(xs)) for _, x := range xs { if x &lt; 3 { filtered = append(filtered, x) } } Or worse: xs := []int{1, 2, 3, 4, 5} squared := make([]int, 0, 3) // too small for _, x := range xs { squared = append(squared, x*x) } It's hard for me to imagine either of these occurring in normal code, though.
lol no generics
Awesome article ! 
Simple, once you start to split the monolithic application from page rendering and backend processing. Then split those backend processing tasks to microservices. Then pair it up with something like a message queue and gocraft. You then have two main benefits. First, PHP shouldn't be used for long running scripts, especially connected to a database. Go has no such issue. Also PHP doesn't have threading, oh there is pthreads but gimme a break. Go will wipe the floor when it comes to concurrency. Go will also use the full cores on the server. I don't think PHP even gets a chance. Have you ever tried to write an impression intensive app? Like getting hit with 10k impressions ever second? With PHP you'll have to scale horizontally with about 30 servers. Go, you can have just 1 or 2 lol. Second, because of the microservice architecture. Now singular developers or groups can maintain a piece of the app. They can add more functionality / fix bugs without holding up or interference from the team. ------- Before I learned Go. I was die hard PHP. Now for me, PHP has been relegated to delivering HTML and doing FE processing. Anything BE related, gets put in an MQ and Go then handles it, very quickly and simply. Some things I do with Go:- 1) Image generation (screenshot) 2) HTML to PDF generation 3) Image conversion PNG -&gt; HTML (for emails) 4) UI Notification (alert after job finishes processing) 5) Sending emails to 10s of millions of users. 6) Posting status on social networks There's more, but you get the idea. With a PHP BE, the job could be running, the server crash and then it gets lost. But with my implementation. The job is clustered and if the server crashes, then gets respawn on another server and tries again. For me, this is the killer app.
Start with small isolated things that make people's lives better, and are good examples of things that Go does well (like highly concurrent tasks, tools that have to be distributed to people, etc).
&gt; Is this even an issue I have to worry about? If you are worried about accessing freed memory, no, that won't happen. For efficiency, instead of planning around elements of the compiler (that could change in later releases) I would benchmark it.
Some of the wording you're using is unclear. So I'll make some assumptions in order to answer. Inside fn2() two allocates happen, one of a channel, and one of a closure while holds the channel. The closure is passed to the child goroutine. The closure can be gc'ed once the child goroutine of fn2 returns, and the channel can be gc'ed once the closure is gc-able and main completes the '&lt;- fn2()' operation. 'a' is a local variable of the goroutine of fn2. 'a' is a pointer to a struct which itself was allocated on the heap, since the struct escapes via the channel. 'a' lives on the stack (and probably just in a register since it only needs to live for 2 statements). The res.Data interface{} contains a copy of 'a' in its value field. I'm not sure what you mean by a goroutine being freed by gc. But in general goroutines are linked to by the scheduler, which is a global object, and thus a goroutine will not be gc'ed until it terminates. I'm not sure if that's what you're asking. I don't know what worries you, but there's nothing obviously wrong with the code you have here. It's not going to crash or do strange things.
Our entire backend is in Go at Meteora. Additionally, I've led projects for at least five companies where we utilized Go as our primary language.
Oh yeah, Go is definitely mainstream now. Everyone knows Docker and Kubernetes and how successful those tools are and that they‚Äôre made with Go. The fact that it‚Äôs compiled, statically typed, and garbage collected make it appealing for companies that have critical pieces of functionally that need to be fast and generate small executables is really attractive. I can‚Äôt wait to see what‚Äôs in store for Go 2. 
Demonstrates how 8 years on and programmers have built fast, scalable, and type safe applications without generics. What‚Äôs the need for them if problems can be solved without the overhead they bring?
Google trends look different if you select Go programming language. In fact trends looks looks downward since 2014! https://trends.google.com/trends/explore?date=2009-10-01%202017-10-30&amp;q=%2Fm%2F09gbxjr&amp;hl=en-US
The classifier might be busted: https://trends.google.com/trends/explore?date=2009-10-01%202017-10-30&amp;q=golang&amp;hl=en-US
I've never once missed Generics in 3 years of Go enthusiasm. I wonder if the people making this complaint come from certain languages where there are common paradigms where generics are useful.
You're not alone in interpreting his tone like that.
Does this do or have any options for encryption or authentication?
Not currently, but that's a good idea.
Yes, by connection I mean the sql.DB, so your recommendation is to have a singleton that lives during the application lifetime 
I guess this guy‚Äôs math was correct https://erikbern.com/2017/03/15/the-eigenvector-of-why-we-moved-from-language-x-to-language-y.html
&gt; Not every decision the Go team makes is the right one. Rob Pike's words are not gospel. Not every single line of stdlib is just pure and shiny and perfect. Who ever said that it is? &gt; So can we please stop with the zealotry Zealotry? What is this? The word of the month? You are honestly reading too much into this. &gt; and admit that it is perfectly fine for someone to not like something about Go? When did I ever say otherwise? &gt; I've been using Go since 1.1. That's 5 years ago! I've been using Go since 1.0. That's like, you know, *more* than 5 years ago (since it somehow matters). &gt; There are many, many bad things about it I can and do complain about and you know what? That's OK. Exactly. It's quite ironic. You wrote all this to complain about my complain only to say in the end that it's okay. :P Because, you know, if yours is okay then mine is okay too.
Still in the "we're thinking about it" stage, though that's better than the "we're not thinking about it" stage that it was in before. They're looking for stories of systemic problems with go that could be fixed in go 2. 
It's due right after Half Life 3.
I only watched the first video, so you may've already addressed this as the series progressed, but you should be careful about the order in which you introduce concepts. In the first video, you pulled the fact that you needed a request handler out of thin air with no context as to where or why it was needed, or how you even knew to do that. I think it's better to teach people _how_ to go about learning this stuff rather than just telling them what to do, or else people will get stuck following video tutorials forever :)
Very early planning, gathering ideas, research - basically the stages that precede preparing a change proposal. I'd be surprised if we see it before by 10th anniversary of Go being opensourced.
[removed]
The Go compiler does an escape analysis of all the objects that get created. If it finds that an object created inside a local scope is used outside this scope, this object automatically gets created on the heap rather than on the stack. (Hence it ‚Äûescapes‚Äú the local scope.) When I run your code with escape analyis enabled and inlining disabled, I get this output: $ go run -gcflags '-m -l' main.go # command-line-arguments ./main.go:22:5: func literal escapes to heap ./main.go:22:5: func literal escapes to heap ./main.go:20:11: make(ResChan, 1) escapes to heap ./main.go:30:12: a escapes to heap ./main.go:43:5: func literal escapes to heap ./main.go:43:5: func literal escapes to heap ./main.go:41:11: make(ResChan, 1) escapes to heap ./main.go:51:12: a escapes to heap ./main.go:48:9: &amp;Anything literal escapes to heap ./main.go:64:13: aFn1 escapes to heap ./main.go:68:13: aFn2 escapes to heap ./main.go:64:12: main ... argument does not escape ./main.go:68:12: main ... argument does not escape {foobar barfoo} &amp;{foobar barfoo} Anything that escapes to heap is not bound to a local scope anymore, and the GC can deal with it like with any object on the heap. For `a`, this is definitely the case.
which is, in my opinion, just right. absent compelling arguments that cover widespread usage patterns deemed obviously incorrect, there's not much action to take. "oh, but i love generics in X, Y, and Z!" is not a compelling argument.
I like how you picked bits of my comment that you pretend was meant literally and only responded to those. Anyway: &gt; Who ever said that it is? Whenever a new user posts about their Go impressions here, there are *always* multiple comments saying it's somehow *their fault* for not liking something, since surely the only reason anyone ever dislikes something is because they either "don't get it" or "need more time with it". Of course someone immediately links to a Rob Pike or Dave Cheney post, and everyone upvotes it like monkeys pushing a button and the circlejerk is complete. &gt; Zealotry? What is this? The word of the month? You are honestly reading too much into this. Zealot: One who is full of zeal for his own specific beliefs or objectives, usually in the negative sense of being too passionate; a fanatic I think it fits pretty well. I can replace it with "fanboy" if you prefer. &gt; I've been using Go since 1.0. That's like, you know, more than 5 years ago (since it somehow matters). *You* implied it matters! Here, let me quote you to you: &gt; &gt; It is quite likely that the author needs more time with time to appreciate it. Which is why I asked if I'm allowed to dislike `time` now, which you conveniently ignored. &gt; You wrote all this to criticize my criticism only to say in the end that it's okay. Because, you know, if yours is okay then mine is okay too. I wrote this, because comments like your are a big part of why so many beginners bounce off of this subreddit. You don't have to believe me, just go to Twitter or the Gopher slack and ask people what they think of this place.
I was talking with a seasoned developer at my company and he told me that Java used to be what go was. At the beginning it was merely a language with some oo features then they began putting more and more crap on it. And that he hopes golang doesn't turn in another java. 
A super long time pending feature. Thank you /u/rsc ! Now I don't have use https://github.com/haya14busa/goverage or https://github.com/wadey/gocovmerge anymore ! 
Yes! This is a fantastic change. Really looking forward to seeing this in a release.
Just use go generate; you'll be fine.
Definitely one of the more considerate and thoughtful posts I've read on the topic.
Thanks for having noticed it ;)
it always returns an error that the LICENSE file is invalid if I do: $ prealloc (in the directory of the package) also it does not really indicate if it has run or not, so I don't know if it has checked anything at all when I just did 'prealloc *.go' (did it the check the sub directories?) maybe work on the user interface because it is really bad. (for the reasons above, just a suggestion from me)
I thought HL3 would be made with Go2
Is its similar to protoactor ?. Not tried protoactor it but i have tried akka actor in scala.
People had been developing fast, scalable and type safe software for more than 40 years before Go existed. Whats the need for Go if problems can be solved without it?
&gt; type-safe &gt; go lmaooooooooou
What does rewording my comment, and making it about Go itself, and not generics, help you to prove?
&gt; to this day there isn't even one LLVM optimization pass done by Rust developers that I am aware of, why is that? We absolutely submit patches to LLVM. We haven't done more work on optimization passes because it's not clear that LLVM is the right place to do them, and because there is more work to do before that kind of thing becomes the highest priority work.
That just because something *works* does not mean it is ideal, or finished. Yes, people can develop applications in Go without generics. They can also develop them in assembler. Neither of those facts tells us anything about how much generics might improve Go.
That's true, idk why you didn't just say that, because that I would reply with that's why Russ Cox and the Go team are requesting experience reports so they can collect actual experiences of how much generics might improve Go via real-world problems. Until then, the people that like to use Go can solve their problems adequately without generics.
[]bread 
Thanks.
Often people doesn't want to try an other language because there is a long learning curve and the deployment is very specific and need also a long learning curve. Go is very easy to learn and deploy. So just try, it will be quicker than to explain ! Try to build a web app that can serve pages, websocket and images live resized for example. Then make it read by someone who don't know Go. Sure he will want to do it also !
You are honestly reading way too much into this. I merely expressed my opinion, nothing else. As for the quotes which you claim I ignored on purpose, I honestly didn't. I just didn't think I had anything to add on that specific quote. There's also the issue of time. As much as I value discussion, sometimes I don't have time to thoroughly comment on every sentence. Since you are obsessing over that, I will avoid quoting you from now on. My original comment includes my opinions. It had some criticism of the article, a few things I disagree with and ended up with a recommendation of the article since I believe it is good. I personally find the criticism part much more valuable but you don't have to agree. It is also just my opinion. It doesn't necessarily mean that I am right or that the author is wrong. But I want to express my opinion regardless. Again, you are reading way too much into my words. Sure, I believe that it is quite likely that if the author spent more time with `time`, he might change his opinion. This is the reason why I used the word "likely". It is just a speculation coming from my own perspective, where initially I thought `time` parsing and formatting was bad but as time went on my opinion changed. You come from an entirely different perspective. Your opinion apparently never changed. That's okay. We don't have to agree. As for the whole, beginners bounce off this subreddit issue, I really haven't noticed anything like this. When I see beginners asking questions I always try to be as helpful and welcome as possible. I use Twitter but again I haven't noticed any discussion like that. Obviously a Twitter experience changes depending on who you follow. So maybe you are following Reddit haters and I don't and thus we have two completely different perspectives? In any case, this subreddit is just one medium where people can find information about Go. It is totally okay if they go somewhere else for their info. At least, I know I am doing my part to help beginners as much as I can. As for Slack, I think it is a wonderful platform but unfortunately it is not appropriate for me. In Slack if you are on the "right" timezone then you will find amazing discussions and if you ask questions you'll get great answers. If you are not though, it's a whole different story. I also find that in Slack you are not allowed to disagree with people (in a sense). There's a few prominent figures that are going to assert their opinions and everyone else will stay quiet. This is only a minor problem as those prominent figures usually know what they are talking about and it creates a more positive environment which is helpful to the majority. But for me the biggest issue and the main reason I have stopped using Slack is "discover-ability". Want to find some great discussion that has happened a few months ago and you didn't think to save/star it back then? Good luck. The new threads feature has helped with this but still I prefer a platform like Reddit personally. That has been my experience from the time I used it Slack. Obviously I can be entirely wrong since I haven't spent too much time on it compared to other people. But in the end, this is my perspective and my opinion. So in conclusion, people can have vastly different opinions and it is okay for them to express them. P.S. As for the "zealotry" I just realized you are the same guy that was using this word on the other thread I created. It's a small world after all :)
&gt; experience reports What are more experience reports needed for when we have 40 years of experience with generics in programming languages to draw on? They aren't implementing generics, and are trying to stifle discussion of it with this useless decision-making process theater. Google is going to do what is important to them, and nothing more. Why so many people outside of Google assume that their motives, incentives and requirements are well-aligned is a complete mystery to me.
If you hate the lack of generics so much, you can just work at a java shop. There are probably more of those than there are go shops. There‚Äôs a reason why so many Developers use go though, and get by just fine with simple, invariant, explicitly typed slices and maps.
As a side note on facebookgo grace, while amazing easy to bolt on, we used it on one high volume service and it just plum doesn't work. We have a 10 node system per data center and the nodes are behind an haproxy load balancer. During rolling restarts, we see spikes in timeouts and terminated connections reported from the calling service. The median response time is 2ms and we have the graceful time out set to something absurd like 30 seconds or a minute. We have not had the opportunity to replace it just yet because the calling service handles retires. I believe the stdlib net/http server can handle graceful stopping now, so there is no reason to use grace.
I heard they had problems getting it stable on GNU Hurd.
How does this differ from https://github.com/docker/libchan and how does it solve the cancellation problem?
It's completely different because software developed before Go could not be made in Go but generics lang could be used when Go was born. People who use Go really choose it and not because it has something that the other have not. It's like when you decide now to use a bike instead of a car, it's not like when there was no cars.
I selfishly want Go to take over the enterprise because I want all these headhunters that are begging for C# and .NET developers to be asking for Go developers instead :)
That's far away I think.. C# and Java are widely used because of OOP and consistency across code, although it can make it a pain to adhere to. I just don't see mainstream businesses writing code in Go mainly, only for smaller services that require specific performance :(
I'm new to Go and made a few small 50 line programs.. coming from Java, I definitely grunted holy crap seeing how fast it compiled and produced an output.
OOP as used in the vast majority of enterprise code bases are extreme bastardizations and are anything but consistent -- at least in my own experience. You can still adhere to object oriented design principles with Go, you just typically don't need to in a lot of cases, and a simple language like Go makes that painfully obvious where as a more class and inheritance based language like C# and Java basically initially force you down that path -- although it seems everyone has seemed to finally catch on, including Java and C# developers surprisingly, that composition really is much better than inheritance, among other things.
Why a channel?
Thought it could be nice to have an endless stream output instead of just requesting a fixed amount of bytes/iterations. You don't like it?
In general, concurrency can be done by the caller, when the caller wants it. So, this thing produces random bytes? That sounds like an `io.Reader`.
You're right and surely an engineer can be convinced, but how would you sell it to some non technical decision maker in a finance company? Public sector? They couldn't give a crap. If Java works and they can find people who deliver as expected, change is the devil.
`io.Reader` sounds great, guess you're right. I'll take a look into that
&gt; to this day there isn't even one LLVM optimization pass done by Rust developers that I am aware of, why is that? Take a look at [this issue](https://github.com/rust-lang/rust/issues/31681) for some of the work that's being done. LLVM currently has bugs around the existing optimization passes that help here, so in many situations Rust just can't enable them. There is progress being made here- the bugs are being fixed, and the optimizations are already enabled in some modes (`panic=abort`). But as /u/steveklabnik1 mentions, there's lots of work to be done and this is just one piece, so it's a long-term thing.
At my last job I worked on the renderer of an in-house AAA game engine. I strongly disagree with the idea that memory safety would "only get in the way." We spent way too much time tracking down memory corruption bugs both in the game code and in the renderer. The kinds of "magic," we used, on the other hand, could have been wrapped up in a safe interface and eliminated those bugs. The real impediment is not the language. It's the tooling and the ecosystem and the job market, and those are solvable problems.
The demo does not seem as fast as I would have hoped, unless the server that the demo sits on is under stress because lots of visitors? I mean no JS is great, but if your pages are taking 950ms that is almost 1 sec to render, wouldn't SQLite be holding this back if there lots of concurrent users anyway?
Try comparing it with Scala which is even slower.
The principle is more or less the same obviously, implementing the actor model on top of golang. In the details, honestly gosiris is far younger than protoactor. Meanwhile the philosophy is the same: "If possible, software should be composed, not built, only add code to glue existing pieces together". They use great technologies like Protobuf or gRPC. On gosiris side it is also built on top on great technologies known for their performance and/or interoperability (AMQP, Kafka, etcd, Zipkin). Perhaps one idea is slightly different. I do not want to be tied to a single protocol and a single serialization technology, I wanted to build something easily extensible. But once again, protoactor is older and more mature than gosiris. Last but not least I do not want to build only a framework for building actors. In the coming weeks, I'd like to try building something similar to an integration framework with built-in connectors (Couchbase, Mongo, HTTP, etc.) but still based on the actor model and easily extensible.
I was probably being a bit harsh there. I don't see anything that sticks out as obviously slow in the view. Some suggestions I have from reading the code though: * You have too much code in your view functions, having such long functions is considered a code smell and can be hard to test because too much is going on in a single function to separate out from what you are trying to test. I would refactor a lot of the queries, maybe into model methods or another layer as a start anyway, that should make things a lot more readable. * Calling packages "models" and "views" doesn't tend to work very well in Go, have a look at the "standard package layout" article for Go, this is referred to as the "rails method" in this article: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1 I used to lay out my code this way too, with a main.go in the top-level package, but it was just too easy to run into import cycles. I also stopped doing this because that means you have to call the top-level package "main" which doesn't feel right. Instead I have a cmd subpackage with subfolders per command which are "package main" and the top-level package is called the name of my app instead (basically that standard package layout article describes all this in much more detail)
"in less than 30 lines of code" plus setting up and maintaining kafka and etcd clusters xD seems cool though
Shit I didn't even think to check if there were packages to do it, I just did the merge using a few lines in bash and then ran my coverage reports on the merged file
I re-read `net/http`'s API but I don't see it. I don't get to use go for work yet (I really want to rewrite our new service in go, though), so all I know is the documentation and what I know about sockets. I can't speak to any bugs that may exist, just their designs. I don't see anything in `net/http` that says anything about that, and it isn't a thing you can do in a library. It doesn't really have a choice. I'm sure it has support for and should always have had support for closing the listening socket before shutting down. Your load balancer needs to know you're shutting down so it sends requests somewhere else. If it's making any sort of TCP health check, that would suffice. But if your HTTP clients send requests before they receive the FIN, or before they check if it's closed, they will probably throw an exception or error in an unexpected place. But it looks like `grace` manages connections in a different process and uses single-request Unix sockets to talk to your HTTP server. So there are two options: semi-graceful timeout + load balancer + clients recognizing closed connections promptly; and `grace`, an adapter between long-lived and short-lived connections. I am already in love with grace. It looks like it's also the only good option if you are only using DNS load balancing. It's certainly the right idea. Of course, I'm not aware of any bugs in its implementation.
Commands is reworked. * Added additional tag element: "sel" or "selection", applies to the struct, from internal fields of these struct user can chose only one field. * That also allow add multiple groups of commands. * Tag element **req** will make these group is requirement. Eventually, it allows to implement more adjustable arguments.
It's in the stage where only backwards compatible changes are still being made in preparation for backwards incompatible ones.
Great to hear that
I'm not very familiar with `libchan`, but at a glance the primary differences are: 1) `distchan` extends regular Go channels with the ability to send messages over a network, so the syntax for using it is exactly the same as the syntax for sending messages within a single program. 2) Due to its use of reflection, `distchan` takes care of converting to/from `interface{}` under the hood, so your own code doesn't need to include any type assertions. There is no answer to cancellation yet since it's a super-new project, but it's something that I'll definitely consider looking in to.
Hi! If I understand it right, [there is](https://golang.org/pkg/net/http#Server.Shutdown) an API to do graceful **shutdown**. But the `grace` and `graceful` tools are exist first to **share** listener descriptors ‚Äì that is, to restart the processes without listening interruption. I have a [little example](https://github.com/gobwas/graceful/tree/master/example) of HTTP server that handles graceful **restart**.
In fairness, the Scala compiler is doing *a lot* more than Go's or Java's. (It's not to say that there isn't room for improvement‚Äîthere is!‚Äîit's just that the compiler is doing more, possibly stuff.)
Good point on the health check. Once a minute, a health and a traffic check happens. I should double check that the traffic check is set to return false when we start a rolling restart / deploy. If that does not get updated for up to a minute, then the restart time could have to wait at least that long to ensure it is no longer getting new requests, otherwise it is as you said. More and more I prefer the idea of a handler in front of the application that sends all new traffic to a new port for the newly deployed version of a service while the old version running on an old port shuts down safely. 
From: /u/joncalhoun
Sure it is. :)
Wait, so ruby is safe, but javascript isn't?
That's my experience. Actually, I don't want to talk about my article here :) I just want other people to write more. That's my motivation in this post.
&gt; Demonstrates how 8 years on and programmers have built fast, scalable, and type safe applications without generics. What do you mean without generics? Go already has two generic types that are used very widely. And the demand for more is pretty evident, most recently in the `sync.Map` type for example. 
There are some situations that are a perfect fit for inheritance and I'll occasionally miss it while writing Go. At the same time, I think it's very easy to abuse. The way I see it, I'm trading a little bit of convenience in exchange for not having to deal with other people's 10+ long inheritance chain monstrosities. Same goes for generics.
&gt; I wonder if the people making this complaint come from certain languages where there are common paradigms where generics are useful. Yes, they come from certain langauges, those languages are typically known as _statically typed_. 
As you answered to my comment, I want to clarify that I am not involved in the project. I don't know if anyone from the project team is following this discussion. Regarding the speed of the demo site, I see instant page load. However, it seems the server is hosted in France, so if you happen to live in a different corner of the world, you might indeed observe some latency.
Ask them to open a file and try again with a different filename if the path already exists in a secure and race-proof way. Oops, you can't.
Oh, I know you're being flippant, but there's lot of cool stuff here, so I'm gonna take it seriously üôÇ *[breaths in]* The Scala compiler has 25 phases (https://typelevel.org/scala/docs/phases.html), which is a lot! I've heard people (admiringly, sometimes with trepidation...) describe the Scala compiler as one of the most complex compilers in production today, and I'm inclined to believe them! A big chunk of Scala'a complexity comes from the [implicit machinery](https://stackoverflow.com/questions/5598085/where-does-scala-look-for-implicits), which powers all sorts of compelling features like higher-kinded types and typeclasses. The reason this complexity exists is that Scala has fundamentally different goals than Go‚Äîhow do you create an ML-derived language that runs on the JVM? (There's more to say, but I'm on mobile right now...)
And Zipkin? 
So, it's the `netchan` idea again, with no discussion on how it avoids the pitfalls the original implementation was scrapped for? Seriously, if the Go core devs walked away from the design, you need to at least explain what you're doing differently. Channels are reliable, error-free, can carry *any* data type, and have well-defined atomicity semantics. What are the guarantees given by this channels-over-the-network implementation?
Also try [Exercism.io's Golang track](http://exercism.io/languages/go/about). It is a great place to practice Go. 
Hey, no worries, the purpose of this poll is not to find my deployment strategy. I'm writing a book about Go, and meant to represent this somewhat accurately in it.
oh, I didn't know about those flags! Thanks a bunch!
the scripts are for mac only?
Done. Looks much cleaner now. Thank you!
&gt; "Just use this email link to log in! No password required!" Yea, I get that they *think* that's an improvement, but...not really. Just let me set a pwd and log in properly.
Create [Transport](https://godoc.org/net/http#Transport) with Dial function that calls [net.DialTCP](https://godoc.org/net#DialTCP) with desired local port. Create [Client](https://godoc.org/net/http#Client) [using the transport](https://godoc.org/net/http#Client.Transport).
For the most part you don't set the outbound port for any communication. Your OS picks a random, unused high number port and you use that. If you can tell us the underlying OS it may be possible to find a solution. 
\* go generate generics
I‚Äôm curious why you want to do that? 
As someone who isn't familiar with netchan, it was more of a proof-of-concept than a battle-tested, robust solution. I make no guarantees of the library being reliable or error-free, but I still think it's a neat idea worth exploring.
the file actually register the CLI command. But they all make a call to "libs.StartTimer(...)". The cli registration will no likely change soon, so i think copy/paste file + change the argument to the StartTimer and comment for cli is not that bad.
Yeah, there was a lot of great timer app on github ! But i wanted to do something easy for tea like "gotea black" for black tea, without think about how many time. I like the idea of fmt.Println("\a") ! Also, i wanted to try [cobra](https://github.com/spf13/cobra)
The primary motivator for this was me not wanting to build out the PW management portion right away to save time. I'll probably add it eventually, but recording more exercises felt like a better use of my time right now.
Just a heads up this is a work in progress. Only 4 exercises are live and I'm still ironing out some kinks. Any feedback or suggestions are welcome.
I haven't had the apparent difficulties that the author has had with semantic versioning. I'd note at least one problem with this approach, and that's when bugs are added to a project in a non breaking fashion, and then the project maintainer goes away. Ideally this doesn't happen, but so long as it can happen, abandoning version numbers altogether makes using tools potentially impossible.
Making a network test where I need to manage outgoing data QOS. Having fixed ports would make the SDN flows easy to configure.
This all makes sense in theory, but I don't think it would succeed in practice. The risk will outweigh the reward of being able to always get the latest version that _should_ work. Bugs do happen, even in popular libraries, well-established code. Not pinning versions with something like a lock file would only make it more difficult to diagnose these issues. What if the library you're using is the only one of it's kind? Sure, something might gain a reputation for breaking changes or bugs, but that might not help a lot of people. Besides, one-off issues can happen too, why punish both the users of those projects and their developers? This would probably work for pet projects, or projects where you're the only developer of a simple system, but otherwise, it introduces more complexity and more things that _can_ go wrong. It basically boils down to "do you want to trust that other humans won't make mistakes?". My answer to that is no.
I definitely agree there are _some_. But I think they are rarer than we like to think. A windowing system comes to mind. Inheritance is great for well-defined problem or at least one where the humans creating the taxonomies understand the domain almost perfectly. In a line of business application or web application, however, this almost never happens, and that's how you end up with your AbstractSingletonProxyFactoryBean and SimpleBeanFactoryAwareAspectInstanceFactory's of the world. Even in some GUI libraries, where inheritence could potentially fit well you get your lovely ones sometimes like InternalFrameInternalFrameTitlePaneInternalFrameTitlePaneMaximizeButtonWindowNotFocusedState
I definitely agree there are some where it is a good fit. But I think they are rarer than we like to think. A windowing system comes to mind. Inheritance is great for well-defined problem or at least one where the humans creating the taxonomies understand the domain almost perfectly. In a line of business application or web application, however, this almost never happens, and that's how you end up with your AbstractSingletonProxyFactoryBean and SimpleBeanFactoryAwareAspectInstanceFactory's of the world. Even in some GUI libraries, where inheritance could potentially fit well you get your lovely ones sometimes like InternalFrameInternalFrameTitlePaneInternalFrameTitlePaneMaximizeButtonWindowNotFocusedState
&gt; I'd note at least one problem with this approach, and that's when bugs are added to a project in a non breaking fashion, and then the project maintainer goes away. There are only two correct responses here: Either find a new maintainer, or move to a different library. Using an outdated version is not a correct option. Unmaintained packages should be considered broken by default, because sooner or later, they *will* be.
This is bull shit. Naming things is hard... Now I'm expected to rename to indicate I've made breaking changes? And how exactly are developers supposed to know they should prefer 'froopy loops' over 'zoom loops? Does not scale. Semantic versioning is not cargo cult, it's an informative statement a package maintainer makes to allow developers to choose how to use their library, package, module whatever. What's next, the cargo cult of read me.md? 
In some way, the author manages to agree with me, but from mostly nonsensical arguments ^^ &gt; Let's just make them a tuple. Instead of "3.0.2", we'll say "(3, 0, 2)". That is *literally* just a different notation for a tuple. Yes, there is a certain amount of uncertainty in parsing different formats for the tuple and the solution is to normalize on a format - but whether that's "3.0.2" or "(3, 0, 2)" or "\x03\x00\x02" makes no difference at all. &gt; Next, move the major version to part of the name of a package. There is‚Ä¶ no technical advantage to this. It's, again, just a cosmetic change. Whether you do that, or just require giving a major version to specify a packages makes no difference - except now the identity of a package changes when major versions get bumped. &gt; Just combine the 2-tuple into a single number. While I agree with the "new is always better" approach, I think simply ignoring the arguments of people wanting tuples (namely, that they want to be able to independently maintain longer term releases) is a bad strategy to convince anyone. &gt; At this point you could even get rid of the version altogether and just use the commit hash on the rare occasions when we need a version identifier. This would be my preferred approach to; basically, a) use "head" for development and then b) distribute a lockfile to guarantee reproducible builds and debug-ability. Lastly, make it as simple as possible to upgrade when there are breaking changes. The thing that mostly irks me about versioning and package management is the duplication of effort inherent in it. Every language builds their own package manager - but that just sucks for multi-lingual projects. Cross-language package management, including lockfiles, versioning, cryptographic signatures, authorship meta-information and‚Ä¶ everything, is a solved problem. Indeed, there are already multiple solution to this problem, in the form of deb, rpm, pacman‚Ä¶ If, instead of duplicating these concepts for every language, we could standardize on one of these formats, we wouldn't need every distribution and every language to figure out what the correct set of versions for a stable build is - instead, everyone would specify all their dependencies in a standardized meta-file and then there could be one (or a small number of) body of people tasked with figuring out stable snapshots that people can use. Basically‚Ä¶ well, the model of linux-distributions. Currently, the frustrating thing is that we have N projects and M distributions and every developer has to maintain compatibility with these M distributions and every distribution has to somehow unify those N projects. Which is an enormous amount of duplicated work. And as no one wants to do that work, we instead move to an isolated world, where we just package the exact versions we need into a container and ship that - often leading to stale versions, security holes and *when* someone has to figure out a compatible set of versions (e.g. in a distribution or just a corporate environment that wants to have strict, scalable auditing) we leave them frustrated‚Ä¶ Anyway. /rant ^^
Portal 3 should be made before HL3.
It hard sometimes to have time to write about stuff. Like my work is giving me a test about default html properties... Idk why but there goes my free time. I'm glad though you are sharing. The more the better!
I think a more sustainable approach that the OP alludes to would be * `package froopy0 // can break at any time` * `package froopy` // stable release * `package froopy2` // oh no, we need to break the API * ... etc I'm not sure how I feel about that. This is how a lot of old-school C libs handled breaking changes, and it got the job done. But it increases the burden on the maintainer, since you're essentially maintaining multiple forks of the project (and maybe even backporting fixes). Not something I'd like to do for a side project.
It would be very useful to have a (eg) TravisCI setup where you test against the lockfile as well as head (although it would have to be non-breaking). I think it's already possible to do testing against multiple Go versions.
Have you never experienced bugs in software?
Another option would also be to become the maintainer. That is likely to be the necessary course of action if the library you're using is the only one of it's kind, or of high enough quality.
Here's what I can see to possibly complain about after one coffee: bit counts and byte counts are confused in the test code. readLength is no longer used. The check of l &gt; 0 in Read() is unnecessary. You create a lot of big.NewInt(0) when the zero-value of a bit.Int is already 0. If you moved some of those *Int into local Int you'd have less code to write. (and just maybe the compiler realizes the *Int doesn't escape and will leave it on the stack). The same goes for the *Int in Generator struct. Let them be Int and the code is simpler. Copying an Int is copying a slice and a bool. It's probably less work than alloc/free. readInit gets checked for every byte. You can do better by checking it only once every call to Read(). Or get rid of it altogether. I'm not sure why that Exp isn't part of NewGenerator(). Speaking of which, s/NewGenerator/New/. I'm not sure why anything beyond New... and Read are public. What am I to do with CalcRandomSeed() and CalcBlumUnits(). Are these useful to users outside the package? There's a // todo left. Back to readByte: why check if bitCounter==0 every time you loop. You know that only happens on the 1st iteration. So move the val = 0 out of the loop. And then eliminate it entirely since val is already 0 at that point. val may as well be type byte to start with, though benchmark, since the overhead of truncating to byte all the time might be visible. Unnecessary () around (1&lt;&lt;bitCounter). The compiler may do better, and the code is easier to understand, if you explicity make it a 8-iteration loop, like 'for bitCounter:=0; bitCounter&lt;8; bitCounter++ {...}'. It's what you have already, but making sure of that took scrutiny on my part. g.x0.Set(g.x1) has to make a copy of the bitint's bits. But you aren't going to use x1 after this. So maybe swizzle x0 and x1 instead of copying. Speaking of x1, why is it preserved in g at all? It can be a local of readByte(). Then you can just assign with =, which copies only the outer struct. CalcBloomBits and CalcRandSeed return values that aren't used. Why bother returning them at all? 
I don't know, it's a fairly standard feature for a website...
Very nice. Are those graphs now generated in go instead of graphviz? 
It was abandoned because of *design issues* not because of lack off ability to implement well.
But it still takes time to develop, even if it's a "standard" feature.
Of course it does. I didn't imply that it took zero dev time, but rather that it's a very standard and expected feature for a site like this (that tracks progress) and not something that you skip to "save time."
[removed]
Such a great QoL feature! This improves testing workflows a lot.
Personally I'm really keen to see more content first.
The thing about it is, basically *every* off-the-shelf framework already *has* that shit implemented. He didn't need to *build* one, just use any of probably hundreds of frameworks that *already have it*. It should have added virtually *zero* dev time.
[removed]
you had me at bull shit.
OK. I'm sure that your feedback is appreciated. Do you have any suggestions for go frameworks that might be useful, assuming this is written in go?
If you already have read dozens of tutorials, I am not sure if I should bother you with another one, but [this article](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1) from Ben Johnson is an often referred-to reference and IMHO an excellent starting point. 
I agree with you, the first video doesn't do a good job with explaining things and I hadn't really figured out a good pace at that point. The recent ones have been a better pace but they've been longer. I'll probably redo the first one soon to address this (and the terrible audio/video quality). Thanks!
Checkout go awesome on github. They have an entire section on design patterns 
Are you referring to the `brew` calls in `setup_kubernetes.sh`? This could indeed point to macOS, although these might work with Linuxbrew as well.
&gt;But when I trying to combine all of this into full project (for example web api) i just don't know how to start and how to structure my code. You're overthinking this. Here's how I *start* my projects (note the emphasis: I *do* use subpackages as a project evolves and becomes more comoplex). 1. Create `./cmd/&lt;program_name&gt;/main.go` 2. Create `&lt;package_name&gt;.go` From there, I just create various files at the same level as `&lt;package_name&gt;.go`. When the namespace gets too crowded, I *might* make a subpackage.
General I would first take a look here: [Effective Go](https://golang.org/doc/effective_go.html) Also take a look at Wiliam Kennedys excellent Go blog: [goinggo.net](https://www.goinggo.net/) For package layout take a look at: [Style guideline for Go packages](https://rakyll.org/style-packages/) If you just need some code samples take a look here: [Go-Design-Patterns](https://github.com/PacktPublishing/Go-Design-Patterns)
FYI, here were the results of this poll: 77 participants. - Binary directly executed on the OS: 38 (49.4%) - Behind an HTTP server (like nginx): 36 (46.8%) - In a scratch micro-container: 27 (35.1%) - Using a PaaS (like Heroku), so just doing it the way they need me to: 8 (10.4%) - Others: 10 (13%) What the 10 "others" were: - On GCP (user also checked: nginx &amp; container) - Docker swarm mode with traefik as a LB (user also checked: container) - Varnish in front (user also checked: on OS) - BOSH (user also checked: PaaS) - Nomad (user hadn't checked others) - Google cloud load balancer (user also checked: on OS) - Also Mesos (user also checked: nginx &amp; on OS) - fabiolb (user hadn't checked others) - In kubernetes pod (user also checked: nginx &amp; PaaS) - haproxy (user also checked: PaaS) Hope it's useful to someone!
I wasn't familiar with the history of `netchan` before looking it up, but `distchan` isn't trying to replicate the exact semantics of channels for use over networks. Its goal is more to enable the use of channels for distributing workloads, and I think the current design is fine for that purpose.
I don't know much about the go ecosystem, hence my interest in the lessons. 
You could also have a look at the [Go Proverbs](https://go-proverbs.github.io/) (click on one to see the corresponding video). 
On one hand, interesting. On the other, lack of tests, way too much packages and voice that sounds like he's chowing something.
Very good, I especially like seeing the ASM output upon clicking a line in the source view. I feel however that the UI could improve (a lot). It would be nice if you could right-click on the boxes to see the source and more. Moving the mouse to the top-left is not too bad though, but the buttons are quite small (hard on a laptop). Overal, some margins could be added etc and also in the source view the `div#bodyContainer` bottom extends beyond the browser windows. I like how https://go-review.googlesource.com/q/status:open was customized by someone some time ago, maybe the same style could be applied here?
The most important rule is to not make folders just to be making folders (i.e. code organization). Make sure each package has a clear defined purpose, and stay away from anti-patterns like making "util" packages. I know you said you read a dozen tutorials, [but I have a feeling you haven't read this one](https://www.goinggo.net/2017/02/design-philosophy-on-packaging.html), because if you have you wouldn't need to ask this question :-) 
is this the oss contrib that is mentioned in the article? https://github.com/census-instrumentation
A Dockerfile tailored for Golang: `FROM scratch`
Well, that actually depends, e.g, if you need `ca-certificates` and if you don't want to have the go toolchain locally. But I mostly agree üëç
My comment was tongue-in-cheek, which admittedly obscures the actual underlying point: I feel quite strongly these kinds of concerns are best addressed by a "proper" web server such as nginx, which also happens to guard against the [most common attack vectors in Go code](https://www.infoq.com/presentations/go-security) quite easily. 
Oh, I see your point (and agree!). I'll update the article with some notes regarding that. Thanks!
Also the standard package layout https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1
[removed]
Why the `lib` directory? To import the package it would look like... import "github.com/username/reponame/lib"
I really like the page [pattern matching](http://go-colly.org/docs/examples/basic/). Super clean and nice interface for promoting a non page-by-page way for implementing scraping. Question though: Will this scale to millions 10's of thousands, millions, or 10's of of pages per site? This problem is encompassed by the classic programming interview design question of how to design a web crawler. [Looking](https://github.com/gocolly/colly/blob/2837d3a8a9da0a2f3b8ce1e4d1ae9cbf187eccdc/colly.go#L63) at the code [algorithm](https://github.com/gocolly/colly/blob/2837d3a8a9da0a2f3b8ce1e4d1ae9cbf187eccdc/colly.go#L319-L326), this currently appears to be an O(n) time efficiency implementation with regard to the number of pages per crawler instance.
&gt; Have you ever tried to write an traffic intensive app? Like getting hit with 10k impressions every second? With PHP you'll have to scale horizontally with about 30 servers. Go, you can have just 1 or 2 lol. Is this a hyperbole or actual numbers? I've written in PHP for the past few years, but if this is true, that's amazing.
well thats a beginnera tutorial, so test is a bit out of scope. about the packages obviously its a crazy over kill for something like this but in abig project I think its ok. although theres no one truth.. about the voice, note taken :) don't know why sounded like that. also I do still talk slow (English is not my first language)
Sweet, pprof sometimes felt a little rough to work with on the CLI. I woound up always creating the SVG file and opening in browser that way. This looks like a very good quality of life update.
I just tried it again now, and it still takes about 1 second to run a statement. I see the gore readme now says: &gt; gore runs code using go run for each input. If you have entered time-consuming code, gore will run it for each input and take some time. 
I've heard that they are waiting for Go3 as they want the version numbers to be consistent going forward. 
Thanks ;) I'm gonna define my own interface in library **A** and create default adapters in a side library for people to use, if they want to use an already defined adapter. For a thing as simple as a logger that should be enough.
I'd like to add a few words to this. In a real world scenario you'd run this on kubernetes (or a similar orchestrator) where there's usually an nginx ingress controller in front of everything. You'd have centralized logging (e.g. via ELK) and centralized metrics (e.g. via Prometheus). So your "app" will usually never get exposed directly and you'll never look directly into your container because it's immutable. That said, from scratch should be fine.
https://blog.learngoprogramming.com/code-organization-tips-with-packages-d30de0d11f46
It looks like d3 in a html template: https://github.com/google/pprof/pull/188/commits/db1575c1d31f17539d908e8bef9c14b99fd73349
Slapping them with a printed copy of [this essay](https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/) should be enough.
oh, yeah, that's totally true - it was just to make the point of having an extra package (aside from the `main` defined in the root). I usually like to keep all the functionality under some packages and then expose a root 'main' which just imports them. Thank you for pointing out!
and I just noticed I missed the `fmt` target! Pushing an update now (should get out of cache soon)
Emojis in every commit message...
Why not?
Great, works great so far for me! I have filled an issue, it would be great if you would choose some licence for the library.
I highly recommend this excellent article by [Chris Beams](https://chris.beams.io/posts/git-commit/).
Thanks for the great reply, really helpful! Two things: &gt; If you moved some of those *Int into local Int you'd have less code to write. (and just maybe the compiler realizes the *Int doesn't escape and will leave it on the stack). &gt; The same goes for the *Int in Generator struct. Let them be Int and the code is simpler. Copying an Int is copying a slice and a bool. It's probably less work than alloc/free. Could you elaborate? I'm not sure if I understood this correctly. About the two methods being public and returning values: They are public because I thought it would be nice if the generator could always be triggered to generate new primes etc. without the need to create a new generator. Not sure if this is a good idea. The returning values will be used in tests, but other than that, I don't think that anybody needs to retrieve those values. Hmm...
hm... license is chosen - "unlicense" [LICENSE](https://github.com/sg3des/argum/blob/master/LICENSE), will suit?
Oh and maybe someone has an idea how to do this better? https://github.com/tsdtsdtsd/gobbs/blob/cdd8ebdf8eae203beaac92d3ae9f8dc6c41d64fb/gobbs.go#L10
A link would be helpful.
Thank you. But that does not explain why I can not use emoji in the headlines of the commits. In my opinion, they contribute to readability, visually emphasizing the context of the commit. In the end, it's not a problem.
Oh no, I never said that you cannot use emojis. You can do whatever you want in your project. But our commit messages can always be improved. For example imagine if I had a commit message "Yay!". What does that even mean? Maybe for a while I can easily remember my "yay moment" for that project but If I went back to that commit message 6 months later I would probably have no idea what it is about. This goes tenfold for people who are unfamiliar with my project. I try to improve my commit messages every day and I think all other developers should as well.
I have no idea about the design patterns section but the link is: https://github.com/avelino/awesome-go
Yeah, I was easily able to find that repo as well. What I couldn't find was the mentioned section on design patterns.
Hi, thanks for your question. I'm currently working on making eGO suitable for Mac and Linux. Do you have any specific requirements? 
HN discussion here: https://news.ycombinator.com/item?id=15685505
TL;DR A guy from cloudflare wrote a little Go benchmark that created a bunch of short-lived objects, and GC kicked in too often, killing performance. He tweaked Go's GC knob, and got better perf. 
Tweaking the `GOGC` variable doesn't seem like the most prudent solution here. Not to mention it's a one dimensional knob, and another part of your code might work better with a different number so now you have to choose what part you're optimizing for. Seems to me it'd be better to use object pooling in the specific instances where you know you're going to use a bunch of objects for short periods of times. Go comes with a simple implementation in [the standard library](https://golang.org/pkg/sync/).
If you're making a bunch of variables just to immediately throw them away then there's no point even making them at all, just use a big amount of fixed storage that you allocate at the start and then reuse.
Agreed 100%. He's tuning it for an encryption algorithm in a loop. In reality, this kind of logic is probably going to be performed in a web API tier or something like that. Almost certainly, GC around the encryption algorithm won't be anywhere near the root of performance problems there. Networking, DB-acccess, serialization, etc... Those things will almost all be more costly, I'd expect.
I don't like using config to specify builds. I believe it should be expressed through code rather than config. Config duplicates a lot. Code can be abstracted and centralized and re-used across projects and peer-reviewed. It's like Gulp vs. Grunt, Chef vs. Ansible, etc. Some people prefer writing out long config files to specify environments. I believe that's way too limited. Because then you need to duplicate and alter it for each environment. Nowadays, you want to be able to scale out to an infinite number of environments, and it becomes way too burdensome to manage that through config files. But what do I know; I use Make for my build system for Go.
The performance section of [this article](https://dannyvankooten.com/laravel-to-golang/), while not a real-world scenario, suggests that a 15x improvement is plausible.
&gt; the error might change in the future and the text is locale-independent I think you mean locale-dependent.
[removed]
A very old talk that I encountered when I started writing Go was Jeff Hodges' talk on Escape Hatches in Go: http://basho.com/posts/technical/escape-hatches-in-go/ One of the main points being that you can avoid many GC issues by allocating a pool of memory and doing simple memory management yourself. It's better when the language/runtime can handle that for you but at least you always have the option to sidestep it if you really need to.
With GOGC at 11,300, if you were to use 1gb, the next GC won't happen until you hit 114gb if I'm reading this correctly. 
First of all, a small website storing passwords is a security concern by itself. The next best thing is the "login with X" button using 3rd parties. But then how many buttons are you going to need? Facebook, GitHub, Twitter, there's quite a few. Even by using the best current existing Go libraries, assuming 2-3 buttons and assuming you care about security, it can be weeks of work since each 3rd party has slightly different procedures and APIs, among other things. There's no such thing as zero dev time, virtual or not.
I like it. Godoc is great, but it's always nice to have an introductory demo that shows usage patterns in addition to function arguments. It's nice that you did that! I'm writing a file synchronization client, so I'm tempted to give this a whirl. Incidentally, I'm looking for some mention of whether or not this library is production-ready. That would be a nice addition :)
Nice! This might be a good fit to [Afero](https://github.com/spf13/afero), esp. with a memory-mapped FS.
While I agree, at least if you're doing it in a loop and you set the value via the runtime call, you can do it before your loop and reset it after so as to not affect performance elsewhere. Maybe this only applies to sequential applications?
You should be more regular here. And in other subs. Would you be willing to work undercover as a bot?
The use case in the article seems to be for a highly parallel application (running on a machine with 24 dual cores + hyperthreading) so I'm not sure it'd work. Besides, changing these settings on the fly is likely to reduce the efficiency of the garbage collector since it depends on historical statistics and predictions to be as efficient as possible. If you know for sure that you are only working with data structures in a non-parallel manner then it's better and simpler to just preallocate and reuse objects. My suggestion to use an object pool is specifically when you need exclusive access to reusable objects without having to worry about other threads.
Normally. But Cloudflare is mostly about proxying and passing through data. Encryption (for HTTPS) is, *for their very specialized niche*, easily going to be 90% of their processing needs.
I had a huge cpu-intensive batch job once that had more GC time than we would have liked. We ended up just disabling GC altogether and having a supervisor program spawn the worker with a somewhat limited batch of work. We had it auto-tune the batch size to keep the program's total working memory around our desired high-water mark. It worked fairly well. Go has some really impressive GC pause time graphs from recent releases, but those only tell half of the story. The non-stop-the-world bits still take processing time away from your application, just concurrently.
[removed]
No, even in your stated case you do not need anything other than scratch. You can mount a volume to where go expects the certificates.
They may help **your** readability, but they are pretty meaningless to someone looking from the outside. If I were using your library in an app, my goal when updating would be to see what changed as quickly as possible. Those emojis don't really help me with that. There doesn't seem to be any kind of theme or pattern, so I'm really not sure what you mean by "emphasizing the context". If there was a consistent pattern, I may buy that, but you use like 15 different emojis for "doc fix" type commits, and same for "Tests" and other things. 
Er. I realize now that this sounds like a spam question. It's not. Context: I'm kind of tired of people slamming Go for being too simplistic, and the kind of language that only people with no experience in "good" type systems would use. So, I wonder how many of you who are using / like Go have experience with more advanced type-systems (Haskell, OCaml, Scala, F#, PureScript, etc)? Also, what was your primary language before coming to Go? And lastly, what language would you choose for your current Go work, if you couldn't use Go?
Interesting that you mention an @spf13 project. I totally forgot about it, but the first time I thought of techniques used in `fst` was when testing my changes in another Steve's project, [Viper](https://github.com/spf13/viper/commit/9fca10189b1307bba68b2cd487dd93da0bfbda06#diff-db3e9f98aa59a770129eb45f83357512R132). Nice reminder :) 
Good call about production-ready, thank you! I did use it in internal production for a while and the only reason I did not post `fst` as `v1.0.0` today is to do so after this feedback about metadata. I will do so a couple weeks after a last suggestion fix I get on this version.
[This](https://en.wikipedia.org/wiki/Software_design_pattern), I assume.
See also /r/adventofcode 
Something I was thinking about was making the code check the first (say) 512 bytes of the file to see if it is already minified, and if so not doing anything to it. This would be fairly easy to do for HTML, for example.
 var x big.Int is naturally initialized to zero, and is less work for you and for the computer than var x = big.NewInt(0) but it changes the code from passing *Int to passing Int. That is a tradeoff in the readByte() method (the one that has to be fast). For the other methods, and for the members of Generator struct, holding the big.Int by value is easier.
They make me cringe.
That's what we in the industry call "a problem for the next guy".
I dont know, the coolest thing i saw in this post was the fact that he built a tool that ran a profile over different values for GOGC in order to find the most optimal configuration. That's kinda neat. 
I built this as a personal replacement for Tiny-Tiny RSS. I wanted something that was easier to configure and extend while not enforcing a specific Web UI. No official client is released yet but I have one in the works: https://github.com/varddum/syndicated-angular. This is currently in an early beta and I would appreciate suggestions on features for first release.
Please don't say things Python advocates say. What is good about Go is uncompromising performance.
Go compromises performance all the time. For example, the choice to always zero-initialize memory or bounds-check array-accesses compromises performance for safety, as does the choice of GC over manual memory management. The GC design compromises throughput for latency. The Go compiler was rewritten in Go, compromising performance for ease of maintenance and other benefits. Go is an [engineering language](https://talks.golang.org/2012/splash.article). If there is one defining characteristic of Go, it is the willingness to compromise.
Uncompromising performance is not about Go.Typically you are going to be at least twice slower with Go than you could be with C++
no, just a curious question. :) 
Or, you know "a sensible tradeoff". Memory is - compared to engineering time - pretty cheap. 114 GB is ~$500 for consumers, with a lifetime of several years. If you have the choice of throwing an Engineer at a problem for a day, or just add 100 GB of RAM‚Ä¶ choose the hardware. Yes, this is a little tongue-in-cheek, but people tend to overestimate how expensive hardware is‚Ä¶ Of course in practice, this benchmark is simply unrealistic, you are unlikely to need such extreme values for GOGC in practice and if you do, there might be some pretty cheap fixes to implement.
I will counter your comment simply by stating that developers frequently forget that the resources they use are often multiplied by the concurrent users, and adding another 100gb of memory per anticipated concurrent user quickly stops looking better than whipping a bad developer for a day.
I've used gorm for the past few years to generate the schema from go code, it works well except for a huge breaking change that happened a few years ago to how time stamps are handled in `gorm.Model`
You mean‚Ä¶ you are building a system which needs to make 700K crypto ops per second per user? (yes, I'm being a bit snarky ;) I did acknowledge that there is more complication to the equation, however)
Basically‚Ä¶ the same as in any other language. You can compose [binary.Write](https://godoc.org/encoding/binary#Write) with [bytes.Buffer](https://godoc.org/bytes#Buffer) for the simplest API, for example. Or you create your own struct type, wrapping bytes.Buffer and adding the methods you want (utilizing the more low-level API of `encoding/binary`), which shouldn't be more than a handful of LOC either. The hard question is about deciding on an actual encoding, not how to code that up.
yes, disable GC for awhile and re-enable it by detecting if current heap allocation has reached to a specified point may be better.
This is a bad idea. A no good terrible horrible horrifying idea. Object pooling is a much much better idea.
Except in generics. No compromise.
Good bot.
Good Human ---------- I am a Bot which automatically collects comments across reddit. Beep Boop
Are you sure about that? Because I am 99.9995% sure that ferociousturtle is not a bot. --- ^(I am a Neural Network being trained to detect spammers | Summon me with `!isbot &lt;username&gt;` |) [^Optout](https://www.reddit.com/message/compose?to=perrycohen&amp;subject=!optout&amp;message=!optout) ^| ^Feedback: ^/r/SpamBotDetection ^| [^GitHub](https://github.com/SM-Wistful/BotDetection-Algorithm)
Good grief.
Is there any inherent increase from the concorrent model in Go? Apart from the ease of doing it, is a multi-threaded C++ program also going to be faster than a concurrent/MT Go program?
Sure I get that this whole thread is us being snarky, but the reality is that developers rarely understand how constraints work. I've been doing this a long time. Countless times have I had the arguments about why php.ini shouldn't have max memory set to 1GB, why you don't allow 256 concurrent requests, why requests shouldn't take 6 minutes to return results, why you don't do select *, why "adding memory" won't speed up your database if all your columns are *text*, and why an hourly cron job that calls curl to execute a script that takes almost 2 hours and doesn't use a lock file is a bad idea. And sadly, most of those situations happen in groups.
Nothing says the server *has* to be written in go. If go's web frameworks aren't as good as another, just use that other. It doesn't mean go isn't a good language, it's not a matter of "siding with" one or the other.
Depends on what you mean. You can probably get some sort of channel and goroutine equivalents for C++ (actor libraries come to mind. Wouldn't be surprised if boost had something‚Ä¶) without too much of a runtime overhead, so you could use similar abstractions. At that point it's just about how familiar you are with both languages. C++ is a much harder language to learn, but you'll have much more control over things compared to Go, plus an abundant number of weird features you might run into and/or be tempted to use. Go is easy as hell to learn but the runtime is dark and full of terrors; if you need more control over what happens and when, you generally won't want to use Go.
Substitute Go with any language or framework you want. My point still stands.
ah I just meant in terms of performance...if Go is half the speed as C++ in a single thread, does that mean its logarithmically slower with multi-thread
*writes charlie brown bot*
[Are you sure about that?](http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=gpp)
&gt; and if you don't want to have the go toolchain locally. FROM go:1.9 as nitpick [blah blah blah] FROM scratch COPY --from=nitpick /app/cmd/actualbinary /actualbinary ENTRYPOINT ["/actualbinary] [Multi-stage builds](https://docs.docker.com/engine/userguide/eng-image/multistage-build/) are kinda cool. And the certificates you can (and maybe should?) mount them from some authoritative source, as /u/dazzford says.
This looks cool! I am guessing the primary difference between this and what I am working on is the focus on Go explicitly along with screencasts that show me coding and explaining in realtime. I've found screencasts help a lot with beginners, especially if they get stuck or unsure if there is a better way to handle a problem they are having. This is especially true for people too shy to post a question on reddit/wherever. The Go focus was important to me here because there are a lot of go-specific techniques that aren't obvious at first but can be incredibly useful once you learn about them. For instance, functional options is something I don't see used as commonly in other languages but are worth learning about and trying out.
&gt; It's not like someone's going to log-in with your email This isn't possible, since they have to access the link that is emailed to the provided email address. It is similar to Slack's Magic Link login option. &gt; I don't even really get the point to track progress at all. Absolutely no progress is tracked at this point üòÇ I'd like to add things like that long term, but again it wasn't necessary to release. The app behind Gophercises is incredibly minimal - probably less than 1k lines of Go code and it isn't using any framework. I spent more time tweaking the design than building the Go backend.
I guess we have different opinions on what is necessary and how things should have been prioritized. ¬Ø\\\_(„ÉÑ)\_/¬Ø I appreciate the feedback (that you feel the site should have auth w/ a pw etc), and as I said before I will likely add it at some point, but not right now. If you'd like me to email you when that happens just let me know - &lt;jon@calhoun.io&gt;
huh, this is actually pretty damn cool (no pun intended)
Sorry was on mobile at the time
[removed]
Don't forget to mention that it would be great exposure.
go to **The Go Programming Language**
*writes lucy bot* ;)
Why?
and they aren't going to be visible outside of github ¬Ø\\\_(„ÉÑ)_/¬Ø
Yes. I have precisely 2 Go books in my library: Go in Action and The Go Programming Language.
Good bot 
The standard book on Go is surely ‚ÄûThe Go Programming Language‚Äú. However, in comparison I find Go In Action more accessible, especially for beginners. 
Multithreading? I would take C++ each time when I need a sane multithreading with fine control, where I can be sure one worker is always working ‚Äì Go runtime can easily replace it with another goroutine. Concurrency is a different deal, it is much easier (obviously) with Go, but CSP model is just an abstraction and like any other abstraction it doesn't provide fine control and with C++ you can achieve higher performance again. https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=fortune
yes, sure, I wasn't aware of such kind
if your router gets to 80C, I don't think a fan is gonna help. Buy a new router. WTF That said... pretty goddamn awesome work /u/zhuoment
Of course I am sure about that. The only benchmark Go could overcome C++ is not CPU bound: https://imgur.com/a/NlnfN Typically, Go 1.7 and below were 3-4 times slower than C++. Now it is only twice slower and this felt as a huge progress. Still, it is far cry from C++ speeds due to natural limitations in languages/runtime semantics and limitations on compilation time as they try to be speedy. At my previous job I did things like these ones https://www.reddit.com/r/golang/comments/6dhbwv/faster_command_line_tools_in_golang/dl9fmp9/ And notice, piece of Go is non-idiomatic, while the C++ is perfectly is.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/UCivY5B.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
The reason why these flags are not widely known is perhaps that it should not be necessary to know them. As the Go FAQ [says](https://golang.org/doc/faq#stack_or_heap), &gt; From a correctness standpoint, you don't need to know [whether a variable lives on the heap or on the stack].
Would you like a third? ;)
you can try this [xmlquery](https://godoc.org/github.com/antchfx/xquery/xml) package to parse XML document as DOM tree, and using XPath to get data„ÄÇ ```golang f,err:=io.Open(xmlfile) doc,err:=xmlquery.Parse(f) // Get Data from XML DOM tree. var xmlHead XmlHeadStruct=XmlHeadStruct{} xmlHead.Field1=getData(doc) xmlHead.Field2=getData(doc) ```
[removed]
This code used quite a few type aliases - was there a reason for those? I haven't had a chance to look closely enough at the code to see if I could find one.
FWIW, my blog is powered by spf13‚Äòs [Hugo](https://gohugo.io).
If I could add my 2 ¬¢, I'd recomment to also take a look on ["Concurrency In Go"](http://katherine.cox-buday.com/concurrency-in-go/) (I've read the pre-print). While GOPL et al surely explain concurrency, they do not really touch on more hard-core details of it, and concurrency *is* what you will work with in any "server" Go program of moderate complexity and above.
Yes compromise. Go has generic datastructures like slices, arrays, channels and maps *exactly* because it's a compromise. You might be dissatisfied with the compromise chosen - and for most people, that's because they wish Go *wouldn't* have compromised and instead adopted their uncompromising position instead. And it's fine disagreeing with the choice of compromise. But claiming that Go *doesn't* compromise on generics at all is simply false. Again, Go is *the* language of compromise. Not a single piece of its design is not subject to tradeoffs or beyond discussion.
I will never understand why people make these kinds of packages that are *incompatible with net/http*. There is a standard ecosystem in Go around `net/http`, whether you agree with the API choices made, or not, deviating from that is a bad idea. This change to add an error-return seems particularly counter-productive to me. A generic HTTP Server can't actually *handle* errors, as it doesn't know what the response code should be. Handle your errors in your Handler.
When you write a lot of servers, you'll realize `net/http` deviates from the idiomatic go error handling. Ever tried writing a custom dir listing on standard file server? Or err handling? Take a shot at the mchain fileserver. It's about better designed APIs. With `net/http` you never know which handler will throw what error. Even the internals of `net/http` is very messy, and it writes error statuses at various different points. Besides, if you design your APIs for mchain, you can use it with `net/http`- it's just `if err != nil {}` check away - :) ..
It just makes things shorter, and nicer. Take the`hconv` package for example - without type aliases they'll look far too verbose making the code difficult to understand. Besides, they are just aliases, if you find them nice, use them - or if you prefer verbosity - don't. Thanks to go1.9+, aliases work nicely :)
&gt; When you write a lot of servers, you'll realize net/http deviates from the idiomatic go error handling No, it doesn't. As I mentioned above, the HTTP Server/Framework/Whatever can't actually *handle* any errors. The idiomatic, correct place to do the error handling is in the business logic; everything lower in the stack is fundamentally unable to do so. Contrary to popular belief, error handling is not about returning an error and how to do so, but it's about what to do, when an error occurs. For an HTTP-Server, the correct thing is to write out an appropriate response and what that is will *always* depend on the application. It's not a decision a framework can make for you. The ResponseWriter interface is pretty well-chosen for that. In the case of an error, you still have to do all the same things as in a successful response; choose a response code, set some Headers (like Content-Type, or Location), write a Body‚Ä¶ From the Servers' POV, there is zero difference between an error and a success response, so it makes no sense to use the error type to communicate this. It's fine to say you want your business-logic to return errors; but then there should be an HTTP-layer, deciding what responses to write and a business-layer, which returns errors to the HTTP-layer. This perceived necessity of returning errors from handlers happens, when you mix up the two. (and‚Ä¶ don't do the "when you get more experienced"-thing, it's condescending. Always assume People know at least as much as you do. Besides, claiming that the way an stdlib package does error handling is not idiomatic seems‚Ä¶ bold.) &gt; Even the internals of net/http is very messy, and it writes error statuses at various different points. If it writes an error status after your handler gets called, that would seem like a bug to me (without closer inspection). Do you have a link? &gt; Besides, if you design your APIs for mchain, you can use it with net/http- it's just if err != nil {} check away - :) .. The problem is, that it doesn't *compose* well. If I have a bunch of middleware based on `net/http` and a bunch of middleware based on `net/http+error`, I can't just mix the two, I constantly need to convert between the different ways to handle the logic. That's a real cost for the Go ecosystem as a whole and I'd prefer if people wouldn't force that cost for the perceived small benefit of an error return.
&gt; As I mentioned above, the HTTP Server/Framework/Whatever can't actually handle any errors. I find this statement disturbing on many levels. In HTTP, you technically only can't change a status sent to the client after you've sent it. But in a server, a lot of things can go wrong between that point and the end of the request - and they `have` to be handled appropriately. &gt; The ResponseWriter interface is pretty well-chosen for that. I've seen comments by one of the primary designers bradfitz, to have stated as well, that the interface assertion style followed by `net/http` was a mistake. &gt; If it writes an error status after your handler gets called, that would seem like a bug to me (without closer inspection). Let's say you choose your API to have a media-type for json. There are tons of places in the `net/http` that will make it send a html content-type as error in-between. It's tried as best as possible to limit those scenarios, but it can still happen. Please read through the `net/http` code and you'll find so many places where it could return error responses. If you follow the mchain way - you can always catch it in the handler, and return json responses, as it would be expected out of the server. Point being - standards are not set in stone. Mistakes happen. And standards can be evolved only through experimentation. It's an unfortunate fact of life, that it's doesn't just inter-operate blissfully. Tough luck. But with `mchain` - I try my best to make it composable and interoperable. 
[removed]
You can see for yourself [here.](https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=fortune)
I have read it both and The Go Programming Language is much better in my opinion.
Why? Especially setTimeout. The only thing it does is to change a general purpose duration type to milliseconds, making things worse for no reason whatsoever. Also, the busy-wait loops with data races in the main functions. There must be better ways to heat a room than with a CPU.
Winter is coming, we need all the heat we can generate
I'm kinda horrified that object re-use didn't seem to even occur to him, instead opting to experimentally derive a nonsensical value for GOGC!
The moment this guy changes his code, that magical number will have to change. This is terrible programming practice. And the guy seems proud of it too.
Unfortunately this is typical for that particular company. It's almost like they are pressured into boasting about stuff they've done, without any real thought into why -- just how.
I have: you're missing measurements. I'd recommend creating a very simple application which would read some chunk of real data from a real database file do real calculations and then serve the result to a front-end (which can be something like `curl` at this point). *Measure* whether it works OK for you. Some random things to note. * Don't be thinking too wishful along the lines of "Golang ‚Ä¶ would distribute the workload": while by default the Go runtime in a Go program will indeed try hard to make sure it's executing `$number_of_CPUs_reported_by_OS` goroutines in parallel, this, in itself, is all it will do. This, in turn, means several other things to consider: * If you spawn 1024 goroutines all crunching math on a 4 core box, you still have ca. 3.8 goroutines running in parallel at any given time (those 0.1 will be eaten by the Go runtime and the OS and whatnot). * You will need to make your data actually *parallelizable* so these goroutines will indeed work in parallel ‚Äî and not in turn (say, by holding a lock to that data). * There may be required some step to collect and combine the results generated by those goroutines. * The SQLite database may be a bottleneck in itself (disk I/O). This also needs assessing.
Good idea re: measurements. I'll chat to the client about setting aside some hours for this. SQLite definitely isn't the bottleneck - the data gets from the go web server almost instantly. It's the processing after the fact (in JS) that is the slow part. This I have measured. &gt; You will need to make your data actually parallelizable so these goroutines will indeed work in parallel ‚Äî and not in turn (say, by holding a lock to that data). &gt; There may be required some step to collect and combine the results generated by those goroutines. Yup. It is going to be a pretty big rewrite of some logic and control structures. However, they are all in JS Promises right now, so it can't really get worse. Thanks for taking the time to reply. Definitely some things to think about.
&gt; I find this statement disturbing on many levels. In HTTP, you technically only can't change a status sent to the client after you've sent it. But in a server, a lot of things can go wrong between that point and the end of the request - and they have to be handled appropriately. My Handler returns `os.PathError{Op: "open", Path: "foo", Err: syscall.Errno(syscall.ENOENT)}`. What status code should the server send? I can, from the top of my head, come up with valid scenarios at least for 200, any 3xx, at least 10 different 4xx errors and several 5xx. Each of this scenarios *could* come with a Body (and a Content-Type Header) and the 3xx *has to* come with a Location-Header. So, to actually *handle* that error, that is, translate it into HTTP, you need to know enough about the business logic to know a) what status code it has to map to, b) whether that handling requires a body or not and c) what other Headers need to be set. Yes, you *could* define a response-type to contain all of that, making the signature essentially `func(req *http.Request) *http.Response`, but that would require, for streaming response writes, to spawn a new goroutine to serve the Body that is presumably returned. Or‚Ä¶ well, you just take an `http.ResponseWriter` which supports the necessary logic. But yeah, between those two, it's basically a tossup. But if you return an `error`, you need to make sure, that you communicate *all of this information* to the server-package. That is not a good design and it is *not error handling*. &gt; I've seen comments by one of the primary designers bradfitz, to have stated as well, that the interface assertion style followed by net/http was a mistake. That is a completely unrelated issue. It's about additional, optional features, not about error handling. &gt; Please read through the net/http code and you'll find so many places where it could return error responses. Can you point me to a specific instance of where that happens, after your Handler got called? Because from what I can tell, [this](https://github.com/golang/go/blob/fa1f52c5f61fdda063851be16366b5eda5a08e58/src/net/http/server.go#L1804) is the point where the server hands off the handling to your Handler and after it calls that, the only code it will send is 200 (if you didn't send a header yourself). But it is impossible to prove a negative, so broad statements like "you will find many places" can not be disproven or discussed. Again, it's not about whether `net/http` would ever send an error code. It definitely will in the part of the stack that handles the protocol, before it hands the handling off to you. And it *might* do it even afterwards, if your response violates the protocol. But it shouldn't handle any business-logic errors of your application, if it does, I would consider that a bug. (there is one thing to consider, which are panics, which the server will recover and send an error response. I consider that a mistake and AFAIK the Go team mostly concurs these days, but panics are the opposite of error handling, so don't really apply to how you should do that) &gt; If you follow the mchain way - you can always catch it in the handler, and return json responses, as it would be expected out of the server. Again, there is an HTTP-Layer and there is a Business logic layer: func ServeHTTP(w http.ResponseWriter, r *http.Request) { p := extractBusinessLogicParameters(r) v, err := BusinessLogic(p) if err != nil { serveBusinessLogicError(w, err) return } serveBusinessLogicValue(w, v) } There is no need to intermix the two. The HTTP handling layer translates HTTP data like Headers and request paths to business-logic values, passes them to the business logic functions and translates the returned values back to an HTTP response. You have to implement the HTTP logic yourself (as it is a design decision what endpoints there are and what is served on them), but there is no need for your business logic to concern itself with HTTP. But it has to be *your* HTTP handling logic, depending on your specific HTTP-mapping, that should handle the errors your business logic throws at you (i.e. translate them to HTTP responses), because it is related and knows about the business logic. The *server* (or middleware or framework‚Ä¶) does not know about your business logic so it *fundamentally can not do that translation*. &gt; I hope you're aware that using net/http will voilate W3C HTTP standards in so many scenarios Please file bugs for any such violations. *if* `net/http` violates HTTP standards, that is a clear bug that should be fixed. I don't believe it really does (in a significant way), though, unless you explicitly tell it to.
I'll put up a codepen of what 99% of the functions are. Its mostly just for loops on large arrays with conditions and comparisons inside them. E.g. https://codepen.io/anon/pen/rYwRaR?editors=0010 So my question is, would that for loop and sorting be done faster in Go or Node? Or do you know of any studies or comparisons? (I know that I could rewrite that specific code to be a lot more performant, it's just a simple example)
It's a bit repetitive but isn't too hard to do. Here's an example of write and read for int64 func WriteInt64(buf *bytes.Buffer, i int64) { binary.Write(buf, binary.LittleEndian, i) } func ReadInt64(buf *bytes.Buffer) int64 { var i int64 binary.Read(buf, binary.LittleEndian, &amp;i) return i } using the imports: "bytes", "encoding/binary"
Think about it this way: `func main` does not return an error. Why? Because the runtime can't actually *handle* your error. It could barf it out and return an exit-code, but that's not necessarily the correct thing to do in that situation. By not returning an error, the Go runtime tells you "you can not return an error, thus you have to *handle* any errors you observe". Error handling is the process of destroying error-values; taking an error and turning it into nothing, guaranteeing the correct exit of your program. Now, of course you *can* barf out an error and return with a non-zero exit code and for *some* programs that's the best thing you can do in response to an error. So the runtime gives you capabilities to still create these side-effects via `os.Exit` and `os.Stderr`. But crashing is not the correct response for all programs, so the runtime doesn't pretend it can handle your error and forces you to do it yourself. In *exactly* the same manner, `http.Handler` does not return an error. A correct HTTP-Server needs to serve *some* response, so the server can't just crash. By not allowing you to simply return an error (which would then, presumably, make the program crash or be returned from `ListenAndServe`), the server tells you that it can't actually *handle* it; it needs to serve an HTTP Response and you have to tell it which. By not returning an error, the server *encodes in its type*, that you need to absorb any errors yourself and transform them into an HTTP response, via the provided ResponseWriter. If, on the other hand, you allow a Handler to return an `error`, you are, in a sense, making the promise that you will be able to handle that in some way or another. And I strongly believe, that there is *no generic way* to handle errors in an HTTP-Server (as in, a generic HTTP framework), as it has to decide on an error code and what the correct error code is, depends heavily on the business-logic, it knows nothing about. Anyway, 'nuff said‚Ä¶
Cool! Checking the interface implementation snippet was interesting. I don‚Äôt think I‚Äôve seen that before
@TheMerovius - What you're saying making perfect sense with one critical assumption that you make - you consider everything to be a blackbox that's capable of handling both it's errors and success. What if there are 2 black boxes, and second executes only if the first fails? Let me give you a realistic practical example - A simple http file server. (This interestingly is a pain in Golang if you care about returning custom errors, custom directory listing etc). Now, your `http.Handler` will take in the request. It has to handle everything now - you have no control over it. What if you want to search for a file, and if it fails, then gracefully execute a different handler? What if in case of a directory, you want to do a custom listing, but want to reuse as much of the handler as possible. With `mchain`, what happens is FileServer will return an error which on success is nil. If file is not found it's returns `NotFound` error. You can check for the error, and handle it in any way you like. If it's a DirListing - you can choose from the default to internally handle it. Or you can choose for the API to propagate the error out, and so you can handle it yourself. The key is, it provides you with very nice flexibility which improves code reuse and better communication between API. I had religiously used `net/http` before, and I designed `mchain` after facing these API design restrictions. While in the beginning it did feel like I was doing a lot of error checking, over time, it felt a lot more idiomatic with other Go code you generally write, and I found build reliable and dependable apis with maximum code reuse much better than the standard APIs. And the best part is, since you design APIs with the mindset of trying to propagate much of the errors, if you want to just make it a `net/http` handler - you just wrap. You can't do the same, the other way. Infact, I encourage you to read the source of go's `net/http` file server code, and mchain `filehandler` (provided in the related section in README). I'd personally found the reuse and api styles to be far nicer. :) 
The SIGQUIT part is already a part of the runtime, otherwise a good list!
I'm just getting started with Go (coming from a C#/Elixir/Elm background) and looked at this book, but it was published over two years ago. That seems like eons in CS years. Is it still relevant enough to buy? I wonder if a second edition will be released.
That was disappointingly thin... it mentions an example context just once, then uses an example that's not directly connected to it. It spends only a brief time trying to explain the principle, and then launches into the conclusions without getting the reader there.
&gt; his interestingly is a pain in Golang if you care about returning custom errors, custom directory listing etc Can you give an example of where this works better? Because I don't understand the point you are making. &gt; It has to handle everything now - you have no control over it. No, you have *complete* control over it. It's your code, after all. &gt; What if you want to search for a file, and if it fails, then gracefully execute a different handler? func ServeHTTP(w http.ResponseWriter, r *http.Request) { name := extractFileName(r) f, err := searchFile(name) if err != nil { otherHandler.ServeHTTP(w, r) } serveFile(f) } &gt; What if in case of a directory, you want to do a custom listing, but want to reuse as much of the handler as possible. What about it? func fileList(dir string) ([]File, error) func ServeHTTP(w http.ResponseWriter, r *http.Request) { dir := extractDir(r) fs, err := fileList(dir) if err != nil { serveError(err, w) return } renderListing(fs, w) } The point is, that if you don't insist on making every single thing in your software an `http.Handler` or a `func(http.Handler) http.Handler` there is absolutely no problem here. You want to write a file server which supports custom listing, custom error handling, custom permission models‚Ä¶? Fine: type FileServer struct { CheckPerm func(context.Context, name string) bool RenderListing func(context.Context, []File, io.Writer) RenderError func(context.Context, int, io.Writer) } func (f *FileServer) ServeHTTP(w http.ResponseWriter, r *http.Request) { re := f.RenderError if re == nil { re = defaultErrorRenderer } name := f.extractFilename(r) if f.CheckPerm != nil &amp;&amp; !f.CheckPerm(r.Context(), name) { re(r.Context(), http.StatusUnauthorized, w) return } fs, err := f.listFiles(name) if err != nil { re(r.Context(), http.StatusInternalServerError, w) return } rl := f.RenderListing if rl == nil { rl = defaultListingRenderer } rl(r.Context(), fs, w) } You want to make the argument, that the builtin `http.FileServer` isn't customizable and great, cool, I can buy into that. But that isn't a good argument about `http.Handler`; just about *this particular Handler*. Build your own FileServer, the stdlib one doesn't have to be perfect for everyone. And you can have your FileServer implement `http.Handler` (like I did above), or you could give it some other signature, if you prefer (like I did at the top of this comment, as a series of composable helper functions returning domain types). But "I want to write $thing and $interface isn't a good fit for $thing" isn't a great argument to change $interface. You could also have the type implement whatever interface you like; if `http.Handler` does not fit the level of abstraction you are aiming at (for example, because you don't want to build error handling in), feel free to provide a different API. But `http.Handler`, as "the type that you give to an HTTP-server, framework or middleware to dispatch requests to" is a sensible interface and adding an error-return is basically pointless; because you are promising that you can correctly handle the error. Which a generic HTTP Server simply can't. An `http.Handler` is a type that says "Give me an HTTP request and a way to respond to it and I will serve it". A `func (http.ResponseWriter, *http.Request) error` is a type that says "Give me an HTTP request and a way to respond to it and I might serve it, or I will return an error, in that case good luck". You are resolving the implementer of `Handler` from handling the error (as they can just pass the buck), which is convenient for the implementer. But you are majorly screwing over the implementer of the server, framework or any middleware. Because now *they* get passed the buck and somehow have to deal with it, even though they have no clue how and even though your business logic is a far more logical place to handle it. Like, that's essentially the point, at *some* point the error needs to handled (that is, transformed into nothing). The `http.Handler` interface tells you, in no uncertain terms, whose job that is: Yours, the implementer of `http.Handler`. An error-return loses that information from the type. "We might pass errors around and someone will deal with it at some point, we hope". Like, take your JSON-example. This obviously will *only* work, if the bottom-most middleware does the translation of errors into JSON serialization. Meaning, you have a correctness-requirement ("the JSON middleware needs to be in the chain") that is not expressed in the type-system. If, on the other hand, you view JSON serialization as an application-specific concern, you can have func JSONHandler(b BusinessLogic) http.Handler which expresses the error handling responsibility just fine. "Give me some business logic and I will make sure that everything gets an appropriate HTTP response".
The router can handle errors. Given the error response in a web app is usually the same for all handlers (show to user error code and message) it makes sense to handle it there IMO. Also fine to handle it with a helper if you prefer. 
I believe that errgoup cancels the context and waits on the wait group, so on the first error it will call cancel, and if other goroutines are selecting on &lt;-ctx.Done() then they can exit with ctx.Err().
Well the CPU running 80C internally is quite normal for a powerfull router from what i know
TGPL is really a fantastic book! It is a stimulating reading, recommended to anyone only small things have been added, all the code is comptible forward
You see. Everything you've done is `workaround` the problem without considering performance or efficiency. I'll tell you why. Let's take this code. ``` func ServeHTTP(w http.ResponseWriter, r *http.Request) { name := extractFileName(r) f, err := searchFile(name) if err != nil { otherHandler.ServeHTTP(w, r) } serveFile(f) } ``` What you're doing is: You're searching for the file, and then passing it on to `serveFile`. Here's the problem. `ServeFile` already will have to searchFile anyway. So, basically, you run search file twice, for every request handled by the `serveFile`. This is the same for dir listing as well. Now, one might think, on the grand scheme of things this is okay. Afterall, search file should be fast enough to run twice. But what if this is a some CPU intensive cryptographic algorithm. With mchain: ``` func (f *FileServerEx) ServeHTTP(w http.ResponseWriter, r *http.Request) error { err := ServeRequestPath(w, r, f.root) if err != nil { e := err.(*Err) l := log.With("path", r.URL.Path). With("status", e.Code()) if !errutils.HasMessage(e) { l = l.With("cause", e.Cause()) } switch e.Kind { case ErrRedirect: if f.RedirectsEnabled { e.Headers().Write(w) w.WriteHeader(http.StatusMovedPermanently) return nil } case ErrFsOpen: l.Warnf("fileserver: kind: %d, %v", e.Kind, e) if f.NotFoundHandler != nil { return f.NotFoundHandler.ServeHTTP(w, r) } default: l.Warnf("fileserver: kind: %d, %v", e.Kind, e) } } return err } `` This is real production quality code at https://github.com/prasannavl/go-gluons/blob/master/http/fileserver/extended.go You seem to be very strongly advocating workarounds, rather than acknowledging the real problem. With `mchain` - You HAVE the option. You can handle things internally as you do currently, if you strongly feel a certain component needs uphold a certain contract. Or you can also pass it along for components that have the option. I'd encourage you to think a little outside of the go std box, and see if better solutions are solutions. However, if you're happy with what it provides, well good for you :)
Thanks for replying. I shouldn't be so surprised. Before approaching Go, I spent some time getting familiar with Node.JS. One of the big attractions to me of Go over Node was that the JS ecosystem moves too quickly in my opinion and Go decisions seem much more deliberate rather than chaotic.
I didn't, so thanks for the link.
Although I do not like their development model, but I like the decisions that are made about the language the language in general (having gone through c, c ++, java and lips) is a joy
Bamboozled by title ._.
From the checklist &gt; always close http body aka defer r.Body.Close() &gt; unless you need leaked goroutine According to net/http documentation &gt; For server requests the Request Body is always non-nil &gt; but will return EOF immediately when no body is present. &gt; The Server will close the request body. The ServeHTTP &gt; Handler does not need to.
Middleware handling in most minimal form is https://github.com/justinas/alice
Actually, this is more minimal than alice, if you just want to use `HttpMiddleware` which the standard. This infact uses a builder pattern, where the middleware chaining is more cleanly separated than alice :)
This did not mention the canonical wisdom: https://blog.golang.org/errors-are-values
&gt; Given the error response in a web app is usually the same for all handlers (show to user error code and message) I vehemently disagree. As I pointed out, there are at least three different pieces of information needed to actually correctly serve a response: a) The code, b) the body and c) a set of headers. Yes, you *can* put them in their own type, but that type shouldn't be `error` -- `error` is *any* error and you can only actually handle these specific `HTTPError` kinds of errors. Promising to handle more, is a problem. However, if you actually do actually handle things that provide these three piece of information, you are essentially just‚Ä¶ passing an `http.ResponseWriter`. &gt; Also fine to handle it with a helper if you prefer. That is fundamentally the correct choice, if you want to remove duplication: The *handler* calls some function to handle the error (or just does it itself). Because, after all, that is its job: Deciding what HTTP to serve.
&gt; http.Handler is actually not very well designed for complex web applications, it needs to be wrapped into something else. Thanks for mentioning this. I'm happy to see someone else share the same view. I suspect Google's priority is likely just microservices, and as such they got away with poor design during the Go 1 - and now it's stuck, and it would break compatibility to change it -- if at all the designers are willing to see the problem for what it is, rather than suggesting workarounds.
The context of the advice is assuming you are a client downloading some HTTP page, not a server reading what was POSTed to you.
&gt; strip your binaries with this command I'd rather use upx.
&gt; No. You wouldn't want to pipe a template stream directly into ResponseWriter But the ResponseWriter interface does not force you to do that. It simply provides a way to pass the minimum amount of information to correctly serve HTTP: a) the code, b) any headers and c) the code. It also *needs* to provide a streamable Writer, because of things like [Server Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events). If the server(/framework/‚Ä¶) where to force buffering (no matter the mechanism. E.g. by using a `[]byte` return), you could not implement Server Sent Events on top of it. Whereas, with the current interface, you *can* build a buffered Handler on top. &gt; You don't want to return a 200 status when your template failed rendering for any reasons. But as soon as you write something in the response stream it is sent to the browser. Yes, don't do that. Only start writing, once you have all the information needed for the headers. Note, that this is explicitly part of the [ResponseWriter interface](https://godoc.org/net/http#ResponseWriter), even though the Go type system is not powerful enough to express that requirement as a type. Yes, there are ways around that. There are redesigns of `ResponseWriter` that would be able to express this, like type ResponseWriter interface { Header() Header WriteHeader(int) (body io.Writer) } But that doesn't change the fact, that you need to be able to explicitly communicate these three piece of information needed to serve HTTP (code, headers and body) - and that using `error` to do that is fundamentally a bad choice. Yes, `ResponseWriter` isn't great in *absolute* terms; but it is great, relative to a design relying on an error-return.
You are correct, sir. There's even an example of using it in the docs, [Group-Parallel](https://godoc.org/golang.org/x/sync/errgroup#example-Group--Parallel). I wonder if it's feasible for HTTP requests without limiting them to X at the same time, because all of them might be in flight before the first one would fail.
&gt; But that doesn't change the fact, that you need to be able to explicitly communicate these three piece of information needed to serve HTTP (code, headers and body) - and that using error to do that is fundamentally a bad choice. Yes, ResponseWriter isn't great in absolute terms; but it is great, relative to a design relying on an error-return. You design doesn't reply on just error-return. Error return supplements the handling with `ResponseWriter`. `Status` and `Body` can atleast be both be handled in a modified `ResponseWriter` fine (though not the best of design in my opinion), like the one I have here: https://github.com/prasannavl/go-gluons/tree/master/http/writer But error cannot be - which is where mchain steps in, and supplements. 
True, I'll add the link on later tonight. Good that I echoed those thoughts pretty well I think :)
[removed]
I'm not in the market but am willing to receive one, if that's what you're asking!
I also use `upx --brute` but maybe there is a code analyzer which removes all unneeded source code right before compilation, without touching the original files. But the final binary can then panic because of interface{} stuff ... but I bet you then have proper integration tests ;-)
&gt; Here's the problem. ServeFile already will have to execute some form of search file anyway internally. Uhm. No? It gets passed the return of searchFile, which can be anything you like (including a `[]byte`, an `*os.File`, an `io.Reader` or an `http.File`), depending on your implementation. This is not an API-problem on the side of `net/http`, this is an implementation-problem on how you implement the `Handler`. &gt; Besides, the file server already has the capability to do the search for, I see no point replicating it's efforts outside of it again. The reason is, that it doesn't support the features you request from it. It also won't support the features (or an arbitrary set of features) if you change it's Handler to something else. Again, you are making the argument that `http.FileServer` isn't great, which is fair, but it's not an issue of the `http.Handler` interface, it's an issue of the `http.FileServer` API. It doesn't have to be an `http.Handler`, if you want to implement a more powerful/feature-rich file server. And adding an error return won't help it *become* a more powerful file server. I mean, let's say you take the existing `http.FileServer` and have it return an error if it can't find the file. Now, I want to have a FileServer with custom ACL-checks. How? Using the returned error won't help me - it will return nil, even if the file should be access controlled. So, the only thing remaining is‚Ä¶ duplicate its searching/path-walking mechanism including all it checks, add my own ACL checking around that, based on the mechanism I want and serve the file. So, in essence, the error-return *seems* to make the interface more powerful - but the reason for that is purely, that the feature you *want* to add (basically a glorified custom 404-handler) can be served by that. But that's because you are being incredibly specific in the feature you want to add. Meanwhile, if you change `http.Handler`, but instead make `http.FileServer` its own type, with its own methods (some of them using http domain types to serve the actual response, others using file server specific domain types to express, e.g. file listings), adding these functionalities and reusing them becomes much simpler. You wrap it in your own `http.Handler`, make the checks you need to do (using its exported helpers for the file-walking and basic checks) and then call its exported http-specific methods to serve the file, if all the checks pass. The problem here, is that `http.FileServer` implements the `http.Handler` interface - it implements the contract of an HTTP-Handler, which *by its definition* serves HTTP as an encapsulated type. If you want to get rid of the encapsulation, don't change the definition of what a HTTP handler does, but change the fact that FileServer bundles too much functionality. &gt; But current model forces you to do it. And that's *precisely* the core of the issue. The functionality of `FileServer` you are interested in changing is *business logic*, not *HTTP* logic. The current model forces you to do it, as long as you implement the interface of an `http.Handler` which is a *deliberate and good choice*. But nothing about the current model actually forces you to implement business logic as an `http.Handler`. &gt; This is real production quality code Uhm, okay. But the code does not, in any way, depend on how the actual *Handler* interface looks. Indeed, you are implementing your own fileserver as a set of [helper functions](https://github.com/prasannavl/go-gluons/blob/master/http/fileserver/fileserver.go ), none of which are `mchain.Handler`s. Which then gets wrapped into an [http.Handler](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/fileserver.go#L24) without any problems (except, of course, that bug where you don't handle most errors, so they cause a panic). And the *actual* [mchain.Handler implementation](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/extended.go#L37) uses‚Ä¶ essentially the same code, doing *exactly* the same thing. Except for the [unhandled error](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/extended.go#L63 ) it passes on. Meaning upstream won't know how to handle with that, as it can't tell where it's coming from (and so all it can do is return an unhelpful and probably wrong error to the user). Like, sorry, but that code, to me, seems to perfectly illustrate everything wrong about the `mchain` approach. The error handling path is simply broken in the examples - even *though* you manage to get exactly the same functionality without resorting to `mchain` at all. &gt; You seem to be very strongly advocating workarounds No, not at all. I'm very strongly advocating the correct error handling path as defined by the interface. This isn't a "workaround", it is the intended, idiomatic solution of how error handling in Go works: You *handle* your errors, you don't just drop them on the floor and hope someone else deals with them. &gt; You can handle things internally as you do currently, if you strongly feel a certain component needs uphold a certain contract. No, you do not have the option of not handling an error. If I write an `mchain.Middleware`, I am *forced* to handle errors, even if I fundamentally can not do it. That is because the thing I am calling returns an error and expects someone to handle it, so I have to do it - one way or another. Meanwhile, if I write a plain old http Middleware, I don't have to handle any errors. The thing I'm calling into will do it for me. And if I call into a non-Handler and that returns an error (say, I read credentials from a database), I am forced to *handle* them, because I can't just pass the bug. If I write an `http.Handler` I am aware that it's my responsibility to actually handle any errors my dependencies pass on to me, so I do. I can't just lazily pass them on, losing context in the process. &gt; However, if you're happy with what it provides, well good for you :) Sure, I mean, whatevs. But just to be clear: I'm still disgruntled by the inherent fragmentation in the Go ecosystem this creates for no benefit (and probably a net-downside).
If I had to guess without any measurements, my guess would be that the fastest thing you could do is to [create the correct index in SQLite to work with the correct WHERE clause and to use an index that will sort in the order you want](http://use-the-index-luke.com/), then just return the data straight through to the user side. If you're doing something else to it as well, like summing it up, try it in SQLite as well. It's hard to be much more specific because while I recognize you're not trying to be, this is a very vague question with answers that could go any which way depending on a huge pile of details. It also depends a lot on the data in question; for instance, is it really just a huge array of numbers, or are you using that as an example but it's actually a huge array of complicated objects?
alice can be used as builder pattern too alice.Chain(first).Append(second).Append(third).Then(handler)
Could you please, please, please, *please* do a blooper reel and call it "for func's sake" ? It would make my day.
It's actually a huge array of simple objects. It's for a analyzing stock data. So it has a timestamp, price, and volume for each tick. I'm having to aggregate. The thing is, the aggregation will change depending on the time range selected which is always going to be user-defined, and some of the calculations I am just not able to achieve in SQL. 
Maybe [Visual Studio Code](https://code.visualstudio.com/) plus the [Remote VSCode extension](https://marketplace.visualstudio.com/items?itemName=rafaelmaiolla.remote-vscode) might meet your needs. You need to have an ssh connection to the server, and you need to be able (i.e., have the permission) to run a tool (mate) on the server. Disclaimer: I have not yet tried this myself yet. VSCode does not come with a strictly *visual* debugger, but at least you can start Delve from within the UI, and see various info (locals, watchlist, call stack of each goroutine) while stepping through the code.
From the docs: &gt; It's even simpler than the very neat alice package. However, the HttpChain provides no Append, Extend like methods. They are cleanly separated into a builder - HttpChainBuilder, that provides all the composition. So, now the Middlewares field is public, and HttpChain can be transparently passed around, cloned, extended at will. The idea is that Chain type is simpler - so you can transparently, pass, clone, and extend with just the primitive Go functions like `append`. 
HTTP client's Transport will not reuse connections unless the body is read to completion and closed Isn't that was fixed in recent Go version?
Can you provide any details on what the setup is? Based on the mention of vim-go I'm guessing this is Linux? Does it have X and/or VNC installed? My first choice would probably be to use a generic remoting solution to gain access to whatever IDE works best (personally I use VS Code in Linux with great success, but if you have generic remote desktop access you could use anything).
If you read the SO link, it's to have SIGQUIT dump the stack *and leave the program running* - though that seems like a terrible idea to me, and better-suited to a signal that doesn't already have established semantics that it *should* kill the program.
ssh + vi?
Err.. &gt; Uhm. No? It gets passed the return of searchFile, which can be anything you like (including a []byte, an *os.File, an io.Reader or an http.File), depending on your implementation. Read into the source, it will `ServeFile` will call APIs like `fs.Open`, `fs.Stat` etc - which is what I meant by search for the file twice. And again, what if these are expensive ops - say a network drive. Or in another context, could be very expensive computations. &gt; Indeed, you are implementing your own fileserver as a set of helper functions, none of which are mchain.Handlers. Which then gets wrapped into an http.Handler without any problems (except, of course, that bug where you don't handle most errors, so they cause a panic). And the actual mchain.Handler implementation uses‚Ä¶ essentially the same code, doing exactly the same thing. I intended it that way - it was deliberately designed to be so, to ensure interop. And it's for a large part heavy refactoring and modification of `net/http` code. But `net/http` code handles errors in so many different places - it took a while to even get all of them and consolidate them. I think you're stuck up on singular examples. It's the mental model that the APIs promote. Why did I have to rewrite a lot of code from `net/http` to get a better file server? It's exactly because of how it was designed. My rewrite consolidates a lot of the err handling so that it's grouped together makes for easier understanding, maintenance and development - which is the model I wish to promote with `mchain`. &gt; No, you do not have the option of not handling an error. If I write an mchain.Middleware, I am forced to handle errors, even if I fundamentally can not do it. Its seem you're so disgruntled, you're skewing perspectives. You are not forced to do anything. Take the same fileserver examples - it handles all the errors for you automatically. But you have the option to opt out of it, and handle it yourself. Try doing that with`net/http`. It's either the `net/http` way or you're writing workarounds. You're entitled to your opinion. But please do try to have an open mind, than sticking to dogmatic views. It's an attempt to solve a set of fundamental problems I've seen in the past years, from experience. I've always felt `net/http` to be very fragile. 
Look into https://github.com/b3log/wide 
Not according to [the current documentation](https://golang.org/pkg/net/http/#Response): &gt; The default HTTP client's Transport does not &gt; attempt to reuse HTTP/1.0 or HTTP/1.1 TCP connections &gt; ("keep-alive") unless the Body is read to completion and is &gt; closed.
Sorry, should have mentioned that! The remote servers are running Linux, it has VNC installed, but they run really slow, so I'd prefer not to go that route.
I would love to see this checklist split up by context. Maybe along the lines of project, file, function, and even subdivide further by domain (e.g. not everyone is using Go for web development so some of these checks won't apply to everyone.)
Actually, you should use both. `ldflags="-w -s"` prevent unecessary debug information from being added to the binary, while `upx` will compress it.
Or "go func yourself"
OK. Then, continuing my guessing game, I'm going to _guess_ that the best thing to do is to do as much as you can in the SQL (which may be nearly nothing, depending on your logic), and then doing as much computation in Go as possible, sending the smallest possible final result down to the user. I'm guessing this for a reason that may surprise you. You've got four systems here: * The user's browser * Node * Go * SQLite and you _also_ have all the pipes between them, which I think are probably the dominant issue here. The idea I'm getting at here is to do as much in the Go as possible, so the serialization in Go and the deserialization in Node is minimized, as well as the serialization from Node to the browser, which is harder to avoid. It's a decent guess that Node might be able to get up to Go-ish speeds if you could put the computation there, because the JIT would probably figure out that you've got homogeneous objects, but that's harder to be sure about without a benchmark. It is also likely that rather than asking for a JSON answer from Go and handling it as JSON in node, that you want to just proxy either the request or the answer as a series of bytes, as that will be much faster than parsing the JSON and then deserializing it on the way out. If you trace through the chart above and consider the cost of all the links, you'll start to understand why the code may have been behaving more slowly than you might have expected. Of all the links there, it is also likely that SQLite-&gt;Go is the cheapest, assuming Go is accessing it in-process, because transferring that data between SQLite and Go will be an in-process memory copy of ints and strings and such directly, rather than an expensive serialization down to a full byte stream, followed by an expensive re-extraction of the data.
It's hard to tell exactly what's wrong with your code without seeing a bit more context, but here are some things to think about: 1) Are you sure you have the correct base address for the health value inside the process? 2) If newHealth is the correct base address for the health value you want to read (which it needs to be, per the API), then you are passing in the wrong size. The size should be the number of bytes you want to read, not the size of the base address. 3) You're ignoring the return value that tells you whether reading the value was successful or not. You probably shouldn't. 4) Once you're sure you're getting the right bytearray, it's pretty simple to convert to an int. See stackoverflow: https://stackoverflow.com/questions/20872173/more-idiomatic-way-in-go-to-encode-a-byte-slice-int-an-int64/20872656#20872656
http://vim.wikia.com/wiki/Editing_remote_files_via_scp_in_vim
Thanks. Its amazing that a stranger would be willing to type an in-depth response for free. I really appreciate it. I asked the same question in /r/webdev but nobody actually seemed to understand the issue. I am going to propose moving some stuff to Go and running some benchmarks to client to get the hours approved.
Pay it forward in a few years. That's what I'm doing. :)
Where? Are you with a school that has an internship program?
Agreed with prawn + prawn-svg you can do amazing things. I'm now having our designers create their vision with Sketch, then export it as SVG and use prawn-svg to render it.
Depends on where you are located. https://www.golangprojects.com/ has some listings of jobs. Otherwise I would look on Glassdoor and search for Golang and reach out to the companies for an internship that have Golang related positions. Best of luck! 
There is no restrictions about where, we have the freedom to do it anywhere in the world. I'm studying Ms computer science in Tunisia , and I have a mandatory internship for 4-6 months starting from February, then I get my degree. 
Thanks
&gt; Read into the source Which source? Your source? That just means you coded it that way, it doesn't mean it *has* to be that way. The Source of `net/http`? But again, that just means you are criticizing a specific implementation. It's nothing inherent to the API. The code you are referring in this part of the conversation ([the top block here](https://www.reddit.com/r/golang/comments/7ctt8z/a_super_tiny_go_package_that_handles_middleware/dpsw6gz/)) is not related to either your code (that I didn't know existed at that point) nor `net/http` - it is pseudo-code I churned out to illustrate how to compose reusable business-logic into an HTTP-Handler. Again, that's what I'm saying: You are criticizing `http.FileServer` for not being reusable and extended. I'm saying, that's because it chose to implement an HTTP Handler - not *what API* of an HTTP Handler it implements. Whether it would've implemented one with, or without an `error` return is immaterial for the reusability of its logic. And you've proven that - by factoring the business logic of it out into non-Handlers, which can then be put *inside* an HTTP-Handler (with or without an `error` return). The error-return from an HTTP-Handler doesn't actually change the situation at all. Thus your example of FileServer to illustrate that the error-return enables new patterns is just‚Ä¶ not correct. The reusability didn't come from returning an error from the handler, but from putting the logic into distinct, non-Handler helper functions. &gt; I think you're stuck up on singular examples. It's the mental model that the APIs promote. No, not really. On the contrary - I am looking at the big picture. Note, that the example comes from you, specifically. My big-picture view is, that a) the definition of an HTTP Handler is, that it serves HTTP responses, b) there is no general, reasonable way to translate an error to an HTTP response. Thus c) it is fundamentally problematic, for an HTTP server or framework, to pretend to be able to handle it, by letting you return an error from the Handler. I *am* talking about the mental model - and I'm trying to illustrate why the error-return model is wrong. `FileServer` wasn't *my* example, I'm definitely not hung up on it. I just happen to also think it illustrates quite well (and thanks for the code to illustrate it) how a HTTP-Handler *should* compose with reusable business-logic composable. And also as an example of how adding an error return value makes things *worse*. &gt; It's exactly because of how poorly it was designed I tried to point out, above, that adding an error return wouldn't actually *help* though. Again, the refactoring that helped, wasn't "we added an error return to `mchain.Handler`", but "we put all the business logic into non-Handler helper funcitons". I *agree* that `http.FileServer` is not very reusable (though I wouldn't call it "poorly designed", I would call it "targeting the 80%", which is different and fine, IMO, for the stdlib) and I explicitly agreed from the very beginning. But the change you are advocating for (adding an error-return to Handler) and trying to justify with this example *does not help with that at all and on the contrary, hurts*. &gt; My rewrite consolidates a lot of the err handling so that it's grouped together makes for easier understanding, maintenance and development - which is the model I wish to promote with mchain. Your rewrite does two things: a) It factors out the logic of the file server into distinct helper functions and b) It adds an error return to `http.Handler`. b) is the change I am strongly opposing. a) is *literally* what I'm suggesting to do instead. Once you do a), b) is not only useless, it's counterproductive. &gt; Take the same fileserver examples - it handles all the errors for you automatically. No, it doesn't. [Here, it may induce a panic](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/extended.go#L40), and [here, it passes on an error, instead of handling it](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/extended.go#L63). Passing on an error is *not* handling it. Your code does not actually *handle* the errors, which is literally what I am criticizing your model encourages and you still insist, that that's not what's happening. Even though the example *you specifically brought up* as a model of how this is superior is fundamentally broken and buggy due to the change. OTOH, compare that with the [http.Handler](https://github.com/prasannavl/go-gluons/blob/8209910ed7278089f9d7171c7ad8a7ef06d77964/http/fileserver/fileserver.go#L24) implementation. Yes, that panics too - but at least, in general, it will actually serve the request and handle the error in the end. Because you can't just pass the buck. And *that* is what idiomatic error handling in Go is. You get an explicit error and are encouraged to handle it gracefully. Not just pass it on. The exact point of the `http.Handler` interface is, that you *have* to handle your errors, because a persistent HTTP-Server can't just bubble up errors and crash, it needs to handle them, one way or the other. &gt; But please do try to have an open mind, than sticking to dogmatic views. I believe I gave pretty extensive and full justification of my opinions. It is super-annoying and frustrating to make arguments and then have them be ignored and be called "dogmatic". Like, here are some of the fundamental points I made, you are simply ignoring: * `http.Handler` is an interface that is used by `net/http.Server` to let you implement HTTP logic on top of a server giving you an implementation of the protocol. That server can't know what the correct status/body/header would be for a given `error` (see my `PathError` example from above, for how this is quite application-specific), so it is fundamentally flawed to include an `error`-return in that interface. * Error handling means "destroying the error", not "passing it on". That is, every error needs to, eventually, be gracefully handled into a code-path that does not error out (if nothing else, then because `main` does not return an error). The information on how to correctly do that is application-specific, so does not belong into generic frameworks or libraries. * An HTTP server *must* serve every single request. It can't/shouldn't bubble up errors and crash. Omitting the error-return from the `Handler`-type serves as a statically checked, type-based documentation of this requirement and having the `error` in there means, that this requirement now becomes dynamic (see, for example, the JSON-server example brought up above. For that to work, the topmost bubbly-uppy middleware must be one that translates errors into JSON; that requirement isn't expressed in the type, meaning if you forget to wire that in, you are going to have a bad time). * If you give me a function returning an error (for example, if I write an `mchain.Middleware`), I *have* to check that error and somehow deal with it. Thus by adding the error-return to the Handler-type, you are forcing anyone implementing an `mchain.Middleware` to check and deal with errors, even if they have no sensible way to actually *handle* the error. Whereas, if middleware needs to implement an `http.Handler` and takes an `http.Handler`, there are no error checks needed, because it is statically guaranteed, that errors are handled down-stack. And the middleware only has to deal with errors, if errors can occur from its dependencies. * `Handler` is supposed to implement the HTTP-handling specific logic of your Application. The rest of your business-logic should be factored out into functions/methods using domain-specific types and information, including error returns, which then get wired into that HTTP-Handler. If you structure your Application in this way as "the HTTP handler" and "the Business logic" as separate pieces, that makes the business logic reusable and composable. Touching the Handler interface, has no positive effect on your ability to do that destructuring. * In regards to *your specific example* of `FileServer`, the issue is exactly that the HTTP-Package *does not* do this destructuring and instead provides a single, monolithic HTTP-Handler. The reason it does this, is to serve the 80% use case simply and easly. It is a fair criticism that it would be more useful to destructure it, but, again, this has nothing to do with how the `Handler` interface (defined as "what you give an HTTP server to implement application logic to serve HTTP") looks, and everything to do with whether you actually destructure it in this way, or not. * Your code contains several bugs in its error handling, which illustrate quite well why focussing on error *passing*, instead of error *handling* is harmful. An error that is handled is one that you don't have to worry about. An error that is passed, you have to continue to follow through your code. As the bugs in your code illustrate, this is non-trivial, complicates things and leads to wrong responses from the HTTP Server. Like‚Ä¶ Don't tell me I'm "dogmatic". These are clear and falsifiable arguments I made, to which, to the best of my knowledge, there was no answer. So yeah, I'm frustrated, because it seems not only do the actual points I'm making go by ignored, I am then also being called dogmatic, because I won't just forget about them. And I'm being told I'm "hung up on specific examples", because I took the example you brought up and used it to illustrate how it is not only compatible with my arguments, but actually supports them. Even though the points I was making where *not* example specific, but very generic and applicable to literally any software serving HTTP from Go.
https://github.com/discordapp/lilliput
You could go full bore and install a web ide like codiad, eclipse chi, or something else and use it from a web browser (depends on your control of access to the firewall etc). I think there might be one or 2 new web ides being developed for golang specifically.
Because you can return easily. Otherwise, you need to juggle around with breaks and gotos.
Very nice !
`emacs --daemon` and ssh?
what does he mean by ``` time.Time has pointer field time.Location and this is bad go GC it's relevant only for big number of time.Time, use timestamp instead ``` Just use an int64? Or is there a timestamp object I'm not familiar with
[removed]
I actually like it. For this very specific purpose like it's a good decision to use the best of different worlds and make it work flawlessly. 
Not really, we do the same thing where I work. C does this faster and being able to do something like this is one of the things that makes Go useful imo.
After a lot of goc at work, I was happy to see how relatively easy it was to interact with pure c libraries/code/whathaveyou. This shows some of the real power behind go, imnsho.
&gt; it is pseudo-code I churned out to illustrate how to compose reusable business-logic into an HTTP-Handler. Yes. It was indicative of the http fileserver, and such I referred to `net/http`. &gt; You are criticizing http.FileServer for not being reusable and extended. Yes, and I reiterate the points I've tried to make - I'm trying to use this as an example of the mental model that the API promotes. Since the `http.Handler` functions don't have to care about returning errors, I've seen a lot of them designed poorly. Returning errors makes the api to be better thought out. This was the point I've been trying to make. I, again pointed to the `mchain` based `FileServer` to say how it tends to be designed when you flip the mental model. One can argue and debate on the weight of the co-relation here, but I seem to think it's pretty high. &gt; No, it doesn't. Here, it may induce a panic Nope. It doesn't. You seem to keep making incorrect assumptions like these, which is makes me ill-inclined to reply to each and everyone of your points. Why doesn't it? - Not all type assertion will panic. It's a safe assertion, because it's a contract that's implicitly upheld by the API. It always returns only `Err`. ` Passing on an error is not handling it.` - Incorrect. All the cases that need absolute handling are handled automatically, in the same code block you referred. You're safe to just ignore `err` as though it's like `http.Handler`, if you don't want to handle custom cases. &gt;. The exact point of the http.Handler interface is, that you have to handle your errors, because a persistent HTTP-Server can't just bubble up errors and crash, it needs to handle them, one way or the other. While the errors are passed on here, and I am yet to hear or see of production code that doesn't include a handler who's exclusive goal is error handling/panic handling. And I follow the idiom of the first handler up there being a logger, and the second handling all of these errors, and sending out http codes appropriately. So, you're statement about bubble up errors and crash is just plain misleading. Also, I along with mchain - I recommend passing along `httperror` that's referred to in the docs, which sends along an http error code. All of these have been tested, tried and helped me build robust services. I'm sorry I can't reply to each and everyone of your statement to cater to your personal frustrations, especially when a lot of them are based on assumption that's are skewed. It's an open-source piece of code that I refactored out my personal and company code, that I thought may be useful for the community - you're free to use them if you'd like or ignore. 
Indeed, right now if I want something cross platform which will work with my GUI programs I write it in C and build either a dll, dylib or .so depending on the platform. Being able to do this using golang will finally be a reason to use Go properly. I can do my front ends using some simple GUI tool with all the real code in dynamic libraries written in golang. That's what I will be looking into anyway. 
I mentioned it because you put a caveat with errgroup: You might want to break execution on error (all goroutines must finish) Maybe I'm misreading this, but it feels like this is covered.
TL;DR 60% fewer server instances, 90% of cpu time used for actual work (compression)
Looks like the Caddy plugin was updated too. Nice work!!
If you‚Äôre in Australia then there are a few places I‚Äôve heard of.
You can use gob if you don't care about the exact format of the encoding.
Ah I missed that part, habit of ignoring comments and directly reading the code.
How would the reader know?
This. Leaning on your IDE to solve ALL your problems (including remote connectivity), you're going to run out of options very quickly. Solve your remote problem separate from your IDE problem, this is the way forward...
Nothing in the article describes how it differs from the half a dozen other similar web services.
No, thanks. Discord is among the most harmful pieces of software around in the last couple of years.
Why do you think that?
I don't use the service and am wholly unfamiliar with it except that it's a bit like an IRC chat. Why/how is this service harmful?
Well, apparently it's less likely to lead to sucking and being unmaintained: https://talks.golang.org/2013/oscon-dl.slide
Will be possible to use the http header "refresh" on the image to not need the write JS?
Why not just fork a child process from node and do the lifting there? It's not clear to me why Go is even involved, you've built a complex system that could be a bit cleaner with just Node a few child processes.
That's why you pass the context to the http client, and it'll abort any in-progress operations for you too.
Care to elaborate? This is just a component of the Discord infrastructure so what have they done that would affect the usefulness of this code?
I have been looking for this for a long time, long story short. I have not been able to find anything that comes close to a native experience (i.e. code completion, debugging). I ended up just pimping out vim and running it all over ssh. After about 3 weeks my productivity is as good or better then using vs code. A big bonus is that I can ditch my bulky machine and just use a chromebook when I am coding away from my desk. 
The Gopher slack channel #golang-jobs is also a good resource
The easiest thing would probably be to use https://golang.org/pkg/mime/multipart/ to send a mjpeg stream to the client. 
I'm a fan of emacs, but the same concept applies. My editor works the same everywhere, local or remote.
Impressive! 
I like Discord, it's basically a less frustrating version of Slack. I tried to get out company to use Discord, which worked until our ~~BDFL~~ GM chose Slack instead and we all had to switch.
Sorry I think you meant to say one of the best.
The only argument I've ever seen is it's centralized, but then again so are all good social network systems so...
If you use Firebase authentication, you get a all that without having to build anything. Can also support multiple providers like Facebook and Google.
I guess solving a longstanding issue for gamers by offering a free and far superior product can be considered harmful... Somehow? 
&gt; If you use Firebase authentication I've never used Firebase Authentication, but it looks cool.
We never used Discord at work (we used Campfire, then Hipchat and now Slack), but I had that discussion in my head. I actually like how Slack integrates with github, jira, whatever the Atlassian wiki software is called, etc, and I don't think Discord would add the same value. Also still use Discord for friends though.
The non-allocation filtering one was cute, but like a few of the others I felt like it would have been much more useful with some accompanying text.
Is anyone using this in production?
How is that sad?
Sshfs? It mounts a directory on the remote server in your file system over ssh. It's not good over long distances or slow lines, though, and if it's a git repo it could get painfully slow if there's git features in the IDE.
Why would anyone use Python in the first place for data intensive operations is beyond me.
MUH READABILITY!!1
I think it's more like: MUH 10X PRODUCTIVITY
A "siries bizness" post on a site hosted on a dotcom doman whose author did not even figure out the language is called "Go", not "Golang". Unfortunately, this gives a clear hint at that the author got their education on the language solely from reading other blog posts.
It always disturbs me if someone tries to praise Go and calls it more often "Golang" than "Go". How serious should I take such articles? Getting names straight is not rocket science and just some basic, non-negotiable courtesy to the one being named. How serious would an article about Java be taken if it would be written sometimes "Java" and more often "Jawah". Btw I'm I big fan of Lamborkiny: They make the best cars, I really enjoy driving my Aventador Lamborkiny with its great traction. These cars are so beautiful and well built high tech tools.
Happens. You know that one guy, he does python but you don't care and delivers working stuff on time. Suddenly you have 1m customers. You scale. That's also a reason why many startups fail. The focus on tech stack instead of pushing the idea and drown in any momentum. 
Getting a Node Sqlite 3 package to compile cross platform was very problematic.
well i think they're equal bruv
Can you explain why you need remote *editing* at all? I mean, I can understand this for cases where a scripting language (like, say, PHP / Python / Ruby / JavaScript) is used, and you'd like to, say, apply some last-time fixups on the server side. But Go is a compiled language; if you intend to use a loop like edit ‚Üí `go run *.go` ‚Üí re-edit on your server, please unlearn this right away ;-) With Go, the approach is to edit everything locally, use `go install` for building, test and then transfer the generated *binary* program file to the server. If your development platform is different from the server, then either use cross-compilation such as $ GOOS=linux go build and/or consider having a simple VM or a docker container to run tests.
I'll add a clarification about cancellation to the article, thanks
I'm only wondering why they wouldn't use [libvips](https://github.com/jcupitt/libvips), opencv dependency also isn't lightweight, and it seems the choice of libraries is ... well, I'd expect libavcodec to be used in video processing, opencv for facial recognition...
Yes, me - but I'm the author, so, this does not count :) I'm using it to secure the access to backend interfaces for web platforms. But there are &gt;80 unique cloners in the 14 days github stats, so .. there seem to be some regular users.
Some where between Germany and The Netherlands)
I can explain: I do all of my development on a high powered Linux workstation, but physically access my workspace from multiple dumb terminals: MacBook, Mac Mini, Windows laptop. I don't want to handle synchronization of both the code and environment across these physical machines.
We‚Äôre probably talking past each other a little here. I agree the handler should be in charge of error handling, but once it has decided what to do, there is little difference between calling a helper or returning an error type which encapsulates the code and message to report. The router and/or middleware sees the writer anyway before and after the handler does, this way at least there is an indication of status from the handler to wrappers. Personally I prefer return error (custom type), instead of two lines - one to handle then another to return nothing - for the majority of errors which don‚Äôt require a retry and require immediate failure informing the user. I do think this is a personal choice and really not a huge deal for the ecosystem compared to using custom args on handlers - handlers are easy to wrap, the router I use accepts both styles and frankly I think this is a design flaw in the stdlib, which while v. good is not infallible. There‚Äôs even an example of this idea on the go blog: https://blog.golang.org/error-handling-and-go
? There are some mature advanced math and scientific math packages, and people write genome learning tools in python It's not blazing fast but it's not exactly uncommon 
You need to call out to another piece of software because Go cannot do the job well enough on its own, how is that not sad?
Congrats to all the commanders that made Go possible!
Did you read the article? They were using a python C extension using optimized simd instructions that was faster than than any of the go libraries they tested.
&gt; I agree the handler should be in charge of error handling, but once it has decided what to do, there is little difference between calling a helper or returning an error confirming type which encapsulates the code and message to report (since error is an interface this is easy). There is an *immense* difference. Let's talk through it with some rough pseudo-code. I guess, this is roughly the interface imagined here: type Handler interface { // ServeHTTP does some serving of Request. If an error occurs, it shouldn't use w and instead return an error. ServeHTTP(ResponseWriter, *Request) error } type Server { Handler Handler } func (s *Server) Serve(l net.Listener) error { // Do some serving things! go s.serveRequest(req) } func (s *Server) serveRequest(c net.Conn) { defer c.Close() r, err := s.parseRequest(c) if err != nil { // The client sent an invalid request. Whelp, but we want to be a good server that can't be taken down by a client, so just log it and move on. log.Println("Client b0rked up:", err) return } w := s.setupResponseWriter(c) err = s.Handler.ServeHTTP(w, r) if err != nil { wellFuck(err, w) } } What is the server supposed to do here? Crash? Obviously not. Just log it and move on? Nope, would violate HTTP protocol, the client sent a valid request, we have to send a response‚Ä¶ Well, I guess we'll have to *handle* it: func (s *Server) wellFuck(err error, w ResponseWriter) { // Well, we better tell someone that there was a bug in the code‚Ä¶ Let's hope the dev reads the log log.Println("You doofus, you where supposed to handle", err) Error(w, "The author of this server was kind of a doofus, so here we are‚Ä¶", http.StatusInternalServerError) } Hm, that's not great. We now a) have the possibility of introducing bugs in the form of unhandled errors and b) will in this case serve a 500, which is very likely not the correct response to whatever went wrong. But haha, you say! We just introduce an error type that people can use to communicate the *correct* Code. And body, and headers, because [all of these are needed for the correct response](https://www.reddit.com/r/golang/comments/7ctt8z/a_super_tiny_go_package_that_handles_middleware/dpssj72/). type HTTPError struct { Code int Headers Header Body io.ReadCloser } func (s *Server) wellFuck(err error, w ResponseWriter) { if he, ok := err.(HTTPError); ok { s.serveHTTPError(he) return } // ‚Ä¶ s.thisDidntHelpAtAll(err) } Hm, drat. Given, that the Handler returns an `error`, we have to type-assert, that type-assertion can fail and we're back to square one. So, let's see‚Ä¶ How about, we instead just say the error can't be anything, but an `HTTPError`? That should help! type Handler interface { ServeHTTP(ResponseWriter, *Request) *HTTPError } func (s *Server) serveRequest(‚Ä¶) { // ‚Ä¶ he := s.Handler.ServeHTTP(w, r) if he != nil { s.serveHTTPError(he) } } Phew. It took some work, but we got there. We can just return an error if an error happens and still get correct serving. On second thought, there is something weird here, we return *either* an HTTPError, *or* write to `w`; but the provide exactly the same information. I guess we can get rid of one of them, then type Handler interface { ServeHTTP(ResponseWriter, *Request) } func (s *Server) serveRequest(‚Ä¶) { // ‚Ä¶ s.Handler.ServeHTTP(w, r) } Wait a minute! We haven't changed anything at all! Now, at this point, let's take a second to summarize: a) In that last step, you could've also removed the ResponseWriter, because you think that interface is bad and passing around a struct is better. I have opinions on that (there *are* advantages to both), but it's only a very weak opinion. Basically a toss-up. And b) The difference between `HTTPError` and `error` is *exactly* what my criticism is about (not the difference between `HTTPError` and `ResponseWriter`). When I say "ResponseWriter is a decent API to communicate the response", I'm saying that a) is basically an uninteresting question in my opinion. The valid criticisms of ResponseWriter, however, *only* deal with a). They are irrelevant for b). b) is the issue I'm talking about. So‚Ä¶ No. I vehemently disagree with this: &gt; there is little difference between calling a helper or returning an error confirming type which encapsulates the code and message to report (since error is an interface this is easy). There is an *immense* difference, whether you call a [Helper](https://godoc.org/net/http#Error), which *handles* the error and transforms it into a response (thus doing the correct thing to solve b), or whether you return an `error`, which does exactly the *wrong* thing about b) - even if that error may also be able to contain all the information needed, because `error` is an interface. `error` being an interface, instead of a concrete type, is *literally* the whole problem. Now, to be fair, there is another stance you could take: That the problems of "chaining Middleware" and "serving HTTP" are distinct. And that the error makes the chaining problem easier. And, to be clear, *that is a totally fair stance to take*. But in that case `Handler` is *the wrong interface to use chain*. A Handler implements exactly the "serving HTTP" problem, not the "chaining Middleware" problem. By reusing/changing the `Handler` type, you are mixing up the problem, instead of separating it out. So, to chain middleware, you should make sure a) your chain implements `http.Handler`, b) your chain *accepts* an `http.Handler` (more on this in a sec) and, optimally, c) you don't use `Handler` as a type in the middleware at all. Make it `type Chainable interface { ChainMePlenty(‚Ä¶) error }; type Middleware func(Chainable) Chainable` or whatever. b) and c) are there, to prevent what I call "fragmentation of the eco-system". If I write a Handler, I currently implement `http.Handler`. And if someone writes a Handler for `awesomechain.Handler`. Then 1) *I* need to glue their handler to a well-behaved `http.Handler`, because I don't want to use `awesomechain` and 2) *They* need to glue my handler to a `awesomechain.Handler`, because they can't live without it. Apply generous glue all over the place until the compiler is happy. This is an unsatisfactory situation; having to do that gluing between [different colors of handlers](http://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) forces a real cost unto the community. It should be well-justified. But *it isn't*, on the contrary. The idea of adding an error is completely useless and counterproductive to the idea, of what a Handler *is*. If you need it to support Chaining of Middleware - then *make an obviously distinct type for that*, which may well contain the requirement to do error handling. Fine, I guess, if you really think it helps, whatever.
&gt; There‚Äôs even an example of this idea on the go blog: https://blog.golang.org/error-handling-and-go Oh, I did not respond to this, I should've. Note, that `appHandler` is not exported. Because it implements application-specific error-handling logic. It is not *meant* to be generically reused, because HTTP error handling logic can not be generic and needs to be application-specific. *Mic drop* ;)
Since you're into stalking this throwaway, let's go by that first. There's no way to convince people into doing a good decision. It must come from within the person itself. People can only ever convince/coerce others into bad decisions. Therefore, there's pretty much no hope for people in regards to their security and freedom. So there is no reason to answer - specially to people that defend stuff like Discord. I am far from accepting of certain techniques Reddit adopted to reach its userbase and its "power" to sway people's convictions, so I don't care about this website either. But I express insatisfaction over people complying and coercing others into bad decisions. In the end, I'm human. Now, about the Discord thing. Discord is proprietary software, therefore it features _at least_ a massive tendency to be malicious. It deals with massive amounts of data and metadata from millions of users... While being proprietary. That quite often doesn't end well for the user side of the deal. When once asked if they had a roadmap to become Free Software, they not only did not, but also thought it meant "freeware". So they quite literally do not give a squat about the user. (This went in a Twitter conversation I saw a couple of years ago, but since then Discord deleted their part. Quite convenient.) They also declares themselves as secure. "Must be because you can access them via HTTPS, haha". Does a SSL cert really defines everything about a system's security? If it's proprietary, their only guarantee will _ever_ be their word. And why trust the word of someone delivering proprietary software that hoardes data and metadata? Why is enterprise such a god to some? While at that, they present themselves in a hip and cool fashion to attract and distract people. It works. They are more than distracted, they are infatuated. So what happens? They _coerce_ more people into entering it. "Everyone's using it" is the one argument. "If you don't join, you won't get information X or social interaction Y" is a common consequence. This doesn't sound like a fairly free option to a species that crave social interaction as us. And gee, what's gonna happen when people ad propane as hip and cool too? So you have millions giving data and metadata to a business that just gives a "trust us, you dumbos" statement on their EULA thing. They have their business partners, and they quite likely can be accessed by other major parties. The best part? There are already options based on Free Software with pretty much the same feature set. It's not a matter of convenience. It's a matter of people _in_ coercing _more people in_ instead of leaving for their safety (and their peers' too). Have a good day; I've seen some texts here and there that expose some more shady stuff on a search engine search. But to be frank, I actually have to go to work right now.
https://www.nomachine.com + some light WM (awesome, fluxbox, etc) + vscode works fine for me.
Your assumptions are almost entirely incorrect, but the gratuitous insults have convinced me to give up on this conversation. 
Sorry, none of that was meant as an insult. It was meant flippant and humorous, but not insulting. Sorry about that.
Emacs is nice. I still use it when I need to gdb something.
this read like an 11th grade term paper written the night before by paraphrasing other sources.
I don't see the problem when you called Go as Golang since it would be much easier for people to search and friendly for Google Search Engine?.
And they still gained a lot of performance by switching from python to Go. Goes to show that even with C extension, python code is slow as s**t.
That's every shit on internet. So u must hate internet...? Go back to your hut.
Java and Jawah are terrible comparisons to Go and Golang. Golang is a nice shorthand for Go Language, something I have to say **constantly** because Go is such a short and ambiguous word that my company, god forbid, has two products named Go, we use a product referred to as Go, and now we're rewriting backends in Go. So sure, I could so "Go language" every time I refer to Go, but frankly Golang is just a nice short hand for "Go language". I'm not defending the authors use of Golang, but if you honestly can't see how Golang is different than Jawah.. well, I'm wasting my time.
Omg. This entire comment could be truncated, but this dude decided to append more words to sound smarter. No wonder youe coworkers hate having meetings with you.
Thanks and congrats! Please provide your email to claim the prize. Since you were one of those who suggested GoLand, our final name, you get 1 free year of GoLand personal subscription. More info: https://blog.jetbrains.com/go/2017/11/02/announcing-goland-former-gogland-eap-18-final-product-name-templates-support-and-more/
Conceptually there are four kinds of parallelism: asynchronous IO, multithreading, distributed computing, and SIMD (CPU or GPU). Go‚Äôs runtime handles the first two kinds of parallelism for you. For distributed computing Go has nothing built in but it‚Äôs a good platform on which to create a system. But Go‚Äôs SIMD performance is not great, and for the most part you‚Äôre on your own to rewrite your code in assembly as necessary. 
[removed]
What the func?
So you also say Clang because it is shorter than C Language and less ambiguous than just C which everybody misinterprets a letter or tune? I'm wasting my time too. 
If there's a lot of ambiguous product names conflicting with C, then yes. Also, C can be difficult to search for as well, because of the ambiguous as hell name. Use specificity when you need it. Quit being obtuse. 
When do the videos usually come out? 
Could it? It was the answer to a question. I don't think you're any smarter than him.
You need to cast the `unsafe.Pointer` to a pointer to the type you want then deference it. Here's an example of getting the second element in an array by pointer arithmetic var ints = [42]int{1, 2, 3, 4, 5} firstPtr := uintptr(unsafe.Pointer(&amp;ints)) size := unsafe.Sizeof(ints[0]) secondPtr := firstPtr + size // do pointer arithmetic // cast to pointer to data type you want then derference to get value secondValue := *(*int)(unsafe.Pointer(secondPtr)) fmt.Println(secondValue) //Prints "2" 
I don't care about being smart, as long as I am marketable. This dude is outright trying to look smarter. 
Eagerly waiting for the videos...
You didn't give a location, but for Cork, Ireland: https://www.teamwork.com/internship/
Out of interest, what do you mean by "real time capabilities"?
Aptly put by someone on twitter: "Rob pike is kind of like Jesus, if Jesus gave hungry people a programming language wisely crafted for their little poor person brains." https://twitter.com/pasiphae_goals/status/923837781176090624 (please dont be offended.. just for humour)
Thanks I will check it , I'm from Tunisia ( north Africa ) and I'm allowed to have the internship anywhere. So will try to get an internship in any country better then mine for now, I'm focusing my search on Eu countries.
As a rule of thumb. If a service is free, **you** are the product. I can see the *potential* evil; but I think they have more to gain by not exploiting the user base.
They mentioned a week, but also that they're filmed with 7cameeas
Time.Duration is an in64 of nanoseconds: https://golang.org/pkg/time/#Duration https://golang.org/pkg/time/#Time.UnixNano https://golang.org/pkg/time/#Duration.Nanoseconds ...etc. It's less obvious why those Location's aren't shared, or why it's not better to manually share them with "In".
[removed]
&gt; Perhaps I should just start looking for a new language and stop arguing about the lack of low level features(i.e. real time capabilities) in Go. Go's at least my 10th language. I lose track, honestly. It's probably why I enjoy it so much; I use it in the domains where it shines, and I don't try to use it where it's a bad choice. I recommend this approach, because it works on the other languages, too. They're _all_ more fun when you're not trying to bash a square screw into a Mandelbulb-shaped hole. (I sometimes wonder if the critics of Go who get so hostile towards Go and assume that anybody who can stand to use it must just be "ignorant of generics" and stuff have the problem where they just know basically one language and get defensive at the idea that it's maybe not the best language for everything. I have no problem saying that Go is not the best language for everything, because in fact I _do_ know a lot of other languages, including many with various forms of "generics", and when I set out to solve a problem I don't have to focus just on "the things my one lanugage I know is missing".)
Just to point out, "Real-Time" and "Speed" aren't related. Real-Time [means](https://softwareengineering.stackexchange.com/a/285336) that you're willing to trade absolute speed for latency. So yes, if you need a _guarantee_ that you won't have a 1ms pause within a loop, use something else (although I'm not sure if regular Rust will help you there either). But if you're not, GC shouldn't hurt you.
&gt; although I'm not sure if regular Rust will help you there either It will, to within the guarantees of the OS that it is running on; it does not itself have a runtime that will switch threads, green or otherwise, out or run GC at unpredictable times for unpredictable amounts of time. Concern about real-time is a continuum, not a binary flag, so whether that's good enough depends on your needs. I suspect there probably is some set of people who angrily and loudly declare Go unsuitable for their needs "because it has GC" then proceed to run their project on consumer multipurpose operating systems that can be even more disruptive than GC quite happily, thus proving they were never that sensitive in the first place. But there is a set of programs where the GC can be a problem even with a lot of optimization, if you have tons of objects.
Async and multithreading is actually concurrency. Parallelism is an impropriate word in this context
&gt; But there is a set of programs where the GC can be a problem even with a lot of optimization, if you have tons of objects. True. I wouldn't run Go on a rocket, where the main loop _must_ run every x ms or the rocket will crash. But this is actually one of those places where plain C (as in, not C++ or Rust) comes to the fore, since you _see_ where functions are called, and can easily avoid calling them.
We have people from a lot of different nationalities. I have no idea how easy it is to get a Visa in Ireland though, or even if we're looking for interns at the moment (I'm just a developer, and not involved with HR).
Thanks so much , the visa is not big problem, I was in Spain with student visa ... I will check the link. Thanks again.
Care to share some of the bad choices it implements? Suggestions? Just saying it is bad is a waste of time.
It's more a specific application than general design patterns, but Rob Pike's talk where he walks you through building a lexer was very eye-opening to me vis a vis what you can do with idiomatic Go.
&gt; You need to consider race conditions ‚Äì if two servers or instances of servers want to access the same resource at the same time, what is going to happen? Languages by design try to help this side effect. *Some* languages are designed to help with this. &gt; Nevertheless, it is going to be the first of its kind to break so many unwritten language design rules. It's really clear he is writing with authority he just doesn't have. "First of its kind"... "breaks so many rules". Does he know how long Go's been around? &gt; It is a fairly young language, and we need more time to see its bloom or failure. Guess not. Maybe another 10 years would do it for him?
The http.login Caddy plugin has over 5000 downloads, so... yes. In addition to git clones, 5000 more people are using it... presumably not just in dev, so I would assume in production?
Can someone explain "implement Stringer interface for integers const values" in more detail?
It's still my daily editor. It fits :)
If you keep Python out of the hot path of your application by using it to set up what you want and then letting C code go at it, you can get a very loosely coupled application that's got plenty of performance. That's not possible in all cases, but there are rendering engines with decent performance that have python bindings to set up scenes and C++ to do the work.
if `ints` is a slice instead of an array, one should use `unsafe.Pointer(&amp;ints[0])` instead (provided `ints` is not empty).
There is a Remote Hosts plugin which allows you to work locally and automatically synchronize your work to a server (via a number of connectivity options from FTP to SFTP). Go to Settings | Plugins | Install JetBrains plugin... | search for Remote Hosts Access. You can see the documentation here: https://www.jetbrains.com/help/go/remote-host-tool-window.html Hope this helps.
Okay, this is days late, but here is the dudes blog which had a lot of really goo examples and sited resources http://blog.ralch.com/tutorial/design-patterns/golang-singleton/
What is the business model that incentivizes garbage articles like this to be written? Is someone picking up a fivr gig to try to flesh out content on some janky website tying to increase traffic? Or is someone trying to juice their career with articles that have x number of hits as a resume line?
Project began on April 20th, I guess this is why Nigel Tao moved away from the shiny project!
In regards to not checking in the vendor directory, what are valid reasons why you would opt for that approach?
Some people find checking in `vendor` kind of ugly. I don't find it necessary with `dep` either.
How do I dereference a pointer that is outside of my Golang program? I might be asking the wrong question because what I am trying to do in, pseudo-code, is: var myPointer = "0x0000CB5" //a pointer to a DLL outside of my Golang program var firstOffset = myPointer + 0x0A //shift to a localPlayer "chapter" in the DLL var deReferencedMemoryAddress = *myPointer //this causes an nil pointer error code (0x0000005) when fmt.println'd var secondOffset = dereferencedMemoryAddress + 0xFC //offsetting a second time to get localPlayer's Health, cannot get to this point w32.ReadProccessMemory(secondOffset,gamePID) // cannot get this point So I think what I am doing now is not making a pointer to this DLL in another proccess (not my goprogram proccess)
Reading through quickly, looks like this is only transpiling to C, but really damn awesome that they managed to get rid of the runtime overhead! I wonder if C as target is due to portability or speed? Seems like setting up a build process for C compilation and linking could be an entry barrier for casual users.
This can be sad for people who convinced yourself Go is that fast. It is not and the sooner you got it the better for you. It is not really suitable tool for raw computations, such as linear algebra computations, archivers, image processing, etc.
Also, you can use tramp ( https://www.emacswiki.org/emacs/TrampMode ) for remote edit
It makes code reviews difficult when there are vendor changes.