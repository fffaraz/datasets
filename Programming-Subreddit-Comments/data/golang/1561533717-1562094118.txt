Awesome, I see its already up! Pledged for another pin now, thanks for the initiative! :)
I know this is not the answer to your question, but just on a side-note: I can really recommend gopacket's [layers](https://godoc.org/github.com/google/gopacket/layers) package for this. It makes handling packets of all sort of protocols a real joy! Some time ago I wrote a DHCPv6 and IPv6 router advertisement server in go and needed a library to handle such packets properly. I wrote [both](https://github.com/skoef/ndp) [libraries](https://github.com/skoef/dhcpv6) myself but ended up reinventing the wheel once I discovered gopacket. Still, I learned a lot from implementing those libraries.
Argon2 or scrypt are suggested over bcrypt in most places I have looked.
cool üëç
If you expose your golang APIs directly to the public, then don't forget [MaxBytesReader](https://golang.org/pkg/net/http/#MaxBytesReader) on your endpoints that read response bodies from requests (ie. receives input). If you don't, your service can be DoS'd by simply: `curl -X POST -T /dev/urandom &lt;endpoint&gt;`
Ok just give me an email notification (i have sent you my email in pm) or just give a comment here. Much appreaciated
You‚Äôre supposed to avoid that in go. Take advantage of type safety instead of reaching for scripting language lack of semantics. That being said, https://godoc.org/github.com/fatih/structs allows you to do that; hopefully you realize quickly enough that this is a bad idea.
My API will only be exposed internally on our company network but this is a very good point still (since the pentest team will no doubt try to DoS anything I write), thanks!!
Git efficiencies aside, having multiple copies of the code (root, v1/, v2/) at a given git state (which itself is a versioning tool, so at commit `x`, we are at a particular time and version in history) seems nuts. A a maintainer I would hate that
Go has WASM as a build target now, but I think there are still a few problems (possibly more): &amp;#x200B; \- WASM has no GC (yet), so that is bundled in the output, bloating it \- Go requires a runtime for goroutines etc, bloating the output \- As far as I know Go doesn't have dead code elimination yet, even if it does a lot of the stdlib uses fmt etc so, again more bloat &amp;#x200B; Honestly as much as I love Go, it seems like a poor frontend language right now. It doesn't have powerful enough abstractions to represent a virtual DOM nicely for example. It could still be done but it would be an awful experience compared to something like Elm.
I like to create separate structs for API input and data models (eg: UserInput and User structs). The validation occurs when making a User struct out of a UserInput struct. You can use embedding to reduce duplication. One nice property of this approach is that handles your API input diverging from your internal representation of a thing. Like your User struct could have first/last name fields for legacy reasons, but your UserInput struct would expose only a full name field.
Try TypeScript. It goes a long way towards making JavaScript a lot more tolerable.
Javascript is the only complete runtime packaged with web browsers right now, web assembly is still in it's infancy, so GopherJS being Go that compiles to JS is your best bet. I don't think you have to actually look at the JS, it's just the compile target
Worten has offices in Porto and Lisbon and they have Golang in the tech stack. You also have OLX and Tlantic, both in Porto and with Golang in the stack
A guide how to make easy things implicit by adding a new abstraction level, let alone loggers and logrus mess.
For `.env` files we use [joho/godotenv](https://github.com/joho/godotenv) to load the env from the software directly instead of relying on Docker.
Convention is anything the complainer learned first.
IMO they should just drop the dep support and go all in with modules.
I hate the mess in main file and a ton of code in it. Also coming to go from other language where the framework had a full blown container. I find this overkill in go so I also choose a resolver package way of dealing with dependencies..
or if even that is not your thing then Dart might be
The thing is this resolver promotes using these dependencies from wherever you want, whenever you want. A proper abstraction will initialize them once, forcing you to pass them down the chain. Otherwise it gets messy real quick, especially in Go.
"A similar domain sold a few years ago for a price in the lower seven-figure range, and the owners of Go.org will give due consideration to similar offers." Google should buy this, this is pocket change to them.
Happy cake day TJ!
https://golang.org/pkg/reflect/
Are there any examples of large scale projects that have taken this step yet? Ideally something that is both a product and a library at the same, I searched for something a few months ago but came back empty handed.
Thanks for the reply. I will try this piece of code soon :)
Thanks for the reply. I will the layer's link to check on it later :\]
What's wrong about the main file? I mean, it's not clear it's a cli program that you are running. Maybe putting the main.go in a `cmd/app` folder? this way you know you are dealing with a cli tool. Personally, i don't like exiting anywhere that is not the main file of my cli program. I try to keep it like this: ```go package main func main() { config, err := config.NewConfiguration() if err != nil { logrus.WithError(err).Fatal("could not load configuration") } app, err := myPackage.NewApplication(config) if err != nil { logrus.WithError(err).Fatal("could not initialize the application") } logrus.Fatal(app.Run()) } ``` So your code describes exactly what the cli tool does and you can actually see when the app can exit. The package would haandle logic and return errors and the cmd main.go file would handle cli things, like exiting Of course this is a simplistic example, it's just to illustrate a little bit my opinion. Thanks for sharing the article.
No, the whole point of pkg-config is to tell go where the library is. Don‚Äôt move it around.
Last time I did pings in Go I just used a combination of the [`golang.org/x/net/icmp`](https://godoc.org/golang.org/x/net/icmp) and [`golang.org/x/net/ipv4`](https://godoc.org/golang.org/x/net/ipv4) packages (and the ‚Ä¶/net/ipv6 package). Unless you want to do the all the bit fiddling yourself as an exercise, there is no reason to re-implement the wheel.
No it doesn't; neither of the two lines is valid in Go. For the first, the OP's `myICMPType` and `myICMPCode` variables are of type `[]byte`; you can't use `+` with that type. For the second, bit operations are only supported on numeric types and not `[]byte`.
ahah I didn't even notice :D
Medium paywalled; didn't read.
That is a very eloquent piece of code
thanks dude idk why it was downvoted by whoever but i meant no offense by my question, was genuinely curious :)
Seems like their best option is what's being proposed here: [https://github.com/mediocregopher/radix/pull/128](https://github.com/mediocregopher/radix/pull/128). Essentially running goforward moves all of the files into a "v2" directory and then makes a "forward.go" file with aliases for all exported functions.
This is great. Especially [https://github.com/cortesi/modd](https://github.com/cortesi/modd). I tried to get something link this working with bash and fswatch, but it made my head hurt. &amp;#x200B; What exactly does GOPROXY offer? Quicker dependency resolution? Anything else? Are there any other githooks you use? &amp;#x200B; Thanks for sharing!
&gt;Hi guys. Absolute beginner at go. As an exercise to push me on studying both the language and the various concepts of network/infra i was trying to implement a ping like tool. Literally the first sentence... &gt;Hi guys. Absolute beginner at go. As an exercise to push me on studying both the language and the various concepts of network/infra i was trying to implement a ping like tool.
I have been using Go WASM for 6 months now. Yes, syscall/js package is rather basic, and there are no good full frameworks to give you higher level abstractions at this time. &amp;#x200B; Still Go WASM is usable. You just need to develop packages that provide easier access and interaction with the DOM. Once you have such packages web fronted development is nice in Go.
&gt; manually convert client inputs to db models (rather than say, blindly unmarshalling to an internal struct) This is fine if you are validating the struct before use. ``` func(w http.ResponseWriter, r *http.Request) { foo := &amp;Foo{} err = json.NewDecoder(r.Body).Decode(&amp;foo) if err != nil { // } isValid, err = govalidator.ValidateStruct(foo) ... ```
Always salt your hashes with a nonce and also store the nonce. It prevents two users with the same password having the same hash.
I typed this from my phone, so you‚Äôre probably right, however he gist is typecast it to byte and use a bitwise and
I'm glad it helpsüòÑ You can deploy goproxy in you own server, then it works like a dependency cache which make dependency installation more fast and stable.
Not practical for some companies. It's a long process to get hundreds of our microservices into and ready for a new build and release pipeline. It's not the fault of modules or go, just a reality at large orgs. We (large companies) adopt new things slowly and would appreciate more time to move.
It's a different model on other platforms. Windows applications allocate a console per application (if launched from desktop). In other operating systems application gets attached to the current window/console which is a separate process, so you cannot control hiding/showing that. It's probably easier for you to write a Qt application that looks like a console that you yourself then can control.
Why do developers insist on introducing complexity? Just inject the dependency dude. That's it. Nothing could be more simple.
Thank you!
Probably Gabe.
Have an upvote!
There is hope ... https://github.com/GoogleChromeLabs/go-hackernews
btw, there's also https://golang.org/dl/?mode=json to parse the versions.
That sounds like a service locator which is an anti pattern. Am I wrong?
[https://github.com/golang/go/wiki/GoUsers#portugal](https://github.com/golang/go/wiki/GoUsers#portugal)
[removed]
I saw that, but it's unclear at what level they're experimenting with. There's a lot to experiment with using those packages and (IMO) very little gained by going too much lower-level.
Maybe flutter or rust
Not sure if anyone has posted this, but it's an updated ebook for building with Go. [https://www.vividcortex.com/resources/the-ultimate-guide-to-building-database-driven-apps-with-go](https://www.vividcortex.com/resources/the-ultimate-guide-to-building-database-driven-apps-with-go)
This is fine, but I‚Äôve found it very helpful to separate the concepts of the client contract and the internal DB model.
Hmm. Those are key derivation algorithms. Not quite the same. I don‚Äôt have an opinion on these as of yet. Cryptographic security is one field where you don‚Äôt want to be on the bleeding edge. Thanks for the reading material :)
&gt;you're several factors of magnitude from running standard Go on an Arduino Not really. [https://github.com/tinygo-org/tinygo/blob/da857108947aa35ff6e6b5ce16c96359e72fe47c/src/machine/board\_arduino.go](https://github.com/tinygo-org/tinygo/blob/da857108947aa35ff6e6b5ce16c96359e72fe47c/src/machine/board_arduino.go)
So they are going forward with the `try` thing, eh? Not a fan. (And so are a lot of people, if GitHub (dis)likes to be believed.) The rest of the changes are obviously good, especially the overlapping interfaces one, but `try` seems to me like it's doing too much and too little at the same time.
Vocal minorities are not to be trusted, there will always be naysayers, and doing nothing is not an option.
There has been no decision to do \`try\` or not. As the blog post says, we are still collecting feedback, especially evidence-based feedback. We are still gathering data and we encourage everyone who is interested to help with that.
A quick overview of the race detector. Hope it will be interesting, all feedback welcome :)
I really appreciate that you have replied! I have provided some feedback [back when the proposal was posted](https://www.reddit.com/r/golang/comments/bwvyhe/proposal_a_builtin_go_error_check_function_try/eq1sb3s/). My main concern is that it will discourage people from providing richer context. Another counter-point some of my colleagues have voiced is that a keyword would be preferred to a predefined identifier. That is, most people would prefer to write: x = try foo() Instead of: x = try(foo()) I know that adding a new keyword could technically break backwards-compatibility, but since we have `go.mod` now, the compiler could decide, whether `try` is a keyword or a predefined identifier based on the `go 1.XX` clause in there, √† la Rust Editions. (While we're at it, the other proposals were universally considered good by my colleagues.)
I mean, it *is* always an option. This is Go we‚Äôre talking about. The language only exists because other languages became too bloated (in a myriad of ways). Further, we don‚Äôt know if it‚Äôs a vocal minority. While those aren‚Äôt reasons to not try `try`, they‚Äôre also reasons to move slowly.
Hmm. So it installs Go if you already have Go installed?
There must be a reason why Go team decided to go with "try" being function and not keyword. Keyword would be more readable. But I guess function can be replaced with your own implementation at runtime, while keyword can not?
[removed]
[removed]
Yeah so one file in my project still used github.com/Sirupsen/logrus and the rest used it with no capital letter so you just have to make sure that every import uses the one without capital letter S. Threw away 5 hours of my life for that mistake...
try being a function and not a keyword means it won't break any existing code that uses try as an identifier. I don't think this can be replaced at runtime, due to the generic nature of the function.
Thank you for that handy bit of info! Just to be clear, is `go get &lt;my-project-url&gt;/...` sufficient to obtain both lib Go modules and the +build tool[.go] dependencies as well? Or would that involve a different command like go mod? Finally, are triple dots still needed as of Go v11 / v12, for installing not only my top level library but also any cmd/&lt;app&gt;/main.go programs?
What‚Äôs wrong with doing nothing if it‚Äôs not a real world problem?
javafication of golang is just.. yeah gurl, no.
try seems the right thing for now but com'on `try f()` Is better than `try(f())`
&gt;&gt; __standard__ Go
Tbh I'm very confused by the ux around modules. I know it's not a simple problem, but damn.
 bool mozilla::fallocate(PRFileDesc *aFD, PRInt64 aLength) { #if defined(HAVE_POSIX_FALLOCATE) return posix_fallocate(PR_FileDesc2NativeHandle(aFD), 0, aLength) == 0; #elif defined(XP_WIN) return PR_Seek64(aFD, aLength, PR_SEEK_SET) == aLength &amp;&amp; 0 != SetEndOfFile((HANDLE)PR_FileDesc2NativeHandle(aFD)); #elif defined(XP_MACOSX) int fd = PR_FileDesc2NativeHandle(aFD); fstore_t store = {F_ALLOCATECONTIG, F_PEOFPOSMODE, 0, aLength}; // Try to get a continous chunk of disk space int ret = fcntl(fd, F_PREALLOCATE, &amp;store); if(-1 == ret){ // OK, perhaps we are too fragmented, allocate non-continuous store.fst_flags = F_ALLOCATEALL; ret = fcntl(fd, F_PREALLOCATE, &amp;store); if (-1 == ret) return false; } return 0 == ftruncate(fd, aLength); }
I see this is the official bikeshed try thread
So then don't upgrade to the new version until you're ready? You can take as much time as you need.
Can somebody tell me why the `?` was rejected?
I haven't looked the code but if he passes/injects the resolver around then this is wrong. I create all dependencies and all instances in resolver and then pass those into the http handlers.
Multiple return values, "errors are just values," and now an early return \`try\` function feels like we're slowly reinventing boxed result types. Not complaining at all--I think result types are the right way to do it, but Go seems to be slowly working towards its own homegrown, partial implementation of this instead of adopting the Haskell, Rust, OCaml, etc solutions. On the upside, multiple returns is really simple. If you look at all the helper functions to work with Option and Results in Rust, I'd imagine Go probably requires a lot less language overhead. Regardless, I'm happy to see some way of inlining error handling. We'll finally be able to nest function calls that return errors.
thanks for this
The reason is in the article.
I don't hate the try proposal but I don't love it either. I tried very hard imagining and writing code as if it was a thing already, and I can't shake the feeling that it'll be an annoying thing during development. &amp;#x200B; The thing I don't like the most about it is that to me it looks like it'll be a huge pain when adding or removing handlers for specific errors. If I want to add a handler, I'll have to delete \`try()\`, capture the error into an \`err\` var, type in \`if err != nil {}\` and then add code and vice-versa. I find this quite annoying as I end up adding/removing handlers quite a lot whether it is during development for debugging or for real code that needs improvement in error handling. It's going to be a pain to switch between the two. &amp;#x200B; This is why I liked a counter proposal more that suggested to do something like: \`\`\` user := try getUser() else { &amp;#x200B; }
[removed]
Someone did an analysis of a significant number of big open-source Github projects such as kubernetes, etc and found only a few dozen or so cases in thousands and thousands of lines of code. My numbers might be off but it should be on the GH issue for the proposal. I think someone from Go team even replied that try as a keyword probably wouldn't be that bad.
[removed]
You raise several problems, and I'm not sure whether to address the ICMP / TCP/IP parts or the Go parts. Why are you decoding hex? Instead of `hex.DecodeString("08")` and error handling you can just write `0x08` or `8`, preferably defined as a constant. e.g., `const ICMPTypeEchoRequest = 8` . In your example, you use the ICMP type 8. That is an ICMP echo request. However, the example then says the equivalent of `myICMPCode := 0x80`. Why? The ICMP code of an echo request is zero, not 128 (0x80). BTW, the ICMP header checksum needs to be calculated over the whole header, not only over the type and code fields. Why do you say you need to do AND 0xFFFFFF? I don't see how that would be useful when calculating an Internet checksum. When representing a packet in Go, you would usually use byte slices at some level. You can address bytes in byte slices directly and append to byte slices. So, you could do: hdr := make([]byte, 8) hdr[0] := ICMPTypeEchoRequest // ICMP type 8 hdr[1] := 0 // ICMP code 0 // Set request identifier in hdr[4:6] and sequence number in hdr[6:8]. I suggest you make a function that takes a byte slice, and calculates and returns the Internet checksum. When calculating the checksum, you need addition and bitwise operations and should use an integer type like `uint32`. You can use bitwise shifting and logical expressions to get the bytes where you need, e.g., `uint32(hdr[i])&lt;&lt;8 | uint32(hdr[i+1])`.
The parentheses mean that it's backward compatible, since `try` doesn't need to be a keyword. It could always be reserved in the future once module versioning gains wide use, and then the parentheses could be optional in the single expression case.
The try proposal will be implemented as an experiment and we'll be asked for feedback, and I'm sure the feedback will be good because it \_will\_ reduce error handling boilerplate. Also, whatever negative feedback people would come up with after trying the change has already been discussed to death on the Github issue. I think the proposal is simple enough (which is great) that it won't make people realize something new after they start using the feature vs they imagine how they'd use it. &amp;#x200B; I'm fairly certain the proposal after experimental implementation will not receive any new feedback (negative or positive) than it already has, and that it'll be eventually accepted which is not a bad thing at all but I can't help but imagine if some of the counter proposals like \`try ... else\` also had experimental implementations available and what kind of feedback it would have received.
The try proposal for me is going to the wrong direction, \`try\` built-in is a magical thing, that looks like a function call, but it returns (or goes to) instead. &amp;#x200B; Imagine having code like \`try(bar(try(foo(try(baz()))))\` later on. &amp;#x200B; \`fmt.HandleErrorf\` what's the point of adding this to the standard lib? Can be implemented in a few lines in utils package if needed.
you mean grandchildren? no. Same with suid or set group executions as you mentioned. All of that will clear any prctl settings for signals. At that point you would just supervise the processes via cataloguing or IPC.
[removed]
Somehow I only got a notification about you reply now, but I fixed the link (it was amzn.com).
 [https://github.com/griesemer/tryhard/](https://github.com/griesemer/tryhard/) ?
It's not about whether you do it, it's about what this pattern creates. The guy that comes into the team in 2 months will start shitting resolvers everywhere because that's easier. If you have code review you are gonna have to explain "yes, you can do it like this, but shouldn't" etc etc.
Don't tell me what to do.
did you google? [https://github.com/quii/learn-go-with-tests](https://github.com/quii/learn-go-with-tests)
Your counter proposal example doesn't look much different from the code we write today with ifs. The thing about try is to remove boilerplate. I don't like the proposal much either but for a different reason. I like the idea of automatic propagation but would like some way of augmenting an error in the process. Right now you just return the error as it is which dosen't look that useful. It's a similar problem as with swift where you have to do/catch every other line just to add some context. Rethrowing errors as it is is useless in many cases. At least with go we have the usual idiomatic way of handling errors.
Do or do not. There is no try.
&gt; Your counter proposal example doesn't look much different from the code we write today with ifs. The thing about try is to remove boilerplate. How does user := try(getUser()) reduce boilerplate but user := try getUser() does not? They are equally good at reducing boilerplate but the latter one makes it very easy to add err specific handlers when needed.
What about it?
If you want to know about the guidelines they are the same for any language. If you want to know how to technically write tests then google it or look at existing projects on Github. Any Golang project with 100+ stars does probably have accompanying test.
Sorry, that was not the intent. I thought about putting "you can now..." or something before but the title already seemed longish.
I would argue that no, no it isn't an option: the most pressing issues of the language were identified, and solutions proposed to address them. One of those proposals is the most focused it can be, solving the annoyance of checking error values with a "big" if statement. The problem people are having with it are seemingly only that it either doesn't go far enough or that it's too limiting, both of which doesn't ring true since there is no actual experience with it. So I would argue how could it be anything else than the vocal minority with the perceived foresight that it's the wrong thing to do. If even this very small very pragmatic thing is so outrageous, what chance is there for any kind of full blown generics proposal to go through. And we're talking about a simple experiment here, it isn't even a done deal that this is the final thing that will be implemented.
By boilerplate I mean the else part. It's the same as a regular if err :=, just a bit different. Kinda similar to guard in swift.
`try` would only be "useful" (in that it saves some keystrokes) in functions with multiple possible error returns. Yet a function with multiple error paths should (in my codebases, MUST) wrap/annotate returned errors so the call stack maps to a single source. Therefore `try` cannot be used, and the defer solution proposed is laughable. Honestly without option types you can't solve the error handling problem in any real way, and that problem is really just a matter of having to type a bit more.
This.
Hi there, I'm the author of the post and I just wanted to clarify that we were planning on releasing v2 with Go Modules, but after realizing it was far from being as simple as promised we decided not to do so. Removing support for Go Modules doesn't break our backwards compatibility, because we never had them.
Agreed, and this requires that Dgraph does *not* just drop dep support completely, to give their users the time to get ready. And that's exactly what they are doing. I think the solution they found is quite clever.
Many/most stdlib functions wrap the errors they return themselves. When that is done there's no need to add another unique wrapper in the caller, the path is obvious regardless. I think this proposal is based partly on that assumption. Personally I rarely wrap errors, which is probably a bit lazy of me. If this proposal makes error wrapping easier, then I'm all for it. I think I might try the defer wrapper thing ASAP, though IMO it needs the wrap functions in the errors package to be really useful, I quite dislike fmt.Errorf errors as they are pre-1.13.
It's not really a language specific thing. You can apply the principles to any language
Hey Francesc! (Been a Patreon supporter of yours for a while now, missing your videos!) I know my opinion is just one, but I gotta say I think what [Andrew](https://discuss.dgraph.io/t/go-modules-on-badger-and-dgraph/4662/13) and [Russ](https://discuss.dgraph.io/t/go-modules-on-badger-and-dgraph/4662/18) are suggesting here is perfect. It's a nice clean break, and while yeah it might result in a little more maintenance on the repo side, I think it's a far better solution long-term. Cheers!
wrapping EVERY error is ridiculous. No one does that.
Parsing not so much, but after a ton of projects I liked the idea of not having to worry if my design is correct, and just implementing an already existing specification (focus on coding and not on system design). Also, I wanted to get a bit into JavaScript, so I thought this might be one way to Go :)
Thank you for pointing out arguments not even I was aware of! But it's right, the actual point where I said that I'm gonna implement a JS-VM was, when I didn't find support for ES &gt;5.1
Watch me.
My main beef with this and other proposals is that they don't clear up a fundamental flaw in Go: Multi-value returns with errors as a poor man's sum type. Most functions in Go have a contract that they _either_ return a valid value or an error: if s, err := getString(); err != nil { // It returned an error, but "s" is of no use } // s is valid Of course, this isn't _always_ true. A commonly misunderstood contract is that of the `Read` method of `io.Reader`, which says that when `io.EOF` is returned, the returned count must be honoured. This is an outlier, but because the _convention_ is that the multi-value return is mutually exclusive, many developers make this assumption (it's [trivial to find repos in the wild](https://github.com/search?q=%22read%28%22+%22if+err+io.EOF%22&amp;type=Code&amp;l=Go) that make this mistake), and so this is, in my opinion, bad API design. (As an aside, it's also true that multi-value returns beyond two values almost always become cumbersome and impractical, especially if said values are _also_ mutually exclusive. Structs, having named fields, are almost always better than &gt; 2 return values.) I would much rather see a serious stab at actually supporting sum types, or at least mutually exclusive return values. For example, I could easily see this as being a practical syntax: func Get() Result | error { ... } Such a syntax would be a much better match for a `try()` function, since there's no longer any doubt about the flow of data ‚Äî there's never a result returned _with_ an error, it's always _either_ a result or an error: result := try(Get()) or simply support existing mechanisms for checking: if err, ok := Get().(error); ok { ... } if result, ok := Get().(Result); ok { ... } switch t := Get().(type) { case Result: // ... case error: // ... } I'd love to see a `case` syntax that allows real local variable names: switch Get().(type) { case result := Result: log.Printf("got %d results", len(result.Items)) case err := error: log.Fatal(err) } A full-blown sum type syntax would be awesome, though I know it's been discussed before, and been shot down, partly for performance reasons. Personally, I think it's solveable. I'd love to be able to do things like: type Expression Plus | Minus | Integer type Plus struct { L, R Expression } type Minus struct { L, R Expression } type Integer struct { V int }
If I had a penny for every time I wanted true sum types in my code‚Ä¶
I just told you that I do exactly that, in large codebases. It works very well and makes debugging issues far easier.
Wow, that's also really helpful! I'm glad to see `go run`... offered, similar to bundle exec and npm bin. Awesome!
Oh, I misunderstood - I thought you were referring to numbers of cases that the try proposal would cover, rather than the number of name clashes.
Don‚Äôt like `try` at all.
That‚Äôs a pretty ugly way of getting a stack trace.
[removed]
It's a troll, forget it. Thanks for your package.
It's far more compact than a stack trace, fits into a single log line and doesn't point to literal line numbers which change over time.
I wrote about my thoughts on error handling in Go, in respect to Go2 FWIW &amp;#x200B; [https://quii.dev/Functional\_programming\_and\_Go](https://quii.dev/Functional_programming_and_Go)
I remain of the opinion that a keyword is the right language choice for control flow and panic should continue to be treated as an... exception... rather than a pattern that can and should be followed subsequently. The nested examples of try solidify the feeling that it's wrong. if a keyword `check` returned an error if the following value was non-nil, it would be rather non-magical and would allow library functions to conditionally wrap errors if the underlying error was non-nil. In a function with no error return, it would be a syntax error. A function `collect` (or pick some better name) that allows you to capture the last item of a tuple of return values and set it to a pointer if the pointer is nil would allow, in combination, the same semantics as this try proposal with better decomposition and clearer control flow. `collect` would work similarly to the proposal for try with a handler, except that it would set it to a variable. See [here](https://www.reddit.com/r/golang/comments/bwvyhe/proposal_a_builtin_go_error_check_function_try/eq22bqa?utm_medium=android_app&amp;utm_source=share) for some previous musing on this. If the Go team cannot add a keyword to the language to solve this problem, I don't think they should solve it. Since that's a strong statement by itself, perhaps the Go team should consider allowing *some* changes that would only apply in files with a .go2 extension.
&gt; I have a map of the type `map[string]map[string]map[string]interface{}` Why? That sounds like the source of your troubles. &gt; type Item struct { &gt; Name string, &gt; Id string, &gt; Items []Item &gt; } Recursive, Item contains many instances of Item? Why? What's this thing meant for?
Something similar to rocket framwork from rust. There is already one implemented in Go [https://github.com/dannypsnl/rocket](https://github.com/dannypsnl/rocket) &amp;#x200B; I get you, at the end, if you organize your code in services, the http handlers endup being just boilerplate üòï
The point of having it in the standard library is so that it can be standard practice. For example, this means it's available in playgrounds. Beginners don't have to write it themselves in order to use it while learning. The standard library itself can use it.
Thanks for sharing, I haven't seen rocket yet. It looks like a simpler version of https://github.com/mustafaakin/gongular. I actually wrote something similar to rocket originally (https://github.com/xeoncross/mid) before realizing that even defining the routes was unnecessary much of the time.
Don't `try` it so
It's actually a very simple problem (it didn't exist when I started coding) - but not easy to solve given everyone wants to use git and import libraries from remote locations (and use tools like npm, pip etc). Personally, I would much prefer to find a useful lib, download it to my working dir, test it, and then use that version for my project when I was happy.
I have to partially agree. It shouldn't have been a function. I know the ideal of full backwards compaibility, but try should be a keyword.
Maybe they'll make it one in 2.0. It should be simple enough to detect and update with an auto-updater.
Was there a backwards compatible promise for go2?
@tty5 which feature were they most paying for
Wrong thread and please provide some reasoning.
&gt; literal line numbers which change over time. I do not understand the relevance of this in practice.
if err != nil is great
Totally agree. I use this wrapped approach too. It works great, like a stack trace with context.
Read the whole release notes and still don't know what you guys are talking about. Is it something in an x package?
To err is human; to super-return, divine.
For me the great things are: go get -u updates only what is imported in the current project, the defer speed improvement, the modules are used even in the gopath if a go.mod is found and the -trimpath compile flag!
Yup. Errorsx
Oh yeah just saw this article thanks: https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md
In my experience those deep in the stack error places only have one or two calls that I need to check for specific errors (like `sql.ErrNoRows`) virtually everything else can use the generic `try` / `defer` pattern to wrap the error in some kind of 500 response. Using `if` in these places seems fine. Also these types of calls tend to be very leaf and usually have have several layers of functions between them that could use `try` liberally.
Behavior of nil channels is documented in the spec. Same for pretty much every other case of nil value.
Being documented doesn't make it a non-wart. Selecting on a nil channel is _different_ from selecting on an open channel; you can inadvertently select on a nil channel by accident even if you're aware of the semantics. See [here](https://github.com/golang/go/issues/28133#issuecomment-506001742) for some examples.
+1 I use this too, it is intutitve just like the way Humans debug things.
I do at least 90% of them. I won't be using try because it'll be confusing. I'm really accustomed to `if err != nil` and using a different syntax for ~10% of the time will be confusing.
It doesn't make wrapping easier. It makes it almost impossible using the new syntax.
Your POST handler is vulnerable to a type of DOS attack. You read the entire request body into memory without taking into account the Content-Length header value. You can easily validate a reasonable content length value within middleware, however your handler should read the body into a buffer no larger than the specified content length. Otherwise, a malicious client could easily cause an out of memory exception and kill your API.
No. That was the point of Go 2, at least in theory. Though I think they've realized/know that Go 2 will **at least** need to be compatible through an automated update/conversion process sort of like pre-Go-1 weekly builds (mostly) were.
To demonstrate this, convert a meaningful package to using try, identify the places it helped, the places it hurt, and write up an experience report. Bonus points if you do this for the keyword if you think the contrast is useful. Nothing is off the table; the team is working within the current timeline, but if experience reports support waiting until modules are in place so that a keyword can be used, that is clearly an outcome that they would consider.
With the response to this relatively minor change? I can't even imagine the storm next time a generics proposal comes out.
Jon Calhoun has a really good video course at [testwithgo.com](https://testwithgo.com), it is a bit dry at first but very thorough.
Go actually already limits the size of a POST body to about 10 megabytes if not defined by the user. You can further limit it with a io.LimitReader or a custom reader which counts bytes.
Go programs are now compatible with Android Q.
Thinking about it, I wish that deferred functions could be given the line number of the try/return that exited the function. Why? It would make a generic wrapped error _significantly_ more useful for debugging in some cases. But I'm not sure how to manage that in the language in a clean manner.
Have a look at this - https://www.vugu.org/
Where do you get that Go limits any request body to about 10 megabytes? I have not seen that in their source code nor have I found it documented. The other options you suggest are suitable as well. However, my suggestion requires no counting of bytes.
Actually, I found in the source code that a request with a Content-Type value of application/x-www-form-urlencoded has its body limited to 10MB. However, you are dealing with application/json.
Let me get this straight: Go modules are still not official? Getting some confusing language around this in the main Go blog.
Seriously, though, how much of this pain would simply go away if dep had the minimal module support that has already been added to Go 1.9.7+, 1.10.3+, and 1.11. It looks like dep has been nearly abandoned, any way the community can give them a hand to get some support added so this transition isn't so hard?
Hopefully this will be fixed in "Go 2" - Once you get to version 13, you've learned a ton about language design and the goals you're reaching for - sometimes early designs end up going counter to your end goals. Major version bumps are specifically designed (in semver) to address these issues - to roll up your backwards incompatible changes. For better or for worse, Python has supported the 2.x and 3.x branches forever due to the grumpiness of it's 2.x users not wanting to / not being able to refactor to 3.x
It doesn‚Äôt reduce boilerplate if you‚Äôre properly wrapping your errors though... I‚Äôm of the opinion that return err by itself should be rare. In these cases, named error handlers and such just make things worse and you can‚Äôt add per call context. More importantly, I loved that it was obvious where your function could exit. Now it no longer is since a random function now affects control flow. Yes, panic did too, but I don‚Äôt believe that panics are something that users _should_ handle generally.
It doesn't handle `json.RawMessage` correctly either.
I did some benchmarking of json-iterator as well and it's quite slow for big structs: https://github.com/erikdubbelboer/json-iterator-benchmark
I don't actually recall seeing the pattern you discuss all that often. Maybe never. Doubt you'll find a linter for it. Writing one seems problematic too; seems like it'd be just as tough for the linter to know you're using the wrong var. This seems like it might just be a place for "don't do that then". That is, just use err, not err1, err2, etc. I get that it can be kind of semantically satisfying to have different variables for different error states, but especially if you're just returning the error each time, just use "err" and leave it at that. If you're doing something more complex than that, maybe just choose better names that err1/2/3? writeErr, readErr, insertErr, etc.
Sometimes reading these threads I feel like I should chime in with some positivity. So: I think `try` is a really sensible proposal, it succinctly and concretely solves a problem, and I am excited for it's possible inclusion in the language. Thanks for all your work golang team!
Don't see the problem. Every language has a learning curve, especially with closures. I've never had a similar problem. That's actualy the first time I see someone complaining about this. About panicking. Panicking is there to force you to properly write your code. Double closing is a logic error. Your example with shutdown flag, instead of fixing one error, introduces an even worse one - race condition. That's the same as trying to send something into a closed channel. Silently ignoring such operations would just hide serious bugs.
I guess I'm going to refactor a project and throw it out then. I don't have a time to deal with it. It's also bad that they claim std lib compatibility. And then they fell flat.
You are right the modules are still not official because some major parts of it are still not implemented. One of them being vendoring (e.g automatic updates of vendor dir, taking code from vendor if it exists, etc.)
Well it's definitely interesting, well done
It's not about learning curves, but about pitfalls. If there weren't a magical value (nil) for special semantics, there would be no possible pitfalls. All nils in Go introduce pitfalls.
Thanks! :)
My favourite feature of the language
You might want to omit the "error‚Äú word from the underlying messages, and only use it if/when you print it out. The way you are currently using it makes it very hard to read
snippets are fine
Making a joke =/= trolling
You comments is very helpful, I've messed up for GOPATH and Go module with Vscode, as varies combination still have issues(some not auto import, some can't jump to definition ). The recipe your provided works ( though I've turned off language server feature, so auto import is working ).
What do you mean by module versioning? Can we eventually use modules to select the go version to use in a project?
I think your code is open to SQL injection. First Gist Line 35.
tried \`go build .\` ?
Part 2 - Security testing in Go ;) Nice catch though
"go run ." should work just to run your code. When you "go install main.go" (or "go run main.go"), you do not include all required files.
I can't believe I never thought of similar; I do contextual logging to enable easy tracing through the logs, but it never occurred to me to do error wrapping. That's pretty neat, I know what I'm doing when I get to the office...
The guide you are following suggests compiling files with "go install". This is wrong. There are other guides
It might at least provide an opportunity to allow try(expr, func(*error)), in order to handle the error right at the call site: try(fetchData(), func(err *error) { if (errors.Is(*err, Retriable) { // Recurse again *err = OuterFunc() } else { *err = fmt.Errorf("fetching data: %w", *err) } })
are we there already? botting üåü on github? üòÇ nice work!
&gt; I was following this blog : Creating Package In Go This is the main problem. Stick to (and only to) https://golang.org/doc/code.html . This description is accurate, complete, understandable and correct.
I made this after seeing someone on Twitter complain about GH not doing anything about bot accounts used to star repos, so it seems that there's at least a rumor that it's the case. I've been able to see a few suspicious repositories, but it might just be that they were starred by a community of people coming from outside of GH especially to star these repos, so I can't really be 100% certain whether it's bots or not. &amp;#x200B; Either way, I guess this can be useful for some people so I'm putting it out there :)
Finally got it working. Thanks a lot!
I just use a good logger that tells me the file and line number. Solves the issue of trying to find where it came from....
It doesn't. Just don't add magic try function with magic consequences. Where does it get the err if it's defined elsewhere? This is bad. Keyword could work I guess.
Also where too much has been tacked on as an afterthought to still call it an elegant language. All these changes make it harder to learn, read, parse, debug. Is it worth it? I don't think so.
&gt; What do you mean by module versioning? Since Go 1.12: _"The go directive in a go.mod file now indicates the version of the language used by the files within that module."_ See: https://golang.org/doc/go1.12#modules &gt; Can we eventually use modules to select the go version to use in a project? Not exactly. Its been suggested, however, that the Go toolchain (compiler, etc) could use the information to allow for triggering a compatibility-mode or at least providing better error messages in some cases. More on that here: https://github.com/golang/proposal/blob/master/design/28221-go2-transitions.md#proposal
Distributed systems PhDs spend months or years working on iterative improvements to existing consensus algorithms. It's... unlikely that two dudes in a startup office can, over the course of a few breathless late-night whiteboard sessions, create a revolutionary solution in the problem space by mashing together a few existing libraries.
Completely agree; for both I and Heyang have spent a years worth of time to construct this new protocol. Nonetheless, it has been peer-reviewed by distributed systems/cryptography academics such as Dimitris Papadopolous, Foteini Baldimtsi, and Joshua Lind from HKUST, George Mason University, and Imperial College. The blockchain community nonetheless has been riddled with iterating on prior documented mistakes foreseen in traditional distributed systems; we at Perlin are taking our heads out of that gutter. We definitely do not take several years of prior research as a joke here at Perlin.
I have never seen this style of error handling in golang either. The naming convention seems bad practice, as u/theclapp also pointed out. I don't understand why you would need several error variables. Typically you can work with only one and call it the conventional `err`. This should work because normally any function returning an error will be followed soon by a check `if err != nil`. For example when writing program that writes something to a file, why bother trying to write to a file if you failed to open it. If opening succeeded, then `err == nil` and you can happily reuse the same variable. If your function becomes so big that you need several errors, this may mean you need to refactor and split the function into one or more smaller ones.
I think we have an [X Y problem](https://en.wikipedia.org/wiki/XY_problem) here. You have some data of type `map[string]map[string]map[string]interface{}`. How did you obtain this data? Did it by any chance come from a common data storage format, such as xml, json or similar? If so, please use one of the [encoding](https://golang.org/pkg/encoding/#pkg-subdirectories) packages to decode your data into a golang datastructure. If necessary you could translate from this datastructure to your `Item` struct.
Don't want, don't need, won't use - there's nothing wrong with error handling as it is.
Thanks for the link. I could not recall having read that anywhere, so I asked.
Using `fmt.Sprintf` for db queries... Next level
Interesting approach. Personally, I just direct all error logs to an errors@company email that no one ever looks in, then occasionally go in and bulk purge the 10k or so reports to keep it tidy.
wowww that's terrible as well omg
- `main.go` and `BrowserMethod.go` are both in the same package `example_work`. - `func main` must be in `package main`. - To import a package the argument is the import path, i.e a directory, not a file name.
Not sure if MS is involved in the library, what do you expect them to do?
That only adds to the realism.
[removed]
Nice catch. I guess it's better to write the correct code to avoid that.
[removed]
... But I thought there were no generics?
&gt; Also, make sure to set the GOROOT env var to point to $HOME/go/, or wherever you extracted the tarball. Stopped reading after that one. Why do people spread this misinformation? You extract the tarball where https://golang.org/doc/install tells you and you do not set GOROOT.
Its not coming from common data storage format.
To be more specific, variable shadowing can lead to problems. Hence using separate names.
While running on https://github.com/kataras/iris/ I got: &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=386" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=387" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=388" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=389" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=390" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=391" &gt; Fetching "https://api.github.com/repositories/50709152/stargazers?page=392" &gt; error while fetching "https://api.github.com/repositories/50709152/stargazers?page=392": &amp;{502 Bad Gateway 502 HTTP/1.1 1 1 map[Content-Length:[32] Content-Type:[application/json] Date:[Thu, 27 Jun 2019 13:10:10 GMT] Etag:["5d14b98d-20"] Server:[GitHub.com] X-Github-Request-Id:[A254:17D65:1090807:14B9C2B:5D14C02A]] 0xc00017c3c0 32 [] false false map[] 0xc000844600 0xc0000a6370} &gt; Fetched 11730 stargazers Querying user info from each stargazer... Maybe some retry logic would be good?
Why do you need automatic? These commands and flags are uncomplicated and easy to use... ``` $ go mod vendor $ go build -mod=vendor $ go run -mod=vendor ```
I'm currently rewriting this part to use the GraphQL API instead üëç
I appreciate your taking the time to reply, but it's difficult to take your claims seriously when you open your narrative with this vignette: &gt; I was in the office in a cold sweat, finalizing the WebAssembly smart contract SDK so that developers could build applications on top of our Avalanche-enabled ledger Wavelet. I hesitated finalizing the SDK. I turned my chair and ... asked: If Avalanche can‚Äôt guarantee that nodes execute transactions in a consistent order, how the hell would smart contracts work? &gt; &gt; Although the debate grew tense, it unfortunately ended in disappointment: as we passed the pencil and paper back and forth, we slowly came to realize that every single attempt at a remedy we conceived made absolutely no sense. It was becoming increasingly obvious that what we were doing was recklessly attempting to workaround the very fundamental reason why Avalanche is even able to scale: Avalanche achieves scalability by not guaranteeing a consistent ordering of transactions across a network. Being one click away from publishing some code that you only realized in the 11th hour doesn't work, at a foundational level, because you hadn't thought through the implications of eventual consistency? And trying to "fix" it with workarounds? I don't want to rain too hard on your parade, I'm sure there's some reasonable engineering in your system, but this kind of fundamental misunderstanding of core distsys stuff absolutely does not reflect years of study in the field. For what it's worth, I see this approach, and almost exactly these mistakes, in almost every blockchain infrastructure organization attempting to solve distributed [Byzantine] consensus. Their talented engineers have a reasonable understanding of basic consensus principles, but believe they can solve the tricky corner cases by thinking plainly from first principles, or gluing together existing protocols or systems in novel ways. It's simply not that easy, and, worse, the problems in these approaches often take months or years of CPU time to get exposed, resulting in severe bugs, exploits, thefts, etc.
Yes, seems you are right that only when using ParseForm() is the content length restricted: https://golang.org/src/net/http/request.go#L1176
the compiler has generics. For example, `append`, `copy`, `delete`... https://imgur.com/a/pGgHB7i
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/7pggMLq.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme)
Perhaps you could use GoRename to rename the variable to something less ambiguous before you move it. https://godoc.org/golang.org/x/tools/cmd/gorename
What about a symbol. Like "@" f := @os.Open() defer f.Close()
PSA: `try` still works with unnamed return values!
the tests do the same for both java and golang versions in cbc and gcm modes. i.e they acquire a random iv and then encrypt, after which they pack the iv and cipher text in a byte array/ slice. the aim of the bechmarks are to show and bench mark a practical example. practical here means you must have the nonce gen inside the encrypt bench. using a constant or zero nonce is fatal for gcm and should never be done. the function I call for gcm is called directly by NewGCM and I pass in the default 12 byte nonce size, which means there is no difference between the two. Please have a look at the nonce size I use, which for gcm is the standard 12bytes. The slowness cannot be nonce generation because the aes+cbc+hmac tests do so much more including a 16byte nonce, and perform much faster than gcm encryption. benchmarking just the seal function is not realisitic because it leaves out and ignores everything the encryption mode needs to work in any practical sense. Im not the only one who has noticed go's bad encryption perf. You can see the links in the post made and also from the first comment in this post.
My code does: enc, err := cipher.NewGCMWithNonceSize(c, nonceSize) from: https://github.com/gerritjvv/crypto/blob/master/crypto2/pkg/crypto2/aes.go#L59 The GoLang code does is: func NewGCM(cipher Block) (AEAD, error) { return newGCMWithNonceAndTagSize(cipher, gcmStandardNonceSize, gcmTagSize) } func NewGCMWithNonceSize(cipher Block, size int) (AEAD, error) { return newGCMWithNonceAndTagSize(cipher, size, gcmTagSize) } From: https://github.com/golang/go/blob/4a0dad211c2158e8763c6fd230fbdc1c7d566cb9/src/crypto/cipher/gcm.go#L84
&gt; -mod=vendor You have to add it to almost every command (install, vet, test, etc) and build, test, ci scripts. Also you have to document it and make sure that every developer is using it on their local builds or they will skip the vendor directory. It should be automatic, why would you use a vendor directory with modules if you don't intend it to use it?
Not a fan either. I like the explicit error checking in go. Why cant they just give a compiler warning if you assign err and don't check it? Im fine with them assuming a local err variable is an error type.
&gt; Just use Goland for the god sake! but.... your name is emacs24 i use yasnippets
Eventual consistency does not imply that a total ordering is assumed over events in a system. Systems that are eventually consistent may trade-off a total ordering over events in order to maintain greater availability (as they have one less property to worry about in establishing finality). Avalanche in this case made such a trade-off, to the point where re-introducing some form of total ordering for the purposes of smart contracts was far too expensive. This is not something necessarily obvious, even to that of an academic. Brushing that aside however, I hesitate at your advice because formal verification is absolutely not what has constructed distributed systems literature, and does not at all describe the reasons why we have functionally resilient distributed systems to date. I could only imagine you are arguing on this belief because you simply do not trust the numerous proposed systems which blockchain literature has proposed over the past few decades. Yet, I must emphasize, blockchains have sparked a great deal of innovation in the distributed systems literature space. For instance, new consistency and availability models had to be invented in order to properly relay what properties Bitcoin actually had as a Byzantine fault-tolerant distributed system. Asynchronicity/partial synchrony models originally introduced from what stemmed from the FLP impossibility results back in the 1900's have been re-worded and re-stated in so many ways because of the numerous new properties that had to be invented to properly attribute the behavior of new blockchain systems. Heck, the very definition of what a Byzantine fault and how they may be prevented is still unclear and has changed in definition several many times over the years. I would insist that you please read Wavelet's whitepaper rather than slandering it off as a pure engineering effort with no consideration or even a slight hint of research effort. Yes, the wording of the blog-post may be fluffy, though in no way speaks of errors as silly as not knowing what eventual consistency literally is. I would rather you make claims, or be more dubious on the statements or combinatorial proofs sketched on Wavelet's whitepaper. Nothing at all from the whitepaper speaks of derivations from the first principles. Just reading the introductory section of the whitepaper should be enough for you to understand that. https://wavelet.perlin.net/whitepaper.pdf
Indeed :)
Glad it helped!
No problem! And there's nothing wrong with asking. üôÇ
Ugh, really hope try doesn't get put in.
Hey, sorry for the late reply. Could you give me some more details e.g. what is the full command you're running and is there anything relevant (e.g. errors/warnings) logged in the output? Also, it might be easier if you create an issue directly on the project here: https://github.com/bradleyjkemp/grpc-tools/issues/new? That way I'll be able to follow your updates more easily. Thanks for trying it out!
The world doesn't work that way.
Don't you mean Iris? https://news.ycombinator.com/item?id=17528793 Couldn't find anything related to Echo. Any pointers?
Yes, I was thinking of Iris. See my edits and response from u/Tikiatua. Sorry for the confusion!
True, I didn't see your other reply. Thanks for the clarification!
&gt; ... Linux and Mac as well. Is there any way to retrieve the console window, in all three cases and hide/unhide it? No such thing, **but** you could just fire up the user's terminal and tail the log files. Some users set a TERMINAL environment variable, its a less established convention than $EDITOR so if not set then try reasonable fallbacks like `gnome-terminal -- tail -f logfile.txt`
I didn't claim it did. I wasn't comparing `try` as a keyword vs current error handling. I was comparing `try` as a keyword vs try as builtin function. Personally I'm fine with not having something like `try` at all but if we are gonna get it, I'd prefer one where I wouldn't have to re-write multiple lines of code to add or remove context.
gross
&gt; Why cant they just give a compiler warning if you assign err and don't check it? [staticcheck](http://staticcheck.io/) already does that. And not just for errors.
From the FAQ: Is this an officially accepted proposal? No! Enjoy it, experiment with it, and don't complain about the syntax ;). Eh, you can, but you know, don't overdo it.
Never heard of that. ill def check it out. thanks
&gt; Go doesn't really support functional programming because it lacks tail call optimization. why?
I'll take this over contracts any day.
This is pretty close to what my first thought was for generics. (I don't mean that an endorsement necessarily, just that if I see it that way, probably others do too, which implies it may be easier to explain.) I like the provided sample implementation and samples. I find the idea of special casing eq, ord, and num as a way of getting out of needing contracts kind of interesting. It does seem like the primary purpose of contracts would be to specify one of those. Possibly a couple of other such things would be needed, but that doesn't break the proposal. A small list of such exceptions may be better than a complicated contracts mechanism. But I'd still like to be able to stick an interface in there; one of the core use cases for generics for me is still things that may require more than just those things. Plus I think it harmonizes with the language better; I think people are going to ask why they can't put an interface in as a type restriction, and I'm not sure I see a good answer for that. I understand the "simplicity" argument but I'd say that broadly speaking, if the language has two features that seem like they ought to go together, they probably should.
The mod.sum file should be enough to verify that everyone has the same files regardless where they get them from. You can set `GOFLAGS=-mod=vendor` to enable it everywhere given that commands that does not support modules won't work.
I like it. You're have a challenge in getting adoption here, though. For example, VSCode's default formatter actually isn't gofmt, but goimports, which both formats and organizes imports. If you turn on the use of the language server (Gopls) in VSCode, then Gopls is formatting. Both of them use gofmt as a library to do this.
You can still annotate via `defer`, it's the recommended way to do so in combination with `try`, see the design document for this.
A drop-in replacement for goimports is available in the repository as well, precisely because some people and IDEs prefer that. As far as gopls goes, they might add better support in the future for custom tools. Until then, I'm not sure what the easiest solution is. In any case, the purpose here isn't to replace gofmt, or to compete against it. This is to automate work for developers who like a stricter formatting standard, like I do.
&gt; It should be automatic, why would you use a vendor directory with modules if you don't intend it to use it? For me it's just a safe guard that I can build the software even with no other network access and CI takes care of verifying that vendor/ has everything in place. I don't have a particular reason for using it locally. It just makes development more cumbersome .
Hey, thanks for the comment! You have a good point with interfaces. You are right that they fit the use case there. What I worry about is that they would, just like contracts, open the doors to a whole bunch of big abstractions that are difficult to understand. Maybe this worry is not justified, I don't know. But consider that you can make generic interfaces. Then you'd be able to do things like this: `type T Equaler(T)`. I'm not sure I like that.
One thing that's a bummer is that I can't just do `gofumpt -s -w **/*.go`, as there are a lot of generated files which pass `gofmt`, but not `gofumpt`. For example, `stringer` generates code with single-variable var groups. Of course, I could just not run it on those files (or only format via my editor, but that'd be `gopls` territory). I do appreciate that it didn't try to reformat my `//counterfeiter:generate` comments, which was my main worry when reading the list of things that it would do.
There are some people involved from MS, or rather some contractors engaged through MS looking at the project. &amp;#x200B; However, the main bottle neck is probably myself. I don't have a lot of free time available. I do contract work too, so you can contact me to arrange $$ if your company needs a specific feature in. &amp;#x200B; I understand the need, it just isn't my need right now. I try to review pull requests when they come in though.
What are the chances of getting real backs/clutches? Not just the rubber backs? Honestly, the rubber backs are junk, I've lost too many pins with them. Most preferred would be flat locking clutches.
This is a fair comment and a reasonable request, and I apologize for being so brusque.
Generated files are a bit of a grey area, yes. I personally do use gofumpt on those files, as I use the tool directly as a gofmt replacement. That also allows me to simply reformat everything anytime, like you say. If you want to enforce this strategy properly with tools that don't produce formatted code, or which follow gofmt, you could always add a line like `//go:generate gofmt -w generated.go`.
Thanks for your feedback. Previously I was only mentioning that the code was copied from rclone, linking to the file it was copied from and mentioning their license. I've now included their full license/copyright.
This is actually really nice. It's got most of what you need without going crazy. Can restriction based on interfaces work though?
[removed]
[removed]
thanks for doing this. im looking at them so far looking really useful for finding where i can help!
Anyone building SQL like that loses any credibility right away. I didn't read the rest of the article
Ooh, this looks _great_. I've wanted most of these for a while. There are a couple rules that I'm not too sure I'd want in my own code, though. - The "short case clauses should take a single line" rule might annoy me if I have something like case "yes-a", "no-a", "yes-b", "no-b" where the cases are grouped by line. As far as I can tell, gofmt does not reformat based on line length, and I very much like that property. - Similarly, I like having the option to have single-declaration specs grouped with parentheses. It clearly communicates "more are coming", and I won't have to reformat the thing if I go from one thing to two things to one thing to two things (as happens with import-statement blocks sometimes). I'll try it out later today. Thanks for making this.
&gt; With a keyword, that might not be feasible Maybe that's a feature...
Ooh, this looks _great_. I've wanted most of these for a while. There are a couple rules that I'm not too sure I'd want in my own code, though. - The "short case clauses should take a single line" rule might annoy me if I have something like case "yes-a", "no-a", "yes-b", "no-b" where the cases are grouped by line. As far as I can tell, gofmt does not reformat based on line length, and I very much like that property. - Similarly, I like having the option to have single-declaration specs grouped with parentheses. It clearly communicates "more are coming", and I won't have to reformat the thing if I go from one thing to two things to one thing to two things (as happens with import-statement blocks sometimes). I'll try it out later today. Thanks for making this.
&gt; where the cases are grouped by line. Interesting. The reason behind this rule was C-like code, so perhaps it's too agressive to be on all the time. Do you have any example of code like this, which the tool modifies? &gt; "more are coming" I too worried about this case a bit. However, I've seen these unnecessary parentheses and newlines in master branches more often than I'd like. I think they should be discouraged, much like unused variables. Both parentheses and unused variables fall under "but what if I'm still writing code". I'd argue that, in that case, you shouldn't format/run your code until you're done writing those few lines. And if you are, you should follow the rules. What made me lean towards being strict here is that `goimports` already deals with grouped imports, and grouped consts/vars aren't modified that often. Personally, I haven't been bothered by the rule. But if you are, please file a bug :)
Do you check for the standard generated file comment? https://github.com/golang/go/issues/13560
The tool doesn't check for or skip generated files, and I think it would be surprising if the tool did. Neither gofmt nor goimports do.
This is well situated in the 80-20 sweet spot.
While your proof of concept is interesting. I'm still confused about why everyone wants Generics? Just stop and think about your data structure first. Too many snowflakes want to just stuff things into places and not think about it, then we will turn in PHP or Python where objects that should be 500 bytes are 5 megabytes. I feel generics are going to negatively impact the language and runtime.
&gt; Do you have any example of code like this, which the tool modifies? I don't. This was an objection based on theory. &gt; I think [unnecessary parentheses and newlines] should be discouraged, much like unused variables. The primary benefit I've seen that comes from having the no-unused-variables rule is that it alerts me to logic bugs in half-written code. &gt; Both parentheses and unused variables fall under "but what if I'm still writing code". I'd argue that, in that case, you shouldn't format/run your code until you're done writing those few lines. Makes sense, but I have my editor set to reformat on save‚Ä¶and I bounce on the ‚åòS key a lot. If I leave a variable unused and hit ‚åòS, I merely get a (1) in my Problems list. If I define a block of consts and only add one in with more to come when I tackle the next thing on my to-code list‚Ä¶then my block structure gets mutated. I suppose my underlying objection is "mutating block structure is a bridge too far".
This is exactly what a generic implementation in go should look like. Great job!
Change https://github.com/mrtkp9993/SimpleCRUDApp/blob/master/responses.go#L29 to stream the JSON body so your server doesn't have to buffer all the bytes you are sending. ``` // w = http.ResponseWriter err = json.NewEncoder(w).Encode(mystructhere) ```
Very nicely done, Daniel!
Reminds me to my https://github.com/Eun/goremovelines tool. Good work!
Why not just write all the commands you want in a bash script and run that instead during the filesave?
I understand your concerns, but they aren't truly justified. Generics don't make objects bigger, at least in my implementation. They simply provide a way to reuse the same code for multiple types. To see what kinds of functions and types you could write with generics, take a look in the examples directory in my repo. You'll find things like a linked list, type safe sync map, type safe sorting, and various utility functions.
I can only do so much with a closed source project, but with some obfuscation... A trivial search on one of my codebases shows 168 matches for `return (.*,\s+)err\s+^` and 61 occurrences of xerrors returns. Tryhard ([https://github.com/griesemer/tryhard](https://github.com/griesemer/tryhard)) outputs about 112 occurrences of opportunities to use `try(...)`. One example, somewhat modified: func GetFoo(ctx context.Context) (*FooSet, error) { foos, err := getFoos(ctx) if err != nil { return nil, err } fooSlice := make([]*Foo, 0) for fid, fub := range foos { foo, err := NewFoo(fub) if err != nil { return nil, err } if err := foo.Set("foo", fid); err != nil { return nil, err } fooSlice = append(fooSlice, foo) } return &amp;FooSet{Foos: fooSlice}, nil } A try based version could be more terse: func TryFoo(ctx context.Context) (*FooSet, error) { foos:= try(getFoos(ctx)) fooSlice := make([]*Foo, 0) for fid, fub := range foos { foo := try(NewFoo(fub)) try(foo.Set("foo", fid)) fooSlice = append(fooSlice, foo) } return &amp;FooSet{Foos: fooSlice}, nil } A `check` based version could be similar, where `check T` is defined as being equivalent to `if T != nil { return ..., T }` func CheckFoo(ctx context.Context) (*FooSet, error) { foos, err := getFoos(ctx) check err fooSlice := make([]*Foo, 0) for fid, fub := range foos { foo, err := NewFoo(fub) check err check foo.Set("foo", fid) fooSlice = append(fooSlice, foo) } return &amp;FooSet{Foos: fooSlice}, nil } To me though, this highlights an important distinction: check err is almost impossible to miss when scanning the function foos := try(getFoos(ctx)) could be. Not only that, but also the property that the builtin can be shadowed (which allows the form of backwards compatibility) but creates control flow ambiguity. So these both reduce the boilerplate a little bit, but I personally like that I can scan for "check" in the same way I can for return statements. However, check as a statement leaves out the ability to simplify some statements and assignments. func CheckAndCollectFoo(ctx context.Context) (*FooSet, error) { var err error foos := collect(&amp;err, getFoos(ctx)) check err fooSlice := make([]*Foo, 0) for fid, fub := range foos { foo := collect(&amp;err, NewFoo(fub)) check err fooSlice = append(fooSlice, foo) check foo.Set("foo", fid) } return &amp;FooSet{Foos: fooSlice}, nil } `collect` would allow us to pull out inline errors, with none of the magic side-effects on control flow. It is intended to follow a similar pattern as `append`. It does however, by virtue of not changing control flow, mean that in the case of an error and therefore a (potential) nil value, the result of collect may not be usable. appending NewFoo can leave fooSlice with a null pointer on it if collect sets fooErr. This means that: info := collect(&amp;err, collect(&amp;err, os.Open(file)).Stat()) check err works, but relies on `*os.File` checking for itself being `nil` on the Stat call and returning an error (rather than panicing). That would result in the outer error being "invalid argument", but the inner one being the error from [`os.Open`](https://os.Open). This is slightly more surprising possibly than the possibility of try avoiding functions that have side-effects within a line by short-cutting to a function return. if err = Get(MessageType, m); err != nil { return xerrors.Errorf("Unable to get message %v: %w", m.ID, err) } if err = Store(ctx, log, m); err != nil { return xerrors.Errorf("Unable to store message %v: %w", m.ID, err) } in this case, `try` is less helpful. In this particular codebase, we're increasing the usage of xerrors. Defer as a pattern only allows a single handler per function in a useful way. [https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md](https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md) However, check could work: check HandleErrorf( Get(MessageType, m), "Unable to get message %v", m.ID) check HandleErrorf( Store(ctx, log, m), "Unable to store message %v", m.ID) Much like the example from the try proposal, this allows library based extension of error wrapping that only happens if the error is not nil. See `HandleErrorf` from the proposal. The equivalent here would be approximately: func HandleErrorf(err error, format string, args ...interface{}) error { if err == nil { return nil } return fmt.Errorf(format + ": %v", append(args, err)...) } As an observation, this is perhaps not that much shorter or clearer than the `if` version, but it does avoid being only useful in a subset of cases. It's difficult to cut down simply because the wrapping is the majority of the code in this. Overall, I come out on the side that `check` reduces boilerplate and scans correctly for me. I don't like looking for try, and I'm somewhat ambivalent to collect as proposed here, although I think it reads without too much magic and allows some of the cases that try supports.
They certainly could, what I worry about is that they could open doors to various big, incomprehensible abstractions. But perhaps I'm wrong. Do you have a specific use case that would benefit from such restrictions?
I updated the package to pass the `context.Context` of the `http.Request` to the service (major oversight) and updated the documentation.
I like it. It's pragmatic and solves things without going off the deep end. I think I'd like to see a more future-proof way of expressing type constraints (`eq` and so on). While these pre-defined names are a good starting point, the syntax might get in the way of some future type constraint language or typeclass mechanism. I also suspect that once you have generics, you'll very quickly be longing for a type constraint system. For example, one thing that's painful with Go's `map` is that there's no way to override the hash function. So let's say we want to build a new generic map implementation that asks the keys to hash themselves, so we have a "typeclass" like: type Hashable interface { Hash() int64 } But right now I can't declare a generic type that only accepts hashable keys as the type: type entry(type K, type V) { k K v V } type HashMap(type K, type V) { table []entry(K, V) } I think the only way to do it would be to accept a hash function in the constructor: func NewHashMap(type K, type V, hasher func(K) int64) { ... } m := NewHashMap(Hashable, interface{}, func(h Hashable) int64 { return h.Hash() }) ...which is not as nice. What could work is a type constraint system similar to Rust: type HashMap(type K: eq + Hashable, type V) { ... } There's one thing I don't like about your proposal, which is that method receivers have to repeat the entire signature of the type they're declared for. That's pretty verbose, and a recipe for copy/paste errors: func (sm *SyncMap(type K eq, type V)) Store(key K, value V) { Not sure how one could avoid that. Rust avoids thing with the syntax `impl&lt;K, V&gt; for SomeType { ... }`, allowing lots of methods to share the same declaration, but obviously Go has chosen a different path.
The reason I didn't opt for a system for making custom restrictions is because I'm worried it is the deep end. I think if we can solve the custom hashing function problem by passing the function to the constructor, I don't think we should invent a constraint system just to solve it. However, if people come with problems that really can't be solve without making custom restrictions and those problems are important enough, I'll rethink it.
There's a simple extension to `interface` that makes the "refer to self with extra parameters" go away: explicit `this` types (you can also use `self` or other nomenclature). Now, adding new features to Go's type system certainly has a cost, but I feel that this one pays for itself. type Equaler interface { Equal(this) bool } A type implements an interface with `this` if it implement the interface you get after replacing `this` with the receiver type. For example, type IntPair struct { x *int y *int } func (p1 IntPair) Equal(p2 IntPair) bool { return *p1.x == *p2.x &amp;&amp; *p1.y == *p2.y } satisfies the `Equaler` type above. Now, you'd amend the language by: - add the primitive `eq`, `ord` and `num` interfaces, which are implemented (in pseudocode) as type eq interface { ==(this) bool !=(this) bool } (but of course we wouldn't provide the ability to actually do this for user-written interfaces) - allow you to write `type T constraint` where `constraint` is some interface type that `T` must satisfy In addition, this doesn't change how you call/interact with non-generic functions or types at all, so all those things stay the same. The main issue is *interface objects with `this` types*. They are somewhat limited: If I have a `foo Equaler` with the above definition, there isn't much I can do with it. The problem is that I know it has an `Equal` receiver func, but I don't know what type needs to be given in order for it to work! In order to call the `Equal` receiver func, you'd either need to type-assert it to some concrete type, or use reflection (which is usually not the right solution). The result is that you can't call any receiver func that uses `this` anywhere inside its arguments. It's slightly-less obvious, but you *also* can't call any receiver func that uses `this` anywhere in its return. That's because you wouldn't know the runtime representation of such an object (e.g. if it returned a `[]this`, that's not coercible even to a `[]interface{}` without copying). The result is that "`this`y interface objects` would have fewer methods available. But I think that's okay! If you really wanted to be able to call them, you can pass them to a generic function; and in general, any function that The main reason I put this forward is that I think constraints are important (so that generics actually pull their weight), but people don't want them to be complicated. Since gophers are already okay with interfaces for describing constraints on types, we should use them. The main problem is that they're not quite powerful enough. Adding `this` types to interfaces today is pointless (for the reasons outlined above) but with generics, it makes them much more powerful in an (I think) self-explanatory way. Certainly people will need to look it up the first time they see it, but that could already be said for the much-proliferated anonymous `interface{}`. Of course, it would still be *possible* to write things like `type Equaler(T) interface { Equal(T) bool }`, but I don't see why people would, since the result is less convenient to use *and* much less-obvious to begin with.
The second one is the solution to your problem. Delegate to a function that is easy to test. You don‚Äôt need to test if the function is executed, because spf13 took care of that. You should worry about your own implementation.
Really nice tool! I'm definitely giving it a try. Any chance it could also remove empty lines between imports? Like going from import ( "fmt" "a" "b ) to import ( "fmt" "a" "b" ) --- This is something that really bothers me when using Intellij+goimports. Intellij inserts those stupid empty lines when autoimporting, and `goimports` keeps them because it likes to respect blocks. `gofmt` also doesn't remove them, and I end up having to remove them by hand. I only wish my sed game as good enough to come up with a dirty hack to solve this because I feel like fiddling with `gofmt` code is kind of really hard.
I *think* this happens already. At least gofumpt tries really hard to join all standard library imports into a single group. If you find a case that doesn't work, please file an issue. Grouping imports outside the standard library is trickier, though. `goimports` knows about the groups via `-local` flags, so `gofumpt` could never get that information. We could make the grouping stricter in `gofumports` (the `goimports` replacement), but perhaps that would confuse users.
https://github.com/golang/go/wiki/Mobile There are limited type support at the moment: so you can't have a slice of pointers (or structs) across the bridge. Slice of bytes works though, so you could use protocol buffers (or similar) across the bridge.
&gt; I don't. This was an objection based on theory. Much of the idea came from gut feelings, but I try to base decisions on real examples :) &gt; The primary benefit I've seen that comes from having the no-unused-variables rule is that it alerts me to logic bugs in half-written code. That's a good point. &gt; I suppose my underlying objection is "mutating block structure is a bridge too far". I get what you mean; I'm still a bit on the fence about this. It's perhaps the only one of the rules that is more for "run before commit" than a "run before save", but I don't have an easy way to distinguish the two. Would my reply in https://github.com/mvdan/gofumpt/issues/23 make it OK for you, or are there cases where it's still too agressive?
I tried it, it doesn't group imports outside the standard library, which is exactly what I wanted. That is, I wanted two groups only: std, non-std. One single line between them. That's it. You're right about it confusing users. This is a very strict use-case, I don't think it's worth the effort to include it in a widely used tool. This whole discussion gave me some energy so I started to fumble with the `goremovelines` cited by other commenter and I guess it's gonna be pretty simple to hack something up. Thank you very much both for the tool and the inspiration!
One thing you could perhaps push for is for goimports to gain the ability to join all `-local` groups always. That is, if one calls `goimports -local group1,group2`, then the resulting code cannot have more than three groups (the two local ones, plus std). Right now, the tool allows extra separations, because otherwise too much code would change suddenly. But if this was opt-in, it could work.
https://github.com/bh90210/CP500 this is a small app I've made with gomobile. also worth looking at https://github.com/ipsn/go-ghostbridge but protobuf would be the best and even mote complicated way to go. if u'd like a piece of advice DON'T go that way. there is a reason there are few resources. People don't use it!
The check version means you need to create err variables where they aren't even needed today (if err:= scopes it's value to the if statement), and that's an antipattern to me. Collect is adding a domain-spdcific language for error handling, and doesn't do anything better than if, and hides some pretty subtle logic. So, while these are alternate proposals that can be considered separately, I don't think that they compare to try along what I see as it's target axis, which is reducing boilerplate for people who are bothered by it without changing the way Go code looks otherwise.
Testing the cobra cli commands directly is either unit testing in cobra or more of an integration test, so I wouldn't call it skirting around a problem as much as I would call it testing a single unit of code.
This is an interesting idea. I don't think I'm gonna incorporate it into the proposal, but it made me think a lot. Now, interfaces as they are solve a lot of constraints problems themselves. Do you have a specific use case where something like what you propose would be useful?
I was happy with if. I'm not fond with try because of it obfuscating control flow. Check doesn't require variables in every case, but it's not uncommon to have an error variable in scope. You'd need a named return for defer handling too in the try proposal. try is magic, and check + collect is intended to almost get you to try, but without obfuscation. try *absolutely* changes the way that Go code reads.
Selecting on a nil channel is identical to selecting on an bufferless open channel nobody else is using.
Ok
I figured you didn't have time. Otherwise a great module. We had 2 large internal projects get passed to other languages (Java) from GO because kerberos auth. I was getting frustrated. Thats all. &amp;#x200B; Thanks for doing what you do
&gt;kuratkull Hoping they have some resources to help the author of go-mssql.
I was hoping someone from their sql server team help the author of go-mssql.
if I didn't ask no one will know. I didn't think I was so off base for asking
sorry if I came as a bit aggressive I wrote the comment in a a hurry üòÇ the reason I say don't go that way is because what at the end of the day u ll realise is that having a mobile app being 24mbs for doing say simple math, a calculator.., isn't going to work in literally any production environment. and also that that it is not a comparable situation to for example react native that u can finish the whole app in javascript. with go the best u will achieve is write a library for android native. u still have to use java etc * * the are reverse bindings but resources wise I really only found the ticket üé´ and a couple articles discussing it.
A couple of years ago I did a talk about gomobile at FOSDEM, it's probably outdated, but it had a bunch of links at the end. Here are the slides: https://talks.madriguera.me/2017/fosdem2017.slide#1 Ivan Danyliuk has some slides and posts about gomobile+flutter for the interface that are great too.
And that can lead to accidental waits that never finish because nobody can close that nil channel.
Nobody can close a channel where you have the only copy, either.
Do enjoy someone else realizing that genetics via code generation is a good idea
I'll look into those, I've no experience with them myself but they might be a worthy investment. :)
Bloom filter?
This works but isn't a complete answer (unless having a probabilistic response is sufficient). If you want an exact answer you'll need a little more work. If you're happy with approximate answers, then you can use multiple bloom filters to reduce the odds of an incorrect answer to be arbitrarily small. But it's still not *exact*. Another answer if both tables are sorted by PK, you can query them both and do a linear time intersection.
Please, have a look at my new blog post explaining our new plans https://blog.dgraph.io/post/serialization-versioning/
Can you say something about the keys/values you want to match on? Ints? Strings?
Better answer. I'm terrible with DBs. Just providing something of potential value.
I'll have to read up on bloom filters but if there's a decent level of confidence then that might be a good enough solution for now. The two tables don't have a PK or any useful unique columns that can help batch the processing.
Yes, and you're responsible for initializing variables and checking if a pointer is nil and so on, and yet mistakes happen. Nil is pesky because it adds an additional value to the set of possible values expressed by the type. In Go, every nillable value is the union of the type's values and nil. For example, some API returns a nil map when the caller assumes it will never return nil. You can program defensively to avoid such cases, but if you design a language to make these values impossible in the first place, then you eliminate entire classes of bugs. For example, Rust doesn't have nil except in unsafe blocks, and its very hard to take the wrong branch when you have an `Option` or `Result` value.
There are hundreds of columns with a variety of decimals, varchars, and datetimes unfortunately
Bloom filters may be helpful. They could answer the question ‚Äúis this record in this other data set?‚Äù With ‚Äúdefinitely no‚Äù, or ‚Äúmaybe‚Äù. If maybe, you do the more expensive check. Also a map of ids would also be an O(1) check, and many languages, including Go, could hold a million ids in a map/hash to do quick lookups.
If you have write permissions for this database it could be useful to store a pre-computed hash for each row, and update it every time a row is added or modified. Then you can perform faster comparisons in the future.
&gt; Another answer if both tables are sorted by PK, you can query them both and do a linear time intersection. This deserves more attention. Sort two lists of ids and walk through them at the same time. Compare left to right. If left is &lt;, inc left and count as not in right. If equal, inc both. If left is &gt;, inc right and optionally count as not in left set. Total time is linear. O(n)
`golangci-lint` might be interesting to you. https://github.com/golangci/golangci-lint It has many plug-ins and it's quite speedy.
This problem seems unrelated to the language you write the solution in. Any solution is not going to be language dependent.
what is the nature of the data? are they strings? do they have a lot of duplicated data like email addresses?
'try' as a keyword is definitely a possibility. It would be allowed under the ["Go 2 transitions"](https://github.com/golang/proposal/blob/master/design/28221-go2-transitions.md#language-changes) plan. I wish there was a TLDR version of that document, but in short, and Go toolchain now knows how to compile older language versions (which can include disallowing newer language features). For example, if 'try' as a keyword landed in Go 1.16 (or whatever Go 1.x version), then old unmodified code would still be able to be compiled by the Go 1.16 toolchain even if that old code used 'try' as an identifier (for example, by having the Go language version set to 'go 1.15' in the older code's go.mod, which would mean 'try' would not exist as a keyword while compiling that older code). The "Go 2 transitions" document is really a foundational document for any discussions of language changes, but that document is long, and I suspect many gophers haven't read it, or are not aware of it. The full document is 15 pages or so long, but the majority is discussion of other languages &amp; rejected alternative approaches. The heart of the transition plan is a quicker read: the 2-3 pages [starting at](https://github.com/golang/proposal/blob/master/design/28221-go2-transitions.md#language-changes) the "Language Changes" section through "Language Redefinitions" section. Finally, none of this is to to say that 'try' as a keyword has zero cost, but there does seem to be a reasonable path for 'try' as a keyword.
I'm more saying that, even if there is no nil channel, that doesn't actually get rid of the possibility of reading/writing to a channel to nowhere, it just means that channel won't happen to be nil. It's sort of inherent in the channel/coroutine model that you're relying on passing in the right values everywhere. I think nil pointers, maps, interfaces, and funcs can cause problems in many cases, I just don't think nil channels are the best example of those problems. I like Rust. I like initialization tracking. If I were dictator of a language, that language would most likely have it. On the other hand, sometimes it can force you into writing code awkwardly. I can see how, for someone coming from a C background, just having guaranteed initialization without adding the kind of friction initialization tracking can might seem like a win. It would be challenging to retrofit Go with types with no zero values. It could be doable, but it would affect other features. Channel receives, map indexing, and slicing all depend on the existence of the zero value. If generics are added, the existence of zero-less types would mean that all generic types would have to be treated as zero-less unless a bound is added. These are solvable problems, but not trivially so.
A few million rows isn't *that* much. Export both tables as CSV or something (making sure to get the same columns in the same order if they're not already like that), sorted by the PK or some other total order, and then diff the files.
Because: 1) it's not cross platform 2) doesn't work across VM 3) different editor/IDE has different ways of doing it 4) can't be shared with other people/project
Hundreds of rows with floats, strings, and datetimes
The quality of your responses is proprtional to the quality of your question. Here, you're giving us very little to go on... http://www.catb.org/~esr/faqs/smart-questions.html
Yeah but I thought go might be good for comparing second table values against the first concurrently.
There's no pk and I'm not sure if there is even column of unique values. There are hundreds of columns...
Fine, just sort it with `sort` then :)
I understand what you're saying, but the nil just adds _another_ edge case. A consumer with no producers is a logic problem that is easy to understand; it meant, well, that you created a consumer and didn't wire up a producer. A nil channel is a semantic issue that leads to surprises: You can have both producers (which would fail on the nil channel the next time they sent anything) and consumers (which would block indefinitely) "wired up correctly", except nothing works. I got burned by this a couple of times and learned early on to never set channels to nil, and treat `close()` as being a message to consumers that they've reached the end, and not as a cleanup mechanism (like closing a file). &gt; I just don't think nil channels are the best example of those problems. Well, I devoted one out of 72 lines to nil channels in my original comment, somehow that was what some people latched onto! :)
I don't think Go is relevant, your database is what's relevant. &amp;#x200B; Starting point: Make a compound index on each table of All The Fields You Care About, which may just be all the fields, but make sure the fields are in the same order. Then it's quite possible that a naive query will work acceptably well. If not, consider exporting them in a predictable format, and there's a well-known trivial solution: \`sort t1 t2 t2 | uniq -u\` This may or may not be fast enough, but "a few million" is pretty trivial. (The results would be any rows in table 1 that weren't found in table 2.)
When you enjoy r/golang
I like \`std\` imports at top. I also separate out 3rd part imports and imports coming from the repo I'm in, so imports are ordered: "std, third-party, local". Do you have any preferences like that? I would find that cool to add.
Snowflakes? Classy.
So basically Campoy changed the semantic of semantic versioning ? ;)
Sorry, I probably could have worded that better. I wasn't talking about breaking compatibility with Go Modules, I was talking about breaking compatibility with all the code that imports your package. Reading your blog post it looks like you want to do two separate breaking changes in the near future, but also don't want to increment major versions too fast because of how that might appear to users. I guess if those are hard constraints you don't have a choice other than to come up with a non-standard versioning scheme. It's unfortunate that backwards compatibility needs to be broken so frequently post 1.0 though. I suppose it wasn't practical to version the changed API functions (DoThing2()) or to support the old serialization format in the newer package version?
https://github.com/mattermost Slack clone
It is about learning in this specific case. As I said, your code is not using channels properly. Nil in this case has special semantics for a reason. If it weren't nil we would use other sentinel value or just opened channel that nobody writes to. Either way, language wouldn't save you from logic errors as is the case in your example. Nils in go make the language simpler. Look at every language that tries to hide nils - there's a ton of language features around optional values. Go would have to get all of that and become just another swift which I write every day. And I don't think go even suffers from nils that much. Its reliance on values instead of pointers in most of the cases make nil panics a rare problem for me. That's not something that go desperately needs to fix. The most annoying thing for me is nil maps and that's not worth fixing by making the language much more complicated.
I appreciate the support, but I have to say that code generation is just a temporary implementation here. This is a full language feature with type checking and everything, and I only generate regular Go code so that I can run it. The generated code isn't very usable for imports, for example.
 mysql database_name table1 -e "SELECT SHA1(CONCAT(column1, column2, column3, column4, column5, etc...))" &gt; table1.csv mysql database_name table2 -e "SELECT SHA1(CONCAT(column1, column2, column3, column4, column5, etc...))" &gt; table2.csv sort table1.csv table2.csv | uniq -u &gt; dupes.csv If dupes.csv contains the same number of rows as both tables, you're done.
Dnote is Go backend and React frontend + Go CLI. It's a note taking software for developers and I'm the author. https://github.com/dnote/dnote I hope it helps you learn more about the stack. Happy to answer questions and share what I've learned using this stack for the last two years.
Oh and about the repeated type signatures for receivers. This is for two reasons. 1. Consistency with functions. The `type` keyword there is again simply marking the first occurrence, nothing else. 2. It does't have to be the same as in the type definition. For example, you can have a type that works for any type, but has a method that only works for numbers. Or only for strings.
Yeah, I'm aware of the linters and analyzers out there. I don't think they fall under the same category as gofmt and goimports, though.
Use bloom and cuckoo filter?
`goimports -local` does this, as does the replacement `gofumports -local`. Note that the tools only separate groups; they don't forcefully join them. I could make `gofumports` do that as well, though. But for now, all changes added have been to both tools.
This all falls apart in the map (Hashable) example in the other comment and drags us back to passing functions that deal with our types without the container having to know how to deal with the type. At that point we might as well pass in `func(interface{}) int64` for the hash function and give this proposal up all together. I do however like the simplicity of the implementation/syntax, and it reads well, but the lack of interface based constrains just makes only suitable for a handful of problems. Also, I've read it yesterday and perhaps missed it, but it felt like this focuses mostly on generic functions, and having generic structs is not that important.
happy I can be helpful :) &amp;#x200B; Also feel free to nag me in the Pion channel of the Gophers slack! Always love seeing new faces/getting more people involved [https://pion.ly/slack](https://pion.ly/slack)
Exactly. The format change is no less a breaking change by having the same API. Surely it would be easiest to make both changes in one release, as v2.0.0?
Not sure if it's enough for you but we just added a react template to https://wails.app. Perhaps the default template is good enough for you?
Agreed. Good point about spf13 taking care of the actual testing of the cli implementation.
Fair enough. And agreed; I want to be testing MY functionality not worrying about the CLI implementation. I'm already using a tested CLI framework, why test it again. Yes, you are right, it is more of an integration test. However, it would be good to line up a bunch of cmd line tests and run them together, testing out the output. Any recommendations about how to achieve this?
Self-hosted comment engine remark [https://github.com/umputun/remark](https://github.com/umputun/remark) [https://www.reddit.com/r/golang/comments/8jdo2l/remark42\_is\_a\_selfhosted\_lightweight\_and\_simple/](https://www.reddit.com/r/golang/comments/8jdo2l/remark42_is_a_selfhosted_lightweight_and_simple/)
Why does that fall part? I think that's a completely valid solution. MakeMap(type K, type V, hash func(K) Hash) My thoughts actually are that if we can do it like this, then that's great because that means we don't need custom restrictions in this case.
I like the proposal, but here are my 2 cents as someone who is relatively new to Go: 1) I don't understand why `type T` should not occur as return type of a function. What's the rationale for `func Read(type T) T {...}` instead of the simpler `func Read() type T {...}`? 2) Regarding wrapping generic functions into concrete functions if they serve as argument: `SomeFunction(func() int {` `return Read(int)` `})` This is a lot of boilerplate. If you'd use my suggestion in (1), we could use instead: `f = Read() int` meaning that f is an instantiation of generic `Read() type T` where T is instantiated to int. 3) Although I understand the design goal of simplicity for Go, I want to mention that the Ada folks seem to generally regret that they have made possible only some restrictions on generic parameters but not any restriction. In the long run, these limitations are pretty severe and they cannot be retrofitted into the language later. Just saying, I would probably be fine with the eq, ord, num hack proposed, but it's not unlikely that myriads of Go3 programmers might complain about it. &amp;#x200B; I haven't followed the discussion about generics so closely, so I don't know why constraints were based on contracts rather than interfaces. Maybe there is a good reason but it seems to me that if it was possible to have constraints of generics based on interfaces, then that would be preferable. This may be naive, but wouldn't it somehow be possible to equip all primitive types with some interfaces? For example, `Sequence` could be an interface for strings, arrays, and slices whose functions are used (and possibly optimized away). It would than be possible to write a function `func DoSomething(s type T Sequence) {...}` that does something with the sequence. This seems syntactically clean to me and could in theory be amended in the future to deal with logical combinations of interfaces, if it was considered worth it. I vaguely remember that there were arguments against using interfaces this way but don't remember the rationale.
Thanks for the comment :) 1. The answer is in the FAQ. It's because putting `type` in the results would make type checking ambiguous. 2. I agree it's a lot of boilerplate. The hope kinda is that it won't happen often. However, if it does, a more concise specialization syntax needs to be introduced. Your syntax works for `Read`, but how about `Map`? 3. You may be completely right here. But I'm still waiting to see actual concrete problems that would require interface based constraints. I think it's quite possible they don't exist, considering that Go programmers were able to live without generics at all so far and considering that interfaces themselves solve a lot.
yeah, i saw it already but it is not much detailed to be honest
About the first reply, I'm not so sure - but I'm sure I haven't thought about it as much as you have. Take your example: | name := Read() | age := Read() | fmt.Printf("%s is %d years old.", name, age) If it's undesirable to infer the return type based on %s and %d, as you believe, then the compiler could complain that the instantiated type of the generic function cannot be inferred. In my syntax, one could then write: | name := Read() string | age := Read() int | fmt.Printf("%s is %d years old.", name, age) to fix the issue.
&gt; This would mean that for our users already on master, adopting v2.0.0 would require changing every single import statement instead of simply marking on their dependency manager that they were now using v2.0.0. &gt; &gt; This seemed to be a roadblock TBQH (and I know this will cost me goodwill), I don't quite understand why this is a roadblock. Sure, there *is* a difference between just touching one file and touching more. Undeniably. But it just doesn't seem an *insurmountable* effort. It's a change that can be easily automated and it needs to happen very rarely. Yes, it is more effort and I understand why you feel it's *unnecessary* extra work (though IMHO it's totally valid to have a different opinion on that). What I don't really understand is why you think it can't be done. Is it more complicated than I see? There definitely is one problem that isn't easily solvable, which is to maintain cross-compatibility with dep and other third-party tools (the go tool itself can be kept compatible relatively easily, even when not in module mode). And if that's the reason - that's fair, it's an admirable effort to support heterogeneous use cases for your users. But I feel like it should at least be said that the fault isn't squarely on modules here. The problem that it's hard to support different build systems simultaneously has long predated the module-plans. `gb` is a good example, it has always been hard to mix projects using that with projects which don't.
And how would your syntax work if there were multiple types in the result, like in the SyncMap example? I know what you're getting at, but one thing I like about my syntax is that it's never a choice between inferring and manually specializing. It's always either that or that and which one it is is clear from the signature. In your syntax, it becomes a choice that depends on the power of the type checker.
Not sure there will ever be a go 2 in the semver sense (i.e backward incompatibility), the "go 2" name above is a marketing name. Java is still in major version 1, 25 years after its creation.
https://github.com/gothinkster/realworld is pmuch the best demo I can think of
What do you think is missing or that needs to be more detailed? I might be able to help clarify something (but it's been a while and my knowledge might be outdated). I added a link to (what I considered) complete example at the end of the slides that should be enough to get you going. It's a lot of work, it only makes sense (in my opinion) if you are re-using existing go code. In our case, we had the password manager working on desktop and just create the bridge to use the same package in an android app.
I'm not sure I've understood this correctly. The author seems to have spent an awful lot of time to conclude the bloody obvious: breaking changes need a new major version. That's how I've always understood semantic versioning: anything else doesn't make much sense.
That's neat. I wish there was a way to write things to Google docs so you can write only what you learned in readable form and share. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Clear, concise, consistent and compilable. What a lovely proposal. I really hope it gets notice.
[gophast-android](https://git.sr.ht/~tslocum/gophast-android) uses gomobile to [bind](https://git.sr.ht/~tslocum/gophast-android/tree/master/app/bind.sh) the [gophast](https://todo.sr.ht/~tslocum/gophast) library. There are a lot of limitations on what can be passed between Java and Go which I wasn't aware of at first. With careful type choice and function structure it can work well.
Also if things like `try(bar(try(foo(try(baz()))))` are proposed by the Go team member(s), the "[Control flow](https://golang.org/doc/faq#Control_flow)" section of the FAQ should be adjusted or deleted. It says &gt; Why does Go not have the ?: operator? &gt; &gt; There is no ternary testing operation in Go. You may use the following to achieve the same result: &gt; &gt; if expr { &gt; n = trueVal &gt; } else { &gt; n = falseVal &gt; } &gt; &gt; The reason ?: is absent from Go is that the language's designers had seen the operation used too often to create &gt; impenetrably complex expressions. The if-else form, although longer, is unquestionably clearer. *A language needs &gt; only one conditional control flow construct.* (emphasizes mine)
Also if things like `try(bar(try(foo(try(baz()))))` are proposed by the Go team member(s), the "[Control flow](https://golang.org/doc/faq#Control_flow)" section of the FAQ should be adjusted or deleted. It says &gt; Why does Go not have the ?: operator? &gt; &gt; There is no ternary testing operation in Go. You may use the following to achieve the same result: &gt; if expr { n = trueVal } else { n = falseVal } &gt; The reason ?: is absent from Go is that the language's designers had seen the operation used too often to create &gt; impenetrably complex expressions. The if-else form, although longer, is unquestionably clearer. **A language needs &gt; only one conditional control flow construct.** (emphasizes mine)
Complete agree. I think they should just leave it as is. I don't understand the whole problem about repeating error checks. I know for sure that it helps my code to be more readable and reliable. All good IDE's have code templates to do the typing for you.
The whole point of `gofmt` is to avoid different styles and arguing about the same. That works iff everyone uses the same `gofmt` program. Every `gofmt` alternative goes directly against those values. If you prefer something else, please fill a proper proposal, so when it gets eventually adopted, we _all_ can continue to use one only `gofmt`.
I agree. That's why I think we should remove the if statement completely and depend on short circuit evaluation. package main func main() { state := true _ = state &amp;&amp; func() bool { print("true branch") return true }() || func() bool { print("else branch") return true }() }
I could imagine that "expect" proposal making for some really confusing and error prone code...
The if err != nil syntax feels more in the spirit of go. Simple and obvious.
Your code block should be: ``` n = falseVal if expr { n = trueVal } ``` But I absolutely agree on leaving err!=nil alone
The text is quoted verbatim from the FAQ. And actually it's correct. The ternary operator guarantees that only one of the two expression get evaluated. In languages with side effects it's an important difference.
Didn‚Äôt see the quote, but of course you‚Äôre right.
Short circuit on Boolean expressions is not control flow. It's just an performance optimization. Once the Boolean value is established, similarly to `x*0*a`, it's a waste of time to evaluate the rest of the expression. Under the hood it's implemented often, but not always by conditional jumps, but the semantics are not the same as control flow. In the body of an if/else statement there can be any statement, including `goto`, `return`, loops etc. None of that applies to Boolean short circuiting, (Actually, the compiler is allowed to shortcut evaluation of `x*0*a` provided it can prove evaluation of `a` is side effects free.)
I'm inclined to agree with this in the face of current proposals. I *would* like a way to say "if any of these calls returns an error, return it immediately to the caller", but it's important to preserve the "simple and obvious" aspect. You just don't need to add context to *every* error.
Why did I read it, I want my time back.
Agreed. Generics are far, far more important imo.
It's very much control flow. From the spec: &gt; Logical operators apply to boolean values and yield a result of the same type as the operands. The right operand is evaluated conditionally. Go implementations _must_ implement short-circuit and your code can depend on it. That makes it part of the language semantics.
Add Generics and implement Maybe and Either types like grown up languages.
\&gt; v2.0.0 \&gt; which would include all of the API breaking changes. This version would support all of those already using master \&gt; , which includes Dgraph 1.0. \&gt; v2.1.0 \&gt; which would include also the data format changes. This version‚Äôs API would be backward-compatible with v2.0.0 \&gt; but files written with v2.0.0 \&gt; would not be readable from v2.1.0 \&gt; and vice-versa. &amp;#x200B; If I was a user of this BadgerDB, I'd expect them to either release both of these as 2.0.0 or release them as 2.0.0 and 3.0.0. I'd expect 2.1.0 to have additional features or fixes but be completely backward compatible with 2.0.0 both at API and data-format level.
\&gt; The import path would be ‚Äùgithub.com/dgraph-io/badger/v2", note that v2 at the end. This would mean that for our users already on master, adopting v2.0.0 would require changing every single import statement instead of simply marking on their dependency manager that they were now using v2.0.0. This is how Go modules \*is\* supposed to handle backward incompatible changes. It was one of the core design decisions with Go modules and IMO has nothing specific to do with BadgerDB. Every other library is expected to do the same with backward incompatible changes. I don't see why having to change all import references is an issue at all especially if the change is going to break both API and the data format. It doesn't cause existing builds to break or force everyone to move to v2.
Yeah Go is already so utilitarian, why try to make it cute now, it‚Äôs far from matching the expressiveness of other languages but that‚Äôs why most people like it haha.
(author of Badger here) Cloning a code base isn't about the size that it introduces. As an author of 2 DBs, unless you're talking about terabytes of data, I'm not too fussed about the size. &amp;#x200B; But, what I worry about most is to bring in bug fixes. While advancing v2.0 series, we still have to cherry pick and bring in bug fixes to v1.0 series. Cherry picking is designed to work on branches, not different directories. So, copying code into another directory is just nuts. &amp;#x200B; Having said that, with the discussion that brewed, the benefit of having two different versions of Badger being imported into a single repo have been more clear (writing the migration tool would be a lot easier).
(author of Badger here) As maintainer, you'd now need to support 3 different versions of Badger. Any bug fix into one would need to be picked into the other two and so on. Simply putting, we just don't have that kind of bandwidth. &amp;#x200B; Not to mention, any small future API breakage means adding another version which then needs to be maintained. In the past, we have done API breaking change to fix a deadlock issue. Any such changes then cause a spinning wheel of version increases, given the purist definitions of semantic versioning.
I guess theoretically I could count how many checks I make against `err` across all my code, count for how many of those I return `err` undecorated, and post the numbers. But would that actually be helpful to the decision-making process?
Don't use "Get" as a prefix for the methods(GetTokenFromWeb, GetClient). In go it's implied.
See also [goup](https://github.com/lpar/goup)
Taking this by its letter is, TBQH, rules-lawyering. Go already has several conditional control flow constructs - both panic/recover and more immediately relevant to that section, `||` and `&amp;&amp;`. You should read by intent, not verbatim wording.
&gt; Short circuit on Boolean expressions is not control flow. Then neither would `?:` be. But of course, it's also [simply not true](https://play.golang.org/p/Tem5SfbXQtN).
FWIW, that's not what the proposal process is for. The default is always to do nothing, so proposing to do nothing is non-sensical (it's what'll happen if all other proposals get denied).
Not exactly what you were asking, but still a good example of React/Golang usage in the same project: [https://tutorialedge.net/projects/chat-system-in-go-and-react/](https://tutorialedge.net/projects/chat-system-in-go-and-react/)
Yeah I imagine a 100 line function and someone new to the language wasting a long time looking for the error handling clause. Idk.
&gt; Short circuit on Boolean expressions is not control flow. This is not true: func main() { fmt.Println(false &amp;&amp; blowUp()) } func blowUp() bool { panic("!!!") return false } If it were purely an optimization, this code would not be safe.
Golang is used to build Docker, Kubernetes, Prometheus, etc.The list of what is essentially the infrastructure backbone, that you as a developer rely on, which is built in Golang is quite extensive. It is already "grown up", if you give it a chance maybe you will too.
Fair enough, one can't use goto or return with short circuiting. However, we should still remove if/else, because it's just unnecessary syntactic sugar for select/default. package main func main() { state := true switch { case state: print("true branch") default: print("else branch") } }
This is the most logical thing to do. Gophers can hate, but they are just being blind.
&gt; Every `gofmt` alternative goes directly against those values. This isn't a tool to compete against gofmt, though. This is why it's backwards compatible; I can use gofumpt at work, while others use gofmt, and we're not fighting over style. The only difference is that my changes will follow a stricter style, which is something that many developers already do manually. In other words, this is only automating the formatting extras I had had in place for years. I write code pretty much the same way I did before - just with less frustration. &gt; please fill a proper proposal Please read the README. Part of the roadmap is to see what works over time and propose it to upstream.
But the nothing opt needs the supporters to be known. I think that‚Äôs missing here.
That‚Äôs why Haskell is so popular right?
It's so explicit, yet so simple. Please leave it alone.
What happened to this proposal which suggested adding `check` and `handle` keywords? Was this rejected? I felt like it was a better idea. https://github.com/golang/proposal/blob/master/design/go2draft-error-handling.md
It doesn‚Äôt matter what supporters want, it‚Äôs what google wants.
Seems like a nice tutorial! I'll definitely try it. Thanks.
This is quite close to something I'm looking for. I'll definitely try to open a PR soon. :)
This is interesting. Will definitely have a look into it. Thanks.
My view is always going to have type something, may as well be if err != nil as anything else.
This is nice. But seems like a very big project from the point of view of a beginner. Thanks.
I didn‚Äôt like it at first, then I got used to it, now I like it.
Yeah and the Internet still runs on fucking Perl. That doesn't make it a professional or expressive or robust language.
I actually prefer using a switch block, and find myself rarely using if/else.
I fully agree - leave \`if err := nil\` alone. I would also suggest that if the Go team is proposing \` try(bar(try(foo(try(baz()))))\` as a solution to an apparent problem, then we probably need to fork Go and let them head off in their own direction.
It's a solution to a problem that doesn't exist. The issue is people migrating to Go and being critical before they've had a chance to actually become Go developers.
Proposals have no defaults. After they are evaluated they are either accepted or rejected.
Nil channels are a useful pattern though. If you have a select statement in a loop, under some conditions you don't want one of those options to be possible. You do that by setting the variable to nil to disable that case, and set it back when it's valid again. A good example is when you're receiving, processing and sending messages, and you have a maximum buffer size that you can hold onto of unsent messages. Once you reach capacity, you want to stop receiving, so you set that select case to a nil channel.
I'm less worried about typing it, I find it mostly bad for reading: it's harder to find the relevant lines when skimming the code. We have a mixed code base, so not everybody has extensive training to fade out the boilerplate lines (me included). I'm not talking about careful reading, but having 30s to see what a function does
I haven't jumped into every conversation about this, because it just gets repetitive, but I want to take this moment to disagree exceedingly strongly. One of the reasons we are discussing proposals at all is that the whole `if err != nil` thing affords writing if err != nil { return err } dozens of times in a function. Because we it's impossible to return out from the current function in a closure or another function, because it appears so often, it is very difficult to handle the very common case where a function can have a sensible default handler (annotating the error with what this code was trying to do when it occurs, for instance), but it's just _exhausting_ to do it correctly. As far as I'm concerned (YMMV), this is the primary reason we should be talking about this. It isn't _directly_ the boilerplate aspect; I'm not too worried about that. It's the fact that the boilerplatey-ness of `if err != nil { SUPPOSEDLY DO SOME THOUGHTFUL ERROR HANDLING }` having to show up over and over inhibits the error handling ideals that Go is going for. It's the fact that all these people are claiming that they like the current system, but they probably like it precisely because in general, they're actually writing `if err != nil { return err }`. I know this, because I find myself in a constant fight against this. I'm there with you. Let's not pretend we're doing thoughtful error handling when we're not. There are very good reasons why the current approach is quite suboptimal and I want to see those addressed, because they will improve my code. Right now, I can't factor my error handling, despite it supposedly being a core element of Go. This is not a strength, and it does not lead to better code. (I did like having the handler function. I still hope that happens.) Also... hate to try to read minds, so take this with a grain of salt, but I'm deeply unconvinced this isn't just people getting overly used to the current way of doing things and just reacting against change, rather than having solid arguments as to why this is a good idea. I can't help but think that if Go came out of the gate with one of these proposals, _absolutely nobody_ would be begging the team to remove them in favor of going back to bare if statements. Personally I think it would literally never even cross the collective community's mind. Besides, I can't help but observe you won't be forced to use this if you don't want to. You may encounter it in other people's code, but you may encounter `new`, named return arguments, methods that return channels, or methods that take concrete structs instead of sensible interfaces, too. You're going to be, at most, very, very briefly slightly annoyed, and then move on with life if you have to work with some other function that has the new style of error handling. You're not going to throw your laptop through a window in a rage, declare this person clearly has no idea how to code, and swear off Go forever. (I'm all about languages moving more slowly than some language communities tend to. But I think at the ten year mark, we can afford to discuss the first couple of major language changes, based on collecting a decade of user feedback with the language.)
It would have been easier, yes. Unfortunately, it was not possible since some projects depended on the API changes but not the data format ones. It might seem like I'm just messing with Semantic Versioning for the fun of it ... that couldn't be more wrong, though. If I could just release everything in v2 and just go with it, without causing drama in the existing community of users I would have definitely done that. The approach I documented is the best one I could come up with given our situation.
This kind of comments is why I don't post on here anymore.
Rust has Maybe and Either. Most modern statically typed languages have generics. From my experience, C++/Java people can quickly understand and quite enjoy these constructs, it's when you get into Monads, Functors and Lenses that they tune out. Check out Elm, it managed to woo a crowd of JavaScript developers even with its Haskell syntax, algebraic datatypes and immutable semantics, but it smartly dropped Monads and typeclasses in general.
Pretty sure you are memeing but regardless unless the go compiler is able to do some optimizations I‚Äôm unaware of, the conditional blocks are no longer inlined. In addition and probably more importantly you can‚Äôt break out of loops around the if statement, goto tags outside of the block, etc. While we are on the topic of break though that some thing that is actually a bit redundant.
Rust is not a popular language.
What? Rust routinely surpasses Go in popularity rankings, I used it precisely because Rust and Go are of similar age and size.
https://trends.google.com/trends/explore?geo=US&amp;q=%2Fm%2F0dsbpg6,%2Fm%2F09gbxjr
My team only writes unit tests and we have a QA team that writes automation for feature test cases. These tests run after our unit tests, build server, code review, and manual QA. Once the tests are created, they are run regularly but outside the CI build process. They usually use other tools than we do and sometimes languages, with favorites being Selenium and Winium. I'm not actually certain offhand what we use for Mac desktop ui testing, and we don't have any integration tests for command line tools, but I would probably use a scripting language like Python or Node and just execute some commands and examine outputs.
Im curious, why dont you pick a language that fits your desires for language constructs?
What‚Äôs wrong with methods returning channels?
I think the problem is Perl is too expressive.
You could use two channels, C1 and C2. Then G1 writes unprocessed data on C1 and waits for confirmation of processing on C2. Subsequently, G2 waits for data on C1 and confirms processing done on C2. Basically both goroutines subscribe to each other to know if they can continue to do something. Hope it helps.
I guess if by popular you mean "searched for on google". Rust had a higher growth on Github than Go (though I'll admit there's a larger number of repositories in Go than Rust), and a Stackoverflow survey put Rust at the top of most loved languages and 8th on most wanted: https://insights.stackoverflow.com/survey/2018/#most-loved-dreaded-and-wanted
People spend more time jerking off to rust than actually using it.
&gt; This is an interesting idea. I don't think I'm gonna incorporate it into the proposal, but it made me think a lot. Yeah, I don't expect someone to just randomly take my word for it. I just feel it doesn't have enough mindshare in the design proposals. &gt; Now, interfaces as they are solve a lot of constraints problems themselves. Do you have a specific use case where something like what you propose would be useful? There are a lot of cases where they would at the very least be convenient. One example is comparison-based data structures, like priority queues and sorted maps: type Comparer interface { Less(this) bool } type PriorityQueue(T) struct { ... } func NewPriorityQueue(items []T Comparer) PriorityQueue(T) { ... } type SortedMap(K, V) struct { ... } func (m SortedMap(type K Comparer, type V)) Insert(key K, val V) { ... } You can try to get away with passing a `func(T, T) bool` comparer function instead, but this leads to several problems. First, it's mildly inconvenient if you use the same ordering in many places (because you need to keep passing a function which almost always could be attached to the key type instead). Second, it leads to problems when you want to *combine* data structures using constrainted types. For example, it's possible to implement *mergable* (persistent) priority queues, i.e. ones that support the operation: // MergablePriorityQueue is an (e.g.) struct type, not an interface; it's a specific implementation func (pq MergablePriorityQueue(type T)) Merge(other MergablePriorityQueue(T)) { ... } The main problem is that it requires that both priority queues are ordered in the same way (otherwise you can't do better than naively looping over all the elements of the latter and inserting into the former, which is much much slower). There's no way to compare functions for equality in Go (for good reason) so there's no way you can do a runtime check. You either have to hope that they're the same (and accept bad bugs when they're not), or insert lots of defensive dynamic checks throughout all of your data structure implementations (which pollute them and don't add much value over plain tests), or just hope that things never go wrong and point to the documentation when a user (inevitably) accidentally misuses it. On the other hand, if the comparison function is *defined according to the type*, then it's impossible for them to mismatch: all priority queues with `T`s in them compare their elements the same way, so they all have to agree. It makes the interface for the `MergablePriorityQueue` simpler and clearer (keys must be comparable, and that's it). The next example worth considering are "operations" on types that produce more-of-the-same. For example, type Adder interface { Zero() this Add(this) this } You can now write functions like `func Sum(items []type T Adder) T` that return the "real" `Zero()` when `items` is empty instead of the "zero value" of `T` (which might not quite work e.g. if your type contains `func` or `map` or pointer fields that are expected not to be left `nil`). Even forgetting `Zero`, basic examples like adding vectors of numbers can't be done without some support for interface constraints: type Vector2 struct { X float64 Y float64 } func (u Vector2) Add(v Vector2) Vector2 { return Vector{X: u.x + v.x, Y: y.y + v.y} } How to (generically) write `Sum([]type V) V`, so that it works on `Vector2` and `Vector3` (and more, e.g. matrices?) They don't support `+` so you can't use `num`, so you have to use some kind of user-defined constraint to be able to use them. You can either use contracts and check that `.Add` exists, or you can use one of two interface types: type Adder(T) interface { Add(T) T } type AdderThis interface { Add(this) this } the former means that your `Sum` function needs to be `func Sum(items []type T Adder(T)) T` while the latter allows simply `func(items []type T Adder) T`.
&gt; Unfortunately, it was not possible since some projects depended on the API changes but not the data format ones. How were they working before v2, then? I mean, why couldn't they continue doing whatever it was they were already doing until they were ready to handle the data format change?
As a *rule of thumb* (emphasis deliberate), libraries should not expose concurrency details. In general, they should just be single-threaded (albeit threadsafe) and allow users to do whatever concurrency they may want. e.g., a simple library for parsing an image; do not provide a method that tries to parse 1000 images at a time in some custom pool thing, just provide a method that parses the image and returns the relevant struct and let users do whatever concurrency they need to do with that themselves. If they do need to be concurrent, they should generally hide the concurrency behind their API. e.g. database connection pools. Intrinsically concurrent, but the API is just "make query, get result"; the library eats the concurrency requirements. However, if you *know* that your library is going to do something that the users are going to want to use in the `select` statement, then you can return a channel. e.g., time.After, whose whole purpose is to provide a channel to use in `select` statements. In the 5+ years I've been using Go now, I've written maybe two or three other functions that actually return channels, all explicitly related to routing messages in select statements. So if you go to J Random Github's shiny new repo and look at the godoc, and you see channels somewhere in the return values, and there's no clear reason, it's often a big code smell.
Which Rust programmer hurt you, Ilya?
lol don't get me wrong, I like Rust. But if you leave the proggit/hackernews bubble most people haven't even heard about it.
&gt; Also... hate to try to read minds, so take this with a grain of salt, but I'm deeply unconvinced this isn't just people getting overly used to the current way of doing things and just reacting against change, rather than having solid arguments as to why this is a good idea. There are probably a lot of people in both the "has solid arguments against error-handling simplification" and the "people who reflexively distrust changes" camps. There are a lot of Go programmers out there, so one can have large subcamps even when the larger camp is generally anti-change when it comes to error handling. Additionally, one can move from one camp to the other. Oftentimes a new thing will bother you for reasons you can't articulate at the time. Only after some times passes will you be able to explain why the new thing is a bad idea. The try proposal seemed neat, but only after chewing on it for a few weeks did I figure out that I kind of don't like it\*, even though it may be a good idea on net. \* It disincentivizes the right thing (wrapping errors and doing other thoughtful error handling) by making the expeditious thing (just returning the error) ultra-terse and annoying to change back to the more-general `if err != nil { ‚Ä¶ }` form.
Yeah, breaking changes are breaking changes, but some of them are easier to fix than others. That's why I'm putting the emphasis on data formats as our major versions, since changing an API call is much easier than migrating your dataset to a new format. We could have also released a v2 and v3 with the changes, but the problem is that this doesn't really says that migrating from v1 to v2 or to v3 is actually a \*very\* different effort.
I thought of this. But every time, I ended up getting ```deadlock all goroutines are asleep``` error. Can you provide me with an example?
&gt; It disincentivizes the right thing (wrapping errors and doing other thoughtful error handling) by making the expeditious thing (just returning the error) I'll echo /u/ficiek and ask what happened to `handle`? Part of the reason I'm so against just letting the status quo continue is that I think the objection being raised here applies 100% to the current situation; if you're against `try` because it makes it too easy to handle errors by not handling errors, then you ought to be equally against the status quo. I'll grant you they may screw that up in slightly different ways but they both screw it up. Personally, not being against named return values (I really don't understand where the idea that name returns are just like super, super bad came from, it just seemed to emerge fully formed from the head of Zeus from my point of view), I can live with try and a high-level defer that overrides the `err` on the way out. I still have a _lot_ of code that would clean up nicely. I also think that if `try` changes the cost/benefit of named return values, then the community should correspondingly update the utility of named return values in its general practices. (I understand the reasons for the human tendency to use logic to come to conclusion B at some point in time because of information A, thus A-&gt;B, and then mentally shortcutting that to B because we can't mentally afford to run the logic every time, but it is frustrating when A is no longer true, but people insist on sticking to B even so.) So my preference is `handle`, `try` is still a big improvement, and the worst case outcome for me is nothing happens. I'm really hoping to avoid the latter, because I'll try expressing it in another way, my feeling is that a lot of the objections being raised against these proposals tend to apply _even more so_ to the current state of Go; if you consider the various options as if we didn't already have `if err != nil { return err }` in our code and put them all on a level playing field, I just can't see it winning. It's got a huge list of disadvantages. _Huge_. Like, the majority of all complaints being leveled against the various proposals, it's actually _worse_ at. I do hope we're far enough along in this process that the Go team just ships something so we can actually try it out, instead of hypothesizing at each other what may or may no happen in the future. I'd _definitely_ rather make this decision collectively with real data, not based on who argues loudest.
My concern with semantic versioning is that it fails to express that API breaking changes are \*much\* easier to fix than changes done to data formatting. &amp;#x200B; Following semantic versioning, I would have release v2.0 and v3.0 instead of v1.6 and v2.0. This makes it look like migrating from v1.5 to v2.0 or to v3.0 might take the same effort, while it's not the case. &amp;#x200B; PS: What might be "bloody obvious" to you might not be so for others and it makes your comment sound more aggressive than necessary.
I wonder what issue the GO team is trying to solve. Is it really just reactive to a couple of polls and off-hand comments from people who use other languages that wouldn't try GO anyway? If it's to try and foster wider adoption of GO in businesses to compete with Java, then the issue isn't how errors are handled, it's that GO lacks a lot of robust plugins that makes a Java engineers job plug-n-play. Alongwith a few other issues I'm sure. Sure, the first time I did a program that did a decent amount of file handling I cringed at all of the "if err != nil" checks. I even tried to rewrite the code in various ways to make it look nicer. But eventually I realized that every time I did an "if err != nil" I was being ***explicit*** on how I wanted to handle that err. Usually pass it up the return stack. Sometimes I want I want to add a composite to the error to give more detail. In some code I want to hard exit with a certain error code (for CLI programming). I really don't want error handling to change. The thing I like most about GO is that anyone with basic understanding of the language can read someone elses code and get an idea of what is going on. More interpretive languages, which I think this "try" proposal will be in essence, make it so you need a PHD in ***how that author writes code***. I really don't want GO to start down that path.
`handle` and `defer` overlap in a big way
&gt;if err != nil { return err } &amp;#x200B; The other group doesn't do this, but they do this instead &amp;#x200B; if err != nil { return xerrors.Errorf("unique, human understable message for the failure: %w", err) }
I'm a Python developer, professionally, that has wanted to pick up Golang. The error handling is the biggest turn off. (now that dependencies are sane) I was watching a Twitch streamer program and every 5th statement was `if err == nil` ... -__-
Hi /u/thepragmaticpi &amp;#x200B; I tried to illustrate and answer your situation as best I could. Without more information, it's difficult to be helpful. [https://play.golang.org/p/8vJrW\_UmMuS](https://play.golang.org/p/8vJrW_UmMuS)
The error handling was one of the major draws to Go from Python for me. To me, having something return an error means that the error is important -- the caller should handle it. I write a lot of Go code that starts off with: if err := something(blah); err != nil { return err } Then, later on, I'll be re-reading the code and handle all the errors I haven't handled already. It's precisely ugly enough for me to *want* to go back and fix them. Whereas in Python, I've read through far too much of other people's code where everything is just in some big ugly try/except block and completely ignoring any error cases. Go pretty much forces you to "do the right thing" in this case.
&gt; I'm still confused about why everyone wants Generics? You usually want to use generics for one of two things: Generic data structures, or generic implementations for algorithms (or, sometimes, even a combination: Where the generic-ness is used to statically allow for different behaviour for how the type works). ### Why would you want generic data types? Well, for one, just ask Go itself: Arrays *are* already generic. If you truly wanted to stay away from generics everywhere, you'd only have *one* array type where each element is `interface{}`. And that is, obviously, a bad idea. Of course, it's especially bad for arrays, but it's bad for a bunch of other data structures too: If you don't want to copy code over for multiple contained data types, you'd just go for an implementation that does all that work not at compile but run time. And while yes, that doesn't often occur in an actual application, generics are a feature that often makes sense in libraries. ### Why would you want generic functions? Just see the example provided in the [README](https://github.com/faiface/generics/blob/master/README.md), if you build functions that are inherently generic over a data type (inherently generic over a type in an array (or other data structure) is the usual candidate, but especially if you go all-out with generics, it makes sense in a lot of places), you probably don't want to copy them for every type you need the function for. Especially if it's a library. To use an example from functional programming: If you want a `fold` function, that is inherently generic. Especially if you are in a programming language where you can't cast a specialized array to a more generic one (which is the case in Go, iirc), you actually *couldn't* provide a one-size-fits-all implementation, not even at a run time expense. &gt; Too many snowflakes want to just stuff things into places and not think about it Too many snowflakes just copy code over (violating the DRY principle) and think there couldn't be a better option, since they are doing it this way. See, insulting doesn't really change the mind of others. For the record, the above, while meant to be insulting, isn't genuine. Since, if possible, I'd like to actually show my viewpoint (and for the record, I'm not the only one holding that viewpoint here) and explain it instead of blindly looking down on others. Which is why I invite you to point things out I got wrong - we can all learn from each other if we don't run head-first into the debate screaming "I can't be wrong". &gt; then we will turn in PHP or Python where objects that should be 500 bytes are 5 megabytes. Well, you wouldn't run either on a really low-power microcontroller. You wouldn't run Go on those either, actually. And the thing is: Outside of that world, memory consumption is, while still important, actually not that much of a deal (especially since it isn't a factor of 10^4). *Performance*, however, is. And if you use run time distinction between types, which you have to do in current Go in inherently generic situations, as described above, you end up paying a performance penalty. And also, while PHP is a mess I don't want to get into, Python has things to show *precisely because* it does *everything* in run time: It gives you very powerful means of metaprogramming, which you just don't have to that degree in Go. And can't have, even. Sure, you usually don't benefit too much from that, but the option is there. &gt; I feel generics are going to negatively impact the language and runtime. Nope. Just, nope. If done correctly, generics do the exact opposite: The compiler has information about those types without you violating the DRY principle. Which yes, may end up in making the compiled thing larger, but it's usually worth it. While currently, you can get the same binary bloat by copying your functions *and whole data types*, or you just give up and pay a performance penalty at run time. So, in fact, regarding mostly library code, it would *really positively* impact both the language regarding ease of use (you don't have to cast outputs of inherently generic functions back to the type you know they are) *and* performance. Of course, doing the work at run time has very real advantages: Faster compile times, (in general) smaller binaries, and sometimes it runs better because of how the binary will be laid out. The problem is that Go doesn't give you a choice to opt into the binary-bloat-but-generally-faster option. And, I have to be honest here: I'm not using Go anymore. And this is one of the reasons why: Go actively takes choice away from you in its quest to be simple. Which isn't a bad goal, but you have to be able to not be a complete purist when it comes to those goals, because it hurts the usability in the end. Albeit not really meant for the same use cases, I went on to learn Rust next, which has a really good generics system, and I love that the philosophy of Rust is primarily giving the programmer choice - sure, it's a way harder to pick up because of that. But what it gives you for the effort is, imho, worth it.
[removed]
Is the issue with the first one maybe a scoping problem? Try removing the colon from the second assignment statement.
`if err != nil ` Is SO simple and easy to follow for maintainers. I don't mind it at all
You're correct, you just beat my go playground link with a working example sans colon https://play.golang.org/p/j0a7ttRsTaV
Here's a basic example where one provider goroutine signals the worker goroutine through a channel and then waits for its response on another channel. When the provider goroutine has finished, it signals the main goroutine that everything's done: [https://play.golang.org/p/hEGEyEw35vo](https://play.golang.org/p/hEGEyEw35vo)
To elaborate what's going on here, the := in your example is defining a new variable named aorb, within the if block. Without the colon, you're reusing the existing variable
Who mentioned libraries? The question is about functions...
Indeed, but the problem here is that your python code doesn't handle errors properly üòâ
Ideally it would be behind the scenes, without needing to use the generated stuff directly.
One of my first app in Go had a stupid error handler that would validate if an error was thrown. The function was basically this boilerplate. That was stupid.
Switch on a Boolean? Lol
"rarely"
[removed]
The general idea is still to not put threading into your interface. This leave callers to pick if they way serial or async.
You see, this aren't really compelling examples. What you described is basically `eq`, `ord`, and `num` extended to other types. But, both `eq` and `num` can be solved by passing a function, a comparator. I believe it's an even better solution that implementing some `Less` method. With a `Less` method, you're limiting yourself to a single way of sorting per type. That's pretty limiting. When you can pass a comparator function, you can sort any type, any way, any time. I think that's much more convenient. Custom `==` operator can also be solved the same way and has similar benefits. Regarding extending `num` operations (or equivalents) to custom types, the use cases are few. Vectors and matrices come to mind, however, since there isn't much more use cases, it's not a big deal to just implement various operations for both of them separately. So yeah, not convinced by these examples.
i.e. shadowing https://en.wikipedia.org/wiki/Variable_shadowing Linter would consider this an error.
I work with a lot of push messaging (AMQP, websockets, etc), so having exposed channels for me to `select` makes a lot of sense. I do understand your point about libraries pretending to be single-threaded though.
I was thinking something similar, even just a bash script which executes all of the available cli commands. I guess any language will work (even go?) as long as I can execute cli commands and compare the output?
[removed]
That's the case i have exposed channels for too.
Well, I dabble in Rust but honestly Go is really awesome as is. Go has become my swiss army knife, formerly Ruby. As much as Rust offers more comprehensive error handling and better performance, Go's builtin cross-compiler is peerless. On the side, I work on some cross-compiling toolchains, specifically premade Virtual Machines, in an attempt to offer a setup approaching Go's cross-compilation abilities, for other languages like Rust, C, C++, D, and so on. I wouldn't have to do any of that work if these languages had half of Go's platform support.
You can do this with one shared channel and a request type with a response channel: https://play.golang.org/p/vP1DX9qSZkB Otherwise you can just create a main response channel, pass both to the goroutines and just put raw values in the channels as opposed to a request wrapper.
We've unlocked 4 out of the 5 revealed gopher pins in our Kickstarter! Functor, Vim-Gopher, and Luke Skygopher are all unlocked. Gandalf the Gopher is next! You can back at [https://www.kickstarter.com/projects/thegrumpyunicornco/greg-the-go-gopher?ref=6oe485](https://www.kickstarter.com/projects/thegrumpyunicornco/greg-the-go-gopher?ref=6oe485). \- On a side note, Functor the Supervillain is inspired by [episode 87](https://changelog.com/gotime/87) of the podcast [GoTime](https://changelog.com/gotime/). In fact, my father was listening to that episode and suggested to us that we make a series of gopher pins, so this whole project kind of came from that podcast! :)
I also don't understand how this preserves backwards compatibility? If anything it breaks anyone who used \`try\` as a function name. It isn't syntactically valid right now to put \`try\` before a function call now anyway, so who would this break?
Exception handling doesn't solve this problem, either. You have to be careful either way. In a Java sense, you can't just look at code and k ow what it does, you have to look at the code that code uses and ubderstand what it does, and you have to look at the parent code and understand what it does.
[removed]
Backed! Thanks for doing this :-D.
&gt; then we will turn in PHP or Python where objects that should be 500 bytes are 5 megabytes. I feel generics are going to negatively impact the language and runtime. ... generics are a great way to *remove* things from the runtime, including things that take up space in objects. `interface{}` costs some extra space, and much more importantly than that: it costs in performance to hide everything behind pointers and then, more than that, have to do type assertions before using those pointers. Compare and contrast a language that can use generics to reduce a the runtime code to using a value of a known type on the stack or at least not having to use type assertions at runtime.
I'll believe you, personally, do it. I do not believe it happens in general.
&gt; reacting against change What's so wrong with that? It saved the C people from the horror that C++ became and would have saved Russia from communism (had the traditionalists been listened too). &gt; Everybody does `if err != nil { return err}` &gt; I know this because *I* find myself in a constant fight against this. Projection much?
We could do return x if y // return err if err != nil as a compromise solution, if reducing line length is the concern. I don't like it but has the following advantages over try: * Easy to understand * Easy to read (including for beginners or people that don't use Go) * Can be expanded: return fmt.Errorf("context: %v", err) if err != nil * Would "clean up" more code (go fmt could change any `if y { x }` to the new syntax) As for disadvantages: * increases code density * do x if y is less readable than if y do x
&gt;Pretty sure you are memeing but regardless unless the go compiler is able to do some optimizations I‚Äôm unaware of, the conditional blocks are no longer inlined. The Go compiler is usually successful at inlining leaf functions. For non-leaf functions, it depends on whether complex control flow mechanisms are present. (e.g. panic, defer, recover)
Rust is well loved but very little used, at least according to stackoverflow dev survey respondents [https://insights.stackoverflow.com/survey/2019#most-popular-technologies](https://insights.stackoverflow.com/survey/2019#most-popular-technologies)
Not sure if this tool should integrate with Google docs because as author I want to put more emphasis on e2e encryption/privacy aspect. But your link is pretty cool. It's like a syllabus for your personal learning. Dnote used to have a public note so that users could share their knowledge but I took it out when I built encryption. What is your experience with having a personal learning roadmap like that one? I've never thought of that and might wanna try.
Have the videos been posted by CERN?
[removed]
[removed]
Hey, I actually watched your talk on YouTube while I was researching this topic and it was a tremendous help. Thanks.
Not strictly unit testing, but my solution is to build the CLI and actually execute the command. You can build the binary using TestMain [0] and do whatever you need to do with it in actually tests. Here is a real life exapmd from a production software [1]. Does it help? [0] https://github.com/dnote/dnote/blob/35dc7abfae2a046d59abb9a3b90d82d6e86b30f4/pkg/cli/main_test.go#L43 [1] https://github.com/dnote/dnote/blob/35dc7abfae2a046d59abb9a3b90d82d6e86b30f4/pkg/cli/main_test.go#L43
To be clear: I dislike exceptions and I'm really glad go doesn't have them. It would be nice if there was a way to execute a function and if there is an error, annotate it and return the annotated error. Though I don't know what it would look like unfortunately :-/
\`\`\` aorb, ok := keys\["a"\] if !ok { aorb, ok = keys\["b"\] // := would shadow the previous aorb } if ok { ...do some stuff with aorb... } \`\`\`
&gt; it fails to express that API breaking changes are *much* easier to fix than changes done to data formatting. Why does the version number need to express that? Is it not enough to say ‚Äúbreaking change‚Äù? When a new major version comes out, you always have to check what it means for your application, anyway. It seems excessive to redefine semantic versioning to express something people always need to check anyway.
Thanks for the explanation.
Backed! I'd really like to see one of these as a pin, but I don't know how you'd go about getting permission from the artists: https://secure.meetupstatic.com/photos/member/5/e/e/0/highres_272004288.jpeg http://www.gophergala.com/assets/img/fancy_gopher_renee.jpg https://cdn-images-1.medium.com/max/1600/1*zzIg5pT-tefugCA2N6i3Lw.png [Tired Gopher](https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/c7d894cb-8d37-4495-a454-89c868b12375/dcycwca-813a3b2d-1eae-4f6a-beab-27f1264b364b.png/v1/crop/w_214,h_250,x_0,y_0,scl_0.46827133479212,strp/tired_gopher_by_quasilyte_dcycwca-250t.png?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NTM1IiwicGF0aCI6IlwvZlwvYzdkODk0Y2ItOGQzNy00NDk1LWE0NTQtODljODY4YjEyMzc1XC9kY3ljd2NhLTgxM2EzYjJkLTFlYWUtNGY2YS1iZWFiLTI3ZjEyNjRiMzY0Yi5wbmciLCJ3aWR0aCI6Ijw9NDU3In1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmltYWdlLm9wZXJhdGlvbnMiXX0.ROUaELP5sPnity8UkcCRwCU9ZYc800x4e7jBbgZncH0)
I don't understand why you say "Go Modules were simply not good enough for us". It's quite the opposite. Go Modules make you remember that a breaking change will have an impact that should no be hidden with one line in `gopkg.toml`. I understand that it's a pain and difficult to maintain, to release v2 for the api and just after v3 for the format, but then maybe it's better to wait and release only one v2 with both api and format change. Anyway, it's sure it's not easy but it's not a fault of Go Modules, it's a feature !
When will you propose this on the Golang GitHub? I can't find your proposal there?
Good parts: 1. Easy references 2. Easy links 3. Quick and visible and not dynamic 4. Easy to update 5. Easy to read and no remembering Bad parts: 1. Too big 2. Starts to get hard to find things 3. Can't check all links all the time 4. Gives not much context or roadmap 5. Starts to get old Yeah I've tried to put it into a site but then you have to click a lot and people don't remember what page what link is on and it gets hard to put together correctly. I think I gotta just stick to this format because it's easy to read, people can share it or copy it and if I don't clutter it, then it stays useful. But there's no context or roadmap for beginners, so it prolly looks crazy to them. Idk how to improve it because of the referencing it allows.
&gt;Go pretty much forces you to "do the right thing" in this case. No, it absolutely does not. For one thing, nothing in Go prevents you from ignoring the error with _. Secondly, in the vast majority of cases, the right thing is just to return from the function with the error, perhaps wrapping the error first to give context. You know what that is? That's a manual stack trace. Yes, in the vast majority of cases, throwing an exception and allowing it to bubble up is the appropriate behavior. And funny thing, in many other languages, including python, that is the default behavior for an error. Somehow, many Go developers have acquired Stockholm Syndrome and actually laud the worst "feature" of the language. I do agree with the complaint about try that it does make it harder than it should be to add further error handling to try, and so I actually prefer the proposal where try can take an optional else, but even without that, try is better than the current state of affairs.
This might be better as a function -- it also brings up the question of what happens when a or b are not in the map. func has(m map[string]int, a string, b string) int { if aa, ok := m[a]; ok { return aa } if bb, ok := m[b]; ok { return bb } return -1 }
Ok, maybe it would be better phrased as "forces you to think about things that can go unexpectedly wrong". My issue with the "try" proposal is that it is syntactic shorthand for just passing the error upstream. If you don't care about the error, you would use the underscore as you state. Go's "defer" is the one "shorthand" that I absolutely agree with entirely -- it removes a huge amount of boilerplate, and reduces implementations to the point that it can be iteratively improved on, such as the recent 1.13 defer improvements. I think far more about "what could go wrong" since moving to Go than in any other language I've used. It took a long time for me to like interfaces, but I've grown to love them. It took me some time to get used to the size of Go binaries, but I've come to accept them. I practically embraced the strong emphasis of error types and error handling after the first or second time I used them.
&gt; One of the reasons we are discussing proposals at all is that the whole if err != nil thing affords writing if err != nil { dozens of times in a function. Why not rely on cold hard facts? Are you aware that people have actually made tools to measure in Go codebases where the `try` pattern could be use? https://github.com/griesemer/tryhard It's far less common than you might think. &gt; There are very good reasons why the current approach is quite suboptimal and I want to see those addressed, because they will improve my code. Right now, I can't factor my error handling, despite it supposedly being a core element of Go. This is not a strength, and it does not lead to better code. Could you provide actual examples. How is it suboptimal? Why is it *actually* an issue? Show us concrete examples. Just because you *feel* like you might save few LOC here and there, you want to force new keywords in the language? That's quite presumptuous of you. &gt; It's the fact that the boilerplatey-ness of if err != nil { SUPPOSEDLY DO SOME THOUGHTFUL ERROR HANDLING BUT ACTUALLY JUST RETURN err } having to show up over and over inhibits the error handling ideals that Go is going for. What ideals are you talking about? &gt; Also... hate to try to read minds, so take this with a grain of salt, but I'm deeply unconvinced this isn't just people getting overly used to the current way of doing things and just reacting against change, rather than having solid arguments as to why this is a good idea. They are simply pointing out that there is actually a lack of evidences that shows the `if err != nil` pattern is taking way too many LOC in Go codebases. &gt; Besides, I can't help but observe you won't be forced to use this if you don't want to. That's a point you really don't want to make :)
Seems expensive. $34 for 2 pins?
Is functor the super average looking gopher that secretly kicks babies when no one is looking?
Do you actually want the other goroutines to stop once one returned true? If so you can you the context package ( [https://golang.org/pkg/context/#WithCancel](https://golang.org/pkg/context/#WithCancel) ) to signal cancellation so all the \`doIt\` running returns. [https://play.golang.org/p/zH7XxT1zFtO](https://play.golang.org/p/zH7XxT1zFtO) &amp;#x200B; Do you just want your main goroutine to proceed without blocking on \`wg.Wait()\` without caring if the other goroutines live on? Then you could just use a channel to signal one returned true. [https://play.golang.org/p/K4Tu4y0TXHQ](https://play.golang.org/p/K4Tu4y0TXHQ) &amp;#x200B; It would be easier if we knew the actual thing you are trying to "compute" is. io stuff?
I'm not sure what you meant by serialization protocol but if it's exposed in any way how about using a separate version number from the server version number? For example PostgreSQL server &gt;= v7.4 uses wire protocol &gt;= v3.0. Personally if anything isn't backwards compatible just bump the major version. Semantic versioning shouldn't be 20 years and still no 2.0 but it's hard to let go if you grew up on Linux. I think semver doesn't work well if you aren't willing to bump major version numbers religiously for any breaking change. We just need to let our editors take care of the work of updating Go paths or take advantage of other language features like hiding DB choices behind interfaces so a major version bump is even more trivial.
I'm guessing most people arguing against try are people that don't think anyone should be doing if err != nil { return err } At least not frequently.
I'd look at how [`golang.org/x/sync/errgroup`](https://godoc.org/golang.org/x/sync/errgroup) functions and adapt its approach to what you need. (errgroup runs multiple functions providing a `Wait` method that returns the first non-nil error return or nil if all succeed). Also, side note, do not re-seed `rand` inside of `doIt`. Either seed it once in main or if the go-routines make heavy use of `rand` give each their own `rand.Rand` with unique `rand.Source`s (since the package level rand functions use a shared source via locking using unique per-goroutine sources can avoid contention).
You‚Äôre not shopping at Wal-Mart, unfortunately.
Yeah, it's not there yet. I'm thinking of posting it there, but first I need to solve the importing issue that some people are having with my implementation.
Well, there are people who do not find it to be more readable. And I would argue that that's actually more common. Patterns which take a lot of volume, yet convey little to no relevant information (due to marely being language semantics thing) eventually end up being skipped by the brain when you're looking for domain logic. Skipping part increased cognitive load. Secondly, sometimes you might skip something which is relevant on that 1 in 500 or so cases. Which may lead to even more confusion. I generally find people arguing that imperative style is more readable than declarative a bit weird. It's obviously easy to understand it if you're new to the language. But once that's out of the picture, it becomes a blunder to chew on.
First off you don't want to fire of multiple goroutines and have them end until they are all done or one is. That's a sure fired way of causing a data race. Why? 1. One might get stuck 2. How are you gonna have channels between them if you don't know when they will end? 3. Simplicity and control. 4. Just sounds not like a specific problem so handling it will be harder with less purpose. 5. The point of goroutines is to make sure the gophers have specific tasks .....to optimize! Secondly, you said it should take 1-5 seconds... So please make sure of this with context package. This way, way less chance of data races. Most of all please understand that if you have anything rely on this data to please make sure the goroutines job is precise and short. This has way less chance of data races and well just getting the "actual" benefit of using them. If one of them takes too long, it won't actually help using goroutines. The whole point of them is to get a faster reaction time then a function, but if the function takes too long or what it locks does, then you won't actually see the benefit. Think of channels as a free variable or let's see the calls as a beehive. A goroutine is a bee "running" to get pollen. A channel is magically a bee ready to take the pollen from the bee already at the flower and can transport it to the hive. But if you have goroutines using channels or other functions with channels communicating, things get super complicated. https://link.medium.com/WpfOPDPb4V http://guzalexander.com/2013/12/06/golang-channels-tutorial.html https://imil.net/blog/2018/12/31/Understanding-golang-channel-range/ https://medium.com/@trevor4e/learning-gos-concurrency-through-illustrations-8c4aff603b3 https://medium.com/@matryer/very-basic-concurrency-for-beginners-in-go-663e63c6ba07 https://www.jtolio.com/2017/01/writing-advanced-web-applications-with-go/
OK, another DI and IoC. u/Barmatat, next time please put those two keywords right in the title so folks won't bother clicking the link, thanks.
Hi, u/Nicklous95, can we please not get notified about blog posts in the style "I have read another couple of paragraphs from a book on Go, and here's the summary"? I'm inclined to mark another post like this one as spam the next time I encounter it.
For cancellation of goroutines see the context package. Here is an example: https://play.golang.org/p/BorBHssd6oI This pattern you are attempting to implement is just very uncommon. If you have a single task to do and it fails you usually just retry it n times until you fail completely. When you start multiple goroutines at once it is likely that either all succeed or all fail.
Thanks. Not a single task, per se. I've got a large data set that I'm processing. "Large", being relevant, but let's go with it. I need to massage the data a bit and then look for certain "patterns". If I see a pattern, then I've found a winner. If the pattern doesn't exist, I bomb out. I can run this code in a single process and it works just fine, other than it's not performant. So my thought is to slice the data up into smaller chunks and scan for the pattern. If one of the chunks is a winner, there's no need to continue scanning the other chunks, so I want to kill them all at that point.
Backed, KUTGW!
Thanks for the context tip. And to /u/DoomFrog/666 as well. See my answer to her/him/it. No IO to speak of. The example code is dumbed down quite a bit. Basically, I have a dataset of some reasonable size that I need to work through and identify certain "patterns". If A is at location B, then C must be at location D and E must be in the range of F-G unless H is equal to location I yadda yadda. That's drastically oversimplifying it, but there are loooong sequences of patterns that I'm trying to identify. There's also some backtracking and looping in the pattern matching. In no way is this a regex use case or anything similar that I'm aware of. The pattern is written in a bespoke DSL. That DSL and the logic to process it is actually quite efficient. It's been around for some time. A typical single-threaded scan through a dataset might take ~15-20 seconds. That's a problem when I've got dozens of datasets to scan. There's some room to optimize that, but not much. My thought is to slice up each larger dataset into chunks and scan each chunk in parallel. If I run 4 (for example) go routines, that 15-20 seconds, maybe gets down to 4-5. If I run 8, maybe it's somewhere around 2-3. Don't know. I'm experimenting. Now, I can easily just let each of those goroutines run to completion and then figure out if any of them were a winner. I'd still be getting plenty of benefit from that. But, many times a pattern will be identified almost immediately and it seems a waste to let a bunch of other routines spin along for a few more seconds for no good reason.
From what I understand, the context package cancellation mechanism is probably what you are looking for. Check at the appropriate place inside your processing function if the context has been canceled. In your case it might be inside some kind of loop that goes through the dataset chunk. Return immediately if the context has been cancelled, otherwise proceed on to the next iteration.
I feel like you're projecting on to me the claim that the problem is the boilerplate, despite the fact I tried to make it clear that's not actually my objection. I told you my objection: It's not particularly possible to factor out my error handling, because there's no way to do it. I don't think I need to show why that's a problem. I don't even really know *how* to show that it can't be done, because, well, it can't be done. That's the problem in the first place!
&gt; That's drastically oversimplifying it, but there are loooong sequences of patterns that I'm trying to identify. &gt; My thought is to slice up each larger dataset into chunks and scan each chunk in parallel. The combination of those two things is concerning; how are you planning on addressing the possibility of a match across slices? Depending on the nature of the matching, there may be no simple way to parallelize this correctly. (Sometimes there may be more complicated ways to do it but it deeply depends on every detail of your pattern matching algorithm. There's no generic guidance I can give.)
You may want to try a pipeline architecture with chan cancellations. Check out the "Concurrency in Go" book.
&gt;... there is actually a lack of evidences that shows the if err != nil pattern is taking way too many LOC in Go codebases. I've not see this evidence but will believe you overall. My particular experience has been that where the if err != nil pattern **is** used in a set of .go files (database related for example) the error handling code tends to take up way more lines of code and added noise than I prefer. &gt; I'm glad this issue was opened on github. The overwhelming reaction shows how a huge chunk of people *actually* coding in Go love the explicit if err != nil pattern. This made me laugh because if you look at Reddit you'll see the exact opposite sentiment. I'm not sure if I can infer anything from this but I'm going to posit that pragmatists tend to voice their views more loudly on github and progressivists (in a non political sense) on Reddit.
&gt;I like having the option to have single-declaration specs grouped with parentheses. It clearly communicates "more are coming", and I won't have to reformat the thing if I go from one thing to two things to one thing to two things (as happens with import-statement blocks sometimes). That deserves _stressing again_. I've configured my edit to run `goimport` _every time_ I do a save, to tidy up the code, and fix the imports. I feel very comfortable doing that (because I choose when to save). However, a tool telling me not to keep such good habit/practice is not very friendly.
Yes, I think more modest title would be better. Leave the provocative stuff to Rob Pike and Russ Cox - they are more than enough :)
Errors.Wrap?
Quoting you: &gt;&gt; You make tons of mistakes Please share what you found erroneous
Thank you for reply Although I still think it would be better if code is readable without support of tools (and this opinion could be invalidated only with emergence of neuroimplants that will make possible programming direct from human brain) As for options structs: I'm still more comfortable with, say function taking 3 struct params each is combining 5-10 fields than with function having 10-15 params.
&gt; This made me laugh because if you look at Reddit you'll see the exact opposite sentiment. I'm not sure if I can infer anything from this but I'm going to posit that pragmatists tend to voice their views more loudly on github and progressivists (in a non political sense) on Reddit. Ha! Different crowds I guess :) If I wanted to tease, I'd say your typical everyday Go users is actually more present on github. This issue is currently the second most "thumbed up" issue out of all (30K+) issues of the official Go github repository. That must mean someting. Silent majority yada yada.
Well, I don't really have anything else to say if you aren't even able to produce a single real life repository hosted on github to back your claims.
I will be using this soon
Go ahead and feedback is appreciated!
I actually love this feature about most editors. I'm typing away and every save the tests are re-running pointing out any breaking changes I'm introducing. I mostly write libraries which is where this feature shines the best. I turn it off for integration tests or more demanding testing situations.
&gt; The combination of those two things is concerning; how are you planning on addressing the possibility of a match across slices? By slicing on well-defined boundaries where I know patterns can't and won't cross. The chunks for each goroutine aren't equal in size. Generally in the same ballpark, but by no means equal. This is a well-understood and mature dataset and solver. We've been doing it for years. I'm simply in the midst of killing a bunch of technical debt tied up in old legacy systems (mostly C, some Java) where this is one of several pieces. I'm trying to step up my Go skills and am trying to figure out a better way to optimize the solver. The current solver stuff is multi-threaded and quite performant. It's however, one piece of a larger code ecosystem which is in fragile, aged, constrained and, generally, in shambles. Another team is working on that larger piece, I'm simply tackling my slice of the pie. What I didn't explain is that each solver is one of many that runs concurrently across a quite huge dataset. Depending on many factors, there could be 2-3 instances of the solver running, or dozens. I'm *very succesfully* scheduling this workload on an Arm64 Kubernetes cluster. Just looking for ways to optimize a bit more. Going to some beefier processors certainly speed things up, but I don't know the price/performance ratio is there. I'm running a sizeable Arm64 (Rock64's, but excited to get my hands on a Pi4 to see what they're about) cluster at a shockingly low cost. Plus, there's no fun in just reimplementing the same old, same old.
Thanks. Heading down the context path. It certainly seems to be a winner for my use case. Can't share the code. Proprietary stuff, sprinkled with some pretty important competitive differentiators. Plus, though it's a great org to work for, they're certainly community consumers but not ready to be contributors.
A new flag to ignore certain folders/files. In a few occasions, I believe this may help! What do you think?
.snitchignore or something?
&gt; Leave the provocative stuff to Rob Pike and Russ Cox Indeed \^\^;;
If you like this, check out http://eradman.com/entrproject/
This is an awesome idea! Thanks for sharing!
Thanks for posting! While I would be happy to have that error checking boilerplate code eliminated, I'm unsatisfied with proposal #32437's try() builtin. I hope the Go devs reevaluate this.
Thank you, I'm glad you like it. I hope this tiny tool can help you on a daily basis.
check and try are the same thing
I use [modd](https://github.com/cortesi/modd) for this. It can also run servers with automatic reloading, and supports many patterns and commands in a single config.
since you have a defined order you could just run it through a simple for loop of keys: &amp;#x200B; `var aorb T` `for _, key := range []string{"a", "b"} {` `aorb, ok = keys[key]` `if ok {` `break` `}` `}` &amp;#x200B; something like that would allow you to grab that value regardless how many keys as you want to fallback on... food for though
Stoked to play with this
That's already part of the consideration. Since it's a function, it can't reduce the if-err-return boilerplate, it can only make the annotation easier
How about ignoring a certain test? I have a couple libraries where I run some high cost tests minimally. An example is procuring a new number on Twilio for an API wrapper
This feature could be easily added, be with an ignore file as suggested before or adding a new param on initialization.
I see what you mean. I agree with everything you've said. No exceptions, make error annotation/return easier. No more than that though. I'd hate to see error/exception handling get to the point that I'm using Java
Maybe add an option to run tests on file change directly rather than waiting for a timer? You can use filesystem event subscription libraries like fsnotify.
This is the best name ever for an auto test runner
Yes, I thought about this cool option, but I have chosen to go with a more simple and less-dependent implementation. Let's think about this for the further steps though. Thanks for the suggestion!
I hope this name sounds interesting with the binary's purpose, since English is not my mother language. hahaha
This has been tweaked to be less agressive, by the way :)
Nice to see more solutions for shorter TDD cycles. I usually use https://github.com/cespare/reflex to lint/test/restart dev server on file change. Anything this can do that I can't with Reflex?
It totally fits the tool. It snitches (denounces, reports) your code when it breaks tests!
So, we made it!
I didn't know reflex until then, but looks good. I don't know, maybe Snitch has a much better name? Just kidding. Snitch came as "itch your own itches" and I decided to explore this idea and see where it took. Just a few lines of code with a very interesting result!
[https://github.com/axcdnt/snitch/issues/1](https://github.com/axcdnt/snitch/issues/1)
but \`ginkgo watch\` ?
What if I'm not using ginkgo? Just thinking. As I said, this binary came as "itch your own itches". This very small tool has today \~100 LOCs and serves a single purpose.
Like Guard, but in Go!
Yes ‚ô•
Thanks for sharing. I wonder if the same functionality can be achieved with a simple bash script without having to install a go program, though?
Of course you can! Bash allows anything. I just wanted to write this tool for Go developers, to evolve through it. It came as necessity as I was exploring test boundaries. I think the way it is now, it'll be easier to keep the code simple and clean. :)
I learned a lot from \`[https://github.com/rakyll/coop](https://github.com/rakyll/coop)\` which has many concurrent examples.
Can't wait to try it out!
Terminal/Text UI = TUI
yeah I was aware of that term but I'm not sure if the average developer is. Terminal GUI is still grammatically correct :P
I like it. Question: Why no go modules?
Need someone to maintain an arch package?
that would be awesome!
When I was working on Lazygit I introduced go modules but didn't end up properly migrating from dep, and it ended up just being a headache having to support both. So in conclusion the reason is because I'm lazy :) Dep works fine and has never caused any problems for me, so I don't feel a strong impetus to switch
Sounds good! I‚Äôll get something up and running. Btw I love the idea of this project. I found this post on my phone and haven‚Äôt gotten to my computer to toy with it but I use docker-compose for my work dev setup. This seems incredibly useful. I‚Äôm very excited to play with this.
Take a look at https://godoc.org/github.com/rogpeppe/go-internal/testscript. testscript was factored out of the cmd/go internals where it is used to test the go command itself in various combinations/permutations. For an example use of testscript see https://github.com/rogpeppe/go-internal/tree/master/cmd/txtar-c. The script_test.go file does the bootstrapping of the script files in the testdata directory. There are plenty more examples of testscript use out there (which we should probably add to a wiki)
Sure all valid reasons ;) I was just curious.
good to here :) let me know what you think of it!
GUI is an acronym for Graphical User Interface. Since this isn't Graphical, it isn't a GUI.
haha I'm probably a little too cautious when it comes to talking about go mod vs dep
but but... but it has graphs!
Thank you so much for lazygit. It has become indispensable to me. I will give lazydocker a try as well!
no worries man, thanks for putting up with the various bugs I'm yet to fix haha
Wrong. You're becoming too judgmental and it's sick. If you think asking cook book style questions is not right, then you have to stop stack overflow first. &amp;#x200B; And you're showing an image to judge and assume that's all the problems I'm facing? Too fucking wrong. The things I'm posting is more or less available on the internet, or less useful. That's why I'm asking here. &amp;#x200B; So please stop fucking judging others.
I use [goconvey](https://github.com/smartystreets/goconvey/blob/master/README.md#in-the-browser) for this. What I like about it is that the test results are notifications and that it gives you code coverage. What I don't like about it is that there isn't an option to only show the failed tests.
Looks great! I will definitely try this one, thank you for sharing. I've been using DRY, a TUI docker manager. One feature that was missing was attaching to a running machine, I love that yours has it.
We vendor all our dependencies.
Module proxies/mirrors are planned for 2019, see [https://blog.golang.org/modules2019](https://blog.golang.org/modules2019) and [https://proxy.golang.org/](https://proxy.golang.org/)
Well, best case to ensure dependencies being there is to use vendoring. But the go imports do rely on git paths through the import path (doesn‚Äôt need to be github, can also be your own local git repo). I‚Äôm not Sure If a global registry/repository Will solve this issue (If that Goes down, nothing will work anymore). Btw, nodejs has the same ‚Äúvulnerability‚Äù: https://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code/
https://aur.archlinux.org/packages/lazydocker/ Really enjoyed using it this evening, nice work.
Me same. And also Arch user, please let us know when you finish your AUR package :)
https://aur.archlinux.org/packages/lazydocker/ Finished it just a few minutes ago!
That's great news. however the concept of proxy is still a cache, isn't it?? What if the cache refreshes and doesn't find a package? Wouldn't it get removed? And what if the owner decides to use the repo path for something else?
A given version would not leave the proxy. Maybe new versions would.
Great to hear :) I'm not super familiar with archlinux packages. Does that package build off the latest commit, or the latest release (i.e. tag)?
It's decentralised
and how are you supposed to specify a version? all I see in every package is \`import ( "[github.com/aa/bb](https://github.com/aa/bb)")\`, people would have to change URLs everywhere, lol
Thanks for the tips
https://blog.golang.org/using-go-modules
Wow this looks really cool. Never seen such a GUI style before.
The go.mod file specifies the version. The go.sum file makes sure you‚Äôre getting what you asked for.
Wowee-zowee, thank you McEntity for teaching me how to use your services.
&gt; some high cost tests minimally Those high cost tests should [check `testing.Short()` and call `t.Skip`](https://golang.org/pkg/testing/#hdr-Skipping). Then you set your editor to run `go test` with the `-short` flag.
Adding to other comments above/below, "go mod" also supports "replace" and as a result can run entirely on a filesystem: [https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive](https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive) [https://github.com/golang/go/wiki/Modules#can-i-work-entirely-outside-of-vcs-on-my-local-filesystem](https://github.com/golang/go/wiki/Modules#can-i-work-entirely-outside-of-vcs-on-my-local-filesystem) But overall if you ask what to do with external things that can be removed: store them in a backup. If it happens, you can fix things using various features "go mod" has, be it "replace" or proxies.
They learned a lesson, though, and will no longer (ostensibly) remove depended on packages: https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm
Looks from the pkgbuild like it uses version `0.2.1` based on the archive of the tag.
Nice article. It seems to me that many of these pitfalls are bit uncommon In particular the `int` without size section: I don't see how someone would run into that one. If you need 64 bits, you better make sure you use the right type. Things I have run into that are not in this article: * Modifying uninitialized / `nil` maps and slices * The unusual behaviour of `switch` cases without `break` or `continue` * Differences in creating pointer variables vs C types such as `var a,b *int` * Ignored `error` return values * Pointer receiver functions vs Value receiver functions (copy struct or not?)
I agree, nested try() calls makes the code harder to reason about. It would be nice if variables declared inside an if block are available outside the if block so that this becomes possible: &amp;#x200B; `if a, b, err := foo(); err != nil {` `return err;` `}` `// a and b should be available here!`
Honestly Go's dependency system is a breath of fresh air. It's fully decentralized but without the usual downsides of being decentralized. In practice, most libraries will end up on GitHub since that's the easiest place to put them right now, but Go isn't fundamentally tied to GitHub. Those repositories could be hosted anywhere, and, with the proper configuration, it's just as seamless to use other hosts inside Go. Since there's no central package registry, there are no naming conflicts. Nobody gets to have *the* short, obvious name for something just because they got there first. Inside your organization, you can still make use of Go's dependency system without relying on some external internet registry, and you don't even need to up some internal package registry (or mirror the external one). Just import straight from your existing internal repositories. If you rely on an external library, fork it and import the internal mirror instead. Or vendor it. In any dependency system that's the only way to be confident the external world won't break you.
Transparent shill post üëç
I can definitely see someone running into the int size problem in their own codebase if they are so short-sighted or inexperienced as to not anticipate it, but the given example - passing opengl slices of `int` - seems very contrived. Either they were using some very naive opengl wrapper that accepted int slices and did something unwise with them, or their own code directly did something unwise with them.
Thanks for the feedback. Now, we also have coverage! So cheap :P
Fair enough. Side note: this is not a go specific issue, C has a [similar](https://en.wikipedia.org/wiki/C_data_types) thing going for `int` types: it's only guaranteed to be at least 16 bits.
In the example with the mutex, I always use pointers to types like that in my struct definition just so it won't ever be copied.
I‚Äôve seen this happen before. I don‚Äôt remember the module offhand, but the developer changed the capitalization of one character in the repo name and it broke a whole bunch of dependent modules.
Built your app in whatever language you feel most comfortable in, Go is great for performance but can be slightly slower to dev than Python or Ruby. If this is more a learning experience then using Go is perfectly fine, but don't pick it for its performance as you can deal with that when it appears. "premature optimisation is the root of all evil"
This might help you to get a sense of overall app architecture for a web service. [https://github.com/ardanlabs/service](https://github.com/ardanlabs/service) Granted you‚Äôre not going to need all the features like tracing etc but it is a project that try‚Äôs to show off best practices.
https://github.com/VojtechVitek/rerun is a pretty slick tool that does similar things, but uses file listeners and is agnostic to file format and commands to rerun upon change. I use for main dev and tests
Thanks!
I‚Äôve actually just started converting my personal website from Python/Flask and MySQL to Go and SQLite. My primary motivation is to just get more experience with Go and SQLite. One of the cons that I‚Äôve noticed so far is that the closest replacement for a JSON like dictionary in go is the anonymous struct, which is more verbose. Otherwise I feel like Go is actually simpler and more compact than Python in many ways. Two resources I‚Äôve been using which have been pretty helpful are www.gobyexample.com and www.gowebexamples.com
This one points at 0.2.1. I‚Äôm going to make one that points to the head of master as well.
yup, Ankur Anand pointed out on Medium's comments that Im not using go's internal copy command. It seems that by using go's internal copy the total time is reduced by 50%.making the encryption almost twice as fast. I'll update my code this week and will post the revised numbers. But Im glad that the perf errors where mine.
If you don‚Äôt vendor, you can stockpile: https://gitlab.com/pokstad1/stockpile
Commenting to track
&gt; If you rely on an external library, fork it Protip: If using Github, do not use Github's "fork" button for attempting to preserve a repo, create a new repo and push to it. Github "forks" are still linked to the origin repo, and pose a higher risk of collateral damage.
[removed]
https://aur.archlinux.org/packages/lazydocker-git/ This package will always build the latest version from git. I updated the normal lazydocker package to 0.2.4 this morning.
Thanks. I think this was what I was looking for; the ability to ensure all my cli commands are running correctly without having to test manually; and being able to test entirely from go. [https://github.com/orbitdb/go-orbit-db/blob/master/cmd/orbitdb/cmd/get\_test.go](https://github.com/orbitdb/go-orbit-db/blob/master/cmd/orbitdb/cmd/get_test.go). Obviously requires a lot of refactoring and improvement but allows me to test each command in isolation.
Can't install it using `go get`. Probably because the package manager is not go mod?
My terminal text is rendered by my GPU and has antialiasing and sub-pixel rendering, so technically maybe it is a GUI now. lol
Were the standard library enough ?
so your git repo holds all your of dependencies and their dependencies? are you living in the 90s?
&gt;so your git repo holds all your dependencies and their dependencies? are you living in the 90s? vendoring means you hold all your dependencies and their dependencies in your git repo? are you living in the 90s?
No, I don‚Äôt. Just saying that‚Äôs a route some like to go...
Well yeah, about five years in production use, zero problems with it. We might reconsider this once the modules and proxy servers are production ready in our selected Go version, so planning to setup an internal proxy server etc.
can I ask what do you use Go for?
The layout of that sucks. Why put everything in internal?
Microservices and various internal command line tools. I think that has been our sweet spot for Go. Data analytics is still and will be in Python, for example.
Are you exposing the internals to a public interface? No? What kind of question is that
If you're planning to build a large application, go ahead and use it. If you're planning something small, go ahead and still use it. &amp;#x200B; Go being a tightly structured language is one of the best languages I've personally worked on. Its error handling is amazing.
&gt;vendoring means you hold all your dependencies and their dependencies in your git repo? are you living in the 90s? This is not an argument for anything. Vendoring may be a blunt instrument, but it *works* - which is the most important thing. Yes, you use something like [Athens](https://github.com/gomods/athens) which leverages the built-in GOPROXY functionality to get an npm-like experience, but this isn't really about dependency management. Using modules, you can exactly specify every single dependency, then vendor them so that you always have an exact copy stored alongside your code.
Is this dependent on docker itself, or could it be replaced by an alternative image/container manager such as podman, as long as they maintain the same API?
Yes. You should write it as if each package is its own contained and documented API. In what world is it smart to have all the database logic duplicated across every project you make from some useless boilerplate you copy and pasted?
https://github.com/golang-standards/project-layout
I‚Äôm noticing most of the tutorials I see out there are using docker to deploy their applications. I never dockerized my flask apps, and i‚Äôm not opposed to it, but I am wondering why this seems to be the preferred method...
Tried it out and it's pretty freakin dope! Way to go man, you've created a keeper!
Sure, yeah
Hey I just wrote my first app in Go with react front end and I came from Django, not too dissimilar from Flask. I used go-base by dhax on GitHub as the basis for my backend which I wrote as a REST api. It's great cos it comes with a lot of great boilerplate for production ready APIs like JWT authentication and authorisation, CORS headers, basic user management, database migrations and email sending for one time passwords. The only thing is it uses passwordless authentication to start with but it's pretty trivial to switch to password based Auth with bcrypt hashed passwords stored in the database. Check it out here: https://GitHub.com/dhax/go-base
A few things here: * EXIT is a command specific to the protocol you‚Äôre writing a client for. It has nothing to do with TCP in general. * ioutil.ReadAll blocks until EOF. This means that as long as the socket is still open, it will block indefinitely. For network IO, you have to read some number of bytes into a buffer with the Read method and then handle those bytes accordingly. Since this protocol is newline delimited, there may be some helpers in https://golang.org/pkg/bufio/ to make this easier for you. * EXIT is causing the server to close the connection, after which ReadAll can return, because it reads until EOF.
Don't worry about it. You're learning at least one new language/tool/environment here, and docker is something you can learn completely on its own later and not using it won't affect your learning experience now.
‚ÄúAre YOU tired of typing every git command directly into the terminal, but you're too stubborn to use Sourcetree because you'll never forgive Atlassian for making Jira? This is the app for you!‚Äù Nice!
‚ÄúAre YOU tired of typing every git command directly into the terminal, but you're too stubborn to use Sourcetree because you'll never forgive Atlassian for making Jira? This is the app for you!‚Äù Nice!
Great job on that interface. I might need to fork this and use it with LXC/D.
As the other poster said, just don't worry about docker for now. I would personally recommend learning it at a later time though, as docker has many benefits (I use it daily at work). When it comes to learning though, stay focused on one thing at a time. Try learning go, and when you get to a point where you're thinking about deploying your code you can start worrying about tools like docker.
Maybe I should clarify: I have experience with docker, and with go as well, just not an expert by any means. I still would like to understand the reason behind best practices. I‚Äôm assuming it‚Äôs a dependency / fresh environment type thing?
Your forgetting the benefits of scope, if you want a and b there then you need to declare them at that scope, ie; ``` var a, b int if a, b, err := foo(); err != nil { return err; } ```
Do you plan to use the template function of go or build a SPA with json rest api?
The idea is that you have an easily reproducible environment for you application. I.E. anyone who has Docker installed can run your app without worrying about anything else. It's also used in modern deployment environments like Kubernetes.
It's common to have packages that are not used outside of an application. Writing each package as a generic API is a naive thought process. There are places for that, and your comment, "You should write it as if each package is its own contained and documented API" is not good or helpful advice.
Keep in mind that a `map[string]interface{}` can be helpful as well.
Hiding variables inside a method with declaring variables with the same name is actually very confusing. That's why many languages do not allow variable shadowing of method arguments and variables inside a single method. So if i have a method with argument a and variable b, I shouldn't be able to shadow a and b inside an if block inside that method. This would make the code easier to reason about.
That's a big part of it, yeah. Using docker would allow you to separate your concerns. Installing dependencies and using the correct environment would be encapsulated in your Dockerfile, which is a nice pattern to follow if you already understand how docker works. If you're comfortable with it I'd recommend going that route.
Does setting USER in the Dockerfile to your local user uid work?
Is it though? Have you worked on any large codebases? Toy projects don't matter as much for structure because you'll be the only one using it. Look at projects like Kubernetes and you'll see the patterns I describe. The advantages of writing code this way - writing each package as self contained, documented modules of functionality - are plenty. You can easily understand from godoc what each piece does. You can reuse functionality later in ways originally unforseen. And you can ultimately move parts of your app into a library if you find you need it for other projects as well. Hiding spaghetti code under undocumented internal packages is not the way to go nor the intent of internal.
Not saying it is the best of ideas, but you could always use your host‚Äôs uid within the container. Not sure what it looks like with compose but the following with docket allows me to create files within the container under my host uid docker run ‚Äîuser $(id -u):$(id -g) &lt;whatever image&gt; Obviously the container won‚Äôt have a name for that user but it will create files under the host‚Äôs name.
What‚Äôs your ideal learning style? - Books - Video Courses - Hands-on exercises Something else? Would be happy to share some resources that I‚Äôve found helpful
Check out go buffalo... Will give you a lot of batteries included
To start: - [How to write Go code](https://golang.org/doc/code.html) - Resources from here: [Idiomatic Go](https://pocketgophers.com/idiomatic-go/) - [Gophercises](https://gophercises.com/) Also feel free to join the [Gopher‚Äôs Slack group](https://invite.slack.golangbridge.org/) and ask the community for help!
[removed]
Hand-on exercises probably work best for me. Video and books can work but aren't as effective IMO.
Thank you! I'll have to take a look at all of those. :)
go mod works great for Go 1.11 and beyond, but only outside of $GOPATH, and it works best if unsetting GOPATH altogether.
 annotate :: Functor n =&gt; (e -&gt; e') -&gt; ExceptT e n a -&gt; ExceptT e' n a annotate f = mapExceptT (fmap (first f)) foobarbaz :: ExceptT FooBarBaz IO (Int, Bool, String) foobarbaz = do a &lt;- annotate Foo foo b &lt;- annotate Bar bar c &lt;- annotate Baz baz pure (a, b, c)
Definitely recommend Gophercises in that case. Jon C. puts out some great online courses and the free Gophercises exercises he puts out are no exception.
[removed]
[removed]
I use these. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
If you have packages that are expected to be ‚Äúpublic‚Äù and used elsewhere that‚Äôs great and you should build them in a way that allows that. Otherwise, I‚Äôm not sure where you are getting at with everything else... no one said you should be writing ‚Äúspaghetti code‚Äù - which the above example is not.
[removed]
the latter.
Yes. :) *(Functor is actually the scientist gopher, but deep down he's very evil)*
It's worth noting that's in AUD, so it's only really $24 USD. :)
Thanks for supporting this! :)
Thank you!
Thanks! Those are good suggestions, I'll look into them. The fancy one is made by Renee French, and has the same open license, so that's definitely a possibility! :)
I highly recommend "Learn Go With Tests". https://quii.gitbook.io/learn-go-with-tests/
This right here. +1
Building even internal packages as if they will be used publicly leads to cleaner, better documented, and easier to maintain code. Especially for testing. It's part of Go's modularity. Again, I encourage you to go explore any large scale community project built with Go. You'll see what I'm talking about.
sirupsen/logrus
‚ÄúPremature optimisation is the root of all evil‚Äù damn gna quote this at work today. Mythical 10x Engineers tend to try to optimise prematurely which seems to cripple the whole development process instead.
It means that creating the map doesn't also allocate memory for any entries. This doesn't affect the semantics of adding new entries to the map later, but it can affect the performance. It has no direct equivalent in Python. https://golang.org/pkg/builtin/#make &gt; Map: An empty map is allocated with enough space to hold the specified number of elements. The size may be omitted, in which case a small starting size is allocated.
The 0 is setting the initial capacity of the map. A better example might be \`row := make(map\[byte\]bool, 5)\` - in this case, the map is initialized with a capacity of 5 and the first 5 elements added to the map will not require map resizing. The map can still grow past 5 elements, but the map will be resized. You can leave off that parameter entirely: \`row := make(map\[byte\]bool)\`. &amp;#x200B; In practice what this means is that if you know how big you want your map to be or even if you know the minimum size it's going to be, you can add the second parameter in the initialization to hopefully gain some small performance benefits.
Are you in the gophers slack group? Highly recommend it as an active community that is constantly sharing learning resources/answering questions: https://invite.slack.golangbridge.org
**/internal** Private application and library code. This is the code you don't want others importing in their applications or libraries. Put your actual application code in the /internal/app directory (e.g., /internal/app/myapp ) and the code shared by those apps in the /internal/pkg directory (e.g., /internal/pkg/myprivlib ).
Thanks a lot! It really helped.
Have never seen a real app use this structure.
&gt;For example, currently on x86-64, only the lower 48 bits of a pointer are actually used. Does that mean there's a practical upper bound of 2\^48 bits of memory? I know that's insanely huge, but, where can I learn more about this?
It‚Äôs from the architecture programming manual of AMD64. [Page 120](https://www.amd.com/system/files/TechDocs/24593.pdf) (PDF) &gt; Currently, the AMD64 architecture defines a mechanism for translating 48-bit virtual addresses to 52- bit physical addresses. The mechanism used to translate a full 64-bit virtual address is reserved and will be described in a future AMD64 architectural specification.
I switched from python to go myself recently and had some great experiences using [gorilla mux](https://github.com/gorilla/mux) as the flask equivalent. [here](https://hackernoon.com/build-restful-api-in-go-and-mongodb-5e7f2ec4be94\) is a guide on how to implement it with mongo as your backend.
While on this topic, does go have anything similar to rails? Just something aimed at convention over configuration.
&gt; In nodejs dependencies can't be removed by their authors, which ensures your project will never break So the leftpad disaster did not happen?
&gt; so your git repo holds all your dependencies and their dependencies? are you living in the 90s? So you don't have control over your dependencies and depend on other people's infrastructure to work? lol. Good luck with that.
Thanks for the approach. Have you worked on Apache Kafka using golang's API?
For point 6, you can use `range` instead, if you're constantly consuming from the channel (like a worker). range will automatically terminate when the channel is closed. https://golang.org/ref/spec#For_statements
https://github.com/PandaWhoCodes/awesome-go-in-education a list of go resources
How about the for loop in main happens to be a separate goroutine? Because creating a goroutine &lt;code&gt;workChecker&lt;/code&gt; for every iteration is not feasible, I think.
I'll look into this. Would be nice to automate this somehow.
thanks for answering! could you tell me why you prefer python over go for data analytics?
- Export all types used in the exported API. As the package stands now, I cannot construct a []paginator.setting and use that in a call to New. - Add a package comment. - Add a link to the [documentation](https://godoc.org/github.com/johnmackenzie91/go-pagination/paginator)
This is great, thanks for the feedback!
[removed]
You may want use an interface rather than a structure.
Just wanted to stop by and say thanks for lazygit. Using it daily, it really helps me committing quickly.
cool, I like this
Something like that \`type Settings interface{}\`? Can you share some simple example?
thanks heaps! Any chance you want to chuck up a PR to add instructions in the readme? I'm not really sure what the right wording should be
Because I have a bit of code that depends on the docker client, currently it's not simple to switch. However there is an open issue for it and I'll probably look into it soon, because podman does look quite cool
well, to be accurate, go's dependency system \_does\_ not depend on github. It's just where most open source projects are hosted. &amp;#x200B; A lot of people maintain local mirrors for their CI pipelines to circumvent anything breaking because of an issue upstream. Another option is to vendor all your dependencies. &amp;#x200B; Also, much unlike NPM, there's very little interdependence in the ecosystem, and most big projects are either maintained by their individual startups or companies. the chances of builds breaking because someone removed something akin to \`leftpad\` is really, \_really\_ low. &amp;#x200B; And the go team is working on mirrors, so that should close the loop on the problem (probably in maybe another year or so)
You've made my day. Glad to know other people are out there who love lazygit as much as I do!
I‚Äôm currently also learning Golang and I‚Äôm working my way through this video from freeCodeCamp.org [Golang tutorial for beginners ](https://youtu.be/YS4e4q9oBaU) Not sure how far along you are, buts it‚Äôs a great course!
It's just not true that Go's dependency system relies on github in any way. Quite the contrary, it is build *from the ground up* to not depend on any central authority (except DNS) at all. Every single component can be easily replaced and you can start hosting your packages on whatever platform you want (or just host them yourself) starting today. &gt; in many cases i've seen authors asking users to modify their imports when they rename their packages. I don't understand this criticism. *Of course*, if the name of the package changes, you have to change the name of the import. I don't see how that's any different in any other language TBQH. If I rename a rust crate, you'll have to change your imports too, don't you? &gt; So how do you guys deal with this, why isn't there a global repository/registry like Rust's Cargo or Node's NPM? See above. Go's dependency ecosystem is build from the ground up to not rely on any centralized authority. There *is* a pretty good central repository/registry in the form of godoc.org, where anyone can just enter their package by fetching a URL with their import path. You can also build your own indices and hosting solutions. There even is a more traditional hoster with `gopkg.in`. The great thing about the Go dependency ecosystem, is that it allows *any* solution you can think of to easily coexist :) If you're unhappy with any of the existing options, just build your own and it's super easy to make it inter-operable with the existing tools :)
what operations do you want to perform?
Are you actually asking this question ?
I don't think anyone needs to worry about keeping their questions in the learn subreddit. We have pretty good traffic here but not high enough for it to matter that everything is in one place. gobyexample.com has been my favorite place for referencing syntax, though now that I know go pretty well, godoc and the source code is pretty much all I need most of the time.
If you used maps or arrays, surely it'd be `map[string]interface{}` and `[]interface{}`, so you'd still need type switches / reflection, etc. Could you use a query builder to accomplish this? Something like goqu maybe? They do have a `goqu.Record` type for example to do inserts / updates, and it's basically a `map[string]interface{}`.
Very promising! How did they achieve 0.5KB size for the read me? Last time I checked GopherJS had quite a big overhead and WASM needed to ship with the Go runtime. What evil sorcery is going on here?
That requires lazy execution or lots of function wrapping, so it's a nice thing to do in Haskell, but won't work in go‚Ä¶
A small tool written in Golang that allows querying YAML using XPath expressions. The underlying mapquery library was written to address the lack of good options for querying unstructured data in Golang, the target application involves manipulating fields within Kubernetes manifests. &amp;#x200B; Thought I would share the project, to see if anyone found it interesting.
Found this, maybe this will get you a little further https://medium.com/redbubble/running-a-docker-container-as-a-non-root-user-7d2e00f8ee15
Thanks for these links! I‚Äôve only recently started learning Go. And the ‚Äúgophercises‚Äù look great!
I think it's via TinyGo
Maybe there is a typo. I've launched the example and got \~2.3MB instead of 2.3KB.
How about using json as output and dynamically access it e.g. via [https://github.com/tidwall/gjson](https://github.com/tidwall/gjson). You don't have to store it as json. You can store your data in tables and output it as json. On the other hand you could also use Mongo DB or similar and simply work with json. I don't know if you want to heavily join tables in which case I'd rather use a relational database. That said from how I understand your request postgres + tables + json output + gjson could do fine. This driver ([https://github.com/jackc/pgx](https://github.com/jackc/pgx)) comes with json as well as jsonb support so you should be good to go. jsonb can easily be indexed and also used to "join" tables.
I thought that WebAssembly was unable to manipulate the DOM API?
For example Room has Doors. If I want to delete the Room, I have to verify that the Room has no associated Doors (ask the user to delete them manually). If I edit a Door, and associate it to another Room - the old Room should remove the relation with the old Door, and the new Room should update its self that it is associated with the new Door. I guess gorm can handle relations, but I think its too much to retreive whole objects when I just need to modify some ids (in a generic way).
You can simply use "syscall/js" to manipulate and access DOM API. &amp;#x200B; var doc = [js.Global](https://js.Global)().Get("document") val := [doc.Call](https://doc.Call)("querySelector", selector) // here \`val\` has DOM element matching selector.
goqu.Record does look interesting...
I guess you'd have to give some examples, otherwise people might not get what they can be useful for.
Yes, will look into it. Seems like a viable option since I mostly need to query by id
Or I am stupid and should just rely on gorm Associations for now?
0.5KB gzipped
Vendoring. I would rather not depend on someone else server that can go down and cannot access my dependencies anymore.
Beware Go, Microsoft is coming at you with Blazor and its 60+mb runtime :3
Have you seen https://github.com/apex/up?
I think the [article](https://blog.golang.org/go-slices-usage-and-internals) on slices from the official golang blog, is a lot better to learn how they work internally: * Less obfuscated with gdb pointers * More graphical * More details
Yeah fair. I don‚Äôt use Go but figured I‚Äôd give a Haskell example for those unfamiliar with Haskell to use as a reference for what can be done in other languages.
I found this gist that kinda shows how you can marshal any JSON obj to map\[string\]interface{} &amp;#x200B; [https://gist.github.com/cuixin/f10cea0f8639454acdfbc0c9cdced764](https://gist.github.com/cuixin/f10cea0f8639454acdfbc0c9cdced764)
This is the pattern I created that I've been using for the past few years: [https://github.com/dougbarrett/example-golang-app](https://github.com/dougbarrett/example-golang-app) &amp;#x200B; it's worked out really well for me. &amp;#x200B; The most important thing to consider when dealing with sites that receive a high amount of traffic is caching: your app cache, a cache like redis/memcached, and proper indexes in your DB so your DB can create a cache. The structure I use can easily support that, you would just add new storage services under the storage directory.
Here's an update for you: [https://play.golang.org/p/f0-AwBLbRwL](https://play.golang.org/p/f0-AwBLbRwL) I have to ask though, is there a very good reason these things MUST be in go-routines? it seems like standard synchronous execution solves your problem just as well and in a less complicated manner.
I have, and it's great! I just wanted something that was simple without abstracting too much of what happens underneath the hood. I think it can seem daunting beginning Go+AWS Lambda, but really it's a just a couple of command lines and yaml files.
Super intriguing, but the lack of any kind of "getting started" tutorial makes it a bit unapproachable :( Unless there is one and I just can't find it for some reason...
Ooh, I didn't know FCC had a Go tutorial. Thank you!
Thank you!
I'll take a look into it. Thank you!
\*Nods* I was just uncertain because a lot of other programming subs tell people to ask questions in the learn(language here) subs rather than the main one. And I have taken a second look at Go by Example. First time I tried it I felt like it didn't help me much, but now I see that it has a lot of useful information. And thank you for the reply!
I concur: the whole post be like "look how I glance at a slice in gdb; how cool is that?". The answer is: no it is not cool at all.
I've read this article and I managed to solve my problem. Here's what I did: * I've updated my `docker-compose.yaml` file to include `user: $(CURRENT_UID)`. * I've updated my `Makefile` to `@CURRENT_UID=$(id -u):$(id -g) docker-compose up -d`. Files have correct permissions and the sun is shining again. Thank you for your help!
The first question I get when reading your readme is, is this a library or an executable? If is a library, just write the go import path, don't tell the user to install it using go get.
I briefly scanned the repository, and I have a couple of suggestions: - Allow overriding the names of the request params and response fields. Mostly useful to allow users to start using your package without breaking backwards compatibility for _their_ users. - In Go, we typically don't prefix getters (i.e. use `Limit()` instead of `GetLimit()`. - Lower the default limit a bit. It looks like it's set to 100 now, but I reckon 20 or 25 makes more sense for most users. - Link to the godoc from the README. - I would simply combine all code in a single .go source file, rather than the three you have now. - The builder's `StateFromRequest` method never returns an error. Unless you have reasons to assume this may change in the future, I'd change the signature to not return an error. This will make client code a lot cleaner. Again: I only scanned the repository quickly, so I may have suggested something that's already implemented.
Yes, these numbers are supposed to be MB not KB. So sorry about this. I realize this is a HUGE difference, it wasn't my intent to mislead with this, just my sleep-deprived brain misinterpreted the output of `ls -s` as being in bytes not KB while I was pushing this announcement at 2am. Corrected here: https://github.com/gopherjs/vecty/pull/242
Correct, one doesn't exist yet. You can read more here: https://github.com/gopherjs/vecty#current-status If you are eager to be an early adopter, see https://github.com/gopherjs/vecty/tree/master/example
the bundle sizes section of the readme says 2.3 MB and 0.5 MB with gzip.
only your project files üìÇ!
Quick answer to your question : only your MyProject files ... ... but
&gt;The end goal is to have good working code, not clean code. if you have the ugliest code in the world, but it runs efficiently, and has no bugs, then it didn‚Äôt matter right? Wow, that is remarkably wrong. What happens when the needs change and you need to change the behavior of that ugly code? Good luck.
I think it's pretty clear it's a library, it describes itself as a package. It's also pretty standard to always show the \`go get\` command for installing a library or command.
(I updated the README to MB after realizing I had incorrectly written KB, see my message above)
Tell a bit more about the domain problem you're solving. Giving a full control over what goes to the dB isn't a good idea. Maybe there are some patterns?
Sweet, I'll take a look. Thanks for the pointer :)
 Your `go get` is the confusing part. That's not a useful instruction for most users, and looks like it's installing a command. This combined with the verb generate as appears in your description makes your project likes like a `go generate` tool that generates go source code. I know what it is after reading carefully, but it's confusing to someone who knows the go lingual well and expects to know what a project is with a quick scan. All you need for libraries is the go import path. Especially considering that there is no .go code in your root path and no import statement in your example code. Anyone trying to use your library has to dig through the sources code to find out.
So do we. Disk space is cheap and the reduction in risk is worth it.
If instead of large interfaces you make small interfaces, you don't need to implement empty methods. Just use the dual return value form of the type assertion to the small interface to determine whether you need to invoke the function.
Do you need to provide the capability to query on the user specified attributes, or are they just opaque data?
Why did you break up main.go and the logic in server.go? http.ListenAndServe blocks, so you wouldn't need any tricks with channels to keep the app from quitting. Even then, you could've just called it 'serve(addr, sc)' without the 'go' in front and moved the 'log.Printf("HTTP Server listening on %s", addr)' above that if you want to keep them split up the way you do now.
Maybe we can at least agree that it is pseudo-graphical :-)
&gt; As the readme points out, memory copying is currently laughably bad. It should be possible to do some much fancier reads directly from memory on the JS implementation side, Correct. See - https://github.com/agnivade/shimmer/blob/master/index.html#L82 and https://github.com/agnivade/shimmer/blob/master/load_image_cb.go#L40 But Go 1.13 takes care of it anyways. In any case, it's always good to learn new things :)
For example, storing products, with a set of attributes. They can have a common set of attributes, but also some particular attrs. Then I want to create other type of objects through the api with a different set of attributes. They should be searchable too.
`go get` isn't just for installing commands. I suppose it could be more clear regarding library vs command.
It was a very nice read. Thanks! At the end of the first article there's a link to the second article mentioning that it is the last article in the series but you have one more, Concurrency Access with Maps, in the series.
Great, but how does it work, if WebAssembly is unable to access the DOM API? Is there some kind of bridge in "standard" JavaScript?
I dislike the use of the raw sql executions in the todo.go file. I would have placed them in their own module so it's easy to find how your api interacts with the data store.
I just describe all services and models via grpc and then use raw [lib/pq](https://github.com/lib/pq) to work with database. I feel much more comfortable googling how to do stuff directly in SQL rather than in some obscure Go's ORM library.
Sounds like a good idea :D i have read about this principle but forgot
Many people complaint about this, but there's a reason for that. I wanted to print a message right after the \`http.ListenAndServe(...)\` statement, but \`http.ListenAndServe(...)\` is a blocking call, that means it blocks the routine. So I placed \`http.ListenAndServe(...)\` in a new routine by using \`go serve(...)\` but by doing this the main routine would end before the child routine and this would make the application close "prematurely" without listening to HTTP requests. So I created a channel \`sc\`, then I created a child routine by using \`go serve(...)\` and right after that I placed a \`fmt.Print(...)\` statement that informs the user that the web server is listening. At the end of the application I wrote \`&lt;-sc\` (blocking call), this line keeps the application up by making the main routine listen for values passed in \`sc\`.
Would have you placed the queries inside the model (model/todo.go)?
You can put that statement above the call, as it will error out (in your case, log Fatal) if there's an issue... and if not, you can safely assume it's actively listening. You're going through too many unnecessary hoops for a placement of a status message. Does your code work? Likely. Would I hire you if this were your coding challenge for a developer position? Nope.
I know I'm going throught too many unnecessary hoops, but I started this project with a purpose: learning. That issue (the blocking call) was a good reason to try out go routines and channels. I know you would not hire me, but I would not apply for a job position in first place, just because I started learning Golang a week ago and I hope I'm doing good.
Keep trucking and learning... you'll get there. You're welcome, also. You got this.
I meant the information about fasthttp guy :)
It's just as good and viable as learning C++, C#, Javascript, Python or any other language as your first. There's so much to learn though, so be prepared. Go isn't the only thing you're going to want to learn. Most Go positions require some type of DevOps experience with it. You'll need to learn about containerization and Docker (Kubernetes is a plus also). You'll want to know how Google Cloud, AWS, and/or Azure works. You'll want to understand CI (continuous integration). You'll want to know what YAML is, and its syntax, etc. It'll seem overwhelming, but you got this. Udemy is actually an affordable route to go to help w/ this stuff.
I think that's fine. My reason is that it's a simple language, with lots of documentation and a small standard library. You should learn another language as well, so you can see the differences. Let's say, golang and python at the same time, so you can observe the difference between (py) lists and (go) slices, the difference in different type systems, etc.
not realy to be honest. go code is fundamentaly different from classic object oriented languages. its "hard" enough to write good go code once you came from other languages but it is possible. the other way arround might be a bit harder since go simply doesnt have these kind of structures other languages have thus you'd have a harder time understanding them.
There are some really nice things about Go for beginners, especially how good the documents are and how accessible the tutorials are, not to mention that Go doesn‚Äôt abstract away the hardest parts of programming and actively makes you evaluate doing stuff if it is costly to do. That said, I look at how many foundational concepts you need to understand to get up and running (GOPATH, compiling, command line, etc), and I think Go makes a much better 3rd or 4th language behind better choices like Python or even (god help me for saying this) JavaScript, because of how easy it is to get started and how quickly you can make something meaningful.
Yes there is js go runtime. syscall/js.valueCall and syscall/js.valueInvoke is probably what you are looking for if you want to know how it is implemented. Haven't yet understood how the compiler generates call to them (R\_WASMIMPORT somehow) [https://github.com/golang/go/blob/master/misc/wasm/wasm\_exec.js#L322](https://github.com/golang/go/blob/master/misc/wasm/wasm_exec.js#L322)
[removed]
This is just not true and I feel bad for the people who attempted to learn C++ as their first language.
I think every person learns their own way and each case is different. All I can say is that I learned Java first and I absolutely wish that I learned something else first. Not to say that Java slowed me down because of flaws of the language, but the verbosity and boilerplate (relative to scripting languages) was discouraging for me personally. Also, the IDE made it seem like a lot of magic was happening behind the scenes - even if that wasn't always the case - so I never *felt* like I fully grasped the language.
It doesn't matter! As someone who started programming with Amiga Basic, I can tell you that the first language you pick in a very long journey is not relevant.
I disagree. Personally I think C is the correct first language provided you're going the whole CS path. Go is a more practical, modern alternative though. People should learn first to think about the shape of things in memory and the cost of various operations. Usually this is taught with computer architecture, data structures and algorithms, discrete math, and computability. These fundamentals will improve the way you can think about efficiency in languages like JavaScript etc. But this is just my asshole. I mean opinion.
Go would be great first language. Start with the Donovan and Kernighan book, working through the exercises at the end of section. Also working through the Unix Programming Environment by Kernighan and Pike would also be great start. That book starts with shell and progresses to C.
This is highly subjective, but I would suggest Python just so you don't have to worry about boilerplate and various details that get in the way of learning the building blocks of programming like conditionals, loops, variables, functions, etc. For instance, a complete Python program can be as simple as: print("Hello World!") The same thing in Go is: package main import "fmt" func main() { fmt.Println("Hello, World!") } So to run your very first program, you are already asking yourself a dozen questions. "What's this package business? Main? What's an import? What's fmt? And func? And what's with the dot notation fmt.Println? And what are the curly braces for?" Etc. *ad nauseam*. The Python version is basically, "What's up with the parentheses? I think I can guess what the 'print' does." Python is just going to do much more heavy lifting for you and let you learn the fundamentals distraction free. Having said that, Go is an amazing complimentary language to Python. If you know Python, and decide you need an implementation of some program that (for example) runs faster than Python or is easier to deploy in a single executable, Go is an easy transition.
I disagree with the majority here. I would not recommend Go as a first language for a few reasons. 1. It has pointers. I think that disqualifies any language from being a "good" first programming language. There's enough of a mental leap just to learn syntax, control flow, logic, etc. Not to mention how to build/run, some common methods you can use, basic data structures, and the like. Adding pointers on top of that is too much, in my opinion. NOTE, I'm not saying it can't be done, because clearly it can and has been done - quite successfully in some cases. Many schools have taught C++ as their first language for years. But it makes the process so much harder than it needs to be. 2. It's just different enough syntactically from most other languages to be "weird". No semicolons at the end of lines, but it does have braces. The object model is non-typical to say the least. Type identifiers come after the variable names. All of this makes learning other languages more confusing. This really becomes an issue when you are looking for examples of algorithms to implement, and they are in other languages that are closer to the C family of language. That said, it does have some things going for it as a first language. The standard library is great. You can do a LOT without ever needing to import another library. The compiler is great. Quick feedback, along with fairly good error messages makes the code/execute cycle very small. No runtime/static binaries means you don't need to fiddle with your system settings to get the code to run correctly. I can't tell you how many times I've had to help people figure out class-path issues in java. Not having exceptions is a bonus. I've mentored dozens of people straight out of school, and only 1 or 2 really grasped exceptions. Until you grok them, it's just cargo culting. &amp;nbsp; I'm in the same camp as MIT. Python is, on balance, the best first language to learn. But, Go would be an excellent second language.
The type of \`snsRecord.MessageAttributes\` is \`map\[string\]interface{}\`, so no your code will not work, and it won't even compile. You need to cast MessageAttributes\["Test"\] to its proper type yourself. If you don't know what that is, you can print it out (\`printf("%T", x)\`). My first guess is it will be yet another \`map\[string\]interface{}\`. Repeat again and you can finally extract the string "TestString". &amp;#x200B; PS this \`map\[string\]interface{}\` stuff rapidly becomes tedious. It seems the lambda code API you are using is imposing this. But it would be much nicer if you could either get the raw message, or supply a struct to unmarshal the attributes into. Perhaps there is such an API. PPS your local var names are confusing. The var named \`snsEvent\` has type \`SNSEventRecord\`, and the var named \`snsRecord\` has type \`SNSEntity\`.
One question, when you say I need to cast MessageAttributes[‚Äútest‚Äù] do you mean I need to create a struct for this interface? Not clear on what you mean by casting Thank you.
Yeah Go is fantastic, Ive been teaching someone how to program recently and Go seems great for it. Static types, close to C but plenty abstraction.
In my opinion, that's just delaying the inevitable. Once they ask "where does print come from?" you're going to need to explain all of that anyway. Teaching someone there's a magic function provided to you to write to stdout isn't any better than teaching someone how to access a magic package that provides that function.
yes i think its a great choice, i did a whole video series teaching programming with go: gameswithgo.org
I've learnt several programming languages and I'm currently learning Go. Imo, Python is the best first language to learn. Python has very simple readable syntax that will allow new learners to concentrate on programming concepts like if statements, loops, functions and classes. Go on the other hand has a steeper learning curve. A beginner would not only need to learn programming concepts but the various "quirks" of the Go language. Personally, I find the Go documentation to be slightly confusing. They have terms that are not used in other programming languages. That said, I still think Go would be a good second language to learn. Once you've mastered the basics of programming, you'll be able to concentrate on learning the quirks of Go like using interfaces, concurrency, channels, pointers, etc. In the long run, I don't think which programming language you learn first matters. But learning Python before Go will definitely make the learning curve feel less steep. Relevant xkcd: https://www.xkcd.com/353/
A lot of that is in C++ and Java too, which are super common first languages.
I'm a bit torn on this. It's a yes from me, because : - Go syntax is really simple. Excluding types, there are only 25 keywords that used by Go language, which make it easy to learn. - Go language is really opinionated, which make almost all Go codes look similar This is great for learning because it minimalize the gap between the newbie and the professional programmer. Thanks to this, you can open any code from a mature project and you can understand it easily. It also makes working in group nice. - The IDE support is great, thanks to Gogland or VS Code. - Go documentation is really nice, and most Go's package is documented nicely. - Go language is popular and has a huge community, which make finding help easy. - Usually, everything you need is already in standard library. - No semicolon, which is nice. In other hand, it's a no from me, because : - Go is statically typed language. For the first language, I think it's better to focus on logic rather than type, so dynamically typed language might be better for first timer. - For simplicity, there are many programming concept that doesn't exists in Go. For example, there are no generic, inheritance, polymorphism, overloading, etc. Since it's for first language and for academic purpose, I think it's better to use other language that support those. (To be fair, those stuff exist in Go as well, however it's quite different than what taught in CS classes that I took in my college). - Correct me if I'm wrong, but I think the area for using Go language is a bit limited. Right now, Go is best for creating server or CLI app. Sure, you can do robotic, game, GUI app or machine learning in Go, but I think it's still limited. Since this is for first language, I think it's better to use other language that more versatile and general to use. With that said, I think Python might be better for first-timer : - It's really easy to use. - The syntax is simple and sometimes looks similar with pseudo code. This help you focused more on logic than syntax. - All(?) programming concept exists in Python, which is good for learning purpose. - It's old and really popular, which make finding help easy. - It's dynamically typed and there are no semicolon as well. - It's versatile and can be used everywhere, including server, robotic, game, GUI, machine learning, and statistic. So, for first time, you might be better with Python. Later, if you decided to become programmer (especially back-end programmer), Go is IMHO better and more productive to use.
What is the data structure of said attributes? Are they just strings such as a tagging system?
Fixed, thank you for the feedback!
I would strongly recommend Go as the language to use for your first major project, but if you're trying to learn basic programming concepts absolutely nothing beats working through "Structure and Interpretation of Computer Programs" in Scheme. Link here: [https://mitpress.mit.edu/sites/default/files/sicp/index.html](https://mitpress.mit.edu/sites/default/files/sicp/index.html)
I mean what is more properly called a type assertion. Something like \`intf.(type)\`. In your case, text, ok := currentEvent.Records\[0\].SNS\["Text"\].(map\[string\]interface{}) or whatever type the lamdba package is using underneath. If it is a \`map\[string\]interface{}\` then ok is true, and you can then try val, ok:= text\["Val"\].(string) &amp;#x200B; [https://tour.golang.org/methods/15](https://tour.golang.org/methods/15)
I was going to put my two cents in, but you've already said everything I wanted to say. I really love Go. I could talk for a long time about what makes it an amazing language. But that doesn't make it a good first language, and I think a lot of people who are passionate about it miss that. When people are first learning how to program, the big hurtle is figuring out how to translate thoughts into code. Take a simple task, like parsing a CSV file, sorting it by one of the columns, and spitting out a new CSV file. Teaching someone who's never programmed before how to even think about that problem is difficult enough as it is; having to also explain pointers, loop mechanics, and other lower level concepts just needlessly adds more complexity, and it distracts from the real lesson. Python is the best first language because it does have a ton of utility in its standard library, and it abstracts away most things so that code can be more declarative. It's much easier to say for line in file than it is to talk about bufio and terminating a loop when error is EOF. Same goes for explaining that variables refer to data in memory, and more than one variable can refer to the same piece of data, rather than having to talk about values and pointers. Go is great because of its simplicity, which makes most Go code look like you were the one who wrote it, but its simplicity is aimed at people who are already programmers. Looks like I added my two cents anyways. :)
Go was my first language commitment, but I dabbled in Java first. I have to say I felt like learning goland was WAY sinpler than Java. Its possible though that its because I was trying to learn android development with Java. Anyways, if you do go with go, the only thing that I screwed up mahorly was not understanding concurrency and how to manage it. If you end up making an app that multitasks (Any web api), make sure your global maps/slices are concurrency safe.
[removed]
Nice read. How about adding an example on how to add the mutex to the default map, for beginners?
We‚Äôre working on a Moss Gopher for our Greg the Gopher Kickstarter, do you think Moss would use Go? (You can back at [https://www.kickstarter.com/projects/thegrumpyunicornco/greg-the-go-gopher?ref=6oe485](https://www.kickstarter.com/projects/thegrumpyunicornco/greg-the-go-gopher?ref=6oe485).)
What's the difference between "hydrating" an object and simply populating it? This is the first time I've ever heard the term.
As much as I love go, I still recommend python as a first language over it. Being forced into go's philosophy, or any philosophy really, on your first run is kind of a pain. I feel like I wouldn't be a programmer if I hadn't been eased in with python. Go as a second language though? Definitely.
Strings: as color, or float: as price, or time: as a timestamp.
Yeah, with go modules now I think it's super easy to get up and running with go. Having to deal with go path and setting up deps and all that was a tough first hurdle for a lot of people I'm sure (myself included) (though go deps did seem like it had gotten a lot easier over time)
I wouldn't recommend go as first language, once habituated you will hate other languages.
&gt;They have terms that are not used in other programming languages. Any examples? I would love to know where Go newcomers, especially who already have a programming background, struggle to understand Go terminology, as I run an online Go course for exactly that audience. In my experience, the Go docs only diverge from standard terminology (a) if there is a need to distinguish a Go feature from a similarly looking but differently behaving feature of the mainstream languages to avoid confusion and wrong expectations, and (b) if the respective language construct has no established "common" name. But maybe the filter on my coding goggles is too selective...
My advice to any aspiring programmer: Do not fret over your first language. Mine was Radio Shack Basic. Then z-80 assembler. Then C. Then DOS (scripting/batchfiles). Then Pascal. Then Visual Basic. Then C++. Then SQL. Then zsh (scripts). Then COBOL. Then Java. Then Perl. Then ActionScript. Then PHP. Then Javascript. Then Python. (no. I fucking skipped Ruby, and you should too). Then Lisp. I'm not even sure what I'm doing now is even a "language" (HCL). On the side, I'm kinda sorta learning Go now, but the Rust folks are selling it. I doubt I will have the opportunity to use either, professionally. Right now, when I need to do "real" coding, it ends up being some quick-n-dirty bash or python. What I learned, I used professionally at that time. Then moved on to something else. I don't remember 99% of most of it, 2 years later. My advice? Never. Stop. Learning.
+1
Can someone clarify the situation ? Is this always a proposal or is this now implemented and will be shipped with go 2 ?
I have to agree on Python. But the platforms really need to get their shit together and deprecate 2.x as the default. (both OS X and Linux. I can't comment about BSD. And Windows is irrelevant). It's long past time to move on to 3.x. It's a huge pain in the ass for noobs, having to deconflict 2.x and 3.x on the same system.
Todd McLeod runs a popular beginner's Go course at [greatercommons.org](https://greatercommons.org) that, in my perception, is indeed a programming course for complete beginners, as it features a full section on programming fundamentals (including a section titled "How Computers Work") and explains basic things like control flow from the ground up so that his audience needs no prior programming knowledge. &amp;#x200B; My own course (Master Go) focuses on students that already have a programming background, but only because I did not want to make my course four times as long as it is already now. (Why four times? Well, its length would easily double by including all the programming fundamentals, and double another time for having to be very repetitive because absolute programming beginners have no prior knowledge that the new knowledge can easily "snap on"). However, I see no reason for \*not\* using Go as a first programming language. &amp;#x200B; A student of mine took a similar route as you are considering - CS50 first, and Go second - and was very happy about that choice. ([Here](https://medium.com/@nahua/review-of-a-new-golang-course-master-go-4c4062a9265) is a review he wrote about my course, and yes, posting this link might here look like a shameless plug, but only because it is exactly that. If this is not appropriate for this subreddit I apologize, and I am happy to remove the link if the moderators advise me to do so.)
Good post and valid points. I'd just like object the statically / dynamically typed reasoning. I think types really help. And as an absolute beginner you start with int, string, bool and float64. Then slices of them. This is not complicated (even BASIC had typed variables) and helps getting the logic straight. So one more point in favour of Go.
Seriously. I don't need TRY
me neither!
I think Go is a very good language, but it has the downside of not being (easily) available to make browser code. So, I would probably start with TypeScript or JavaScript. Or python.
To the author ‚Äì do you plan to add unit tests, and have a security audit at some point in the future?
Yeah, your Kickstarter is very cool, but aren't you spamming a little bit the subreddit...?
I‚Äôd go with JavaScript first (though I find the whole Babel, Webpack etc. crap discouraging) because it‚Äôs simple and ubiquitous, then Python because it‚Äôs fun.
There is a proposal for error inspection that is [partially accepted](https://github.com/golang/go/issues/29934#issuecomment-489682919) for Go 1.13. The "try" functionality is a [proposal for Go 1.14](https://github.com/golang/go/issues/32437), so it is still time to raise your voice for or against it.
I'm open to a change in the way errors are handled, but I don't want try either.
ü§£ü§£ Love him.
Used to be off topic, but now it's spam.
Sorry, I'm just eager to share, and this was the only place I could find that shared this interest! I don't mean to be spammy, excitement got the better of me. Maybe I'm too much like Moss! ü§ì
/r/ITcrowd
Ok boomer
Totally off subject, but J'adore ton pseudo
I would really more prefer something like `a, b := f() or { return nil, err }`
Agreed, I think a lot of us have this ingrained aversion to repeating code - when you're constantly writing the same thing over and over again, it's usually a code smell and a sign that something needs abstracting/refactoring. That's the alarm that went off in my head when I started Go - but eventually you realise every error case is different, in real production code you'll be generating different messages to users, doing different cleanups and most functions tend to have only a couple of if err != nil { return nil, err } statements, which is totally fine.
Cannot agree more. I actually wonder what problem do they try to solve. I mean, those "error" values represent side effects from the outer world. And code what deals with these errors is 1. Ease. Error processing logic is really far from rocket science. Sophisticated logic works over already processed data. 2. Very important despite the ease. The faster we can realize what have happened the better. So careful diagnostic is always welcome. I have an impression they are solving the easiest problem at the cost of reduced diagnostic quality. Go's natural application domain rarely has complicated problems at all at the coding level, still I had a couple and a half of them and error processing was not a problem at all there. Lack of something like slice and map comprehension was an issue, so did lack of sum types. Damn, I even felt a lack of generics at times. But errors annotation work has always been rewarding.
the snake has eaten its tail
it's about performance. &amp;#x200B; sometimes, we just need a fixed length array, so prealloc enough space will avoid "append" causing reallocation for too many times, and this will get you a better performance. &amp;#x200B; so, make(\[\]int, 0) or make(\[\]int, 5) is according to your condition.
What are you gaining with it?
It _is_ possible to always start with a nil slice or a make([]int, 0) or a []int{} and append. But this is an ridiculous overkill if you know from start that your slice will have 3'421'978 elements: In that case it is a) much faster (less slice copying), b) uses less RAM (less slice growing) and c) much clearer. A similar argument is for make-ing maps: If you know you will store half a million elements: Why not start with a properly sized hashmap instead of growing and reorging the hashmap 15 times? For channels (the third thing you can construct with make) is different: It is simply _impossible_ to start with a nil chan and "append". And it is impossible to create a buffered channel without using make. All said: For slices it is _very_ common to start with a nil slice (`var s1 []int`) or an empty slice (`s2 := []int{}`) and append _unless_ the size of the slice is known and possibly large in which case you definitively should use the appropriate size or an appropriate cap. For channels there is no discussion: You need to make them.
This topic is something I'm struggling with so I really appreciate the article!
&gt; But this is an ridiculous overkill if you know from start that your slice will have 3'421'978 elements Then why should I use an slice instead of an array?
&lt;3
This is a good start to understand a declaration approach in Go: https://dave.cheney.net/practical-go/presentations/qcon-china.html#_use_a_consistent_declaration_style The rule of thumb: 1. Use `:=` by default, to declare a var and initialize it with a value 2. Use `var b bool` to declare a var to assign a value later 3. Use `make()` where it requires e.g. for channels `make(chan int, 2)` About slices, to make an empty one have to use `s1 := []int` or `var s1 []int` it depends on p1 and p2. So you do not need `make` function to declare an empty (zero-length) slice.
Agree. I don't need or want Try.
Yeah you're right . However, i solve examples by myself, so that i know more about Golang and i teach well.
I wouldn't mind it, but I'd hate it to be a magic function.
I'm sure you can come up with an answer to this question yourself. At least you should try.... If the size is a compile-time constant you can use an array. If the size is known but known only at runtime you cannot use an an array.
What worries me more than the syntatical taste issues is that try() does not allow wrapping errors with context about the function that failed (only the surrounding function). But that kind of wrapping is an important best practice IMO. So this will actually lead to worse error handling behavior unless you hammer it into people's heads that they should not use try() at all (at which point its addition to the language becomes almost pointless). See also https://twitter.com/juliusvolz/status/1145968806642225153
go at it.
Blockchain helps us to build [Diamond Open Market ](https://debourse.com/)‚Äî a decentralized blockchain-powered transparent marketplace indicating real supply and demand. The platform‚Äôs target audience is a wide community of individual holders, traders, jewellers, wholesalers, small-scale producers around the world. Every market participant will be able to sell and buy natural or lab-grown diamonds, paying by fiat or cryptocurrency and using a convenient search system. Diamond Open Market will change the rules diamond industry lived to this day and bring new opportunities for every party.
You can go even broader here! make([]int, 5) gives you an array with size 5, that you can use as arr := make([]int, 5) arr[0] = 0 arr[1] = 1 .. You can also do make([]int, 0, 5), which sets your array to size 0 but initialises the backing array to size 5. This means you can do the following without reallocations: arr := make([]int, 0, 5) arr = append(arr, 0) arr = append(arr, 1) .. Only after the 6th append will the backing array need to be expanded and reallocated!
I kinda like this but it makes code less readable.
You will make all programming languages look the same. Just look at the features that are being added to every single language. Lambdas in java, ES6 in JavaScript making it look like Java,... You want every programming language to have all of the cool features of other languages and if you keep it that way, it will converge to a single language. I like go because of its simplicity and its different approach. If you don't like it, use a different tool. There is probably a good reason why they didn't accept the try in the first proposal so please, stop looking how different languages solves their problem and concentrate on how the problem should be solved... Look at how web dev is different in Go and other languages. That is its beauty and don't take it away.
I'm against. For slightly unexpected things in Java or C# I used to just slap an exception handler around a whole tranche of things and log it. But now I actually deal with errors properly. Initially I didn't like it but my code is now much better.
Yeah exactly, Go is far from being a terse or beautiful language, it's utilitarian and that's why most of us like it haha. If we're getting cute with try() etc, why not add kwargs and a boat load of other things, that would help us cut down on the \~6+ ways to provide "options" to constructors, but for some reason that's not on the radar.
hahahha good one, though I think he is zoomer...
WK should post that to the ML, not on some random blog the Go Team possibly never heard of.
&gt;Most Go positions require some type of DevOps experience with it. That's not really true. Maybe at small startups where you need to do everything. Definitely not related to Go.
+1 for statically typed language Prevents loads of errors and makes you understand what is actually going on (which sets you up better for future). But python is great otherwise, and virtually everything is better than languages like php or javascript.
Hi. Not the author but I'm curious: You mean hire a security specialist to audit or is there a tool (or tools) that help evaluate flaws in software? If its the latter, please share!
Thanks, what is the best option to raise my voice against it ? Commenting the issue on GH ?
Thanks! Some good points raised.
Try is a cancer in the dev world. Anyone advocating for it needs to go to chemo.
oh wait, you *are* the fasthttp guy!
Fuck it, why not? Pick any language you want and code. Don't listen to people that say it better to learn this or that. Just fucking code. That's all you have to do.
I started off strongly disagreeing with you and was about to Google for the classic Go error wrapping example to prove how wrong you are, but then remembered how often I rely on a simple stack trace in languages like C# and Python to tell me what line my errors originated and you know what - you‚Äôre probably right. Try is a glorified GOTO but the built in sugar makes it worth it because, quite simply, we spend more time debugging than most other coding activities, so anything that makes that more efficient is a worthwhile compromise. Hat tip.
Pointers are bad when you can do pointer arithmetic. Go doesn't have that kind of pointer. (Barring unsafe, of course.) I wish they'd have been called "references" instead of pointers, precisely to avoid this problem.
&gt; You will make all programming languages look the same. Just look at the features that are being added to every single language. Lambdas in java, ES6 in JavaScript making it look like Java,... What you are framing as feature copying, I think of as facilitating common coding concepts. Python doesn‚Äôt need to have the same multiline lambda syntax as JavaScript to have the important concept of anonymous inline functions represented in some way. Generics and Try/catch are common coding concepts. When what is commonly done in other languages isn‚Äôt available, you have to learn the correct idioms for the substitutions, and that‚Äôs where we spend a lot of calories judging whether those substitutions are ‚Äúbetter‚Äù. I like Go too, but not because of all the non-typical things it does - and it does a lot of them seemingly just to be different. Like putting names before types instead of after, or using return types for errors, or calling them runes instead of character types, or whatever else. Those are all distractions that cause endless hours of digital ink spilled, the same as Python did with not including an ‚Äòend‚Äô keyword and making white space part of the language. For me, it comes down to whether idiomatic Go makes me productive solving the problems I need to solve. With error codes instead of try, it‚Äôs a big yes for me. With generics, the balance tops the other way.
Yeah, you could point to the relevant source line with a stack trace like this: https://play.golang.org/p/EI2beJk2ZyQ But that's often a bit much, and I want to be able to provide a human-readable prefix to the error to explain which sub-call went wrong.
It should be that simple, yes. What is your specific question? Did you follow those steps and find success or failure? If so, how did it fail? What did you expect it to do, and what did it actually do?
It worked fine, but it is so simple that it almost seems that I don't understand it completely or missing something important.
"Errors" or what we consider errors are arbitrary. It's an error if WE, humans decide it is. The `err != nil` construct gives you a value, from which YOU decide whether it's what you want or not. The "try" construct is magical, I never know what it does under the covers and I always felt like it's a way of sweeping the dirt under the carpet. Please don't add a new error handling construct when this one works perfectly fine, just so (a minority of vocal) developers can type 3 keystrokes less
Yeah, I know about debug.PrintTrace. In reality no one does that until after there‚Äôs already problem or there‚Äôs a hot spot for prior problems. It‚Äôs forcing humans to do stuff that the machine should do. It‚Äôs why I begrudgingly admit that error handling in other languages has some worthwhile concepts that Go lacks.
It's a large project worked on by an even larger company, throwing vast resources at making it Just Work. That's the point of a library; you write to the API and you don't concern yourself with how it does what it does (at least for the purposes of your task at hand). That said, if you want to hack on the grpc library itself, please ask a specific question. As far as user support goes, if it worked fine, it sounds like, as a consumer of the library, you did indeed figure it out. Don't worry about understanding the autogenerated code.
So, are you saying that you add context to all of the errors you encounter? Maybe most of them? Because otherwise the codebase is filled with statements just checking if error is nil and returning it.
Okay, thanks a lot!
well then
Sorry I couldn't give you a more satisfying answer; you are indeed not understanding it completely until you read the source of the library (and any of its large dependencies) to know precisely how it does what it does. This will probably take a bit of time and effort, and a lot of the choices won't be immediately apparent as this was borne out o Real World Pain faced by a large organization running eleventy-zillion services at scale in production. RPC is a complex beast with a bunch of different bottlenecks and failure modes, and an RPC library crystallizes a bunch of engineering trade-offs and wisdom and failure modes together. Reading the full source of the grpc library will definitely teach you a thing or two (both about grpc and about life), I would assume.
Oh the answer you gave is fine. It means that I can continue with a project of mine without studying the deep internals of grpc. But maybe I'll do that this summer, got plenty of time.
If the board is green, ship it, friend.
There‚Äôs no difference, I didn‚Äôt know about the populating term
I know what you mean. I think it‚Äôs because in other languages there are more dominant frameworks
Do, or do not. There is no `try()`.
‚ÄúYou have to learn the correct idioms for the substitution‚Äù This incorrect reasoning is why languages are converging like the original commenter said. Some languages use completely different paradigms that include concepts that are not present in languages of a different paradigm. For example some pure functional languages provide a no runtime exceptions guarantee. In a language like that you do not have to ‚Äúlearn idioms for the substitution‚Äù of try...catch as it is simply not a concern.
Just for completion if somebody wants to start go after the above post. You can write GUI Programms in go actually, nearly the same way as in python(as in, python also has QT bindings). There is the andlabs GUI and bindings to QT: [https://github.com/andlabs/ui](https://github.com/andlabs/ui) [https://github.com/therecipe/qt](https://github.com/therecipe/qt)
Maybe this will help the try() people out: ``` "If Error": { "prefix": "e", "body": [ "if err != nil {", " $0", "}" ] }, ```
lmao
A large part of the reason I like go is the beauty of error handling... Please don't take that away...
As a person who is not from "anti-try" movement, I actually want to try the "try" (haha) and see how it turns out. But still, I disagree a bit with you: 1. Try is just a syntax sugar for returning from a function. You can avoid using it. 2. You can still augment error with context in a deferred function, which do execute on function return and they even keep the stack trace of where function return initiated from. The downside here of course is that to do so, you'll have to use named return values, but also it makes the whole "try" change easier to implement. Feature is very non-intrusive due to that. 3. I don't think "try" breaks anything, I see a plenty of libs that just do if err != nil { return err }. Let's just try the "try". In fact I see some interesting ways to provide the context using try function, e.g. func foo() (err error) { var ectx ErrContext defer addContext(&amp;ectx, &amp;err) // if err != nil, will augment error with context ectx = ConnectToSQLDBErrContext{} sqlDB := try(connectToSQLDB()) ectx = ConnectToRedisErrContext{} redisHandle := try(connectToRedis()) // do some stuff } Yes, it looks a bit questionable having a variable like that, but again, let's try the damn "try". It might work in practice...
I like how it is now, I don't know why it needs to change.
Couldnt agree more, and one could even say that it is beautiful in it's own way because of its utilitarianism.
Totally agree on this with @DeusOtiosus. I also encourage the open letter about error handling wrote by Bill Kennedy earlier today which you can find at his twitter profile: [https://twitter.com/goinggodotnet/status/1145887636609015809](https://twitter.com/goinggodotnet/status/1145887636609015809) &amp;#x200B; I know that Go Community and some of its Auhors are taking bias actions based on some opinions and polls for a long time now but I have to confess that I never expected a solution like this for a problem like that. Really dissapointed but we can't give up our hope, I strongly believe Go Authors will see the whole picture eventually and give us a more safe and complete solution to error handling and wrapping. That's all.
I cannot recall what they are right now. I came across them while reading the documentations. I'll get back to you if I come across them again.
Comparing functional and procedural languages was not what I was talking about at all. You purposely mischaracterized my argument to make your own point.
Everywhere I've worked that's standard practice. Conversation goes something like: "What happened to XYZ?" "Oh, it had an error and we logged it. What action should we take in the future?" It's the same story in Gov work, Wall St., medical, etc.
True, both are great. I've personally used `therecipe/qt` and except for the license (LGPL is not really suitable for my job), it's really nice. When I said the GUI programming in Go is limited, it's not because the lack of package. I said it more because of the IDE support, specifically the autocomplete support. Right now all GUI package in Go (except [Goki](https://github.com/goki/gi) maybe) uses `cgo`. Unfortunately, there is a bug in [`go/packages`](https://github.com/golang/go/issues/32821) that make `gocode` and `gopls` uses the entire CPU when processing cgo project, which in turn makes autocomplete fail. So, when I'm working on GUI project back then, I have to use lot of snippets instead of autocomplete, which is not really fun. Hopefully that bug will be fixed soon.
Completely agree. I could get behind an error handling proposal that didn't solve it half-heartedly but instead provided a full solution. I find the reasoning that this is easiest to add to the language because it is just a built-in very strange. It'll impact the language in very significant ways for decades to come. I don't think it should matter if a proposal can be implemented easily with existing constructs or if new constructs are needed. The price we'll pay is too much in comparison. If a proposal demands adding new constructs but actually provides a full solution that doesn't split code-bases in two styles of error handling, then we should pay the price of adding those new constructs. &amp;#x200B; I very strongly believe that Go or any language shouldn't be designed by the masses and a small group of people should be in charge but this change just doesn't do it for me. I tried to imagine very hard to use \`try()\` and also tried the \`tryhard\` program on my codebases but couldn't justify using try either way. I find it really annoying to imagine codebases having two styles of error handling based on whether they add context to errors or not. &amp;#x200B; When discussing other proposals, it was brought up that errors are just values and shouldn't need special constructs like \`try ... else\` but I don't see how \`try()\` as a function is not something very special just for errors. &amp;#x200B; The idea of having error handling code (with defer) not near where the error are actually handled also baffles me. &amp;#x200B; If handling mechanism is added to the try function at a later stage, I still think it'll be inferior to the original \`check + handle\`, the \`try ... else\` counter proposal and the current state of error handling. &amp;#x200B; Another thing I can't come to terms with is that it was proposed that \`try()\` will be implemented as a experiment so people can try to use it and decide if they like it. However, we won't have experimental implementations for other proposals like \`try ... else\` so people will only be able to compare it with existing \`if err != nil\`. This point is not a criticism of the Go team. They are not obliged to implement proposals from the community and it would be unfair to expect that of them. &amp;#x200B; That said, I still feel that we'll miss out on the best possible way of handling errors if \`try()\` is accepted. It feels like the bare minimum to reduce boilerplate in roughly 50% of the cases and that makes me very sad :(
Yes but I'd suggest to not just add a "me too" comment. Best thing people can do IMO is to provide data-driver arguments. May be write small scripts to analyze existing public and private Go code and share insights from that.
I think it's as good as accepted. The proposal received a lot of criticism and negative feedback. Go team's answer to that was to implement it as an experimental feature (like any other proposal) so people can play with it in 1.13 and then give their feedback. That is very fair IMO but I don't see it changing anything. \`try()\` as proposed is not hard to imagine to use or even update existing code to see what it looks like. I doubt people will find any additional insight after the proposal is implemented. I think it'll have the same amount of supporters and detractors given how simple it is to understand and form an opinion on, and that tells me it'll most probably be accepted eventually.
The last two Go development jobs I've had, both for Fortune 500 companies, required experience in the cloud platform (mainly GCP and/or AWS), Docker, and Kubernetes experience. Though no mention of Swagger during the hiring process, Swagger was also used extensively at both. There are a lot of companies around where I live hiring Go devs (Toyota, Capital One, CBRE, etc.) in the Dallas/Ft. Worth area all requiring the same.
&gt; You can still augment error with context in a deferred function Yeah, you could use `debug.Stack()` to add full stack context, but that's quite heavy and not useful for the average user of a program. I really just want to prepend a human-readable string prefix that immediately tells a user what went wrong, like "creating /foo/bar failed: permission denied".
Do. Or do not. There is no try.
Probably, Go is not a good choice for first language :https://www.reddit.com/r/golang/comments/8j04nh/is_go_a_good_first_language/dyvxiiu?utm_source=share&amp;utm_medium=web2x
You're welcome to keep using Go 1 or the old error handling.
The fact that I need to attach metadata manually instead of relying on a stack trace is killing me. Sometimes you want to explicitly attack metadata, that's cool. But please let's have an automatic way of knowing where the error originates from without tons of boilerplate and copy-pasting.
1. Some variants of BASIC had pointers too. You can learn a shitload of programming in Go without touching pointers. Like lots of people did when learning BASIC. Your code might not be elegant and fast but it works. If your argument would be true nobody ever would be able to learn programming with C. And: Ignoring how a computer actually works is not really helpful. 2. I think this argument is very wrong. FORTRAN has no semicolons, Python has none, Pascal uses semicolons a separators (instead of terminator), Lisp is totally different. Just because C++ and Java and C# promote a certain object model does not mean this disqualifies Go. Lots of languages have similliar object models Pascal, FORTRAN77, C. "Type identifiers come after the variable names." of course! This is normal! See Pascal and Haskell (albeit not the type annotation). The C variant is the unnatural one. If you ever tried to explain the spiral rule to anyone new to programming you would agree.
I do add context to all errors, otherwise it's impossible to know where they came from.
&gt; classic object oriented languages ... are a major part of the problem space.
If you take it a step further and apply optimizations, you might see potential for concurrency here. If you did a cost/benefit analysis of spawning multiple goroutines, you might be able to send some of the analysis work out to be done in parallel. I think because all the work needs to be done, results need to be aggregated, and none of the analysis of the pixels needs to be done sequentially (aka no blocking dependencies from you picking any random pixels to analyze in the same grid), you might find huge time savings. After doing some cost/benefit analysis, you might find that it‚Äôs only worth it to spawn another goroutine per million pixels or something. You could also find where the numbers are that you get the highest level of benefit for the least amount of cost. Then you could do the same for Rust and find where it‚Äôs tipping point is, and write back with a follow up report. Sorry Python, this time you‚Äôre out :(
Errors are so badly designed in Go that nobody does anything useful with "context", and if they attempt anything at all they do if err != nil { return errors.New("doing the thing: " + err.Error()) } which puts you directly into a world of puzzling things out from strings, and discards any *real* context or identity from the original error. Maybe if it had been done better from the beginning, but as it is, if you want any kind of robust error handling you need to write a very substantial amount of machinery yourself, and I doubt that as many as 5% of Go devs know how to do it correctly.
Swagger is not really Ops. But I agree that Docker is common, though I would again argue that it's not specific to Go. Anything more advanced (GCP/AWS/Kubernetes), I haven't had the "luck" I guess, I've only seen these at a few small companies. Though I do not scan available jobs that much. Either way, I don't think it's specific to Go, but I can see how stuff like Docker could be more prevalent there with the focus on microservices as opposed to heavy apps from (for example) Java world.
[removed]
Honestly, this sounds like a symptom of some kind... Surely if we're adding context *everywhere*, all the time, then something is wrong? For example, this is why exceptions tend to carry stack traces in other languages. I know Go considers that too heavy, but is it really heavier than having massively nested error interfaces? And maybe there's a different solution than stack traces, but regardless we should recognize it as a problem. What if `try` allowed you to optionally `errors.Wrap` with a string, somewhat similar to Python's assert? So it would be `try(expr, "Error on %v", x)`, for example?
Make sure it's not just a reiteration of something already noted: https://swtch.com/try.html https://github.com/golang/proposal/blob/master/design/32437-try-builtin.md#faq
am grateful for this comment :)
Thank you all for commenting I have read through everything and I appreciate all the help! My reason that I have interest in Golang is because a good friend of mine (who is pretty famous in the crypto space), said that he can hire me instandly if I can program in Rust, Golang or Solidity. &amp;#x200B; I have 0 programming experience, and studied Tax Law till now. But I'm really motivated to start learning programming, especially that I now have 2 months of free time (summer vacation). A lot of people in this thread recommended me Python, with good arguments. Thanks again for the tips guys. I will give myself three more days to choose my first programming language!
Thanks for the help, that worked out!
[removed]
For Python, you might be able to use multiprocessing. Or you could use, for example, Numba or PyCUDA and dump it on the GPU, probably beating out the goroutine version.
I have started to now that I have xerrors. Maybe not everywhere, but certainly in a lot of places.
Yea putting it everywhere is definitely too much. But it‚Äôs not good in a lot of cases, especially if I am making a library for someone to consume. I wouldn‚Äôt like that syntax for try either. I can only imagine how gross it would look with too many arguments.
I do see a bunch of libraries that just return the error, yes. But that‚Äôs the errors issue I think that needs to be solved. Xerrors is pretty new and not widely adopted. To me, wrapping errors to add context in a lot of places is where we need to get to. Right now, the best thing to do was generally just float up the error without context because losing the base context is certainly worse. The additional defer seems to me like it would eliminate the benefit of try by making the code extremely fuzzy, instead of clear what the code always does.
A first class xerrors would be a dream; one that you could just: return .., xerrors.Stack(err) Or something similar, that attaches the stack from the beginning of the error. Stack traces are really bad for user end things, but in a debugging flow they‚Äôre great.
"In Go‚Äôs history, once things are introduced as experimental they are never rolled back." This is technically not true. Part of the error inspection proposal for 1.13 was rolled back. We haven't had a lot of time in the current proposal process for there to have been many more examples than that; before this, only accepted features were really even implemented. I'm skeptical but I'm willing to rework some of my packages with try+HandleErrorf and see how I feel about it.
Agreed! Have you looked at xerrors yet? It‚Äôs basically exactly the fix for this. You can wrap errors all the way up which lets your consumer detect the levels of errors. It‚Äôs not perfect, by any stretch, but it‚Äôs a step in the right direction. My hope is it gets turned into a first class library to replace ‚Äúerrors‚Äù as a first class library, and I believe that‚Äôs the hope for it in general, IF people use it.
The question in the Go Survey that people are commonly referencing was: "What is the biggest challenge **you personally face** using Go today?" So it wasn't asking people what they thought they would like changing or improving about Go, it was asking people what aspect of Go they found challenging to work with. Error handling ranked fifth, having received just 5% of the votes - so with 5883 respondents to the survey, that means that ONLY approx 294 individuals decided it was an issue. It certainly doesn't rank highly and certainly wasn't overwhelmingly condemned.
But it's not good üòï. It's probably the weakest part of the language imho. Try doesn't help either tbh. What I don't understand is why not improve upon exceptions from other languages.
Yes there are definitely bigger fish to fry for sure. I think the survey ultimately removed context from it, hence seeing things like ‚Äútry‚Äù. I also don‚Äôt think that only 5% think error handling is an issue, but instead, only 5% think it‚Äôs the ‚Äúbiggest‚Äù issue. That could mean 100% think error handling is an issue BUT 95% think there are other issues that are more pressing. It could just mean 5% in total think it‚Äôs an issue, but I suspect it‚Äôs higher. Hard to say with the data available. Either way, try is diametrically opposed to problem I have with the current state of errors. That is to say, it‚Äôs not only going to keep the stats quo of poor errors, but potentially make it worse when we have tools like xerrors to make error handling better.
[removed]
Don't blame you doing it wrong on Go. Hint: https://golang.org/pkg/os/#PathError
A good logger offers the best of both worlds. When u want log output it tells you where it came from and when u want to know where an error occured it allows you to add context. In production just set the log level and you're good to go...
Fair point. But I still think the syntax around pointers is too much cognitive load for new developers. If you are still struggling with loops, knowing when to define a method on a pointer to a struct vs a struct literal can be daunting, and frankly, a waste of time (at that point in the learning process). &gt; I wish they'd have been called "references" instead of pointers Agreed. &gt; don't think there's any language that could survive your definition of "weird" Maybe. But I think Pythons syntax makes a bit more sense (once you get past the whole `self` as the first parameter). Anyways, those are just the opinions of some stranger on the internet. Take them for what you will.
&gt; Ignoring how a computer actually works is not really helpful. You aren't the first person to make this argument. But, I think it's a red herring. If it wasn't, then the first thing you should teach a new programmer is basic electronics. You can get well past the "intro to programming" phase before you need to know that a register even exists, or how memory is accessed. re: #2, I'm not sure I made my point well there. I probably should have said it was different enough from other **main stream** languages. The point being that if you google for how to do something, you will more often than not find examples in either python or a c-syntax style language. But, I will concede that this is a weak point.
It's crazy people care this much about a programming language mascot
Go 1.13 should be released in about a month, so I decided to post it.
&gt; But the platforms really need to get their shit together and deprecate 2.x as the default Agreed. It should be coming soon since 2.x is EOL the end of this year (it *only* took 11 years!). I remember hearing something about the next version of OsX not shipping with python at all.
[removed]
What kind of programs are you making in Go? Command line tools? If so, sure, your perspective makes sense. For those of us making services in a web environment, stack traces are exactly what we need. The common user never sees the errors.
Finally, someone who actually admits that Go error handling is the worst. Since the hubbub started over try() I've seen nothing but people saying that Go error handling is great as is. This is my take from another thread: &gt;in the vast majority of cases, the right thing is just to return from the function with the error, perhaps wrapping the error first to give context. You know what that is? That's a manual stack trace. Yes, in the vast majority of cases, throwing an exception and allowing it to bubble up is the appropriate behavior. And funny thing, in many other languages, including python, that is the default behavior for an error. &gt;Somehow, many Go developers have acquired Stockholm Syndrome and actually laud the worst "feature" of the language. Try is a step in the right direction. The context issue should be solved separately, by implementing stack traces like should have been done from day 1. Add stack traces to the errors from errors.New().
That's not how it works.... You should propagate errors and log at the highest level possible instead of logging all errors everywhere because you will end up with errors logged multiple times.
I just want something like Rust's `?`, so I can do something like this: func canError(arg interface{}) (interface{}, error) ... val := canError(arg).WrapErr("context %v", arg).Stack()? This would either return early from the function by adding context to the error message and optionally adding a stack trace (you can certainly include such things in a custom error type). Ideally, a stack trace would only be added once, and future attempts would merely do nothing. Rust's error handling doesn't do the above (except the `?`), but the type system allows this behavior (see [error-chain](https://github.com/rust-lang-nursery/error-chain) or [failure](https://github.com/rust-lang-nursery/failure)). In fact, error handling and mutexes are the two reasons I want generics in Go because I like how they're used in Rust. I agree that the `try` proposal (I assume you're talking about [this](https://github.com/golang/proposal/blob/master/design/32437-try-builtin.md)) _could_ be harmful, but if it had some way to add context and/or a stacktrace, I think it could work out.
It depends. I would benefit from both the original `if err != nil` statement and `try`. Personally I like the if-statement if I want to either take a lower level error from a different package and turn it into a higher level one that my app can expect, or if I need to add explicit context or do other special handling that might examine if the error can allow the function to continue. However, there are a myriad of cases where I organize code into small functional units where errors are not really necessary to have context with and only need to tell the higher order functions that *something* happened. In the latter case, `try` is a godsend as it clearly denotes I'm okay with scrubbing the error context, which in many cases is acceptable for very low-level functionality. And it is very nice to read as well (imo). the case I'm thinking of would apply more to something like a lower-level function that does something like func getIntegerPlus5 (someString string) (int, err) { return try(strconv.Atoi(someString)) + 5 } Obviously this example is contrived, but the syntactic sugar is pretty nice imo and I don't much care to add context to this kind of error. Just knowing the error occurred is enough for the higher order function to handle and of course chaining is easier with try as well. I see the downsides and understand the fears, but personally I'm a yes for it. Just my 0.02
the go pluging for intellij no longer works sadly &amp;#x200B; [https://blog.jetbrains.com/blog/2017/12/01/clarification-on-go-support-plugin-availability-in-intellij-based-ides/](https://blog.jetbrains.com/blog/2017/12/01/clarification-on-go-support-plugin-availability-in-intellij-based-ides/)
[removed]
An example of the fan-out pattern with one of our project - any feedback welcome :)
[removed]
Right, u mean in packages out of your control... I propogate the error message back to where I control it and then log it, but I see the issue people mean now. For that I use a debugger to follow it up the stack.
```if crash() { DoNot() }
&gt; 294 I was one of these 294 individuals. But the thing I am dissatisfied with with Go's error handling is not verbosity: I needed stricter type checking. [`errcheck`](https://github.com/kisielk/errcheck) and similar Goland inspection basically solves this for a new code. I would love to see mandatory handling similar of what Rust have but with imperative feeling Go always was so good in. `try` is not solving anything I would love to be improved. I bet this will give me some more work as lazy juniors will be using it whenever possible to reduce their work.
But I really do want the ternary operator :)
I'm on this boat with you!
Yeah a debugger is something we all use. However on that cryptic once in 6 hours in production error a debugger won't help, only good logs.
Can you give examples of code or packages to help do it correctly.
Personally, I like having both. Detailed context primes you with what the code is supposed to do and the stack trace gives you the exact lines where the problem exists.
You're right. Just today I got dumped in the lap "Could not parse". Alright ... could not parse what? Luckily I could `grep` my way towards the culprit. Backtraces would have helped better. It's also great for debugging: the generic error handler can wind up the stack and collect local variables. If you can do it in PHP, it's a real shame for Go, nro?
In my experience, that's all you can do. Most of those errors outside of dev consist of some network resource being down. Nothing to do then other than to log it and return an error. In the cases where you can do something, (i.e. use a local cache), then you explicitly code for that.
Very often there are things you can do if you consider them during coding/design. Like retrying network connections, using an alternate destination, etc. With Go, I've been considering them more instead of just bubbling them up to a generic catch-all logger. At first, I didn't like wasting effort on that, but I've changed my opinion on that: it's not a waste, it's part of the final deliverable.
Indeed. This is why I made the post. Go error handling is bad, but it‚Äôs not because of the syntax. Sure, it‚Äôs kinda ugly, but it‚Äôs also that way to force you to actually handle the error instead of passing it along. Bubbling up some context is super helpful. Sure, a stack trace is useful for us as developers , but for the end user, not so much. Instead, if developers are able to control the trace by wrapping it at appropriate points would be helpful for both the developer and the end user. I would personally like to see a better syntax for error introspection. Xerrors is starting that but it‚Äôs not great yet.
Maybe, maybe not. If we‚Äôre bringing in hardware and 3p libs, gorgonia/cu can help offload work to a GPU for Go. I‚Äôm not a rust person myself, but it looks like at a surface level there‚Äôs not much out there yet that‚Äôs mature for them. As for setting the number of goroutines to be limited to gomaxprocs, this is only partially decent advice, some of the time. There‚Äôs a ton of articles out there on the constraints and decisions surrounding setting your gomaxprocs, but the jist of it boils down to this: - A goroutine is not a thread - One or more goroutines can be scheduled into a thread - A thread (and the amount of them in your program‚Äôs execution) is set by GOMAXPROCS by default, but this can be edited - A thread, or any count of threads, are not bound to a specific virtual cpu core. If one blocks, some can be moved, though only one thread is ever executing per core at any point in time. Again - a cost/benefit analysis on performance and necessity is completely necessary to understand the sweet spot for maximized and efficient full hardware usage. It may turn out that a billion comparisons is the break even point for a new goroutine, or maybe a million, or maybe some other amount. And because we can have multiple goroutines scheduled per thread which may or may not be 1:1 with our GOMAXPROCS which does not have to be the full amount of cores a system has, we have a ton of moving parts. My suggestion would be to profile the whole thing, and see how much it ‚Äúcosts‚Äù in resources (cpu, mem, time) to do each individual step (new thread, new goroutine, loading the images, pixel-by-pixel comparison, distribution of work, etc) This is what optimization is all about, finding that balance. üòä
Is there a framework or toolset that you use to build your ETL jobs?
The fact that it forces you to handle the error instead of pass it along is exactly what is wrong with Go error handling. Passing it along is usually the right thing to do. That argument is like saying c is superior because not having garbage collection forces you to clean up after yourself.
I would disagree to an extent. It should pass the original error up if it can‚Äôt handle it, but it should also add some context. Blindly passing an error up is really bad as it robs you of context. Even a stack trace isn‚Äôt going to do that. Showing that the error was nested in an obscure function doesn‚Äôt help a consumer of the error at all. But letting a library writer add context to the error to let the user/developer know what it was doing in a more usable way and actionable way, is far better. Hence xerrors over try.
Your final conclusion, about Go being a language that's hard to create monstrosities in, is exactly what interests me about the language. I've worked on many huge codebases that have finally collapsed under their own weight, and we're just starting to move to Go. At first, not being 'clever' was a bit upsetting, because I'd gotten used to weighing my solution by how clever it was. Now that we're starting to see extremely high-performing replacements for our 'clever' code, I'm realizing nothing I thought I was doing well was having any benefit. I replaced thousands of lines, and carefully designed object architecture with 1/10th the code that performs 10 times faster! There's really no argument when it comes to maintainability either, since the go codebase is so much smaller, and so much easier to understand. I really hope Go doesn't go the way of so many languages and slowly become more complex, until it loses its charm.
Mostly prometheus.io, which is a command-line-run server, yeah.
I disagree with the wrapping statement. I would say 9/10 times I don't wrap the error and just return it up the trace. Usually errors are only logged or acted upon once, so only at that top level do you need to do some kind of wrap or format of the original error.
Once I found a small mistake in the examples in README file, I fixed it and opened a PR without opening an issue. The change I suggested was reviewed and merged into master in minutes. So yes, they are looking after this beautiful library which make things much easier for the devs...
It's also worth noting that 9% of the survey noted differences from familiar languages/ecosystems add an issue and only 5% found error handling an issue. This looks like the problems with error handling are a result of people simply being used to try() in other languages. I've yet to find a situation that the current error handling isn't capable of solving in a clean readable way. I can say the same for try() though. Please, please, please don't go down the try() path.
Yes! I was looking something to test myself on but I had no idea about this site. Thanks for sharing it...
I really don't see what problem try() would solve that didn't already have a clear solution.
If `try` allowed wrapping I'd be fine with it. As proposed, it's useless to me.
Start time: 9:00 pm Central European Summer Time
i and j are the indexes of two elements to be sorted and your function needs to decide the order of those two elements (whether they're equal, greater or less than each other). The Go default library calls your function multiple times so it can decide how to sort the entire array, according to its sorting algorithm (which we shouldn't care about exactly). So you just need to assume that the i and j are some indexes from your array, and they're called when the default library needs to know the order of those elements. That makes it easy for us to sort a slice without caring about the underlying sorting algorithm - just how to sort two any elements at a time
&gt; a small mistake in the examples in README file What does this say about the state of a project if someone finds that PR offensive, or in need of further discussion before resolving?
Thread from Russ Cox: [https://twitter.com/\_rsc/status/1146128393542492160](https://twitter.com/_rsc/status/1146128393542492160)
Not really, I mean I'm absolutely fine with how the errors are handled in Go. But sometimes I open a go file and all I see is a wall of if err if err. So all I actually need is making such pieces of code more readable
I am not really sure what are you asking or what did you find offensive in that comment.