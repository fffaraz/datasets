Nice! I've used goxc but typically develop and test on OSX and deploy on OSX or Windows. I just end up doing it manually because I need to be on Windows to deploy anyway.
must pay well
http://godoc.org/code.google.com/p/go.tools/cmd/goimports &gt; Command goimports updates your Go import lines, adding missing ones and removing unreferenced ones.
The more I work with Go, the more I realize the vision. For instance, I can "go get" any package and read over code as if I wrote it. That is the beauty of it. It's clean and well spoken.
It's like gofmt, except it also adds/removes imports as needed to prevent compiler errors. http://godoc.org/code.google.com/p/go.tools/cmd/goimports
And there are tools, that can help you with the tedious part, like this one here: http://mholt.github.io/json-to-go/
Yeah, looking back at it now that I have it set in stone, I did some things that were not exactly the best for performance, but hey, it's a mousepad not a production server :D
During dev I just have a bash file that walks every folder in the project and builds it and quits if any of them fails. If it's successful the bash script goes on to run the program. 
Ooooh, this looks pretty awesome. Thanks! Any word if this has been outright rejected for merging upstream?
Ooooh, this looks pretty awesome. Thanks! Any word if this has been outright rejected for merging upstream?
Is the badge supposed to link to the `.com` or `.org` domain? The `.com` links to some sort of empty e-commerce site ...
If I understand this correctly people will then come and look over your code for you? That is fucking amazing. I've never heard of anything like this before.
cgo and reflection in a tracing package? What is the impact on performance? Also, the AppNeta stuff is "open source" only insofar as you agree to their proprietary "open source" license.
Looks great. Does this library have support for json encoded data? 
I don't think there's a service for this, but it would be REALLY cool if that site would track referrers so we could go help out new users. Please make!
And you aren't checking errors.
Sadly I'm a baby myself :(
&gt; I find the code I write in Go tends to be much more error free than in other languages I second this. I'm not sure why, but I've had more features (~100s of lines) work on the first try in Go than any other language. Interestingly, they don't always compile the first time, but once they compile they do seem to work.
thats the sign of a very smart compiler and coding conventions that make sure your code is doing what you would think it should do when reading it, right?
Afaik, Goroutines won't stop when function return, right? In Killable, I don't see the actual "kill" of the fn function, so when you send the kill signal, the Killable function will stop, but the gorountine contains the function won't. Can someone explain this further to me?
Right. And there's probably a good deal of subjectivity to it - the language paradigms that Go uses (channels for concurrency, slices for array manipulation, etc) map really well onto how I think about problems. I don't think I'm alone in that regard.
I would agree with you, but the thing that meshes with me the most is interfaces
Francesc said he just had it printed and that the phrase "go t.shirt()" is of course not copyrighted. Any local t-shirt shop should be able to make one for you. ( source: https://groups.google.com/d/msg/golang-nuts/8uo73enuXwY/0Ug2XErTvD4J ) 
Awesome, thanks 
I bet gofmt helps so much in this sense - remember that you spend much more time reading code, including your own, than writing it. As a tool, gofmt basically tells you: "Writing in a proper consistent style that gets out of your way? Don't worry, you don't need to learn how to do it, or remember to stick with it, just learn how to read it."
This library is modeled after the `encoding/json` package, but is designed to handle `x-www-form-urlencoded` data, so the two complement each other.
I wrote this package because I had a fair amount of code like this: func setup() error { if err := setupThing1(); err != nil { return err } if err := setupThing2(); err != nil { return err } } but in my case, setupThing1() and setupThing2() were independent and I could speed up startup time by running them concurrently. Still, I wanted my setup() function to return an error if any of them encountered a problem. Using multierror helps with this: func setup() error { ch := make(chan error) go func() { ch &lt;- setupThing1() }() go func() { ch &lt;- setupThing2() }() var e multierror.Errors if err := &lt;-ch; err != nil { e = append(e, err) } if err := &lt;-ch; err != nil { e = append(e, err) } return e.Err() }
I created a similar type in https://github.com/dgryski/go-shardedkv/blob/master/storage/replica/replica.go#L28 , but never thought to bundle it separately. My use case was the same as yours -- querying multiple replicas in parallel for data, and wanting to report back to the caller only a single error which they could introspect if they wanted more detail. 
Nice idea for cheatsheets, actually!
Nice! I created a similar package: http://godoc.org/github.com/augustoroman/multierror One thing that I've found very useful is a Push(e error) method on the type that ignores nil errors, and a Pushf(...).
That's a great idea, thanks. I noticed in your implementation that you return a private _error type when you call Error() on the main type. I had done this in an earlier iteration but decided to expose two public types so that the caller could type switch to get the MultiError. If you use an internal type for that, users can't do that.
Good point. I like your approach of having separate types, I might switch over to that. I had originally put that in because appending a nil error ruins the nil-ness of the returned object. Since that object itself implements the Error interface, I didn't want someone to accidentally return a list of nil errors and fail on that, but with Push and Pushf I never manually append and the risk is very low.
That inspired me to make [this shirt](http://i.imgur.com/rlduAd3.jpg) which I'll use on GopherCon Denver!
Wow, that's clean. I tend to forget the useful and powerful ways to design programs for Go.
nice pic!
The new DSL isn't as nice as the old one, what are the benefits of alleged `go test`compatibility? Thanks.
interface{} is good enough for most cases. http://stackoverflow.com/questions/15104795/generic-programming-in-go
Nice ... You can also look at https://github.com/olekukonko/merror 
Interfaces are a bandaid.
True. They are not a replacement but for most cases where people use generics, interfaces are fine.
Interfaces are cool, they are not generics.
I miss `gofmt` so much when writing in any other language. The genius of it is that you don't have to think. You just press save and your code snaps into place in your editor instead of thinking, "Hmm, should I go back and put a space before that bracket or would it look better without the space?"
Thanks for explaining it. I agree, even tho its not as clean anymore, its worth it. Good job!
Okay, I see what you mean. At first glance it looked like another "But I'm used to Java, and one of the great patterns in Java is the Builder Pattern, therefore I must find a way to use the Builder Pattern in Go" kind of thing. It might help to have a slightly more complex example in the readme for the builder package. It still seems like it's a little bit of a hassle to define your own builders, but I don't see a way around it. I don't know much about the tricksy `reflect` stuff.
Yeah, I probably should have picked a different name; using this as a standard builder is probably the least interesting thing you could do with it.
Alright, I'll forgive you... *^^This ^^time...*
Thanks for the good question. I'm certainly open for suggestions about the DSL. I've debated for a long while about the nicest way to go about this change.
I don't think I really see the advantage over creating a builder the usual way. E.g. converting the example: http://play.golang.org/p/prtJbmDzKT Which more straightforward and easy to read. If you don't want mutation, copy the struct before returning, and don't make the struct fields visible outside the package. The downside of your reflection approach is that you lose type checking. E.g. what if the member *Name* is changed to *FirstName*? The compiler will not complain, because the member is only resolved at runtime.
Copying a struct is easier said than done, which is why I built this in the first place. Its true that you lose type safety in the builder methods, but those tend to be relatively simple and just need to match the resulting struct. This is meant for use in libraries, so the end user should still see a type safe interface.
I agree that it makes it easier to make immutable builders. One question about the example though. If you don't want to leak implementation details to the user, it would be nice to add a *Build* function for muppetBuilder, where GetStruct is called. Then the user of a library could just do: MuppetBuilder. Name("Beaker"). AddFriend("Dr. Honeydew"). Build() Ps. I should have started with the positive 'criticism': great work on the package!
Yes indeed - the current example isn't very good. I'll get something better up soon. Meanwhile, check out the (work in progress) SQL generator I built this for: https://github.com/lann/squirrel/blob/master/select.go rows, err := Select("col"). From("tab"). Where("x = ?", 1). RunWith(db).Query()
Just FYI, this is called the [decorator pattern](http://en.wikipedia.org/wiki/Decorator_pattern), except that where inheritance-based languages need a bit more machinery to invoke composition instead, Go uses composition natively, so that first class diagram doesn't precisely match what Go uses. In Go, it's just a box connected to another box with the composition diamond of UML, though when I'm diagramming this for coworkers where I don't give a fig about UML, I typically draw it as a box entirely encompassing the inner box, to how many layers there are.
"x |= y" is equivalent to "x = x | y", just like "x += y" is equivalent to "x = x + y". | is the [bitwise OR](http://en.wikipedia.org/wiki/Bitwise_operation#OR) operator. It's the same in C, C++, Java, C#, JavaScript, etc.
It's [bitwise OR](http://en.wikipedia.org/wiki/Bitwise_operation#OR). Basically the same as val = val | whatever.
Like `a += b` is equivalent to `a = a + b`, `a |= b` is equivalent to `a = a | b`. Operators `| &amp; ~ ^ &lt;&lt; &gt;&gt;` perform bitwise operations on integers. If you're not familiar with those, read up on them on [Wikipedia](https://en.wikipedia.org/wiki/Bitwise_operation).
Have these changes been proposed for inclusion in the language?
 val |= (boolToByte(hdr.DupFlag) &lt;&lt; 3) It's the bitwise OR operator and it's generally used to turn specific bits to 1 on a number. The statement above can be broken down to: 1) tmp := boolToByte(hdr.DupFlag) 2) tmpShifted := tmp &lt;&lt; 3 3) flag = flag | tmpShifted The statement above will read the state of the "hdr.DupFlag" (true or false), turn it into a byte (0 or 1). If hdr.DupFlag is false, it has no effect in the end. Otherwise, tmpSifted will be evaluate to "1000" in binary (the decimal number 8). Then it executes #3 (flag = flag | 8) which essentially will turn the 4th bit on "val" to 1. So, in a gist what it does is "set the 4th bit on 'val' to 1 if hdr.DupFlag is true". 
You don't want a `main()` function in `main_test.go` file.
I did not put a main function in that file though. Do I need to link it to actual functions in main.go? I was trying to create a test like func Test_OneIsOne(t *testing.T){ ... } and test that 1 = 1.
Actually thank you for the help :-). I was running '$ go test' in a directory of go files all in package main (these are just scripts essentially). It was testing them all. I just tested the individual script and it worked.
In other words, anonymous structs that have lots of stuff in them need a name (and thus can't be anonymous)? If that's the case, why not pull the really big struct out into its own type definition, then just replace the anonymous struct with the named struct type? Should only take a few seconds to do.
Is there any information how will/should it behave with multiple producers/consumers? E.g. 10 producers, 5 consumers and then 2 producers/consumers fail... IMHO `forselect` would be a more appropriate name instead of `doselect`.
Send returning bool is a feature I'd like to see in mainline go.
I recommend the excellent (and free to read) [An Introduction to Programming in Go](http://www.golang-book.com/).
Yes. But, yes in a "not yet" way... I was just recently looking into whether to teach "Creative Programming" with Go in a high school, but the setup would be too cumbersome on Windows machines (i.e. to get everything setup you need - go, git, hg, gcc and some nice IDE). So in a general sense yes, if someone creates a bundle that brings together audio/visuals etc. Not that these are a requirement for programming, but for getting people interested and stick through the initial pain, those are invaluable. But, if you are interested, I would definitely recommend starting with Go... it will teach you better programming practices than any other language.
Ayup.
I think yes. The only thing I'd be wary of is the lack of easy google-ability which longer termed languages have for every little syntax error. If you can get around that, go is great for a starter, I think.
Honest question (which you may want to use to modify your docs): What is the primary use case you have in mind for this, and how does your code meet it? (Assume I do in fact already know what DI is, and I'm _still_ asking. I'm not asking about DI in the abstract, I'm asking about this code in particular.) I will freely admit I have some preconceived notions that I am sort of leading into, but I want to give you a chance to speak directly on that before I lead too much, and perhaps make a fool of myself if they turn out to be wrong.
I think Go would be great for new programmers, but remember that they engineered around some fundamental concepts that you need to know with most other languages. Rob Pike did an excellent presentation with regards to this: http://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html 
Looks very similar to https://github.com/codegangsta/inject/ but this one has a readme ;)
That's a good question and something I'll plan to address in the docs, thanks for the input. While this is just a bare bones DI container mostly as a proof of concept I plan to use it to have flexible function signatures.
Yes, inspired by that code. I opted for keeping it simpler. I did use your (*InterfaceType)(nil) trick -- I was wasting some time before I looked at that.
Nice! Keep up the good work!
It's a bummer that there isn't a more concise way to get a reference to an interface in reflection. But it is what it is for now :)
&gt; I plan to use it to have flexible function signatures. Can you expand a bit on what you mean by this? I've read the code but I truly cannot envision a single use-case.
How difficult would it be to implement the same functionality in Revel, I wonder.
Oh. Well, that's pointless: all of those Handle invocations can be separate functions (Handle, HandleResponseString, HandleCodeResponse, etc.) which would give you static type checking and save you the cost of reflection. It's like a poor man's syntax sugar, except it makes the program worse in multiple dimensions.
Why so complicated? The pain point with e.g. Java is that you always had to write dedicated classes and interfaces, and when it came to libraries supposedly making DI easier, you had to configure them with XML and what not. When I need DI in Go, I use this simple pattern: http://play.golang.org/p/V5EQ2Qidf3 It shows all you need in DI, the consumer, the dependency (as interface), and the dependency injector. And it's type-safe at compile time.
Go is pretty much my first language - I'm pretty decent with Bash and can do some basic Python. The syntax and environment is amazing, and the builtins like testing are really nice too. However it becomes really difficult to learn higher level stuff since there is no Go specific documentation. For example, I wanted to learn [Test Driven Development by Example](http://www.amazon.com/Test-Driven-Development-By-Example/dp/0321146530/ref=sr_1_1?ie=UTF8&amp;qid=1390865650&amp;sr=8-1&amp;keywords=tdd+by+example) whose first half is in Java. With a bit of tinkering I could very easily translate a Java command into a Go command - Go's type system really helped with that too. However, I eventually had to quit because Java uses classes and Go uses structs and interfaces and it became difficult to juggle not knowing Java, what the Java app is doing, translating that to Go's idioms, and then writing that in Go. It was also hard to ask for help on the IRC channel because people would get stuck on pointing out that I was trying to code in a Java idiom and Go doesn't have objects like Java does but my question was exactly what they're pointing out to me so ugh! Similar thing goes for everything else - if you have a problem, you'll be able to Google a solution. But it will be in C or Java. At that point you really won't be able to translate it yourself unless you learn another language. I think learning any language would be hard, and Go's ease really helps mitigate some of the difficulty outlined above. I'd fully recommend it if you can find a mentor who knows CS and is willing to spend time with you, and I'd half recommend half un-recommend if you don't.
I largely agree. I see this sort of thing more as a thought experiment than solid engineering. Basically I saw the over-engineered approach in martini and wanted to provide a simpler solution. 
In that case, I'll have to take a look at your implementation :)
Hey, this could be really cool! Are there any other Go libraries that do something similar?
You can find more similar packages at https://code.google.com/p/go-wiki/wiki/Projects#Console_User_Interface . However, most of them are bindings or "low-level" console libraries, while gocui is a pure go library based on termbox-go. For more info: * Summary about the gocui's features: https://plus.google.com/+RoiMartin/posts/as2xkfTQGuT * On-line documentation: http://godoc.org/github.com/jroimartin/gocui
I think beego is what you wanted. 1. RESTful 2. sample code show how to use AngularJS+beego https://github.com/beego/samples/tree/master/todo
If I'm understanding this right this pattern has these downsides: * Your functions now know about and depend on an environment, which consists of a non-cohesive collection of interfaces * You don't know for sure what a function actually uses and needs without reading the code (of the function and recursively everything it calls) Is this the case?
I hacked this together in a few hours and hope other folks find it useful. Let me know if you have any feedback or suggestions. And I would love to accept contributions.
Well this hase some serious flaws. 1. Request is not available in handlers. 2. What if I want to change serialization of values from url.Values to json. 
&gt; * Your functions now know about and depend on an environment, which consists of a non-cohesive collection of interfaces Sort of. Your function already depends on an environment (abstractly, not the exact `Env` structure I'm defining); that's life. The point is that gives you a standardized way of invoking the environment via `environment.Null()` for testing. The alternative isn't that you have functions that don't depend on an environment (unless you're willing to put the work into that, and it's still not always possible), the alternative is that your environment is implicit and unmanageable rather than explicit. I'm finding in practice this gets _more_ useful as the number of things in it goes up, rather than less. I absolutely agree this is not what I would have expected, but it has been my experience. And I mean "more useful" from a software engineering perspective, not a "convenience" perspective; I'm getting great integration testing on what is actually a heavily-state driven program, while at the same time getting pretty decent isolation on _only_ the things I'm testing; the Null environment tends to isolate nicely. YMMV. &gt; * You don't know for sure what a function actually uses and needs without reading the code (of the function and recursively everything it calls) The recursive bit is not a result of this pattern, that's a result of using a language like Go instead of Haskell, which is one of the only languages where you actually can gain some assurance that a given function absolutely doesn't call something, no matter how many layers of recursion you go down. (Nor am I saying that's bad at the moment, just observing I'm not creating this situation.) In Go, any function can in theory end up calling anything. As for what the function calls, yes, this does obscure exactly where the method's implementation comes from. However, recall the context I'm using this in... it's something I would _otherwise_ be very tempted to make global anyhow. I don't suggest just slamming any ol' thing in there. Many things are pretty clear, like logging functions. If it's not clear, don't do it. That said, if you have the discipline to always invoke the methods by a qualified name, I'm not going to object at all. `s.Logging.Critical(...)` is fine, and I still wouldn't feel that bad about dropping the `Env` out of the chain. You still get the other benefits. I'd rather you use `s.Critical(...)` than invoke a global.
I really disliked the article, I was expecting much better. More than half of it is useless text, and the whole "Showdown" is just two graphs. No code, no links to the official sites of Go and node, and the info is outdated (I can name at least three web frameworks for Go and I'm pretty sure there are much more). To say nothing of the design that makes my eyes sore.
&gt; Golang ... Golang Just call it 'Go'. You can tag it 'golang' in the HTML metadata for search engine crawlers if you want. &gt; but with ... features like ... dynamic typing Go is not dynamically typed, it's statically typed. Not overly typeful, but statically nonetheless. &gt; dynamically cast types (no more type casting problems like C!) Again, Go is not dynamically typed. Type casts are done explicitly. Maybe they mistook structurally typed interfaces for dynamic types. &gt; Maturity in market Go has proven itself many times in production for high traffic services: https://code.google.com/p/go-wiki/wiki/GoUsers It's pretty robust by now. &gt; Much more advanced and powerful language features (if used correctly) I know both languages by heart, and Go is light on features by design, but I don't see any language feature of JavaScript that's clearly "more advanced and powerful". Some are just different (e.g. prototype chain vs. embedding, dynamic vs. static typing, objects vs. structs). &gt; Built-in JSON parsing support Same for Go (package "encoding/json"). &gt; Faster than Golang for handling multiple IO streams I don't believe this without evidence. &gt; More wb development frameworks than Go (27 vs. 2) I don't think that quantity is a useful criterion here. Nevertheless, there are definitely more than 2 web frameworks for Go. I see a new one every week. http://go-search.org/search?q=web+framework &gt; Supported by Google - no risk of project dying I don't understand this causality. Aren't Google critics saying the opposite? &gt; Go 1.1 Why do these tests still use Go 1.1? Go 1.2 has been released for quite some time. 
You have to try Flask, and then plug whatever ORM you like in there. ;)
&gt; but I don't see any language feature of JavaScript that's clearly "more advanced and powerful". Arguably, the ability to dynamically put objects together is more powerful, though I'd never call it more "advanced", it's "just" a closure attached to an attribute (along with some potential interaction with the prototypes, depending). That said, it's a type of "power" I happily eschew since it's also a huge part of why JS code bases tend to fall apart at the seams as they grow.
I'm under the impression that it was written by a teenager with shallow knowledge.
&gt; It really just comes down to whether you are willing to jump on a new technology before it is proven, or stay on the NodeJS train until you are comfortable. IMO I don't think NodeJS is a proven technology for web applications.
I've been rewriting my whole API for alienstream in go and I almost chose to use .net instead. I'm so glad I didn't and the community has been a huge help. There is so much great documentation for this language and the people behind it all seem very passionate about what they do. Never been happier to have picked up a new language and the performance increase I got from leaving php is crazy. 
Thanks for the link! That actually looks exactly like what I was looking for. Light-weight wrapper-like tool.
While I like the idea of a full-stack framework, I am wary of them (coming from Python). I am definitely keeping an eye on it, though. It is by far the best effort so far. I especially like that it is coming from a team in China.
Very cool. But may I ask why one would use this instead of an ORM?
Attractive? More like addictive!
What a hilariously bad idea.
thank you for your feedback ;)
If you think this is easier than writing some `if` blocks, I've got a bridge to sell you.
sending a byte at a time over a chanel is going to be insanely slow compared to just doing things the conventional way
import "github.com/go-on/queue/q" func SaveUser(w http.ResponseWriter, rq *http.Request) { u := &amp;User{} q.Err(ErrorHandler(w))( ioutil.ReadAll, rq.Body, )( json.Unmarshal, q.V, u, )( u.Validate, )( u.Save, )( ok, w, ).Run() } where ErrorHandler(w) returns a generalized error handler that returns input / validation error to the client and stores other errors with debug infos (for example). How is that not easier to read and understand than 4 if err blocks? Also, if you want to change the error handling for your routes, than do it at one place.
I will add some links to screenshots of real use cases in the release v0.2.0. Thanks for the advice! :)
It's really orthogonal to an ORM, though some ORMs may include similar functionality. You could use this along with sqlx for example, which populated structs but doesn't generate (complex) SQL for you.
I totally agree. I've been considering query building in Go for a while and I always thought that it should be composable with hthe actual "marshalling" layer to allow people to swap in or customize things according to their needs. 
another possibility is to use defer and panic: func SaveUser(w http.ResponseWriter, rq *http.Request) { defer handleFailure(w) u := &amp;User{} err := json.NewDecoder(rq.Body).Decode(&amp;u) failIf(err != nil, http.StatusBadRequest, "Cannot read user: %v", err) err = u.Validate() failIf(err != nil, http.StatusBadRequest, "User not valid: %v", err) failOnNonNilError(u.Save()) // 500: internal server error if this fails } This allows very explicit control flow, customized error handling and clear error reporting, and is still compact. 
I have some partially finished code to do exactly that - its tricky to make it flexible enough to support many marshalers though. Currently it uses an adapter pattern to wire up ReadOne and ReadMany methods on the query builder, but I'd love to hear other ideas. 
Oh! Yes! I just _assumed_ so hard the channels would be byte _slices_ that i didn't even notice that! Yes, that's not a good idea. Thanks.
First of all, the point isn't to use channels to back readers and writers. The point is that, if you already have a channel, it allows you to use readers and writers to interface with them so you can do things like pass them to functions that take those interfaces (like io.Copy, for example). Second of all, if you use buffered channels, it's MUCH faster.
Now the if err != nil blocks are replaced by failIf(err != nil,...) lines.... Also the error handling is very explicit, making it hard to fullfill an evolving error policy (e.g. for a REST api), where you want to handle the same kind of errors the same way (e.g. errors based on wrong input vs development or network errors). With explicit invocation of the error handling functions you will have to change a lot of code, if the policy changes.
I actually went to Tornado :-) lovely micro framework. Chickened out and went for a Mongo backend so I didn't have to fight with a DB. It makes a nice change of not being tied to an ORM and under the hood magic. Never tried Flask, but have heard excellent things.
With the defer scheme, you can centralize error handling in handleFailure if you like.
I hate to suggest the ugly thing, but in my code I just manually do an UPDATE when I change the struct. I put this into a function of course, so that all the code that affects a struct is in one place, but I've found that having such functions has other benefits, like it's a good place to do error checking on the change itself, or to log changes at a semantic level, or to catch UPDATE failures (consistency, etc.) and deal with them.
It's similar, but not quite the same. The idea with chanio is to allow people to take existing channels and interact with them using the io interfaces (for example by using io.Copy or other utilities). 
Yikes, lots of panics and uses reflect. "Runtime suupport"... I guess, yes, technically that's correct
Well, it's either that or use interfaces for everything for the generics. Some other libraries do that, but it imposes a burden on the programmer. Granted, it's the idiomatic Go way to do it, but I wanted to try something different. You definitely shouldn't use this in performance-critical code (for example, my Map implementation is about 30x slower than map written for a particular type without using reflect).
If you are using `gorm`, you are possible to do this with UpdateColumns. https://github.com/jinzhu/gorm#update-attributes-without-callbacks
I ran into this problem recently when I ported a project from a document store to PostgreSQL + sqlx. My approach is ultimately pretty hackish, but in order to keep the operation atomic I just: db.NamedExec("UPDATE table SET field1 = :struct_tag, field2 = :struct_tag, etc, etc, etc WHERE id = :id", &amp;mystruct) It's pretty unwieldy when you have ~12 fields and error prone. Helps to have good tests for this stuff. Alternatively you could retrieve a copy of the stored struct, iterate (via reflect) over the fields and compare them to the updated struct. Save the names of the fields in a slice/map and use that to populate your UPDATE query. 
Thank you.
ahhh I see where you are coming from...I feel like you could make a thread safe API similar to channels that is based off of an array of bytes...You would lose the &lt;- syntax sugar and the goroutine scheduling that channels do internally...but you might be able to get some of that goodness with the sync package
When you say "MUCH faster" do you mean in comparison to passing around arrays of bytes/io interfaces or in comparison to unbuffered channels?
Where I was coming from is I very often go the other way, where I spawn off a goroutine to Read from something and stuff it down a channel, a bog-standard technique. I could imagine a use case for going the other way, though, honestly, I'd probably just code it up rather than reach for a library. (Libraries below a certain level of triviality just aren't worth the pain of finding them, working out the licensing, and tracking the source repo.)
I would try fronting your Go app with nginx as a reverse proxy for the TLS offloading.
hmmmm well what about if you used the same idea but instead of sending a byte at a time you sent an array of bytes and on the other side you only recieve from the chan when you hit the end of the array and you just return a single byte at a time internally so you can still fulfill the io interfaces...that way you are not sending on a channel for EACH byte but every 1024 wouldn't be so bad...and if you make the array size configureable people who use your package would love you more lol...and the sync package is part of the std lib
In comparison to unbuffered channels. Again, this isn't meant to be used /instead/ of readers (as somebody pointed out in a now-deleted comment, that's what http://golang.org/pkg/io/#Pipe is for). It's meant to be used when you already have a channel, and want to interact with it using the io interfaces.
You've basically just described buffered channels.
You should not use panic for normal error handling. To quote from http://blog.golang.org/defer-panic-and-recover "Panic is a built-in function that stops the ordinary flow of control and begins panicking. [..] The process continues up the stack until all functions in the current goroutine have returned, at which point the program crashes. " So the guarantee for the returning functions only holds for the current goroutine. If you use panic and defer widely in a project or libraries you will soon run into a situation where the panicking code is inside another goroutine. Then the functions of that goroutine did not return and defers are not executed, files not closed etc. That leads to unexpected behaviour. That is why you always should use errors where possible. Exceptions are initialization code that you want to panic early since the program is not supposed to run any longer after the panic.
Intuitively you can think of buffered channels like that but there is still alot of overhead with using them vs passing arrays...I actually ran some benchmarks and while sending single bytes across a buffered channel is up to 2x faster than a regular channel, it is almost 5 times slower than sending an array of bytes https://github.com/Inspiravetion/Go-Chan-Overhead-Test
That's interesting - I got similar numbers on my own test as well. The weird thing is that I ran a test server using buffered vs non-buffered channels and serving a stream from /dev/urandom (one goroutine just read from /dev/urandom into a channel and then handler threads read from the channel). That was WAY faster using buffered channels than non-buffered. I wonder if it has something to do with the access pattern.
hmmmmm well I just realised that I didn't set GOMAXPROCS before...so I changed that and the new numbers have buffered chans being about 5.5x faster that unbuffered chans but still 7 times slower than the array based implementation. So yes buffered channels are ALOT faster than non buffered channels but they are WAY slower than just filling an array and sending it through the chan...ps im about to push my commits so you can see what I changed
How exactly does one use this?
Another issue, the primary can only be a int64. Being able to use "string" would be nice, since I would like to use GUIDs instead of sequential IDs. Thanks
very cool! thanks
Nice work! This looks great for PXE booting systems.
My guess would actually be that it's cache invalidation. If you're context switching on a single core because you're reading a value that another goroutine left there for you, it's still in cache. If two goroutines on different processes have to communicate, though, that value has to get pushed through to main memory and then pulled into the cache on the receiving core.
touche i think you are right
No need to install anything, you get it for free with the new **Cloud IDEs / Virtual Machines**. I am really impressed with [Nitrous](https://www.nitrous.io/). It has a template for Go, full terminal access with installed tools like Git, Heroku Toolbelt, nano, ... Her *Parts* utility allows you to install DBs (postgres, mongo, mysql, redis) Even easier, use the free services from MongoLab / MongoHQ or Heroku Postgres. Not least, it lets you choose the AWS zone for each VM, which makes it really fast for non USA residents. For training groups, I would check the social characteristics of [Koding](https://koding.com/). It is just a matter of time before some one integrates a full IDE with debuging as [Godev](github.com/sirnewton01/godev).
I'm not advocating using panic and defer widely. I'm suggesting that it can be used within handler functions to interrupt the control flow in a readable fashion.
You do understand in "Creative Programming" the end result often is a visual (2d/3d) or audio synthesis program, hence the need for integrating with native API-s. Alternatively, if the result is in javascript, either you are going to take a huge performance hit due to communication overhead or need to program the whole thing in javascript. Linux VM is a possibility, but this would add another burden when teaching (you now need to explain linux).
Thanks so much for this. I was stuck trying to do all the structs manually and I finally gave up and just used this. &lt;3
This package looks incredible; enough to make me want to learn go inside out, right now. Do we have any users here with 1st hand experience of it and if so, what are thoughts/feelings on it?
Note that all the feedback for 2.0's DSL will be retained should that upgrade happen in the future (but for now, that won't be necessary). Go has an awesome, active community!
This is just great! I was cool with the proposed breaking changes for 2.0, but this outcome is obviously better. Go is quickly turning into my go-to (no pun intended) language.
Thanks! I will have a look.
You can reduce the boiler plate error checking in your functions that use reflection with [ty](https://github.com/BurntSushi/ty). The explanation is [here](http://blog.burntsushi.net/type-parametric-functions-golang).
The only comments on this post so far (other than the OP's) are complaints. This contrarian attitude is really tiring, and it seems to be a chronic problem with modern CS students and younger software developers. The core problem seems to be that if you're smart enough, you can complain about everything, arguing the opposing side of any position! I like the sitemap function. It could be made more useful by adding a way to exclude from the search certain files that we want to keep private, but on the other hand, one might consider that to be the responsibility of the person using rigid. 
Master should be the stable branch, imo, with most development being on feature branches. Granted this is not what OP is doing either.
I typically develop (when not working according to other teams systems(never let anyone ever suggest using cherry-pick as the main method to move code between branches)) with master being the head of working development. While broken or partial code should not be committed into master (topic\feature branches) they should be fairly short lived and nice small testable changes. Additionally i should not comment before midday. [I require more caffeine](http://angryczeck.com/wp-content/uploads/2010/08/Vespenegas.png)
The programming community on Reddit has a tendency of being pretty discouraging to newbies. And yes, I happen to believe that complaining about complaining is as legitimate as being intolerant of intolerance or using violence to end a streak of violence (the verb and the subject discuss different applied subsets of the core action, leaving no implied contradiction). Also, statements like &gt;Why aren't you doing X? Y is the proper convention are complaints disguised as questions/clarifications. It's the sort of passive-aggressive crap you see on Stackoverflow all the time. And it wasn't even applicable in your case, it was a snarky question asking someone why they don't follow your *personal* repo management convention. Occasionally, it's nice to encourage someone, or comment positively about a good feature. 
The generics package looks useful, thanks. 
&gt; it was a snarky question asking someone why they don't follow your personal repo management convention. Master is the default branch in git. it is created with the first commit if you don't specify a branch. Perhaps had i had more caffeine the question would of been phrased "why don't you have a master branch? it does seem to be something reasonably important to git" I honestly can't think of any workflow where the master branch does not by design exist. the only one that really comes close would be the [git-flow model](http://nvie.com/posts/a-successful-git-branching-model/) which has multiple long running branches with the master sitting over on the side with no real involvement in the day to day coding. So if this project didn't have a master and had a reason for not having one it would be interesting to know. The different models that git supports are all kinda interesting and sometimes equally valid (centralised repo with non merging long running branches and cherry picking of code is one of the ones that are really not valid) 
In https://github.com/atmoz/rigid/blob/master/fileutil/meta.go, you defer file.Close() on line 18, then you call file.Close() on line 69 as well. Other than that looks good!
&gt;I honestly can't think of any workflow where the master branch does not by design exist. That wasn't the issue. According to his comment, he created the master branch before you even responded. You asked why he wasn't *developing* on the master branch. But it's perfectly reasonable to not develop on the master branch, so once again, we're back to **[**snarky question "asking" why you don't do things exactly my way**]** territory. 
We'll be blogging about the talks today in the Go devroom, but you can also watch a live stream at http://streaming.fosdem.org/.
I had some returning errors between those two lines of code before, but forgot to remove line 18 when no longer needed. Thanks for noticing!
The livestream says, "No current event", but it's K.6.401 (I'm watching right now)!
`etext` marks the end of the text segment, which suggests that it's code that after the text segment that's taking up most of the time. I'm not familiar enough with go internals to say exactly what this could be, though. One very vague thing I've thought of is: Have you tried [memory profiling](http://stackoverflow.com/questions/19080755/golang-how-to-use-pprof-heap-profile-to-find-memory-leaks)? If you have a memory leak in the way you're generating event objects, this could cause slow-downs as the garbage collector has to handle an ever growing heap.
Outputting a heap profile just gave me Total: 0.0 MB Am I doing something wrong?
I don't know if you are doing something wrong but that sounds pretty weird. Does `etext` appear in the graph you can generate with the profile tool? This is just a wild guess but could the `etext` be anything C code such as the Allegro library you are using? The graph could easily reveal that if it shows `etext` somewhere.
Yeah, it does. I just refactored the Allegro bindings to remove a potential memory leak with event handling, but it doesn't seem to have made a huge difference. Using `runtime.ReadMemStats()` confirms that the memory grows slightly over time, so I know there's another one, but I feel like that's not the entire problem.
Just pass in the URL for a valid HLS stream. For examples see http://stackoverflow.com/a/13265943/1027246
Ah, turns out that my problem was caused by a bug in my implementation. Still, I learned a lot about profiling Go programs that will hopefully serve me well later.
Does go not have a curses library? Seems like this is reinventing the wheel. 
Ooh cool; thanks!
Could you provide more details?
If you actually want to obfuscate IDs, say to avoid analysis via the https://en.wikipedia.org/wiki/German_tank_problem , then you're probably going to to want a 'real' encryption algorithm. If you have 32-bit IDs, something like https://github.com/dgryski/go-skip32 should be fine. If you have 64-bit IDs, just use AES or another 64-bit block cipher.
&gt; // Use field tags to specify custom bit widths. &gt; type unixMode struct { &gt; User, Group, Other uint8 `gopack:"3"` &gt; } I have never seen any Go code like this - what does putting a backtick string literal there do exactly?
Those are called "struct tags." They're not actually "part" of the struct, except that they are included in the runtime. This means that they can be accessed through reflection, and are often used to provide information to packages that use reflection (like gopack). For example, the [encoding/json](http://golang.org/pkg/encoding/json) package uses them to specify json variable names. There's a nice little blog post about them [here](http://strangebit.wordpress.com/2012/02/29/go-struct-tags-and-the-backtick/).
It's used in a fair number of packages to identify a special "tag" of sorts for certain struct fields. For example, if you had: `db:"file_id" json:"fileId"`, that would tell the database package to map that field to the specified column, and the JSON package to marshal that field with the specified key.
Ah, I see now, thanks (the [relevant bit of the spec](http://golang.org/ref/spec#Struct_types)). That also explains why I never came across it before, as the code I dabble with doesn't really need it.
Can someone explain what I can use this for? Example use cases?
My issue was very specific to the Allegro library, and in particular how it should handle the main loop. The FPS is controlled by a timer, and according to the Allegro docs, that part of the loop should look something like this: needsUpdate := false for { eventQueue.WaitForEvent(&amp;event) switch event.Type { case allegro.EVENT_TIMER: needsUpdate = true } if needsUpdate &amp;&amp; eventQueue.IsEmpty() { Update() Render() needsUpdate = false } } Mine instead looked like this: for { eventQueue.WaitForEvent(&amp;event) switch event.Type { case allegro.EVENT_TIMER: Update() Render() } } I'm not entirely sure _why_ this approach causes gradual slowdown, but switching it to the other one fixed my problem. As for what I learned about Go profiling, trying to track down this issue was my first time outputting and trying to read CPU and Heap profiles. They didn't contains a lot of useful information, but it was still interesting. EDIT: fixed the correct implementation.
I found this article saying it's for saving space. Makes sense, considering the name "bit packing": http://lemire.me/blog/archives/2012/03/06/how-fast-is-bit-packing/
&gt; Concurrency is the ability to execute multiple computations simultaneously. No, that's parallelism.
Looks like a decent ~~article~~ bunch of words, but just impossible to read in that format. 
As atmozpheric mentioned, it's often used for saving space. However, the practice of bit packing values in RAM purely to save space in RAM is relatively rare nowadays because of how cheap RAM is (for example, old video games used to bit pack like crazy to make use of the tiny amounts of memory available in game consoles). Nowadays, it's still used in things like network and file protocols where, even though space isn't so much of a concern any more, the protocols were defines decades ago when it was a concern, and programs still have to meet the protocol specifications exactly.
I think it's actually a proposal, not an article. I'm pretty sure that this is the same guy who spearheaded Go's most recent goroutine - OS thread overhaul (http://morsmachine.dk/go-scheduler).
Excited -- whenever dvyukov makes something, you know it's gonna rock.
Always fun reading dvyukov's proposals.
Is this proposing a change to Go's semantics or just an improvement to the implementation?
Wikipedia says: ' In computer science, concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other'
It looks like it's just a proposal for the implementation.
To me concurrency is dealing with multiple threads of execution, and parallelism is executing those threads simultaneously.
The first implementation drains all events before updating and rendering. The second updates and renders once per event. If more than one event of any kind is generated per Update/Render, what will happen is that as events are put on the queue, it will take progressively longer and longer for them to reach the front and take effect. I suspect rather than seeing slowdown due to excessive CPU, RAM, or GC consumption, the usual suspects, what you were seeing was ever-increasing input lag brought on by it taking an increasing number of frames for the event to actually arrive to your code. This would look like ever-increasing slow down to the user. Tricksy. That definitely took me a bit to work out. I got stuck on the idea that it was Update/Rendering too often for a while before I realized that made no sense.
Certainly. The regressions with heavily contended channels have me a bit worried though - any real-life use-cases where that might be an issue?
I knew that the recommended approach was to drain the event queue first, but I never thought too hard about why, and I had written the original implementation from memory rather than consult the docs. All in all, I'm glad that the problem turned out to be there rather than in the language itself; for a moment there I was starting to lose my faith in Go's performance. =)
in memory sqlite database that imports the source? Clever. I like it.
&gt;To me There we have the crux of the issue 
You might prefer this format: https://docs.google.com/document/d/1yIAYmbvL3JxOKOjuCyon7JhW4cSv1wy5hC0ApeGMV9s/edit (just change /pub at the end of the URL to /edit)
Interesting. I deal with massive csv files at work and I'd use this if it had the following: - Don't re-import the csv file every time I run a query. Store the db file as sampledata.csv.sqlite. - Auto detect the line and field delimiters. - Auto detect headers. I'm considering contributing these additions myself.
Because of the structure and amount of the data I have, I'm considering moving some tables to CSV myself, but I would not use this code for at least two reasons: * it first loads the file to memory so it will not work with big amount of data * it's using sqlite which does not work too well after exceeding sertain amount of data * it does not provide any extra optimizations (indexes) Why not just load csv file into databsae (1 command), do the work and remove the data (1 command)?
&gt; it first loads the file to memory so it will not work with big amount of data That's something that can be fixed. It can be made to load and insert in batches. &gt; it's using sqlite which does not work too well after exceeding sertain amount of data I don't know about sqlite limitations, but I'd assume it should be able to handle more data than a spreadsheet application. &gt; it does not provide any extra optimizations (indexes) I'm guessing that can be added in either as command line args or to automatically detect which fields are best to index based on the given query. Alternatively, it can simply index all fields! &gt; Why not just load csv file into databsae (1 command), do the work and remove the data (1 command)? I don't want to install a DB server on my machine. I can use a remote one, but it adds to the complexity. Also, I'm proposing for this to automatically detect field types and other things. Loading data manually is error prone.
What has prevented me from leaving Go is its IMHO superb multi-threading with green threads and communicating sequential processes (CSP) that keeps synchronization much easier as with locks, semaphores, etc. Well, also Objective-C does not have parameterized types. It is widely used (3rd place on Tiobe for several years) and nobody seems to complain about it much. I hate Len(myArray) instead of myArray.Len() actually much more than lack of parameterized types. You can work around it by adding typed accessor methods for your array of type Foo. But it's really not nice and effortful. What makes me think, though, is that I don't believe Go will ever have parameterized types. If you look at C and then at Go you see that Go is in every way a modernized C. They just want a modernized C with CSP. So I don't really have hopes for Go ever to have parameterized types ...
Yes, that's a pitty. If D had channels, green threads, CSP like Go it would be a nobrainer for me to change to using D. Maybe D is lacking "novel features" what seems to make people change from one language/framework/system to another one.
The C++ "making copies of stuff for each type" is called monomorphisation, for anyone that didn't know.
I was actually just looking for something like this. Thanks for sharing!
Does anyone have any idea why it is called "koremutake"? If you decode "koremutake", you get 10610353957. Why is this number special?
Haven't figured it out so far. It's a 'secret' according to the details page. Maybe there is something to it if you decode the syllables one by one as single numbers? Could be a specific date or something..
I wrote a basic cyclomatic complexity analyzer: https://github.com/thraxil/cyclo There is an open question of how goroutines and `defer` should factor in, though.
This mystery must be solved. It is very important.
Looks nice, and I love how simple it is. I was wondering if it or other tools could do the following: * Generate an initial Godeps file for you based on imports (might be as easy as a single ``go list -f {{.join Deps "\n"}}`` that filters out the stdlib?) * Support repo aliasing The latter feature is for when I fork a repo and submit a pull request but don't want to change all my imports. I can understand if this isn't a desirable feature though.
https://github.com/golang/lint
Also `go vet`. A month ago `http://codebot.io` was announced on golang-nuts, but it seems to be dead already. It combined a few of these existing tools into a pretty web interface (but didn't add any major new functionality.)
Yep. Go is nothing short of an amazing language and toolchain.
I use go lint, go vet, go test (with race conditions), go coverage, and goimports. There's also benchmarking using go test. I have goimports set to run instead of go fmt when I save a file in Sublime Text. Supposing you have them all installed in your PATH you can use the following: goimports *.go golint *.go go vet go test -race -coverprofile="coverage" go tool cover -func="coverage"
Love the generics call-out in the comments. 
In the example, you should probably add after the `for rows.Next()` block: err = rows.Err() panicIf(err) to catch any errors encountered while iterating across the rows. I've found http://go-database-sql.org/ to be a very helpful resource in learning best practices with `database/sql`
I didn't say for all benchmarks. I said for many benchmarks. Even in the link you sent it beats Go on some benchmarks. And it seems for Java that's the case too: http://benchmarksgame.alioth.debian.org/u64/benchmark.php?test=all&amp;lang=java&amp;lang2=go&amp;data=u64
I certainly wouldn't panic on an error like that! You should just use the normal if err != nil { // do something } idiom. A DB error isn't a "critical, can't proceed at all" situation. It probably just means the row doesn't exist and/or there's a connection issue. For a small example just log.Fatalln(err) and in a real application, deal with it and/or return the err to the caller.
After having wrote some production level code in Go, I still prefer Python for quick-and-dirty stuff - file-parsing in Go is a bit annoying, nothing like a quick for line in open("file.txt"): list_line = line.rstrip("\n\r").split("\t") print "\t".join(list_line[:5]) In Go: package main import ( "bufio" "fmt" "os" "string" ) func main() { file, _ := os.Open("file.txt") defer file.Close() scanner := bufio.NewScanner(file) for scanner.Scan() { list_line := strings.Split(strings.Replace(scanner.Text(), "\n", "", -1), "\t") fmt.Println(strings.Join(list_line[0:5], "\t")) } } and here I didn't even handle any of the errors in either language. Edit: inb4 cut -f -5
It isn't a golang discussion without it. Wouldn't feel right, ya know?
Python isn't very good at that either, compared to Perl or Awk. Or in this specific case, something like: $ cut -f 1-5 file.txt
haha my edit came too late
The [hadoopconf](https://github.com/elazarl/hadoophelpers/tree/master/go/lib/table) is a tab based table and does not support table lines, multiple lines and alignments etc like [tablewriter](https://github.com/olekukonko/tablewriter). If you need tab bases solution alone [tabwriter](http://golang.org/pkg/text/tabwriter/) does a better job
Please share with us what kind of Vim plugins you use for Go editing.
True, fixed
&gt; Even in the link you sent it beats Go on some benchmarks. Which is not 'many'.
As a neutral observer, this thread is kinda circlejerky. &gt; Go is the most exciting new mainstream language to appear in at least 15 years and is the first such language that is aimed squarely at 21st century computers  and their programmers. Go is nice but not ground breaking. It certainly popularized coroutines and channels, but it's not flawless either. I dislike Java quite a bit, but I don't see Go displacing the *JVM* any time soon. Edit: My initial point wasn't to start a language discussion. We're here because we're interested in Go. However the "Go is the best thing since sliced bread" echo chamber is not healthy for the community.
Thanks for the kind words! Let's see.. Repo aliasing I think is out of scope for the project, it's probably better to approach changing import paths with awk or `go fix`. Helpers for management of the Godeps file have been on my mind or a while (and some where even in gpm for a while) but I can't find a way that is handy: - I've toyed with getting the last release from github, but this won't work as gpm should work with anything `go get` works. - I've thought about just installing the dependency and taking the last commit for the Godeps file, but I don't like that you're effectively just adding HEAD to the file, something that might not work, I want people to be aware of what they're throwing into their project. Anyway, I'll definitely continue to think on a way to help with the Godeps file, if you (or anybody reading) have any ideas [please open an issue!](https://github.com/pote/gpm/issues?state=open) This is something I'm really interested in improving.
Quite a relevant username you got there too.
Seriously. I actually Google stalked this guy hoping he had answered this. Please please share. Edit: oops. Im on mobile. In response to sharing his vim setup. 
I agree. For now, though, we've opted not to incur the extra, non-git dependency in GoConvey. Long polling is very lightweight and works totally fine for GoConvey's needs.
The tight tool chain integration, 'just right' syntax and semantics, elegant addition of co routines and channels, and overall light weight feeling that tackles heavy weight problems *is* , in my professional opinion, what makes go innovative.
My dotfiles are public https://github.com/codegangsta/dotfiles
I responded above :)
Thanks for catching that. I will update the shownotes
I've been coding in C++ for a long time. And now I try to code in Go whenever possible, and only resort to C++ whenever it's unavoidable.
&gt; The robustness of a compiled language with the ease of use of a dynamic language. Go's type deduction is a poor man's H-M type system. &gt; Ultra fast compile times. Compilation speed has been a problem for your projects even using ccache? You realize that re-compiling Chrome can take a few hours even on a powerful machine right? &gt; It's very well suited for large projects. &gt; Enforces very good engineering practice. Your arguments need to be a bit more concrete. &gt; Co-routines are very lightweight. Yes... because they're *coroutines*. &gt; Concurrency and channels are built in. Yes, and that's awesome. At the same they're not *new*. &gt; Single file distribution and zero dependencies. Static compilation exists in many other languages. &gt; And lastly, do you really think Google is going to be able to build their vital, high-performance infrastructure on a JVM?? **You do realize that most of Google's Android and web products are written in Java (with the exception of search)?** Right now the only penetration Go has at Google is in the YouTube group.
I'm just curious: in which cases do you still need C++?
Why are you nitpicking the meaning of the word "many"? The point is, its unjustified to call Go faster than Java. And you are sitting here nitpicking my choice of "some" vs "many". Glorious Go! I should not cast aspersions on thee.
Thanks!
I think the very restricted nature of Go makes it in principle more suitable for "compile for anything" (including native code for small systems, Chrome's NaCl and PNaCl, Firefox's Asm.js, JS for generic browsers, code for iOS devices, Windows 8's WinRT and similar) than the alternatives, such as C or Java. Java, being heavily dependent on virtual methods (with a high dynamic frequency of their invocation) and support of dynamic class loading, would probably be quite a bit slower without a heavier runtime, but PNaCl, iOS and WinRT disallow dynamic code generation (for inline caches, for example) entirely anyway (I'm not sure if the old NaCl allows it). C, on the other hand, is difficult to compile into generic JS because of pointer arithmetic. Go seems to cover the largest gamut of compilation targets without making it exceedingly difficult to compile for any single one of them, so it seems like a nice choice for long-term generic code bases you might want to write once and run on various devices to satisfy your computational needs.
&gt; Go's type deduction is a poor man's H-M type system. All type systems are a compromise. Even the H-M type system is a compromise. Why not a dependent type system, instead of H-M, for example? &gt; Compilation speed has been a problem for your projects even using ccache? You realize that re-compiling Chrome can take a few hours even on a powerful machine right? Yeah, C++ is a fat bitch. :-p &gt; Static compilation exists in many other languages. I suspect that it's easier to write new backends for Go's runtime and static linker, though. After all, it's a brain child of Oberon and the Plan 9 tool chain. The other languages that sport this are very heavy in terms of tooling. &gt; Right now the only penetration Go has at Google is in the YouTube group. That's actually not true. They're rewriting all sorts of old pieces of infrastructure in Go. They just don't flaunt them (although they publicly mentioned their file distribution services in a presentation, for example the ones serving the Chrome updates or something like that).
I was asking about V8, actually.
We've built a more complex kv store API at work with pluggable backends: https://github.com/tsee/p5-ShardedKV . The original is in Perl, and I've written a compatible version in Go that we're also using: https://github.com/dgryski/go-shardedkv
How neutral are you?
It appears I was absolutely mistaken. Sorry on my part.
What exactly is going on here?
Awesome work! I think you also want to place the call to `defer rows.Close()` before you check for the error. If there is an error your program will panic and will leave the connection open. I just submitted a pull request addressing this change!
Would be interesting to see that same stripping function implemented something like this: func BenchmarkTrimLeadingAndTrailingSlashes3(b *testing.B) { pageName := "/home/" b.ResetTimer() for i := 0; i &lt; b.N; i++ { pageName[1:len(pageName) - 1] } }
The problem with that is that it assumes there definitely are leading and trailing slashes. "products/categories/abc/" would be turned into "roducts/categories/abc"
Go + Python covers almost all programming tasks. Throw in some C/asm that can be called from Python or Go and you're all set. 
https://twitter.com/golang_news seems to already mirror anything posted to this subreddit.
Aha, thanks, then a link to this account from the side bar (the bar on the right side of the reddit) will be helpful :)
You want to go generic, which is kind of bad, but sometimes worth it. Use type assertions (and maybe a type switch if you have a number of known UnderlyingTypes): type MyGenericMap map[string]MyInterface func (gen MyGenericMap) ConvertTo(spec interface{}) error { switch interface.(type) { case map[string]UnderlyingType: for k, v := range gen { if underlying, ok := v.(UnderlyingType); ok { spec[k] = underlying } // optionally: else { return errors.New(...) } } return nil default: return errors.New(fmt.Sprintf("don't know how to convert to %t", spec)) } } If you know all the underlying types ahead of time, you should make a function for each type and have it use this code. If you can guarantee that the internal generic code can never be called in a way that produces a runtime error, then you can expose a type-safe API to your callers. (I'm not sure how expensive the type assertions would be compared to copypasta customized for each type, but I do like to keep my code DRY). If you don't know the underlying types ahead of time, you could go even more generic with the reflect package. I do it a lot myself, but I don't recommend it without good justification and thorough test coverage in anything that calls this code (since you're telling the compiler to leave you be and exposing your callers somewhat unknowingly to a host of potential runtime errors). To me this tends to make sense when you're providing some sort of data marshalling framework (encoding/json, fmt, DB interfaces, etc.). 
God, I wish. I'm still new to Go, and was *not* expecting to hit my head on the lack of generics so soon.
most of the times when i end up thinking that i need generics, go provides me a better way of doing what I want to do. What are you working on?
&gt; The problem is, I have multiple places where I want to do this kind of conversion, and the redundant, nearly-identical code irritates me, not least because it increases the testing burden. Get over it. That's the only advice I can give. Asserting to/from `interface{}` is code-smelly. I hit this wall full-speed a while ago, and it nearly stopped me from taking Go seriously. Yeah you'll have a bunch of structs that are mostly identical, but so be it.
DRY (do not repeat yourself) is a god worth worshipping, but it is not the most powerful deity in the world of Go. In the way of Go, KISS beats DRY.
&gt; Casting to/from interface{} is code-smelly. Unless you're trying to verify structural correctness, so that when you Marshal the data as JSON, it will be in a valid structure. Sometimes you really can't treat members of the same interface as identical.
I thought I had explained this in the original post. But I could certainly go more in-depth here. I have a few different types of objects, each of which has an ID and a Group ID. I want to keep a registry of each type of object, that indexes the objects by ID and by group. So I've implemented this as an ObjectManager type and a Manageable interface. The ideal would be using generics, so that each ObjectManager could be statically restricted to a single type of object. This would not only be safer during runtime, but would *immensely* simplify serialization (no need for original question, converting from map[string]Manageable to map[string]Event or whatever other specific type - it's *already* a map of the specific type). Without generics, this is clumsy and arbitrarily difficult, vs. the straightforward generics approach. And before you ask, the ObjectManager does too many things for me to even entertain the idea of copy-pasting it into an EventManager and a QuorumManager etc.
&gt; **Asserting** to/from interface{} is code-smelly. FTFY :)
The isn't being unable to do things due to a lack of generics, it's about generics making certain things easier, particularly iteration helpers over slices such as maps and filters. If we had generics in Go, we'd be able to do something like (assuming imaginary package "slices"): import "slices" nums := []string{"one", "two", "three"} filtered := slices.Filter(nums, func(s string) bool { return len(s) == 3 }) // filtered == []string{"one", "two") Without generics your only real option is to do the heavy lifting yourself: nums := []string{"one", "two", "three"} filtered := []string{} for _, s := range nums { if len(s) == 3 { filtered = append(filtered, s) } } // filtered == []string{"one", "two") There are a couple of benefits in this specific case, one is that the first version is more concise, the second is that the first version is chainable (combining a filter and a map is something you commonly do in higher level languages). There is a drawback though: the second version, while longer, is arguably easier to understand as you're not hiding the nuts and bolts.
But I think that's part of the core statements of the language, no? To be easy to read / understand. In which case, adding such a feature, albeit powerful, would be against what the language is designed for. And so far I've rarely seen code that requires time to understand past the initial read.
&gt; One thing I've seen mentioned is that many functional ideas are tough to implement type-safely in Go. Then don't do it. Go is not an FP language. The target paradigm of Go is imperative programming.
One thing conspicuously missing in Go is a library of data structures, like the STL in C++ or Collections in Java. It's great that append() is type-safe, but if you want a variant that uses a linked list or tree or priority queue, you give up compile-time type safety. That may not appear to be a problem, just like pre-generics Java didn't at the time appear to be a problem, but try going back to that now in Java and you'll see just how much better and safer generics have made the language. On the other hand, I've spent some time in the Java compiler, and it's insane how much of the code is there just to deal with generics. It's a much more complex feature than it might appear. 
Because I already know how to do it with casting... by using casting :P
This is great. I really like your work. I've recently done exactly this type of stuff on my martini server for an auth setup. Am considering generalizing it for contrib and/or making a writeup. Keep trucking dude!
I actually have an example that I posted to /r/golang today! http://www.reddit.com/r/golang/comments/1x6wsg/best_way_to_turn_mapstringsomeinterface_into/ Basically, if you want to define your own container type (in my case, a map that also indexes by group), you are going to have to endure some suffering, in one way or another. It's just a matter of trying to figure out which path is the *least* suffering, based on the scale of the problem/how many places you use the container. Whereas, with generics, there would be one obviously right answer that works regardless of context.
It's not just a problem for FP programming. Attempting to program in Go, lots of data structure things are bloody hard. Sorting a list with structs, for example : http://play.golang.org/p/rIXRapmVtn Shortest I've found so far. What a fucking disaster. Why doesn't this work : x := []Vertex{...} sort.Sort(func(a, b Vertex) { a.X &lt; b.X }, x) It's not just FP. All data structure operations in Go have extremely long-winded implementations. I would say Go is a slightly more modern version of late-90s programming languages, like Oberon or Modula-2, where similar things were necessary for basic data structure operations.
&gt; To be easy to read / understand. In which case, adding such a feature, albeit powerful, would be against what the language is designed for That's not why they're not adding it. It's because it would add too much complexity to the compiler and the rest of the tool chain.
I think you're confusing generics and templates. Your suggestion about Max and Min would only work with templates, C++ style. With generics you'd still need different versions of the functions because each would need a different instantiation, which generics doesn't give you.
&gt; Your suggestion about Max and Min would only work with templates, C++ style. It would also work fine with ML-style and C#-style generics. The only thing it wouldn't work with is Java because Java's erased generics are weird and half-broken.
It seems that the Go authors' opinion is that: "maps and slices should be enough for everybody!" More seriously, this issue seems to be pigeonholing Go to be more of a web dev language, as opposed to a "systems" language.
I think people who adopt the Don't Reapeat Yourself (DRY) principle cringe at the idea of re-implementing collection operations for each data type that they use.
Pre-generics Java didn't have Go's `map` type. To put it another way, Go _does_ have generics. It's just that it only has them for slices, arrays, and ~~lists~~ maps, instead of letting you add them wherever you want.
Yeah what I think MatrixFrog meant to say is "only has them for arrays and maps", which, admittedly, is what you need them most for.
Okay, so they're just like C++ templates and we're just arguing over terminology. I don't know whether the OP was discussing Java-style generics (which really only affect subclasses of Object, or interface{} in Go), or C++-style templates, which can be used for any type, and therefore require code duplication or specialization.
*This has nothing to do with generics* I think you're most likely just adding a lot of noise for no reason. Let's think about it for a second. You have a `map[string]MyInterface` and you clearly intend for it to contain only `UnderlyingType`s. The first question is: why not just have a `map[string]UnderlyingType`. Ok, maybe you were passing that to something else that *needed* it. In that case, the question changes only slightly. Why are you putting things that are not `UnderlyingType`s in there? You aren't? Then the code is simply: result_map := map[string]UnderlyingType{} for key, value := range interface_map { result_map[key] = value.(UnderlyingType) } 
I would just make a "generic" ObjectManager that only deals with Manageables, and then wrap it for each type that uses it. It's repetitive but, unless ObjectManager has a wacky API, it's a trivial problem. I'd probably make the underlying manager unexported, too, so I can guarantee type safety. I tend to run into problems like this because I'm overly focused on having stuff like ObjectManager try to take care of too much. Go's interfaces and lack of generics force you to focus more clearly on separating concerns and laying out contracts. Sometimes it's repetitive and menial but your code will be very clear (and statically type-safe!). 
I'm writing my first biggish project in Go, part of it is regression algorithms. The good: I've never written something so big and performant. I'm wildly productive in Go. My test and doc coverage is almost 100%. I'm clocking in 8 commits/night at a very steady pace. Things just work. The compiler errors are obvious. I love gofmt removing indentation decisions. The bad: Everything is a float64, which isn't too big of a deal. Float32 would be nice if I ever need it. It'll be a dark day when %s/float64/float32/g The other issue that's bugging me is the lack of operator overloading. No matter how much I clean up a BLAS interface, my linear algebra code looks ((((l)(is)(p)(y)))). I don't yet have a clean solution for multidimensional slices not being contiguous in memory. I've dabbled in Rust and Haskell. The parametric polymorphism in Haskell comes free of charge. It doesn't translate quite as well in Rust. That might change, but last I tried they don't have a working solution of the Num problem yet. All things considered though, I really love Go. It solves a lot of problems that most languages ignore.
This seems like the ideal solution, I'll see about doing it this way.
`gofmt -r 'float64 -&gt; float32' *.go` is safer than a regex.
Ah, this alternative is not type safe then. But still, why define `len()` and `swap()` in addition to `Less()`, and not just the latter?
No, it's not type safe. Not at compile time anyway. Cases like that are why people complain about the lack of generics. `Len()` and `Swap()` are needed because `sort.Interface` is not strictly for sorting arrays/slices. You can in theory implement the interface for custom containers. I had a quick play around, and couldn't get Go to accept something like `[]Vertex` as `[]Sortable` even when `Vertex` implements `Sortable`. Either I'm doing something wrong, or Gos type system won't allow it.
&gt; Potentially, but any time something is built directly into the language, it means it can't be extended. That's exactly right. Building things into the language makes things easy for the easy things and then unnecessarily complex for the harder things. I have this problem with maps right now. They are so convenient that using anything else for key-value pairs would be crazy. But. There's an API I'm replicating in go that I already have in C that handles a tree of keys with values. One of the operations that I need to provide is an iterator with a well defined sorting order. Now I have a choice. Either use maps over all of the code because it's pretty and fast and implement the iterator by copying the map, sort it, then iterate over the sorted copy, or roll my own tree implementation and be unnecessarily verbose all over the code. I do the sorting now, but I'll probably be forced to roll my own implementation of everything before getting this into production because those iterators are used very often and are performance critical. And I know it will not be as fast as the C code because in C I could do a generic implementation of trees with inline data structures and some pointer magic and in go either I will have to rewrite the tree implementation every time I need something stored in a tree to get the types safe or make the whole thing not inline and much slower. Which actually nicely leads us back to generics. In C I can make things efficient and generic by ignoring type safety and doing clever things with pointers, in go I can't and it doesn't provide an adequate replacement mechanism (like generics).
The place I most commonly find myself thinking generics would be useful is when I end up rewriting the sort.Interface functions over and over for a new type of struct or something I need to sort. Invariably, it looks like: type sortMyStruct []*myStruct func (s sortMyStruct) Len() int { return len(s) } func (s sortMyStruct) Less(i, j int) bool { return s[i].foo &lt; s[j].foo } func (s sortMyStruct) Swap(i, j int) { s[i], s[j] = s[j], s[i] } And, well, that only took a moment to write. Yeah, it's kind of annoying, but the diatribes I've read whining about the lack of generics are often longer than the code necessary in their absence. I'm a big fan of Go, and still painfully aware of its limitations. But you can't let perfection be the enemy of good. It's usually good enough.
He says he's not aware of generic arrays and then you say you meant generic arrays?
A pure go reference blas is being written then could be used as a basis for producing the asm code. This would be straight asm without simd, but could be massaged to lose the bounds checks. The simd could then be added after for the additional performance.
Yeah, and Google has already given out grant money for real refactoring tools. Which are going to be open source and not tied to an IDE, so hopefully we will see plugins to all the major editors and IDEs.
A "filter" call _is_ easier to read and understand. When you see a filter call, you know it's going to iterate over each element once, call a function on it that returns true or false, and include it in the new list it returns if the function returned true. When reading a manual implementation of it, you _must_ individually verify each of those statements, because if you just skim over it, you might miss the fact that it superficially looks like a filter but does something slightly (or even substantially) different. (One easy example would be if someone implemented "something like a filter but it keeps the values that the function returns _false_ for"; a very small, one-character change that completely changes everything, and when you're spelling functions out manually, exactly the sort of shortcut you'd be inclined to take.) In other words, there's _absolutely nothing exceptional_ about this code because that's just a principle in general. Clarity of coding is not about having to spell out certain bits of code over and over... indeed, if one thinks clearly about that, that's a recipe for _unclear_ code, where you can't see what it's doing because it's too busy taking care of low level details. Clarity of code is obtained when correct abstractions are chosen and implemented so that each function shows what it does, at the correct layer of abstraction for that function, and no other extraneous details. Needless repetition inhibits that, it is not a help, and the fact that Go currently has a few weaknesses on that front is indeed a weakness for generating clear code. In other words, if you're going to claim that code clarity is obtained by essentially inlining code everywhere, then why just _here_? Why just for this code? There's nothing that special going on here. It very nearly amounts to a claim that functions aren't good for code clarity. I think it's not something anybody would even remotely take seriously if there wasn't a somewhat pathological attitude in the Go community about generics, in which people will suddenly take patently absurd claims and defenses seriously if it lets them rationalize how wonderful Go is here. There's a much easier way to deal with this, which is to understand that there's no _need_ for Go to be perfect in every way to be useful and even at times the best choice for a task, and there is therefore no reason to surrender all rationality and discretion at the altar of "Go Is Perfect And If You Don't Get That You, Personally, Suck". This isn't some brilliant code-clarity design from the unimpeachably-smart designers of Go; this is a probably-temporary limitation of the language because they did not want to charge in with a bad implementation of such an important feature, which is a fine choice. Those of use here who have confused the two would do well to keep these two separate things straight.
/u/islandberry changed their comment -- originally it was asking about lists, and Go has no built-in type called "list" anyway. But, they have a point. Arrays are generic (you can have an array of T, for any type T) but you can't write generic functions for arrays.
Definitely this. Anything constructed with `make()` _is_ generic, but you can't define your own things to be make-able. If you want your own container of typed things, you can't build it in the way that slices/arrays/maps are built-in. For user-level sets, tries, graph nodes, whatever, the choices are: 1. Write it for a fixed data type: every node's data has to be float64 or whatever. Write multiple near-identical versions for multiple data types, if needed. But, you get to keep compile-time type-checking. 2. Write it to store `interface{}`s, make user code assert types, and lose compile-time type-checking. 3. Hack it onto the built-in data types. Represent "set of Foo" as a `map[Foo]boolean` and treat the keys as the set's elements. Depending on the representation, this could waste a lot of memory. None of these really strike me as particularly good ways to write code. Still, I'm personally using Go for small enough things that #1 is my typical approach.
C# generics are not like C++ templates. You can't do this in C#: T Sum&lt;T&gt; (T one, T two) { return one + two; } But you can do it in C++. 
&gt;With how flexible types and interfaces are, what problems that seem to need &gt;generics turn out to be problems because of thinking in terms of a different &gt;language? If you design your interfaces well and design your objects with an emphasis on composition and modularity, you can avoid most woes of not having template generics. The fact that Go lacks templates and operating overloading means that the language has a hard time creating a type that mimics the properties of "map" object, or "channel". The authors ameliorate the lack of generics in the language, by providing these special types built in to the language. &gt;Are any of the cases really instances of choosing an interface that should have &gt;been approached differently in hindsight? It depends on how you design. I find that trying to avoid defining overly complex interfaces (ie interfaces with alot of methods defined) allows for most polymorphic code. For example consider the Reader and Writer interfaces. They are simple, and thus it is easy to define my own types that can exploit methods that has Reader or Writer arguments. It is encouraged to exploit these standard interfaces in your own code when possible because that allows for more generic functionality. &gt;Is one of the problems about using built-ins like maps and channels "raw" rather &gt;than wrapping them for different uses? I dont think so. Like I mentioned earlier those are special types that are provided because the language lacks generics. &gt;Looking at the sort section of the standard library shows a novel approach to a &gt;collection type that avoids the need for a generic collection completely- can that &gt;sort of thing help with some of the use cases that need generics? What needs to be understood is that empty interfaces require type assertion or reflection to be useful once they are used in the Sort pkg's container types. People typically feel this is an unnecessary expense on performance that generic templates would avoid. What I have done in code to avoid this concern is to copy the Sort pkg code, and paste it into my pkg, replacing the empty interface with interfaces that actually exposes the methods I intend to be able use without having to resort to reflection or type assertion. &gt;How much of this is chafing from people used to languages with dynamic or &gt;inferred types? How much is from those who learned from static types? Go is a static type safe language that feels like a dynamic language. Anybody who is used to a specific language type system will find Go awkward initially. &gt;Considering how much of a mess it is to write stuff that handles generics in other &gt;languages (seeing that writing for generics in other languages is orders of &gt;magnitude trickier than merely using generics in said languages), in what cases &gt;would generics really simplify the code? Or would it just simplify using libraries &gt;while making the writing of libraries harder? IMHO, generics almost never simplify code. I mean just look at the standard C++ library code. http://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/a01475_source.html Imagine having to debug this. 
I'm aware of that link from before I posted.
Who are we sending money to?
Umm whhhhhaaaattttt. That's amazing.
Thanks, good to have confirmation! (The page of fundly for the user running the campaign was basically blank)
 func (self *Person) SetDefaults() { self.Foo = "Person" } Or func NewPerson() *Person { return &amp;Person{Foo:"Person"} } 
Thanks jan; I understand how to use the function. What I'm asking is 'why' we need to use the function. As in 'why' have the devs avoided that super simple syntax in my example?
Go would rather not add extra syntax for things that can be accomplished easily with other methods. It's core to the philosophy behind the language.
Fair enough. I'll use a function to initialize. Thanks for the reply.
From what I've seen in the standard library, the second way of doing it (`NewPerson()`, or, if on more of a package scope, `person.New()`) is more idiomatic. But I do think this is the answer.
NewTypeName() is the most common way of making a constructor in Go, btw, the second suggestion that Jan gave above. 
The way Go is now, if you see `p := Person{}`, you know it's going to create a `Person` struct, and it's going to initialize all the fields in that struct to their zero value, and that it's not going to do anything else. But suppose we take your suggestion. Then someone might write: type Person struct { Name string = nextName() } where `nextName` is an elaborate function that picks a name from a list or something. Now `p := Person{}` could be doing *anything* (much like a constructor in C++) and you don't know what it's really doing unless you inspect the definition of `Person`. Maybe you could mitigate that by limiting what you're allowed to use as default values (e.g. string/number/struct literals only) but it would still add some unnecessary complexity, I think. I don't know if it's intentional, but I think the lack of a "default value" feature also makes the language "feel" a little different from other OOP languages I know. Structs in Go are not like classes in other languages. They're just chunks of data, that you can tack methods onto. No constructors, destructors, virtual methods, abstract methods, or subclasses. Simple but powerful.
Hey everyone, I'm the original author of that post, and I just wanted to say thanks for your comments and conversation. Concurrency vs Parallelism... unfortunately the terms are open to interpretation. I used a very simple definition based on a narrow set of what both features offer, and it served my purposes. Performance... I could probably have worded the article differently. My intention wasn't to state that Go offers a literal equivalent to C performance, or that it is literally faster than Java in every sense. For a language that is only a few years old, I think Go does a wonderful job of offering a balance of performance vs productivity. Of course, if you want pure performance, you'll write in assembler, but then productivity goes out the window. If you want pure productivity, you'll write in Ruby/Rails (or Python etc), but then performance goes out the window. Go is definitely closer to C than it is to Ruby, while retaining productivity. On top of that, considering Java has had a massive number of years to optimise, I'm not surprised that Java is quicker. But remember, in the first few years of Java it had woeful performance, and was certainly nowhere near where Go is after only 3 years. "This author doesn't know much about Go". True. I am no expert. However I find that the best way to learn is to teach. Some of you are obviously experts, and thus you are probably not the intended audience for my article. Those that are new to Go may find my simpler understanding and explanation of the language beneficial, and as I go through my journey of discovering the language, I may be able to help others along the way.
There we go. That made it super clear. Thanks a bunch!
It's also worth observing that the "simple" task of object initialization has become a nightmare in languages like C++. Cutting through the Gordian knot by just not making object initialization "special" and letting normal code handle it makes a lot of opaque, difficult-to-correctly-compose, and sometimes just plain bizarre corner cases just go away. And, frankly, "automatic" object initialization just isn't that special in the first place to justify such a weird wart.
Never mind, found it in the README! https://github.com/jingweno/gh#homebrew
The way I see it, interfaces are abstract definitions of contracts, not actual "things". They just define the way an actual object would behave if it can be considered an "X". Being abstract enforcement of contracts, they contain no behavior. 
From the golang FAQ: &gt;Rather than requiring the programmer to declare ahead of time that two types are related, in Go a type automatically satisfies any interface that specifies a subset of its methods. Besides reducing the bookkeeping, this approach has real advantages. Types can satisfy many interfaces at once, without the complexities of traditional multiple inheritance. Interfaces can be very lightweightan interface with one or even zero methods can express a useful concept. Interfaces can be added after the fact if a new idea comes along or for testingwithout annotating the original types. Because there are no explicit relationships between types and interfaces, there is no type hierarchy to manage or discuss. This quote was copied from the FAQ question [Why is there no type inheritance?](http://golang.org/doc/faq#inheritance)
Totally +1. Just wants to add that you can also define methods on any type (like int etc) except interfaces.. :)
Yes, I know what an Interface and an Abstract Class; from Java and C++ is. What I'm asking is why is Go's Interfaces not more like Traits (http://scg.unibe.ch/archive/papers/Scha03aTraits.pdf)  also know as Flavors in Smalltalk, Mixin's in Ruby, Roles in Perl. It seems like a very small step to go from Interfaces as Go defines them to limited traits as defined by the fore mentioned paper. It's about being able to compose behavior side-ways; something (in my opinion) Go's implicate interfaces moves us towards.
But, if it's all about behavior, why can't you add additional behavior onto of expected behavior. In my example I'm not adding any additional state. Just added behavior that's build on expected behavior? Especially, since this just falls out of the language.
I think what you want is similar to what are called embedded classes in golang. You can embed classes in other classes by specifying them in the class members without var names. The methods of those embedded classes can be called directly off the higher level class. I don't think they are quite as flexible as the mixins that you want however -- I don't think the mixins would have easy access to parent class variables -- although I haven't really thought it through. Go's reflection capability and support for C and assembler makes extending the language through user written packages quite feasible. I think embedded classes with reflection would allow for mixin capability. Go is purposely a very simple language. I find it much more elegant and usable than C++ for example. Well I hate C++ anyhow. But I can't even see using a language I like, like Python, now that I have go. Sometimes you just have to be willing to think in terms of the language you are using, or use ruby or whatever if what you really want is ruby. Everybody asks the Go designers "Why not this?" http://golang.org/doc/faq#Why_doesnt_Go_have_feature_X . I personally am happy that they haven't crudded up the language. If you try to make go another language you may be missing the unique advantages of go.
Thanks, I didn't know about tabwriter in the standard library. Just to clarify, the table library is just a small part of the hadoopconf util, which gives you an easy way to configure and look at Hadoop configuration. 
We @countersoft have just offered to pick up the entire $7.5k cost of sponsoring/getting the talks online for the benefit of the entire Golang community... 
Flowing idiomatic Go, interfaces are just a way to describe behavior and not a place to put code that does things with that interface. You would make an interface Fooer and the out code that does things with Fooer into FooerUtils or something. I suppose they could add this functionality to the language without breaking anything but keeping it separate does help keep the language tight and simple. Doing things this way flips the design process on its head (bottom up vs top down) but makes for surprisingly simple and flexible code. 
Just make a function that takes an interface as its first argument. That's all methods are in Go anyway. Who needs a class to attach the function to? If you absolutely must have a class, just make a wrapper struct. type Fooer interface {} type FooPlus struct { Fooer } func (f FooPlus) multiOnIn(other FooPlus) { ... }
&gt; But, if it's all about behavior, why can't you add additional behavior onto of expected behavior. Because each type that implements that interface has different internals and would want to implement that method differently. If all the types that implement an interface will do something the same way regardless of what type they are, that's not polymorphism. You can just write a function that takes that interface as a parameter in that case. 
&gt; Could someone please tell me the reason why this was not designed into to language. Unless someone from the core team reads this sub, all we can do here is speculate.
The main problem is that a type may satisfy multiple interfaces. What if multiple interfaces define a method - which of them should be chosen for execution?
This is a *very* cool writeup. I really like RethinkDB a lot (anyone reading- check out the admin interface if you haven't already, it's super slick). Martini looks really cool and I appreciate the minimalism as Revel kind of turned me off a little bit in being too big without providing that much value. At the same time, raw handlers + gorilla toolkit libraries mostly get the job done but leave a little to be desired in terms of architecture / clean code (not gonna lie, I like a little handholding in this regard- kind of neurotic like that). Gingko is the least familiar to me of the three but it looks very cool as well. Thanks for the writeup / tutorial and cheers!
The problem with putting methods on interfaces is that you couldn't sanely use them to satisfy other interfaces  you'd get some sort of weird Russian nesting doll syndrome, along with issues around type assertions and method resolution. And if the methods can't be used to satisfy interfaces, there's not really any point in them being methods anyways, since they wouldn't provide any polymorphism. As others have mentioned, you can use type embedding in order to accomplish something like what you want, with the benefit of making the structure explicit and thus easier to reason about. More likely, though, is that you'd just use a function instead, 
&gt; They just define the way an actual object would behave if it can be considered an "X" Isn't that what the OP was asking for then? Once some abstract interfaces have been defined, it might be possible to sometimes define not just the typing behavior but also the runtime behavior. Say you have an interface that defines an *equals* and *less_than* methods. Now you can build up *not_equals*, *greater_than*", "*less_than_equals*", "*greater_than_equals*" for example. Any object that defines those two can get the other ones as well. Floats and Integers might have a different implementations of "*equals*" and "*less_than*". But once those are implemented, they don't each have to separate implement all the other ones. 
Had a busy week but finally came around to add the error handling to Decode() :)
Yeah, I was hoping someone from the core team was reading this sub. :P I should post the question to go-nuts.
Are there any languages that allow methods to be fully defined for interfaces, rather than simply specified as signatures? Doesn't that make them abstract classes?
True, interfaces don't contain proper methods _by definition_, but it doesn't answer what appears to be OP's intended question.
Basically says....nothing...Other than dick swinging.
+1 for simplicity. I keep saying that Go is one of the simplest, most practical languages I've ever used. Sure, it lacks some "features" but some of its most sublime features are subtle ones that come from its engineering.
I'm from the core team; [angrychuckle](http://www.reddit.com/r/golang/comments/1xd1ko/what_is_the_reason_that_we_are_not_allowed_to/cfa990t) is pretty much spot on. However, take a look at [this example](http://play.golang.org/p/pv7o3G32I1). It demonstrates that interfaces aren't something that with which you "wrap" a value. They are more superficial, mere transient labels that you give values temporarily, so the compiler can verify you're using the right thing in the right place. So if you could add methods to interface types, how could a value of that interface type every satisfy another interface? As soon as you convert it to the new interface type, the original interface type is forgotten.
And Github is going to move towards it for their official hub implementation.. https://github.com/github/hub/issues/475
I never know whether it's me or the project that's dumb when I can't figure out what the hell it's for.
You probably don't want to put your mailchip api keys out in the public, so you need to have something running on the server side to make the post to mailchip. This seems like a very light-weight way to do it.
You probably don't want to put your mailchip api keys out in the public, so you need to have something running on the server side to make the post to mailchip. This seems like a very light-weight way to do it.
You can just create a form through the Mailchimp interface, and get the plain HTML code which just POSTs to a URL to register your users. Still, a good small app for getting started with Go.
Ah, I wasn't aware mail chimp let you do that.
I'm going. Who else is going to this? 
mailchimp explains why one wouldn't want to go [all static](http://apidocs.mailchimp.com/api/how-to/basic-subscribe.php). And yeah learning experience! Also I was surprised how little code it took to accomplish
The README has an overview of the project, which essentially started as a means for me to get a feel for Go. If anyone finds it useful, then that would just be a great bonus. From the README: &gt;Basically, geto can be used to offload an arbitrary task to another, target, host and retrieve results. &gt;You might want to use geto if you have a machine (or more) that needs to offload work to other machines. Geto code is only required on machines from which the work is offloaded; geto is not required (or in any way useful) on the target host machines.
Looks interesting to me. Are you sending compiled binaries to the hosts? How do you handle different architectures?
I'm going and very excited about it!
Any suggestions/improvements are welcome! It's a wrapper around the time package with some handy helper functions and methods. 
Constant switching from code/slides to guy talking was irritating :/
[Table Writer](https://github.com/olekukonko/tablewriter) updated and now has support for - Optional Headers - Optional row lines - Set Borders - Set Footer - [Simple command line tool](https://github.com/olekukonko/tablewriter/tree/master/csv2table) With this options you can create something like : DATE | DESCRIPTION | CV2 | AMOUNT +----------+--------------------------+-------+---------+ 1/1/2014 | Domain name | 2233 | $10.98 1/1/2014 | January Hosting | 2233 | $54.95 1/4/2014 | February Hosting | 2233 | $51.00 1/4/2014 | February Extra Bandwidth | 2233 | $30.00 +----------+--------------------------+-------+---------+ TOTAL | $146 93 +-------+---------+ 
Oh, I wish I knew there was a Vancouver golang meetup group! Where can I sign up?
Write martini middleware to get the spdy interface before other middleware hides it with a response writer wrapper. Use dep injection to pass the spdy interface to handlers.
Thank you both - I'll give it a shot. The fact that something could lose an interface like that was really throwing me for a loop.
I seem to recall that MySQL doesn't support rollbacks of changes to the schema, but I'm not sure if they forbid schema changes in a transaction. If they are forbidden, then this package just won't work at all with MySQL. Otherwise, it will "work", but without rollback support.
The Golang Vancouver page is at http://www.meetup.com/golangvan/ . For a more complete list of Go user groups, see https://code.google.com/p/go-wiki/wiki/GoUserGroups .
My roommates a huge MTG geek, so he's probably going to be really excited when I show him this! How are you getting your card data?
Card data is pulled from [mtgjson.com](http://mtgjson.com). I manually created the [banned and restricted lists for formats](https://github.com/kyleconroy/deckbrew-api/tree/master/formats). 
Thanks for this... I know this was posted back when it originally came out, but I couldn't find it in this subreddit.
Spdy author here. Just replying so I get notifications on updates. It sounds like this should work fine. Good luck.
Yes, absolutely write up your experiences!
with a websocket api, this could be useful
Damn I better buy mine then
Yes please. I'd be also interested in finding out if the system you created is available (in full or part) via some other library like Gorilla for example.
Yes, please write up something. Would love to see what you learned.
How exactly? Can you explain in detail?
Yes, please.
That would be great! Please do! Is it available on GitHub?
Thanks for the responses!! Alright, I'll definitely make a write up. The source is on bitbucket. I'll clean up a lot of the cruft before the write up - writing from mobile ATM. http://bitbucket.org/levilovelock/webserver 
&gt; Used SHA2 + Salt for password hashing just don't publicize it in the post you are going to write and go with something standard like bcrypt http://godoc.org/code.google.com/p/go.crypto 
You can follow this link : http://golangtutorials.blogspot.com/ and http://golang.org/doc/effective_go.html :)
Of course there's nothing in the language itself that makes it a bad first language. The comment was about the lack of tutorials for newbies, compared to most other languages.
https://gobyexample.com/ and http://learnxinyminutes.com/docs/go/ are great for getting started. Also take the interactive tour if you haven't done so already. http://tour.golang.org
Good luck; it's a long way down the rabbit hole. For an absolute newbie, you should focus on the basics: loops, selection, function calls. As a kid I learned by writing number guessing games and such, and that should be just as easy in Go.
Rabbit hole? You mean the gopher hole! :)
DNS failing to resolve on golangvan.org for anyone else?
Got me there :)
Although they are mainly targeted toward experienced developers, https://gophercasts.io/ has some getting started videos and a brief overview of some of the language constructs
&gt; tough because: go is a mid level language. &gt; easy because : The language is very small.
Bah, I was hoping maybe they had fixed it by now. This was the primary reason why I switched to Postgres a few years ago. Thanks for trying though!
Not sure I see the point, since we already have `basename`, `dirname`, and `readlink` as standard UNIX utilities.
It's by no means ground breaking and everything it does can be done with bash. But it does add a few extra features and I find it really cleans up my one liners. for example: find . -type f | xargs path -x | grep -v '^$' | sort | uniq -c
Just curious, what does postgres do when you alter the schema of your 100 terabyte table in a transaction?
Dunno. Never worked with data even close to that big and I'm no expert on DB internals. I also couldn't find any in depth literature on how DDL rollbacks work in PostgreSQL after a quick search. Although, I'd imagine that *any* `ALTER TABLE` is going to cause the creation of a new table followed by a copy. But that's just an educated guess.
Noting that I'm successfully running Go 1.2 binaries with CGO on android/arm, cross-compiled from darwin/amd64 (my macbook). You can check out the Makefiles in libtorrent-go[1] and torrent2http[2] [1] https://github.com/steeve/libtorrent-go [2] https://github.com/steeve/torrent2http 
Beside flexible asserts my Go Test Support provides a generator package. See http://godoc.org/git.tideland.biz/gots. The text and name generator currently gets a more flexible change and new functions for the generation of times are added.
Someone care to explain what is 100% precise GC?
Awesome, thank you!
Could you give a bit more guidance about what your role on the project is going to be? General advice can and has been given, but specific advice could be better.
GC means "Garbage Collection". Rather than the programmer caring when memory is no longer holding an active thing and returning or repurposing it, it becomes the runtimes responsibility to do so. A GC will have a basic set of things that are "alive", like the stack or global objects that have been declared so somehow, and will look for things not connected to this group to get rid of. If things are connected in a loop, GC has to be trickier about collecting it, but it's still possible to notice the loop is disconnected from the "live set". An imprecise GC is mostly ignorant of the running program, and guesses whether any given live value is a pointer, especially on the stack, and might keep things around that are really free if there happens to be an integer or series of characters or whatever that looks like a pointer to that object, because it can't tell that that chunk of live memory isn't actually pointing at anything. Precise GC knows what is a pointer and is always sure what to collect, so it never accidentally keeps around that 3GB value because an int happens to have the same value as the pointer.
Alright, that makes sense. I'll do that tonight! UPDATE: bcrypt is the way to go! Very easy to switch out. Thanks guys
Question about imprecise GC from someone who has briefly played with GC in toy language runtimes: What characteristics of a value determine whether it is an integer or pointer (or float for that matter) assuming they are the same size in bytes?
That question is what makes imprecise GC imprecise. There isn't anything to differentiate them. Making the program able to differentiate them is what precise GC is.
Why not use [html/template](http://golang.org/pkg/html/template/)?
Thanks for the response guys - I've got a few programmer buddies who are happy to help be grasp the basics and go on from there. I'll look into all the suggestions made here - Danke! 
Thanks i have been curious about this for a while (just not enough to Google it myself, ha). What's the benefit of doing GC like this instead of something with reference counting besides a CPU/memory tradeoff? Or am I missing something?
It's all trade offs. Reference counting is super easy for the non-looping cases, but requires a lot of writing to memory to keep track of how many references anything currently has. 
Yes please! I'm actually using authsession from the martini contrib right now. I'm done auth/login stuff but I just need the other half, registering users!
In a multithreaded environment reference counting requires syncing every time a reference count is changed. That gets expensive.
I really have to say that Dmitry Vyukov does some super awesome work.
Are atomic increment and decrement operations really that bad?
You make the best web-dev Go tutorials, period. Especially since Gin/Martini stack is awesome.
When you talk about looping cases do you mean circular references or actual, say, "for" loops? And specifically with Go might it help that it optimizes things to the stack when it can? I'm not sure why I'm so interested in this, I guess further research is necessary!
Seriously, I've logged in only to down-vote you. Now, you go back, fill the missing pieces elaborating on why "Google Go fixed your all problems", what problems they were and how you measured the solution and then you can come back.
A comparison with html/template would be useful.
They are when you're doing them constantly in a loop. Pointers get copied pretty often.
vs. not doing an extra memory read/write every time a pointer is assigned/goes out of scope, it's pretty bad - and a bit worse when it has to be atomic. 
I was referring to circular references, which prevent reference counted memory from ever reaching zero references.
I've just made some commits with user addition tonight. Check out the usermanager_test.go test suite and maybe, just maybe it may make some sense to you :)
It is html/template. The render package is just a nice interface that handles all the template loading and responsewriter writing for you.
Like a linked list that has a pointer to the head in any of the child nodes. a =&gt; b =&gt; c ^======/ While this is a simple case, some things can become huge trees of pointers. Being able to decide if none of the objects have pointers from the heap/stack is a challenge if you don't want to walk every single object taking polynomial time. Or write counters to memory with every assignment operation. 
Thanks! We are always open to feedback and improving the quality that we can deliver. It's exciting to see people looking forward to a new cast each week
Just when you thought Go couldn't get any better...
The stars counter looks shady on this one...
Shameless self-plug: http://danjou.de/goup/ EDIT: Why the downvotes? It's very similar to OPs project. UPDATE This was my first Go project. It's a single-file file server with upload capabilities. Some more features but also some more LoC than OP's project.
Is bcrypt the best one out of all of them? I'm using it right now, but I see sha3 in the package and it won some award last year. Not sure if I should switch over. 
Does your CreateUser() assume that the password has been hashed already before being passed in? It's because I see that InsertUser() doesn't hash and just inserts it in the db. 
I think this might replace a python script I use for situations where I'm working on some remote server and something (clang static analyzer, sphinx, doxygen, go tool cover, etc...) generates a directory of html and/or images that I want to look at in a web browser.
Also take a look at srvdir.net for a pre-built solution that can serve files for all your needs.
... Good point, cheers for spotting.
Thanks!
Wrong title: I was there and Keith Rarick was not there to explain Dependency Management. You can see this by watching the video.
Hmmm... YouTube has it wrong then. Oops. :(
Hey just the first thing I saw. for i:= 3; i*i &lt;= n; i = i + 2 { if n%i == 0 { return false } } More idiomatic imho. Also gets rid of loss of information in going from a double to a float. Other gophers may scold you for your use of panic, since where you're using the assert, you should just be returning an error. Just some stuff to think about.
How comes its got 250 stars in first few hours, and than nothing more...I'm sorry for being an asshole, I'm just curious.
I don't know if editing a post updates your inbox, so I'm making another with my findings. Martini itself is wrapping http.ResponseWriter in a martini.ResponseWriter and exposing that via injection rather than the raw http.ResponseWriter passed into ServeHTTP. This means the spdy type info is being lost 100% of the time - middleware doesn't help since what I'm getting back in the handler definition already has the type info lost. Changing c.MapTo(c.rw, (*http.ResponseWriter)(nil)) in createContext to c.MapTo(res, (*http.ResponseWriter)(nil)) fixes my issue, as long as I don't use any of the handlers that depend upon the injected response being a martini.ResponseWriter. Perhaps doing this and adding an additional mapping of martini.ResponseWriter to its own interface would be beneficial? Or maybe adding a "super" field to the responseWriter struct with the unwrapped version available?
Don't worry about the script- python3: $ python -m http.server python2: $ python -m SimpleHTTPServer
I heard this is not fit for serious traffic...
Some short documentation would help a lot. Contributors start as users, and to get users you'll have to let people know how to use it. 
I added binaries for multiple platforms
&gt; srvdir.net Nice, but this is for other use cases (see README)
Probably not, but I was mainly replying to the comment above me. Really handy if you have python on the machine you're looking at (which if it's a *nix machine is going to be 90% of the time). If a machine that was designed to handle "serious traffic" had its application broke, and for some crazy reason the best current solution was pointing to a static directory to serve, I'd probably just quickly write in a simple document root config and point nginx / apache at it rather than anything else. 
I'll remove you from the possible markets list then :)
Thanks for the feedback. You are right, `IsPrime` is much simpler this way. `Assert` mimics asserts from other languages. I use it rarely in small "scripts" but not in production. Is `i = i + 2` preferred over `i += 2` in Go?
Thanks for the memories. :) I remember when I was a kid coding up that fractal on my Apple ][+ in BASIC (the code was out of a book, I think). It looked just like that, but the color matches because all I had was a monochrome green monitor.
I agree, but the project isn't really ready for use yet. I'll be sure to throw together my design thoughts however.
Minor nit: to me this is not a lint tool. It is a style checker (which is a valuable tool as well). Lint normally checks your program for possible incorrect usage which could lead to runtime errors. For instance, not checking error returns, possibly indexing off the end of an array (or slice), etc. go vet works somewhat as a lint, but does not go far enough. While jslint muddles lint with style checks, IMO, these should two different tools, though, I suppose only old C programmers like myself really care about this distinction.
"go vet" is closer to the traditional C linter. 
https://github.com/kisielk/errcheck
Don't forget govet as well: go tool vet I played with golint yesterday and the flagging of comments was good but the variable naming was a bit nitpicky. Compared with more error-prone languages like javascript where jshint is practically mandatory I don't think golint is quite as useful. I find the language itself, gofmt and the compiler errors are a pretty solid combination.
I've been using [goconvey](http://goconvey.co/) to run all my test suites recently, even though most of my tests only use the testing package and not the goconvey package. It shows coverage for every package in the tree that it's watching.
So simple but actually really useful.
The talks were all recorded and will show up http://video.fosdem.org/2014/K4601/ when they're ready. Edit: Aram's slides are at https://bitbucket.org/4ad/gofosdem2014
Fear not: the videos exist. I saw snippets of the raw bits. They're still in the queue to be edited for cut points and audio and alignment and whatnot.
Was hoping for squeaking, was disappointed, still an interesting use of Go, multi-channel networked audio is yet another thing Go can make easy.
I think there are several Pythonistas here, so this could be interesting for them. Note that in `present` you can embed any scripting language (if the first line starts with a shebang).
[OT] Why they are burning books?
I gave the talk, the slides are here: https://bitbucket.org/4ad/gofosdem2014. The number files are the slides themselves and porting.talk are my speaker notes. The talk was not as good as I hoped it would be, lack of practice made me underestimate the time it would take to talk about things so I only talked about one third or maybe half the things I'd hoped to talk about, and I didn't show any demos. Sorry about that! Next time it will be better, I promise. In the meantime, I I will write in detail about my experience, eventually. If you have any questions about your port to Haiku please CC me (aram) in any threads you might post on the mailing list, otherwise I might miss your mails. 
Or you can just set `$CDPATH`. oos:aram; cd os /home/aram/go/src/pkg/os oos:os; cd net /home/aram/go/src/pkg/net oos:net; cd runtime /home/aram/go/src/pkg/runtime oos:runtime; cd signal /home/aram/go/src/pkg/os/signal oos:signal; cd http /home/aram/go/src/pkg/net/http oos:http; cd fmt /home/aram/go/src/pkg/fmt oos:fmt; My `$CDPATH` is oos:fmt; echo $CDPATH .:/home/aram:/home/aram/go/src/pkg:/home/aram/go/src/pkg/archive:/home/aram/go/src/pkg/archive/tar:/home/aram/go/src/pkg/archive/zip:/home/aram/go/src/pkg/compress:/home/aram/go/src/pkg/compress/bzip2:/home/aram/go/src/pkg/compress/gzip:/home/aram/go/src/pkg/container:/home/aram/go/src/pkg/crypto:/home/aram/go/src/pkg/crypto/ecdsa:/home/aram/go/src/pkg/crypto/rsa:/home/aram/go/src/pkg/crypto/tls:/home/aram/go/src/pkg/crypto/x509:/home/aram/go/src/pkg/database:/home/aram/go/src/pkg/database/sql:/home/aram/go/src/pkg/debug:/home/aram/go/src/pkg/debug/dwarf:/home/aram/go/src/pkg/debug/elf:/home/aram/go/src/pkg/debug/macho:/home/aram/go/src/pkg/debug/pe:/home/aram/go/src/pkg/debug/plan9obj:/home/aram/go/src/pkg/encoding:/home/aram/go/src/pkg/encoding/json:/home/aram/go/src/pkg/go:/home/aram/go/src/pkg/go/build:/home/aram/go/src/pkg/go/build/testdata:/home/aram/go/src/pkg/go/build/testdata/other:/home/aram/go/src/pkg/go/doc:/home/aram/go/src/pkg/go/parser:/home/aram/go/src/pkg/go/printer:/home/aram/go/src/pkg/hash:/home/aram/go/src/pkg/html:/home/aram/go/src/pkg/image:/home/aram/go/src/pkg/image/color:/home/aram/go/src/pkg/image/png:/home/aram/go/src/pkg/image/png/testdata:/home/aram/go/src/pkg/index:/home/aram/go/src/pkg/io:/home/aram/go/src/pkg/log:/home/aram/go/src/pkg/math:/home/aram/go/src/pkg/mime:/home/aram/go/src/pkg/mime/multipart:/home/aram/go/src/pkg/net:/home/aram/go/src/pkg/net/http:/home/aram/go/src/pkg/net/http/cgi:/home/aram/go/src/pkg/net/rpc:/home/aram/go/src/pkg/os:/home/aram/go/src/pkg/path:/home/aram/go/src/pkg/regexp:/home/aram/go/src/pkg/runtime:/home/aram/go/src/pkg/runtime/race:/home/aram/go/src/pkg/strconv:/home/aram/go/src/pkg/sync:/home/aram/go/src/pkg/testing:/home/aram/go/src/pkg/text:/home/aram/go/src/pkg/text/template:/home/aram/go/src/pkg/unicode:/home/aram/go/src/cmd:/home/aram/go:/home/aram/go/src:/home/aram/go/src/cmd:/home/aram/go/src/pkg:/home/aram/go/src/pkg/runtime I did not write that though, my .profile generates it: # Add to $CDPATH non-leaf directories from $HOME/src, common names excluded. if [ -d $HOME/src ]; then cdpaths="$(find $HOME/src -mindepth 1 -type d | egrep -v '/(\.)|_[a-zA-Z0-9]' | egrep -v 'bin|cmd|doc|lib|pkg|test' | xargs -n1 dirname | sort | uniq)" for i in $cdpaths; do CDPATH=$CDPATH:$i done fi
don't blame yourself too much, 4ad. The schedules at FOSDEM 2014 were insane. And most talks could be divided between a) "experienced talker knows he has no time and thus gives a very superficial talk ending with 'if you have any questions, come see me afterward'". everybody is frustrated becaue nobody wants to stand up and lose his chair/seat. b) talker has to stop just as he gets to the actual meat of the presentation. everybody is frustrated.
Yeah, right? "Such innocent-looking cute little gophers... oh wait, what are they doing? Burning books?"
They are C++ manuals. See http://blog.golang.org/concurrency-is-not-parallelism, @ 4:30.
Information overload is not really a road blocker, you just need to know those things exist and what they do. When you code for real, those seemingly impossible to remember information will carve deep into your head as you look up for them, ask questions and take a deep look into them, if once is not enough maybe several times. That's it, just learn on, no need to worry too much.
It's just [powerline](https://github.com/Lokaltog/powerline). I have it added to my tmux config. The documentation, which has install and configuration instructions is [here](https://powerline.readthedocs.org/en/latest/). I think my config is pretty much the stock minus a few things.
Right, powerline, not awesomebar :) Thanks for the links.
Using the go-&gt;c interop has a high overhead. Besides, the delta between pure go and pure c is 33% for popcount. In my applications, I found GC time to completely overwhelm the actual time spent in computation. Finally, for Set(), Will's library does bounds-checking and will dynamically grow. That's convenient but slows down every call to Set(). For a zero-alloc BitSet that trades flexibility away to gain performance, check out https://github.com/aaronblohowiak/bitset
Wow, that's a whole different world for me where your code isn't fast enough until you use GCC intrinsics or SSE opcodes explicitly. Guess I've been using interpreted languages for too long :) It's neat to see the code generated for calling into C from Go (linked in the first comment), even if the real overhead is hidden behind various runtime* function calls.
Why not just go full bore?Compile your Go code into assembly, then optimize _that_ directly. If you're willing to do the work of a C port, how much worse could assembly be?
When I "brew install gpm", it hint below: Error: No available formula for gpm
http://www.doxsey.net/blog/go-and-assembly/
Hey thanks a bunch, I'm really excited about checking out your presentation.
Interesting. Have you thought about documenting what you've learned?
It's pretty readable because the compilers do very few optimizations. 
No mention of gccgo. :-/
I'm very interested in one of the comments' suggestiongs, using the compiler from the Go toolchain and linking it directly into your program without cgo. I understand the kencc compiler produces slower code than gcc but the results would be interesting. That said, given the plans for a Go rewrite of the compiler, Go might not ship with a C compiler for much longer.
I thought it was mostly covered in http://golang.org/doc/asm
run `brew update` so it downloads all the latest formulae, then you should be good to go :)
why the need for this if there is already godoc.org available?
Godoc.org is fairly frills-free. Gowalker has more repo info, including ranking info. Go-search.org is another one which has an integrated crawler and more packages indexed. I think they'll eventually all converge to a useful set of common features, but I think we're still figuring out what that feature set is.
I like godoc for its simplicity. Its just standard go documentation. For jumping to source definition theres a `godef` plugin for Vim. For a readme, go to github. `gowalker`, kinda brings all together, so feature wise, its superior.
There is a few early days ones out there, like Beego ORM, GORM, gorp, hood...but YMMV.
Cool! Very unique. One suggestion; as you've said, the code hasn't been tested. As soon as you can, get the code under test. There's a *lot* of low-level stuff going on here that is kind of scary without test cases to validate that each unit is working properly. Can't wait to see what people use the library for.
godoc.org links to the source definition, just like the standard go documentation does. 
I like both gpm and gvp, they could be very useful! However I can't seem to work out if it's possible to have sub packages in my repo for a project. e.g. tree: myproject - .git - .godeps - etc - main.go - web - users.go - posts.go Since gopath has been set to the .godeps directory, the web package wouldn't be found by the go command. Am I just being short sighted here?
This is actually super useful. Only problem I see is confusing it with mgo, the mongodb driver, which is pronounced the same.
People should stop insisting that their thing's names be pronounced differently from how they are spelled.
There's also https://code.google.com/p/mango-doc/ It was written pre-Go 1 so the code is a lot messier and duplicates stuff that is (now) in the standard library. I really need to rewrite it at some point, if just to use the conventions that are now solidified but at the time were more in flux (cf. the panoply of flags for specifying the package). This mango seems cleaner in general, and does a better job of extracting flags, but it uses markdown for the formatting and mine sticks much closer to the godoc standards (not 100%, another reason for a rewrite) so what you see in the man page is basically what you see in godoc and vice-versa. If you like this kinda thing I also have the much newer https://github.com/jimmyfrasche/autoreadme for generating github README.md's from comments. It doesn't extract flag's from the AST like (either) mango because I gave up on that, see https://github.com/jimmyfrasche/autoreadme/issues/1 for more information.
Which types of cards does it currently support? Mifare, Felica etc. And does it support both reading and writing?
You know, I kinda think it's time for Go package authors to move beyond using "go" in the name of every package... but, yeah, that one's irresistible.
My wrapper supports all the things the libnfc does. This is, it can interface with all the device types supported by the libnfc and can read (and emulate) all types of cards the libnfc supports. For higher level access, I'm currently wrapping the libfreefare to give support for Mifare Classic devices.
Instead of using cgo, one could also write the Go parts in Plan 9 C, as the standard library does. This removes the overhead of setting up an extra stack, as 8c / 6c / 5c compiles C code with split stacks.
In the last example, there's no guarantee that the json response is printed before the program exits. There are probably more errors in the examples.
What kind of applications? Web? CLI apps? Server-side services? JSON APIs? OpenGL?
http://godoc.org/ You can read the Popular Packages, all open source.
One advantage is that you don't need len(goroutines) channel objects to be created, so it's a bit more efficient. 
Huge list of projects that might be worth a look, organized by category: https://code.google.com/p/go-wiki/wiki/Projects
This article is dangerously inaccurate. In each example there is no guarantee that the final message is ever printed; the main goroutine and the printing goroutine race against each other. It's often the case that the main goroutine will win. Here I will re-write some of the example so that there is synchronization around the printing step, so that the programs behave reliably all the time. * [The Hacky Way](http://play.golang.org/p/jwv_5nHJYB) - you should really use time.After and a select to ensure that the final message is printed. Although sleeping is obviously hacky, as noted by the author. * [The "Old-School" Way](http://play.golang.org/p/BA8QVgPi1m) - the original "done" channel is unnecessary. You should just count the results sent on the messages channel. * [The "Canonical" Way](http://play.golang.org/p/gHLIyhawM1) - the original program leaves the printing goroutine hanging (it blocks trying to receive a fourth message that never comes). This will create a memory leak in a long-running problem. You need to close the messages channel after the wg.Wait, to make sure that goroutine terminates. Obviously not a problem in a trivial program, but we should teach good practices at all times. But that still doesn't solve the problem of the racing and printing goroutines, and there's no reason why the so-called "old-school" way isn't appropriate here. When you know the number of messages to expect you might as well count them to know when to finish. Here the waitgroup is superfluous and confusing. WaitGroups are more useful for doing _different_ tasks in parallel. [Here's an example of a more canonical use of waitgroups.](http://play.golang.org/p/PcZJFvNp7T) * The fourth example exhibits the same problem as the previous one. You must close the jsonResponses channel so that the printing goroutine may exit. Also there's no reason for else blocks after a log.Fatal. And, again, the waitgroup is not the right thing to use in this case, since you still need to count the messages to make sure you print them all before exiting. I also think the fourth example misses an opportunity, where we could demonstrate handling errors from concurrent processes. [This version of the fourth program](http://play.golang.org/p/ydnJl0afbr) uses a separate error channel to handle the errors in the main goroutine. [Another approach](http://play.golang.org/p/iEzVKTnQuK) might use a type to pass the original url along with the body or error value, so that it's possible to associate those values with the original url being fetched. I'll make sure I send this comment to the author.
enneff, Thank you for your polite, candid, and extremely informative feedback. Writing an article such as this there is always a risk that my cursory understanding of the problem domain will turn out to be incorrect as it is here. I will write a follow-up article incorporating your feedback and edit the original to reflect my new understanding. Thanks again! Nate
Why not have the go routines spit out an OK packet via a channel to a collection loop, easy having an arbitrary number of routines to wait for.
That's pretty neat-o. I don't think I'll use it, but it'll help inspire my own work.
Way to be humble. Good on you!
The problems with that approach will only emerge at scale. Suppose the first goroutine takes the longest to run; all the rest of the goroutines will produce their result, then sync on sending to their channel, which your iteration routine won't get to until the first one completes. So instead of whatever processing is supposed to be occurring, all the results will be sitting there in RAM, waiting, and consuming resources. You also will be imposing excessive serialization on the whole process; in the time it took for the first goroutine to finish, perhaps you could have processed all the other responses from all the other goroutines. Also, you're maximally exposed to the possibility of a code flaw making something go wrong; if the first channel is never sent on for some reason, you hang everything. As the number of processes increases, the odds of something like that going wrong increase. Of course bugs are bugs, and if you have a bug, bad things may happen regardless, but at least with a WaitGroup you have a decent chance of getting more of the work done before a "bad thing" happens, and won't be imposing unnecessary serialization. I say this only appears at scale because for 3 little goroutines, none of this may bother you. However, if you're doing thousands, this approach becomes extremely likely to have negative performance or correctness characteristics.
&gt; The basic theory of operation is it checks all dependencies into subpackages of your project. Instead of importing code.google.com/p/goprotobuf you import github.com/coreos/etcd/third_party/code.google.com/p/goprotobuf. A similar approach failed me when I wanted to use a github library that used a github library (both, as it turns out, mine). The first had an import to the second written in to it. Does goven have anything for dealing with that? (I'm not a huge fan of modifying the underlying third-party library, which I would really like to be a byte-for-byte identical copy to some hash.) I've settled on using the seemingly-little-known fact that the GOPATH can take multiple elements. `go get` puts it into the first element; if that is either not in your repo, or ignored by your source control, it never makes it in to your repo.
https://github.com/pierrre/imageserver/blob/master/_examples/advanced/advanced.go#L129-L167
Exactly. You can be more verbose and use the comment formatting while keeping `flag`'s usage strings short and in plain text.
You can run goven multiple times to fixup those sorts of dependencies.
Are you complaining that the author is announcing their project prematurely ?
"Telling a programmer there's already a library to do X is like telling a songwriter there's already a song about love."
Oh great, another one! /s
Since that's a low-level standard library, the community will create abstractions around it for sure.
README is the documentation
Relevant: * http://rcrowley.org/articles/golang-graceful-stop.html * http://www.youtube.com/watch?v=chutIR1rsWw
Neat. Good job on this. 
Hey, thanks for taking it in good spirits! I was worried that I might have come across as a bit of a jerk. I was thinking more about canonical uses for waitgroups: they're also great in situations where you are spawning multiple goroutines from other goroutines, and to keep track of the final count you'd need to atomically increment some counter. For instance, imagine walking a directory tree concurrently; you could launch a goroutine to handle each directory, but as you walk each directory you might be spawning more goroutines. A waitgroup would be ideal here.
Whoops. Yeah, += 2 would be preferred. 
This look like a great idea for non-http services. It seems like most of the work is already done by net/http if you are only interested in http. I'll keep this link in my bookmarks. Thanks!
I know what you mean, but perhaps the announcement is way of letting people know the project is there so they can contribute.
No, it's a small **Quick Start** part of the docs. Devs don't just want to know how to use your library, they want to know how your library **works**, in order to use and modify it.
Sorry, but channels are never automatically closed. They are automatically garbage-collected when there are no more references to them, but that's different. A consumer that is blocked on a range will wait forever, even if the only remaining references are read-only. Observe how these deadlock: http://play.golang.org/p/5Jah-pfZFl http://play.golang.org/p/cey2VZKLXf Fortunately though, it's easy enough to close the channel yourself after all your producers are finished. Add a sync.WaitGroup around them in the usual manner then have another goroutine that closes the channel only after Wait()ing on them to finish: http://play.golang.org/p/YWzCN1oGOd.
You're half right. A `for x := range &lt;-ch` loop will terminate when `ch` is `close()`-ed. But, the channel will have to be explicitly closed. Also, it is an error to close a channel more than once. So, if you have multiple producers, you'll need to synchronize their termination in order to `close` once after the last is done. Read-only and write-only references to channels are merely type safety; they still refer to the bidirectional channel. Nothing is closed implicitly.
I hacked this together over the last couple of days and would appreciate any feedback folks here have. If anybody else is interested in AWS Elastic Beanstalk support for Go, I'd love to combine efforts.
It wouldn't be a good idea to rely on garbage collection to impact the flow of your program. You have no guarantee of when a GC cycle will happen. So, if you were done supplying input into a channel, you might expect the consumers to finish whatever they do with their inputs and move on, but instead they'd hang on the loop until the runtime decides to implicitly close the channels. That could happen within seconds, or hours, or maybe never. So, while it might seem convenient to not have to clean up your channels in one particular use case, the unpredictable behavior would lead to complication in other cases.
ahhh great point...I feel like, and this is with no real knowledge of how the runtime is implemented, there is some type of immediate cleanup done by the runtime when a goroutine finishes...rather than rely on the GC to take care of it, I am wondering if an implicit closing could be done at this stage...That does introduce the problem of a producer being done producing but still doing some long runny calculations before it exits but this case could be handled by the explicit closing synchronization you mentioned earlier.
Better to be explicit all the time. The kind of implicit clean-up immediately after a function call you describe would essentially require a GC run at the end of every function. One goroutine may be done with a channel, but it would be an error to close it if another goroutine still wanted to send values through it.
I needed a color package for my upcoming personal projects. The existing one weren't that good for my needs and many of them had a cumbersome api. Also none of them had tests (albeit I'm not sure if it's perfect but I've tried my best to implement one). Let me know what you think!
looks great...I just recently used an approach similar to this for a logging package in a personal project of mine...only thing I would suggest adding is a Sprintf version of the function so that you could have a single line with multiple colors
agh I guess you are right. I have been sitting here trying to think around the problem but it comes down to needing to know what other references are in play and thats basicly the GC's job...ohwell thanks for the input!
Thanks for the feedback!. I've just add the SprintXxx API calls: http://godoc.org/github.com/fatih/color#Color.SprintFunc You can use them like: yellow := New(FgYellow).SprintFunc() red := New(FgRed).SprintFunc() fmt.Printf("this is a %s and this is %s. Aborting\n", yellow("warning"), red("error")) Or there is also PrintXxx API calls for lines: blue := New(FgBlue).PrintlnFunc() blue("blue text will be printed.") 
While gpm is pretty mature already gvp is still **very** beta, so issues/pull requests are more than welcome so it can grow to accommodate common Go workflows. Anyway, I've been thinking about how to handle this for the last few days, my reasoning thus far is: I don't like that people keep all their Go projects in the GOPATH as I think it's a mistake to do so. In my mind only libraries should be there and subpackages inside Go applications should be either imported with relative imports (import "./package_name") or moved to their own repo. I'm still not sure though, I need to think more about it and encounter more use cases, I'm absolutely open to change my mind on that as I know lots of people follow that pattern, I guess time will tell. Thanks for the feedback and feel free to open issues on github with your thoughts! :) 
I have used Laravel a lot so I understand why you like the Eloquent ORM. However Go does not have objects and personally I have found this package https://github.com/jmoiron/sqlx which extends go's native sql package to be perfect and enjoyeable to use.
SoundCloud even built their own continuous deployment system in Go that adheres to the 12-factor app principle: http://gotocon.com/dl/goto-zurich-2013/slides/AlexanderSimmerl_and_MattProud_BuildingAnInHouseHeroku.pdf 
[**@GopherCon**](https://twitter.com/GopherCon): &gt;[2014-02-18 12:24:29 UTC](https://twitter.com/GopherCon/status/435751674704310273) &gt;Only 60 tickets remain. [#golang](https://twitter.com/search?q=%23golang) [#gophercon](https://twitter.com/search?q=%23gophercon) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/1y8zr5%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
`...` is syntax for variadic arguments in Go. Essentially, in a function definition it packs arguments that you pass a function into one slice of that type. This way, you can pass as many arguments as you want (this is used, say, by `fmt.Printf` and friends, so they can take any number of things to print). `...` when calling a function does the opposite: if you have several arguments in a slice, it will unpack them and pass as separate arguments to a variadic function. [See this for examples.](http://play.golang.org/p/NUlXmVtjAA) Now, why is this needed for `append()`? Well, `append` has a signature similar to this: func append(where []T, what ...T) It's useful, because you can do things like: append(slice, 'a') // one argument append(slice, 'b', 'c') // two arguments And so on. But what if you have lots of things you want to append in a slice? `...` helps you unpack them. So: append(slice, []byte{'a', 'b', 'c'}...) is equivalent to append(slice, 'a', 'b', 'c') . Note that you can't just do append(slice, anotherSlice) As `append` takes single elements of a type as arguments and not slices of them. This is why unpacking is needed here.
Without the dots you are trying to add a byte slice as an element of a byte slice. This is not allowed. By adding dots you essentially unpack the second argument into a bunch of individual bytes and add them one at a time.
###Thank You
This is great! I started using goconvey a couple weeks ago, and quickly benefited from its automatic feedback every time I write a source file. The degree to which my development is legitimately test-driven has probably doubled, while my efficiency has also increased. I'm looking forward to removing the awkward step of manually executing a coverage run and generating a report when I'm trying to eke out those last few percentage points of coverage.
The flynn.io developer just got hired by Digital Ocean to work on it full time. That week be another huge boost to the several high quality private PaaS projects out there.
In case anyone is wondering why the world needs yet another S3 client, I built s3gof3r to address the deficiencies of other S3 clients out there, which are mostly speed and robustness of error handling and retries. For large S3 objects (tens of gigabytes) this can mean multiple attempts, restarting from zero each time, and transfer times measured in hours. To address this, s3gof3r retries all http requests and also uses a deadlined tcp transport to counteract throttling of connections by S3. The error handling of go made all this much easier to reason about as well. The other feature that isnt available in most other S3 clients is pipeline support, which is made easy with Gos reader and writer interfaces. This allows usage like $ tar -czf - &lt;my_dir/&gt; | gof3r put -b &lt;s3_bucket&gt; -k &lt;s3_object&gt; $ gof3r get -b &lt;s3_bucket&gt; -k &lt;s3_object&gt; | tar -zx We use the command line tool at CodeGuard to transfer many terabytes into and out of S3 every day, tarring directories in parallel with the uploads and downloads. I hope others who have similar use cases may find it useful too. 
So it's meant to be an s3cmd replacement? that's cool. How about using it from a Go program? I don't see much documentation of it as a lib.
Try GoDoc? http://godoc.org/github.com/rlmcpherson/s3gof3r
At this point it's definitely not a full s3cmd replacement, as it only supports parallelized streaming uploads and downloads (get and put). These operations are the most problematic on other S3 clients, which handle the less-data-intensive operations like LIST and DELETE fairly well, in my experience. The documentation for the Go package api is at: http://godoc.org/github.com/rlmcpherson/s3gof3r Since it's on godoc.org, it's not duplicated on github. The command documentation is here: http://godoc.org/github.com/rlmcpherson/s3gof3r/gof3r
This is such a silly and narrow view. How often do you use Github?
Thanks. It would be nice if you put an example function in the godoc. 
Good idea. Noted: https://github.com/rlmcpherson/s3gof3r/issues/5 In the meantime, you can see how the api used in the gof3r command tool. get: https://github.com/rlmcpherson/s3gof3r/blob/master/gof3r/get.go put: https://github.com/rlmcpherson/s3gof3r/blob/master/gof3r/put.go The get and put functions implement the ReadCloser and WriteCloser interfaces, respectively.
FWIW, I also have been working on an S3 client in Go, but mainly with the goal of replicating s3cmd without the dependency on Python and whatever else (shit's a pain on Windows, and in general when provisioning many machines). If you are open to it I might have some time to work on the other features for you.
First comment on the blog is from Rob Pike, it's definitely garnering attention. GoConvey is a fantastic tool, very glad to see it improving all the time.
Asking if a language is twelve-factor compliant sounds a bit odd, being twelve-factor compliant is related to how you design your application, not what you write it in.
Definitely, that would be great. As I mentioned in the comment above, I focused on the uploading and downloading first since they are most problematic on other clients, but having additional S3 functionality in a statically-linked Go binary with almost no dependencies is reason enough all by itself. By the way, I haven't tested it on Windows at all so I'd be interested in hearing if there are any problems. 
Looks like you upload 5 mb chunks concurrently. Is 5 mb an arbitrary number, or did you find it to be a sweet spot for performance in some way?
Great feedback. Do you could point me to any docs that shows it?
There is a Wikipedia page on [terminfo](https://en.wikipedia.org/wiki/Terminfo) which links to a lot of resources.
Thanks, I'm going to look at it.
I've been asking myself that very same question recently too. I've managed to come up with one (good?) answer: To use HSQL for dev, Postgres for Prod. What do you think?
Great work! I built s3funnel once upon a time which was the only concurrent s3 tools at the time, but it was quite painful to make it work in Python. I imagine the future of an s3 tool in Go is much brighter. :)
~~I'll work on getting a demo copy up soon for people to mess with.~~ Demo is up [here](http://gobb.stevegattuso.me) if you want to test it out. It'd be awesome to have others help out and contribute if it's something that interests you. Why should php be the only language with decent bulletin board implementations? :D 
@morsegeek If you've learned anything useful about authenticating with S3 that isn't already implemented in [go-aws-auth](https://github.com/smartystreets/go-aws-auth), we'd be happy to see it contributed! Particularly, I'm curious about the Content-MD5 header. That's part of the string to sign... but requires reading all of the content so you can hash it. Seems inefficient, but I couldn't think of a better way. How do you handle that? All I see in `sign.go` is that it uses the hash which is already present, but I'm not sure where it comes from.
yes it has, I'm curious if you have open source projects or you're just a hater?
You are storing plain-text passwords, use [bcrypt](http://godoc.org/code.google.com/p/go.crypto/bcrypt)! gobb/config/config.go@10 func GetConfig(path string) *goconfig.ConfigFile { When using that function it will look like "config.GetConfig". Notice the stuttering "config". Use something like "config.FromFile" instead, it is more informative and has less stutter. Run "go fmt" on the whole repository, there are some places that aren't fmt-ed properly. I would probably separate the controllers to different folders. Once you start adding things like permissions, static pages, notifications, spam protection and so on, it can get quite messy. Instead you could do something like: controllers/admin controllers/user controllers/board controllers/thread ... And then I would rename things so I could use: admin.Main admin.Boards admin.Users user.Login user.Logout user.Register user.Show Avoiding global state could be benefitial, i.e. create a controller with injected DB or pass the context into the controller. It may make sense to use martini for that stuff, but it can be without it by wrapping the controllers. Try to hide the DB or/and the repositories behind some interfaces that way you can swap them if necessary. e.g. currently it would be quite hard to migrate to appengine.
If you need parallelism, increase it. If concurrency will suffice, don't.
Thanks for the advice! I'll definitely switch to bcrypt (I didn't know it existed), but am I really storing in plaintext right now? I'm hashing the password and a salt in models/user.go. Edit: Relevant issue is [here](https://github.com/stevenleeg/gobb/issues/25).
Isn't Discourse written in JavaScript using the ember.js framework?
they use ror and backbone.js
Yes this is correct as far as i understand it. It depends very heavily on what you actually do, but the best way is to actually bench it like /u/EmptyBeerNotFoundErr suggests. I for instance run with GOMAXPROCS=4 for all my production code where i have several hundrerds of connections to both clients and other servers with heavy dataload and benching have shown it to decrease latency.
The function that calculates the md5 hash for the content-md5 header is here: https://github.com/rlmcpherson/s3gof3r/blob/master/putter.go#L293 s3gof3r always uses the multipart upload api, and the content-md5 for each part is just the hash of that part's content. As far as memory-efficiency, that's just the size of the part (default 20 MB). The md5's of each part are also stored and uploaded on completion, per [the aws docs](http://docs.aws.amazon.com/AmazonS3/latest/API/mpUploadComplete.html). All the Go standard library crypto hash functions implement the writer interface, so that makes the code both easy and elegant. I hope that answers your question, but let me know if it doesn't make sense. 
Helper library to do this without interfaces: https://github.com/pmylund/sortutil The code to do the equivalent would be: sortutil.AscByField(posts, "Date")
They're all gone!
&gt; https://github.com/pmylund/sortutil good to know, thanks for sharing! 
Just for the record, it was more of an aside. Your approach is the best if you know for sure what you need/it's performance-critical. (Although in recent Go versions, sortutil's benchmarks seem competitive.)
I humbly recommend using [TOML](https://github.com/BurntSushi/toml) for your configuration instead of what you have. It's not that I think the format is better (it is almost the same as what you have already), but my package has a reflection interface that makes it pretty convenient. Meaning, you can get rid of all of those `GetString("database")` calls and just access struct members yourself. I've included a full [working example](https://gist.github.com/anonymous/9100387) with your default config (which I had to modify in a few places to make it compatible with TOML, but it's mostly the same). Since the structs all embedded, you can just do `conf.SiteName` or `conf.Account`.
this is what I'd call simple. the article... not so much.
dev and production should use the same RDBMS.
Hmm, I believe it supports piping for PUT but not sure about GET. It has been a while since I handed it off to sstoiana.
You might like this: http://blog.safariflow.com/2013/02/22/go-as-an-alternative-to-node-js-for-very-fast-servers/
Go code is much more readable and lacks all these nasty JavaScript glitches. In Go there even is no need for a === comparison operator.
This is funny, I'm watching you on FLOSS Weekly right now (well, I paused it to read the article...). Thanks for the link.
I really dislike Javascript, but Node is interesting. It's main selling point is that everything you write is automagically concurrent. Even in a language that implements concurrency well like Go, it is mental overhead. Not having to think about threads or alternatives to them at all is nice. Also being able to use libraries like jQuery server-side and send DOM to the client is a nice advantage of working in straight Javascript.
For future blog posts, I think that a link to a code stub on play.golang.org would be useful. Obviously its simple to just copy paste from the gist, but I think giving an even easier way for the reader to see the code running and toy around with it would be useful.
Profiling node.js programs is a pain in the ass, especially as you have to track time usage through callbacks. With Go's builtin pprof toolset, you can easily locate performance (CPU OR Memory) problems. When you do find performance bottlenecks, your optimization options are more limited in Node.js than what you can do with Go because Go exposes reference vs value semantics to the user -- and this extends to using embedded structs. Depending on what you are doing, leveraging better memory layout/access can greatly improve your performance. Go's deployment story is better, but node's dependency management is better. In general, Go is lower-level and that control comes at a cost of ramping-up and trading off some runtime flexibility. Go's type inference keeps the visual burden of types-in-code to a minimum (though it isn't HM.) 
Note that client certificates aren't supported in 1.1, which Ubuntu still ships with. Caused me a great deal of frustration when things that were working on OSX stopped working on Ubuntu.
Yeah. To be fair, MongoDB is easier to get up and running and the Go bindings are fantastic, but we definitely need to get more examples out there that use database/sql. I ended up having to figure out how to put together a SQL-backed web app, and am happy to see that my code is pretty similar to yours. (Although I am using sqlx rather than gorp...) Anyway, thanks again.
Upgrading on Ubuntu is easy with [godeb](http://blog.labix.org/2013/06/15/in-flight-deb-packages-of-go).
Sure, I was just under the impression that bleeding edge Ubuntu would be running 1.2, which it didn't, and it didn't even occur to me to check.
https://github.com/PuerkitoBio/goquery may help.
Go supports OOP... It uses composition instead of inheritance, but it has object-oriented paradigms... Would you also make the claim that JavaScript doesn't support OOP because it's prototypical and not classical?
Sure there are coding practices that need to be followed. If you didn't have the freedom to be noobish I would also be worried.
Yup, sums it up pretty well. People should remember that writing async callback or future based code is a hack, not the way you should write application code. Go makes all this bullshit go away and keeps you focused on writing good apps, and not on micro managing callback spaghetti. 
"Callback hell isn't a problem anymore with this new workaround." And in Go, all this stuff has always been handled by the runtime. That's just a whole different quality of abstraction.
Oops. Yeah, sorry. I'm an engineer in the "social space" (whatever the hell that's supposed to mean) and I do it sometimes out of habit.
Thank you for the feedback, I will keep that in mind for the next time.
It looks really good. Though I can't help but notice that `GetDbSession()` call on every type member method in package model. [here] (https://github.com/stevenleeg/gobb/blob/master/models/connection.go#L13). It looks very inefficient. That said, I have not used gorp.
Please stop calling it "Golang".
I don't know if it works but that is exactly what I'm looking for. Champion, have an upvote!
We used GWT with one of the main arguments being "You can use the same Java on client and server!". And, like you, I saw very little code reuse. Even for things as simple as enums, they would often be duplicated on the client side and server side because the enums on the client side would have some extra special bit of native javascript attached to them or the server side enums would do some extra special bit of server side logic. (Though, that was somewhat of a code smell anyways..) Either way, the benefit of having the same code run on client and server was more imagined than realized. In most complex apps, the client and server are responsible for vastly different things so code sharing is going to be minimal.
The big thing regarding Node is sharing code between client and server. You can escape callback hell using a myriad of different modules, like async or Q. When it comes to code sharing, I use this alot. Everything that requires validation is shared in my applications. That way I can validate it on the server, but also validate the information on the client in realtime, or before sending it to the server. When creating games I also share game logic, so certain things can be calculated on the client, and validated at the backend. Another great thing about sharing code is sharing models, enums, datastructures. If I need more functionality at the backend, I use inheritance or monkey patching. Of course, code sharing might not be a big deal, it depends on the project. For me, pros also include better package management (npm), access to a REPL and smaller mental overhead as I only need to know one language. Go is great, but it still feels a little unfinished. A static language without generics feels a little limited. Not that I use generics often, but when I do, it's annoying not to have. Another thing that I don't like about Go is that they force the project layout, which Node doesn't. Minor thing, but it annoys me. I think both are great technologies and I think that it really boils down to shared code. Then again, they are working on a Go2JS (GopherJS) so you might be able to get that benefit with Go very soon. Another thing to look at would be Clojure. It gives you one language for client and server (Clojure and Clojurescript) and you also get Goroutines (core.async) and static typing (core.typed) as optional libraries. Best of both worlds in my oppinion, but YMMV.
If so, then Python is not OOP, because it uses prototypical inheritance too. 
cool, I've added the ability to pipe in mine too now 
You seem to be venting :P &gt; Node.js: Callback hell. It's easy to fall into the trap of callback hell, no doubt, but there are many techniques to avoid this ([here is one for example](http://callbackhell.com/)). &gt; I have honestly only had ONE occasion where I used the same 4 lines of code both in the server and in the client You may have not used it, but it is a readily available option that is used by very many people (see [browserify](https://www.npmjs.org/package/browserify) for example - also note the **Version** section on that link, more on that later.) &gt; Ohh and did I mention Node.js isn't really all JavaScript? I am not a fan of this either. That said, *A*) CoffeeScript is compiled into JavaScript to be used by node and *B*) [sourcemaps](https://www.npmjs.org/package/source-map) (please note the **Version** section again) &gt; But most of them are useless abandoned junk. So, even that is questionable. [This is just incorrect.](https://www.npmjs.org/browse/updated/0/) Please see my examples spattered through out this comment as well. &gt; Testing: Lets just say that in Node.js/Javascript you would have to write tests that check the type of a variable. If you are writing your own tests to check var type, you are going to have a bad time. There are tons of libraries that do this! [nodeunit](https://github.com/caolan/nodeunit) (last updated 15 hours ago), [mocha](http://visionmedia.github.io/mocha/) (last updated a month ago) and [jscheck](http://www.jscheck.org/) to name a few! &gt; OR!!!! here is a revolutionary idea!! let the damn compiler do it for you! MIND BLOWN!!! /me tries to imagine how the internet would be if every page loaded compiled executable files instead of using an interpreted language. In my limited experience with Go, one of the most awesome aspects has been the testing. [net/http/httptest](http://golang.org/pkg/net/http/httptest/) is win.
I haven't used enough Node.js to hate on anything more than tons of abandoned packages in npm and callbacks so I'll just list my pros and cons about Go. First the pros: - Go is ridiculously easy to get started with and requires minimal setup. - It's simple! - Using others' packages is simple - Deploying is simple - Testing is simple - Profiling is simple - It's easy to utilize multiple cores if that ever becomes relevant. - Static typing without being too verbose! And the cons: - It's simple! - The default package management tool (go get) doesn't handle versions and always grabs the master branch. - Code can be a bit too explicit at times. - Very little syntax sugar and generic code can be verbose. - You will miss map, reduce and friends if you are used to them. **TL;DR: Go is wonderfully simple but sometimes a little too simple.**
Like /u/deftly [mentioned](http://callbackhell.com/). Personally, when organized well, callbacks aren't as awful as people make them out to be. If you follow the patterns of the language/framework, the concurrency comes automatically.
I would say "the same amount of mental overhead" is an overstatement, at least from personal experience.
It makes me sad to see 75 odd up votes on a ragey troll bait post like this. You're better than that /r/golang
&gt; It's easy to fall into the trap of callback hell, no doubt, but there are many techniques to avoid this (here is one for example). And all of them, _every single one of them_, is an attempt to use hacks to get closer to the actually-correct way to do it, which is the way Go does it. And the reason why they have to use these hacks is that Javascript is too weak a language to do it the right way. (It is not alone. Nor is Go the only language doing it right. But this is one of the more head-to-head comparisons.) The wide multiplicity of approaches Node has to this problem is not a sign of strength; it's a sign of massive, massive weakness.
From that article: &gt; Node.js is one of the worst things to happen to the software industry in recent times, a whole generation of programmers are being taught the worst of all ways of doing concurrency, in a system that doesnt scale either in performance or project size and with one of the languages most plagued by pitfalls ever created. This is literally true. It blows my mind how an approach that the entire industry has known to be _massively, massively_ flawed, event-based programming, is heralded by the Node community as an amazing breakthrough. I mean, seriously, think about this; we had _decades_ of experience with the approach. The world's most popular operating system is based on events. Every program written for Windows is based on events. If it was the awesome solution to concurrency, we'd _know_. Instead, it is precisely what we are fleeing from. If you unpack Node's claims, in a lot of ways it boils down to (with the bits in parentheticals the parts they don't tell you) &gt; We know that concurrency is hard (because we learned that concurrency is hard from decades of experience in large-scale event based systems). So we're here to save you with this _brand new innovative awesome_ event-based system. Event-based concurrency is the awesome, new solution to the old problems of event-based concurrency! The community shows its heritage of being a whole bunch of web developers. (BTW, I'm as loud about this as I am in an effort to save others. It's no skin off my nose if you still choose to write big Node programs, I solve my personal problems by just not doing that. I'm not angry, I'm _warning_.)
I don't think you read the callbackhell link. Named functions and modules are not hacks. They are part of the language.
&gt; It's main selling point is that everything you write is automagically concurrent. In Node, that's a lie; you have to manually write the concurrency. I use the term lie fully on purpose. They've had time to fix their propaganda and I see no evidence they have. I also use the term "propaganda" fully on purpose. Through linguistic legerdemain, they turn this negative into a positive. It's actually Go that has a _wildly_ better claim on that statement.
Generators are just one of many things that make avoiding callback hell easier. There's always been promises, which I personally don't like. There are many control flow libraries, the most popular being caolan's async. And commonjs has always encouraged breaking up code into smaller chunks.
Actually, node can do code like that just fine. Look up generators and co.
&gt; The default package management tool (go get) doesn't handle versions and always grabs the master branch. Almost. From the docs: &gt; When checking out or updating a package, get looks for a branch or tag that matches the locally installed version of Go. The most important rule is that if the local installation is running version "go1", get searches for a branch or tag named "go1". If no such version exists it retrieves the most recent version of the package. Unfortunately I cannot find _any_ reference docs for what the rest of the rules are. Apparently it was too difficult to drop a URL into some brief help output.
The code he wrote is pseudocode, sort of a blend of Go and JS. It wouldn't actually run on either. But with some syntax changes (and hopefully some error handling) it would work fine in Go. The json.Parse function would not be called until after the page was fetched, because the Get function would block until it was. Maybe you can't imagine code like that working, because you're so used to callback-style, non-blocking code. But that _is_ how it works in Go.
&gt; Maybe you can't imagine code like that working, because you're so used to callback-style, non-blocking code. But that is how it works in Go. Really? I completely agree with /u/shadowmint, I expect better from this sub. Your suggestion that I **"can't imagine code like that working"** is rude and brings nothing to the conversation. My above statement is asking /u/jerf if he is suggesting that the *correct* way to write JavaScript is to write it as if it is blocking. &gt; The Node community even has the audacity to try to teach people there's something wrong with that code, when it's the Node way that has nothing but unmitigated negatives associated with it; it's harder to read, they have to jump through poorly-composable hoops to handle error contexts, they produce code that is at least one of hard-to-read and full of paperwork, and for all that they still end up stuck on one processor. The above isn't very clear - and there are no examples, so I can only assume he is talking about *his* example when he says ***that code***. 
&gt; "string" "string" -&gt; "strings"
Well said! Everyone scoffs at me when I say "I wish go had npm" - but it really does a wicked good job! When you say deployment, do you mean deployment of binaries? or source?
To deploy a Go app, you just need the one file (and maybe a config file). For node, you need to have the language runtime on the target machine and a huge number of source files. The former is far, far preferable to the latter.
Then you should warn with correct info, not FUD.
Yes, I understand that it's 'automatic', but that comes at the cost of forcing concurrency on you even when you really want synchronicity. Callbacks are just functional GOTOs. GOTO statements can be fine when properly organized too, but they should be used sparingly - the fact that one can organize them is no excuse for using them when higher level abstractions are better suited. 
There is LiteIDE http://code.google.com/p/golangide/ . It gets the job done once you understand how its "Folders" and "Package browser" views work. You also have to guess that code completion works with installed packages (ctrl+I to install), not just what's open in your session. So I had to relearn a thing or two when I switched from Eclipse to LiteIDE but I'm quite happy with it.
There are a few options - [Go Ide](http://go-ide.com) - [IntelliJ Community Edition + Go Plugin](http://plugins.jetbrains.com/plugin/5047?pr=phpStorm) - [LiteIDE](https://github.com/visualfc/liteide) - A sublime plugin for Go [GoSublime](https://github.com/DisposaBoy/GoSublime) - And of course good old VIM I used Sublime and Vim before and only just started using IntelliJ+Go plugin. [This article](http://pivotallabs.com/setting-google-go-plugin-intellij-idea-13-os-x-10-8-5/) shows how you can get started with it. I have no experience with Go-IDE or LiteIDE. Hope this helps. 
Use http://go-ide.com/ its also based on IntelliJ Platform
There may be F, there's no U or D. Node's approach isn't new. Full stop. It's well explored and was found to be wanting a _long time ago_. This is all but objective fact, again, because if event-based solved the problems Node claims to be solving there would be no _need_ for Node in the first place, because existing systems would already have solved them. "Event-based" is not a new idea, it has been the _dominant paradigm_ for most of my life. The series of "solutions" to the problem that the Node community has come up with for "callback hell" are _also_ all well-explored for a long time now and _also_ all found to be wanting a long time ago. The Node community has not covered any new ground yet, so why should we pretend otherwise? For what it's worth, neither has Go. Go's only real innovation here has been bringing the way it works into an Algol-esque language. As has been pointed out by many, including Go's developer's themselves, the very point of Go isn't that it's brand new, but that it combines a lot of existing, known-to-work approaches in a new system that takes advantage of the resulting simplicity. If you'd care to explain which parts of that are objectively false, I'm all ears, but I suppose I should issue fair warning that my experience is much more diverse than "web front-end developer for the last three years".
I use LiteIDE.
No, generators can't trivially convert that code either. The Python community played with that approach a long time ago, and it didn't work out, and ECMAScript generators are basically straight ports of Python generators. It's hard to show a quick example of where they fall down because little snippets can always be fixed, but they turn out not to work at scale. Node will rediscover that in due course, just as with everything else they've rediscovered.
&gt;I do not wish to be rude, but andbolholm may still have a point that you're not used to seeing that sort of code. In Go, the equivalent of that code (expanded with error handling, which I left out since both cases require it anyhow) just works. I fully understand that go routines allow for node-async-like behavior. I never claimed that the code you wrote was in any way not able to be multiplexed or "asyncie" - I simply made the statement that it would not function well as JavaScript (without modification and re-structuring into the "callback" style). The code (I wrote) was also meant to show how inaccurate your "pig in lipstick" comment was, and that named functions (a valid feature of the language) are not a *hack*. I made absolutely no claims about go's concurrency model or that your code was not concurrent. &gt; The Node community teaches that such code "must be synchronous"... this is objectively false. They teach this in the context of writing JavaScript. There are absolutely zero claims that this paradigm is or should be the standard in anything except JavaScript. My entire point is (and I think yours is as well): You must write code differently in JavaScript. I don't view this as a bad thing, where as you seem to.
&gt; It's just as asynchronous as anything in Node. It's just that you don't have to do the plumbing yourself. In Node, a callback will be called when something is ready. In Go, your code would just throw stuff on a channel and something else (probably in another goroutine) would read off of it until done? How does this compare with promises? Say you have a map that returns an array of promises... this is basically equivalent to the values coming in on a channel, right? (Except with the array of promises you'd have to keep checking which ones were ready?) Sorry for the somewhat vague question, I'm trying to get straight how all this stuff interrelates. Edit: are futures/promises commonly used in Go or is there really not much of a need because getting values from a channel is equivalent?
Also interested in this. [I hear Gorilla is pretty good too.](http://lincolnloop.com/blog/djangonaut-building-webapp-go-gorilla/)
right now the most trending framework is martini, if you come from ruby you will feel very similar to sinatra
Can't go wrong with Gorilla. Pick and choose what components you need, very well designed.
I'm a big fan of Martini. It's easy to use and allows you to work with the built in net/http package. https://github.com/codegangsta/martini http://martini.codegangsta.io/ http://blog.gopheracademy.com/day-11-martini
Before using any framework, I recommend learning bare net/http as it's the foundation for all of them and it's actually very complete. It will also help you decide which framework/lib you wanna use, specially understanding the drawbacks and advantages of each framework design.
[GoDev](https://github.com/sirnewton01/godev) is a web-based IDE for go with debugging tools. Looks pretty cool! But I personally use Sublime Text with GoSublime and GoImports. Very nice combination there.
What I like about martini, in addition to being very minimal and clean, is how much effort Jeremy has been putting in with documentation, and more recently with some video tutorials. (https://gophercasts.io/tags/martini) Also, as the martini contrib continues to grow, the framework is becoming even more powerful, but still modular. Thanks for all the effort so far!
A great deal of it should be owed to the community. Reception of Martini has been staggering to say the least and the community has been making some amazing contributions to both Martini and Martini contrib. If this instance is an accurate representation of the Go community as a whole then I am really excited to see it flourish in 2014. :)
I currently am in love with GoSublime, mostly since I tend to use Sublime Text for almost any language I write. I love that it auto formats on save and does all of the usual code completion, compile error warnings, and usual stuff that a full blown IDE would do but with the speed and simplicity of Sublime. That combined with vintage mode makes my life so damn amazing. 
I have a question for the sessionauth-contrib. https://github.com/martini-contrib/sessionauth/issues/8 Is there a way to have a session that expires when browser is closed? 
I couldn't get LiteIDE to run, always crashed on compile even after configuration. Went for the good old Eclipse plugin and it seems pretty sweet, haven't worked out how to use breakpoints yet though, doesn't want to stop on debug. [GoClipse Project](https://code.google.com/p/goclipse/) - [GoClipse Eclipse Plugin Install/Update Site](http://goclipse.googlecode.com/svn/trunk/goclipse-update-site/)
The Sessions middleware has options for MaxAge https://github.com/martini-contrib/sessions/blob/master/sessions.go#L48
SublimeText + GoSublime + GoImports: https://michaelwhatcott.com/gosublime-goimports/
Can you change that on the fly so if a boolean is set (remember me), the max age is different? I've only seen examples of passing in options when setting up the middleware.
Yes. https://github.com/martini-contrib/sessions/blob/master/sessions.go#L130-L138 If you have any followup questions, be sure to do so as an issue on the repository or the mailing list. I don't wanna Hijack this thread :)
I just added a gofmt section at top. Was almost too obvious, but worth stating.
Is this what you are looking for? http://godoc.org/github.com/ld9999999999/go-interfacetools
vim + gocode
There are no other rules. "Go get" does not otherwise handle versions.
Could be. Felt like this should have been something packaged with the language that I was missing so I was hesitating to look at third party packages. There's also https://godoc.org/code.google.com/p/rog-go/exp/deepcopy
Vim.
I don't know what you need. But I think beego is now enough for web develop. ORM/session/cache and other useful modules. there has many products use beego. http://beego.me/products here has an introduce for how to use beego: http://www.goinggo.net/2013/12/sample-web-application-using-beego-and.html the follow list is the open source project based on beego: 1. https://github.com/beego/wetalk BBS system 2. https://github.com/beego/beeweb Website 3. https://github.com/beego/admin administer system 4. https://github.com/insionng/toropress CMS 5. https://github.com/dyzdyz010/MartianBlog BLOG 6. https://github.com/Unknwon/gowalker Go Package analysis system also I think beego's documents is the best of all Go framework. http://beego.me/docs/intro/ Many product such as Bmob &amp; 360. they has about 100 million PV everyday. So I think beego is good enough for you. 
Hence my request for a wrapper/extension/alternative. Thanks, for the link, i'll check it out.
FWIW, I had a terrible time getting LiteIDE to do source level debugging. After a few hours of struggle, I kind of got it to work, but it was pretty flakey. The documentation for either gogdb and gdbsublime is incomplete, and the maintainer has disabled issues, so it's difficult to find help for a problem. Is there a good IDE that offers batteries included in-editor debugging?
The golint tool notices many of these problems.
After playing with a number of platforms for a backend API, I've been really pleased with the performance and thoughtfulness of gocraft. Mostly just for routing/contexts, but that's exactly what I needed. https://github.com/gocraft/web
You couldn't be more wrong. Its like a transformer, starts as an editor, but turns into a neat IDE when you devote a bit of time to it. I love it for Go, its really good.
Martini and Revel are good. Just don't use bare stdlib if you're planning to build big apps. Revel is more like Rails/Play! however Martini has its own style and suits better for mid-size apps.
Having a different GOPATH per project is considered an antipattern. The best way to solve this problem is to not do that :)
I'm also starting web development in Go. I'm looking for example apps that - use net/http or frameworks that work with it (I think this disqualifies Revel) - uses logins / authenticates users - stores stuff in a database (SQL, using an ORM) - generally cover many of the common web development aspects Can anyone recommend something to me?
There are also more generalized solutions like [autoenv](https://github.com/kennethreitz/autoenv) that solve the same problem. 
The server side web part of your app is always going to be rather trivial. The choice is rather irrelevant if you're building big things, it might matter if you're building small things.
I like gorilla's libraries really much. They do only what you want them to do. If you only want routing just only import gorilla/MUX. Every of their other libraries I used e.g. sessions or schema do one job but a fantastic one
How well does beego work with net/http?
beego is based on net/http
It's not an IDE even after the huge time investment trying to ape an ide. Integrated debugging, project templates, and refactoring tools are required tools.
This is very cool. I've never used AWS EB before, how does it compare to Heroku? 
&gt; If you have any followup questions, be sure to do so as an issue on the repository or the mailing list. And... people using Martini will more likely find it there instead of here.
OK... so what happens if you need different version of the same library for different projects?
A friend wrote a similar goenv utility (5 line shell script): https://github.com/chuckha/goenv Works like OP's, minus the "download + install go" feature.
Yes, Go is the perfect language for this. Watch this talk featuring a simple "chat roulette" server in Go: http://vimeo.com/53221560 Slides: http://talks.golang.org/2012/chat.slide
Yes, yes, yes. Go is excellent for server applications and network communications in general. For serving requests, you should look into the [net/http](http://golang.org/pkg/net/http/) package. For more raw TCP connections, use just [net](http://golang.org/pkg/net/). Sprinkle some [type definitions](http://mholt.github.io/json-to-go/) and [encoding/json](http://golang.org/pkg/encoding/json) into your server so you can easily communicate with HTML front-ends. Apply go routines liberally for performance and as a nice way to avoid gnarly mutexing. Bake that cake into a binary and see how it turns out.
Perfect fit for it. You could use websockets very easily from it and write a pretty decent chat with "onlY HTML/JS on front
Thank you, I'll check those out.
Thank you, never realized a project like this was so common with Go.
Thank you, websockets is exactly what I had in mind. 
What if you are doing a bug fix to an old version?
Seems a good fit to me. Just make sure your professor approves. Most problems in life are people, not technology. :-)
I think I'll write it in C as well just to be sure :) The Go version would be just a learning experience. 
Switch to that version, fix it, switch back? 
That's why a mechanical tool deals with the hassle, so it's not a hassle. And then we still get nicely readable code.
Where I work, I'm hoping to propagate Go usage out quite far. The idea that the entire company with a couple dozen teams potentially working on it is going to stick their code in one $GOPATH is quite silly. Maybe it's an antipattern for your personal projects... and I'm still only willing to meet you at _maybe_... but an antipattern at scale? No, the antipattern would be piling everything into one directory. That said, I'm planning on using multiple elements in the GOPATH and having quite significant _sharing_, but I still end up with different GOPATHs per team, if not project.
What would be awesome extra credit would be linking the servers so a client attached to one gets messages from the other... *evil grin* Just make sure you don't repeat my mistakes... make sure the assignment is complete and working before extending it. 
It's just a few lines in Go, so I'm not sure if you could call it a project.
And commit / backup what you have, just in case. I once rewrote a badly factored library into a pretty neat lib for a uni project... and kept the only copy in an USB flash disk that of course died. Luckily I had *printed* the code (interspersed with text, for the project presentation) so I could type it back up; lol
Go was basically designed for networking applications first since those are the types of programs Google creates.
Use source control. Tag and branch. You will have to do that in industry anyway. 
I know a guy that used zip files and dropbox as version control :X I've also seen a guy that made a patchset for VLC, then made a github repo for it. The contents of the github repo were a readme with a link to a skydrive shared folder. Inside the folder, there were zips, full of perfectly cromulent git format-patch patches. Whenever he had to update the patchset, he'd generate a new zip with the format-patches and upload. Why he didn't just set it up as a branch in a github vlc fork repo is a mystery. Though you had to be careful when picking the patches to apply from his patchset; he also included plenty of unrelated changes in the format-patch zips :S
The danger with Go is that the standard library probably does most of the work the professor expects you to write into your own code. You could get around this by not using the standard library. But then that is half the pleasure of Go.
I'm almost entirely convinced that the only reason you wrote this response was to use the word 'cromulent'. 
On Linux LiteIDE is awesome. OSX was a little more work because of GDB. I find LiteIDE to be much smoother than Eclipse but less feature rich.
If this content becomes a torrent, I'd be quite happy to seed for quite a while.
Great, thanks! I'm really excited about Camlistore and what you plan on using it for. I like your views on document management (from scanningcabinet) and how you'd like to move to Camlistore for that. Have you done any work on that side yet? I was hoping to include additional metadata such as the "document date" for documents you scan after the date you received them or "total cost" for tracking receipts. I was looking at possibly starting that myself but I was overwhelmed trying to find a place start hooking that in. I know people have mentioned that documentation is starting to become a goal now, but I think it would be helpful to have something like a "this is how outside applications should interact with Camlistore". Is it a REST API? A Go package you import? A TCP protocol? I can't wait to see where Camlistore goes. :)
An interface is an abstract provider of functionality. "Deep copy" is an implementation detail of that provider. If you are absolutely sure you need to be able to "deep copy" on an interface, you should add that method to your interface definition.
Hard to argue with that logic. That's actually more OO-centric than I was expecting from go.
I would personally love to see this happen. Been using it in vim on auto-save and I'm really happy with the result. Thanks!
In apps I know will generally benefit from parallelism, I drop in: func init() { if os.Getenv("GOMAXPROCS") == "" { runtime.GOMAXPROCS(runtime.NumCPU()) } } There are cases when you might always want multiple processes even if you have only one core, as well as cases where using NumCPU coroutine's just causes more contention, so this is not a cure-all by any means.
Another video on YouTube: http://www.youtube.com/watch?v=kYwtzDXxxtY "Write your own Go compiler"
Technically goimports does two other things (groups, automatic adding of imports). And considering that there are enough people who disagree with that second feature, it would at least need to be optional.
what about the slides ? 
Why is it troublesome?
The line count is not impressive, but the knowledge acquisition required to understand how everything works is useful for an undergrad project.
I would imagine most libraries and framework make use of it. But what I'm really trying to ask, is it hidden or exposed? Can you mix beego and gorilla? I'm lead to believe that revel is written so that gorilla cannot be used with it.
Apparently I misunderstood your reply. I thought you were saying "That would never work (on any platform)", but it seems that you meant "That won't work in Node." &gt; My above statement is asking /u/jerf if he is suggesting that the correct way to write JavaScript is to write it as if it is blocking. I don't think that /u/jerf meant to say that his example was an example of the correct way to write JavaScript. He knows you can't write JS like that, and that is his biggest gripe with the JavaScript platform.
&gt;In Go, your code would just throw stuff on a channel and something else (probably in another goroutine) would read off of it until done? Actually, channels aren't used as often in Go as newcomers to the language think that they would be. For the example we're discussing, there would be no need for a channel. You would just run it in its own goroutine, and let the rest of the program go about its business until it was done. Channels are needed only when you need to communicate or synchronize between goroutines. &gt;How does this compare with promises? Say you have a map that returns an array of promises... this is basically equivalent to the values coming in on a channel, right? (Except with the array of promises you'd have to keep checking which ones were ready?) You would probably use a channel in a situation like that, but if you think of channels as a replacement for promises, you will get confused. &gt;Edit: are futures/promises commonly used in Go or is there really not much of a need because getting values from a channel is equivalent? Promises are almost never used in Go. Most of the places where they would be used in JS are replaced by blocking calls. You just call a function that returns the result you need, and it doesn't return till the result is ready. Where you actually do need a way to get a hold of a value that will be produced later, on another goroutine, you would use a channel.
I didn't use it either, but it's become a brilliant feature for me. All I have to do is type `:Fmt` and it fixes all of my imports for me. Pretty useful when you, say, want to import the `fmt` package to print something, and then get rid of it. (Of course there are other work-arounds for that, but still, very convenient.) And this extends to third-party packages in your `GOPATH` too.
This is my first time creating a torrent so I hope I did it correctly. I can seed for a bit. magnet:?xt=urn:btih:6abb482edd5b8385ed02a88443e3e5630f8b6a03&amp;dn=FOSDEM%202014&amp;tr=http%3A%2F%2Fopen.tracker.thepiratebay.org%2Fannounce&amp;tr=http%3A%2F%2Fwww.torrent-downloads.to%3A2710%2Fannounce&amp;tr=http%3A%2F%2Fdenis.stalker.h3q.com%3A6969%2Fannounce&amp;tr=udp%3A%2F%2Fdenis.stalker.h3q.com%3A6969%2Fannounce&amp;tr=http%3A%2F%2Fwww.sumotracker.com%2Fannounce&amp;tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&amp;tr=udp%3A%2F%2Ftracker.ccc.de%3A80&amp;tr=udp%3A%2F%2Ftracker.istole.it%3A80
I've been getting things done with NodeJS for 3 years, and Go for a year, and will keep using both. You don't have to make a choice between these two. Just structure your app the right way and use both. This is what I do and I'm very happy with this approach since I benefit from the strengths of both: getting things done fast and scaling better. By the way, don't give a fuck to those who hate JavaScript and NodeJS. They don't understand the benefit there and just hate it. NPM has over 70000 modules, and there are good, bad and ugly for sure. This is the point of having market rather than static standards. Don't be a hater, learn how to benefit from both.
Playing around with this - https://github.com/metaleap/go-leansite It's a good example of how to use the net/http in conjunction with Gorilla/mux. 
&gt;You don't have to make a choice between these two. Just structure your app the right way and use both. This is what I do and I'm very happy with this approach since I benefit from the strengths of both: getting things done fast and scaling better. Interesting. Where do you choose one technology vs the other, and why? 
Runs (very slowly) on my Nexus 10. Pretty cool!
Great job! Tested on Acer A211, speed is OK.
tried it on a galaxy s4. bit slow and noisy like other people said. runs ok though. cool stuff
Maaan, it IS loud. I startled my friend. It works on Nexus S with current CM and on a shitty tablet with ASOP. It feels pretty slow, but it's bearable. So, how you find the experience of coding in Go for Android?
Writing games in Go is cool! Concurrent patterns fit very well in this domain, imho. And this is only the beginning! About performance, please consider that the demo is completely unoptimized, stay tuned for further improvements. Thank you for testing. 
&gt; Writing games in Go is cool! Concurrent patterns fit very well in this domain, imho. And this is only the beginning! I still haven't found time to give Go a... go. But being able to build some applications for Android is something I'd like to try and Python (what I develop in day-to-day) never really got there (I still haven't tested Kivy!). 
Actually https://play.google.com/store/apps/details?id=org.camlistore was probably the first Go app on the Play store. :-)
Hi Brad, thanks for pointing it out. Is this below the correct link to the camilistore client for android? https://github.com/bradfitz/camlistore/tree/master/clients/android 
Very cool.
It's hybrid Java and Go, though. The UI is Java. All the real work (network stuff, reading files, uploadnig) is in Go, which is camlistore.org/cmd/camput (you can "go get" that)
Ok, thanks for clarifying!
Original art files can be downloaded here: https://github.com/ardeay/gocos2d/tree/master/assets/logo
Thank you for this! Finally an example of a "typical" app with a normal stack
Samsung galaxy note 3 user, reporting in. Performance is not stellar, but it works! I'm excited to see more progress in using Go for Android development. 
You could still copy the version of that library you need into your project and only upgrade it when you think it's suitable.
Graphics and garbage collectors are historically a lousy idea, but I guess it's sometimes fun to make the round peg fit the square hole. Nice proof of concept.
http://www.youtube.com/playlist?list=PLtLJO5JKE5YDKG4WcaNts3IVZqhDmmuBH
You're right. I was thinking of the List pkg. http://golang.org/pkg/container/list/#Element
Non-related question, but how would you deploy go w/qml? Does the user have to have qt installed or can it be packaged with the app?
Except for static linking, I think the deployment options wouldn't change much, comparing to C++. You could require Qt installation or you could have the go binary alongside its Qt dll/so dependencies (which in themselves, have their own dependencies).
As with go you can static link c stuff too, some tweaking may lead to a statically linked Qt to a Go binary too (I had never tried or looked into this).
If you want to read about each talk before watching the videos, check out our liveblog of the event at https://sourcegraph.com/blog/fosdem-2014-go-devroom. 
Fun! Just tried it on my 2nd gen Nexus 7 and even on that hardware it's still pretty slow. What do you think is the bottleneck? Is it your code? The runtime?
I suspect it is in the way I'm handling sounds. Please, check the link below for more detailed info: https://github.com/remogatto/mandala-examples/issues/3 I'll work on some improvements in the next days. Stay tuned and thanks for testing! 
The only way to copy a struct is to obtain the value type of the struct (not pointer type) and then perform a plain assignment: type Foo struct{ I int } var x *Foo = &amp;Foo{I: 3} var y Foo = *x var z *Foo = x x.I = 5 fmt.Printf("x.I = %d, y.I = %d, z.I = %d\n", x.I, y.I, z.I) ([runnable example](http://play.golang.org/p/iC-que-PH8)) If you have an interface, then there's no telling that the underlying value is a struct. It could be a type alias to an int or whatever that isn't necessarily a struct. [Here's an example that illustrates this situation](http://play.golang.org/p/xRBBJRsQIp). I have an interface Booler and two types, Foo (which is a struct) and Bar (which is an int), both of which implement Booler. When I have a variable of type Booler, and the concept of copying (which applies to value types) does not apply to this variable. If copying is something you truly need, consider either using a type switch (which is brittle) or add a Copy() or Clone() method to the interface and make all types conforming to the interface implement it.
You already have an option: don't use goimports if you don't want automatic adding/removing of import lines. As for adding more flags: almost certainly won't happen. We're actually removing them to make things more simple. I removed the tabs/tabwidth/comments flags in Go 1.3.
GOPATH is part of the environment and thus explicitly a target for customization for [12-factor apps](http://12factor.net). Which is a philosophy/manifesto that I happen to like, after being burnt a few times IRL with over-sharing of code paths when incompatible version requirements showed up. I know the canonical Go documentation wants you to put One Go into its One True Path (`/usr/local/go`) and all that, but that's best for large projects that consume a dedicated server or more. That really doesn't cover _anything_ I've worked on! Which means I consider the anti-pattern to be shared environments installable only to fixed paths. (edit for clarity, removing the double-negatives) Docker/containers/"OS level virtualization" could change that, by letting me install multiple versions of Go and exposing them to each app in separate filesystem namespaces, but until that's universally available/stable/easy (and I have the bandwidth to do all the tech support on the switch for my team), my systems are probably going to operate in legacy mode.
Does anyone have an extra? I missed out!
cp ;) Don't over complicate things. If you need library a explicitly in version b, just copy it into contrib/ and import $yourproject/contrib/foo.
Don't panic! ;-) Panic is not for common/expected errors. Return or handle errors. If the files are in a single directory, os.File.Readdirnames is simpler than filepath.Walk ioutil.ReadFile is I think what you want for reading files. You can test filenames for matching a pattern and extract the title in one step using regexp.FindStringSubmatch, e.g. see http://play.golang.org/p/DK2CnDUmOu I'm not familiar with blackfriday, but I suspect you don't need the bytes.NewBuffer wrapper, and could just have: pages[title] = blackfriday.markdwonCommon(content) You're probably better off going to [golang-nuts](https://groups.google.com/forum/#!forum/golang-nuts) mail list or #go-nuts IRC (see http://golang.org/help/ )
Wrote this for work, thought you guys might find it useful. Would love to hear any feedback!
Ah, Fosdem. So much fun!
Would love to hear any feedback on this post. :)
Please make the text darker. It is difficult and very annoying to read as it is.
Thank you, that's much better.
I don't know if OP is the author, but if so, please fix the contrast between the text and the background. Bright gray text on a bright background is difficult and annoying to read. (Even more) off topic: First time I've seen one of the new money-grab TLDs being used.
So, yes, this is how error handling works in Go... you use multiple returns, and one of them (generally the last one) is an error. Usually either the error is nil, or all the other values are nil (or their zero value). You definitely don't *need* to return a pointer to a struct just so it can be nil, but it can be handy.
* `os` package is the operating-system level package. * `io/ioutil` contains convenience methods for common "io" operations. * `io` is just a collection of different interfaces that declare how input/output can look... e.g. tcp, files, byte-buffer, memory-buffer etc. * `bufio` implements a reader/writer that buffers. Reading byte-by-byte from file can be slow, hence it will read larger chunks at a time, but still presents the usual interface. So general guideline, use `ioutil` if your files are small. Otherwise use `os` + `bufio`. Generally [gobyexample](https://gobyexample.com/) can be helpful and also... [writing web applications](http://golang.org/doc/articles/wiki/). Also use `if f.IsDir()` instead of `if !!f.IsDir()` and don't use all-caps naming `PAGEDIR`.
similar to https://github.com/braintree/manners
Revel uses the built-in net/http package (https://github.com/robfig/revel/blob/master/server.go) and we encourage you to interface with it. I think that goes for just about every Go web framework. No one wants to reinvent what is available for free, plus the built-in http is quite good. Revel also has a handful of sample apps that touch on user auth, DB access and other common web MVC. I like the look of Martini because I favor minimalism, but I am currently invested in making Revel awesome and I would invite your feedback. We have a great community (that is growing) and I make sure that any GH issues are answered quickly. PS - We just released Revel v0.9
See my comment below; Revel, like most every Go web framework, is based on the built-in net/http package. Revel seems to be the only opinionated web framework that cares about how your organize your web app. It's very similar to Rails in that sense. Other Go web frameworks are much more flexible because they are just packages that you import and make use of.
I agree, Martini has been very well presented and developed. It's definitely worth playing with just to get a feel of how a good Go library works. Also, look at Revel, because it's much awesome and very code. Wow. :)
Absolutely. Take time to understand the interface to net/http at the very least. It will help you better evaluate the Go web frameworks out there.
Interesting read. I just started with Go, and having a C background, this really explained what's going on behind the scenes (hadn't had the time to check that out myself). Thanks!
Cute trick there. Activate should save the current transport, and Deactivate should reset the saved transport, instead of hardcoding the original default. I'd also add a note that the mocks are incompatible with tests being run in parallel, due to the fact the transport in net/http is a global variable. (That's naughty, but it's not your naughtiness and there's nothing you can do about it, except just warn people off.)
Good post! Definitely information that a lot of people don't initially realize about Go.
Perhaps it's worth noting that the Go scheduler as of 1.2 does have some logic around preemption in certain cases which means you can't rely on Go to be purely cooperative: http://golang.org/doc/go1.2
Thanks, I fixed the link. It now points to youtube.
Crypto is hard :/
It is, and I'm still learning, so it's nice to have feedback pointing me in a better direction.
If you've never studied any crypto, https://class.coursera.org/crypto-preview is a good introduction.
Thanks, this looks like a good resource.
Looks very interesting, unfortunately the audio is quite bad.
Great! It's much more readable now.
I find it pretty nice that you put references, and further documentations!
Why is the world do people use CUDA when OpenCL is an open format and performs much better on AMD.
Many thanks for the hints, all upvoted!
Take inspiration from the gorilla crew: http://www.gorillatoolkit.org/pkg/securecookie
I'd like to know how people handle generic or undistinguishable errors that can come from any layer in the call stack. For instance, [web context] --&gt; [business api] ---&gt; [database/gorp] Maybe gorp will throw a SqlNoResults or other highly technical error, but I definetely don't want to output a raw gorp error on the web layer. So I might have a pattern like var ErrRecordNotFound = errors.new("Record couldn't be found") func massageError(err error) error { // type switch on err, return ErrRecordNotFound if its SqlNoResults } func (ds *myDataAccessLayer) doSomeCrap() { if err := ds.doSomeQuery(); err != nil { return massageError(err) } return nil } But then the error becomes more coarse and the error messages are generally so vague that they are unhelpful. This seems like a general programming problem but it's even worse in Go because I've found that the standard library and many 3rd party libraries just create errors like `errors.new(fmt.Sprintf(...))` instead of using their own types that satisfy the error interface, or use error types that aren't exposed. It is really shit for user-facing apps.
Thank you :)
Handle errors early instead of letting them travel up the call stack. Make each component in your stack responsible for handling it's own failure modes. Log errors that aide in debugging, then return something more meaningful to the caller. Everything else (such as what error is delivered to a user) is a business decision, not a technical one. 
Having programmed with both, I'd say it's because CUDA is simpler to work with and get stuff done. Sure, it can only be executed by computers they have Nvidia chips, but that's not a very big problem. More than half the computers in the Steam Hardware survey reported having nvidia cards.
Fortunately there are links to the slides and project website.
&gt; not a very big problem. &gt; half of your customers cannot use this What
Almost all OpenCL is done on linux... from data centres to coin miners.
This is not 2002. I get nvidia-destroying compute performance on Windows and Linux.
Actually it's worse, nVidia is about 35% of GPUs, whereas OpenCL works on AMD/Intel, and now some ARM devices too.
It is only a little easier to work with, and it doesn't work better on nVidia, it ONLY works on nVidia. OpenCL performs far faster on AMD. Just look at the huge gap between AMD-OCL and nVidia-CUDA coin mining.
That said, I still understand people use CUDA if it's for their own use and happen to have NVIDIA cards - which is quite plausible in academic circumstances. But yes, for shared open source code you'd think there would be more focus on being cross-platform.
Nvidia's gpu drivers are better under Linux. 
Oh, im sure that you can get great performance out of AMD cards on whatever you want. but you can get equal performance with Nvidia using CUDA. also, coming from the perspective of the guy who manages a GPU compute lab, You can come install AMD drivers if you want. Ill stick with the ease of NVidia. Again, its not 2002. 
It really sounds like you are basing your experience of 'AMD is bettar than Nvidia' solely on dogecoin mining.
Contributors and testers welcome! For those of you not familiar with Revel, check out the docs: http://revel.github.io Also note that we've recently moved to an organization repository, which is explained in the release. Feel free to ask any lingering questions either to me here on Reddit, on IRC (#revel on Freenode), or just submit an issue.
with the new skeletons: https://github.com/iassic/revel-modz is more accessible 
No. Render farm.
&gt;you can get equal performance with nVidia using CUDA That's flat out wrong, the architecture doesn't allow that, although maxwell is up to speed at 32-bit work now.
That's a hardware architecture difference, not an SDK difference. NVidia chips don't have a barrel shifter because you don't need that for graphics; AMD chips do for whatever reason.
&gt;AMD chips do for whatever reason. Because it's an OpenCL feature...
It isn't entirely true about blocked goroutines not wasting system resources. The runtime will create new threads when goroutines call blocking syscalls.
&gt; The number of independent primitive concepts has been minimized in order that the language be easy to describe, to learn, and to implement. On the other hand, these concepts have been applied orthogonally in order to maximize the expressive power of the language while trying to avoid deleterious superfluities.[10] From: http://en.wikipedia.org/wiki/Orthogonal#Computer_science I also think of orthogonal vectors from linear algebra, which form a basis; well, there are non-orthogonal bases as well, but the normalized way to define a subspace is via orthognal (unit) vectors. 
I've learned about orthogonal code in the book "Clean Code"... and for me, it means code that's independent from other code, implicitly or explicitly just like variation in the x axys is independent of variation in an orthogonal y axys, they are independent variables. With code, when you have a method that you need to refactor, and because of the refactoring you have to take care whether it's time to also refactor another method or not, that means you're not, in the first place, taking care for them not to be related so that you don't need to be worried or whether you just need to remove a method that's doing other methods work. Other related term is to have simple and proper *separation of concerns*. Just as you stated and as can be seen, this leads to easy of prediction, since foo( ) won't be implicitly related to some unrelated bar ( ).
(This here is my understanding of orthogonality in programming languages; feel free to send me to hell if it's wrong in some aspects.) How I see it, orthogonality summed up in one sentence is "Everything in its right place". It is a property that makes designing easier by making you do it the simplest and most obvious way. This means that when you hear a problem, you know exactly how to solve it. For example, if you need to work with data structures with known attributes (say, a point in space, with X, Y and Z coordinates, and maybe colour), you know that you'll probably use structs, but if you know that these data structures may have arbitrary attributes and that number of attributes may change over time (e.g. an HTTP header or an HTML element), you also know that you'll use maps. Maps and structs are similar (they store various values and let you access them with a key), but you know that when you need better performance with restricted number of fields, you use structs, and when you need more flexibility with a price of slight slow-down, you use maps. They are orthogonal. Could Go also have tuples? Enums? Extensible objects a-la JavaScript? Built-in lists a-la Lisp? Algebraic data types a-la Haskell? [Tuple structs](http://static.rust-lang.org/doc/0.9/tutorial.html#tuple-structs)\* a-la Rust? Yes, it could. The question is, would that make your life easier? Would that make you ask less questions while designing a system? Or would it now make you ask yourself, whether you should use a tuple, or a struct, or just use JS objects everywhere and not give a crap. \* If anyone Rust-literate could explain me, what is this and why I would ever use it over structs or tuples, I would be very grateful.
Honestly, I wouldn't bother trying. It's going to be hard for someone steeped in the world of PHP to hear this as anything other than "Go lacks features", and the Pythonistas already have a decently orthogonal language. ("There should be one-- and preferably only one --obvious way to do it." is a core Python value statement.) (Before smashing the downvote button, please read that paragraph carefully. That's not _my_ opinion about Go. But I am serious, pretty much from experience, that a very heavy PHP programmer is not going to go "Oh! Orthogonality! That's what I've been missing." You'll be lucky not to be dismissed as an ivory tower academic with that approach.) In what I presume is an hour or two hour presentation, I would focus on showing them the things that are effectively impossible in PHP and annoyingly difficult in Python (even with gevent); that'll keep you busy enough. Build up to something like a concurrent web scraper or something, and then blow their socks off with the performance or something. Focus on getting them hooked, not giving them a complete education in an hour or two.
First let's consider that the concept of orthogonality is not limited to Go. You can write code in other languages that is orthogonal, you can craft something with your hands using orthgonal principles. In Go's case, the language was designed with orthogonality in mind. What this means largely is that Go favors a smaller, and simpler syntax and design to other languages. Instead of having a ton of options, there are simply fewer options to keep the language small and simple. Many people come to Go screaming about how "their" feature in "their" favorite language is missing from Go but the truth is, most of these features add a lot of cruft to the language that introduce many corner cases, bad practices and even long compile times. Go's approach is, instead let's define the smallest and purest pieces we need in a language and let's use those pieces together to build larger solutions as needed. In essence we are trading a complex language for easier readability, writeability and maintainability.
I'm somewhat Rust-literate and for me tuple structs usage just fits where it seems obvious, you want a *named* tuple type (not an anonymous one, like a raw tuple). You can then use this feature to disambiguate "tuples" in pattern matching and other situations, if you only had tuples, you won't be able to do this, and if you only had structs, you would need to have named members, which sometimes is not desired. So it sits right in the middle between tuples and structs.
The article reads amusingly. Go interfaces are, in some sense, like magic. That they're satisfied implicitly makes it really easy to extend existing code without upheaving a bunch of things, assuming your funcs/methods take interfaces instead of concrete objects. Plus, it's often much easier to test interfaces where mocks or fixtures are required than it is to mock up concrete types.
Hey, thanks for cross-posting this, [dgryski](http://www.reddit.com/user/dgryski)!
No problem. I try to keep /r/golang filled with content to showcase the active community. I think it's great when people write blogs about their projects and experiences with Go.
"good" although he's passing lengthy structs by value in the this/ref param which also affects mutability of his types....
It's the fact that the small set of features on the language fit each other really well, which allow for flexibility and powerful constructs while keeping the simplicity. In practical terms, it allows your application to grow gracefully without increasing the complexity. This talk illustrate a bit of what I mean: http://vimeo.com/53221560
We use PuerkitoBio/goquery and it is fantastic!
IntelliJ IDEA + Golang plugin looks pretty good. 
Hey, thanks for the link - good stuff there. I've been using revel for a while in a personal project, and I'm sure this would have helped me when I first took it for a spin..
I use one GOPATH as well. Love it. No project setup needed. 
You can have multiple paths in your GOPATH. `go get` saves the things it downloads into the first path in the list. It's a good idea to have a staging path in front of the others, just so that when you `go get` something new, you can see all of its dependencies at once before you integrate it into your system.
I almost never want to do that. The source code doesn't take up much space. It doesn't collide with any other projects. It can just stay there. If I do feel like I need to remove a package I just delete the directory. Can't really remember the last time I did that though.
I've only done this a couple times... I think you just delete the source folder, the package files, and the binary (if any). Takes about a minute if you're clumsy on the command line (like I am quite often!).
Damn that's impressive. Did you write the parser entirely by hand?
&gt; These features are not implemented yet, but on the roadmap: &gt; &gt; * goroutines, channels, select While impressive, I'm even more impressed by https://github.com/tardisgo/tardisgo which implements all the hard things (goroutines, channels, select) and compiles Go -&gt; Haxe, which then goes "Haxe -&gt; JavaScript / ActionScript / Java / C++ / C# / PHP / Neko", per the github page. The demo at FOSDEM was amazing. Here's the video: http://www.youtube.com/watch?v=Qe8Dq7V3hXY ... great presenter, too. And a live demo: http://tardisgo.github.io/ --- http://tardisgo.github.io/gohandlingmouseevents/index.html 
its not my project
You don't need a framework. Build your software the right way: separate your backend (API) and frontend (whatever is good).
Thank you all for the answers, the links and the references! They helped!
Was the talk recorded?
it was, video should be coming soon
Great :)
This is awesome, thank you.
This was the result of scratching an itch of an issue that I'd really struggled with to automate (see my original question here: http://serverfault.com/questions/482804/how-to-maintain-file-folder-ownserhip-and-permissions-over-time/578897). Previously, we'd used a cron job that ran every hour by running a find on files and then separately on folders, and running chgrp across the whole lot, ensuring to set the setgid attribute on folders... it was pretty heavy handed and didn't offer us the flexibility we needed for subfolder configuration. This daemon has the benefit that it uses inotify to catch file changes and is much lighter on the system.
Also, with regards to Go specifically, I found development to be relatively straightforward with a couple of exceptions. One being that while the package os provides chwon and chgrp methods, it doesn't provide the ability to read the user or group attributes of files  this has to be done via a syscall which wasn't at all obvious to me. And that while the package os/users provides the ability to translate system users to ids, there's no group parallel  and so I had to resort to calling out the C function equivalents. Would love to find more idiomatic ways to do this. Also, whilst I know this will probably never happen, it would be wonderful to have the ability to mark certain variables or data structures as immutable, and pass them between goroutines confident that they're set in stone.
This is pretty cool. I actually recently wrote something in Python to achieve similar goals. I'm using POSIX ACLs though. Rather than running a daemon, the tool is setuid, so directory owners can update ACLs for people who have RW or RO permissions. The member list for a directory is just stored in a hidden YAML file (.dirname.yml). Anyway, I'm rewriting it in Go now along with a Go library for POSIX ACLs.
&gt; Focus on getting them hooked, not giving them a complete education in an hour or two. basically: "sell, don't teach"? 
The problem exists for all languages. throw new Exception("something went wrong") raise "Something went wrong" etc. Good packages will provide specific values or types to match against. If you want to make errors more generic without losing the original error then you do what people do with exceptions and wrap your specific error value in a generic error value. eg. type ErrRecordNotFound struct { Err error } func(ErrorRecordNotFound) Error() string{ return "Record Couldn't be found" } func massageError(err error) error { if err == SqlNoResults { return ErrRecordNotFound{Err: err} } return err } func (ds *myDataAccessLayer) doSomeCrap() { if err := ds.doSomeQuery(); err != nil { return massageError(err) } return nil }
Sell through teaching. And I don't recommend a _hard_ sell either; really, the point of a short presentation is ultimately to answer the question "Do I, the listener, think this is interesting enough to pursue on my own time?" and it's not just better salesmanship, but more respectful of the audience's time to keep that in mind. Answering questions like "Does the presenter think this is awesome?" is, by comparison, much less interesting for all concerned.
Everything in my post here is just additional info. There is no criticism intended of a great, fun project that you've written up. Everybody should do this at least once. Traditionally, a "Symbol" is externally represented as a string, but internally represented as a number. You'd add a `map[string]int` (possibly wrapped in appropriate types) and a counter to keep track of the last one you generated to the `Env`, and then do a lookup when you encounter one, adding a new value to the map when a new symbol is encountered. In a full language implementation you'd probably eventually need to keep a reverse-lookup map as well, which you'd use when outputing something to the user, who doesn't want to see (and really shouldn't be able to see) the internal value. This explains why in many languages you have to be careful about generating symbols; if you continue generating distinct symbols indefinitely, you will eventually consume all the RAM with the symbol table. This is a prime case for a [sum type in Go](http://www.jerf.org/iri/post/2917) if you're so inclined to continue working on this. I suspect it would also contribute to speeding the core interpreter loop up, as I suspect a type switch would be faster in a couple of places than a series of string comparisons. (I'm not sure if Go implements this, but they ought to be able to use the ancient "leap directly to the correct implementation" compiler switch trick on type switches, which should be substantially faster than a series of string comparisons, though whether that impacts execution speed would depend on how fast everything else is.) However, be aware that language implementation has no obvious stopping point... you could literally spend the rest of your life improving your language. :)
Thanks! I really appreciate your feedback. I would like to continue working on the interpreter just because it's so fun to write and LISPs are so elegantly simple. It's also a great way to learn how to use a LISP.
TL;DR: A single `GOPATH` doesn't scale. I have several different types of projects, and I find that having a single `GOPATH` forces the `go` way of doing things on all of them, which is quite often the *wrong* way for those projects. For example, Dart projects follow a [package layout convention](https://www.dartlang.org/tools/pub/package-layout.html), with `./bin/` and `./build/` being where binaries and build deps go. `go` expects `$GOPATH/bin` to be where binaries go, so unless I `GOPATH=$(pwd)`, I have to either `go build server.go` or `cp $GOPATH/bin ./bin`. Sure, maybe this is a fringe case. But what about libraries? Let's make a hypothetical project: / util/ util2/ Let's say this code is hosted at `github.com/jeremiahs_bullfrog/project`. My imports (within the project) then look like this: import "github.com/jeremiahs_bullfrog/project/util"` import "github.com/jeremiahs_bullfrog/project/util2"` Let's say someone wants to fork and fix my work. In order to keep things mergable, they just `ln -s $GOPATH/github.com/jeremiahs_bullfrog/project path/to/their/fork` (or `git remote add path/to/their/fork`). I *would* use [relative imports](http://golang.org/cmd/go/#hdr-Relative_import_paths), but they're [frowned upon](https://groups.google.com/forum/#!msg/golang-nuts/n9d8RzVnadk/07f9RDlwLsYJ) and [aren't supported](http://code.google.com/p/go/issues/detail?id=3515&amp;can=1&amp;q=relative%20import%20status%3DWorkingAsIntended&amp;colspec=ID%20Status%20Stars%20Release%20Owner%20Repo%20Summary). Let's say I reject the user's patches, but others need to rely on the changes, so the user has to change all imports to match his/her fork. On a large project, this can be time-consuming, and this process has to happen every time someone wants to use their fork (and changing imports is definitely *not* going to be accepted in a patch). Then there's the case where I'm working on two packages (A and B) that depend on the same import. Upstream introduced a bug that affects A but not B, and B relies on new features from upstream. A and B then need separate versions of the same package. I *could* use branches, tags, etc, but my entire team would have to have the same setup (which can be scripted), not to mention the possibiility of a corrupted `GOPATH/pkg` (which also *has* happened). I *could* clean `GOPATH/pkg`, but then I loose fast compiles. Having a workspace is nice because then I can use `git submodule` to manage deps, and everyone's on the same page. Cleaning `$GOPATH/pkg` only affects one project, and only when dependencies change *in that project*. Having a single `GOPATH` simply *does not work* in this case (and I've run into it...). I end up having to sandbox my applications in workspaces (quite often with a `./build.sh` that does `GOPATH=$(pwd) go install`). This has the nice side-effect of being able to track specific commits for dependencies within a project, which helps with reproducible builds. I *do*, however, use a single GOPATH where possible, but it isn't always possible.
You're absolutely right. It's still not decentralized because your traffic flows through a third-party server. It does, however, mean that your data is stored entirely on your own servers which is a step in the right direction. It's true that if the srvdir servers go down, the decentralized ones do as well, but keep in mind the srvdir servers are just dumb proxies. This has two benefits. First, because they're simple, it's easy to keep them up. They don't have the operational complexity or resource requirements of something like GMail or your typical cloud service. Second, they are shared-nothing and you as a srvdir user should be able to pick one or many to connect to - even using different "tunnel providers". This could give you HA even if a whole tunnel provider went down. There's one other issue, which is of more concern to me: Even though all of the connections are encrypted, you still have to trust the tunnel provider. There are two things that will help with this: 1. The tech in go-tunnel allows you to expose services which proxies TLS traffic by looking at the SNI extension data. This means a third party can proxy your traffic to you *without having the keys to decrypt it*. This is huge. At this point, you don't even have to trust your tunnel provider anymore! It doesn't matter that the data is flowing through third party servers because they don't have the keys. (Just like you don't have to trust the routers/switches of your ISP) 2. QUIC will give us some hope as well. It's basically building SCTP on top of UDP. You'll get TCP's guarantees, encryption, multiplexed streams *and* the ability to enable peer-to-peer communication, because you can punch holes for UDP-based traffic through NATs unlike TCP.
Go [doesn't use jump tables](https://groups.google.com/forum/#!searchin/golang-nuts/switch/golang-nuts/Sz7i4zQT9os/TLYP9GplZ4EJ) for a normal switch. Not sure about the type switch, though. For a switch statement with case &gt; 4, it will do a binary search.
Oh crap, you wrote your own PEG parser-generator? That's super impressive.
not this post again with zero substance to it
It's been updated, so not a pure repost. Have you written about your own dependency management solution?
The post is just a summary and a call for help. The title is linkbait imo.
On Motorola RAZR with Carbon ROM downclocked to 800MHz, the performance is fine. I have no idea why it works well here.
Haven't I read this before? Or something extremely similar? I remember getting to "When you release open source libraries, aim to minimize the number of dependencies. Learn and use the standard library. Be go gettable." before and being -___-, what really, your solution is just don't have dependencies? Great.
Bringing the article up to date was my intention. There were still people reading the old article written in July, which no longer represented my current thoughts on remote packages in Go.
If you plan on using JavaScript, I'd go with JSON. Speed won't be an issue and you don't need a 3rd party protocol buffer decoder.
I would also start using JSON, just because it's the simplest thing to do. If you find this isn't fast enough find out what the bottleneck is and optimize for it. Do not over-engineer this from the starting point.
It probably wouldn't be that hard to have multiple end points, one for JSON, one for protobuf, one for GOB
It isn't really that hard to just set the situations up and benchmark them. Once you've set up your favorite situation first, though, the next question is whether you even _care_ about the other alternatives. It is very likely that all outcomes are going to be equally fast and all outcomes will be dominated by network times. If you are _really_ speed bound, I suspect (but only _suspect_; benchmark!) that rather than serialization method being the bottleneck that you will find that using websockets instead will be significantly faster, and feel faster to the user. Websockets will avoid the TCP handshakes and other issues that can arise on AJAX connections (even with pipelining in the web server, it takes longer to establish, and your client has to support it too). It is likely that JSON-over-websockets will be your best bet. But I can't promise; it still depends a lot on details you haven't given. Getting Go to serve websockets is easy; I do not know if you can find a client. Alternatively, real TCP sockets may work too. The meta-answer is still "benchmark". If you're moving arrays of strings, JSON is actually pretty effective; it is likely that the serialized data structure will still be mostly payload. JSON starts losing out when it starts moving objects around; it really pays for the redundancy of the endless re-specification of property names. Yes, you can do somewhat better, but not a _lot_ better.
The overhead for encoding/decoding JSON in this case is going to be vastly lower than what you're already paying for HTTP+TCP. However, if you're seriously concerned about performance (and you *should* profile JSON first to make sure it's actually not good enough), you don't really even need a library for this. Write a 32-bit int indicating the number of strings, then (N times) a 32-bit int indicating the length of the string, then the string contents. Decoding this is trivial. Msgpack is kind of the best of both worlds, in that it uses almost exactly the schema I described above, but has libraries available for most popular languages, including Go. Protobuf is overkill here, unless you're already using it for other, more complicated endpoints.
Is gob, at least for now more or less Go specific? IMO, JSON is great for prototyping and often good for production.. But protobuf is my goto for performance which is a concern on one product I work on..
You say you're accessing a member of a struct in init...you've initialized the struct already previously in the init, right? Or that is handled by the init in your config package?
Note that if you have multiple init() blocks in the same package that there is no guarantee as to their order of execution.
That looks pretty neat. It indeed generalizes on the regex-based lexer. I guess the biggest difference I had in mind was that while yours uses native data structures and generates the lexer at runtime, mine would compile a text file into go. However your implementation gives me some ideas. Instead of using the crappy Lex/Flex input format, I could use json and a structure similar to your input and use the standard library to save me a lot of work.
&gt;Is gob, at least for now more or less Go specific? Yes, gob is only meant for use by Go programs.
Not entirely true. init blocks in the same source file are executed in the order they appear in they source code if I recall correctly.
I wrote a benchmark of many different Go serializers: https://github.com/alecthomas/go_serialization_benchmarks On my machine, [msgpack](http://github.com/vmihailenco/msgpack) is the fastest serializer. [XDR](http://github.com/davecgh/go-xdr/xdr) is also fast, but does not support `time.Time`. The benchmarks also highlight a number of issues with some of the serializers, mostly around deserialization of `time.Time`. Edit: the benchmarks obviously don't address your secondary requirements about Javascript.
Hmm, my reading of [the spec](http://golang.org/ref/spec#Program_execution) says no: &gt; A package-scope or file-scope identifier with name init may only be declared to be a function with this signature. Multiple such functions may be defined, even within a single source file; **they execute in unspecified order**. Later in that section, it clarifies that you can rely on the `init` functions of imported packages to execute before the package that is importing them. However, the same section also says: &gt; If two items are not interdependent, they will be initialized in the order they appear in the source, possibly in multiple files, as presented to the compiler. But that paragraph starts with: &gt; Within a package, package-level variables are initialized, and constant values are determined, according to order of reference And doesn't seem to mention `init` functions at all. So I'm led to believe that that paragraph is only talking about package level variables and constants.
Can you do anything in the game other than walk around? I don't mean to be a negative nancy, I just want to know if I'm missing something. As a demo of how to use Go with websockets, walking around is more or less all you need.
&gt; but I only see one println output, the one in init() outputs "" Of course it does. The value hasn't been populated yet, because init() runs before main() does. Where is the value for Config.Label supposed to come before that?
Thanks for your input! What you're saying makes a lot of sense: Go AST's are much more complicated than HTML parse trees and I shouldn't expect to manipulate it as easily as adding a few lisp macros like enlive does. 
Would using something like [godep](https://github.com/kr/godep) be a better solution? You gain the ability to automate the checking in of dependencies into your repository without updating import URLs. The only drawback I see is that you need to depend on the godep tool vs sticking with the standard go build, go ....
In this particular case, there's not much point in having a pointer; had you declared it as just a `MyConfig`, it would have been zero-initialized for you.
&gt; For example, the way I keep thinking of pointers vs values in Go is the same way I think of objects vs strings in Javascript. The former is mutable, meaning it's possible to get side effects when it gets passed around, and the later is immutable. It probably oversimplifies the difference, but it works for me. Values can be mutable in Go. The reason the callee won't see any modifications to it is because it gets *copied*, not because it's immutable.
It's a waste of OP's time to benchmark. Just use JSON.
Issues to fix: * [do not ignore error return](https://github.com/Shoen/phaser_multiplayer_demo/blob/master/server.go#L41) * [synchronize access to slice](https://github.com/Shoen/phaser_multiplayer_demo/blob/master/server.go#L51) * [ditto](https://github.com/Shoen/phaser_multiplayer_demo/blob/master/server.go#L59) * [don't block on client that's not reading socket](https://github.com/Shoen/phaser_multiplayer_demo/blob/master/server.go#L82) 
I'm using git submodules, but with the repos pointing at clones on our internal git server instead of at github or whereever. I don't have to change import paths, we have local copies of everything, we can patch our local copies, and we don't lose history when we update the third party code. Seems to be working well so far.
Does anyone know of any similar podcasts? The only similar podcast I know about is Software Engineering Radio, but it stopped being good.
Those are great points, thanks for the reply :) Will definitely have to look into QUIC. As I said, I love where this is going, will be making a lot of use of this :)
Ah yeah, I've heard about that approach too, but haven't jumped down the submodules rabbit hole yet. :-)
http://thinkdistributed.io/ , from some Basho (Riak) people.
Browser based realtime multiplayer games will always be sucky because of the browser's limitations and protocol slowness, I've been playing with Go on a regular multiplayer game, UDP based protocol. Works fine for anything non-realtime though. Go is GREAT for this if you're not super crazy about latency(a couple ms instead of microseconds), you can easily handle clients in the hundreds, and quite easily have multiple systems involved. Chat server, item server, and world server, all behind a front-end.
Yo gopherjs, imma let you finish, but Elliott has one of the best transpilers of all time! 
I didn't know that there's a reverse proxy like that in the standard library. Neat!
Why use AngularJS (or any JavaScript at all)? It is completely superfluous for this purpose. All you're doing is slowing the page by requiring browsers to download 4 separate scripts (not to mention the five stylesheets) and annoying people who disable JavaScript. All a pastebin is supposed to do is to take some text from a form and put it on a page with a permanent URL. This can easily be accomplished without any JavaScript.
Try this: https://raw.github.com/pote/gpm/master/gpm_install.gif
upgrading Go is so insanely easy.
Thanks to the Go devs, and also to the GVM devs! gvm install go1.2.1 &amp;&amp; gvm use go1.2.1 --default 
&gt; The former is far, far preferable to the latter. Especially if you need to give something to a client/customer to test.
Absolutely should have linked to the raw, my thinking was that I'd be better to have people see the actual repo. Thanks for the heads up!
Having written many projects for work I can see this being highly valuable. If you are new to go then think of it just like you would package pinning + virtualenv for python development. Multiple projects requiring different versions of the same package can get unwieldy quickly and the only way to maintain any sanity is to use virtualenv. gpm + gvp is an awesome idea. 
Yeah, the timeout approach is pretty effective, especially if you don't mind http requests blocking for a short time in the hopes they can get a worker. Alternatively, you can just create the WorkQueue channel with a large buffer, and do a true nonblocking send select { case WorkQueue &lt;- work: w.WriteHeader(http.StatusCreated) default: http.Error(w, "I am busy; go away", http.StatusServiceUnavailable) } I think the dispatcher idea gets really interesting if you don't want just one WorkQueue, but instead want some sort of priority system where higher priority WorkRequests get processed ahead of lower priority ones. That'd be interesting to see implemented.
Author here, let me know if you have any feedback. The GitHub repo: [https://github.com/tsileo/btcplex](https://github.com/tsileo/btcplex).
Why a REST interface? A simple web page would suffice. Why write it in go at all? A shell script exposed via cgi-bin would have been fine for a pastebin. Why go to the trouble of running a web server? All you need is a port. Why all that TCP connection setup overhead? Just use UDP. Why do I even look at other people's code at all if I'm just going nitpick every decision they make to hell and back? Cut and paste is enough for my own code.
&gt; My complaint was specifically about the use of client side scripting to accomplish something the browser is already perfectly capable of handling. That doesn't even make any sense. The browser *is* handling it. It's running javascript to consume a REST interface and using angular and highlight.js for presentation. You are telling him to run it server-side and spit unadorned html at the browser. &gt; Using Angular adds complexity while easing neither development nor use of the pastebin. Why use anything. Why make anything.
&gt;That doesn't even make any sense. The browser is handling it. It's running javascript to consume a REST interface and using angular and highlight.js for presentation. You are telling him to run it server-side and spit unadorned html at the browser. Now *you're* nitpicking. But since you insist on doing so, I'll rephrase it: &gt;My complaint was specifically about the use of client side scripting to accomplish something the browser is already perfectly capable of handling **without the use of additional client side scripting**. Are you happy now? &gt;&gt;Using Angular adds complexity while easing neither development nor use of the pastebin. &gt;Why use anything. Why make anything. That doesn't address my criticism at all. Making things is great, adding unnecessary complexity is not.
Awesome. I love Docker. [Drone](https://drone.io/) is a cool new project that allows you to do CI with Docker as well.
What criticism? You're complaining about present-day-standard web app architecture not being 1990s enough. He wrote an API and consumed it via standard browser tech - OH NO IT'S TOO FANCY BURN THE WITCH. You'd have a valid criticism if the entire thing was written in, I don't know, flex or silverlight or something. Or if his browser target included lynx. Even that would be stretching it; since the backend is an api and he can just write the vanilla http interface you lust for in addition to what's already there in 10 minutes.
What's wrong with using a regular HTML page? What exactly is gained by using Angular?
Can someone post a link to the said talk?
There is a reason for not using the standard tools bundled with every go dist?
I tend to compile directly to the target os/arch when I need cgo support...but rarely I need it.
This approach does use the standard tools. It's simply a wrapper around the standard tools to automate the build process rather than manually changing environment variables and building it yourself a dozen times. 
Excellent point. It doesn't work with CGO. I should add this to the article.
I primarily used goxc for cross compiling my projects, but I tend to use https://github.com/mitchellh/gox now when my needs are simple. Parallel builds are handier than you'd think, and I rarely personally need the ability to do all of the post-compilation steps goxc provides. That said, they're both wonderful tools and I would advocate using either.
Addendum, goxc and gox both provide the ability to build your cross compilation toolchain. For goxc: `goxc -t` *(Actually optional, toolchains are built/updated as needed now)* For gox: `gox -build-toolchain`
Using CGo is fine on Linux/MacOS, but on Windows, ugh, such a pain.
Mine is not a critique, it's just a question =). I usually cross compile my go projects for deploy and I'm done with a "GOARCH=386 GOOS=linux go build". My needs are quite simple, for now :)
There's a lot of dependencies in the form of DBs in the documentation; I see that SSD is for storing big lists of data that I assume makes sense in this type of application. But you then use Redis, a key-value store AND levelDB, another key-value store. Could you elaborate as to why not a single kv-db can do the job?
I'll try to do my best: SSDB (which is backed by LevelDB internally) and Redis have the same interface, but SSDB is used for persistent data (blocks, txs, address balances...), data stored in it is never deleted from SSDB, while Redis (faster than SSDB, because everything is stored in RAM) is used to store short-lived data (everything related to unconfirmed transactions) and for its PubSub features (which SSDB doesn't support, and needed to power the API and communicate between processes). In fact, if you have a server with 100+GB of RAM, you could just drop SSDB and only use Redis. LevelDB is only used in the import phase (btcplex-import), I would love to use Redis, but none of my server have enough RAM available, and since LevelDB is embedded, it's faster than using SSDB. I should make sure if using LevelDB really makes sense. I agree that it makes the setup a little complicated, but I feel the data(base) is safer this way. **Edited**: forgot to talk about Redis PubSub
This is something I haven't had the pleasure of doing. But I'd like to statically link 0mq into a cross platform application in working on, so I suppose I'll have to 
Have an example? My biggest fear is having to create a VM farm to build for all targets if I want to statically link 0mq, which takes away the painless build chain I've come to love with go. 
Well of the 4 platforms Go in on, seamlessly supporting MacOS/Linux/BSD is pretty trivial, I just have 1 VM for each, I pull my project on the VMs, compile, push result. Windows... ehh I still need to get around to that. You can also compile for different arches on Linux which is nice, I make i686 AMD64 and ARM all in one shot.
I don't get it... How exactly is this type-safe if I need to cast every object I pop to the appropriate type? In Java, a generic Stack implementation's pop method would return an object of the specific type - here it would return something that is `interface{}`, i.e. the `void*` of Go.
You typically won't be exporting the generic version, and instead just exporting the type-specific version. If you have a little care when writing the type specific versions, then the code using the container (or whatever) won't be able to insert strings into a ComplexStack. 
OK, so the idea is to wrap the non-type-safe container in a type-safe one, do I understand that correctly? If so, this is a valid approach, but I think it further proves the problem with the lack of generics in Go.
If that's so, you should explain what "generic" means.
I think that's a good idea, I'll keep that stashed away for when I need something like this. On the other hand, I've found that if you can rely on the compile time checks to sort stuff out, then you should. Reflection (used in type assertion) is a package that converts compile time errors into runtime errors, where they're harder to catch. I guess this is a tad in the micro-optimization side, but reflect related things are also noticeably slower in golang. You can benchmark stuff like strconv.Itoa vs Sprintf to see some of that (though I can't prove that the slowness is just due to reflect).
It's not like it's just "free" performance there either, the author seems to be throwing away thread safety by using this global: var encodeBuf bytes.Buffer It should probably be behind a mutex, if it's going to be used that way.
The proper choice is Sync.Pool, as described in the Cloudflare blogpost and this issue: https://code.google.com/p/go/issues/detail?id=4720
`goimports` is one of the best additions to my toolset since Go itself. Thank you!
The idea is that if your container implements a lot of complex logic, you don't want to duplicate that across multiple nearly identical versions.
Code that's _type parameterizable_, which that's not. That's just one type: `void *`.
What sort of answer do you expect? It depends on what you are doing.
&gt;The proper choice is Sync.Pool Your meaning of "proper" is different from mine. Sync.Pool is only in tip, not in a release version and has the comment that it is experimental and may not get in mainline. Avoiding unnecessary object creation (as was done in this situation) is superior to object reuse.
The title is *Approximating* Generics in Go, so it's preparing you to expect something that *isn't* generics (as you say). There's no misrepresentation here.
&gt; What sort of answer do you expect? Yes/No/It's Complicated? Quantitative answers are best, of course. &gt; It depends on what you are doing. Well, no. It depends on additional overhead for JIT VMs like the JVM, if such a thing exists. I'm talking about CPU bound systems. My project is this: http://www.reddit.com/r/roguelikes/comments/1xa9rj/i_have_been_writing_a_pseudoroguelike_mmorpg_with/
:\ I don't feel like this explains how goroutines work.
There are three main advantages of not relying on a JIT. You use less RAM. You get a smaller (and all-inclusive) binary, and you don't need too wait for the application to warm up for your application to be fast. Of course, a JIT might be able to optimize better, so you loose that...
I'm no expert but my guess is it depends on the AOT compiler and the VM/JIT you're comparing. JIT definitely imposes some overhead but it is also take realtime production stats as input on the optimization process, which can improve performance considerable on long running processes. It will definitely use more resources but it might be able to squeeze more performance out of it. That said, depending on the problem you're solving the AOT compiler can optimize heavily the generated code to a point that JIT overhead is greater than the performance it's real time compilation/optimization can yield. 
&gt; Reflection (used in type assertion) is a package that converts compile time errors into runtime errors, where they're harder to catch. With a little bit of care implementing the short amount of boilerplate, there is no possibility of runtime type errors. The only things that go into or come out of the StringStack implementation are strings.
Note my question is not just about JIT. It's about JIT on hypervisor virtualizers like Xen.
Note my question is not just about JIT. It's about JIT on hypervisor virtualizers like Xen 
I think the point the OP is making is that you can implement some complex data structure with `interface{}` and then provide a thin wrapper over it with concrete types. The wrapper is grunt work and certainly is indicative of a less expressive type system---but one might prefer it to duplicating code for a complex data structure. There's a laundry list of downsides to this approach, sure, but I think delusional is a bit strong. Besides, "generics" is the Go buzz word of the decade. I can hardly blame someone for using it liberally, especially with the word "approximating" preceding it.
I actually have a real-world implementation of exactly this pattern! https://github.com/campadrenalin/go-deje/tree/master/manager The generic version of the code is unexported. The type-specific wrappers *are* exported. There's a tiny bit of type-specific serialization code in some of the wrappers, and other than that, it's just boilerplate. Obviously not as good as "real" generics, but this is a perfectly viable solution.
I've been looking for a post like this. I tried following TDD by example in Java and translating to Go, but I don't know any Java so I eventually gave up.
There's a lot of variation with virtualization: it is very dependent on the hardware- whether it has the processor extensions that speed up virtualization and how that interacts with various runtimes. It's a very complicated situation that would really only be measurable case-by-case per hardware and per virtualization suite.
Personally, I like [this](http://godoc.org/bitbucket.org/santucco/btree#Key) approach better, since it avoids code duplication and reflection.
I'm really interested in TDD instead of testing as I write, but I feel lost working with existing code bases that don't support this. I wish someone would write a blog post like "Here's the best path to go down to get to code coverage over time". I don't care about the language, but Go would be nice.
I did TDD in ruby for a long time but in Go I find BDD to be more helpful than TDD.
It's not a blog post but there's a book called "Working efficiently with legacy code." It's not about TDD but getting untested (aka legacy) code testable with automatic tests. Make sure to at least read his article on the same subject as it contains a lot of good information too. Edit: Link to the article: http://www.objectmentor.com/resources/articles/WorkingEffectivelyWithLegacyCode.pdf
Doesn't really matter though. Once the VM is hot (most code has been compiled) the JIT doesn't really pose that much overhead. The reason some software would run slower on a hypervisor setup like Xen is because Xen has alot of overhead. You should expect the same performance difference on a Xen setup, as you would on a dedicated server. The dedicated setup would of course be faster due to the lack of hypervisor overhead.
Good start. I want to make a few suggestions. First, use `go fmt`, It doesn't *really* matter, but it makes your code stand out when you don't. You can also use types to make unmarshaling data much easier. I commented out some stuff, but you can see an example here [http://play.golang.org/p/7Nl93X_lCN](http://play.golang.org/p/7Nl93X_lCN). You'll also want to check your errors, especially with user input.
&gt; yes really, no IDE. I wrote the entire project using Sublime Text. So okay, if you think of Sublime as having no IDE than yes, you don't need IDE. But besides debugger integration, Sublime with GoSublime is pretty much an IDE (it has code completion, jump to source, compile inside sublime, auto formatting, auto linting, auto error checking).
Speaking of IDEs, the IntelliJ Go plugin has been making huge progress and became very active in recent weeks. I don't know about a stable release, but I've built the tip of its master, and it solved a lot of problems I had with it, AND added gdb integration that actually works!
cgo has worked fine with cross-compiling for some time. You need a target gcc and target libraries, so it's still a PITA though. 
yeah. they have some loose UI ends to tie, especially configuring project structure and paths. but you already have everything one might expect, including running go get and go fmt automatically, unit test UI integration with go test, some refactoring macros, jump to source, etc etc. 
I think I'd agree and I lean the same way, but I still tend to refer to the process as TDD. Usually I end up with a mixture of testing styles, but I do think that the behavior focused ones tend to be more useful.
Agreed, it's improved tremendously lately. There are still some strange hiccups (like GDB pointing to source lines that are all comments) but I'm hopeful the kinks will be worked out soon.
No, our entire gopath is commited -- the 'src' directory is at the top of the checkout, and we set GOPATH to where we cloned the repo to. Inside the src directory is where we have our internal code (under $company_name directory), and also our deps from github.com and code.google.com , etc. I can fake a directory tree listing if this still isn't clear. 
Not clear. Do you still use go get to populate the GOPATH; then checkin ? Or don't use go get but go submodules instead ?
As long as you write concurrent code using goroutines, Go's runtime should automatically run those on multiple threads if it sees it benefical. It will not magically parallelize your sequential code flow though.
Is three weeks of vacation generous in the US?
Yes
Thanks. Makes me realise how fortunate we are in Europe. I couldn't imagine spending so little time with my family each year. Edit: I wonder if people tend to take a lot of sick days as a consequence. I took perhaps one last year.
Got it. Going to give this a try. Thanks
It depends on exactly what you're asking. Go does not have the GIL in Python, and multiple goroutines can be executing truly concurrently on multiple processors. This is the big threading issue that is _specific to the standard Python implementation_ (and a few other languages as well, but Python is where people complain about it), and it is definitely true that Go does not have it. I am not sure what happens if you try to do that with C libraries in Go, though. Go does theoretically share some other threading issues, though. It is, technically, a shared-state threading environment, and technically, you can still get into all the trouble with that that you can get into with any other such environment. However, the Go culture is to have separated goroutines that communicate via always passing around full data structures, which makes it _less_ prone to these issues than older languages that were around during the first phase of threaded programming. It is likely that if you use something like [gofpdf](https://code.google.com/p/gofpdf/) that you will find that your performance is radically better than Python (this could easily be 10x-20x) _and_ that you can get multicores going all at once without significant additional effort, if you can cleanly separate your PDF generation tasks.
&gt; We love writing tests at CloudFlare, and having unit tests that include some kind of random component can turn up interesting issues. This is a terrible idea. Unit tests are supposed to be as deterministic as possible, so that failures are solely the result of the change being tested.
No, Americans also take very few sick days. I wish we took more, all the coughing and sneezing in the office surely increases the infection rate. 
At the very least, you should log your seed. And also have a flag to set it. That way you can debug the failure easily. But yes, ideally, determinism would be nice.
Well, there's a difference between using a PRNG with a deterministic seed and actually initializing it with entropy. Randomized inputs belong in load tests, stress tests, and automated fuzzing. Not the tests that you run on every change to verify that no regressions are being introduced. Random unrelated failures just make your tests noisy and more likely to be ignored.
I've shown Go off to some companies, they think I'm lying when I show how much more powerful it is compared to PHP...
Scary.
Hmm I didn't see any job openings that specifically mention Go :(
&gt;This is a terrible idea. Unit tests are supposed to be as deterministic as possible, so that failures are solely the result of the change being tested. There are many different types of tests. I am sure that the code which is tested with randomness is also tested with deterministic inputs. Learn more about this here: http://en.wikipedia.org/wiki/Fuzz_testing
I feel so lucky, the company I work for just started this year with unlimited PTO. Our CEO was inspired by Netflix. 
Yeah, as I mentioned above, there are tests where randomness can be of value, but unit tests are not among them.
SendGrid bought 26 tickets to GopherCon. I think it's fair to say pretty much any engineering position will be working with Go at some level.
Fuzz tests can be unit tests. The strictness you imply simply isn't there.
It's a little confusingly named. There's already several **goath** packages, usually for doing OAuth. What about **httpauth**?
Probably because then the first comment would have complained that the changelog didn't tell what the project is. I prefer OP's link, myself. Also, thanks for your link
I did set Hugo up a few months ago. I thought is was nice, but the docs were somewhat hard to follow. Hopefully that has improved.
It's pretty typical in my experience. Everywhere I've worked has been either 3 weeks or "unlimited" (in which case I would always take 15 days). Plus 5-7 holidays. Actually, one place I worked had a 2 week vacation policy, but they also had full weeks off around the major holidays, so we usually ended up getting over 4 weeks off each year. 
I think writing good documentation is harder than writing good code. But that might just be me... (Some would argue it's one in the same!)
is there a searching functionality? - didn't see on the demo sites
Just a quick note, this book is just a draft. It will get better over time but it's currently used to help people attending the Go Bootcamp we are running tomorrow in Santa Monica, CA
Version releases should link to the change log, project announcements should link to the introduction page. Version announcement threads that get upvoted are only for projects that are fairly well known anyway, and it's not that hard to navigate from a change log to the introduction page.
If I ever get around to converting my existing static site to Hugo, it might be a fun project to write an [xmlpipe2](http://sphinxsearch.com/docs/current.html#xmlpipe2) converter, such that Hugo pages can be indexed in Sphinxsearch. It seems like the only potentially complex part of it might be frontmatter. Since all the source data is in Markdown already, aside from that, it's ideal for indexing.
Looks nice. I think maybe they could make the read link a little more prominent, because I was wondering for a while if the book was only available by signing up for the bootcamp (which I'd love to, but I don't even live in the US).
it looks we could [read it online or download it](http://www.golangbootcamp.com/book).
Since Hugo is going in the direction of multiple source file types, I think it would be a mistake to make any sort of assumption on the source files for the sake of searching. You would need to search the HTML.
Is there any way to get the generated HTML in isolation from the surrounding page markup? It seems like there ought to be.
http://youtu.be/HxaD_trXwRE
There is an option to control the directory the generated HTML goes into. You can also just get it from the default public folder. If you put that into a system that can handle searching with HTML (Sphinxsearch as you mentioned can do it), you'll have a search feature.
Here is my attempt at tokenizing the HTML. You may want to try something like this if it's a pain to deal with a search engine's api. (This is rough. You have been warned) [http://pastebin.com/C05m6HQ3](http://pastebin.com/C05m6HQ3) I think that if you use a custom short code, you can embed a search box into the main template file and then add an http handler for a dynamic search page. In an extreme situation, you can use something like memecached or groupcache. I would spend the next couple hours writing a simple fuzzy string matcher, however, the short codes look like a pain to deal with and the examples are pretty weird to look at. 
As you said in your post, `map` has some overhead. So find a way to get rid of it. I've run into similar problems with large biology data sets, and while `map` was convenient, it had the potential of exhausting RAM on particularly brutal data sets. If your ids are just line numbers, then it sounds like you could just use a slice of slices instead. You may need to get creative with your indexing though...
another thing that I am unsure is whether golang slice is continuous. what if the allocater cannot find a continuous block? does it simply request more memory from os in this case? I feel golang slice is not really ideal in this case (correct me if I am wrong). 
it is for good performance
If you're under about 100 elements, a linear scan though an array will be faster than a map lookup. That will reduce memory usage. You would move to a struct containing the wordid and count instead of a map for your k/v pairs.
Go slices are contiguous in memory.
They are contiguous. A slice will be awkward because you need to come up with your own mechanism for mapping your ids to a location in the slice. This is why a map might better. But memory usage is a problem. Less convenient? Maybe. Inappropriate? I don't see why. You're after less overhead, so go with a slice.
If memory is the problem, accept the time hit and move to O(log n) access. I did a similar thing for a large database of IP ranges to data in https://github.com/dgryski/rgip/blob/master/main.go . Look for the ipRange structure. This was simpler than moving to Patricia trees with path compression, and more than fast enough. Remember that with 3M items, a binary search is only 21 probes. You'll waste more time fetching the items from main memory.
I see this got a downvote. However, at small N processor cache effects out weight the algorithmic ones: http://igoro.com/archive/gallery-of-processor-cache-effects/ and https://www.youtube.com/watch?v=YQs6IC-vgmo
How does it go up that big again? Is it 178 bytes * 3million? 4 byte doc ID * 5 byte keyword pair * 30 pairs * 3 million?
I understand that. But 8gigs is starting to get a little excessive. Maybe split the struct where the initial key stays in memory but the larger value stays serialized somewhere? Don't understand the down votes. 