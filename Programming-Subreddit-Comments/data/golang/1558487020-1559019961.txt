What are these obvious reasons you speak of then?
Would really love for you to expand on this point as to why you think this? To me it really depends on so many factors of the type of HFT Strategy you are building and therefore how and why you need something like RPC
That application link is total disaster.
I actually did it a few years ago (may have been totally different back then though). I remember it was nice to go through but without a practical project I didn't really have where to go with it.
[removed]
A proof of concept OS kernel written in Go [https://github.com/achilleasa/gopher-os](https://github.com/achilleasa/gopher-os)
Neat. Hopefully this feature isn't far off from becoming native.
Are you having a specific issue with it?
yeah good point. I'm already familiar with RPC + Thrift which is pretty similar to gRPC + Protobuf (we use it at work) but we get all the boilerplate and configuration out of the box so I feel like I don't really know "how it works" or why to use it, it's just what we do. Seems like people on this sub are using gRPC for a ton of different stuff, and even using it by default, which is pretty interesting
The Inferno operating system was written by Rob Pike and other core Go developers in Limbo (the predecessor of Go). It's really a masterpiece!
an awesome comment. I think you pretty much nailed it with some of the downsides of REST. the uncertainty of what will come through the interface means a ton of extra required error handling + conditionals on both sides of the API which by definition means your code is less clean.
Yea of course. Lots of strong advocates of gRPC here but not many defenders of REST. The biggest strengths I see from my perspective: \-- if you want a hot-swappable team of devs pretty much everyone already is familiar with REST \-- public-facing API's, client and server both need the schema / have some familiarity with gRPC ecosystem to configure a consumer
Or better yet D.
You should make \`Zero\` a \`const\` instead of a \`var\`, or else it can be modified by another package.
The Fuchsia networking stack is written in Go, FWIW.
Constant structures are not allowed in go
On Linux, the vscode go extension with gopls has been great for me and I would recommend it. A side note, at least for me on windows it basically just doesn't work, so if you are stuck with windows perhaps try one of the other workarounds suggested.
Not Docker for Mac :)
Thanks man. Completely agree. It's so much extra work to get around the nebulous "standards".
Well docker for OS X and windows are flawed at a fundamental level since containers rely on Linux kernel features. Not really a go related problem.
&gt; I haven't had any trouble using VS Code with modules. You should had: https://github.com/Microsoft/vscode-go/issues?q=is%3Aopen+is%3Aissue+label%3Ago-modules :)
Surprisingly Go alive well in my country, lot's of old &amp; new startup converting to Go since 2018
alternatively does it need to be exported?
Hit Ctrl+Shift+P (Windows/Linux) to open the Command Palette, then type that command.
Here is a paper from USENIX that describes the author's experience writing an operating system in Go. &amp;#x200B; [https://www.usenix.org/system/files/osdi18-cutler.pdf](https://www.usenix.org/system/files/osdi18-cutler.pdf)
Well actually, circular import problems can be solved by introducing interfaces and separate data types, keeping everything loosely coupled. Circular dependencies only come from too many parts of your code relying on the same thing. For data structures, ask yourself if it's necessary that every bit of code uses the same struct. Often the type used in a database for example shouldn't be the type used to expose to a web for viewing or editing. If you keep those separate, it's much easier to change something at either side. If the underlying data type is one and the same, you can't change your DB scheme without breaking web, or you can't cleanly add web specific fields or logic to that data type.
Valid comment getting downvoted.
Is that Zero value needed at all when it's just the zero value for the struct? Probably won't get reassigned, but with IsZero, there's probably no place it'd be used anyway.
D isnâ€™t better than Rust.
You ever heard of holyC?
From the [gopenpgp](https://gopenpgp.org/) website: * Added support for elliptic curve cryptography * Undergone an audit by SEC Consult * Fixed a number of security issues, including: * Rejecting packets that are not integrity-protected (those exploited by Efail) * Preventing potential spoofing in cleartext message headers * Increasing the default key-derivation (S2K) cost parameters * Added a high-level wrapper library, which provides a simple API for common operations such as key generation, encryption, decryption, signing, and verification, and which is compatible with go-mobile [Source Code](https://github.com/ProtonMail/gopenpgp)
You still need the `GO111MODULE` env flag in 1.12
thereâ€™s an additional infrastructural overhead to managing database level logic
Still, it's a user-space kernel
Everything works better for me in vscode when using gopls, can recommend!
If you're doing low level Linux stuff you want to stick with C. The reason is your ultimate goal usually for whatever you're writing that low level is to become part of the mainline Linux kernel at some point.
great!
Thank You so much !!
Seems like there is an experimental effort happened for implementing generics in Go, seem cool https://twitter.com/kapoorsunny/status/1131121201022197760?s=21
FWIW they are also very unhappy with the performance of it and rewriting it. I believe in Rust.
[removed]
A great comment on Hacker News: &gt; I'm going to risk being labeled an ~incompetent dev~ or whatever but learning golang was seriously a breath of fresh air compared to literally any language I have ever tried to grok before. &gt; Everything felt like it was there on purpose. It always seemed like there was a "proper" way to achieve something. Being told to use this opinionated formatter was like removing a 40kg bag after a bush walk. You never have to worry about if you're writing Go "the right way", because it's extensively documented what that way is. &gt; Generics is an awesome feature, writing C# is my day job so sometimes I miss it, but I have full faith in the designers when they say it will be in the language in a "Go appropriate way". The last thing I personally want to see is Go being handed over to the community to be designed by committee.
Link?
Here is a direct link to the actual article https://protonmail.com/blog/openpgp-golang/
Someone commented &gt; Dep was discarded for a reason: it didnâ€™t solve stable builds problem If he meant reproducible then I don't understand this. Dep did solve that problem. Commit vendor directory with the rest of your code and you get stable reproducible builds even offline. Actually it's Go modules right now that don't solve that problem as they don't properly support vendoring (proxy/caching is not a solution). Something that community was very vocal about and, thankfully, will be implemented in 1.13 &amp;#x200B; If stable here means simply being able to checkout exact versions of your dependencies then it's also solved by dep. gopkg.lock locks exact Git commit for every dependency.
Ok, this post is a big better. However, the font is too big. \`\`\` &gt;**if ct != "text/html" &amp;&amp; !strings.HasPrefix(ct, "text/html;") {** &gt; &gt; **return fmt.Errorf("%s has type %s, not** &gt; &gt;**text/html", url, ct)** &gt; &gt;**}** \`\`\` Would be nicer if the content part of your website was a bit wider (content is the most important part, I think) So it would read more klike real Go code: \`\`\` if ct != "text/html" &amp;&amp; !strings.HasPrefix(ct, "text/html;") { return fmt.Errorf("%s has type %s, not text/html", url, ct) } \`\`\` The line is not wrapped in my example. But I like it, that you taken the advice to do something about the font. Perhaps if you make the code part of your explanation into a monospacing font that is a bit smaller, so it has less wrapping?
[removed]
Why not? * The garbage collector can be disabled or a large block of memory can be allocated once, then be managed manually. * GCC supports Go and can output executables in the same way as for C.
&gt; Actually it's Go modules right now that don't solve that problem as they don't properly support vendoring $ go mod vendor $ go build -mod=vendor . I'm pretty sure this has been in since Go 1.11, if not, I'm definitely using it now in Go 1.12.
Nice work. &amp;#x200B; \&gt;&gt; The name uint128.Uint128 stutters &amp;#x200B; have you considered using "large" as package name ?
There're numerous problems with that. You can read about it here [https://github.com/golang/go/issues/27227](https://github.com/golang/go/issues/27227) [https://github.com/golang/go/issues/29058](https://github.com/golang/go/issues/29058)
That becomes a bit cumbersome for structured loggers though. In those cases the message is less important than the context you're passing to the logger. Other than that I agree, that functions are easier to use, but might require more setup. I'm usually am using two functions, one for info level logs and one for actual errors.
Another issue is that it doesn't properly vendor all files from the dependency; only what it deems to be the direct source needed for compilation. It can miss C dependencies or other important files.
Just had a quick look at the mod file and saw that they are replacing crypto with their own implementation? `replace golang.org/x/crypto =&gt; github.com/ProtonMail/crypto v0.0.0-20190427044656-efb430e751f2` Isnâ€™t the first rule of crypto to never roll your own? Disclaimer: didnâ€™t dive into the implementation.
Without knowing what they modified, you can't really say whether they're "rolling their own" or not
We use Zap extensively in our apps, it's a superb logging package. Adding context to the logger instance is really convenient. I can elaborate later on how this looks at 1000ft.
https://github.com/ProtonMail/crypto/issues/21#issuecomment-492792917 &gt; Hi! ðŸ‘‹ Here's a current list of changes: &gt; &gt;- Expand ECC support &gt;- Bump default and minimum key-derivation (S2K) cost parameters &gt;- Default to AES128 and SHA256 instead of CAST5 and RIPEMD160 for keys without preferred algorithms, as required by rfc4880bis-06 (rfc4880 required 3DES and SHA1) &gt;- Disallow generating RSA keys of less than 1024 bits (recommended by the audit) &gt;- Fix and move Signature.KeyExpired to PublicKey.KeyExpired; add Signature.SigExpired (golang/go#22312) &gt;- Detect expired signatures; though leaving it up to the caller whether they want to reject them &gt;- Use latest-created valid self-signature instead of the last-appearing one; don't drop other self-signatures when re-serializing the key &gt;- Add higher-level function to verify clearsigned messages, in order to be able to verify that the algorithm mentioned in the header matches the algorithm used in the signature (one of the findings of the audit) &gt; &gt; We're hoping to merge these changes back into the original, so I won't add them to the readme for now, but I hope that's useful anyway ^.^
Here ya go https://news.ycombinator.com/item?id=19978200
If there's at least one serious fork that will probably receive seldom use, when Google does something egregious to Go then it may trigger an exodus to said fork.
Sure not, I would kill for having future version of Go!
Good to know!
&gt; Isnâ€™t the first rule of crypto to never roll your own? Well, *someone's* got to roll the crypto, right?
Yes it is indeed very good, especially the stacktrace and its speed for structured logging. But do you pass it as a parameter to your function or as a global package struct?
Thanks!
I happen to be working on a vector drawing library, which is in a fairly advanced stage, see if this is useful for you: [https://github.com/tdewolff/canvas](https://github.com/tdewolff/canvas) There are also others, such as [https://github.com/llgcode/draw2d](https://github.com/llgcode/draw2d) and [https://github.com/srwiley/rasterx](https://github.com/srwiley/rasterx)
I'm so tired of people purporting to speak for "the community" - especially when they diametrically oppose my own views. It feels a lot like they are co-opting me for their own agenda while simultaneously excluding me. The things mentioned as evidence that community doesn't matter have a lot of buy-in from the community. Modules in particular are an effort that - at least from what I can tell - is heavily driven by non-Googlers (in particular Rog Pepe, Paul Jolly and Daniel Marti are people who put a lot of work into making modules actually work for practical workloads). These kinds of pieces only make sense if you have an extremely limited view of who is or is not part of "the community" - in particular, if you throw everyone agreeing with the Go team out of that bucket.
&gt; GO111MODULE &gt; It's set to on by default, so by my not having that in my env, it assumes I want it on in 1.12
Sure. There are still issues, but I think it's better than before modules rather than worse. Before gopls, the plugin wasn't fast enough to be very helpful if you weren't working on a very small project.
&gt; Second, the release of GopenPGP paves the way to open sourcing the ProtonMail mobile and desktop apps, which has been a high priority for our team and for our users (our web app has already been open sourced since 2015).
It's worth noting that react-native increases development time over plain react + cordova/phonegap (if not using mobile library plugins). However, there are two main benefits: 1) more performant and responsive. 2) better(?) access to native api's like https://facebook.github.io/react-native/docs/cameraroll If using plain react + cordova you also have access to plugins: https://cordova.apache.org/plugins/ Certainly look into https://expo.io/ and google around for "things I learned" using react-native if this is your first project with it.
I wish at least constant byte arrays could be supported, since strings can be constant.
Thanks for your support!
Thanks for your support!
I'm not sure "large" (very generic) would be a better name. I tried to think of something more specific like `largeint.Uint128`.
Interesting. Thanks for your help! I wouldnâ€™t need access to native processes (camera etc), so that doesnâ€™t come into it for me. Essentially, itâ€™s a choice between learning how to program in React or sticking with my tried and tested method of building web apps purely in Go. It would be good practice to learn how to build apps in React, but I donâ€™t want to learn a new framework purely for the sake of practice.
&gt; Modules in particular are an effort that - at least from what I can tell - is heavily driven by non-Googlers (in particular Rog Pepe, Paul Jolly and Daniel Marti are people who put a lot of work into making modules actually work for practical workloads). Sure, they have buy-in _now_, but they were announced as a fait accompli that would eliminate what the community had been working on, and the community was then invited to help make modules work. (Which they still don't always.)
 - You need to talk to the API from a browser. - The API is simple enough that the development overhead of gRPC isn't worth it.
Most HFT shops use almost the same trading strategy, you win when you are the fastest. You do not use anything that needs to make any syscalls/context switches etc for iPC or network communication in your hot path, this is just waste of precious microseconds. Ask anyone that is running real HFT shop and make profits.
What is your base image? This might be caused by the fact that it is a minimal image like Alpine that doesn't use XDG by default so the required XDG environment variables are not defined.
GC, unpredictable pauses (like 100+ microseconds), you pause for that much time and you already lost, no control over threads, no control over userspace scheduling of tasks, using IRQs instead of network polling, very slow FFI, compiler optimizations compared to for example C++ with LTO and PGO is just awful and many, many more reasons. Top HFT shops are doing FPGAs now so you compete in microseconds, not milliseconds.
I use them a lot in my studying of game theory lately. But I've never used them in a slice. Nor did I when I wrote a few chess engines. &amp;#x200B; So I think that's more of a personal preference / project requirements
This is something that could be a native type so tbh I would consider a dot import and writing a comment in the README file about it instead.
I waffled on it, but what swayed me is the aesthetics of (e.g) `foo(Zero)` over `foo(Uint128{})` when you want to pass 0 to a function (or initialize a struct field).
Maybe, though the suggestion of doing a dot import to get `Uint128` will also mean you're stuck with a weird `Zero` in scope as well. (The type alias suggestion might work better)
I felt like React was actually surprisingly easy (if you are comfortable with Javascript) even though it looked messy when I first looked at it. I avoided redux and other unnecessary parts at first. I would certainly spend a day playing with `create-react-app`, looking at some [react projects on github](https://github.com/gothinkster/realworld), watch some videos, take the tour, etc. React is the biggest player right now with an extensive ecosystem (bootstrap or material design, native mobile support, good performance, and so on). As an aside, I think Angular/Vue/React could eventually move (or be replaced with) the ideas found in the new https://svelte.dev/ system.
FROM golang:latest
Don't start with a struct with methods. Start with variables and functions. If you find yourself doing multiple operations on the same struct you can then turn it into a method. When you need to use a piece of functionality project wide then turn it into a package and import it. &amp;#x200B; Don't couple things together prematurely. Always think about what your data is, and how you want to transform that data and start from there. In other words, the best way to structure your app is to do the simplest possible thing that works in the clearest way, and periodically refining that by noticing repeated patterns in your code and extracting that into something reusable like a function or a package. At least that's my opinion, I see a lot of Go code where every file has a struct with a bunch of methods and even a constructor like func NewThing(), I don't know what the compulsion is to write Go as if you're writing Java.
Can you provide a fully reproducible example?
&gt; Dep did solve that problem. No. Remember `go-bindata`: hysterical owner closed repository. `dep` had no mechanics to deal with such kind of issues. Modules has `GOPROXY`, where the proxy can cache request so the module will always be available once returned â€“ `https://proxy.golang.org` does this, for instance.
Yes, the solution is to vendor your dependencies and commit them in Git. Caching proxy is not a proper reliable solution to this kind of problem. That's why community heavily insisted that Go modules are not usable for many people where reproducible offline builds are needed and current way of vendoring is frankly broken. Especially when you need to build a project outside of your infrastructure. Deploying prefilled caching proxy just to be able to build your project is nuts.
Do you have a source for that? After reading this, I spent 2 hours looking, and I only saw the original bragging about how it is far simpler and safer but at an impressive 90% of the performance of a C network stack. TCP is certainly unlikley to ever be a bottleneck outside of synthetic benchmarks. Lots of people reference it as recently as 6 weeks ago. The last commit to the master branch of the repo was 16 hours ago.
You don't need a vendor with modules, period. It is just a shortcut for projects where builds were using vendoring.
You need vendoring to achieve reproducible offline builds even when whole github goes down. You need vendoring to be able to compile your project anywhere you want. The links above give plenty of reasons why vendoring is important and how vendoring in Go modules is simply broken.
Thar rule is for you as a developer working on your non-security focused application. If you are a crypto and privacy based company that forks a library to audit it, make changes, and intend to mainline said changes back to the open source, different story.
&gt; Caching proxy is not a proper reliable solution to this kind of problem. Caching proxy is much better solution for development. Just no contest. And you can put your company's cache proxy in front of remote cache proxy. This basically solves availability problem.
How about `fp128.Uint` (do for "fixed-precision")? That would make it trivial to add `fp128.Int` later. Still, I prefer `uint128` for symmetry with the native `uint` types.
I thought Go was used in Docker to tie together a bunch of other tools that if you did it manually would take forever. I use Docker but didn't bother learning the guts. This might be just my ignorance but I was treating Go like Perl. You could create a full application but it is better as glue.
Why not just use https://godoc.org/github.com/jmoiron/sqlx#ConnectContext with timeout on context?
Biscuit is kernel written in Go (only 5-15% slower than C version). https://www.usenix.org/system/files/osdi18-cutler.pdf And here you have network drivers written in Go ixy-go https://www.net.in.tum.de/fileadmin/bibtex/publications/theses/2018-ixy-go.pdf
c always is the best for the low level
As long as whoever rolls their own isn't a company who's product main feature is cryptography, their code isn't open source, and they don't have cryptographers on staff, and don't pay SEC Consultants to review their work. Anyone else can roll their own though.
The "don't write your own crypto" thing has probably done more to discourage budding new cryptographers than anything else. It has it's place in pragmatic engineering, but people take it too far. There's no reason why aspiring cryptographers trying to learn the science can't write their own crypto as long as they are honest about its suitability for real work applications.
Both. When the apps start, they create an instance of the logger and then set that instance as the new [global logger ReplaceGlobals](https://godoc.org/go.uber.org/zap#ReplaceGlobals). Now everyone can import zapper and get the same logger instance configured at initialization. Within the functions, I add context to the local logger instance as data makes available. Later, if I call log.Info or log.Error it'll include all the additional context I've assigned. See functions get passed a logger instance that contains additional context like who is calling them, and others just use the global instance. Hope this isn't too convoluted.
my feeling was that if "big" is taken, you could use "large" .. but these are minor details..
It's not clear what the OP meant by "stable builds," but either way, proxies are not a reason why modules needed to _discard_ dep, rather than working more collaboratively with us. Nothing about the design of dep precluded doing the exact same thing. In fact, we had a small group of people quietly working on _exactly_ such a service, which we kicked off at Gophercon 2017. We kept it quiet because any kind of external service had long been controversial, and it seemed pointless to stir up controversy over it when we could work quietly towards making something minimal, and it could then become part of the conversations about transitioning dep's key parts into the toolchain that we hoped would happen. In any case, that work - which looked astonishingly like the proxy - was also summarily discarded. (Or maybe it was lifted for the proxy spec. i don't know.)
[removed]
[removed]
&gt; Sure, they have buy-in now, but they were announced as a fait accompli that would eliminate what the community had been working on, and the community was then invited to help make modules work. (Which they still don't always.) Again with that "the community" stuff. Yes. Russ worked the concepts out. And because the community was dissatisfied with dep (see, I can do that too) they saw it's a good idea and jumped on it. My point is, that there is no "the community". That's pretending a homogeneity that just doesn't exist. I personally know a bunch of folks who are contributing a lot to Go (and modules specifically - no, it *wasn't* fully fleshed out when they where originally announced) and don't feel represented by this "the community" business a loud subsection of the community is trying to make a thing. Modules weren't a "the community vs. the Go team" thing. If anything, they were a "the dep team vs. the Go team" thing. And I'm honestly glad for that - the Go team sure did more for the Go community so far than the dep team. That being said, seriously: Anyone can fork Go. I wish the people who are constantly complaining they wouldn't have a say would just do that. Yes, a fork is bad for the community (in this case, yes, I *do* mean the whole community). But it can't be much worse than this constant rabble-rousing TBH.
Those compose around just fine too! It's really more the composition point I'm making, that if you use Go's composition features correctly, you'll find that you generally *aren't* passing around loggers everywhere. They are passed around a bit more than a "global variable", but it's worth it for the tiny bit more effort to do something much, much more correct, and reap the benefits of it.
There's no direct solution in the core library. I don't see any immediately obvious libraries for it, though [https://godoc.org/github.com/retailify/go-interval](https://godoc.org/github.com/retailify/go-interval) can probably give you some thoughts on the matter at hand. Beyond that, there's no magic to it. Since its likely that this is a homework problem, I will just give you the slight hint, which you can also get by looking at the API for the package above, that most beginning programmers miss a *lot* of cases for this problem, which is why it turns out to be such a good one. Use unit testing, and be creative with the inputs.
Yes, it's usually a at least a bit of a misdirect when most anyone says that they speak for a larger community. And certainly, there are non-Go team-ers who are contributing to the development of modules. However, we did, as a community, self-organize a process, culminating in dep. And processes are what create at least some legitimacy, such that speaking "for a community" isn't just handwaving, while still not necessarily including every last person. Acknowledging that it was a poor process that led to modules does not say anything about which implementation you prefer, and certainly not anything about people who are contributing now. Conflating process with technical outcomes just makes healing harder.
\&gt; I was treating Go like Perl. &amp;#x200B; No, the use case for Go is rarely as a \`glue\` tool like in Perl. If you look, very few Go CLI tools will shell out to other binaries. You are right that *initially*, Docker did shell out to various Linux commands to setup the containers. But they quickly re-wrote those as native Go libraries that do the same syscalls directly from Go. (See [https://github.com/containerd/containerd](https://github.com/containerd/containerd)).
I went ahead and wrote a --nested and --flatten flag to handle this. &amp;#x200B; This will work if your top level object is a list, unpacking {} one key/value at a time is a slightly larger project. But hopefully I can figure out a efficient way of making it happen.
Can you clarify what you are looking for? What is your goal? * Do you want to write an OS kernel in Go? (There are already a few out there. See also [gVisor](https://github.com/google/gvisor) ) * Do you want to want to write an OS runtime in Go? See [Router7](https://github.com/rtr7/router7), [U-Root](https://github.com/u-root/u-root), [GoBox](https://github.com/surma/gobox) * Do you want to write Device drivers for Linux in Go? Look into [FUSE](https://en.wikipedia.org/wiki/Filesystem_in_Userspace) or [UIO](http://www.hep.by/gnu/kernel/uio-howto/) * I'm not sure what you mean by "Linux System Programming". Wouldn't that be any app written in Go that runs on a Linux System qualify? [Systems programming](https://golang.org/ref/spec) was literally a design criteria for Go.
Awesome! That sounds like a great start.
Strip the binary using -w -s and you'll see how much harder it gets
\&gt; Caching proxy is much better solution for development. Just no contest. And you can put your company's cache proxy in front of remote cache proxy. This basically solves availability problem. From another answer of mine.
You are finally here. \&gt; Nothing about the design of dep precluded doing the exact same thing. So, you missed the most important part: a specialized protocol to replace a ridiculous idea of using VCS-es as package registry. Says a lot of you Sam Boyer. Please, admit it and learn further: we are mostly who what will do something in a future, not who did something in the past.
See, I'd recompile my kernel more often if it didn't take forever to do so. Rust doesn't seem to improve on C in compile times; it seems to be slower. I haven't looked at any benchmarks, only that when I see the package manager reaching for the Rust compiler for some piece of software, I groan. I dislike that I hate compiling software these days. Everything takes so long. This is Go's killer feature for me. I like seeing go projects in the community repo, because it means the install isn't going to take much longer than if a binary was available.
That's strange, it's the official Go image maintained by the Docker community so this can't be the problem. Can you please post your complete `Dockerfile`, otherwise it'll be hard to find the problem. If it states that even `$HOME` isn't set there must be dome kind of user creation problem in the build file.
Not app like ios and android. But you can sell infrastructure packages, but that would be a lot of work. Infrastructure package like. You only require amazon access,secret key and it will automatically configure roles create lambda function and stick that bianry there to do a specific task.
hmmmmm, yes, but in this case you are selling a "service" not a piece of software
golang is more of a backend language. So you can't really sell apps, you can sell cli tools but the general consensus for any `go` software, you open source it and give it for free. You don't close source and sell it. You make money via selling service.
Yeep, it's just how I thought it was. Thank you!
You might want to look at the gvisor project, which is a user space kernel written in go, but touches on a lot of full operating system concepts. [https://gvisor.dev/](https://gvisor.dev/)
[removed]
\+1 to the Gophers Slack.
Yeah, skimmed through the comments and discussion in there, and can't think of a single reason I should be bothered by this fact - which isn't exactly a revelation to me in the first place.
Worth noting that Inferno and Limbo are based on a VM (Dis), and the implementation of Dis is in C. However, yes, all the utilities are written in Limbo (and I've been curious about porting Go to the Dis VM, but I'm not much of a programmer and have no idea where to even begin).
I would be far more bothered if the reverse were true. Language design is not something large communities are good at.
 |_____________________| // t[0] |_____________________| // t[1] |_________| // t[2] If that is what you are describing, you shouldn't need any fancy libraries at all. You should have all the info you need in the first two slices to build the third.
I just started to learn Golang 1 month ago. I read a lot of tutorials while studying to write code. I found the great tutorial about a test driven development. The author teach why you should write tests and how to do that in the real world projects. The first part of this book is about learning fundamentals, the second is about writing web api for playing poker. https://quii.gitbook.io/learn-go-with-tests/
With React you can also easily turn your application into a Progressive Web App that people can save on their phone/desktop and use offline. Now you can even add Progressive Web Apps to app stores. The create-react-app boilerplate makes I'd dead simple to make your React app into a PWA.
Note that web apps (websites) can do many fancy things like: \- [install themselves](https://www.w3.org/TR/appmanifest/) on the home screen with an icon \- cache themselves locally \- receive [push notifications](https://w3c.github.io/push-api/) \- talk to [USB](https://wicg.github.io/webusb/) and/or [bluetooth](https://webbluetoothcg.github.io/web-bluetooth/) devices
It's been working fine for me on VS Code, but seems to be a lot slower now with modules. (I haven't tested the difference thoroughly though, and could be wrong)
`auto` by default; so only on if outside GOPATH https://golang.org/src/cmd/go/internal/modload/init.go?h=GO111MODULE#L98
ah, that explains it. I immediately stopped organizing my code in that directory once it didn't have meaning.
I've since gotten it working with atom again; I think you're correct. It does feel slower now
I'm not really sure what you're asking. Ours are just in github... we considered keeping them in a separate repo from the server code, but that has proven to be too much overhead, and too much of a manual process of keeping two things in sync.
That is exactly the kind of discussion that I would like to have. We have experimented with having a monorepo containing all of our proto definitions but immediately noticed the overhead of pushing pulling and syncing the changes. I am trying to look for solutions on how to reduce the overhead.
lol - all good mate - best to get down to the point. check this out for general info enz.org/forum Roles pay up to $130k nzd for senior people
sorry all roles are required to be local
sorry all roles are required to be local
thanks !
We tend to keep client info as confidential until we engage a little further, there seems to be a growing number of organisations moving to go but they are restricted by available skills
It isnt wrong. Go would benefit quite a bit from generics..
Elaborate? Used Go, but what's this trying to say?
The desire for generics goes down over time the more you use golang.
So Stockholm syndrome?
It's Lupis.
Pretty sure bare-bones parametric polymorphism (the kind ML has had since the 70s) would be pretty useful. Just punt on dealing with subtyping &amp; unboxed values etc. There is value to be had for cheap imo. Same goes for bare-bones sum-types (tagged unions) with compiler-checked exhaustive matches. But that requires more decisions to be made at a syntax-level. Add those two things to Go and the language becomes much nicer with very little cost. I'd love to be argued with though :) maybe I'm missing some issues with adding these things.
Why do we need them? Having them, bring s more complexity to the codebase. Don't we try to resolve the issue about code duplication with generics? Is it the best tool? I'm interesting because in some cases I miss generics too. And still, there're no tasks in the backlog with the status "Blocked - waiting for generics". Somehow we deal with it with help of interfaces and other technics.
Isn't dealing with boxed values a substantial cost? I'm not too familiar with Go so I don't know how much of an impact it would have.
It can be, but for many practical workloads (IO bound things that most Go programmers probably write in their backend code), it isn't going to be a large enough percentage of total cost to notice.
Nope
I can write everything in VB6 too, but that doesnâ€™t mean I should.
&gt; And still, there're no tasks in the backlog with the status "Blocked - waiting for generics". A frequent argument I hear is that generics help reduce bugs. How many items are in your backlog that would have never been there in the first place if generics were available?
&gt; And still, there're no tasks in the backlog with the status "Blocked - waiting for generics". Somehow we deal with it with help of interfaces and other technics. In like 1950, there weren't any issues with a status "blocked - waiting for high level languages" either, but if it weren't for Fortran and Lisp, there would still be like 85 computers in all existence. Don't confuse the need of practical people to get shit done with the lack of importance of improving the tools they're using to do it.
It's funny, the reasons people give for Go not needing generics are the exact same reasons people gave when C# didn't have generics.
But there is generics, in form of reflect package. I absolutely abhor any other form of generics. Coming from the world of JavaScript and Python I really appreciate static type check in golang
&gt; However, we did, as a community, self-organize a process, culminating in dep. You and some others did. Plenty of us in the community said we don't want another npm. You absolutely failed to listen to Merovious' point. You're *again* just claiming you speak for the community.
You seem to be talking about dynamic typing. Generics are about being able to statically type check code that can work with a variety of types. That doesn't work with reflection.
[removed]
Besides obviously the text that says "generics", what part of the urinals symbolizes generics? What a weird cartoon joke.
Ah, TIL! Never have Generics in any of the languages that I worked with.
The cartoon asserts that people that *actually* develop and understand Go are usually not the ones to complain about its lack of Generics. The man that walks up to a urinal needlessly close to the man tagged "Go Dev" symbolizes people outside of the community injecting their own opinions and biases without actually understanding the language they're attempting to change. Note that I am not arguing in favor of the cartoon, just explaining what it is going for.
Avoid """free""" software that constitutes a **sophisticated advertising campaign for major government-loving corporations**. Those corporations control many aspects of the developer culture in those ecosystems, and manipulate them in various subtle ways to their benefit. Examples of this in the software world are Microsoft (GitHub, C#, F#, TypeScript, .NET, Mono, and everything built on top of it), Oracle (Java, and everything on top of JVM), Google (Android, Go, Dart, Flutter, etc), Apple (iCrap, Swift, LLVM), IBM/RedHat, Facebook, Twitter, etc. Examples of more independent grass-roots programming languages include: Python, Haskell, C, [D](https://dlang.org), and [Nim](https://nim-lang.org). Choosing genuinely free software means **software you can do anything with, independently from anybody else**: [no legal attachments](http://copyfree.org) (no EULAs / licenses, including "well-intentioned" commie licenses like GPL), **no cloud addiction**, and no centralized support communities with a strong left-wing bias. Google wants to manipulate you, to **gain your trust and make you addicted** to ever-more of their online APIs! They want computers to only work through them, and they'll have to power to manipulate or disempower all users whenever they so choose! Just as Facebook and Twitter use their media power to promote the political causes they like and punish those they dislike, so do software companies through services like GitHub, Play Store, Amazon AppStore, etc. If left-wing corporations think it's OK to throw milkshakes at right-wingers, why not inject malware into their software downloads as well??! See [this older rant &amp; comment replies](https://voat.co/v/programming/2853775) for more info.
what about Rust? ðŸ˜œ
No one says you should. There are plenty of tools/languages with generics - use them. On the other hand, why do people still use C (no generics) when there is C++? And there is nothing wrong with writing things in VB6. I still write in Delphi 5 (Object Pascal) occasionally. It's great for some quick console or UI copy-deploy applications.
Got it...so...people outside the community want to urinal-buddy with Go devs
I don't disagree, but I also find their use cases to be a lot more niche than the demand for them would have you believe.
Its never Lupus.
Hi @aroneus @metamatic thank you for replying. But with the coming of the REST proxy for gRPC API like the gRPC Gateway, does it nullify all the REST advantages since we can expose gRPC API as REST API?
Wrong. It stays constantly burning. Every time I'm forced to write a tedious boilerplate for loop instead of a more functional construct, I mentally shout a curse upon Rob Pike.
and getting generics opened the door for LINQ and TPL which opened the door for async Go for better or for worse skipped all that.
Horrible examples, just a printf in an otherwise-abandoned goroutine, and a "test" that doesn't test anything.
If this is the case, it might be useful for the author to be aware of After and Before as methods on the time.Time (not the package, which also has time.After).
[Filestash](https://github.com/mickael-kerjean/filestash) was initially a side project that became my full time job for the past year. It is somehow a magic set of circumstances and bold luck that made me find 1 customer hiring my services to pay for the set of features the company needed. Since then, the project has delivered what the company needed and the money compared to a classic employment was good enough to keep working on the project for nearly a year. I'd love to keep doing this but I'm not a great sales guy and the money will run out in a few months.
I've build many apps over the years and despite what the internet tells you if you're not the elephant in the room, the stack don't matter much, just pick one and stick to it. The hard part is to get \*\*focus on your stack\*\* and \*\*stick to it\*\* without being distract by all the things that shine around you
Sure, because you can always just use `interface{}` instead of generics, but then you lose type safety. Or you can re-implement a pattern/algorithm/data structure every time you need it for the specific type you need it for (either manually or via codegen), but that's repetitive and potentially error prone.
If you are using zap, it's worth just understanding that the way it is built is designed to be passed down the call stack. Imagine you have a program that opens files, and then uses io.Reader functions to operate on them. In your processing function, you have no idea what the file was, but by doing fileprocesslogger = log.With(zap.String("filename", path)) and passing this new logger down, all lines that might be logged in there would have the filename in it. In this sense, zap works like a context, or an error in reverse (errors should have context added as they bubble upwards). This allows you, for example, in a web server, to add the endpoint to any logs generated by calls to the endpoint, or the authenticated user. &amp;#x200B; zap also allows you to override the logging level in a zap.Core, so you could default to info level logging and use debug level logging if the user is from a particular IP, or if you're retrying processing a message from a message bus that is being redelivered due to prior failure, or just because you were called with -v as a cli option. &amp;#x200B; So you absolutely want to log where the things happen, and derive "new" loggers as you pass things downwards. &amp;#x200B; I also personally think that the zap levels are far more sensible than the standard Go log ones. We try to use error for something internal that indicates a problem with our service, warning for anything passed in or external that's not working as expected, info for light logging of what's happening (if needed) and debug for stuff that's almost always disabled and too verbose to turn on all the time, but potentially useful in very select contexts.
Reflection is not generics. Not even close. Generics-based code is far more typesafe and static than reflection. Maybe youâ€™re confusing generics with dynamic type systems? JavaScript and Python do not have generics, they are dynamically typed.
Why are you guys so appalled by generics? People make it sound like Go will turn into Rust, in terms of complexity, if they add generics to Go. Are you guys finding C# and Java complex too? Sure, the factory pattern in Java is horrid, but that is not related to generics. It seems most people who dismiss generics are either working on pet projects or are parrots. Try spending more than five minutes in the math library and see what an abomination it is.
C++ templates have strict type checking, FWIW.
Friendly advice :) As you form options on unfamiliar ideas in the future it would be good to learn a little more about them before claiming that you "absolutely abhor" them
You don't say
[removed]
I think it's more that over time you learn to use the features of the language (like anything else) and it becomes less and less a pressing concern. FTR I would really like generics in golang.
Yeah I don't get the personal bubble bursting aspect of asking for generics.
I understand the premise, it might be the experience of some, but itâ€™s not generally true. This constant drumming that only non-go users want generics is fallacious and myopic.
Rails is Basecamp's framework, too. I get that the author is having issues with how the modules thing went down, but that is the score with having a Benevolent Dictator For Life (or in this case a team of benevolent dictators). They get to decide how the language changes, in accordance with their vision of how it should be. This has nothing to do with Google owning Go, but is a result of how the whole project is set up: there is a core team of people whose opinions matter more than the rest of us. But there's nothing stopping anyone from starting OpenGo as a project, and forking what's been done so far...
Utterly irrelevant rant on this topic, as Go has nothing to do with Google's online API's.
Relevant to those who care about software freedom and understand it.
I write in go. Go needs generics
maybe in the OOP that you learned, inheritance is important, just be mindful that there are definitions and OOP languages where it's not. If your code is truly polymorphic you would never have to think about whether an object is an A or a B. You just know that it can do x (via an interface) and that's what OOP is about. When you model your domains by "x is X" kind of mindset you inevitably run into entities that can be more than one things and be told that's not possible because of the diamond problem bullshit. A better way is to avoid categorizing x just for the sake of categorization, think interface segregation and single responsibility, make composable abstract (interface of) behaviors and compose them, in whatever way the language provides you.
This is a good argument. For instance, there are a variety of data munging, resource-handling, concurrency patterns that I hand-roll constantly instead of writing once quantified over all types. This hand-rolling inevitably results in bugs.
I'm honestly just worried they'll fuck it up. It's such a large change, I really don't want a python 2/3 situation. That and I don't really miss generics that much.
Any plans for uint256?
Finally. Thank you! Iâ€™m not alone after all!
OP, I laugh in your general direction.
sync.Map
Nah. interface{} is good enough /s
It highlights the lack of situational awareness. It is commonly understood that one chooses the furthest most available urinal from any other urinal in use. To choose the urinal right next to another person, when further options exist, demonstrate that one has not taken the time to learn about urinal etiquette. It is also commonly understood that the Go team has been working on generics since [at least 2011](https://github.com/golang/proposal/blob/master/design/15292-generics.md), realizes the need for generics, but have been unable to find a satisfactory solution for implementation. To state that "Go needs generics" only demonstrates that one has not taken the time to learn about what the Go language is all about.
In C you kind of have generics because of pointer arithmetic. The sort function just needs to know how many bytes does one element occupy. In Java you need generics for a generic sort because there is no pointer arithmetic. So how is a sort function implemented in go? It's a bit log ago I did something in go but does it have pointers like C or just references like Java?
Ive been working with Go full time the last two years. So far, my desire for Generics have increased. At times itâ€™s down to Generics, Code Generation/Duplication or Reflection. Either of the options is with a lot of drawbacks or not available. That said, I would still recommend Go - even if the alternative have Generics.
The complexity worry is not directed at the syntax. It's not just adding a feature, it would touch every part of the language.
Love it when people randomly down vote but not say what's wrong.
Just box everything
Couldn't you use generate for that?
You implement the `Less(i,j int)` and `Swap(i,j int)` methods for your collection type which makes it fulfill `sort.Interface`.
[https://golang.org/pkg/sort/#Interface](https://golang.org/pkg/sort/#Interface)
https://utcc.utoronto.ca/~cks/space/blog/programming/GoIsGooglesLanguage
&gt; However, we did, as a community, self-organize a process, culminating in dep. And processes are what create at least some legitimacy, such that speaking "for a community" isn't just handwaving, while still not necessarily including every last person. I might've said this to you before: I specifically didn't participate in that process, because it seemed chaotic, burdensome and I couldn't see any outcome of it I would like. If you would've asked at the time, I would've told you right then and there that I don't feel represented by that. And I don't think "anyone could've participated, so we have a claim to speak for the community" has any more (or less) validity than "anyone can create a Go proposal, so Go is community-driven". Anyway, I didn't really intend to open up the module/dep-snafu againâ€¦ I'm just *really* annoyed by these constant efforts to pitch "the community" against "the Go team". Hashtag NotMyCommunity, I guess.
I imagine a big chunk of people against generics to know just as much as you about them.
You can make a game in go and generate profit: [https://dev.to/hajimehoshi/go-packages-we-developed-for-our-games--4cl9](https://dev.to/hajimehoshi/go-packages-we-developed-for-our-games--4cl9)
Ooooh. That's awefully similar to the proposed contracts for generics.
excuse me i have to write web scale memes and generics will impact performance to the point where my memes won't be fresh by the time they're generated and then i won't get any vc funding
I recommend Redis for your job queue. Have a look at [https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-4-task-queues/](https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-4-task-queues/)
https://pastebin.com/n1aPcfU5
https://pastebin.com/n1aPcfU5
[https://github.com/nadoo/glider](https://github.com/nadoo/glider) a similar tool
&gt; JavaScript and Python do not have generics https://docs.python.org/3/library/typing.html#generics
I've got a few questions.. 1. Why does the worker have to run on windows? 2. How many requests/s are you expecting? 3. How long does it take to complete one job on average? 4. What should happen in case of a process crash? Would it be okay to lose the queue? 5. In your proposed solution it seems like if one job crashes the job will be marked as "processing" forever, doesn't it? 6. Do you want to enforce job timeouts? 7. If you are afraid of performance when using a lock within a single process, how many requests/s are you expecting? Why would you even need a lock in a single job processing queue? There's zero concurrency istn't it? 8. Why do you think a channel is overkill? It's a Go primitive to solve the problem of communicating between goroutines. In case of a fan in queue design it could make sense to use a channel so that multiple goroutines can handle requests and enqueue their job. This however is prone to losing all state because a channel isn't safe to a crash.
What version of ES are you using? AFAIK olivere/elastic doesn't support the latest version yet.
No need to be a cunt mate
do you mean the version of the ES I am running locally or the version of the library? I am using 7 for both
The version of ES. And it looks like 7 isn't fully supported - this is probably related: [https://github.com/olivere/elastic/issues/1007](https://github.com/olivere/elastic/issues/1007)
ah thanks for that, that must be it. Btw if I use v6 of the library with my v7 ES running would it cause any problems? will my code still work?
I write in Go daily. 2 years now. We even use Go on our embedded linux chip. Before this I was just a Java dev. I have absolutely no idea what problem generics are meant to solve, but this is because I relate generics to a type hierarchy (which go does not have). Can I get an example of where a generic would be useful over something like a closure?
&gt; codegen ... but that's repetitive and potentially error prone. If it's good enough for C++... I'm glad the Go team is putting a lot of effort into getting generics right for official language inclusion. I believe it will be worth it in the end, even if the wait is excruciating. But in the meantime, I have settled on using the Go generics tool that Google released and find it to be adequate for the majority of my generics needs. Better syntax would be nice, but it is pragmatic. I'm interested in what repetitiveness and/or error proneness you have experienced as I don't see it as being any more repetitive or error prone than C++ templates.
Ok so it's done via an interface that have to be implemented. That's actually the same as in Java actually.
I wouldn't recommend it for production as you could find other elements of v7 ES functionality that aren't supported by the v6 library. You could always use direct calls to ES via the REST API, or even write your own lightweight client library implementing just the functionality you need.
I also write Go daily and also have been for two years now. The problem that generics would solve are ones that involve common data structures and concurrency patterns that requires us to write a lot of boilerplate code instead. Heap is pretty common and having to write the same thing over and over is pretty annoying. Having said that, it is relatively rare that I bemoan the lack of generics even though it is pretty painful when you have some code that would seriously benefit from it.
Do you use Go?
Using channels as a queueing mechanism is not a good idea if the jobs/tasks need to survive a crash. To implement a job queue, there's many options - Redis and beanstalkd, for example. You can also consider cloud solutions such as Amazon SQS or Google Cloud Tasks (beware: if I remember correctly, the latter is still in beta). It is however also likely that SQLite will get the job done. It will likely not be as performant as solutions like the ones mentioned above that are more optimised for this kind of work, but it's up to you if you even need that performance. You can try implementing it and measuring it with a load test. &gt; i could do a lock around every database access - but not sure if that will slow things down extremely much and is it safe at all to do that ? The docs at https://golang.org/pkg/database/sql/#DB mention that "it's safe for concurrent use by multiple goroutines", and SQLite is also safe for concurrent use - this will not be a problem (performance should also be fine, having a connection pool - like `sql.DB` implements - that's shared across HTTP handlers is a very frequent use case). &gt; but they always have to be able to call the GET API to get a status of a current or previous job This is a good idea. Additionally, you can also think about delivering webhooks to your users when the status changes.
Okay, so you workaround the problem, and you modify the model (the rows) you actually pass to the widget each time you press PageDn. Yes, this is an acceptable workaround. &amp;#x200B; OTOH I'd prefer to solve that inside the table/list component by the library and find the library a bit of incomplete if I had to workaround it.
Maybe he can, but the language itself should solve this problem IMHO.
I wouldn't be so sure about that
This was already reddited [here](/r/golang/comments/brlpqy/go_is_googles_language_not_the_communitys/)
It's merely your own opinion. You're entirely entitled to it, and it's just fine, but this does not somehow magically makes it correct. At my $dayjob we use (full) vendoring and not going to switch away from it anytime soon (even after we will have switched to `go mod`, which did not happen yet).
Coming from you doesn't inspire confidence
Yes.
but, think about the github stars you'll have
You joke, but there are codegenerated versions of sync.Map available, and I don't see the point in adding compiler support for something that's so easily resolved.
This is not how you ask for help. From what you wrote, I'd assume you don't know programming, don't know English, and probably won't be able to understand if I try and explain that stuff to you. To get help, you need to: 1. Show what you have already done. (Nothing? Then go and try to do something before asking.) 2. Specify what's the thing you're not understanding or a problem that you can't crack. More specific the problem, the better. 3. Use language to convey that you're a human, not a robot.
1) it has to execute a windows application, its an external application that is only running windows, so in the end the rest api and the queue will be encapsulated as a service on a windows machine and that is running a process with os.exec (as blocking ) &amp;#x200B; 2) for the incoming request i dont expect that many, but because of the execution time (in answer 3) of the windows application they will be a queue accumulating ( it cannot run more than one instance of the windows application ) . If i have to put a number on it - it happens in peaks - then lets say 1 per minute - but ofcourse there could be at the same time so there could be one where 10 tries to call the rest API at the same time. &amp;#x200B; 3) there are 2 situations for the windows application, one that replies 'fast' - 2 seconds, but the other situation it can take 5 minutes for it to finish ( this is where the queue will be accumulating ) - in the 'fast' case i want to return an answer back on the rest request right away - for the slow request i would return a 'in progress' reply back on the rest, and then the client will know that it has to poll for status of a job. &amp;#x200B; 4) thats one of the headaches because all requests that are queued up that the client got a reply back on (OK or In Progress ) these in case of a crash i would need to keep, i would be able to spot if the external process that is being os.exec'ed by the statuscode in the persistant data. &amp;#x200B; 5) The process will return a reply file always if it runs correctly and its associated with the job-id, i want to have a filewatcher going on that will sense on reply files and the reply file has reference to the job-id so it would be able to survive after a crash as long as the job was 'processing'. &amp;#x200B; 6) yes, if a process seems to be running ex 10 mins ( assuming 5 mins is max) then i will actively kill the process and the state goes into ERROR. &amp;#x200B; 7) its more because i would like to be able to scale the model, also from a learning point of view to find out what would the smartest approach be to do such a queue/consumer project - the incoming REST API's they will for sure be queing up - and i still need to handle 1 job at a time but i still want clients to be able to connect into it and get a reply (even though it might be 'in progress' because of time of reply back ) &amp;#x200B; 8) channel was my first approach here as it seems so simple, but then the data persistance (its not stored on disk ) and i read the famous "channels are not good" article and get worried if it would be the wrong approach, but most importantly is that its lost if the program stops.
Yeah, not going to do that in production, I was talking about dev. Thanks for your help
You totally misunderstood your audience and your topic. I (for one, and I strongly suspect I'm not alone) completely grok the issues involved in open source, free software (including the difference between them). We care about this stuff. But that's not the same as knee-jerk rejecting anything produced by or financed by tech giants. We get the subtleties involved. Apparently you don't.
Create a struct for your data Read csv: https://golang.org/pkg/encoding/csv/ Create instances of your struct with csv data marshal them: https://golang.org/pkg/encoding/json/ Create a webserver that serves them https://golang.org/pkg/net/http/ Call your API and retrieve the data Write results to file: https://golang.org/pkg/os/ Try to explain what you're tryin to do better and show where you're actually stuck if you've actually written some code as faiface said
Write a custom comparator, go doesnâ€™t have this in the standard lib. Also, first Google Hit: https://stackoverflow.com/questions/44956031/how-to-get-intersection-of-two-slice-in-golang
I don't know what's your experience with Docker/containerization, so here's a small review of your Dockerfile: - If you like to use the latest tag of an image you can skip the definition of the `latest` tag, Docker will use `latest` by default when no other tag is specified. - To minify the image size and layer overhead you can use a smaller `golang` image based on [`alpine`][df-go-alpine]. - As of Go 1.11, [Go Modules][gmod] are supported by default (the latest Go version used in the `golang` image is 1.12.x) so there is no need to explicitly specify the `GO11MODULE` environment variable. The Go `build` command will automatically detect if your project uses Go modules by looking for the `go.mod` file. - I guess you've only added the additional `ENV` declarations like `XDG_CACHE_HOME` or `HOME` to try to fix the issue, so these can be removed too. - Installing `git` is not necessary because it's never used. Also most images come with it installed by default like the `golang` image. - Since you're using _Go Modules_ there is no more need to explicitly `go get` your dependencies like `github.com/elazarl/go-bindata-assetfs` or `golang.org/x/net/websocket`, they will be automatically resolved when running `go build`. - Is is intended that you're specifying `CGO_ENABLED=0`? _CGO_ works fine for Linux while only not (yet) fully supported on macOS. Since your project will run in the container you can use it without problems. - Better move the `EXPOSE` command above the `CMD` command for better overview and to make it actually work, otherwise it won't reach that point since `CMD` will be the last task. So here's a `Dockerfile` that worked fine for me, simply replace the `main.go` file with your project's main file: ```dockerfile FROM golang:alpine # +-- Build Phase --+ COPY . /project WORKDIR /project RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o main main.go # +-- Preparation Phase --+ EXPOSE 8080 # +-- Execution Phase --+ CMD ["./main"] ``` I can also recommend to read the base principals of containerization and official Docker documentations and resources like [â€žDockerfile Best Practicesâ€œ][d-bp] (Multi-Stage Builds are awesome) or the [Dockerfile Reference Documentation][dfr]. [gmod]: https://github.com/golang/go/wiki/Modules [df-go-alpine]: https://github.com/docker-library/golang/blob/master/1.12/alpine3.9/Dockerfile [d-bp]: https://docs.docker.com/v17.09/engine/userguide/eng-image/dockerfile_best-practices [dfr]: https://docs.docker.com/engine/reference/builder
Go dev for 8 years. Tried it in 2009. It needs generics. If anything for better concurrency patterns, and decent data structures.
I also think it's a bit of Go's downfall; adding generics _(depending on how far they go with generics, at least)_. I love Go, used it for ~5 years professionally. I now program fully in Rust, because I _also_ love Rust. I've not found a reason for me personally why one language needs to have the same features as the other. To me, there's very little overlap in workloads between Go and Rust. I can easily advocate Go from Python for our shop. Generics _might_ complicate that.. it seems like risk for little reward, personally. Don't get me wrong, I _love_ generics. That and ownership are why I use Rust. The functional patterns that they can empower is huge. Yet, it doesn't mean that every language needs them. Go is in a sweet spot imo, and problems I'm solving with Rust _(and generics)_currently are perhaps not the ones I _need_ to be solving in Go. Regardless, I'm interested to see how all this plays out over time.
[removed]
You were a java dev but donâ€™t see the benefits of being able to tell the compiler that you have ArrayList&lt;Dog&gt; vs ArrayList&lt;House&gt;? What? Were you a java dev pre-Java 1.5 ? Inheritance? That has nothing what so ever to do with â€œgenericsâ€ (parametric polymorphism).
Generics, i.e. parametric polymorphism, actually works best _without_ subtyping. For example, Haskell has no subtyping, but has extremely powerful parametric polymorphism features. You constrain type variables with interfaces (Haskell calls them type classes), and then write in terms of that. For example `sort : Ord a =&gt; [a] -&gt; [a]`. A isn't any specific type, but it does need to have an order to be sorted.
I read both of those issues. They arenâ€™t â€œblockersâ€ per se - both refer to various things the tool could do automatically to make devsâ€™ lives easier, yes, and will be great, but the go mod vendor system works. What am I missing?
https://golang.org/pkg/container/list/
Most (all?) C++ compilers may have eliminated the need for a second build step these days, but they still use code generation internally. While I think we all appreciate simpler build systems, it is really the end of the world if you have to introduce a Makefile in the interim? It is not like the Go team isn't working on generics. They have put serious effort into them, with public-facing work dating back to 2011. The biggest holdup is simply that they don't want to go down the road of C++ and resort to code generation. But if you are already happy with C++-style generics...
Opinion? 1. Local caching go modules proxy solves availability problem. Just use it for your development purposes which delegates to another go proxy or just returns cached results. Package modules needed will be in cache already during a build process â€“ devs already requested them. 2. Vendoring doesn't work for libraries. This is hard fact. 3. Dep is easily replaceable: you can easily do the same by `go get`-ing packages needed, cd to the downloaded source, then `git checkout` to package version needed. Then copy it to the vendor directory. Dep doesn't do anything other than that.
You answered precisely none of my question. Tone down the condescension there, friend.
Niche? I think a lot Go programmers who think that didn't code anything but simple programs. Even stdlib uses them, they just decided that generics would be too confusing to users.
Iâ€™ve always been a fan of projects driven by a â€œbenevolent dictatorâ€ type figure. Fully â€œcommunity drivenâ€ leads to Perl6 and Rust ( check out the absolutely *insane* level of bike shedding around the async/await feature if you have 4 hours to kill) Not a popular opinion, but having people who are opinionated *and* know their shit, in charge, is a good thing in my book. Go being terrible because â€œthe communityâ€ is being â€œignoredâ€ is the new â€œApple is dyingâ€ bullshit.
We all must make tactical compromises when necessary. Fortunately Go is not such a case. There are programming languages that are more powerful, more productive, more portable, and produce faster executables than Go (ex. D, Nim). The original article post (which isn't mine) criticizes the politics of Google and Go. If the "audience" doesn't like this discussion, it came to the wrong place.
You know Rust really isnâ€™t that complex once you understand the borrow checker...
Codegen works fantastically well in rust.
Compile time generics/templates would suit me just fine, though I feel that's restricting it unnecessarily. I use syncmap but it's a pain in the ass and gets messy.
That's pretty cool, I would never have guessed that you can pull off polymorphism sans a type hierachy. Some reading required but thank you for the example :D
What features replace generics interface {}? So now you check types at runtime and lose benefit of having a type checker check correctness of your code? Or writing multiple versions of the same thing for different types? Even stdlib internally has generics, they just decided to not provide that to the user.
I've found myself just using code generation instead. I've realized that Go will probably never have true generics, even the proposal looks bad and not much better than using interfaces (empty or otherwise) for everything.
ctx := context.Background() q := elastic.NewMatchQuery("client", "android") sr, err := es.Search(). Index("index"). Query(q). From(0).Size(10). Do(ctx) if err != nil { log.Println(err) } if sr.Hits.TotalHits == 0 { return } for \_, hit := range sr.Hits.Hits { }
[removed]
Does it improve the go community as a whole? It's hard to argue for that. I'm sure it solves some very specific examples, but people do get hung up on the whole scope of generics in other languages, without considering you don't need to bring everything to go.
Also I've been writing Go for almost 5 years and YES Go do need generics and a better error handling (Would love to see sum types to solve this)
Generics solves some very broad issues tbh. Just because Go has 2 of those use cases (maps, channels) built in doesn't mean it doesn't need them. The stdlib alone is a mess without them. Look at how backwards sort is. Look at how messy math is...
Survivorship bias.
Rabble-rousing? You're the one who brought up modules as an example of a community-led effort.
&gt; And still, there're no tasks in the backlog with the status "Blocked - waiting for generics". Somehow we deal with it with help of interfaces and other technics. Of course you can by without it, same as you could get by without float or only have int8 for numbers. It doesn't mean it wouldn't cripple your productivity.
[removed]
I actually had the idea of an OpenGo a while ago when binary only packages were being removed because 3 people at Google decided there were no use cases for them, despite being presented with several use cases for them. Just denying the existence and claiming that the barely functional plugins could replace them all. I think it needs to happen, the gatekeeping is getting quite bad.
That's pretty amazing! I wish I could live of any of my pet projects.
An easy example would be a math library where you have a function for sum, without genetics youâ€™re either going to be using interface{} with reflection or generating a function for every type like int, int8, int16, float, float32, float64, etc.
We pass the empty interface (i.e. `interface{}`) around a bit but generally you can work around it with more tightly scoped interfaces. Writing multiple versions of the same thing for different types can be made faster with snippets or with larger things with `go generate`. The conceit here is in a long lived codebase that "copying" pays dividends later.
Sure, in the same way the Linux Kernel is Linux Torvalds' and not the community's. This argument kind of ignores the essential difference between the way something like Java is released, licensed, and controlled by Oracle vs. Go to get emotional brownie points by connecting Go to Google.
Rust's generics are implemented using code generation? I admittedly haven't studied the internals, but I was under the impression that Rust's generics have heavily inspired the direction the Go team want to go with generics, which is decidedly to not use code generation like C++. Maybe you are referring to code generation outside of the scope of generics, but that's off-topic here.
I cannot agree with you enough. I had that attitude already one week ago but after the newest political happenings surrounding huawei I just now a sane human beging should never use any Kind of technology from Google, Facebook Microsoft, Amazon or Apple ever, again. I know I as a European of course habe another view than an American would.
If you study Rust a bit, you'll notice that it's actually a relatively simple and easy language if you pretend it's Go and ignore all the generics-related features. Even just ignoring lifetime annotations yields big cognitive simplicity benefits.
[removed]
If you're able to marshal / unmarshal your jobs to \`\[\]byte\`, you can take a look at [https://github.com/blueboardio/go-blobqueue](https://github.com/blueboardio/go-blobqueue), which is a library I've made to manage queues, it comes with two implementations: one using \`\[\]\[\]byte \` (so not persitant), and another one using a redis connection via [https://github.com/go-redis/redis](https://github.com/go-redis/redis). It's quite basic but it works and it's safe to use with channels.
&gt;It is not like the Go team isn't working on generics. They have put serious effort into them, with public-facing work dating back to 2011. The biggest holdup is simply that they don't want to go down the road of C++ and resort to code generation, but have struggled with the alternatives. It's a solved problem though (at least for the simple `forall a` / parametric polymorphism case). You just erase them (put them in the `interface{}` box) and cast on the way in and out. Here are all the "downsides" of that: * Unnecessary boxing - It would still be hugely useful despite this cost in most cases. The usual solution I've seen to help is specialization (often in the form of a pragma) * Constraining the `forall a` \- Once again, still hugely useful without any constraints (and interfaces universally quantified over types would be amazing). This is probably the design talk that held things up as there are a variety of approaches out there. My point though is that straight-up parametric polymorphism implemented via erasure would be a gigantic productivity and (way more importantly) correctness+safety boost to the language that it's worth punting on the harder stuff. And throw in sum types while you're at it and all of a sudden Go's type system is 10x more capable with only a small amount of related cost.
No code generation is not needed for rust generics. But rust has fantastic code generation.
No, the author of the linked article brought it up as "the most clear" example of the community not mattering. And yes, I stand by the term rabble-rousing for the way "the community" is constantly pitched against "Google".
TIL. I didnâ€™t know this package existed. I thought typing was antithesis of python.
You could possibly use goreleaser which has nfpm functionality: https://goreleaser.com/nfpm/
Another option is Nativescript/Vue https://www.nativescript.org/vue
Here I am, having used go for 3 years intensively, completely convinced go needs generics
Code generation, however, *is* needed for C++ generics, and it introduces tradeoffs that the Go developers are not willing to accept for the official language specification. Presumably the Rust developers also felt the same way if you are telling us they chose not to use code generation for generics, which is also my understanding. That Rust allows code generation elsewhere is irrelevant to the topic at hand. However, if for you, the end user, C++ generics are considered acceptable then Go already has generics. My question is how they introduce the problems mentioned by u/chippydip. That Rust allows code generation beyond the scope of generics tells us absolutely nothing.
How was it before?
No offence. He is right. I am baffled just as much about your confusion.
I want to call out that if you add parametric polymorphism to Go, you don't *need* a constraint system to do things like `sort` or abstract over numbers. Manual dictionary-passing would be available (via parameterized structs or interfaces) and work - it just wouldn't be the most ergonomic.
it wasn't.
People already manual compile erased generics in Go all the time by casting to &amp; from `interface{}`. Adding parametric polymorphism to Go could just be a compiler-checked way of doing that. I'm pretty sure I could fork the Go compiler &amp; add it in a week. It by no means would touch every part of the language.
I just recently was implementing a data structure to store arbitrary data, for my use case I needed to store int64 and float64 (ideally I would like to be able to store any int and any float, but Go makes it hard), but the structure could be used for any object, not just numeric. I don't think I could use anything other than `interface {}` I don't think there even is an interface that would overlap with all integers since those are primitive types. Interestingly Python doesn't need generics because it is dynamic duck-typed language. But if I would use mypy for type checking it even has `SupportsInt` which I could use and would encompass any integer including objects that can pretend to be integers. The `go generate` is what I used together with `genny`, but it is just a way to automate writing dedicated version for every type. Ultimately it works and I get type checking, but it is still ugly, there's still duplicated code and I need to run the generator and compile code every time I make change to that file. I currently work at a place that likes to have everything written in Go, and honestly I miss Python. My biggest issue with it was it being dynamically typed, but together with mypy it is awesome to work on.
Relatively new to Go. I was reading [this article](https://dev.to/deanveloper/go-2-draft-generics-3333) on the proposed generics implementation, and contracts seem odd. Considering that you can't define the behaviour of standard operators for custom types, the common way to handle that is something like `foo := bar.Add(baz)` (eg. the big package in stdlib). How does this work with contracts when the proposed syntax to say that "addition on t must be defined" is `t = t + t` when + can't be defined for custom types?
I think it's progress but there are still some pretty major omissions IMO. Including things that have been solved forever with dep. For example: 1. You can't vendor non-go code (e.g. proto files or templates) 2. You need to use a tools.go file to vendor tools which is kind of weird. 3. Private repos are really tricky to use. No way to override http to ssh (you can do it with git as a workaround). Most go commands don't use a .netrc which makes ci integration harder (download does but get doesn't for example).
Are there any other golang podcasts? I have searched in the past and not found anything relevant.
With Qt in the mix, we do cross-platform apps entirely in Go (although you could quibble that Qt has a go wrapper around c++ functions, but we donâ€™t get involved with that, so our team is pure go). By cross platform - we cross compile to MacOS, iOS, Android, Linux and Windows. So yes, we do!
Then please do.
When I have a week to spare, maybe I will :)
That's awesome :D
Only if I can find an efficient division algorithm for 256-bit numbers. The other operations are straightforward (well, multiplication is slightly tricky) but division is hard enough that I don't trust myself to get it right.
By the way, I'm not being facetious here. Okay, maybe a little bit, but the point is if you have a system in mind that works well and fits everywhere I want to see it. My main point of contention is when people try to bolt generics onto the language. I've been saying for a while that a generics system should optimally extend or completely replace the current generic data structures and functions in the core. If you can get new, make, slices, and maps working in a generic system so that they are extendable and still work with existing code, my hat will most definitely be off to you.
If we get a more tool aware system that'll be really great; even though tools.go feels like a hack at the moment, it and gobin together do a very good job (and I'm removing more and more binaries from my GOPATH all the time, though it's not a replacement for "I just want this program in PATH to use day to day").
[removed]
Go modules.. looking forward to listening to this one
&gt; I also think it's a bit of Go's downfall Easy there, Nostradamus. &gt; I've not found a reason for me personally why one language needs to have the same features as the other But they won't have the same features, even with generics. Rust is a completely different beast, and parametric polymorphism is a staple of every decent statically typed language. It's so important that the original spec includes at least some basic generic data types, because without them the language would be completely useless (Java 1.5 wasn't fun, at all). &gt; To me, there's very little overlap in workloads between Go and Rust One can argue that this is because Go, while easy to use, is only really useful in certain niches (mainly pushing bytes over the wire). It's not exactly general purpose, and there's nothing wrong with a general purpose language. &gt; Generics might complicate that Why? Also, how? &gt; Yet, it doesn't mean that every language needs them. No, it doesn't Every statically typed language however does need them in the long run, which is why Go at least provides some builtin generic types.
Java can also sort simple collections without a Comparator. Whereas in Go, even simple slices need to implement that interface, and thus suffer the indirection penalty on every iteration of the sort. Which is why sort.Slice, even though it uses reflection, is faster.
Postname and git account suggest you may be the author, /u/timesmaster, in which case let me just say that I have now read your README.md and godoc information, and I have only the vaguest ideas what this is supposed to do. Posting it to /r/golang suggests to me you think other people may want to use this, so I'm trying to be friendly, if sadly negative, and trying to give you a chance to improve the project, if that's what you want.
Go never needs generics on day 1 of a project. On day 128, go _definitely_ needs generics.
You refer to the natural order that is used by primitives and string? I really want to know what's actually bad about generics, you don't have to use them if you don't want :3 (Talking in general not specifically you)
What happens when someone deletes their public repo?
go devs defending the language for not having generics will celebrate when they are added. I've used go for 2 years now and have gotten used to boxing types and using reflect, and I would be thrilled if go2 was released with generics
I don't know. I've been in the pro generics camp from the very beginning.
Then we're fucked.
Unrelated: how do you get the command highlighted in your terminal like that ('go' is green, and so is 'cat')? I'm using oh-my-zsh for my zsh terminal session
I wrote a project dealing with around 80 different structure type which all had a similar set of properties; id, val, name, etc.. Each one of the types then branched off to have very different contexual props. It would have been awesome to write the main engine of the program generic, but instead we had to use the code generation tools. Nothing is more annoying than generating 80 different types and then having a change in definition or scope and then having to do crazy refactoring and hoping things still work.
Likely https://github.com/zsh-users/zsh-syntax-highlighting
Unfixed.
You should be using a buffered channel and push urls into it(when done, close the channel), then have a number of workers pull these urls from the channel and process them, each worker is a separate goroutine, this way you can do a certain number of tasks at the same time without the feat of exhausting all system file descriptors or draining the network.
&gt; Easy there, Nostradamus. I didn't mean to imply that Go is downfall. Relax, buddy. I simply meant that it seems to be a departure from the fundamentals of what I feel is successful. There's only so many of those that a language can suffer without losing identity. Lest Facebook come out with the new Run language. A language built for concurrent scalability and ease of use. Hah.
Yes
Also limit the amount of routines depending on the server you are downloading from. Most public Webservers limit the amount of parallel downloads to 2 or 3 at a time.
Use a proxy such as https://docs.gomods.io/intro/ Go also has an official, well beta, proxy https://proxy.golang.org/ Then you're unfucked.
1. `$ go mod vendor` 2. `$ git add vendor &amp;&amp; git commit` 3. One of your dependency disappears from git{hub,lab} 4. Nothing happens, because you have complete control over your dependencies.
Generics were one of the many reasons I felt constrained by Go, and switched to Crystal. Now *everything* is generic!
I read a webcomic that said otherwise.
I actually made a similar package last year, I'd be interested to compare algorithms and swap ideas. [https://github.com/ryanavella/wide](https://github.com/ryanavella/wide)
And (if it isn't obvious) you'll need to use zsh.
I'm someone who uses Go for quite few years now, Go needs generics. &amp;#x200B; AMA
The error prone bit is if you choose to just reimplement a pattern each time you need it.
Can you expound a bit more on the tools.go. How is it used, is in just a file in the `main package`. Wondering how I'm going to vendor the tools I depend on with `go mod`
Does having the Go version set in the `go.mod` file prevents older versions to use that module? If so, how to set minimal compatible version? That's something that didn't happen in 1.11 and I'm unaware of its meaning.
[removed]
Yeah, I mostly just want sum types and RAII. Multiple return and defer work, but they're clunky when compared to alternatives (e.g. Rust's `Result` and mutexes). They're really not the same thing, but many languages use similar syntax for both. I don't know how many times I ran into issues because a lock wasn't released, and I hate having a bunch this everywhere: val, err := fn() if err != nil { return nil, err } I _really_ like Rust's syntax here: let val = fun()?; Or better yet, if you want to change/chain the error: let val = fun().map_err(|e| some_other_err(e))?; But no, I have tons of `err` everywhere, and sometimes I get compile errors because I put a `:` somewhere for a _different_ `err` that happens to be in the same scope. Give me sum types and RAII and I'll be _much_ happier (and my code will be a bit more readable and simpler).
Go n00b here. Couldn't you just add methods to each of your structs that you feel have similar properties, with each method having the same signature? Then use interfaces where you want to actually use the structs polymorphically? I was under the impression interfaces were the recommended way to go to achieve polymorphism in Go.
[removed]
&gt; you don't have to use them if you don't want Well, you do if you want to use large parts of the standard lib of a language that uses generics. A _lot_ of things in C#/Java take stuff like `List&lt;T&gt;` or `Map&lt;K, V&gt;`. You're basically forced to use them if you use huge swaths of the standard library. That being said, I think it's generally a good thing. I _much_ rather implement `Compare(other T) int` on the type than `Less(i, j int)` and friends on the collection.
It was such a huge turn off for me was reading that Golang adopted generics like the rest of the filth. I love this meme I upvoted it and I'm going to put it on twitter now. Thanks for the good post.
It's more like you give up hope and accept the status quo, not that you don't want generics anymore. As a relatively long-time Go developer (started pre-1.0, been continuously developing with it since), I think there are more important issues to be solved, such as RAII. Every time I have a concurrency bug because of a misplaced `Mutex.Unlock`, I curse the language team. Every time a socket doesn't get closed and results running out of files, I curse the language team. Every time a database connection borrowed from a pool doesn't get returned properly, I curse the language team. Generics and other proposals are definitely quality of life improvements (I hate `if val, err := fn(); err != nil { ... }` as much as the next person, but something like this is _much_ more common and problematic: // can't defer here because it's a loop for range c { lock.Lock() // do stuff that may panic lock.Unlock() } // can't defer here because you could end up in deadlock if condition { lock.Lock() // do stuff that may panic or return lock.Unlock() } if other condition { lock.Lock() // do other stuff that may panic or return lock.Unlock() } In Rust and many other RAII languages, I get to choose whether I want to unlock a mutex early or let it unlock when it goes out of scope, so it's _very_ unlikely that I'll end up in a bad state accidentally. I end up in this state in Go _all the time_. I like generics and I think they would be a good addition to the language, but I'm mostly interested because most languages have an overlap in syntax with RAII, which is what I _really_ want.
Neat. Looks like my package makes more use of `math/bits`, which improves performance a bit. (I believe the compiler recognizes them and converts them to intrinsics where available.) `bits.Mul64` and `bits.Div64` are really useful for implementing the `Mul` and `Div` methods; my `Mul` and `Div` methods don't contain any loops. I don't fully understand the division algorithm I used (I adapted it from [this one](https://www.codeproject.com/Tips/785014/UInt-Division-Modulus) but it seems to be doing what you describe the docstring of your `Div` method. API-wise, you have lots of methods for bitwise operations, whereas I support only and/or/xor. You also have a `Mod` method, whereas I only have `QuoRem`; I should probably add `Mod`. Your `String` returns hex, whereas mine returns decimal. You include a few variants for adding/subtracting/shifting by 1, while I include variants for 64-bit arguments. And of course, you support `Int128` as well, whereas I only have `Uint128`. I like the name `wide`. Maybe I'll rename mine to `fat`.
You have a bug. You are passing the sync.WaitGroup by value. You want to pass \`&amp;wg\`, so the child goroutines call Done() on the same wg as you are calling Wait().
I would recommend using the file system as your DB/queue. In your case Redis or other fancy systems just over complicates operations. A simple folder structure would be sufficient performance for your case - it seems. You could have a single worker go routine that executes your jobs and let it communicate using channels. Then just do disk I/o for status files when getting GET requests.
Before it was solved with dep. Russ essentially forced modules down our throats when it wasn't needed. Modules is still good, but it didn't solve any problems at the time. &amp;#x200B; Before dep, dependency management was a cluster.
Except go build won't use the vendor folder by default until they fix that bug.
Nope still fucked cause now you have to maintain an entire distributed state store and hope you keep all the versions you need to ensure repeatable builds.
girl please.
While it isn't mainstream, Nix does work pretty great with Go, and since Nix is language-agnostic, it addresses all your points. The cost is you have to buy into &amp; learn Nix. In my experience, it's been one of the most useful tools I've ever learned. But it isn't universally loved either :|
Just create an `http.Handler` in other file, and use it at `ListenAndServe` in `main.go`. ``` package transport // imports omited func MakeHTTPHandler() http.Handler { mux := http.NewServeMux() mux.HandleFunc("/foo", fooHandler) mux.HandleFunc("/bar", barHandler) return mux } ``` ``` package main // imports omited func main() { h := transport.MakeHTTPHandler() err := http.ListenAndServe(h) log.Fatalln(err) } ```
I assume you mean having different sets of routes in multiple files. I took a stab at a nice way of doing it here: [https://gist.github.com/ramirez7/095f455f47e0bb3a100a466ecbab0728](https://gist.github.com/ramirez7/095f455f47e0bb3a100a466ecbab0728)
&gt;now you have to maintain an entire distributed state store No, you don't. All you have to do is. ``` export GOPROXY=https://proxy.golang.org ``` The go core team maintains the store for you.
If you want to spread it to packages per domain, then something like this (these are REST endpoints): ``` package foo // imports omited func MakeHTTPHandler() http.Handler { r := way.NewRouter() r.HandleFunc("GET", "/foo", list) r.HandleFunc("POST", "/foo", create) r.HandleFunc("GET", "/foo/:id", get) r.HandleFunc("PATCH", "/foo/:id", update) r.HandleFunc("DELETE", "/foo/:id", delete) return r } ``` ``` package bar // imports omited func MakeHTTPHandler() http.Handler { r := way.NewRouter() r.HandleFunc("GET", "/bar", list) r.HandleFunc("POST", "/bar", create) r.HandleFunc("GET", "/bar/:id", get) r.HandleFunc("PATCH", "/bar/:id", update) r.HandleFunc("DELETE", "/bar/:id", delete) return r } ``` ``` package main // imports omited func main() { mux := http.NewServeMux() fooHandler := foo.MakeHTTPHandler() mux.Handle("/foo", fooHandler) mux.Handle("/foo/", fooHandler) barHandler := bar.MakeHTTPHandler() mux.Handle("/bar", barHandler) mux.Handle("/bar/", barHandler) err := http.ListenAndServe(mux) log.Fatalln(err) } ```
That's really helpful. Thanks!
This is exactly what I was looking for. Thanks!
But be aware of doing this. Having all the routes defined at one place serves as a nice documentation. One can easily go to `main.go` and see what are the endpoints this service provides.
&gt;Neat. Looks like my package makes more use of math/bits, which improves performance a bit. (I believe the compiler recognizes them and converts them to intrinsics where available.) Huh, I didn't know this, I definitely want to look into it now. I was a little new to Go when I started writing Wide. Back then I was skeptical that the Go compiler had a decent optimizer, so everything I wrote was under the assumption that calling functions from math/bits would add overhead and wouldn't be inlined properly. I also didn't realize that type conversions were basically no-ops so I naively tried to avoid them wherever possible. But recently I've started to shift perspectives on this, and I'm beginning to trust that the Go compiler knows what it is doing. &gt; Your String returns hex, whereas mine returns decimal. Decimal is probably the more intuitive choice here, I only chose hex because it is easier. :) &gt; You include a few variants for adding/subtracting/shifting by 1, while I include variants for 64-bit arguments. Yes, I figured that these variants where one of the arguments is 1 are encountered often enough that the specialized versions would encourage optimization and inlining. It's mostly a personal preference, I didn't benchmark anything to see if it made a difference. &gt; And of course, you support Int128 as well, whereas I only have Uint128. If you see my Int128, it actually isn't a whole lot of work to implement. You could probably copy most of your Uint128 code, with only minor differences. The biggest change is that the high 64 bits are better represented as an int64 rather than a uint64, so that sign extension is automatic, and it looks cleaner to check x.hi &lt; 0 rather than e.g. checking the MSB. &gt; I like the name wide. Maybe I'll rename mine to fat. I like that, fat.Uint128 has a certain ring to it. And less stuttering too. By the way, I've learned some new Go tricks reading your code! I didn't realize until now that structs can be compared with ==. I also like your left-shift-and-xor trick for converting a Uint128 into a Big.Int. Neat!
&gt; Does having the Go version set in the go.mod file prevent older versions to use that module? No. But the mismatch will be noted only if the build fails. See https://golang.org/doc/go1.12#modules
`#2 ` wasn't a solved problem in dep. There was no straightforward solution. Atleast at that time - https://github.com/golang/dep/issues/1572. Not sure of the state now.
There's a very good example of worker pools on Go by example, I'd probably recommend trying that. &amp;#x200B; [https://gobyexample.com/worker-pools](https://gobyexample.com/worker-pools)
assuming it's available in your country, assuming they have a copy of your module, assuming that it's not down or inaccessible or just incredibly slow. It's still more moving parts than committing it to your repo.
+1 to this, I use it, and trying to introduce in my company. It's really neat. The great thing is that once you use nix to describe how to build your application (list dependencies and thing like version of go used to build) you can then for example create shell.nix with development environment (including all tooling you need) a new developer after installing nix, can just type nix-shell and have all tools available. Similarly you can use the definition to then package it the way you need it, into a minimalistic docker image, a system/language package or if you use NixOS install it directly from the definition. It's great because it's fully reproducible everyone has exact same environment when using it. You mentioned protobuf for example, this by itself can be an issue, when people have different version installed on their machines. It is especially bad if they use different version of the compiler than the dependency in the project. Nix can coordinate all of that.
Guys, I'm a bit new in Go and cannot get what is the power behind Generics and why we need an additional syntax if we already have interfaces. The generics approach is the way to describe concrete behavior. That behavior is an interface. And Go is about interfaces, so what are the benefits? And finally, we will get like: "There Is More Than One Way To Do It"
Shameless plug: https://github.com/AudriusButkevicius/recli only asvantages is indexing into arrays by non-numeric index and adding structs to slices.
You should measure whether this is worth your efforts. Itâ€™s very likely network I/O is the bottleneck - these tricks wonâ€™t work then.
Yeah I get that. My thing is services. I have services that depend on each other. Putting the interfaces for them into a "models" package and just having the implementation in each "actual" package allowed me to import models into all the other "actual" packages.
Except we're in r/golang. So the audience is Go coders. I don't know about the others,but I chose this language for a reason. I'm curious about what, exactly, you think Go (the language) does to impede our freedoms though?
How does work, there is a handle for /bar in main, and /bar in makehttphandler. Does it work for /bar from the original request now, or /bar/bar ?
I experienced that not long ago with one dependency using thrift hosted on apache repo which looks like it was shut down permanently.
Looks weird, but no. It handles just `/bar`, not `/bar/bar`.
&gt;(including all tooling you need) Yep - I love that with Nix I can check files into git and devs can `git clone`, `nix-shell`, and get going. You can even include `emacs` w/`go-mode` installed &amp; all peripheral CLIs (`gocode`, `godef`, etc).
`export GOPROXY=https://some.other.trusted.proxy` There will be more than one proxy, and I hear talk of some kind of distributed notary for package signing being specced out/worked on. I assume you'll be able to set up your own private instance of a proxy pointed at the notary (or whatever it's called now) at some point. Even if you're vendoring it, you'll want a proxy verifying checksums for the initial download to assure you're getting what you expect.
The thing that's irritating me right now is directory structure flexibility. I'd like to be able to dump the go.mod at the top level of a project, but map the declared module root to projectroot/src, then have other stuff (like main packages) living somewhere else. Maybe I am not using `replace` correctly, but I don't think it behaves as I'd prefer. If I had written a design doc, it would have been a single three-word sentence: Just clone Cargo.
\&gt; Private repos are really tricky to use. No way to override http to ssh or vice-versa (you can do it with git as a workaround). Most go commands don't use a .netrc which makes ci integration harder (download does but get doesn't for example - although this is fixed in the next release). &amp;#x200B; go get (and go mod) support private repositories, provided they provide the go-import meta tag. I wrote a quick and dirty hack for our privately hosted bitbucket repository. Bitbucket has rudimentary support for go-import meta tag, but only for public repos, and only over http(s). So I wrote a little proxy meant to sit in front. &amp;#x200B; [https://github.com/myENA/bbgoget](https://github.com/myENA/bbgoget)
Itâ€™s inexcusable imo that Go was even released publicly without a solid dependency management system in place.
Why do you still need vendoring?
It's difficult to determine what you're asking for but I can definitely understand why coming up with python and node left you so ignorant and clueless. &amp;#x200B; If you want to know about golang read the documentation or buy "the go programming language" book. &amp;#x200B; If you want to know some first principles try this course. It doesn't use golang but it sounds like you need it. [https://www.nand2tetris.org/](https://www.nand2tetris.org/)
Yeah you need to figure out the go docs. My first thing was reader and writer interface. Start with this package. https://golang.org/pkg/io/ Learn the types. Make your own copy method. Pick apart these and make your own methods. The point is to deal with these types and de engineer what's going on. There are some methods that don't give you everything but that's fine, just keep digging. Learn also the strings package. https://golang.org/pkg/strings/ Especially NewReader! https://golang.org/pkg/strings/#NewReader Then move to []bytes and conventions. There is a world of things to do. Combine types, slice the types, use slice of custom types...ect. it's amazing once you see the power of them.
It wasn't perfect, but `go get` and `GOPATH` have been there since the start.
I just started go - would you mind explaining how generics would benefit concurrency patterns? I've been reading quite a lot about goroutines and I'm curious
I think thatâ€™s something I definitely need. I tried looking at assembly and C to get and understanding of how things go from the ground up. But it was too confusing. I will give that a shot
csvkit (csvjson) will read csv and output json. There is a tool (sorry forgotname) that serves json as api. Why do you need golang?
Why not just use the default tmpfs? I thought ramdisks are a thing of the past...
It is using tmpfs, which is a 'ram disk'.
Tmpfs and ramdisks are two different things IIRC.
You're probably confusing it with ramfs. Ram disk can use either tmpfs or ramfs. This is using tmpfs.
Ah, yes, you're right. I was thinking about ramfs.
...that's not the joke at all. The joke is just it's really god damn weird to walk up to someone when they're pissing, and usually if youre going to do that youre probably going to talk to them/harass them/tell them something they don't want to hear. Like "Go needs generics".
I'll just pick one thing: &gt; Like the context of a database driver. This has nothing to do with the language, its theory or whatnot. Go's stdlib contains a package `context` and which is described in https://blog.golang.org/context . It might be hard (or impossible or useless or just strange) to reimplement package context in JavaScript or Phyton so you might not have seen this way of propagating information to some function which might take some time and you would like to signal "you can stop whatever you have been doing, I'm no longer interested in your work". But there is nothing _fundamental_ about this. Just understand that a Context can carry information and allows for cancelation. So if you do not know what package context does: Read the package documentation and the relevant blog post. Same for slices, same for strings. These are just language details and are not covered by CS degrees. (A tin smith degree will teach you basics of tin-smithing but will not explain things like "machine X from vendor Y has its on/off key on the left side and needs to be turned ccw by 45Â° to turn on". Such details are in the manual of machine X. If you work somewhere where they use machine X you will have to learn this--by reading the manual, asking your coworker or trail and error--same with package context. It is Go's way of propagation information downstreams to DB queries, HTTP reguests and whatnot. The details are in the handbook.)
Well how would you actually obtain the cookie in a GET request if its \*name\* was the UUID? Generate a UUID. Send a set-cookie header with the name of "sessionId" or whatever you want, and the value as the UUID. Persist the UUID in a database like Redis, MySQL etc. When you get a request, get the UUID from the sessionId cookie being sent to you in the request body. Look it up in your database, for example "HGET (key)" or "SELECT key, date-created FROM sessions WHERE key = (key)". If it's there, you know they've logged in.
Sessions are a way of storing data. While cookies store the data on the frontend, sessions store a small identifier on the frontend that matches to the data stored on the backend. You need to link the session value to the userID, either in memory or in a database sessions table. Of course you could just store the user ID as the value with a cookie called userID if you don't care that the user sees their ID which would give away how many users you have if you're using an incremental database ID. Also make sure the UUID you're generating is using a secure random implementation. You want it to use `"crypto/rand"` not `"math/rand`.
You donâ€™t want to put the username unencrypted in the browser for security reasons. You wonâ€™t be able to associate a random uuid with a user u less you store that in the DB when you generate it. A good approach would be to encrypt the user Id when and store that in sessionID cookie then you can decrypt on sever with requests
Let's think about the analogy here for a bit. Is using a programming language to develop software like using an urinal? Are language feature sets constant and unique like the urinal and a developer must pick one or the other? And if so, what is the social etiquette when talking about "someone else's language"? In my opinion, this is a false analogy. Whether to include a feature like generic in a language is trade-off made by the language designers at some point in time. When someone says "wouldn't it be nice if go has generics", they are expressing an opinion that adding the feature will make a certain set of problems easier to solve, or making the code easier to read, or reduce the boilerplate code needed to write good software. This is a discussion very much worth having for Go to improve as a language and become a more useful tool for building real-life software. For those that said that they have not found a use for generic in Go, please read â€œGo Experience Report: Generics in Kubernetesâ€ by Aaron Schlesinger https://link.medium.com/Yd7wvsivWW. As one of the largest and most successful project written in Go, the Kubernetes team essentially had to create their own type sysyem because the language does not support it natively. It can be done, but at what cost?
I think the value of key "userIdArray" is nil, that's why it cannot be converted to \[\]string.
I thought ramdisk and tmpfs are the same thing.
As someone else commented ramdisks can use both ramfs and tmpfs, so yes, sometimes it's the same thing. What I don't understand: Why not just use /tmp for compiling which is usually already mounted as tmpfs. That should be possible IMHO.
For #3 (private repos), I wrote up a quick explainer for how we are handling it: [Go Modules with Private Repos](https://link.medium.com/ZMgGuZlzWW) The basic concept is to use a user:auth_token url format in your git config. I found the ssh alternative to be harder to debug, but my understanding is thatâ€™s also workable.
The way to not release anything of note, ever.
I think you should check is the type is of []string before converting example import "reflect" if reflect.TypeOf(bodyMap["userIdArray"]) == reflect.TypeOf([] string)
You might want to checkout [https://github.com/mh-cbon/go-bin-deb](https://github.com/mh-cbon/go-bin-deb) Very, very, nice. This fellow has a very nice couple of helper tools for the release process of Go binaries (Windows MSI, RPM, Readme stuff). Recommended.
Couldn't be more right. I'll take the downvotes with you.
How long the rsync takes? Because you â€œgainedâ€ 0.5 sec on compile time which is small enough to almost not be seen. Cool so now how long it takes for rsync to sync it :) because if it takes none zero amount of time the gain could be really minuscule :(
Yeah that's possible. Linux also mounts multiple tmpfs directories so I guess it's best practice to have a dedicated mount? Plus you get to set the size limit. Which can prevent you from accidentally copying too much files into memory.
I think this is more likely the cause. Doing a direct type assert without a check, and even without checking the map access, is likely to cause problems.
`/dev/shm` is also usually available by default.
Sometimes its' easier to have tools reference dependencies without having to use go list. For example it's easier to configure prototool to use like ./vendor/foo/bar.proto than to have to look up the location in the cache. It's also more convenient for CI since it's harder to cache directories outside of the project's path in gitlab. But I agree it's less important now. Previously we'd go-install tools from our vendor directory but now you can just go get them at a specific version which is nice.
It's difficult to calculate. But based on experience, without the ram disk my compile time sometimes jump to 4 to 5 seconds or more. This doesn't happen on my ram disk so I would say it's pretty worth it. And this is a small project with few files.You'll see a bigger jump on larger projects. Since the copying happens at the same time as the compilation, there is virtually no loss if you're doing auto compilation.
&gt;it has to execute a windows application, its an external application that is only running windows, so in the end the rest api and the queue will be encapsulated as a service on a windows machine and that is running a process with os.exec (as blocking ) Sounds like you might want to use a CQRS framework for this problem. &gt;for the incoming request i dont expect that many, but because of the execution time (in answer 3) of the windows application they will be a queue accumulating ( it cannot run more than one instance of the windows application ) . If i have to put a number on it - it happens in peaks - then lets say 1 per minute - but ofcourse there could be at the same time so there could be one where 10 tries to call the rest API at the same time. You definitely want a persistent queue and not just a channel. &gt;there are 2 situations for the windows application, one that replies 'fast' - 2 seconds, but the other situation it can take 5 minutes for it to finish ( this is where the queue will be accumulating ) - in the 'fast' case i want to return an answer back on the rest request right away - for the slow request i would return a 'in progress' reply back on the rest, and then the client will know that it has to poll for status of a job. I would always return just a job id when the job is enqueued. Then the application could poll once per second. This makes things simple. &gt;thats one of the headaches because all requests that are queued up that the client got a reply back on (OK or In Progress ) these in case of a crash i would need to keep, i would be able to spot if the external process that is being os.exec'ed by the statuscode in the persistant data. You don't have to care about this when you are using a queue that guarantees at least once semantics (There are many). Once the "handler" handles a queued item it has to signal an "ack" within a defined timeout. If that timeout is reached, e.g. because a crash happened, the item will be redelivered. If you need exactly once semantics, e.g because you want to prevent the job from running again, you might want to add an idempotence key, e.g. an input hash, to mitigate multiple executions of the same request. &gt;its more because i would like to be able to scale the model, also from a learning point of view to find out what would the smartest approach be to do such a queue/consumer project - the incoming REST API's they will for sure be queing up - and i still need to handle 1 job at a time but i still want clients to be able to connect into it and get a reply (even though it might be 'in progress' because of time of reply back ) As I already said, I think CQRS might be an appropriate approach to solving this problem.
You are missing two checks: ``` rawUserIdArray, exists := bodyMap["userIdArray"] if !exists { // The field "userIdArray" does not exist in the map } userIdArray, ok := rawUserIdArray.([]string) if !ok { // The value in the map is not of type []string } ``` In your case, the bodyMap probably doesn't have a value at "userIdArray" and therefore it returns a nil value. Then you try to typecast the nil value to a []string and it panics because it can't do that. Always check the "ok" value on a typecast for exactly this reason. Additionally, based on your function signature I'm assuming you're using elasticsearch and are trying to parse the results of a query. If that's the case, have you considered creating a json-encodable struct that way you can use `json.Unmarshal`? For instance: ``` type ResponseObj struct { UserIdArray []string `json:"userIdArray"` MyBool bool `json:"myBool"` ... } ... r := ResponseObj{} err := json.Unmarshal(rawBytesFromResponse, &amp;r) // Frequently something like: result.Hits.Hits[&lt;a loop&gt;].Source ```
You could add 100 mb worth of deps and see how it fares.
[removed]
"go get defaulting to proxy.golang.org and sum.golang.org": https://groups.google.com/forum/#!topic/golang-dev/4Kw_OfGa7cc
Did you compare with an ssd pcie disk or a classical sata spinning disk ? If compilation speed is relevant, I would use a PCIe SSD and not with QLC cells.
there was dep
As a relative newbie myself, my advice is to learn as much as you can about interfaces. They seem easy at first sight, but IMHO they are one of the most complicated concepts in Go - only concurrency primitives+context package are harder, but that's because getting concurrency right is hard in almost every language. The ways in which interfaces interact with pointer receiver and non-pointer receiver methods of structs can be the source of weird error messages and segmentation faults. Using structs with non-pointer receiver methods together with interfaces has been one of the biggest learning hurdles to me so far. One neat trick I've recently learned is that you can use the following code to check at compile time whether a struct `Structname` implements an interface `IFace`: `var _ IFace = (*Structname)(nil)`
Agreed and can't understand the downvotes. Honestly I don't exactly know how to use modules. Dep simply works for me since the beginning.
I have a lot of endpoints which can be clearly categorized. I will have to find a way to get around the documentation part.
Minor correction. There's no libc in go binaries. Go implements everything through syscalls.
Didn't know that, thanks!
You can store it encrypted and then decrypt in init(). That doesn't truly "hide" it; it's just a bit harder to find. Even something like base64 would be enough for this. I suppose.
Try to use upx. It it easy to unpack.
I know, and itâ€™s useful, but something like go modules shouldâ€™ve been there from the start imo. I like go but every other recently new language that Iâ€™ve learned has had much better tooling from its inception (elixir, rust, etc.).
Thanks! I am working on windows env. Can I use upx on windows?
There's no way to truly hide it. You can't keep anything secret in a binary.
Starting with version 3.91, UPX also supports 64-Bit (x64) executable files on the Windowsplatform.[7] This feature is currently declared as experimental. https://en.m.wikipedia.org/wiki/UPX
Not sure if I understood. I will write the code snippet to make myself more clear - ============================================ package main import ("fmt") func main() { var sensitive = "this is my sensitive info" fmt.Println(sensitive) } ============================================= Now, compile an exe: go build -ldflags="-s -w" -o testbin.exe &amp;#x200B; notepad++ testbin.exe &amp;#x200B; now you can see "this is my sensitive info" in notepad. &amp;#x200B; Holy shit this is real flaw. isn't it??
No.
I would recommend to avoid storing sensitive information in your source code. Try putting all sensitive information to the Environment variables
[removed]
Thanks. Will try it.
Agree. But, env can be intercepted as well. Thanks!
Bro you're printing it to the screen but you don't want people to see it ðŸ˜‚
hahaha. This is just an example buddy, to clear what i was trying to say. Also, the dev of the language thought to produce an error if you don't use the variable.
&gt; Holy shit this is real flaw. isn't it?? It's like this in every language except maybe brainfuck. If you want secrets, don't put them into your source code. It's as easy as this. Load them from the environment. &gt; But, env can be intercepted as well. It's much harder and needs higher privileges.
It's doing exactly what you told it to do. You use no encryption or other obfuscating technique. Why would a compiler go ahead and produce executable code that is much heavier on the CPU than required?
I usually put a gen.go file in the same directory where .proto files locate
How would you go about doing the same on Windows?
This will take somebody reverse engineering your app an additional 10 seconds. If you write a custom packer and encryptor that time might go up but what youâ€™re asking for is impossible. There is literally a Linux command called strings that will dump the strings of regular binaries. You literally cannot trust anything in your binary cannot be viewed or edited.
&gt; Any idea on how to hide those information [?] No. &gt; Can i do obfuscation? Yes. But why?
How else would you expect it to work? If you compile that it needs to get the `"this is my sensitive info"` from *somewhere*, so it gets stored in the binary. You can store it "hidden" as : var ( sensitiveHidden = "55hqdyjdsfdsafaff" sensitive = "" ) func init() { sensitive = decrypt(sensitiveHidden) } But that just makes it harder, and not impossible. Any reasonably skilled attacked will be able to get at the secret without too much effort (I actually recovered a secret like this once, and I'm not even a security specialist!)
&gt; env can be intercepted as well. Completely hiding secrets is a hard problem. You can say "can be intercepted as well" about most things. Environment is certainly better than storing it in the binary, and for most purposes it's "good enough".
&gt;Any idea on how to hide those information. If you want to display information on someone's screen, then you can't hide it. If you want a computer to be able to read information, then you can't hide it. That's an inherent flaw in computer-based thinking. You can't send someone's computer code and then expect the code to work as you sent it, without the computer being able to see how it's working. The computer has to know how to execute it, for it to work. Think about a few examples, why do cracks always seem to exist for programs and even keygens which generate valid serial keys for the program? It's because the program comes with the computational logic to describe that validation logic and the checks and balances to prevent piracy. The problem is that it's a game of cat and mouse, you can only make attempts to obfuscate it or make it very difficult to crack but the information is still there, it has to be for the computer to run the program's code. Even if you check validity against the internet, people can still crack it because they can reverse engineer the code and change the checks so that they are skipped. There is literally nothing you can do about this. You can't store sensitive information on the binary you are sending to people if you want them to be able to use the sensitive information. You could say, encrypt it, but then you have to give instructions for the computer to decrypt it if you want them to be able to use it, or else the encrypted info is worthless and you might as well not include it. The only way to protect information while still allowing people to functionally make use of it on their computer is to not send it to their computer for execution by the computer.
On the other hand ... I no longer waiting 5 minutes to update a small 500-line dependency to the latest version, so there's that.
&gt; flexibility Go has never really been about that kind of flexibility. Using a `src` directory isn't very standard in Go (unlike C, or Rust).
You can use `-mod vendor`.
by default.
When running a main package with more than one file, all of the files in the package need to be provided. See this related stack overflow post: [https://stackoverflow.com/questions/23695448/golang-run-all-go-files-within-current-directory-through-the-command-line-mul](https://stackoverflow.com/questions/23695448/golang-run-all-go-files-within-current-directory-through-the-command-line-mul)
k
I don't understand. Maybe this affects cold boot builds, but what's the point? The cost you avoid is accessing the disk once, since clearly your system must have enough memory to keep your code &amp; artifacts in its disk buffers while also running the compiler (otherwise, your compilation would fail while the RAM disk is allocated). However, you're not really removing that cost, your just hiding it in your rsync. And the cost for that rsync is at least as bad as reading the files from the disk, since it does read the files from disk AND copy them to another memory location. I don't think you're really going to gain anything, at least on Linux, since Linux uses all of the unused system memory for disk buffering, effectively avoiding (synchronous) disk access for anything but the first time build your code anyway.
You can give [ImDisk Toolkit](https://sourceforge.net/projects/imdisk-toolkit/) a shot to create a ramdisk on Windows.
Awwesome! Thank you for the link.
No, the two of you suck ass at comprehension. Here: The comic is about generics in **golang**. What solution (to a problem in **golang**) do generics present? Especially when you consider tools like closures. I mean seriously
Yes, better do the type check, before type coercion.
It's worth noting that you don't want to *embed* secrets into the environment. That is to say that I, as someone naive and learning, definitely thought that the correct approach became to embed secrets in my docker containers using environment variables. This is also not very safe, as anyone who has access to your image can probably get access to your environment variables too. The safe approach is to use a secure key store and have the environment variables injected into the container/service at runtime.
I wonder what happens if you happen to go-getting from a repo in a private network.
I don't even understand this argument? You would add it locally and source it locally, exactly like you do with the standard library. Exactly like C does it.
[removed]
[removed]
[removed]
http://go-database-sql.org/ (https://github.com/VividCortex/go-database-sql-tutorial) could use a section on using context.Context.
Why are people downvoting you?
No secret downsides. What you gain in convenience you lose in the ability to update static assets without updating the binary, etc. If a single binary is convenient for your deployment needs then go for it.
I don't know mate. I am fairly new to reddit. I am unable to figure out why I am getting down voted. I asked this question which I thought people on reddit can help. I am indeed getting help but with downvote. I guess this how it works here.
Itâ€™s not common. You didnâ€™t say anything wrong as far as I can tell. For what itâ€™s worth I think youâ€™re a quality individual.
Seems like everyone in this comment section who has used Go extensively thinks it should have generics
The number of people who seemingly disagree with you is crazy. The lack of guaranteed reproducible builds should have given any engineering manager a pause before adopting it.
I recommend you https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831
ah-ha! you're assuming the secret is ever decrypted! What if the OP is simply embedding a family secret hot sauce recipe in a popular image editing package so that it can never be lost as long as those with the 32 byte key memorized keep their minds sharp!?
Just tried it original size of testbin.exe was 7 MB upx.exe --brute testbin.exe after compression 1.8 MB cool!! also, can't see the sensitive info. But, i don't think its difficult to get it back as per iends comment.
One optimization that a frontend like nginx will do is use gzip content encoding, which many of the asset-bundling packages don't do. Can often be solved at the CDN layer or by fronting your app with nginx, so usually not a big deal. However, my favorite asset bundler supports this as well as storing the contents gzipped: https://github.com/shurcooL/vfsgen . Side note, the way vfsgen leverages the http.FileSystem abstraction is brilliant (see the author's https://github.com/shurcooL/httpfs package too, which mimics many of the useful tools the stdlib provides for working with files, but for working with http.FileSystem instead).
From my experience when files are large it can slow down compilation by a lot.
People downvote for a huge number of reasons. It can be personal "I dislike you" or a statement about dislike "I dislike what you said" but in technical subs, I tend to think it means, "this isn't my preference" or more helpful "this isn't the better technical solution". It's best to never take it personally because it's such a rough binary piece of communication. In this case, I think you are being downvoted because you're stating something that I think people are pointing out is technically not useful. If you have a secret that needs to be used by the application, then the user that can run the application (and maybe just the user that can view the application) can access said secret. If that isn't the case, then the secret can't be used for a connection string, product key, etc. Now, you could encrypt a key and decrypt it outside your application, but if you do that, then the outside application might as well have done what you needed already. There might be other solutions to what you're trying to solve. It depends upon what you're trying to defend against. What type of secret do you have? What type of app? Server, cli or desktop app? Of the people who use the app, who is trusted and who is not? What are the maximum consequences of the secret being stolen and abused?
I'm using an Optane SSD for my development drive and compilation is pretty darn fast. It's not quite as fast as DRAM but it's about an order of magnitude less latency that a traditional NAND SSD. &amp;#x200B; [https://www.intel.com/content/www/us/en/products/memory-storage/solid-state-drives/gaming-enthusiast-ssds/optane-900p-series.html](https://www.intel.com/content/www/us/en/products/memory-storage/solid-state-drives/gaming-enthusiast-ssds/optane-900p-series.html)
[removed]
Create a makefile with the appropriate install and build paths and use *dpkg-buildpackage*
+1 Just setup vfsgen yesterday for a project that uses a small React front-end. Was dead simple to setup and use.
[removed]
[removed]
https://github.com/peterbourgon/ff
Don't store anything but the session identifier on the client (unless you encrypt/sign). In a simple example, you can store a map of your session uuid to a user struct on the server and retrieve the request's user by doing a lookup with the cookie value. In practice, you'd probably want to store the lookup table in a key value store like redis or badger (embedded kv store).
k
40% faster than 1 second. thank you for all your hard work!
Thank you very much! Very helpful article.
My own https://github.com/christophberger/start uses a hierarchy of config sources: flags, then env vars, then config file, and finally default values in the code. However, the priority is fixed, so YMMV.
Yeah, as long as you are the only one building it. Once someone else wants to build it and they canâ€™t, then you get the left-pad npm fiasco. I know the go community is better than that!
Mostly this. Iâ€™ve had a little trouble with tears and load paths not lining up. My solution was just to run packr before running tests (via make task), although it probably wouldnâ€™t be hard to put some logic in to adjust the root up a directory or two in test mode. Honestly, the convenience of single binary deployments has more than outweighed this one tiny bit of extra complexity. I put packr in, sorted out the test issue, and havenâ€™t had to think about it since. Itâ€™s Just Worked&lt;tm&gt;.
Right because Russ fucking Cox himself doesn't properly "understand the issues" of designing a programming language. Is this blog post satire?
is that the normal convention for doing sessions and logins for most web apps? I have a database in mysql containing the users signup information and a uuid to identify the user and I have it so when you signup it creates the sessionID cookie which is also a UUID
my db is based off uuid instead of auto inc so are you saying it would be fine for me to store the UID in the sessionID cookie since its random? Also how would I go about a db sessions table?
the part im getting lost in is the whole database storage concept, I have my users in a mysql table so should I make another table called sessions and it would have a sID and hold a uID?
I gave it a shot two years ago and I just couldn't make it work. The docs/UX was just too immature, I couldn't get anything done without having to read lots and lots of source code and talking to people in the #nix IRC channel on free node.
Start developing back ends for other things outside of games and work your way in. This might mean working for a website or mobile app. Try to find a company that deals with a lot of customers and has a lot of scale.
[https://github.com/spf13/viper](https://github.com/spf13/viper)
ANything can be intercepted but that doesn't mean you don't use the better option. Environment variables are a better option that hardcoding in binary, not just for security reasons but also to ensure that one has nothing to do with the other necessarily. Think about this. Just because you are updating a secret in the code, are you going to recompile the binary ? Why ? What if your binary was large ? Just use Environment variables for all secrets. I suggest using something like godotenv library [https://github.com/joho/godotenv](https://github.com/joho/godotenv)
Well by just a glance don't put goroutines inside goroutines and I would leave defer out of the for loop. In general for simplicity separate the logic out of the goroutine and just call it inside. You get a better idea then of what you are waiting for and what you are sending.
Yes, it's the normal convention.
I have experience with web apps.
&gt; 1. You can't vendor non-go code (e.g. proto files or templates) Vendoring is not really needed with modules. Caching proxy is everything you need â€“ it solves availability problem. &gt; 2. You need to use a tools.go file to vendor tools which is kind of weird. Again, you don't need vendoring with modules (caching proxy blah-blah-blah) &gt; 3. Private repos are really tricky to use. No way to override http to ssh Private repos are to be used via their APIs and go modules proxy. Authorization data can be stored in basic auth params. We do something like `export GOPROXY=https://&lt;user gitlab token&gt;@gitlab.company.org` to have authorized access. You can look at ready to use components and usage sample at https://github.com/sirkon/goproxy.
Thanks for the tips. Can you make me a little example based on my problem? Thanks
Proxies are composable: just set up your own caching one delegating to remote proxy on misses.
dep is nearly useless: you can replicate its work with list of dependencies and bash.
In the Kafka example, you have the producer as the variable â€œpâ€. You probably want to pass that to your gRPC handler function. You then pass the gRPC data to the Producer as in line 53 of the Kafka example, once itâ€™s been received by the handler. Worth bearing in mind what format you want that data in. Should it remain in the â€œrawâ€ (binary) protobuf format, or do you need to marshal to JSON first? Depends what your consumers are expecting.
YES!
Would I still need the results channel? I'm fairly new to Go, so the way I interpret doing this method is initializing the jobs channel with the strings of urls, then calling the for loop that invokes the goroutine on the worker function. Inside the worker function is where I am confused. Would it just be a for loop where inside is just the steps to download a single file? i.e. func worker(jobs &lt;-chan string) for j := range jobs { // download image here // j = current url string }
Yep, just your opinion 1. It solves it by introducing another peace of infrastructure. That's one way of solving it but not the ideal one. It introduces additional complexity just for the sake of it. And frankly, caching proxy is not the solution to availability. It solves completely different problem - ability to request dependencies faster. Availability through caching is just a by product. And it doesn't work at all when you don't have caching proxy. For example, when your customers requirement is to be able to build application just from source. Asking them to install caching proxy populated with all the dependencies is not a solution. 2. It's not supposed to work for libraries. Vendoring is for applications. That is a hard fact that was always known. 3. By that logic same with go modules because they work pretty much exactly the same. They read dependency list, give it to some kind of solver to produce dependency tree and clone it from git either by commit hash or tag. Of course, contrary to what you're saying, both dep and go modules are a bit more complicated than that. But in the end you can get by perfectly will with just git modules. Latter solves exactly the same problem - reproducible builds with version tracking. It''s just not very user-friendly.
I would recommend "Designing Data-Intensive Applications" book and some videos from "Battle(non)sense" youtube channel.
Vendoring with go modules works completely different from vendoring before. Why? No justification was given to that. Go modules requires you to enable vendoring manually - not good. Go modules can silently break your builds or worse. On local machine Go will happily ignore vendor directory and build from source cache. The moment you push changes to CI you get problems because Go modules don't sync vendor directory with your dependencies. Again, you have to do it manually every time. &amp;#x200B; When UX is that bad you can say that it doesn't work. That's why for many people these issues are blockers, me included. I will not switch to go modules until this is fixed. Hopefully, in 1.14. Until then, dep it is.
Just your opinion, mate. I don't want another piece of infrastructure that I will have to drag everywhere I want to build my app just to solve a simple problem of vendoring your dependencies.
I used to work in the back-end team for a game studio, and we basically did everything described in this book [1]. You may also find this one [2] quite illustrative. Building a server for a multiplayer game is not much different than building the back-end server for a high-availability and distributed software, so if you read books around these two topics, youâ€™ll be good to go. Also, read a lot about UDP, youâ€™ll need this knowledge, I can assure you. [1] https://www.cs.cmu.edu/~ashu/papers/cmu-cs-05-112.pdf [2] https://pdos.csail.mit.edu/archive/6.824-2005/reports/assiotis.pdf
Repo is gone but my vendor directory is committed with the rest of the source. Problem solved. Caching proxy is a bonus piece, not the solution. Especially when we're talking about [proxy.golang.org](https://proxy.golang.org) \- it has the same problem as github. You can't depend on them if you're really serious about being able to build your apps anytime you want. &amp;#x200B; Vendoring is not supposed to work for libraries. But dep works perfectly. Just don't commit vendor directory.
I use RiceBox. Is there an advantage to using packr?
I used to follow their channel. They are great. I will be getting a hard cover of the tomorrow. Thanks.
That's quite a find for me. I guess developing gaming backends are harder than I thought.
Pls donâ€™t shoot me down on the env topic. I know I can use env variable, but I missed to mention that it canâ€™t be used effectively in my scenario because this program has the capability to run a script. So, I can easily run a command like : Mytestbin.exe thisscript.ps1. Now, thisscript.ps1 can have cmd.exe /c set &gt; allEnvVar.txt I hope this should make things clear. BUT thanks for all the info and sharing the go env package.
How ? Share with us. Was it hex editor u used?
The docs says /dev/shm might not always be present, while /tmp is - from my experience - always mounted as tmpfs now. I'd go for /tmp then.
/tmp is a directory exactly for things like that, minus the advantage of setting a size limit. Both is possible, it's just I don't think the benefit of having a separate mount point is big enough to justify its use. &amp;#x200B; Anyway, thanks for the article :)
Thank you!!
You can make text harder to extract from an executable, but anyone good at reverse engineering will be able to get past your measures anyway. It's a silly game to play, and doesn't add much (if any) security to your application. Important sensitive info shouldn't ever be seen by a user's computer.
I suggest you learn a couple of more years if you believed backend software engineering was easy.
Have you developed backends for any other type of system?
Thanks for sharing. I may read this out of curiosity.
https://tech.townsourced.com/post/embedding-static-files-in-go/
Mostly REST APIs
It's not xD
That's not the point of the question
Maybe you could use AWS game lift? It's still not any easier, you wouldn't have to worry about automatically scaling and having the computer resources as much.
Rust before 1.0 had frequent breaking changes.
As does pretty much every software pre-1.0. I believe cargo has been around since 1.0 or slightly earlier.
I fully agree that slices in Go leave plenty to wish for, so much that I routinely reject the language for problems involving lots of transformations. Or choose less elaborate solutions. Which I suspect is sometimes an advantage but I reject the idea of needing a language to constrain me, I prefer dealing with my biases and learning from experience. I went the other way and built a Lisp (https://github.com/codr7/g-fu/tree/master/v1) on top of slices, with transducers (https://github.com/codr7/g-fu/blob/master/v1/lib/iter.gf). Transducers is one of those ideas that makes you scratch your head and wonder what took so long; if it hasn't clicked yet, I strongly suggest trying until it does. The general idea is to chain the operations instead of chaining the process of applying them one at a time, which decouples the sequence type being transformed from the operations and means less busywork and intermediate results.
Great article. Thanks!
I wrote this up on Medium: [Go Modules with Private Git Repos](https://medium.com/cloud-native-the-gathering/go-modules-with-private-git-repositories-dfe795068db4) &amp;#x200B; We use the &lt;user&gt;:&lt;auth\_token&gt; url format to access private repos. The SSH suggestions are also obviously quite valid, I just found it more difficult to debug issues when they came up.
Yeah, exactly
&gt; 3. â€¦ No. Because modules are not meant to work via VCSes directly. They are working via some `$GOPROXY` and some (like https://proxy.golang.org which will be enabled by default since 1.13) will have a once requested package forever. You have no such guarantee with dep.
These wrappers add no value.
"Oh look we're concerned about having to maintain these moving parts and the difficulty it puts on our build infrastructure because we don't have dedicated teams that maintain this infrastructure" "Oh just add more moving parts"
I would very much recommend using a bundler that can zip your resources to the end of your binary rather than one that compiles them in. Go-rice does this and has a tool that scans your source for references and builds the zip file for you. Rationale: doesn't slow compilation or static analysis. It also allows you to just run `unzip` on a deployed binary to list the files or unzip them.
Are you talking about handling the parameters from the Go http handler (backend) side, or how to pass them from the front end? If it's the latter, that really isn't specific to Go. So you are likely going to find plenty of tutorials if you search generically for making GET and POST requests from an http page front end.
Thanks for the clarification! Yeah what I actually want is how to pass them from the frontend, I'll do more googling on that ðŸ˜ƒ
If you store the actual user ID youâ€™re no longer using a session, youâ€™re just using a cookie to store actual data on the client. This is all dependent on your app and how you implement security, using a session allows you to keep data (such as a user ID) on your server and only expose a session ID which you can revoke at will. For example when a user logs in you create a session ID, add it to a sessions table along with the users ID and then when your app gets a request with that session ID you can assume they are the logged in user. When they log out you delete the session row and that session cookie becomes no longer valid. I suggest doing more research into cookies vs sessions, try searching YouTube for a login session tutorial.
There's been [an issue](https://github.com/golang/go/issues/19282) open for it for a while now. I've seen a few people working on it in IRC before, but most people seem to just give up. If I'm being honest, Go plugins aren't really in that much of a workable state in Linux/MacOS either; [this](https://github.com/golang/go/issues/20481) issue causes a lot of problems in real-world situations I've tried to use them. (That issue doesn't only affect environments with bundled dependencies, but also prevents you from building plugins in different GOPATHS than the host, IIRC) In general, you might be better off using one of: - an embedded scripting language - building a go plugin as an executable, having the host run it, and communicate with it using stdin/out
True the two interfaces could be two structs instead pkg/flag exits on parse by default https://golang.org/pkg/flag/#pkg-variables Heh artisanal? Frictionless in that out gets out of the way. Opts is quite magical though no more magical than pkg/Jason No, adds an "--un/install" and only adds the short flags if unused Agreed the shell completion library I'm using https://github.com/posener/complete is a bit blunt with its install method.
I want to add WASM as a more and more viable option here.
[removed]
Closed already. Bummer. &amp;#x200B; I do think "megabytes and disk IO" is a bad argument. 1. Computers can have TB of RAM nowadays 2. The compiled script is cached 3. Down the road, someone could make the compiler more efficient (i.e. not use temp files in simple cases), or make a JIT compiler. 4. Many temporary files never even hit the disk. (Linux will wait a while before writing dirty pages, and if the file gets deleted in the meantime, the disk never hears about it.) &amp;#x200B; People nowadays run git and kubctl as part of their command-line prompt, so I don't think it's a big deal to have Go scripts.
I completely agree with Rob Pike on this one. There is no point in making Go scriptable. Just build your binary and place it the same place as the script would be. Done. And now you donâ€™t have a dependency on any form of compiler. You donâ€™t need to worry about grabbing dependencies. Instead, you can just package that single compiled executable, even on a system without Go installed.
I donâ€™t see a case for why you canâ€™t compile a binary and just drop it in the same place. Why does it need to be a -script-, which has dependencies all over that can be fragile, when you instead could have a stable binary with no dependencies?
Jquery post has an example at the very bottom showing how to collect multiple form values and make a custom request: https://api.jquery.com/jquery.post/
That is a point that I don't see anyone making, that is pushing for scripted execution behavior. I've never used `go run` for anything other than hacking on a single test program for a quick result check. If I wanted to reuse anything I would want to have a packaged binary containing all the linked dependencies. An issue posing this feature should make a real case for why its important. Just because other languages do it isn't a good reason. And I don't even think it's worth mentioning dynamic languages in the list anyways since it is their native mode of execution to run through an interpreter.
Hereâ€™s some starting points. https://github.com/gen0cide/gscript/blob/master/compiler/obfuscator/stylist.go
\&gt; People nowadays run git and kubctl as part of their command-line prompt, so I don't think it's a big deal to have Go scripts. Those are both compiled binary programs. How are they supporting your case for scripted Go programs?
Use nm
Stop writing malware
Glad to hear you agree but him closing the issue without even responding was very abrasive. &amp;#x200B; It's a script, it's not an application running in production. Scripts are usually used for development and in such a case, a dependency on Go is not a big deal. Devs can already abuse \`go run\` for these purposes if they really want to, I don't think they'll abuse \`gox\` much more. &amp;#x200B; You can still build it as an executable if you really want. But it's clear there are devs that enjoy the localization of code with the executable for development/workflow scripts so I think the convenience is warranted as the cost is now very low.
The easy way to kind of solve the issue is to just write one in Go. Basically just make a wrapper binary that does just run similar to an interpreter. If it gains traction, then it could be moved into the main code like go modules are. But I donâ€™t see the benefit. Running a go install puts it in your gopath. So if itâ€™s only on a development system as you say, it will already have the gopath in the environment.
What a useless proposal. I guess author should sponsor someone on github via github sponsors who can fork Go and deliver this feature. Author should be able to find some dev would be happy to do this work for $10.
Does this not solve your problem https://blog.jessfraz.com/post/nerd-sniped-by-binfmt_misc/ ?
TL;DR: This is a story about how I got nerd sniped by a blog post from Cloudflare Engineering. The TLDR on their post is that you can script in Go if you use BINFMT_MISC in the kernel. BINFMT_MISC is really well documented and awesome. In the end, all they had to do to script in Go was to mount the filesystem Jessie Frazelle is awesome.
&gt; I appreciate you continuing the discussion. Rob Pike closing the issue without even responding was very abrasive. I understand how Rob's comment comes across as abrasive, but try to understand things from his perspective. People like Rob have been doing this for a while, and from his perspective a lot of these discussions have a "not again" feel to them. People post proposals all the time, and many have been discussed before. Re-visiting them every time with a detailed discussion would be *extremely* tiresome. It's just not possible.
It's useful for code generation too: `//go:generate go run gen.go`
\&gt; building a go plugin as an executable, having the host run it, and communicate with it using any arbitrary RPC system over stdin/out &amp;#x200B; Here's \[hashicorps implementation\]([https://github.com/hashicorp/go-plugin](https://github.com/hashicorp/go-plugin)) of plugins using RPC over stdin/out
https://github.com/erning/gorun Isn't that enough? I honesty never though of using go that way, the very fact that I can produce one binary, deploy it anywhere that matches the architecture and "it just works" is why I'm using Go to begin with and not perl or python. I don't need to care which version of the interpreter is on the server or in which version.
[Niklaus Wirth](https://en.wikipedia.org/wiki/Wirth%27s_law) would like to have a word with you.
It *is* possible to be brief, but friendly. Or at least polite. Several of the top Go developers comes across as complete douchebags because of the way they communicate, including Rob Pike.
To quote Neil Gaiman when talking about A Song of Ice and Fire fans demanding George R.R. Martin work harder on the next instalment of the series: â€œ[George R.R. Martin is not your bitch](http://journal.neilgaiman.com/2009/05/entitlement-issues.html)â€. I feel some community members are similarly entitled. Rob Pike is not your bitch, and he doesn't need to go out of his way to justify rejecting a proposal that has been discussed several times already. [The Hard Parts of Open Source](https://www.youtube.com/watch?v=o_4EX4dPppA) by Elm's Evan Czaplicki is a pretty good talk about this. Could Rob be friendlier about it? I guess. But I think you underestimate the amount of effort it takes to be "friendly". It's certainly a lot more effort than merely marking it as duplicate. There are 1 500 issues marked as "Proposal", and many more on mailing lists etc. If we want to point fingers about who is "rude" or not, we could also reverse things and claim the OP is "rude" for not taking enough time and effort in understanding the reasons and perspectives about why it was rejected in the past, and creating *yet another* useless proposal (this is not my viewpoint, but I don't think it's any less valid than "Rob was an ass by just closing it as a duplicate").
This proposal will mean than instead of typing ` go run script.go ` one will have to type ` script.go `, remember to make the go file executable, and then add the extra burden for the Go maintainers to support the special shebang comment in Go files, not to mention other tool authors. Because otherwise there's no real benefit to it. Correct? If the amount of typing needed is the concern solved by this proposal, then how about using a shell alias like ` alias g=go run ` then type ` g script.go `, which will save an extra 4 chars leaving the rest at an extra 2 chars compared to the shebang changes?
I don't understand this problem. The path to the plugin is a parameter. So it's the app responsibility to lookup for plugins in the different paths. Vendor, etc.
[Never parse HTML with regex](https://stackoverflow.com/a/1732454/71964).
[removed]
Your exactly right as the others have said, if you donâ€™t expect much traffic, or a need to scale in the future you will be fine using the database to store sessions. On the flip side, you will want to use the likes of Redis to store sessions.
I also highly recommend to check out https://vincent.bernat.ch/en/blog/2016-pragmatic-debian-packaging This is not specific to Go, but it provides a pretty good overview of the packaging process.
[removed]
Thanks for this link
Nice. Looks like the .filter(), .find(), .pop(), .push(), .splice(), .shift(), .unshift(), .indexOf(), .findIndex(), .forEach() (...) array methods of javascript :) Maybe strip of this "Fp" from the method names, because they are not neccessary to understand what the method does i think. (what does Fp stand for?) I think i will give it a try when i came to the point i need functionality. :)
Much like your comment.
Hopefully genetics make libraries like this easier to implement with a more ergonomic API
I also wish Go had functional options available. Your library will make it reasonable to use Go for data wrangling (eg. ML) applications. Will make myself acquainted with your library and maybe see if I can use it in a project :)
Those papers looks old and a bit different from reality, also backend is a very generic terms, backend is more online services ( auth, player persistent storage, matchmaking, leaderboard, chat, ect ... ) on the other side you have the game server which is basically the engine stripped out of rendering.
&gt;Also, bitmaps tend to be \[\]uint64, so they're totally slices ;) I use them a lot in my studying of game theory lately. But I've never used them in a slice. Nor did I when I wrote a few chess engines. So I think that's more of a personal preference / project requirements
Where are those asm optimized features in the stdlib?
``` code blocks donâ€™t work on Reddit. You have to indent code blocks by four spaces.
fp = functional programming
TouchÃ©
&gt; Rob Pike closing the issue without even responding was very abrasive. He _did_ responded. He give the full, complete and sufficient reason for closing. Everyone can see his response: https://github.com/golang/go/issues/32242#issuecomment-495819327 Why are you saying he did not responded? Also, filling a proposal for something that has been already proposed and rejected is just rude. Reconsidering rejected proposals _is_ fine. But that should go to the appropriate mailing list and iff there's a clear agreement about reopening _then_ the original issue may be reopened or a new one filled if that's more appropriate. (But generally dups are not welcome anywhere.)
A better URL: &amp;#x200B; [https://github.com/codr7/g-fu/tree/master/v1](https://github.com/codr7/g-fu/tree/master/v1)
I appreciate the code example. Perhaps I missed it, but where is the web server getting notified of a client's request drop?
My company has several services that were created by new gophers who didnâ€™t understand how context works as a propagation mechanism. Weâ€™ve used context as a place to conveniently store and retrieve things during requests and such, but thatâ€™s it. These services have grown quite large (an issue for another day), and suffer the burden of unwanted processing and data errors that stem from a cancelled/expired upstream context. The lesson is that this is definitely not something to be bolted on after your service is mostly built.
Learn to write solid code. I work on a backend team for a large online game and we hire the best coders we can find regardless of previous gaming experience. If you want to spend a career solving problems with codeâ€”and you hone your skills through experienceâ€”then youâ€™re on the right track.
I think I added Fp because there was a name collision or something like that. I might be wrong and will update that if necessary.
I think that ( and I am not very sure because I have been struggling to learn in depth how the context package internally works ) when client cancels the request , the server receives context cancellation in the ` ctx.Err() ` . My reference here is a video by Francesc Campoy [here](https://youtu.be/LSzR0VEraWw?t=1136)
# Hey sorry if the code is all messed up because inline code doesn't work in reddit . # You can see all the code in this Gist [https://gist.github.com/ahmedaabouzied/ab0ac6259c2f13bb29a764207ebc734f](https://gist.github.com/ahmedaabouzied/ab0ac6259c2f13bb29a764207ebc734f)
Inline code works just fine, you just don't know how to do it. package main import ( "context" "encoding/json" "fmt" "io/ioutil" "log" "net/http" "time" ) type ResponseCast struct { Status string `json:"status"` TotalResults int `json:"totalResults"` Articles []Article `json:"articles"` } type Article struct { Author string `json:"author"` Title string `json:"title"` Description string `json:"description"` Url string `json:"url"` ImageUrl string `json:"urlToImage"` PublishedAt string `json:"publishedAt"` Content string `json:"content"` } func getNews(ctx context.Context, link string) ([]byte, error) { request, err := http.NewRequest(http.MethodGet, link, nil) if err != nil { return nil, err } request = request.WithContext(ctx) resp, err := http.DefaultClient.Do(request) if err != nil { return nil, err } defer resp.Body.Close() a, err := ioutil.ReadAll(resp.Body) if err != nil { return nil, err } return a, nil } func (c *ResponseCast) parseNews(ba []byte) *ResponseCast { json.Unmarshal(ba, c) return c } func getArticles(ctx context.Context, cancel context.CancelFunc) []string { resp, err := getNews(ctx, "https://newsapi.org/v2/top-headlines?country=us&amp;apiKey=&lt;API-KEY&gt;") if err != nil { log.Printf("Context Canceled") cancel() } c := new(ResponseCast) r := c.parseNews(resp) var t []string for i, article := range r.Articles { t = append(t, fmt.Sprintf("Article %d : %s \n", i, article.Title)) } return t } func main() { http.HandleFunc("/", handler) log.Fatal(http.ListenAndServe(":3000", nil)) } func handler(w http.ResponseWriter, r *http.Request) { ctx := r.Context() ctx, cancel := context.WithTimeout(ctx, 2*time.Second) log.Printf("Handler Started") defer log.Printf("Handler Ended") art := getArticles(ctx, cancel) err := ctx.Err() if err != nil { fmt.Fprintf(w, "Time out error \n") } else { fmt.Fprintf(w, "%v\n", art) } }
Each to their own.
Not sure, but maybe also add to your reading list: [https://www.alexedwards.net/blog/configuring-sqldb](https://www.alexedwards.net/blog/configuring-sqldb) &amp;#x200B; Love to know if Golang is a good replacement for you, coming from PHP...
Global variable is not a bad idea tho it's also not the best one just because global variables are not the best thing. Yet there is nothing wrong with it for, let's say, the eally small application. You dont have to close the pool, nor the connection.
I love this just for its apparent silliness. What motivated this effort? Also, do you have any docs for the language + stdlib? Or perhaps instead of a stdlib is has the ability to call go code a la Clojure + Java?
With regards to `getArticles` error check block, why not `return` after `cancel()` ? Seems to me that `parseNews(nil)` would crash, after you exit the error check block
PHP for 10+ years including as lead dev, architect, etc. I believe I wrote fairly elegant PHP (lol). My languages after that would be javascript, python, bash. Been messing w/ golang for 4 years but I'm seriously developing something with it now. I love it.
I can't wait until it will finally be possible to create library that will let you do stuff like `find` or `map` with a slice in a type-safe way.
I use that package. I usually have a struct that contains the server configuration and state (including `http.ServeMux` and `http.Server`). One of the fields is the DB. I then instantiate the struct in `main()` or a command handler function and start the server by calling one of its methods. As you keep around the db connection for the lifetime of the server, you don't have to close it (the OS drops the connection after the program exits), but it is nice to do it. I would usually implement a `Close` method in the server and defer it before starting the server.
https://github.com/nytimes/gziphandler
&gt; I've been developing large scale web applications using PHP for several years What is *large scale* in PHP those days? (and I am not talking about facebook case) I am curious, touched PHP last time like 10 years ago.
Nothing silly from my perspective. Go makes a great foundation and nothing beats Lisp as an extension language. Calling Go directly requires some kind of FFI or compiling to Go, both are possible moving forward. For now, you need to explicitly let g-fu know about host functionality. It's also a potential sandboxing issue, which is a common use case for embedded languages.
Well in my case I just mean web applications that thousands of users use each week. Specifically I maintain a site that allows users to capture and stream live video, with chat rooms etc.
Is there a way to call into Go code from this?
It shouldn't be reasonably possible if you're setting thing up the conventional way. If you're writing a program that's supposed to be started at boot or started automatically at some point conventionally you'd use the init system (on Linux nearly always systemd) and you'd feed sensitive values to that program through the init system using a secure means it provides (ex: systemd has the `EnvironmentFile=` directive which will let you specify a file that only the root user can read, and all the environment variables in there will be passed into your program and not reasonably found out by any non-root user on the system.)
Do you ever plan on testing the code that uses it? If there is even a slight possibility of future tests, then forgo global singletons
I'm not as familiar with Windows but I really, really hope Windows has a way to let you spawn a subprocess without it inheriting your env. A quick Google suggests that [CreateProcessA](https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-createprocessa) has an argument `lpEnvironment` which allows you to spawn a new process with an environment of your choosing (so you can just make an empty one).
Seconded. It's a pain in the butt trying to stub out DB connections or set up automated testing if you use a singleton. If you must have a singleton, just make it own an instance of your DB connection pool. That way you can sub it out for something else, or test the DB connection pool separately.
[removed]
I do plan on testing. Thank you!
[removed]
[removed]
[removed]
Not sure what the gain is to use keywords for things that has well known keywords in most lisp's already. It seems like you use `mac` instead of `defmacro` and `fun` instead of `defun`. To me this seems wasteful forcing people to remember yet another set of keywords that does the same thing as the ones people are used to.
Iâ€™m pretty sure the only reason youâ€™d want to pass a pointer to a slice is if for some reason you might need to overwrite the slice itself. For example JSON unmarshaling requires a pointer, so that it can replace the slice after deserializing the data. Iâ€™ve never actually needed to do this in my own work, and in fact have had to fix other peopleâ€™s code that had issues due to passing of pointers to slices.
Before it became a religion, Lisp used to be a tool. It doesn't work, you can't redesign parts of a language without dragging the whole thing along. Well you can, but its called JavaScript. The reasons for the names Common Lisp chose are complex and involved a lot of politics, there's nothing sacred about them. Lispers with eyes to see and control over their minds will see what's really there. Non-lispers get an easier time by not having to memorize endless exceptions to vague conventions. The last group is too busy arguing about these things to go anywhere and is best left alone mumbling in a corner.
It's not just common lisp that uses those names, my point was that it's the most common words among all lisp dialects I know. If I pick up any new lisp dialect i'm going to try defun before anything else just from muscle memory. Also the `def`-prefix serves to communicate what the purpose is (to define something).
A guy from Monzo did an in depth talk about how they used context including your use case in the April London golang meet-up, you can watch the recording here : https://youtu.be/GhRG_7X4BPI
I get it, and there's value in keeping with traditions. But its not the only priority, or even the top. g-fu does use some standard keywords, like `let`; but only where it makes sense from a whole system perspective. It's the first things you'll learn; bindings, functions and macros. And you'll use them everywhere, all the time. Descriptive names doesn't make much sense in that context. Another reason is that they are different. `fun` doesn't define anything at the top-level like CL; the same keyword and runtime logic is used for lambdas, which are really functions without names. They also return values, `fun` and `mac` return the function/macro, which may then be passed around or bound to an identifier by the caller.
I second this, viper with cobra is a great combination.
No
Scheme uses `define` and `define-syntax` and is all the better for it.
I mean, its an interpreter for a programming language and I kinda want it to be cross platform.
Think map (walk) over tree (e.g. filesystem or web links) and collecting results into slice. You could make a point for returning slice. I tried and pointer slice was subjectively better in one real task. ` func into(x *[]T) { for ... { *x = append (*x, next) into(*x) } } `
Ok, I kinda see, but why does unmarshalling JSON require overwriting the slice? Also, what kinds of complications can arise from passing pointers to slices?
[removed]
Wouldn't appending to a copy of x do the same thing? Ultimately you're just storing values in the underlying array, aren't you? Are you somehow limited by the size of the underlying array?
You should really double-check your theory about functions taking up memory.
https://stackoverflow.com/questions/21735407/do-functions-occupy-memory-space
[removed]
\&gt; Plugins are buggy Care to elaborate? I've used them quite successfully in the past. &amp;#x200B; \&gt; CGO Shared libs are expensive The typical 70ns/op sounds like a small price to pay for what you're asking. &amp;#x200B; As another approach, what about one of the several Lua VMs for Go? [https://github.com/Shopify/go-lua](https://github.com/Shopify/go-lua)
It's more to manage. (i.e. at the very least, you need 2 files, when a script is just one.) Plus you have to manage having the program out of sync with the source code. In a script, that can't happen. It also makes more steps (from "edit + run" to "edit + compile + run". That's fine if you only use Go, but it's a big change for those coming from Javascript, Python, Ruby, Perl, etc.
[removed]
Answer number two on this question says they donâ€™t take up space. Have you come to the same conclusion?
You have a strong entitlement to other people's labor. It doesn't exist because nobody has implemented it.
Define prior assumptions. :-) Scenario 1: Declared fixed size array, then sliced it with `[:]` and appending to slice to have more fun. Yup, still can access array, using slice instead of explicit index/length pair. Scenario 2: `make([]T, 0, guesstimate_upper_bound)` you only have a slice to begin with. Pass pointer around, it gets reallocated as needed. Again, function argument of *[]T and return value of []T could compile to exactly same instructions. It's a matter of idioms, compiler smartness, programming culture.
&gt; I do a lot of work offline and want to make sure all dependencies are available when I have no network connection Run `go mod download` before going offline.
Plugins don't work on windows. Ps I have followed the issues on github on plugins and it seems that they won't be updated anymore, they don't fit well with the way golang and the runtime works. I could use CGO but you lose the ability of cross compilation and compatibility with it.
I think you need to apply some engineering principles here. Instead of saying â€œx is expensiveâ€ and potentially repeating some dogma, actually measure and do the calculations? What is the exact memory and cpu cost? How many iterations or items do I have to process? Whatâ€™s the total cost then, and can I live with that? You can do something thatâ€™s 70ns 10 million times before a human can notice it.
What does the top answer say? If you didn't know your code occupied space then don't bother replying, I asked for help not debates. Please move forward with life.
That's actually right, maybe I should rethink this situation...
Another reason would be memory management. Not sure what the slice contains, or its length. Better to reference the slice by pointer than passing copies of the entire thing, if you're able to.
You may not know how many elements are going to be in the slice when unmarshaling it. If you pass in a slice to a function, you can edit the contents of the underlying array, but not change the capacity or length. So if you need to change any of that data, youâ€™ll need a pointer. The problem I had was a `*json.RawData` (which is actually just a `[]byte`), and I couldnâ€™t get my data into it. The compiler would not let me cast into that data type (or couldnâ€™t take the address of it).
Itâ€™s really only allocating three items on the stack: pointer to array, length (int), and capacity (int). So yeah, technically youâ€™d be saving two ints worth of memory (128 bits?), but Iâ€™m not sure thatâ€™s really worth it.
Er... It's literally the same thing: &amp;#x200B; **In the prompt, you have a script that shells out to several binaries that people run 100s to 1000s of times per day.** Shelling out to git to see the status of your directory may actually involve running SHA1 on all your files. &amp;#x200B; **In a go script, you have a script that shells out to the compiler binaries.** In fact, I'll contend that \`go run\` uses less resources than running some Perl or Ruby scripts. (Ever run `strace` on a Ruby script? It's not uncommon to read 1000s of files and do 10,000s of stat calls during startup.) &amp;#x200B; I'm just pointing out that "go scripting might encourage waste" isn't really a valid concern. They even admit they don't discourage people from doing it. (If you want waste, let's talk about how Google encourages people to spin up entire servers instead of using shared hosting, or the fact that checking Google email on a Google browser takes half a GB of my memory.) &amp;#x200B; So their only remaining argument is "it adds a tiny bit of complexity to the parser". I don't really have a dog in this fight, but I do think it would be good for Go.
 &gt;you can edit the contents of the underlying array, but not change the capacity or length. Just so I'm clear, you can't edit the length of the slice?
When passed by value to a function. Since it would be a copy of the original slice, if you append to it, youâ€™re changing the length (and possibly capacity) of your copy, not the original.
[removed]
My bad. So, referencing a slice doesn't copy the entire slice and its contents?
&gt;If I wanted to reuse anything I would want to have a packaged binary containing all the linked dependencies. Right, and that's more work. If you view Go as "a better C or Java", then you don't mind. But there are far more people familiar with scripting languages, who expect computers to be simpler. We constantly have to examine our assumptions. &amp;#x200B; It's easy to say "I'll just compile this binary and use the compiled version", but how do you prevent the source from drifting from the binary? How do you even FIND the source when you realize you want to make a change 2 years from now? Go doesn't have any tools for that (which is why people resort to "make", which is yet another tool to manage and even more to learn, etc.)
Actually, this answered my question: [https://stackoverflow.com/questions/39993688/are-golang-slices-pass-by-value](https://stackoverflow.com/questions/39993688/are-golang-slices-pass-by-value) Good to know, and you're correct! Thank you...
Well, itâ€™s not just two files tho. Itâ€™s the script, plus the interpreter. Plus all the library code. Plus all the imports. There is a lot there. If youâ€™re hacking away at something, go run works just fine. Thereâ€™s no need to make it directly executable. Hell, when Iâ€™m hacking away at Bash or other scripts, (even python), I usually call the interpreter directly anyways. As for source being out of sync, its not like youâ€™re going to just be installing it from a git repo direct onto the system. Shebangâ€™s are used in places where you put the file in your path. Either way, I think if you have a use for it, go for it. Write up an interpreter for it. It should be fairly straight forward to do. Then install that interpreter into the system path, and youâ€™ll be able to use it anywhere. You can then release it into various package managers, like apt-get, and yum. See if there is a utility and a market for it. There have been others asking for it, so you at least know thereâ€™s some interest in it. If it takes off, Iâ€™m sure Rob Pike will change his tune and include it into the main Go.
Oh right, of course. Thank you. Ok, just to make sure I'm absolutely clear on this: ` yourSlice = someValueReciever(yourSlice)` Is equivalent to ` somePointerReciever(&amp;yourSlice)` ?
Ok, I think I got it. So, I commented some code on the thread above: &gt; yourSlice = someValueReciever(yourSlice) &gt;Is equivalent to &gt;somePointerReciever(&amp;yourSlice) ? So, there equivalent, and one should use whatever is idiomatic? Just want to make sure I'm clear on this, because this seems important.
Basically yes, but the first one is usually preferred. You have to do some weird dereferencing in your function if you want to pass by reference. Some examples in action: [https://play.golang.org/p/e2OxlzS\_9C7](https://play.golang.org/p/e2OxlzS_9C7)
Yikes. Don't DIY. There are literally dozens of mistakes that you can make that will make your site vulnerable. "Broken Auth" is literally the #2 problem on the web according to [OWASP](https://www.owasp.org/index.php/Category:OWASP_Top_Ten_Project). Don't roll your own, use a library.
Thank you so much for your help
Here's a very common code structure I use in Go. type X struct { ChildList []*Y Field1 string Field2 int } type Y struct { OwnerX *X ChildList []*Z Field1 float32 Field2 string } type Z struct { OwnerY *Y Field1 string Field2 string } How could I create this in Rust and ignore ownership, lifetimes, memory management, etc?
If you actually bothered to read your own link, instead of attacking people, you would've seen that both answers are correct. Program code resides in the data section of the binary, and unless its currently running, it almost never actually resides in physical memory.
&gt;Jessie Frazelle is kind of the best. Not really, she has really bias feminist view. However, she is really good with computer stuff. Hey, nobody is perfect/best.
use a library for what? this didnt really point me in any direction but thanks
If you want to write an interpreter, which is a dynamic-type language, you gotta reflect anyway. So why not deal with dynamic-signature functions with reflect as well?
If you have the knowledge and experience â€œrolling your ownâ€ simple user authentication isnâ€™t that difficult. A trusted package would be good nonetheless.
No, if you donâ€™t know the size, use a slice. If you have an array, you can slice it when passing it in: `myFunction(myArray[:])`
&gt; If you have the knowledge and experience â€œrolling your ownâ€ simple user authentication isnâ€™t that difficult. Do you really think "most people" have the knowledge and experience to "roll their own"? (When most people hear that phrase, they assume they will be picking their own crypto algorithm, their own validation functions ,etc.)
&gt; Plugins don't work on windows. Fair, I'm fortunate enough to not have to worry about that. If that's your target platform, then I'd agree, plugins won't help you any. For other platforms, the issue you linked is mostly resolved by using go modules, after this was fixed: https://github.com/golang/go/issues/28983 &gt; I could use CGO but you lose the ability of cross compilation and compatibility with it. You can cross compile with CGO as long as your C compiler supports cross-compilation in addition to your target being a supported Go platform.
Aside from the authentication part, which you probably don't want to DIY, generally what happens is that you have a column in your database that contains a user_id and you key off that to get data related to that user. So, for example, you create a new user. When the user is saved to the database, it's given a unique user_id. This could be an integer or a string, as long as it's unique. You store the user data in a table that contains, at minimum, (user_id, username, password_hash). When the user logs in, you then know the user's unique user_id and you use that as a key to fetch other data for that user, perhaps via a SELECT statement: SELECT ... FROM user_data WHERE user_id = current_user_id;
I'm not sure if I understood correctly. If you want to load functions lazily (like lazy imports in scripting languages), it becomes a lot trickier. I think first you gotta make sure it's really worth it.
I already have setup authentication and authorization, cookies, sessions I linked my databases. When the user is logged back into their dashboard though I just want to display the content they have saved is my only question Iâ€™m not one to just throw packages into my code for simplicity I enjoy the learning process and regardless if I have the experience or knowledge now itâ€™s good to practice and learn these things for your own
thanks a lot. I learned a bunch in the last hour or so.
&gt; leaves little room for metaprogramming or syntactic cleverness these should never be a programmerâ€™s goals on a production code base.
Attach an incrementing ID sequence to the input stream and use a heap to sort them on the way out.
perfect timing! i've been working on coding a copy of a board game and was planning on using this to enable clients. thanks!
Look into [Argones](https://agones.dev/) and [Open Match](https://open-match.dev/) by [Google](https://www.youtube.com/watch?v=_mgUGCD5vBQ).
Wow Iâ€™m in the middle of exactly the same thing. Funny
and it'll open doors for LINQ and TPL like things in Go as well. We can either wait or contribute to the design discussion but complaining won't help. [https://github.com/golang/go/wiki/Go2GenericsFeedback](https://github.com/golang/go/wiki/Go2GenericsFeedback)
Kafka. I donâ€™t believe rabbit will process in order like Kafka does. If you just want to do it internally youâ€™ll need some kind of synchronization. Channels are first in first out but if you want subsequent workers processing in order then youâ€™ll have to deal with it via sequence IDs.
[removed]
Please correct your attitude, especially when you're asking other people to give you their time and assistance.
so let's say there is a service that listens to data changes on google sheets and all those are sent as events to a task queues after some processing those rows in google sheets are updated, since these are sheets the order of the rows should remain intact
You get a free connection pool when using database/sql.
Dayemn!! Both are written in GO. Thank you very much, I've been looking for something like these!!
You'd only need sequence IDs for a channel solution if you did fan in / fan out. You could easily chain a bunch of channels together in a pipeline pattern, and they'd maintain order.
Yea exactly. Wasnâ€™t totally verbose about it.
You might want to check the Google API, if youâ€™re really doing it. Last time I checked Sheets doesnâ€™t provide promises of order.
I donâ€™t have specifics on them, but if youâ€™re using PayPal, there have been a lot of issues with them screwing people over. Donâ€™t leave money in your account unless youâ€™re OK losing it. Braintree is another good one that lots use. Uber used them last time I checked.
PayPal owns Braintree btw ;)
There are downsides to any and all ORM usage. Your data model should represent the best way to store the data. Your functionality that the api provides should be whatâ€™s the best UX, not necessarily mirroring the data model.
Cool project! One suggestion I have. I notice you are writing comments describing what a block of code does. Could you refactor those blocks to separate functions with descriptive names? That way the code is a bit more self documenting. Or if it makes sense you could factor them out to separate files. That will make them more testable!
There's no rule of thumb but it could depend on the amount of changes you expect and maintenance. I picked an ORM for my group because the level of SQL experience was low. I made sure we used Repositories (DDD not the pattern) to save and retrieve objects. There were several time the ORM created some terrible SQL to save and retrieve. I could go in and highjack the normal way and use my quicker and simpler way without any changes to the rest of the code base. If you research it you will people saying "Never ORM" because of performance reasons or lose of deep DB functionality. I sleep well because I can spend time on other things than SQL queries.
Stripe is the industry de-facto solution for card payments at this point. There are sample implementations in Go on their page. It's a \*lot\* easier than it looks at first, just take it step by step. The decision to go with PayPal or credit card is a business one. There are lots of arguments for each (PayPal has the smoothest "one-click" process, and is trusted by most purchasers more than a credit card form. But they can be absolute bastards to merchants and that one-click process only works well if the customer has a Paypal account with funds in it). If you can handle the work, do both and let your customers decide how to pay you.
Also, I think Braintree is moving away from startup/small business payments processing and focusing more on their larger customers, so they may be less effective for small projects.
Thank you! I'll try that out Other than organization, did I do anything else dumb as far as efficiency?
They also want an absurd amount of documentation to approve live payments. It's so bad that we completed a full Braintree before getting approved, then ditched them for Stripe after realizing how scummy their onboarding process was. Threw out all of our existing payment gateway code, but it ended up being only a half-day job. Stripe, on the other hand, approved live payments with zero human intervention. PayPal/Braintree are an absolute dog's breakfast of a company. Bad documentation, bad merchant interface, bad business practices. /u/_barjo , implementing Stripe Checkout is really not that hard with Go. There's not much code. Just follow along the Stripe documentation, don't get spooked before you've tried it.
Please, please donâ€™t do your API with an ORM! If you are learning SQL keep going. Iâ€™ve used new APIs by database noobs riddled with ORM bloat. The one Iâ€™m dealing with today is beyond stupid. Consider yourself a better distributed computing engineer if you never have to use the crutch known as ORM.
&gt;Er... It's literally the same thing: &gt; It's not the same thing at face value of your original statement. It only becomes similar after you replied with a better explanation. Still I don't see it as comparing the same things. In one case you have the unit of work being requested of the git, kubectl, or go program. And then you have the startup costs before you can even get your requested results. Git and kubectl have nearly transparent startup costs, as would a Go program if it were compiled. If you run it as a go script, you are now choosing to add startup time for compiling and linking before you even get your requested unit of work. Yes I have looked at the strace of python programs and seen a single invocation cause 10s of thousands of syscalls. Their startup costs are caused by being interpreted languages with runtime dependencies. Anyways, I don't care about the feature either way, as well, since I would just compile my "scripts" since it is the ideal and primary approach for Go.
You could look at this two ways. The other way is saying how can you be sure of the Go version 2 years from now? Do we have to start being aware of major/minor references for that now in the shebang so that it can have enough info to keep running? Modules can log their Go version now. But that hasn't been considered for "scripts". What about dependencies that were there when the script once worked but are no longer on GOPATH. Which version were they? Does my script stop working like a python program if the GOPATH changes? I think you are trading an extremely simple go build process for a more complicated situation later. Go build is so far and away from the complexity of building C++ programs.
The normal method is to use Go Templates [https://golang.org/pkg/html/template/] to do this. So instead of writing raw HTML files, you write templates, and include template directives to write the data, like so: &lt;html&gt; ... &lt;body&gt; ... &lt;p&gt;Your name:&lt;span&gt;{{.User.Name}}&lt;/span&gt;&lt;/p&gt; {{if .User.DateOfBirth}} &lt;p&gt;Your birthdate:&lt;span&gt;{{.User.DateOfBirth}}&lt;/span&gt;&lt;/p&gt; {{end}} &lt;/body&gt; &lt;/html&gt; In Go, you pass your template and your data to the templating engine, and it creates the appropriate HTML output directly, so that looks like: func ServePage(rw http.ResponseWriter, templatename string, data map[string]interface{}) error { tmp, err := template.ParseFiles(templatename) if err != nil { return err } return tmp.Execute(rw, data) } So you just load the data from your MySQL table into your struct, add your struct to the `data` map, pass it to the ServePage function, and your data will be written into the HTML served to the client. As an alternative, I've been creating javascript objects directly using Go Templates, which works better if you're using a front-end framework like Vue or React. So (a simplified version of) my javascript looks like: &lt;script&gt; var form_data = JSON.parse(`{{.User}}`); if(form_data != null){ //populate the HTML form with the data here } else { console.log("null user data!"); } &lt;/script&gt; I've had endless problems with JSON formatting of complex data types with this, though, so the first method is preferable if you don't need the javascript objects.
&gt; Just punt on dealing with subtyping &amp; unboxed values etc. There is value to be had for cheap &gt; &gt;I'd love to be argued with though :) There's a lot of performance cost to just boxing everything, in addition to the overhead of heap allocating all the boxed types and less cache locality, you're generating tons of garbage. Maybe your application is IO bound and doesn't care about performance, but I think Go is designed for pretty good performance and that's one of the core features of the language. Just throwing performance away as a priority now (in a core feature like generics) is inconsistent with the design choices that Go's already made. Like why have explicit pointers to begin with then? Why not just have most things be reference types like Java? It's a little more memory safe that way too, I prefer Go's multi-word interfaces and slices, but you can actually corrupt memory with data races in a way that I don't think is possible with Java... what was the point of that if just boxing everything is OK now? Maybe you're suggesting that they could just do it the easy way now and figure out value types/specialization later. But just hoping things work out later if you haven't designed it is a bad idea. Maybe they could do it "for cheap", but the real cost of doing that is realizing later that you f\*cked up, and now you can't do it the way that works best without breaking compatibility or making things complicated with two systems that work differently. I'm not against generics but I think it's much better if they keep working along the lines of their actual proposal for a more general-purpose system, even if it takes them longer.
This is great advice, thank you. Just a note, you don't need funds in your PayPal account to make purchases, as long as it's linked to your bank account. &gt;they can be absolute bastards to merchants Could you give a bit more detail on this? I've seen this opinion about PayPal a few times, but I haven't found any information on how/why this is the case.
I like C#'s generics (at least compared to Java) and how they use the struct/class distinction for determining when to specialize. I think they relied on having a just-in-time compiler for some cases so certain things needed work-arounds for ahead-of-time compilation but that doesn't seem to be a huge deal in practice. There were definitely some big weakness last time I used them though, for example I don't think it was possible to write generic code across 32 and 64 bit floats. I'll totally forgive Go for taking a long time as long as it's good when it comes out.
I want generics (although not C#/Java generics, I want generics that can at least cover float32/float64 code). I don't want high overhead to generics like generating lots of garbage with boxing, and I want to keep fast compile speeds and not sink down to C++/Rust/Swift level. It looks like Go is trying to deliver all those things. I'm willing to wait longer for it if they think they can avoid those problems. I get that the math library is kind of annoying, I ended up writing my own wrapper for float32... it's not like C# or Java are great there either, they're not even using generics just method overloading.
They are equivalent in the sense that you need either one to modify variable. It's valid for any type, not only for slices. Quick grep over few Go projects will show that pointer to slice is very uncommon.
Thank you very much. You've been very helpful
I almost never have code that's allowed to panic, there's a few isolated places but most places panic() is basically just a failed assert() and it kills the program. I'm curious why is panic allowed so much there, that certainly seems like a pain... is there a reason the panics can't be replaced with errors? I guess you could use an inline function in the loop so you can defer, that seems like there could be overhead, but it doesn't seem \*impossible\* that the compiler could optimize it...
Iâ€™ve built a billing system using Stripe, but not using Go. I highly recommend Stripe. They make it so so easy to test your app. They also have the best API versioning story in the business.
PayPal is known for shutting down accounts for alleged fraud by accident and then being almost impossible to communicate with. Recent story: https://news.ycombinator.com/item?id=19867120 It's a small risk, but a risk nonetheless. The downside of just doing Stripe is that it only accepts credit cards, which are not common in e.g. Europe. Many people just have a bank card with an IBAN and internet payments happen through various national systems (e.g. [iDEAL](https://en.wikipedia.org/wiki/IDEAL) in the Netherlands). If you're targetting private individuals and want payments from Europe, then accepting non-CC payments as an option is almost certainly a good idea (e.g. do both Stripe *and* PayPal). If you're targetting businesses or high-income people it's probably less important. There are many more payment providers, and some provide integrations with systems such as iDEAL. [Wikipedia has a list](https://en.wikipedia.org/wiki/List_of_online_payment_service_providers). I don't really have any experience with any of them.
Ah ok, thanks for the correction. I don't link my PayPal account, so have to keep putting funds in there. There are numerous stories of PayPal freezing accounts of merchants for no reason. The disadvantage of using PayPal is that they control your funds, and they always take the customer's side in any dispute between merchant and customer. You can end up with your whole business hostage to one nasty customer. It's very googleable, so I'll let you do your own research ðŸ˜‰ Like I said, if you can do both, then do both. If I had to pick only one, it'd be Stripe. But I don't know your customer base. There are demographic reasons to prefer each solution as well.
This is pretty cool! Two very minor things: First, you probably don't want to include the gRPC functionality in the same package if you intend for clients who don't use gRPC to use your package, as it pulls an unnecessary dependency into the build. Second, you should always check errors: func (pcl *PeerCredListener) Accept() (net.Conn, error) { return pcl.AcceptPeerCred() } This will never return a `nil` value for the first return param. While this will not be a problem normally, if people do something unwise like `if conn, err := lis.Accept()...` and elsewhere assume that conn will be nil, it can cause really hard-to-diagnose problems. So even though it won't be your fault, it is something I recommend.
It depends, I think. If your web application is small, using a global variable is seem to be easy. But when your web app needs scale, I prefer using a singleton pool connection.
If it was only those 2 cases, I'd probably just have one int64 structure and add setFloat()/getFloat() functions (using math.Float64Bits/Float64frombits to store the float in the internal int). Or just put in both fields if the overhead is acceptable (keep in mind it's probably still much more efficient than interface{}, which (on 64-bit systems) will take the same amount of space in your structure as having both int64 and float64 \*and\* take some heap allocation space somewhere else). For me with Go it hasn't been too painful, but that's because almost all the time it's been fast enough to use some dumb algorithm on the built-in slice and map generics. If I really need something custom I've usually been able to use a specific interface (not interface{}) or type, so hardly ever have I had to do the last resort interface{} and casting. What sort of data structures are you generating? IDK what you're working on so this could be totally off, but as long as you're not working with insanely huge amounts of data I would try not to worry about the O(n) too much and just use brute-force algorithms on slices/maps by default, and only worry about casting/code-generation with a more advanced data structure if there's a performance problem with that.
Ordered queue. Should be able to find plenty of ideas (non go specific, it's an old need)
You could savd time/effort with ORMs But an ORM does not mean you don't have to know SQL and databases stuff, an ORM won't add indexes or check if the execution plan looks acceptable If I have an advice : NEVER gorm ! Dangerous for your data consistency (in case database crashes), it generates terrible queries Plus, its usage is weird, have a lot of magic that make debugging hard. Sqlboiler is imho a great choice, but it's up to preferences as it's a "database first"
Actually working on a golang app that subs to multiple websockets at the same time. Used this tut to get me up and running.
You shouldn't ignore errors, for example I saw these lines of code: * body, \_ := ioutil.ReadAll(resp.Body) * json.Unmarshal(body, &amp;data) &amp;#x200B; You shouldn't panic in libraries, for example I saw this: * panic(err.Error()) You should instead return errors and return them to the caller so the caller can decide what to do with it. &amp;#x200B; Similarly your library is calling log.Fatal which calls os.Exit. This means that if I wanted to import your code and call one of the public functions, my program would exit if anything were to go wrong. What if I wanted to call the function in your library and then do a few additional things such as do additional clean up steps? Calling os.Exit makes things less flexible and would prevent my program from doing so. Libraries should generally not call os.Exit.
This seems to be a viable alternative: [https://github.com/qor/amazon-pay-sdk-go](https://github.com/qor/amazon-pay-sdk-go)
This looks great for CPU/Memory. Any ideas on how to do http metrics? Nonetheless, I am going to test it out. Thanks!
You get downvoted so I'm commenting here. ORM is crutch. We're using plain sql queries in production and everything is fine. The code is readable, the functionality is clear, the queries are optimized and it doesn't take significantly more time to implement. ORM is a crutch because it lets you to not-know sql while working with a sql database. In my opinion, software engineers shouldn't use ORM's on regular basis. ORM should be used, in my opinion, by inventors who are creating prototypes, throwaway code etc.
So I've setup a docker with graphite-statsd. Ran it with the sample code: `METRICS=titan:2003 ./main` Where would I see it in the Graphite web interface? Sorry, totally new to this. So bare with me, if you could.
You need to install a software to set up a ram disk. Use robocopy instead of rsync. Use cmd or powershell instead of bash. The concept is the same.
Unfortunately I only have a HDD
Worked like a charm! Quite easy to get it up and running with the basics. [https://imgur.com/wcwICPz](https://imgur.com/wcwICPz) I should mention, we can deploy whatever systems we need for displaying metrics, so it is not a blocker. I will now work on it and see what I can capture. Even the base memory metrics are interesting to visualize. I just need to do some work with capturing some http metrics. Found this blog which has a general workflow of capturing some http metrics... [https://blog.alexellis.io/prometheus-monitoring/](https://blog.alexellis.io/prometheus-monitoring/)
SaaS business here. We use Stripe and PayPal. Revenue distribution is maybe 70/30% in favor of Stripe. The decision which payment processor to choose should not solely be done based on ease of implementation â€” but to give you a roughy idea about the differences: Implementing a Stripe backend was essentially a half-day effort from start to production. API &amp; documentation feels awesome. PayPal literally took months, because we needed to get approval for recurring charges which means it took multiple attempts to even talk to the right people, which would then start a due diligence process, and keep us waiting for too long. Also, the developer site did not feel half as slick and sandbox testing felt overly complex. Might have changed during the past two years, but you get the idea.
Stripe has more payment methods than creditcard only. It also supports iDEAL and numerous other payment methods. Here are the other supported payment methods: https://support.stripe.com/questions/pricing-of-payment-methods-in-the-netherlands
Ah cool, they must have added that since the last time I used it (or I simply missed it back then)
The `sql/db`'s [DB](https://golang.org/pkg/database/sql/#DB) type maintains a connection pool, so that's what you should be using. It's safe for concurrent use by multiple goroutines. It is rarely necessary to close a DB. It's best to store a connection pool/DB within a type that handles your inbound HTTP requests. As a result, you can provide any DB to run tests against. For most projects, I have a service layer in between. These would typically go in separate packages. Have your business logic within the service package, whilst the server is ONLY concerned with interpreting HTTP requests (e.g. unmarshal JSON bodies in POST requests), then passing those values to the service and finally generating a response based on what the service returns. The benefit to this is that you can test your service's business logic independent from HTTP details. Here's an example. I've omitted things like input validation and proper error handling to keep it somewhat concise. https://play.golang.org/p/r2wU996jpv0
No problem. It's just that the speed advantage of ram disk disappears.
Yes, the r.Context() will be cancelled. You can check with select { case &lt;-ctx.Done(): // cancelled case &lt;-time.After(10*time.Second): // timeout } or check the err, which I find handy in a loop for ctx.Err() == nil { // do stuff }
Keep it up Elliot!
Both Badger and Boltdb are not distributed databases. Only one writer can have the db open. But the connections to that open database are concurrency safe. I don't know anything about Buntdb. I'm not sure of a database that is both embedded and distributed and immediately consistent.
Seems like you are looking for something like ectd https://github.com/etcd-io/etcd
[https://github.com/olahol/melody](https://github.com/olahol/melody) is what I used to use, and it worked very well...
I don't think the goals of what is traditionally referred to as embedded and distributed combined make any sense in an app. Why not just deploy and connect to a distributed DB, such as [TiDB](https://github.com/pingcap/tidb) ?
This was my conclusion too. You can embed etcd. That seems like the best approach.
I went from basically no coding experience to a cart/purchase system using stripe with go. Thats going to be my biased choice, havent really messed with the other two. I dont know how much experience you have but one thing I learned the HARD way is how to handle concurrency. Make sure you lock and unlock your maps when you have an api that lets multiple users access the same data at the same time. Iirc my issue was I had a map of currency conversion rates I used and I updated this map once an hour on a seperate thread, if I tried to read from this map (user got a quote) Id crash the payment server.
The project I'm working on must be compiled into a single binary, so unfortunately it is not an option to use an external service like Redis. The storage must be embedded into the project as a package.
I'm not sure what you're looking for is even possible under CAP theorem. If I understand your requirements: * Every node has its own copy of the data, and gets what it needs from that copy. * Once one node performs a write operation, any other node that does a read will immediately see the changes from that write. * This isn't stated above, but if one node fails the other nodes should be able to carry on. Those requirements can't all be met at the same time. About the closest you could come would be that before attempting a write, the writer would have to notify every other node that it's about to write to a given key (and get acknowledgements from the other nodes). If the other nodes attempt to read that key, they then know that they have to wait until the write operation completes. Additionally, the nodes can't consider the write complete until every other node has acknowledged the write, or else you could end up with inconsistencies across nodes. Waiting for acknowledgements across a network before writing means that your write operations will be as slow as your slowest network link. If another node becomes unresponsive, you can't perform a write operation at all, because you can't know whether it's down or you have issues in your network layer. If a node fails in the middle of a write operation, do the other nodes keep that key locked forever? You have some options that give you approximations of what you're looking for. You could use a centralized datastore instead of an embedded one (centralized might be sharded and replicated, but it's still distinct from every node has a copy). Each node reads and writes from the centralized system, which makes sure everything is consistent. You'll have network level latencies for both reads and writes, but any node that can access the database is available without concern for whether they can communicate with the other nodes. Alternatively you could use something like Kafka for streaming write operations across all the other nodes. Every write operation gets sent to Kafka, and every node copies those writes into their own database. There are some latencies though - you don't necessarily know when you do a write operation that other nodes won't do additional read operations with the old version of the data. If you're looking for an embedded database, synchronization is probably going to be the responsibility of your application, not the database layer. The complexities and trade-offs of different synchronization approaches are such that it's not a one-size-fits-all solution, and embedded databases tend to focus on being a good embedded database, and let other layers focus on synchronization.
Note that people are using python as a scripting language. The valid points you raise don't stop them. But I agree that a Go binary is much better than a go script. Go scripts is a false good idea. It looks good at first, but when examined with scrutiny, it raises a lot of problems.
... and the libs the code depends on.
Yes, go 1.0 through 1.4 were using a compiler that was written in C.
Itâ€™s called self-hosting https://en.m.wikipedia.org/wiki/Self-hosting . You are correct that first self-hosting version is considered to be 1.5 https://golang.org/doc/go1.5
Yes, I didn't mention partition tolerance, now it's clear that what I'm looking for is not possible. I believe I can use only a single node for writes, and all nodes for reads, which makes the problem far less complex. &amp;#x200B; Unfortunately, using an external database is not an option in my case, so the app will be responsible for synchronization.
FWIW I think this post is nonsense. I also think that a corporation controlling a language isn't a terrible thing. It should ensure regular code contributions, some level of quality, financial backing. Mostly cross-posted to finger in the air see how others feel
I last implement something with websockets/go in 2015 when http2 wasn't quite everywhere. Is there a reason to favour websockets over bi-directional http2 these days?
To be honest I donâ€™t trust Google, but I trust Rob Pike, Ken Thompson and the license they chose for go.
[removed]
&gt; Is Go Google's Programming Language, Not Ours? Yes. Next question.
this is how i do it : &amp;#x200B; // main.go `package main` `import (` `"os"` `"os/exec"` `"syscall"` `)` `func main() {` `cmdpath := "C:\\Windows\\system32\\cmd.exe"` `exefile := "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"` `parms := ""` `if len(os.Args) &gt; 1 {` `args := os.Args[1:]` `parms = args[0]` `}` `cmdinstance := exec.Command(cmdpath, "/c",exefile, parms)` `cmdinstance.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: false}` `cmdinstance.Run()` `}`
This has now been posted 3 times this week.
Superb. Subscribed
How would this compare to Kubernetes?
See: Java and all the nonsense around that Not saying it'll happen, just saying it's the worst case scenario you have to watch for
Use Stripe. I've built several payment systems with `stripe-go` and it's been nothing but a positive experience.
Sadly if you want to add extra stats you'll need to : * Add the stats somewhere so you can export them * Update the library to submit them
* Create a new dashboard * Set the data-source to be the local carbon server * Add a panel/graph which has "titan...." in it.
Is there a mock stripe server you can use for testing? What makes it do easy to test?
When you say nodes do you mean kubernetes nodes? You could perhaps have a redis container running as a node in your cluster (not external). I think traditionally having multiple nodes is to share load and resources, not state.
It would be great if you could explain things. Currently it is "We are going to make an upgrader" without explaining why and what it does. You might as well copy the example code.
As you discovered, badger at al are embedded stores, but not distributed. One potential solution is to combine them with something like [Raft](https://github.com/otoolep/hraftd).
Plugins are a tech demo feature at best, and shouldn't be used for anything meaningful.
&gt;According to https://golang.org/doc/install/gccgo, gccgo-4.8.2 includes a complete go-1.1.2 implementation, gccgo-4.9 includes a complete go-1.2 implementation, and gccgo-5 a complete implementation of go-1.4. Ultimately we hope to build go-1.5+ with a bootstrap process using gccgo-5. As of go-1.5, go cannot be bootstrapped without go-1.4, so we need to use go-1.4 or gccgo-5. Mips is not officially supported, but it should work if it is bootstrapped. \-- [https://git.savannah.gnu.org/cgit/guix.git/tree/gnu/packages/golang.scm?id=0f377aad75314df6c6296f4172801519315d81cd#n50](https://git.savannah.gnu.org/cgit/guix.git/tree/gnu/packages/golang.scm?id=0f377aad75314df6c6296f4172801519315d81cd#n50) &amp;#x200B; Alternatively someone could write a small go implementation in C to get there... or contributing to llvm.
By nodes I mean instances/processes. Each process might be either an ec2 instance, container or a process on the same machine.
I donâ€™t see why this is a big deal unless you deeply mistrust Google. Seems like a tempest in a teacup to me. There are all different models for language development - corporate driven, BDFL driven, and full community driven. Sometimes even corporate and community have a BDFL like Go has Pike and C# has Hejlsberg. Sometimes, like in the case with Perl with Wall, being BDFL driven doesnâ€™t work so well in the end. Sometimes being corporate driven like Java used to be doesnâ€™t work so well. And sometimes being community driven means thereâ€™s no strong driver to break backwards compatibility to make a language better like with PHP and JavaScript. Thereâ€™s pros and cons to all. Iâ€™m pretty happy with Goâ€™s corporate backing (even though I am personally no fan of Google), and Pikeâ€™s unofficial BDFL status. I think that bodes well for a bright future for the language.
Here's a link to a discussion of approaches some people take: https://www.reddit.com/r/golang/comments/bcj0tm/database_access_in_golang_seems_a_bit_tedious/. My preference is to stick close to plain old SQL with some auto generated code for common CRUD database actions, using gnorm.org. Other good options too though.
A service mesh is a different thing from gRPC. gRPC is a communications protocol built atop protocol buffers. A service mesh controls the connections between services to provide things like automatic retries with backoff and such. &amp;#x200B; Alternatives to gRPC are things like HTTP+JSON. Istio is an example of a service mesh.
They give you a live and test account. You can create customers on the fake one. They have a huge list of test credit card numbers. They have a huge list of credit card numbers that will purposefully fail in certain ways (expired, bad billing address, stolen, etc).
That link is dead.
Worked for me, unless you are threatening the link...
&gt;Alternatives to gRPC are things like HTTP+JSON. gRPC uses HTTP as transport, and meshRPC is currently HTTP+JSON, but I'm planning to add support for other types of serialization as well. So it's much more modular than gRPC that will forcefully stick with protobufs. &amp;#x200B; The reason of comparing it with gRPC is that because you wouldn't use gRPC alone: you will also reorganise your app to operate with protobuf schema, install Envoy or Istio to manage cluster and end up with Kubernetes. But I always look for a middle ground because I work in mid-sized startups and we don't have time and human resources to take care of Kubernetes and Istio alone. I just want to throw a bunch of services and have reliable RPC between them, that will have balancing and allow rolling deployments. &amp;#x200B; \&gt; A service mesh controls the connections between services to provide things like automatic retries with backoff and such. &amp;#x200B; meshRPC contains built-in p2p service discovery, connection multiplexing, load-balancing and retries/circuit breakers will be added. I'm trying to have the best features of a proper service mesh, without drowning in configs :)
really? I pasted via the search-box, so it shouldn't be. Apologies if it is the same link.
Thanks, that's great news. I was planning on using stripe so that's comforting
The article excepted and linked in the /. post has been posted twice, so not exactly the same link, but the same content.
It's back up. It was timing out about 40 minutes ago.
The story, the Hacker News comments on the story, and now Slashdot comments have all been posted.
Kubernetes is a tool for orchestrating Docker containers on a lot of machines. I prefer \`docker-compose\` and now \`docker stack\` because I like my cluster to be simple. And for that reason I'm working on meshRPC â€” to have reliable cross-container RPC without too much configuration and maintenance overhead. In terms of performance (this is a reasonable comparison), I didn't put a test MeshRPC versus Istio+Kubernetes yet, but I would do that soon. I have a simple benchmark to check that latency is acceptable and there is no obvious bugs, but a real perf battle is ahead.
Every time I have tried to use plain SQL queries it is great at the onset, and then a maintainability nightmare later when you have to touch 100 different queries when requirements change. A good ORM can resolve that. How do you deal with that? Or is your application small enough that you don't have to worry? If the latter, if your application continues to grow, how will you start to deal with the scale?
Your vm.go looks like it is decoupled from the other code, so if this were my package, I would personally put it under chip8go/vm/ and split it up into a few .go files for organization. Or if you want to communicate to other developers that they shouldn't be using vm.go directly, put it in chip8go/internal/. If your project were to grow larger, then you can start thinking about e.g. a chip8go/pkg/ directory. Then I'd put the main binary in chip8go/cmd/chip8/ (or whatever you want to name your executable).
Well TBH I'm subscribed to this sub and I've never read it, so sucks, but I wasn't aware
https://www.reddit.com/r/golang/comments/bt775a/is_go_googles_programming_language_not_ours/eouzmba/
I donâ€™t understand your rationale that gRPC -&gt; istio+k8s. The protocol you use to communicate is totally independent of the orchestration engine youâ€™re using to manage your infrastructure. At my place we donâ€™t have any sort of service mesh setup yet (weâ€™re in the process of transitioning from VMs to containers), but several of our services use gRPC to communicate.
Ok, I might agree with you that gRPC can be used alone successfully. And the title might be confusing, I understand that now too. Just for sake of clarity, I'd say that meshRPC aims to be an alternative service mesh, but it also implements own RPC that might be on par with gRPC. ðŸ™ƒ
Thanks for your comments. I hadn't really thought of splitting this -- given that its *raison d'etre* is in support of a gRPC-based project I'm working on -- but I'll consider it. The fact that it works at all *without* gRPC is really the *extra bits*. :D Also, I'm not sure I follow your concern about error checking. Maybe you're talking about something else but, I think you're off the mark with the claim that `return pcl.AcceptPeerCred()` "will never return a `nil` value for the first return param". Since `Accept()` is merely a wrapper around `AcceptPeerCred()` \-- both of which return two values -- when the latter returns `(nil, err)` then the former will do the same - kinda like [this](https://play.golang.org/p/iIazYMNpti8). n.b. The only difference between the two (other than their names) is the type of the first return value. At first I had only `Accept (net.Conn, error)` (to satisfy `net.Listener`) and its body was what is now `AcceptPeerCred`. However, that forced the caller to always do a type assertion to access the `*PeerCredConn` value (and ultimately get to its `*Ucred` member (which is why we're here in the first place, right?)). Splitting into two methods seems cleaner and more in line with the calling conventions in the standard `net` package.
*&gt;&gt; I donâ€™t see why this is a big deal unless you deeply mistrust Google.* Because missing but necessary features like generics, exceptions, dynamic typing, spaces, and spacing between urinals don't get added. You know, features required by true programming languages. My take on the original article was the author was more bothered by the lack of interaction between Google (or the Go team) and the user community than Google "owning" Go. Google's typical radio silence with the musings of the development community does tend to come across as not caring to even slightly hostile these days. Their prerogative of course but a bit more interaction (even if just to reiterate the "nos" and whys) would go a long way mitigate this perception.
If the community cares about Generics so much, go ahead and submit a pull request: https://github.com/golang/go . Itâ€™s not like itâ€™s closed source. Thereâ€™s a difference between actual community contribution and being run by community demands. Otherwise do what the rest of us do, and use `go generate` for the handful of places (collections) where genetics are helpful.
If the goal of the package is to implement peer creds for gRPC, I would personally have just named it "peercred" so that you have peercred.Transport and peercred.Listener, but naming is hard :). As for the `nil`ness, here's a quick example: ([playground](https://play.golang.org/p/kfr4IEn9toy)) type PeerCredConn struct { *net.UnixConn } func Listen() (net.Conn, error) { return ListenPeerCreds() } func ListenPeerCreds() (*PeerCredConn, error) { return nil, fmt.Errorf("Unimplemented") } func main() { var conn net.Conn var err error for conn == nil { log.Printf("Listening...") if conn, err = Listen(); err != nil { log.Printf(" - err: %s", err) } } io.WriteString(conn, "Hi!") } Without running it: 1. Do you think this program terminates? 2. If so, what do you think the output is? Now try running it in the playground. If the output surprises you, check out [this FAQ entry](https://golang.org/doc/faq#nil_error) for an in-depth explanation, just substitute `net.Conn` for `error`.
A 100 queries?? On a single table?? And they ALL access the modified column?? Seems like the sql part is the least of your worries. I don't run around writing sql queries all over the place. I use structs, functions and constants to make my code more maintainable. The point is that a good architecture will hide the persistence layer so deep in the code that using an ORM will not add value, except as a sql query builders. And you can use those instead of the full bloat of an ORM. To be blunt, the "benefit" of ORM's is that they add simplicity to spaghetti code. The fact that you have hundreds of different sql queries in your code is an indication that you haven't separated your core business logic from the mechanism that persist some bits of that logic to a hard disk.
Thanks for the link! I'll dig the conversation, thanks to also the other redditors I understand that using plain SQL is safer and more educational.
If you think that collections are the only place where generics are useful, or that go generate is a good solution, then I don't think you have a very good grasp on the usefulness of generics. For instance, go lacks the functional-style constructs of other modern languages, and they can't be implemented as a library, because it also lacks generics. Also, your suggestion is ridiculous. Without buy-in from Google, that PR will never be approved. Nobody is going to use an unofficial fork of Go, either.
Threat delivered, methinks.
Then what's the useful point of modules?
Thank you for the suggestion, by reading the other comments I think I'll go with some well though prepared SQL queries
Lucky me my application is way more smaller ahahah
Thank you for the comment, I think I'll go with plain SQL to begin with as my application is small enough to allow it.
Thanks for the feedback
Have a look at https://mollie.com offers many payment options
Oh hush! This comment (do it yourself and submit a pull request) and "there are lots of other languages out there, use another" are two of the most disingenuous comments the Go community uses. These two comments probably do more to make the Go community appear toxic than most of the other STFU comments combined. Adding generics to the language would be a huge undertaking. Way more than one person would be able to do. You'd need a community of developers working for many many months to do this. You'd want open discussion with the core development team too. Otherwise wouldn't everyone's time and effort be wasted? Someone should write an article about how the core Go team's interacts with the community. An article that shows how welcoming Google is to people making changes to their language. Yup, that would do it!
[removed]
Look, Iâ€™m excited for generics when they come too. But am okay to let Google drive it. Sounds like weâ€™re making the same argument. Iâ€™m just not doing all this handwringing in the mean time.
Nice project. We developed a small utility to use envoyproxy together with docker containers for a simple to use service mesh. It works really well and is very easy to use with docker containers and docker compose in development as well as in production â€“ service discovery is done via docker labels. It is also fully compatible with grpc. Envoyproxy (also used for Istio) [https://envoyproxy.io](https://envoyproxy.io) Kolumbus (our utility for service discovery with docker containers) [https://github.com/dkfbasel/kolumbus](https://github.com/dkfbasel/kolumbus)
Sorry you feel that way. I donâ€™t think the go community is toxic at all. Strange argument for someone who disagrees with me that itâ€™s fine for Google to be driving development of the language though. I find gophers to be one of the most welcoming and responsive development communities there is. I see go developers getting stuff done and being productive and happy to wait on Pike and team to move the language forward. I appreciate that they donâ€™t listen to the noise around generics and have worked to make the language grow and thrive without it. Java didnâ€™t have generics for years. C# was without generics until 2.0. I think we agree, but for very different reasons. I donâ€™t care to see the community drive the language forward and think it works best to let it be Google.
I tried my best, but the library doesn't allow you to run a string and an int with functional programming. It would pull up and error of "varna me is string not int". So, in that case it is type safe. Please explain. This might give me a new idea for the next update.
I added Fp because map had a name collision with Golang's keywords. I kept the Fp throughout so that I keep consistency within the library.
&gt;generics make libraries like this easier to implement with a more ergonomic API It does. I had to write stuff similar to this from my programming classes, but without generics made it hard. I doubt they would add generics because of the "I never seen the use of generics" thing.
As long as there is a single `interface{}` in the code then it is not type-safe. It is impossible to create a type-safe library for this purpose without generics. Runtime type checks are not type-safety.
&gt; It has to be persistent, and the changes made by one node should be immediately visible to the other nodes (upon next read/write attempt). It should work well with concurrent reads and writes performed by multiple nodes at once. So, this paragraph really is where the crux of the matter lies: What does "next read/write attempt" mean and what does "multiple writes at once" mean? In their most generous interpretation, they are mutually exclusive - that is, if you want the first question is "after a write to Node A returns, a read from Node B should always return the written value", then you require linearizability, which means you can't have to writes happen *at the same time*, they will always happen one after the other. etcd supports linearizability *if you configure it as such* - the default configuration doesn't. There are weaker levels of consistency - for example, in its default configuration, etcd doesn't require reads to go through a quorum, meaning if you write to Node A and read from Node B, it might respond with a stale quorum - but every client reads the same sequence of writes in the same order. There are *even weaker* models - one of the weakest, is causal consistency, where writes can be perceived in different orders, as long as one of the writes didn't depend on values from a different write. Unfortunately, that's the strongest model that would *actually* allow you in the strictest sense, to have actual "simultaneous writes". So, this is actually a hugely important question and it's exactly why distributed systems are hard. A linearizable store is at most as performant as the slowest node, so the *only* advantage it has over a single-node system is reliability. If that's what you're going for with having multiple nodes, then yeah, linearizability is the way to go. If you have multiple nodes because your problem doesn't fit on a single node, then you have to kiss strong consistency goodbye. OTOH, if you can get along with very weak consistency, you can get incredibly scalable systems, because every node can essentially operate independently. As for concrete suggestions: In [RobustIRC](https://robustirc.net/) we ended up with serializability (AFAIK. That's the same as the etcd default config mentioned above) and implemented that using the [hashicorp raft implementation](https://github.com/hashicorp/raft) and [leveldb for storage](https://github.com/robustirc/robustirc/blob/master/internal/raftstore/leveldb.go). It's not a simple library, but it's also not a lot of self-written code. Essentially, this provides you with an "embedded etcd", so to speak - it's the same underlying consistency model and algorithm as etcd, but you don't have to deploy the server. You'll still need to linearize your writes though, so you can't have more writes than a single node can handle, either way. If you are distributing your system for performance, you *have* to relax your consistency models. [Jepsen has a nice overview and description of the choices](https://jepsen.io/consistency). Distributed systems are hard :)
Yes, many of the grailbio commits were applied to this fork, however I doubt if it will play well with the netdicom package, though I haven't looked into it. There have been many API changes and under the hood improvements on my fork, which start to have it diverge away from what it was before... let me know if you give it a shot though!
Aha! Your concern isn't so much about *not checking errors*, but rather about the typed `nil` pointer never being `nil` as an interface -- which is absolutely true. I don't really see a problem here, simply because I've always operated under the assumption that, whenever a function returns `(foo, error)` and the error is non-nil, then the value of `foo` has no meaning and should be ignored. A practice I would highly recommend. :) That said, I can fully appreciate that a great many people don't really grasp the nuances around typed nil interface values, so I've added a little protection logic. Also, splitting out the gRPC support into a separate package was wicked simple -- so there's now a sub-module/package for that. v0.3.1 has both changes. Thanks for the feedback! :D
&gt; I believe I can use only a single node for writes, and all nodes for reads, which makes the problem far less complex. FTR, depending on what you mean "after the next read/write attempt", this wouldn't solve your problem. If answered in the most intuitive sense ("client sends write to A, then reads from B and should always get the same value") you still a) need to distribute a write to every node before returning and b) need every read to go through the writing node, to make sure the value wasn't updated in the meantime. Meaning you end up with something like an embedded etcd (in fact, that's exactly what etcd does - it uses raft to elect a leader and only the leader writes and only after confirming with a majority of nodes). Maybe embedding an etcd is just what you want? Or you want to overthink the level of consistency you *actually* need.
Oh, ok. Yea, there are no generics which definitely hurts. The only way I could thing of this is maybe making it in C or C++ then use CGo. However, Rob Pike recommended to not do this because each platform has different versions of C or C++ and it's not supported/unpredictable behavior.
Hi r/golang, just wanted to share this with those on the go subreddit and see what all your are. I'm aware the library is a bit messy still and has more to go test wise, but I'm particularly interested if anyone would find this library useful for encryption, particularly for text and passwords. &amp;#x200B; Thanks!
*&gt;&gt; Sorry you feel that way.* No need to feel sorry for me. For the most part I've found gophers to be very friendly and inviting too. I've just found a small vocal subset of gophers, who are otherwise friendly too, that get annoyed (is that the best word?) when people talk about language changes. Maybe Go is perfect for them but certainly the discussions about error handling, generics, pick your poison, wouldn't be so enduring if the way Go is now was perfect for everyone. And no, this is NOT the time to throw out the one about lots of other languages to choose from.
\&gt; how would one compile the Go source code without Go? How would one compile a C compiler without C? (See also [Trusting Trust](https://www.archive.ece.cmu.edu/~ganger/712.fall02/papers/p761-thompson.pdf).)
No problem :) I also strongly recommend being diligent about not using returned values when there is an error, but it's something I point out to new Go programmers on a weekly basis at work. One of these days I'll make a vet check.....
Thereâ€™s some incorrect things in here. gRPC works with protocol buffers but you donâ€™t have to use protocol buffers, itâ€™s compatible with other protocols.
It is interesting that a very expensive ( [https://unidoc.io/pricing/](https://unidoc.io/pricing/) ) commercial software is so popular. Normally, commercial products did not attract interest in this subreddit.
that is stil more clear than `mac` and `fun`
nice
$1500 a license to generate PDFs? My spidey sense are tingling Smells like paid updoots, doesn't it
I'm also interested in the answer to this question.
&gt; A 100 queries?? On a single table?? A single table joined with other tables in various ways with various conditions, sure. Obviously you'd never `select * from table` 100 times over and over again. &gt; And they ALL access the modified column?? Quite possibly, depending on the specific requirements. &gt; I don't run around writing sql queries all over the place. Well, neither do I so I fail to see the relevance of this? Did you forget to read my comment or something? &gt; The point is that a good architecture will hide the persistence layer so deep in the code that using an ORM will not add value I don't see how architecture solves the problem of needing many different queries to accomplish different functions? &gt; To be blunt, the "benefit" of ORM's is that they add simplicity to spaghetti code. Maybe you've just never used a good ORM? If your experience is with GORM, I can see why you'd prefer SQL. Nobody should be using GORM. Period. &gt; The fact that you have hundreds of different sql queries in your code is an indication that you haven't separated your core business logic from the mechanism that persist some bits of that logic to a hard disk. I don't see how that logically follows? Can you explain yourself further? This isn't a case of duplicate code. The queries are all different, serving entirely different purposes within the application.
It also avoids the "design by committee" problem, where a language tries to go in a dozen different directions at the same time. It's not the only way to avoid it, but it certainly helps
Do you know of any data structure if I want to know if a string is in a set of strings without associating data? Iâ€™ve never found one except a bloom filter and I donâ€™t like dealing with false positives.
Not OP, but concurrency would benefit because certain patterns that use channels currently have to be rewritten for each type of channel you want to use the pattern on.
Holy crap talk about restrictive licensing practices! Iâ€™ll just keep using [gofpdf](https://github.com/jung-kurt/gofpdf).
that comment is a response to the "Go is not a community project" article that made the rounds last week. a good read.
I donâ€™t think there is such an abundance of go developers to do leetcode interviews in it (yet) - most go developers Iâ€™ve met were senior engineers coming from other languages, and almost none of them wrote code in go before.
Exactly, I got to Go at my work so I didn't go through Go interview while being hired since company didn't use Go, but since we are looking to expand the team of two people only programming in Go, the company will be looking more for senior smart people who not necessarily have strong background in Go but have good engineering background and is able/willing to adapt and progress.
If you don't want a probabilistic structure, you have to store the strings.
&gt;Do you know of any data structure if I want to know if a string is in a set of strings without associating data? Iâ€™ve never found one except a bloom filter and I donâ€™t like dealing with false positives. Yes bloom filters!
I badly miss error checking and handling. Your package will panic in many cases where error handling is possible and should be done. For example, what if I pass an invalid index to RemoveAt? What if I pass a function to FpMap whose argument type does not match the vector's element type? What if I call FpReduce on a `nil` receiver? When errors are expected, handle them. You do not necessarily have go give up the FP style of your package to add error handling. Add an error field to Vector, and store the last error in there. Every method of Vector checks this value and if it is not nil, the method just returns, doing nothing. Then add a method to allow the user checking the error value and acting on it accordingly. This way, when an error occurs inside a function chain, the flow simply "falls through" to the end of the chain where the error checking method then can take action.
This is the first development job I got and I was hired for golang and nodejs. &amp;#x200B; The interview was kind of what I expected: 1. At the second interview the HR asked me to complete a set of 20-30 basic exercises similar to leetcode in a language of my preference, I chose go. 2. At the final tech interview, two Sr. Devs come and asked me to explain them how a sorting algorithm of my choice works, breadth first search vs depth first search, difference between Go and Java (interfaces), threads vs goroutines. Concurrent vs Parallel. 3. Whiteboard 1. Fill a given interface with implementations. 2. Make some http requests to a rest api, send queries to a db. 4. Why I would choose Go over another programming languages, what are the benefits to using it. &amp;#x200B; The next day I got hired.
&gt; Furthermore with the introduction of Go modules, $GOPATH is being phased out and it's become idiomatic for Go code to be anywhere on the system. But also, the source code needs to actually be a module, including a `go.mod`, which makes this idea pretty pointless. Yes, that's a solvable problem, but you can't have it both ways: Either go modules are an argument against, or they aren't an argument at all.
I could not find any info on that matter before. Can you give some examples please?
Well, Go is definitely not a community project. To getting support added for obscure targets and you will soon realize how much weight Googleâ€™s corporate word has. In comparison, the Rust project is a true community project where they accept almost all contributions by the community provided they meet the quality standards.
At my last Go interview I got asked to make a React app ðŸ¤· Ther's no telling what they'll ask you; it can vary greatly even between different teams in the same company.
Yeah it's easier that way. You can do this also in production. The fancy word for this is "sercives architecture" and it basically means you write many small apps. The measurements for small are "small enough to maintain". I also use the hexagonal architecture in each service. https://youtu.be/vKbVrsMnhDc In summary, it's a way to order your code in small, independent parts. This architecture is possible in Go thanks to interfaces. This is the architecture I use, and it keeps us from needing an ORM.
and it follows a patter you can find in many other languages
Which obscure target (platform?) contribution has been denied and with what reason?
Hi! Would you mind sharing some advice on a path a new developer might take to become a go dev at a crypto company? I'm starting to take Todd McLeod's Go Udemy course, and I have Andreas Bitcoin book. What else would you do, if you were starting out fresh today? Super thankful for any feedback/advice!
In principle, I agree. I have not found any good authn/z libraries in go though. Do you know any?
- What operating system do you have? The installers for macOS, Windows, Linux, and others are slightly different, and so the instructions as well. A â€œblack screenâ€ is not enough information to help you explain the problem - Since youâ€™ve never coded before, and the normal installation process is clearly not working for you, you may want to consider learning how to program in Go using this website (you donâ€™t need to install anything) â€” https://tour.golang.org/
1. Go to [Golang.org](https://Golang.org) and download the latest go installer for your platform (e.g Windows x64) 2. Install Go using the installer 3. (Maybe needed) Reboot PC to make PATH changes work (e.g. make 'go get' work on Windows CMD) 4. Install / Open up a Texteditor of your choice 5. Write Code with a main function and main package 6. Save it with `*.go` file extension. 7. Execute `go run *.go` in the directory you're in, using your favorite Terminal (or embedded Terminal from Texteditors and IDEs)
Update your Gopkg.toml to set it to major version 5: ``` [[constraint]] name = "gopkg.in/olivere/elastic.v5" version = "5.0.0" ``` Use the gopkg.in metapackage rather than the direct github repo. Then just do a `dep ensure -v` and it'll use v5.
What is "bi-directional" http2? Do you mean Server Sent Events combined with POST request?
There is a difference between `inline code` and code blocks
I won't need to change any of my imports to elastic like `elastic/v5` something like that?
Oh right, the package you import in files should be `"gopkg.in/olivere/elastic.v5"` as well.
Small objection: Kubernetes implements the Container Runtime Interface (CRI) and that doesn't mean Docker per se. In fact, you can use any container runtime that implements that interface. As of Kubernetes 1.10 you can use containerd, cri-o etc. These runtimes are often optimized for Kubernetes usage while still providing simplicity through the Open Container Initiative (OCI). I agree with your statement that Kubernetes mostly makes sense if you have a bigger set of services you need to orchestrate.
You do not "open" the Go program, the go tool is not an interactive program with a window you interact with. The simplest way to learn the language is by use of the Playground and the Tour. On any case: Ask a human on how to use a text editor and the command line as this is the most efficient and least painful way of learning this kind of stuff.
&gt; Then what's the useful point of modules? Proxies.
Yeah, take a look at the [DAWG](https://en.m.wikipedia.org/wiki/Deterministic_acyclic_finite_state_automaton). Otherwise, you can also use the Patricia trie, with struct{}{} as data. But the dawg should be more efficient by orders if magnitude, although.
What you have installed is a compiler and a bunch of tools. You also need an IDE or a text editor to write and save your code. For Windows, there's a quite good (and free) semi-IDE from Microsoft: Visual Studio Code. It is a universal editor and I recommend installing Go plugins to make programming in this language easier.
The front page at golang.org has a prominent button labelled "Download Go". Click it. Plase note the correct language name, it's 'Go', not 'go lang'.
&gt; In comparison, the Rust project is a true community project where they accept almost all contributions by the community provided they meet the quality standards. If the Go project would do the same, we would now have preprocessor macros, templates, etc. But the language would no more be Go. It would be C++.
Awesome! I'm thinking about using this for a large index and have a question about it: What does fuzzy matching do / how does it work? Neither the Godoc nor the Readme seem to really explain that. I assume it means that some characters in between might not match? If so, how are the results ordered? Is there some implicit scoring of fuzzy matches?
The builtin generic containers are not safe for concurrent use, so you're very nearly out of options except code generation, the empty interface, or a fantastic voyage with unsafe.Pointer before you even begin.
You're right, I should probably update the README :) Fuzzy matching of a given query matches every key that contains the characters of the query in the right order, but not continuously. I.e. 'nna' would match banana. The results are not returned in any order, just as they are discovered when traversing the tree. But, with fuzzy matching, a integer 'skipped' is returned for every result that determines how many characters were skipped when matching. That means for 'nna' and the result 'banana', skipped is 1, because the second 'a' was skipped. So this is something that you can sort after, it works pretty well in my experience. For substring searching, I usually order by the length of the key.
For fuzzy search is better to use [ngram index](https://github.com/alldroll/suggest) .
If anything, necessarily resorting to code generation to avoid duplicating the code by hand should be a harsh reminder of the urgency. Code generation is not an elegant solution to any problem. It's merely the only solution to many problems in Go.
I'd do it the same way as you. There is probably a fancy algorithm you could use, but I find those are usually more trouble than they're worth. You could have a second map that holds the set of duplicates. Then subtract the len of duplicates from the len of unique values.
The easiest method is probably to just add each value to a map, empty the slice, and copy each element of the map back into it. &amp;#x200B; If the slice is sorted, then you can use a linear algorithm to speed up the process somewhat, but Go's maps are generally quite efficient and should be your standard solution to problems like this.
I made a PR on the paho.mqtt.golang project to fix this problem. https://github.com/eclipse/paho.mqtt.golang/pull/319
Howabout this: [https://play.golang.org/p/BUf8hrehfzA](https://play.golang.org/p/BUf8hrehfzA)
 package main import ( "fmt" ) func main() { intSlice := []int{1,2,3,3,4} fmt.Println("1:",intSlice) tempSlice := make([]int,len(intSlice)+1) fmt.Println("2:",tempSlice) for _,value := range intSlice { tempSlice[value]++ } fmt.Println("3:",tempSlice) var mycount int for j,_ := range tempSlice { if tempSlice[j] == 1 { mycount++ } } fmt.Println("4:",mycount) } Simple implementation. \`Prints the number of unique elements in a slice\`. &amp;#x200B; Output : 1: [1 2 3 3 4] 2: [0 0 0 0 0 0] 3: [0 1 1 2 1 0] 4: 3
Thanks for the explanation! I'm thinking about converting my text to metaphone, feeding it into your tree and then score by skipped (less is better). Combined with some additional scoring, that should yield a pretty good indexing engine.
the way you're doing it is pretty good. i can't think of a much better approach conceptually. personally, i'd use a map of ints to empty structs (`map[int]struct{}`) to store each value as empty structs genuinely take up zero space: ``` func removeDuplicateItems(intSlice []int) []int { keys := make(map[int]struct{}) list := []int{} for _, entry := range intSlice { if _, exists := keys[entry]; !exists { keys[entry] = struct{}{} list = append(list, entry) } } return list } ``` but then i'd go a step further and pre-allocate our temporary map and our destination slice. here's my first pass at writing my own: ``` func uniq(s []int) []int { m := make(map[int]struct{}, len(s)) for _, v := range s { m[v] = struct{}{} } rc := make([]int, len(m), len(m)) i := 0 for v := range m { rc[i] = v i++ } return rc } ```
In your solution you'd have to _also_ remove the item from `list` to achieve `[1 2 4]` if that were your goal. If it were me, I would instead try to get a count of each item in your slice, and convert them to a count. Then you can loop over them and add together each number that has count == 1 e.g. https://play.golang.org/p/AVmakplZBoZ
What does this do? Can you link to an article that explains what is meant by decoupling bytes. I tried to Google it, but your github was the first hit :-). Also, running the EncodeBytes example gives: panic: open /tmp/gopath082257932/pkg/mod/github.com/marcsj/decouplet@v0.0.0-20190526213934-a47dc6af8c4e/versions.json: No such file or directory goroutine 1 [running]: github.com/marcsj/decouplet.init.2() /tmp/gopath082257932/pkg/mod/github.com/marcsj/decouplet@v0.0.0-20190526213934-a47dc6af8c4e/metadata.go:26 +0x240
That's pennies compared to usual enterprise pricing. Procurement at my previous employer had no problem paying that, because we needed a single feature of this library -it was cheaper then having a dev work on it even if it would have taken a week. Library itself is ok, but the last time I've used (a couple months) it it was seriously slow in some areas, but only when dealing with large PDFs - a few hundred pages with a couple images each. Slowdown was exponential
I don't know in Go lenguage, but in other languages this is a bad idea, you are creating variables again and again instead of reusing it, so, you are adding execution time and also creating unnecessary variables, create it out of the loop and then reuse it inside, I hope this help you
It should be possible to write a quick benchmark and compare the two approaches.
thats premature optimization
This only goes for allocations, if you are not allocating memory then it is basically free.
If you are not allocating, why will you need to define it inside a loop?
Go is a compiled language. The compiled doesn't create/allocate new types during runtime.
Intuitively I can see no reason why a type declaration should be in a loop and I don't think that type declarations should be as close enough to their use as possible. As for variable declarations, I agree they should be close enough to their use, but then every variable is initialized to its zero value if its not assigned a value immediately. If you use the variable in a loop, you should therefore also assign the right value to it immediately, and then there is no way to do this faster anyway. If you don't use the variable in the loop, on the other hand, then it's not closest to its use and it shouldn't be in the loop.
Yeah, the pricing is fair for enterprises But as a professional who likes to write code during my personal time... $1500 is a lot And if I'm unable to use the library freely (for personal/non-commercial projects) for an unlimited amount of time, I wouldn't even mention it in the enterprise I'm working for Still, it's very strange that the post have a large amount of upvotes (65 at the moment) but very few activity and upvotes in the comments When a post is interesting, it's upvoted, but most importantly people talk about it in the commends, downvotes and upvotes eachother Here, the comment section is practically a desert field &amp;nbsp; A bit off subject, but not that much I just want to give a shout-out to [wkhtmltopdf](https://wkhtmltopdf.org/) It's a very simple binary: you feed it HTML and it outputs a PDF Dead easy to use with Go when coupled with the following native packages: - [os/exec](https://golang.org/pkg/os/exec/) to launch the binary - [html/template](https://golang.org/pkg/html/template/) to generate the html Free, open-source, and very useful especially if you already know HTML
Works fine
If the type isnâ€™t used anywhere else, why not put it close in the loop? That way itâ€™s clear to other people that itâ€™s not used anywhere.
Windows. Thanks I'll try it out
Hi there, Thanks for the great sum up ! Zap's `With` is indeed pretty useful but requires to change your way of thinking about wrapping and bubbling up errors with passing down the logger. Although this depends as the error sometimes should be handled instead of logged. One last simple question (probably more an opinion than a question) Would you rather have 1 or 2? 1: ``` package main // imports omitted func readParam() (param string, err error) { param = os.GetEnv("PARAM") if param == "" { return "", errors.New("PARAM not given") } return param, nil } func main() { logger, _ := zap.NewProduction() param, err := readParam() if err != nil { logger.Fatal("parameter error", zap.Error(err)) } } ``` OR, 2: ``` package main // imports omitted func readParam(logger *zap.Logger) (param string) { param = os.GetEnv("PARAM") if param == "" { logger.Fatal("PARAM not given") } return param } func main() { logger, _ := zap.NewProduction() param := readParam() } ``` Thanks !!
No, doesn't make sense to me. Either you declare it outside the for loop or inside the for loop you have semantically the same results (apart from the scope). Only difference is that inside the for loop you are executing that instruction countless times however all of the times but one is totally useless
In what real world use case do you have a type that's only used inside a single loop?
I think his point is that just defining the type will not allocate memory, so it does not matter (performance-wise) whether the type is defined in the loop or in a wider scope. Or, put differently: the allocation would have to happen inside the loop anyway - irrespective of where the type is defined.
20-30 leetcode tasks, in an HR round. Sounds pretty brutal.
you don't
yes
Passing something that will be cast to interface {} and used in a callback?
Even JavaScript engines optimize this away nowadays, reusing variables is a bad idea unless you need to use the variable after the loop has ended or if the variable is a buffer of sorts.
Why do you even define a type for a single use? Just declare your variables as struct { member int }
It's perfectly valid code. Minimizing visibility is a good practice.
It's not panicing on purpose, but on accident. Such as: mut.Lock() // can panic someArray[i] mut.Unlock() Panics are typically caught at the top level of most goroutines so the app doesn't crash on a panic, but it can also get things into a bad state if resources aren't unlocked properly. Go is easy to learn, but deceptively complex, and having RAII would go a _long_ way toward making things better (and no, `defer` isn't enough).
Thanks for running it, and giving me that error. I just rewrote the versions part, as that was something that never came out during testing, but obviously was a mistake on my part as it was a neglected feature. &amp;#x200B; This library is just a different way of encrypting bytes. I try and call it 'decoupling' as it was referred to in a whitepaper that it was based off(DVNC whitepaper noted on the [README.md](https://README.md)), and decoupling in this case mostly refers to reducing the 'cipher coupling' of a message from its key. In my own words, the coupling relationship between the key and the message is further reduced, and without a key the message is rendered completely useless. &amp;#x200B; The reason I keep referring to it in that way is because I'm not sure better wording for what it does. Google searches don't really give me a whole lot of info on this kind of cryptography, apart from some really simple articles about how people explored this idea with images.
[removed]
1. It conveys the wrong intention, since you're not intending to iterate the type declaration (and it wouldn't be possible that way either, of course). 2. It obscures what is going on in the loop, namely something else then declaring a type.
Iâ€™m actively interviewing for Golang developers in London currently. Most developers have come through a language such as Python. We donâ€™t do anything like Leetcode, instead we give the candidate a take home task that is representative of a task they might do, but also takes advantage of their existing skill set (albeit written in Go). So far itâ€™s been working really well for us.
Why don't you try benchmarking it? Since a struct is just declaring a memory layout, I'd imagine it wouldn't make much difference, but I wouldn't believe one way or another without a benchmark proving int.
A enterprise level shop gave me the following sample project requirements for a mid-level dev role focused on Go: &amp;#x200B; As a user, an online address book as a REST API is needed. The data set needs the following data fields: First Name, Last Name, Email Address, Phone Number . &amp;#x200B; The API need to follow standard REST semantics to support a list of entries, a specific entry, adding, modifying and deleting entries. &amp;#x200B; The code should included go test files that demonstrate how to exercise all operations of the service. &amp;#x200B; Finally, endpoints are needed that export and import the address book data in a CSV format. &amp;#x200B; The hiring manager wanted this done in 48 hours.
These are tags, which are used by reflection. For example the JSON tags define certain properties to the field, e.g. which field they are coming from, or should the value be converted to int (useful when working with JSON APIs). Here is an article that explains them better: [https://medium.com/golangspec/tags-in-golang-3e5db0b8ef3e](https://medium.com/golangspec/tags-in-golang-3e5db0b8ef3e), but I think once you know the nomenclature you'll be able to find more information on them.
db is specific to an ORM or similar library.. but the JSON one is documented in the [standard library here.](https://golang.org/pkg/encoding/json/#Marshal) The tags themselves are part of the [reflect package](https://golang.org/pkg/reflect/#StructTag) that you can use for your own purposes if needed.
Here is a list of some more: https://github.com/golang/go/wiki/Well-known-struct-tags
last week's discussion https://old.reddit.com/r/golang/comments/brthn3/go_is_googles_language_not_the_communitys/
you know that was just google complying with new US government directives, right? No idea why the coverage made it sound like it was Google's initiative at the time.
Note if this is only to unmarshal, you can omit the type declaration and just make a var: var el struct { member int } json.Unmarshal(b, &amp;el)
And this one: https://www.reddit.com/r/golang/comments/bt775a/is_go_googles_programming_language_not_ours/ At least when we see the same thing on other subs, they at least wait like a month for the reeeepoooost.
You can use this for your personal project as long as it remains like that or is open source: tl;dr; from https://tldrlegal.com/license/gnu-affero-general-public-license-v3-(agpl-3.0) `You must disclose your source code when you distribute, publish or serve (i.e. through a web portal) modified or derivative software.`
This would make great practice. Thank you!
Why not create an anonymous struct?
What? wkhtmltopdf is distributed under LGPL-3.0, but you've linked AGPL-3.0 `If you distribute this library in an executable, you must make the source available for 3 years.` No mention whatsoever about published/served versions on a web portal Win!
Nice! I totally missed their public github repo
Also true for virtually everyone on the SDE side of my current company. The SRE side had more people coming in with some Go experience, or so I've heard.
But if every new language looks exactly like the ones that came before we're going in circles, which is what Lisp has been doing for quite a while if you ask me. Because the truth is always somewhere in between, never at the extremes. Every single aspect of software and language design is a compromise. `f` and `m` are better left for local variables, the risk of `fun` and `mac` clashing is negligible in comparison.
I'm not saying that every language based on another language must look the same, I was saying that it's maybe not worth the additional things to remember in this case.
Create a new block: ```go func() { // some code { // new block type element struct { member int } for { // code in loop } } // element is not visible here } ```
Thank you very much! The links are really helping me out to google more info on them =)
Thanks for pointing me to the package, seems really handy indeed. Most likely I will use it for JSON (un)marshal
You might notice that the image types use a (1D) \[\][uint8](https://golang.org/pkg/builtin/#uint8) for storing the pixel data and an [int](https://golang.org/pkg/builtin/#int) for the stride. (bytes between vertically adjacent pixels) Working directly with the pixel data is sometimes reasonable.
The other links posted here so far are far more useful for understanding tags IMHO, but for the sake of completeness, here is the link to the relevant section in the language spec (tags are mentioned near the bottom of this section): https://golang.org/ref/spec#Struct_types
Performance vs potential scope conflicts is the trade off. Also the fact that it looks and smells really weird
It's more efficient to work with 1d. If you really want to use 2d subscript, as in img[x][y], you should better store and process your image by column so that img[x] is a pixel column of your image. I bet the panic you get is due to boundary checks. The difficulty with a convolution window is dealing with the borders of the image. What I would suggest is to process the image by columns if it's stored by column, and copy the column in a bigger slice so that the convolution kernel never moves out of the slice boundary. It's difficult to explain in such a comment.
If it is Yet Another(TM) slices library, how does it compare to the other ones?
Go badly needs generics...
To clarify, the syntax is var bleb struct { a int; b int } bleb.a = 10 etc
No what he means is Go is great because what little features it did choose were most fitting for most use cases or very specific ones. The issue is generics and error handling are general problems with a lot of use cases. If you want a language that doesn't care about that, then there are plenty. The Go team is trying to address this here. https://youtu.be/RIvL2ONhFBI They said they are working on it but that it will take a while to make sure it's like go. I'm sorry they are not quick to fill the gaps enough for some. Again, don't like it then move on. I personally want them to tackle this problem in their own way. Seems to be working pretty well considering they built this language for their problems. But no let's complain about our problems with our language and maybe they'll be rush into it on our terms too. Not open enough not... quick enough... Not like other languages enough... https://youtu.be/2k0SmqbBIpQ
The thing is that it's possible to do HTTP+Protobufs and to even convert between protobufs and JSON. I'm just thinking that if you're trying to draw a comparison, it seems to me that comparing meshRPC with features (and complexity!) of Istio or Linkerd makes more sense. It also seems like toolkits like [Micro](https://github.com/micro/go-micro) or [Go kit](https://gokit.io/) would be useful comparisons to draw. I totally agree with you about the complexity of adopting k8s and Istio, and I think it's great that you're putting work and ideas into that. I just think the tagline is important for helping people decide to look further at your project and comparing with gRPC may not be doing your project justice. (At the same time, I would be interested in a comparison against other Go projects that _are_ trying to do something similar.)
The Go spec does require that signed integers are represented using 2's complement, which may be what they are referring to. I think it also requires that CHAR\_BIT == 8, but I can't find a solid source for this one. This is true for Rust too however, so I'm not sure what they are trying to get at.
No performance tradeoff whatsoever. Unlike, say Python, types are not created at runtime.
Oh okay. That actually makes me like it less since itâ€™s not obvious whatâ€™s happening
People who do things 'shamelessly' often are very shameful
If the input slice is sorted, as in your example, the solution is trivial. The result can be obtained with a single linear pass. Otherwise, the use of a map would do the job. If efficiency is relevant, and input slice length is small, I would copy and sort it to use the trivial algorithm. It is also possible to use efficient map as a bit map or simple slice where the key is the index. All we need is a bool flag for each value.
&gt; "Go is not a community project" Link?
The whole process for creating a self-compiling compiler is called [bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(compilers\)), and yes, you create a compiler/interpreter using another language and eventually move on to a compiler made from a subset of the compiled language.
In my test code, I'll often have table-based testing like this: for _, test := range []struct{ Input string Output string }{ {"In", "Out"}, ... } { // test code here } I find that in non-test code it's never very useful.
The main things that Go panics on (array out-of-bounds and null pointer dereferences) are undefined behavior in C++, so it's not like the most popular RAII language is great for letting you correctly resume execution there either. If you view panic as just a way to get clean debug info where the error occurs and stop security holes it's not so bad... I'm on the fence if RAII or exception-type error handling (with panics) is a good idea. Designed-for errors can be handled explicitly, but can most programs really recover correctly from accidental bugs that weren't even considered when the code was written? Locks are one thing but there could easily be other invariants that get messed up when execution abruptly stops in the middle of some function that wasn't designed for it. And if the error isn't considered when the code is written, that situation isn't likely to be covered by tests either. I guess it depends if it's better to keep (potentially incorrectly) executing or just quit.
Conforming to an externally-defined JSON or XML structure for (de)serialization is another use case, especially if you're using a different data structure internally.
With compiled languages, especially modern compilers, you really have a lot less control than you would expect. But types should just be assumed to have no overhead unless you are doing things and worrying about memory alignment.
been there, done that. Switch to python and save yourself a bunch of time.
&gt; (forgive the Javascript terminology)? Predates JavaScript by decades.
Thanks. I had a look and to me it looks like the cipher is a variation of a simple substitution cipher. A byte X will be replaced by a random keyword from a (small?) set of keywords determined by the key. The substitution does not depend on the position of the byte X in the message, only on the value of the byte and the key. I believe such substitution ciphers are quite weak and can often be broken by hand and are found as puzzles to be solved with paper and pen. The one-to-many, random substitution function is a bit odd and leads to that the same ciphertext can be successfully decrypted using different, similar keys. [https://play.golang.org/p/XDuSJsEOpmN](https://play.golang.org/p/XDuSJsEOpmN) DecodeBytes("[dcplt-byteec-0.2]f4j1g5j1c5j0d4j1a4j0", "abc123") -&gt; "hello" DecodeBytes("[dcplt-byteec-0.2]f4j1g5j1c5j0d4j1a4j0", "def456") -&gt; "hello" &amp;#x200B; Do you know of real use cases for this cipher, or is it more as a curiosity cipher? How is it intended to be used? As it is, I don't think it is directly suitable for encrypting passwords or other secrets. I don't intend to sound discouraging in any way, but just want to be extra careful when it comes to cryptography and security. In general it is recommended to play safe and select well known, well understood, thoroughly researched cryptographic algorithms, modes, formats and protocols. There are implementations for many such algorithms in the Go standard library. Even then, I often find it difficult to pick the right ones and be certain how to use them correctly. Here is an example that I think looks good in how it describes what it solves and how to use it correctly: [https://github.com/minio/sio](https://github.com/minio/sio)
thanks for the help buddy but a few boundary checks made dat easy for me
thanks for da help buddy i tottaly got you...
&gt;we give the candidate a take home task For a job interview? Why would a candidate agree to do such a task for free? Especially in this job market?
&gt;The fancy word for this is "services architecture" Yes! That's the way to go. To make that work you need a "Service Layer" in your tech stack where you have all the hard-coded (or dynamic) SQL set up to provide data to ANOTHER layer, which is the actual REST API. This abstracts the underlying persistent database into what the API trying to represent.
In my experience, the employer doesn't care that much what language a candidate has experience in as long as they can write code, especially for junior positions.
Take home interview tasks are very common here in London and their use seems to be increasing more generally from what I've read.
Ironically, this example won't work because the json package cannot access unexported fields in structs. Capitalize member and you'll be all set.
**meshRPC** does the same job that **gRPC** does. It takes a contract (Go interface instead of protobuf schema) and generates RPC client/server code allowing services to call each other over network, with streaming support as well. It is not cross-language and cross-platform yet, unlike gRPC, that's a simplification for now. &amp;#x200B; I love how a piece named ApplePen gets downvoted by people who thin it is not an Apple, and people who think it is not a Pen ;)
The title of this article makes it look like go handles boolean logic different than other languages, but this is not the case. If you know basic boolean logic, this is not worth reading.
That's not entirely true; you can create new types dynamically using the reflect package.
 asically the answer is: no. If you know the type of the context implementation that holds your value you might be able to do some magic using reflection but that is brittle and might break.
With all due respect, I don't believe this is a substitution cipher. In this case, by taking the differences in those places on a key, we're referencing something known with instructions that hardly mean anything without a key. In your case, you're using about as simple of a setup as you can, understandably, but a key that small will never produce cryptographic secure output. When you make a key as small as that with very little variation, my byte encoder is left to find the variations itself, and in your case you are able to reproduce it by making the differences the same. &amp;#x200B; As far as the keywords, I'm not really sure what you mean. The alphabetic letters are used to vary the input for when a key is not sufficiently different enough, by supplementing the values in those positions for a sufficient difference. That might make it more predictable in some sense, but among values without information as to the key, I'd argue it's pretty meaningless. I think if you were to give the image encoder a try, it would make a more compelling case. The byte encoder is made to be simpler and more approachable, but it does come at the cost of allowing very small keys like those ones, and supplementing values which may be more visible. In the case of the image encoder, I'm measuring color values in pixels on the image and comparing them against other spots along the image. &amp;#x200B; I certainly agree it's good to be careful. I'm not intending this to necessarily be used as the only tool in a toolbox, but I thought that if by using this we could further obfuscate a message, and maybe even encrypt it again with something more standard, it could be useful. It absolutely isn't done by a long stretch, and I'm glad to get some feedback. The intended use would be to aid in reduction of rounds used in a password manager, or something similar. Thanks for the thoughts and criticism, I appreciate the interest and help.
Some suggestions: * remove the `Slice` suffix from the types, the package name already qualifies them. * rename `IfEach` to `All` * rename `TryEach` to `Any` * remove `SortAcs` and `SortDesc` and implement `sort.Interface`
[removed]
^YES Especially the first point
[removed]
&gt;To getting support added for obscure targets and you will soon realize how much weight Googleâ€™s corporate word has. **Citation needed.** How does "not adding support for obscure targets" further Google's corporate goals? &amp;#x200B; Also, adding new architectures to Go is pretty trivial *if* you have a good CPU manual in PDF. Instead of hand-writing a new assembler for each arch, Go has a generic assembler that maps instructions based on [parsing the PDF of your CPU manual](https://godoc.org/golang.org/x/arch/x86/x86spec). It's completely automated, so it's really "writing a parser that understands the Instruction Set Architecture ([ISA](https://en.wikipedia.org/wiki/Instruction_set_architecture)) from the documentation", not writing a new assembler manually.
You will save yourself some headaches by writing a function that returns a 1d index based on a 2d coordinate and the image width. You may end up replacing it during optimization but it will help you figure out bounds issues better.
This sounds like an XY question. What are you *really* trying to do?
Do you mean ashamed?
&gt;*&gt;&gt; If you want a language that doesn't care about that, then there are plenty.* Sigh
[removed]
Would SIMD help with that? Like SSE? Examples are in the crypto packages https://github.com/golang/crypto/tree/master/blake2b
Ken and rob sighed during a c++ build and didn't complain and go was then born. Sigh...
I approve of your variable naming convention
We are happy to take on such issues when reported to us. In those cases it is usually helpful to get access to the file and a code snippet so that it can be reproduced. We recently added a lazy loading feature which loads only objects as they are encountered, rather than loading the entire document tree. This significantly speeds up processing in many cases, especially when only parts of a document are being processed.
You cannot, but why would you want to?
The license is perpetual, it does not expire for versions released within 1 year of the license creation date (so can use any tagged releases within that time frame).
I'm not a cryptographer and I readily admit that I don't really understand what goes on with the substitution function and the reasoning behind it. I've never seen anything like it. I just drilled down the source code and found the basic primitive that every byte is replaced by a short string symbol (keyword was a bad term) something like "k19g2". The substitution depends only on the input byte, the key, and a small pseudo-random value. So if say "\\x00" is once replaced with "a4c0", then every "a4c0" in the ciphertext corresponds to "\\x00" in the plaintext! Because of the small pseudo-random value, "\\x00" may map to a small number of other strings like "f3a1" and "a2a2" also. This is so, regardless of whether I understand how the substitution function calculates the output or why. I called this a variation of a substitution cipher (every symbol is replaced by another, in this case one of a few), but I believe you if you say that is not the correct term. It of course depends on how to use this, but such a cipher can be open to many different attacks. Frequency analysis is possible. A known plaintext allows decryption of data encrypted with the same key. It is unauthenticated, so an attacker can change any byte at any position in the plain text by editing the corresponding substitution string in the ciphertext (may not be able to freely chose what the resulting plain text byte will become). An attacker can copy, cut and paste around strings in the plain text by doing the same operations on the ciphertext. And to demonstrate another effect I redid the classical "ECB penguin" example ([https://blog.filippo.io/the-ecb-penguin/](https://blog.filippo.io/the-ecb-penguin/)) with this cipher. I took a pic of the gopher mascot ([https://blog.golang.org/gopher/gopher.png](https://blog.golang.org/gopher/gopher.png)), converted to PPM as in the ecb penguin blog post, and encrypted using EncodeBytes() with a randomly generated password. I then did DecodeBytes() with a completely different, wrong password and got a new picture: [https://imgur.com/a/vsx4bDT](https://imgur.com/a/vsx4bDT) . So in these examples I clearly used the cipher in a wrong way, and I need to be careful when I don't really know how it is intended to be used. Is there some article explaining the algorithm and its security? The guy who wrote the white paper seems to not have followed up on this and the web sites of the project and the company behind it no longer exist.
I'm also fond of `flerb` and `gleb`
wow, I did use them without thinking much where they come from.
that seems like a great idea but wouldnt it be slow... like the time to copy that thing into something oter and then taking it back... if you have something in mind or have seen something of that sort workin fastly .. please share dat
thats a high level stuff.. but thanks
I second that.
/r/ThereWasAnAttempt to create a clean and native-like Go library.
k
No it won't be slow, it's like five CPU instructions to calculate a 1D index from (x, y) and the width of the image.
So, the point is that, as is compiled the type is defined but it's not created in memory so you are not wasting memory? I think this is a bad practice to define something inside a loop but, I suppose you have more experience than me, reusing variables is not the exact name, is defining them before, and using them after, no using them again and again, sorry for the bad english
Thanks, makes it easy to understand.
Fantastic, thanks.
`context` is often used to store certain data for systems with cross cutting concerns, often interacting with RPC mechanisms. For example, timeout values, [distributed tracing system metadata](https://github.com/opentracing/opentracing-go), and so forth can be stored and emitted in headers. Often, the authors provide APIs to extract or otherwise manage these values. Very rarely, they neglect to do so, and it becomes painful to accomplish certain goals. Often the best solution is to file a ticket and / or write a pull request.
There is a very small overhead calling a function. When working on images it does become noticeable as you will literally be calling it every pixel you iterate through. But it is fine for prototyping and can be refactored our once you have a working filter.
It's very nice answer!
Thank you for your method!
Awesome answer!
Finally it had got the goal.
It's not bad practice per se, it's just a rare case. It's perfectly fine if you need the type only inside the loop
Thanks for updating the readme with this info. This does make it a bit clearer for me.
I can't watch the video right now, but I use protobufs at work with go (and a variety of other langs) and I have to say fuck yea get to learning protobufs y'all they're awesome
I think there's a problem with the setup. You have an error displayed in your first "go get" command, and when I followed your instructions (on a Mac), protoc didn't exist. I followed the instructions here: https://github.com/golang/protobuf which says the protobuf complier needs to be installed separately (not as a golang module) and to download the compiler from here: https://developers.google.com/protocol-buffers/docs/downloads.html after I did that that things were ok.
&gt;What if I call FpReduce on a &gt; &gt;nil &gt; &gt;receiver? If you read the source code, you will see. [https://github.com/kodecreer/go\_vector/blob/master/functional\_programming.go](https://github.com/kodecreer/go_vector/blob/master/functional_programming.go) If the type the vector has is not a type that has the + operator supported, then it would produce panic() where I describe why it failed. &amp;#x200B; &gt;what if I pass an invalid index to RemoveAt I'll add that to an update. Please add stuff I probably missed on the issues tab on Github, so I am not walking in the dark. &amp;#x200B; &gt;What if I pass a function to FpMap whose argument type does not match the vector's element type? The vector functional programming only works if all of your elements are the same datatype. The way I structured the code makes it impossible to use a the FP functions in a vector with ints and strings. Golang already handles this by saying something like "int is not Player" or something like that.
Iterate through all the elements \*inside the each iteration\* * check if the map has the value as a key * if it isn't add the value to the map {value : index} * else remove the element from the slice.