If you're talking about javascript libraries, like node_modules/ folder, then yes. But I guess that exe would be so so huge.
On mac it's control + number so if you wanted to go to the first window, it would be control + 1.
Vim!
&gt; I encourage you to take ownership of any binary in a linux distribution of your choice What about Ubuntu snaps? From what I understand they statically link all dependencies and package it to a single thing that just works.
I was talking about the go part. Electron (is) apps are usually 100Mb+ so ye,huge. I basically just have a small go exe that scans the filesystem for media files. Using goroutines is just faster than doing it in J's.
Sweet, I just joined too.
Oh now I get it. Thanks
what type of ml algos you are looking for? :) would suggest you look into `gonum` – a mature scientific calculation lib, and `gorgonia` if you are looking for something similar to tf. 
Have a look at Just for Func: https://m.youtube.com/playlist?list=PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ
I recommend a course by Todd Mcleod on Udemy which can be found here https://www.udemy.com/learn-how-to-code/. He really cares that you learn how to code in Go and is very dedicated to it. He also has a Web Development with Go course on the site as well. If you want course that is brief but in depth I highly recommend https://appliedgo.com/. It's a little spendy but it's worth it.
vscode 
I've taken 2 of Todd's courses, both are quite good. You can also visit his new teaching website Greatercommons.com i think he is offering the intro class for free. Also check out his youtube channel, he post his recorded live classes there as he is also a college professor.
Well I don't know which libraries you mean. If you're talking about shared libraries like libssl, libvips, libjpeg, etc., then I don't know of a way you can package them into your program, if possible. If you're talking about libc and you're using only vanilla go code without external C libraries, then you can produce a static binary with CGO_ENABLED=0 environment variable. Any assets you have you could package into the binary with go-bindata, or something else, I've seen a project by rakyll recently which does pretty much the same, it's called [statik](https://github.com/rakyll/statik). Hope any of this helps ;)
Why can't you just package the whole program together in a zip or using an electron packager?
Replying to both u/_el_psy_congroo_ and u/MattJBrowning I did try one of Todd's Udemy courses. With due respect to Todd, as we all learn differently (and clearly, you both enjoyed his course), it was tough for me to get through. It was somewhat... informal. Seemed as if he headed out to his garage (?), and just started rambling. I found it difficult to follow, and difficult to stick with. 
Emacs although I am trying out goland
I can but I still do not know how to properly load libtag so my go code works without the user having to install it from the command line.
Yes. As I said, a pyramid scheme. Pushing the problem down one level further, to the user.
Shared libraries. I basically want have a small exe written in go that uses a shared library. I can easily distribute it but I do not know if and how to load that shared library once the go exe starts. Something like loaddll that can load a relative dll file instead of having it installed on the system would be sufficient for me.
If you instantiating it from the electron server code, why are you having the user run it from command line? 
I completely understand, I found that to be the case later in the course, most likely due to spending so much time doing it in a single session. I also think it depends on your background, I knew a fair amount of general programming before I took his course and I found myself looking over the code on Github because the course I think is geared towards absolute beginners, but he does have some good things to say throughout the course.
Maybe I wasn't clear enough. So the application is client side. No server involved. I need to scan thousands of media files and extract their metadata. I previously have done this using node. But the performance was so bad. No mutlithreading made the whole process take minutes to complete. So I decided to use a custom binary that will do the stuff using go with multiple goroutines. It speed up the process from taking multiple minutes to just 2 seconds. The problem that I know have is that I rely on libtag. I am creating the executables from go using dynamic linking (at least that is what the library go-libtag from wtolson does). So I need the users to have libtag installed. My question now is, how can I manage to somehow package ligtag with my exe/electron app so I do not have the users to install ligtag separately. My first idea was to just package the dll/so and load it during the startup of my golang part using some kind of loaddll/loadlib runction. Seems like such function doesn't really exist. The second idea is to somehow statically link the lib. If I am not mistaken this would package the Li rary into the exe file,meaning users do not need to install it on their system separately. I can easily add any dynamic libs to the electron part as I use an installer for that. P.S.: the golang part does get called from within node/electron and just waits until it finishes to retrieve the data collected. Hopefully I explained it better than the first time.
This is what I'm not understanding. In what circumstance do you have to make changes to a Go program across Linux distributions? From my understanding one of the main draws to Go is how easily cross platform it is, and that's not even a separate platform. I don't like putting that much trust into the hands of the software developer that I'm using libraries and you're delusional if you think any business will as well without concern. This just falls into more of Go's flawed philosophy of taking control from the user because "they don't know any better". The fact that somebody versions their use of a library or API is so that they don't have to do extra work in case the idiots supplying the library or the API break something. I don't know any reason someone using an API would not update to the most recent version of an API if it is backwards compatible (as it should be).
Very interesting read. I was hoping that you'd show an example code snippet for the last algorithm thought; it's a really smart idea. The bit manipulation sounds like a lot of work though, especially since all (modern) computers are byte addressable.
I don't disagree but how can it still be a problem when instead of dealing with dependencies you use a single binary/static/thing that just works?
It's even better to have your tests be part of your code.
Both of the full algorithms are simple to describe but have a bunch of bookkeeping in order to actually produce workable implementations. My implementation (go-boomphf) is about as simple as it gets since I don't yet support concurrent constructions. The paper was pretty readable too.
Was a good read, but while you compared it to Go map it would be very cool to see it compared to cdb (DJB's C one, or I've seen a couple reimplementations in Go) ... or even http://cmph.sourceforge.net/
I'll go check those out, thanks!
The cmph library is the hash/displace algorithm I describe. Likely the cgo overhead would make it slower, but the compression that cmph would reduce the space overhead. For a Go version of cdb, my *guess* is that a perfect hash table would be faster than cdb (since cdb is designed to be an on-disk format, rather that in memory) and also use less memory (since cdb also stores the keys and has larger values).
First I also was annoyed with a Todd's webdev Go course, but later I've got that strong opinion that it was one of the best and comprehensive courses about Go I did. Sure it is somewhat "boring" from time to time, but Todd's courses are composed in a such manner to give you a solid background and present entire toolset (after web Go, I took another as well with this tutor). I have to stress that I had rather comprehensive knowledge before - so there was a bunch of an irrelevant content for me, but in total I had enjoyed it. In fact I am still visiting Todd's source code whenever I need to solve some complex issue, even that it was 3 months ago since I did this course.
Do you have your GOPATH set? Go expects things (source code and libraries) to be in a particular place in relationship to GOPATH. Take a look [here](https://github.com/golang/go/wiki/GOPATH) for some background. 
Spacemacs
u/charliegriefer at first I felt the same way, but there is hardly another individual online (that i know) that explains GO with as much clarity. What I did to help get through the slower parts was I turned the playback speed up to 2x. And if you're really good at faster speeds there are chrome extensions that allow up to 10x video playback, though u cant use audio after 4x. I hope this helps , if you find any awesome online courses please DM me. I would love to learn more from different perspectives.
Because the problem isn't to get something that "works", but to get a sensible, operable software stacks with upgrades. If a critical security bug happens in `x/net/crypto`, having a "single binary/static/thing that just works" is just about the worst thing you can have - especially if it's deep inside a dependency stack where each level thought vendoring a fixed, years-old version would be an amazing solution because nothing could ever break. People have to *update their packages*, not isolate themselves from upgrades, pretending that the problem went away since *they* don't have to deal with it.
&gt; This is what I'm not understanding. TBQH, that seems to be the core of all the discussion. I can pretty confidently state, that I understand the problems that vendoring and package management tries to solve. I have fought them and got annoyed by them myself quite a bunch. Yet, the other side of the argument doesn't seem to (even really try to) understand the problems they *cause*. &gt; In what circumstance do you have to make changes to a Go program across Linux distributions? A security hole in a `x/crypto` package, imported by several thousand packages would be the example coming to mind. Have fun pushing that out in a world of dozens of layers of vendoring, rotting for years, forgotten by their maintainers. Or the little things; a 10% speedup in the protobuf library, that you want your fleet to take advantage of. Or - as was the case for me - you simply want to take advantage of a new feature in your static site generator and can't, because the debian-package is old and stale and you are literally going crazy when trying to untangle that mess and pull it to a newer version, because of vendored incompatible libraries and unlicensed copy-paste code. &gt; I don't like putting that much trust into the hands of the software developer that I'm using libraries You are, indeed, putting *ultimate* trust in them. Their code runs on your machine, that is pretty much the worst case scenario, from a trust-perspective. It is intellectually dishonest to claim, that this is a sensible line to draw. &gt; This just falls into more of Go's flawed philosophy of taking control from the user because "they don't know any better". That is the opposite of what the GOPATH/go-get approach is about. That is about "we trust developers to do the right thing and not unnecessarily break their reverse dependencies". Indeed, Go gives you *far* more control than languages like python, node, ruby, rust, perl… You can use any kind of hosting, versioning, release strategy… that you'd like. It's exactly that freedom that people complain about. &gt; he fact that somebody versions their use of a library or API is so that they don't have to do extra work in case the idiots supplying the library or the API break something. a) Calling people whose code you are using idiots makes you look ungrateful and childish. It is certainly not helping your case. And b) if you have such a low opinion of them *you shouldn't use their code*. I hope we can agree, that knowingly using code written by idiots constitutes… idiocy. &gt; I don't know any reason someone using an API would not update to the most recent version of an API if it is backwards compatible (as it should be). Yes, I tend to agree (though, seriously, there *are* good reasons. The disadvantages just outweigh them as a widely used strategy). Which is why I don't want people to vendor their stuff and pin versions. Use HEAD. But making-my-case-for-me aside, it turns out that in practice *people just don't*. People just vendor and forget. You don't know any reason to not upgrade? Plain laziness or forgetfulness is more than reason enough.
Maybe this will help? No idea if it's Linux exclusive though. http://gridengine.eu/index.php/other-stories/232-avoiding-the-ldlibrarypath-with-shared-libs-in-go-cgo-applications-2015-12-21
I was implying they are idiots if they break backward compatibility. I was not calling developers that supply libraries in general idiots, so my apologies that I came across that way. Either way, it feels that Go does have quite a few restrictions in regard to how one writes code. I mean, hell, it forces its own convention and tries to mask that by saying "the lexer doesn't understand curly brackets on the next like". I really don't feel Go is as "developer choice centric" as people make it out to be. The time I spent writing it I really just felt boxed in. I had to write my project in the format they told me to, if I wanted a certain version of a project too bad. Using the Go QT bindings at the time for the software I was writing was extremely subject to change. Yet, they gave me the functionality I needed and due to simply being bindings were not subject to the general security flaws or bugs that most APIs are. Yet because I could not version and because go get would grab the most recent version on the master branch, my code was subject to breaking anytime they changed a small feature. It's just not something I want to worry about when writing software. 
One of my side projects was made specifically to figure out how to handle a database. I ended up doing most things manually through `database/sql`, using the `github.com/lib/pq` driver, with migrations handled using `github.com/pressly/goose`. Check it out: https://github.com/fsufitch/prez-tweet/tree/master/prez-tweet-server/db (political implications aside) Some notes on how stuff works: - *All* the database interactions are abstracted by the `db` package. None of the rest of the code is aware of how the db works. - The [`setup.go`](https://github.com/fsufitch/prez-tweet/blob/master/prez-tweet-server/db/setup.go) file contains some boilerplate that sets up a singleton connection and can create DB transactions. I checked that all this is threadsafe and won't blow up in my face, too. - Table/schema creation is handled via the migrations [here](https://github.com/fsufitch/prez-tweet/tree/master/prez-tweet-server/db/migrations). This code is triggered by the [`RunMigrations()`](https://github.com/fsufitch/prez-tweet/blob/master/prez-tweet-server/db/setup.go#L37-L50) function, which itself gets run [at server start time] (https://github.com/fsufitch/prez-tweet/blob/master/prez-tweet-server/server.go#L49). The biggest difficulty is running queries with a variable number of parameterized arguments. For example: `SELECT [...] WHERE some_value IN ($1, $2, $3, $4, $5, ...)`. Those numeric designations for the arguments need to be there, and I ended up with a somewhat dirty solution of a function that generates them. See for example [here](https://github.com/fsufitch/prez-tweet/blob/master/prez-tweet-server/db/tweets.go#L20-L44). I don't like it, but I see no better way with the tools I am using. I don't know that this is the best way to handle DB interactions, but I learned a lot doing it. Hopefully it helps you too!
From my recent researches, I don’t think Go is actually a good fit for what I’m seeking for. Go is currently not able to output bitcode which is required if you want to write something that will run on WatchOS and TVOS. Even if there is some tentatives to improve this part of Go, this is still very experimental for now and no official ETA has been given. Hope that will help some folks.
I kind of agree with this. Sure, every time he laughed he sounded stoned, but I’m never going to forget the”responsewriter, pointer to a request” method signature ;)
I actually paused the video and wrote that down. :)
Nice read. I made a perfect hash generator some time ago here: https://github.com/tdewolff/hasher. I wonder if I can make it faster with some of the algorithms in your article ;-)
&gt;"handle your dependencies" is a euphemism for "giving you the illusion that you don't have to care about them". Or you know... Actually manage the dependencies.
This looks pretty reasonable: https://github.com/herohde/beam/blob/go-sdk/sdks/go/examples/cookbook/tornadoes/tornadoes.go This makes me happy!
Did you look at how gperf works? The hash/displace algorithm could easily generate static tables as a build step.
It seems to shift between the open editor windows. What I wanted was to move through Explorer -&gt; Editor -&gt; Terminal.
I use sqlx, upper.io/db, or sqlboiler for connecting to Postgres.
Avoiding SQL injection works the same way in most languages: you use bind parameters and you don't concatenate user input into sql. This is important to learn, and if Laravel was sheltering you from it, that's not really a good thing IMO. For migrations, we use goose. It has some quirks but gets the job done. I agree that gorm's migration situation is strangely crude. I have no idea how anyone lives with that.
I agree with the mutex approach above. It will be simple and efficient. You may also want to limit the number of connections the server holds so that the limit is more is more predictable. If you have to scale beyond one web server I suggest using something like Redis to keep track of which instance has a web socket connection to each user. 
[removed]
The only thing it misses is auto-completion. It is scriptable with Lua, so build shortcuts can easily be added for example.
I am fairly new to Go in general. Just written a little here and there. The GOPATH is so different than any other language I've used thus far. It takes getting used to :/.
LiteIde. It is blazing fast compared to other IDE's I have tried and it works very well. 
Debugging the way it's implemented in IDEs is only useful for toy projects / toy code. Problems in typical code deployed in production (which results from bugs not caught by testing) can only be solved by studying crash reports and tracing and looking at the code and thinking. So my humble opinion is that a programmer wishing to work on highly-concurrent code should try to develop a skill of "mental" debugging rather than stepping-through a single thread execution and poking at variables — this simply doesn't apply to solving real problems.
To those who pondering clicking that link: it's not about GUI, it's about bolting Electron on top of your app. Not worth spending time reading unless you like this sort of "solutions" already.
Sure, I should have made this clearer in the title. Cheers
The title should be mentioning electron like solution.
I'm well aware of the fact I'm an old fart, and hence I naturally refuse to repurpose well-established terms. I have already seen how the term "API" was repurposing by all-web kiddos to exclusively mean what we old farts would call "web API", so let me try to defend the term "GUI", sorry :-)
Deleting and recreating the thread
Makes sense, I've deleted this thread and recreated one to make it clearer. I don't want to mislead the community :)
Go doesn't have a DLL loader or something that I know of which you could hook into specifically, that is you'd have to resort to CGO and hook into the libraries you want over a FFI bridge. It sounds overly complex for your use case tho, but it depends on your shared library I guess? Projects like [nexe](https://github.com/nexe/nexe) lead me to believe that what you want would be possible. I did a write up [on nexe some time ago](https://scene-si.org/2015/10/08/run-nodejs-anywhere-using-docker-and-nexe/) if it helps, but I'm not sure how much of this is feasible without underlying support, ie, what Go would have to provide to make this possible. I'm supposing Docker isn't a valid use case for you, so I don't have to recommend that one? Bringing the libs you need is an usual use case for Docker, maybe there are some projects which can deliver the container as an exe :) I know it was a valid use case some time ago, but I don't know of any project that set out to provide this.
Cool project. Thanks for this. I have ran the demo and it worked flawlessly. I have not check your underlying components much but can you tell us more why did you need to build the custom tools (the asti-bundler) ? I do not have much experience with electron so I do not know what's required to hook Go to Electron to make it work.
I recommend https://github.com/doug-martin/goqu as SQL builder, if your SQL need to be managed well.
Yes but with snaps the responsibility for the upgrade falls to the library author. The best the linux packager can do is get the latest version which will hopefully have fixed the security issue if the library author cares enough. &gt; but to get a sensible, operable software stacks with upgrades. That's how the current system works. Take a look at snaps.
For sake of everything good, please, get rid of that smooth scrolling...
Thanks for the post. I noticed some "odd" code. WindowOptions: &amp;astilectron.WindowOptions{ BackgroundColor: astilectron.PtrStr("#333"), Could you explain why something like this is not possible, i.e., using a value instead of a pointer: WindowOptions: &amp;astilectron.WindowOptions{ BackgroundColor: "#333", 
The problem when you want to run a GUI is that the user doesn't execute your binary through a terminal. He double clicks on it. And he/she usually wants to double click on a nice icon instead of a scary binary. Because users are scared (as they should be :D) Therefore, once you have built your binary, you're still missing a step to present the binary nicely: - add the proper files + folder structure for MacOSX users to create a valid Mac App - embed an icon to the .exe binary for Windows users - add an optional script to add a .desktop file for Linux users Also, in order to make Electron work, you need to have Electron present on disk as well as you js/css/html files. The best solution for that is to embed its content in your binary and disembed it upon the first execution. That's what [astibundler](https://github.com/asticode/go-astilectron-bundler) does: - embed your resources in the binary - for windows user create a .syso file with the proper icon - build the binary with the proper ldflags - add the proper files/folders (for Mac for instance) 
IntelliJ, but I'm planning to switch to GoLand now it's come out of EAP. I do like having IntelliJ for the plugins you can't get in their other IDEs though, but I guess GoLand will get new features faster than IntelliJ will.
In that specific case, using a pointer to a string is not really useful (I keep it so that everything is consistent). But for other types this is really important. Indeed, with Javascript and Electron we need to make sure JSON fields that needs to be empty (so that they can get assigned default values) are indeed empty. Problem is it's not doable in GO unless you use pointers instead of values. Here's an example: you need to send an `int` to Electron that will default to 3 if the field is not present. Of course you'll add the "omitempty" attribute to the json flag in your GO code. Problem is, if you want to send 0, GO will omit it in the JSON, and Electron will understand 3. BUT, if you use a *int instead, if you set it to 0, the field will appear in the JSON since GO will consider it's not empty. Does that make sense?
Or even many individuals to be honest.
Yeah, gotta agree with /u/ZetaHunter, please remove the scroll hijacking, it's super annoying.
Ok, I understand the reason for your decision better now. In my opinion you should not expose such detail to the user and I'd still use values. Just remove the `omitempty` attribute and Go will print out its default value (e.g., 0 for `int`). As the Go default value `0` might not reflect default values for Electron, just make sure to set the Electron default values in Go first. Might as well combine that with a functional approach. https://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis A call could then look like: astilectron.NewWindowOptions(astilectron.WithBackground("#333"), ...) Or: w := &amp;astilectron.NewWindowOptions() w.BackgroundColor = "#333"; In both cases the `NewWindowOptions` function initializes the struct with the Electron default values.
Yeah I get your solution, but the main drawback is that I would have to keep up with Electron's default values which I honestly can't. I do agree with you that kind of logic shouldn't be exposed to developers, but that was the most readable and most maintenable solution for me.
You can definitely have more than 18 goroutines running at the same time. Without seeing your tests it's hard to say what exactly you're measuring. Each goroutine takes about 4.5KB of memory, which means if you have at least 4GB of ram, you can have one million of goroutines running already. Here's a more exact number in the form of a [stackoverflow reference](https://stackoverflow.com/questions/8509152/max-number-of-goroutines).
&gt; Yes but with snaps the responsibility for the upgrade falls to the library author. The best the linux packager can do is get the latest version which will hopefully have fixed the security issue if the library author cares enough. Fair enough. That means they no longer actively participate in the pyramid scheme. But it means - from my POV - they no longer fulfill what I consider the primary function of a linux distribution. On the bright side, as bad an implementation I consider snaps to be - at least finally there might be a push towards a unified package manager that *could* reflect the realities of open source and push the responsibilities back up the dependency tree. :)
https://github.com/ddo/advent just done the day3 without creating the grid :) no bonus yet. 
Acme I'm using acme for many languages (Golang, Ruby, Rust, C...)
I only get this on save, maybe you're saving everytime you stop typing?
Look, I understand the old "x is a crutch" thing. And I won't tell you an orm can't be a crutch in some cases (and op case is one of them, imo). That said: an orm can do wonders to make maintainable, scalable code for bigger projects that need all type of data flowing through it. There's just cases where dealing with creating SQL queries will fuck you up. I mean, there are other solutions, but an orm can be good for a team effort. 
Search for example for the corresponding words in the command palette: focus terminal, focus file explorer, and focus editors view. In case those do what you want then you can just bind them to the keys you want. 
Nice. I managed to do part one without creating the *whole* grid, but for part two ended up generating the entire thing. 
Emacs.
yeah i still thinking about the part 2 solution without creating the grid. possible?
Yes, I know that golang can turn on a lot of goroutines. My concern is that when handling a lot of tasks, such as 10000 tasks, I turn on 18 goroutines to consume tasks to accomplish tasks faster than turning on 256 goroutines. In other words, too much goroutine does not improve performance, I think probably with too much CPU switching?
Isn't the concurrency achieved depend on the parallelism?
The network bandwidth isn't actually determined by the client. The client can do relatively little to influence it. In actuality, the server will push data as quickly as it can manage, which will then land in the buffers of the operating system your client runs on (to a good approximation. There are more complexities with intermediate routers). So, the best a client can do, is read slower from the kernel buffers, letting them fill up quicker. That *will* eventually lead to less bandwidth consumed, because it will lead to TCP backpressure (i.e. the network card will stop ACKing TCP packages that it can't buffer, which will lead the server to slowly throttle the connection), but it is a very inefficient way to do that and will lead to extra chatter on the network in-between. A *far* more effective strategy is to throttle the connection server-side (and you might want to do that anyway; it would be bad to rely on clients to well-behave for a safety like that). For example, you can limit the rate at which you write to the `http.ResponseWriter` given to your Handler, giving you very good control over the bandwidth used (to the lower bound of 1B/TCP idle timeout).
I think in a certain range, yes.
If your effort requires no complexity. One of the main reasons on why ORMs are so bad is that because people don't know SQL, they use only the most basic functionality of the ORM (and not all ORMs are created equal). I have seen major shit shows because people did not take the time to learn SQL. It would have been a shit show whether they used an ORM or not. I would also argue it does not make scalable code. If your code is performing an unnecessary number of queries because the ORM cannot create the appropriate single, multi-table join query, or multi result returning query, you are just wasting cycles. Now with all that said, code readability trumps pretty much everything else. ORMs can obfuscate what you are trying to do, but in some simple situations can be acceptable.
Ah, thanks for letting me know! fixed.
Ah, that answers a lot of questions I had. Thanks, wasn't sure where I needed to look to figure this one out. I will indeed do the throttling server side. Thanks :)
I have a question: does it ever make more sense to forego Electron, and just make my Golang desktop application a web server that opens an embedded HTML file in the user's default browser, and have it send messages back into the application using local HTTP requests? It seems like it'd be an over-elaborate weird solution compared to a native UI toolkit, but really, isn't that what Electron is doing anyway? Assuming I don't need Electron's extra features like MacOS menu bar integration etc etc, would this be a sane way of doing things? I'm writing a collection of ebook processing and conversion tools in Go, and I've thought of creating a UI to make something like Calibre/iTunes for books. I don't know Qt, though, and don't know how well-integrated into Go it is, or how many learning materials are available that aren't C++ specific. I had the idea of making a web-based UI using this technique, partly because I know I could do it in an aesthetically pleasing way quite quickly and simply (and it's a personal project I can't dedicate a lot of time to so quick and simple wins even if it's not the best), but partly because it would make it easier to create a decoupled self-hosted version people could connect to on their phones.
There are a number of things that might be going on, without seeing the code I can't really comment further. We don't know if your goroutines are I/O bound or CPU bound for example. If CPU bound, you could issue [runtime.Gosched()](https://golang.org/pkg/runtime/#Gosched) to ensure that the time is distributed between the goroutines more fairly. Running a recent Go version might also improve performance/behaviour in this regard.
Oh believe me, it's on its way out. I use hugo to generate the site and that had been an unfortunate side effect of the current theme I use, but I'm looking to change the theme to make it into more of a blog later this week. 
&gt; at least finally there might be a push towards a unified package manager that could reflect the realities of open source and push the responsibilities back up the dependency tree. :) Yes that's how I understand it too. &gt; as bad an implementation I consider snaps to be To be honest I haven't looked too much at snaps. I just know that they are new, are supposed to be an improvement (over the existing system) and that they package things together. So the implementation might be bad for all I know. Care to elaborate on why you think it's bad? Going back to the GOPATH discussion, I belong in the (from what it seems) minority that agree on your opinion about GOPATH. What I'd like to add is that in practice the idea has a few drawbacks. I'll give you a good example from my personal experience. I have a bunch of pet projects that I work on my free time. Many of them need data from the same database. So instead of writing the same code again for each project I created a package that does all the db handling and which the other projects import. So this is probably the best case scenario. We are talking about code that I own 100% and I can do as I please with the dependencies since there's no hurry. I have to admit that at some point I did a change to the db package that affected a project I wasn't working on at that time. It was a project that I hadn't touched for months. Due to many reasons such as laziness, difficulty with context switching, RL etc. instead of switching to the problematic project and fix the issue I simply decided to vendor the older, working version of my own package just so that the project will keep working. (And to this day I still haven't fixed it! But the project still works fine.) I could have gone the extra mile, care about my dependencies and fix the issue but I chose the easy solution. So this was the best case scenario. Now imagine the standard/worst case scenario of the real world where there's extra pressure, deadlines, bosses, costs etc. involved. Unless you are Google and you have a giant monorepo AND the software to support that monorepo, I sadly have to admit that GOPATH doesn't work all that great in practice. And speaking about the software at Google, If we had an easy way available to manage all the software that is under GOPATH, maybe the situation would be different. But in fact we don't. If a programmer is working on `github.com/&lt;some company&gt;/XXX`, they will just care if that XXX compiles and works. I doubt they will go and check everything under `github.com/&lt;some company&gt;`. Besides from the top of my head I can't think of an easy way to make sure that everything works. Maybe `test ./...`? And what about `github.com/&lt;3rd party&gt;/YYY`? It's as if there's a missing piece from the GOPATH solution... 
interesting combination. this reminds me of TCL and Tk.
This is how I've done the "GUI" in some of my personal projects. The nice advantage of this solution is that unless you do something really hacky, you can just take the same code and run it on a server. :)
&gt; as Dave Cheney said It's actually [Rob Pike that has said that](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=12m37s) and not Cheney. Please ammend.
Dave Cheney [has also said it](https://dave.cheney.net/2016/01/18/cgo-is-not-go). Don't know who said it first though.
The compiler performs escape analysis and allocates on the heap when the address escapes the local scope.
thank you.
There are bindings for LPSolve https://github.com/draffensperger/golp and for GLPK https://github.com/lukpank/go-glpk . or-tools provides SWIG interfaces for Python, Csharp and Java, that is how bindings are generated. Go also has support for SWIG so I guess it should not be that difficult to generate Go wrapper (for someone who knows C++/SWIG at least).
That would be a solution too. I don't believe it makes more sense though. The upsides of using [astilectron](https://github.com/asticode/go-astilectron) are: - the complexity of provisioning Electron + your own resources files is abstracted. All can be done in GO + running the [bundler](https://github.com/asticode/go-astilectron-bundler) - you write a very small amount of NodeJS lines (only HTML/CSS/JS-like lines) - you can focus on the "server-side" GO code and "front-side" JS code To my opinion the main drawbacks of your solution would be: - you would still need to run the Golang server in the background in NodeJS, so you would need to know some NodeJS and implement some stuff for that (handle errors and all that stuff too) - you would still need to embed some files in your Golang binary (the ones that you're going to display in your server) and would need to implement some stuff to disembed them upon the first execution.
Ha! Just after I posted my comment I thought I'd edit it and add the word "first" because someone might reply with "Technically speaking...". But then I said, naaah, people will get it. I guess I was way too optimistic! P.S. Check the dates of the article and the video.
Good point. I'll fix the post! Dave has talked about it quite a bit more, but certainly credit should be given to Rob.
Sublime doesn't seem to be up to Vscode or Vim/Emacs when it comes to Golang.
&gt; you would still need to run the Golang server in the background in NodeJS Why?
Because Go-sublime is pretty mediocre at best
if you're writing command-line apps/tools/servers I highly recommend starting with github.com/spf13/cobra. It's got a nice generator that builds the skeleton of a commandline app that's easy to understand and extend. I use it for nearly everything now. 
1. A good way to start is to get a working prototype asap. That might mean to have all your code in `main.go`. Once it takes shape, you can start identifying things you can separate in packages. That's when you can start writing tests too (for the packages). 2. Just separate your code into packages. It's theory it's the same as importing a whole different project. If a particular package ends up being so useful that could be used by other projects, then sure you can move it to a different repo. 3. If you are writing something you've written many times such as a web API, you can certainly do TDD from the start. If it's unknown territory you can just write tests as you need them. See 1.
Arf maybe I misunderstood the solution, you don't need to run the GO server in the background? How does Electron communicate with GO? I do agree embedding data in a GO binary has very good libraries, I've used [go-bindata](https://github.com/jteeuwen/go-bindata) for [astilectron](https://github.com/asticode/go-astilectron). But all that means that you need to implement several functionalities in your GO or Electron binary that you wouldn't need to implement if you used [astilectron](https://github.com/asticode/go-astilectron). That way you could just focus on your GO code, and the HTML/CSS/JS front-side code.
&gt; Arf maybe I misunderstood the solution It's entirely possible I am also misterstanding as I've never used *lectron. &gt; you don't need to run the GO server in the background? How does Electron communicate with GO? You certainly do. But you said "you would still need to run the Golang server in the background in NodeJS". So why "in NodeJS"? &gt; But all that means that you need to implement several functionalities in your GO or Electron binary that you wouldn't need to implement if you used astilectron. Several functionalities like what? &gt; That way you could just focus on your GO code, and the HTML/CSS/JS front-side code. But I can already just focus on the Go code and the HTML/CSS/JS front-side code. :P So it seems what's missing is those functionalities you mentioned before. My point is that, I wouldn't consider those 2 things you mentioned as the main drawbacks. For me the main drawbacks is being unable to offer a native/app feeling and not being able to do things like close the app and also close the server.
Haaaaaa I do understood the solution now. I misunderstood it earlier. Damn I feel stupid :( The main drawbacks I see are: - what if the user doesn't have a browser? (event though it's unlikely nowadays) - if the user has a browser, compatibility will be an issue (depending the browser the user is on) - you can't add an icon to the application - you can't add a native menu (as in MacOSX or Linux) - you can't add a Tray - you can't make the window the size you want - you can't position the window where you want or play with the available displays
I misunderstood the solution you've proposed earlier. Here's a correction to my reaction: The main drawbacks I see are: - what if the user doesn't have a browser? (event though it's unlikely nowadays) - if the user has a browser, compatibility will be an issue (depending on the browser the user is on) - you can't add an icon to the application - you can't add a native menu (as in MacOSX or Linux) - you can't add a Tray - you can't make the window the size you want - you can't position the window where you want or play with the available displays
Compile with -gcflags="-m" to see compiler's escape analysis. Or "-m -m" for more verbosity. 
Alright now I understand what kind of functionalities you are talking about. Yes I agree with most of those. In the end I think it's a trade-off. If you are okay with not having those functionalities, you can have something truly lightweight + being able to run it on the server with mostly no changes. But if you need those functionalities and you don't mind the size/RAM, I can see how Electron is a good solution.
&gt; Is there any way to test and debug just one file or feature of your go code without having to comment everything else out? Yes. Write tests for each feature (you're doing this already, of course!) and use tags to differentiate the tests. Or use the `-run` flag to select a subset of tests.
Plus you have to hit a public facing server, which can be a bottleneck if bandwidth is an issue. (Image resizing tool, mp3 encoder, etc)
I prefer to decouple them and use a standard message library like ZeroMQ, to comunicate the app logic (in this case written in Go) from the GUI (in this case written in JS), then launch the electron app using the exec package.
But imagine you want to distribute your GUI binary to end users (for which you don't control the environment), how to you make sure ZeroMQ is installed?
Just use javascript. - but I want a statically typed language? just use typescript. - but I already have a go codebase ? sure just compile your go executable and pipe them through electron, that's exactly what VSCode does with C#. I thought people used Go because of the idea of simplicity? this philosophy should be applied to Javascript tools as well, even if you don't like the language.
Others have already answered the "why?", so I'd like to address the following point: &gt;how Go shoves this down my throat is extremely frustrating.. Go is very opinionated on many things, not only project structure (naming conventions, code formatting, etc.) You are correct it is very frustrating, but it has a reason and a huge upside. Open up any open-source Go package. You will be surprised to see how it's code is similar to any code you have written. Most probably you will be able to easily navigate around the package without much introduction. Uniformity can be a bitch, but it pays off. Go is really good at enforcing uniformity on the "How?", without getting in the way of the "What?".
Try to make jobs fatter, for example push slice of few hundred elements instead of single one, you might be hitting channel bottleneck
I never figured out how to actually be productive in Acme. I agree that the Go fonts look awesome in Acme though, so I made my vim config look [similar](https://github.com/ajgrf/parchment).
Y'all be nice now.
That argument is for `gofmt`, not where I put my project.
I've read these previous years. Google translate generally does a reasonable job of making these accessible.
Fair points. Coming from other languages, a lot of people feel the same way when starting with Go. You have to mold your mental model from thinking in your previous programming language to thinking in Go way. All I can say is don't give up. Give it some time. You will see the "Go way" eventually. I leave you with this - https://opensource.com/article/17/9/seven-stages-becoming-go-programmer. A bit tongue in cheek, but its core essence is true.
It's an awesome article. Thanks for sharing.
Thanks! This is very helpful! So for point 1, the prototyping phase, do you typically just make a note of imports you need and comment them until you've implemented them? How big does this prototype get before you start breaking things out ( I'm sure that depends a lot on the project in question but if you have an idea....) ? I have a preference for working lots of with small concise files rather than larger files. 
I've never had to put my code in PYTHONPATH to be able to use pip. If you mean pip does it for you for the duration of the command, so should Go.
How big was the dataset you ran your benchmark against? Wondering how would memory usage compare against encoding/csv for 1gb dataset.
Hmm, I don't necessarily disagree with any of the individual points, but I'll say Go certainly has been the language that's been easiest for me to internalize, and when I do have questions, I can easily resolve them by reading the language spec. That's certainly been much different than my experience with C++ or Python, or even emacs lisp. So in that sense it does feel simple to me. But it's not as simple as, say, straight C, or scheme. I guess it tends to be good at avoiding incidental or unnecessary complexity. Try cracking open and reading some Go standard library code vs. some C++ standard library code. Night and day.
&gt; IMHO the simplest and most straightforward way to express a receiver is the UFCS rather than what C++ or Go do. Go does support this, in a bit of a roundabout way: https://play.golang.org/p/H9b1fhn85p
Ye, docker isn't a solution (sadly). I was experimenting last night with creating static linked executables. It works for Linux and windows but oh boy. OSX does not provide any statically linked libraries and thus I can't link my executable statically for that os. I couldn't find any useful resources on whether it is possible to tell cgo to just link the taglib library statically and everything else dynamically, making it possible to create a working exe. I used `-static` LD flag during the go build command to make a statically linked executable. If not I have to come up with another solution that can be compiled cross platform. That's actually the reason why I chose go to be honest. But it looks like it might not fit my conditions here.
You have a valid point and believe me executing Electron in the background was really not the way I wanted to go initially. But unfortunately, I was out of options since I wanted: - to implement my UI in HTML/JS/CSS since they're the languages I'm the most effective with when it comes to implementing UIs - not to be stuck with "native" looks and be able to experiment with my UIs (which is not possible with solutions like Qt unless you're an expert in Qt. I'm not saying Qt is bad, on the contrary, I'm saying that Qt gave a look too "native" to **my taste**. And I'm not an expert in Qt :D) - to rely on a stable and maintained solution (such as Electron)
This is an excellent write up! Thank you. With my previous line of thinking I wasnt really focusing on the go testing infrastructure but Im seeing the benefits and will def take another look at the doc One point I want to make sure I understand from your example, are these subpackages truly go subpackages nested in the project directory or are they separate projects all together located in gopath/src/ 
Good point, will revisit go test docs. Thanks! 
I really miss the simple days of undefined behavior and template errors in C++.
Thanks! Will check it out. One issue I've had with generators when learning a new language or framework is that, via the scaffolding process, certain important concepts get abstracted away, which isn't necessarily bad but, if there's an issue, I find that it's harder to figure out where something broke. Haven't looked at cobra but I'm just wondering how much is being abstracted away by this tool or if you could see this as a valid concern? 
1. I've not really seen people express keyword number as a big thing, but I have seen people argue about always using just "for" or "while" in C code. Shrug, feel free to rant :). 2. Having this as an explicit argument in it's own "list" seems easier/simpler to me. It is explicit in python too, and not everyone calls it self everywhere. Meh. 3. Like #2 this seems to be "this is different" and different is bad. Which I kind of understand. I would like tuples in the language, but I'm not sure it's better if they were. 4. This seems to be missing the point, yes you can abuse parts of the language to get C (and some C++) like inheritance but interfaces are a much better way of solving that problem and are used/advocated everywhere. 5. Maybe. The complaint is a subset of generics, and I think it would be better ... but it's still way way simpler than C++/python where you often have no idea what errors are happening or where (and indeed they might magically change at a later time). 6. "Generics are simple lol", sure getting any kind of generics would be easy ... but they all have tradeoffs and I'm not sure I'd trust the author to pick randomly. 7.1. They are also used in types to say "this is only a receiver". 7.2. I mostly agree iota is a bit too clever for it's own good, but I understand why they did it ... and the common case is simple to use. 7.3. Why is this bad? Because you don't use them? Would you prefer floats not be native in languages because a lot of apps. don't need those either? 7.4. "different is bad"? ... it is rarely used, and when it is tends to make things clearer IMO. Also there's a simplicity in things acting a similar way (for, switch, if).
Ugh.
After more thought, I think there's a general confusion between being simple to read and simple to write ... and Go-1.0 comes down consistently on the side of simple to read, even if that means you have to put more work in when writing it (and thus. being less "simple").
This is some dedication to debugging. If I had to build the kernel that many times with different configs to find out exactly which flag caused the issue, I might as well give up. My laptop has only 4 cores though, OP's laptop had much more. :P
Biggest surprise for me is the fact that https://play.golang.org/p/cSCLyGHssR compiles without issue and I don't know of any static tooling to detect this.
[removed]
I don't think it's even roundabout, really: https://play.golang.org/p/0HegVwuMaF Seems to exactly match what's being described on the wikipedia page, unless I'm missing something.
In my experience, most Go proponents totally understand that different languages solve different problems, and that there are many many areas where Go is not the ideal solution. We tend to talk about the places where go solves problems well and ignore the places where it doesn't... so it may seem like we don't realize its limitations... but we do. If you avoid projects that need screws and wrenches, a hammer may do you just fine most of the time :) I think anyone who has a tool that has been good to them will evangelize it probably more than is strictly called for... but at the same time, we all have different experiences, so our views of even very similar events will be colored by those experiences.
On a related note, has anyone looked into using a minimal amount of Qt (or some GUI framework) just enough to embed a Webkit component? Basically to roll your own Electron, but instead of needing to bundle _all of Chromium_ you can use your OS's existing Qt and Webkit libraries. As long as you're not using bleeding-edge features that only the latest Chromium supports it seems like that would work well for a lot of simpler apps.
I have a hard time following multiple embedded structs like that.. can you explain what is surprising or confusing?
Your comment sounds like an invitation to a religious movement. To actually answer, after trying out Go for a bit, I've stopped believing that there is a "Go way" or that Go is much different from other languages, as the advocacy would have you believe. As you can see in many of the points in the blogpost, I found out Go is in fact pretty similar to other languages. (For example, I might object to the lack of generics, but I am used to it from C.) It just had different/unusual syntax for familiar concepts. 
Not necessarily. The Go app could listen on some random `localhost:12345` port and then launch the user's web browser to point to `http://localhost:12345/`, while not binding to public facing addresses -- so an outside computer can't connect using your IP address.
Very cool, I didn't know of this! I think the biggest difference is between the Server and Subscriber. net/http was a big inspiration for this library so the Receiver interface defines how messages are processed. Seems like Subscriber defers that by just returning a channel - the user can define how they want to work with messages. Nothing wrong, with that but I think the Receiver pattern can lead to some interesting things, like decorators/middleware. I hope to add some more documentation / examples in the future for that.
It's the diamond problem, like http://www.well-typed.com/blog/9/ but then with data structures. If you access `T4` from a `T1`, do you mean `T1.T2.T4` or `T1.T3.T4`?
The fact that the `foo` element is shadowed with no warning and no (to my knowledge) static tooling to detect that. It seems easy to add a struct somewhere and now you're shadowing field and you'd never notice..
I recently found [webview](https://github.com/zserge/webview), and I'm finding that to be a much simpler alternative. Just spin up a local webserver with the handlers you want, instantiate a webview, and pass it the objects you want to have accessible in the UI. Together with [PicoDOM](https://github.com/picodom/picodom) and [PicoStyle](https://github.com/picostyle/picostyle) you basically get a full-fledged GUI templating engine with custom tags and all that jazz, with basically no loading at all.
The encoding/csv package was significantly optimized for Go1.10, so it may be worth running your benchmarks against tip. https://github.com/golang/go/commit/89ccfe496224bc92f2d2af860cae2f5d7e830f8d
This is a really sound idea. I'm not a Qt expert therefore i can't say whether this is possible to implement all basic features (add a native menu, add a tray, add an icon to the application, etc.) but I will look into it. At first I was using [thrust](https://github.com/breach/thrust) instead of Electron, but unfortunately they stopped maintaining it. And I was basically screwed. Therefore I decided it was a key element to rely on a stable and well maintained solution to avoid this problem in the future. And that's why I've chosen Electron. But will definitely look into your proposal. Maybe there are already some projects out there.
Yet great
&gt; There’s an important way in which embedding differs from subclassing. When we embed a type, the methods of that type become methods of the outer type, but when they are invoked the receiver of the method is the inner type, not the outer one. &gt; &gt; *What’s the difference? Inheritance typically works exactly the same way, the inherited methods also act on the inner type.* I don't think this is true of C# and Java... not sure about C++ TBH (it's been too long). The main thing is that overridden methods are not callable from the base class. Thus, if you have type Animal struct {} func (a *Animal) Speak() string { return fmt.Printf("Hi, I'm an %s", a.Name) } func (a *Animal) Name() string { return "Animal" } type Dog struct { Animal } func (d *Dog) Name() string { return "Dog" } If you call d.Name() it'll return "Dog". But if you call d.Speak(), it'll say "I'm an Animal". In Java, if you override Name(), the base class would call the overridden method on the object. In go, there's a wall between the two functionalities. This can make some things more difficult, but it also means that you encounter unintended effects less often. I'm sure there are other examples where Go's embedding is very different than Java inheritance. 
Does this convert your Go code into JavaScript (like gopherjs) and in the end it's running a 'normal' Electron app with server-side "node.js" that was converted? Or, does the Go code run as a server side-by-side with Electron, and the Node backend in the Electron app forwards messages between the Electron front-end and the Go server? Or something else entirely? I'm curious what the architecture is with all this.
This is a really nice project indeed! However those looking to add more advanced features such add an icon to the application, add a menu, add a tray, etc. won't be able to do it.
Yeah, that's a shame. You could fake it a bit but it won't fool anyone, especially not on OSX. I have hopes that some of those features will be added later though. I really don't want to run a Node instance in the background for simple applications, or for any applications really. Atom burned me enough that I'm not touching that stuff again.
No it doesn't convert your code. Here's how it works: - electron and [astilectron](https://github.com/asticode/astilectron) (the JS Electron app) are provisioned on disk - when the go binary is run, it listens to a TCP socket and spawns an electron process in the background executing the [astilectron](https://github.com/asticode/astilectron) JS app connecting to that TCP socket - they can then communicate and the GO code can order the JS code to do some stuff I wanted to use stdin/stdout first instead of TCP but there was a bug in Windows so I had to revert to that solution
[removed]
It depends on the code. Even it it is fully parallel, the gc may kick in and slow things. Check this cloudflare block post about the impact of the GC on parallel execution performance. https://blog.cloudflare.com/go-dont-collect-my-garbage/ 
Yeah I do agree with you regarding the Node process in the background. But I mainly hope this webview project won't hit the "must be compatible on all platforms" wall that usually is the death of those kind of difficult to maintain/evolve projects.
 don't forget spring overhead! i'm looking into go for this exact reason. 
still not available :(
any idea on a date when this will appear in the console as an option for lambda?
in java at least you can export your entire working project as a 'fat' jar with all the dependencies bundled within the jar itself. you deploy all your own code as well as the dependencies. this is awesome for convenience and terrible for performance but there's no better way to do it yet.
[removed]
For 1GB data set decoding: ``` Pure encoding.csv/Read vs csvutil.Decode. Both are using encoding/csv underneath in this case, so the difference here is just a decoding overhead. benchmark old ns/op new ns/op delta BenchmarkUnmarshal/1GB_set/35714285_records-8 45292444028 97528345683 +115.33% benchmark old allocs new allocs delta BenchmarkUnmarshal/1GB_set/35714285_records-8 35714379 71428726 +100.00% benchmark old bytes new bytes delta BenchmarkUnmarshal/1GB_set/35714285_records-8 8225355824 21209061224 +157.85% ```
So i figured a way out to realize this. Looks like you can just add a path that the OS will use to resolve dynamic libraries. On OS X it is `DYLD_LIBRARY_PATH`, linux it's `LD_LIBRARY_PATH` and windows just needs to be within the path to be found. I read about the macOS version not working since Sierra (they introduced something called SIP) but it seems that it only protects Apple libraries and not 3rdparty ones, meaning that the option is available if you do not need Apple signed libraries/frameworks. 
Yeah, I am looking forward to Go 1.10, it will also bring strings.Builder which will help to significantly decrease number of allocations during encoding
The differences in method signatures was hard for me to get used to at first (coming from C++, C#, java, and python). But after a while, you get used to it, and it's not really a thing anymore. Learning any new language is like that. Named returns are encouraged to be used sparingly, only where it's useful to distinguish what return values actually mean. Thus you might have func SplitName(name string) (first, last string) {} As opposed to just returning two strings and having to read the docs about which is returns where. The same can be said for non-obvious return values, like func GetNextThing() (t *Thing, offset int){} If you just saw `GetNextThing() (*Thing, int)` as the return value, you'd have to go read the docs to see what that int means. With the name, you get a hint about its meaning (probably not enough info if you don't have any idea of what the code does, but enough that if you do, it'll jog your memory). 
Can you please explain a little more the type of GUI interactions where you'd use a message queue? From my experience, the vast majority of client-server interactions I've dealt with were better suited over HTTP. The obvious exception is a one-way publishing/alerting/notifications system which I have had experience with. Even then, I've used websockets (not with Electron though) successfully.
I'm sorry, but no. As a professional C++ developer myself I see that, the article's author understanding of C++ and multiple inheritance is factually incorrect. The whole article can be destroyed starting from "this" keyword (quick quiz - what is this in C++? Can be null? Why?) to the error handling (EOF). The only somewhat debatable point is generics. Also - if with initialization is actually coming to C++ and I couldn't be happier about it. Folks - it's OK not to like, like, hate, love or feel anything else about the language. Any language. What is not OK is making false analogies after you claimed to be a professional, resulting in false statements. I had very hard time explaining to people how things actually work after they had read this kind of stuff. 
&gt; I don't think this is true of C# and Java... not sure about C++ TBH (it's been too long). The main thing is that overridden methods are not callable from the base class. That was a reaction to the quoted part of the doc only. But you are right about the difference, basically in Java a class is equvalent to struct+interface in Go. Ie. in Go the polymorphism part is separated from structs. Which I think is a good thing, for the most part, but I don't feel competent enough to estimate which of the two causes more/less unintended effects. (That's a very hard question IMHO.) 
Why do you compare it to C++ in your article?
[Please don't do this.](https://www.reddit.com/r/programming/comments/64oqaq/electron_is_flash_for_the_desktop/)
&gt; C has no inheritance The most known/documented example of this is probably glib, but more than a few C codebases use it. https://developer.gnome.org/gobject/stable/chapter-gobject.html &gt; &gt; They are also used in types to say "this is only a receiver". &gt; Can I read about this somewhere? https://gobyexample.com/channel-directions
Very well written, and I agree with almost all points. Your niggles at the end are a bit too niggly for me, but that's probably just a question of learning to live with it. The diamond problem was a bit of a surprise, as well. The one thing where i disagree is with the multiple argument lists being bad. I think it works well for separation of what's going in and what's coming out. I'm not saying they're the best solution, but I don't see how they're any worse than regular return types, or no return information at all. Tuples are a good idea, but they'd still need to be specified as a return type in the signature, and then you have the same problem.
[removed]
[removed]
Hah, fair point, C++ really is a beast. But! Python and C++ are the two other languages I've used the most in the past, so those are my reference points. Lately I've also been using C# and a bit of Java. I like C# a lot, but overall somehow Go still feels simpler. I haven't really dug super far into why that is...
In my opinion, just use the standard library `flag` package to get started with making a command line app. There's no need to use such a huge dependency as cobra unless the complexity of your command line app is really huge and/or you keep making many non trivial command line apps.
[removed]
just to be clear - csvutil doesn't provide a new csv parser, it provides the means to decode and encode structs. Any csv reader or writer that implements Read() ([]string, error) and Write([]string) error methods can be used
I had to double check this as I'm actually building something with CGO_ENABLED=0 for darwin, and it's unclear to me: # file pendulum-darwin-amd64 pendulum-darwin-amd64: Mach-O 64-bit x86_64 executable, flags:&lt;NOUNDEFS&gt; Feel free to check the binary from the [pendulum releases page](https://github.com/titpetric/pendulum/releases). It's a simple web server with a markdown editor front-end, no esoteric libraries included so I'm guessing that's why building a static binary is possible. Does `CGO_ENABLED=0` not work for your case?
I don't think this is really that bad. The access is unambiguous in the example given. If you do add something that would make it ambiguous, like another `foo` member to T3, the compiler will complain: &gt; ambiguous selector t1.foo https://play.golang.org/p/KIf-otodnW So far, I've found Go's struct embedding to be nicer to work with than inheritance. ¯\_(ツ)_/¯
&gt; do you typically just make a note of imports you need and comment them until you've implemented them? I don't usually mess with imports and I don't think you should either. Just use `goimports` on save. &gt; How big does this prototype get before you start breaking things out ( I'm sure that depends a lot on the project in question but if you have an idea....) ? Yes indeed it depends on the project but as a rule of a thumb, if the `main.go` file starts getting too large to manage before you have realized which parts need to be broken into packages, then maybe you should start separating your code into different files in `package main`. I'd also say that the prototyping phase ends when you have your proof of concept or maybe a minimum viable product. By that time it usually becomes quite obvious the parts of your code that can are reusable and can be put into packages. I think this workflow is quite effective when you explore uncharted territory. The way I see it, it's much better to have something minimal that works even if the code is a little ugly, than to stress about architecture and details early on. Of course if you are working on a concept you are familiar with or you are building a complex system, then you better start with a paper and [Design the architecture, name the components, document the details.](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=18m09s)
This article is correct Go is a large-ish language. But I can access and read the Go spec and standard library easily. I can't say the same thing about C#, Java, Python, or Ruby. It also feels small. You introduce "type", "func", "struct", "interface", "for", and "if" and you can read at least 90% of code. It is simple in that it has fewer corner cases then say javascript or C# in my estimation. It is simpler then Java in that I can read more code with less knowledge in my estimation. I would caution you against conflating different for the arguments for or against simplicity. Fair enough, "simple" is a subjective term. But I do think the spec and average code is more readable then other languages. This may have more to do with ecosystem and package concepts (no Java single Class per file annoyance) then what the language spec conveys. 
That's a really nice color scheme!! thanks for sharing 
You just said "of course Go is [simpler] than C++", so why are you comparing it to C++ to demonstrate the opposite?
The main advantage of using tuples is that you can do something like func f(arg string) (val, error){ .... } .... fmt.Println(f("this is a constant so I _know_ it won't return an error")[0])
[Simplicity has many facets. Simplicity is complicated.](https://youtu.be/rFejpH_tAHM?t=33s)
Like this? https://github.com/zserge/webview They do it a bit differently than I would, I'd just start the browser with exec() rather than using CGO. I've hacked up in the past a little Vala program (Linux) that did just this (not really suitable but could be). The issue is supporting Windows/Mac with a version for them.
Cgo: avoid if possible.
1. This doesn't require tuples, you just make that syntax not an error. 2. More generally tuples are often used in python for "write simplicity" over "read simplicity" IMO, which is why I'm less sure they are a good idea ... even though I've often wanted to use them instead of having to define/create/document a struct. 3. There is a common way to do your example in Go: fMust(arg string) string { val, err := f(arg) if err != nil { panic(...) } return val } 
I've seen it all in my career, from assembly, c, c++ to Java and python and most likely 20 other languages long forgotten. The thing *for me (disclaimer)* is that go fills in the gap between low level C and the high level scripting languages like python and the likes. It is high level enough to abstract you from the hardcore memory management in C, but at the same time it is low level enough to really feel what I am doing. And did I mention the ease of cross compilation? That really is a Java killer for me. The language constructs do take some time to get used to (havind one workspace for everything? Really?) but I cannot imagine myself without it in the meantime. Having said that: I do recognize some of the reservations you shared.
Do you prefer reading? Well, now there's a blog post https://medium.com/@francesc/whats-the-most-common-identifier-in-go-s-stdlib-e468f3c9c7d9
I tend to agree that Go, the language, isn't particularly simple. But *Go code* tends to be simpler - by a wide margin. The language isn't simple because the spec is so short, but because it doesn't give you a bunch of features that are traditionally used to write complicated and hard to understand code. Understanding the difference helps reframe at least some of the complaints from the article. &gt; IMHO the simplest and most straightforward way to express a receiver is the UFCS rather than what C++ or Go do. UFCS only addresses the call syntax, not attaching methods to types. How would interfaces work? &gt; Another thing that makes matters not simple is panicking. Panicking is actually really simple. Recover is, where all the problems lie. Which is why I tell people to never use recover. &gt; Many people in the Go community seem to believe that generics are inherently complex The argument (at least from me) isn't that *generics* are inherently complex, but that generics inherently *encourage complex code*. The very design of generics encourages programming with types and adding layers of abstractions (every argument in favor of them is "we can write better layers of abstractions"), which significantly hurt simplicity. If writing generic code is a PITA, people won't write generic code and write concrete code instead. And understanding this, means reframing this sentence: &gt; it causes quite a bit of additional complexity in other parts of Go as well, mostly by requiring the presence of various “magical” functions/types. Yes. By putting some additional complexity into the language, you vastly reduce the complexity of the *code* written in it - while still maintaining an enormous chunk of the usefulness.
Mind-blowing the amount of knowledge in that brain !
Wow that’s incredible. How do you even gain such insights? I don’t understand half of the stuff he’s talking about and I have certainly never met anyone working on that level (as in finding false bits in memory, compiling kernels, debugging assembly, ...). I’m genuinely interested in what I’d have to do to gain a bigger understanding in this, because right now I have no idea where to start.
Well I couldn't agree more with a topic. "Go is not (very) simple", but reading it is. I am also a newcomer, and I have to admit that it is hard to learn and master, yet it still easier and requires less learning curve than C++ (where IMHO you have to have at least 4-5 years of professional exp to consider yourself as a very productive person(c++ is my background btw.). That being said, let me advocate Go. What I like that by learning it you are getting nice UX, crashes are easy to track. The worse part however is that if you (as me) have a strong OO mindset it is a puzzlement to write nice and clean code in the first place. I have learnt hard way that the best approach is to "make it work, then refactor". In fact I am always shock how clean and easy to read is the end product. Rich stdlib and community is also a huge win for Go. So I am biased to Go because I like this feeling of being productive. Don't have to dwell much about how to do something, then it is always easy to refactor since I don't get abstraction wrong due to the class hierarchy, and yeah I also thought that embedding == inheritance, but I did my homework, and now I understand why their names differ (spoiler alert: there is no equality between them). Since refactoring is easier, reading code base is easy to follow - it is also easier to work with it in a group of programmers.Cheers. 
GOPATH is part of the Go ecosystem. Maybe you should try and learn how to work on this new for you ecosystem instead of trying to force down its throat what you are already used from other languages.
The https://github.com/therecipe/qt package has support for Webkit, I use it for my url2img project here https://github.com/gen2brain/url2img , though I use it offscreen, and compile everything statically. Webview below uses different components (MSHTML, gtk-webkit, Cocoa/Webkit), so your app can look and behave different on different platforms. Also, I guess it is possible to just add systray icon and use QDesktopServices to just open your url in browser, without Webkit. Anyway, for desktop apps I prefer to work with real GUI components and not CSS. therecipe/qt is great for that. 
&gt; It seems to encourage developers to do all their development in a single workspace. An environment variable is used exactly so that you don't have to use a single workspace for all your development. You can set `GOPATH` to whatever you want for any individual process. &gt; Just pull a `node_modules` and let us live. `cd yourproject &amp;&amp; mkdir node_modules &amp;&amp; export GOPATH="$PWD/node_modules"` And there you have your dependencies in a subdirectory to your package directory, no fuzz and no particular requirements as to how you organize your own code. You could also dump all your dependencies into the package local `vendor` if you want your project itself to fit nicely into another workspace to be importable by others while still making sure you get the exact revisions that you want. I personally mostly use a single `GOPATH` tree and whatever is at `HEAD` when I download a dependency, but for my job and other projects where I obviously couldn't just shoot from the hip, I needed repeatable builds thus carefully managed dependencies. There were a few simple solutions like using git submodules or a short script to get the revisions I assumed. My point is that `GOPATH` doesn't get in the way of any of that.
About that too "native" look, you can use Qt Quick Controls 2, those doesn't have native look anymore, you have Default, Material and Universal styles, see here https://doc.qt.io/qt-5/qtquickcontrols2-styles.html .
First, recognize a loss of productivity in the pursuit of education, don't get upset when your computer doesn't boot your custom kernel or your assembly finally compiles but runs slower and doesn't work on all hardware. I'd start with compiling your own kernel. it's been a while but there's a helpful ncurses command that will run through every possible kernel config option. Start by removing support for hardware not even in your system. If you don't know what an option is for, look kit up, read about it. For assembly, Go had facilities for dumping the assembly it generates, and there's some tutorials out there for getting started writing assembly for Go. Start with something basic, like needlessly squeezing a little extra performance out of some method and then work your way up. As for the memory bit, learn about the hardware your using and what people do to test, replace, fix stuff as a hardware technician. MemTest is really popular for making sure there's no hardware issues as a low effort first response when someone drops a "broken" computer at your desk and asks you to fix it as a hardware technician. Be realistic about the timeframe to learn these things. Make it a ten year plan, where after, you can see how far you've come. Take opportunities to teach others what you've learned along the way, that's a great way to review the basics you think you know and take for granted. Also, have fun.
Thanks for sharing this article. This summarize exactly what I thought about it. 
&gt; Inheritance typically works exactly the same way, the inherited methods also act on the inner type. c++, ruby, python, java, javascript all merge the method namespaces of the base class and the subclass, where the subclass is shadowing the base class. this is the cornerstone of what is known as the [fragile base class](https://en.wikipedia.org/wiki/Fragile_base_class) problem. &gt; Various kinds of error handling are typically a huge flamewar material. I don’t want to get into that. ok but you _do_ want to get into that, that's why you brought it up. This whole section reads "error handling in Go is bad, don't @ me". I mean none of this is exceedingly wrong, it's just yet another "I used Go for one week here are my opinions" post. Like OK that's nice but a lot of these posts illustrate the following behavior: - author tried to use Go - author didn't like Go - author wrote talking points that have been discussed at length elsewhere missing in this is the "author read previous posts and discussions on these topics". The discussion of generics gets particularly annoying because the situation is usually something like: author talks about Go as if the people that work on Go have never seen generics, have never used generics, don't know how generics work, and need generics explained to them. &gt; Many people in the Go community seem to believe that generics are inherently complex What people? What did they say on this topic? What was their actual argument? &gt; Listen here folks, generics are not a bogeyman. this is honestly the crux of why these arguments are so annoying: you talk about it as if Go doesn't have generics because the Go team _just doesn't understand them_. The problem with generics isn't that people don't understand them: the problem is that there's no consensus on how to implement them in a performant manner that works well with the rest of the features of the language. Please consult [the summary of Go Generics discussions](https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/preview). &gt; People also don’t realize that if used sensibly, generics can make matters much simpler for users of many types and functions. ^ "people just don't get generics" is what you said.
He uses Gentoo, it means he is building kernel with customized config, and not with everything on by default. On my laptop with 4 cores it needs aprox 15min to rebuild kernel.
&gt; It is, for example, absolute hell to manage a security fix to a library, if every project out there just vendors *some* version of it - you don't know who gets the fix and if a project uses too old a version, timely upgrades might be alltogether untennable. Just betting that HEAD is good by the time someone else needs to build your package means that every package also assumes *some* version of it. The difference is that with a clearly pinned revision, you know exactly what *some* version is. All in all, I get what you're saying and agree that it is a good thing to foster the idea that packages *should* work fine and be backwards compatible at HEAD, but when I am responsible for production software, getting different binaries whenever the same revision of a package gets built is not an option. An upgrade of a dependency needs to be deliberate and well motivated. It needs to be reviewed and verified. I don't think that's lazy, it's the only sane way to manage external dependencies. Incidentally, that's typically how OS package maintainers work, too. I can't help them if making their job easier means not doing mine. That said, `GOPATH` fits that workflow decently and doesn't get in the way just because I want to manage dependencies in a particular way, and I believe *that's* the point of it.
Yes, I like multiple return args as well. I agree that the &lt;- notation is ugly, weird and unfortunate.
You must be real fun at parties. In all seriousness though, I don't understand your arguments for function return values. What makes it hard to understand? If you're worried about overloading functions with too many arguments/return values I think that's a different problem. I'm a little unsure of what your stance really is on concurrency as well. Is it good? Is it bad? I feel like you just don't want to admit it's simple. Arguably it's the most powerful feature of the language. Show me another language where it's as just as easy to write concurrent code. It may not be as expressive as other, mature languages but you have to admit it's dead simple.
I feel like [this post](https://stackoverflow.com/questions/2399544/difference-between-inheritance-and-composition) helps me understand the difference between inheritance and composition and why Go decided to use the latter.
For whatever reason, Go's dispatch model is simpler to me. I think it's because Go makes it harder to build inheritance hierarchies that make reasoning about calling so difficult. For example, making Child.A() accidentally invoke Parent.B() instead of Child.B() is trivially easy in Python, and reasoning about which will be called requires a lot of deep thought. With Go, this is hard and the explicitness makes its behavior obvious.
I agree with most of the author's points in the article, and personally I'd say no language stays simple forever and they will always become more complex over time as new features are introduced. Even C is changing (e.g. sizeof not always a compile time call, generic macros, etc.) IMHO it is more important to minimize undefined behavior or implementation specific behavior to help us reason about the code.
Contrast is a normal rhetorical device, but Go is also simpler than C# or Java or Python or ...
Check out io package. The file is relatively not tiny but the interfaces are.
The largest difference is Python is apt to hiding complexity around magic double under methods, @property decorators or other trickery. It may seem less complex, but the complexity is hiding elsewhere. Go makes you deal with the complexity up front which in turn make it's a simpler language. But a newcomer may feel the opposite without giving it a chance to learn the "Go" way.
The power of any language lies in its primitives. If you don't change your approach to solving problems in a way that is amenable to the new set of primitives, then you won't be able to be as productive in the new language. If you judge Go on its ability to build inheritance hierarchies, then you will have a harder time than with Java, but if you realize that your goal isn't actually to build inheritance hierarchies, then you'll probably end up appreciating Go a bit more. :)
Oh boy, that’s a long way to go. I’ll develop a roadmap for an optimal learning curve :) Thanks for your tips!
&gt; One point I want to make sure I understand from your example, are these subpackages truly go subpackages nested in the project directory or are they separate projects all together located in gopath/src/ For a really simple program that does't need more any support packages you could do everything in your main. When you need just 1 or two support packages that may be general purpose and you see a potential for reuse it may be worth giving them their own repository. For a more complex application that may need many supporting domain specific packages I tend to do something like: $GOPATH/src/repo/project/ # repo root cmd/name/name.go # contains the main pkg that calls Run # Contains the name pkg that defines Run. For really large projects # this will construct a valid name/config.Config from flags, env, # service discovery, may handle some CLI version compat # as well. It will then start the service using the api in pkg/name. pkg/cmd/name # pkg/name glues together all of the support packages to bring up a # working system. It usually has a simple API / Entry point such as # pkg/name.New(cfg) or for projects which start a service it will # be pkg/name.Serve(ctx, cfg) pkg/name # As mentioned above, a small note here is I typically have a rule that # it does not reference ANY external structures. It can be tempting to # embed structures for configuration, but I've found it can be really # distracting to have to change all your API call sites that take cfg # anytime you want to add fields. pkg/name/config # If the project has a public API, any types needed for its use go here. # If a package seems useful but isn't related to the project its # probably better to make a new repo for it so you don't get tempted to # import your into application in the future for access to a few general # purpose utilities. pkg/&lt;public facing support packages&gt; # As a general rule of thumb you could put ALL other packages that do # not fit the public support packages criteria in here. pkg/internal If you are solving small chunks of your problem at a time it doesn't ever hurt to start at the simplest form in a main pkg. Splitting off from that is usually as simple as cd ..; cp -a prog subpkg; cd subpkg. Good luck hope things get easier.
I'm sorry, but yes. You can disagree with someone about opinions. You can even disagree about facts. And you can still be nice. I will grant that there are times in life when you can't or shouldn't be expected to be nice. Technical disagreements are not one of those times.
Why do I need to tinker with my environmental variables in the first place?
That's a very weak argument. Just do it this way, without knowing why it's superior. Right now I see no reason why this is "better".
I have to say, `io.Reader`, `io.Writer`, and their ubiquitous usage is one of my favorite things about Go. Now if it was just a bit easier to use a blocking `Read()` call with a `select` and a channel...
Good comment. Reminds me of that saying, if your only tool is a hammer then everything looks like nails.
&gt; Calls into Cgo are much slower than native Go calls No kidding. I had a project I was working on recently that had to call a small C function a whole bunch in a loop. I used `pprof` and found that that `runtime.cgocall()` was not doing so well, time-wise, so I rewrote the little function in Go and called that instead. Speed went up about 5 times.
I chuckled to myself - there's nothing quite like 5 pages of VC++ template errors.
I think despite any chosen language, emergent complexity is inevitable with scale.
just realized that question is autistic 
 m := map[string]bool{ "foo" : true } m["bar"] = false https://blog.golang.org/go-maps-in-action
You can do some terrible things with virtual methods. I find that Go encourages better decomposition because it's not possible to to abuse inheritance to extend a base class.
Exactly my point. :)
If i initialize an empty map, it gives me a nil map error. By creating it with one value, just like you did, will it be capable of being expanded ?
Yeah, so maps have to be initialized to be able to write to them (it's a quirk of how maps are created in the runtime). var foo map[string]bool This creates the *zero value* for a map, which is a nil map. Nil maps panic if you try to set values on them. foo := map[string]bool{} bar := make(map[string]bool) These two are equivalent, and initialize a non-nil map that has no items in it. You can set values in them. foo := make(map[string]bool, 500) For the make version of creating a map, you can give it a size hint, which helps the runtime set up memory to store the right number of variables. This can prevent the code from wasting memory by allocating too little for the map and then having to recreate it bigger when you add more items than it in it. 
[removed]
Can you talk about the bug on windows? I have code that runs through stdin and stdout, and I'm wondering if it might hit the same thing on windows.
&gt; Finally, where does this article leave me, the writer? I’m not sure yet. I don’t know yet if Go will be chosen for a (sub)project in my dayjob or if I’ll perhaps use it in a hobby project or not. I’d like to avoid the part of the community that pushes upholding the kind of dogma mentioned in this article. Is there perhaps a place where somewhat less ideologically oriented Go people hang out? Feel free to advice me on that. &gt; I was writing a reply until I got to the bottom and threw it out. I got the hint the author hadn't written any software in Go thus far and was trying to make arguments without attempting to seriously understand the design decisions in the language. This can be seen quite easily in the function call style, if the author had written a couple hundred lines of Go and contrasted it against his C++ the design should be somewhat obvious. Just because people disagree with you doesn't make it dogma or ideology. I don't get what the goal of this article was, after every section of text there is a dismissive tone of your own points as "oh by the way I don't really mind what I just complained about". The points raised in the article aren't new, except for some rather bizzare ones like it being a negative there is built in complex number type. Any chat with an experienced gopher could have explained the questions raised in this piece. I don't get an idea these questions were asked. I don't see a request for answers anywhere in the blog post either. What was the goal here?
On a similar note, removing the `foo` member from T2 also causes abiguity that results in a compile error. The reason this code compiles and runs is because the `foo` in T2 has resolved the ambiguity. Just because there isn't an `override` keyword in front of it doesn't make it not an override. IMO this example is somewhat contrived, but even so, the behavior is exactly what I'd expect. You could argue that the lack of an explicit override keyword hurts reability, but there's always a compromise between concision and verbosity on that front. I find this to be fairly readable and intuitive as is.
But the moment you try to make that ambiguous call, it does become a compiler error. https://play.golang.org/p/umyMFEFTb- This is a feature, not a bug. Imagine you have embedded two types that each have their own String() method. That's not too uncommon. If you aren't actually calling string on either of them with the ambiguous ID, why would you want to be forced to resolve that conflict. If later, you do need to call one of those methods on the embedded class, you can either override those methods on the outer class at the time OR just use the more explicit `t1.T2.T4.foo` style, unambiguous identifier and continue to not worry about the conflict. Go lets you not worry about this whole ordeal until you actually want to. That's a benefit IMO. 
Do stuff, pay attention to what you're doing, ask questions, play around, read. No magic tricks, you just need a strong enough interest to sink lots and lots of time into it.
I think it depends on what you want to get out of the spec. The JS spec is nice because it exhaustively documents every aspect of the language, which is a necessity when you have multiple implementations that need to be compatible. Go gets away with leaving most of the details undocumented because there's only one implementation and "it's like C, just use common sense" works decently well.
&gt; Show me another language where it's as just as easy to write concurrent code. I can think of a number of languages with concurrency that is better than Go in various ways. But I suppose it depends on how you judge it.
Your question is perfectly valid as there *is* a difference between slices (`append()` works fine with a `nil` slice) and maps (m["foo"] = "bar" does not work with a `nil` map) that may not be apparent to newcomers. Consider `append()` as a convenience function for slices to manage dynamic size behind the scenes, which, as a side benefit, also takes care of letting a slice "magically" spring into existence if it is `nil` before the first append(). Maps grow dynamically by default and so they don't need a convenience function like `append()`, which also means they do not spring into existence on first assignment.
I mean the errors package just implements a basic implementation of the error interface, that's not really surprising. It would be more interesting to see the error interface definition, but that is baked into the language so not sure how it works.
Only worse thing was Bloodshed Dev-C++ :(
A SQL `NULL` is a beast of its own. It does not map well to a `nil` pointer, which is why the `database/sql` package defines extra `NullXyz` types (`NullString`, `NullInt64`, etc) with a boolean flag to indicate if the value is `!= NULL`. In SQL, `NULL` means "this value is currently unknown". It represents neither an empty nor an invalid value. As an example, consider a table containing personal data. If the `middle_name` column of a given record is `NULL`, this only means that the middle name of this person is unkonwn. It does NOT mean that this person has no middle name. (In this case, middle name would have to be set to "".) As a consequence, `NULL`s are not comparable. Two persons with unknown middle name can actually have different middle names. In contrast to this, two `nil` pointers of the same type in Go *are* equal. Therefore, SQL `NULL` does not map well to `nil`.
Golang =&gt; Wonderfull.
Interesting, I've recently started to play around the idea of a web crawling platform (something similar to ScrapingHub or Apify but completely open source), using Go. I won't provide a framework for implementing the crawlers so the goal is to support whatever you need to deploy/orchestrate, collect the data from them, etc., even if they're written in different languages. In case you're curious you may find it here: https://github.com/zcrawl/zcrawl
The first sentence of my last reply to you serves to answer this question. If you are not content with the answer you should ask a more specific question. If you don't mean to ask a question, but to make some sort of point, please make it. You can ask "Why do I need to tinker with x in the first place" about *many* x. Why do you have to tinker with executables? Directories? Compiler flags? Programming languages? Computers? It's not a very interesting question on its own. You *already have \[your\] own project folder structure setup*, but how does forcing your every project to have a `node_modules` directory help?
[removed]
[removed]
[removed]
[removed]
[removed]
ABSOLUTELY DISGUSTING.
&gt; but when I am responsible for production software, getting different binaries whenever the same revision of a package gets built is not an option. Then use a lockfile to describe a build and use that to reproduce it. "What versions where used to produce this binary" is a very different problem from "What versions do you need to produce a binary". &gt; An upgrade of a dependency needs to be deliberate and well motivated. And this is, where we fundamentally disagree (and that's fine). If an upgrade needs to be deliberate, it won't happen 9 times out of 10 \[citation needed\]
[removed]
[removed]
Another person mentioned this awesome project and I do agree it seems really good. Unfortunately I see several drawbacks (in my context): - not entirely cross platform (and using CGO stops us from using cross compiling as easily as a simple `go build`) - not possible to add a icon to the application - not possible to add a menu - not possible to add a tray - only one main contributor which is too few for a project that wants to tackle the "cross platform" complexity (which means developing at least for windows, linux and darwin which are way different) Some people may not care about some of those drawbacks, but adding an icon and a menu is usually a minimum requirement for those who want to publish their GUI out there.
[qt](https://github.com/therecipe/qt) is an awesome project indeed but I see several drawbacks: - cross-compiling is difficult since you have to use CGO (installing toolchain or setting up VMs is not a simple thing to do) - you're stuck with "native" looks which I'm not found of - I'm more effective with HTML/JS/CSS when it comes to UIs That being said, this is only true for my specific case and I do get that others will be happier with [qt](https://github.com/therecipe/qt) than with [go-astilectron](https://github.com/asticode/go-astilectron). But I think some people will feel the same as I do and will find [go-astilectron](https://github.com/asticode/go-astilectron) helpful.
I've seen this comment a lot, but I personally disagree. Well designed applications don't take that much memory (for example, VS Code never takes more than a few megabytes, even though technically is doing much more for my productivity than Slack) and even "memory hogs" are justifiable as long as they improve my productivity. I haven't had a computer with less than 16GB of memory for 4 years.
I've seen this comment a lot, but I personally disagree. Well designed applications don't take that much memory (for example, VS Code never takes more than a few megabytes, even though technically is doing much more for my productivity than Slack) and even "memory hogs" are justifiable as long as they improve my productivity. I haven't had a computer with less than 16GB of memory for the best part of a decade.
You're right and I'm not found of Electron either. This is more of a default choice than anything. I'm always looking to replace it with something way lighter since we don't need all its functionalities. I'm open to suggestions :)
On my Ryzen 5 1600X, building the defconfig kernel takes less than two minutes. It's kind of awesome.
I think this is an Electron-related bug so you're good if you're not using it. Check out [this issue](https://github.com/electron/electron/issues/4218) or [this issue](https://github.com/Jam3/devtool/issues/58). Basically you can't listen on `stdin` on Windows with Electron. Which is a bummer in my case.
[removed]
Ha it's nice to know. I will check it out.
I've seen this presentation and I'm not sure what to really think of it. I agree with many of the points but disagree sharply with others. For example, Pike critizices other languages for adding features too much. That seems quite unfair to me, because estabilshed languages have to maintain backwards compatibility and, believe me, they aren't very happy about it either. But they just have to do it, they _literally can't_ remove a feature. Many other languages would be much simpler if backcompat could be broken. It is cheap to criticize that from a position of a new language where the author could do whatever he wanted without having to worry about breaking existing code. 
&gt; Then use a lockfile to describe a build and use that to reproduce it. "What versions where used to produce this binary" is a very different problem from "What versions do you need to produce a binary". It's not a very different problem if you want *a* binary to work as you intended. If an OS package maintainer sees a vendor directory or a gopath with a bunch of submodules they should consider it exactly a description of what I personally use to build and verify that it works as intended. They can ignore that if they want to build it from a different set of revisions. As you already said, this is *always* a problem to package maintainers. The only additional problem to the package maintainer is to patch out the vendor directory in their build script. &gt; And this is, where we fundamentally disagree (and that's fine). If an upgrade needs to be deliberate, it won't happen 9 times out of 10 [citation needed] This is not the experience I had working this way. If it was, the choice between "don't upgrade something that has been verified to work" and "upgrade things indiscriminately in a way that prevents you from knowing what you built" would still be easy. I don't personally care if other teams have problems working this way, so pointing to statistics doesn't help me in the least. The poor choices of those nine others don't affect me until I decide to use their software. They can do dependency upgrades on a fixed schedule if that helps them stay on track. Consider Debian an example of what I believe is well maintained software. I prefer it over other distributions because an upgrade rarely break my system. This is because its maintainers deliberately consider the implications of upgrading its components and verify that it works, yet diligently patch insecure software and release it quickly. The 1 time out of 10 you suppose is in this case a hard requirement, and that's for a very complex piece of software. The software we work on is likely several orders of magnitude less complex, so I don't see a reason why my team can't employ the same rigor and discipline.
It's astonishing to me that you think writing concurrent code in Go is "more or less the same" as in C++ or even Python. Getting a highly-concurrent program in either of those languages to compile and run successfully under load was always a _significant feat_ for me. In Go it's just orders of magnitude easier.
This post confuses the notions of _simple_ and _facile_. Go is a language geared towards concurrency, which is not an easy (i.e. facile) task. The language itself has few features and is highly regular, i.e. _simple_.
npm *just works*. There is no `export`ing or tinkering with workspaces. The libraries you need and the version you need sit inside your project. virtualenv requires you to `source venv/bin/activate` to work properly but it's not a requirement to start using packages, nor does it require you to put your code alongside vendor code (I would argue that Go wants you to do this, but this is purely how I feel).
Well, like I said, it very much depends on the notion of 'concurrency' being referred to. If you need a bunch of concurrent tasks done (which additionally might also be I/O-bound) and need to schedule them onto cores, in Go, this will probably be much more simple than in C++ since a lot of is taken care of by the runtime. This thing is what I like about Go and what I think is the whole reason to use Go (as also pointed out by the blogpost - maybe not clearly enough). The trouble here is that when 'concurrency' is mentioned, everyone pictures something a bit different. And yeah, concurrency in Python sucks.
May i ask the reason?
[removed]
So /r/golang isn't a [wretched hive of scum and villainy](https://groups.google.com/d/msg/golang-nuts/XoOhzUClDPs/bYS9SKY7CAAJ) anymore?
[removed]
I have followed the link and read the whole page. Still have no idea what that thing really *does.* What the heck "task" is — in its vocabulary?
You can automate every golang command or define additional commands to manage your workflow with ease. 
&gt; There's no effective difference [between pointer types and sql.Null*]. &gt; -- Russ Cox
It looks really nice, and as a Go-specific tool I suppose it might have some advantages, but I'm still not sure why so many of these tools seem to be specifically for running Go's commands. In fact, are there some Go specific features? Maybe showing test completion in a nice way or something?
Congrats for the project. I think most people expect a "task runner" to be a command line tool, while Realize seems to be a web app, which cause this confusion. Would you mind elaborating the motivation? E.g.: many Gophers use a Makefile or similar to automate tasks; why do you think they should consider Realize instead?
You should use [Preload](http://jinzhu.me/gorm/crud.html#preloading-eager-loading) err := DB. Where("foo = ?", "bar"). Preload("Allocations"). Find(&amp;contract). Error
That reminds me of ModelSim!
Not necessarily. You've made some reasonable points, but you've not proven that Go is not more simple that those other languages, just that Go is both not as simple as people appear to claim it is, and also not as simple as you expected given those claims.
If you take care you *can* have NULL represented by a nil pointer. Stil they represent different concepts. 
I mentioned this at the bottom of the article, but the Cockroach Labs folks did a nice performance analysis that's worth reading if you are thinking about Cgo performance: https://www.cockroachlabs.com/blog/the-cost-and-complexity-of-cgo/
I can imagine that the live reload mechanism can be quite useful and convenient in a couple of scenarios.
It isn't. The new moderators are active and very good at keeping things on-topic and peaceful.
So, if I write func Foo(s string) {} you suggest that now `string` implements `interface { Foo() }`? And could I have multiple types all implementing `io.Reader`? There can only be one top-level identifier of `Read`, no matter the function signature - or do we need to add function-overloading too? &gt; As others have show, the receiver argument is in fact the first argument of the function, it's a just a strange (IMO) syntax thing... But that is simply not correct. You might want to argue that it *should* be just a syntax thing, but it definitely isn't right now and understanding the difference is key, if you want to have a productive conversation about what the correct solution should be. The receiver acts, in some ways, like an argument: It is scoped like an argument, it is named like an argument and it may be implemented to be passed as an argument. But it is *different*, because it makes a function into a method on the type, instead of just a function. And that matters, among other things, for interface-implementation. The compiler treats them very differently. It's a *semantic* difference, not a syntactical. That's what I meant, when I said that UFCS (as the name suggests) only deals with *call syntax*, not with the actual question of how to attach methods to types. For example, Rust has UFCS and it solves the question of how to attach methods to types (so you can use them in traits, which is Rust's equivalent of interfaces) by putting them in a special [impl-block](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax#Rust_programming_language). Are you suggesting that we do that? That'd be fair enough, but then you'd have to say so and at least acknowledge that a bunch of people (certainly me) wouldn't like that. And give a good argument for why you think my preferences are less important than your preference. Handwaving and saying "UFCS is better" without acknowledging what the tradeoffs are, is simply unproductive.
But `NULL` also doesn't map well to `sql.NullString`. 2 null strings represented in Go by `sql.NullString` are also equal. see https://play.golang.org/p/oK_pU5506M. Therefore this is a bad argument.
&gt; For example, Pike critizices other languages for adding features too much. That seems quite unfair to me, because estabilshed languages have to maintain backwards compatibility and, believe me, they aren't very happy about it either. People have been asking for new features in Go for at least 6 years. How easy do you think it is to keep saying 'no' through all those years and keep the language's core philosophy alive? You are saying it is unfair but on the contrary. Those other languages were once much simpler. Yet they kept adding more features on purpose. Meanwhile, Go is getting constant backlash on social media and from several articles about missing features or features that do not follow the norm. &gt; they aren't very happy about it either. I don't think the Go authors are very happy saying no all those years either. &gt; But they just have to do it, they literally can't remove a feature. Sure they can't now. But they could have said no from the very start. That is what makes the criticism fair. &gt; It is cheap to criticize that from a position of a new language where the author could do whatever he wanted without having to worry about breaking existing code. Again, the authors of those languages were once in the same position. Yet they keep adding more and more features till this very day.
[goSQL](https://github.com/quintans/goSQL) might interest you . It is based on database/sql. It has everything you ask and more. It can also be used to execute sql directly. It works with MySQL, PostgreSQL, FirebirdSQL and Oracle. It has SQL DSL, Versioning, Optimistic Locking, easy Joins, Pagination, etc Disclaimer: I am the author
Because both language kind of partially address the same problem space ?
I'm curious as to which ones they are. In my experience I haven't found a language like it. Node is probably the most similar but programming with an event loop isn't as intuitive as goroutines.
*Kind of*, but not completely. Most of what I'd call "type extension" in classical OOP is not possible with interfaces. For example, if you don't know a type statically, it is impossible to override any of it's methods. While you can do type X struct {} func (X) Foo() {} type Y struct { X } func (Y) Foo() {} to override a method if you know the type statically, if you try and do that with interfaces (the only way to subtype in Go), you'd get into this problem: type X struct {} func (X) Foo() {} func (X) Bar() {} type Fooer interface { Foo() } type Y struct { Fooer } func (Y) Foo() {} func main() { y := Y{X{}} y.Foo() // fine y.Bar() // not fine } So, while `X` is a subtype of `Fooer`, there is no way to a) extend `Fooer` and b) apply that extension to `X`. You have to explicitly mention `X`. There is another way in which Go's subtyping works differently from a bunch of others: It is not functorial (neither co- nor contravariant). That is, while you can subtype using interfaces, function-types using the super-type don't "lift" to the subtype. Or, to be more explicit: type X struct {} func (X) Foo() {} type F interface { Foo() } func A(X) X { return X{} } func B(X) F { return X{} } func C(F) X { return X{} } func D(F) F { return X{} } func main() { var f func(F) F f = A // does not work f = B // does not work f = C // does not work f = D // okay } Both of can be rightfully called limitations of Go's type system (and both of them occasionally frustrate me). But, as I mentioned in another thread, limiting expressive power is exactly the way in which I call Go "simple"; by preventing you from writing complicated code, it forces you to write simple code.
&gt; useful and convenient in a couple of scenarios. cause there are a lot of go commands that you need to use during the develop of a go project
Go errors **are purely a convention**, not a language construct (although error is a builtin type). Go errors don't do anything special! You could replace them with int error codes it wouldn't make a damn difference.
this is a command line tool but there is also a web interface for monitoring the workflow
Just like PHP doesn't have a built-in ORM, neither does Go. A lot of people use Go for micro-services, where using that level of abstraction is unnecessary. I'm one of those people, and I tend to stick to using plain SQL, at the moment mostly with the standard library's `database/sql` package. I have heard many good things about sqlx though too. SQL injection is actually trivial to avoid using prepared statements. The _one_ place I miss having some kind of abstraction (though, not an ORM actually) is the one time I switched from MySQL to PostgreSQL and had to update some of my queries. I missed having a DBAL in that case. ORMs tend to do a _lot_ of magic for you. They also tend to result in much slower code (at the very least in PHP, i.e. Doctrine / Eloquent). If you get used to using either some very (very) thin abstraction, or just plain SQL then you'll find if you organise your code well you can make something that's much more performant. I can see why you're worried about security and bugs, but honestly, just learn some basic best practices, there's really not much to it.
&gt; But NULL also doesn't map well to sql.NullString. 2 null strings represented in Go by sql.NullString are also equal. Valid point, but if you use NullString you usually are aware of the meaning of `NULL`. My point is that it is too easy thinking, "ok, `NULL` is something like `nil`, so I'll just use a pointer" and not noticing that there is a semantic gap between the two. Your point about memory locations is absolutely right, albeit on a different level (implementation).
So it basically replaces cmd +c =&gt; up =&gt; return?
[removed]
to be clear "author didn't like Go" is a valid stance lol. I mean I program a lot of Go but it drives me nuts a lot of the time too, it's just the least awful thing I've found.
[removed]
Agreed, I too had that confusion. I wish projects would explain core concepts of their product.
I have done something similar before, in my security research. Well honestly a big thing you should invest in for a distributed web crawler is scheduling / lb algorithms built into the clients, I followed this variation of P2C https://cs.stanford.edu/~matei/papers/2013/sosp_sparrow.pdf , also another thing that saves up a good bit of work, as you go along, is writing an endpoint that has a bloom filter to check if a link is found before it's submitted to the workers, preferabley one that is mergable along with any other state, also for the sake of avoided duplicate work being sent instead of simply replicating requests to N masters to trigger the state change, I suggest you should just have them periodically pull eachother to merge such state. As for what kind of state you may have, worker membership, bloom filter, and master membership.
:) Ok, that's a cool stance.
Yeah, for sure it could be replaced with a simple cmd +c =&gt; up =&gt; return. Realize can help you in some case like: manage rebuilding on file change on more than one project, filter std outputs (on a web page), run more than one task on file change (ex: fmt, vet, test, run, build). I hope you could understand! I'm a developer of realize and if I can help I'm here!
So uhm.. cron?
Go is certainly simpler than C# or Python. Both of those have feature lists that just go on and on. [Python and Go I happened to write about a month ago](https://www.reddit.com/r/programming/comments/776onv/why_we_switched_from_python_to_go/dol35jc/). Python is a nice language and I think it's easy to just sort of _forget_ about how complicated it is now, but it is complicated. C# has pretty much every feature Go has, and then the feature list goes on and on. Java has gotten more complicated, but Java _qua_ Java might not be _that_ much more complicated than Go. (Dunno. You still have a lot of complicated OO machinery that Go doesn't have. Certainly I wouldn't accept the proposition that Java is _simpler_ than Go.) However in practice the number of layers of abstraction you have to use to do anything makes Java code much more complicated than Go code. It isn't just a culture difference, either. There's a lot of little semantic differences here and there that add up to Java affording much more complicated code, despite the fact that on paper, Go and Java are very similar to each other. The code in C# certainly comes out more complicated. In Python, you have the option to write simpler code, as long as you don't end up using certain libraries that end up essentially forcing complication on you. I watched a QA person basically bounce off of Python because of things in the testing library that were just too magical to understand or debug. The Python code itself wasn't bad but the test library made extensive use of decorators and introspected on functions to look at their argument _names_ and magically provide the right arguments given the name... it was not simple code. To make my biases clear, I like Python, C#, and Go, and wouldn't program in Java if you paid me.
[removed]
No because a cron task is executed any X time offset; realize watch project files and you could define a set of go commands when file change event is raised. Hope is more clear now!
You have something better to come with? It's your time, go to those stupid engineers in Slack/doscord/microsoft/etc and sell your super cool ui kit which is not disgusting. Context: first comment was a guy blaming Electron.
I thought it was a pretty interesting read TBH - Go fills that spot for me between java and python, and I have to agree with the assessment of generics. On another note, it does seem a shame that opinion pieces need to have disclaimers.
&gt; In SQL, NULL means "this value is currently unknown". NULL strictly means "A value does not exist in the database." Whether that means the value is unknown, non-existent, both, or other is up to application logic.
The golang beginner books don't have the answers to all the problems, but they provide a decent set of rules of thumb to follow that have been beneficial for me. The language is simple. The number or words in the golang language may contain a few more words than the C language, but the fact it can get so much done with that deliberately constrained language is a great feat. The fact it has saved me loads of time doing different tasks speaks volumes also. Doing the same tasks for me using non golang languages I perceive to be masochistic. I'll also re-iterate and acknowledge that golang is a software-engineering language and holds its water against Ada and Java in every respect including long-term maintenance. Hats off to the golang creators and maintainers.
No, you find that Go has a few oddities; you don't show that it has fewer than C#, Java, or Python. And you certainly don't show that "oddities" are a more meaningful indicator of complexity than the size of a language's feature matrix or the pervasive use of inheritance and other bad abstractions in the standard library.
Well taken literally, I'd say it's easiest to write concurrent code in Javascript. All you have to do is add async and await to your code. As far as making it easy to write concurrent code *correctly*, Rust wins hands down. I'm not sure what are so intuitive about goroutines. They're just green threads. If you ignore the stack usage optimization, it's the exact same programming model as traditional threads. Channels are nice for simple tasks, and I guess having built in syntax for them makes things easier, but then again Javascript has built in syntax for promises, and those are more useful than channels in most cases. And for more advanced usage, you'll quickly run in to the limits of channels and be back using mutexs, atomics, and the like anyway. At that point, you may as well be programming Java. 
&gt;The language constructs do take some time to get used to (havind one workspace for everything? Really?) but I cannot imagine myself without it in the meantime. You can definitely have multiple workspaces in Go. I see this comment over and over again. Please see this link: https://golang.org/cmd/go/#hdr-GOPATH_environment_variable. The relevant part is here: &gt;The GOPATH environment variable lists places to look for Go code. On Unix, the value is a colon-separated string. On Windows, the value is a semicolon-separated string. On Plan 9, the value is a list. That means you can have multiple Go workspaces, and just like the $PATH in Linux/Unix and Windows, Go will search each workspace in turn until it finds what it needs. So, you can have GOPATH=/home/user/work;/home/user/school;/home/user/personal and your code will all get recognized by Go.
&gt; Go has precisely two cases: Either you have a struct type, in which case it is going to call the c method on b, or an interface type, in which case it's going to indirect off of the interface and then simply call the method. To be pedantic, there is a third case: `c` is a field on `b`'s struct type that is a function type. (for example, `type B struct { c func() }`). Of course this doesn't affect your argument, as it's still very easy to reason about.
Not to the same degree, and you don't get there by accident because you were trying to reuse code. If you do this in Go, you're doing it intentionally, and your readers can predict what will happen. OTOH, you can do things like this in most OOP languages just in the normal course of trying to reuse behavior, and suddenly it's unclear what will happen (and mind you, this is a toy example--the problem worsens exponentially with complexity). class Parent { foo() { print("Parent.foo") } bar() { this.foo() } } class Child extends Parent { foo() { print("Child.foo") } } var c = Child(); c.bar(); You would never see something like this in Go as an accident of reuse--if someone builds something that does that, its behavior and the intent are both evident.
Good point.
If it's not on the same level, it's not an ambiguity. It's not a bug, it's your preference.
I understood some of those words.
&gt; That's a very weak argument. "Just do it this way", without knowing why it's superior. Right now I see no reason why this is "better". Who ever said it's superior? It's just part of the language/ecosystem. When someone is new to Go one of the first things they read is [how to install the language](https://golang.org/doc/install) which has a link explaining the concept of a [workspace](https://golang.org/doc/code.html#Workspaces). So instead of doing one of the first things you learn about this language, you go on the forums and complain? I honestly could never understand that attitude. This is equivalent with trying to learn the Java language and complaining that you have to install the Java runtime on your machine.
Or c is a method on a recursively embedded field
That is like saying "in Python, there is no ambiguity with the diamond inheritance problem, because the MRO is part of the spec". It would also imply, that it would be fine to *never* break and, e.g. resolve the ambiguity by saying "if two embedded fields are at the same depth, the one that is mentioned first in the embedding type is used". Surprising behavior does not become unsurprising, just because it is formally described. I do agree that Go's behavior is unfortunate here (though I don't believe it to be a problem in actual practice). Like, say I publish some code on github type Foo struct {} And someone else publishes type Bar struct { X int } And then some other people embed these types in some hierarchy, until finally someone writes something like type Stuff struct { A B } where A recursively embeds Foo and B recursively embeds Bar. If I now add a field `X` to Foo (without *any* knowledge of this whole embedding snafu), I will either *break* Stuff (if, by coincidence, the length of the path from A to Foo is the same as the tree from B to Bar) or I will silently change the behavior of anyone referencing Stuff.X (if, by coincidence, the length of A-&gt;Foo is shorter than the path B-&gt;Bar), or nothing changes for users of Stuff (if the length A-&gt;Foo is longer than B-&gt;Bar). And what happens is basically random, with no one actor able to predict it alone. I think it is a very valid complaint, that this is not a good situation to be in. And I tend to agree that unconditionally breaking in this situation would probably be the best solution (as the compiler can't know the history of changes and prioritize accordingly, to not change behavior). It seems worth rethinking this for Go2. However, as I said, I don't think this becomes an actual problem in practice very often, so using this to come to the conclusion OP does &gt; **No one can convince me that Go is one of the simplest languages out there or maybe even a simple language after I’ve seen the code above.** seems a bit of a stretch and like making mountains out of molehills to me.
Adding fields to an exported struct is a breaking change to an API, because you can no longer construct them with `type{val1,val2,val3}` syntax in the same manner, so If someone actually does this it's on the fault of whoever added a field to their exported struct.
[Every API change in Go is a breaking change](https://blog.merovius.de/2015/07/29/backwards-compatibility-in-go.html). And FTR: a) The Go1 compatibility guarantee has explicit exceptions for unkeyed struct literals for that reason, b) it also now has an exception for embedded fields, for that reason and c) the same argument also applies to methods, so the unkeyed struct literal is a red herring. I agree with your premise (obviously, which is why I wrote that article), but not with your conclusion. Taking the position that if a change can possibly break some code in existence you can not make it is an impractical position. Adding fields to structs is widely accepted to fall under "backwards compatible enough to not warrant a major version increase" in the Go community. Because, in general, the Go community tends to value pragmatism (sometimes to a degree that frustrates me, but most of the time to a degree that I find delightful and refreshing).
Ah cool. I run lint, import, tests, build etc on save in my IDE so i have never really seen it as an issue. Good to know it exits though. Might find use of it in the future if i work on something with a more complex build process. :)
The comments seem to misunderstand what this tool is and what it does. Think of it like `nodemon` for Go.
I use atom and the debugger works for me. It is far from perfect though. I have tried vscode before but not for go. Everyone in here has convinced me to give it a try. :)
Yes, you are going in the wrong direction (both you and /u/Sythe2o0). UFCS would be [this](https://play.golang.org/p/9nQJ9NOVtU), which doesn't work. Relevant quote from the [Wikipedia](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax): &gt; that allows **any function** to be called using the **syntax for method calls**
The utility of channels doesn't really shine through until a select is involved IMO. A while back I wrote an oddball toy scheduler to monkey with (abuse) Go's synchronization primitives. It tries to serialize jobs while allowing each one to control when concurrent subtasks are run in relation to neighboring jobs in the queue. Being able to nil out channels in a select to ignore work that has already been added made this far easier to reason about. The code is pretty horrifying but I wouldn't know where to begin implementing something similar in another language. https://play.golang.org/p/mVFzEeAKz8
&gt; Nikola Visnjic Sept 4 email &gt; Gogland will be included while the transcription is running, however, as it has not come out yet, it will not be included in the perpetual fallback license.
There is a difference between "this design choice is different from the rest because of reason xyz" and "this design choice is different just because". 
[removed]
I'm curious as to what you mean with this - there's no "inheritance" with interfaces, there are only implementations of the interface spec. I can, in some sense, 'inherit' the implementation of an interface by anonymously embedding a type that implements it, but I cannot change how that implementation inside the embedded type works, even if I implement one of the calls on the outer type. Even embedding the type 'X' in 'Y', the behavior inside X never changes (ie. if another method on X calls "Load", it never calls Y::Load()). I find that this tends to make your type design rely more on inversion of control, such that you would have a Loader interface and make it a parameter, which also tends to have significantly more clarity (you can see that it's something provided from outside), more testable and more flexible (since inheritance can be very limited once you have more than one axis of options).
Can you go a bit into the roles/teams? Also, compensation range, etc would be really appreciated.
Virtualgo looks interesting, I'll check it out.
Sure. Let’s chat about that offline though re: comp. feel free to email me direct Team-wise most of our backend is built in go and most teams are hiring so a lot of flexibility depending on your goals, experience etc. 
have you looked this: https://github.com/golang/sys/blob/master/windows/svc/example/service.go
I think the authors could really do with taking this to heart and making sure they answer the question of "what does this do for me that I should want it?". The fact that has the best performing live reload something means nothing to me if I don't know what experience that aids me with. Pick some use-cases and explain how it makes them easier.
I haven't, I'll check it out closer. Thanks!
Oh, makes sense. Thx.
[removed]
Thank you very much!
I'm using https://github.com/kardianos/service you should check it out
[here](http://maradns.blogspot.ca/2009/03/ive-got-working-windows-service-running.html?m=1) is a link to a very small c program that does it. Should be adaptable into go.
It depends on exactly what you are looking for, but there is a [gofmt -e option to check syntax only](https://stackoverflow.com/questions/16863014/is-there-a-command-line-tool-in-golang-to-only-check-syntax-of-my-source-code). If you demand that it be very fast, that's probably the best option. That still doesn't prove it will build, because there can be non-syntax problems, but if you start down that road you end up at "you're gonna have to compile it" pretty quick.
&gt; Go requires you to put all your projects and your dependencies one roof just because. Not really. There's many reasons why Go uses the concept of a workspace. Here's some of the [reasons](https://talks.golang.org/2014/organizeio.slide#12) behind it.
"It depends". RPM at the very least adds versioning in a standardized way, which your Go binary won't have. (I routinely add versions to the help string of my Go binaries that I ship, but it's not _standardized_, because there isn't a standard way to invoke an arbitrary EXE to get a version.) My guess is that they want RPMs to integrate into a pre-existing process or tracking mechanism of some sort, in which case, yes, it absolutely makes sense to wrap Go binaries in RPMs to work with those systems. You can't "yum install" your binary. If you're having trouble with the build process, I suggest learning enough shell scripting to make it as easy as "make_rpm". It should be very repetitive. Though you may need to at least advance a version string. Sufficiently creative shell scripting may even ameliorate that requirement. I would also recommend using the RPM mechanisms to ensure you have a repeatable build, by making sure the source RPM has all the relevant source in it. There's a variety of ways to do that, but it's a good idea.
And the slide immediately afterwards say: "It is possible to have multiple workspaces, but most people just use one." This creates the dependency hell problem I am talking about. In Python using `virtualenv` for dependency isolation is pretty much standard practice, and with one `source`, you don't need to worry about polluting the main environment anymore, since whatever Python commans you run will automatically be run in the right context. With Go you have to constantly reference the $GOPATH, which IMO is very annoying.
"#1"? Automatic downvote for being ridiculous.
Personally a go binary and an init script/systemd unit is all thats needed. People love their RPMs and even their [Maven](https://github.com/raydac/mvn-golang) builds, and then they'll throw the [rpm-maven](http://www.mojohaus.org/rpm-maven-plugin/) plugin when its just unnecessary. Go makes things ridiculously simple, unless you have other things that require bootstrapping around the application, why complicate it?
To ensure Go source builds, you must build it. There is no way around this, what are you actually trying to achieve? If it’s to lower the time between feedback while writing Go code- “go build” may be suitable so I would start there. If you have found it takes to long than maybe you have a project with large amounts of compiled code inside it, which could be moved to another package to lower compile times. As a last resort you could run go build without any ssa passes by passing -N via gcflags which should disable the lions share of the processing time.
Yes, one workspace is the standard practice because of all the advantages it offers. You don't have to like it and I am not saying it is superior than other solutions. But if you follow it, it simplifies things a lot. It is *convention over configuration.* &gt; This creates the dependency hell problem I am talking about. Dependency management is a whole other topic. I thought your problem was that you wanted to use your own project structure. (Which you can do by the way. Check out [gb](https://getgb.io/).)
Maybe [go-bin-rpm](https://github.com/mh-cbon/go-bin-rpm) can help.
There is a reply feature on reddit. You should probably use it ;)
&gt; E: Forgot about migrations too, migrations are actually far easier than you'd think to implement yourself. How do you do your migrations?
I'll also just add that if your company expects deployment to work through RPMs, you shouldn't try and work around that just because your thing doesn't need it. There are possibly all sorts of reasons (like easily seeing what's installed/available, staging to production repositories and just doing an update) and systems that are assuming it, and you'd be creating a snowflake for everyone to deal with. It would also be a bad idea if your manager / lead has asked for RPMs to go back to them with "the internet says no". This said, maybe a binary rpm is acceptable, especially if you can dramatically reduce the size and remove the need for a go toolchain to be installed on production machines?
The way to do it on Ubuntu server is with [Systemd](https://fabianlee.org/2017/05/21/golang-running-a-go-binary-as-a-systemd-service-on-ubuntu-16-04/) or [Upstart](https://www.digitalocean.com/community/tutorials/the-upstart-event-system-what-it-is-and-how-to-use-it) depending on the server version.
Dependency hell is a side effect of encouraging a single workspace: If your projects live with your dependencies it is possible for dependencies to clash. Workspaces can be used to solve this problem but it's only a partial solution as conflict of nested dependencies is still not accounted for. It seems like to me workspaces is just a fancy way of forcing a directory structure (which I have no problems with) So I guess I don't understand why workspaces exist in the way it does right now, and what advantages it brings over just enforcing a directory structure in a project, wherever the project lives on the disk.
Ah shoot. Getting downvoted now. Sorry!
We use you guys a lot, can you do a dark theme, or a dark neon theme.. the ui could look so much better..
screen 
Decent pair of posts, but "fully tested" is not the same as "the Go backend has some unit tests".
Thanks! I’ll float to our UI team right now!
Per a slack message with our director of design “ha yeah that’s in the works”
&gt; would also consider remote engineers in the US where needed/qualified. This phrasing is a bad sign for remote people as it usually means that remote working is not a priority and that you will be an outsider on your own team.
Cheers, also the emails that get sent out could be far better, allow us to customise them, select the data shown, and allow web hooks etc. Also a iPhone app would be good, with a cut down set of options, just giving me a snapshot overview of our system. Cheers and keep the google work up.
Well about 20 percent of our tech team is remote. We do have a remote first culture but the majority are in Paris or NYC. 
Supervisor would work as well
&gt; I didn't compare feature matrices, that's a good point, but even if I wanted to, I really don't know how I'd even go about it so that it would make sense and would not be affected (or rather entirely based on) opinion. This discussion (including your article) has been entirely anecdotal and subjective; why should we toss out feature matrix comparisons? &gt; I probably would never count inheritance as a very significant factor, probably because I don't have the bad experience with it that you seem to. More likely you're missing the good experience *without* inheritance that makes you realize how poor your inheritance experiences have been. Inheritance is the conflagration of two distinct concerns: abstraction and reuse. Good primitives keep orthogonal things separate. There are cases where inheritance is reasonable and desirable, but those cases can be supported by emulating inheritance with other primitives. We don't go around creating arbitrary "primitives" from every combination of simple building blocks. The other problem with inheritance is cultural--a generation of programmers were not taught to use inheritance where it's appropriate (when we want both abstraction and reuse) so we have whole ecosystems (including standard libraries) that are littered with inappropriate uses for inheritance. Further, even if you have a use case that is appropriate for inheritance *today*, there's no saying whether or not you'll need to extend it *tomorrow*; inheritance unnecessarily paints you into a corner (getting out of it means refactoring including breaking a public interface).
&gt; The JS spec is nice [...] You can tell what any given piece of code is supposed to do just by reading the spec. Obligatory https://www.destroyallsoftware.com/talks/wat
Agreed. I just wanted to demonstrate how to test all layers of the application, from server, to router, to handler. By "fully tested" I rather meant "all important aspects are covered with some form of tests", but used the former expression for lack of a better title
The "one workspace" thing was probably the largest initial hurdle to get over that i have ever experienced in a language. To get up and running you have to figure out these directories, environment variables and github namespaces. Made it harder than it should be to get started 
My laptop has 4 cores too (8 threads). It's just a mobile i7, nothing extreme.
[removed]
I posted a gist with the systemd unit file I use for GopherAcademy's website which is written in Go (in Buffalo) here: https://gist.github.com/bketelsen/b6f8123cf66d1edd602c50a0b5a549f5 You can modify it to suit your needs, then add it to /etc/systemd/system and run: systemctl enable yourfile.service systemctl start yourfile.service journalctl -f -u yourfile.service &lt;&lt; to see logs Search for info in Google on SystemD unit files if you have any questions, or ping here, plenty of people probably do!
[removed]
Thanks for replying and trying to address the concern. I'd still be wary with that positions associated with that wording. A remote-first company wouldn't "consider" remote engineers, it would welcome them.
Sorry for not conveying what I meant to say properly. There are circumstances when remote wouldn’t work and that would be for more junior engineers that haven’t done remote previously or people that have difficulty communicating when geographically far from a team. Outside of that, we foster a culture that is built on having a widely dispersed team — most chat is done via slack vs in office, meetings are done at times that are most conducive to other time zones where possible and done via google meet. Hope that clarifies things a bit. 
Are there any available internship opportunities for Summer 2018?
It’s a bit early to start that now but closer to then, yes we will be hiring interns. 
You cold use ranged request and limit bandwidth that way.
rpm isn't the standard. rpm is for redhad based systems (redhat, centos,etc) deb is probably the most popular, based on debian systems (Debian, Ubuntu, Raspbian, etc) If you want to be portable maybe use docker instead. That's what it's designed for and will run on windows and OS X as well.
Yes, same for me.
Yep, I know you can, but hassling about with environment variables is not the easiest path to get started. Adopting an IDE which supports overriding this really helps :-)
You're offering equity in the company? Are you certain? Do you mean stock?
Hey Ryan, I submitted an application for a summer 2018 internship about a month and a half ago and didn't hear anything back. Given what you've just said, can I be hopeful and assume that no one's looked at it yet?
Thank you very much! 
&gt; Dependency hell is a side effect of encouraging a single workspace: If your projects' code live alongside your dependencies it is possible for dependencies of different projects to clash. Yes indeed that is possible. But we are talking about a monorepo here. If in your monorepo you have two conflicting dependencies then you have a problem that you gotta fix. In an ideal scenario, there can't be dependency hell in a monorepo as long as you do your job right as a developer. Of course we are not living in a perfect world. There's always time constrains, developers who have been trained to import 50 dependencies just to start a new project, developers who don't care about their dependencies whatsoever, or simply lazy people. So for this more realistic scenario there's vendoring. This is the official way to do dependency management in Go. Do you want to do it manually? With a tool? It doesn't matter. It solves the problem. Is it superior than the way other languages do it? Probably not. But that's the way it's done in Go.
Most likely they want to store/retrieve all packages in a common repository and (not unreasonably) don't want per-language exceptions. There are advantages to that; binary formats and package formats are really orthogonal and serve different functions. [fpm](https://github.com/jordansissel/fpm) is excellent and may be of use if you want to easily create an rpm package from existing files without learning any arcana of the rpm packaging process.
I think with the latest Go version you don't need to set the environment variable anymore. There's a default one. The github namespaces are entirely optional too. As for the directories, how hard can it be to create 3 folders? :)
If Go wants you to put multiple projects in one workspace, it's not really monorepo anymore is it? (Notice projects being plural)
If all Go projects live under `$GOPATH/src`, how is it not a monorepo?
Yeah. It’s a bit early for our intern processing. 
In regards to using Datadog as a customer or developing for datadog as an employee. The former is hard for me to comment on since I’m not in sales. The latter would be not difficult but depends on the person and their experience / aptitude but generally experience building a monitoring product is a big plus. 
Two completely unrelated projects under `$GOPATH/src`.
Note that go's spec is written with multiple implementations (at least two fully complete ones) and they did that specifically to remove ambiguity.
Have not looked thoroughly but just FYI `range` returns copies of values so you are not going to `Init` elements in slice but copies of them. And the slice you allocate is a slice of Worm not of *Worm so you are not operating pointers but whole objects. You should be able to figure the rest.
Ok, thanks! I'll keep my fingers crossed haha. 
No is temporary, yes is permanent.
aah! Thanks, that is definitely the problem! I was convinced it was gonna be something really derpy I was doing but I decided to post it in case it was some go-specific detail (like this) that I just didn't know - and now I do. 
Yes, I know that now, and you know that now. But for a completely new user. Someone that just wants to try out go. It is kind of odd and a hurdle when starting out. Compared to some other languages this is kind of a wall to hit: https://golang.org/doc/code.html
I've already told you. Either manage your dependencies properly and fix the issue (monorepo) or vendor.
An idiom I heard somewhere and has saved me a fair amount of headache is "never take the pointer of a `range` value". By running `w.Init`, defined as `func (w *Worm) Init`, you're effectively doing just that. Change your range from `for _, w := range worm` to `for i, _ := range worm` and then use `worm[i].Init`, and that should work.
thanks, aboukirev's comment beat you by a few minutes and pointed me to the error in my thinking. Didn't even occur to me that range might be returning copies rather than references to the array items.
&gt; Whatever makes you think I only have experience programming with inheritance?!? I coded quite a bit in C, in fact, that was the main language in my previous job and it was ok for me without inheritance even before Go was even around (and no, we didn't use GObject or anything like that). Also, I have written quite a lot of code in Rust (including code which shipped in a product) and Rust rejects inheritance even more than Go (there's no embedding). I am confortable programming both with inheritance and wihtout it. There's no reason for a dilemma here. Sorry, that was a joke. I didn't mean to sincerely impugn your credentials. &gt; From your examples in the discussion it seems you might not be aware that overriding can be controlled and prevented. Only by way of *even more complexity* (additional keywords or tweaking metaclasses in the case of Python). And it still doesn't get you the full flexibility offered from composition + interfaces (for example, you can't swap the parent "instance" at runtime, like you could with `type Child struct { Parent }` in Go). This is what I mean by "inheritance is a bad primitive".
&gt; But for a completely new user. Someone that just wants to try out go. There's the go playground for that. In fact it's an incredibly friendly way to try the language, especially for an non interpreted language. &gt; It is kind of odd and a hurdle when starting out. Compared to some other languages this is kind of a wall to hit: https://golang.org/doc/code.html I suppose it's possible. I can't know because I've had hurdles installing most languages. I remember back in the days when I was learning Java and I had trouble setting JAVAPATH. I also remember having trouble with Python (2 or 3) and Ruby (that was hellish). Go wasn't much different I suppose but I'd argue that it was easier. Of course it's entirely possible that I found it easier just because I've had experience installing the other languages. It's also possible that the installation experience of the other language has become much easier since the last time I tried them. Nevertheless, now that the newer Go version sets the environment variable by default, I truly cannot understand how people are still having trouble with it.
&gt; A remote-first company wouldn't "consider" remote engineers, it would welcome them. Do they call themselves a remote-first company?
Why should a dependency conflict between *two completely unrelated projects* bother the developer? They are *unrelated*. Their dependencies should have nothing to do with each other. If the solution is to vendor, why have workspaces at all? If the solution is to isolate environments, why would Go encourage people to use a single workspace? This is what I don't get. Go is trying to pull a Python virtualenv then tell people to not take advantage of it and do a npm node_modules instead. 
Forgive my ignorance, what do you mean when you say widget? There were windows gadgets, but they were discontinued for security concerns. 
Thanks for this. 
Also in your range loop w is a value, not an index as you use it in your code.
&gt; If the solution is to vendor, why have workspaces at all? Vendoring was introduced in Go 1.5. &gt; If the solution is to isolate environments, why would Go encourage people to use a single workspace, causing a potential dependency clash? If you properly manage your dependencies in the single workspace/monorepo then there can't be a dependency clash since there is by definition only one version of each library installed. They probably came up with that idea since at Google they use a giant monorepo. Obviously it wasn't appropriate for the wild so vendoring was introduced later. The situation is much better right now but it can still be improved. Russ Cox (rsc) one of the Go authors already replied to you about that.
But does `go get` not put all dependencies in `$GOROOT/src`? Are you saying I should not use `go get`?
Go, with its implicit interfaces, already gives the compiler enough trouble eliminating unused methods from the compiled code. With your proposal, it would be almost impossible to ever eliminate any unused functions.
That or this https://nssm.cc/
I couldn't find any details on people who are in the Reserves / National Guard at Datadog. Next year is my last year in the Reserves where I have one weekend a month and a month in the summer that I have to take off work for mandatory training. Do you hire people in the Reserves? 
Thanks
&gt; But does go get not put all dependencies into $GOROOT/src? It does. &gt; Are you saying I should not use go get if I, god forbid, have two unrelated projects who happen to have dependency clashes? First of all, Go libraries are encouraged to have as few dependencies as possible. ([It's part of Go's mantra](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s)). When a library absolutely needs to have a dependency then it can just vendor it. That way, there won't be clashes even when they end up under the same monorepo. So in practice it's very rare to have dependency clashes so you can use `go get` freely. If you do happen to have a clash then you really need to take a good look at the projects you are importing. The monorepo might be somewhat restrictive but it really does make you think about proper dependency management and the code you are importing. &gt; I am aware of the vendoring experiment, I'm just not sure how that fits with workspaces and go get. If the projects are properly vendoring their dependencies you won't have any trouble when you use `go get`.
Can use docker
If vendoring is the future of dependency management in Go, what is the point of copying vendor source codes into `$GOROOT/src` when `go get`ting? I don't see a need for `$GOPATH` or even Go workspaces if projects are supposed to be self-contained, with vendoring taking care of dependency storage. (Which is what /u/rsc said I guess.) I think from now on I'll be sticking with virtualgo.
&gt; I'm not sure, but presumably the same way? ie. So, that requires function overloading. Meaning you now need to add a definition of how overloaded identifiers resolve. What if multiple functions could take a given receiver? For example type X struct{} func Foo(X) {} type Y struct{X} func Foo(Y) {} type F interface { Foo } func Foo(F) {} func main() { Foo(Y{}) } which gets called? And you haven't dealt with the question of what happens with predeclared types, or types from a different package, or interfaces. Wouldn't this be totally counterintuitive? type X int type F interface{ Foo() } func Foo(X) {} func Foo(int) {} // Predeclared types. Yes/No? func Foo(F) {} // Methods on interfaces, currently disallowed. Yes/No? func Foo(*os.File) {} // Methods on types from other packages, currently disallowed. Yes/No? If you say "no" to any of these, you have to explain which are forbidden and why - which seems hard to justify, after all, the goal was to make the receiver equivalent to other parameters. But if you say "yes" to any of these, you have to specify with the semantics of each and deal with the fallout. For example, how you are going to explain to people that importing package foo might change what interfaces a type in package bar implements (because foo might add methods to them)? And yes, of course you can now come up with another ad-hoc answer. Of course it's possible to give a self-consistent spec of how to resolve all of that. But we already added a *lot* of complexity and confusing extra behavior and deep incisions into the language for something, that was supposed to a) simplify and b) be just "a simple syntactic thing". I'm not trying to be mean or anything, just to illustrate *how much extra complexity* is hidden behind something that seems to be simple to you. And how hard it seems to me to justify that, just because you don't like the receiver syntax. Maybe it isn't that bad after all? Maybe it is indeed *simpler* than the alternative? &gt; Do you mean that the receiver argument is treated differently than the others? Yes. The receiver is, what makes a function a method, i.e. a property of a specific type. Your proposal either means, that there is no longer a semantical distinction between functions and methods (currently, there is one and no, that is not about syntax, as illustrated with interfaces), or that you'd need some other way to specify that you are declaring a method, not a function (e.g. by putting it in an `impl` block, or prefix it with `T::`, or by using a different keyword, or whatever). The latter would indeed be a purely syntactical change, but it wouldn't actually improve anything, IMO. &gt; this is also the case in languages with UFCS. No. By its definition, UFCS just gives you a bit of syntactic sugar to use method call syntax to call a function - I'd even go so far as to say that it explicitly *maintains* the semantic difference between them (the definition is "it allows you to use method call syntax on any function", clearly saying they are different concepts). Which brings us back to above choices. Currently, Go makes a semantic distinction between methods and functions; either you maintain that (meaning you need a syntactic indicator of whether you are writing one or the other), or we are no longer talking about a purely syntactical change (meaning you have to deal with all the implications of your overhaul of… basically the complete language). &gt; In D for example, you don't need to explicitly attach methods to structs (although there are methods as well, obviously) AIUI you do, if you want to use inheritance/polymorphism. You are still only referring to the *call syntax* and, yes, UFCS still does handle that. But that's not the whole issue. (also, D has the features I talk about above; most importantly, function overloading. That means the marginal cost of UFCS is lower for D, than for Go, given that they already paid the price of adding overloading).
[removed]
There are a lot of reasons that RPMs are valuable. Versioning is a big one that has different implications. While you might manage a version number for your binary, you also might use a git sha in which case an operator wanting to rollback your change needs to do a lot of legwork to even try to understand how to revert. Also, different software systems have different version standards. Python for example allows things like `1.2.3b` where as Go doesn't really have a prescribed standard. Another thing is that RPMs define dependencies. While your Go binary might not have dependencies, if you Go binary ever shell's out to a program you expect to be there, you avoid a ton of work by just naming that as dependency of your RPM and letting the package management install it. Otherwise, that implicit dependency would need to fulfilled by a config management tool like Chef or Ansible or even shell scripts. The RPM allows that index to be maintained and avoid installing packages where dependencies might not be available. Also, there are many existing repositories that support tooling like yum that query and download RPMs. This automatically puts the files in the right place, takes care of file permissions and can even include default configurations, set up init scripts or any number of helpful things that need to happen in order to actually use the package. None of these requirements are intended to be operating system specific either. You can do all this with more custom RPMs (for example if you use ubuntu hosts, but deploy RPMs in a specific directory). It is very helpful to standardize on this sort of tooling, even if it is painful, because you can start to create a clear path from code to production that includes a defined binary. Without that structure, you need to solve for many problems that system packages like RPM handle perfectly fine. Also, docker is very similar in this regard with the difference being it does provide different guarantees like a defined init system (the docker daemon). The downside is that docker still needs to be configured on the host and your "package" can't necessarily define all the constraints such as what networking to configure or volumes to mount. These are different problems than RPMs of course, but the point being is that in either case, you get similar packaging benefits, with different runtime information needed. 
&gt; If vendoring is the future of dependency management in Go, what is the point of copying vendor source codes into $GOROOT/src when go getting? As I said vendoring was introduced in Go 1.5. There's always the issue of backwards compatibility. &gt; I don't see a need for $GOPATH or even Go workspaces if projects are supposed to be self-contained, with vendoring taking care of dependency storage. Convention over configuration has many advantages. The majority of the awesome Go tooling that we have today is built around the idea of GOPATH (except some notable exceptions like gb) and without it, some of them would be impossible to exist. Personally I find it a breeze to work with GOPATH but I digress. It's possible that it will be removed in the future but for now it is part of the ecosystem and you need to learn to work with it. &gt; I think from now on I'll be sticking with virtualgo. Suit yourself. Don't forget to also take a look at gb and [dep](https://github.com/golang/dep).
Thanks again for replying and expanding on your previous comment. This policy makes sense to me and I could work with it. I've worked remotely most of my career and always have an eye out for good remote-friendly companies. I'm glad I decided to ask.
Fantastic @eikenberry. Feel free to email me direct. 
Firstly, thank you for your service. We’d love to consider our bravest men and women for positions at Datadog!
Simple and clear, thanks.
&gt; What are you talking about? In C++, stuff like multiple inheritance, generics or exceptions were added after some 10 years of the language's existence. Yeah, so? Those are just the "big guns". Smaller features and language changes happen much more often. Look at Go though. Barely any language changes since Go 1.0. &gt; (C++14 was only a minor update not featuring anything "big") If you would allow me to be humorous for a moment, I wouldn't be surprised at all if C++14's feature-addition-diet was inspired by Go's popularity considering the time period. It also reminds me of that relatively recent talk of Stroustrup where he kept repeating that he wants to see compilation speed increases of x10 magnitude and better "import management". Considering those two things are so core to Go, I really couldn't help but chuckle! :) &gt; Java 7 came 5 years after Java 6 and wasn't a very big change to the language anyway, larger changes were postponed till Java 8 in 2014, that's 8 years after Java 6. Generics in Java were added in 2004, that is, after 8 years of its existence. Yeah sure I get it. In fact, it's entirely possible Go will also get generics at some point. But one of the biggest factors in Go's success is keeping the number of features that are added in the language at the bare minimum (as showcased by the talk). Java and most other successful languages have had many more features added at their first years of their life, comparatively. &gt; You're talking like other languages add features willy nilly every other friday, but that's not true at all. Oh but it is true. Surely not every other Friday but almost every major release includes new features and language changes. Then again look at Go. :) &gt; Let's revisit that statement after another at least 6 years of Go. Sure. In the end, no one can predict the future. For all I know the Go team might get burnt out and leave the language to people who have never understood Go's core ideas and who could start bloating the language with new features. Then we will have the "bloat without distinction" effect mentioned in the talk. In any case, if you enjoyed Rob Pike's talk on Go's simplicity, I can also recommend you Dave Cheney's [related talk](https://www.youtube.com/watch?v=_6AYkV2mz80) ([text version](https://dave.cheney.net/tag/gophercon-india)).
What about it, it's very easy to read what it's doing. If your argument is that it is verbose or hard to read then 1) you can come up with more verbose, more complex examples in every language (including Go) to prove just as little of a point and 2) you should work with Go more if this is hard for you to read. 
Not just in the works, but in beta. My AM was able to get this enabled for us, but it's still a little rough.
There is a dark theme already in beta. Ask your Account Manager to get it enabled on your account.
You guys are the best, hope you find someone awesome!
Yes. This is true :)
&gt; I'm glad to be switching back to JS and cut the fat U wot m8?
&gt; open vacation policy Do you require people to take a minimum amount per year? Or is it one of those "everyone takes as much as they need but somehow people need very little because we are happy little loving family" scams? 
I’ve been pushing for the former but it’s definitely not the latter. I just took two weeks and got back from Vietnam on Saturday. The CTO thanked me saying that I am doing the form a great service by taking time off which will allow me to step away from my work and come back refreshed. So anecdotally I can say we want people to take time to unwind — it makes for a better employee. 
Ok thanks for your response.
It's nowhere near the level of JS though. (Not that it necessarily should be, as there is a real cost to documenting things that means less time spent improving the implementations, but it is what it is)
Thanks for you suggestion, this project just begin starting, and lack of some middleware/Components, such as filter duplicate URLs, HTTP link depth tracking,etc... Before start distributed web crawler(if i'm still want), need a lot of time to made this framework more availability and extensible.
thanks lot, i am now able to continue my journey towards mastering golang
Less than a minute !! Didn't realize stripping down the config had such a drastic effect. Anyways, those are some mad debugging skills you have. Thanks for the post. I enjoyed reading it very much.
It's also recommended to have an `ExecStop` stanza.
Is there a reason these bridge types aren’t built into Go?
I second this recommendation. I used it for a production service that ran on ~150 Windows servers at my last job and it worked well.
Or you could be upfront with your salary range instead of wasting people's time...
Should have been &gt; New Realize v2.0 - The #1^\* Golang Task Runner &gt; &gt; ^\* No, really!
Downvoted: 1. No direct link to sources in the post 1. `mc` name is taken with quite [popular product](https://en.lmgtfy.com/?q=mc+midnight+commander) 2. [This](https://github.com/minio/minio/tree/master/browser) shows your half-hearted approach. Why Node.JS crap if could easily do this in Go?
thanks very much. and congrats on the release 2017.3
&gt; I wouldn't be surprised at all if C++14's feature-addition-diet was inspired by Go's popularity considering the time period. LOL sure. I can't even tell if you're serious any more. If you really wanted to know, you'd find out that C++14 was planned as a small bugfix-mostly release way ahead and basically was just a followup to C++11. Vast majority of the developement of C++11 and 14 was done before Go even existed. Compilation time has been an issue for decades now and various strategies have been used before Go existed as well. But sure, if if it makes you feel better, keeping telling yourself Go is the ultimate source of wisdom here :D &gt; any case, if you enjoyed Rob Pike's talk on Go's simplicity I certainly did not. I mean there are some good points and it would be fine if it weren't for those nonsensical attacks against other languages. I think it would be better to promote a language by showing what it can do rather than by trashing others. Besides, I still think the point of Go are goroutines and the simplicity jibber-jabber is just PR talk and politics to get people to switch. 
Expired SSL cert, do people read these?
Totally off topic, but are you related to emacs or did you just get really lucky with your username? 
[removed]
There's a function for this now: https://golang.org/pkg/net/#IP.Equal
`Emacs24` was available, so I took it. No relation besides usage.
you should use supervisor. there is a sample : https://beego.me/docs/deploy/supervisor.md
Why do you run your program in a bash shell?
Thanks for the sentiment! We are growing like crazy and I’ve aged quite a bit as we’ve gone from under 100 to over 500 in less than 2 years, with amazing talent nonetheless. :)
Appreciated. Regarding the comment about having to compile it, I thought as much, but I was hoping there might be a way to go through a partial compile. Though, I imagine that heavily depends how the compiler is run. Eg, if the binary is built incrementally then there's no way I can stop at a certain "phase" of the binary, for improved performance, I would have to run the whole thing. Conversely if the compiler runs through the entire AST and works in phases, hypothetically a feature could exist to identify problems but not move onto the next compiler stage. Purely imaginary of course, but I'm just making a fake example. As an aside, do you know of a way to compile a package? Eg, if I'm working on a library, I won't even have a binary `main` package to compile, but obviously I'd still like to confirm the code is buildable. Thoughts? `go test` is the only thing I've thought of so far.
&gt; There is no way around this, what are you actually trying to achieve? To verify correctness of code. Eg, I want my editor to identify a line of something that is broken. I already check syntax with `goimports`, but I want to identify any non-syntax problems as well - eg, ones that `go build` would identify. &gt; As a last resort you could run go build without any ssa passes by passing -N via gcflags which should disable the lions share of the processing time. I'll definitely try this, thank you! Sidenote, do you have any idea if it's possible to build a package, with no main? Again, I'm purely trying to check code correctness, so I run into an issue where I can't `go build` a library without a main. `go test` is the only option I'm aware of here, though I'm still looking for a reliable way to ensure no tests are actually run. Atm I plan to just filter based on a fake test name.
Having read a little bit of the stdlib's source code, I must say its readability is pretty poor. Naming included.
&gt; As an aside, do you know of a way to compile a package? You can actually run `go build` in the non-main package just fine, and it compiles and yields errors, etc. I believe it puts stuff in $GOPATH/pkg/... .
This looks great. If it doesn't take anything from the rest of the book, I don't think it's a bad idea to have the UI chapter as well. Would love to get my hands on this when it gets published!
MongoDB :-(
This. Simplicity is ultimately a pretty squishy word for a technical discussion, meaning different things in different contexts and from different perspectives. The sense of simplicity that's most important to me, and is what I'd mainly be referring to when I call go "simple," is that it is straightforward. You can look at a line of go, and you pretty much know what it does. There's fairly little magic going on. 
See: https://www.tedunangst.com/flak/post/moving-to-https and https://www.tedunangst.com/flak/post/live-off-the-chain &gt; aCuriously, some browsers react to the addition of encryption to a website by issuing a security warning. Yesterday, reading this page in plaintext was perfectly fine, but today, add some AES to the mix, and it’s a terrible menace, unfit for even casual viewing. But fill out the right forms and ask the right people and we can fix that, right? &gt; &gt; I find it strange, to say the least, that I am required to request permission from the authorities to make a secure web site. When I first created flak, there was very little paperwork. I started a server, and that was that. Do we really want an internet where the use of encryption requires authorization? He's not wrong IMHO.
Looks very nice. Except for MongoDB. If I were you, I would write 2 books: this one without chapter 7 &amp; replacing mongo with anything else (sqlite maybe?), and another one front-end oriented. Just my 2 cents. Either way, keep it up! 
Good to see code with comments.
It has absolutely nothing to do with HTML forms. the HTTP spec describes an easy way to do file upload : https://astaxie.gitbooks.io/build-web-application-with-golang/content/en/04.5.html You don't need a form to build the body payload. Any http client in any language can upload binary files to an http server.
Thank you. That's the issue with the UI chapter, I feel it is going to be huge, so I either will do a quick one or not at all. You can keep in the loop via my [Twitter account](https://twitter.com/dominicstpierre)
haha yeah, this is generally the response, hmm. I don't want to get too verbose in the "data access" package. But I might use a RDBMS. Thanks for your feedback :)
It is funny because I'm aligned with what you've said and had considered it at first, but removing the entire chapter felt incomplete. What's up with MongoDB and the Go community :)? But I hear you, so far it is a recurring feeling. I'm using MongoDB at Roadmap and must say that so far it is not bad for this use case. Thank you for the feedback.
Code optimization techniques? Go tracer... etc I am usually interested in such kind of tools. 
Whoa, not sure where I picked up my bad logic here, thanks! This vastly simplifies my concerns of accidentally running logic with `go test`.
Agreed! Some packages are indeed really old, but others are beautiful pieces of code. Have you read context?
He's not wrong, but there is a logic to it, too. Picture two scenarios: Stranger #1 shows up and says his name's Bob. He could be lying but you have no reason to doubt him. Stranger #2 shows up and presents an obviously-fake ID that says his name is Steve. You strongly suspect his name may not really be Steve. Certificates are necessary for encryption, but they're also intended as positive identification - self-issued certs are fine for the former, but completely useless for the latter, and so, browsers complain.
&gt; What's up with MongoDB and the Go community :)? I don't think it has to do with the Go community in particular. In fact I know many gophers who love Mongo especially since we've had a very good driver for a long time now. I think it's actually more of a [general issue](http://www.sarahmei.com/blog/2013/11/11/why-you-should-never-use-mongodb/).
I don't remember now. But there was a legit reason at the time... and I've copied &amp; pasted that unit file ever since.
If someone has a link to a really well done unit file for a Go web service, this would be a good place to share it!
I prefer this approach too. 
Vim and VS Code
&gt; Actually, in case of C++ the default is the non-overriding one and you need a keyword (virtual) to make a method overridable. Maybe Java made a mistake by not following the same approach. Java and Python are in the same virtual-by-default bucket if I recall correctly. Java isn't a lone exception. Besides, knowing the type at the callsite isn't sufficient; you need to know whether or not the method is virtual just to reason about the dispatch, and the dispatch in Go is "the interface implementation", not "whichever the most recent ancestor is that overrides the method". IDEs can alleviate this burden, but again we're solving an unnecessary problem by throwing more complexity at it. &gt; Anyway, a keyword or two is hardly "complexity" to me, but this seems to be where the Go community consistently disagrees with me, so I guess agree to disagree is appropriate here... It's not a keyword, it's a suite of keywords *and their interactions with each other and existing features*. Extends, protected, virtual, sealed, etc are all unnecessary concepts that exist solely to support inheritance, which delivers no value over Go's primitives. An experienced programmer may be able to avoid improper inheritance, but he still has to deal with the ecosystem and less experienced colleagues. Generally I prefer to avoid unnecessary problems. &gt; I think you can do that in C++ with some hackery. But honestly it seems like a bad idea to me anyway. It's really strange how people can be uneasy with virtual method overriding but be ok with this sort of thing. This isn't strange at all; it's very useful to be able to construct things with polymorphic constituents. For example, a `type Logger struct { Output io.Writer }` lets you build a logger from a file, socket, buffer, etc--anything that looks like a byte stream. If you were to use inheritance, you would have a logger that *is also* a byte stream, and has all of the methods of a file (or whatever byte-stream implementation you choose to inherit from), even though you only care about the logger methods. You also can't create Loggers backed by other byte-stream implementations without writing out those classes (`class SocketLogger extends Socket`, `class BufferLogger extends Buffer`, etc). &gt; I guess my takeaway from this whole discussion is that my views are simply too incompatible with most of the Go community (which doesn't mean I won't code in Go, I guess I'll just have a different reason to use it). I'm not sure how important philosophical compatibility is, but if language-level support for inheritance is a requirement, then Go simply won't meet your requirements. My only point is that inheritance as a language-level feature is strictly (and I believe objectively) inferior to composition and interfaces; there are no advantages to inheritance, only pitfalls.
Yeah, I appreciate that the entire concept isn't useless; but I have the impression that a lot of the crypto/security people often only think about protecting your bank details and such, and forget about regular folks using encryption in a more "casual" manner. Schneier's *Applied Cryptography* starts with "there are two sorts of encryption: those that will protect your files from your kid sister and that will protect your files from major governments". The "protect-from-government" kind of encryption *is* very important in many cases, but it often adds a number of hurdles and for many purposes "kid-sister-protection" is "good enough". Adding https to your personal weblog is a good example of that. In addition, "better encryption" does not equal "better security". Giving people unjustified certificate warnings will just train people to click through warnings. One of the best examples I've seen of this was a few years ago when I did some contract work for a certain large well-known company. All the sales rep's laptops were protected by no less than four passwords: one for the disk encryption, one for the BIOS startup, and one Windows login, and one to access the VPN. All passwords had strict security requirements (capitals, symbols, length, etc), had to be all different, AND had to be changed every 4 months. Without a single exception, every laptop I've seen at that company had a post-it with all four passwords written down.
Oh, I agree for the most part. Thing is, certifying who you're talking to really *is* a vital part of secure communications. All the encryption in the world is useless if the site you're communicating with isn't trustworthy, or isn't who you think they are, and for a browser, identifying when it does or doesn't really matter isn't a trivial problem. Also, the bar for getting a certification from a recognized certification authority isn't particularly high - it's not like it acts as a barrier except to those who object in principle because the word "authority" is a trigger-word for them.
When is the target release date of the book ?
Great read, thanks for taking the time to make a write up !
Does it even make sense to use mongodb with Go, wouldn't it become some interface{} hell?
&gt; Java and Python are in the same virtual-by-default bucket if I recall correctly. That's right, unfortunately. &gt; Besides, knowing the type at the callsite isn't sufficient; you need to know whether or not the method is virtual just to reason about the dispatch The idea is that you shouldn't need to. As long as the particular method fulfills the contract specified by it's interface and by the interface of its class, it shouldn't matter where exactly it is dispatched. I think all the counter-inheritance examples you provide are examples of a bad design. In the example in the comments above, one of the methods depends on another one that is virtual, isn't private and it isn't intended to be overriden. That's a fairly obvious recipee for problems. The method should either be private or at the very least not virtual / marked final / whatever is appropriate in your language. Basically it's an encapsulation violation, which is problematic with or without inheritance. In Go, if you make public a struct field on whose consistency methods of that struct depend, then you'll run into similar problems when someone messes with the field from the outside of the struct. You could argue that with inheritance encapsulation problems get worse, which I'd probably agree with. &gt; This isn't strange at all; it's very useful to be able to construct things with polymorphic constituents. I'm not sure what you originaly meant, however, the thing I am concerned by is when the identity/state of the composed object is important. Consider something like this: type LockedSomething struct { Lock, something Something } Now if someone goes and swaps the Lock instance underneath the struct, Bad Things™ will probably start happening. &gt; If you were to use inheritance, you would have a logger that is also a byte stream, and has all of the methods of a file That sounds like a really bad design. Inheritance is inappropriate for such a usecase. &gt; I'm not sure how important philosophical compatibility is, but if language-level support for inheritance is a requirement, then Go simply won't meet your requirements. It is not a requirement for me, in fact, as I told you already, I prefer the separation like Rust or Go have (sans my complaints about embedding ambiguity). Besides, the whole "Composition over inheritance" idea isn't really anything new. I know qutie at least a couple of Java and C++ people who were very anti-inheritance and mandated always using composition + interfaces long before Go came to be. &gt; My only point is that inheritance as a language-level feature is strictly (and I believe objectively) inferior to composition and interfaces; there are no advantages to inheritance, only pitfalls. That seems to me like a pretty black-and-white opinion. While I typically also prefer to not use inheritance, it makes some specific use cases much easier. A typical example are things that are composed into rich hierarchies, such as richly structured documents or data formats or, typically, GUI elements. You can of course do without inheritance in such cases too (that's what languages like Go or Rust are doing), but it's IMO a PITA. 
Glanced over, actually. Looks pretty good indeed. I think I stuck with first impression of reading `net/http` though
The go playground user experience is horrible IMHO. No syntax highlighting, no auto lint/vet/import/format, no autocomplete. It's good to share examples but i would bever use it for actual development. I just found it odd with a shared workspace. It's just something i have never seen before. Different apps could have different versions of dependencies. The whole thing just feels messy and fragile. I like the direction go is going though(tp my understanding). Default go path for system wide tools like linting tools. All other dependencies are installed in the apps vendor dir using dep. Lock-files for dependencies. These apps doesnt have to live in the workspace. I hate to have my own projects mixed in with their dependencies... I hope to not use a shared workspace anymore when dep is finally released. :)
It certainly wouldn't make too much sense conceptually, IMHO. Go is all about safety and being "boring". MongoDB is the exact opposite.
This is what I use - [Unit] Description=This is the web backend app After=network.target [Service] EnvironmentFile=/opt/webapp/conf.prod ExecStart=/bin/sh -c '/opt/webapp/bin/webapp 2&gt;&amp;1 | funnel' ExecStop=/usr/bin/pkill -TERM -f "/opt/webapp/bin/webapp" LimitNOFILE=65536 Restart=on-failure RestartForceExitStatus=SIGPIPE KillMode=control-group [Install] WantedBy=multi-user.target I am in no way an expert on this. So feedback / criticism is most welcome. :)
What is the content-type of the request body? If it is audio/*, then just straight up read from `http.Request`'s `Body` field. If it is something else, like, say, multipart/form-data, then you will have to extract it as appropriate (see the multipart package in the case of multipart/form-data).
&gt; As for UFCS, I refer to the term rather loosely, after all, it works somewhat differently in each language. You mentioned the impl block in Rust, but that is not the only syntactic difference between a standalone function and a method in Rust. Interesting, but yes. I have so far taken the claim that Rust implements UFCS at face value, but it seems that it doesn't - and that seems to have been the source of most of the talking-past-each-other here. The definition given by the Wikipedia is: &gt; Uniform Function Call Syntax (UFCS) […] is a programming language feature […] that allows **any function to be called using the syntax for method calls** (as in object-oriented programming) […] This pretty clearly says, that UFCS desugars `a.f(b)` into `f(a, b)` for *any function* - which agrees with my understanding of UFCS. Both the examples for D and Nim show exactly that: Free functions are defined and then called with method-syntax on the first parameter. The [C++ proposal](https://isocpp.org/files/papers/N4165.pdf) for UFCS also understands it this way: "Extend the member call syntax to fall back to find nonmembers". Rust, on the other hand, allows you to only go into the other direction; write `f(a, b)` instead of `a.f(b)`. And it calls that UFCS - but it seems to be pretty lonely in that regard. In either case: UFCS seems to not be the term you are looking for. Because either UFCS is what Rust refers to (which you seem to be happy with), which Go has too. Or UFCS is what *I* think it means, in which case it would require significant semantic changes to the language in how scoping, lookup, overloading, interfaces… work. So, to be clear: Rust allows you to define *functions* (`fn foo()` as a top-level declaration) and *methods* (`fn foo(&amp;self)` in an `impl` block) and the two are different concepts (only methods implement traits). It then also allows you to call *methods* using *function syntax*, but not the other way around. Which is exactly what Go has: Go allows you to define functions (top-level `func`-declarations without a receiver) and methods (top-level `func`-declarations with a receiver) and the two are different concepts (only methods implement interfaces). It then also allows you to call methods using function syntax, but not the other way around. And yes - between Rust and Go, there is indeed just a syntactical difference in this regard. This is what I was alluding to [in the last paragraph here](https://www.reddit.com/r/golang/comments/7hi7ai/newcomers_opinion_go_is_not_very_simple/dqsncyb/). Being dissatisfied with the method-syntax is fair enough, but honestly, that's not a technical argument and IMO has not a lot to do with simplicity - it's just an aesthetic opinion.
So, I'm quite new to Go, rereading [*The Go Programming Language*](http://www.gopl.io/) to get a better feeling of the basics, but feel you are writing a book that I'm going to enjoy in due time. :) This might be one of those "duh! it was assumed!" questions, but are you going to release the source code along with the book?
There is one here https://github.com/glycerine/go-capnproto/ and it seems to have been generated directly from some capnproto tools
Yeah, I liked context so much that I made a video about the implementation I think you might enjoy it https://youtu.be/8M90t0KvEDY
They're trying to grow so fast they don't hire for specific roles. They just hire people and figure it out later. Source: interviewed there. 
Might be a little unrelated to projects, but something like advanced manipulation of structs would be cool
Love the sections (except I'd also throw my hat in to say use a relational database). Only thing I'd like to know more about, which would be filtered throughout the book is best debugging tips and tricks you may have. Go's pretty awesome about tracing but if you've come across any particular helpful tricks that's always nice for the reader. Looking forward to it's release!
There are countless articles that explain why you should never, under any circumstances, use MongoDB. The golang community is understating this, if anything, compared to most communities. Use anything and everything else before turning to Mongo.
MongoDB, for when you want an *exciting* database. Maybe you've been sleeping too well at night... well, sleep no more! Introducing Mongo!
You still have struct to define your data, this is an example of production code I have `similar. var account Accounts where := bson.M{fieldEmail: email} if err := db.C(collectionAccounts).Find(where).One(&amp;account); err != nil { } I'm thinking of having the data package targeting sqlite and Mongo maybe that could be an idea to have a straight comparison for the reader of the book. Not sure yet.
I'm sorry, I don't have an ETA at the moment. Ideally sooner than later. I will have a more valid ETA in the following week.
Thank you that's a good suggestion, it could be a good chapter replacing the UI one if I remove that one.
Yes thanks for the suggestion, that could be a good one to replace the UI chapter.
Didn't work out for you? 
What kinds of struct operations fall into that category?
I worked with mongodb for 3.5 years on Juju. It's not interface{}. It's basically like JSON serialization.... structs in and structs out. It lowers the barrier of entry, but in my experience, most people that use it really should just use a relational database like postgres, because the lack of relational functionality really hurts the long term stability and velocity of a project. Most projects store highly structured data (see the part about "structs" above)... that's what relational databases are for.
&gt; But for a completely new user. Someone that **just wants to try out go.** &gt; The go playground user experience is horrible IMHO. No syntax highlighting, no auto lint/vet/import/format, no autocomplete. It's good to share examples but i would bever use it for actual development. I spoke strictly in the context of a new user that just wants to try the language.
Some thoughts: 1) I echo the Mongo DB comments - use Postgres 2) SPA's are a little unique and I don't see how Go fits except to serve the assets. I'd use Vue or React and also GraphQL if I was starting from scratch today for an SPA. 3) If I was starting today I would have full tracing throughout my apps. Check out the HotRod example in Jaeger! 4) Auth is a minefield, if you can do it justice it would be very beneficial. Users auth with ID/Pswd, or OAuth (use FB and Google) and app uses JWT(?). I like JWT but refreshing them is awkward and canceling them is hard. Orthogonal: I am a "mini-angel" investor. Did your startups succeed? If so, why? If not, why not? Cheers, Dan
&gt; *If you would allow me to be humorous for a moment* &gt; LOL sure. I can't even tell if you're serious any more. :-/ &gt; If you really wanted to know, you'd find out No thanks, I really couldn't care less about C++. :) &gt; I certainly did not. Ok then!
This is a beginner-level post on reading, processing, and writing CSV data. I plan to make a workplace automation course with more content like this one. I figure this could help beginners to practice what they learned, as well as absolute newcomers to get first impressions of Go in a practical context.
It might be interesting to include a section about Redis (or similar software).
The reason is log forwarding (2&gt;&amp;1).
https://github.com/golang/go/blob/master/src/builtin/builtin.go#L255
The stdlib [net/http has ParseMultiPartForm()](https://golang.org/pkg/net/http/#Request.ParseMultipartForm) which you can call with your upload file max size and then read the file contents with a call to request.FormValue. You can support PUT requests. If you need to test an upload with that it should work with curl, something like this: curl -s --upload-file test https://filedrop.si/file/drop?name=test.pdf As you see, you'd have to specify the filename as an URL, a query string parameter, or pass it with headers. As @skidooer said, you'd use the requests Body field on the server (write it to a file with io.Copy or use ioutil.ReadAll and then store it somewhere else).
So a while back on here I was helped with [this json transformation](https://gist.github.com/arehmandev/87a63bf5964ce4a8833294fb831c6373) - it would be nice to see more solutions to real world issues like this
This code is reading from `crypto/rand` but not handling errors. That's not a good idea.
Maybe use a "Repository" interface and put the data details behind that? You can discuss the pro's and con's of each datastore specifically, without it influencing the whole book as the "business logic" works with the interface.
Yesssss! I've been looking for a good tutorial on manipulating csv data for a while now. Thanks!
Don't rewrite the schema parser! You really don't want to do that: it's more complicated than you think and you'll spend months getting it right. It's really not necessary to have the parser rewritten in every language; it's better if everyone reuses the official one. In particular, if you run `capnp compile -o- myschema.capnp &gt; bundle.bin`, you get a file called `bundle.bin` which contains a binary descriptor bundle describing your schemas, then distribute that bundle to whatever runtime process needs it. The bundle is in Cap'n Proto format as defined in `schema.capnp` (specifically, it's a `CodeGeneratorRequest`), so you can load it up into your Go program using one of the existing Go implementations.
Heck ya, automating spreadsheets is how I got started in coding years ago, except back then it was following along a Python book here: https://automatetheboringstuff.com 
I use https://github.com/genereese/togo to create RPMs. Works with pretty much anything.
I like the "Kind" value instead of using interfaces like type NotFound interface { NotFound() bool } The annoying thing about the above, which Dave Cheney proposed in his "check for behavior" post.... is that every single one needs its own custom written function. You need IsNotFound, you need IsNotValid, etc etc etc With this method you only need one function to check any Kind. It's just `errors.Is(foo.NotValid, err)` yes, it ties everything into your custom errors package, but like Rob said, this is a project-specific errors package, so that's going to happen anyway, and that's ok. The only drawback is if you ever want an error to be two Kinds, like IsTemporary and IsNotFound. You could probably even hack that to provide a Kind that will AND two other kinds together... but not sure that's worth it for the few times that might come up. Really interesting blog post... neat to see how one of the creators of the language is dealign with errors in a large public project.
That's a great article! I actually wrote a csvutil package that helps with decoding and encoding structs. I wrote my own version of your spreadsheet using it. Maybe someone will find it useful. The main.go that would work with the csv file from your article: https://gist.github.com/jszwec/6f1407debef484d598fdbca80e964aec 
I have been using this too, and it works great. golang.org/x/sys/windows/svc
Is it year 2000 again? Use the tools like python pandas to do that. Also fix the misleading title - use CSV instead of spreadsheet.
you're right, `bufio.Scanner` is much better. [Here](https://github.com/steven-ferrer/gonsole/commit/9c8e00b13d8945f82a4a5ac300d39aa45cc494b9) i made the change. 
great stuff, I'll be your reader! one question, do you use Docker anywhere in your process? For example, building SPA must require lots of dependencies, which I would bundle in a docker image. The same applies to Mongo, spinning up MongoDB within a container seems a way easier to me. Unless, your custom built CI does the same))
Which raises the question, should gophers use this approach as a blueprint for their own projects? While Rob Pike points out that there cannot be a one-size-fits-all approach, at least some of the ideas in `upspin.io/errors` seem to be independent of any specific project requirements.
Indeed, the idea of workplace automation is not new. I just want to port this topic to Go, as I feel there could be a decent interest in Go-specific solutions.
`map[string]interface{}` might be a better choice if you're able to do so. It should let you unmarshal the first level of your JSON content and then you can do some type assertions on each of the interfaces. Here's an example of how you can go along and write a custom Marshaler and Unmarshaler: https://play.golang.org/p/7nk5ZEbVLw
Thanks for sharing this (and for creating cvsutil of course)! I intentionally focused on using the standard lib only, but of course, a specifically tailored package might scale better for real-world applications. I will mention your package in the upcoming course lecture.
Thanks for the example. Will look into it and let you know how it goes.
Thanks! You also might want to have a look at [cvsutil](https://github.com/jszwec/csvutil) mentioned in another comment thread here. 
Also check out raw message https://golang.org/pkg/encoding/json/#RawMessage
&gt; The only drawback is if you ever want an error to be two Kinds, like IsTemporary and IsNotFound. You could probably even hack that to provide a Kind that will AND two other kinds together... but not sure that's worth it for the few times that might come up. No hacking necessary: ```go type Kind uint const ( LostConn Kind = 1 &lt;&lt; iota Timeout ) type Error struct { Kind Kind } func E(args ...interface{}) error { var err Error for _, a := range(args) { switch a := a.(type) { case Kind: err.Kind |= a } } return err } func Is(err error, kind Kind) bool { e, ok := err.(Error) if !ok { return false } return e.Kind &amp; kind != 0 } ``` Then just define a `String()` method for `Kind` that's called from `Error.Error()` and returns something that makes sense for each possible value.
I find the title a bit misleading. It's about CSV, and that has nothing to do with spreadsheets. "A spreadsheet is an interactive computer application for organization, analysis and storage of data in tabular form" Spreadsheet data is not the data after export to some external format, like CSV, XML, or whatever format. But you apologize in the end. You better could have started this explanation in the beginning, so readers can know upfront what to expect. The piece you wrote is good material for beginners, so please continue to write, but watch the order of the paragraphs ;-)
Would have been nice if the website was fully tested too :-) "502 Bad Gateway"
`Next*` seems redundant because every method of Reader attempts to return the *next* value anyway. Unless you add other methods I'd keep it that short.
True, CSV data is no the same as a spreadsheet, but CSV is de facto a "lingua franca" for spreadsheet data. Whether Excel, Calc, or Numbers, they all can write to and read from CSV, which makes it a natural intermedate data format between the spreadsheet apps and Go code. The point of the article is to process data that originally resides within a spreadsheet application. How would you approach this task?
I would start with an introduction paragraph that tells the reader about the choosen path. (there is nothing wrong with the path, only the explanation is at the end) When I write pages, I always start with a short explanation in what to expect in the information, like: for which audience it is written for, and perhaps in this case why the reader will find information about CSV. At that point a reader can decide after reader the first paragraph that he/she stops there, or... is interested in the whole message. Since the readers time is valuable, you want to tease them into reading more, but you also want to respect their time. So I was reading, and hoping for some interesting stuf to appear, but... yeah, you catch my drift ;-) Nevertheless, do write more :-)
I'd recommend just digging deeper to understand how things work at the lower level — at the HTTP protocol itself. When a HTTP client performs an HTTP POST request, it sends: 1. The request line — that `PATH /path HTTP/1.1` text which identifies the request's method, the location of the endpoint to perform the request on and the protocol's version. 2. The header — a set of key+value fields with meta information about the request. 3. The body, which is the request's payload. Now when the HTTP server reads a client's request, it reads the fields of the header to figure out *what to expect* in the payload. There exists several crucial fields to get that information from, with the `Content-Type` being the most important as it identifies, well, the type of the payload contents. The `Content-Type` field contains one of the so-called [media types](https://en.wikipedia.org/wiki/Media_type) — things like `application/json`, `text/html` etc. OK, so let's move on to how in works. In the code of a particular HTTP requst handler in your server you roll like this: 1. Get the content type of the client's request. 1. Determine where you know whether you know how to handle it. 1. If you don't, reject it with [HTTP status code 415](https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.4.16). 1. If it's okay, read the requests payload and *process* it in a way appropriate for its type. Now let's move on to the client's side of things. Technically, as you have seen, it's absolutely possible to send *any* raw data as a payload of an HTTP request. So there's nothing *in the protocol* which would not allow you to POST audio data "as is". Say, `curl` has no problem doing such a request: a call $ curl -X POST \ --data-binary=@foo.mp3 \ -H 'Content-Type: audio/mpeg' \ http://server:port/endpoint would read the data from the file `foo.mp3` and POST it "as is" to the specified endpoint of the specified HTTP server while telling it the type of the data sent is [`audio/mpeg`](https://stackoverflow.com/q/10688588/720999). And now we have web browsers. That's where this becomes more complicated. In the good ol' days the web was composed of static files and plain CGI applications, the AJAX (or XHRs, if you want) wasn't invented yet, so the only way to "upload" something from the browser was indeed providing an HTML `&lt;form&gt;` in an HTML page. When a browser POSTs an HTML form, it *invariably* encodes its contents in a special structured format which has its dedicated media type `multipart/form-data`. "Multipart" here is specifically because a single form may have an arbitrary number of "inputs", and their contents must be all POSTed at once. In the present days, when SPAs reign the web domain, HTML forms are used very sparingly, and most of the communication with the servers is done using XHRs. But the relevant support for POSTing *arbitrary binary data* was suboptimal (if existing at all) for too long since XHRs were invented with passing XML back and forth, and then they were repurposed to carry JSON. I'm not a webdev so I can't really say for today's hot HTML5-ish APIs expected to be provided by the browsers for JavaScript code they execute — I heard there now exist ways to effectively wield binary data on the client side but can't say much on this. All in all, there are two points worth reiterating: - As long as the HTTP server is concerned, it's absolutely possible POST to it whatever you want, in any format. It's just needed to be documented for your HTTP API. - As long as *client support* is concerned, there's something to research. - Say, if you need to support olden browsers, you might need to be able to handle POSTs with `multipart/form-data` and document what exactly field must be used to contain the file's data when this method is used. - If you control the client side (say, you will be writing the client code, or you know the cliens will not be web browsers) then just expect plain audio data and document which media type(s) your endpoint supports. - It's also possible to support both kinds — either on the same endpoint — by switching processing code paths based on the `Content-Type` header field supplied by the client, — or on different endpoints. Hope this helps. I recommend deepening your knowledge of the underlying technologies as this immensely helps when solving problems like this.
**Media type** A media type (also MIME type and content type) is a two-part identifier for file formats and format contents transmitted on the Internet. The Internet Assigned Numbers Authority (IANA) is the official authority for the standardization and publication of these classifications. Media types were originally defined in Request for Comments 2045 in November 1996 as a part of MIME (Multipurpose Internet Mail Extensions) specification, for denoting type of email message content and attachments; hence the name MIME type. Media types are also used by other internet protocols such as HTTP and document file formats such as HTML, for similar purpose. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I kinda hate upspin error handling, I have to say. It is rather of unfriendly to the user: client.Lookup: ann@example.com/file: item does not exist: dir/remote("upspin.example.net:443").Lookup: dir/server.Lookup That's… a bunch of internal debugging info I shouldn't have to care about, as a user. To read this message correctly, I have to know how upspin works, what a "Lookup" is and why there are sever levels of lookup. The actual error is hard to make out and formatted weirdly ("ann@example.com/file: item does not exist"). This error message should actually read file ann@example.com/file does not exist If I'm the administrator of an upspin server (which I am, I do run an instance myself) and know the file *should* exist, I can always add a `-v` to debug the problem and figure out where things go wrong. At that point, you are dealing with someone who said they know enough about how the things work, so, sure, give me *all the debugging*. Which is why I dislike these "adding context info to errors in $way" packages and articles for error handling. They promote dumping this context on the user and consider the error handled. But software should be made for humans and not every human will (or wants to, or should have to) know how the software works internally, to be able to decipher an error message. Providing good error messages requires thought and work and code.
TCP flow control is quite primitive but effective. Basically the bottleneck propagates the available bandwidth back to the network by dropping packets which then need to be retransmitted. But your code and neither the Go runtime are the agents that do the dropping; it is your operating system. Between your network interface card and your `io.Reader` are a number of buffers that need to fill up before your NIC cannot accept more packets. In other words: If you do not control the buffer that drops packets, it is hard to shape traffic precisely. You need to shift the bottleneck from one buffer (NIC) to another (io.Reader), effectively remote controlling one with the other. Shameless plug: You could use my [github.com/wjkohnen/bwio](https://github.com/wjkohnen/bwio/) package, which is a wrapper for the `io.Reader` and `io.Writer` interfaces. In your example you would wrap the `res.Body` reader and then copy from that.
&gt; No thanks, I really couldn't care less about C++. :) You don't care about the other languages, but you're sure they're doing it all wrong... Btw. I just found out language changes in Go aren't really that infrequent: [1.9](https://golang.org/doc/go1.9#language), [1.8](https://golang.org/doc/go1.9#language), ... that's a language change _twice a year_. There's even a compat breaking change in [1.2](https://golang.org/doc/go1.2#language). Hipocrisy? 
If the map[interface{}]interface{} is marshaled and unmarshalled to/from JSON, then you can safely replace it with map[string]interface{} and remove key type assertions.
&gt; Rust, on the other hand, allows you to only go into the other direction; write `f(a, b)` instead of `a.f(b)`. And it calls that UFCS - but it seems to be pretty lonely in that regard. Yes. Rust implements UFCS only in this 'one-way' manner, which you could say is strictly speaking not UFCS, and mostly uses it to disambiguate trait implementations or use methods as regular functions in FFI et al. The main reason Rust doesn't have function overloading (and, by extension, _true_ UFCS) is the type inferrence algorithm which wouldn't work well with overloading. &gt; Or UFCS is what I think it means, in which case it would require significant semantic changes to the language in how scoping, lookup, overloading, interfaces… work. Well yeah, it would require quite a lot of changes, it's absolutely unrealistic to do that in Go at this point in time. However I'm not entirely convinced that if done from the very start (rather than changing the behaviour now) it would be more complex than the current solution. The scoping rules of Go as of now aren't super simple either and I think they are different than in Rust. What are the rules regarding where a method can be placed in terms of files and packages? Can you implement your package's interface for a type from another package? (You can do that in Rust and use it for both static and dynamic dispatch.) It seems you need to create a new type to do that in Go unless I'm wrong. &gt; Being dissatisfied with the method-syntax is fair enough, but honestly, that's not a technical argument and IMO has not a lot to do with simplicity - it's just an aesthetic opinion. Hm... My concer with the syntax is _readability_. The reason I brought up the whole 'issue' is that I think the syntax has bad readability for no good reason whatsoever technical or otherwise. I don't really know about aesthetics. Of course I realize that _readibility_ is pretty subjective too. 
Thanks. But the biggest issue is tracking down all such assertions. Is there any way to track down all assertions in a golang project? This is obviously the best way to proceed but would require a lot of effort. I guess I better get started then.
Thanks for explaining, after reviewing the post with your points in mind, I see what you mean. To my defense, the article is fairly short (in my eyes), and the term "CSV" appears quite early in the text, which should give a hint about where the whole article is heading to. But I will definitely keep your ideas in mind for the next post. But I am still curious about the technical side of your comment: Given the task of processing Excel, Calc, or Numbers data in a Go app, how would you access the spreadsheet data, if not by exporting to CSV? The only alternatives I found are specific to a particular product (.xslx, .ods, Google Docs, etc) which I wanted to avoid. In the end, CSV seems to be a suitable universal data format, and thus I do not think the title is too misleading.
But when you google for 'not using mongo' all the articles pretty much point back to that one..?
grep maybe?
&gt; Is there any way to track down all assertions in a golang project? grep something like `[.](.*)`? 
Perhaps I would do the same approach, or have the CSV as the final solution, but also mention that you can export to CSV via using a solution like: github.com/xuri/excelize github.com/Iwark/spreadsheet 
Thanks for the suggestions, point 3 and 4 are very important. I was planning on having Slack as an OAuth source and JWT for authenticating requests. re: startups succeed. I left LeadFuze after almost 2 years when the product was fully built I'd say, we were doing good. I started Roadmap after leaving LeadFuze. We've had a pretty strong starts, some roller-coaster startup-like adventure. Now it is just me at the moment, we were 4 after I launched the MVP.
Yes absolutely, I think if I decide to remove the UI chapter that will leave some room for caching and other techniques, good point thanks :)
Thank you, that is so re-comforting to hear :). I wasn't planning on using Docker, but maybe that could be easier to get started. The CI is more a CD in fact, looks like I did a typo there, It is a small Go app that automates the deployment of the app from a GitHub branch with multiple app environment bound to specific GitHub branch like master=production, staging, dev. 
But most of the countless articles seem to point back to that one article. 
&gt; However I'm not entirely convinced that if done from the very start (rather than changing the behaviour now) it would be more complex than the current solution. That is not a constructive position, though. It is neither verifiable, nor falsifiable, it is based on subjective opinion and it's, most importantly, not *actionable*: It doesn't provide any way or path to improve Go or even talk about why this decision was a good one. There is no possible response to "if you'd just designed a completely different language, this one syntactic element wouldn't bother me" is to say "well, whatever, then be bothered, I guess" (and come off as evangelical or condescending or douchey for not respecting your opinion). I can't tell you, that designing a different language wouldn't have enabled a different syntax to be used here (on the contrary). I can only try to explain the design choice in the context of the language as a whole :) Though, again FTR: Trivially, you could use a new keyword and do, e.g. `meth(x X) Foo() {}`. Or even implicitly `self` in a `meth` block and forego the receiver-name. But whether that would be better or not… Opinion :) This is what I refer to, when I say "aesthetics", the syntactical elements are mostly the same, it's just removing or changing a symbol here and there. Compare that to, e.g. pattern-matching in Rust, or the fact that Rust has an expression-based syntax and no statements. That is more than just "aesthetics" (though it certainly influences aesthetics), it is a deep and important difference between the syntax of Rust and Go with lots of repercussions and informing a lot of other syntactical choices. &gt; The scoping rules of Go as of now aren't super simple either and I think they are different than in Rust. What's not simple about them? I know of two issues with them: a) the scoping of loop variables (leading to [this FAQ item](https://golang.org/doc/faq#closures_and_goroutines)) and b) the behavior of `:=` in terms of when it creates a new variable. Apart from these two, I'd consider the scoping rules of Go to be incredibly simple (far simpler than any other language I know) and these two hardly seem dealbreaking to me. They are caveats that you have to learn, yes, but once you learned them, they tend to not be a problem. (oh, there is one additional issue: Scoping of imports is file-based, not package-based. That is *kind* of unfortunate, but also not a deal-breaker, IMO) &gt; What are the rules regarding where a method can be placed in terms of files and packages? In the same package. Just like any function, variable, const… &gt; Can you implement your package's interface for a type from another package? No. You can't attach methods to other packages types, just like you can't change anything else about other packages types. That is, again, equivalent to most other languages with a module system (languages like Python are in a weirder position here, as they are not typed, strictly speaking). (You can, of course, *define* an interface that types from another package implement; that is the structural typing part of interfaces) &gt; It seems you need to create a new type to do that in Go unless I'm wrong. No, you are correct. As mentioned in another thread, that is part of Go's omission of type-extension, in favor of composition. And, to be clear: All of these certainly are *differences* between Go and some other languages. But that's not the same as saying that they are more complicated than other languages. &gt; My concer with the syntax is readability. But readability is subjective, hard to measure and hard to talk about. I find, Go's syntax improves readability, as you can place methods where they make sense when reading the code of the package as a whole and interspersed with helper-types, -vars and -functions. Instead of having to declare them in one designated place (be that a `class` declaration like in C++ or an `impl` block like in rust). You feel differently. I find Go's usage of mostly very short variables improves readability, as it makes the control flow clearer and keeps lines shorter - a lot of people feel differently. And that's okay, but we have to recognize that these are subjective and hard to justify opinions :)
One inconvenience thing I found is that it doesn't contain the file or line in this printed error. Look at the output, how can I know which line cause the error? I know that there is the debug mode, but in the article Rob said that they rarely use it, so I don't understand how they know where the error is.
Look at https://goreleaser.com/. It can hook into FPM to build an RPM file as well as other formats
&gt; Look at the output, how can I know which line cause the error? Why would you care, unless you are an upspin developer? If you are an upspin developer, turn up the logging level (arguably, the debug logger should include line numbers, though, but I assume that searching for the message-string will be sufficiently unique). &gt; I know that there is the debug mode, but in the article Rob said that they rarely use it, so I don't understand how they know where the error is. I guess "by knowing the code very well" :) In any case, I don't think the error message is, where debugging info should go.
&gt; You don't care about the other languages, but you're sure they're doing it all wrong... I do care about the other languages. I just don't care about C++. ;) &gt; Btw. I just found out language changes in Go aren't really that infrequent: 1.9, 1.8, ... that's a language change twice a year. There's even a compat breaking change in 1.2 Aliases was a big change yes. The 1.8 change was tiny and the 1.2 compat breaking change was a safety thing but I digress. Because even if we count all those, we are talking about 3 language changes in almost 6 years. Meanwhile the author of [this article](https://medium.com/@afinlay/new-language-features-language-changes-in-c-17-7e953ff64c65) lists 33 language features in just C++17. He even closes the section with: "Why so many features Bjarne?" &gt; Hipocrisy? Really?
cool, thanks for the in depth reply. 
cool, thanks! 
cool. thank you.
I've been using this kind of error handling for a while now and any chance I got I kept linking the Upspin errors package to other gophers here. I can tell you that it's real and it's spectacular.
I've done something similar in a project, not via go generate but as a pattern. There's a problem with the naïve approach: if another package declares a struct that embeds one of the cases of your sum types e.g. `type ExternalStruct struct { yourPackage.KeyValeExpr }` it will also have the `expr()` method and hence implement your sum-type interface. My solution was to add a return value to the private method e.g. `expr() Expression` and let *my* cases simply return themselves. Then, in a method that will use an arg `e Expression` do `e = e.expr()` to ensure it's one of your own types. You can then "safely" type-switch it.
&gt; But when you google for 'not using mongo' all the articles pretty much point back to that one..? Maybe they do, maybe not. What's your point? Really just think for yourself. Is MongoDB a good fit for your project? if it is then use it. But here we have an author that is writing a book and is asking for feedback. MongoDB can only be used for very, very, very specific data models and situations. As far as I am concerned it's a very bad fit for a learning book.
&gt; Aliases was a big change yes. The 1.8 change was tiny and the 1.2 compat breaking change was a safety thing but I digress. Because even if we count all those, we are talking about 3 language changes in almost 6 years. Those were just examples, there's a language change in every minor release except 1.3 and 1.6. There's also one additional compat breaking change in 1.1, so that's two breaking changes in some 6 years. Some of the changes are indeed fairly small, I agree, but I still wouldn't call it "We don't add features". I'm looking forward to Go 2.0, at that point I'll just grab popcorn and watch the show... &gt; Meanwhile the author of this article lists 33 language features in just C++17. He even closes the section with: "Why so many features Bjarne?" Well then, perhaps we should rephrase Pike's argument from "Other languages constantly add new features and converge to the same languge" to "C++ adds a ball of features every couple of years in recent years"? Btw. that Pike's talk took place some 2 (?) years before C++17 came out... Anyway, I absolutely agree C++ is getting pretty crazy starting with C++17 (even more crazy that it was before which is surprising in that it turns out to be possible :D), but that still hardly justifies Pike's attacks against all other languages. 
&gt; Anyway, I absolutely agree C++ is getting pretty crazy starting with C++17 (even more crazy that it was before which is surprising in that it turns out to be possible :D) Good so we agree then. &gt; but that still hardly justifies Pike's attacks against all other languages. I am not trying to justify Pike but if you look at the history of Go, it's a language that has been created as a [reaction](https://www.youtube.com/watch?v=5kj5ApnhPAE) to the industrial programming of that era and a solution to [Google's problems](https://talks.golang.org/2012/splash.article).
Video linked by /u/shovelpost: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [OSCON 2010: Rob Pike, "Public Static Void"](https://youtube.com/watch?v=5kj5ApnhPAE)|O'Reilly|2010-07-22|0:12:31|734+ (97%)|71,604 $quote http://oscon.com Rob Pike (Google, Inc.), "Public Static... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/shovelpost ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=$comment_id\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
One tip I have for you is not having a `src` folder, but a `cmd` folder. Then the source goes to the root and your main file goes to `cmd`. It is a lot cleaner. Just my two cents on Golang projects. Have fun! 🙋
waht if i want to send some json data aswell as the file in the same call is this possible? 
Upvote for thumbnail pic!
Oooh. thanks will do
&gt; That is not a constructive position, though. It is neither verifiable, nor falsifiable, it is based on subjective opinion and it's, most importantly, not _actionable_: It doesn't provide any way or path to improve Go or even talk about why this decision was a good one. Few of the points I mentioned in the blog are actionable, it _was_ mostly a rant. Perhaps generics, in the future. That's about it. Anyway, I should've made it clearer, in this part I wasn't really concerned with syntax/aesthetics of Go (anymore), I was basically just thinking out loud about comparison of complexity of the solution Go has and a solution where UFCS works but where interfaces and structs are still separated the way they are in Rust &amp; Go (or in similar way). It's purely hypothetical, sure, but I find it interesting... &gt; Compare that to, e.g. pattern-matching in Rust, or the fact that Rust has an expression-based syntax and no statements. (Strictly speaking, Rust does have statements, but that's not important here, ... Rust also has aesthetics problems according to many people and I'd agree with some of them.) &gt; What's not simple about them? Well, the questiones that followed that were unclear to me. (Thanks for answering them.) &gt; But readability is subjective, hard to measure and hard to talk about. I agree with one reservation: I think it is near-objective that a consistent name for the receiver helps readability. I can't see how _not_ having it would help. &gt; I find, Go's syntax improves readability, as you can place methods where they make sense when reading the code of the package as a whole and interspersed with helper-types, -vars and -functions. Instead of having to declare them in one designated place (be that a `class` declaration like in C++ or an `impl` block like in rust). You feel differently. I don't, in fact :) For example I hate Java's limitations in this depratment, they are pretty ridiculous IMO (and I'm glad Kotlin lifts them). I'm not very fond of C++'s limitations either, although at least you can have definitions located wherever you want. I think C# doesn't have this limitation but I'm not sure. Sidenote: Rust isn't like C++ in this, it is actually more similar to Go in this regard. You can have any number of `impl` block per type located anywhere in the package ("crate" in rustese). You also can't extend foreign types the way you can do in C++, Java, et al. You can `impl` a `trait` for a type, but only if you own either of those (or both). Basically you can either extend foreign types for your code, or your types for foreign code (with a trait that the foreign code defines), but not both. You cannot override a type's method even if you implement a trait for it that has a method with the same name. 
Hey thanks for sharing. I looked at the source, and have some considerations: - Each file is its own leaf/key. Have you considered supporting a simple key/value format to allow for the consolidation of each locale's tree? - The use of a radix tree, which is type leafNode struct { key string val interface{} } when this package is only concerned with string -&gt; string. You could replace the Locale's Tree with map[string]string, and have done with the dependency on `go-radix` - I wasn't looking closely for code smells, but did notice that *Locale.Tr() will `panic` if `go-radix` doesn't have a value for a leaf. It would be better to return (string, error/bool) and let the caller handle the issue. Straight forward read code-wise, so kudos to you, hope the above helps in getting it more traction!
&gt; I think it is near-objective that a consistent name for the receiver helps readability. Well… I disagree :) Readers are pretty consistently called `r`, so it makes sense to call the receiver of a Reader-implementation `r`. The problem you are having, I'd consider a more general "following an identifier through the code". Which will stay a problem, even if the receiver-name was consistent. And once you solved that (e.g. by hovering highlights in your editor, by some keyboard shortcut…), the receiver isn't special anymore. Further, the canonical candidate for such a receiver would be `this` or `self`, which is significantly longer than most receiver names are today - so see my note above on how short identifiers can increase readability :) Really, it might be surprising how subjective "readability" is. &gt; Rust isn't like C++ in this, it is actually more similar to Go in this regard. It's most similar to Haskell, from what I understand - which I don't know *that* well either, but better than Rust, so that is the bridge I took to understand Rust's type-system during this conversation :) Anyway, I hope we agree to disagree at this point, which is nice :) 
 1. He links to the GitHub page of the contributor who forked it. That's not trying to hide something. 2. Minio has almost 10k stars and isn't new. It's not as old maybe, but someone using CLI for stuff will be able to easily use something different to launch one if they have both installed. Also, name overlap just happens. Like Unity: the game engine, the document storage API from Hyland, and the Ubuntu desktop that may or may not be defunct now. Like PIXEL: a phone product line, a Go game engine, a Linux video blogger (Nixie Pixel!), and probably hundreds of other things. It happens, and we seem to be doing just fine. 3. I see 3.5% JS in one of many projects and it seems to be for React in a UI for something. I'm not sure if you're aware, but there isn't really a pure Go UI. So...
Thanks for your tip! I do prefer having all application related source code in a separate folder as the root of the application often contain quite a lot of configuration files e.g. docker, docker-compose, gitignore, ci/cd related and so on. And that's becoming a mess quite fast.
Interesting, some of this is very similar to an errors package I just wrote for the place I work at. I'm pushing for it to be open-sourced, but may make another package based on what I learnt from it. The thing is, like this post even suggests, error handling can be quite specific to the application the errors are happening in, and the way you handle them may also be specific to that application, making a generic application sometimes less useful.
"that one article" When writing an article like these, it's usually standard practice to link to other corroborating sources. They're not all summarizing a single article. There are a number of unique experience reports and interactions with the MongoDB team which have been written up, and naturally those will link to articles in the same vein.
Indeed! I would keep your `src/` folder, but rename it to `internal/` though. `internal/` is a special directory name, and it makes all of the packages beneath it hidden to anything not at the same level as the `internal/` folder or below. It's very handy to avoid polluting your `$GOPATH`. To try to illustrate that a little more clearly: foo/ cmd/ internal/ state/ bar/ cmd/ internal/ state/ Both projects have similar structures. Both projects happen to have a package called `state`, neither project can import the `state` package from the other. If you did want to share something from within your application (instead of making a separate library), then a lot of people tend to go with a `pkg/` directory. This way it becomes a lot clearer what you are and are not exposing externally, and if you're using an editor that suggests package imports, or goimports for example, you will have a much easier time.
&gt; That's… a bunch of internal debugging info I shouldn't have to care about, as a user. I personally really like errors that have what I call a "human" result, which is an error message that can be displayed to the end user, and a "computer" result with all that debugging information. However, whenever I have introduced that into a system, nobody else picks it up, so I seem to be in a very, very small minority with that idea.
&gt; Further, the canonical candidate for such a receiver would be this or self, which is significantly longer than most receiver names are today - so see my note above on how short identifiers can increase readability :) I like short identifiers too, although to me anything under some 4 or 5 chars is "short"... &gt; Anyway, I hope we agree to disagree at this point, which is nice :) Ok, sure, thanks for the talk
That wasn’t meant to sound bitter. It’s verbatim what I was told when I asked what role I was actually applying for. 
To me, this is simply: The message (return from `Error`) is for a human. The value (type and/or value) is for code. The log is for debugging.
I just wrote about this a bit ago in [another post](https://www.reddit.com/r/golang/comments/7hhq45/advice_on_a_good_local_development_workflow/dqs0s4n/). I would drop the arc folder as already suggested for sure.
Yeah, that's probably what I would do if I were writing the kinds all in one place. I had kind of hoped for a solution where some far off package could make its own error Kind (like PopcornFailure), without worrying about collisions with existing Kinds. In that case, errors would be like context.Context keys, where the type keep them different... But maybe that's not a big enough use case to complicate the code. 
I agree that the errors are hard to read.
I think the problem is that all the debugging info can scare off non-technical people.. or really ,anyone who just doesn't want to debug this software. Every time I see a python stack trace in a tool I'm using, I want to throw my computer across the room. My cardinal rule is that users should never see debugging info, because too often, developers lean on it as an excuse not to make their error handling (including error messages) better.
What about embedded catalogs in binary such as https://github.com/jteeuwen/go-bindata ?
I would make sure to check out the repositories in [golang.org/x/tex](https://godoc.org/golang.org/x/text). It provides the [gotext](https://godoc.org/golang.org/x/text/cmd/gotext) command which you can use to build a [catalog](https://godoc.org/golang.org/x/text/message/catalog) to back the [message](https://godoc.org/golang.org/x/text/message) package. The nice thing is it supports all the other aspects of 18n like currency, date, number, pluralization and some helpful packages to deal with the more tricky bidirectional locales. They are a tough set of packages to beat, maybe you could provide some of the rationale for creating your package and the benefits it provides?
&gt; good luck finding out that unused variables are a compiler error from the Go spec "If any variables are still uninitialized when this process ends, those variables are part of one or more initialization cycles, and the program is not valid. "
Both your posts have way too high level of problems, you're asking how to write a project rather than how to solve a problem you are facing while writing the project. Effectively your "questions" is how to perform software engineering using Go, it doesn't have a single answer. If you are just starting with Go I suggest [getting started](https://golang.org/doc/install) and [effective Go](https://golang.org/doc/effective_go.html) which may paint a partial picture of some of your questions. Then I would begin the project yourself and if you get stuck then feel free to post here or maybe join the gophers slack channel for a lower latency feedback loop. Make sure not to provide an [XY](https://www.google.com/search?q=xy+problem), the best way to do this is to post a working playground example showing something as close as possible to what you want to do.
Everything work out for ya?
That's a nice approach. I use a similar method in go, the old gettext locale approach (https://github.com/gabstv/i18n). It loads gettext files (.po) from the filesystem: locale/ locale/en/main.po locale/fr/main.po ex: package main import ( "github.com/gabstv/i18n/po/poutil" ) func main(){ defaultLang := "en" provider, _ := poutil.LoadAll("path/to/root/locale", defaultLang) // get the user lang from context etc lang := provider.L("fr") print(lang("Hello, %v", "username")) } It merges all files on load and supports Gettext context
Yes, at the end of the day it's just a matter of preference. Feel free to use whatever feels better to you! Even though I don't structure my projects like that, I like studying other points of view. Just to clarify my opinion, for a RESTful API, I usually only keep a `server.go` or similar in the root, since models, routes and controllers are kept in a subpackage and the `main.go` equivalent goes into `cmd`.
Our team began using Go this past year because of its great standard library, performance, fast GC, and single-binary compilation artifacts. However, coming from languages with "proper" package management, things like this just perplex me. I know I'm not the first person to complain about Go, or even this issue in particular. And hey, I think Go is a phenomenal language in a lot of ways, even if my personal tastes lean more toward functional languages with more "capable" type systems and overall conciseness. In general, I sum my feelings on Go as "I hate writing it but I love reading it." I think that's a huge win for the language, to be honest. But holy crap.. the lengths this guy has gone through just to get repeatable and isolated dev environments for multiple projects is nearing levels of absurdity. And worse? I don't fault him at all. Google's niche use case of developer scale and single-repository SCM pattern fit so few of rest of the Go-lang community's workflows yet these niche situations are the basis for all of Go's workflow idioms. Our team's solution? We use old school`make` with Makefiles that add the necessary environment variables and command line flags to allow for vendor directories work in a sensible manner. I've seen people include shell scripts to setup the environment before you run `go` commands. I've seen Docker users. And now, this. Probably the wrong sub to rant in, but feeling like I'm fighting the language because my team has little to nothing in common with the development organization at Google. And that's really frustrating. My understanding is that there is [may be?] a package manager coming. Is this true? If so, do we know if it solve the majority of the author of OP's article's issues? And for those who have been using the language longer and are, perhaps, more in tune with the core development of the language - is there any sense that Google's niche use case will have less sway over the workflows over time? Or am I in the minority in terms of users who find it frustrating?
If anyone has not played with raylib-go yet - give it a try. It's super easy and fun to write little demos in it. /u/gen2brain thank you for your work :)
I think the "project specific" part is the path and user values on errors, and the specific values for "kind". The rest seems eminently useful. And honestly, most of the kinds will be universal for anyone running a server against a database. You could pretty easily copy and paste the whole thing and only tweak a little bit to make it useful for many of the common applications Go is used for.
did you find anything yet on this? i did https://www.okgo.coffee/ for a bit, but couldn’t sustain it
I would upgrade http file from helpers folder and move it into independent package. In pg.go i would delete unnecessary error checking and just return pg and err Same for functions in model.go, you can return struct and err right away instead of checking it. In handlers.go i would not return "Login failed", just "Wrong email/password"(if you don't mind lying a little). First one sounds like application outage. Consider using some more advanced log package, like Logrus or Zap. CreateUserBody and loginBody are identical, why don't just use one of them for both handlers? Consider writing function for getting userID instead of: &gt; userId, ok := r.Context().Value("userId").(int) 
Moving to Go from an object oriented approach reqiures inverting a lot of your usual logic. Instead of a base class that implements a lot of common logic, you write functions that work on interfaces to perform common logic. The customized bits are the bits in the interface's methods. This is (somewhat) easy to say, but definitely harder to explain and put into practice. There are definitely some things which Go will never do well at... like writing custom containers that are reusable with any type without having to do some gnarly stuff with interface{}. However, that's only one solution to a vary narrow problem. In general, and deliverable project you work on is totally doable in go with minimal hacks, as long as you don't try to swim upstream (and as long as that project falls within Go's bailiwick... obviously a GUI for an embedded device with 16k of disk space is not going to be a place where Go shines).
shameless plug: I've also created my own `csvutil` package: - https://godoc.org/go-hep.org/x/hep/csvutil - https://github.com/go-hep/hep/tree/master/csvutil it allows to read data directly into slices or structs with an API ressembling that of `database/sql`. and I created a `database/sql` driver for csv: - https://godoc.org/go-hep.org/x/hep/csvutil/csvdriver - https://github.com/sbinet/jdev-go-datascience-2017/blob/master/_code/csv-clean-ex-01-solution.go hth, -s
Ctrl+1 focuses your code panel, Ctrl+ö (german keyboard layout, I assume it is Ctrl+` on 'normal' layouts) and Ctrl+E focuses your file browser. Do you _really_ want to _cycle_ focus? 
&gt; bravest men and women I once wrote an app in php can I have an interview
For the string matching part, you haven't quite given enough details but it sounds like you might want https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm . There's an implementation from Cloudflare: https://github.com/cloudflare/ahocorasick
Is that a php joke :). We actually have need for a php expert to instrument applications written in php into the datadog ecosystem...
That's not true, I'm using ST for Go for the last 3 years. Trying each new IDE/editor announced, and there is nothing new or useful they could offer. They only add lags to the the workflow and noisy tips. 
Don't know about Upspin but has anyone tried Updog?
**What is inside?** * Deferred nil func * Defer inside a loop * Defer as a wrapper * Defer in a block * Deferred method gotchas
FYI, your solutions to #2 (defer inside a loop) are reversed
Thx! Fixed.
&gt; So instead of inheritance you have to do composition and it is very limiting compared to true OOP. This is a puzzling statement since inheritance is strictly a tight coupling between reuse and polymorphism and composition/interfaces represent the decoupling of those distinct concerns. I tend to find that the OOP crowd have the worst understanding of OOP; I guess its hard to understand something apart from its alternatives, and the "OOP crowd" is probably largely comprised of people who haven't been exposed to other models. I'm aware of how pretentious that sounds, but I think it's true in this case.
I wrote this because I needed a solution to trivially serve my GRPC methods as JSON over HTTP. I checked out github.com/grpc-ecosystem/grpc-gateway but I didn't like having to do custom configuration, I really wanted something more plug and play.
You could also make the sum type the thing that wraps the individual instances. For example: type SumType struct { wrappee interface{expr()} } This should solve your problem, albeit anyone else can still implement `expr()` on their own and satisfy your interface. Basically you can't prevent people from willfully violating your abstraction, but you can get nearly there.
*Yet another guide to dep that fails to mention that dep can't work with symlinks... Yes I'm bashing dep on purpose just to put the pressure on this long standing issue, so sue me.* With that out of the way, this was a great guide on two pretty common (well, common for me at least since I bump into them time and time again) problems with managing dependencies and how to easily solve them with the 'source' field. But is there any hidden disadvantages to manually specify the 'source'? Well, except for overlooking having used it to avoid some upstream bug.
On Example 4; the output should be: block ends func ends block: defer runs you have the first two lines swapped currently. https://play.golang.org/p/xjt20jJEEr
I built something similar: https://github.com/weberc2/tdl. Basically it lets you describe all of your types in a different syntax that then compiles to Go (or in the future, to other languages). Currently the output isn't ideal, but I'm confident it could be improved significantly. It also builds a `Match()` function to emulate pattern matching. For example, here's the definition for JSON: type Field = {Name FieldName; Value JSON} type JSON = Array []JSON | Object []Field | String String | Number float64 | Boolean bool | Null () And here's some Go that uses it: https://github.com/weberc2/tdl/blob/master/examples/json/main.go In the future, I'd like to build a statically-typed expression language around it which also compiles to Go, but with fully-fledged pattern matching instead of the `Match()` mechanism.
&gt; anyone else can still implement expr() on their own how is that? Assuming they don't modify your package's code.
That seems correct and clear, what bothers you about your code?
I'd suggest the solution to #3 be assigning the returned disconnect func to a variable and then deferring it. The double parens is hard to read and easy to miss later, generally a bad practice.
I was just wondering if there was a better way! I would rather not have to deal with channels and goroutines (even though I will obviously have to use goroutines since I'm running two servers at the same time). Maybe something in the stdlib? Seems like there's always a cleaner way to do things in Golang.
This, and the playground link points to a different code that doesn't even run.
&gt; Iris [No.](http://i.imgur.com/YcAQlkx.gif)
I'm not aware of anything in the stdlib that would do this. In fact, I like the way you wrote it.
If you are finding it strange that the article has a clear bias in favor of Iris, that's because the author of the article is a contributor. This is not mentioned anywhere in the article. Oh and by the way this is a [repost](https://www.reddit.com/r/golang/comments/7dz0o0/top_6_web_frameworks_for_go_as_of_2017/). 
I guess they can't, because they don't have a mechanism for setting the private `wrappee` field.
The first comment pretty much shows it. We know of shady stuff going on with Iris. Author claims that the account creation of the guy who asked is shady. Thanks, you cannot show more how biased towards Iris the article is just by looking at this answer. 
If the list is sorted you could use [sort.SearchInts](https://golang.org/pkg/sort/#SearchInts) to binary search the start and end values. Keep in mind your implementation is probably fine until you hit hundreds of items, for end range search make sure to give the call to SearchInts a slice from the previously found start boundary to prevent needless scanning of those elements.
me too
Distributed and recursive files scanning - my suggestion here would be to look at the Sift project: https://github.com/svent/sift It is a code-focused grep alternative written in Go, it is a project that already knows about things like reading .gitignore files, using parallelism in searching, ignoring irrelevant files, skipping binary files, etc. It should give you at least an idea of how to handle concurrently consuming a file set while matching regular expressions. As to the 'distributed' part, this seems relatively trivial - basically, the problem space is already chunked for you, by being divided into files. So you would have something like one app that receives the notification from a git hook that a new check-in has occurred (I assume - not sure how else git hooks would be relevant), which would go into a queue of apks to be produced, I assume, and it would read the repository file list, and then hand those files off to your distributed workers, in the form of a JSON or grpc query with a list of files and a git URL+ref combo or something like that to rejoin the returned results. Distributed workers submit results, either to that same master, or to some other worker that collates them into a master list of dependencies for that repository. Cache that somewhere. Have the first, master service recognize the git url/ref pair and pull from the cache instead of streaming to the workers when it gets the same request again. Take that and match those dependencies up to your apks, find the ones that are missing from your list of already generated apks, and submit them back to the first service to be scanned for dependencies. If there are NO missing items, then this project is ready to be wrapped up into an apk, so either do that, or submit that to a service that does that. Now, go through that and add something to detect and break import loops so you don't end up with infinite requests flowing between your services.
mmm, version two &gt; https://play.golang.org/p/oQdHrjVUHi
I was debating the value of middleware frameworks with a buddy and offered to put my thoughts into an article. I've used the custom context pattern for two different backend services in the last year and pretty happy with the results. Happy to answer questions and very open to criticism. 
or tree? https://play.golang.org/p/IfQGuXzvwB
&gt; You also have to think differently about the code since Go is a dumbed down language, which is also the reason one can be productive in it in less than a week. Not so sure about this one... Go isn't "dumbed down". It's designed to be easy to pick up and use (as the author has found), but just because it isn't an OO language doesn't make it "dumbed down" - it's just a different approach. &gt; Unfortunately Go does not have anything like method_exists() so you have to use switch inside the handler method and process logic centrally instead of delegating the logic to appropriate methods. It sounds to me like you found a solution in PHP, the language you're most experienced with, and decided to try implement the same thing in Go without really thinking about how you could achieve the same result in Go idiomatically. This is understandable though, it can be very difficult to alter your approach to problem solving if you've done it one way for a long time. One possible solution to this would be using a map where the keys are strings, and the values are some interface that consumes and handles an event. Maybe you could even get away with the values being functions that you call. That way, you can look up event handlers by name and delegate to some other function or type. My advice would be to try to learn a little bit more about Go first. You've dived in headfirst into writing something totally new and reasonably complicated. Go _is_ easy to learn, but usually I see 2 areas where that really works: new developers learning how to code, and existing developers joining existing projects. If you're an existing developer making a new project diving into Go you'll have a harder time because you'll not have much to guide you, and you're in a situation where you want to get the solution right. My background is also mainly in PHP. I started working with go about a year and a half ago now, and I've only been working with it full-time at work for 2 months, but I must admit, I don't miss PHP one bit. It's not that PHP is bad, it's that Go is much better suited for the problems I want to tackle. Go also provides much more of a challenge. I can deal with concurrency, long-running processes where memory leaks are important. It feels like I'm working much more low-level, but not _too_ low level. It's great, and really fun.
[errgroup](https://godoc.org/golang.org/x/sync/errgroup) makes it slightly better and more correct (the last goroutine will block on the unbuffered `errch` the way your code is written): func run() error { // ... defer httpServer.Close() defer httpsServer.Close() g, _ := errgroup.WithContext(context.Background()) g.Go(func() error { return httpServer.ListenAndServe() }) g.Go(func() error { return httpsServer.ListenAndServeTLS(certFile, keyFile) }) return g.Wait() } 
The goal wasn't to create strict sum-types per se, because that would limit the number of implementors of the type. Rather it was to reduce boilerplate when creating interface decls, e.g. in the ast package. Here is an example of what that would look like with sumgen. https://gist.github.com/smasher164/fa19e0541957499c86a9b9d6b7179b59
/u/siritinga I fixed it now.
Thx, I fixed it now.
Thx, that is indeed a bad practice. However, I put there for people to understand `db.connect()` should be resolved first and that's not the one which gets registered with defer. As it seems, it was a poor choice. Now, I updated that part again and included the bad practice as an example.
I don't want to sound antagonistic but what's the point, then? We already have interfaces. The benefit of sum-types is that there is a finite, statically-known amount of cases. Now clearly, Go won't ever complain about a missing case in a type-switch like a language with real sum types, but at least you can ensure sanity and some safety through this mechanism. 
I really like your approach, this makes reconsider using a framework oO
From the x/sync/errgroup docs: "Wait blocks until all function calls from the Go method have returned, then returns the first non-nil error (if any) from them." In the above, if one server started up fine but the other failed, g.Wait() would never return.
&gt; func E(args ...interface{}) error &gt; &gt; As the doc comment for the function says, E builds an error value from its arguments. **The type of each argument determines its meaning**. The idea is to look at the types of the arguments and assign each argument to the field of the corresponding type in the constructed Error struct. And with this I give up on Go's philosophy. This is not simplicity, this is a huge unsafe hack to deal with lack of language features.
Yeah, you'd need to separate the listening and serving, and do something like g.Go(func() error { &lt;-ctx.Done(); return httpListener.Close() } g.Go(func() error { &lt;-ctx.Done(); return httpsListener.Close() } 
Do i understand right, that your array has to be read as tupels marking the beginning and end of a rectangle? 
The point is to reduce boilerplate for already existing interface type declarations, especially when there are a large number of satisfying types. You could argue that preventing concrete types that embed the interface from implementing the sum-type interface will increase safety in these situations. In fact, I may add that as an optional flag in the future.
yes, beginning, interceptions and final
&gt; client.Lookup &gt; dir/remote("upspin.example.net:443").Lookup: &gt; dir/server.Lookup Those point to the package/path, type and functions/methods like `pkg/type.func` Good enough for a developer, less scary than stack traces for endusers.
I like two parts about your article, the simplicity of inferred Context struct values that enable you to have a `Body()` function without explicitly having to pass a http.Request (convinience / utility). And the type safe way to pass dependencies to the implementation(s) for your APIs instead of resorting to the request context and type casts. That said, I don't think you're driving home any bonus points for `Get` and `Set`. I wouldn't say that writing your own `BadRequest` function is somehow a case against middleware either. I mean if you're outputting errors, possibly in several places, you would have to think about providing a generic function to print these errors to a http.ResponseWriter? There's also a significant caveat to `stack`, mainly that in any part of the list of `mw` handlers, an error might occur. While your example tends to handle these errors in the handlers themselves, it doesn't have a facility to break out of the stack, and each of the handlers will run. Nothing of this is drastic, I just see room for improvement. I'd suggest you to read [error handling in go](https://scene-si.org/2017/11/13/error-handling-in-go/) for a bit of context along the lines of sequential error handling and improving it. And the final point, you could very well have an internal API which would not operate with any knowledge of http objects, but would take type safe, concrete inputs. Unfortunately I don't have a good example to share at this point, but [this will have to do](https://github.com/titpetric/pendulum/blob/master/main_api.go). While the distinction here is only between the internal API (List, Read,...) and the HTTP API (ListHandler, ReadHandler), there's a relatively straighforward way to use embedding to your advantage to write a cleaner separation of concerns. If I'm not clear on some thing or if you'd like some clarification, feel free to reply or DM if you want to take it private. I can't share some code snippets publicly if you'd like a more concrete example.
For #4 you could also mention that you could replace the block with an anonymous function. That way you can use it like a block and the `defer` would be called where you expect it to be called.
Which language features would help in this particular case? To me it looks like a developer sacrificing some compile time safety in return for keeping the API small. I somehow doubt they've had problems due to using `...interface{}`
There was a solution for this in gotcha #1 but it's good to mention it again there too. I updated it. Thanks!
Algebraic data types.
IMO the reason why errors package is so small, it only has errors.New function is because projects are expected to override their own errors package.
It's really important to test on your projects to discover any issues before the final release. Every single time there are always bugs filed on the first day by somebody running their unit tests. Add it to your CI, build your code in dev, run canaries in production. All these help improve the quality for everybody.
Here's what I came up with.. Create two listeners (tls &amp; tcp) and serve them from the same http server struct. Apply the error handling /u/tgaz mentioned or try this package https://github.com/oklog/run. https://play.golang.org/p/49Ji8TeTAY $ curl http://localhost:8080 hello from: http://localhost:8080 $ curl -k https://localhost:4343 hello from: https://localhost:4343 
Hey /u/joper90 if you email help@datadog.com we can enable this for you. Thanks
Look at socks4 and socks5 standards. A client does handshake first where says to a proxy what is a destination IP and port.
Additional protip that has been useful to me lately if you use Travis: ``` matrix: allow_failures: - go: tip ```
math.Round() 🎉
I create a "MulitListener" which implements the net.Listener interface {} and can listen to any number of configured ports, and accepts sockets when connections arrive, I then use this as follows : err := httpServer.Serve(webServiceListeners). I remember I had an issues of creating two seperate web servers using the same routing, which would either hand or panic, this was my solution to the problem and it works so far perfectly. 
Here's another approach with graceful shutdown: https://github.com/sassoftware/relic/blob/master/server/daemon/daemon.go
Hi @titpetric thanks for the reply! &gt; That said, I don't think you're driving home any bonus points for Get and Set. Agreed. Contrived. &gt; I wouldn't say that writing your own BadRequest function is somehow a case against middleware either. I mean if you're outputting errors, possibly in several places, you would have to think about providing a generic function to print these errors to a http.ResponseWriter? Good point. It could be a `func BadRequest(r *httpRequest, ...) 
Because ops has a way of doing it for everything, not just go apps, and rpms are where deployed software comes from. This makes so many things much simpler for a lot of groups: ops, security, Dr team etc
`json.Decoder.DisallowUnknownFields()`! Can't get Offset information out of the error though.
Hi @shark1337 thanks! Let me know how it goes. I'm not 100% committed yet but it's working nice so far. 
that version number is confusing. I thought this was a nostalgia post about go 1.1
The only genuinely surprising gotcha was #5 I wasn't aware of this: &gt; the passed params to a deferred func are saved aside immediately without waiting the deferred func to be run.
&gt; The concepts are universal, you only have to learn the new syntax. You want to look like a pro, OK &gt; Unfortunately Go does not have anything like method_exists() But this shows who you really is. Method exists, LOL.
Wow, SQL for CSV. This should easily address even the most sophisticated use of CSV data. Tagged for my course.
At risk of answering a different question, does that need to happen at the app level? It might make more sense to just let the app listen on a single http port and use nginx/haproxy/whatever to terminate ssl and reverse proxy on multiple ports.
That's another thing I was considering doing, nginx reverse proxy. For a couple of reasons our team decided not to do it, but I would normally just go with that.
[Semantic versioning](https://semver.org/) doesn't use a decimal system, the second number just keeps being incremented for non breaking changes.
If you allow them to intersect, i dont think your representation has enough abstraction. You need the info which point is a starting point and which is an endpoint. Then you can search the startpoints for a and b and then the remaining endpoints for a and b too. 
Dep! How close are we?
How do you pronounce "ozzo"?
I think we could just do that in the run() goroutine, and just wait for context cancellation before `Wait`.
Work in progress
Maybe like Oso the bear? https://www.youtube.com/watch?v=XmnV_C73XEo
makes sense. by the way, I've made some changes, and i added a method called `Reader.Word`, it reads the next word from a line. If it's not obvious yet, i'm trying to imitate the behavior of `Scanner` in Java. Most of the methods now are using `Reader.Word` (except for `Reader.Line` of course). If you have a time, I would be glad to hear your review :)
Draft release notes https://beta.golang.org/doc/go1.10
So you have problems with numbers above 9 ?
The build cache is a nice one. On another note, I would love to see benchmarks on compilation speed and runtime speed. Has the goal of reaching Go 1.4 compilation speed ended/stalled?
does anyone have some benchmarks ? (not very important but still .. possible lower latency &amp; overhead sounds good..)
Very cool project. I really like the colors. I see you are using MyAnimeList. If you want to get rid of (some) of the regex and HTML parsing, I've written a [Go client](https://github.com/nstratos/go-myanimelist) for their official API. The project is "done", very stable and has quite a few [examples](https://godoc.org/github.com/nstratos/go-myanimelist/mal#pkg-examples). Unfortunately some info is not provided by their API so for certain things you will need to keep doing HTML parsing.
I would say italians would pronounce it with two "tse"-s — like in "pizza". (Disclaimer: I'm not in italian) ;-)
Some benchmarks comparing go1.9 vs go1.10 performance are here - https://groups.google.com/d/msg/golang-dev/sRodVfN15jw/pInHrYrECwAJ
Major version 1, minor version 10.
I've 15 more gotchas coming in the queue.
Have you been drinking?
&gt; I guess its hard to understand something apart from its alternatives, and the "OOP crowd" is probably largely comprised of people who haven't been exposed to other models. I primarily come from a PHP background and that is indeed the case for me as well. Trying to wrap my head around Go's way of doing it vs PHP/JS isn't very fun.
Hackernews [comments](https://news.ycombinator.com/item?id=15867015) if anyone's interested.
Yeah I came to know about the API only after I made the project. But I really wanted to learn regex and put it good use. Would be really happy if you could give me a star :) 
lots of gotchas (if legit) means the language is badly designed. see: javascript
Tell me one language which is not badly designed.
While I agree with #2 that it's a bad idea to defer *a lot* inside a loop, this reasoning seems wrong to me: "[..] All calls here will eat up the func’s stack and may cause unforeseen problems." Go uses [contiguous stacks](https://docs.google.com/document/d/1wAaf1rYoM4S4gtnPh0zOlGzWtrZFQ5suE8qr2sD8uWQ/pub) where there's no way to eat up the func's stack and thus this should not cause any problems whatsoever. For example even this doesn't (and shouldn't) break: for i := 0; i &lt; 10000000; i++ { fmt.Printf("i = %d\n", i) defer func(num int) { fmt.Printf("defer num = %d\n", num) }(i) } 
Using ragex for html is not a good use.
I run a benchmark and saw that defer is hungry. Check out: https://play.golang.org/p/GJ7oOMdBwJ WITHOUT DEFER: no split: 376.385945ms with split: 370.558991ms both split: 372.674467ms WITH DEFER: no split: 10.554299489s with split: 56.384446484s both split: 49.519827551s
my fault, the lack of clarity the numbers are the limits of the "squares" and 0 5 15 22 45 50 55 ^ ^ ^ ^ ^ ^ ^ ______________________________ |1_|_2__|__3_|___4___|_5_|_3_| a-----------b = 3 | | 9 32 the range a-b is an arbitrary value. what I try to know is how many of these squares crosses the range
Initial benchmark numbers seem to change a lot and eliminate most regressions from beta till final release, so if there are bad numbers anywhere, don't worry yet.
Awesome advice. Thanks! 
I'm planning to, why're you asking?
I get html is not a regular language according to automata theory. But these pages tend to never change. I don't need to parse a lot of pages so never thought of using something like beautiful soup for golang parsing
I really don't get why everyone is complaining about golangs error handling. I think it's fine the way it is now and I even started to like it. What would be your preferred alternative to handle errors in go?
[Here you go.](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf)
Since all you got so far was snark, I'd like to say thanks for curatedgo, I really like the idea of a hand-curated feed and it's a hard project to keep going over years. I've found a few articles through it that I wouldn't have otherwise and can sympathise with the rush for meaningless internet points - social media machines (like twitter or reddit) have been fine tuned to keep us returning, and continuous notifications are part of that. In some ways a hand-picked feed is the antithesis of that so even posting less frequently would be fine if it means you only surface stuff you personally value. 
I'm sorry, I didn't ask for the c++ spec :D I'm asking about the motivation as to why Go avoids such scope, possibly explained by someone within the Go community in some spec, maillist, article or blog. At some point it was a design decision, and it's very much a part of a whole argument as to why some things will not be implemented. Like [this](https://github.com/golang/go/issues/12168). Actually, to expand on it with your reference: &gt; Flowing off the end of a function is equivalent to a return with no value; this results in undefined behavior in a value-returning function. But unlike C++, Go has named return values, meaning that at the end of the function, all the values are defined and can thus be returned implicitly. The GH issue argues against this, since this would be "magic", also skipping over the fine print that the return statement is also a flow control statement. At the end of the function, the utility of that is taken away. I'm trying not to be biased and push my opinion as the one true way, but to inform people with some references and let them decide for themselves. :)
Gopher Academy just posted: https://blog.gopheracademy.com/advent-2017/custom-JSON-unmarshaler-for-GraphQL-client/ A quick glance at it, and it looks like it's a better resource than the code example I posted earlier. 
Still no fix for the XML namespace issue. It's been so long! :( https://github.com/golang/go/issues/9519
I don't think there is a single comprehensive answer. Go is pragmatic: It adds a thing, when the tradeoffs involved where suggesting that it is worth it. The tradeoffs are different for each thing. Most of the things have been decided a long time ago (a bunch of them before Go was even made open source) and ever since Go 1, the tradeoffs have, again, changed. It makes more sense to ask about specific constructs.
`time := int64(claims["exp"].(float64))`
Thanks for all the hard work. I want to point out that even those of us that have been using Go for a long time find it valuable to have a feed of interesting Go content to explore! CuratedGo isn't just for the new comers. You provide a valuable service to the entire community. Thanks again.
Made the rhyming library myself using Go in a means to learn when Node was too slow. Feedback would be appreciated!
You can build a shared library in Go [1] and then call into it with ctypes from Python [2]. But if marshalling really is the bottleneck stopping you from a multiprocess approach, my bet is that you may still have performance problems and overhead interacting between Python and Go. [1] http://snowsyn.net/2016/09/11/creating-shared-libraries-in-go/ [2] https://docs.python.org/3/library/ctypes.html
thanks. i dont get it though? 
I'd go with something similar to Ozzy.
Thanks for the links. I'm somewhat concerned about the overhead of calling between Python and Go as well, but the problem is that there is a large Python data structure which needs to be operated on. If I can avoid marshaling that data structure and instead reference it from Go, then I'll save the marshaling cost, and if I can make only a few calls between Go and Python, then hopefully I can mitigate the overhead as well.
You could also have your python code call a go binary to run in a new process. The go process could be provided all the data it needs to fully run without further communication and the calling process will be notified when the binary is finished running. Not sure on the performance overhead of this. Probably really depends on how much information you need to pass back and forth. If its suitable for the go binary to perform it's effects as side effects then you may be able to just wait for the binary to finish successfully and then continue via a callback in your python code without rebinding the data. I perform something similar but reversed on one of my machines for library access. I need to use a ruby library but my server is written in go. So I have a ruby script that I can pass a few command line arguments to and then I simply call the script from my go process. If I need to pass some data back I send it on standard out and read it in golang once the process finishes. For you the same approach in reverse may work out if you can minimize the necessary communications.
Just tossing out ideas, but could the structure live in a Go process and then be operated on via an API from Python? Or possibly live in something like Redis/SQL/Mongo where both processes would have access? I realize that there may be too much Python logic mixed into the data structure, but generally you'd expect the data to live closer to where the performance-critical code is executing otherwise moving it around will be an issue.
There is still a lot to be done. We won't see it in this release, sadly.
Atom. In the rare situation where I can't run Atom (looking at you, ARM Chromebook) I use vi.
Not OP but I've recently switched to GoLand and it's awesome. Have used vim, Atom, and Sublime with relevant plugins and GoLand just works so much better than them all. It feels like a proper IDE rather than just a load of plugins. Work pays for the license so there's that, too. 
Alas, the data structures between Python and Go are so dissimilar that the code for making Go use Python data structures directly would make using the Go `reflect` library look simple by comparison. That's even before we consider what the Go GC thinks of interacting with Python in Python's space. Plus, a non-trivial amount of Python's slowness is precisely the inefficient way it stores everything. If you wrote Go that tried to operate directly on Python's data structures, I wouldn't care to guarantee it would run much more quickly! You basically have a marshaling problem no matter what; the cost of shipping it across a network may actually not be that much by comparison.
It is a fun experiment, but pulling up syntax into function handlers like that creates two separate layers in the code, an inner and an outer platform, and there's very little that can be worth that enormous cost on a language. And let me both start and end with how good it is to experiment with this sort of thing; I'm not saying this was a bad thing to do.
Uhhh... one does not preclude the other. As you think about your code next time think also about expanding your vision of the right tool at the right time. You know to encourage that thought just used these old cards I have to work out your program flow. ;-) Seriously, we know what you mean but your comment does not appear as an HO. Masybe just not enough non-toy projects going on in the world.
&gt; the cost of IPC/marshaling seems to prohibit a multiprocess approach The Linux kernel manages to pass data between processes at gigabit rates. Exactly how much data are you passing?
HTML scraping is always going to break if they change their HTML. Regex isn't going to change that. Sure, in production, regex for HTML is error prone. That being said, for a fun project, who cares? :) Nice work!
Using `val.(int64)` is a *type assertion*. With it you are saying that the interface{} is really an int64, however in this case it is a float64. Using `int64(val)` is a *type conversion*. With it you are saying "take this value and convert it into an int64".
I think you should consider using something like [Cython](http://cython.org/) instead. If you're not familiar it lets you write a hybrid of Python and C code, the file is then compiled to a C-extension which can help improve performance.
Cool, support for 56 new emoji 🤓
Maybe gopy could help you? It can now generate Python modules from Go packages (generating a .so file + the ctypes file to expose a somewhat pythonic interface.) https://github.com/go-python/gopy 
Thanks for the suggestion, but I'm wary of investing in Cython. I expect whatever language we choose to gradually eat away the Python (our performance requirements are projected to grow more severe) and I would prefer to have a large Go code base to a large Cython one. It may still prove to be the best choice, but I want to evaluate other options first.
The cost is (de)serialization, not moving bits. We attempted to parallelize with multiprocessing, but the time spent pickling neutralized our gains. Unless there is a faster serialization format, I'm not sure what to do.
Pickle is a terrible serialization format. There are many others (all with different tradeoffs, of course): A sample: https://github.com/alecthomas/go_serialization_benchmarks
Unfortunately the structure is convoluted and largely undocumented. I don't know what permutations it would have, so I can't very well rewrite it in Go (not in its entirety anyway). I was hoping that there might be a way to rewrite known chunks and wrap those chunks in Python interfaces where necessary, but I'd have to take care not to let it point into Go-managed memory. I'm open to suggestions.
Lisp
i do not check twitter alot is it possible to get the feed on facebook/ fb messenger bot 🙄
The C++ specification is actually a pretty good resource for understanding why Go decided against such magical constructs. C++ is the poster boy over an overly-complicated language spec resulting in hard to understand code. Find a large C++ class without comments, with lots of magical constructs and try to explain what it is doing in plain English. Now do the same with a large go file. Unless you are a C++ wizard you probably had a much easier time with the go file. Usually magical constructs will save you some typing / repetition but at the cost of being less explicit and harder to understand at a glance. When you consider you probably spend 10-20% of your time writing code and the rest reading, understanding, and maintaining code. You probably should prioritize understandably over minimizing keystrokes. I can read well written go code as if it is plain English. There is less magic happening during each given line of code. I need to know a little bit about the run-time and the built in function behavior and I am mostly set. The same cannot often be said of C++ code that uses many magical constructs. Often you need to know under the hood details of how all these magical constructs interrelate to get the full picture of how the code will function. Granted if you are a C++ expert you may like the fact that you don't have to repeat yourself and there is less boilerplate required for some functionality. But the first time you get bit by a magical construct / overloaded operator / and or spend hours trying to find why something is misbehaving because of the loss in explicitness; you may reconsider. Also consider Go was designed to be friendly to new programmers, and allow programmers to easily inherit code from other departments/individuals. The more straightforward and explicit the code is, the easier it is for someone else to read and understand it. If I gave a newbie / 3rd party programmer code that depended on operator overloads, multiple inheritance, constructors / deconstructors, etc. I would expect them to be more likely to overlook something than if I gave them line by line imperative English instructions. Hence we can see why the go programming language was designed to look conversational to humans but compile down to machine code for the computer. 
If that's the case your best bet is to just re-write your Python code to Go (or whatever other language will work for your use case). There are several companies that write highly performant code in Python at scales that most applications will never reach. I would recommend watching [this video](https://www.youtube.com/watch?v=_1MSX7V28Po) from a developer at Instagram talking about Cython and how it worked for them. IIRC he goes over the good and bad.
Which one?
Alternatively instead of jwt.MapClaim use your own type with concrete types and pass it to ParseWithClaims. Usually this is the correct approach.
Calling out named return values in Go vs C++ specifically- you have useful and most importantly consistently defined zero values for values in Go. In c++ you do not, which aside from each language having completely different philosophies makes comparing tradeoffs across each language into some quantifiable metric more difficult. 
FYI, I noticed this in your example: func (ic *IntContainer) Put(elem int) { (*ic).Container.Put(elem) } (*ic).Container can be written just as ic.Container ... go auto-dereferences the pointer as needed. 
What is your criteria for "terrible"? The reason I mentioned it was because I would expect it to be at least *performant*, and if we can't get good performance marshaling with pickle between Python processes, I wouldn't expect to get significant performance from a different format. I wasn't proposing using it as a serialization format between Python and Go.
I've used it. It lags a bit behind the native compiler, but I've used it to compile a few of my apps and they run just fine. I tend to not use cgo so there really isn't much advantage gained by using it oher than file sizes, gccgo compiled apps will dynamically link against glibc and knock about 5.5 megabytes off your executable.
Yes, I know this is old. I fell down a rabbit hole when watching videos from dotGo 2017. I followed Youtube's "view next" links and picked up a reference to this talk in a talk by Dave Cheney. I really liked this talk and just wanted to share in case somebody else had missed this as well.
It feels like boilerplate and it gives you no stack trace
&gt; I would expect it to be at least performant For specific applications, perhaps, but obv. not yours. Sounds like you need to make a CPython extension to do your serialization on the Python end, then pass the context to Go.
Presumably the popular serialization libs are already in C? Especially Pickle.
Your're right, thanks for pointing this out. Guess I use pointers too often in situations where dereferencing is not automatic...
Nope. In Python 2, there is pickle and cPickle. In Python 3, importing pickle will try to import cPickle or fall back to regular pickle. cPickle claims to be "up to 1000 times faster". It might be worth checking whether you're actually loading cPickle.
The receiving end has to read the value using binary.LittleEndian.Uint64()
True. But on the flip side you can program with it and add context.
I'm with you there. I find it much more approachable than the 'exception' of the Java world. It was a little odd at first, but I feel like it really fits the language.
Thank you very much!! I started reading more about conversion, and it seems simpler to do this: // UIntToByteSlice is a helper function to convert down to byte slices to add to the // RabbitMQ stack func UIntToByteSlice(num uint) []byte { str := strconv.Itoa(int(num)) return []byte(str) } And now on my receiving end I just grab the ID and do `string(ID)`. 
&gt; I'm planning to, why're you ~~asking~~ buying?
I miss Result/Option from Rust or Either/Maybe from Haskell.
Go's way of returning a result and an error is a poor version of a `Result` type.
I would put the message in a struct and use json, or use the binary package if performance is a concern. Well formed standard encoding scheme is “simpler” in my opinion.
I think you need to look at Go a bit differently, something that goes back to the initial development. The initial authors had a policy of "anyone can veto" -- so features were easy to keep out and only got in with unanimous consent. That doesn't mean it was mistake free, I think you can find a lot of mistakes (I find named returns among them personally) but it explains why feature $X was more likely NOT to be included than included. "Go is a language made of grumpy-old-man rage" esr.ibiblio.org/?p=7724
[Rob Pike - Simplicity is Complicated](https://youtu.be/rFejpH_tAHM) explains why a lot of the decisions around the architecture of Go were made.
Because its made for "programmers... not researchers... not capable of understanding a brilliant language" -- rob pike http://nomad.so/2015/03/why-gos-design-is-a-disservice-to-intelligent-programmers/
You might want to say what library you're using.
What's the benefit over just using the built in TLS libraries? I'm kinda skeeved out by a custom crypto protocol with no security audit visible
tl;dr thought experiment on integrating error/panic/defer. Refs: github.com/mpvl/errc github.com/mpvl/errd
Any other solutions in this thread won’t be as clear or as good as what you wrote OP. Don’t over think it.
Alright :) 
Hey, very cool idea. You may be interested in the new [metaparticle](https://metaparticle.io) project announced at this week's kubecon. [more info](https://venturebeat.com/2017/12/06/kubernetes-cofounder-launches-programming-library-to-simplify-cloud-native-development/).
thanks bro :) I would be happy if you could reward me a star.
That does sound better as it enforces a standard on both ends. Will do that monday!
Would be nice to have variables in there too. You cant evaluate these asts until the user provides an instantiation of the variable, but it would probably be useful if someone builds an app around your library. 
Does the regular compiler not have something like LOT? Or is it the runtime itself that needs 5.5 MB of libc?
I’ve used it on some occasions to investigate or confirm bugs in gc compiler.
Maybe he should use ruby or python. 
[removed]
&gt; This is an experimental project and it can break things. What things can it break? I mean, is it just that an install may fail occasionally, or can this extension potentially damage my existing brew installations? I would be curious to try this extensions but I would like to have a rough idea about possible implications... :)
Thank you! I wish I had more of an insider view about Go from back in the day. As for C++ my experience was negative with it also, as I am also not a fierce advocate of all that complexity. PHP makes OOP look easy, but in the end it also doesn’t have a lot of things other than constructors. inheritance and interfaces bound to a class (unlike the Go unbounded ones). And namespaces. And static methods. Whatever.
Thank you, exactly what I am looking for. :)
Survey has ended.
[removed]
To be fair the author is a well known cryptographer. 
For a more serious answer, check: https://www.youtube.com/watch?v=5kj5ApnhPAE
Meanwhile, the author of that article is now writing Go. How delightfully ironic. About Pike's comment, Pike gets a lot of hate for this but for everyone who gets this personally and thinks "Pike is calling me an idiot", I challenge you to think of the times that you were put to work with inexperienced or plainly bad programmers. You can do extra work and teach them or ignore them and wait till they learn but the fact of the matter is that if something could make those programmers even mildly effective, that's a huge boon for everyone on the project/team. Large software cannot be built by one person at least not in a reasonable amount of time.
Variables are a great idea! I tried implemeting them here https://github.com/relnod/calcgo/pull/4. Currently I can only have integer variables, because I'm not sure, whats the best way to pass both integer and float variables to my interpreter. Currently I pass my variables to the Interpreter like this: result, errors := calcgo.Interpret("a", map[string]int{"a": 1, "b": 2}) The Interpret function now looks like this: func Interpret(str string, variables ...map[string]int) (float64, []error) { Is there a good way to support both integers and floats like this?
go jwt . https://github.com/dgrijalva/jwt-go
What it does is just generate a temporary brew formula and runs brew install formula, which go-gets the tool into a separate GOPATH in the brew's cache directory and runs the go install into brew's bin directory. Hacky but simple. But putting a warning notice in the readme I only meant that I'm not a brew internals expert (neither ruby developer), so I'm not yet sure how the cmd aligns with other brew's things. It works with my test cases :)
Thanks for replying! Guess I'll give it a try. I like the idea of brewing directly from Go sources.
Glad to read it! Feel free to fire up an issue or a PR if something worked not as you expected.
Go's compiler has to include the runtime plus any libraries you use. gccgo can provide the runtime and standard library externally. Also, gcc is a much more mature compiler and as such should be expected to compile "better" binaries. The expectation is that a gccgo binary would be smaller and faster, and be able to take advantage of more cpu features of the target.
I love it - though something I think would be a little more powerful would be a YAML file to list your namespace, context etc. Currently we store our kube manifests with our applications so its fairly easy to build and deploy as one.
Or he can even try protobuf. :)
[removed]
I dont know any unfortunatly. You could make the input floats and require the user to cast ints to floats but that is a bit ugly too :/
Glad to help!
Even in ruby or python code checking if object has an attribute is considered stinky.
Isn't your benchmark assumes a split stack? (And not the currently used continues stack) Also, why not use the Testing library for benchmark?
I just morphed the one from the original continuous stacks doc. You can do another benchmark yourself to see what happens. Usually, yes, I'd use testing.benchmarks.
I guess a rust fan didn’t like your post. Leave a comment, cowards! Have an upvote, I thought it was interesting. 
At my organization, we call this pattern a "type guard". If there's an official name for it, I haven't heard it, and I'm convinced that properly naming things is a prerequisite for effectively using them. Further still, I'm convinced that most of the bitching about `ingerface{}` stems from the fact that this pattern often goes un-articulated, and therefore remains under-exploited.
thanks for sharing this so script kiddie like me can learn it
I think he's right, by and large. Rust's advantage dminishes quickly as the task's complexity increases. I've ported an Earley parser from C to Rust, and it works almost as fast as the C version. I had to pull a few ugly data duplications to get it working (after trying a gazillion life-time options), but that's fine. However, there's no way I can get my shared forest representation in the Rust version without using "unsafe". In Go, it's a doddle. Go still feels a bit sloppy to me, but it's the most productive language without serious drawbacks for very many tasks. Perhaps (something like) Kotlin can be a contender.
While Go improves on C, Rust is an improvement over C++. Both have their purpose. The author is no entirely correct about D though as `dmd` (compiler) became open recently, i.e. no longer proprietary. We'll see if that gives the language more exposure.
I think you're right that Go is one of the most productive languages for a lot of tasks. But I think the same holds true for Rust. The problem space where they shine just doesn't overlap a lot (at least at the moment). Places where I think rust shines are: - Programs/libraries requiring extreme performance (databases, web browsers, but also things like `ripgrep`) - Programs that need to operate with C/C++ libraries - Highly reliable code (Go's type system is just not good enough to achieve this) Also, using "unsafe" Rust is not a problem in itself, sometimes it's just needed. Go its regular mode is basically comparable to Rust its unsafe mode, when not doing too weird things in unsafe mode. 
I feel a little disappointed that he didn't mention interfaces. I suppose in this case it was impossible to find common methods for all types and create interfaces from those but I still would have appreciated it if it was mentioned as an examined solution.
Subjective but reasonable enough options except the reliability one. The very last thing I think after compiling an idiomatic Go program is “I wish this was more reliable”. What about Go’s type system makes it unreliable? If your answer is eface than what is missing from the type system for reliable usage? Between type assertions and type switches I’ve never found reliability to be an issue, comma ok and return an error. Assuming the use of eface is correct to begin with of course. 
The things I miss from Rust its type system when trying to write reliable code in Go (in no specific order): - Non nil-able types, dereferencing nil is the main source of panics I get when using Go - Sum types for error handling. It's really nice to be sure that you didn't forget to handle an error that was returned. - Actual enums, not custom int type that can still be the full integer range. So you always have to handle the case where it isn't any of your constants. - Not using empty interface for custom container types. This can be worked around with by using code generation, but I wouldn't call that a nice way of writing code.
Great talk. The presenter got a lot better performance by simplifying the problem, handling errors at runtime instead of pawning it off to the compiler, and architecting the problem to leverage the structure of the data to find commonalities I’m what’s being modeled. Sounds like great programming instead of depending on too much on generics and not wanting to write too much code. 
what about javascript though
A thing I miss: * In go its not that hard to get a race condition when using goroutines, while it is almost impossible to get a race condition in Rust
&gt; If you’re testing function Foo, you can’t use Foo to verify that Foo works! That’s just nuts! lol
Go rather improves on Python, not C – it would be an improvement if it was aimed for the same niche, but it is not and it just can't.
A language in which you can write if (somecondition) { class.prototype.member = anotherfunction; } does not count as a good language. It also lacks in other departments, such as multi-threading.
Javascript sucks, that is enough.
That looks pretty good, that’s the first thing I’ve seen Go related in Oklahoma for a meetup.
I don't see any of these as barriers to writing a highly reliable Go program. They are part of the list of trade offs that come from the difference in design between these two languages. Idioms exist for everything in your list, some of them may require developer discipline in place of syntax. But this comes quickly along with the appreciation for not having the arduous engineering cycles imposed at ground zero by Rust. My point here is trade offs do exist between the design of Rust and Go, but writing highly reliable software isn't one of them.
https://github.com/taylorchu/generic#gorewriteyaml-reference This is the tool I developed to tackle the same problem. The difference is that you can write go package code (instead of template) to generate go code. And the whole thing uses the go compiler to reduce runtime overhead.
Writing concurrent code in Rust is at its infancy. `tokio`attempted to cover underlying complexity by introducing all kinds of new complexity. The fundamental issue is that Rust's borrow checker is having trouble reasoning about concurrent code. So one gets limited concurrency, no green threads, and, hence, no race conditions.
that happens a lot more than you'd expect
It was an informative article. Thank you for taking the time to write it out and share it.
Thanks! I have seen a tool like this (maybe it was this one), but couldn't find it anymore. This is exactly the way I want to program "generics" in Go most of the time if at all. 
You got that wrong. No race conditions is because of the type system (that's what we are talking about). Tokio needs some time to mature, but there is rayon today - which is easy to use and 100% save.
If there are no common methods/interface generics won't help at all because you'll have to build some Collection&lt;object&gt; and `object` is no better than empty interface. With complex geometry I would go in a different way: multi-polygon is a set of geometries with "add" operation while a hole is a polygon with "subtract" operation. Same for multiple lines - only "add" operation applies. Don't know though how that would work for in context of desired functionality and performance. But it would make everything more consistent and universal, no need to generate derived types.
Type system has nothing to do with race conditions. I do hope Rust gets concurrency right: safe and easy to use.
Try TypeScript?
sasha-s/go-inline? 
nw, feel free to ask any questions
Despite your downvotes, this is accurate. C developers have for the most part not transitioned to Go, but Go has absorbed many Python and Ruby developers.
There's a LOT of painpoints with handling errors and type checking at runtime tho - namely performance related stuff. A key advantage of a lot of type systems (go's included) is erasure - after checking at compile time, the checking code at runtime is erased, leaving a codepath that will never be traversed (unless required by say the reflect package). This leads to higher performance in general
I agree mostly. Rust for lowlevel and/or really fast code. Go for most other things. When you say reliable code, I assume you are talking about safety critical code. Medical devices, industrial controls, etc. Is that a correct assessment of your statement? 
[WAT?](https://www.youtube.com/watch?v=VTE3DM2Aygk)
https://github.com/shurcooL/graphql is also another interesting GraphQL client for Go.
Shit stinks! Try typed shit.
People love to think they are writing low level, so these downvotes :)
I'm absolutely a Go fan and user since it was announced pre-1.0 (even a contributor), and haven't yet tried writing Rust, but still can't see how can one not agree with what Jelterminator wrote above. I'm working daily on a well-tested codebase, and totally confirm and know what Jelterminator is talking about the nil panics. We absolutely do occassionally get nil panics from some rarely used code, or incorrectly tested one (people are not perfect); also sometimes we catch potential nil panics only in code review. As to point 3 and 4, I also understand the sentiment, though I can't recall now if we were actually bitten by panics from those sources at any point.
First of all, developer discipline is not a replacement for enforced constraints IMHO. I mean why have static typing at all when you can just tell developers to only use the correct types everywhere in a dynamicly typed language. Secondly, except for my last point (containers) I don't know what tradeoffs you're hinting at. Especially non nil-able types doesn't have any downsides as far as I can tell. Except for implementation cost and needing some other way to have a None type (like sum types ;)). I hope I'm clear that this is not a rant against Go (I use it with pleasure 5 days a week). I'm just trying to point out the problem spaces where Rust shines. 
Kotlin has one major drawback: the Java VM and library overhead... I can't see myself writing microservices on a Java VM: just too damn much overhead.
Yes, but also code that should basically never crash or reach inconsistent state (like kernels or databases). 
Yup. Just removed add a stickied post.
There are plenty of reasons not to use the JVM, this is simply not one of them. It's right up there with "you have to use threads for concurrency", both of which usually indicate a poor understanding of the runtime and the JDK. 
&gt; First of all, developer discipline is not a replacement for enforced constraints IMHO. I mean why have static typing at all when you can just tell developers to only use the correct types everywhere in a dynamicly typed language. First of all- I said no such thing, lets review: &gt; Idioms exist for everything in your list, some of them may require developer discipline in place of syntax. But this comes quickly ..... I am simply presenting that I believe most of the drawbacks in your list are mitigated by common idioms found in Go programs today. I inserted a comma and made certain to acknowledge the fact these things require developer discipline in place of syntax. I presented this as a "cost" and this should be clear as I go on to justify this cost by saying I believe they are easy disciplines to pick up which and present this process as a good trade off verse the more arduous engineering needed for rust. Perhaps instead of racing through to find something to disagree with you should slow down a little and focus on the things that truly don't align with your own conclusion. This will prevent needless slights that don't contribute to technical discussion like "oh why use static typing hah, got ya!". &gt; Secondly, except for my last point (containers) I don't know what tradeoffs you're hinting at. Especially non nil-able types doesn't have any downsides as far as I can tell. Except for implementation cost and needing some other way to have a None type (like sum types ;)). Non nil-able types would be the entire set of types which do not have a zero value of nil. The only different is syntax and constraints. But if your goal is to write highly reliable programs and feel non nil-able types is the only way to achieve that, you can: type AlwaysMap struct { m map[string]int } func (a *AlwaysMap) NeverPanicHighlyReliable() map[string]int { if a.m == nil { a.m = make(map[string]int) } return a.m } var plz AlwaysMap everythingIsOkay := plz.NeverPanicHighlyReliable() // scale up infra But you don't see such code because it's not a problem in practice. Even day 1 developers trying Go for the first time quickly learn the common NewT()-err check idiom. I like Rust, I think it may be better in many problem spaces, but writing reliable software as a blanket statement I can't agree with considering it's one of the most important aspects of software engineering. I don't think you will be able form an argument that will allow me to concede so I'll agree to disagree. Take it easy.
All of his bullet points are the same exact thing, I want an extremely rigid and verbose type system. If you implement all those things in Go, you no longer have Go, you have Rust. Regardless none of those things prevent writing highly reliable Go programs today.
 Generally speaking, going for code generation is definitely not the first thing ones does. Attempting to write clean and idiomatic Go code using interfaces should be the first attempt. If that is impossible then other solutions can be examined. My point is that I'd expect the author to mention why interfaces didn't work before he jumps on to code generation. Or it could even go the opposite way. The author gradually simplified the problem. So once he talked about finding the common behavior I was expecting the last "level up" to be the usage of interfaces. But in any case, I have to assume that the author has done enough research on the problem domain and has concluded that the way they chose was the best. 
&gt; Even day 1 developers trying Go for the first time quickly learn the common NewT()-err check idiom. Hmm care to elaborate on this idiom? I wasn't aware it was a thing. I mean I do know about `NewT()` but I wasn't aware it was idiomatic for it to return `err`. In fact I thought the idiom was that `NewT()` returns `*T`.
I thought there was a way to get the Twitter feed via RSS/Atom but I couldn't find it. However, I'm currently working on having each tweet show up on a new website, so I can always add a feed there. Thanks.
Hey, thanks for your comment, it makes me happy that you get something out of it. I guess that's what it exists for.
That's great to know since sometimes I think it's mostly beginner friendly, but I'm glad more experienced devs get something out of it too. Thanks for the confirmation.
Python, Ruby, Java guy here (mostly). . . this is true for me, there are many use cases where I choose Go now. However, I prefer Python for quick and dirty scripts, CI/CD tasks and anything small where I need to parse JSON or YAML. I cannot stand parsing JSON or YAML in statically typed languages unless it's for a big project/application. I love scripting languages to just take the text and turn it into a hash/list/scalar mix.
You're being kind.
Sure, if the [constructor for a composite literal](https://golang.org/doc/effective_go.html#composite_literals) of *T may fail resulting in the zero-value of nil than the function should return a second parameter explaining why the failure occurred. This is all over the [standard library](https://golang.org/pkg/net/http/#NewRequest). Which really it's just a natural consequence of the fact [errors are values](https://blog.golang.org/errors-are-values) and not really specific to constructors. If something can fail it should return an error so it may be checked by the caller, correct constructors along with responsible callers make the occurrence of an NPE near-zero in my experience. Since this idiom is so common it's pretty much a compiler error to not check a value in a constructor, since: t := NewT() // multiple-value NewT() in single-value context Is more or less an immediate signal that I should: t, err := NewT() if err != nil { return err } The language is so minimal there are very few ways for people to be creative and make "new" patterns for creating values objects. This is why I like Go.
&gt; The expectation is that a gccgo binary would be smaller and faster, and be able to take advantage of more cpu features of the target. Did you find that to be true (in real-life testing)?
Great laugh
Take a look at - - https://medium.com/@farslan/ten-useful-techniques-in-go-ddd94296c21b#.6xai61cyd - https://peter.bourgon.org/go-best-practices-2016/ 
thanks!
It defaults to home directory/go these days. You can set it to anywhere you want though
Those aren’t mutually exclusive. Rust manages memory with a substructural type system (see: [Affine Types](https://en.m.wikipedia.org/wiki/Substructural_type_system#Affine_type_systems)).
I’m unaware that there’s two paths to set, for “Global” and “Projects.” If by “Global” you mean $GOPATH then stick with the defaults. Your projects will reside under $GOPATH/src — the official docs cover this.
i thought the local devops group under techlahoma might have more golang talks, but that hasnt been the case i’ve seen so far. do you currently use go at work?
I do, but it’s I’m not really in a developer position. I’m in a IT position working on network related stuff mostly.
Have you ever tried to run micro services in a JVM? Did you run 22 JVM's? Or did you wrap them up in one fat JVM? How did memory management go in the first case? 
Dropped the usage of go-guru, so performance got much better (it generates the code instantly).
I developed a tool to generate Go code from Go code and specialize it, instead of relying on templates (https://github.com/dc0d/goreuse).
If gometalinter has no such linter yet, it should get included.
&gt; What about Go’s type system makes it unreliable? I'd like sum types. 
&gt; Highly reliable code (Go's type system is just not good enough to achieve this) There really aren't any great mainstream choices for this at the time. There's a lot of really interesting research (Idris, ATS, etc.) but none of it is ready for primetime yet. 
You could require a special header in your api but that would be security by obfuscation not real security. Is it bad that someone else could use your api without your website? 
If you haven’t already found: try this guide, it explains a lot about Go‘s approach and how it should be used. https://golang.org/doc/effective_go.html I suggest some YouTube talks of rob pike as well. 
If you need to set the GOPATH, then go to Settings | Go | GOPATH. There are a few options: - Global GOPATH: this allows you to configure a GOPATH (which can have multiple values, of course) for all the projects you are using the IDE with. You'll configure it once and reuse it across the projects - Project GOPATH: has the same properties as the Global GOPATH but this one applies only to the current project. This means you can configure different GOPATH values for different projects. To configure them, simply click on the green ` + ` button on the right side of the configuration panel.
What if i wanted to add and edit posts in my site.Wouldnt that allow everyone to add and delete posts in my site.Sorry if i am missing the bigger point,but i am trying to see how people use the api to connect with their backend.
Noise is already used by WhatsApp and Wireguard. It was designed by the guy who also designed Signal's end-to-end encryption protocol, which is the most state-of-the-art in encrypted communications today. He was also inspired by DJB's work (like the work he did on NaCl, from which libsodium was later born) when creating Noise. The NCC group is is a well known top-notch cryptography auditing firm.
Is the "testing/quick" package being frozen a sign that it's not really meant to be used by new projects? Are there some actively maintained alternatives?
Ah, you would need some athentification for your api then
If you don‘t expose port 8080 to the internet only your website can use the port from the private ip. Or add basic auth for the api
Thank you for this, pretty cool
&gt; All of his bullet points are the same exact thing, I want an extremely rigid and verbose type system That's *your* strawman representation of what they wrote. An expressive type system that doesn't force you to e.g. use the equivalent of void pointers and reflection doesn't have to be "rigid and verbose." Look, we're probably all in agreement that Go is a "get shit done" language, but I don't understand this completely irrational fanboyism where any sort of criticism of the honestly quite simple type system is some sort of call for "rigid and verbose."
Wait what? Overriding these is even possible?
Would also be useful to find redeclaration of packages; e.g.: ``` import "net/mail" [..] mail := "test@example.com" ```
syscall.StringToUTF16Ptr will do the job here. It seems this function is deprecated, the syscall package has a function with a very similar name that will return both the wide string and an error. The syscall package is pretty dead for these types of functions, I recommend pulling from golang.org/x/sys/windows That has UTF16PtrFromString. As far as Windows specific stuff alike always on top I am not sure, only thing I ever did was open a window and draw in to it haha.
This rather tells about your very limited experience. Go type system is nearly sufficient for network interaction processing indeed. But it is totally inadequate when the logic becomes more tricky. In this case you need generics, algebraic (sum) data types, non-nil types, etc.
Thank you,thats helpful.So,the website calls localhost:8080/api/blahblah right?
The syntax and semantics can be terse with dedicated support on certain types (Result and Option). For instance, error handling with algebraic data typing (Result type can be either result or error): ``` file := os.Open(name) if !file { // file has error type in this branch return file } // file is an actual file here ``` And this will not compile ``` file := os.Open(name) scanner := bufio.NewScanner(file) ``` There should be no nullable types semantically, but there should be null value and there should be option types that can be either a specific value of a type, or null. In Rust these types has compiler optimization which represents them as just a pointer, where value 0 means null and others means actual value. The bad thing with Option in Rust is heavy branching which leads to ladder code. But it can be done easy, just like in case with Result: ``` fieldValue := object.StringField(name) if !fieldValue { return } // fieldValue cannot be nil here, so process string returned ```
Yep if my opinion is different than yours it must just be my expierience is limited. Such tacky and childish statements are only made by engineers young in their career or narcissists who haven’t gone anywhere in theirs. Which are you? Anyways, Does the language the Linux kernel was written in have generics and algebraic data types, non nil-able types and etc? I don’t know enough about computers yet to know for sure. Hurr. Durr.
Sure: https://play.golang.org/p/O5ULfYGOb4
Kotlin seems to have a native compiler, though still in early stages.
I used it and don't like it. Because it is not compatible with standard middlewares. I made transition to gochi.
[removed]
starred, thanks!
It’s not a straw man, it’s a list containing the largest differences of the type systems between rust and Go. You do not agree? What other big differences does rust have that Go doesn’t that makes my statement inaccurate? Or perhaps you don’t think rust is a rigid and verbose type system, in which case computer science does not agree. Regardless this isn’t me being a fanboy, I’ve made no mention of my preferences for any of those features he listed and if they should be in Go. The truth is people feel so passionate about them they are missing the only point I continue to regurgitate. You can write highly reliable programs in Go today. I know this because people are writing highly reliable programs in Go today. People are writing highly reliable programs in Go despite the missing features the person I replied to declared as barriers to do so. I only tried to outline the idioms I see in use to compensate for these lack of features, while I did make it clear I find these idioms a fair trade off from the other affects such features have on a language. Nothing more. Nothing less. I am writing highly reliable software in Go today, as are many others. People can feel hurt and passionate about generics and language Y feature X, I don’t care. But if you think X is needed to write highly reliable software you are wrong, measurably so by the large evidence in the form of software you are using daily written in Go.
Can confirm, even small teams can turn a well-structured project into a big ball of mud with stunning efficiency. Large JS projects (yes, even "modern" React and otherwise ES2017 projects) will always descend into chaos. TypeScript is an *okay* guarantor against this but it's generally opt-in, so that only papers over the issue.
Nice code. If opening a file fails just return to the caller that it failed with no error reporting why. So you need sum types. Then you need generics. It sounds like what you “need” is to use rust, oh great experienced one.
&gt; Does the language the Linux kernel was written in have generics and algebraic data types, non nil-able types and etc? This is really poor argument 1. Code in OS kernels is (and it must be) quite simple. 2. Linux is full of bugs and regressions. 12309 is one of the most annoying ones, don't know if they finally fixed it (12309 appeared in 2.6.18) 3. You can move 1000 tones of sand with a shovel and wooden card, but would you if will have dump track and excavator?
what the fuck
I need them much more than generics :)
MUCHOS GRACIAS
1) Code in OS kernels is quite simple.. the Linux kernel is simple...? Ugh. So what is complicated to you? 2) Bugs are a natural occurrence in software engineering, they happen in languages with or without the features you listed. 3) What? No wonder you insulted my experience, when left to form real arguments you result to calling kernel development simple and buggy with a side of sand castle theory. Really odd conversation here. I got no interest in continuing sorry, happy coding though.
I've done this about a year ago and it worked pretty well. https://github.com/while-loop/competitive-programming/blob/master/collection/go/Stack.go I would suggest you also wrapping the Get() function to be able to use the int without the need to assert in situations like: sum := 3 + cont.Get()
You eat nothing gooder than grits boy. `file` is `!*os.File`, i.e. it is either an actual `*os.File` or an error, you can branch between them with switch file { case Error: // in this case the file has string type (branch Error) default: // file is *os.File } or with proposed compiler intrinsic.
Actually, I like TypeScript. It still has drawbacks, but it's much better than JavaScript. Recommended if you ever have to do something browser-side.
I remember there was a java to c compiler once. Once kotlin has a native compiler, I'll have to take a peek at kotlin :-)
Yep. I normally do setup some kind of reverse proxy like nginx or apache to handle https and forward to the ‚website‘ and then the website calls the api on the localhost 8080 just make sure the api is not listening on the public interface. Look into „ bind to localhost“ Otherwise you can do a basic authentication with nginx or apache on your api so internet facing api needs a user/passwort and no authentication on localhost. This is a config option for nginx or apache. 
But how will you restrict users on your website to not abuse your website links? 
Looks good to me. See [SliceTricks](https://github.com/golang/go/wiki/SliceTricks) for idiomatic ways to pop/push etc.
Ask and you shall receive. https://golang.org/doc/faq Why does Go not support overloading of methods and operators? ¶ &gt; Method dispatch is simplified if it doesn't need to do type matching as well. Experience with other languages told us that having a variety of methods with the same name but different signatures was occasionally useful but that it could also be confusing and fragile in practice. Matching only by name and requiring consistency in the types was a major simplifying decision in Go's type system. &gt;Regarding operator overloading, it seems more a convenience than an absolute requirement. Again, things are simpler without it. 
Do you even understand what generics is?
No, so please oh wise internet persons, explain them to me. 
I don't know if using a RESTful API is the best choice,but i can't find another way for the front-end to communicate with the back-end.As i said in my post.For now,i want the user to enter a url in my site,send the url to a .go program,download the video,and return the download link.But i don't want that to be publicly availabe like api.example.com/video/videourl.I want it inhouse only.Is that sort of thing achievable?Am i going about in the wrong way?
Okay- so just to recap, you want to change the standard libraries os.Open method from: func Open(name string) (*File, error) To: func Open(name string) Result&lt;*File&gt; So that you may write: func loadRecords(filename string) error { f := os.Open(filename) switch T := f.(type) { case Error: // in this case the file has string type (branch Error) return T // Allowing default would make code much more difficult to read, I would have // to crawl up the call chain to determine what the T of a default case was. // This is why Rust, does not have a "default" so if you are going to borrow // from another language at least do so correctly. The closest thing to this // in Rust is the underscore as it serves as a placeholder for any value, but // it receives a value of the unit type (). case *os.File: defer T.Close() return processRecords(T) // Oh look, semantics of switch statements changed too, I now need to know // the full signature of os.Open or compile my code to know if all the cases // here are covered. Reading code just got more obnoxious. If there is a // return statement below than it gets even worst. // // I guess that is what happens when your am in a complex feature from another // language into the basic conditional control flow of another. } return nil } Which to be fair when you remove my comments annotating your errors, is a little bit shorter: func loadRecords(filename string) error { f := os.Open(filename) switch T := f.(type) { case Error: return T case *os.File: defer T.Close() return processRecords(T) } return nil } Because you feel that the below prevents you from writing software beyond "networking": func loadRecords(filename string) error { f, err := os.Open(filename) if err != nil { return err } defer f.Close() return processRecords(f) } Based on the premise of: &gt; Go type system is nearly sufficient for network interaction processing indeed. But it is totally inadequate when the logic becomes more tricky. In this case you need generics, algebraic (sum) data types, non-nil types, etc. Further supported by the fact that the Linux kernel not having these features, because: &gt; Code in OS kernels is (and it must be) quite simple. &gt; Linux is full of bugs and regressions. 12309 is one of the most annoying ones, don't know if they finally fixed it, but they couldn't do this for years (12309 appeared in 2.6.18). &gt; You can move 1000 tones of sand with a shovel and wooden cart, but would you if will have dump track and excavator? Which I am unable to understand due to my: &gt; This rather tells about your very limited experience. So I guess then I should just accept that Go should add **sum types**, **generics**, **patterns**, **which all form a massive dependency tree of other language changes to support them. For example how do you guarantee the semantics in patterns for reference types without introducing the concepts of RAII? You can't. You must be able to create static guarantees about the scope of a reference type. So any *T in go now has introduce the concept of lifetimes. Which means we will need explicit annotation for every constructor function we use today that returns a reference to a composite literal. This becomes verbose and painful so the immediate demand of lifetime elision emerges. On and on these dependencies emerge throughout the language.** All so you can write: f := os.Open(filename) Which instead of the following error from the compiler we get today when we forget to write 3 lines of code to check the error argument: multiple-value os.Open() in single-value context We can write 6 lines in a switch construct and enjoy the glorious reward in the form of a compiler error of: error[E0004]: non-exhaustive patterns: `Err(_)` not covered Which will give top notch engineers like you the missing edge you need while writing software more complex than the Linux kernel. Okay. Got it. &gt; If it is hard for you, then it is a good idea to switch a job, boy. Yes good idea, I realize now I'm clearly in over my head with this programming stuff. I really appreciate you being here to save me from my own ignorance, thanks! Honestly I got a lot of amusement out of reading your posts so no hard feelings, I have a feeling your trolling me and I'm okay with that, it provided me entertainment while I drank my coffee. Thanks. Happy coding man.
This article is poorly written trash. He doesn't back up and if his criticism with examples or reasoning, just states them as face and moves on. 
This is some of the most rambled nonsense I've ever read about Go and gets so many things wrong it's almost impressive. I don't even know where to start.
First of all, knowing the concept of generics doesnt make a programmer wise. I believe that its an introductory topic in CS. Look at Go 1.9 `sync.Map` docs, because Go has no generics, were forced to use `interface{}` which defeats type safety.
Type safety issues arise in Go assuming the person implementing the code doesn’t use type assertions or select statements to multiplex type specific work when using the empty interface. Remember the empty interface says nothing.
This way adding a new built-in won't break existing code.
Ohh
First of all, you seem to be operating under the assumption that a more expressive type system will always be hard to use and limit what you can do (assuming that's what you meant with "rigid"?). Expressive type systems *can* be more verbose (as you supply more information with them and syntax design is hard), but usually the more expressive a type system is, the *less rigid* it becomes. They often also allow you to offload complexity from the code, and do so in a *safe* fashion. Now, because Go's type system is extremely simple, there's not a lot you need to learn. There are no type hierarchies, there's no user-definable generics (but we do have `chan T` and `map[A]B`). This also means that if we want e.g. polymorphic containers (`sync.Map` anyone?) we're left with either using `interface{}` + possibly `reflect` (giving us runtime panics and overhead), having to write one-off boilerplate types, and/or `go:generate` fuckery. &gt; It’s not a straw man, it’s a list containing the largest differences of the type systems between rust and Go. You do not agree? What other big differences does rust have that Go doesn’t that makes my statement inaccurate? I definitely don't agree that that list represents the biggest differences between Go's and Rust's type systems, that's bordering on ridiculous. Go doesn't even have *subtyping*, let alone polymorphism, higher-kinded types, lifetime annotations, traits, what have you. None of the features is in any way even particular to Rust or even a new concept. Just because they're features that Rust has doesn't mean they'll automatically make a type system exceedingly complicated, just by virtue of being associated with Rust. &gt; You can write highly reliable programs in Go today. I know this because people are writing highly reliable programs in Go today. Nobody is contesting that. People can write highly reliable software in C, assembler, or physical switches. This does not mean some additions to the type system wouldn't make it *easier* to write reliable code. &gt; People are writing highly reliable programs in Go despite the missing features the person I replied to declared as barriers to do so. Again, nobody said that a simple type system is a barrier to anything. However, what people *are* saying is that there are a number of different concepts that could be added to the language to make it more expressive. ADTs for example could solve a lot of the problems we have with the language without making it ridiculously complex or even requiring something like subtyping. &gt; I only tried to outline the idioms I see in use to compensate for these lack of features, while I did make it clear I find these idioms a fair trade off from the other affects such features have on a language. Negative effects you *claim* these features will have. Personally I don't think Go should even incorporate things type hierarchies or generics (which would somewhat have to go hand in hand), but for example ADTs would fit the philosophy of the language and make a huge class of runtime panics re. runtime `interface{}` conversions much less likely, and reduce the amount of boilerplate required to do it safely. What would the negative effects of e.g. ADTs be? Right now we have to compensate for the type system's simplicity by writing error-prone boilerplate, and many of us think it could be improved on. This doesn't mean we want to bring in everything and the kitchen sink.
I was curious about the author so poked a bit. [This blog article from late November is illuminating.](https://medium.com/@ivanjaros/my-entrepreneurial-obsession-and-the-curse-of-perfectionism-d279bdd1466b)
I wanted to keep the modifications minimal but indeed wrapping the getters would be the obvious next step.
&gt; I'm convinced that properly naming things is a prerequisite for effectively using them. A valid point indeed. Which reminds me of this line from an old [Talking Heads song](https://genius.com/Talking-heads-give-me-back-my-name-lyrics): &gt; "...names make all the difference in the world."
Is it necessary to use ParseMultipartForm? Because FormFile is using it anyway.
Does predeclared provide useful exit statuses, for CI integration?
ANTLR and its tools are really great, but the Go code it generates is questionable (I mean it is horrible), I even thought to implement the Go target myself.
Yes. If the '-exit' flag is provided, the command exits with exit code 1 when issues are found. More details in the [exit code section](https://godoc.org/github.com/nishanths/predeclared#hdr-Exit_code) of godoc. Alternatively you could check whether the command wrote any output to stdout.
If only there were a feature that enforced that type safety at compile time instead of relying on all programmers writing flawless code. Since it would be guaranteed at compile, we also wouldn't need the performance overhead of runtime reflection for type checking/casting those interfaces. As an additional bonus, the person implementing the code could immediately understand the intent of the author! Maybe we could call that feature "~~Generic~~ Common Types".
That's neat. Is it possible to check this accurately without also looking at the AST of the imported package? The package name won't necessarily always be the basename of the import path.
Maybe a separate tool would be better since the issue isn't related to predeclared identifiers. :)
https://kotlinlang.org/docs/reference/native-overview.html
&gt; Is it possible to check this accurately without also looking at the AST of the imported package? You could probably regexp it with reasonable accuracy; but it's not the approach I would recommend. &gt; The package name won't necessarily always be the basename of the import path. Not sure if I fully understand what you mean with that?
This line will panic on file smaller than 512 bytes. filetype := http.DetectContentType(fileBytes[:512]) There's no reason to truncate data passed to DectectContentType. Call it like this: filetype := http.DetectContentType(fileBytes[:512]) 
Yeah, that's possible. The downside of that is that you need to invoke two tools and walk down the ast *yet again*. If you look at the number of tools/linters many projects already run with gometalinter... :-/ All these small tools we have in Go to check for a specific error are pretty neat, but it does come with a (performance) price unfortunately. Anyway, it's your project so you decide. Just an idea I had :-) Accidentally redeclaring package names is something I've actually run in to a few times.
&gt; First of all, you seem to be operating under the assumption that a more expressive type system will always be hard to use and limit what you can do (assuming that's what you meant with "rigid"?). Nope. I called it rigid and verbose, contextual hints from this statement and rest of my messages it would be more reasonable to conclude I meant **exacting** and **thorough**. But hey man, if you want to think I believe generics make a language less flexible feel free. &gt; Now, because Go's type system is extremely simple, there's not a lot you need to learn. There are no type hierarchies, there's no user-definable generics (but we do have chan T and map[A]B). This also means that if we want e.g. polymorphic containers (sync.Map anyone?) we're left with either using interface{} + possibly reflect (giving us runtime panics and overhead), having to write one-off boilerplate types, and/or go:generate fuckery. Your just venting about Go not having generics to me, I have never stated once in this thread I don't think they should exist in Go. I can't draw a conclusion for something I haven't reasoned through. Once a serious proposal containing one of the features is drafted and I can weigh the trade offs I may form a more concrete position for a specific implementation and you can passionately debate against me if my conclusion is different than yours, fair? &gt; I definitely don't agree that that list represents the biggest differences between Go's and Rust's type systems, that's bordering on ridiculous. Go doesn't even have subtyping, let alone polymorphism, higher-kinded types, lifetime annotations, traits, what have you. None of the features in the list is in any way even particular to Rust, or a new concept for that matter. If you read my post [here](https://www.reddit.com/r/golang/comments/7imxl9/the_big_break_in_computer_languages/dr1h78z/) filtering out the silly banter with sand castle guy you will find that to implement the list of features I was originally referring to it would require nearly every thing you just listed. Hence I feel my statement is reasonably accurate so I refuse to concede my position, let alone on the premise of it being *ridiculous*. &gt; Nobody is contesting that. People can write highly reliable software in C, assembler, or physical switches. This does not mean some additions to the type system wouldn't make it easier to write reliable code. Yes, they were. That has been and continues to be the only argument I feel strongly about and what I originally replied to. ** Highly reliable code (Go's type system is just not good enough to achieve this) **. &gt; Again, nobody said that a simple type system is a barrier to anything. However, what people are saying is that there are a number of different concepts that could be added to the language to make it more expressive. ADTs for example could solve a lot of the problems we have with the language without making it ridiculously complex or even requiring something like subtyping. Again, yes they did. I disagreed and made my position clear. I also never said one or more features added to Go would make writing highly reliable Go programs simpler, because as I already said such features do not exist for me to measure. &gt; Negative effects you claim these features will have. Personally I don't think Go should even incorporate things type hierarchies or generics (which would somewhat have to go hand in hand), but for example ADTs would fit the philosophy of the language and make a huge class of runtime panics re. runtime interface{} conversions much less likely, and reduce the amount of boilerplate required to do it safely. What would the negative effects of e.g. ADTs be? Interesting, so I say **"I only tried to outline the idioms I see in use to compensate for these lack of features, while I did make it clear I find these idioms a fair trade off from the other affects such features have on a language."** but you decide to interpret that as **"Negative effects you claim these features will have."** despite never making mention of the word negative. I said fair trade off. That is it. I am sure I have opinions you may disagree with, so why create ones inside your head? Just ask me about topics you feel strongly about until we disagree and we can have a meaningfully debate, this is essentially you arguing with yourself. &gt; Right now we have to compensate for the type system's simplicity by writing error-prone boilerplate, and many of us think it could be improved on. This doesn't mean we want to bring in everything and the kitchen sink. I don't have an opinion on the first sentence without a specific proposal to measure as an improvement. The second may apply for many people- but it does not apply for this conversation. I asked straightforwardly "What about Go’s type system makes it unreliable?". I was given a complete list of what it was missing to be reliable. I disagree. Some how people decided from such a simple and concise set of responses that: - I am a Go fanboy - I think Rusts type system is not flexible - I am against the list of features Rust has that Go does not - I am inexperienced - I should quit my job - Something about sand castles and writing kernels is easy All formed from a simple opinion that you can write highly reliable Go programs today- thanks to a small set of idioms that compensate the set of language features that were missing. Adding that the trade off seems fair to me by comparing to the only realistic thing I have to compare against- Rust itself. It didn't mean I hate Rust (I don't) or I think Rust is not interesting to write (I do). It only meant that each language has its own balanced set of trade offs that enables engineers to write highly reliable software. So to summarize for the final time here since this thread has degenerated as far as I'm willing to participate in: &gt; My point here is trade offs do exist between the design of Rust and Go, but writing highly reliable software isn't one of them.
&gt; You could probably regexp it with reasonable accuracy; but it's not the approach I would recommend. This is the [approach](https://github.com/nishanths/dedupimport/blob/master/main.go#L719-L747) I tried in a command that needed to do this. At its most complicated, it can guess `foo.org/blah/go-yaml.v2` as `yaml`. &gt; Not sure if I fully understand what you mean with that? In `gopkg.in/yaml.v2` the basename is "yaml.v2", but the package name is "yaml".
If you have any development experience whatsoever you would have to be a complete moron to willfully use PHP for anything. His criticisms only seem to reinforce that.
Most of my stuff isn't so performance intensive that I need to pay attention to it, but I wrote something up that did some actual work in a useful manner and ran some benchmarks. I wrote a small program that serves images over http and adds a dynamic watermark based on the referrer header, and used `ab` to benchmark it. In every case, gc was slightly faster than gccgo. The differences weren't huge, but they were there. Request Threads|gc|gccgo ----------------------------- 1|15.148|16.544 2|8.673|8.801 4|6.475|6.638 10|6.384|6.706 Given those results I would say the performance is close enough that defaulting to gc makes sense and gccgo is mostly useful (to me) for targeting platforms not supported by gc. 
Ah right, now I know what you mean. I completely misread your first comment for some reason &gt;_&lt; I my defence, I've been looking at code since 8 this morning. You can pass `parser.PackageClauseOnly` to `go/parser.ParseFile()`, which should make parsing of the dependencies relatively quick.
Neat! Maybe you can answer this: last time I looked at the Docker registry (the [distribution project](https://github.com/docker/distribution/), the next-gen registry written in Go), it wasn't suitable for stand-alone enterprise use. It didn't have any built-in authentication and relied on the user to provide their own backend authentication and authorization service. Is that still the case? Does your front-end support this?
Thanks! As far as I know v1 security was exactly as you describe, it required nginx or something similar to server as the auth service. V2 supports JWT, and I believe that is currently the preferred method. My front-end uses a fork off https://github.com/heroku/docker-registry-client for registry communication and currently works with basic auth. I'm hoping to add LDAP support and some more enterprise level features as my next todo, but wanted to see how the project was being used before proceeding. In the meantime take a look at https://github.com/SUSE/Portus, I believe they've addressed some of your concerns in a more thorough manner than I've had a chance to yet.
Just wanted to start off by saying that I'm sorry if I came across as hostile, and calling you a fanboy without actually reading the rest of the posts in this thread was uncalled for. What I meant with the negative effect bit was not that you were directly claiming anything about them, but that it's built in to the concept of a trade-off. People just value things differently, so what's a negative for one isn't for another. Still, I really wouldn't put Go into the same category regarding reliability as Rust (or Ada or Eiffel or what have you.) I mean, sure, people write highly reliable stuff with Go, but there's different definitions for reliability and different ways to achieve it.
That's great Feedback, thank you. :)
I don’t think you were hostile so don’t sweat it, trying to advocate such a focused core tenet in this kinda thread was my own mistake. Happy Go / Rust coding man.
I'm sure they would accept patches for improving the generated code. Is it the sort of thing that could be incrementally fixed?
Get the package names of imported packages by calling [build.Import](https://godoc.org/go/build#Import) for each import. The Import function locates the package in the workspace and parses the files. The package name is in [Pacakge.Name](https://godoc.org/go/build#Package.Name). 
Go to Run | Edit Configurations select the run configuration you created and instead of Run Kind file, use Run Kind package. See: https://youtu.be/ko-wKntCLjg for a visual guide of this. Please note that the linkmode is needed only in special cases, it's entirely optional.
Files are uploaded to and served from random file names. How would a client go about discovering one of those file names? 
reflect.SelectCase is what you're after. Example here: https://stackoverflow.com/questions/19992334/how-to-listen-to-n-channels-dynamic-select-statement?answertab=votes#tab-top
Surprisingly, there is no built-in syntax to do this. You can do it using the reflect package, however, with the function reflect.Select.
Thanks! [Done](https://github.com/nishanths/dedupimport/commit/eaca8f7e0b9b868e9781ca01a21f473cd4ea9b38).
[removed]
go is typesafe. if you use interface{} and fuck up you get a runtime error, just like python or whatever garbage language you like.
I was involved with the release of the Go target, though my (tiny) contribution was mostly on the Java side of it. The Go target is young and there are certainly many low hanging fruits. Some oddities may result from the fact that ANTLR itself is primarily a Java project and a lot of the initial Go target code was a port of the JavaScript (sic) target. PR's are very welcome, I suppose. :)
In this very simple demonstration they wouldn't, but I hinted at handling (e.g. saving in a data store) the original file metadata in the article for exactly that purpose. :) The randomization is just for preventing file name conflicts (e.g. uuid in practice). But there are several ways of dealing with that as well of course.
I think it just means that it's useful enough for the Go standard lib. Certainly useful enough for me as I don't really need the advanced shrinking features. If you do, definitely check out GOPTER, which I link to in the article
Does there happen to be a reason this syntax is not built in? 
I found this post by Russ Cox (a very early and influential go team member): &gt; We intentionally left array select out. It's an expensive operation and can often be avoided by arranging for the various senders to send on a shared channel instead. (https://groups.google.com/d/msg/golang-nuts/ZXDfIkVk54g/BcrR50rVrdsJ) So in your example, rather than channel per worker, just one channel that all workers send too. If you need to know which worker you got a message from, have them include that info in the message they're sending on the channel.
I guess you have the files in the same package, next to main.go. In the go build arguments you need to pass all files of the main package. In the cli it would look like `go build *.go`. Should be something like this in goland
I'll give up yacc when you take it from my cold, dead hands.
Make the workers send their results on a single channel.
Imo: Write tests. Read the standard library. Allow time to refactor the code after you have tested it. Repeat.
That's not type safety. 
&gt; Go provide out of the box route handling, but it is not possible to 'split' route part and handle entry part with custom type - now it's possible What makes you say that?
you are wrong
Knowing Amazon, and based on the public information available as well as previous product announcement / launches, I think it's going to be in some sorts of Preview mode for a few months, depending on demand / how stable it is and then become publicly available. I expect to have it full GA in a year or so at most, probably somewhere around the summer. Better ask your Account Manager about this, they might have more information.
Check out the reflect package. Specifically https://golang.org/pkg/reflect/#Select
Go does have some kind of generics, not complete by all mean, but certainly has it minimal implementation, see below for examples: mapOfStrings := make([string]string) mapOfCustomObjects := make([string]*structDefinedObject) arrayOfInts := make([]int, 0) arrayOfStrings := make([]string], 0) arrayOfCustomObjects := make([]structDefinedObject, 0) I actually find these pretty much solve most of my problems if I think through the problem enough and design it well (Generally :-) ) 
In practice you won't need to do this, as mentioned by tv64738 you should fan in the results to a single channel. Your question is covered very well in [blog.golang.org - Go Concurrency Patterns: Pipelines and cancellation](https://blog.golang.org/pipelines).
In Go all files in a package (directory) belong to the same package (except for the _test test named packages, in _test.go files). So it doesn't matter how the functions are named.
thanks! this worked!
I used to be an Atom fan, I even wrote a couple of plugins to make my workflow easier, and I hated VSCode because I hated visual studio and I was prejudging the editor. However after a year of annoyances and seeing how all my teammates and convention speakers used either GoLand or VSCode I decided to give the latter a go.. and now I'm a VSCode fan. It's not perfect but It's by far better than Atom and Sublime (IMO), never looking back at Atom, sorry :'(
Hey /u/mzupzup - there are a few things here I think could be improved, like using a map and 'ok' book for allowed mimetypes, and using http.Error to write server errors for better readability. Otherwise, awesome tutorial! Look forward to the rest of your blogs.
I’ve been noticing a trend recently where programmers complain about too much boilerplate, wanting more abstraction, and depending on generates code and frameworks to do their jobs. Any amount of effort or thought that has to go into some software is immediately shunned as an issue with the language. Now programmers are afraid of if statements and the thought of seeing a huge block of code frightens them. You sir, are a great example of this new generation of programmer. Genetics won’t save you.
I agree with this answer. There shouldn't be a need to select from an array of channels. I think that sometimes people try and make a language like another one, but idiomatic Go code is often what works best in my experience.
https://github.com/derekparker/delve Seems to be gaining popularity.
As a bystander to this conversation you come off as really defensive and insecure. You first embarrassed yourself by showing a complete lack of understanding of generics, then treated it as a personal attack when someone was nice enough to correct your mistake. :)
I'm a tool that generates Go code. True story. 
I thought they just announced it a few days ago
What a miserable post. Here's the continuation, two days later: https://medium.com/@ivanjaros/moving-from-php-to-go-and-back-again-9ea1f57018c4 Choice quote: &gt; And that is because they are limited by the language itself. You cannot define interfaces on their own. It has no meaning. You have to define basic functionality that can be extended by the user. You can do this and have an interface and base struct but once the user extends the struct via composition all you binding methods will go out of the window and the user is left with having to re-implement everything anyway. Wat.
`fmt.Printf()`
I'm not saying Go wouldn't benefit from generics. But I'm doing fine with Go and I don't have them now. I like interfaces, and I don't feel like I'm missing anything by not having generics. Initially I did feel like they were a missing thing, but once I "got" interfaces I never looked back. I really love Go they way it is, it has a great "feel" to it. Interfaces let me accomplish what I need to. People have strong opinions on the topic of generics (for and against) and one day there may be a proposal that is acceptable to the community. Until then, generics aren't a thing and it gets kind of boring hearing how they're "missing" so often. I personally wouldn't vote (not that my vote counts for much) for generics to be added unless it is clean, clear and doesn't end up looking like the mess I see so often with other languages. I probably shouldn't even comment as this will probably receive a heap of angry messages from the "for" side of the generics debate that will tell how wrong I am, and try to convince me of the error of my ways. For all of the above reasons, that isn't going to happen at this point in time.
There is an [excellent reply](https://medium.com/@jamesmcminn_13411/you-seem-to-have-misunderstood-go-to-a-very-high-degree-45ef3287b665) in the comments section.
Documentation, you must specify whole route for a handler or handle func, or am I wrong ?
You can use [apex/apex](https://github.com/apex/apex) if you want to run Go today, and when AWS will start to support Go, you can just drop the node wrapper without changing a line of Go code.
Yes, because writing the same code over and over again is not a huge waste of time and money.
Seriously, with its support for options like `%x` for raw bytes, `%#v` for complex structures, and `%T` for showing underlying types, `fmt.Printf()` has never let me down while debugging.
http://www.informit.com/articles/article.aspx?p=1941206
looks good. docker is a;ready in Go