Yeah it does use a lot of resources to host gitlab yourself, I'll admit that for sure. We've been hosting it for around 1400 people internally and it steady states around 20GB of RAM, on a 16 core VM, you have the runners for CI, but I still love it even as the one that manages it.
So you're cool losing all your data when your application disconnects from SQLite?
&gt; I want to delete my Github account. Why? What are the disadvantages of keeping it?
Of course not. This service is non-critical side thing, so I'm okay with slower, on-disk sqlite. This will barely get 10 write *per day*. For my main product, I'm using Postgres, so no Docker-based disk issues there. The quest for finding why the Docker version was slow was merely educational, although an important one. If it had been an network issue, I would be worried because I would potentially be facing the same issue on my main product.
[httptest](https://golang.org/pkg/net/http/httptest/) is a core package that will bring up a testing HTTP server which you can make requests against using net/http. I don't know about database packages that make it easy to create testing databases. I always end up having to implement that myself since it doesn't seem to be a "feature" that anything implements. It's way easier to do it at the beginning that retrofit it. But if you do have the ability to create test databases, then you can use that.
dep can already rewrite repos like that arbitrarily. I have used it for cases where I want to have some package pulled from a local mirror, possibly with changes, instead of off of the internet. So it's definitely possible, and doesn't make Go explode or anything.
Instead of testing against a real database, I open a connection to an in-memory sqlite database.
No because you still have to return if not nil
Darwin doesn't provide a stable kernel ABI for these calls, so they are implemented via libc just like on solaris.
I believe you're asking for ways to test using the real API's. Use a build tag. At the very top of your tests files, **if they contain external calls**, put a `// +build integration` comment. Then when you run the tests, they will be ignored. Any time you actually want to run the integration tests and hit the real API's and DB's, you can call `go test -tags=integration` to have those tests included.
C/P from a reply to someone else I don't have and I don't want to have any Microsoft controlled account anywhere, regardless of what they will do or will not do with Github. Additional comment: It's a personal preference. There's actually no need for some "why", even though I could probably find some examples if I would be in need to rationalize it. Which I'm not.
Use the Write method and check for errors: https://golang.org/pkg/net/#IPConn.Write 
That is how we do it at our job as well.
I see that the issue was already solved. But I'm still puzzled by how severe the performance penalty is, when running in a docker container. Could you possibly do one more test? We had much better experience (performance wise) running sqlite in WAL mode instead of the default rollback journal. To activate it you just have to issue the queries: PRAGMA journal_mode=WAL; PRAGMA synchronous=NORMAL; after opening the db. It would be really interesting to me, if this improves the performance considerably. 
I maybe could help planning to send some pull requests on weekend
I can get it piped to a CSV now, which is great. Now i'm having trouble adding the headers \-before\- i put the data in there. The code below adds the headers to the bottom which is not ideal: func main() { // Load up some items from our fake dataset var items Items json.Unmarshal([]byte(testJson), &amp;struct{ Resources *Items }{&amp;items}) // For now we want to just display them to the screen, but we could write to a file or a buffer or anything var data = [][]string{{"Name", "Type", "Criteria", "Notes"}} csvfile, err := os.Create("asset_groups.csv") if err != nil { fmt.Println("Error:", err) return } defer csvfile.Close() writer := csv.NewWriter(csvfile) defer writer.Flush() for _, value := range data { err := writer.Write(value) fmt.Println(err) } if err := items.ToCSV(csvfile); err != nil { //fmt.Println("error encoding to csv", err) //return } }
Can you elaborate on: *"Even if you get a TCP ACK the data could still be missing on the remote server application."* What do you mean by this?
Addendum to 2) but they may arrive coalesced on the other end, eg. "MESSAGE 1MESSAGE 2"... or even split, first read "MESS" then second read "AGE 1MESSAGE 2" TCP is just a stream connection. If you need messages coming out as they go in you will need to add a framing format of some kind, eg. write a 4-byte size integer holding the size of the message, then the message itself - then at the other end read the size first then read 'size' bytes until you have the message.
And be treated as values. https://play.golang.org/p/HrtLSJgjFHW
It's called a "method expression" and here's the part of the Go spec that defines it: https://golang.org/ref/spec#Method_expressions
Hmm afaik overlay2 is the recommended option for Docker on Debian... I wonder if this is a bug in the Docker disk logic? Might be worth reporting if you can get it down to a reproducible piece of code
OS kernel acknowledges TCP payloads, but all data gets stored in the socket buffer. You've got to read it first on the remote side.
Whats the preferred storage driver for OP's case? Using :memory: isn't a real solution. 
Run strace inside the container and look at what files/folders are being accessed. I'm suspecting your Dockerfile needs a VOLUME instruction to bypass the Copy\-on\-Write filesystem.
Rather than trying to set the value as "sunday" you should directly use the enum: ```x.Set(reflect.ValueOf(SUNDAY))```
i have reflect.TypeOf WeekDay and i have valid value of one of the constants. Im trying to create an instance of WeekDay. How do i do that? 
1) No. In most, but not all, cases you'll get an error when it fails. Always check for errors from every operation, including when you close the connection. Reliable delivery across an unreliable network, error handling and duplicate message handling have some ugly edge cases, but for the normal sort of app where you send a request and get a response the simple model is good enough. In some cases adding a higher level protocol "Yes, I received this message" response at the app level can be helpful. 2) Yes, they'll be ordered. The server will see "MESSAGE 1MESSAGE 2". It may see them in a single packet or multiple, but the order of the stream will be maintained.
Just swapping this one line works https://play.golang.org/p/bduSNMHKIwK. But this seems a very weird thing to be doing. I take it that you're getting a raw value from somewhere and trying to convert it to the enum with that value? In which case you should just be doing a type cast: https://play.golang.org/p/iFMjt8_ItPI
This seemed odd to me, till I tweaked the example to this: https://play.golang.org/p/VWl_6VU3beu . Python lets you do something similar -- `MyClass.method(instance, arg1, arg2)`
Shameless plug: https://github.com/go-testfixtures/testfixtures See also the "Alternatives" section in the README.
As some wise person once said, objects are equivalent to function closures. I guess that is what is going on behind the scenes is the method is being bound to the state of the objects and returned as a closure which is already a first class citizen in Go. It makes sense when you think about it and it would be trivial to implement in a language that supported first class functions with lexical closure.
The "defer write.Flush" is unnecessary. Why did you defer that, anyway? Defer will execute the function when the function ends. func main() { // Load up some items from our fake dataset var items Items json.Unmarshal([]byte(testJson), &amp;struct{ Resources *Items }{&amp;items}) // For now we want to just display them to the screen, but we could write to a file or a buffer or anything var data = []string{"Name", "Type", "Criteria", "Notes"} csvfile, err := os.Create("asset_groups.csv") if err != nil { fmt.Println("Error:", err) return } defer csvfile.Close() writer := csv.NewWriter(csvfile) if err := writer.Write(data); err != nil { fmt.Println("error writing csv headers", err) return } writer.Flush() if err := items.ToCSV(csvfile); err != nil { //fmt.Println("error encoding to csv", err) //return } }
xhyve?
That is pretty cool
So long as the connection stays open, TCP will continue to try and deliver the messages. This will survive packet loss, network saturation, etc. It may fail, too, sometimes quickly and sometimes after several seconds. Always check returned errors, assume nothing works, everything fails, and that the internet runs on fairy dust and the alignment of the planets, and you'll start to get the right idea of how to approach the internet. TCP only guarantees 1 thing: If bytes arrive, they will be in the order they were sent. It's just extra features that it will retry, control for network saturation, have other command signals, etc.
And even call like this (pointer) https://play.golang.org/p/-7JZfPxr9lZ
Hi OP, This is a known issue. Disable the CFQ scheduler and try again: echo 0 &gt;/sys/block/sda/queue/iosched/slice_idle echo 0 &gt;/sys/block/sda/queue/iosched/group_idle
am i correct in assuming this will have a negligible effect on performance?
Was the direct binary run (which was 16x faster) also on a DigitalOcean VPS?
https://play.golang.org/p/ImSVVzI7ZHu
Correct.
I'm pretty sure that it's not some sort of closure as much as it is an implicit argument to the function (which becomes explicit when you use the function as a value). The same thing happens in C++ with `this`, when you work with classes in Python (`self`), and to some extent in many C APIs which accept some pointer as the first argument. In Go, the function receiver is that argument (and can be a pointer or a value, which makes sense given what you're allowed to mutate depending on the context).
Is tls\-nsi\-02 the domain for the machine you're running the container on? If so, what may be happening is that the hostname of the container is not that of the app. You can either use host networking or you can explicitly set the hostname for the container to the hostname of the host.
Love it! Looking forward to that.
yes, [each Method Corresponds To An Implicit Function](https://go101.org/article/method.html#method-as-function).
and [https://play.golang.org/p/D8aSaVND7ik](https://play.golang.org/p/D8aSaVND7ik)
good guess, but unfortunately that doesn't seem to be the issue
You did get me on the right train of thought to fix it though! I forgot to bind port 80 even though it was exposed. Thanks for your help. :)
I give up. Thanks for the effort, but unless we could sit down I feel I can't get you to grasp that it is clear to me that there is still a pointer to the buffer as far a gc is concerned, despite the fact that there isn't one in the code. I am aware of the underlying structures of all kinds of types. I don't know where I gave you the impression I wasn't.
It looks like you are right about the implementation being an implicit argument. Not sure if it changes my mental model.
Seems like a nifty way to namespace some functions. How idiomatic is it to do that? I'm not sure I've seen it yet in the core libraries.
Is there a reason you're using such an old version of Go?
been using Gitblit for years on a container and it works great!
MS' image has definitely changed over the past few years. I remember MS used to be very hostile against FOSS and one of its CEO called FOSS "cancer". However, in the past few years, MS has definitely tried to change its image in FOSS community by open sourcing a lot of its project, including .NET Core and VS Code. I personally don't mind giving MS a chance to change its image among developers. After all, if MS recogonized its mistakes and want to be FOSS friendly or FOSS advocates, why shouldn't we be supportive? At least for now, MS has more repos on Github than Apple or Oracle does, and is slightly shorter than Google. I personally believe MS acquires GitHub mostly for the software hosting, probably as a replacement for its old code hosting site and NuGet \(correct me if I am wrong\)? If so, I think it's a wise business decision for MS. I think as long as MS does not mess up with the domain of Github \(such as changing it to [github.microsoft.com](https://github.microsoft.com)\), Go projects on Github should probably be safe. However, I don't think it's very likely for MS to do so as it has a designated xbox domain \(instead of using xbox.microsoft.com\). The only concern that I have with this move is that Github may turn into a paid services even for public repos. I will probably switch to bitbucket if Github requires paid subscription.
I used `golang:1.10.2` first, but then realised I didn't want to introduce a difference between the two versions because the latest Go version in Debian 9.4 is 1.7.4. So I switched the Docker version to 1.7.4 too, for cosistency. But it didn't matter; 1.10.2 had the same performance FWIW.
Yes, it was the same VPS.
In addition to what /u/danredux mentioned, I think following parts can be improved as well: 1. There is a little bit too much inexplicit coupling between modules. Right now you have a flat module since it's a small project. If the project gets bigger, then I would suggest using more interfaces to reduce the coupling between your controllers and data\-access code. Currently your are using global variables and code has dependency on concrete classes. Wrapping the db with a layer of interface will bring you more flexibility in the long term. 2. Even for a small project like this, I personally would still create smaller modules to reduce the coupling and imposing some clean architectural design in the project. A flat project like this is a good start, but once it gets a little bit bigger, a better architecture will be required, and modular design will be needed. I personally borrowed a lot of design philosophy from .NET MVC architecture and so far it has been very helpful in keeping my code relatively reusable and loosely coupled.
Very interesting! I swtiched back to a file-based sqlite database, and added these two statements before the `CREATE TABLE`, and performance improved incredibly. Docker was able to push 2.7k+. I think this should be documented more visibly in go-sqlite. Hope this benchmark was useful. Thanks a lot for letting me know about WAL, I'll read up on that.
Hmm, I don't have those (virtual) files in the host/container. Maybe it's because it's a VPS and probably running in a VM?
This is excellent because it gives lots and lots of examples. Just what you need to reinforce what you learned on the golang tour.
That happens in Python, but is unnecessary in Go because the compiler knows exactly which function is being called at compile\-time, so it just transforms \`[foo.Bar](https://foo.Bar)\(\)\` into \`[Foo.Bar](https://Foo.Bar)\(foo\)\`. Of course it's slightly more complex with interfaces, it has to lookup the function pointer in the vtable of the interface.
Definitely, as it grows I think it will become more apparent for me what parts can refactored into their own modules/sub packages!
Agreed, starting off the question with "how to reflectively instantiate an enum" is a rather extreme example of the XY problem. I would not doubt that type-casting is the actual solution to their initial problem. http://xyproblem.info/
From my experience, you don't need a framework to help you to achieve MVC in Go. Many frameworks like django or .NET MVC provide developers with a code skeleton to get started fast, but also take away the learning opportunity for truly understanding MVC and the architectural design though behind the framework. The best part of Go is that it provides you enough tools to build and explore MVC pattern on your own. This way, you don't have a framework that babysits and hides a lot of details from you, but you also have the opportunity to explore the thought behind MVC. This way, when a new language come out in the future, you can easily develop a MVC project regardless if there is a framework for that language. I agree that you should consider using a JS framework \(I personally use Angular for the benefit of TS\) to do all the front\-end work and use Go for API. After all, front\-end technologies are so volatile these days, and it's not ideal to modify the back\-end code simply because user wants a better UI. After all, UI is subject to change more often than the core system \(which is your Go code\). Since you mentioned that you want to implement a dynamic website, I assume that you are talking about web applications that allows user interaction. I personally develop the front\-end and back\-end separately, and the connection between them is the API that my back\-end provides. Your Go code will be mostly feeding data to your React/Angular/Vue UI, and the UI updates itself according to the data sent/received. I have a project \(DAS\) that implements exactly what I mentioned above: [https://github.com/DancesportSoftware](https://github.com/DancesportSoftware). This may not be the "most solid" way, but it is probably not a brittle way either.
To call these youd need an instance of the struct which would be confusing. I thought namespacing was done through pakets
Hopefully they will start hiring again based on merit so that they can roll out some product improvements. 
And it will be my first contribution 
Basically, that's because this is all just about dispatch - the method syntax in Go is just syntactic sugar for what you're doing by hand there. If you think about it Go doesn't even need the "method" feature. This: ``` type Foo int func Bar(f Foo, message string) { return fmt.Sprintf("%s %v", message, f) } ``` Is exactly equivalent to this: ``` type Foo int func (f Foo) Bar(message string) { return fmt.Sprintf("%s %v", message, f) } ``` I strongly suspect the latter form only exists in Go to make people who were brought up on OOP systems feel comfortable. 
Thanks, this seems really useful! I've been doing Go for years, but have never seen/noticed this before
&gt; MS' image has definitely changed over the past few years. Yes, that's true. It's because corporations are not people. Meaning a change in the management can make the corporation change. However, this works both ways. A change in management is always one tragic traffic accident away, for example. That's why corporations can basically never be trusted while people with a good history record can be.
``` serve("/page1", func(ctx){ func() (err error) { defer func() { switch err { case "tx_error": tx.Rollback() } }() tx,err := db.Begin() if err != nil { return err } err = tx.Write("hello world") }) ```
I think there's something more powerful going on. By hoisting the first argument out of the parameter list, you remove the type you're operating on and only talk about what you want to do with the type. So in C, you typically had multiple functions that write to something \-\- a \`FILE\` handle or an \`int\` file descriptor etc. They usually take the type as the first argument followed by the exact same parameters \(usually a string of data to write\). Hoisting that parameter out allows you to talk about behavior regardless of the type you're working on and this in turn allows you to specify interfaces.
Ah yes, you're right with regards to interfaces. It saves the need to specify the first parameter as an empty interface itself.
There's absolutely no reason to use the `Write` method as this is what `fmt.Fprint*` functions will call on its `w` argument anyway (they might also be clever and call `WriteString` on it, when needed and possible). But checking for errors is a must‚Äîyou're correct here. u/nuanda2, the fact most of the code do not check the error return when calling `fmt.Print*` (i.e. when the function is told to write to `os.Stdout`) or when calling `fmt.Fprint*` on `os.Stderr` is merely due to the fact *usually* these are printouts *not* intended to be captured (by stream redirection) and processed; IOW, one expects the printout to get straight into the user's terminal. This is not always correct. For instance, if your program streams to its stdout some valuable data (like, I dunno, CSV stream or whatever) you'd better check for any error returned by `fmt.Print*` or `fmt.Fprint*` and fail as soon as possible.
I would also stress (again) that TCP does not preserve message boundaries, so only the ordering is guaranteed‚Äîthe bytes of "MESSAGE 2" will be delivered (if at all) strictly after the bytes of "MESSAGE 1" will have been delivered (again, if at all), but *reading* of them might occur in arbitrarily-sized chunks, including byte-sized ones. That's why reading from TCP sockets often is done with the help of the `bufio` standard package.
Did you try replacing `sda` with your specific device? (These should be done on the host and available on pretty much any modern kernel.) echo 0 &gt;/sys/block/&lt;device&gt;/queue/iosched/slice_idle echo 0 &gt;/sys/block/&lt;device&gt;/queue/iosched/group_idle You can also try the following: echo deadline &gt;/sys/block/&lt;device&gt;/queue/scheduler Let me know if this helps. 
Of course. The devices in the VPS are `vda` and `vdb`, and the two files you mentioned aren't present. I'll try the scheduler thing.
Oh, interesting -- so this isn't root on a VM, it's a traditional VPS that gives you a chroot?
REST API, map/reduce, really any back end application written in Go is all you need to practice writing. I'd also focus on TDD and using Go's benchmarking package for learning the language the socratic way. I programmed a simple Todo for my portfolio but I made it robust using several features of Go and Vue.js I had bst search, doubly linked list goroutine traverse (starting from both ends of the list simultaneously to find stuff), cache using maps, authentication, CORS, logging, error handling and more. The key is pick something you can do in your sleep and build features as you learn the right packages and syntax. Good luck!
Send PRs to Docker, Kubernetes, packer
you also need read https://go101.org/article/memory-block.html
You could call `runtime.Goexit()` in the error handler to terminate the calling goroutine.
Just on a completely unrelated side note; For your final docker image you can use ‚ÄòFROM scratch‚Äô rather than ‚ÄòFROM alpine‚Äô. Not that alpine is all that big, but it is an additional attack vector.
Do you use the docker\-compose tool via an external script, or from inside your tests?
The deal will take 6 months to close, so we probably won't see much of anything change regardless of their intent for a bit.
Gonna say something unpopular: blockchains contributions/implementations.
I think the fundamentalism tag is based upon your fundamentalism. üòã If I didn't want to use cell phones then there would be some people that would roll their eyes and tell me that the choice has the consequence of me being harder to contact.
I checked out get lab yesterday and saw that you can't search by language, can't explore projects by type, and stay seems to be pretty scarce analytics on things such as project pulse. It's an alternative, but it sure seems like a sad alternative.
While I think Jira and Confluence are fantastic for managing issues and documentation, bitbucket has none of the exploreability of GitHub.
Personally I would be far less likely to trust a vanity import path as compared to a GitHub import path.
The chances are that if you're applying for a more junior position, they will expect to have to train you up to work with their stack. What they're going to be looking for is that you can write code that isn't a mess, have enthusiasm for learning and have a little experience in something backendy. 
Not sure if you're testing your own API, or a client for another API, so: * http://dredd.readthedocs.io/en/latest/ * http://www.mbtest.org/
Make sure you know and understand goroutines and channels well
Sorry to rain on your parade, but this seems like bad advice. - The projects are complex, meaning you'll never showcase a larger part of your abilities even if you submit some PRs, - Sending PRs to large corporate projects means you'll have to navigate their politics and roadmaps as well, - If you're doing all this, most likely you'll apply for a job there (google, hashicorp, docker, related vendors like redhat/microsoft/etc. who are working on k8s mostly) But apart from that, the only benefit is that you can put `[Docker, Kubernetes, Packer] contributor` on your CV. It might get you a second round interview because the paper looks good. If that was your intent, sure, it can't hurt. If somebody drills down a bit to find your contributions, it's not going to make much difference in the hiring process, most likely.
How about a subscription management platform in Go? See: http://killbill.io/ Contributing to an existing project would be difficult. Starting your own from scratch will help you showcase your abilities.
Have an upvote, sorry for your downvotes. I feel like you'd get some upvotes if you wrote `distributed immutable append-only database` instead of `blockchain`.
[removed]
Build an open source project for fun or because it‚Äôs something you (or others) would re-use in other projects. Open source is probably the most important thing in the world. Ensure it has test cases too. Then run all the lint and cyclo tools out there on it. Optimize it if you can. That way you can show how you solved a problem and then how you improved performance. Following community best practices as well, you can really demonstrate a level beyond just knowing the language.
couple of options: * https://learnopengl.com/ - not in Go but the gl function calls are the same * I have a video series I did, and starting on episode 39 we got to opengl: https://www.youtube.com/watch?v=yxAPS2eyKmA&amp;index=40&amp;list=PLDZujg-VgQlZUy1iCqBbe5faZLMkA3g2x we set up a nice shader hotloading system and we get to your question I think when we start adding lights a few episodes after that. tldnr; Here is an example of a function that will set a float on a shader: func (shader *Shader) SetFloat(name string, f float32) { name_cstr := gl.Str(name + "\x00") // make the string null terminated because C location := gl.GetUniformLocation(uint32(shader.id), name_cstr) //get the location of the name gl.Uniform1f(location, f) //set the value at the location } so if your shader had `uniform float x;' you could call `myshader.SetFloat("x",10.0);` It can be nice to set up a bunch of shader methods to set things lik.
Thanks. That‚Äôs alright. I saw it coming. Blockchain has become somewhat of a bad word amongst programmers these days.
IIRC there is a function called gl.Str to do that.
You don't have to solve world hunger by submitting PR's to these projects and if you do learn how to navigate politics and roadmaps, then you will earn that job much quicker because the reality is being a software developer is 90&amp;#37; navigating politics and roadmaps and 10&amp;#37; writing...
You should also try a ‚Äúreal‚Äù docker volume instead of bind mounting a directory. The real volumes supposedly do less abstraction and should perform better. Ie docker run -v myvolume:/path ... 
From the example, it looks like you don't need an instance of the struct. You need to have the struct defined, but you don't need to have an instance. 
Blockchain gets a bad wrap as far as I'm concerned. Immutable ledgers have been largely ignored *(by the population at large, not researchers)*, and can prove some interesting advantages and problems.
One can't predict ones future on ones past and by doing so you're only projecting your own ignorance and bias. 
Wow, that's cool! Thanks for testing it out, I did not expect it to work so incredibly well. This is nothing go-sqlite specific by the way, it's a standard sqlite3 feature: https://www.sqlite.org/wal.html I'm not sure why this is not the default journaling mode, it usually works so much better.
Build a real world "production" REST or gRPC API 1. Scalable, must be able to run more than one instance. 2. Dockerized. 3. Unit tested, must be able to run "go test" directly from clone. 4. Integration tested, recommend docker-compose. 5. Swagger documented. 6. dep vendored. 7. Authenticated and Authorized. 8. Built and tested via CI. Travis and Circle are both good. Recommend Makefile for task documentation. 9. Flag &amp; ENV config, API keys, ports, dev mode, etc. 10. "why" comments in the code, not "what" which should be clear through func/variable names and godoc func comments. 11. Use of Context to limit request time. 12. JSON logging, logrus or similar. 13. Postgres/MySQL, sqlx or an ORM. 14. Redis/memcache for scalable caching. 15. Well documented README.md with separate sections for API user and service developer audiences. 16. Clean git history with structured commits. No merge master commits. 17. Passing go fmt, go lint, and better go-metalinter. Show me that on Github/Gitlab and I'd be arguing to hire you.
You need to pass an instance for the actual call though. Or am i wrong? I read it lime the first parameter becomes an instance of the struct. 
You're not wrong, Walter, you're just an asshole.
[removed]
On the other hand, there's really stupid funding hype for anything featuring the word "blockchain" too and plenty of startups "mining" that. Expect quite a few unemployed blockchain programmers when that bubble bursts, and beware when applying to a one.
Yea, I'm mildly speaking as a developer writing things. It's a tool in a bag that was not often talked about, especially in the context of content addressable storage.
This is more like method currying rather than method to function conversion.
Have you seen GoConvey? It's quite interesting for doing testing. Has a web interface also.
Have you seen GoConvey? It's quite interesting for doing testing. Has a web interface also.
I use reflex and invoke it with: reflex -d none -r "\.go$" -- zsh -c "time go test ./... ; repeat 100 printf '#'"
could be wrapped in a magefile
Not exactly sure how they do it in DigitalOcean haha
&gt; Build a real world "production" REST Hey, if u don't mind could you please elaborate on this?
Nope, you're right, I didn't catch that right away. Yeah, that makes it confusing. I'm not sure what value there is in this at all then, other than it being an artifact of how Go defines methods?
Are you sure you‚Äôre not a technical manager? üòÇ
I have not used mage, what are the advantages?
That is pretty slick, I think I might have come across it before.
Or trusty [realize](https://gorealize.io/), my goto for auto running things whilst developing
Okay, I brought up a DigitalOcean instance and it uses 'none' as the IO scheduler, which effectively offloads to the hypervisor. Really curious as to if the second option helps your case: `echo deadline &gt;/sys/block/vda/queue/scheduler`
Not sure how many people play OW here, but a sanity check on my code might help me a bit. Nothing too fancy going on in there.
And is too closely tied to the word "Blockchain". Guessing hashes does not a blockchain make, imo
anything related to kubernetes
If they are asking this kind of question they likely do not have a lot of skills to showcase. Being able to contribute to large existing codebases is a valuable skill, internally or externally.
*I'll assuming what you are asking, but please rephrase and ask specific questions, if my assumption is incorrect.* I'm suggesting building a backend service/application API as if it were real important production software. The actual code is a small part of the process of writing maintainable systems. I don't care if you can balance a red/black tree in an interview. In fact, if you submit a PR where you've [NIH](https://en.wikipedia.org/wiki/Not_invented_here)'d one, I'll tell you to [use an existing library](https://github.com/sakeven/RbTree) (link for example, not specific recommendation.) I want to know if you can write tested, monitored (error rates and overall metrics), maintainable, software following Go and software engineering best practices. It could be the common "todo list" or something more interesting, such as a video processor using ffmpeg to convert anything to web video formats with background workers. The actual function is less important, unless it's something unique and useful in its own right. That's also, why open source contributions are interesting to me. Does this person give back to the community on business or personal time? Even just a bug report. How do they handle code review? Have they used correct grammar and spelling? (Not needed on reddit, but important in a business environment. Haha) Are their PRs clean and organized? I should probably mention: I am speaking for myself and many people I know. Some engineering interviews do just want that, IMHO silly, red/black tree.
I volunteer backend work for https://highnoonpickem.com/ and could definitely benefit for this, so I'll probably be looking into this sometime in the next few days. I'm happy to provide feedback once I can sit down with it. 
This post is great. Really thought provoking stuff.
Enables library-based tasks over raw command shells, which results in much higher cross-platform support of your build commands!
I'm using https://github.com/smartystreets/goconvey for that, without their testing api (https://godoc.org/github.com/smartystreets/goconvey).
Well, the name is dynamite.
Yeah, we should have an own plattform for go packages like npm or rubygems have. There is no need to bind it to some plattform, nor some VCS. Just code and versions needed and a tool to upload them.
I couldn't find a test runner that would scratch my itch so I built one. I used to use ginkgo for a number of years (just for the test runner, I dislike the actual testing library). But then when I tried to pass flags to it sometimes it was awkward so I just made my own, uses fsnotify so it's efficient: https://github.com/aarondl/rtest In reality I just want to run go test with some flags when files change, so that's what this does. rtest recursively watches files and runs go test with flags working as you expect to be able to. I like to pipe it into my colorizer too (colortest) which consumes the json format and outputs something colored and reasonable to look at. I have an alias that does: rtest -- -json | colortest
It doesn‚Äôt hurt, that‚Äôs true. It does seem overkill for something that seems to be a mid-junior position however.
$ ldd ./tut3 | grep libc libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007f3e9fe41000) 
Use RAML over OpenAPI.. so so much better for API design.
Haha, now I want to use it myself. I got dropped into a codebase already use OpenAPI and in the interest of consistency used it in the next project.
Haha, now I want to use it myself. I was dropped into a project using OpenAPI, and then used it in the next for consistency.
I would agree that it is too complex. In general IIRC standard practice is to keep cyclomatic (gocyclo) below 15. https://goreportcard.com/report/github.com/gogs/gogs#gocyclo
Me, I am working on a some Kafka consumers. Read from a queue, process the data, save to a database, and add channels for concurrency. Not too hard but still involves a good set of tools. 
Anyone trying to abandon github over this acquisition is at best stupid. At worst, the free software movement are virtue-signaling and using this as an excuse to advance their agenda at the expense of others. 
If you excuse the bad code layout, as this was just to learn some of the opengl pipeline, i worked on getting messing with shaders this past week. Check it out here: github.com/thegtproject/goshaders
I'd try doing this MIT lab and put the result on GitHub linked from your resume: https://pdos.csail.mit.edu/6.824/labs/lab-raft.html
There are several constraints presented by the nature of distributed immutable ledgers with multiple masters (ie all nodes can write) that make their codebases pretty good educational tools for a go programmer, even if you don‚Äôt usually do work that involves this kind of distribution. 
Please don't break my imports. That's all I ask for. As for the problem - moving your stuff somewhere else doesn't solve anything. Gitlab can be bought too. Just like bitbucket. Just like anyone. That's how things work. So the current solution is to have vanity imports and a custom domain. In future - vgo is probably going to solve this using mirrors. P.S. Threads like this are going to be a thing for the next few days, don't they? 
As an open source advocate and MS hater for quite some time, I agree with this. They learned their lesson with Skype and without Balmer, the company is far better off. Remember when they bought LinkedIn? It still operates as its own entity but under the Microsoft umbrella. As far as their motivation goes for buying GitHub, it actually makes sense when you think about it. MS makes a good chunk of money from enterprises and they are hiring more developers these days to write code. With that come the expectations from developers to use Git in a place that still uses Subversion. Trouble is, enterprises tend to need all their stuff to run in their own data centers, so GitHub.com isn‚Äôt an option for them. GitHub Enterprise on the other hand is a money maker, gives enterprises the on-premise solution they need while giving their developers the familiar GitHub interface they‚Äôre already used to. It was even in the announcement that they plan to enrich the enterprise offering and I think that‚Äôs their primary motivation: add GitHub Enterprise to their catalog and make it easier for companies to purchase it, since they all have vendor agreements with Microsoft. In the end, it‚Äôs a way to make more money from enterprises. As far as GitHub.com goes, don‚Äôt expect them to make any radically negative changes. They know they‚Äôve bought a powder keg and that the slightest mistake would ruin all the credibility they‚Äôve earned with developers over the last few years. They‚Äôve done well with VSCode, TypeScript, etc. Now, every developer in the world is watching GitHub very closely, waiting to see if the keg explodes. I seriously doubt they would do anything to let that happen. 
I use https://github.com/dnephin/filewatcher and https://github.com/gotestyourself/gotestsum
I still don't like vanity imports... not only website can be required by someone you don't like, it can also vanish.
I would add instrumentation for metrics to this list as well.
I'm worried people are going to be panic-deleting their accounts and my deps will vanish overnight.
Great! Thanks for the recommendation.
Yea, when you can't avoid a complex method, I like breaking the conditionals out like this and bailing early if need be. Thanks.
Very cool. Did you handle authentication with cookie based sessions? Or something more fancy like jwt?
This is a great checklist for any project, not just go IMHO. Thanks for writing!
Check this https://github.com/avelino/awesome-go
I dropped you a PR, though I know nothing about Overwatch. Their API is extremely.. Generous, with what it returns. Usually API's return something like "Match.Players" as a list of Player ID's, but nope - this API just goes ahead and embeds each full Player in there, too. :D
We mentor new golang hackers over at https://github.com/purpleidea/mgmt/ Ping me in #mgmtconfig IRC on Freenode if interested. Good luck!
Have you tried, perhaps, entering the directory?
It's too bad no one uses HTML or CSS anymore, eh! Also, Chrome Dev Tools has audits that do a great job of this. Nevertheless, cool project!
A central repository for go packages run by the go community would a good idea around now.
there's g3n a nice engine written in go, you might want to look through their code... http://g3n.rocks
Not Golang related, but from the same GitHub account: https://github.com/baltimore-sun-data/banned-license-plates
Was your database stored on a volume mount (`-v`), or directly in the container filesystem? If the latter, it's known to be notoriously slow. If you can, use a volume mount, I'd love to know if that solves your issue.
I tried both, and there was virtually no improvement.
Will do later today! :)
I would also suggest running `iotop` on the host, when you're running your app in the container and outside of it. You might notice some additional io which isn't coming from your app. I'll reply when i set up a github repo with your env so i can test it out.
Finally some sensible comments thread. People are blowing things out of proportion without looking at the last few years of MS history. They've come far and while I'm really far from MS fan - I am happy to see how MS is changing and their focus on OSS (without breaking things). Skype was long time ago and they messed up big time, but they have managed to learn from it. 
Are you a student at MIT? If not, how'd you get a copy of the project skeleton/tests?
https://github.com/avelino/awesome-go
Work through the official Go Tour. It will give you an overview of the language in a very short space of time. Once you've done that, have a look at the package page on the website, which will give you a good idea of what libraries are available.
Thanks! I will look into it.
Get yourself the book ‚ÄúThe Go Programming Language.‚Äù
[Go By Example](https://gobyexample.com/) is a really good primer starting with Hello World and going through one Go concept at a time. Highly recommended to get started.
Www.golangprograms.com
Also be sure to check out [the list of Go books](https://github.com/golang/go/wiki/Books); you can pick, say, [a free book by Caleb Doxsey](http://www.golang-book.com/) which is IMO great for beginners. They consider booking [*the* book on Go](http://www.gopl.io) and read it. This does not mean you should not practice using online courses (which exist in abundance) but proper education is a must IMO; that's why I recommending books.
I would recommend starting with the Tour of Go. Then read Effective Go. After that, pick a project and just work through the learning process. go By Example site is also very helpful in the beginning when you are first learning the syntax
Learning Go is **really** easy. The Go site has good resources, and "The Go Programming Language" (Addison-Wesley) from Donovan &amp; Kernighan is a good book. What will take more time is stopping thinking for C# or any language with inheritance. Go has no inheritance, but a far better support for encapsulation. Interfaces are still interfaces, but usually more focused. There is no generic. Sometimes will be frustrated, just take the time to re-think, change you habits. C# have many features which allow developing frameworks Go does not have. But often you don't write framework, just create code to solve specific problem. The good part is more simplicity. You will not play with (often too) many abstraction.
If you‚Äôre familiar at all with any other programming or scripting language, just writing things in go helped me learn a lot. Also depending on what your interests are writing some sort of chat bot or gimmicky web service (grab stuff from the reddit api, do some calculations on the data, etc). Is always a nice way to give yourself a goal. Or even just a web scraper. Easy sources of data and possible ways to get people to use your code. Apart from that generally reading the documentation, mailing lists, github issues for busy or popular packages. I tend to learn a lot more by doing, or trying and failing, then falling back on books or reference material. The mailing list is definitely a good source of info.
Let's assume I follow the standard package layout with */cmd* and */pkg* project layout, can this tool be used to determine which binary needs to be rebuilt in the */cmd* directory based on changes in */pkg* directory?
Thank you all for the info, I will look into it tonight . does anyone know from the top of their head if the language is massively different from C#? Will it be hard to maintain a "dual" Learning channel .(C# and Golang).
Thats whats scare me the most, I will still have to maintain working and functioning knowledge at C#.
Interesting. I see `UCANCER` is not listed.
[https://go101.org](https://go101.org)
Some stuff * https://github.com/teh-cmc/go-internals * https://golang.org/ref/spec * https://golang.org/ref/mem * [GopherCon 2015: Rick Hudson - Go GC: Solving the Latency Problem](https://www.youtube.com/watch?v=aiv1JOfMjm0) * [GopherCon 2016: Keith Randall - Inside the Map Implementation](https://www.youtube.com/watch?v=Tl7mi9QmLns) * [GopherCon 2017: Keith Randall - Generating Better Machine Code with SSA](https://www.youtube.com/watch?v=uTMvKVma5ms)
As soon as you feel you are ready, read the standard library. Not straight through, but when you use something from the strings package for example, click through to see how it is implemented inside. Some other good choices are encoding/\*, and archive/\*) This advice does not apply for the runtime, sync, fmt, or reflect packages, which need to do fancy stuff to make the rest of the language easy to use. Don't read them expecting to learn beautiful idiomatic Go. \-jeff
Jon Calhoun's [usegolang.com](http://usegolang.com) course/book was worth every penny for me.
You can do both. Disconnect the C# part of your brain when you use Go, at least at the beginning. My opinion is : don't stay with only one tools too long time. You can have a main tool, using it as your primary tool for many years, but either use or learn another one from time to time. Thinking always the same way isn't good. It's like brain gymnastic ;) 
Half way though Chapter II of teh-cmc/go-internals, it's a good read. Thank you.
Yes it can. In fact I do the same thing. go list ./cmd/... | tainted
Trusting a person is not a prediction of anything future. It's an evaluation of the past behavior.
Right now half of those words does not say anything to me, but i guess it will with time
I just finished up [Todd McLeod's Golang course](https://www.udemy.com/learn-how-to-code/) on Udemy. I learned a lot and he covers many topics that would be hard to grasp without someone there explaining it to you in detail. If you have $15 bucks to spare and really want to learn Go, this would be a great investment. I think it's around 20 hours of total content broken up into about 160 videos.
Have you looked at existing tools such as bazel?
I really liked [Go: The Complete Developer's Guide](https://www.udemy.com/go-the-complete-developers-guide/) to get started, and I've been working through [Webdevelopment with Google's Golang](https://www.udemy.com/go-programming-language/). Both instructors are really good at explaining things.
What about a shady place under a tree?
I have, bazel is very good, however I find it rather heavy, although for much larger projects it does allow you to query the entire dependancy universe. For small projects or for simplicity I just wanted to replicate something similar to how the go toolchain resolves dependancies without the need for changing my entire build system as it does not always play nicely with every CI/CD tool / platform
Correct me if I‚Äôm wrong, but Chrome can only audit one page at a time, no? That makes it pretty much all false positives. 
May I quote you in the README?
Nice one. I built a tool like that as well (unfortunately can't publish it), because I couldn't use the one that was already out there ( https://github.com/jharlap/affected ) due to licensing stuff. You might want to have a look at this as well: https://godoc.org/golang.org/x/tools/refactor/importgraph It does all the dependency graph stuff, which helped me remove that part of the code from my version of the tool.
And what are you evaluating for? Are you evaluating that current ceo and much of the company has been making good strides or are you projecting your biases of the Microsoft from the 1990s?
Go is a sufficiently simple language that you shouldn't have too much trouble picking it up. You will struggle with slicing syntax a little, you might find the lack of C# style objects a bit weird at first but it will be fine. 
He has newer versions of his courses available on Greater Commons. Even the older ones on Udemy are really good, though.
Search thorough r/golang for "go microservices" and "learn go by writing tests". Each of them is like a 10 part series with one taking you step by step in creating Go Microservices and the other taking you step by step in learning the Go language but forcing you to write tests along the way. Both are very practical guides in learning Go.
Is there such tool for python projects?
Above I wrote that companies are not persons. BTW, nowhere I'm judging Microsoft. It's just my preference to have nothing to do with them. No rationale really necessary. My preference does not affect others. Yet it seems most of the posters in this thread assume otherwise. Isn't it funny?
No, it just shows how stupid our tech culture is that we play games like this for no reason than personal bias 
Sure.
The point is to use a domain that you own. 
/u/FUZxxl already mentioned the book "The Go Programming Language", which is very good. I also really like https://gobyexample.com/ for quick overviews of specific features.
LiveLesson has a course called "Ultimate Go" by william kennedy or something like that. It will accelerate your golang understanding. Pickup C# in 2 months? Guess its possible, but really master it takes a few years, and mastering the framework. I would advise kick back, relax, and its not a contest. Completeing projects is more important than mastering a language. Its the edge cases of C# and Golang that causes growth, and you do not see the edge cases until way later on near completing a project. Avoid hype trains. Avoid ultra new languages written by one author that thinks he/she knows better than MS design team, Google Design teams. There are very solid reasons for their design decisions. Also avoid languages that are overly complex written by pure academics. \*\*looks at scala\*\* DOWN VOTE ME SCALAISTS! 
Wow thanks I'll have a look into that.
Don't know. Not looked. Must be one considering the popularity and age of python
Get that book he suggested. Here is the site for it. [http://www.gopl.io/](http://www.gopl.io/) Then watch these videos to lock it in. [https://www.safaribooksonline.com/library/view/ultimate\-go\-programming/9780134757476/](https://www.safaribooksonline.com/library/view/ultimate-go-programming/9780134757476/) My team took a ruby programmer, into a very productive golang developer using those two things in 2 weeks. While he is still learning the stdlib, VSCode golang extensions helps alot.
IMHO the idea that you "can use them more effectively" if you know how "GC, Routine and Channel etc are implemented" is deeply flawed. If such knowledge would be necessary or even just helpful would mean you have to change all code every 6 to 12 month when such things get their implementation changed. You do not need any understanding of the implementation of the runtime to use Go properly.
Seems to miss the .999 etc variants for ms etc. Otherwise: Nice!
Done, thanks.
It's on GitHub as well as their own public site.
The only way to learn in depth is to read and write code. If you want to learn the core libraries in depth, just read the go source code. 
Massive shouts out to u/campoy and his [JustflForFunc](https://www.youtube.com/channel/UC_BzFbxG2za3bp5NRRRXJSw) channel. Having the thought process behind Go design explained is supremely helpful. I get anyone working with me watching his videos after working a week or two through the basics.
Is it just a mistake or did you replace 'preference' with 'bias' just intentionally? Do you think everyone having different preferences than yours is biased?
I second "The Go Programming Language", but do understand the it is a little advanced. Having said that, if you already have 1 year of C# experience, it should not be a problem for you. I still refer back to my copy even after 2.5 years of Go programming.
Go by Example is easily the best resource I've used over the years.
Is this [Learn Go by Writing Tests](https://github.com/quii/learn-go-with-tests), and [Go Microservices](http://callistaenterprise.se/blogg/teknik/2017/02/17/go-blog-series-part1/)? If so, they look like stellar resources - even though I've been writing Go professionally I may have to *go* through them (*badum tsh*) during some downtime.
LGTM
Many good developers commit themselves to learning a new programming language each year, even though they have to continue with another language at work. Learning Go should not interfere with your C# programming. On weekends and evenings, try writing small programs in Go for your own use \-\- things like utilities or small web servers. Most of all, enjoy this fantastic language!
Thanks! I've added the "no trailing zeros" .999 option.
&gt; You do not need any understanding of the implementation of the runtime to use Go properly. This was the ideal situation. But sometime, some knowledge is needed to help avoid pit falls, especially when you trying to design a system which may have many layers of abstraction. I have written about twenty thousand lines of Go code before I realized many features that I've implemented with Go for my various project can be done in a whole better way. And the lessons that I've learned from all this is it's already good to be prepared. I know some information will be updated, and some knowledge will be expired. But I think if I need to write an application that is good, then I better keep learning and updating rather than blindly trying, right? (Assuming the core part of Go will not receive massive changes every 12 month, of course)
I always explicitly return the zero value if there's an error. This makes it clear to the person reading the function that if there's an error, the result shouldn't be read. While it is usually the case that if there's an error ,you should ignore the returned value... it's not impossible to forget, and some small number of functions may return valid data even if there's an error (see io.Reader). If you return a half filled-out value, it's harder to see further down the line that it's invalid. You get deep in the code and you see this user with an ID but no email address and wonder what happened... if instead the user is nil, it's pretty obvious the user is invalid and somewhere along the line someone forgot to check an error. The thing of it is... it only takes a tiny amount of time to do it the slightly safer, more correct, more explicit way. Why do it some other way to save 3 extremely simple lines of code?
I wrote Scala professionally for 4 years. If I never have to write Scala again, it will be too soon. The language has so many way to do each thing that it is almost impossible to understand other people's code if they used a technique that you do not use often.
&gt; If you‚Äôre familiar at all with any other programming or scripting language, just writing things in go helped me learn a lot. After I looked through [A Tour of Go](https://tour.golang.org/list) and decided it was definitely a language I could work with, I pretty much started writing different little examples and working on a pet project. Admittedly, I relied heavily on both the [official documentation](https://golang.org/doc/), and [Go By Example](https://gobyexample.com/) during the initial few days, but these were pretty adequate. Go is quite an instinctive language if you're coming from a language with C-style syntax IMO. I didn't find *many* surprises that I remember; I'll admit that I still find gaps in my knowledge that require a quick google - but with more experience - in addition to further reading - those gaps seem to be disappearing. 
So, just if somebody wants to follow along with the benchmarks: [here is the github for the benchmark](https://github.com/titpetric/research-projects/tree/master/docker/benchmark-io), just updated to go 1.10-alpine, added a --timeout option to wrk and vendored deps: Want to follow along and have a Linux with Docker? `./build.sh ; ./run.sh ; ./benchmark.sh [hostname]` Running the benchmark against an instance running in docker (wrk on same machine, against localhost, so tests are tainted, compared to remote testing): ``` Requests/sec: 1056.92 Requests/sec: 1178.50 Requests/sec: 1014.06 Requests/sec: 998.68 Requests/sec: 1138.48 ``` And then, running the same application in the host: ``` docker exec -it dco cp /dco/dco /data docker rm -f dco rm dco.sqlite3 -f screen -dmS dco bash -c "ulimit -n 100000 ; ./dco" ``` As you see above, the database is deleted before re-running the benchmarks, so they start with the exact same state. ``` Requests/sec: 504.13 Requests/sec: 518.41 Requests/sec: 557.56 ``` In fact, seems my performance on the host, if anything, is worse. Thoughts: 1. Set http server ReadTimeout and WriteTimeout values to help with ulimits, 2. Don't write data from a http handler directly, hand it off to a dedicated goroutine via channel or just a mutexed append list, serialize your writes if you can, 2. Have a dedicated benchmark server (any app can affect your total i/o), 3. Don't benchmark over PSTN (you said you're benchmarking from your laptop?), 4. Take a look at pprof, 5. Obviously the issue can be anything ephemeral like a botched docker configuration, an old Go version with different GOMAXPROCS value, or even noisy VPN neighbours. 6. Run your tests more than once. I have gotten anything from 800 to 4000 requests/s on a test, especially when the database starts filling up. 
If they‚Äôre unfounded most certainly, it‚Äôs either willfully ignorance or unfounded bias. Both are irrational if you‚Äôre trying to make a point about it. If you really had no opinion like you claim, why are you trying to make it heard so loudly? Makes absolutely no sense.
i like course by [Stephen Grider](https://www.udemy.com/go-the-complete-developers-guide/#instructor-1) very much :) 
It depends. In this case, I would just use the short form because whatever is using FromJSON will probably check the error itself.
You are missing out. The reason everyone gravitates to OpenAPI is the idea/name, and the tools. Which is not a bad reason. However, I tend to think if you are designing APIs with something like OpenAPI, you would be much happier using RAML. The good thing is Mulesoft has donated the AMF tool to OpenAPI (not sure the exact status yet on this though.. e.g. if its ready to be used), but AMF (API Modeling Framework) is basically the ability to take any api spec (right now RAML and Swagger 2) and convert them to any other API spec. I believe Swagger 3 is not far off, and others like APIary, Blueprint, etc should all be possible. It is a sort of intermediary API definition that can then be used to translate to any other API spec. Why do this... well while RAML has some good tools (RAML2JAXRS, RAML2HTML and RAML2POJO (Java pojo generator from RAML Types), they were not as adopted as Swagger was before OpenAPI. Sad thing is OpenAPI didnt even consult with Mulesoft and RAML... they just adopted Swagger.. which is odd that the better format was not even considered. At any rate, assuming AMF is usable, you can design with RAML 1 and bask in the glory of an awesome API spec to work with, and still generate code, tests, etc using OpenAPI tools if you want. I am a hard core API first sort of developer. I see the magic in providing APIs that can be consumed by 3rd parties, UIs, etc over writing a bunch of code first, then trying to retrofit an API onto it using the way most swagger users go..which is add swagger annotations into their code (yuck) to then generate a swagger json file, then go back and generate tests, docs, etc. I much prefer the API first, generate everything from single source of truth route. Also.. I dont have to remember to keep my annotated API in sync with code changes. But that is just me. :D 
The tour is pretty good at explaining some of the features https://tour.golang.org/
I prefer red vine before white vine therefore I must be irrational, ignorant of unfoundedly biased. Give me a break ;-) Wrt loudly. This is just nonsense, sorry. I have my preferences, you may have different. That's just fine. What's not fine when you are not just fine if I talk about my preferences and start to analyze why I have them, if they are rational etc. And finally tag them as being heard loudly. Nothing of the above is my problem, sorry.
* [Value parts](https://go101.org/article/value-part.html) and [memory blocks](https://go101.org/article/memory-block.html), which are good for understanding how GC works. * [Channel mechanisms](https://go101.org/article/channel.html) and [channel use cases](https://go101.org/article/channel-use-cases.html), which are good for understanding and using channels.
it will be easier to use C# since you are using unity for the client. serialization will be simple with C# at both ends, and you can share code. 
If you have any feedback on learn go with tests do raise issues or whatever, i always appreciate it :) 
Hey, I want to share with you some project I developed lately that hopefully will make your life easier. So what is RQL? RQL is a resource query language for Go. It provides a simple and light-weight API for adding dynamic querying capabilities to web-applications that use SQL-based database. It functions as the connector between the HTTP handler and the DB engine, and manages all validations and translations for user inputs.
Surely, with built\-in and cross\-platform network packages, Go is good for developing game servers. I heard of some game companies using Go to develop their game servers and the results are great.
Hmmm, for the server portion, Go might be a nice option. There aren't as many examples covering UDP as TCP (which is the case in any language), but it isn't very complicated. See here for a syntax comparison. http://www.minaandrawos.com/2016/05/14/udp-vs-tcp-in-golang/
The Go Wiki provides two lists of learning resources: [Learn](https://github.com/golang/go/wiki/Learn) [Training](https://github.com/golang/go/wiki/Training)
There was no change to the "taste" or "flavor" or "quality" of github to qualify as a personal preference or reason for abandonment. YOu have a personal vendetta against Microsoft and that's ok... just don't know why people like yourself can't admit it and try and disguise it as something it isn't.
Take note that native object serialization is one of the easiest ways to get your server exploited. While C# isn't nearly as bad at it as Java is, [it pays to read Microsoft's guidelines](https://docs.microsoft.com/en-us/dotnet/framework/wcf/feature-details/security-considerations-for-data) on [how to safely work with untrusted serialized data](https://docs.microsoft.com/en-us/dotnet/framework/wcf/feature-details/serialization-and-deserialization).
This is the main issue, and re-implementing all the classes in Go will be time consuming.
Couple of suggestions: * The second code box should link to the playground. * The code box should do RFC3339 (but not use the constant). * 2006-01-02 should also be in the date section. * Should note that go can't _parse_ 24:00 as well as not output it. * Maybe note that the numbers work by counting up from the month as 1 to the seconds as 5, then the year is 6. Eg. https://play.golang.org/p/SoPO39WqN0B
Protobuf.net is really nice: https://github.com/mgravell/protobuf-net
‚Ä¶but when you're using protobuf anyway, it doesn't matter what languages you exchange data between.
well, it matters a bit less. I think go makes a great language for game servers but it is really nice not to have to duplicate all your structs and write physics code twice (which has to be exactly the same) and not have to flip between languages all the time. C# is similar enough on performance and relevant features the only compelling case I can come up with for using Go in this scenario would be "I want to learn some Go" 
I second this. That is where I started.
&gt; Will it be hard to maintain a "dual" Learning channel .(C# and Golang)? For work I write/maintain code in C#, Java, Kotlin, Swift, Ruby, VB.net, Javascript, Go, and Python. Once you learn the look and feel for a language, you've got it. You may have to come back to reference a library if you've been away for a while but that's extremely minor. 
I tend to stick with something stable, has a large number of contributors, and is well documented. For my food project I used Gin with sqlx. For micro services at work I tend to stick with Gorilla router. For testing, I stick with standard library httptest 
Whatever works for you and your requirements is fine.
1. Gorilla mux is the best most feature complete router out there IMO. 2. Don't send the db around in context. Depency inject. So you could have a function that takes a db as an argument that return a http.HandlerFunc, this way the handler has access to the db. Or go down the struct route that implements the http.Handler interface and has the db on it as a property. I would mix a match, simple handlers can just be funcs, complex handlers that need loads of dependencies use structs. 3. Use httptest to spin up a real http server with your handler you can throw real requests at. Imo always connect to a real db loaded with fixtures for repeatable test cases. You can also interface your db to force certain error cases if you need.
Oh also check out table testing and also I wrote an article about testing with golden files here: https://medium.com/soon-london/testing-with-golden-files-in-go-7fccc71c43d3
When I was learning go, I threw this together. Hope it helps: [https://gitlab.com/J\-keys/go\_notes.git](https://gitlab.com/J-keys/go_notes.git)
just started a few weeks ago. I watch some videos (YouTube and pluralsite since my company provides access), and am reading the book "go in practice" come over to r/learngolang! it's super slow in there so we need more new people
I use go-kit and it's fine. Doesn't provide too much, is a bit opinionated, and needs too much boilerplate I guess. But once you get going it's very easy and separates the layers very well. There was a short talk by the author at some conference, should be easy to find.
[https://www.youtube.com/watch?v=M3BM9TB\-8yA](https://www.youtube.com/watch?v=M3BM9TB-8yA)
There's not just one way to accomplish something... Of course there are many ways to do REST APIs, just like how there are a million ways to write fizzbuzz or something. Whatever works and is clean is good. Here's a project you can look at for an idea of what one might look like (that I wrote): https://github.com/fharding1/todo
If you've got a ton of handlers that have the same needs, you can use one struct: type DBHandler struct { db *whateverDB } func (dbh *DBHandler) Handler1(rw http.RequestWriter, req *http.Request) { // has access to dbh.db } func (dbh *DBHandler) Handler2(rw http.RequestWriter, req *http.Request) { // has access to dbh.db } // register these via: dbHandlers := &amp;DBHandler{whateverDB} route.Add("/...1", http.HandlerFunc(dbHandlers.Handler1)) route.Add("/...2", http.HandlerFunc(dbHandlers.Handler2)) Though the instant you grow a handler that needs another parameter, be sure to create a new object, rather than an HTTP handler [God Object](https://en.wikipedia.org/wiki/God_object).
This. A "REST API" isn't a framework, or a piece of software, or something magical. It's just a defined set of URIs and HTTP verbs, and then one or more pieces of software which handle requests matching those definitions. But I know that isn't what you were actually asking. I think what you want the framework space to quiet down and for people to settle on "the" way to do things, to which I can only reply: "Look upon the Javascript space, and despair." Stay flexible, enjoy learning, and realize that there's never going to be any tool which will last forever.
That completely makes sense and thanks to your reasons, I will make SQL scripts instead of components that extend my code. Initially, my issue with writing SQL scripts was that I had to parse the data (CSV, TXT, XML, JOSN, etc.) and convert it into SQL statements. My thinking was, if I just used the component approach, I could parse and convert the data through the code in one neat\-component. But, you made valid points about maintenance and code/SQL flexibility. Thanks for your input!
I will tell you what would be ideal. RAML 1.0 to design the APIs, a Golang generator for generating the data models and server side resource handlers. Done. Longer story.. in the Java world we have RAML2JAXRS which JAXRS if not aware is the Java EE standard for handling http requests/responses (more notably, rest requests/responses). Within the RAML2JAXRS generator is the ability to configure a few things.. for example there are various libraries used for json to java and java to json objects. GSON, Jackson, JAXB, etc. You can configure it to use any of those libraries. Thus, what we need is a good RAML 1 to Golang (server side) generator that can be configured to use one of a few options. One would be straight http with what I see is the most common example of handling routes. One should be built around Gorilla/mux. Something like that would go a LONG way in abstracting the underlying concern of what is the right way to do APIs on the back end. Then you focus on your API itself, and let the generator build the code for you. Some will balk at this, especially those using Swagger/OpenAPI (as I understand there is some sort of half baked solution similar to what I am talking about for Swagger). The majority of java swagger users I have seen tend to build code first, then go back and add proprietary swagger annotations to generate a json swagger api doc. Then they use that to generate the awful swagger api doc and in some rare cases, see some people use the doc for generating tests and even client sdk code. It is, in my opinion the wrong approach though. API First design, single source of truth really allows you to focus on your API as you should, and generate all artifacts from that design doc. Anyway.. got off topic slightly.. but would love to see someone that is good enough with Go build a RAML 1 go parser that can use templates to then generate whatever, including server side api handling code in go. 
Have a look at my URL shortener microservice: [https://github.com/h00s/url-shortener-backend](https://github.com/h00s/url-shortener-backend) I've tried to keep it clean and simple. Adding routes is simple, DB queries are separated in own file as const etc. Would also love to get comments from fellow gophers on my code as this is my first Go microservice. 
This is my own attempt from a couple of years ago. I rather liked it but the company I wrote it for had shut down. https://github.com/Everythingme/vertex
That's awesome! I like the **database\-first, then ORM\-generation** approach. I'm glad you all are working on this. Also, ah, I see. I did notice a few, recent commits to the v3 branch relating to eager loading. Seems like you're almost there. Thanks for the invite. I'll see if I can jump in the Slack channel sometime this week. Otherwise, I'll look forward to the release.
this. And dave cheney's blog https://dave.cheney.net/category/golang
Situation: There are 15 competing standards.
What is the advantage of this async feature over doing the the usual way? 
Just remember about separation of concerns and create interfaces to be able to mock them easily in unit tests. 1. You want to have handlers as structs that implements http.Handle/HandleFunc and dependency inject your repository/store interface. Repository layer can be ommited if no advanced caching/multiple data sources fetching needed (just one data source like db). It should be used if you want to first check cache for data, if no data then fetch from store, save to cache etc. Store interface should have funcs for your DB operations like CRUD. Then your proper struct implements this (like postgres- dependency inject your *sql.db driver implementation and use it to implement store interface). For routing you can use gorilla mux that someone post here before. 2. For unit testing I would use gomock (it can generate your mocks implementation based on interfaces, very handy and convinient to use). Sometime with advanced scenarios or as other tool you can use monkey patching. I prefer BDD testing so ginkgo and gomega are tools that I like to use. 4. For integration tests you can use docker-compose to spin up needed DB, you service and scripts to invoke your tests. 3. Use wrk to test REST API performance. If needed, implement your handlers/repositories/stores using Chanel's for operations that can be done asynchronically (you can avoid blocking request, return some created ID and heavy I/O operation to be done in goroutines. This advice only if you want to scale and optimize every request. 
I thought the server struct pattern was fine: type Server struct { db \*whateverDB search \*elasticSearchHandler rt \*realtimeHandler }
I'm curious, how does Mat Ryer's suggestions not scale well? I've been meaning to try out his method, but what are the pitfalls? Mat Ryer's article: [How I write go http services after seven years](https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831)
Articles from medium for sure. medium.com/tag/golang
Amazing news Anything that reduces friction to refactoring is a step toward making Go an even more favourable choice
Also this. People can't agree if to pass authorization tokens in the URL query, HTTP header or even a cookie. All three ways are valid, preferring one over the other is subjective, and won't make your app one bit different to the user. There's no way to quiet it down, as you say: despair. Add websockets and gRPC to the mix, and you'll realize that you have to structure your APIs way differently than you would just for HTTP handlers, because damn sure you're not going to re-implement everything for each protocol you add. Or at least, you don't want to get stuck writing glue for it either. tl;dr: learn and go your own path young padawan
Yes this is also fine
I just copied the same model, controller, component/business layer model I use at work in c# for my home project in golang. It works great. Its small but it can scale to lots of routes. I have a api package where I define my route functions, and a component package where I define structs for my business logic. [Here is a picture of the general layout. This will work fine for you.](https://i.imgur.com/nZtiUFQ.png) 
Currently this is sitting in a language proposal: See: https://github.com/golang/go/issues/20504 Do you want to convert the key to be used with box or do you want to just do sign/verify? Also I'm wondering why does the sender have the public key? Shouldn't the sender by signing with the private key and the receiver verifying with the public key?
That's just called normal development, especially when learning.
For more complex needs I'd argue that Go could turn out to be troublesome. You'd have to program carefully to avoid allocation and unexpected GC pause lengths. If you follow zero allocation patterns Go can probably be good enough, though personally Go loses a lot of it's appear when having to be so careful about the GC. I'd likely choose Rust, fwiw. Now for simpler servers where you're less concerned about the tick rate, Go is a great option. Easy prototyping, overall very fast.
Yes, sure, but A: they all play with each other just fine and B: this is programming. Any language powerful enough to solve the problem is going to have multiple ways to do it. If Go isn't prescriptive enough for you, I've got bad news... you're already pretty much at maximum prescriptiveness.
I use [Vestigo](https://godoc.org/github.com/husobee/vestigo) and [Negroni](https://github.com/urfave/negroni).
Take a look at [Gorsk](https://github.com/ribice/gorsk).
See, if this answered the question, it wouldn't have been asked in this sub at least once a week for the past many years. This question will be asked again in this June, and the top comment will be similar to the parent of this comment.
Or just use Go instead of making another fucking runtime using another JavaScript spinoff.
If golang would fix (wink) the variable declaration order more people might use it...I was pleasantly surprised to see "struct" there and what looks like pointers. Also not fond of that Pascal remnant :=.
I started using buffalo, mainly because I wanted to create a RESTful API. I know frameworks are frowned upon in the Go community but I really wanted something where I can create migrations and manage the database that way instead because it makes deployment a bit nicer. I have only been using Go for a few weeks so I'm probably doing it wrong. 
Even "solved" problems are constantly evolving... while it can be frustrating, it's also a steady source of better ideas, and in a way, job security. Only so many people can keep up with all these varying ideas and concepts floating around... But the reality is that we tend to settle on something and cruise with it for several years. The decision paralysis is usually just a short window of time.
We just need to define a standard over those standards, and then we'd have 16 standards. ;)
Thanks for sharing this article, this is great. Simple, clear and practical examples. Definitely going to be applying some of these patterns to my projects.
Watch the video about this linked in another comment. He agrees with you but for proof of concepts and scientific computing it‚Äôs nicer to have dynamic languages. 
This is right up my alley, as I have been doing just this on my current project at work. We are using the gin framework, it‚Äôs super quick and straightforward. Every request is a context, and you can access query params or url params, you can use json marshaling with struct tags to easy bind json from requests into your go structs. We use swagger code generation to generate our models, but not any other go code. We are using dynamo db, which I don‚Äôt recommend. The biggest thing in Go is getting the hang of using interfaces and packages and understanding the order in which packages are initialized. Encapsulation is at the package level, so you can have as many files in a package as you want and all that code is in one namespace. Oh and write your tests in (package-name)_test format, that way you can import them and you test them the way they are imported elsewhere. There‚Äôs so much I could say if I went on and on. But yeah, Go is fun. 
My only comment is that Gin isn't the best, it's really lacking documentation wise. I was using it before too, but I much prefer Echo.
whats wrong with your eyes haha jeez
As long as we are talking about generated code, we have had great success with gRPC APIs with a rest-grpc gateway on top to provide the json http interface. All our developers need to do is write a protobuf and the business logic in a function and the rest is generated for them. It's still up to the protobuf designer to fit to a REST verb structure if they want, but most people only really mean JSON+http when they say REST anyway... Massive secondary plus side is having a much faster gRPC interface, which has since become our primary interface with JSON+http as a compatibility interface basically.
https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831?source=linkShare-b9a723f6b2a0-1528336752
Go‚Äôs HTTP library is already asynchronous (NIO), just spawn a new goroutine.
its just a wrapper over Go internal HTTP and go routine. you can make more easier way to sending http request. 
[Previous post from the author](https://www.reddit.com/r/golang/comments/8p3gfo/http_client_for_go_with_asynchronous_support/).
Previous post was deleted, I just edited its title.
No, sorry. Different constraints lead to different solutions for this task.
Except for vi and emacs, those last forever
Go examples: [https://github.com/shijuvar/gokit](https://github.com/shijuvar/gokit)
Cool read, thanks :)
I have been using gin too for about 3 years, and it proved itself to be easy yet powerful tool. Very flexible to different application structures, and easy to manage. In couple of projects, I use it to create proxy endpoints to other rest services like PostgREST and OSNAME geolocation, while keep authentication and session management on the main backend service.
Nah, there‚Äôs nothing wrong with using a framework if it solves your problems. Buffalo is decent, Gin is decent, most of the popular frameworks are at least good and some are great but it‚Äôs not like writing everything with just the std lib makes you better somehow. There are times when that‚Äôs appropriate (a small throwaway proof of concept, a one-off service that only needs a handler or two, constrained environments without easy internet access, whatever), but these frameworks exist for a reason. People find them useful.
&gt; 16 hours a day on weekend whoa there partner, take some breaks! go outside for a bit! :-)
16 Hours is on the very high side, i usually do 10 hours , so i do have the time for some fun :)
btw, I'm very impressed with how easy it is to run integration tests in Travis CI. https://github.com/a8m/rql/pull/2
I concur. If you plan on having collaborators and/or multiple clients, nothing beats a .proto contract. 
My setup that I'm very happy with: - Postgres via go-pg - Gin gonic for rest handlers and json handling - One-time email passwords, jwt for auth (with bcrypt) - Clean/hexagonal architecture (separate stores, domain logic, entities, ui adapters like rest) where each layer is a different go package. - Tests at each layer of the clean architecture using go test. I make and populate a throwaway db on each test run at the store and domain layers. Your db stuff should be nowhere near your http handlers / context. Just make a db handle in your stores package. Your domain logic and anything above should know nothing about your db.
Good point. I like Go, it's fast, concurrent, typed and it's strict.
you can either read a config file with the values or read the values from the environment variables on the program startup. heres the gitea conf file: https://github.com/go-gitea/gitea/blob/master/custom/conf/app.ini.sample#L202
Hopefully at least the words "as soon as you feel ready" at least make sense. :)
Wow, going into great detail. But I have one question left regarding memory allocation. You all know probably about the programming-languages benchmark game and I am talking about the binary trees benchmark which is a pure GC allocation stresstest. You allocate one big tree first which has static lifetime and then a lot of trees with a very small lifetime. In comparison Go performs worse in this benchmark compared to most other static or VM languages. I always thought it was the allocators fault providing memory slowly as the GC chasing pointers runs concurrently and I got 12 vCores at hand so only higher CPU load. But what exactly is the bottleneck? When you calm down the GC by setting the GC value higher (I think I settled at 750) the performance more than doubles. I heard that the GC can pause a goroutine if it's allocating too much and it then has to help allocating new memmory. Is it that what holds it back?
encoding/gob is great, but the order of map items in the output is randomized. I needed the output to be deterministic in order to take the hash of the resultant binary. stablegob is a fork of encoding/gob with some minor changes to enable this. Note: Map keys are buffered and sorted before writing to the output, so this will affect performance, and custom marshalers can break it... So use with care.
encoding/gob is great, but the order of map items in the output is randomized. I needed the output to be deterministic in order to take the hash of the resultant binary. stablegob is a fork of encoding/gob with some minor changes to enable this. The binary output only differs in the ordering of map items, so it's 100% compatible with the Decoder in encoding/gob. Note: Map keys are buffered and sorted before writing to the output, so this will affect performance, and custom marshalers can break it... So use with care.
4. Use a quick JSON marshaller/unmarshaller. The one in the standard library is fine for small/medium projects but there are quicker implementations out there (which are interface compatible)
4. Use a quick JSON marshaller/unmarshaller. The one in the standard library is fine for small/medium projects but there are quicker implementations out there (which are interface compatible)
4. Use a quick JSON marshaller/unmarshaller. The one in the standard library is fine for small/medium projects but there are quicker implementations out there (which are interface compatible)
Single file doesn't mean you can't have a config file.
Not RAML, but something similar to Swagger before it was openAPI or whatever: - The main schema tool - https://github.com/titpetric/spec - https://github.com/titpetric/crust/tree/master/docs/src - spec.json (schema input) - auxiliary docs like /message/index.md - generated spec/ folder with individual API schemas - README.md generator from the spec files (PHP) https://github.com/titpetric/crust/tree/master/docs - Generated scaffolding based on API schema: https://github.com/titpetric/crust/tree/master/sam The scaffolding itself takes care of pretty much everything except as the inner API local implementation. I'm also thinking about generating .proto files and in turn a gRPC API layer, but I haven't evaluated any http-gRPC bridges yet. It would be possible to extend it further to actually take valid swagger schema or RAML definitions as input. Not to mention that most of the codegens here are PHP, I just chose what was easier to work with in terms of dependencies as Go templating isn't my forte. The other option would be Node EJS, but I didn't want to pull in a 100MB node_modules folder. Go with what you know.
It is possible to embed resources (like configuration files) in an executable. Many of the single binary apps I have encountered creates a config file on first run with default values. The default values for a database is usually set to sqlite3, which is an embedded database (does not require an external process to run) and allows the executable to setup everything it requires. This can then be changed for the second run, by editing the config. So to answer your questions: &gt; How do databases work with single binary Go programs like Gitea/Gogs, Mattermost, etc? I guess the same as most other applications. &gt; Is it typical just to do database configurations from the frontend at runtime? _typical_? I don't know. _Common_, sure. &gt; is that usually with the assumption that you have installed and prepared a database? They can use sqlite3 and then they don't have that external dependency &gt; Are there no standard ways to do this? I guess not. I don't think most things are truly "no config, click once, use". So for things that run on servers there will be either config files, or if it is a web server, a config page. For things that a command line tools (another area go excels at) then reading from environment or flags is a go-to. Hope this helps. If there is anything specific that I have missed, feel free to ask. 
I agree, this does seem possible.
That's a nice optimisation with regards to the SDK indexing. Nice work as always JetBrains.
yeah. I faced up same issue. I spent a lot of time for learning deeply. Now I am using qor easily.
Oh, jerf was talking about a single handler needing another object, say. Sorry. I wonder how much stuff I misunderstand every day.. 
I've used that technique for services with about 100 endpoints and it scales nicely. You can break it into multiple structs if you'd prefer, but I'd only do that if the list of dependencies grows too large, not if the number of handlers do. Hit me up on Gopher's Slack if you'd like to discuss it more.
In `db.go` why are you doing empty returns when `err != nil` ?
I'd love to get your feedback, especially on performance. ‚ò∫
The only pet peeve I have is that VSZ isn't explained properly. From the article: &gt; Virtual Memory Size(VSZ) is the amount of address space that a process is managing. This includes all types of memory, both in RAM and swapped out. And actual explanation from a stack-overflow answer [here](https://stackoverflow.com/a/21049737/112129): &gt; VSZ is the Virtual Memory Size. It includes all memory that the process can access, including memory that is swapped out, memory that is allocated, but not used, and memory that is from shared libraries. The article simplified the concept of VSZ so much, that it's not even true anymore. The process isn't managing this memory, it just has access to it. There's a whole kernel subsystem dedicated for de-duplication of memory allocation, called [Kernel same-page merging (KSM)](https://en.wikipedia.org/wiki/Kernel_same-page_merging). If anything, this memory is managed by the shared libraries the process uses, and the kernel itself. tl;dr I'm anal about VSZ
Let's just all use gRPC and live a happy little life with a bit of consistency.
https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk I would take a look at the Reader type and the Writer type first. https://medium.com/@matryer/golang-advent-calendar-day-seventeen-io-reader-in-depth-6f744bb4320b Follow the Reader type into the strings package for string.NewReader() https://tour.golang.org/methods/21 Then follow them into the io package where they are both used and just work out the methods. Then follow the oi package and then into the http package. You start to then understand how packages are made. Don't throw everything into closures! Like interfaces and embedded structs. This is not c# and don't make it into it, cause youll be running into a lot of errors. The go way is easy readability! So use it as such and just follow it, later on you will see why.
This is always a good reference for apps I think: https://12factor.net/ Number 3 covers keeping config values in the environment. 
Consider whether you can just a SQLite database. That's a database existing in the form of a single file that simply gets read from and written to, the engine and schema embedded in your Go binary itself, not needing any pre-existing installation or user-side configuration. It's not appropriate for a big web/network app like Twitter where thousands of users initiate writes constantly, but for almost any other type of application it works shockingly well. Firefox, Steam, Android, iOS, iTunes etc are all built around a SQLite database or databases.
Thanks for sharing. I do have to ask "what's the benefit of this client over other clients out there?". For example [https://github.com/parnurzeal/gorequest](https://github.com/parnurzeal/gorequest) seems quite well\-established. Would love to know reasoning behind creating another one and what did not work with existing projects.
That's an excellent writeup. It's longer than I expected it to be, but the content is great. It might make a good chapter in a book, actually. Got something in the works?
One problem with this is though, if the code you're calling does not return the zero value in case of an error, and some where down the line there's a check like: if val != nil { // whoops }
Thanks, I'll keep an eye that proposal, it would do exactly what I need. If I had the conversion functions, I would use box with an ephemeral key. I'm experimenting with stateless mixnet routing. In this case, the sender is the origin, the receiver is a routing node and the message is the next node in the route. So the message is not signed. Admittedly, I could solve this by giving each node an exchange key, but other parts of the system require them to have a signing key, so I'd prefer to just use that.
Would be nice if they try something else in the json serialization, I think we have tons of fast json libs nowdays ...
Hate the title, reminds me of bullshit self-help books. Content is good though
Both `=` and `:=` exist in Go for different reasons. As a statically typed language you can infer the type of a variable using `:=`, where the type returned is the type of the variable. This gives you an intuitive shorthand in Go to assign `varname := functionA()`. Let's says functionA returns an uint32, then variable `varname` is of type uint32. Varname was not declared prior to this, and it's short and easy and minimizes verbosity. You could have also declared this variable previously, in which case the declaration of the variable and assignment in separate lines would be var varname uint32 // Some stuff happens varname = functionA() They serve different purposes and it works pretty intuitively. 
I've been a C# developer since the first beta release, and I transitioned to mostly Go about 3.5 years ago, so I feel I can add some insight. If you are proficient in C#, here are the few things that will seem non\-obvious in Go: * Slices (easy once you think of slices as a value that holds a pointer to an underlying array) * Channels &amp; Go routines * interfaces / duck typing * Embedding / Composition That alone will allow you to hack something useful together. Then you will eventually learn to think in Go and write idiomatic code. There are a few things from C# that you will likely miss: * Generics (not wanting to debate the merits, but you will want them if you think in C#) * EntityFramework / Linq (see above bullet point) * Perhaps exceptions Learning Go will make you a better C# developer. Here is why: * OO architects often talk about "preferring composition to inheritance", but Go will teach you to think that way and why it's better * You will depend less on abstraction for the sake of abstractions * You will think harder about dependency * You will write cleaner code * You will think differently about error handling Now, one could argue that many of these benefits come from learning any other language. In my career I've written C, C#, C\+\+, Go, Java, Obj\-C, Python, PHP , JavaScript and a few others. I've probably written my most SLOC in C#, and I have no doubt that I've become a better programmer since starting to write Go. 
Alternatively\-\-*for the specific goal of de facto standardization in writing REST APIs*\-\-you could look upon the (modern, post ASP.NET Core 2) C# space and say "why can't we have that? /sadface" My take, as someone who likes both Go and C#, is that this is actually a very fundamental difference in philosophy, but that neither is demonstrably and quantitatively better than the other. The C# community has chosen a "batteries\-included" philosophy where you don't have to spend mental cycles thinking about things like which router to use, but you may have a bad time if it doesn't work in the way that you want. Meanwhile the Go community has chosen a "linux utilities" philosophy with a loose collection of individually specialized parts. Here there is actually a pretty daunting initial learning curve\-\-at least there certainly was for me\-\-to getting up to speed on what pieces you need, and what their differences are, and which ones aren't preferred any more, and how you piece them all together. These fundamental philosophical positions are unlikely to change. If you want the experience of there being a "right" choice, you might seriously consider whether C# is just a better fit for how you write code. OTOH if you are already motivated to write in Go anyway, try to appreciate the potential benefits of flexibility. Neither direction is wrong; just different.
&gt; I always thought it was the allocators fault providing memory slowly as the GC chasing pointers runs concurrently I think allocation part should be really fast :) &gt; I heard that the GC can pause a goroutine if it's allocating too much and it then has to help allocating new memmory. Not exactly, when a gouroutine is allocating a lot, it has to help GC to clean the garbage out. A couple good resources explaining that: https://www.infoq.com/interviews/hudson-go-gc https://www.youtube.com/watch?v=aiv1JOfMjm0 &gt; Is it that what holds it back? Probably, but it depends on how benchmark is written. If one goroutine is doing all of the allocations, when most likely yes. 
Cool, you are definitively right! Thanks for letting me know. I'll fix it by just using and referencing stackoverflow answer's definition.
Re: "Not exactly, when a gouroutine is allocating a lot, it has to help GC to clean the garbage out. " Found a beautiful explanation by Rick Hudson: &gt;it. So our coordinator, which we call our pacer, needs to somehow slow down that application thread so that it can meet its deadlines, the GCs deadlines, and it does that quite cleverly. It says ‚ÄúOK. You want more space, but before we give you this space, you have to do two things: first, you have to check to see if the GC has made enough progress that you can just take the space, or you have to stop and you have to help the GC out enough so that there is enough credit, if you will, for you to go and do the allocation.
Interesting, so basically this is the trade off between latency and throughput in Go. That's why Java is faster in heavy allocation/throughput cases but stop the world pauses are longer.
Java is still dominating everything aside from plaintext, tho it's not surprising. Rust and Go hold first two positions in plain text benchmark but I hard it find to justify "custom nginx" where there is normal nginx. Other than that - Go still holds quite good positions. It would be interesting to see how it changes with new runtime changes in 1.11. Especially new [scheduler](https://github.com/golang/go/issues/24543)
I usually delineate that scripting languages are best for scripting and robust languages are best for applications. Maybe [Neugram](https://neugram.io) will get some more attention someday.
mint is already: * a vegetable * a Linux distribution * a Swift package manager Stop naming things mint!
[removed]
I added chi benchmarks and also added the fastest JSON libraries available: gojay, sjson and easyjson. you can see the results there
Hehe. I made a static site generator in golang and tentatively called it mint. There's something so satisfying about that name!
It's also where they make all the pennies!
Err.... exactly what are you looking for here? I can review this for you if you like, but it's, errr, not a very positive review. If you'd like it, I can give it to you (I wrote a lot of it up before realizing it was a bit much to just blind post), but I think you'd better ask for it. But, even though I sort of hate to say it, it sometimes needs to be said: if you are reading this, don't use this library. You're better off with net/http directly and simply factoring out anything you find yourself repeating a lot. (I hate to say it, but experience shows me that if nobody says it, sometimes inexperienced people can get trapped by these things, and before you know it if nobody speaks up sometimes these things even become "best practices", and I know that sounds dramatic but I've seen it happen. So I have to speak up.)
There is probably something wrong, not sure how gojay is that slow compare to the rest, from my own test it's up to 10x faster than the regular json lib.
Great write up. Extremely informative.
Wonderful! I have been in need of most of these features for a while. Kudos to JetBrains! 
Named returns. err is set before defer(). Because of that, defer returns that err. In defer, I'm checking if err is not nil. If it's not, there was an error in one of the transaction execute's. That's an information I need to rollback transaction. If there wasn't error, I'm trying to commit transaction. If that fails, that error is returned. If I wasn't using defer with named return, I would have to put rollback in all statement executes (in err checking).
I was using Echo before in one of my small pet project. Echo's documentation is really far better than Gin documention. However, I read that Gin is much faster than Echo so I chose Gin for this. Should I switch to Echo? Didn't know about sqlx, will look it up! Thanks for the suggestion, I really appreciate it!
There are go projects that don't have "go" in their name?
Embedding a database inside an application is handy if most of the calculations are local. Ledisdb (like redis) and sqlite3 (like mysql) are two more full-featured databases. Rocksdb, Leveldb, Boltdb, and others are more basic key -&gt; value data stores. Often a "single binary" is actually a file that contains it's own internal structure. Mac apps for example, are really a folder disguised as a single file. (https://github.com/Xeoncross/macappshell)
Well Java will keep dominating. May be it is not their purpose but they do not mention how much memory that framework is consuming. Go will perform very well on that metrics. Now I know many claim RAM is cheap and all. But in cloud environment Java based solution will be more expensive to run.
Can you recommend a better title? Something that will spark interest 
Do you have a source for that? Most things I've seen show Echo a little bit faster. Regardless I don't think any speed difference would be worth it anyway. It's not like we're actually going to be serving 100 reqs/sec or anything.
If you don't feel you're missing anything then you're not missing anything. I've been using vscode for quite some time and I have started evaluation of goland because I'm so sick and tired of vscode lagginess. Plugins pause (and I have only few plugins, mainly go related) and nothing works and it takes few minutes to restore from this, vim plugin stops (or never starts) working when I open vscode so usually every day I have to reopen vscode few times before plugins wake up.. The SFTP plugin was the only thing keeping me in that corner until it went buggy and started to upload everything which takes ages. Oh yeah and all that grief is multiplied when I open a second window of vscode. I'd rather use vim but I'm stuck with windows at work and I'm getting sick and tired of the constant bugs and instability it has. Hopefully goland will be better since I'm at the end of my rope when it comes to vscode.
Can you recommend a http-grpc bridge, and a websocket one too? A codegen which would generate http routes to grpc rpcs? Would you need to create two way grpc bindings for websocket implementations, or would you just result to internal polling in most cases?
https://goa.design
What's the difference between this and transpiring TS into JS, performance wise? 
[https://labstack.com/](https://labstack.com/)
here's the code: https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Go/chi/src/chi-gojay/server.go#L131 
I think the new scheduler is coming in 1.12, not 1.11
Switch to gRPC http://grpc.io
its single binary, not single file. we use flag files, config files, or just cmdline flags to point the program to a db.
I've been following a pattern similar to this for a few months with great success: https://github.com/douglasmakey/ursho Sometimes there are weird edge cases where the logic doesn't flow like I'd like it to, but overall it makes it easy to seperate what's controlled by the data layer and what's controlled by the HTTP layer. The only big difference would be is I don't have my main.go file in the root of my project, I have it under a cmd/app_name/ directory where app_name changes on the context of what I'm writing, typically a 'frontend' and a 'manager' where the manager is a user admin. I found this while watching this video from Francesc Campoy: https://www.youtube.com/watch?v=SWKuYLqouIY I've been trying out different ways of organizing my code for go over the past few years, and this is probably the pattern I'm going to settle in on for the foreseeable future as it's what I've been building up to. The take-away is the DB isn't connected to the context, I've seen that pattern, but to me it didn't make too much sense. The DB is connected to the service that handles the routing, so I may have something like: type frontend struct { svc storage.FrontendService } func New(svc storage.FrontendService) (http.Handler, error) { e := echo.New() f := frontend{} f.svc = svc e.GET("/", f.homepage) return e, nil } func (f *frontend) homepage(e echo.Context) error { users, err := f.svc.GetAllUsers() if err != nil { return c.JSON(http.StatusBadGateway, err) } return c.JSON(http.StatusOK, users) } Then, the svc passed through might be a cache layer but it's pointing to an interface, but when I set up the app that cache layer is set up with a DB layer, so I know that when I call the svc from the controller I'll always hit the internal cache layer first and then the internal cache layer has it's own logic for clearing out stale caches and pulling from the DB. If you'd like to know more, I can provide more info.
Often times, these web apps seem to advertise "single binary" as a selling point. If there are other supporting files, like config files, is the benefit purely that there are less dependencies (like node_modules) and less files executing code? 
Thanks for clarification on the GC pausing goroutines part. And here is the link to the currently fastest implementation: [https://benchmarksgame\-team.pages.debian.net/benchmarksgame/program/binarytrees\-go\-4.html](https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/binarytrees-go-4.html) It does indeed use one goroutine per tree.
Yes. No. Maybe.
Username checks out...
[removed]
A few feedbacks: 1. Your `tree.Node` and `list.Node` both defined `Data() string`. It could be `Data() interface{}` the you just use `fmt.Printf("%v")` to use whatever `String()` their actual data type defined. 2. Your `queue.Print()` and `stack.Print()` would both `pop()` everything from the `queue` or `stack`. That's a huge side-effect for a `Print` function no one would want.
1. Agree. Will make the changes. 2. Indeed. The reason I chose Pop/Push to iterate through the elements was because both stack and queue are abstract data types. You can build them using different data structures like arrays and linked lists. Regardless of the underlying d.s., developers will need to define insert/delete methods on the type. I reckoned, just calling these methods when implementing the interface would be faster (to use) [e.g](https://github.com/shivamMg/ppds/blob/master/stack/stack_test.go#L28). I think I'll add documentation around how it uses Pop/Push internally so it's clear.
le relevant username XD
Font to large?
Probably worth pointing out that the guy who's making deno is the guy who made Node.
If I was going to pick one to go with first, which would you recommend?
hmmmm $250 is steep, but I'll take a peek.
[https://forum.golangbridge.org/c/jobs](https://forum.golangbridge.org/c/jobs) And the jobs channel on [https://invite.slack.golangbridge.org/](https://invite.slack.golangbridge.org/) also [https://golangnews.com/stories?q=Hiring:](https://golangnews.com/stories?q=Hiring:) is a good place
Go is so easy to learn I imagine you could just find yourself good programmers rather than looking for Go programmers. They will be Go programmers in 7 days. 
That website has absolutely 0 information about what it is, just has code and forums
The piece of mind of having such brilliant engineers behind the project.
Instead of forking all of encoding/gob, you can converted the map into a slice before handing it to encoding/gob. That sounds much nicer to maintain.
and a fantastic but no longer maintained self\-hosted analytics project. 
the color scheme is interesting lol
There is newer frontend language called Mint https://www.mint-lang.com/ :)
I‚Äôd go for the introduction to go on Greater Commons then follow it up with the web programming in go course as it‚Äôs amazing as well. It starts off with the absolute basics, but Todd does such a great job going in depth on things that it doesn‚Äôt get boring and I still find myself learning things. Plus, he gives great examples of how things are done in golang, so if you‚Äôre coming from a different language it clears things up nicely.
vim-go in powershell default.
I would checkout [Golang API Skeleton](https://github.com/crwgregory/golang-api-skeleton.git). Pretty simple to set up. Dockerized, scaleable, tested in realworld applications, MVC architecture. I would use that as a template to build out your application.
The only thing that is a single file is the binary (app) all the relevant assets like HTML/CSS/JS and even configuration, are separate files. That said, even in PHP one of the best practices according to 12 factor apps (12factor.net) is to use the environment variables as means of configuration.
Good writing. Too long for a single blog post though. If I were you I would split the content into multiple blog articles where reasoning from one would immediately lead to the next entry. 
Great overview. I switched to go in January after nothing but C# for ~6 years and this is all spot on
[https://github.com/gorilla/websocket](https://github.com/gorilla/websocket) Gorilla is known to be pretty stable, so I'd suggest this lib.
https://godoc.org/golang.org/x/net/websocket Extended lib has you covered
From the package documentation: &gt; This package currently lacks some features found in an alternative and more actively maintained WebSocket package: 
It works great for us in production 
It works great for us in production 
Why does a social app need to use a blockchain?
I have played around with [https://echo.labstack.com/](https://echo.labstack.com/) . It worked pretty well for me.
go get -u golang.org/x/net/websocket here's sample: https://gist.github.com/9nut/11052587#file-wstest-go
Why ask why? Bring it on!
Its not intrinsicly wrong, or too a hard problem to crack. It would be nice to nto have this issue like with node. Relative file paths lead to an easy way to make starter style applications. I would rather sidestep this issue rather than manually change paths
The largest rectangle that contains 2 rectangles would be infinite, it is the smallest possible rectangle that is returned by Union
Gotcha, I kept conceptualizing it as the largest rectangle *overlapping* r and s, not the smallest rectangle *containing* both. I get it now, thanks!
&gt; go1.10.3 (released 2018/06/05) includes fixes to the go command, and the crypto/tls, crypto/x509, and strings packages. In particular, it adds minimal support to the go command for the vgo transition. See the Go 1.10.3 milestone on our issue tracker for details. From the linked text at https://go.googlesource.com/go/+/d4e21288e444d3ffd30d1a0737f15ea3fc3b8ad9 &gt; &gt; cmd/go: add minimal module-awareness for legacy operation &gt; &gt; We want authors to be able to publish code that works with both &gt; the current standard go command and the planned new go command &gt; support for modules. If authors have tagged their code v2 or later, &gt; semantic import versioning means the import paths must include a &gt; v2 path element after the path prefix naming the module. &gt; One option for making this convention compatible with original go get &gt; is to move code into a v2 subdirectory of the root. &gt; That makes sense for some authors, but many authors would prefer &gt; not to move all the code into a v2 subdirectory for a transition and &gt; then move it back up once we everyone has a module-aware go command. &gt; &gt; Instead, this CL teaches the old (non-module-aware) go command &gt; a tiny amount about modules and their import paths, to expand &gt; the options for authors who want to publish compatible packages. &gt; If an author has a v2 of a package, say my/thing/v2/sub/pkg, &gt; in the my/thing repo's sub/pkg subdirectory (no v2 in the file system path), &gt; then old go get continues to import that package as my/thing/sub/pkg. &gt; But when go get is processing code in any module (code in a tree with &gt; a go.mod file) and encounters a path like my/thing/v2/sub/pkg, &gt; it will check to see if my/thing/go.mod says "module my/thing/v2". &gt; If so, the go command will read the import my/thing/v2/sub/pkg &gt; as if it said my/thing/sub/pkg, which is the correct "old" import path &gt; for the package in question. &gt; &gt; This CL will be back-ported to Go 1.10 and Go 1.9 as well. &gt; &gt; Once users have updated to the latest Go point releases containing &gt; this new logic, authors will be able to update to using modules &gt; within their own repos, including using semantic import paths &gt; with vN path elements, and old go get will still be able to consume &gt; those repositories. &gt; &gt; This CL also makes "go get" ignore meta go-import lines using &gt; the new "mod" VCS type. This allows a package to specify both &gt; a "mod" type and a "git" type, to present more efficient module &gt; access to module-aware go but still present a Git repo to the old &gt; "go get". Very excited to see this moving forward so quickly!
Just to chime in but I'm not aware of many games using deterministic physics that would require "rewriting physics code." That idea is mostly screwed already if you use a popular game engine with something like PhysX. 
Your stackoverflow link is broken
[removed]
Brought to you today by the letters G, M, P and the number 7.
[removed]
whether the physics is deterministic or not, an authoritative server architecture is going to run physics on the server to decide where things are, and the client is going to run physics to do prediction while it waits for authoritative responses from the server. https://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking 
I would disagree. They would be able to adjust to Go syntactically and parse through the logic bits, but it‚Äôs a paradigm shift with respect to composition vs. inheritance. Some of the most seasoned principal devs where I work said it took them 2 months.
The package has bugs that are only triggered in some circumstances. It's great that the package is working for you, but it does not work for all. 
two months is still pretty quick. maybe that was the joke! I had more trouble with slice syntax than composition. Don't tell anyone. 
Well I did say the principal devs, dudes that have been coding since like 10. =)
I think we might be thinking of different "physics" here. There really isn't any physics "simulation" in e.g. counter-strike. I'm talking very latency sensitive kinematic/kinetic simulations. Even still, I don't know of any games that are doing fully authoritative client-server interaction, other than older MMORPGs where you could get away with it for a few reasons (relatively predictable, simple motion, higher tolerance of latency, etc.). Yeah there are things like lockstep, but unless something has flip flopped since I wrote game client-server stuff, it's more about using basic kinematics to keep semi-authoritative clients in check; many larger titles make heavy use of mandatory anti-cheat services to further mitigate things.
&gt;I think we might be thinking of different "physics" here. Yes sometimes people use physics to just describe any movement in the game. In countrstrike you would at least have bullets traveling in vectors, or maybe arcs, players moving and falling, etc. &gt;it's more about using basic kinematics to keep semi-authoritative clients in check If you want the player to fire a projectile, and see where it went immediately, the client needs the code to simulate where the bullet goes. If the server is then going to decide if you actually hit someone, it needs the code to decide where the bullet goes. That code needs to be identical. If you think games typically just let the client say they hit someone authoritatively, that is incorrect. 
Fixed, thanks!
I am definitely in the camp of "keep it simple". [I to Mat Ryer's article](https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831) for the basics, though I often supplement it with a few personal opinions. - I prefer RPC over REST. Usually I don't worry about the specific verb; I'd prefer an endpoint like `/user/create` over `POST /user`. - That being said, there are legitimate reasons why you wouldn't want some operations, especially non-idempotent ones, to be on GET requests. Often I'll simply force every request to be a POST request. Philosophically I don't "care" what the verb is, but technically it is always POST; you can't just send anything. - I try to keep every parameter to the RPC inside the JSON body of the request. No query/url parameters. A query might look like `POST /user/get { id: "12345" }`. - Specifically with read operations: I always conceptualize the "query" you pass in the body as a series of and-filters on the set of all data. So if you say `POST /user/get`, logically start with the set of all users, filter them by the list of users you're allowed to see based on your authorization, then apply each "filter" in the query one by one until you get the list of all results. Of course, you'll want to do this in the code before the query instead of making multiple database calls or querying for everyone then doing the filtering in the code; just basic query-building. - HTTP status codes in the result are important, but I don't think they solve the whole problem of letting clients know what the heck happened during a request, especially in the case of errors. I've always liked the idea of having your own set of "error codes" you can return which map back to HTTP status codes + a human readable message. - Building on that, I like having a single format for every single request that gets sent back, error or not. The basic format might look like `{ ok: true, data: { ... }}` for successful requests, or `ok: false, errorCode: "UserNotFound", errorMessage: "the request user 12345 was not found" }` for errors.
Well, what I mean by semi-authoritative is the clients are "optimistic" i.e. they assume the client's game state is accurate. You then run a very barebones "simulation" on the server that would be able to verify the client's actions as correct before updating its game state and broadcasting to others. Thus you could see yourself as shooting and hitting (e.g. blood/splash particle effects and sound) enemies despite your Internet dying. I'm coming from more of an MMO background though and you rarely are aiming for or players expecting the same accuracy as in something like counter-strike though.
I've refactored most of the project into sub packages, still have to abstract away my user handlers and not make them dependent on "http.ResponseWriter" 
Just refactored most of the project, still lots to improve and need to figure out how to add testing but I think overall it definitely has improved. Thanks for recommending that I create smaller packages, definitely a lot cleaner.
&gt; I kept conceptualizing it as the largest rectangle overlapping r and s Which would still be infinite :) (containment is a form of overlapping)
You can actually get it for $10 right now! I went ahead and dropped $39 on the Great Commons one mentioned below. 
A chatbot for what? Discord? Slack? IRC?
I have to agree with /u/rangeCheck here...that's really a *huge* side effect for a pretty printer... I don't think it'd be unreasonable to expect `Peek(n int) interface{}` and `Len() int` Other than that, looks very pretty :)
Technically, Rectangle is 2 points, and a Point is 2 ints. There is no "infinite" int, so the largest Rectangle would be starting at a Point somewhere between `-math.MaxInt32, -math.MaxInt32` and `-‚àû, -‚àû`, and ending at a point somewhere between `math.MaxInt32, math.MaxInt32` and `‚àû, ‚àû`, depending on platform. :D
For more pedantic fun: The smallest containing rectangle of any two subject rectangles is the same as the largest overlapping rectangle for which at least 1 of each pair of adjacent points is contained within the subject rectangles.
A chatbot for what? I have packages for FB messenger and Viber chatbots: https://github.com/mileusna/facebook-messenger https://github.com/mileusna/viber
Works well with arrays and slices where arbitrary access is easy and fast (O(1)). What if you've built your stack/queue over a linked list? To implement the Peek function developer will need to write logic that starts at the head and iterates until nth element is reached. Probably something like: func (s Stack) Peek(n int) (interface{}, bool) { if n &lt; 0 || n &gt;= s.Len() { return nil, false } // s.head is ptr to first node in the linked list node := s.head for n &gt; 0 { node = node.next n-- } return node, true } I didn't want the developer to go about writing much logic to implement the interface. The library should be sort of pluggable. If push/pop methods for a stack type (enqueue/dequeue for queue) have already been implemented (pretty good assumption), why not just call them inside Push/Pop. [e.g.](https://github.com/shivamMg/ppds/blob/master/stack/stack_test.go#L28). Also, Peek in case of linked lists will take O(n). When I'll be using it for printing it'll take O(n^(2)) - not a big factor since people probably won't print huge lists but still.
"Having learned" a language can mean different things.. Besides understanding the syntax of a language there are paradigms, knowledge of the standard library, knowing all the crazy quirks that come with every language and so on. You certainly won't learn all of that in 7 days.. I know it's a common statement that learning the next language is easy if you already know another. But this is merely about picking something up not becoming good at it. I even heard this kind of statement from management before.. it's really time to kill this sentiment for the sake of serious developers.
Sure, bulletproof code (as in no-bugs) is a myth. This is about code quality and confidence. No need to oversell it.
You need to call r.ParseForm() first. Check out: https://golang.org/pkg/net/http/#Request.ParseForm
Are you submitting the data from Postman as form encoded data? Your browser will be doing that automatically from forms.
It was on sale last week. Email me and I'll get you the discount code from the sale. jon@calhoun.io
Why is 1.9 also being updated? This is the first time I‚Äôve noticed a previous minor version be updated along with the newest, but I can‚Äôt say I‚Äôve really been paying attention. Why not just ship 1.10.3? Anyone running 1.9 code should work perfectly with 1.10, no? I‚Äôm sure this has been asked and answered before but it‚Äôs the first I‚Äôve noticed. 
If you want some projects to practice on for free plus screencasts to accompany them - Gophercises.com
This would be a little experimental but if HTTP/2 is what you are aiming at maybe you could look at gRPC streams as a solution which would give you a defined contract between your frontend and your backend. Here is a frontend example https://github.com/grpc/grpc-web. On the backend you would expose the gRPC service publicly that itself could consume from a pub./ub message system. Iv'e not tried it myself, just floating the idea. Or just go with https://github.com/gorilla/websocket - I've used that with a lot of success :)
Consider also the new websocket library with focus on performance: https://github.com/gobwas/ws
Reading this article makes it so obvious that versioning is *required*, it should have been published years ago :-)
Same reason why backports exist. A minor release only contains regressions and security fixes. 1.10 is a major version upgrade with major code changes. If your application is running fine with 1.9 and you need to get those regressions and security holes patched, 1.9.x is the right way. Otherwise, you are taking a risk by deploying 1.10 directly in production. If you have tested your app with 1.10 thoroughly, then you should already be on 1.10, in which case, just upgrade to 1.10.x. https://github.com/golang/go/wiki/MinorReleases
Oh man, thanks a lot. I never thought of that option
You may also need to send set the `content-type` header to be `application/x-www-form-urlencoded`
The most honest answer to most of your questions is basically "this is why you don't see a lot of this kind of library for Go". The aren't any great solutions right now.
How is that related to websockets?
Oh yeah that is a much clearer answer lol
Any of those is fine, but messenger will do.
That will do. I will check them out. 
https://github.com/qbeon/webwire-go
I scanned the article but couldn't see any note on the number of developers surveyed? Interesting article, and always important to keep in mind the sample size.
last time I checked the other implementations they were using memory pools/arenas so it's not exactly a fair comparison.
You can find more information on methodology and numbers here: https://www.jetbrains.com/research/devecosystem-2018/demographics/
No I wasn't sarcastic. Of course you won't learn everything in 7 days but you will learn enough to be productive, especially if you are on a team where other people have been doing the language a while. If we were talking about C++ or Rust or Haskell I would agree with you that it would be a long time before you could be productive on a project, but Go just doesn't have that many quirks. Anyway at my company we are a mostly C# shop but we have never hired caring very much if you happen to know C#, and this has been fine. Many other companies are similar. Of course there would be exceptions if you need something hard done very soon! 
Thank you for sharing. Being new to go this was a clear explanation of go and concurrency.
thanks - I guess we'll have to wait for the raw data to get an answer. Overall it seems there were ~6k developers surveyed, but the go subset is unknown as "go one of 3 primary languages" but there are no language usage breakdowns on the demographic summaries. So Could be anywhere from 100-6000 :-p 
Bad title. The parser reached v0.5. They didn't write it in Go v0.5. 
According to this, 12% use it regularly and another 16% plan to adopt it: https://www.jetbrains.com/research/devecosystem-2018/
my bad, I cannot find how to fix the title, is it possible?
I don't believe it is, unfortunately. 
I find them to be helpful and friendly, if a bit literal at times.
Seems like a collection of misc APIs with a collection of packages to use - e.g. exchanging currencies (I wonder how realtime the values are): https://labstack.com/docs/api/currency
They always update the previous major as well. 
&gt; without having to do any extra type assertion. This is not really possible, your return type has to be *something*. As you said you can perform type-switches with `interface{}` being the type of `value` but there's not much else you can do here.
Yeah, I feared as much. It'll just be easier to store all parsed args as strings, and convert before using them as necessary. Thanks for the quick reply! :)
This is impossible. The compiler needs to know the function signature. Even using generics would require passing in the type. Use the empty interface and type assert it. Better yet, if you're wanting to learn Go, I'd suggest you stop trying to force it to be like Python. While right now you're unhappy you can't just return anything and have the runtime handle this "types" stuff, later you'll love knowing that your variables actually hold what you think they hold. You'll hate Go if you try to write it like Python.
Until Go 1.11 is released both 1.9 and 1.10 are maintained. It would be interesting to see 1.8 updated or 1.7. Go is always current stable and current stable - 1.
[https://github.com/gobwas/ws](https://github.com/gobwas/ws) a zero\-copy upgrade websocket lib.
 type argument struct { name string value interface{} }
Find one on GitHub. Find one in another language that you know, and translate the components into a Go edition.
&gt; Should I avoid using reflection? Yes.
If I don't find any I'll get it done with one of the python tutorials. I use python pretty frequently. 
What are you on about? [`time.Duration`](https://golang.org/pkg/time/#Duration) is a type. What does it even mean to multiply a number with a type? I think you meant the following: dur := a * time.Second
I think you meant: dur := time.Second * 10 which does work.
&gt; strings Why not just byte arrays? If you're going to go the marshaling/unmarshaling route, you can make it more interesting and store json blobs or protobuf blobs.
I would advocate that it is best to explain what you want to do, rather than how you are doing it. It is possible that a completely different approach would better solve for what you are trying to accomplish. With that said, on the limited information here, why not provide methods for the various types that may be returned? .Int() returns an int, .String() returns a string, etc. That way the caller doesn't have to worry about asserting the type. You can do it for them. 
Thanks, edited. I wrote that comment quickly from my phone and it was a big mess. 
It seems Asp.Net Core is catching up and now faster than nodejs :)
You‚Äôre welcome!
Isn't reflection in Go really fast? (Basically just dereferencing a pointer)
That‚Äôs not why it sucks. It sucks because you‚Äôre trying to do an end run around the type system and in almost all cases (everything except serialization/deserialization) that‚Äôs a mistake and you‚Äôll have a better system by going with the type system. The same applies in Python, by the way. For Python, you should almost never use metaclasses or look at types at all. 
I've been coding since I was ten, it took me 2 days to pick up Go.
&gt; I want to be able to be able to call .Value() on my argument to retrieve the appropriately typed value I think you're confusing static and runtime types. Because `value` can be anything at runtime, it should have the type `interface{}` (the static type for a value that can have any time at runtime). Any time you want to assert that the runtime type in an `interface{}` is a particular static type, you need to use a type assertion. And to be clear, this isn't a limitation in Go, it's how types work in every language (including languages like Python and JavaScript, where everything is implicitly an `interface{}`).
I‚Äôve been coding since 2016, I picked up Go in a few weeks or so, however I wouldn‚Äôt qualify myself as Go programmer or put it on my resume at that point. I‚Äôm just highlighting that good Go programmers that understand idiomatic Go and its principles don‚Äôt happen in a few days.
But it is mint-lang, not mint. Just like Golang. *duck and away*
I just compiled a bunch of things with Go 1.10.3. No hitches. The golang devs totally rock as always!!!
This is a runtime type anyway, so generics wouldn't help.
Great points. These are pitfalls I'm trying to avoid, hence the question about how to go about it idiomatically. Thanks :)
It is a bugfix release, It is not supposed to have hitches.
I second this. Be aware of [the XY Problem](http://xyproblem.info/).
i'd take O(n^2) over 'innocuous looking function modifies my data'. I certainly agree there are downsides. Another option might be to support a read only iterator of the stack/queue, so it'd only need to be traversed once. Or expect an `ForEach(func(interface{}) bool)` function, where the callback returns false if iteration should halt
You are correct. I did indeed muddle up static and runtime types. Thanks for the reply!
Yeah I've had a couple of suggestions for using a byte array. 
Yeah, this seems to fit my issue to a T lol. Thanks :) I'll reply to poster above
Thank you for the correction. I was failing to recall accurately my inability to produce untyped constant coercion with loop variables. for i := 0; i &lt; 10; i++ { fmt.Println(time.Second * i) } This doesn't work and I couldn't figure out a way to use the values from the loop without casting them to unsigned integers first (which limits me to the 64 bit address space that untyped constants aren't limited by).
If you want a conversational bot look into Dialogflow. There is an official Go client SDK and a Go library for webhooks.
I saw that, but I do have a question about that I checked their licenses and I assume the standard version is not available for commercial use. I want to use that in the future but, I don't know how I could afford it. 
Fair enough, here's a more indepth description of what I want to do: I have a binary which can be called with certain options/arguments. I wanted to make argument definition as easy as possible, and have all these arguments checked (for correctness/required/etc) in one place by looping over all defined arguments. Furthermore, I wanted to use these argument values without having to do any type assertion or reflection (for which \- my initial assumptions are correct \- this is impossible). Here's an SSCCE, on playground: [https://play.golang.org/p/a7Pi\_XQgcZj](https://play.golang.org/p/a7Pi_XQgcZj) I'd heartily appreciate any suggestions. I know it's messy, i wrote it last night to try out whether or not i could try arbitrary values.
? ``` data Argument a = Argument { name :: String , value :: a } readRandomAssArg :: (Read a) =&gt; (String, String) -&gt; Argument a readRandomAssArg (name, raw) = Argument { name=name , value = read raw} helloInt :: Argument Int helloInt = readRandomAssArg ("hello", "1234") helloBool :: Argument Bool helloBool = readRandomAssArg("hello", "True") ```
Code generation is your friend. Check out how urfave/cli does it: https://github.com/urfave/cli/blob/master/flag_generated.go#L60
If you're fine with just half the numbers being available, sure!
If you have no specific need for it to be unsigned, then using a regular int is perfectly fine, and more convenient.
`uint` should generally only be used for doing binary operations, bit flags, etc. because even if a value can‚Äôt be negative there might still be a case where you want to loop from N to zero or detect an overflow. 
My midwest metropolitan area is heavily C# or Java and companies struggle to find Go engineers. What recruiters told me those companies do is resort to hiring solid mid-to-senior level C# or Java engineers and give them a month to get up to speed with Go. Those who succeed are kept and others are let go. Go demand is certainly higher than Go engineer supply where I am.
this is what The Go Programming Language recommends, with the specific example of uints being useful when you want to do bitwise operations
is there any specific reason for not going for platforms requiring zero coding? I'd simply go for chatfuel to create a bot on messenger.
I want to learn how to do it myself. It's no fun having it done for you. 
They wrote Echo, the Go web framework.
[removed]
Such a cool project! Keep up the great work. 
I just did this to myself. I started with a situation where I needed to have a cheap way of mutual exclusion on numerous entities, so I used a uint32 with a simple atomic compare-and-swap spinlock. Then I realized I needed to support RLock() and Lock(), and more than this, I needed a queue'd sort of fairness, to ensure that numerous RLock()'s couldn't starve a Lock(). So fine, now I had an array-based queueing lock, allowing each locker to wait on their own core-local variable at a given index in the array. After each check, they would sleep for a bit before trying again to see if they had reached the queue head. Each Unlock sets the locker's array variable to 0 and sets the next one to 1. I realized I had in the end just reimplemented RWMutex, and poorly, since it caused 100 times more voluntary context-switches than RWMutex when I benchmarked it. LOL. My simple lightweight uint32 had become a poor replacement for what I should have used all along.
In general, the downside of using an unsigned int type to enforce positive values is that you lose the ability to test for an unexpected negative value. You can assert that n &gt;= 0 if n is signed, but the assertion will always pass if n is unsigned, even if your code unintentionally does something that would have made n negative.
If you have to convert constantly, then consider using `uint`. But in general prefer `int`, `int64`, and/or `float64` for almost all of your code. Also, using `uint` in particular is pretty rare. Usually if you want something unsigned then you need it to be a specific size too. Don't use unsigned types to enforce or suggest that a number must be positive. That's not what they're for. The compiler doesn't check that they never go negative or that they never wrap around. And usually they just increase the probability that someone makes a mistake by incorrectly converting an `int` to a `uint` (or an `int64` to a `uint64`).
This is the answer I was looking for. I don‚Äôt run any mission critical go so I don‚Äôt ever worry about upgrading major versions since they‚Äôre always backward compatible. It makes sense to be careful though for prod systems. Thanks for the clarification. 
Go is not a dynamically typed language. There are situations where `map[string]interface{}` is necessary, but it should never be the default. APIs should return well-structured responses, which can be unmarshaled into well-defined structs in the client.
I'd recommend Server Side Events. websockets is NOT compatible with HTTP2, SSE is. It is basically a regular HTTP connection that is turned into a stream that never closes and the server arbitrarily sends data through it. Server Side Events are very easy and work great. SSE for server to client and regular AJAX for client to server.
I've used gorilla websocket extensively with great success, but recently moved to server side events when i heard websockets is not http2 compatible.
All fixed size numbers wrap around, it's just a matter of will you catch it or not. It's more likely that if a positive number suddenly turns negative that you'll catch it than if a large number happens to become a smaller one.
[https://medium.com/@boltmick1/best\-golang\-books\-12a56fc256ab](https://medium.com/@boltmick1/best-golang-books-12a56fc256ab)
unsigned integers behave "weirdly" when close to 0. Signed numbers behave "weirdly" when close to their max value. You're more likely to be close to 0 then to max. Unsigned numbers are useful for bitwise operations, but I rarely see them used elsewhere. Another useful property of signed ints is using negative values as the "absence" of a value. maxVal := getTheMax() if maxVal &lt; 0 { fmt.Println("no max value defined") } Dumb example but you get the point. Using unsigned, you'd have to pick 0 as "absence", which might cause problems if a max value of 0 indicates "presence" as well. Your other solution would be to use a pointer-to-integer which requires extra indirection and could be worse. There's a reason the Java creators excluded unsigned numbers from the language - too much abuse from people who don't understand them. 
Yes. I don‚Äôt know why (Go is my first language that has unsigned ints), but it‚Äôs very common in Go. Also in the standard library.
You should look at goa.design . I've been using fir the last months, and it's pretty nice
I checked it out.. swagger based.. ugh. For the life of me I do not understand why tools continue to support swagger and dont embrace RAML. RAML 1.0 is so much nicer to design with.. and more powerful too! It is mind boggling how many developers choose Swagger and OpenAPI simply because it has more tools for it. If you look at the quality of the tools.. most of them are half baked no longer supported generators that were being built for specific purposes and left undone and not supported. Same goes for RAML to be fair.. but I am just baffled why choose a more difficult to use spec that is clearly inferior to the RAML 1.0 spec for designing APIs with. 
You're gonna have to fill me in on what RAML has that swagger/OPEN API doesn't, because I don't see it. Also goa generates swagger, but uses it's own internal DSL. That's because it recognizes that those tools that build upon swagger are very useful. What does RAML have other than a (presumably) nicer DSL? Is there anything out there actually taking advantage of it in a way that couldn't be done with swagger?
Which state is that in the Midwest, if you don't mind sharing?
Is there a good way to do this on Windows?
Depends I guess on how you look at it. For me API first means I design the API, the resources, the request and response payloads, etc... first. RAML 1 with its RAML Types to model payloads is much nicer to work with than json schema that swagger uses. As well, being able to inherit from types allows you to build things like GET and POST payloads sharing common properties, while specifying specific properties for each method type (e.g. a GET may return an ID field generated by the DB, where as the POST shouldnt contain that in the payload). Annotations are another powerful customizable feature that are fairly easy to use that swagger/openapi lacks. As an example, you can use annotations to define new ways of processing the APIs... lets say you want a way to indicate what API to call to get response data that feeds in to another. You can create a custom annotation that allows you to easily specify the the resource to call and what property(ies) that resource provides that the current API resource needs as part of its request (e.g. query params, request body, etc). Now, it does require custom code to process the annotations too, but it is not difficult to write that code. There was a process started to try to gather some more common/useful annotations, but it has not gone very far at this time. 
Yes!! Love it
Saw this posted on /r/linux and thought some people here would be interested.
I use frp for my office and home access. Nothing especially mission-critical though. It lacks a proper daemon and package for Linux distros though. Also, I'm not afraid of the Chinese. Disclaimer: I'm of Chinese descent, and I got my degree there. It's not so bad, and I don't think they would really spy on people with open source software.
See also David Crawshaw's recent littleboss package: https://twitter.com/davidcrawshaw/status/1005072029257814018
You really should take a deeper look at goa.design. All of the things you are talking about can be done with it, and writing it off just because it can generate swagger is silly. I think the design format is less important than how you use it. I imagine you can just as easily write code first and write a RAML spec after the fact. Goa strongly encourages design first, which is more important than whether it uses RAML or swagger or neither. 
I looked at it.. and like the many that blow off RAML because they are already using swagger in some way, I do the same by using RAML. Having done APIs in both formats, and used code generation of both, including swagger annotations and more.. RAML 1 is such a beautiful feast and breath of fresh air to work with. If I hadnt experienced both (and more) I couldnt say that fairly. Having done so though, RAML is truly what OpenAPI should have been based off of. Why they chose to not even approach the RAML Group before brashly deciding on Swagger as the spec is unbeknownst to the public. The good thing is the Mulesoft team gave a product called AMF to the open community and OpenAPI which solves all the problems. It is a normalized DSL that RAML 0.8 and 1.0 as well as flavors of Swagger can utilize in the middle so that you can design with one spec while still being able to use tooling from another. It sounds like goa should take a look at AMF and look to add its capabilities to supporting AMF as another input format.
Those aren‚Äôt runtime types; this doesn‚Äôt do what the OP requested.
How can it provide distributed transactions and proper isolation? If multiple transactions are committed they cannot happen atomically and therefore a reader could read part of a transaction.
Yeah that's the idea with generics...
Yeah... I work at a small startup. We upgraded to 1.10.2 recently and a really obscure minor bug in how a couple of bytes were being copied caused an avalanche of problems for us. We ended up reverting a lot of our binaries to 1.9.x until the issue was resolved.
A lot of times people use this kind of graceful restart when they'd be better served by having this handled by the routing layer. You usually want your routing layer/load balancer to have some kind of connection draining so when you want to rollout new config or code you make new instances with the new behavior, start routing traffic to the new ones and stop routing traffic to the old ones, then turn them off when all pending requests have finished. Of course, if you're building a load balancer, all bets are off.
You can even do blue/green deployments to load balancers using DNS.
Unsigned ints have twice as many possible positive numbers: int8 range: -128-127 uint8 range: 0-255 https://golang.org/pkg/builtin/
I highly recommend using the standards compliant http package to send and receive standards compliant requests and responses.
Don‚Äôt use DNS you‚Äôre gonna have a bad time.
HTTP is an application level specification. This means if you don‚Äôt use correct verbs and URLs you‚Äôre literally doing it wrong.
 &gt; never aggressive. You just don't know. 
How else are you gonna do it? Use DNS with a &lt;300 second TTL. Works just fine. Any clients dumb enough to cache DNS beyond the TTL deserve to get broken.
That‚Äôs very interesting. Did you file any bug report for it? I‚Äôd be interested in seeing more info on that. 
This is what you expose yourself to if you use public DNS for blue/green deployments. https://pbs.twimg.com/media/B89fpvpIAAAIZSS.png
&gt; But a v0 package makes no promises. The reason why v0 is an exception to SIV is that every single v0 version is essentially a different major version. You could solve that problem by having the full v0 version name in the import path, but it would be as ugly as sin. Yes - an earlier iteration of vgo (prior to the release of the vgo blog posts starting Feb 22) had extended SIV back into the v0 range. It is indeed "ugly as sin," but the real risk is about the complexity resulting from potentially needing to do all that mapping. That's a major focus of the planned SIV blog post. &gt; I'm not saying that we should never use v0 packages, just that we should handle them with serious caution. Normative statements like this are not new. All vgo does is increase the risk of interacting with v0 packages, particularly for transitive dependencies. Are you making the argument that vgo _should_ increase that risk, because you believe that making the world harsher will induce people to test more aggressively? It seems like you might be, from this: &gt; Again, that doesn't mean we don't use them, it just means we put more thorough tests around them and use them with more caution than more battle-proven dependencies. i'm sorry, but i see no causal relationship here; it scans to me as the same kind of wishful thinking behind vgo that i referenced in the intro to this post. As the post carefully details, nothing about vgo _structurally_ encourages that behavior in an individual. It just makes it hurt _other_ people (your dependers) more, on the expectation that they'll come and yell at you for not writing better tests. So, if people are more cautious about the v0 range, it might be because we all chatter about it a bunch, but it won't be because anything about vgo's structure encourages it. Also, to the idea of writing better tests - as the next post on compatibility will touch on, that's gonna generally be quite difficult. Think about how hard it is to fully capture all the nuanced guarantees of your own software in tests; trying to do so with tests of your dependencies will be, even more difficult, because you don't know the intimate details of that code. To be clear, i am not saying that we should not try to do hard things, or capture our guarantees well in tests. i AM saying that we all have limited innovation tokens, particularly in unpaid OSS work, and we should think long and hard about the actual benefits of a system that forces us to spend those tokens.
I'm just starting to look into learning go and this is really good to read
It could be cached at their ISPs DNS cache of which some ignore TTLs. Which whilst stupid, isn‚Äôt something most users can sort out barring knowledge of how to switch DNS provider. 
Really?
I understand your point, but the aim of the library is to utilize assumptions about the data structure to make it easy to print it. If I've created a stack implementation, calling existing push/pop inside Push/Pop is less effort.
Overalll I find the go community pretty great. Generally developers are of a higher skill level than that of JavaScript or PHP, and feedback is usually more constructive and comes with an explanation. 
I think he is taunting somebody to write ‚Äúfk you‚Äù :))) this sub is good i agree.
I believe Go does allow you to pass file descriptors to children (see `Cmd.ExtraFiles` or `ProcAttr.Files`), it just doesn't let you pass _all_ file descriptors.
&gt;&gt;Again, that doesn't mean we don't use them, it just means we put more thorough tests around them and use them with more caution than more battle-proven dependencies. &gt;It just makes it hurt other people (your dependers) more, on the expectation that they'll come and yell at you for not writing better tests. &gt; &gt;... &gt; &gt;Also, to the idea of writing better tests - as the next post on compatibility will touch on, that's gonna generally be quite difficult. Think about how hard it is to fully capture all the nuanced guarantees of your own software in tests; trying to do so with tests of your dependencies will be, even more difficult, because you don't know the intimate details of that code. When I talk about tests here I mean writing tests that exercise my dependencies (particularly v0 packages). Of course it would be ideal if all of my dependencies had thorough and extensive tests but a) that's out of my control and b) that's particularly unlikely for v0 packages for the same reason they're most in need of it. What I *can* do however is write a load of tests to exercise the assumptions and requirements I have about my dependencies. That way, if an updated dependency breaks those assumptions, at least I know during the build rather than at runtime. I don't need to know the intimate details of how it's been implemented to do this, as I'm only testing my assumptions and requirements. If something outside of that changes I'm probably ok. I'm not saying vgo (or dep, or cargo, or whatever) solve this problem, not necessarily that they should. These are all parts of software engineering. If the versioning system makes a load of things easier and doesn't make anything much harder (which is true for vgo from my experience and understanding so far), we all win.
I personally have learned and grown a lot just by learning to write Go.
You have to include those files in your `go run/build/install` step if it's your main package. `go run *.go` 
Yes. ints are number and uints are bitvectors. No need to cramp a non-negative number into a bitvector just because it is possible and bitvectors provide +, -, *, etc.
Isn‚Äôt systemd already doing that?
Nothing to bad, but some controversial threads: [https://www.reddit.com/r/golang/comments/59nk46/stalking\_people\_online\_for\_thought\_crimes\_this\_is/](https://www.reddit.com/r/golang/comments/59nk46/stalking_people_online_for_thought_crimes_this_is/) [https://www.reddit.com/r/golang/comments/5eqs64/proposal\_to\_delete\_rgolang/](https://www.reddit.com/r/golang/comments/5eqs64/proposal_to_delete_rgolang/)
*peace
I have to deal with a site with self\-signed https cert, but I don't want to disable the whole cert verification just for that. So I wrote this library to whitelist some bad certs, but still have standard cert verification for everything else.
&gt; I think a key observation is, that neither is particularly well supported by observational evidence. Of course it is. Remember, there are no _new_ choices people can make in vgo - it's just taken away our ability to symbolically declare incompatibility (absent a Declare-MVS), leaving us only with the "refactor" strategy. That strategy has always been available. The mere existence of anything other than a `^` constraint in e.g. Cargo - though certainly, they are uncommon - is evidence that people do not necessarily consider it their responsibility to chase whatever pseudo-compatible updates may have happened in their dependencies. For vgo to present any kind of novel environment, you have to assume the stated goal of a globally compatible ecosystem. As the piece discusses, though, that's a goal that we only ever approach (and not asymptotically - more like in fits and starts), and we _never know where we are on the spectrum of compatible-or-gotcha-filled future_. As i noted in the conclusion, it replicates the "authority without responsibility" problem that people have experienced problems in dep-style systems, , while ALSO creating the We do not have to have seen this _exact_ situation before in order to have observational evidence that is relevant. &gt; Personally, I've been on the receiving end of the negative externalities in dep's approach¬π and this biases me towards optimism for vgo's approach. i understand that i cannot expect people to make a direct comparison against gps2, given that it is not fully articulated yet. However. given that you're using the term "externalities," and that i have emphasized from the beginning that "eliminating negative externalities" is essentially the core design goal of gps2, it seems...i don't know, odd that you would choose to make that comparison here. This is a sketch of the declaration design: https://gist.github.com/sdboyer/8be4cac4d75e75e1c12eece108937076. i am confident that it will allow us to largely, and in some cases entirely, eliminate the negative externalities of both vgo and dep. &gt; I always compare working at Google to working in a hermetic open source ecosystem. Most of the processes and incentives work exactly the same. There are similarities. [i've argued as much](https://medium.com/@sdboyer/so-you-want-to-write-a-package-manager-4ae9c17d9527#4d37) - though that argument is focused on risk, not incentives. What's fundamentally different is velocity, compensation, and availability of labor. This is something i actually feel uncommonly well suited to speak to personally, being that i have spent most of my career in the less-well-resourced areas - both open source and my dayjob - but moved to Stripe six months ago. And it's night and day. Larger, well-resourced companies typically admit specialization and progressively more narrowly-scoped responsibility. And, while it's not like The single most common complaint i hear about Googlers when they move to startups, especially early ones, is that they have to learn how to write "bad" code, because trying to adhere to the standards they were accustomed to at Google would literally cause the company to go under. &gt; a generally shared understanding that everyone should be cooperative and work together to make the whole ecosystem work well. i honestly do not understand where this line of thinking comes from. Where is this person thinking that they didn't need to be cooperative? What were their motivations? Most importantly, how is the track record of coercion (in the form of purely symbolic failures resulting from the information loss problem) on promoting organic cooperation, especially among those who are not already predisposed to do so, and when doing so provides them little benefit? IMO, the real problem here is those _incidental_ negative externalities, in both dep and vgo. &gt; You try to argue for your predictions with game theory. But in my opinion, game theory is incredibly hard to apply to practical situations and when you try, fails more often than not. Yes, i also often find game theory dubious for practical use, as i noted in the introduction. But primarily what i was doing was identifying individual strategies, which are absolutely useful for helping us to more rigorously think about the micro-scale choices people can make in a system. For the most part, i think those speak for themselves, particularly in the way they highlight the difference in the choices available to direct vs. transitive dependers. The only argument i made on the basis of a theoretical principle was an impossibility statement: that vgo does not meet the basic criteria for a purely altruistic system to achieve a stable state. This isn't even really necessary for the overall argument of the piece, but as you note: &gt; Even more so, if you do not actually model payoffs (which, TBH, seems intractable for an open source ecosystem) Yes, i didn't model payoffs for an open source ecosystem, because i agree, it's quite complicated. But _that's exactly the point_: it's kinda ridiculous on the face of it to understand what benefits people get from open source, whereas it's trivially easy to see the costs: labor. (And also, shitty interactions with people, like maybe the ones that happen when people show up in your queue and inform you of your obligation to refactor to accommodate some stealthy breaking changes.) If we can't even posit a plausible universal payoff model, it's hard to believe there's one out there, especially when the observational evidence from every other community actually IS that people get burned out by open source all the time, often as not by unduly high demands placed on them by users. So: &gt; If you remove that, however, you basically come down to what /u/nicpottier argues i disagree with the notion that "there are no payoffs, therefore this tells us nothing at all." &gt; At least in a couple of places you appear to me to make uncharitable assumptions about how vgo's technical design could or couldn't change in the future. Please, be specific. i have invested enormous effort in elevating this discourse from strawmen to steelmen with this post. The only exceptions i can imagine are: * i omitted discussion of Cargo-style yanking, which is possible under MVS. This was intentional, because it's planned for post 5 (hey fun, it would complicate `go {test,run,build}` behavior) and it seemed like one way of reducing complexity. * While i did discuss Declare-MVS as a strategy in the body of the piece, i did not discuss it in the introduction. This seemed acceptable to me, however, given that the way Russ has before, [and continues to](https://research.swtch.com/vgo-eng), talk about vgo as though it magically solves the problem of real incompatibility by making symbolic incompatibility impossible. &gt; But some of your arguments are really good, from a technical standpoint (at least the section about losing information seems hard to refute). They definitely deserve consideration, made me think and will continue to do so. This issue is independently sufficient to render MVS unfit for purpose as an intermediate algorithm. &gt; But in the end, everything (on both sides) still seems to hinge on vague predictions about how the community will handle certain situations. And not only is it very hard to actually argue about that - I'd even go so far as to say such differences in opinions are fundamentally unresolveable. Perhaps i did ask too much of the reader by presenting the eventual possibilities of this system as inevitabilities. That's certainly a technique that i've been frustrated when Russ has employed it, and i could have been more circumspect. But accepting those outcomes really isn't necessary to accept the argument. The information loss failing is sufficient. IMO, the loss of automation, even in the case of a Declare-MVS. is as well. &gt; It is that last part, which really excites me for vgo, FWIW. My predictions (based on my anecdotal experiences) to how this will play out and what the actual effect on toil will be seem to vastly differ from yours - and they are, what underlie my resistance to vendoring, to dep and also, initially, to vgo :) i'd love it if we could stop comparing to dep. Really would. But, with any luck, you'll see those same benefits existing in what i come out with next, when we get rid of most/all of the harmful externalities from both systems.
i guess? i believe we should optimize for a system in which we share as much information about the world as possible, in a way that is as likely to be as true as possible, in pursuit of an actually compatible ideal. Russ' writing about vgo repeatedly equates getting rid of symbolic incompatibility with having that ideal of compatibility ideal, with no rigorous thinking that i can find applied to how that lands on the people trying to achieve that goal.
I'm not sure about that one. I know they offer a free version and a standard version. I'm not aware of the licensing of either.
&gt; (I mean, I don't care. I'm fine with go-get as it is. But it seems the community at large seems to find this a problems that needs solving) i think what i mean by "artificial" is...yeah, maybe non-obvious to others. It'll make more sense soon. Gotta say - feeling like `go get` is fine as-is strongly suggests to me that you either just haven't felt this pain, or don't care about it. That's fine, and that doesn't make your experience "wrong," or anything. However, i also find it emblematic of the problem: it seems to me that we have a process, and a tool, created by folks who simply don't believe that the problems we experience are real, displacing a process that did believe these problems are real. Seems pretty backwards to me.
&gt; If the versioning system makes a load of things easier and doesn't make anything much harder (which is true for vgo from my experience and understanding so far), we all win. That's _the entire problem here_. Information loss DOES make things harder, because it means you have cascading rollbacks whenever things go wrong, and it creates problematic incentives for everyone involved. Phantom rules just pile on to make that worse. These are eminently fixable problems. Just, not under MVS.
You do it with anycast. Stop publishing the route to a load balancer and the traffic will go to another. When it stops receiving traffic, update it and it starts publishing its route again.
Hah, I‚Äôve been stalked on this subreddit for 1.5 years and the threats have escalated to threatening to ruin my life. I don‚Äôt post here much anymore because I got tired of dealing with it. I‚Äôve emailed the code of conduct group for assistance, first time they eventually replied saying they would get back to me but never did. Second time was within the last two months (last time they started saying they would ruin my life for ‚Äútriggering‚Äù them) and I emailed conduct@ within the last month after the Reddit admins gave me a one line sentence of ‚ÄúThank you for your report we took the appropiate action.‚Äù and ignored me there after. Point is that a single post with some ‚Äúnegativity‚Äù can get their full attention but being stalked in dozens of posts across 10+ throwaways, having my real name posted, saying I should be fired from X where X is my real employer, weird sexual remarks, talking about my physical appearance, threatening to ruin my life, I even recall them making comments about swatting...... and I don‚Äôt even get an email telling me theirs nothing that can be done at least. Sure I can be a bit stubborn and come across as a condescending when I don‚Äôt mean to. Sometimes I know my tone isn‚Äôt justified and I do my best to recognize this to work on better interactions in the future. But ya know it really pisses me off that some anonymous coward can stalk me online for **years** and am just shrugged off lol. I just want the dude to leave me be, I know his github, his first and last name with 99.99% certainty and was just looking for a third party to maybe bring things to an amicable end. Whatever. I‚Äôm a grown up and I‚Äôll get by just fine, it just annoys me when I find myself avoiding a conversation I want to participate in because I know it‚Äôs one of those ‚Äútrigger‚Äù areas that he‚Äôs bound to show up. Anyways, this sub Reddit stopped being as enjoyable for me ever since.
It should only be failing if you are trying to use `go run` and not including all files. Better to stick to `go build . ` and build the package instead of individual files 
50% of my reddit messages it's me apologizing for my typos. Thanks!
The correct way is to do IP failover. It's not going to be cheap (you need your own ASN, ISPs who let you advertise BGP and some expensive routers, and two sets of equipment in different data centres), but it will work properly with zero downtime.
It seems the golang nuts group considers this subreddit as their competitor, lol!( Õ°¬∞ Õú ñ Õ°¬∞) 
It used to be worse, much worse,
Yeah haha. It was this: https://github.com/golang/go/issues/25322
So there is more in the world then Linux with systemD
Couldn't you have just used CertPool and SystemCertPool? https://golang.org/pkg/crypto/x509/#CertPool 
You're right that skipping verification is bad, but this is typically solved by trusting the CA of the certificate you wish to trust. You'd usually do this by installing the certificate to your host. Alternatively, you can just modify the http transport to use your own certificate store (you could also combine them), rather than the one from your host. package main import ( "crypto/tls" "crypto/x509" "fmt" "net/http" ) var badssl = []byte(`-----BEGIN CERTIFICATE----- MIIDeTCCAmGgAwIBAgIJAIb7Tcjl3Q8YMA0GCSqGSIb3DQEBCwUAMGIxCzAJBgNV BAYTAlVTMRMwEQYDVQQIDApDYWxpZm9ybmlhMRYwFAYDVQQHDA1TYW4gRnJhbmNp c2NvMQ8wDQYDVQQKDAZCYWRTU0wxFTATBgNVBAMMDCouYmFkc3NsLmNvbTAeFw0x NjA4MDgyMTE3MDVaFw0xODA4MDgyMTE3MDVaMGIxCzAJBgNVBAYTAlVTMRMwEQYD VQQIDApDYWxpZm9ybmlhMRYwFAYDVQQHDA1TYW4gRnJhbmNpc2NvMQ8wDQYDVQQK DAZCYWRTU0wxFTATBgNVBAMMDCouYmFkc3NsLmNvbTCCASIwDQYJKoZIhvcNAQEB BQADggEPADCCAQoCggEBAMIE7PiM7gTCs9hQ1XBYzJMY61yoaEmwIrX5lZ6xKyx2 PmzAS2BMTOqytMAPgLaw+XLJhgL5XEFdEyt/ccRLvOmULlA3pmccYYz2QULFRtMW hyefdOsKnRFSJiFzbIRMeVXk0WvoBj1IFVKtsyjbqv9u/2CVSndrOfEk0TG23U3A xPxTuW1CrbV8/q71FdIzSOciccfCFHpsKOo3St/qbLVytH5aohbcabFXRNsKEqve ww9HdFxBIuGa+RuT5q0iBikusbpJHAwnnqP7i/dAcgCskgjZjFeEU4EFy+b+a1SY QCeFxxC7c3DvaRhBB0VVfPlkPz0sw6l865MaTIbRyoUCAwEAAaMyMDAwCQYDVR0T BAIwADAjBgNVHREEHDAaggwqLmJhZHNzbC5jb22CCmJhZHNzbC5jb20wDQYJKoZI hvcNAQELBQADggEBALW4pad52T7VNw2nFMjPH98ZJNAQQgWyr3H2KlZN6IFGsonO nCC/Do8BPx6BnP3PFwovWMat1VvnRRoC8lw/30eEazWqBRGZWPz6LHTE3DNBJdc8 xz6mh8q9RJX/PAj+YYGNElTu6qj49YT0BEhMF4U+dTQ0G8y3x4WNfiu9pGqyrp8d AzeidMfQ/pU01PpoPTDLvRDNkmMsABNE1fXBfJxDDGwfq1xY1j23Fm6BolwZC2y7 n19h+vMYVWbGoovrf2/ibTvtcTyfDop7gl5Yy3OncZxokFj21rUZpLgx9ea4a9z3 FzEz5ufynq03RhHTE1eu+gDzMEF0GNhGGsKqeA4= -----END CERTIFICATE-----`) func main() { pool := x509.NewCertPool() pool.AppendCertsFromPEM(badssl) client := &amp;http.Client{ Transport: &amp;http.Transport{ TLSClientConfig: &amp;tls.Config{ RootCAs: pool, }, }, } _, err := client.Get("https://self-signed.badssl.com/") if err != nil { panic(err) } fmt.Println("Everything is awesome.") } 
I would try to find a library for messenger, look at the examples and start tweaking them. Slowely but surely trying to make more complex bots until you are happy.
Don't forget the whole iris thing
You will be look at building a content delivery network more than building a website. 
Thanks, I am going to try it within `php-parser-demo`
I agree. But you could do blue-green deployments by changing an internal DNS or a CDN origin's DNS and avoid a lot of that.
Video encoding and queues too but AWS has a few services to turn that into an easy to scale solution with a few API calls. It‚Äôs s massive project, but perhaps less so than when YouTube was created. Still don‚Äôt underestimate it.
The "why" is that numbers underflow and overflow and don't have any trap or signal or anything else when it happens, and for some reason 98% of programmers consider this hunky-dory and actively fight the idea of putting such things in our languages, which I can only presume is because "that's how it's always been done" because there is almost no other argument against it trapping being the default that makes any sense. (Well, there's the performance one, but if we all used it, the CPUs would catch up, so I don't put much stock in this.) If we had trapping, I could easily recommend using unsigned numbers when you want something to always be positive. But in reality, where unsigned numbers have a near-certainty of suddenly becoming multi-billion without warning or error, is difficult to recommend them. Using signed numbers for such things means you may still get unexpected negatives, but at least then your bug creates a _cleanly detectable_ invalid state, which during debugging is better that getting large numbers and trying to heuristically decide if it's invalid.
https://golang.org/doc/effective_go.html#embedding It‚Äôs using embedded types, you can see it in the first line of the struct definition for the engine. 
Thanks! Neat bug. 
[removed]
I used YouTube as functional description. This will be for hosting proprietary videos so it will be a lot smaller in terms of traffic and global cdn. 
&gt; evidence that people do not necessarily consider it their responsibility to chase whatever pseudo-compatible updates may have happened in their dependencies. But whether or not it is going to turn out a good thing or not, if they *will*, is simply in the air. You criticize Russ saying that "in practice dependencies will move forward at just the right speed" -- but ISTM that you are essentially arguing that the speed will be too high (and others, me included, have argued that the speed will be too slow), causing unduly stress/pressures. *That's* where, really, no position is particularly well supported by evidence. I agree that the upgrade-speed and pressure will increase in a vgo world - as a consequence that it removes the possibility to just stay the same. You seem to predict that increase to be bad - "we" predict that increase to be good. &gt; i have emphasized from the beginning that "eliminating negative externalities" is essentially the core design goal of gps2 I'm not sure how this is supposed to work out. From my perception, again, the basic point of contention seems to be, whether it is better to enforce a higher upgrade cadence or allow people to hold upgrades back. Your assumption seems to be, that the latter choice can be given without negative externalities, because it would only affect the author of the package/binary. My point is exactly, that I consider that fundamentally impossible, because there is no such thing as "refusing to upgrade" - in the end, whether it's in a single binary build or when packaging for a distribution, you will *have* to converge on a single (or a very small) number of versions of each package and apply all the fixes necessary to make software work with it. The difference is, where this pressure is applied, if you will. It might be applied to the author of the breaking package, or it might be applied to the distributor of a binary using it (say, when the rest of the distribution moves forward). What I'm saying is, that I experienced the cost associated with allowing authors to hold back upgrades for their binary, because I then had to try and package them for debian, which disallows vendoring and requires using a single version. Which then meant *I* had to go through the trouble of bringing the transitive dependencies of the binary I was interested in up-to-speed to current versions in debian. In some cases by filing bugs and chasing the author and in other cases by providing patches. ISTM that you are disregarding those costs in your post. If you start from the assumption that *at some point* you need to converge the ecosystem to a single/small number of versions of any package, then the remaining question is just where the pressure to apply upgrades lies - near the author of the leaf-package, or near the end-user. I don't see how gps2 is supposed to fundamentally change the equation here - it seems you fundamentally contest the notion that it should be near the author and I fundamentally belief that it should. &gt; i honestly do not understand where this line of thinking comes from. Where is this person thinking that they didn't need to be cooperative? FWIW, there is a difference between "thinking that you don't need to be cooperative" and "not thinking that you need to be cooperative" and I'd argue that *mostly*, the latter is the problem (though *sometimes*, the former is the problem). And it comes from experience - among other things, the apparent notion that your problems are solved, once *you* provide a working build (disregarding that there still needs to be upgrades happening at some point). And intentional or not, the framing of you article, in terms of "game theory" (with, TBH, enormous air quotes), enforces that notion by creating an adversarial tone. &gt; But primarily what i was doing was identifying individual strategies No. Sorry, but that is *not* what you where doing primarily. You where using it to justify your predictions of bad results. The "Update strategies" section alone contains a whole lot of invocations of game theoretic results, which IMO simply *don't hold* in this context. You might not have intended it that way (though that would surprise me, TBH), but the effect of your usage of game theory is to grossly misapply a rigorous field to give you arguments a pseudo-intellectual paint job. &gt; i disagree with the notion that "there are no payoffs, therefore this tells us nothing at all." But then you are misunderstanding game theory. *Any* game theory is only really applicable under a rigorous model of payoffs. I'd posit, that if you went around to actually create such a model, you'd find out that your arguments become self-contradictory. i.e. I'm pretty confident that your game-theoretic arguments are bad and that the only way you can be under the impression that they are not, is that you didn't model payoffs that would expose that. Note, that you can still talk about different actions and their characteristics *without* invoking game theory, so I simply don't buy that you had to use that terminology to talk specifically about the "strategies". And to me as a reader, your invocation of game theory is detrimental to your goal (to convince me) because it comes off as bad pseudo-science. &gt; Please, be specific. i have invested enormous effort in elevating this discourse from strawmen to steelmen with this post. TBH, I find it extremely hard to argue specifics though, because it is so extremely long-winded and that there is a lot of noise in there that is hard to grab at. The assumptions you are making are often implicit and spread through several sections. But to be as specific as possible, say for example: &gt; vgo does not allow such declarations, as respecting them would entail that MVS cross Schaefer‚Äôs dichotomy into an NP-hard search. This is simply not true and while you are *acknowledging* that, you continue to litter the text with references to differences in how vgo and dep would handle those constraints. For example, a bit further down you write &gt; * If Aparna Declared under gps, then Deon‚Äôs dep ensure -add B would result in a failure with a conflict message indicating the problem. This is a frustrating outcome, but it‚Äôs also optimal: the tool immediately carried Deon to the inevitable conclusion. (Declaring in this way would also require a new release of A.) &gt; * If Aparna Declared under MVS, then Deon‚Äôs vgo get B will exit successfully, but show a warning about the A‚ÜíC combination. Deon could then take manual action, eventually coming to the conclusion that he has to abandon B entirely. (As the mechanism for an incompatibility service is TBD, it‚Äôs not clear whether a new release of A would be required.) But this difference is *completely immaterial*. A charitable assumption would be, that `vgo` has the behavior you consider optimal, whether that's warning or failing - because given that what happens isn't decided yet, you might as well assume the better behavior. Even if the result is just additional noise, because you are differentiating between things that don't need differentiation - it still detracts from your arguments, because it comes off as if you are trying to intentionally paint `vgo` in a bad light. The difference between a SAT solver and a theoretical MVS-based vgo when it comes to how upper-bounds are handled, is that the former will continue to search for a different solution, whereas the latter will only be able to detect it. It would've been beneficial to leave it at that, in the context of "does MVS navigate us into a dead-end". &gt; This issue is independently sufficient to render MVS unfit for purpose as an intermediate algorithm. I obviously disagree. Your argument seems to be, that if you don't include that information, you can't build dep/gps2 as a tool on top of vgo. But I don't even believe that's a desirable goal. I believe the goal should be, to get something into the core Go toolchain and converge on it, not to continue the fragmentation. And I don't believe you show "unfitness", because while that information isn't there now/soon, nothing prevents us, if we decide we need it, to add it to the spec/tools later and move on. To put it another way: It may render vgo unfit for purpose as a basis for continued, simultaneous usage of dep - but not as an *intermediate* algorithm, that later gets this information added and take advantage of. And while I understand that *you* dislike if it doesn't achieve the former, *I* consider it a good thing, because we won't continue to be fragmented.
You would be surprised at the number of people vehemently against learning Go at my current company. They really love Java.
&gt; probably You say this but decades of experience say otherwise.
If you‚Äôve been writing Go for more than one decade, color me impressed. 
Not go, but several languages for more than a decade each. This is a super well understood issue, not making things up.
Ah, I've done this before but I sent in the file descriptor numbers as flags... Using environment metadata is much more clever. Great little write up.
Yeah, that would seem to be the approach I should take. Thanks. 
I haven't dug into netlink yet but I keep meaning to. Is there a particular source of documentation or inspiration you used to figure out what to send?
I am not the author of the above, I just found it interesting enough to share. As far as your question goes, I am far from being remotely qualified to answer it :(
Note that there are existing solutions for doing this internal to a company, one of the best approximate algorithms to solving a problem at a company is to only solve things with proprietary solutions if you're going to sell them, you can't find a solution you can buy or they have a big return on investment :)
Can it be done in Golang?
[removed]
Sorry to hear that. Bugs like that are rare, but do creep up every now and then. That is why, it is very essential to hammer out the RCs, so that you shake out the bugs early on and have much more confidence when you deploy the actual releases. On the other hand, it is good to see how fast the bug was fixed. It was filed, triaged, fixed and pushed all on the same day !
For the record, the `.` is optional. `go build .` and just `go build` are equivalent.
I really like the write-up but I think the terminology is wrong. Graceful restart is somewhat canonically defined via httpd's behavior In the 90s, we called this feature "hot reboot" or copyover. These were stateful sessions though, so a little more of a coordinated handoff rather than just handing over the file descriptor. Tough to find references still but here is one brief mention: http://www.circlemud.org/maillist/1998-10/0123.html
Then Go is a good language to use, especially if the businesses wants to keep their videos in their own servers. On the hard requirements side of things, you can really use any language for the website, since most of the work is in transfering, transcoding, and storing of the videos, what you use to serve the front end and fire of transcoding scripts are going to have negligible resource usages. 
[removed]
Yes you are right. For self\-signed certs this is a better way to handle (also I would use \`SystemCertPool\` instead of \`NewCertPool\`).
Thanks, groups.google.com UX is unbearable.
We‚Äôre all in this together. Let‚Äôs make it as pleasant and fun of a ride as we can. 
Hey all! I wrote the netlink package used a base for this package, and you may be interested in my blog series about netlink: ‚ÄúLinux, Netlink, and Go ‚Äî Part 1: netlink‚Äù @mdlayher https://medium.com/@mdlayher/linux-netlink-and-go-part-1-netlink-4781aaeeaca8. As far as poking at subsystems like nftables, I usually find a kernel header and start looking at various commands, attributes, etc. You can also strace Linux utilities to see what they do! I've got a bunch of netlink based stuff on my GitHub if you're interested! https://github.com/mdlayher!
Few years back people could barely handle different opinions. Over time that grumpiness faded away. Much better now.
Thanks for the explanation. &gt; Personally I find the idea of adding two positive numbers and getting a negative without any warning to be an absolute disaster and an atrocity Coming from a Python background, yes, that is insane.
Yes, if you control the clients, it‚Äôs not as bad. You just can‚Äôt trust anyone to respect the TTL.
The Go communities, dating back to before 1.0, have always been exceedingly friendly and helpful. That has become an enduring part of the community and led to the establishment of the community standards to help set the expectation for the future. It's been a pleasure to participate in, and I love helping to bring this awesome tool to even more aspiring gophers.
[removed]
this sub isn't filled with soy boys the way most of reddit is. good job assholes.
Sweet! Thanks for the follow-up
Your question is akin to asking "Can I build a library with concrete?" Yes. It is possible to do this in Golang. Did that help? No. What you need is a design: * User uploads video. * What happens? * It gets transcoded, processed, and stored "somewhere"? * User visits site. * What happens? * You have to talk to the back-end and get a list of videos, tags, meta-data, etc. * User clicks "play" on a video * What happens? * File must be streamed. All of that ignores the fancy front-end and javascript magic people expect. If you can break the process down into steps you might be able to hack things together. Otherwise your qusetion reads a littley naively and I would ask "What is your budget?" 
&gt; Any clients dumb enough to cache DNS beyond the TTL deserve to get broken. Sure, if it was their choice, like [writing something in Java](https://javaeesupportpatterns.blogspot.com/2011/03/java-dns-cache-reference-guide.html). But often it's forced on you by your ISP. Many do dumb things (like ignoring low TTLs). I operate a consumer web site with a lot of traffic, and even with a TTL of 1h, I still get a small amount of legit traffic 24+ hours later. (i.e. not including the bots, which ignore DNS TTLs.)
This is not good advice. Having endpoints like /user/get and /user/create is not only ugly but dangerous. For example, let's say you have an IOT garage door you're writing an HTTP API for. You decide to make /door/toggle an endpoint. Because you made it GET, rather than something like POST /door {"open": true}, the browser thinks it's fine to repeat that request for things like thumbnails and do other weird things. This is something that actually happened: https://twitter.com/rombulow/status/990684453734203392?lang=en.
Agreed. Gophers are awesome! I‚Äôm happy to be here.
Indeed I'm naive! I should have said "Is anyone aware of a open source CMS written in" Golang "which I can make a site like YouTube?" I'm told Golang handles concurrency better than any other language (Nodejs) I found a lengthy answer here https://stackoverflow.com/questions/4216430/python-cms-to-create-a-video-site-like-youtube Next time I'll frame the question better. The budget will come after I have figured the ideal way forward; off-the-shelf or custom dev. 
 ! ! Very interesting. Thanks for sharing.
Have you totally abandoned `gen` development?
Heh. Glad you found it useful. Apparently I commented on the completely wrong reddit story :-)
De facto that‚Äôs been the case and and feeling bad about it. :/ I should at least update to make sure it works with current Go.
1. I don't normally see people separating their libraries into commented functionality. Not saying it is wrong, just that I don't notice it being common. I usually use the [goimports](https://godoc.org/golang.org/x/tools/cmd/goimports) tool which will automatically sort the imports into stdlib, and external/user. 2. If you want, you can group similar \`const\` definitions like \`\`\`go const ( A=1 B=2 C=3 ) \`\`\` 3. Naming in Go prefers camelCase instead of snake\_case. So, \`valid\_png\` would be \`validPng\`, along with the other snake\_case functions. 4. Your functions that take \`\*os.File\` could be made more reusable, especially for mock testing, if they instead took the interface [io.Reader](https://godoc.org/io#Reader). This means you could pass not only a concrete File, but also a buffer, or anything that has the correct \`Read()\` method signature. 5. For the infinite loop problem, I would suggest checking all of your \`io.ReadFull\` calls for errors (do that anyways). But to specifically make sure you are communicating the EOF error back from \`read\_section()\` to your main loop. You should break the loop at the end of the file.
It‚Äôs fine. If you want to you can try being more deliberate with errors. And remove the comments in the import statement. If it‚Äôs going to be any bigger, look up a standard go project directory structure. Oh, and please, for the love of go, write some tests. 
1. Is there a reason you are panicking and not just using os.Exit? 2. parse_ztxt doesn't need to be a method. There's no interface that it implements, it doesn't change state. Just make it a function. 3. I second the comments about having io.Reader as the parameter type rather than *os.File.
1. Nope, no reason. If Exit is preferred, good to know 2. sure, makes sense
This was good stylistic help, thanks! The comments were mostly for me, starting to learn the libs and telling _myself_ why I was using them. I used to do the same with C until it became more obvious to myself which headers were bringing in what. Awesome tip on changing the functions to take the io.Reader interface. I don‚Äôt think the interface abstraction (duck typing even) has sunk in yet. Or at least I haven‚Äôt learned the stdlib interfaces that enable what yet. Got a bit confused with ioutils.ReadAll taking something and io.ReadFull having something just a bit different. More exposure and experience I guess and it will come. 
Look into channels for replacing the infinite for loop, I'm not sure if they would work for your use case but definitely read up on them. I usually name all my return variables, it avoids weird stuff like `return a == b, nil`. Also I don't think your code will work properly since your constants don't have the newlines escaped. Any time you want raw string input use the backtick symbols instead of double quotes.
I read a little on channels. They seem very tidy and nice. Not sure how I would be able to use them here though. At least, the section parsing can‚Äôt happen in parallel anyway because each section‚Äôs start point is dependent on where the previous ends which isn‚Äôt known until the previous is initially parsed. But I could perhaps use them for organization‚Äôs sake. If they would help in that. What do you mean name your return variables? Like in the function signature? ‚Äòfunc something(a,b int) (sum int, error){ }‚Äô giving the returned int a name of sum? Or do you mean storing ‚Äòa==b‚Äô in a variable like matchesName := a==b return matchesName, nil Is having the comparison in the return unusual? Thanks for the tip on the const strings. They do happen to work as they are now (the script runs and matches the python output 100%). But differences in escaping between strings and raw strings with backtics is something I should look up. 
Channels aren't for async operations, it's for synchronous operations with a kind of locking mechanism. Even I don't fully understand them haha. I do mean naming the return variables. But instead of doing `return a == b, nil` you would just assign to those named return variables, then just `return`. Having anything in the return is unusual for the most part, a lot of times it cant be avoided. 
Kind of weird that none of this code would work due to everything being private.
Yeah, there were a few things which rubbed me the wrong way about the post, especially so since the topic has been well covered by better posts \- a re\-hash should raise the bar.
How should i interpret your non-response to my points about out the differences between experiences at Google, and experiences in less resource-abundant places? &gt; If you start from the assumption that at some point you need to converge the ecosystem to a single/small number of versions of any package, then the remaining question is just where the pressure to apply upgrades lies - near the author of the leaf-package, or near the end-user. I don't see how gps2 is supposed to fundamentally change the equation here - it seems you fundamentally contest the notion that it should be near the author and I fundamentally belief that it should. None of your inferences about what i'm saying about "eliminating externalities" are accurate, here or in the preceding paragraphs. i certainly believe that the responsibility is ultimately on the author to do that. What i don't believe is that it's helpful towards that goal to create artificial situations (via information loss) where Deon has to pressure Aparna to get that done. It may not be productive to discuss this much further until i have more of it together, but as you've also objected to me keeping things private for too long, in the past, let me try to break down avoiding negative externalities this way: 1. If minimums are separate from current 2. And we have reasonably accurate minimums 3. And incompatibility declarations can be made 4. But incompatibility declarations can be bypassed without requiring a root-only property like dep's `override` or vgo's `replace` Then we've created a system that should be able to minimize the harmful externality of "symbolically, but not actually, incompatible." A declaration structure that could have these properties is what i've begun to sketch out in the gist. --- &gt; Note, that you can still talk about different actions and their characteristics without invoking game theory, so I simply don't buy that you had to use that terminology to talk specifically about the "strategies". And to me as a reader, your invocation of game theory is detrimental to your goal (to convince me) because it comes off as bad pseudo-science. i'm of two minds about this. On the one hand, i do think i pushed the outcomes argument too far, and had it figure in the final wrap-up to the piece more than it should have been. Really, this is the key problem paragraph: &gt; Intuitively, that means that the system will never reach the idealized goal of an ecosystem in which it is reliably true that ‚Äúthe semantics of a Go source file are not dependent on go.mod.‚Äù It may not even converge on it. Basing a system design on an unreachable goal is not usually the best way to go. This is especially the case because the only _actual_ conclusion i was pushing for was, "it's unlikely we ever reach Russ' ideal state of a compatible ecosystem." TBQH, that kinda seems like something we all agree on, anyway - he's just designed the system around "whenever you see a problem, go fix it, because that's the only permanent solution." So, i omitted discussion of payoffs. Your suspicions notwithstanding, i actually did spend time modeling those out, and they did not lead to contradictions - at least, when not at a BigCo. It was a lot more words to tell us something that it seems like no one truly disputes. (The real dispute is over what labor is reasonable to demand.) Maybe an assumption like that is another difference between mentalities of scarcity vs. plenty, though. On the other hand: &gt; But then you are misunderstanding game theory. Any game theory is only really applicable under a rigorous model of payoffs. This really kinda _is_ my point, because i'm making an impossibility assertion: that a particular outcome (Russ' ideal compatible ecosystem) probably _won't_ occur. That's because, unless some adequately universal direct payoff structure exists, then it suggests we're in an [indirect game](https://en.wikipedia.org/wiki/Evolutionary_game_theory#Routes_to_altruism), which are exceptionally vulnerable to defection, absent a reputation/shaming system. And defection from altruistic But we both seem to have agreed to stipulate that such a universal payoff structure for open source is at minimum fraught, if not actually impossible. Russ has said as much to me, as well. So... --- &gt; TBH, I find it extremely hard to argue specifics though, because it is so extremely long-winded and that there is a lot of noise in there that is hard to grab at. i think this discussion is mostly useful, but this is not. To say "extremely long-winded" here is equivalent to [tone policing](https://en.wikipedia.org/wiki/Tone_policing), as it aims to discredit the argument by attacking the manner in which it is presented. Still, i certainly understand not wanting to do the work to tease out particular points - i've spent months on that myself. Perhaps, instead of the overwhelming prospect of putting together ironclad arguments, you could phrase the areas you have concerns about as questions, instead? Maybe it could take some of this adversarial edge off. i really do care a great deal about getting the foundation right, even if we never reconcile our viewpoints on the interpretations. --- &gt;&gt; vgo does not allow such declarations, as respecting them would entail that MVS cross Schaefer‚Äôs dichotomy into an NP-hard search. &gt; This is simply not true and while you are acknowledging that, you continue to litter the text with references to differences in how vgo and dep would handle those constraints. It is unequivocally true that MVS cannot respect conditional exclusions/incompatibility statements. (It can respect global/root-only ones, e.g. the `exclude` rule). The MVS blog post expressly states this, under "Excluding Modules." That's what i'm referring to here. If a Declare-MVS is implemented as an external service, it _cannot_ be consulted by Algorithm 1 (the build list algorithm), because that would mean `go {test,run,build}` necessarily have to consult it. That would mean the loss of reproducible builds, because such a service is necessarily mutable (at least, relative to the immutable timeline of releases + rules, which is the sense of mutable that matters here). Russ and i agreed on this point when i raised it months ago. Therefore, such a service can only be consulted when versions are being expressly changed, e.g. via `go get` with Algorithms 2 or 3. Though the fact that other `go` subcommands can also change versions means it's they can't be counted out either, though that's one thing i haven't run down to its conclusion yet (it's slated for post 5). Maybe i've misremembered or misunderstood something here, but i don't think so. The bottom line is that Algorithm 1 has to be able to operate solely on `require` statements. So, whatever else Algorithms 2/3/4 do in look at Declare-MVS-type incompat information, Algorithm R has to ultimately create a `require` statement set that will cause Algorithm 1 to produce exactly the desired build, without looking at other types of statements from non-root modules. &gt; A charitable assumption would be, that vgo has the behavior you consider optimal, whether that's warning or failing - because given that what happens isn't decided yet, you might as well assume the better behavior. In this particular case they _look_ the same, but that's only because there's only one possible `B-&gt;C` combination. i do see now why that makes this a less-than-great example - sorry. Still, that does not make them the same, because the user knows that a "failure" for gps/2 means it attempted a search, whereas a "failure" for MVS just means "this current, obvious combination doesn't work." When i say "optimal" here, that's what i mean - "failure resulting from search." --- &gt; To put it another way: It may render vgo unfit for purpose as a basis for continued, simultaneous usage of dep - but not as an intermediate algorithm, that later gets this information added and take advantage of. And while I understand that you dislike if it doesn't achieve the former, I consider it a good thing, because we won't continue to be fragmented. i am not talking about continued use of dep overtop MVS. Not here, not anywhere, and not when i made this point [in the proposal thread](https://github.com/golang/go/issues/24301#issuecomment-392549295). Let me concisely rephrase: **any algorithm** operating atop MVS to search for a "not-known-to-be-incompatible" solution will face cascading rollbacks, because MVS' information loss entails it. So, we can roll in incompatibility information later, but most anytime you have a diamond and need to react to incompatibility information (i.e., the only time things are actually hard), MVS will make backtracking worse than it has to be. Which means that if we roll this stuff in later and work on top of MVS, then we're still solving SAT - üò±üò±üò±- except that we have one hand tied behind our back. This is why, per the gist i linked, i believe that the way to approach this is to start from a better base set of declarations.
Mostly this. You are also ignoring the error from [`url.QueryUnescape`](https://github.com/pzl/drawio-read/blob/master/read.go#L128). Handle that. A few more comments: 6. Use the "flag" package to handle arguments. 7. A struct and its methods are usually grouped together for readability. So in your case `(c Chunk) parse_ztxt()` should come right below where `Chunk` is declared. Also, move the `main` function to the starting function. A few perf tips: 8. You are allocating a new `buf4` and `databuf` everytime in the read_section function. For performance sensitive applications, this might be costly. Perhaps, you can declare a global `bytes.Buffer` and reuse that. (Or encapsulate the entire functionality in a pngReader struct if you don't want globals.) To prevent dynamically reading `databuf` everytime, you can use the `io.CopyN` and read just `c.Length`. 9. As a further step, look into `io.Pipe()`. And use that for stream parsing/decompressing your png file. Hope that helped. Have fun with Go. :)
as a general suggestion tools like govet and golint can be helpful too, recommend integrating those into your editor and checking them out.
&gt; Naming in Go prefers camelCase instead of snake_case. So, `valid_png` would be `validPng`, along with the other snake_case functions. Along these lines, Go is also particular about the styling of acronyms in the camel case when they start identifiers. This is important because of the casing rules for exporting. Essentially, an acronym should either be all uppercase or all lowercase, never mixed, so `urlEscape` or `URLEscape`, not `uRLEscape`. &gt; duck typing even This is my favorite feature of Go: Static duck typing. The best part is how well it's used in so many places. `io`, `bufio`, `net`, `bytes`, `strings`, and several others all fit together really nicely. Makes dealing with streaming data, or data that you want to treat as streaming data, kind of painful in a lot of other languages once you get used to it. &gt; Got a bit confused with ioutils.ReadAll taking something and io.ReadFull having something just a bit different. I've been using Go since `panicln()` existed and I still never remember which is which. I guess the one in `io` is technically lower-level, but it's still kind of annoying to keep track of. Trying to remember which one's named what throws me off the most. Thankfully, cleaning up `ioutil` is on the tentative roadmap for Go 2, so that should get fixed eventually.
I would not use channels for replacing the for loop, I don't think they are a better fit.
It's also weird that a lot of this code won't compile
Searching for [video streaming](https://www.google.com/search?q=site:github.com+video+streaming+golang) and [video server](https://www.google.com/search?q=site:github.com+video+server+golang) on GitHub returned some interesting projects.
If its didn't serve your purpose please don't use it. Its not for you sorry
Typically you would just return the error and it would be processed by the main func eventually. 
No
I find with the more "fringe" languages that aren't taught in a formal setting you get developers who are self-starters and like to learn beyond what they know.
A lot of people are using it. In my previous company, we wanted to use it. Problem is, when you're picking a new library, if you see too much old PRs, it's hard to use it in production! Why don't you transfer ownership to somebody, or put it in an GH organization? 
Hi, all I am the author, this is my second serious golang project, just found it's possible to take c structs as golang slices, and then created this project for concept proof, also trying to find a efficient way to make use of eBPF, oh, that could take a long period of time :'( Very happy to hear from your advices, thank you all!
I don't think you do. The point is no one wants a print function to clear their data.
If you wanted to be more idiomatic about this `string(uncompressed)` would be a defined type (struct field, or struct) so you can express it as a type. With the current implementation `deflate()` should return `(string, error)`. 
Beware: This can lead to issues if you try to use `http.Server{RequestTimeout: x, IdleTimeout:y}` so you are forced to manage request lifetime manually. This bit me hard, but it's manageable. Also, you should always think of very slow clients, that might hog your server -&gt; (D)DoS Tip: always have sane timeouts (uploading a 2GB File needs a a read timeout for each buffered read/write, etc...
&gt; it is good to see how fast the bug was fixed. Indeed, but it should have been included in 1.10.3.
I agree with some of the comments below. A good programmer will pick up the language and can start completing tasks within a week (I have seen many cases of this). A good Java, C#, Ruby, PHP, C/C\+\+, Python, JavaScript developer, for example, will have no trouble grokking 75&amp;#37; of the language within days, because the language was \_designed\_ to be simple. \*Get a programmer with some experience, aptitude and passion and your are good.\* Good tooling also helps. For enterprise\-grade development Goland is my tool of choice. Thanks to JetBrains for making world\-class tools! If you don't have a dime to spend on development tools Visual Studio Code is a strong free alternative. I personally believe the availability of Go programmers will increase as more companies make the choice to use it and the productivity and performance gains become apparent. Take it from a former Ruby on Rails programmer now doing strictly Go for a large global commercial real estate company.
I agree with some of the comments below. A good programmer will pick up the language and can start completing tasks within a week (I have seen many cases of this). A good Java, C#, Ruby, PHP, C/C\+\+, Python, JavaScript developer, for example, will have no trouble grokking 75&amp;#37; of the language within days, because the language was \_designed\_ to be simple. \*Get a programmer with some experience, aptitude and passion and your are good.\* Good tooling also helps. For enterprise\-grade development Goland is my tool of choice. Thanks to JetBrains for making world\-class tools! If you don't have a dime to spend on development tools Visual Studio Code is a strong free alternative. I personally believe the availability of Go programmers will increase as more companies make the choice to use it and the productivity and performance gains become apparent. Take it from a former Ruby on Rails programmer now doing strictly Go for a large global commercial real estate company
When it comes to interfaces, be careful not to apply any Java experience you might have. This is a really common mistake, but interfaces are used slightly differently in Go (but this isn‚Äôt obvious because you can ‚Äúmisuse‚Äù them like Java interfaces without technically doing anything wrong). The section ‚ÄúHow much interface do I need‚Äù towards the end of this article is a pretty good description of what I mean. In general the whole article is great if you‚Äôre going to be using Go professionally. https://peter.bourgon.org/go-for-industrial-programming/
It _is_ a backport [candidate](https://github.com/golang/go/issues/25335). But I see that Filippo has changed the milestone to 1.10.4 from 1.10.3. So it was probably an internal decision and considered not important enough. Feel free to comment on the issue if you think it should have landed in 1.10.3.
Awesome, thank you very much!
I don't really feel like complaining on issues, but seeing this is a data corruption issue, I am very surprised it wasn't included, but it might just have gotten lost.
Great job mate! Seems to be working well in my test run with it :) 
I think I saw comparison on Gin github page. But, you're exactly right, couldn't agree more. I have swapped Gin for Echo, wasn't that difficult. Oh, and now their Echo github page claims that it's faster than Gin so that's the plus :) Thanks again for the suggestion!
&gt; That being said, there are legitimate reasons why you wouldn't want some operations, especially non-idempotent ones, to be on GET requests. Often I'll simply force every request to be a POST request. Philosophically I don't "care" what the verb is, but technically it is always POST; you can't just send anything 
7 syscalls for Sleep give you peace of mind?! 
In addition to what others wrote, I'd replace the `checkk(err)` with proper error checking and a different resulting error state for each condition. I like to use a little helper like this: // exit prints to stderr and exits with the given code func exit(code int, msg string, a ...interface{}) { fmt.Fprintf(os.Stderr, msg+"\n", a...) os.Exit(code) } So you can use it like: uncompressed, err := deflate(decoded) if err != nil { exit(2, "failed to uncompress: %s", err) } I get that `if err != nil { ... }` feels tedious, but it's worth it. I wrote more about why in this blog post: https://medium.com/@shazow/code-boilerplate-is-it-always-bad-934827efcfc7 
Yeah, then GraphQL is doing it wrong. And JSON-RPC as well. Put gRPC in there as well. HTTP is just a tool. Many projects have come and gone which lean on it to simplify things (json-rpc), make it more powerful is complex ways (graphql, gRPC), or make it more powerful in abstract ways (REST). None of them are "wrong", they're just abstractions on top of layer 7. Call them layer 7.1. 
The bad faith implication in your reply highlights exactly why many do not want over-reaching CoC's. 
ValidPNG is more idiomatic.
Care to share? :)
gofmt is a fantastic tool for automatically formatting your code to the commonly accepted format
Look into flattening the big for-loop. You could start with `for chunk := new(Chunk); chunk.Type != endHead; chunk = readSection(file) { ... }` The function `valid\_png` does not need to return an error. If you encounter one return false. Use golint `go get golang.org/x/lint/golint` Use pointers to structs to avoid expensive copying. Else really great job! 
Yes! This is one tool I happened to already read about, so the script was run through ‚Äògofmt‚Äô. And I can‚Äôt recommend it enough. 
Extremely helpful. This is the stuff I definitely didn‚Äôt know about. Thanks for the tips on flag, io.Pipe, and the buffer reallocations. All the error handling stuff was indeed me being a little lazy. It seems frowned upon :D
Oh great page to check out!! Thanks for the link
Oh that‚Äôs a great way to rewrite the loop! And good tip on not passing copies of the struct around. Thanks!
I'm going to follow up later this week with a video on how the USB packets were reverse engineered and I'm hoping to add more supported controllers to the project in the near future. Any questions feel free to ask them here or drop me a private message. I really like how this is a testament to the versatility of the language.
Not sure what editor you use, but VS Code had a Golang plugin that had a bunch of the common linters and formatters built into it. Extremely helpful. 
Sublime text. Probably also golang plug-ins for that, just haven‚Äôt installed any. Will take a look though! As much as it isn‚Äôt the hip/trendy editor these days, I prefer the simplicity
This thread is being brigaded by right wingers and outright racists trying to appear as genuinely concerned people. That article posted above is a favourite of that type and your lack of experience dealing with such unsavoury people shows that you don't actually know what constitutes "bad faith" here after all.
Why is the incompatibility an issue? 
That‚Äôs a good idea.
thanks, nice pack
So now we can use go instead of javascript. cool.
This is very cute. It hits a sweet spot of simplicity for little projects that I've been looking for. Only request I can think of is that it would be nice if there was a documented migration path from this package to something like prometheus if the need arises (and maybe a comparison of what's missing). Ideally the library would make it super easy to plug into prometheus. At the very least, it would give me some comfort in relying on it. :)
There‚Äôs a lot more than just the programming. You‚Äôre underestimating it.
1. Think all your functions should return errors that you can choose to exit on (or ignore, depending on the context) in `main`; 2. More specifically, errors returned by calls to `ReadFull` should be checked; 3. From clarity and for more idiomatic code, you simply reuse `read_section` to implement an `io.ReaderFrom` interface on `Chunk`; 4. Consequently, I would incorporate valid_png in the ReadFrom and simply return an error if the file is not a valid PNG; Also, helps keep track of how many bytes were read in your reader; 5. Using io.Reader interfaces is not just better for testing and future-proofing, it's a very useful to keep track of who owns and therefore should close the stream/file handler after using it. In your case, it's `main`.
There's an open source histogram library I've contributed to which handles some of the gaps in this implementation. When you merge bins like in the code does in this article, you lose the important property of histograms called mergeability, which allows you to combine it with other histograms with the same bin steucture. https://github.com/circonus-labs/circonusllhist
Thank you for the idea! I will have to tihnk about it. My original assumption was that the app developer has a feeling when the app becomes too big, and before that he can manually move on to some grown-up solution. But if he misses the time - it would be of course nice to have a simple way to migrate.
I have only used pants and bazel. Of those, I would never recommend pants - it's very heavy, touchy, slow, and complicated. Bazel isn't a whole lot better, and rules_go seems to spend extended periods of time fully broken, but it's still better than pants. For anything less than a company-wide monorepo with many dozens of projects... You're probably better off with Makefiles.
Absolutely no idea what I‚Äôd use this for just yet, but it‚Äôs super exciting. I can‚Äôt wait to see what doors the performance increase will open. Will probably be a very long time before any mainstream framework for it, but I wonder about 3d graphics and VR.
Honestly, no. I've used Bazel extensively in a corporate environment with a large monorepo, and it was great. I've used it at home for smaller projects and it was okay-ish, but contributors to the project didn't like having to deal with it at all. Most of those projects were in C/C++ and moved to either CMake or plain makefiles. Some projects were in Go and I just migrated back to plain `go build`. I'd only consider Bazel in a setup where there are many developers, a single shared codebase for multiple projects, and you can afford some amount of control over your developers' workflow to be non-standard (basically a company, or a software project as strict and successful as, say, the Linux kernel). It's not designed to be used in small environments.
I‚Äôd also suggest looking at Mage (https://magefile.org) it‚Äôs a make-like tool but written in Go. You write the magefile itself in go which let‚Äôs you organize and share things just like normal go source. As an added benefit, you don‚Äôt need to think in yet another language just to build your code.
Do you like use Golang to execute shell script? ü§î
You can shell out for things, use native go packages, or whatever you‚Äôd like. Just like make or rake. 
Rather than adding an explicit handler for the .wasm file, you can use https://godoc.org/mime#AddExtensionType with an ordinary FileServer.
Your assumption is not wrong, but there is a paralysis up front knowing that you'll have to redo work later if the solution holds you back. Knowing that there is an easy migration path (or at least a well-documented one) helps alleviate that fear.
It is fine for prescriptive builds. It's not fit for cases where you want declarative build description with automatic tracking of file modification times. It could be eventually adapted to the latter with helper functions/packages. Still, it might work for a medium size project given `go` short build times - just perform complete build routine regardless of file modification timestamps.
[This](https://blog.gopheracademy.com/advent-2017/go-wasm/) article was interesting. 
[removed]
I know exactly what I want to use it for: Speeding up the playground for [the scripting language I'm working on](https://deedlefake.github.io/wdte). The current version used GopherJS and, while really nice, it's got a few performance issues as well as two moderately large bugs. One is that `context`-based cancellation doesn't work right, and the other is that [you apparently can't have packages with the same name as stdlib packages in some situations](https://github.com/gopherjs/gopherjs/issues/705).
No. Many issues (like dependency, build items) already solved by go-build itself, no need for a mammoth build system like bazel. For makefiles, they can be kept minimal, just to kick off go-build.
That's still bad advice... You can't just ignore HTTP verbs and make everything a POST request.
A recently posted article touches on an approach that I like, "\[Standard Package Layout\]([https://medium.com/@benbjohnson/standard\-package\-layout\-7cdbc8391fc1](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1))"
It's hard to say what you need by the information you just gave. Why exactly do you need several Makefiles? Go has a builtin build tool that automatically only builds the packages that were modified since you last built them. So, a build tool is not required. I still like to have a tool to run complimentary tasks like generating code, running tests, etc., but let Go do the hard work of compiling the project for you. Here's a list tools built with Go you can take a look: \- [https://github.com/go\-task/task](https://github.com/go-task/task) (Disclaimer: I'm the author of this one) \- [https://github.com/rliebz/tusk](https://github.com/rliebz/tusk) \- [https://github.com/magefile/mage](https://github.com/magefile/mage) (Already cited in another comment) \- [https://github.com/markbates/grift](https://github.com/markbates/grift) (By the same author of the Buffalo framework) \- There are others \- Or just keep using Makefiles =)
&gt; Most of that is in the HTTP specification, but never all of it. It certainly is in the projects I create. P.S. REST is just another way to spell HTTP
Thanks for go\-task/task. I use it, and like it.
Bazel is great for large, multi\-language projects. For a pure\-Go project, it's overkill. IMHO \[mage\](https://magefile.org) is a better choice. Read \[this thread\]([https://twitter.com/thor4hansen/status/971919031283273728](https://twitter.com/thor4hansen/status/971919031283273728)) before you choose Bazel.
I caved and just approved https://go-review.googlesource.com/c/go/+/113396 , even though we normally don't approve additions to DetectContentType until the upstream mimesniff spec has been updated. Oh well.
Author here. Unfortunately, nftables is rather sparsely documented. I used the sources of nftables, libnftnl, and the output of ‚Äúnft \-\-debug all‚Äù, which contains detailed dumps of what‚Äôs being sent over the wire. Have a look at the tests, too, which explain that the byte slices in there come from \`strace \-x nft ‚Ä¶\`
Did you look at all at [the Go Mobile stuff](https://github.com/golang/go/wiki/Mobile)? Libui isn't ever going to be a contender because it would be a drastic change in focus for them to support mobile. Now, Go Mobile isn't native-like, but actually native. If that's fine, I'd recommend trying it out. I only skimmed [this article, but it contains more info on this approach](https://hackernoon.com/react-native-why-and-how-to-build-your-native-code-in-go-9fee492f0daa).
I'd also take a look at melody: [https://github.com/olahol/melody](https://github.com/olahol/melody)
Ah, very cool. Great way to derive your test cases! Thanks for the response :)
Websockets and HTTP2 are different protocols. They do not clash in any way because a connection either uses one or the other. A Go server can handle both with no extra effort on the part of application programmer. 
Haha .. thanks Brad ! I was wondering what made you change your mind until I saw this post. I see that you still hang around these parts :)
The GoSublime plugin has everything you need :)
I'd been meaning to approve it anyway but this is the third or so mention I've seen of workarounds for the content-type, so it was a good reminder.
[removed]
[removed]
I love go but I don't think it's the ideal language to write mobile apps in, sure it's possible in some ways but there's better tools for the job 
I am wondering how the garbage collection is implemented / translated to webassembly and how much the overhead is compared to Rust/C/C++‚Ä¶ ü§î
Dead link
Java is typically considered "slow" because the JVM is slow to start. Bazel doesn't have this slowness, because the "bazel" command you run is a C++ client to a Java "server" that runs in the background.
Could you maybe give more information what systemd is doing exactly the same here? Not a linux user and I found that there even exist a systemd for application monitoring developed by etsy. Pretty confusing :)
You're forcing Go into a use-case it simply doesn't solve. Go excels at backend/systems programming. You could absolutely use it for handling the service of the app, whether it's local or remote, but when it comes to UI/UX don't waste your time. Look at either native dev with Java for Android or Swift for iOS. If you want it on both consider React Native. If you want to incorporate Go into the app, it could run as a service on the device handling requests from the app similarly to a web service but beyond that it's not the best idea. 
I've edited the post, but in summary, i'm not asking about the best way to do mobile/frontend development. GopherJS and Jasonette *(two options i mentioned)* are far from ideal. I'm looking for developer ease, and with a good resulting UX *(ie, probably native ui)*. This, as mentioned, is a project *for me*, it does not have production requirements.
&gt; ... but there are better tools for the job right now I've edited the post, but in summary, i'm not asking about the best way to do mobile/frontend development. GopherJS and Jasonette *(two options i mentioned)* are far from ideal. I'm looking for developer ease, and with a good resulting UX *(ie, probably native ui)*. This, as mentioned, is a project *for me*, it does not have production requirements.
[https://github.com/ivandavidov/minimal](https://github.com/ivandavidov/minimal)
If you want your process to run as a "system" service and be able to start/stop/restart it using "service" command, you use systemd. It effectively works just like a process monitor for the times when your process crashes or system reboots because of God knows what. I've written a similar thing in Rust, Python and Go. Although my Rust impl was by far the lightest one (which is what you need for such things), I later realized that systemd would've sufficed.
Why don't you use Kotlin to write the UI and then write the backend in Go? I have done this serval times for simple apps. You just use callbacks to communicate between Go/Kotlin. Kotlin is a nice language.
Yeah, I said exactly that.
Tell that to Facebook (GraphQL) and Google (gRPC). RPC is fundamentally different than REST, so if you adopt an RPC-like API then also dipping into REST just doesn't make sense. 
[removed]
[removed]
u/natefinch is the creator and cool dude, we used to work together years ago.
Only Bazel has a mature Go support (via rules go). So far it's been working great for us, especially in a GRPC/Protobuf setting.
Good to hear that. =) Let me know if you have any criticism or suggestions.
Care to explain? 
Is that sarcasm?
Yes
It would help to put up a README.
webassembly uses a GC as well so I don't think it matters.
So all right wingers are unsavory? Also can you point out which outright racists are in this thread? I haven't seen them. What I see is genuine concern, including from myself. I see a core group of mods who are more interesting in defending a closed decision than reaching a good outcome. I see a CoC with the ill\-defined and much abused term "micro aggression" next to "we police outside of Go spaces", and the only real defense of the CoC in this thread has been "stop brigading us pls", not an actual rationale. If that's what I see then many lurkers coming here who are not right wingers and who are not racists, despite your bad faith assumption, are going to see the same. 
Sorry mate I will add one tonight.
Here you go, my friend. https://gist.github.com/dantoye/c420957f06979a730af7e935c5da8641 Basically, figure out the domain objects: a PNG file, a Chunk, a ZTXT chunk, a ZTXT file, and figure out which methods belong where. Handle errors as much as you can, provide some CLI sanity (in this case a few CLI switches, and a flexible amount of files to run through). Performance is ever so slightly better than your Go version for some files, due to "seeking" over chunks instead of reading them, but the main point is it's error handling and extensibility.
A suggestion is you probably want to use `sync/atomic` package instead of directly `++`.
just found a bpf sniffer inside google/gopacket, while using deprecated api
By definition, yes, in fact. &gt; Right-wing politics hold that certain social orders and hierarchies are inevitable, natural, normal or desirable &gt; Although the right-wing originated with traditional conservatives, monarchists and reactionaries, the term extreme right-wing has also been applied to movements including fascists, Nazis and racial supremacists. &gt; Right-wing politics involves in varying degrees the rejection of some egalitarian objectives of left-wing politics, claiming either that social or economic inequality is natural and inevitable or that it is beneficial to society And that's from skimming the article on wikipedia. In practice, everyone knows there's a great deal more associated, especially in the US where this is sub is concentrated. Now as to the brigading, I have neither the inclination nor the time to pore through the post history of everyone in the thread. But it's quite obvious when you look at the amount of people participating, and consider that the prior code of conduct was posted in a subreddit dedicated to collecting examples of "SJWs" "corrupting" the tech industry.
‚ÄúDependency Injection In Go‚Äù https://medium.com/golang-tips/dependency-injection-in-go-99b09e2cc480
That hasn't shipped yet, so this probably bundles it's GC in the executable
[removed]
I'm actually more concerned with bundle size. I'm wondering what we are likely to expect.
Why not use React Native instead? 
I actually enjoy /r/golang much more than the official golang forums. They are going a bit overboard with the activism lately in the official community spaces. The latest code of conduct is extremely overreaching. I know they are trying to go for diversity, but at this point it really feels like "if you don't think like us we don't want you in our community" I find that here, there is more diversity in the sense of diverse opinions and diversity of thought, and you can typically have constructive arguments about controversial subjects without fear of the backlash that you would get from the official groups and channels. 
So you disagree with the fundamentals of right wing politics (which have many valid arguments, just like the left wing) and conclude that right wingers are by definition unsavoury. This is bad faith clear as day. In any case, none of the top posts are racist or discriminatory. Many of them have solid (or at least valid) arguments. If the racism or invalid opinions were so clear then you wouldn't need to "pour" through all the posters, it should be obvious. It isn't. Anyway, I appreciate your replies. I think gap between our perspectives may be too large to reconcile on an online forum. 
This is a side project I started about a week ago, so it's still in its very early phase. I found it helpful in my daily work when I need to run multiple commands to test out code changes, set up deployment, or share my CLI workflow with my teammates. Please give it a try if you would like to, and any feedback is very much appreciated :)
https://hackernoon.com/why-go-ef8850dc5f3c https://stackoverflow.com/questions/2896191/what-is-go-used-for https://www.quora.com/What-is-golang-good-for https://www.reddit.com/r/golang/search?q=good+for&amp;restrict_sr=on&amp;sort=relevance&amp;t=all
Go is a great language for server-side web development due to its native support for concurrency. I've seen people using it in the area of DevOps a lot as well, some famous tools developed in go are docker, kubernetes, etc. Also it's been used heavily for making command line tools, some good examples are docker (again), kubectl (again), and https://github.com/DrakeW/corgi (disclosure: this is a shameless advertisement - corgi is a CLI workflow manager written in go built by me, try it out if you would like to or take a look at the code base just for learning purpose, it's relatively simple :P)
I guess you could ask a lot of different people and get a lot of different approaches. Most of them would probably be fine and your current approach might be as well. I personally do most front-end in Angular, and that won't be available for an existing project. Building an object from the items on your form like you are doing might be fine. 240 lines of code isn't a lot (unless you are doing something expensive like DOM insertions in a loop which would cause the browser to do a lot of rerendering). There could be some other issues in your code... I'm not sure if you are going to have problems with your selectors. You use an id to reference days of the week but on an individual page, an ID is supposed to be unique, so if you have more than one id="sun" you will not get correct behavior. If it is unique, it is not necessary to specify another ID tag that it is nested within. If you do decide to use templates to generate something on the server, I don't believe you will see many people generating dynamic JavaScript. The HTML form itself might be something you can use templates just save some repetition, but nesting a language like JavaScript inside a template will probably just be too complicated to avoid errors. You mention modals a couple times when I think you mean models. However, if I'm correct, I'm not sure what you mean by a bootstrap model, so perhaps I'm not understanding your question entirely. My guess is that performance issues will be related to logical mistakes and not to a bottleneck based upon a decision to do something on the server vs browser. If you are using a Raspberry Pi and viewing with a modern browser, the Pi is still going to handle thousands of users and browser many thousands of lines of JavaScript.
I'm having a lot of fun with game dev with go. Just recently figured out how to get shaders working well. Currently working on adding this shader support to the opengl library i like to use, pixel. https://github.com/thegtproject/goshaders
In the actual code I try to use those, or lock it with a mutex. Did I miss something? In the article however to keep the code small I pretend that thread safety is beyond the scope and use simple non-atomic operations
Correct. Go's runtime (GC, maps, scheduler, etc) gets included in the wasm module. 
Yeah that should be good enough. Basically on prod there's a high chance that more than 1 threads could be trying to access/mutate the same metrics.
From my preliminary investigations, it is slightly smaller than binaries for linux/amd64. Though I am yet to test with -ldflags="-s -w".
It's a computer programming language. It does whatever a computer can do.
It's also a wonderful language for command line tools. I also find it a great fit for periodic or manually run "scripts". That is, the kinds of things that you might have started writing (or almost started writing) in bash, and then realized that it was complex enough that a bash version would be hard to understand and/or maintain. Python is also a good fit for both of these use cases, but Go tends to be significantly more performant and only slightly less readable. I'm usually happy with that tradeoff.
Thanks. That makes a lot of sense, except for the mocks part. Ive been using mockery and tend to write the tests in the same package as SUT, to have access to package privates. Using a separate package for the mocks results in an import cycle. Do you have any thoughts on that?
hi. I'll try to answer this. :) I can't safely answer for the windows stuff as I don't know. :/ But as for the rest: The plugin is loaded into the same environment. That's why there are some security concerns that it might be able to access shared objects and manipulate them. And since you have no idea what you are loading as the binary may contain code that you didn't see on the open source version, and there is no sandboxing option I wouldn't use these in a production environment. Unless it's you own code. You cannot unload plugins. And probably will never be able to. Code using it may contain references to code in the plugin. Related issue: [Unload Plugins](https://github.com/golang/go/issues/20461). Go plugins are compiled binaries. They are in their own main package. If your code has exported fields they would be able to use those fields as any other code would be. And than they export their own function in their main package and that's what you in your code would be able to call. You just call a function and that's it. You load that function via reflection. Your code doesn't compile with this plugin. It just uses it. You could potentially shoehorn the return value into your own type and than use that. In Go interfaces work differently as in Java. Describing that would be a post in it's own accord. What you could benefit more from would be scripted plugins. Lua is a great choice for languages such as Go and C to interface with as you can manipulate the ingoing data and the outgoing data pretty nicely. For a reference implementation see these projects: My Project [Ferguson](https://github.com/Skarlso/ferguson) is small and has a very minimal approach for Lua plugins loading and using them. This project [Micro Text Editor](https://github.com/zyedidia/micro) has an extensive use of Lua plugins and a complicated system managing / loading / unloading them. Since Lua plugins are scripted you have a much greater control over them and would be able to allow / disallow one runtime. They run in a lua VM which is also a Go implementation. They are fairly fast as well. I hope I was able to help somewhat.
Some hate against code thievery and copyright infringement is justified imho \^\^
From discussion in another thread - Advantages of Corgi over using shell functions for reusable commands: 1. More entry-level friendly: For non-expert in Shell/Bash (including me without surprise), Corgi provides an interactive interface that doesn‚Äôt require a user to learn how to define functions in shell or manage its complexity 2. Management: corgi manages your snippets for you under the hood, you don‚Äôt need to remember where you put your shell script or try to infer what they do by looking at file names or code. Corgi provides an interactive search interface that let‚Äôs you find your snippet quickly, and a ‚Äúdescribe‚Äù action that allows you to know what your snippet does without looking at actual code 3. Execution flexibility: if some function failed to run in the middle of running your shell script, you‚Äôd have to rerun everything again or comment out code to run the remaining functions. But corgi let‚Äôs you continue from where you failed by specifying a step range with the ‚Äú‚Äîstep‚Äù flag 4. Template: while achievable by shell function too, corgi‚Äôs interface for template/argument could be applied across commands, and it‚Äôs more intuitive to use (for non-expert I guess) 5. Better formatted output: you‚Äôll know exactly which step failed with the colorized step-scoped output, no more code digging to find the bad function call There could be more as more use cases being explored.. I‚Äôm thinking about adding remote server configuration so that corgi can run your command seamlessly on a remote server without typing all the ‚Äússh‚Äù 
\`goreturns\` is the one with most feature \- [http://goinbigdata.com/goimports\-vs\-gofmt/](http://goinbigdata.com/goimports-vs-gofmt/) \- [https://github.com/sqs/goreturns](https://github.com/sqs/goreturns) Note that it's default on \`VS Code\`
I created this issue [Suggestion: Can you add ¬´ Goreturns vs Goimports ¬ª section in README.md](https://github.com/sqs/goreturns/issues/47)
I hate these kinds of people("Sarah adams"). Fucking toxic snakes wearing a holy cloak. Authoritarians masquerading as inclusivists.
Personally, I use goimports and I'd probably recommend it over goreturns. The rationale being, that goretuns comes dangerously close to an ecosystem of code formatters with lots of knobs, IMO. goimports just makes a formerly incorrect file into a correct one - whereas goreturns enforces a style-opinion (and if you work on a project that uses naked returns, it would "fix" already existing code). You could easily imagine the next tool doing everything goimports does, but *also*, say, change all single-line struct literals to multi-line. And suddenly, we live in a world where each project has its own "correct" set of tools to use to format code, i.e. we get configurable code formatters, instead of a single style. (You could make the argument, that goimports also enforces a style-opinion over gofmt, namely that it not only *adds* imports, but also sorts and groups them. IMO that means that it either shouldn't do that, or that gofmt should *also* do the sorting/grouping, so that goimports is purely about adding them. Personally, I'd prefer the latter)
desktop programs. one liner to create redistributable executable for linux/win/macosx.
\`fmt.Sprintf(**\`\%x\`**, string(item.ID))\`
https://godoc.org/labix.org/v2/mgo/bson#ObjectId.Hex godoc is pretty great.
Try `item.ID.Hex()`. That converts the ObjectID to its Hex representation and returns a string.
Thanks a lot man
Thanks a lot man
&gt; goimports just makes a formerly incorrect file into a correct one - whereas goreturns enforces a style-opinion üëç 
A: `gofmt`.
You could start and implement it that way and then ask for improvements. 
Well, yeah. But I could also do it correctly the first time. I'm not asking for someone to do the job for me, just someone to say "Hey, there's actually a better way to do this. Go has a good library for...". 
The best solution is one you fully understand. If that means it takes some iterations over one thing why not go this road? Not bitching just curious.
This can be done with the std library and some channels and goroutines. I would look into logrus for logging. I would not use extensive third party stuff. For json structs there is a website : json to go. You can look into that. I would not do much more 
I'm sure I will understand it. I'm not new to programming and I've gotten pretty far in to this project without failing miserably, Go is working really well. If it's working better than what I did in Python, I may as well see if I can improve on it more, no? I could do it and it could work. It could work really well, but it could still be wrong. If I do it the same way and it out-performs Python, I have no reason to ever question it. You're suggesting that I need to do it one way and potentially fail first before I qualify for the right answer. Whereas a simple "Yes, this is the best way to do it" or a "No, actually, Go can do this better by..." will suffice. If someone asks you how you like your tea, do you let them do it potentially incorrectly first before you tell them how you *actually* like it?
Brilliant, thank you! I've already got handling the JSON response down, I was just curious as to if there is a better way to handle the subprocess thing.
You could clone it and benchmark it learn about testing and benchmarking in go and see them side by side. I was thinking of comparing them. If you want to have an idiomatic program sure then i would ask for the best idea how to do that. Such as concurrency and using them with fan in/out channels and waitgroups. There is a great talk from rob pike concurrency is not paralelissm and sone other about the fan in/out pattern in go. But learning it that way in the first iteration is hard. That is why i tend to ask people to do it simple and then improve it. But yeah i could have used better words :) 
Ah, that makes sense now. I thought you were implying I don't really qualify for help unless I do something first. I just thought you might have a problem with people coming to this subreddit and getting people to do their jobs for them! I'm re-writing in Go because 1) I want to learn Go and 2) Python is starting to struggle. Nothing major, you can just see the signs and I thought "hey, wouldn't it be cool if there was an easy solution and I learn something at the same time?"
Yeah my bad sry :) 
I find this a better explanation: https://appliedgo.net/di/
There are lots of ways... https://github.com/spf13/cobra &amp; https://github.com/spf13/viper work together to support CLI config flags and persistent setting management. However, typically programs just assume a set a defaults and start running. For small programs, they usually just use a database like sqllite which just means creating a text file. For programs that need an external database, they'll either walk you through setting up the database, or ask for credentials that allow them to setup the database. There are almost as many standards as programmers. ;)
I'm using [https://github.com/rcrowley/go\-metrics](https://github.com/rcrowley/go-metrics) just because adding a timer to HTTP handlers is so easy with something like: func WithTimer(name string, handlerFn errorFunc) errorFunc { timer := metrics.NewTimer() metrics.Register(name, timer) return func(w http.ResponseWriter, r \*http.Request) error { var err error timer.Time(func() { err = handlerFn(w, r) }) return err } }
autoproclaimed "standard"
That's the thing. Go shines as a back end language and so you won't find too much front end stuff to 'ease' things when it comes to go. At least not now.
1 goroutine kicked off for every line of the input file, ouch..
thank you. I think you've made me feel better about the approach I am taking than. I have been contemplating switching the front end to be something like angular or something similar but for now I'm not going to fix what is broken. As for what i'm referring to by bootstrap modals: [bootstrap 4 modal examples](https://getbootstrap.com/docs/4.0/components/modal/)
+1. Works for me. Tried with chi and echo, whatever.
I use goimports because when I'm refactoring code I have a habit of saving frequently and since I start at the top moving things over as I need them then based on the compile errors will know what to bring over next. When I was using goreturns by default it would remove unused imports and delete things which when moving code from one file to another that was proving to be dangerous.
I disagree, projects like Jasonette (and possibly developments in React Native) are language agnostic. Implementation can easily be done in *any* language, as they're effectively an RPC for UI.
`goimports` can take over 20 minutes to run (at least it can if you have a large enough GOPATH) so I use `gofmt` on save, and run `:GoImports` manually when necessary.
Pondering about this same question myself, I found the following solution on StackOverflow which works _great_: go run $(ls -1 *.go | grep -v _test.go) The thing is, that you only import _packages_, not project source files. `go` is your compiler and you need to provide the source files that makes up your project to properly build/run it. If you use testing, this above command will exclude the test files, as they shouldn't be included in your project when building it.
That is not normal. 
Combination of a couple different things, plus timing, but primarily I wanted a simple language, written in pure Go, that is fully embeddable and customizable. There's now a command-line interpreter, but the original plan was to have the language be a library exclusively. I wanted something relatively easy to integrate into other projects to add scripting capabilities to them. The original goal was to use it in a game engine, but I'm not sure if that's actually going to go anywhere at this point.
You should be able to use goimports on a per-file basis, and it should be basically instant in that case. I have mine set up to run on save. Unless maybe you're working on files with thousands of lines I suppose?
I will leave some comments on the codes.
Much appreciated :)
Writing tests in a different package is especially helpful when you're providing an external API to be used. Other than that, whatever works for you!
[removed]
&gt; The resulting WASM module is about 4MB but when compressed I'm curious what is taking up the space. I would assume supporting stdlib, but which parts? I wonder if there is any more dead code elimination that can be done beyond what already is.
If you read the whole thing you‚Äôll see that it‚Äôs not the fastest or final solution
Awesome write-up and advice for optimization in Go. 
I'll throw in my 2-cents along with /u/skarlso. Go plugins do not work in Windows due to the way they have to be loaded. Last I checked there is no one working on it. The "c-shared" compile option is for using a shared library written in Go in a C program. [This article](http://blog.ralch.com/tutorial/golang-sharing-libraries/) (not mine) does a decent job explaining how shared libraries work. The way I typically use plugins is with a register function that the plugin calls when it's initialized. For example, I have an IRC bot application that can load modules for extra functionality. When a module is opened, its init function calls a register function in the application. The application itself never actually uses the plugin directly. How you use plugins will of course differ, but it's just another way to do it. Using something like a register function also removes the need to use type assertion on a plugin's function or variable. I think this way of using plugins fits nicely with you Java comment. The plugin would register some function that fulfills a Go type or a struct that fulfills an interface. The application would then use the function or object like any other object. One last point, Go is very picky about "versions" of plugins. If a plugin wasn't compiled with exactly the same version of a package used in your application, the open will fail. I've made a point to always recompile plugins with the application itself in my Makefiles. Plugins can be useful. They have their limitations but if your environment is mainly Linux and plugins are used for added long-term functionality to the application, they can work really well. Once they're open, they act like any other part of the application.
I did read the whole thing, I don't know how you read my comment as implying that that was the only problem 
Thank you Asti\_!
Nice one. Thanks for the insights! 
Yeah, unbounded goroutine spawning is low-hanging fruit. Good to see it illustrated here with hard data.
Looks like a neat project, I am however always wary of open source projects that don't have tests. It would be great to see some good test coverage. Also I would consider renaming the util package as one of the design philosophies of go is to name packages well (Checkout https://www.ardanlabs.com/blog/2017/02/design-philosophy-on-packaging.html). Also it would be great to see some comments on those exported methods, use go lint spot where to tidy that up. 
Thanks for the suggestions, I'm trying to validate my idea at this moment and do plan to add tests in the near future :)
Yeah it sounds like he's using it on every source file and (probably even worse) it's getting ran on an entire vendored deps directory. That's potentially tens of thousands of files for an operation that's supposed to take ms and if he's on a spinning-rust HDD then it's no surprise to see it north of 20m.
Awesome! I'm gonna do a service that parses a csv file. This is gonna be awesome for some performance tricks :) thanks
My `$GOPATH/src` is over 100GB. So when I start using a new package (or make a typo) I imagine it's searching through all of that for the correct package.
as hinted here: - https://github.com/golang/go/issues/25612 using the `start` feature of wasm, we could probably ship the runtime as a separate wasm-module and pre-import it during `start`. (well, there's a huge amount of hand-waving there...) obviously, not for Go-1.11 :)
Glad to hear it, keep up the good work!
Thank you. I like your register idea. that does fit well with what I was asking. Essentially, if I understand it right, you load the plugin, call its init method and that method in each plugin calls your main apps register function passing to it a handler (in the plugin) that implements an interface (or struct, etc... as you said could differ from app to app). In that way, I could require plugins to use this method I have in my main app (register) which would dictate that an interface implementation be passed it. My plugin management would keep some sort of map of these to access them in some way. Right? if so, that is essentially kinda sorta what I had in java. I actually built a plugin engine very similar to the original eclipse IDE. Basically plugins could define extension points (interfaces essentially) that other plugins could define extension implementations for. This allowed plugins to work with other plugins, not just the main app. I could do something like this in go as well.. e.g. the plugin manager register function would have one or more bits passed to it that allow a plugin to define either an extension point, or extension to another plugin. What I liked about this extension point/extension thing.. it reminded me a lot of a bare app that was all plugin based. Even the main app was plugins. For example my main app had an initial frame (window frame) that was an extension point (well it had several extension points.. for frames, windows, dialogs, menus, etc). Other plugins could then build up off of those extension points. The main way to do this was to add a menu item extension, that when clicked by a user, activated the plugin that provided that extension in some manner. Usually it would be some sort of pop up window or something. I dont know much about Go yet, hence my query about all this. I assumed that like Java, Go would manage objects in memory.. e.g. the GC it has that it runs. I assumed like Java, you could define objects and eventually when nothing referenced it any longer, it would be GCd.. discarded... memory reclaimed. From what you and /u/skariso are saying, it sounds like there is no way for Go to reclaim object space.. or at least.. there is no way it handles determining when an object/method/etc is no longer being referenced? 
Not yet. I assume someone is writing something for it, maybe by adapting gopherjs's DOM library to use syscall/js. Curious to see how a full frontend framework will turn out for this.
I never gave much thought on whether or not to use goreturns (I do use it), and maybe this is because I have always been thinking that naked returns are not a style opinion but rather just feel wrong. But that's just my opinion! ;)
I never gave much thought on whether or not to use goreturns (I do use it), and maybe this is because I have always been thinking that naked returns are not a style opinion but rather just feel wrong. But that's just my opinion! ;)
Yea, that's the idea I was trying to get across. And you don't call the plugin's init function manually, Go's plugin package does that for you. So if plugins only do registration, you wouldn't even need to keep track of the `*Plugin` object returned by `plugin.Open()`. You could do that. All the main application has to do is provide a way to wire up the different handlers and run them appropriately. Either by some sort of hook system or callbacks. My applications so far have been fairly simple so I just have a single `map[string]HandlerInterface` type thing which I get query to see if a plugin name has been registered. Go very much as a garbage collector and a good one at that. Go will reuse or free memory of an object if it doesn't have any more references. It's just that there's no way for it to know if all references from a plugin have been removed. If you read the issue posted by /u/skarlso you'll see some of the issues they have with this approach. There's issues with non-deterministic finalizers and being sure that no dangling references are left behind at all. For me it's not a problem because my applications are designed such that when a plugin is loaded it's designed to stay loaded so long as the application is running. So I have no need to close plugins.
[removed]
 var chunks []string for i := 0; i &lt; len(s); i += 2 { chunks = append(chunks, s[i:i+2]) } The efficiency and everything is the same or better as with Python.
You know it is interesting too.. typically in most UI based applications, when you load a plugin, it sticks around. You dont typically unload it. The only time unload/reload becomes a thing is for server side hot-swap... which in this case, seems like it would be a much needed capability for Go since it is used heavily for server side stuff. Back in the day, I built Java Swing apps so plugins were a great way to offer 3rd parties additional avenues of use. I love plugins especially the concept that I mentioned before.. e.g. a core little module that just loads plugins so you can use/configure it however you desire. However, I am not entirely sure with a Go app when this would be useful. Even with hot-swap, today with containers, kubernetes, and more.. it seems hot reloading web applications is not something done in production. We tried to use it in the early 2000s in production and it worked.. but back then we still didnt truly understand the JVM, class loading/unloading, etc. You mention as does /u/skariso, about no way to know when an object has no more references to it. I would have thought if there is a GC in go, it has some sort of reference counter built in to objects.. so every time anything refers to it in any way, it increments the counter... and then decrements when they are no longer referring (e.g. null is assigned, or object is reassigned to something else). Is that not the case? Again, total noob and I have a lot more reading to do, and plan to understand how GC works in detail at some point. So if the plugin module is full supported by Go (e.g. first class citizen), I would hope that it properly increments references to objects exported by plugins.. or if plugin code references objects in another plugin or the main app.. that it can properly manage the references. Is there some caveat with the plugin system that once the binary is dynamically loaded, it is sort of this not so well behaved bit of code that doesnt follow the same rules as the main app? I am guessing not... but it is confusing to me then how an object loaded from a plugin is not able to be properly GCed. 
I understand this isn't exactly what your article is about, but you may want to mention that if you just want to locally view your swagger, the go-swagger tool has `swagger serve $SWAGGER_FILE` which will pop open a viewer. I see you're talking about shipping it as part of your binary and that is a different use case, but I can easily see people reading your article and thinking that's the only way they can view their swagger spec.
If you want a tiny bit more efficiency (especially of x tends to be long), pre\-alloc \`chunks\`, since you know what length you'll need: `var chunks = make([][]T, 0, (len(x)+1)/2)` Depending on how clever the compiler is, it also might be slightly faster to have len(chunks) preset and assign `chunks[i/2] = x[i:i+2]` rather than append(). But you'd have to measure.
This is where my knowledge of the internal runtime hits its limit. Go doesn't use a traditional reference counting type GC. Instead it uses a concurrent, tri-color, mark/sweep collector. This type of GC was first introduced in Go 1.5 and brought with it great improvements in performance and reduced the need to "stop the world". Some references for you to check out include [the blog post](https://blog.golang.org/go15gc) introducing the collector and [this post](https://making.pusher.com/golangs-real-time-gc-in-theory-and-practice/) has a cool animation that illustrates how it works. As for the plugin issue, there's two options. Either the garbage collector has to force resources to be freed upon plugin unload which could cause dangling pointers and instability. Or it would be the job of the developer to ensure all references where removed before unload. Other languages could implement this using some sort of finaliser but those can be "non deterministic when this freeing occurs as finalisers are not guaranteed to run promptly, or indeed, at all." ([davecheney](https://github.com/golang/go/issues/20461#issuecomment-303246760)). Also, there's an issue with what happens if the plugin starts goroutines? There must be a way to stop them. The runtime exposes no way to handle goroutines directly. Instead they simply have to return. This posses a challenge to the developer that is error-prone and just plain buggy. Just to be clear. Plugins are correctly garbage collected like any other part of your application. There's nothing particularly special about a plugin except that its code is loaded in after compile-time. Unfortunately I've hit my limit of GC knowledge. It seems like in modern development the advantage of unloading plugins is indeed supplanted with technologies such as containers where services are simply restart/rerouted rather than the application itself being hot-swapped. This also plays in with the whole "micro-services" architecture that a lot of people are moving too. For an application as you described with a small kernel and plugins for real functionality, unloading seems like a non-issue. For other software there are ways around it. Hopefully I've made things a little clearer. Regardless, welcome to the Go community.
Thanks! I did mention that approach in my [previous article](https://www.ribice.ba/swagger-golang/).
Good call on he registry. Can't believe I didn't suggest that. I'm actually using that here: [https://github.com/Skarlso/go\-furnace/blob/master/furnace\-aws/config/config.go#L125](https://github.com/Skarlso/go-furnace/blob/master/furnace-aws/config/config.go#L125) What this does is, it loads in all the plugins when it starts from a specific location. Then stores them for later calling and passes in the name of the stack as reference ( could be anything ). Once that's done, it calls a specific plugin at given event. You could do this too and pass in whatever you want. You just have to copy any struct you create in the source project though. Unless you reference it in the plugin as well. It's just another compiled Go program and thus can do whatever a typical Go program would be able to do.
Go has one more function for comparing slices, subtle.ConstantTimeCompare 
[removed]
Its a general purpose programming language but more geared for the cloud development. One of my project is to determine what are the logos in a video using a third party api. By extracting images from the video at a predetermined frames and using golang to send to the api concurrently is very fast. It's an alternative for building web, ML, microservices, cli.
https://github.com/golang/go/wiki/vgo-user-guide ^? 
AFAIK Russ' VGO blog series is the only decent reference about the proposal so far and also explains all of the reasoning in (possibly too much :) detail: [https://research.swtch.com/vgo](https://research.swtch.com/vgo) Walkthrough: [https://research.swtch.com/vgo\-tour](https://research.swtch.com/vgo-tour)
It would be useful to understand what issues you have with it rather than just saying "^" in the thread description.
I have been using the same approach for serving swagger docs within go binary. Primarily using it with chi, statik and swagger-ui. I find this much more easier then any codegen based approach.
Did you know there are projects that do exactly the same thing ? * https://github.com/lytics/cloudstorage * https://github.com/graymeta/stow If so, what is different in gost ?
You could have a look at how [protobuf](https://developers.google.com/protocol-buffers/docs/reference/go-generated#enum) does it - protos allow the same concept.
Thank you. That was helpful
Typically enums are represented with [iota](https://golang.org/ref/spec#Iota).
One of the culprits: unicode data. To fully support Unicode the program needs data about classification of all Unicode characters and this data alone is over a megabyte. Even when programs don't care much about unicode, it'll get pulled by standard library like fmt.Sprintf(). Another culprit: description of all types for reflection and precise generation. Each is relatively small but it adds app because there is a lot of unique types. 
Yeah, all the utf8 stuff can be cumbersome. I wish I could tell Go that I'm us-ascii only and just have single byte chars for my wasm library. Same with reflection. Especially in the case of generated code, I have had bloated binary sizes simply due to the number of exported identifiers. I also wish it were an option to eschew reflection info. But I know for both of those it won't happen because Go doesn't really appreciate conditional builds that way (e.g. optimization levels).
https://github.com/inconshreveable/go-update
Only just started with it, but, this worked: 1. download vgo: \``go get -u golang.org/x/vgo`\` 2. inside project root, build using vgo not go \``vgo build`\` 3. run your code, use vgo not go: \``vgo run cmd/main.go`\`
Started going through all your feedback, thank you so much I made a lot of silly mistakes so was good to have a fresh pair of eyes over it. I also learnt a bunch of new stuff, too! Really appreciate it :)
Hmm, interesting how a Go IDE developer left IDE/editor choice out of the survey results. I use Goland and like it. I see they include PhpStorm in the PHP section of the results, of course in that case it is the number one IDE. No hate on JetBrains, but I'm sure IDE/editor preference was part of their survey and the only reason to leave it out is it makes them look bad. It's okay to not be number one (yet) JetBrains, just include all the relevant questions and be transparent rather than hide unflattering results.
I'll ask why that was left out, if we did indeed asked that question (I honestly can't remember that now), but since the raw data will be available, I don't think it's going to take a lot of effort to do the math. You can also use the Go Survey from the Go Team from last year. I don't think numbers have changed that much.
Thanks :-)
Didn't read the blog, but have found my best "boosts" came from stealing others' ideas. So, as much as is practical, I devote some time to reading books and attending conferences... two benefits you should be getting from your employer. Very high signal / noise ratio from these sources, as compared to reading blogs and Tweets and such. 
Looks like coreos has (partially) implemented google's self-updating binary protocol, omaha, here: https://github.com/coreos/go-omaha * https://godoc.org/github.com/coreos/go-omaha/omaha * https://github.com/google/omaha/blob/master/doc/ServerProtocolV3.md * https://github.com/google/omaha depending on your needs though it might be simplest just to build it yourself.
One example: after [hearing about Toxiproxy](https://github.com/Shopify/toxiproxy) at a conference, I added the tool to our CI system to improve our the reliability of our services. The payoff is that our testing found some flaky components and helped us develop a very reliable system before hitting production.
I have the same situation 
I think that Go has been sorely lacking in UIs (despite what I think others may claim). The fact that it can easily interop with JS opens up an interesting possibility for Go as a cross-platform game development library if bound to Phaser or cross-platform desktop development if bound to Election. I don't particularly LIKE Electron, but these are options.
``` type Weather int const ( Sunny Weather = iota Cloudy Rainy ) type Country struct { weather Weather } func (c Country) Weather() bool { switch c.weather { case Cloudy, Rainy: return true default: return false } } ```
Maybe I'm not understanding the code completely, but what is the purpose of forking then shutting down when receiving a SIGHUP?
Mage has file mod time checks like a makefile. https://magefile.org/filesources/ Yes, if you want a 100% declarative build system, mage won't do it, but realistically nothing else will either. And in my opinion, fully declarative build systems are a lot harder to write and maintain anyway.
You write go. If you need to execute other binaries, there are helpers - https://godoc.org/github.com/magefile/mage/sh Ends up looking like. err := sh.Run("git", "reset", "HEAD", "--soft") The library does nice things like supporting expanding environment variables in the args, stderr as the error text, and optionally printing stdout to the console if you run mage with -v
[removed]
`The execution time is now dominated by the allocation and the garbage collection of small objects` Could a pool not help with this?
I am looking forward to the next part. I use [github.com/go\-openapi/spec](https://github.com/go-openapi/spec) in my RESTful applications.
Isn‚Äôt there better than electron now? I thought there was something people used for Go desktop. I wish Flutter did desktop too. I feel like Flutter + Go might be interesting and wonder if wasm has a role there. 
I feel like the CLI doesn't need the single/multiple option, since you're either specifying a CIRD that covers multiple addresses, or a single address or CIRD that covers a single address. Not really code related, but the usability would be easy to improve that way.
They're declared in the return values in the function signature. They, like all declared but unassigned variables in Go, start with zero values in them, which is 0 in this case.
Its works fine if you declare the variables to recieve those values https://play.golang.org/p/timTW21MlK7
Ah, got it thanks!
Well, no, they're the function arguments. 't' and 'err' are the return values.
 func (s *Hilbert) Map(t int) (x, y int, err error) What? No they're not. `t` is an argument. `x`, `y`, and `err` are returns.
X and Y came from mommy and daddy.
Swagger, Open API, Hypermedia (and all the HATEOAS, Siren, etc), GraphQL and more should probably all beg the question here... look, I‚Äôm for clean and consistent design, but are we getting to be a bit silly? Has it been that hard to work with APIs? 
Ok, if you are making a modal, the code almost for sure belongs in the JavaScript then. Templating JavaScript in Go will make your IDE powerless to help you with syntax and errors will be pushed from dev time to run time. I'm mostly repeating myself now, but I'm glad you are feeling better about the approach. There are libraries you can add to an existing project like JQuery, Knockout, Moment, Underscore (to name a variety of unrelated stuff we all love) and then there are things that require a specific approach from the beginning such as Angular and React. Good luck!
I echo the sentiment with how I think Microsoft has come quite a ways. I think it was last year's Github conference where I found myself watching a presentation by Microsoft about how open source has changed drastically over the last bit there. Found myself looking through Microsoft's public facing repos and was really impressed with just how much they've been putting up there. May have been a move that was mandated with the impending deal but even still, shows something imo.
`Syncthing` is a good example of a self updating Go binary.
Gah. I was looking at MapInverse. Sorry.
Sounds like you need Code Generation, not reflection. The compiler needs to be aware of any variables you're using, so reflection won't work here.
I could be very wrong, but iirc channels are not resources and do not need to be closed. The only reason for closing a channel is just to signal that you are done with it
Also note that they don't need to be explicitly returned, if you just 'return' the last value they are set to will be returned.
True. It's a tad finnicky sometimes though because of the way shadowing works, so it's generally better to be explicit in larger functions.
So my experience is with desktop clients in Java, but there are similarities. I didn't do self updating like you would think about with chrome. That shit is hard and left for Google. Someone else linked to a google library, if that does it and does it well, use it. Of not, this is what we did. First, realize that your app is more than a binary. It is a binary, am install script, an update script, and an install script. All made to work with each OS. You are now targeting users that don't or care what a binary is or what language you used. They want a working app that helps them. Go binary queries server for updates If new version, binary run update script, passing in new version. Go binary shuts down. Script waits for binary to stop (check OS running processes). Script backs up old binary and other files. Script downloads and replaces binary and any other necessary files. Script relaunches app. If script ever encountered an error, restore old files and launch old app Make this Bullet proof and dont change it. Don't ever get in a position where the app can't update itself. Don't have there server send a new url to the binary, send a version. That way, a MITM can't change the URL. Some upgrades take multiple upgrades to accomplish end goals. Like updating the upgrade system. Make this Bullet proof. Remember, an application is more than a binary. Go does some many problems like not needing to ensure the correct jre for a Java app is installed but you still need to think of more than a binary. For reference, see sparkle for a OSS Mac upgrade system. https://sparkle-project.org/
Same tbh
https://github.com/inconshreveable/go-update internally has a pure go implementation of Bsdiff. You can use this with your own signing infrastructure to send signed deltas and apply them on your binary. Host the signed deltas on s3 or similar http/https site. Here is a library for Ed25519 signing and verification: https://github.com/opencoff/go-sign (I‚Äôm the author of it). I‚Äôm happy to walk you through setting up an update system using these building blocks.
Also worth having a look at (although this one has a slightly different feature set): https://github.com/spf13/afero 
They're declared implicitly by the signature `(x, y int, err error)` This is equivalent to var x int var y int var err error It just saves you some boilerplate. It also has the nice shortcut of just typing `return` instead of `return x, y, int`
When dropping the requirement of *fully* automatic updates, a suitable alternative is to distribute the binary via Homebrew (macOS) Linuxbrew (Linux, obviously), and Chocolatey (Windows). This way, users can stay up to date without manually compiling from the sources, and there is no need for a complex self-update process.
There is a more performant way to compare slices by using BCE: [https://go101.org/article/bounds\-check\-elimination.html#slice\-comparison](https://go101.org/article/bounds-check-elimination.html#slice-comparison)
[removed]
Here is a really good example of how to do self-updating binaries implemented with the least effort. [Yitsushi's TOTP CLI](https://github.com/yitsushi/totp-cli/blob/master/command/update.go).
Yeah, that's about what I was expecting when I thought about filesystem abstraction. Go, with it's `os` package, already provides a reasonable API and the needed interfaces. Imagine how easy it is just to import a different package with an `os` compatible API and you start storing files to S3 or whatever. That's a great package. In fact, I wanted to write an article about how to do it in Go, since it's just a terrific use case. I've done filesystem migrations so many times in PHP, and obviously you rely on the stdlib there, and it's definitely not easy to replace that after the fact if you didn't create your own abstractions around it. Most people don't write their own abstractions, and in the case of OP, a pitfall is that he didn't use the existing ones, like with aero.
Just saw this comment! I made the switch initially out of curiosity (this was before I started working at Microsoft, if you're wondering). The first thing I liked was that it seemed to handle gocode servers running against big Go codebases. Kubernetes has always been a beast for me and gocode would end up taking &gt;1GB of memory. I guess vscode properly restarts it or something? I honestly have just accepted that it works and never looked into why. The built-in Go tester is cool too. That was the big one. The themes are pretty nice and the plugins for web development (HTML, CSS, JS, Typescript) are kinda nice too. So overall it wasn't a big decision or switch. A rarely but sometimes go back to Atom, but I'm 90% VSCode right now, and probably 5% vim. The rest is grab bag ;) Hope that helps answer!
Just a heads up, you're making ints there, not `Weather` typed things. You have to specify the type in the const declaration: type Weather uint const ( CLOUDY Weather = iota SUNNY WINDY )
Opps, I explicitly looked up the syntax for that and still managed to miss type it, thanks for the catch.
I have written a README. It should be sufficient to get someone started.
**code
What kind of tool? Design of the code or the usage? Is it a CLI app with various commands? You can look at this project: https://github.com/spf13/cobra
There's also a programming language called Mint github.com/mint-lang/mint
&gt;That way, a MITM can't change the URL. With a MITM proxy you can change it even this way.
No, thank you. That was an enjoyable read. The pprof section deserves a follow-up (hint: flame graphs :)).
yeah! I knew and used. Because ƒ± think how design another tool. 
If you would be flushing the []Message's into a database log or stdout or something, then most likely you'd be able to use and reuse a buffer of them. As for those tests, the messages are thrown away immediately and individually, so optimizing this to use a buffer would change the parameters of the test. By that I mean, the test wouldn't benchmark line operations anymore, but would become a bulk-test, ie, 1 x 100 lines, instead 100 x 1 line.
Sorry, it was late and I was tired. Not really MITM. But a compromised host can't hand put arbitrary urls. 
What tools do you use? What kind of tool do you want to make? 
What's your use case? I ask because my old company did a ton of micro services, many out of our control, so we did a lot of self updating binaries. With that said, it's a complex way to propagate updates, and I wouldn't recommend it unless you need it. What *would* I recommend? Non-fancy, straight forward approaches. Ie, in my current company we've got a bunch of processes but they're on static servers. Sure, they could update themselves, but why? We can do it with a manual trigger, or an automatic CD push, but regardless, an initiated script. Then the state of our architecture has either updated, or not - and is either successful, or not. Self updating binaries serve a purpose, but I just don't see the benefit in many scenarios.
[removed]
Great shout!
ƒ∞steƒüinizi T√ºrk√ße yazabilir misiniz? Daha fazla bilgiye ihtiyacƒ±mƒ±z var.
If I may deviate a bit, what is it about Semantic UI specifically that is causing the incompatibility with screen readers? Do screen readers depend on CSS being formatted in a certain way? I would have thought they didn't care about CSS, only structure of the document. Though perhaps it's the html structure itself, but is SemanticUI worse than other projects with similar goals? Ie, if the grid layout structure is the problem, do other grid frameworks achieve Screen Reader support with grid layouts? This is all ignoring ARIA tags of course, I'm just seeking understanding on the problem, as I haven't been following developments in the last handful of years for accessibility and semantic HTML. Appreciate the input!
Try something like this: https://play.golang.org/p/jfCs11ZOZy2
I now use glog, but when the app crashes, it loses log, even I changed the flush interval to mitigate it still exists. 
Not bad article, but why is this in /r/golang ?
the naive way would be to convert the slice into a string, and than simply check for equality `string(msg) == "Let's play"` it is naive for a reason though, don't do that if it matters
That would not work without first making them the same length: https://play.golang.org/p/F_L5MnRR6HX
sure, that is yet another detail that needs attention: re-slicing the original slice with the length returned by Read
Yes, this is important because my original solution will match even strings like "Let's play or not"
You can use `bytes.HasPrefix` https://play.golang.org/p/x16k5FUnRvM
One more alternative, inspired by both above posts: var x []T chunks := make([][]T, len(x)/2) for j := range chunks { chunks[j] = x[2*j : 2*j+2] } 
Recommends "clean code" by Bob Martin. Uhh, no thanks.
Isn't this more of a HTML / CSS problem than Go?
You can go the other way, too: [bytes.Equal](https://golang.org/pkg/bytes/#Equal) This is skipping a discussion of protocol design that the other thread is getting into, which for now I'll just handwave at [type-length-value (TLV)](https://en.wikipedia.org/wiki/Type-length-value) and call it a day. Broadly speaking, you probably don't want your protocol to _literally_ involve sending a bare string "Let's play".
Agreed, this project needs to outline what it does best/different. Funny enough, I'm in the market for this, but I still need to pick one of the projects, and I usually go with pre-vetted, not new, etc. Ie, Stow.
Author here. I've been working on Fo part time for 4 months. Feel free to ask me anything.
The problem is that many UI libraries use a DIV or just a plain paragraph as a UI control, with Javascript that handles events, e.g. when that item is pressed, expanding/collapsing DIVs, etc. Since this happens programmatically, i.e. dynamically, a screen reader has no knowledge of the control type, nor what happens when that control is used. As a result, dropdown menus, for example, do not act as one to a screen reader, and a blind user cannot really activate or select items, since the item itself is just text. In this regard, CSS needs to be tagged properly via ARIA, to signal that items are expanding, that a DIV is actually a button or a dropdown, or hide items that are actually hidden visually. Just a few examples, of course, but hopefully this helps.
It would possibly attract more attention in a frontend sub, however, in this case Go knowledge is needed, in case the UI needs to be rewritten from scratch. There are two possible solutions and since the main project (Gitea) is written in Go, it made more sense to post it here.
I'm not too familiar with the Gitea codebase, but maybe you care to explain: To what extent is Go knowledge needed for a frontend lib switch in this case?
You should not notice much a difference between go and vgo commands. Note that you can specify a specific version of a package with the @ symbol (it works with git tags) and maybe the import annotation becomes more popular but it is already part of the toolchain (package mypackage // import "github.com/me/mypackage") You should however notice a go.mod file whenever you dealing with vgo which contains version information.
If you still need a string representation implement the 'Stringer' interface.
* Gitea uses the html/template package. * The templates are in bindata, which needs Go to recompile. * Because the UI and the underlying Go server are intertwined, and the server API is not documented, it is very likely that one will have to look at the source to see what URL is being called, etc.
&gt; This is skipping a discussion of protocol design that the other thread is getting into, which for now I'll just handwave at type-length-value (TLV) and call it a day Is TLV a real thing implemented anywhere? That page is pretty hard to decipher (where are the values for command_c etc. ... why aren't the quotes included in the length). It kind of looks like a simple list of Key/Value pairs which is fine, but why not use something like [netstrings](https://en.wikipedia.org/wiki/Netstring) for each or if you really want more readability then something like a simplified form of [bencoding](https://en.wikipedia.org/wiki/Bencode). 
[removed]
 If I have a package Customer where I define a Customer type. I will not be able to define a List of customers (where generic List is defined in another package). Because it will create a circular dependency. Am I right? If yes, have you a workaround? For me, that's one of the biggest problem with the lack of generic which can not be resolved with code generation.
https://golang.org/cmd/compile/#hdr-Compiler_Directives &gt; The //line directive specifies that the source line that follows should be recorded as having come from the given file path and line number. Successive lines are recorded using increasing line numbers, until the next directive. This directive typically appears in machine-generated code, so that compilers and debuggers will show lines in the original input to the generator.
That helps a lot, ty
[removed]
Pretty cool dude! Keep up the good work
His series is great!
Did you consider different type of syntax for the type declaration? type Box[X] struct { v X } x := []Box[string]{{v: "ten"}} vs type Box&lt;X&gt; struct { v X } x := []Box&lt;string&gt;{{v: "ten"}}
If you look at their implementation you see they have just one method each. This is what makes them so powerful it's the best abstraction you can get. Familiarize yourself with the standard library and write small cli tools. One of the most important types in the standard library implementing Reader/Writer are *os.File and bytes.Buffer. Take also a look at io/ioutil and os.Stdin/out.
[removed]
Playground looks down? &gt; https://play.folang.org/
More specifically why did you use [T] (which is confusing with slices etc.) instead of &lt;T&gt; (which is commonly used for generics in other languages)?
Have you tried converting any of the [GoDS](https://github.com/emirpasic/gods) packages to fo?
Probably getting hammered. I'll see if I can get it back up.
No, it's a category of things, of which netstrings and bencoding are examples. I just wanted to reference the ideas, not get too prescriptive. The Internet is based on quite a few textual protocols, and they have some advantages, but they require a certain amount of code infrastructure to obtain their advantages, and they are also shot through with subtle-but-very-important issues that can be difficult for early programmers to understand and mitigate. Binary protocols are much easier to bootstrap, most notably because one of the things you can do is just use length-delimited strings to create an unambiguous textual protocol. If you use "2 or 4 bytes of length in network order, then than much string", you will save a lot of headache vs. trying to just send the strings down the wire. (In the case of UDP, 2 is the most you can count on.) As the protocols grow, well, each type of protocol has its own massive traps in it. But I think for quick prototyping work and for earlier programmers, a TLV-esque protocol is in the sweet spot of easy enough to program, easy enough to understand, easy enough to extend, and easy enough to grow for quite a while. (Many other important protocols like TLS are fundamentally TLV at the core; it can grow with you all the way to that scale.)
As per the documentation, Go's `strings.Field` is fully Unicode-aware, using `unicode.IsSpace` to determine which characters are [whitespace](https://en.wikipedia.org/wiki/Whitespace_character#Unicode). Python's split is not.
Just a guess here: it's possible that the bytes to string conversion and copies are bogging it down. Maybe try scanner.Bytes() and bytes.Fields. But there's a lot of things to remember about that, since those are slices into a byte buffer that gets reused by scanner, you can't store them without copying first. Here's a sample of how I wrote it: package main import ( "bufio" "bytes" "os" ) func main() { scanner := bufio.NewScanner(os.Stdin) var b []byte var fields [][]byte for scanner.Scan() { b = scanner.Bytes() fields = bytes.Fields(b) for i := range fields { if i &gt; 0 { os.Stdout.Write([]byte(", ")) } os.Stdout.Write(fields[i]) } os.Stdout.Write([]byte("\n")) } }
And what about a slice of generic functions?
A corresponding Go snippet should more look like file, _ := os.Open(file_name) defer file.Close() scanner := bufio.NewScanner(file) for scanner.Scan() { _ = strings.Fields(scanner.Text()) } Will probably not make much of a difference, but for one line, as your example suggest, it could. How do your files look like?
Lol I thought he was just going to do this for some reason: https://godoc.org/golang.org/x/tour/tree Great vid as always!
[] is confusing, what's the reason for this choice?
If you're just getting bikesheded on your choice of braces, you might be onto something :) Curious about how it's implemented -- does it just treat the initial definition like a template, and generate an appropriate type at compile time? Is type inference possible in the future?
https://www.reddit.com/r/programming/comments/8qk6w4/fo_an_experimental_language_which_adds_generics/e0jv553/
Man, something about that site is just terrible for me. I also can't tell if it's just spam, or if there's a legitimate post somewhere.. I'm feeling the urge to block that domain from my network. _(not being snarky, entirely serious - I'm confused on this post)_
clever strategy of "just" going with rewriting Fo code into normal Go1 code. \- [https://github.com/albrow/fo/blob/master/main.go#L71](https://github.com/albrow/fo/blob/master/main.go#L71)
I am confused, the following seems to have python unicode aware a = u'a\tb' a.split() gives [u'a', u'b']
That error either means you are not root. Only root can use ports under 1024.
weird because my portNum = 8080
[removed]
Try it with a whitespace character that isn't also whitespace in ASCII.
I think not. üôÇ
Wife her/husband him if you didn't already.
No mention of vgo?
&gt; I wanted to write an article Wanted? I hope you *still* want to! ;)
Great name. I‚Äôm going to make a semi-compatible version called Fo++ that is totally over-engineered. 
Sorry to confuse. Not entirely sure but I guess you refer to dev.to the site and not the question I posted? Let me clarify: I am curious about answers to the above question. The link is simply a reference since I asked the same question in that community as well. However here I intended to ask with a focus on Go since I am curious what tools people use in the real world together with their Go applications. 
Vgo is targetting 1.12
Of course it is a general programming language that can be used for a wide variety of tasks but in my case it has replaced Java and Python for Sysadmin tools and utilities. I like it's readability and static compilation over the import nightmare on servers that Python is and it is rocks as a Java replacement on server backends where you don't have to worry about Java versions and JVM's etc. In both cases because it is compiled the raw speed is useful to have.
Yeh, I agree with all that ... I guess the wikipedia page just needs a lot of love. I would add that using JSON as the message is nice to get something up an running but is much less fun for everyone, in a public protocol.
got it, thanks
 log.Println(srv.ListenAndServe()) router.ServeFiles("/static/*filepath", http.Dir("static")) log.Fatal(http.ListenAndServe(":"+portNum, router)) Both the first and last line here starts a server. Remove the first line, and replace log.Fatal(http.ListenAndServe(":"+portNum, router)) with log.Fatal(srv.ListenAndServe(":"+portNum, router)) and it should work.
`wedding, err := valentine.Wife() if err != nil { wedding, _ = valentine.Husband() }`
Tank you. We aren't formerly engaged yet... But it's matter of time ;)
I don't think comaining about [] qualifies as bikeshedding. [] has meaning to programmers and is ambiguous to the parser. &lt;&gt; has problems, but ## isn't taken, @@ isn't taken. Generic tags don't *have* to be directional for any reason that I can see.
Looks good. Thanks. 
If you get stuck there is a #mobile channel on the Go slack group.
Bikeshedding? `func MapSlice[T](f func(T) T, list []T) []T` is eye cancer, I'd rather use Rust.
I'm looking forward to [https://go\-review.googlesource.com/c/go/\+/72810](https://go-review.googlesource.com/c/go/+/72810) enhancement. I've been wanting to setup the TOS/DSCP for TCP connections. And and net.Conn.File() no longer having its ugly side effect is good. I've been working around it by calling syscall.SetNonblocking() after every call to File(), which isn't perfect (one bool down in the runtime doesn't get reset) but works well enough for what I need.
Append is not ever thread safe. 