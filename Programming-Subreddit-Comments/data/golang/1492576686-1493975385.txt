Well, it's a growth buffer then, which is also not bad :)
Nice !
That link is broken isnt it? 
What you're calling "useless repeated code" is in fact _incredibly valuable_, more valuable than anything else in the call chain except maybe the names of the functions. Those enumerated dependencies make it clear the scope and possible behaviors of the called code. You can bundle them up into structs if they become too numerous, but to eliminate them entirely by shoving them into some global DI context is a middle finger to everyone who's coming after you to maintain the code.
404 page not found
And now it loads.... Weird
Package names shouldn't be a composition of multiple names. They should be terse and single-purpose. In the situations where the compose multiple concepts they should be all together and lowercase: `io/ioutil`, `index/suffixarray`, `net/http/httptest`, `net/http/httputil`, `net/rpc/jsonrpc`. - [CodeReviewComments on Package Names](https://github.com/golang/go/wiki/CodeReviewComments#package-names) - [Effective Go on Package Names](https://golang.org/doc/effective_go.html#package-names) - [The Go Blog on Package Names](https://blog.golang.org/package-names)
Never had 404. Lucky I guess.
It shouldn't split. It should return link to the same chain. It has been made for Use stacking, not for splitting. But thanks for the idea. I'll add such functionality.
I never had a 404 either. I don't understand the downvote.
Basic typing doesn't even work on that page.
There are a few decimal type packages but I think it's better to go with integers that represent the smallest single unit of currency. That's how the Stripe API deals with it. It becomes a bit of a mess when you're looking at ways to have the types help prevent you from adding together two different currencies without conversion. The best I've been able to come up with is boxing the values as you have done with an internal representation in single unit decimals and the currency then having your methods like `add, subtract, multiply, convert`. The bad thing about the go type system is that it makes it difficult for the compiler to catch when you're in a situation of doing an operation on incompatible currencies without a lot of boilerplate. 
Fails (404) the first time, then if you refresh the browser it loads. Odd
From a quick look through one of the HTML files (`doc/go1.8.html`, to be precise.), it looks like they are using raw HTML, but with a very simplified convention and a JSON header at the top in a comment. I assume that the file's being included in another page, since it seems to just be some contents.
There's a huge caveat here if you actually intend to cover every platform that Go supports: The OS may not be POSIX compliant, lacking the uname command or the flags you require. It may also lack bash or any sh compatible shell. Particularly, this could be true for Windows and (less likely) Linux+glibc.
I personally can't stand indentation-based formats like YAML.
How does it compare with sqlboiler?
I didn't know about sqlboiler, but it's definitely nice. The obvious difference between sqlboiler and kallax is that it still forces you to use strings for accessing fields and such. WhereIn("name, age in ?", "John" 24, "Tim", 33) And it also does not enforce the use of the correct type on where clauses.
How does it compare with https://github.com/go-reform/reform (also based on code generation) ?
Yes, theses shortcomings you are mentioning are definitely a need, and all of them will be implemented in future releases. The library is currently being used by two of our teams in production so we can identify things that we don't like or are painful to use and improve them over time.
That's a very nice one. My main problem with all of the ORMs I found was the type safety, that's why I built my own (https://github.com/MohamedBassem/gormgen) which is very similar but yours is much more mature. I'd definitely give it a try in my next project. Is mysql support planned at some point? Thanks!
Can you build queries fluently and type safe way with Reform? Example from kallax readme: ``` q := NewPersonQuery().FindByAge(kallax.GtOrEq, 18).FindByName("Bobby") ```
Awesome! I've been looking forward for codegen-based ORMs, since it's basically the only way to solve two of the biggest issues in the field, which are type safety and performance. But people here seem to be taking the codegen approach as an disadvantage. What's wrong with it? The OP says it's 'hard to maintain', but I can't see why. Anyone?
&gt; the idea of *accepting* support for more systems Call it like it is.
Well, I'm not gonna lie to you, it's definitely hard to maintain. You have to remember to regenerate all the code every single time you change your models, a lot of generated code show up in the code reviews (if you're lucky GitHub hides the diff, if you're not, well...), it's more code that can cause conflicts during merges and rebases, it can get out of date when the core library changes and would require regeneration, etc. But it can be overcome. When we first started using kallax, we forgot some times to generate the models, so we added a check in our Makefile that made the build fail in the CI if we run `go generate` and there are changes. It can also be solved with a git hook before committing, etc. So yeah, there are solutions to working with generated code, but they require you to do something as opposed to not generated code that does not require that you do anything.
As of MySQL 5.7.8, MySQL supports a native JSON data type (https://dev.mysql.com/doc/refman/5.7/en/json.html).
Accepting implies adding, but ok, edited.
That would have been me (see reasons here: https://baymard.com/blog/line-length-readability). However I understand with this benchmark table, it doesn't work very well. My apologies for the inconvenience.
I see. I guess I haven't used go generate that much yet, but wasn't it supposed to be run by the compiler commands automagically and only when needed? I assumed there were baked in ways to not need to commit generated code and have it automatically generated/updated only when needed. Like its a first class feature of the language, isn't it? 
Well, it adds some pains, certain rules/workflow for the team to follow, etc. It's not the worst thing ever, but it is harder than non-generated code.
It seems like people complain about code generation, but I've yet to run across an ORM that doesn't involve generated models (not many people hand code these, some do I guess). Granted in languages with generics you have less to generate, but you pay the price for generated code in almost every case I'm familiar with.
Do i need ORM for graphdb and mongodb?
/u/opher200 , the last /u/erizocosmico answer should satisfies your doubts
Yeah, I found it and started using it, and was surprised to see that it had been checked in 5 hours prior. Rather fortuitous.
I always enjoy a new player in the Go ORM space, but I'm not sure to what extent I would want to pick this over something like [sqlboiler](https://github.com/vattle/sqlboiler), which is also type-safe through codegen (barring the QueryMod issue brought up in a couple other comments before I finished typing this...). One thing I'm really liking about sqlboiler is that I only have to write my schema and migrations in one place. If I want to migrate my data, I do it in the database, then the Go portion is generated from the database schema itself. By doing so, I can't make the mistake that the blog post gives, i.e. making a typo in the table name when using it. Even the typo problem can still occur in Kallax (for now), since you have to specify the table name in the struct tag _and_ the schema. Given the "next steps" being to generate schema and migrations, that will probably disappear, but I still think there's a little bit of comfort in writing the migrations yourself and knowing exactly how your database is transitioning over time. I'm definitely a huge fan of codegen for the exact reasons the blog post gives (type safety mostly, but also transparency), and I'll be interested to see if the benchmarks get expanded to look at other ORM-ish things like sqlboiler/reform/dat/sqlx/etc. Benchmarking against gorm feels a little like cheating, since it's probably the most heavyset database library out there. :P
That's really unfortunate. I don't know where I got this idea that it was ran automatically. But still, that seems more of a "workflow" problem than a maintainability one. As others have suggested, you could use make, git commit hooks, etc to aleviate the problem. Anyway, thanks for the responses! Much appreciated.
Idk, but its probably not good, its Oracle after all.
Imagine library A requires generated code but did not commit that source. Library B uses library A. Library B is required to include instructions to build also library A, because it's missing required generated code. And you need to build B and A by hand, because when you `go get` them, they won't build. Now imagine this situation for N libraries. Right now, codegen is very manual in Go. So I think committing generated source code is the lesser evil compared to a build hell. 
After going through Kallax for a bit and trying a simplified version of what I'm currently working on, it seems difficult for me to do the following: CREATE TABLE patterns ( id SERIAL PRIMARY KEY, name text NOT NULL, exp text NOT NULL, counter int NOT NULL ); -- some insertions SELECT * FROM patterns WHERE ? ~ exp; To me it feels like Kallax is interesting for the codegen (though there are a number of other tools you didn't seem to be aware of...), but when it comes to querying, [it's just a wrapper of squirrel](https://github.com/src-d/go-kallax/blob/v1.0.5/operators.go#L22). I can't use the POSIX match operator unless I start writing my own `Condition` functions, but at that point, I'm just writing squirrel code (which is funny, as the usage of squirrel is never mentioned at all in the documentation). When I go to write more complicated queries, the "type safety" ends there. What if I want to select every pattern that was used more than some number of times, say with: SELECT * FROM patterns WHERE counter &gt; ?; The generated code only has `SelectByCounter`, so I have to create a new query with `PatternQuery`, and then do: models.PatternQuery().Where(kallax.Gt(models.Schema.Pattern.Counter, num)) // num is some int Except that the signature of Gt is `func Eq(col SchemaField, value interface{}) Condition`, so, whoopsie: models.PatternQuery().Where(kallax.Gt(models.Schema.Pattern.Counter, "num")) And I don't get to know that I've given it a bad value until the query happens. It's great that I was able to unambiguously specify some of the query (even though typing out a huge field access felt awkward), but if I'm going to be doing anything more complicated than simple finds on fields, I'm still paying the performance and development cost of `interface{}`. Am I missing something?
The same thing that happens to anything bought by Oracle. A slow, painful death.
&gt; ``` models.PatternQuery().Where(kallax.Gt(models.Schema.Pattern.Counter, "100a")) ``` It should be done: ``` models.PatternQuery().FindByCounter(kallax.Gt, 100) ``` And you can chain more filters! ``` models.PatternQuery().FindByCounter(kallax.Gt, 100).FindByName("Bobby") ``` And it will cry if you do not pass an `int` to the first `findByCounter`, and an `string` to the second one, because the autogenerated `findBy` are type safe as explained in https://github.com/src-d/go-kallax#generated-findbys
Ah, I see. That's reassuring, and I feel bad for missing that when I read through the docs.
This behavior is maybe no properly described in the docs, but you can get more info in its PR description: https://github.com/src-d/go-kallax/pull/92
Oh, my, we forgot to mention squirrel in the README. Thanks for pointing that out! will do ASAP. We thought of rolling our own query builder, but a query builder is a query builder and squirrel is awesome already. That's why internally all queries are built with it (also because it has nice stuff for caching statements with zero effort, etc). We just implemented the most widely used operators, but we're planning adding all other operators available. The idea is that you don't need to define any operator. As /u/rizome said, also `FindBy{{FIELD}}` methods are generated, and that's where you have the type safety. Of course, as queries grow in complexity, there are cases that can't possibly be covered easily in a general way and are not type safe. But, at least, you never have to write strings with the field names or any sql syntax (unless you go full raw sql), which is more than nothing. Thanks for your feedback! Will update the documentation and add support for the `~` operator while I'm at it.
You remembered a delicated subject: "interoperability". In this case, I didn't refer to that; What I was pointing is the case when the same model can be persisted in different db (maybe the whole entity is in PostgreSQL, one of its properties is a counter that is persisted real time in Redis... another model of the same application is read from Cassandra...) In that case, how would be "generated" that model if it comes from different db schemas? Should those ORMs for different DB be compatible when generating the same model, or related ones? On the other hand, if the source of truth is the Go code, the persistence can be understood as an implementation detail, and some things are simplified. I'm not saying that "it is the only one possible way to face that problem"... I'm just pointing the underlying reason: "some people feels more comfortable handling code, and having the DB as a 2nd citizen" By the way: you mentioned protobuf... idk if you know this other crazy tool from the same crazy guys ;) https://blog.sourced.tech/post/proteus/ (because its underlying idea is the same: "having the Go code as source of truth") For some ppl, "generated code sucks", for other ppl, it rocks; it is just a matter of perspective and necessities; same than when you decide where to locate the "source of truth", in the code, in the db, or in a proto file
Oh wait what?
Author here. If you can get away with using sarama or sarama-cluster alone then absolutely, KISS and you're good to go. Kasper is meant for applications that need to do complex stateful processing, such as joining multiple streams or computing materialized aggregations. The target audience is similar to that of Apache Samza, Apache Storm, Spark Streaming, Apache Flink, and similar frameworks.
Please someone send a drone to flatten Oracle once for all.
&gt; Since the common case is using a pattern by hand I preferred using a string parameter as pattern. If not, it would have been `interface{}` to check if it's either a column or a pattern and the error would not be compile-time anymore. That doesn't exactly cover what I was saying (in terms of where `interface{}` comes from). I can see these three variants needing to exist (pretend these had better names): FindByPOSIXRegex1(s SchemaField, pattern string) FindByPOSIXRegex2(s SchemaField, pattern SchemaField) FindByPOSIXRegex3(s string, pattern SchemaField) // No FindByPOSIXRegex4, since that would be (string, string), which is either true or false anyway I'm assuming you mean the first one of these. Then, to deal with the 4 other variants, one could probably do (again, ignore bad naming): const ( PatternMatch = "~" PatternMatchInsensitive = "~*" PatternNoMatch = "!~" PatternNoMatchInsensitive = "!~*" ) I guess I'm curious what underlying change there would be, as I think doing this would be as simple as implementing a `squirrel.Sqlizer` with the operator in the middle, which is like doing Gt/Lt, etc. I'd look at the PR, but I'm supposed to be doing things other than use reddit, and clearly failing at that...
&gt; In this case, I didn't refer to that; What I was pointing is the case when the same model can be persisted in different db (maybe the whole entity is in PostgreSQL, one of its properties is a counter that is persisted real time in Redis... another model of the same application is read from Cassandra...) In that case, how would be "generated" that model if it comes from different db schemas? Should those ORMs for different DB be compatible when generating the same model, or related ones? I feel as though at that point, all bets are off, because you're already doing something that's not just accessing a database. I don't think Kallax (or sqlboiler) solves that problem in any way. I think these libraries are instead just creating a handy mapping between Go and the database, which is good itself. &gt; By the way: you mentioned protobuf... idk if you know this other crazy tool from the same crazy guys ;) https://blog.sourced.tech/post/proteus/ (because its underlying idea is the same: "having the Go code as source of truth") I don't typically background check before commenting, so I didn't see that. it's funny that I used the same wording as that post's title, for sure. I understand why Kallax is structured the way it is, but it's definitely a matter of choice. &gt; For some ppl, "generated code sucks", for other ppl, it rocks; it is just a matter of perspective and necessities; same than when you decide where to locate the "source of truth", in the code, in the db, or in a proto file And I am definitely in the "generated code rocks" group. :)
Author (one of two) of sqlboiler here. I haven't looked in depth, but from scanning the readme these are the things I've seen that are different: The most fundamental difference I think is that when we created sqlboiler we specifically did not tackle definition of models in some sub-language of struct tags and embedded structs because there were existing ORMs that took this approach and we disagreed with it. As it's pointed out in the sqlboiler readme here: https://github.com/vattle/sqlboiler#why-another-orm - we don't want to define the schema because other tools are already much better than that. There's database specific features that you can never achieve by writing struct tags, like postgres triggers that will have to be implemented after you've generated your models from Kallax and managed in a separate tool anyway. I think this is one of the important differences since there are a lot of drawbacks of using the ORM tool to define your database (one big one is that it's much more difficult to use if you already have a database created that you're working with). It's also worth noting that they cannot generate a database yet either unlike GORM, so although it's a code generator it looks as if you have to manually create all your CREATE TABLE statements for the database in the end anyway. They currently only support Postgres, whereas we support Postgres, MySQL, and soon to be announced &amp; merged: MSSQL (SQLServer). Their queries where multiple results are returned are looped over whereas ours are simply returned as slices of the model. This may have broader performance implications (negatively for us actually) but I don't know for sure yet. But it does help a lot in serialization out to JSON etc to have them delivered to you as an immediately serializable slice and not have to create your own. They don't support many-to-many relationships, whereas sqlboiler does. As eriz noted, we do have bouts of type unsafety whereas Kallax does not. Their transaction API forces use of the transaction inside a lambda which means that there's no delegation of transaction use able to happen here, it's completely transparent to the user, where as we give you a transaction that's compatible with the sql library so you can do whatever you want with it. They use a Kallax-specific database connection which you have to inject throughout your entire application. Whereas SQLBoiler uses an interface that's compatible with https://golang.org/pkg/database/sql/#DB and any similar variants like sqlx's light wrapper around sql.DB. The implication of this is that applications previously using sql.DB everywhere or something similar will have to ripple this change throughout their code base, whereas you can start using SQLBoiler without changing it anywhere. This is the stuff that jumped out at me the most. I think it's a very cool ORM, but I think that sqlboiler compares very favorably to it (yes bias, bias, disclaimer etc.). I hope that we each amend our benchmarks to compare to each other soon too. As the developer that did most of the performance work in sqlboiler I wonder what the completely-pointless-but-somehow-still-interesting micro benches will look like :) edit: Added more info on one point about JSON serialization
Let me explain at least why sqlboiler went the route of not using a go file to manage sql (author here) as I think our own discussions on it are relevant to the wider group (though perhaps not :p). SQL is a tremendously huge language. Once you get passed the common ground, Postgres, MySQL, SQLite, and T-SQL (MSSQL/SQLServer) all diverge an incredible amount in functionality. Triggers, indexes, full text searches, field types all of these have widely varying syntax (sometimes) and options. You will never be able to have this functionality defining it through a sublanguage written in Go unless you make it as big as each variant of SQL is itself (which isn't truly feasible). Versioning of your database is very important when working on a team with multiple people. Rails/ActiveRecord solves this through having a migration system that tracks which migrations have been applied to your database so that at any time you can run the migrations and be right where you're supposed to be. Imagine you're working with Kallax which defines your models and running some command to fix your database up. How is it going to know that you happened to miss an important data migration that occurred in a previous version of the code that you missed checking out (since you were away from work for a week or something), and that a future change removed a column that you needed data out of? You can't do incremental steps in Go code unless you start putting migrations in the Go code itself, and then the question is: Why is a Go file that's limited by some domain specific language better than just a plain SQL file itself? The ability to record every change to the database in increments and run it at a later time (or from scratch) is -very- important. To your point - the code is the source of truth. Because the migrations are part of the code. They're in the same repo, they're beside the same files, they're versioned the same - so I'm curious how it's different. Your only responsibility becomes to make sure you do "migration-command migrate-my-database" every time you check out newer source code (or have code that checks for version mismatches on startup as rails does). I highly recommend the use of the wide variety of migration tools that are out there for Go. We use a fork of goose because it has some crazy behavior we don't like - but in general it's a decent tool.
More go shops are on the way to get acquired by Oracle. These news will become common in the upcoming months. Oracle needs desperately to fight against its own decadence (now no one really cares about Oracle DB - except those already invested on it; no one really cares about old Sun hardware, except those already invested on it; Java is still relevant, but other languages - Go included - is eatings its lunch...) So yeah, Oracle is trying to buy its way out of a problem that its own gigantic structure put itself into. edit: typo
Oracle is poison. They are the antithesis of Open Source. Seriously. Fuck Oracle.
ok, I threw this together and it seems to do the trick. Cleanliness is a matter of preference, so I don't know how to help with that, but functionally, it's all there. main.go package main import ( "database/sql" "fmt" ) func main() { fmt.Println("foo") } type ItemModel struct { Name string Description string Price int } type SQLItemStore struct { DB *sql.DB } func (sis *SQLItemStore) Store(i *ItemModel) (id string, password string, err error) { err = sis.DB.QueryRow( "INSERT INTO items (name, description, price) VALUES($1, $2, $3) RETURNING id, password", i.Name, i.Description, i.Price, ).Scan(&amp;id, &amp;password) return } main_test.go package main import ( "testing" sqlmock "github.com/DATA-DOG/go-sqlmock" "github.com/stretchr/testify/assert" ) // a successful case func TestStore(t *testing.T) { db, mock, err := sqlmock.New() if err != nil { t.Fatalf("an error '%s' was not expected when opening a stub database connection", err) } defer db.Close() // input i := &amp;ItemModel{ Name: "foo", Description: "bar", Price: 42, } // expected output expectedID := "ebe875eb-1313-48b4-9f77-fa808f081da0" expectedPass := "super secret password" // define the rows you want the mock to return rows := sqlmock.NewRows([]string{"id", "password"}). AddRow(expectedID, expectedPass) // tell the mock what to expect and what to return mock.ExpectQuery("INSERT INTO items").WithArgs(i.Name, i.Description, i.Price).WillReturnRows(rows) // now we execute our method itemStore := &amp;SQLItemStore{DB: db} outputID, outputPass, err := itemStore.Store(i) if err != nil { t.Errorf("error was not expected: %s", err) } // we make sure that all expectations were met if err := mock.ExpectationsWereMet(); err != nil { t.Errorf("there were unfulfilled expections: %s", err) } assert.Equal(t, expectedID, outputID) assert.Equal(t, expectedPass, outputPass) } 
A good example is worth a thousand words :-)
sqlboiler has a similar featureset and supports mysql already. Maybe take a look :)
What I didn't like much about it is that it kind of scaffolds the code form the design but makes that a one time thing. Any changes don't generate everything again unless explicitly forced to do so. What I'd like to see is a system where I only code the business logic and then the generator handles the generation for API and other stuff. Have I misunderstood how Goa works?
It'll happen whenever enough great ideas accumulate that the core team will want to incorporate them and break backward compatibility. It'll not happen for the sake of happening. So, in order to make Go2 happen, the community needs to come up with design proposals to fix the warts of the language and may be some very thoughtful features.
Only typing improvements among the 3 points will need a breaking change and to make if happen, someone will have to come up with solid reasoning and possibly a proposal to spark the discussion. It'll most likely not be accepted but it'll lead to better proposals which eventually might get accepted in some form or shape. 
BTW there are plans to make GOPATH thing more automatic in coming the releases. 
I use standardized sql and therefore its easy to switch between servers by switching drivers. For live I use a remote mysql server but all tests run local on sqlite. For each test the db is reset and then filled with the data needed for the test. Super fast and no mocking needed.
http://bad.solutions :(
I checked and it looks like this uses the same fatally flawed password generation method from the original "lesspass". The problems are detailed in this podcast episode: https://www.grc.com/sn/sn-586.htm
Have you considered using httprouter? Can be found here: https://github.com/julienschmidt/httprouter
It's good to see more contributions to the eco-system, but I see no reason to use this over SQLBoiler, which has more features, and I like it's API better -- it seems a lot more thought out.
Probably nothing, and I assume the Go codebase will continue and grow. Oracle only cares about the license, and the Go license is as permissive as it gets.
The time you put into this and valuable input is great. After only using SQLx in the past, I'm tempted to look at you tooling now as a Much different type of approach.
Done is open source now, no?
This makes my decision to start with Go a good one. I still think it is crazy with the performance.
&gt; I don't think Kallax (or sqlboiler) solves that problem in any way. You're right. But I was not saying that "_Kallax **solves** that problems_", I was trying to explain that in some cases "DB first" is not the best approach, as we do not always do OOP, or FP, or shell scripts... My point is that there are situations when you need to keep save your data, and you focus in interoperability; or when you do not have a main language in your codebase. In that cases (and in many others), doing "DB first" can be a good way to proceed. But there are other situations: you try to maintain your business logic in code; you have a main language in your code base; the persistence is not the core of your business because it can be changed, splitted... In those and other cases, I thing that doing "Code first" and putting the source of truth in that main language, can be better than doing "DB first". And if you do "Code first" -because there are situations that require it- it make sense using tools that follow that pattern.
Google has taken their Java and now Oracle is taking their Go.
From their [FAQ document](https://www.oracle.com/us/assets/wercker-faq-3680198.pdf): &gt; Oracle and Wercker will continue to operate independently. &gt; Q: Will the community edition of Wercker remain free? A: Yes, there are currently no plans to change the community edition. So lets wish for the best.
Excellent article, thank you. I'm really excited to play with some Go machine learning libraries when I get some spare time.
I agree. Probably migrations will be written by hand in SQL, but we haven't decided yet. In case we go this way, we'll probably integrate some existing migration tool. 
&gt; In both approaches you've thought about persistence first. Not at all. The use case of my prev comment describes clearly that initially the ```Thing``` model is not persisted, so persistence is not considered at all. The persistence is considered only once it appears the necessity of persistence, and in that exact moment is when you need to proceed considering "code first", or "db first". Both approaches are quite different, and requires different actions to modify and handle the ```Thing``` model. And as described, one of them requires less effort in that use case. 
What are you on about, drone has shut down their commercial offering in favor of the opensource version, which is still actively maintained by the community. I've been using it(self hosted) for over 12 months now and have no complaints.
Thank you very much for these precisions and references.
if using https://github.com/go-playground/pure (disclaimer I am author) it has a helper to decode these SEO params as I call them into a struct https://gist.github.com/joeybloggs/c610086166130d4f5d78ea082916b6c2 Please note this will decode non-SEO query params as well such as ?id=13; I will be adding another helper today just to decode the SEO query params. 
Awesome! Finally!
I really don't get it. You can't call `Thing` a model, because it's not one at that point, it's merely a fairly useless (it has no model functionality) struct. If you want it to be actually useful then you have to call the generator anyway, and if you don't care about it being a model and just want a struct then you can do the same thing and create a struct with a DB-first approach... I'm just not seeing where "less effort" comes into this at all. From what I can see it requires the exact same amount of effort.
From reading this, am I to understand that people using GPIO via Go on Raspberry Pi previously had to use Cgo? If so, this is a fantastic improvement! I didn't know Pi users were stuck with that since my Pis mostly collect dust or run webservers that nobody visits. :)
Hey you made it into the Readme! Also the [commits](https://github.com/zeebo/goof/commits/master) messages gave me a chuckle as well.
"moby" has mentions of docker all over it. Very strange...
https://blog.docker.com/2017/04/introducing-the-moby-project/
What happened is a good idea: restructure the docker project to accommodate all the R&amp;D that has happened. But then they named it Moby. Yeah like the super famous musician who has songs in a dozen movies. Did they forget to Google? I get it. Moby Dick. They have a whale logo. But you know that the story is about killing the whale right? Better, their reference implementation is called "Moby Origin" which is perhaps the least original name you can make. Not only does it sound like one of Moby's albums, but also like maybe a sequel to a video game? So I'm salty about the stupidity of taking a well recognized, well branded project -- that kinda explains what it does in the name -- and instead calling it Moby. But otherwise seems to be good business as normal.
&gt; Import paths are fucked. Are they? The PR you linked to explains that the Go tooling should handle the redirect transparently. I dislike the move, but I don't think it's cause for panic.
What is not obvious to me (neither from this package, nor the documentation on Mastodons pages) is how the oauth story works. The example does a plaintext password auth, which creeps me out. I know Mastodon supports some form of oauth, but I don't see any support of it here. Apart from this, this looks like a well-designed API and I would be very excited to use it :)
&gt; But you know that the story is about killing the whale right? SPOILER ALERT Despite the determination of his pursuers, Moby wins.
Have a look at: [https://github.com/golang/go/wiki/SliceTricks](https://github.com/golang/go/wiki/SliceTricks) Awesome tips and tricks, helped me a lot.
Perfect. Thank you so much for the detailed answer! This makes a lot of sense. I understood that slices were backed by an array but couldn't figure it out. I think the piece I had missed was that `append(b[i:], 3)` was actually modifying the underlying array of `b`, not allocating a new one. I think that makes sense.
https://news.ycombinator.com/item?id=14157715 &gt; Hacker News new | threads | comments | show | ask | jobs | submit soroso (115) | logout &gt; shykes 5 hours ago | parent | flag | favorite | on: Docker is transitioning to Moby &gt; &gt; Hi all, Docker founder here. It appears that the explanation in the pull request is not very clear. Sorry about that. We didn't expect the PR to be the first thing people read: there is a new website at mobyproject.org. Unfortunately Github is struggling under the load, and I can't update the PR text to clarify. &gt; Here is an updated version with some clarifications: &gt; &lt;&lt;&lt; &gt; Docker is transitioning all of its open source collaborations to the Moby project going forward. During the transition, all open source activity should continue as usual. &gt; IMPORTANT NOTE: if you are a Docker user, this does not change anything. Docker CE continues to exist as a downstream open-source product, with exactly the same interface, packages and release cycle. This change is about the upstream development of the components of Docker, and making that process more open and modular. Moby is not a replacement for Docker: it's a framework to help system engineers build platforms like Docker out of many components. We use Moby to build Docker, but you can use it to build specialized systems other than Docker. &gt; You can learn more at http://mobyproject.org &gt; We are proposing the following list of changes: &gt; - splitting up the engine into more open components - removing the docker UI, SDK etc to keep them in the Docker org - clarifying that the project is not limited to the engine, but to the assembly of all the individual components of the Docker platform - open-source new tools &amp; components which we currently use to assemble the Docker product, but could benefit the community - defining an open, community-centric governance inspired by the Fedora project (a very successful example of balancing the needs of the community with the constraints of the primary corporate sponsor) &gt; &gt;&gt;&gt; &gt; EDIT: I'm happy to answer any follow-up questions here, if it helps clarify.
Let me quote the top question in that thread (Unanswered until this point): &gt; Do you know that keeping your users in a constant state of confusion is not the way to convince them that you're building a stable and secure product? Also, isn't it kind of ironic that you built your company on OSS and then invited a well known destroyer of OSS onto your main stage? Plus, I want my DockerCon money back. What exactly did you announce besides multi-stage builds at the general sessions that is actually benefiting Docker users? I don't care about your plumbing and constant rebranding, other than finding it very discouraging, I want to know what you're actually doing with your product this year. I guess nothing. 
This was always a possibility so I don't think it damages Go as a language in any way. No more so than say MySQL EE damaged C/C++'s reputation. The permissive license that allowed Docker to make this kind of move was presumably in place before the community decided to contribute and grow around Docker. If you care about open source software remaining open source then this should serve as a gentle reminder to look at the licence before contributing.
To be honest this isn't as much a license issue as a branding issue I think. If Linus Torvalds suddenly decided "Linux" is their "EE" product and "FuckYou" is their open-source "CE" project. With things like trademarks I think there has to be some degree of trust involved in the whole thing... I mean, its really hard to legally state "This is our trademark, we control it, but we promise not to change the licensing of the products under it in any way shape or form". Maybe there is a way, but we are getting too much into law at this point and I'm a software developer not a lawyer. And really, if the fore-front of the community is composed of assholes, there's not much to do about it. Also, in the plethora of open projects written in C/C++ the fact that mysql sold out doesn't make much of a difference, with golang I'd be hard-press to name even a few projects written (even partially) in the language as popular as docker.
Well it's on reddit now for posterity. Thanks again!
We used Bolt as a local DB for a high transactions per second product and we very quickly found out that it doesn't perform well under those circumstances. Because it basically uses a giant memory mapped file, it would lock it for each transaction and cause a ton of contention issues for concurrent transactions. In a flood of GetItem requests to it, a majority of them would lock up and end taking 60 seconds for the DB to respond. Not saying any of that is outlandish for a DB, but I would say to be apprehensive of it if you have a performance critical application. Perhaps it has improved since we last used it, so take this with a grain of salt. 
I have no idea why anyone would even remotely consider this when deciding what language to use for some task, nor do I have any idea why you would think this has any impact whatsoever on the license any other project will use. That's not how anyone picks languages or licenses. I'm not sure why you'd even think this would damage anything. Who do you think is picking Go because they believe it will... force them to use open source licenses irrevocably? I can't wrap my head around anything you're laying down here. Docker isn't that important to Go anymore, if it ever was. Plenty more "real users" now.
I've learned an awful lot from GO IN ACTION by William Kennedy with Brian Ketelson and Erik St. Martin. (Manning Publications) I bought it online before seeing a post by the author that you might be able to have it for free. Enjoy! Also the free docs at golang.org are excellent. 
would you rate it as an intermediate, advanced or beginner book
what migration? the docker ce version is still there, you won't have to do anything 
Thanks for the advice, I plan to do something similar, and I've already implemented the interface and memoryitemstore and sqlitemstore!
how is this relevant? 
There shouldn't be any issue getting content concurrently from a BoltDB... sounds like you might have been using the View / Update funcs incorrectly? Or were you managing the transactions manually? Read-only transactions are super fast and thread safe. Writes are a bit slow and are atomic (though don't interfere with reads), compared to other disk backed in mem datastores. but if you manage them with some care and batch when possible even they can be tuned to be very fast. 
This will be amazing once it's finished, although Windows support is imperative as well imo.
Of course. That's why Scala ranks below Go, since it's even less confusing, right? People don't post on SO just because they're confused. It's correlated with popularity. Plus too, Go has plenty of warts of its own that can be confusing.
I think this headline is wrong. From the site: &gt; Package sqlite is an in-process implementation of a self-contained, serverless, zero-configuration, transactional SQL database engine. (Work In Progress) So it is DB server not DB driver.
Okay. Is it something like in memory database like hsqldb? I have used that with Java. It was loaded in same JVM process as application. I would run queries and put results in file /console etc.
Iiiiinteresting.
A web service for generating Go source defining a struct based on YAML input and too much guessing.
The D&amp;K bible at http://gopl.io/ is really great but does assume familiarity with instructing computers.. you might still gain a lot from it.
SQLite data can be held in memory, but typically it uses files. I would suggest reading instead of asking about it on Reddit: https://www.sqlite.org/
With sqlite its both simultaneously.
Yeah I mean the lack of cgo makes it nice so that it isn't cstdlib dependant but cross platform is what really sells it.
No need for such an attitude specially when you don't understand the point op has made. The title is in fact wrong, it is not a driver, it is an SQLite implemention, the whole Engine, not merely an interface hook to sql package, it just happens to expose the API through the sql package. 
Misleading title. Should say "written in Go".
The title is not wrong. This is a driver (as in `database/sql` driver) for sqlite. It's clear from [the documentation](https://godoc.org/github.com/cznic/sqlite).
Awesome! Gorgonia is on my "I just have to look into that some day" list since some time. I feel that this and the upcoming articles will give a smooth entry into the DL realm.
I think you are partially wrong here I looked and it does seem to rely on SQLite.. but in a very.. ugh, different way. Lol. I think he actually compiles the SQLite source code in a custom compiler to an IR. Then loads the IR into a virtual machine he wrote in Go.
This is insanity. I stand corrected, but it is still not a driver though :P
&gt; This is insanity. This. Is. Golanggggggggggg! ... and a Driver, how he got their doesn't matter dude, he crossed the finish line! In style if you ask me hehe..
Try Go Programming Blueprints (second edition) -- excellent book, written as couple very long tutorials that guide you through the development of typical things where Go is used (webapp with websockets, CLI app, using AppEngine among others).
Why too much guessing?
It was a great read. Thanks!
&gt; Software going closed-source pay-to-use all of a sudden is exactly the kind of crap that happened in the "Java community" which makes people hate java so much, its not Java they hate, its Java EE and the cloud of proprietary crap that floats around it. Not only that but Java has this EE mentality aka pay thousands of dollars in training to become certified that you know how to use a certain framework. Then you do not write Java anymore. You write that framework and you need other people that know that framework. And of course in order to use some niche/advanced feature of the framework, your company has to pay. Smells like docker CE/EE already. Go on the other hand has a strong standard library which makes frameworks unnecessary and makes collaboration and maintenance easier. Unfortunately where there's success and money involved such things will keep happening. You already see frameworks getting "pushed" to the community and now we got the moby dick move. It's kinda sad to realize but it seems that Go's "golden era" is slowly coming to an end. It has happened to Java and most other successful languages so it shouldn't be so surprising. But personally I love Go so much that it hurts to see this happening.
Why are you conflating Go and Docker ? Go itself is not changing and this move by Docker will have no impact on Go si I'm not sure how you can say Go "golden era" is ending. If anything it's the reverse 
there are some in github... https://github.com/search?o=desc&amp;q=ransomware+language%3Ago&amp;s=stars&amp;type=Repositories&amp;utf8=%E2%9C%93
&gt; Why are you conflating Go and Docker I am not, that's why I quoted that specific part of PedanticGeorge's text that talks about Java EE. It's just that the moby dick move gives the opportunity to open this 'meta discussion' if you will. &gt; I'm not sure how you can say Go "golden era" is ending If anything it's the reverse I suppose the term "golden era" is relative. For me seeing Go slowly following the footsteps of Java in terms of community and tooling is a nightmare because that's exactly what I am trying to escape from. But for others maybe that's exactly what they want. People want different things. Go figure. ¯\\\_(ツ)\_/¯
¯\\\_(ツ)\_/¯
Thanks that one indeed looks better. :D
Did docker ever contribute libraries that anyone used in their own code? (Is anyone importing something in `github.com/docker/...`?) I think this will have no impact whatsoever. There are plenty of other companies out there contributing code written in Go that you can actually use for your own programs. For example: Uber: https://github.com/uber-go Facebook: https://github.com/facebookgo Google (of course): https://github.com/google?utf8=%E2%9C%93&amp;q=&amp;type=&amp;language=go Dropbox: https://github.com/dropbox/godropbox Shopify: https://github.com/Shopify Vividcortex: https://github.com/VividCortex?utf8=%E2%9C%93&amp;q=&amp;type=&amp;language=go (I use their stuff all the time) I could keep going... and honestly, most of the most popular packages in Go are written by individuals. The Go ecosystem is quite healthy. These days you can find open-source packages for almost anything. 
I agree with you, but FWIW, cznic is doing a lot of amazing work and this actually puts a lot of context unto the things they've been doing for the last year or so. I've seen all the C-compiler frontend stuff previously, as I was interested in parsing C for a project. It seems, the end goal was to write a C compiler for a virtual machine. Unleashing it on sqlite is merely a tech-demo, if you will :)
&gt; Docker having a EE version is not the same as if we had some sort of Go EE. True. &gt; Well I don't want to have a J2EE equivalent for Go either, but I don't see that happening. J2EE is more than just tooling. It is also a school of thought, and attitude from the community. Those things do not happen overnight obviously but you can already see some signs. It is a combination of many things happening at the same time right now in the Go community. But let's not get into specifics because this will end up becoming doom-talk. The Go veterans should focus on preserving Go's school of programming and prevent any of the above from happening. That's the important part.
http://importgolang.com/books/ for a listing of books.
I don't think you understand the original post. The popularity is a poll about which languages the polltakers use at their job. Not volume of questions asked on SO. Why even talk about simplicity here? It's not relevant and would not impact the poll results. Further, correlating dependent datasets (the users of go and the volume of questions about go) is not a bad thing. Don't just repeat reddit's favorite empty counterargument without understanding it. 
D'oh! That's what I get for sprinting for too long.
Hey everyone - I just wanted to post this here to re-emphasize that Caddy is staying free to use and open source, no change from the Apache 2.0 license, despite some temptations to do otherwise. The Go community is great -- one of the best I've ever been a part of -- and the last thing we wanted to do was fragment Caddy's developers and user base. This is really a nod to you. Thanks for teaching me so much, and for helping to make Caddy a fun project to work on!
hey sdboyer quick question. I know this is bikeshedding but I was wondering if there is any strong reason for the files Gopkg staring with capital letter. The way I see it, lower case is always better for file names (less headaches when dealing with windows).
I suspect it would have been less work to just go through the sqlite source line by line and manually translate to Go. At least the main source without tests anyway. 
I would do it that way if SQLite is the only C code I like to have translated to Go.
I'm liking the new website look. You got rid of the empty "Serve the web like it is INSERT_CURRENT_YEAR" text and have a much more focused design. There's a clear outline of what to do after downloading Caddy and it shows off how nice Caddy files are to configure. I just have one problem with it, you never say what this HTTPS thing is or why anyone should care and yet HTTPS is prominently stated twice at the top of the page. You and I know, but you are targeting a wider (less technical) audience. Please consider adding a small bit about how people will benefit from HTTPS.
Seems not to work with vendor/ directory. It tries to resolve my imports only in $GOPATH. :/
The two sites have completely different target demographics. Startups use lots of Go, enterprise companies not so much.
Thanks for the feedback! I assume that people who find Caddy already know what HTTPS is (or know that it means security or privacy) -- but I will consider that for when I work on the homepage again; it probably deserves a place below the intro.
Looks interesting. Can you at least add enough documentation to describe how to configure it for one's account, etc?
This looks useful. Recently I had to implement an ACL system and it turned out to be way more work than I expected.
I can't use a type switch because T is not known by foo and the helper returns `[]interface{}`. Besides the problem is not how to distinguish between slice and and struct. That is taken care off. The problem is how to fill `v` with data in case `v` is a slice. In other words I am trying to figure out how to do the `v = s` part of the code.
The goal is to fill `v` with data when it is passed as an argument in foo. Returning aka `v := foo()` or `v := helper()` is not allowed.
I do not know the type of `t`, that's why I named the type `T`. Sorry for the confusion. &gt; What is the purpose of foo()? The purpose of foo is to fill `v` with data in the same exact way for both cases. Imagine there are two data providers which I cannot change. `helperOne(v interface{})` `helperSlice() []interface{}` So the purpose of foo is to allow to use those two functions inside it seamlessly as I described above.
I liked [The Little Go Book](http://openmymind.net/The-Little-Go-Book/) It's probably an intermediate book, but a great introduction to the language.
&gt;To continue reading this article register now Nope.
I have added some documentation to the README. Hopefully it'll be easier to see how to get started and it will show what kind of things can be done with madonctl (or with the library).
Because a single sample input cannot express fully what Go type is appropriate.
Neat.. I had built something like that that used github.com/fedesog/webdriver. Not as advanced but only 150 lines. Managing chromedriver is a PITA though. Hopefully the new headless features in chrome will make things like this easier.
Companies that use go https://github.com/golang/go/wiki/GoUsers
You lost me at the R200, having a different function for a status code does not seem smooth.
&gt; Appending to a copy of a slice doesn't change the original slice. Ok and how can I modify the original `v` slice then?
At first I used WebEngine, but was not satisfied with many things, and my goal was to have one static binary (this one is semi static), only possible with new WebKit https://github.com/annulen/webkit .
hmm, could you please tell me which part you found complicated. Is it, how to use and setup a webapp or the code itself?
The dedicated functions for some of the status codes, I added them because I found it extremely convenient to use compared to specifying the status code every time. I built this framework when I was building a webapp, and I found this extremely useful (dedicated functions for frequently used responses). Thank you for the feedback, I'll re-consider those.
&gt;It seems as there isn't a way to stop processing a request in a middleware I made the signature of middlewares and handlers the same (so no returning `error` from middleware). The only way to stop execution of a chain is to write a response, because my teensy brain could not think of a scenario where you had to stop executing the chain but not send any response. &gt;Also, doesn't seem to support a pre and post request modification. Each route has a field `FallThroughPostResponse`, which if set to true, will continue executing the chain even after writing a response. But thank you for the heads-up, it's not documented nor used in the sample app. P.S: Thanks a lot for the feedback, really appreciate it.
It makes less sense to measure the advantages to an engineering problem and take on additional infrastructure by default? How could serving a few static files that rarely change from the binary be better than requiring a Nginx server. More net flows, file system boundaries, you are adding more failure points to monitor and maintain. Point is, measure, do what makes sense. Patterns that work against you surface early and it's much easier to add new technology than it is to turn it off. 
how?
"go getter"
https://github.com/jteeuwen/go-bindata is simple and popular (edit: but apparently no longer maintained) https://github.com/GeertJohan/go.rice has fancier features There are several other options 
[removed]
Haha, what is this "ready to use it in anger" bit?
I do. Primarily to have convenient binaries that are fully self-contained, easy to ship and run. I've created and use `vfsgen` for this: https://github.com/shurcooL/vfsgen It creates an implementation of `http.FileSystem` for you, which is compatible with `http.FileServer` and many other things. It's very general. Also see [alternatives section in README](https://github.com/shurcooL/vfsgen#alternatives), I've tried to list all known similar projects.
$ go get github.com/ponzu-cms/ponzu error : package github.com/ponzu-cms/ponzu: no buildable Go source files in /Users/xxx/go/src/github.com/ponzu-cms/ponzu 
Very excited by the MiTM feature!
Ah, I like it. The point is clear and hilariously aggressive. 
PUT or PATCH, it doesn't really matter. It just the method. You have to think up a logic to handle. Imagine a struct which holds your data model, for a userprofile or a single todo. You have some fields and an id for each row in your DB. You may require the whole fieldset for one item, then you dont have to do anything: Update all the fields where the id matches. Or you may want just the id of the item, and the field what you want to modify. Now there is two road you can take. Implement a modify for each field(you can write a smart func for that which does that) or get the data for that id, change that data which was modified and overwrite every field like in the first method I could think of. If you want to do it really neat, that would require some time.
I mean, technically there are differences between PUT and PATCH. With a PUT you're sending the whole object back, and a PATCH is for amending specific fields in a specific object. 
GitHub should redirect paths; this can cause problems/confusion down the line of course, but nothing should break *right now*.
To be fair, the OP didn't give any indication at all of how many assets he was talking about. But "vastly faster access" and "lower latency" is frankly stupid when you're talking about access over the network. Round-trip is already high enough, plus page render time. Unless you're trying to game the number of requests per second you can hit, the loss of metrics (because your application probably isn't logging successful/failed requests, and if it is, it's definitely not in a format that can be consumed with zero effort by graphite, plus then you're touching the disk anyway). Plus, you are then relying on go stdlib to do the right thing with a complete clusterfuck (web browsers). It wasn't long ago that there were 3 major issues with net/http's implementation of http pipelining. A problem web servers don't have
&gt;But "vastly faster access" and "lower latency" is frankly stupid when you're talking about access over the network. Round-trip is already high enough, plus page render time. Network latency can be as low as 0.100ms for a local intranet site, a harddisk may achieve average latency of around 2ms when you're not hitting it's caches. &gt;Round-trip is already high enough Depends on the network. &gt; plus page render time The page render time is of no concern to this, if the server can finish the request sooner rather than waiting for the disk, we can close the network stream sooner and handle another connection. &gt;Plus, you are then relying on go stdlib to do the right thing with a complete clusterfuck You're relying on stdlib to pipe a bytestream over network with minimal headers if you're using ServeContent. &gt;A problem web servers don't have Nginx or Apache will introduce an array of dependencies, memory usage and disk IO usage that you simply don't have by hitting only files in memory. Unless you're website exceeds 20MB in assets, which it honestly shouldn't for any reason IMO, you will probably not see any reduction in memory pressure compared to backing in the assets to the binary. &gt;It wasn't long ago that there were 3 major issues with net/http's implementation of http pipelining. That is relevant how?
&gt; Network latency can be as low as 0.100ms for a local intranet site, a harddisk may achieve average latency of around 2ms when you're not hitting it's caches. Again, caching in webservers is a solved problem. The first user may hit 2ms per file (though it's extremely unlikely). Subsequent users will be served straight from cache. &gt; Depends on the network. It does, but that's not relevant. 'Network access is the slowest part of the stack' has been accepted wisdom for over a decade. &gt; The page render time is of no concern to this, if the server can finish the request sooner rather than waiting for the disk, we can close the network stream sooner and handle another connection. If were's talking about turnaround and visibility to users, it is of concern to this. Page render time is gonna be longer than 2ms. Is going from 2ms to .1ms a worthwhile tradeoff versus configuring the asset caching without modifying/redeploying a binary, lack of standardized logs, etc when that 1.9ms is less than a blip to the end user? &gt; You're relying on stdlib to pipe a bytestream over network with minimal headers if you're using ServeContent. I meant stdlib handling pipelining properly with a mess of browsers. [For example](https://github.com/golang/go/issues/10876). 'Is your old, corporate-mandated browser buggy and slow? Let's show a message, and pipelining won't work'. &gt; Nginx or Apache will introduce an array of dependencies, memory usage and disk IO usage that you simply don't have by hitting only files in memory. &gt; Unless you're website exceeds 20MB in assets, which it honestly shouldn't for any reason IMO, you will probably not see any reduction in memory pressure compared to backing in the assets to the binary. He's talking about packaging JPGs. Adding nginx as a separate docker container basically adds nothing to depdendencies given that he's already talking about docker. The memory usage is trivial, dependencies don't matter (docker), and the disk i/o is primarily logging, which you'd want. It also makes it easier to scale it out later. &gt; That is relevant how? Because pipelining is substantially faster than 1 request per file.
No pls
But as static CSS/JS should be compressed, you have 3 times (plain, gzip, brotli) versions of the same file? 
 So you run static assets through uglify, but then don't run them through gzip or brotli? And then use something like ngx_brotli static module to save nginx having to compress on demand. 
Honestly, I run everything through webpack with plugins to handle compression, then let nginx serve it and figure it out and serve (either gzipped files which are deflated on the fly if needed or straight gzip) Since brotli isn't in the packaged version of nginx, I don't use it, but the product I work on is much more invested in horizontal scalability across kubernetes than strictly "maximum throughput from a single nginx instance"
Plug for https://github.com/carlmjohnson/monterey-jack here. 
Why not just use webpack or gulp? No reason to use a weird stack
Depends on the scenario. I agree that serious web dev nowadays will require webpack, babel, React/whatever, Sass, etc., so you may as well just handle stuff there, but for a simple project you might not need all that stuff or want to figure out how to configure it.
Its not clear where you got stuck. Are you trying to solve this problem generically in Go? Go does not support generic programming directly. Common alternatives include code generation and runtime reflection. Not every problem lends itself well to generic programming either. It may be that the best solution is to write code specific to every resource you will handle.
Yes, you're looking at [(Time) After](https://golang.org/pkg/time/#Time.After) time.After is in [sleep.go](https://golang.org/src/time/sleep.go?s=4766:4800#L140) You can click on the function name in the docs to go to the source. 
I'm having a hard time understanding the need of this library. IIRC, the go runtime will zero out memory before releasing it to the OS.
If you want to protect sensitive data in swap you should encrypt it. OpenBSD for example, encrypts the swap per default. Linux also has the ablility to do so.
thanks! I wasn't even aware you could click on function names! they really need to make it look like a link or something
Everything that's blue is a link.
Your solution is ugly and disgusting because you are setting a difficult task for yourself, not wanting dependencies. If your target machine had Cygwin and OpenSSH and rsync on it, you'd be set. But it doesn't and you are doing a service to the next guy to come behind you by keeping all the mess in one place that cleans up after itself, so I say go for it. (Just make sure that the docs explain WHY it is ugly and messy, so that the next guy appreciates it and doesn't tear it all out and make it depend on stuff you have a legit need to not depend on.) -jeff
Amazing! You are a true reflection-dark-arts-voodoo master! :D Thanks a lot!
Agreed. From what I've heard most people agree that it should be one of the first features to be removed from the language. Personally I do not mind it too much and what I'd much rather get is a way to do this: `return _, err` instead of `return struct{}, err` In other words `_` should return the zero value of a type.
Here here. Named returns I find quite unreadable and inconsistent. Can anyone give a scenario in which named returns are "better"? Edit: found some decent reasons on [stackoverflow](http://stackoverflow.com/questions/15089726/why-should-return-parameters-be-named) &gt; There are some benefits to naming them: &gt; It serves as documentation. They are auto-declared and initialized to the zero values. If you have multiple return sites, you don't need to change them all if you change the function's return values since it will just say "return". 
Go passes everything by value - however a slice is a struct with a pointer to an array, a length and capacity. When you pass a slice into a function, you pass in the struct with those three things. When you pass in a pointer to a slice, you pass in a pointer to the struct of those three things. So what you want to do is copy the data from the underlying array, to a new array. Use the built-in function, copy. A quick Google search came up with [this](https://blog.golang.org/go-slices-usage-and-internals) which should help you with all the details.
I get those "benefits" but don't agree they're net-helpful. There's always a struggle between convenience and simplicity...
I'd make that trade any day!
For better or worse, golang tends to lean on readability over type complexity. If you give it some time and allow yourself to "let go" of your current way of doing things, it turns out to really not be that big of a deal. &gt; I'd like to make this function inherently thread safe If it mutates the data in a way that is visible outside of the function, don't call the function with the same argument from more than one thread. I know this might not be the answer you're looking for, but in my experience, it tends to not be an issue once you start designing your program in idiomatic golang. If it ends up not being acceptable to you, just use a different language. Edit: I should mention that a nice trick for declaring read-only functions is to use interfaces which only have getter methods for the argument types.
The short answer is, it isn't smart. You can have exactly the same kind of shared-memory errors in Go as you will have in Java/C++. This is why they have a race detector tool. Note that C++ const is fairly useless. It is pointless (heh) to have a const pointer that is aliasable. Also, constness in C++ is not transitive, [which is useless](https://bartoszmilewski.com/2009/01/26/the-more-things-change-the-more-we-need-immutable/). A const object should not be able to point to a mutable object. Only Rust and D provide deep const. btw, slices are already references. You don't need pointers to slices. Goroutines are the useful part of Go's concurrency story; they allow you to structure concurrent code differently, as zillions of communicating state machines, rather than having to agonise about holding up a thread and having to return to the event loop or some artificial constraint like that. Safety is not part of Go's concurrency story.
To "guarantee" no mutation occurs on the "list of values", simply wrap the slice in some container type that has a read only interface. Golang is about types, trying to squeeze functionality out of built-ins is a trap; antithetical to the language's design. Create a new type with the behaviour you want. :) 
Citation needed, I don't think this is guaranteed. Certainly not if it's killed or the system crashes though.
&gt; btw, slices are already references. You don't need pointers to slices. Ahm, no, no they are not. Its actually this kind of shitposting that got me confused in the first place. Slices are just normal values that can be passed by value or by reference/pointer. Passing a slice by pointer gives access to the same underlying memory structure tot he recipients whilst passing it by value simply offers a copy to the recipient. Unless you would care to explain this statement, I'd call you a perpetrator of missinformation
How often do you really need to write anything other than 200 though? Even if you do it's only a single line to set it...
&gt;passing it by value simply offers a copy to the recipient It still shares the same underlying array. What is copied is only a pointer to this array, and the length of the slice. https://play.golang.org/p/mgEBjfPxMo 
We heard you liked languages. So we put languages in your languages :)
The only statement on the project is this goal: "I want to build a language that focuses on developing microservices. Which should be performant and easy to write. This is why rooby has Ruby's user friendly syntax and is written in Go." There are lots of languages that do microservices (Go itself does), Ruby is already syntax friendly and performs fairly well, as does Go. It doesn't address why this should exist. Maybe crappy comments are just your thing, but if someone makes a new language, people are going to ask why you're doing this and what it does that something else doesn't currently do. 
This func f(s []string) {} is equivalent to func f(ptr *string, len, cap int) {} or type stringSlice { ptr *string // points to an element within an array of strings len, cap int } func f(s stringSlice) {} 
Thanks for the feedback! I opened a github [issue](https://github.com/b3ntly/distributed-token-bucket/issues/2) to explain my thoughts to others who may have the same suggestion as I think it's a good one. Copy pasted here: I received a suggestion on Reddit that this library should support multiple Redis libraries by abstracting various methods like .Get and .Set to a common interface. I definitely agree with this, in fact (though it predates my initial commit) the original implementation used an interface called Storage to do exactly that, though it was intended to abstract the database system itself (to support memcached and Redis) and not just Redis client libraries. The API looked like this: storage, err := NewStorage(options interface{}) bucket, err := NewBucket(name string, capacity int, storage *Storage) However I pulled back for the initial release for a few reasons: * The library currently had 0 users and I wanted to keep the surface area small so I could focus on core features * The library currently uses the lock-less approach of lua scripting to maintain thread safety thus any other redis library would preferably support Lua scripting and any other database system would likely need a fair bit of custom logic to maintain feature parity and quality. * I think theirs some turmoil in Go where newcomers struggle to choose the "best" third-party library for a given task. I think many of the redis libraries do have feature parity but in my opinion Go-redis (a.k.a. gopkg.in/redis.v6) has been the best maintained and implemented redis library for Golang for the past few years. So in short yes I will be implementing an interface that will support this but not in the next few weeks for the reasons stated above. First priority of the "Storage" interface will be supporting an in-memory version of the token bucket, then support for memcached (because that would allow Google App Engine users to implement a token bucket with GAE's mostly free managed memcached service which is cool), and finally for Redis client libraries. As always thanks for the feedback and let me know if their are any more questions on the topic. 
Yah, passing a pointer to something is passing by reference. Slices in go are inherently references though so you don't pass a pointer to a slice, you just pass the slice and it's like you passed a reference to it.
&gt; Ahm, no, no they are not. &gt; Its actually this kind of shitposting that got me confused in the first &gt; place. Slices are just normal values that can be passed by value or &gt; by reference/pointer. Passing a slice by pointer gives access to the &gt; same underlying memory structure tot he recipients whilst passing &gt; it by value simply offers a copy to the recipient. &gt; Unless you would care to explain this statement, I'd call you a perpetrator of missinformation Easy there. It is just as in C/C++; everything is passed in by value, whether it is a pointer, a pointer to a pointer, or a struct. Just as in C/C++, there is a semantic difference between a pointer and pointer-to-a-pointer. A slice is a pointer already (to an underlying array, plus with the offset and count), so you will get race conditions simply by sharing a slice between two goroutines. You don't _have_ to pass a pointer to a slice for efficiency or for showing race conditions. 
And who says an internal part of the service is going to correctly run if the service crashes?
Agreed, using named return values for documentation is fine. Naked return statements, however, are only misleading and should be avoided. What I mean is: func f() (min int, max int, err error) { // name the return values // lots of code return min, max err // always list the return values, never use a naked return } Best of both worlds.
https://mholt.github.io/json-to-go/
I see that author read: Writing an interpreter in Go. :) That book is worth of every penny!
Oh sorry, thought you were just referring to plain-old json.
&gt; But still useful to load a jsonschema file in the first place, such as I might have to Not so, on 2nd glance :D
~~Is it just the "$" in "$schema" that it doesn't like? (when I removed that it was able to load the schema)~~ Seemed to load it fine even with the $ on a second try, must have had something else wrong. I understand that still isn't what you want though. I think there's a lot more users of json than json schema which is probably why its trickier to find an existing lib.
Quick google / godoc search shows a few: https://godoc.org/?q=jsonschema https://www.google.com/#q=jsonschema+golang Top results: https://github.com/xeipuuv/gojsonschema https://github.com/alecthomas/jsonschema 
The first one already doesn't generate **structs** from schema, though it can load structs into a schema. Not what I need though. The second one I found before too: "Generate JSON Schemas from Go types" Have I mispelled my post title somehow?!
I recall having this conversation with you before, talking about dependency injection frameworks. The method of using flags for each dimension of configuration, constructing objects in func main, and then passing them explicitly to components that need them as dependencies doesn't break down when you reach some number of dependencies. It continues to work fine for even the fattest of apps. func main() { var ( dataDSN = flag.String("data-dsn", "", "DSN for data DB (rw)") adminDSN = flag.String("admin-dsn", "", "DSN for admin DB (ro)") // ... ) flag.Parse() dataDB, err := sql.Open("mysql", *dataDSN) if err != nil { // ... } adminDB, err := sql.Open("mysql", *adminDSN) if err != nil { // ... } // ... databases, err := listDatabases(adminDB) if err != nil { // ... } // ... } No need for frameworks or abstractions to confuse future readers in order to save you some typing. No need for a dependency injection package or an object factory to hide deps in a magic black box. Definitely don't put them into a context object — _every_ tutorial or blog post on context tells you never to use it in this way.
Ah okay that helps me understand better what you're actually trying to achieve. So what you actually want is to create Go structs that are for json that matches the json schema, not for the schema itself. You may want to clarify your post to explain as such, I thought you wanted to parse the schema, not json messages which match the schema.
You can easily understand slice if you know that a slice is just a structure containg a pointer to some memory, a length and a capacity. Passing a slice makes a copy of that structure, but the pointer still refers to the same chunk of memory.
Thanks. I still think a pointer is a reference but it's good to be explicit to avoid confusion.
2, 2, 2, 2, only 2. Please God only 2. Please make main() your outermost shell of your application. Main() responsibility is to pull as much information from the environment to bootstrap the running program into working correctly. This means both physically pulling information from the environment (e.g. Reading binary flags, reading a configuration file, reading ENV variables) and also configuring the various subsystems and plugging them into each other, to make sure it will work when run. And *then* it **tells** the fully configured and initialized program to run. That means all of the rest of your code can be assumed to be configured correctly. It means the rest of your program can use the power of the type system. 
&gt; But if you call Open once, the logical conclusion is that it will only make one connection, and additional connections will be made only on additional calls to Open (and released on Close, ie, returned to the pool). tl;dr: no, not at all. But dig in: [func database/sql.Open](https://github.com/golang/go/blob/d40bb738ff59bada723fe5f834d41531391b532a/src/database/sql/sql.go#L568) launches the [connectionOpener goroutine](https://github.com/golang/go/blob/d40bb738ff59bada723fe5f834d41531391b532a/src/database/sql/sql.go#L582), which [opens a new connection](https://github.com/golang/go/blob/d40bb738ff59bada723fe5f834d41531391b532a/src/database/sql/sql.go#L838) by delegating to the [underlying driver.Open function](https://github.com/golang/go/blob/d40bb738ff59bada723fe5f834d41531391b532a/src/database/sql/sql.go#L847) as necessary. The driver performs the mechanics of opening and closing connections on request; the database/sql.DB maintains the pool.
Well, it's not actually named returns, but *naked* returns. Named returns could in theory make sense, but *naked* returns make things a million times worse. Not the only bad feature either, though. Go has a few nasty warts, but that's in a world where most languages have thousands.
While this is a cool idea for convenience, it's a terrible idea for the ecosystem IMO. Blurring the lines between the official go tools that come with the language and 3rd party tools like goimports or go-metalinter just adds confusion to new gophers for nearly zero benefit.
I know that Go's benchmark is much more accurate and gives better insights. Though, I'm just trying to learn along while building these simple ~~libraries~~ packages. 
Passing a pointer and passing by reference is the same thing. Don't get caught up arguing over semantics
Agreed, there's a lot to be said for not reinventing the wheel, but context is key. If no one every reinvented the wheel or attempted to invent new wheels, we'd still be writing code on punch cards. If you're a manager, it's easy to make the case for never (or usually not) reinventing the wheel. But if you're a developer, there are many excellent reasons for doing so, among them: 1. It's an educational/learning experience. 2. You build exactly the wheel you want/need. 3. You fail to build the wheel you want and end up appreciating the existing wheel(s) more than you did before.
.Article is a struct, not a list or a map. You can't range over it. Instead of just one Article containing a list of titles and texts, you should make a list of Articles where each one contains only the title and text for a single article. You can range over that list of Articles. 
&gt; However I pulled back for the initial release for a few reasons All very good reasons :) &gt; any other redis library would preferably support Lua scripting I'm a heavy user of Lua scripting in Redis, and I've been happy with [redigo](https://godoc.org/github.com/garyburd/redigo/redis). &gt; any other database system would likely need a fair bit of custom logic Yes, of course. Though it shouldn't be too hard with e.g SQL transactions. &gt; First priority of the "Storage" interface will be supporting an in-memory version of the token bucket, then support for memcached Sounds great, looking forward to it!
Can you please give me a working example of the template syntax in this context?
hmm this might be a bad practice, but I usually send back errors from handlers directly, and not have an error responder like you're suggesting. Though obviously a custom error message and not the actual error generated by the app. P.S: I keep a set of errors created in a central package, and pick one out of those while responding. 
https://play.golang.org/p/5Z2moskNGE
If everyone followed your way of thinking, we'd still be programming in punch cards. Creating a new language is not a simple task and demands a lot of effort, and even if this doesn't turn out to be next hot language, I'm sure the author learned something while developing it.
Edit: I created a short test to verify, you are correct! Of course, as I said, it's just one of the possible clients that keep a long running connection which can't be shared in that way. Redigo/redis is definitely one of those where requests will be pipelined on a single connection. For those a connection pool needs to be created and we can't just pass it along directly without some impact on performance/ops. ~~I'll trust you on your word, however it deserves some verification, not because you might be wrong, but because sqlx is just one of the possible clients that might keep an open connection and manage a connection pool transparently.~~ If you'd create a new kind of client (websocket or something else that's keep-alive), you might need to create a pool of those connections or move this logic individual app functions. Again, totally valid for sql, but ~~might~~ not ~~be~~ with redigo, websocket, etc. where you're dealing with a single connection. Thank you.
tl;dr: upvoted; There's where the distinction between a microservice and a "fat" app would come in. I agree with you but I still need some pattern that would introduce as little friction/verbosity as possible ;) There's a lot of bad practice going around, including defining flags (with flag stdlib) inside init functions for submodules. Singletons are definitely something I'd like to avoid. And it's usually not a trade-off with using the power of the type system, just how to *elegantly* do this without increasing verbosity :)
You do you man. The go language itself lets you do just about anything on your own box (as it should), but the community is very resistant to anything that could potentially complexify the wider ecosystem. You're 100% right about that.
This is quite nice, actually. The status codes are not that bad. As for some comments, be cool if you added something like gores (https://github.com/alioygur/gores) has with HTML / JSON / XML etc reposes. Might fork this and build / modify on top of it. Good job mate!
Err, no. You would be programming in C/C++/perl/python/java/golang. Probably not ruby because of the silly names of all the modules, the silly use of do..end when the language has perfectly good braces, the silly :symbol thing which even Matz wants to get rid of, and the general ugliness of what ruby programmers call idiomatic code.
I agree! All too often I hear: Why should we use https? Our site is only about xy, nothing sensitive. Even if you agree with this statement: Many people forget that it is not only about user privacy, but also to make sure, shady hotspot providers or any other entity between you and your users do not inject ads or worse into your site.
Best of luck!!! Purely as a learning exercise I've been trying to port the Python [schema](https://github.com/keleshev/schema) to go. A nightmare is the best way of describing it. Not that either of the languages are better than each other, it is simply that they are different, with the contrast between dynamic and static typing standing out a mile.
&gt; Go with powershell, learn it, love it. Seriosly. I second this, use the right tool for the job. For more details: [Calling WNetAddConnection2 from PowerShell](http://stackoverflow.com/questions/1477328/calling-wnetaddconnection2-from-powershell) 
What's the problem with increasing verbosity? What makes you think it's going to increase verbosity? Where's the friction? And yeah, no defining things in init functions, period.
This doesn't answer your question but it's related, so you might be interested. I've been working on a tool that: 1) Consumes type descriptions in a json format (similar to json schema). 2) Generates Go structs. 3) Generates a custom json unmarshaler. 4) Importantly, the unmarshaler supports unmarshaling objects of different types into an interface. This is the secret sauce that makes it really useful. 5) Validates json data using extensible validation rules described in the type definitions. 6) Presents an extensible web UI for editing the data, using validation rules. It's rather a mess at the moment. I stopped work on it a few months ago to concentrate on splitting out and releasing some of the tooling I developed for it (see [github.com/dave/jennifer](https://github.com/dave/jennifer) and [github.com/dave/courtney](https://github.com/dave/courtney)). However, soon I'm going to embark on the start of a big refactor to streamline and get it somewhat ready for public release. Feel free to have a poke: http://frizz.io/ 
That code-gen looks quite neat! Would totally switch out my various codegen-ing `string`-`Buffer`s scattered throughout my GOPATH for it.. probably will do it next time my brain demands some downtime =)
Do you name your repos by your exes? Guess that solves the "naming problem" in computer science most neatly =)
Cool I went through your readme's features listing and was pleased to notice I implemented everything in my (certainly less 'refined') quick&amp;dirty lib except format=date-time =)
A couple of code quality comments that have nothing to do with the purpose of the repo: * Your files feel "upside down". It's hard to read them when going top to bottom as you reference errors and structs that simply haven't shown up yet. * All of your strings are raw strings. Typically those aren't used unless there's a reason to avoid escaping, i.e. when defining regular expressions or multi-line strings like templates. Otherwise, double quotes. * You have no reason to use `testing.M` (and you haven't followed the documentation's notes about calling `os.Exit`). * You have a number of copy/paste errors in your tests to do with asserting things like type, e.g. erroring out with "not an int" when checking for time.Time. Maybe you would benefit from using something like testify. * `t.Error()` followed by `t.Fail()` followed by `return` is the same as `t.Fatal()`. If you're writing the same couple lines out over and over, there's probably a better way to do it. * You build `Data` structs in your tests by creating them and then setting their members, instead of just specifying them on creation. * Your tests are split up into different blocks, which could instead be sub-tests.
ooh, a variant of a CKY parser. package [`lingo`](https://github.com/chewxy/lingo) is missing a CKY parsing - /u/atamiri - wanna contribute?
Those are some really good tips. It's great to see this and hopefully the author takes it onboard. I'd recommend the official coding/style guidelines as well - https://github.com/golang/go/wiki/CodeReviewComments
It's $ go get github.com/ponzu-cms/ponzu/... The '/...' suffix is required to build the internal tool 
That's not a use case..
$ go get github.com/ponzu-cms/ponzu I get the same error
Found some free time today to abstract the Storage interface and add an in-memory option. Feel free to take a look when you get a chance. It should be trivial to add new providers (use redis.go or memory.go as templates) as well as incorporating them to automatic testing (which iterates through providers to test against all of them where applicable). Benchmarks for in-memory are very promising (although it makes me think I did something wrong).
Thank you n1 work 👍👍👍
Again, add the /... to the Github URL as documented. If you can't get that to work, file an issue on Github. The full command to install Ponzu (which is in the readme) is: $ go get github.com/ponzu-cms/ponzu/... Include the "/...", or you will continue to get the error you're seeing. 
I'm going to say that I'm way too entrenched in OO programming languages, and things like composition, inheritance, and some other OOP concepts in fact do help to keep verbosity down. I'm trying to create a good example of the above pattern like a rubiq cube to make it easier to write the application while keeping it idiomatic. Things like codegangsta/inject help a lot along these lines, but with obvious pitfalls. I will consider things like tags to provide me with a more coherent/transparent way to do this, but I feel that it's also an anti-pattern. But having the option to get your database/redis/etc in a lazy way, with 1-2 lines, would help a lot along these lines. I actually consider an object factory/context bad form, because it results in poor documentation, while codegangsta/inject especially with Invoke func, puts your requirements for these service objects straight into the function definition. Interfaces are a great way to provide uniform invocation of functions which match a declared signature, but when you have functions with an arbitrary count of services, there's again little way to resolve this. I found [facebookgo/inject](https://godoc.org/github.com/facebookgo/inject) which works somewhat like what I had in mind when I mentioned tags higher up in the comment. With named tags, a specific instance of some object (or a fresh instance, not necessarily a singleton) could be populated inside a struct. This basically cuts down function verbosity for the actual work to about 3 lines total, given the example from the original question. If it's suitable for use or not, that's a different question :)
PUT and PATCH have clearly defined different semantics and use cases so its a little odd to just say that PATCH makes usage more difficult
thanks a lot for the feedback! &gt; cmd/main.go should instead use the Example support of godoc: https://golang.org/pkg/testing/#pkg-examples Sorry but I'm not sure what you intend to show from that link, is it the *commenting*? &gt; libraries do not call println (no production code should, in fact). If you really need your library to log, use the standard library logger. The caller can hook it in order to decide how to collect the logs herself. (There are legitimate arguments that the std lib logger is not good enough, and you should be using a different one. Watch for a consensus to develop and get behind it, please!) On it! &gt; a function called Stop should actually be sure all goroutines are dead before returning. Read this: https://dave.cheney.net/2016/12/22/never-start-a-goroutine-without-knowing-how-it-will-stop I got the same feedback recently from someone, which I defended with some logic of mine. Though, this propping up again makes me think, that I should implement it. Thanks a lot again.
Thanks:) My goal is to help those Golang projects do the tedious work related to authorization in a professional way, so they can focus on their own business logic.
Not if you just use it like that. Only if you plan to use it from multiple goroutines.
Also: let me try to flip the question for you: If you have a helper around sqlx as a package, and this package produces a `*sqlx.DB`, and you want to do something like: db := helper.GetDB() do you feel that it's somehow better or worse than importing sqlx directly in your package and declaring your function as: import "github.com/jmoiron/sqlx" func ListDatabases(db *sqlx.DB) Or would you embed `*sqlx.DB` into a struct that's returned by helper package, so you'd use `*helper.DB` instead? Which way would work best for you? Note: the example is completely fictitious, it just goes to show that a dependency can be declared/retrieved/obtained with type inference which brings down verbosity due to less imports, and packaging common dependencies into a package for reuse (instead of reimplementing them in main always).
I'm not sure exactly what you mean. An interface is a set of methods, and I won't be able to reach a value for db without a function that returns it or resorting to reflection? You did give me an idea of how to use interfaces vs. injection, as I can declare a partial interface for different handlers. Feel free to elaborate your idea if you can, I appreciate it.
Hi, no problem, I can contribute the code. I have some more NLP code which might be useful too. 
nice. Email me - chewxy [at] gmail.com Let's talk
I would not use go-bindata, it's been abandoned for some time now.
I think this is only partially true. If you pass a slice to a function and alter that slice (by setting slice[0] = something) then the underlying array is also modified. That means you don't need to pass a pointer in that case. /u/ChristophBerger demonstrates this behaviour here - https://play.golang.org/p/Gs3KRf47v8
What does it mean?
Code you must show. What you tried to do seems perfectly fine so there probably is a bug in your test code. 
Oh silly me, I changed the folder name to `cmd`. Thanks for the heads-up.
A function with signature "func ParseArgs() ([]string, error)" is not easily testable, because it has external dependencies (on os.Args). Better to make the function "func ParseArgs(in []string]) ([]string, error)" and then call it as ParseArgs(os.Args). (But you should really consider using the flags package for this instead, it is idiomatic Go, your approach is probably not.) Once your function is completely independent of the outside work, use a table-based test to check it's behavior in response to various kinds of inputs. https://github.com/golang/go/wiki/TableDrivenTests -jeff
I upvoted this because he measured and then discarded his work after a careful consideration of the costs and benefits. That, to me, is excellent engineering! -jeff
okay i try at the moment to something like this: []Article = append(Article, {title,text}) but it dint work. so i need a way to create a list with 2 Variables. mabye you can help me by this - sorry im a beginner or mabye you can say me the search tags - because i cant find something useful on google 
Fair enough. Perhaps I should have said it's worst feature. :-)
Not to mention VPNs. Best way would be using GPS module if possible.
solid points :)
It seems the author has just written this in C. Why not attempt a native go implementation ?
Aside from the C comment already made, restore terminal flags in a defer.
Callbacks aren't used much in Go. Just stick a blocking read into a goroutine.
Which is also the easiest, most straight-forward way... Usually you don't even need to wrap it in a go-routine since in most scenario's, your code will probably need to block on input in the current context (which can already be a go-routine).
You could use a channel for this? Create a channel, and then write to that from your goroutine, and have your other main thread or another goroutine 'listen' to that channel. https://gobyexample.com/channels And if you need it to not block: https://gobyexample.com/non-blocking-channel-operations Doesn't have to be non-blocking depending on what you're doing obviously, but that would be closer to the 'Go' way to do it rather than callbacks.
Thanks, all, for the comments and help on this. Looking over the suggestions, it's clear that I have a few things to refactor to separate things a bit more and make it easier to test. I like the idea of flags, /u/jeffrallen and have started moving in that direction. I think rewriting the input using the flag pkg will make a big difference. To /u/sethammons and /u/jerf, that's both for suggestions about testing. My tests were very similarly structured to what you've suggested and I think with some refactoring, things will flow out pretty easily. Appreciate the help, all!
Thanks for such detailed and constructive comment/review! I've applied these practices as much as I could/understood. Though naming tests is cumbersome for me, so I got lazy there. Just one point about Data type, since it embeds some other type, struct value construction literal can not be used except for it's own fields (not embedded ones).
Its funny when a concurrency helping library has data races... Why chan *struct{}, why not just chan struct{} ? The latter uses a constant amount of memory. How do you stop the goroutines? I'll stay with context.Context and golang.org/x/sync/errgroup.Group.
However, bear in mind that you only use the channels if you actually need to move that data between goroutines for some reason. In Go, the standard answer is have a goroutine that simply reads from the socket and "blocks", because if you're coming from Node you need to bear in mind that Node's definition of "blocking" and the rest of the world's do not match in a critical way. In Go, reading from a socket does block that goroutine, but it does _not_ block the runtime, which will happily just schedule another goroutine in and get on with life. In Node, "blocking" is treated as a terrible, terrible sin because a naive blocking read from a socket will block the _entire runtime_. Node's definition of "blocking" is actually a very local one to the Node runtime, not a globally-applicable one. In Go, if you want to read from a thousand sockets, you happily spawn 1000 goroutines, each reading from their own socket, and write straightforward "blocking" (but not blocking the runtime) code. You almost certainly don't need a channel. You also, as /u/koffizet said, probably don't need to spawn a goroutine "just to read". You spawn a goroutine for the task you want to do, like "read a webpage" or "service a socket for a network protocol", and stay blocking within it. The only exception I've encountered is that if you're in a situation where you have a socket where either side might at any time read or write to the socket, you may need to spawn one goroutine for the "reading" duties while other goroutines do the writing. The rule of thumb here is that you should find your code refreshingly easy to write as compared to Node; if you find yourself getting confused about the goroutines you're spawning and where the channels go and why is this deadlocking, etc. etc., you've probably got something overcomplicated there.
`-gcflags "-trimpath $GOPATH/src"` It produces Go binary with all source strings (those are used for panic tracing and debug) stripped from "$GOPATH/src" prefix (although I'm not sure that it does strip everything). It doesn't strip $GOROOT tho. From the doc: &gt; -trimpath prefix Remove prefix from recorded source file paths. https://golang.org/cmd/compile/ `-ldflags '-s -w'` This is how you pass flags to linker. The `-s` is used to omit the symbol table and debug information. The `-w` is used to omit the DWARF symbol table. Both allows you to compact the resulting binary, by dropping "unnecessary but useful" information from it. https://golang.org/cmd/link/ `CGO_ENABLED=0` This is how you disable the build of any included C libraries (last time I checked - Go net package uses this for DNS resolving by default, but can use the internal one) https://golang.org/cmd/cgo/
You can be even more specific, as far as I know. It's only if you plan on reading and writing from multiple goroutines simultaneously. I fairly frequently have a map that I construct in one goroutine, then "freeze", which means it can be read by anybody freely but they can't write to it safely. (Generally a good idea to use private methods here rather than making the map public, to help enforce that.)
&gt; Just one point about Data type, since it embeds some other type, struct value construction literal can not be used except for it's own fields (not embedded ones). That's not true. Any value you don't explicitly define will just be a zero value, including embedded structs and unexported values. https://play.golang.org/p/9YicI1p4JK EDIT: Sorry, I misinterpreted what you meant, but you can set up embeded structs in one go too: https://play.golang.org/p/UIuE3rnb7C Though, it's maybe a tad bit more annoying and maybe not better.
Use rust or crystal, Go 2 probably doesn't happen in this decade
dude do u even program
What do you mean?
That's a bummer. Someone ought to fork it and migrate over the outstanding issues/PRs
It's so abstract that it prevents giving really useful help, and can lead us off the reasonable path. See http://xyproblem.info/
It safely reads in a password from the console.
I generally use pointers for mutation only, but lots of APIs use pointers egregiously. Both seem pretty conventional.
That's not the only point of failure. If you have a dependency which itself depends on Docker and it's not vendored, then fetching with `go get` will bring a second git repo.
You should crosspost this to r/coolgithubprojects
&gt;Slices in go are inherently references to the underlying array, not themselves. So, if you copy a slice, you still have a pointer to the same underlying array. Because of this, there doesn't really seem to be much of an advantage to passing the pointer of a slice, but I believe the difference is still there.
https://godoc.org/golang.org/x/crypto/ssh/terminal#ReadPassword is already pretty reliable for doing this.
I'm not arguing what's good pattern - I, too, would prefer to return a new slice. However, you shouldn't make blanket statements without knowing one's use case. 
Good point. Unrestricted access inevitably invites spammers. On the other hand, established "drop-in" discussion services are not only bloated but also regarded by many as giant Web bugs, so I would love to see projects like this develop into a suitable alternative to those services. It would be great to see at least moderation and/or a mandatory email address (with verification) on the roadmap. Or maybe just a simple measure like disabling links.
Unix has provided environment variables for configuration injection since the beginning. It boggles my mind why developers are continuously trying to reinvent the wheel on this.
&gt; Easy, .Stop sets Pool.block, and Push reads it, without coordination. Run the following with "go test -race" to see it in action: Oh boy, I totally missed the `block`, shame on me. Thank you. &gt; make(chan struct{}, 999999999) uses the same amount of memory as make(chan struct{}, 1) - you cannot say this for make(chan *struct{}, 999999999). You can declare a "const token = struct{}{}", and use it instead of nil. Could you please tell me how this works? `nil` consumes 0 memory, right? What happens let's say, if I insert 10 `token` into a buffered channel, how's the memory handled? P.S: we can't create a `const token = struct{}{}`. &gt;[... and can only be numbers, characters (runes), strings or booleans.](https://golang.org/doc/effective_go.html#constants)
What's the goal of this program? There's probably a lot better way to do things than what you wrote now. I didn't check your program, since you don't say what your goals are, only that you hate it. To make a string out of a float use fmt.Sprintf("%2.5f", blah) or use fmt.Fprintf() to write to a io.Writer. Why float32 instead of float64? Are you using 32bit hardware? The math package works on float64. One last thing, you can replace a lot of fmt.Print() and fmt.Println() with fmt.Printf(). You can replace a lot of it with text/template too. As others have said, learn to walk first and then run. It doesn't look like you have even done the Go tour. This is on the 2nd page of it: https://tour.golang.org/basics/2
You're missing the point of the question, dear.
Thank you for the links. I've also created somewhat of an overview of some common/bad/better approaches as to how to pass around objects in Go, while keeping some functionality like lazy-load for convenience. The example is not too elaborate, I'm just trying to illustrate the impact that different approaches have to verbosity and to development-time overhead when you'd need to add/remove your dependencies and possibly modify your code in several places because of it: [README and examples on GitHub](https://github.com/titpetric/research-projects/tree/master/golang/dependencies). Your example has some pitfalls. You're mixing things like "NewPetHeaven" with "Open" inside the mysql package, which doesn't handle only the MySQL service but also needs to import petheaven for PetService{} and other possible structures. The example on GH above (while much more trivial), does present a single-responsibility approach, or separation of concerns if you prefer. The handlers (under the api package) don't have a need for anything else except the services (in line with 12FA backing-services paradigm), and the services itself don't have any other responsibility or concern apart from providing you with a client/struct that deals with exactly that service, and not some other part of your application logic.
You should probably do the Go Tutorial if you haven't already. There's also a great tutorial on working with slices (variable length arrays) [here](https://blog.golang.org/slices).
Hi, based on a thread a few days ago about passing stuff around, I decided to write up a few examples of some handlers/services and main to glue them together. I used structs, interfaces, object factories, and injection to see what it means in terms of SLOC verbosity and benefits like documentation, lazy loading, refactoring. If you have an example or a way you'd like to add, I'll gladly consider PRs against the repo.
Of course that project is still in very early stage, but two features come to my mind which I consider pretty important to be introduced. One is caching between database and server application and the other one is some kind of database abstraction, so that users could also use a DBMS or even NoSQL.
I didn't know how to help you OP, so I Google'd. Turns out Google and some other companies have massive databases on the physical location of our access points, based on their MAC addresses. I couldn't find a working public database, but I know now that theoretically finding out where someone lives isn't that difficult. What you want is the location of the MAC address of access points/BSSID location. Good luck!
When you make a channel, it allocates a slice for the buffered elements. And a nil needs a pointer worth of memory: a word, 4/8 bytes. A nil is not nothing, but a pointer which does not point anywhere. I could create a const struct{}{}.
Thanks, I hadn't heard of that sub before. https://www.reddit.com/r/coolgithubprojects/comments/67f7mu/commento_an_open_source_lightweight_and/
&gt; Your example has some pitfalls. You're mixing things like "NewPetHeaven" with "Open" inside the mysql package, Not really. It is `mysql.Open` and `mysql.NewPetService` which is completely different. `mysql.NewPetService` provides an implementation for `pethaven.PetService` and it makes sense to be in `mysql` because it is a mysql implementation. If you were writing a Redis implementation for example then it would be `redis.NewPetService`. I am not sure where you see the pitfalls. &gt; which doesn't handle only the MySQL service but also needs to import petheaven for PetService{} and other possible structures. This sounds like you are trying to "force" the organization philosophies of other languages into Go. It makes perfect sense for `pethaven/mysql` to import `pethaven.PetService` because it provides a mysql implementation for that service. I am going to refer you to the [relevant section](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#c0fa) in Ben Johnson's article. You can also see that pattern in the standard library as well. For example `encoding/json` imports `encoding`.
Yes, I've thought about voting. It's not really that hard to implement, but I was wary of the tracking issue. Yours sounds like a good compromise. Thanks!
&gt; It's so abstract that it prevents giving really useful help I already got an [answer](https://www.reddit.com/r/golang/comments/66qwet/could_anyone_help_me_with_some_reflection_voodoo/dgm9t4g/) that works. I am not sure what is the problem. &gt; and can lead us off the reasonable path If you are implying that reflection is not the reasonable path then I would agree in general but in this case there is no other alternative for what I am trying to do (make the API nicer to use).
Someone recently opened an issue to require a captcha before every comment. That might work, but I'm worried about the tracking component - does reCaptcha track its users? Also, captcha might make it less lightweight. Moderation is pretty important, I agree. I'll look into doint that this weekend.
I suppose this depends on how complex your application is, but making a service for each interface, and then just passing those exact interfaces to a handler manually isn't that difficult in a lot of cases too. Maybe that's at least something that could be mentioned in the pros/cons of the ones you've put up there.
Captcha doesn't avoid spam completely either. You would need some kind of moderation controls too. Overall a great project- excited to see where you take it!
Good idea, but this needs CSRF protection and some way of blocking spammers. Otherwise most comments would soon be spam. 
Looks nice. One quick critique, your js puts a whole bunch of things into the global namespace. You should definitely reduce that, and try to just only add a single `Commento` to the window. Also, have you seen isso? One thing I like that they do is give each user a short cookie with a unique id. It is not for tracking, so much as identifying "this user made this comment". It allows you to edit/delete a comment in a short window, without requiring a long-term login. They also generate a random image based on that, so messages by a user in a thread are consistent.
thanks for your response - i'm glad you mentioned the frameworks thing i was asking myself the same thing RE caddy, didn't know why i wanted to use it so probably best not to. Can you speak to any particular libs regarding twitter or stripe? 
Perhaps a bloom-filter of IP addresses that have voted on a given comment? Feels like overkill when the worst case is the wrong comment is shown at the top.
Yeah, sqlite is great, but it always makes me cringe a little in fear of cgo. I have not had issues building it recently, but I fought it and lost a few years ago. Can't remember the details though. But for a small blog or something, just throw it in boltdb and call it good. Blog comments are not exactly big-data.
The only important metrics are * Is it easy to understand what's going on? * Is it easy to test? 
It was just an example to illustrate the usage of interfaces since that's what you asked in the previous comment. Sure you can use the structure that best fits your project's needs. I will just say that packages with generic names like `services`, `handlers`, `models`, `util` etc. do not fit very well in Go and you should avoid them if possible. If there's one thing that you should keep from this discussion is that Go has a different philosophy and thinking than traditional OO languages. Best practices and design patterns from other languages are very useful but you need to apply them in the context of Go. If you are interested in a deeper understanding of Go's school of programming I can recommend you a few talks: * [Go Proverbs](https://www.youtube.com/watch?v=PAAkCSZUG1c) * [Public static void](https://www.youtube.com/watch?v=5kj5ApnhPAE) * [Simplicity is complicated](https://www.youtube.com/watch?v=rFejpH_tAHM) Happy hacking!
Thanks, putting those on the queue when I'll have a block of time to dedicate to watching it :)
I've replied to the comment asking if reCaptcha is suitable - if you think it's acceptable, I wouldn't mind giving it a go, if you're ok with that! I submitted a PR for another small change (serve assets from the Go binary itself) as well. Alternatively/additionally, something that may help with spam could be a honeypot field, like Formspree.io uses: [https://github.com/formspree/formspree/blob/master/formspree/forms/models.py#L122](https://github.com/formspree/formspree/blob/master/formspree/forms/models.py#L122). Basically, include a hidden input in the form called "_gotcha", or something, and if the value is not null, reject the submission (silently). The assumption here being that robot form fillers will inadvertently populate this field.
Your factory names like NewBucket and NewStorage could be simplified to just New since they have to be prefixed by their package name. b := bucket.New(...) s := storage.New(...) 
You'd need a GPS device accessible for 50 meter (or better) accuracy, for sure.
Relying on internals of the protobuf package is pretty nasty.
I'm not sure what you mean by "not scrubbable". Can you elaborate? At this time I don't have anything in writing for this particular video. I hope to later but no timeline right now.
Great writeup. My main fear of plugins at present is the requirement that host and plugin have the *exact* same version of every package in common. If the plugin references any package from the host app, that plugin binary is locked to that **exact** commit in the host app. Neither can update unless both do simultaneously. How do you coordinate upgrading go versions or any shared dependencies? Am I missing something? It really feels completely useless to me because of that limitation. 
I is impressed. Much documentation. Very demo. Wow.
Yeah basically go-astilectron executes an electron app (astilectron =&gt; https://github.com/asticode/astilectron) through Electron and communicates with it through a TCP connection
Agreed! Nice catch. So far the next patch to v0.4 will include: * Shortened "constructor" names * Default options * Better "constructor signatures * bucket.DynamicFill() The API will look like this: // will give you a bucket defaulted to use in-memory storage b := bucket.New(&amp;bucket.Options{}) // with redis storage store := storage.New(*storage.Options{ Type: "redis", Options: *redis.Options{}}) b := bucket.New(&amp;bucket.Options{ store }) I'm currently working on this library for a production use case so it's changing pretty quickly (thus the pre-release semver)
Well, I could say the same if the change of a dependency causes the modification of code in two places (main and handler). Do you have a suggestion which might mitigate this? Interfaces example mitigates removal as an object with more functions can still satisfy an interface. +1 for "done fucked up" 😂
I'm not much of a fan of game development, but this looks super nice. The only problem is that now I have to find an excuse to use it. ;)
Thanks! Some reasons that are totally not to be ashamed of are just having fun, experimenting, visualizing, or just exploring new areas of programming ;)
&gt;global namespace Thanks, I'll do that. &gt;cookie with a unique id Yeah, I've been thinking about it. I guess we can't really escape some kind of user tracking when it comes to stuff like voting/editing. The best I can do is to create a cookie only when the user actually comments.
Hi nuts! I'm open for every feedback for my tool :)
Not completely useless, but fairly limiting. You can always continue to use rpc style plugins to have hot-swappability without worrying about shared dependencies. Having multiple copies of the same library being used inside the same process is generally a really bad idea. Pure functions wouldn't be a problem, but having multiple copies of package level state is. Consider logging packages that you configure in main by setting package level variables. Also the "same" type from the 2 different versions wouldn't actually be the same. So passing instances around gets very messy. 
thanks a lot for that, I had it somewhere deep in my head about empty structs (0 memory usage), but ended up using pointer and passing nil, instead of using the memory efficient empty structs.
Huh, I am going to look into this. But if i may ask, why couldn't someone just use a webserver with CSS and HTML for the GUI? Thats what i have been doing. doesn't this need you to download electron as well?
Hmm. Might be somewhat difficult to achieve. Do I understand it correctly, that you would like to have an IDE or editor outside the docker container that should connect to a running process in the docker container and instrument the process using something like delve for debugging.
Oops I meant skimmable. Scrubbing thru the video is a lot of work
Using a webserver is a great idea but how are you going to create windows, menus and load your webserver pages so that you can display them to your user? Above all cross platform. One solution is to open up chrome but then there's no way for your GO app to actually communicate with the JS in your webserver. With astilectron you still need to start a webserver with your GUI HTML/JS/CSS. But then what astilecton does is the following: - download electron in the background (or extract it if you'd rather embed it in your GO binary) - execute a custom electron app through electron, communicate with it through TCP and create a window that will load one of your webserver page That way your GO app can communicate with the JS in your webserver, something that is not possible if you're simply opening your webserver page in Chrome. Does that make sense?
Pixel doesn't directly have a "camera", but has a more powerful concept: Matrix. I highly recommend you read a tutorial on that (there's a link to it in the README), which explains how to implement a camera with like 2 lines of code in Pixel. It's really easy. Also, such a camera can be zoomed, rotated, whatever.
Hmm, After playing with the examples a little i am kinda liking this! I am going to try and convert one of my programs to use it. Will keep an eye on this project. 
Hey, Sorry, edited the response, but yes, if this expands further, I don't see why I wouldn't use this instead. I hope it does. Such as that "camera" I was talking about. Please take look at the API it has.
Do you expect to be active with this library? I don't want to invest time using this instead, and see this just become a ghost.
Yes, very much so. I started this library because I wanted to develop game in Go, but none of the existing libraries felt good enough. I don't see giving up on game development any time soon, so yes, definitely. If you have any suggestions on improving the library, let me know, either here, or gitter, or issues. But camera is easy in Pixel, trust me ;)
Funny enough, I started doing a game using the same gopher animation series image you use in one of your examples. But now, it seems to me that I should move over to using your library instead. As I really, really, prefer as much as possible to be in Go. Maybe this can help you to add more useful stuff: http://www.raylib.com/cheatsheet/cheatsheet.html ?
How about "Curved Lines" support? :) https://github.com/raysan5/raylib/issues/244
A struct will always be more efficient. 
Why wouldn't it be more performant? One is tossing strings into a map, the other is doing reflection to verify what goes where.
I haven't really looked through all of your code but there are already a couple of things that seem to be bad for security.. Here: https://github.com/SaturnsVoid/SimpleLicensing/blob/master/SimpleLicensing/Licensing.go#L51 This seems to be pretty bad for security.. you should be using &gt; cipher.NewGCM Because it gives you AEAD ( https://en.wikipedia.org/wiki/Authenticated_encryption ) Also, I see that you are using math/rand to generate random strings https://github.com/SaturnsVoid/SimpleLicensing/blob/master/Server.go#L8 https://github.com/SaturnsVoid/SimpleLicensing/blob/master/Server.go#L87 You should be using crypto/rand instead.. math/rand is not suitable for "security-sensitive work" This is what it says in the math/rand overview &gt; For random numbers suitable for security-sensitive work, see the crypto/rand package. 
Have you seen the [Qt bindings](https://github.com/therecipe/qt) for Golang? It has wider platform support than Electron and is much nicer on the client's resources (typically a couple of megs of memory vs the ~500MB average Electron app). Thought I'd mention it in case you missed it, because you mentioned you couldn't find a project with as good platform support as Electron.
Looking forward to digging into this one. Go could be a great language for games. Of course we have the GC, but it could still work for many many types of games especially now that pause times are improved so much these days thanks to the Go team.
Interesting idea for a tool. Thanks
Please stop spamming this. It's been posted a few times already.
Best answer by far to this. Also, what's the point of not using a fixed struct? It makes life so much easier because you can remove the uncertainty about typos in key names and even have your favorite editor autocomplete them.
Ok, probably README is confusing a bit. You can (and should) make a submodule in layer directory so for example you can have: *github.com/roblaszczak/awesome-app/auth/domain/user* And this path is compatible with your article or even *Effective Go*.
Ok, thought the README was pointing in the other direction. Thanks!
Ive bought a few books and am working through them myself, but honestly look up todd mccloud on udemy or something. He teaches academic level golang and has made a series on intro to golang and goweb. Both have been great supplements to the books i use and in many ways more so since he is great at explaining the "so what" to so many golang nuances.
Good point. However, the licenses of QT and the bindings are not suitable for everyone. And it looks like the bindings require cgo, another possible drawback. But resource consumption is indeed an aspect worth thinking about.
And there is more. Even if your host app doesn't use package/dependency X but your plugins are: 1. Plugin1 is using X v1 2. Plugin2 is using X v1.1 Loading both plugins will fail because they don't use the same versions of shared dependencies. For me, I see no ways to reliably use plugins: 1 Just build them along with application (rofl) - so they will share the same environment on building. 2. Include some hack (bundle with go binary...) in host app so it will be able to build plugins from go files transparently. This wouldn't be so bad if unloading plugins would exist. 
Yeah I've heard some people mention that too, but according to some there shouldn't be a problem if you dynamically link to Qt. [There's some info here](http://stackoverflow.com/questions/11994053/can-i-use-qt-lgpl-license-and-sell-my-application-without-any-kind-of-restrictio). The Go Qt bindings seems to mostly be dynamic linkage, with the exception of iOS. edit: There's also [libui](https://github.com/andlabs/libui) ([go version](https://github.com/andlabs/ui)) MIT licensed. Never used it so don't know how good it is.
Glad you like it! I'll try to update you guys as soon as there's something new about this projet :)
I'd go with public-key cryptography: - on the server, generate a private/public key pair - distribute the public key with your software - when generating a license, simply list some data (recipient, expiry date and such) and sign it with the private key - the client then validates the license with the public key (Come to think of it, this seems like a prime target for JWT.) This largely eliminates the need for an active internet connection. On the server side, you also won't need a DBMS, simply store the license on disk. The obvious revocation problem can be mitigated either by periodically connecting to the server (say, once every month), or by issueing only short-lived licenses + auto-generating new ones before the current one expires (similar to Let's Encrypt).
When you group by category and when you have 50 different services, 2000 different views and even more models, then the *Value* in the system will become a box full of lego bricks and not a system with clear purpose. "models", "views", "interfaces", "databases" etc. are implementation details; not the important parts of software architecture. With small projects (less than 50KLOC), whatever you do, will work. Please compare https://github.com/marcusolsson/goddd to https://github.com/citerus/dddsample-core. Which do you feel is clearer about its intent and *Value*? Which one gives better standing how different components are related? *The shape and architecture of the building screams at you... about its intent. What does it not scream? It does not scream: bricks, wood, nails, saws, hammers...* - [Architecture: The Lost Years](https://www.youtube.com/watch?v=HhNIttd87xs)
This is cool. Would it be hard to implement a webview?
I do agree with you regarding the memory consumption difference even though I think with nowadays machines it's not much of a problem. As for Qt bindings, I think this is a great solution if you want to give your GO app a native look. However, if you want to do fancy things (moving things around, animating, etc.) I do think you're going to get stuck pretty quickly. Whereas if you can use HTML/JS/CSS possibilities are somewhat limitless.
Heya, tried a couple of the examples, couldn't get them to work - upon executing go run main.go or go build and using the binary I get something like this with nothing appearing: ``` Killed: 9 Saving session... ...copying shared history... ...saving history...truncating history files... ...completed. ``` Running on mac
For now, I have been thinking of doing a project in this summer which will be helpful to students.
What do you mean by a "webview"? Like, an HTML5 backend? Rendering in browser?
Also not maintained anymore (at least Go-QML)
Thanks alot! TBH, the game jam wasn't the inspiration to continue my work, I was working on it and would release it anyway. The game jam just came out of the blue at the right moment, and it's really great that you made that happen. You definitely see a submission from me ;)
The project I linked supports QML. Look at the [Hello World example](https://github.com/therecipe/qt#hello-world) (collapse the "Advanced" section) edit: actually, here is a lot of better examples: https://github.com/therecipe/qt/tree/master/internal/examples
To expand on a few answers already given,. Think past the actual parsing and to the usage of the data, a map will have lookup time and a struct won't. A map will be harder to reason what data is included, but a struct is clearly defined, especially if the data need to be passed to other functions. If parsing more than just a strings you'll have to do all the type checks and conversions yourself wherever you use the data. The small amount of overhead in parsing and clarity of your program will be far better served by using a struct 99.9999% of the time.
Not really. Quaternions only do rotations. Matrix does rotations, movement, scaling and all combined. Matrices are also used in 3D graphics. Search wikipedia for more studying.
That's awesome! I love seeing a code which uses Pixel that's written by someone other than me :D. And your code is nice, you use the package just as it's intended to. Edit: Btw, you have a race condition in the plasma code. Sprite can be update (s.Set) and drawn (s.Draw) at the same time. Edit2: There's one more subtle problem with your plasma code. Sprite caches each Picture it's set to for performance. Since you're setting a different Picture each frame, this leads to an unbounded memory, a memory leak. The fix is that you create a new sprite each frame, it won't decrees the performance. I'll put that in the documentation.
I have a service which converts and serves preview quality images from a cache, after converting them from source. We had the same issue with thundering herd request for the same source image which was not cached. I ended up adding support for addressing this. The first thing I did was update my cache item interface to have something like a Get() or Value() method. Then when a request comes in for an uncached image I immediately place a "promise" concrete item into the cache for the key. The promise contains a mutex which is initially locked. It remains locked until the initial goroutine finishes processing the image and updates the promise item with the final value and unlocks. Any other goroutines that come in for the same value will look up the cached promise and block when calling Get() for the value until the original goroutine has finished. The refactor was kind of a drop in replacement to the cache since consumers don't know the difference between getting the value now or once it is ready. 
Slap varnish in front of the backend, it can handle thundering herds by bundling incoming requests for the same resource, processing all of them with a single request to the backend proper.
If you just need it within a single process you can also use https://godoc.org/golang.org/x/sync/singleflight , which is basically what groupcache uses under the hood (AFAIK it was first developed for groupcache and extracted later).
I didn't know varnish can do this! Interesting
This looks really interesting, thanks
I think you're right Svenskunganka, a good summary would be : - Qt is more optimized resource consumption-wise but I think only a few developers know how to use it properly - Electron + HTML/JS/CSS is less optimized resource consumption-wise but most developers will know how to use it properly Maybe this is a big stretch and I could see why not everybody would agree with that, but as far as I'm concern writing a GUI using Electron + HTML/JS/CSS is easier than with Qt and has bigger upsides for me. That's why Astilectron has so much upsides for me.
I also like https://www.manning.com/books/go-in-practice https://www.manning.com/books/go-in-action
Welcome to Go! &gt; it seems like Go's type system is insufficiently expressive One of the Go creators explains why Go is the way it is in [this talk](https://www.youtube.com/watch?v=rFejpH_tAHM). 
Is a good source to learn. https://www.ossblog.org/assimilate-go-programming-open-source-books/ Basically you want to know about : open interface {} (can take in any data type) Useful for type switches https://newfivefour.com/golang-interface-type-assertions-switch.html Creating data types Adding these data types to a struct (especially function types} Knowing how to use slices [1:][:1] (gets rid of a ton of need for array methods) https://tour.golang.org/moretypes/7 Here is a good Dave Chaney video about first class functions and pointers https://youtu.be/5buaPyJ0XeQ And many great os methods! If you are a visual learner A good udemy course https://www.udemy.com/mastering-go-programming/learn/v4/ 
Thank you! Many of these concepts are very useful, and most are available in other languages that I've already learned. Goroutines make a lot of sense to me and I'm very excited to use them. interface {} is somewhat confusing to me, however. It seems as if Go handles the type system's lack of expressiveness by becoming dynamically typed sometimes. Is that the case?
"insufficiently expressive" for which purpose? Go is mainly a server backend/devops/tools language (although happily used for other purposes in many cases) with a focus on fast compilation and fast execution. The language spec has been deliberately kept small, first to achieve the speed and second to keep code readable. (Especially other people's code.) Hence if you want a feature-loaded language, Go is not for you. About generics, they do not come free of cost, and the discussions about how to implement generics in Go have been summarized in [this document](https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4/edit#). TL;DR: The Go team is not against generics but they have not yet found a way to integrate them into the language without compromising other important goals (like clear syntax and semantics, fast compilation, etc). A while ago I wrote an article about a couple of alternatives to generics, as it appeared to me that people would demand generics even if the actual problem they tried to solve can be solved by other means. Find the article [here](https://appliedgo.net/generics). Caveat: The article heading may sound like "Go needs no generics", but this is far from what I actually want to say in this article. The point is, there are some useful techniques in Go that make the need for generics less urgent. Bottom line: If you work in an area where generics, sum types, and similar constructs are intensely used, you probably do not want to use Go there. If you just want to learn Go to have it "on your toolbelt" (which is what the title seems to imply), then by all means do it, and feel welcome in the Go community... but just don't mention the g-word again - at least not in this subreddit ;-))) --- EDIT: More articles on generics and sum types: http://bouk.co/blog/idiomatic-generics-in-go/ http://blog.jonathanoliver.com/golang-has-generics/ http://www.jerf.org/iri/post/2917 https://medium.com/@haya14busa/sum-union-variant-type-in-go-and-static-check-tool-of-switch-case-handling-3bfc61618b1e --- EDIT: Also VERY interesting is this approach on polymorphism in Go (actually, it is a language extension on top of Go and transpiling to Go): https://github.com/lukechampine/ply --- EDIT: typo.
Currently all I get is "signal: killed" after a go run command - I have the latest version of xcode-select installed
singleflight is the way to go for something like this. In general a circuit breaker is also useful for thundering herds: https://martinfowler.com/bliki/CircuitBreaker.html You can use a leaky bucket on the number active requests, error rates, or latency, and once exceeded block all new requests for a period of time.
Hmm. I don't know that I completely agree with him there. He argues that more features make programs more confusing and less readable because there are so many ways to do things, but I don't really think that's a valid complaint. There are always lots of ways to do things; some of them are right. For instance, in Rust, there are a lot of ways to do things, but only one of them is _right_; that is, the most restrictively typed, most restrictively borrowed, least copying way. Errors, for example, are often done using strings in prototypes: `fn do_something(x: i32) -&gt; Result&lt;i32, String&gt;` This is very similar to error handling in Go, but _even in this lax case_ the type system ensures at compile time that the caller handles that error. In addition, most production-ready systems use sum types for errors, e.g. enum DoSomethingError { FailedWrite(String), FailedRead(String), FailedSpellcast(String), // etc } fn do_something(x: i32) -&gt; Result&lt;i32, DoSomethingError&gt; This not only ensures that the caller handles the error, but if that caller doesn't chose to panic on error (with `.unwrap()` or `.expect()`), it ensures that they handle _every possible error_. In Go, however, this is not an option at all. Not only can Go not have a Result type (because it doesn't have generics), you can't even use sum types to statically ensure that all cases are checked. This isn't necessarily a bad thing; I just don't understand the motivation behind it, or what idioms are used to get around it.
You need to learn the power of interfaces. [Nemo's answer to this SO question](http://stackoverflow.com/a/21567136/2012396) shows how to use them to make type safe sum types with interfaces. Interfaces can also allow for generic programming in some cases. [The stdlib sort function](https://golang.org/pkg/sort/#example_Slice) is a great example of this. The one generic thing you really can't do with interfaces is functional programming. Do not try to bring your map, reduce, filter, flatten, etc paradigms into go. The "correct" way to transform a list in go is a for loop. This makes some people sad, but it's really a small syntactic difference that most polyglots get used to after a little grumbling. Edit: I almost forgot, in the very rare cases where interfaces do not suffice and you absolutely need generics for something, there are plenty of tools like https://github.com/clipperhouse/gen that will essentially do the same preprocessing that C++ templates do in the form of code generation. I want to stress again that this is a measure of last resort. 99% of the time, interfaces can do what you need. Edit 2: the most thorough way to learn these concepts (diving off the deep end) would be to write something that reads the ast of go files using [the go/ast package](https://golang.org/pkg/go/ast/). It's not pretty, but it works, and if you can represent and work with an AST without sum types or generics, you can do anything. 
I've been planning out an app with a similar setup, I was thinking about just building a "lightweight" native webkit wrapper that points at the localhost server. This way I can still make a mac bundle and get expected menu/shutdown semantics. It'd be sorta like [Adobe AIR](https://en.wikipedia.org/wiki/Adobe_AIR) or [Electron](https://electron.atom.io/) but for Go apps.
This is a good explanation of what happens on the machine. However, most languages (C, C++, etc) have different definitions of what pointers are, and many operations that seem reasonable on the machine model are in fact undefined behavior. In C, for example, you cannot reference one object from a pointer to another object (there is one exception to this rule).
&gt; expressive, comprehensively checked types make code more readable for me. Agreed. My point on readability is more about the number of features a language has. In feature-rich languages, programmers are exposed to the danger of over-engineering their code. They start focusing on creating "clever" constructs using all those cool features in order to solve a problem in an "elegant" way, perhaps just to prove they have "understood" the language at black belt level, and the resulting code is just incomprehensible to anyone else. I frequently hear people saying that reading Go code of other people is a delight compared to other languages. (Yes, this readability is partly also due to `gofmt`.) &gt; If you just want to learn Go to have it "on your toolbelt" (which is what the title seems to imply), &gt; Whoops! I didn't mean to imply that. Misunderstanding on my end, sorry for that!
Thank you for pointing that out, and yes I was aware of the race condition… but didn't bother handling it :) I'll change the code to create a new sprite for each frame as per your suggestion.
This looks neat! I wonder if this could be used as the basis for a UI toolkit--I've been longing for a cross-platform, hardware-accelerated, native-Go UI toolkit.
&gt; I just don't understand the motivation behind it, or what idioms are used to get around it. Well, the motivation is given in the talk you just watched :) When I see code in languages with a more powerful type system (be it Java, C++, Haskell or, yes, Rust), there seems to be a lot of focus on developing a type hierarchy and signatures that make it impossible to use the thing wrong. As a consequence, there will be friction when reading the code (as there are additional layers of abstraction), when maintaining the code (code that is harder to use wrong is also harder to use creatively or to change) and also when writing in the language in the first place (you first need to think very hard not only how you want your thing to be used and why it is correct; but also how you can convince the compiler that it is, indeed, correct. I don't like arguing with compilers too much, I rather want them in the role of providing helpful advice). In general, go goes the middle-ground; have a strict enough type-system to catch most common errors and feel somewhat safe when refactoring, while also making it hard to build abstract code and in general trust the programmer to do the right thing. For example, while you can do getters and setters in go and enforce safety in them (e.g. "you can't change the logger concurrently with serving requests"), it's in general deemed unnecessary and totally fine to just export that member and tell people to not do dumb things (see, e.g. [http.Client](https://godoc.org/net/http#Client) -- you could totally concurrently modify the client while it's also used to do requests. But that'd be stupid, set it up first, then use it, simple as that). These things always seem like a bad idea to people who are used to "keep things as private as possible" and similar mantras from the OOO world. But for whatever reason, empirically they seem to work. Go code is generally observed to be pretty safe, have a low frequency of bugs and to be relatively easy to debug (which, arguably, is the reason that the debugger-story for go isn't as fleshed out as for other languages). In my opinion it's because the simple design forcing you to write simple code pays off; YMMV.
Well, I'm glad to know that there has been a lot of thought behind these decisions, and I'll definitely spend some time looking at those links. Thank you!
&gt; code that is harder to use wrong is also harder to use creatively or to change That absolutely makes sense, and sort of changes my perspective on the issue. &gt; I don't like arguing with compilers too much, I rather want them in the role of providing helpful advice Again, I think this is something I thought was an absolute which turns out to be something of an aesthetic choice. I personally love it when my compiler tells me that I have written a program that's in some way internally inconsistent, but apparently that's not universal. &gt; simple design forcing you to write simple code pays off Seems like a good philosophy, and, as you say, it's empirically effective. Thank you!
I am Java developer, just recently started looking at go. With go i fells less powerful, the type system is too weak with interfaces{} all around. But there are some good thing like gofmt, compilation speed, convention of Pascal case to be public. It is lacking some good libraries for web development. So at the moment I think it is still a very good choice for some work but if you are looking at web backend development there are too many better choice. I am also looking at Rust, which feels like a much better language for its domain. 
Pointer fun with Binky.
I am also having this problem. I have the latest xcode and command line tools installed, but when I run it in Gogland I get: `Process finished with exit code 137 (interrupted by signal 9: SIGKILL)` There's no other output. Edit: Using go 1.8 on macOS 10.12.3 with version 8.3.2 of Xcode and commandline tools. Here's the output from Gogland if I run it in debug mode https://pastebin.com/XzFSpRKr
A more expressive type system (probably by definition) increases the decision space by increasing the permutations for expressing the same program. I recently heard a clever quip about how Haskell can be confusing simply because there are soooo many ways to do the same thing, and for this reason every programmer's approach to a particular problem looks different. For example, I don't need to choose between higher-order functions and generators, because Go only supports one. This also means everyone's code looks the same.
Thanks! Sadly, there is no way to do client-side streaming until fetch/streams API becomes prevelent: https://github.com/improbable-eng/grpc-web#client-side-streaming This is also what the draft gRPC spec says: https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-WEB.md
&gt; entire projects are built with Python, Ruby, and JS which are 100% type-unsafe Sadly, yes :P But I take your meaning. I need to get over my purity obsession.
&gt; I don't need to choose between higher-order functions and generators, because Go only supports one Right - but what happens when you need the other one?
[Blinky pointer fun!](http://cslibrary.stanford.edu/104/).
Not too bad. Good that there's some traction to do game development in Go. Hardly a "game library" yet, so far it's still just graphics library. But keep it up.
I have yeah. I see so there's a separate `select` running in a separate go routine for each `addr`? Therefore in the first evaluation of the select it will call `sndMsg()`? Will it hang here waiting for the return of sndMsg()? I'm guessing it will. Once that returns, if there's no error then will it wait for a message on the quit chan?
Ok, this seems like a problem. Could you please submit an issue with all the description of the error?
Thanks I'll read this.
An exit button in the UI is probably necessary, because users are going to want to be able to shut it down. Catching the close event would require more careful engineering; if you don't control the browser window you can't stop users from opening your app in a second tab, and you don't want to terminate if that tab closes. You can try to play games to deal with this but it would be fragile. One thing I'd suggest is documenting that the "exit" button shuts the app down and that this is the official mechanism for terminating it, but also implement something like "If I haven't seen a request for $SOME_TIME, I shut down." You can wrap a bit of middleware around the top-level router to track "the last time I saw a request of any kind" pretty easily, and if you do go with a websocket or something you can easily write something that refreshes that too. I'd also suggest doing something like having the program manually count seconds rather than using the system time and just setting an alarm for an hour in the future. If you, say, want to shut down after an hour of not being used, by using a channel to ping you every second and counting those, the time that a computer may be suspended or hibernated won't count against that time, which is what you want. (Normally this is a bad idea precisely because it misses out on suspend/hibernate time.) You probably ought to set that timer to something like every 10 seconds or something, too, to avoid getting scheduled too often while idle, which eats battery. That just leaves making sure that the app itself can detect shut downs and handle them gracefully, giving the user clear instructions on how to restart the app. Unfortunately, there just isn't a way to fully bind these two elements together without embedding a full browser under your control, but if you can live without that, these things will be "good enough". I wouldn't particularly recommend trying to use the presence of a websocket to determine whether the app is open; in addition to the challenges if a user opens your app in a second tab, in extreme situations such as memory deprivation I can't guarantee it'll do what you want.
FWIW, I'm a big fan of gRPC and even created r/grpc. . . I'm curious to see where this gRPC thing goes, it almost feels like it could become the standard way for microservices and even web clients (browsers, mobile and custom http clients) to communicate. I've been using Protobufs for a while now and absolutely love them as a wire protocol.
The "dynamic typing" aspect of Go is in the "reflect" module, which basically gives you the machinery of a C-level dynamic language interpreter and allows you to write dynamic code as if you were writing a plugin for Python in C. It's tedious and only as fast as an interpreted dynamic language is, because that's basically what it _is_, but it is available for selected locations where that makes sense. Go certainly does not encourage heavy use of that, but because everything in Go is actually tagged with its type you can dabble in it.
I got a question. Where is the type of information that's being stored figured out? I guess it's gotta be at the compiler level or identifiable by the way it's stored. So when I dereference a pointer, it knows how many bytes to grab starting from that address and how to format it into the data structure I need (integer, struct...). So is that information contained within the memory the pointer is referring to, or is the compiler keeping track of this for us? When I compile down to byte code, does the program then know how much data to retrieve from the address because the program code knows it wants an integer, or 35 character string... Or does it go to that memory address and the information at that address contains a way to identify what's being stored there? I asked the same question 3 times to try to clarify what I'm asking. Plus I'm on mobile and didn't know where I was headed when I started typing, and I'm too lazy to keep scrolling around reading what I wrote. Sorry. 
It's a combination. If you're dealing with a concrete type, the compiler keeps track of the type size. If you're dealing with an interface, there's a lookup table that gets consulted at runtime.
&gt; But when trained on generics it's easy to forget or not realize when they aren't actually necessary. A very important and often underestimated factor. It's like getting rid of good old habits. Very difficult. 
done: https://github.com/faiface/pixel/issues/7 Edit: It looks like it's an issue with go 1.8 when using Xcode 3.2. Updating to go 1.8.1 seems to fix it. I recommend adding a comment in the requirements section mentioning that 1.8.1 is needed on macOS if using the latest Xcode.
https://github.com/faiface/pixel/issues/7 It looks like it's an issue with go 1.8 when using Xcode 8.3. Try updating to go 1.8.1 and see if that fixes it.
Why gogland over LiteIDE, though?
The use cases for higher order functions are a strict subset of the use cases for `for`.
I'm the same way. I find that I often have to choose between elegance and completion. I find that with Go I'm much more likely to complete a project and it won't be *too* inelegant. :)
&gt; I've been using Protobufs for a while now and absolutely love them as a wire protocol. This might be crazy, but I have a wild dream that one day HTML will be transformed into a protobuf schema. Then we will just be sending protobuf messages all over the web.
Upvoted because I'm interested in this as well. I recall reading about 2.0 of Gin being worked on when the devs had time but I haven't seen anything since.
on the contraire. a go backend with a frontend html. a web view to render the html
not what i'm aiming for. i want to substitute electron as a frontend layer. besides i don't think gopherjs is the way to go. too much boilerplate code
Great point. 
Sorry, just got off for lunch. It's bigger but just ease of use (great debugging, great intellisense, great database management, and youd be surprised how fast they respond) and no setup. But yeah eventually gotta pay. As far as doing extra things in C. Sure you can do extra things in C but not only are their steps but every time you pick up the code you mentally have to think about what you were thinking about when you wrote it and unless you are a lifetimer there, forget about others reading your code. The point of making readability first is to design a language where people's minds are important. This is important in any understanding of science. 
https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors
Checkout http://stackoverflow.com/questions/10306272/apache-crashing-parent-child-process-exited-with-status-3221225477-restarti Summary: something is access memory which is not allocated. Something is up with one of the unsafe address, probably either null, the wrong data type, not sides correctly
Is it possible to change a (the non-pointer) to point to a different address in memory? If so how, and would the pointer b then point to the old address or is it somehow updated to the new address?
I took that route here: https://github.com/tmc/grpc-websocket-proxy
Didn't know Iris stole code, and always had a sneaking suspicion that the numbers provided for the benchmarks are fake (but I really don't have any way to backup that claim). 
Alright i needed to call it instead, now just trying to figure out how to get it to listen to the default mic...
I totally agree that it would seem that for most cases reducing allocations is ideal. What I'm speaking against is the trend that has it's primary focus on this endeavor, which as shown here, doesn't always result in the most optimal outcome.
Thanks epiris. You're totally right in suggesting that it may have been wrong to rely entirely on the memory copying through passing of the values. I'll consider your suggestion of controlling the immutability more tightly rather than relying on memory semantics in my future post where I look at ways to improve the performance of the immutable data structures.
The select doesn't start until all its arguments are fully evaluated. In this case sndMsg must complete, and return its error, before sending on the errc chan or recv from the quit channel. The easiest way to test this out is just to open the go playground https://play.golang.org/ Paste the code and implement sndMsg as a &lt;-time.After(time.Second) call. You'll see that even if quit is ready, it'll still block for sndMsg to finish.
It's a great web framework! I switch beego to echo!
If a user right-clicks a link and opens in a new tab I need to recognize that it's the same session. If user logs out in one tab, it should immediately invalidate/close session in all other tabs working with the site. On the other hand, I need a "remember me" function in one of my projects. Server sessions worked for me thus far in PHP, Python, C#. I'll use JWT when it's required: service to service, 3rd party authentication.
I was surprised to discover that in Go we can't increment or decrement a pointer value. I feel that this info is missing in this short presentation because it is a significant difference with C and C++. 
Plurasight (www.pluralsight.com) is much better. Yes, it's a subscription model, but the content is much better than udemy. There's some good Go courses on there, and a trial option to test it out.
Good luck to you. Try to find a publisher, though, as being able to sell on amazon adds huge amounts of credibility and exposure. (Also, shaving 20-30% off your pricing would make what you offer more attractive. ) But excellent website and like i said best of luck to you.
It's would be good to get an ELI5 on when/when nor to use them
Pretty cool. I'm also using and enjoying Echo; v2 was a bump in the road, but v3 is back to awesomeness. I can't really approve of this style of changelog though; it's a mishmash of various people's vague and inconsistent issue/PR titles, making it hard to figure out what actually changed. It would be a great improvement if each point was rewritten to use a consistent tense and style, e.g. --- ## Bug Fixes * `c.Response.Flush()` now correctly flushes the response when using `middleware.Gzip`(#871). * Changes to the `middleware.LoggerConfig` struct were reverted, restoring compatibility with apps written for 3.0 (#821). * Path components are correctly decoded by `c.File()`, allowing `e.Static()` to correctly serve files with spaces (and other characters requiring escaping) in their paths (#839) --- Isn't this a huge improvement over --- ## Bug Fixes * Gzip with streaming (Flushing) #873 * Change to middleware.LoggerConfig broke my service #821 ## Closed Issues * Static files. Spaces in path. #839 --- ? It doesn't add *that* much work to the release preparation, and sitting down to summarize the changes in such a form also forces you to go over them and helps to detect any issues at the last minute.
With WebSockets you'd need to build your own equivalent of HTTP2 stream multiplexing. It would also require a change to the semantics of the gRPC protocol itself across many implementations or a use of a proxy forever. Using HTTP bring the hope that a client-side stream will be available once StreamAPI lands. We talked with the gRPC team about it, and they preferred going with pure HTTP, and will be implementing gRPC-Web in other libraries (gRPC-C++, Java and others). At the same time, we had very little usage of client-side streaming requests, and just went with that as the simplest solution.
Just found this: https://nodekit.io/ :)
Relying on Electron is more a choice by default than anything else. I would rather use a C based library with which I wouldn't have to communicate via a TCP socket. Unfortunately there are none that fitted my needs as well as was as well maintained as Electron was (or still maintained for that matter). 
In fact last valuable commit (not in the readme) seems to have been done a year ago :(
I've continued my experimentation with the Pixel package by implementing the old school tunnel effect :) https://gist.github.com/peterhellberg/80df53fa909a2012f5acc00e2b908fc0
It's clear, but it doesn't really explain and provides examples.
I disagree. All the repo says is &gt; So which should you use? Use whichever is most expressive and/or most simple. well, to me a mutex is the most expressive and simple, because I'm already familiar with them. So how am I to know if channels might be better for some of my use cases? The rest of that repo page is at most 3-4 paragraphs so it doesn't really make a strong case for one or the other beyond "pick whatever you want"
Good explanation, my main issue that I've always struggled with bouncing between languages that have pointers is what makes them useful? I'm not trying to be a dick, I genuinely want to know why I should be using them. I recently made a simple Golang app (i'm very new to the language) and I didn't have to use them but when I browse through opensource code they're everywhere. Why can't I just edit the value I have or return a new value in a functional way so I don't mutate an existing value?
One question around server-to-client streaming (which seems to be supported): From the grpc-web specification I conclude that the content type is still something like `application/grpc-web-text+[proto, thrift]` and that chunks are taken from XHR progressevents (because fetch readablebodystream is not ready yet). From as far as I remember XHR + progressevents are not suitable for "real" streaming, because the XHR API will not only deliver the latest received bytes to JS but also still buffer the complete received response body internally. Which means a long stream will consume an ever-growing-amount of memory. Was this considered? I think a workaround would have been to use SSE formatting for server-side-streaming, which means every new stream object is transferred inside one SSE event (maybe base64 encoded). Drawback is that SSE afaik doesn't have a request payload. It could be added as a header however.
&gt;what makes them useful I'm new to pointers too, but if I understand correctly, pointers don't allocate new memory, they just point to an existing memory location. Using pointers allows your programs to create a smaller memory footprint than they would otherwise. 
https://tour.golang.org/ and https://gobyexample.com/ are all I really needed as examples.
thanks mate, it worked with stdout, err := cmd.StdoutPipe() buff := make([]byte,10) var n int for err == nil { n,err = stdout.Read(buff) if n &gt; 0{ fmt.Printf("taken %d chars %s",n,string(buff[:n])) } }
But this isn't really a Go specific feature. Most languages that deal with exposing pointers are like this. 
In some other languages, affine and linear types allow a compiler to treat immutability as mutable. Would it be possible for the Go runtime to make a similar optimization for objects called only with non-pointer receivers via some kind of reference counting? I figure it's not worthwhile I'm just curious whether it's possible and roughly how it would work. If anyone isn't familiar: a linear type (e.g. linear string) must be used exactly once. An affine type must be used at most once. Languages with these types can treat a series of immutable instances derived from each other as a series of modifications to the same underlying storage.
I imagine you'd use HAMT based data structures much in the same way Clojure manages to get fantastic performance for it's lists and maps.
&gt; I understand that the for {} loop will iterate indefinitely No they don't. Both `for` loops iterate `len(addrs)` times.
Wow. Go inside the Postgres runtime. What could possibly go wrong? :) -jeff
&gt; Would it be possible for the Go runtime to make a similar optimization for objects called only with non-pointer receivers via some kind of reference counting? Possibly, but your intuition may be deceiving you on how often such an optimization could actually fire. In imperative languages not really meant for such optimizations it is generally surprisingly easy to violate an optimization's constraint. And when I say "surprisingly easy", I mean, you will literally be surprised. A fun and educational exercise: Take a non-trivial package you've written. Look it over, and try to guess what functions will be inlined and what variables will be stack-allocated. Now build your package with "go build -gcflags -m", figure out how to read the output (which will take a bit, yeah), then compare it to what you expected. If your package is non-trivial, I all but guarantee you will be surprised at some things that don't inline, and why. The really simple cases you'll probably get right (a variable in a function that doesn't have any closures and never leaves, a one-line property check function), but once you get into even slightly more complicated functions you will learn how quickly the optimizations become difficult or impossible. ("Difficult" being things that Go could theoretically get better at by being either smarter or willing to be slower, "impossible" being things you thought were safe and simply aren't.)
[removed]
This is the obvious answer, there are other ways to do it but they won't be as good.
Just saw this performance comparison between eawsy and Apex Lambda Go shims. eawsy shim is 20X faster with 2X less LOC. https://twitter.com/fsenart/status/842336581776220161
Late to the party here, but to quote Russ Cox on this: &gt; Go is more an engineering project than a pure research project. Like most engineering, it is fundamentally conservative, using ideas that are proven and well understood and will work well together. The research literature’s influence comes mainly through experience with its application in earlier languages. For example, the experience with CSP applied in a handful of earlier languages—Promela, Squeak, Newsqueak, Alef, Limbo, even Concurrent ML—was just as crucial as Hoare’s original paper to bringing that idea to practice in Go. Programming language researchers are sometimes disappointed that Go hasn’t picked up more of the recent ideas from the literature, but those ideas simply haven’t had time to pass through the filter of practical experience.
The v0.1-alpha release was created today, more information [here](https://github.com/itsmontoya/linkedlist/releases). I'll be collecting issues/notes/requests until May 15th for the v0.2-alpha release. I'd love to hear what functionality would make your lives easier!
You can embed whatever you need for the installation in your self-contained GO executable using https://github.com/jteeuwen/go-bindata if you wish
Here you go: https://play.golang.org/p/kgAywwVMym The problem is that DeepEqual wants the interface{}, not a reflect.Value. The reflect.Value themselves are not equal, but the values they represent are equal. (As an aside, I would advocate not using reflection for something this. It will be slow, and defeats the type safety the language gives you. I would just write separate versions of contains for each type that you need. E.g., in this case, right conatins for []int. If you also need it for strings, then write containsInt and containsString. Sure, it's some copy-paste code duplication, but so what -- it's simple, fast, easy to understand code.)
Thank you for the quick reply :) I'll continue to experiment.
Cool! Your results look amazing!
Is it a conscious choice to use the same value (200) for a memory addresses and variables values to explain a complex subject in a simple way? Or is it just random? 1. sentence "To write a program that retrieves the value stored in memory location 200" 2. sentence: "On the first line of main we declare a new variable a and assign it the value 200."
I am not familiar with either of the Lambda libraries but I do use the Go skillserver package in a side project I am working on. The main benefit is that it wraps a HTTP server and parses the incoming Alexa request JSON. With that said, you won't need the HTTP server part for Lambda but it is still helpful for parsing incoming Alexa JSON and serializing the outgoing Alexa response. There are some nice helper methods for creating speech output as well as cards in the Alexa companion app.
I really fail to see why having 2 pointers is suboptimal... Care to elaborate? What is suboptimal?
Is your workspace set up correctly​ and did vscode download all the extensions? For me everything is working really fine!
Didn't have any of these problems when I configured it (on mac os X sierra)
These were not the points agains JWT but the points for server sessions for a particular project, not on general merits. These things have been debated at length in /r/programming and at HN. There are cases for JWT and cases for server sessions. The reason I explained my choice is because I was asked to. I am not trying to convince/sway anybody either way. I have nothing against JWT. I will use it where it is the right tool for the job. `echo` already has JWT middleware but not session middleware. 
That's correct but having the pointer means you can also modify the value it points to. The default value for a pointer is nil where types like int or bool will always have a default value- 0 and false. People take advantage of this when unmarshalling JSON or XML. A *int will be nil if the JSON didn't contain a value. Non-nil indicates that there was a value unmarshalled.
I used IntelliJ with node.js stuff in the past but the sluggishness for a small project really got me nervous. Maybe it's improved. I do also like using one editor that works for multiple languages; do you switch between IDEs/editors for different pieces of the stack?
Go has been a smooth experience for me on VS Code. Is your project in your GOPATH? I've never played with code not under my GOPATH, but I could see that being an issue. Also, between updates to Go itself I run 'gocode close'. Nobody on my team has heard of syntax highlighting issues but we don't have Macs. Perhaps it is OS related.
"[Reflection] is not for you" -- Rob Pike https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=15m29s
Go pointer = C++ Reference with nullable
Neat idea! Never really thought about how to hot-load configs. I guess if you end up specifying file names in the configuration you would also need a hook to reload dependent bits on config update. If you're loading configs from JSON (or YAML or whatever really), you can usually use a configuration structure rather than an arbitrary map, which IMO ends up being far easier to manage / maintain (and I think should be MUCH faster than accessing a map of maps). Then the same task becomes much less complicated / could end up looking something like [this](https://play.golang.org/p/-1jrMqniqT) (totally untested).
I have the extension installed and it works like a charm
Your question is odd, since the first and only example in your post is not about text, but some basic integer matching, and you don't even mention text (which is a separate can of worms to just matching by equality — tokenization, ranking, etc.) other than in your first sentence. Are you really indexing text? If so, have you looked at [Bleve](https://github.com/blevesearch/bleve)? It's a text-indexing library. If your data doesn't need to be on disk, consider a column-store-type approach stored in RAM. The cache efficiency potentially allows you to race through huge amounts of data in a short time without having to use complicated indexes such as B-trees. 
interface{} is pure dynamic typing. Interfaces with methods are a bit more of a grey area.
The interface matching (lack thereof) has hitched me a few times as well, it seems... very unnecessary. You are returning a type that **does** satisfy the interface but the compiler complains anyway! I would love to see feature this introduced into Go :)
Have you seen [viper](https://github.com/spf13/viper)? Seems to meet all your requirements. 
The only thing I would change is to never return interface{} but take it do take it as a parameter.
Interface vs specific concrete type look very different in memory, the compiler can't just "allow" that.
Determining behavior for a system signal is too far reaching for a library. At least leave a way to disable that particularly. Consider centralizing reload behavior - For example: https://github.com/codemodus/sigmon.
Demonstrating good practices in brief is helpful for beginners and essential for documentation. Equating this to writing "production ready code" is unnecessarily hyperbolic.
Your code is well written and appears to perform well. Comments could use a bit of work, but I would be happy with it in my code base. However, It would not make good sense to pull in an external dependency for 300 or so lines of code. You really have to weigh the value you get from an external dependency to the work it takes to produce it. 
Thanks for your work! Map/Filter/Reduce has historically been difficult in Go especially due to the core team's [explicit discouragement](https://github.com/robpike/filter). Are your fluent calls lazily evaluated? Do provide any mechanism, even if verbose or inconvenient, for users to type check at compile time?
Documentation is a valid reason to add error handling. "Because people copy-paste" is not. When someone does copy-paste into a production environment that code is by definition production code. To expect authors to write code with the mindset "someone may copy this straight into production environments, so I should code my example for that" is by definition attempting to write production ready code. Authors should write with good practices, but "good practices" depend on context and the context is determined by the goal of the example code. :)
It should be obvious that /u/tv64738 does not mean that users would copy and paste the code then ship. If a user starts from an incomplete example and continues in that lacking pattern whether by literally copying/pasting or by doing so figuratively (i.e. repeatedly digesting poor examples), the net result is negative. Though, I do understand your sentiment.
You have a valid point here, considering that dependencies want to be maintained, can go stale, can break their API, etc. However, if the alternative is to write 300 lines of code myself (that I need to maintain from this point onwards), would I then really be better off?
Very fair point, which is one of the reasons I put it out there. If someone can make use of it in their project or read the code and learn an idea/technique, then it's worthwhile to me. 
The idea of having a push/pop function is not a bad idea, I'll add it to the possible feature additions for 0.2-alpha! As for concurrent access, I wanted it to be treated similarly to a map or slice. To explain further, I expect for the user to handle thread safety. In my usage, I have the linked list sit behind a struct which is thread-safe. So there was no need for an additional mutex. I could easily create a SafeLinkedList wrapper which handles the thread-locking if need-be. 
True lazy eval is very complicated with go. That being said, chaining filters handles huge lists quite nicely. It's pretty damn lazy in comparison to other methods. If you want TRUE lazy eval, utilize a language such as Haskell IMHO. 
Serialization is not a responsibility of a concrete type. The only thing it probably should provide you is a set of methods to save and restore object state. That is if object should have this "restore state" functionality at all (which it doesn't in 99% of the cases). I fully disagree with your point about primitive types and structs of primitive types because it's a)violates encapsulation principles b) hurts performance because you do things I wouldn't have done if I didn't need them c) shrinks flexibility of usage. It doesn't provide any bonuses either because object can be serialized in hundreds of ways, so your "enduser representation" can be very inefficient (storing RSA is binary form can be much more efficient BTW). As for interface{} - I suspect that Go developers are starting to really abuse that pattern. It hurts readability, it hurts performance, it hurts memory locality. So it should be used ONLY when there is truly no other way. 
+1 for comedic value
I'm able to clear the canvas with a color and draw that to the window (using `canvas.Draw(win)`) But as soon as I use `canvas.Texture().SetPixels` the program crashes with: ` fatal error: unexpected signal during runtime execution [signal SIGSEGV: segmentation violation code=0x1 addr=0x348 pc=0x7fff7d662a47]` **And a stack trace (that I parsed using panicparse):** runtime stack: runtime.throw(0x415dd44, 0x2a) /usr/local/Cellar/go/1.8.1/libexec/src/runtime/panic.go:596 +0x95 runtime.sigpanic() /usr/local/Cellar/go/1.8.1/libexec/src/runtime/signal_unix.go:274 +0x2db exit status 21: syscall [locked] [Created by mainthread.Run @ mainthread.go:41] runtime cgocall.go:131 cgocall(0x40ecbb0, 0xc420036dc8, 0x4115ce0) gl _cgo_gotypes.go:5448 _Cfunc_glowGetIntegerv(0x7fff7d662a35, 0x8069, #3) gl package.go:6191 GetIntegerv(32873, *int32(#3)) glhf util.go:16 (*binder).bind(*binder(#2), 0xc42096c000) glhf texture.go:137 (*Texture).Begin(*Texture(#2)) main canvas-xor-tunnel.go:104 run() mainthread mainthread.go:39 Run.func1(func(#1)) runtime asm_amd64.s:2197 goexit() 1: select [locked] mainthread mainthread.go:44 Run(#1) pixelgl run.go:32 Run(func(#1)) main canvas-xor-tunnel.go:139 main() 1: chan receive [Created by main.run @ canvas-xor-tunnel.go:87] main canvas-xor-tunnel.go:68 run.func1(#6, #7, #5, #9, #4, #8, #10, #11) 1: syscall [locked] runtime asm_amd64.s:2197 goexit() Do I need to do any type of setup before I’m able to call `canvas.Texture().SetPixels`?
Perhaps something such as a Website which has a queueing system? You could use channels so that you're only adding one person to the queue at a time. There's probably something more interesting than this though.
I’ve opened https://github.com/faiface/pixel/issues/8 and will add an example of using SetPixels. (I get SIGSEGV even with using Begin() and End())
Hi there, You could take a look at our scratch repository on https://github.com/dkfbasel/scratch. It provides a base repository structure and code to start medium sized golang projects. 
A simple http server will use a goroutine for each HTTP request by default. You can take a look at [titpetric/sonyflake](https://github.com/titpetric/sonyflake) for an ID generation service, which doesn't need additional service dependencies like databases or whatever. Or you can do anything else within your http handler that doesn't need a global state, as the ID service is synchronized between coroutines (mutex, i think).
In Go yes, but not as pure Go unfortunately. Eg, cross compiling is troublesome, unfortunately. Oddly enough, there is a pure Go SQLite in the works. :)
I don't have one, but any project that's pushing data or a stream to stdout (think `zcat`) will have problems with the printf approach.
I don't use gocodeAutoBuild, sorry. I don't even have go imports turned on because it has a bug with the level of nesting in my microservices.
This article, and I guess transitively its author, struck me as very confused. I'd love to better understand the context from which they operate, because I'm sure there's a reason. But, as I see it, the problem here is a conflation of responsibilities: domain behaviors, and transport/encoding behaviors. We should all of course design our packages and APIs to operate on domain objects that make sense in the domain. In the author's example, if an object contains a certificate, then it should be represented as a proper eg x509.Certificate, and of course not a base 64 encoded whatever. This does mean that serializing it to a storage layer requires work, but that work makes sense: it's not the job of domain objects to know, or guess, how they're going to be used or stored. This is a less of a problem than the author makes us believe, because in the second example, the author has needlessly painted themselves into a corner. The Store interface methods return an interface type. Why? Surely there's no good use case for this: retrieving an object from a storage layer should return an actual, business domain, concrete object type, not a collection of behaviors with indeterminate implementation. And this aligns with proverbs we already know and understand, specifically that our methods should accept behavior-definitions (interfaces) and return concrete types (structs or primitives). 
Sounds good! I like it!
To explain, lazily-evaluated languages make it so that under the hood, all lazy values have two possible types. One is the "real" type of the evaluated value, and the other is the type of the closure that will generate the value, usually called a "thunk" as in lazy languages this is likely to be lighter-weight than a full function call due to the large number of them being made. You can't layer this on to Go very easily because you can't return "either a value or a thunk". If you sit down and work it out, you can't return the value, either, because that recursively requires that you've strictly evaluated all the possible component values. (Demonstrating this would take more time than I'm willing to spend; please if you have just _some_ doubt about this, consider taking my word for it at least for the sake of argument.) So you have to return the function that yields value you want to lazily apply all the time. Since in Go you can't overwrite the thunk with the expected value, if you want to cache the value generated by the function it would be the responsibility of the function itself, so all of these lazy values would also generally have to be created in a specialized routine that has a boolean flag for whether the value has been computed and a place to store it, so creating these lazy functions would also be a challenge. So a lazy int would look something like: func LazyAdd(a, b int) func() int { var computed bool var value int return func() int { if computed { return value } value = a + b computed = true return value } } Furthermore, if you want laziness to propagate down to structs, which you certainly do for recursive data structures, you have to put that in the structure itself: type LinkedIntNode struct { Value func() int NextNode func() *LinkedIntNode } each component of which will need to be implemented with the above caching function computation in order to avoid recomputation. To demonstrate, I wrote the _near_ equivalent of the following Haskell program in Go and [put it up on the Playground](https://play.golang.org/p/dlEG5YsXIp): main = mapM_ print $ take 10 [0..] though as the comments note I really ought to wrap sync.Mutex around all the lazy computation to get even closer.[1] I ran out of patience for this exercise; with a bit more work you could expose the increment function a bit more nicely for this special case where the next value depends only on the previous one, but in the general case you need a split between the state of the computation and what is output, too; if you want to generate Fibonacci numbers, you need to store the previous two numbers somewhere in order to add them, too. I suppose if you are feeling saucy you can consider that an exercise for the reader. I'm also not 100% confident that I'm not leaking something here. I've manually checked and I _think_ when we advance to the NextNode we only end up with a reference to the previous (strict) value, and that as we advance along the garbage collector should be able to pick up the previous nodes, but it's really easy to get that wrong. This is a lot of very fiddly code (I made some fun mistakes along the way to what you see here). [1]: Haskell does not promise each thunk will be evaluated exactly once, but because the values are immutable it means that in general two threads evaluated the same thunk are guaranteed to get the same value. In this particular example the list is also basically immutable once I create it, but in the general case in Go we'd have to lock to get the same effect, or declare the entire structure non-threadsafe, which is of course viable.
Heres a working example I made with a Vue.js todo app: https://github.com/b3ntly/vue-grpc
&gt; /user/:id &gt; So why is that important? well as you might have guessed, for SEO purposes, but also how any sane API is written; I'm not convinced search engines care where the ID lives. I think it may make it easier for humans to edit, but that's about it. In the URL spec there is a specified way to pass key value parameters "?key=value". So other than athletics, I see no technical reason to prefer them. I could be wrong, if so, please point me to resources to explain. 
Finished a simple program that uses windows own winmm.dll to record audio to a .WAV file. This is a simple low bitrate version but if you readup on https://msdn.microsoft.com/en-us/library/dd757161(v=vs.85).aspx you can to a lot with it to make it sound better. Kept it as lightwaight as i could, Got the idea from a Visual Basic Tut here; http://www.visual-basic-tutorials.com/MicRecord.php 
&gt; So other than athletics That's an amusing typo
Use OpenID Connect. It's a subset of OAuth2. Whereas the OAuth2 standard leaves you with a ton of options, OpenID Connect picks out a subset of those options that will actually be secure.
I agree with your advice on testing the public API, and to format errors in a readable way. But in this case, distinguishing between errors is intended for internally testing the parser. Although the user will see regular error messages for invalid input, I thought that relying on parsing strings to distinguish between two error messages would be bug-prone. This may or may not be the case. Consider this example: // Check the prefix of the error if !strings.HasPrefix(err.Error(), "integer") { t.Errorf("Wanted integer error, got %v", err) } While this may work for a specific case, both the breadth of different possible error values and the fact that the message is bound to a specific format make me uncomfortable. A slightly better option would be to return an error code, but then the public API would be forced to reflect that. If instead we create named types that embed an error, we can type assert to distinguish the error, albeit at the cost of extra type information.
This is really helpful.
Congrats! This is amazing, Ebiten should be a lot more popular than it is.
What exactly would a go app do to help this though?
&gt; Oh wow! that got ugly fast! The code is a little ugly yes. Among other things, it has a lot of unnecessary spaces, the comments could be better and to me it seems that the redirect checks are unnecessary. &gt; and that’s only 3 URL’s, just wait until we start adding more and event some static URL’s into the mix. I really don't see the problem. If your API has so many sub URLs then you can always *program* your handler to accept those. For example you could pass your handler a map of the sub URLs (or a struct) and then use a closure to end up with the standard HTTP handler signature. In the end it's a matter of choice. You can import 1000 lines of code from a package like [julienschmidt/httprouter](https://github.com/julienschmidt/httprouter) which can handle most cases or just write 10 lines yourself. 
&gt; But in this case, distinguishing between errors is intended for internally testing the parser. Well, I understand the intention, I just don't agree that it's a good idea :) &gt; Although the user will see regular error messages for invalid input, I thought that relying on parsing strings to distinguish between two error messages would be bug-prone. You haven't answered the question why you need to distinguish them in the first place. What is the advantage of doing that in a test? I don't see any. Your testcases should be small enough, that the actual issue is obvious and the error message should describe the error well enough *anyway*, that it will give you a clear idea of what went wrong. I see zero advantage in distinguishing anything here. And *if* there is any advantage, you very likely just want to export the errors in the first place, because apparently, for some reason, the correct usage of your API depends on distinguishing between different errors. Maybe showing some code and some testcases would be a good idea to illustrate what advantage you see in distinguishing errors here? That would enable us to tell you whether you need to improve your error messages or whether there's genuinely a point in exporting the errors. But in any case, I do strongly believe, that adding a private API for your tests is the wrong thing to do here.
And what I'm saying is that anytime you are considering returning interface{} you should take it as a parameter instead passed by reference. 
No, that won't fully clear the map of all backing data (at least not yet), see https://github.com/golang/go/issues/20138 
That link is almost perfect... and will be perfect once the issue is fixed. :) Thanks!
What issues have you ran into? Indexing big gopaths during startup is a pain but I haven't noticed any bugs since it came out
Strange behaviour when completion text when there is already some new text after it. It often will eat up components of names. For instance if I have a customer.ID and I then try and complete a word before that it will eat up customer. Annoying handholding for imports. Turns out I have some packages installed with an errors package inside them. This makes Gogland ask me for which errors I want. It would be nice if it auto assumed I wanted a standard library one. The type information(documentation) display is lacking. I would like a better usage of GoDoc. There were other things I can't remember off the top of my head. The poor performance and battery life and things that are the biggest issue for me. I like to write Go for fun and I'm often on a pretty slow tablet thing device when writing Go. I have to fall back to Vim in those cases. 
I currently use Visual Studio Code with the Go plugin and I swear by it. 
VSCode, for sure.
I use emacs with go-mode and some other plugins (company-go, go-guru, go-rename, etc). I tried VSCode and Gogland as well, but Emas e the best so far.
What's good (to program in GO) VSCode compared to others? Enough people (public) are using.
Here is a video of a guy who worked at Google then moved to Microsoft, who loves Linux and explains how go is better then Python with dealing with different operating system environments and how running a go app takes no dependencies and changing that app doesn't take much to Port it. https://m.youtube.com/watch?v=hsgkdMrEJPs&amp;feature=youtu.be&amp;t=55s
I feel that it's more lightweight than big IDEs but doesn't sacrifice in useful features. Intelisense and the integrated terminal are a huge plus. I don't have to leave the IDE to play with the terminal. It does these things without being too bulky. 
Doesn't VSCode use Electron (which is known to be heavy)
ST3 with the Gosublime package./. Works like a charm
Yeah but as shown [here](https://blog.xinhong.me/post/sublime-text-vs-vscode-vs-atom-performance-dec-2016/) it does so slightly more efficiently than something like Atom (which I also use just not for go). I've used both and I could tell the slight difference. Where my "lightweight" statement stems from is compared to something like any of the JetBrains IDEs (which I also use just not for go). There's definitely a difference there. I also feel like the VSCode UI is less cluttered and clean. It reminds me of Sublime but with much better code completion for Go and a nice integrated terminal. 
I love watching your tutorials and have learned so much, thanks! You've also got the perfect speaking voice 👌.
Really happy to see golang being used in released full games. 
Did you understand a better IDE because of the plugins? Because it's not for that, I think the best IDE or editor is the one that you master the most, the more productive your tool, the more agile you write code. Now if it is, some people are using VSCode and they say it's good.
I think this this hits it on the head. The tooling available for Go isn't "IDE" specific. This allows you to pick the "editor" that you personally prefer, and get install whatever packages needed to integrate the tooling. The choice of IDE is less important with Go, than with any other "modern" language I've worked with. For me, I like Emacs. But I see Go devs working with Emacs, Vim, Atom, VSCode, IntelliJ... whatever they prefer. What a time to be alive.
Oh nice, i would try it out this weekend
I think the solution you are reaching for is that you need to implement an object that implements Error, but has all the data you need not in a string, so the correct implementation of `integerError` is: type integerError int func (ie integerError) Error() string { return fmt.Sprintf("Wanted integer error, got %v", ie) } That makes an `integerError{443}` an error. Because errors are just interface values, if you use an internal type for them they are indistinguishable to the caller from any other errors [generated by errors.New()](https://golang.org/src/errors/errors.go?s=293:320#L1), which also is just a internal type. They won't be able to cast the error into the internal type, so they can't be tempted to do anything you didn't want. However, if you put your testing code into the same package it will be able to verify the error exactly. (In fact you can use something like `reflect.DeepEqual(err, integerError{443})` to do so, you don't even need a complicated chain of casting or anything.) (Contrary to some people's advice, I _always_ have my testing code in the same package, for this reason among many others. I use discipline to maintain separation and have decided I'll just wait until my testing code routinely goes stale due to worry about moving it to be strictly external based. Either I write testing code a lot differently than other people in a way that generally prevents its from going stale, or that concern is something that people theorize might happen, but doesn't happen often enough in practice to deny oneself the other advantages of having private access into testing time. The former is a legit possibility; I observe I also tend to create lots of relatively tiny packages for things that a lot of people make monolithic and it's possible that's what saves me.) That said, for a parser I would see a case for a publicly-available "ParserError", which would be something like type ParserError struct { Line int Character int Error error Expected string } or something like that, because if you do make that stuff available it ought to be programmatically available. For a parser I'd likely make the guarantee that a call to the parser will either succeed OR produce a ParserError, guaranteed. The reason I have an `Error error` in there is that if the parser takes an io.Reader, which it generally should, you also need a mechanism for returning the underlying error if one arises. 
Gotta say, your videos are very informative, episode #9 helped me better understand the context package Might I add, loved the "modern bear" shirt, looks good on your good looks haha
Does it force telemetry like the operating system or can you disable it?
I think for anyone to use this you will want to make separate repos for the storage backends. Go developers like to keep minimal dependencies, so "one cache" that comes with a bucket of libraries will be a negative for most. Think like std lib sql with drivers, imagine if they included all the db drivers :)
Yeah, it's mind-blowing how amazing vim-go is. Fatih should be paid to work on it full-time. Good stuff.
[You can disable it](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting). Most editors give you the option of sending telemetry data so you have the option of disabling it. 
Thank you!
Yeah, I hope more games in Go will be released.
It really feels the simplicity ethos of Go. For example if you open Go files it tells you to install the defaults Go plugin set.
Molt ben! Gràcies!
When it works the Gogland debugger is great. Unfortunately I found that it often did not work well for me (on OSX), with go programs that call into C libraries using cgo. Often times the debuggee would just die, other time the debugger would randomly detach from it without warning. 
Only tried Atom and Webstorm, settled for webstorm.
&gt; For this reason the proper way to test their functionality and ensure correct file system semantics is through the OS file API (open, close, etc. on POSIX and CreateFileW/NtCreateFile, etc. on Windows). Not sure I am following you here, that is precisely what os.Open does. It calls syscall.Open which makes the os / arch specific syscall. To clarify that was my point with the unit tests comment, I thought you wrote the tools for testing because the url was under your name. I was saying a simple test runner for all the [test files](https://github.com/billziss-gh/secfs.test/tree/master/fstest/ntfs-3g-pjd-fstest-8af5670/tests/open) by making a simple parser for the test format so they could be ran directly in the Go ecosystem. For example the entire [main.c](https://github.com/billziss-gh/secfs.test/blob/master/fstest/ntfs-3g-pjd-fstest-8af5670/fstest.c) is just str parsing for the most part- there is nothing special with the syscalls that couldn't be achieved in Go code pretty easily. Thanks for the follow up, good work again.
My apologies I thought you were looking for some form of unit testing and I was trying to point out that it makes more sense to do functional testing when dealing with file systems. 
Atom with go-plus package. https://atom.io/packages/go-plus
Another Gogland user here. I'm a full time Go developer and was using the Go plugin with IntelliJ before Gogland was release. As a result some of the issues mentioned here are "features" (the same happens in IntelliJ unfortunately) e.g. eating up component names during auto-completion. There are some bugs at the moment but I rarely encounter them in my daily use. In terms of the auto-complete for the package imports I actually prefer it asking as, in my case for example, I use github.com/pkg/errors instead of stdlib errors and so this kind of behaviour suits me fine. You can customise and turn on/off a lot of different settings. My advice is to just give the pre-release a try while it's free and the time limit is generous (unlike the 30 day trials for the released software like IntelliJ). It'll give you a good indication of whether you like it enough to actually purchase a license when it's fully released.
Good question. We also developed an game editor for this, and the editor is just an web application written in JavaScript. We adopted JSON since JSON was easy to use from web applications (and also from Go). 
I think part of the confusion over references in Go comes from the loose usage of the term "reference" when talking about pointers. When a pointer points to something, it seems natural to say it "refers" to something. And "de-referencing a pointer" is also a common phrase. And poof!, the r-word has appeared in the Go world. However, the term "reference" is already widely used (C++, Java,...), with different meanings, and that's where the confusion occurs. Thanks Dave for clarifying this once and for all.
This is awesome! You might wanna check some of the work the guys from keybase have been doing on a go-powered cross platform FUSE setup: https://github.com/keybase/kbfs
Have you tried Gogland? It's a very slim IDE, from JetBrains, but compared to IDEA it's focused only Go and as a result is a lot more snappier and resource friendly.
Have you had a look at Gogland?
Congratulations! I am really happy to see games developed in Go. Could you provide some insights about the Go part of the development, if the GC is a problem and how smooth it runs?
You're attempting to convince someone that "id" matters, but your examples show that the URL value "id" isn't terribly important where it really matters (at the search engine). You're likely better off advocating for `POST` requests to the `/id=?` URI with `page=?` in the body. Unfortunately, that requires respecting the POST conventions in lieu of that GET request Google SEO deliciousness. 
No i haven't, what are the major advantages over webstorm + plugins?
This question and many of the comments is such an obvious attempt at marketing Gogland.
Well, as for GC, I've never experienced that GC is a problem. It might be that the game is small enough that we don't have to care GC. EDIT: The app works as 60FPS smoothly. As for gomobile, gomobile is still a developing project, but we confirmed that at least `gomobile bind` has enough capability to make an application released on mobile app stores. I'm not sure about `gomoibile build`worked as well, but I imagine it is almost impossible to make such games with `gomobile build` since apps built by `gomobile build` can't have signatures which is required for stores. IMHO, The greatest insight is that simplicity way of Go worked even for game developing. I want to share this idea so I'll make this OSS in near future :-)
No IDE is best IDE.
Indexing GOPATH should be a one time operation, and if you disable the Javascript / nodejs support, or other languages plugins it should be even faster. If it's not something that happens only once after install / upgrade to a new version / installing a new language plugin or updating one then it sounds like a bug. But in any case, please send up a bug report here https://youtrack.jetbrains.com/issues/Go following the information here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems and someone will have a look at it as performance is something that the developers are really keen to have. 
Attempt by whom? According to the Go survey that ran in last year, VIM, VS Code, and IntelliJ where the three most used development environments. Looking at the replies here, that seems about right. And I'm passionate about Gogland, which is the dedicated IDE unlike IntelliJ was, thus trying to understand where some people have problems with it or complain that IntelliJ is heavy. I'm not dissing any other editor and in fact the good response for this type of question is always: Depends on what you are used to. There are a lot of editors that support Go, like vim, emacs, Atom, VSCode or IDEs like Gogland or LiteIDE (not sure about others?) but at the end of the day they are all IDEs because IDE means Integrated Development Environment and every one of those provides a lot of that to blur the lines between an IDE and an editor in the classic sense. So, you can go and suck that conspiracy lemon a bit more to make more baseless comments like that, or you can accept that people like something and they express it as such without being the person you are making this comment.
While I mainly use gogland as well (mostly due to just being very comfortable with intellij as a java dev), it's worth nothing that VSCode does have an integrated debugger that works perfectly with Go.
Genial Francesc, merci!
I have experienced same on OSX (10.12), its not problem with Gogland, but more with Delve debugger's issue with OSX's security. im not sure if it will ever be stable or reliable on OSX. 
I tried gogland and found it pretty heavy going on the resources and loading projects took a lot longer than vscode
The guys behind delve have made some significant change in the upcoming release so now delve will use lldb-debug server (iirc) to do the debugging on OS X, which hopefully should give a much better experience to users. But it also has to be noted that it's not only delve but also Go which is at fault as it doesn't produce the necessary or correct debug information (and as such you should always use the latest Go release) but also the linker version on OS X matters.
I think I read a similar article already, but nevertheless a good refresher on chaining http handlers. Thanks
My tutorial [Concurrency Slower?](https://pocketgophers.com/concurrency-slower/) will take you through the process of taking a broken, slow concurrent program to a fast functional one. You will see how to use Go's testing, benchmarks, and profiling tools as you follow along.
You should use a proper GUI library. Beyond the security aspect, it's easier to write more consistent apps with richer functionality that integrate well into the DE. The very question you are asking wouldn't be a problem if you used the right tool for the job.
This is great, I'll have to look into it. Annoyingly I spent the last couple of weeks writing a small tool for our company to do multi-stage builds, pretty much for nothing in the end. Oh well.
[Concurrency is not Parallelism](https://www.youtube.com/watch?v=cN_DpYBzKso), a talk by Rob Pike. Very helpful for wrapping your mind around Go's concurrency concepts. Which are actually very old ones envisioned by Tony Hoare. Related paper, if you want to dig deeper: [Communicating Sequential Processes](https://en.wikipedia.org/wiki/Communicating_sequential_processes) ([PDF](http://usingcsp.com/cspbook.pdf))
I almost think we need a sticky warning against Iris.
Let's see, I spent ~6 years with C, then 9 years with C++. Then I reluctantly switched to Java (for 7 years) because the job was interesting enough, but over time came to appreciate that Java had fewer dark corners and was more easily cross-platform than C++. My switch to Go was more purposeful. I like the simplicity and design of Go better than the languages I used before. I agree with the philosophy behind Go and like the ecosystem and community that has built up around it.
I'm running 17.04.0~ce-0~ubuntu-xenial, with experimental=true, and still no joy. Might anyone have any suggestions? Step 1/11 : FROM golang:alpine AS build-env invalid reference format I think that it won't be available until 17.05.
I come from the other side. Web Dev in PHP, Laravel specifically. Last year I picked up Python, which felt a lot nicer than PHP. Having heard a bit about Go over the years, the final straw for me was watching some tech talks by the engineers at a certain startup bank that uses kubernetes and emojis. Most of their microservices are in Go, so I though why not, and haven't looked back.
It is on, still: Error parsing reference: "golang:alpine AS build-env" is not a valid repository/tag: invalid reference format PS: Version 17.03.1-ce, Experimental true
I like many aspects about Go. I like the aesthetic, I like the community, I like the static typing and fast compiler and many more things. But the #1 reason why I embrace and recommend Go: It's a powerful language that is easy to learn and hard to make a mess. This makes working with other people on Go projects much more enjoyable than most other languages. Beginners can start doing useful work within a day or two and the excellent opinionated tooling with good defaults helps keep them on track.
ViM and LiteIDE are open source and not backed by a company with an agenda of selling licenses of related software. The incentive is clear. There is no conspiracy.
Probably I'm still breaking a lot of GoLang conventions and my code is probably very inefficient. Currently the most confusing thing for me is the way you use packages. I am using packages as a sort namespace within my application, such as the websites package, because that's how I'm used to do things according to the PHP PSR4 standard. Any feedback is appreciated. 
I spent most of late-2001 through 2009 in C#. In the early days, .NET was still in beta. I liked C#. While I learned a bunch of other languages along side it, C# was my main thing. But towards the end, I got more and more frustrated with some little ugly bits of C#. To the point where I couldn't stand the language anymore. By that point, I ran into the open source release of Go and I was immediately sold. While C# potentially still has some uses, almost all my time is spent in Go. Also, since I started working with it, I have become much more at home with C and various flavours of assembly. The one thing that bothered me most about C# was the annoying amount of boilerplate one had to write for every single new thing. That, plus the 'everything is an object' mantra. I really don't feel that adds any value at all. Go was a breath of fresh air with its simplicity and (for me) novel approach to OOP. Plus not having to write a class for something that is fine as a global function, was amazing. C#'s brand of OOP definitely has its uses, but it isn't nearly the be-all-end-all that some people seem to think it is. Go is not perfect, but as the right tools for the right jobs goes, Go fits a lot of those jobs very nicely. Go also taught me to let go of 8 years worth of indoctrination over what constitutes 'best practice'. While I will never be as awesome as the likes of Ken Thompson, reading Go's source and being exposed to the Go community, has made me a vastly better programmer in just 1 or 2 years since 2009, than all the previous years combined.
* I added the makefile because I tought it was a cleaner approach. The purpose of the makefile is that people don't have to know how to build a program or library * I did't want to clutter the main file too much, but I can try to make it part of the main package and still have the website array in a different file * Yep I was also thinking of using a file instead of hardcoded news site array. That's for a future release.
I'm always interested in learning new tech. Seeing that Go is a language that was created out of need and that it was gaining some traction, I wanted to jump on the bandwagon in case good job opportunity arrives.
Vendor lock-in and getting users hooked on a free product for then to sell an expensive one is a bad thing. This does not make neither free nor proprietary licenses "evil", as you put it. Paid licenses help the development of paid software. Why this is desirable when there are equal or better alternatives that are free software is beyond me. I support open source software by creating open source software, or helping open source projects and using open source software. In short, nice try, JetBrains employee.
I wasn't the one making the call, but... As it tends to be, the choice was somewhat arbitrary, there were probably many valid alternatives we could've choosen. We needed something to build a relatively complex API and processing pipeline, so we needed something that supported a reasonable amount of concurrency out-of-the-box, that was relatively fast, that could talk to other HTTP services (particularly AWS) without difficulties, that had a good-quality postgresql library (not an ORM -- all of our SQL is hand-written.) Absolute throughput or performance was also not a huge concern for us, so we preferred something that did some basic hand-holding for the programmer (managed memory, typesafe, safe containers etc.) We preferred static typing. We also wanted something easy to build and deploy. For these aforementioned reasons, C/C++ was not the best fit. Erlang provides even more of some of these guarantees (like hypervisors for added resilience) but its syntax is too obscure, talent is too hard to find and it's library ecosystem isn't that mature. Using systemd units and breaking up our service into several microservices replaces the role of hypervisors in erlang for us sufficiently (a big part of our infrastructure is various services that retrieve jobs from queues (mostly database tables) and slowly process them asynchronously, so if they go down and get restarted, that is mostly no big issue.) Rust wasn't mature enough at the time. Maybe it could've been a choice now, since it gives some really nice extra safety guarantees, but maybe not, since syntax and semantics are quite a bit more complex than many other languages, which would be an issue for us (we have quite a few junior devs and interns and such.) Python would've probably been the closest second choice, since most everyone of us already had a background in python (as well as C and C++.) Ultimately we still managed to have a couple of reliability issues like leaked filehandles/goroutines etc in a couple of places, but I'm sure it would've been worse with C/C++ (maybe we wouldn't even have let some of the juniors write code, had we chosen C/C++. We still have some amount of C++ code in our codebase, but it's relatively minor, less than 4kLOCs). CEO/cofounder at the time was pushing for PHP, but none of the technical staff was on board with that, and Go was pitched by someone as alternative, and then it just happened. There is still some friction in that new people have to learn Go, and it's usually a little different to what they've used in the past. This would probably be less of an issue with python, but it's still better than it probably would've been with erlang or rust, I reckon. Either way, it's not too big of a deal to us, at least at the moment. Go also works great withhin a containerized environment, which wasn't a criteria at the time, but worked out well for us. I personally don't expect to use Go again in my career if/when I stop working at this place, since it's still not that mainstream. I personally feel no allegiance to any kind of language in particular, but except for a couple minor exceptions, working with Go was pleasant and I would not object to doing it again.
&gt; And end up with an un-maintainable mess just because you refuse to be pragmatic. It was just a quick thought. Maybe it doesn't work well in practice. You can always come up with something else. It's part of programming.
Yet another mistake, I'm not a JetBrains employee, never was. Vendor lock-in when it comes to editing text files is probably the stupidest thing I've heard this month. But I like how you dodged the donations part as well. Nice trolling but it seems you're all talk and no substance. Have a nice day.
I previously had learned/used C++ (then Python) before, and while I appreciated those languages, I also had some gripes; C++ became very unreadable and I was always fighting the compiler, whereas with Python, there wasn't any type-checking, eventually became unreadable (I don't like reading Python code anymore, oddly), and was not able to upload my package to PyPi and install it successfully. Go, however, in the two months that I had used it, was easy to learn after knowing those two previous languages (including its different syntax), had a rich ecosystem that made sharing packages easy, and addressed my problems with C++ and Python. Unfortunately, I don't work with the language now, but I'd like to return back to it soon.
Good question. Ok let's see... I started off with assembly and BASIC because I wanted to control hardware. One was fast and the other was easy. I moved on to C, which to me at the time seemed almost as easy as BASIC, a lot more expressive and almost as fast as assembly. I moved on to C++ because of object oriented programming. I was a junior then and it seemed like a powerful way to model the real world. I spent over 10 years in C++. Along the way, I dabbled in Python (to write tools quick), PHP (web), C# (to see what something like the .NET library that had networking and threads felt like). This was before C++11. Just after C++11 was released, the time it took for various compilers to catch up made me realise that I wanted a language without a pre-processor, without header dependency loops and with one standard compiler. I also did not want to learn about garbage collection strategies just to get more performance out of my code, because the idea of not having compete control over garbage collection runs was unacceptable to me. I wanted a language with an official compiler that worked on all the platforms I was interested in (Mac, Win, Lin). C++ didn't have that. I wanted a language that built in under a minute because I had come to love Test Driven Development and I noticed that the build time delays were getting ridiculous. A nice to have would also be that the language built static binaries because I hated writing tools and sharing them and then have them not work because some stupid DLL or library was missing. I wanted a language with built in support for standards compliant networking, serialisation and a nice, natural way to express when code should run in parallel - I had looked at threads, queues, lock free code, wait free code, parallel for loops, etc. and each worked well, but did not feel natural. I just needed to express concurrency naturally and it needed to work regardless of the number of cores or the architecture. Last but not least, I wanted a language whose source I could read and learn from. Ideally, the source wouldn't look like gobbledygook but would be commented on the why. So all these ideas were kicking around in my head when I heard about Go. I kept an eye on it for a while and it only seemed to be growing, so I decided to check it out by first watching Rob Pike's 2009 talk on it (https://youtu.be/rKnDgT73v8s). I was blown away. It was like somebody had taken my wish list and come up with a language to suit it. It felt so natural I had to try some code. A week later I was hooked because of simply how productive a language Go actually is. It is amazing how much more you get done when you don't have to think about whether your HTTP implementation is up to scratch or how to deal with Unicode, or how to calculate time. The biggest bonus for me? It favours composition over inheritance. I still am hooked years later. Still enjoying the language. As for garbage collection? I can totally live with a maximum pause of 10 milliseconds for GC. As of Go 1.8.1, that typical pause is now more like 100 microseconds. So why do I like it? Because it makes me focus on the problem I'm solving and not on the technology I might need to use to start solving it. 
I'm using Perl since 2001. Some day I read article by former Perl-programmer about Go, and I wanted to try. I like it. Though it is very hard to understand and keep in mind everything, making first steps now.
But Go has also a lot of boilerplate?
It was new and i noticed you could do most anything i wanted in it. I also like the syntax
&gt; Thanks Dave for clarifying this once and for all. But he didn't. He just confused people who do not get pointers, maps, slices and channels even more, by not clarifying them. He went out of his way to explain why saying "pass by reference" is technically wrong, but he spent exactly zero effort on actually explaining people what the correct term would be, how they *should* think of those kinds of types or to actually resolve this confusion. If I wouldn't get the topic already, I would now be completely off-put. "But if a map is not a reference, then why does the original change, if I change it in a function? Why does my slice change, when I pass it to this function? Or when I do `x := append(a, foo...); y := append(a, bar...)`, why does `x` also changes to `bar`? With this blog post, Dave focuses more on being technically correct, than actually being helpful and I find that incredibly counter productive. It is probably wrong to use the term "pass by ~~value~~reference" and it *might* not be technically correct (though I'm pretty sure it is. But either way) to use the term "reference type" when referring to maps/channels/slices. But that doesn't change the fact, that saying "it's effectively a reference type" resolves 99% of the confusion around it, while just saying "you are wrong!" resolves exactly 0.
Idk I like a single solution to all this... Go Also, rewatch the video on porting your program and Python.
Learning go and what makes it nice is I can install Go 1.8.1 on my phone with free Termux app. https://play.google.com/store/apps/details?id=com.termux
I wrote a blog post about how to think about shared memory in Go: https://blog.carlmjohnson.net/post/share-memory-by-communicating/
I got tons of useful responses. Thanks to this post's comments and the videos linked, I now understand a lot more about the engineering tradeoffs made during the creation of the language, the target industries that Google had in mind, and idiomatic use of the limited types system to build large systems that are efficient and relatively easy to maintain. It's just that your comment wasn't relevant or useful.
Go chose me!
I haven't tried go yet but what's intriguing is that it's being used to replace both app dev (c#) and scripting (python) languages. I've been using python for automation with cloud functions (only moderately proficient) and it looks like I need to give Go a look. 
I've worked with more languages than I can count, and I came to understand what I liked and disliked in a platform. I wanted simplicity, a rare commodity after working with Java and C#. I wanted static typing after nightmares with PHP and JavaScript. I wanted something compiled, but quickly so it wouldn't slow down iteration. I wanted something easier to thread than Ruby or node. And I really wanted something that could be deployed with no dependencies, after working in DevOps for a while and getting tired of having to install Java and Ruby and node and Python and so on just to run other programs. I wanted to write self contained software and I didn't want to resort to docker to do it. I came across Go when working with Consul as a DevOps engineer. I started following HashiCorp and learning more about Go, and decided to mess around with it. I usually pick up languages pretty quick but I was productive with go faster than almost anything else I can think of, and it makes writing simple code the natural thing to do. I've been working with it for a couple years now and haven't moved on yet.
I like it a lot. I've been playing with https://github.com/hajimehoshi/ebiten for a while which is also good but less idiomatic, and with that package I really appreciate the gopherjs support. I have to niggle a little at the complex128 Vec. While it's a nice way to get the builtin operators I never really longed for them; I mostly wished for trig builtins.
It sounds like you need a basic nosql db. I implemented this type of thing about five years ago using couchdb and couchdb-lucene. I ended up doing a ton of the filtering like you mention here in map reduce views, only using license for full text searching with shingling and such. But in general you aren't going to find a all in one full text search db with traditional database / storage built in. You probably wouldn't want to, that's two huge academic areas in one code base. Better to search and join the results with your primary storage.
Similar here: several years of C, a few years of C++, with the occasional Perl and Ruby sprinkled in. Then Go came along, and its concepts and simplicity at first made it feel like a 21st century C, but then it also reminded me of my time in school when I did quite a bit of programming in Pascal. Go has been my day-to-day language at work for more than 3 years, and it's also my language of choice for private projects, and I don't see anything else coming along to replace it in that role.
Here's most of the content of an email I sent to my Lead Link on why i choose Go to implement a single sign-on service rather than Java (the previous language) or a different language. _____________________________ **Go (and why not Node.js or Rust or Python or Java)?** Go was a tough decision. I hadn’t touched the language since January 2015 so I wasn’t going to be up-to-speed in a heartbeat, but it did have some advantages over other languages: * I love Python and it would certainly have been a fine language to use for SSO. Throw flask into a virtualenv, add modules for LDAP and RSA, and you’ve got a stew going! It’s a very readable language (although it suffers once you start tossing too many annotations at it), and what it loses in execution time, it makes up for in fast development. The downsides were that it would need a bit more environment configuration up front, we’ll be chasing Python versions on servers (like we currently do with Java versions), and it’s significantly harder to prove you’re doing it right at compile time. * Node.js was a top-three contender. It’s got a lot of great module support, almost everyone knows how to read and write Javascript, and you’re your scripts are correctly written, it’s a really fast environment. The biggest downside was shared with Python. Because interpretation happens at runtime, syntax or coding errors won’t show up until unit test (if you’re lucky) or production (if you really messed up). * I strongly considered Rust. It’s got good (unsafe) integration with native libraries, has compile-time borrow checking for variables and memory, and has support for generics, traits, mutable and immutable fields, etc. However, if Go was going to be a stretch for the environment, Rust would be doubly-so. The first time someone tried to do maintenance on the code and ran into compilation errors because of immutable fields or double borrowing a variable would cause unnecessary pain. Sorry Mozilla: I love your language, but I’ll keep using it at home for now. * Erlang was a surprisingly strong choice. It’s got great web frameworks (including the standard Elixir) and a concurrency and failure model that would leave me very confident in that choice architecturally. I’ve used Erlang in RabbitMQ and, once I got over the environment problems, was very pleased with the speed and reliability of the system. Erlang makes Rust look easy if you didn’t read SICP or write in functional languages. There’s no way I’d expect it to be maintainable. * If I was going to write it in Java, I’d spend the next week evaluating which libraries are the best ones to do each job. And then I’d wonder why I’m changing languages instead of ripping out parts of CAS. Everybody “knows” Java, but in talking to people around me at work, deep knowledge of these frameworks is spotty at best. * Go is the reluctant hero of this story. It compiles to a single executable for very easy deployments, supports static linking so I can distribute one binary with the VM, all the libraries I need, and all my compiled code, and it’s strongly statically typed with a compiler that flags many classes of error. I can start the SSO server essentially instantly. From personal experience, linking to native libraries is very, very easy – even OS X dylibs – and it runs fast enough that my SDL programs needed sleep timers to be usable. Downsides are that the company's developer community isn’t familiar with it, that a lot of the libraries aren’t as mature as Java or Python, and that package management and versioning are abysmal compared to Python or Java. Because of this, I’m avoiding as many third party libraries as I can and sticking to the standard library implementations (e.g., using html/template instead of Hugo). If a programmer has used C/C++, Java/C#, and Python, Go will be very familiar and easy to pick up. It’s got pointers (the way C should have had them), a garbage collector (no more malloc/free), and interfaces instead of objects. _____________________________ *Edit:* What do I think about my career with Go versus other languages? I was an early Java adopter, writing in it back in beta, while I followed but didn't develop with Go until version 1.1. Unlike Java, which took off surprisingly quickly (probably because Powerbuilder and Visual Basic were really bad for web development in 1997-1999), I don't expect to be finding a lot of "Go" consultancies offering teams of programmers for enterprise projects. The language landscape has grown too diverse. In my company alone, we've got people doing Java, C++, Ruby, Perl, Python, R, Go, Node/Express, Angular, React, and Elixir for new development on a daily basis. In 1996 it would have been C/C++ and Visual Basic or Powerbuilder, and in 2006 it would have been Java (and maybe C++ or Perl). I expect it to be a lot like Python: I didn't get strong interest from recruiters for Python until 2014-15, and even those are significantly fewer contacts than Java development. Go will pick up with time, but having experience in hard-to-find protocols (like SAML) or specialized systems (like FileNet) will still get more recruiters each month than just saying, "I know how to write in Go." Treat Go as another tool in your belt, but don't expect it to define your career like Java or C#.
This reminds me of an example program in the book "Go in Action". Makes sure you update this to accept user inputs. 
Well, you can type vec.Angle(), which will give you exactly what Atan2 would.
The fundamental issue here, I think, is that you're unaware of how programming works in other languages. Haskell, Rust, C++, and C (and many others), for instance, all compile to static binaries, all can be compiled onto any platform with any OS, and all have static type systems. C's type system is _less_ expressive than Go's, C++'s is about on par, and Rust's and Haskell's are far more expressive. You talk about having "control over allocations" in Go, which is true; but you don't have control over _deallocations_, which you do in C, C++, Rust, et cetera. You talk about "building a web server from scratch" and then proceed to use a library that someone else wrote. That's not from scratch. If it were, then the Python program below counts too: def run(server_class=HTTPServer, handler_class=BaseHTTPRequestHandler): server_address = ('', 8000) httpd = server_class(server_address, handler_class) httpd.serve_forever() You criticize Python and .NET because they have large libraries (like Django) available; Go has those available too. You don't have to use Django to use Python for web development. Go has a lot of good features, but you seem to think that it's the only statically typed, compiled, portable language in existence. There are dozens. While Go has what you call "composite literal primitive types" (product types), it has no sum/sigma types, no generics, no lifetime specifiers/borrow checker, and no monads. This is not a _bad_ thing, but it does make the type system nowhere near a useful level of expressiveness for large projects. Go is an improvement over C in its use case (server software). This is partially because of Goroutines, which are a totally revolutionary feature. But `defer` is both a hack and a [kludge](https://en.wikipedia.org/wiki/Kludge) around the fact that Go has no RAII and relies too much on its garbage collector. What's really interesting to me about this whole thread is that I've been writing Go code for a few weeks and I've grown to love it. I think it is very useful for a set of specific use cases, an opinion which I considered mostly because of input from people in this thread. But you, and several others, seem to be unwilling to hear any kind of criticism about the language. Stop that! Go is great for some things and bad for others, just like every other programming language. I also _really_ don't appreciate your implications that I'm straight up lying and/or ignorant in a number of my points. Yes, I've read production Python - I've _written_ production Python. Yes, I know that `void *` is bad; `interface {}` is bad _for many of the same reasons_. You don't know as much about programming as you think you do.
I have been using intellij with the various go plugins and can do refactoring, find usage, coverage, invoke tests inline so I would not trade it for anything. I like the git support also. On the topic of go debugging - I kind of freaked out when I found out go did not have a debugger but IMO it's better to write good tests anyway.
Write a command line tool that loads records into a database with a record generator. Support taking records on stdin one json record per line and/or a list of files or just create them and publish to an out channel. Create a configurable number of workers (by flag), each worker should run in it's own go routine and receive records from the channel and write to the db or anywhere. The workers should exit when the out channel is closed. Wait on the workers and exit only when they are finished. Handle signals and exit if a termination signal is received.
I don't know enough about low-level development to disagree with you, but this was an interesting read. I'm still snuggled safely in short/sweet scripty Go bits for now.
I'm still sticking with Go for now due to market forces...but I now see Go as just too simple and in many ways under/mis-spec'd interesting comments on concurrency...I am personally sick of watching every coworker trying to use every concurrency feature just cuz. Your program is not an OS, stop trying to make it one If Rust can make some headway with more ergonomic APIs over the next couple of years, I can see it displacing Go eventually. The Go overlords will just say no to everything and Go will never be able to meet the needs of the future
It's found directly in [golang faq](https://golang.org/doc/faq#Is_Go_an_object-oriented_language) but to be fair, they do use "object" in quotes. Other people here usually refer to instances of structs as objects as well, but yeah, as the answer says: Also, the lack of a type hierarchy makes “objects” in Go feel much more lightweight than in languages such as C++ or Java.
I often wonder if I will look back on Go as something to outgrow. And I can accept that I am not clever enough to share your sentiment. Nonetheless, at this time not a single point you've expressed resonates with me. Time will tell.
Can you link a repo that you hit performance concerns on or provide a concrete example of a problem you couldn't scale? You talk about intensive I/O but what type of I/O is bound by cache line misses..? Cache lines .. I think matrix multiplication, rendering pipelines, game engine stuff maybe? I don't know of a single I/O subsystem that provides that type of throughput to pin any modern server. My workstation is a dual Xeon, 256gb ram and 6 ssds in raid 10 I can push 2.6GBps through. Two intel da2 x520s running sfp in bond at 20gbps. Lots of I/O, amirite? I've had all of pinned numerous occasions .. in Go with plenty of CPU to spare, while luks and mdadm, os etc is powering tcp stack and disk i/o. Of course ignoring the fact in real systems you don't scale vertically and shouldn't have to think about "cache lines" .. in order to keep your systems healthy. Point is this seems like an unfinformed rant / troll, but will happily concede if you provide any sort of examples. As it sounds now this has very little technical merit as written.
Funny you should mention Ada: I'm also diving deep into SPARK and the Ravenscar profile.
I wish I had that hardware... games require "cheap and dirty" provisioning. I can't provide a repo as I'm all closed source, but look at valve's client/server source engine sync stuff for an idea. Computing client deltas over massive slices for _every_ client. At 60 ticks/sec. with physics. With lag compensation. So much loading. So much rescheduling. Edit: I've contemplated provisioning FPGAs for the job, but the cost is extreme. And aws is lacking.
Hi, I didn't capitalize those on purpose. I am referring to fully-featured OOP languages like Java EE, and the evolution of OOP features in PHP specifically, and in part also the ES5-&gt;ES6 evolution. The implication of using "EE" was the *enterprise* part of that one, where basically large enterprises enforce Java-like OOP principles on language development for lanuages like PHP and Node that gained significant traction (IBM and Microsoft to name a few). PHP features for OOP from an outsider perspective are evolving into Java OOP features. For example, during the years of PHP development I remember: * Overloading (granted, not like Java), * Traits, abstract classes and interfaces, * Inheritance, composition, * Throwable, Error and Exception (this is just ridiculous, why) And this is from a language which is/was basically a glorified HTML template. Sure, some OOP concepts help out with building good software, but you're still basically dealing with a language that was created to spit out HTML and not give you a windows desktop application, yeah? You do have a point about type safety - but alas those are the characteristics of PHP and Node in comparison. What makes it enterprise is the traction they are getting, and in turn the "coercion" by bigger players to enforce Java concepts down their throats. So far, Go has managed to avoid this, just as you say - because of a lot of specific use cases it handles. Web apps might not be one of those cases, but web APIs definitely are where Go shines, this is what I am saying :)
Yes, there actually is. A pointer does not allocate going in to / coming out of the pool. A plain byte slice would allocate. I had it written with the plain slice at first, but profiling showed the pool operations (specifically, Put) were allocating.
Could you please spare a few minutes to file a bug report following the steps here: https://intellij-support.jetbrains.com/hc/en-us/articles/207241235-Reporting-performance-problems I've seen just a few complaints im the issue on the tracker and they should be solved on the next EAP, due to in the next couple of weeks, but that doesn't mean that the particular issue you've bumped to has been solved. Thank you. 
This is just another confirmation that there can be no such thing as a jack-of-all-trades programming language that can meet everyone's needs. C or Rust seem a better fit when automated memory management is going to get in the way. Just as a side node, if Go's memory management was genuinely insane, or if Go's only valid domain was scripting, I wonder how so many successful production-level Go projects could have been possible. (See [here](https://github.com/golang/go/wiki/SuccessStories) and [here](https://github.com/golang/go/wiki/GoUsers) to get an idea.) 
Ahh I see, the slice header not fitting into a eface. Looking at the location you acquire it at, could you stack allocate a byte array there and avoid allocations for a lot of cases? Not sure what ya could get away with in that scope, maybe [128] or even 256? Then you could flush in the for loop if the next write would oob or something. Have no idea what the average size log line is. Clean and interesting code base though, thanks for sharing.
He did quite clearly say C but I guess it's easy to miss that.
I don't think I've ever heard the struct tags be a problem for anyone. I agree they are not ideal, but having written a en/decoder a-la json or xml, I appreciate having them. I do feel it's a good example of Go's pragmatism. It's not meant to be a beautiful language. it's just meant to get the job done with as little fuss as possible.
There are many ways of writing the same idea. As a simple example, are you using `type Vec struct { X, Y, Z float32 }` or `type Vec [3]float32`... or `History [2][]Entity` or `History [2][]*Entity` etc... all these tiny details matter. *I'm sure you are aware of this*. So, it's difficult to say whether the problems you were facing were inherent in Go or not. I agree, that when you want the best performance, Go is not the best player around... but it gets you close. I.e. hitting 0.5x performance of C is possible in most cases.
&gt; but it does make the type system nowhere near a useful level of expressiveness for large projects. [Go was designed for large projects.](https://talks.golang.org/2012/splash.article) It is just that "large" in this case means Google-scale-large.
You could probably add that as another layer with [go-flags](https://github.com/jessevdk/go-flags) or something similar that handles environment mapping. Also I think you probably need to be thinking about mutual exclusion / fetching config copies. What happens if you read something from the config map while it's being updated?
A few years ago, I heard of a company which developed an ad server type application in Go. I was surprised. Although I hadn't heard anything about it at that time. I wondered why not C++ or Java, or heck PHP. I mention PHP because some other ad server tracking software is written in PHP, such as prosper202, imobitrax, Funnel Flux. There are others I am sure. Anyway, it came to needing an in-house solution as then the current players didn't have the custom features required. I rolled up my sleeves and wrote out an MVP over a weekend. 200rps. That's all it was able to do. I looked at many tutorials, spoke to many people. They all blamed the database. It must be the database. Look at your indexes, yada yada. Nevermind it was actually wired up to redis lol. Changing from Slim, to Codeigniter, to Lumen. Performance either got worse or it never really broke 250rps. Lets be honest, someone even brought up a similar story: [1]. Which of course, someone suggested he had an agenda. But wait, Taylor of Laravel fame recently posted: [2]. A mere 521 rps. But really, I am just proving the point of my story. PHP was a poor substitute for what was really sorely needed. I then learn Go to a decent extent over a weekend. It's really easy to learn. Over the course of a few weeks. I have the same MVP which has the same functionality as the PHP MVP. The result? It completely and utterly destroys PHP. What would require dozens of high-spec servers running PHP to handle the load that was required. Only 3 servers running Go would be needed. Fast forward to now. Whenever I need heavy lifting or micro-services. It's all done with Go. PHP has pretty much been relegated to handling sessions and some front-end business logic. Unfortunately, I'm not sure I will ever leave PHP. As there are many libraries in composer that I still use and it's not available with Go. If there was parity between the two, then I would move over in a heartbeat and migrate over to VueJS for the front-end. That said. I don't see myself using PHP in 2022. It's like Python. I never use it now. I see myself just developing in Go and JS (VueJS). [1]: https://www.reddit.com/r/PHP/comments/67st8w/lumen_laravel_sham/?st=j24khbuc&amp;sh=9167d68f [2]: https://medium.com/@taylorotwell/benchmarking-laravel-symfony-zend-2c01c2b270f8 
Just use the languages and tools thats right for a particular project instead of "leaving go" or something like that.. I strongly dislike a lot of things in both C and C++ but I still use them when they are the best fit.. Knowing your project requirements is the only way to make a good call for each individual case, leaving Go isn't. 
We can call this GoLP Stack :D
Huh, TIL the P in LAMP can be any language that starts with P. It was always PHP in my book. 
Because Go is ok for web apps and it's perfect for enterprise: no need for a complex env. setup, installation, etc. No need for expensive PHP "encryption", obfuscation, etc. Send one binary file, and gg.
last sentence.
Portuguese?
Yeah, I was going to say python/perl - actually forgot about PHP... I guess I still kind of figured if anyone had a choice between the three they'd choose python :)
I also thought it was PHP. 🤷🏽‍♂️
I don't know, however, I will show you the proper way of benchmarking go stuff: # File slice_test.go package main import ( "math/rand" "testing" "time" ) type Stuff struct { A float64 B float64 } func setup() (lst []Stuff) { rand.Seed(time.Now().UnixNano()) for i := 0; i &lt; 1000000; i++ { lst = append(lst, Stuff{float64(i), float64(i)}) } return lst } func BenchmarkCopy(b *testing.B) { lst := setup() b.ResetTimer() for i := 0; i &lt; b.N; i++ { chg(lst) } } func BenchmarkPtr(b *testing.B) { lst := setup() b.ResetTimer() for i := 0; i &lt; b.N; i++ { chgPtr(&amp;lst) } } func chg(s []Stuff) { for i := 0; i &lt; len(s); i++ { s[i].A = rand.Float64() } } func chgPtr(s *[]Stuff) { for i := 0; i &lt; len(*s); i++ { (*s)[i].B = rand.Float64() } } # Benchmarking $ go test -bench=. -benchtime=10s testing: warning: no tests to run PASS BenchmarkCopy 1000 25255135 ns/op BenchmarkPtr 1000 25572549 ns/op ok _/home/anossov/slice 56.059s &amp;nbsp; It's not faster for me ¯\\\_(ツ)\_/¯ (i5 6600k @3.5GHz, Ubuntu subsystem on Windows 10) https://golang.org/pkg/testing/#hdr-Benchmarks
Hah, awhile back I was going to write a blog post countering the whole MEAN stack with a new GRaM stack - Go, React, and MySQL. The answers already posted though from natefinch and hahainternet are correct. For the vast majority of applications, all you really need is Linux, Go, PostgreSQL/MySQL, and then React/Vue.js for the front-end. I will say though, don't be afraid of testing out new technologies. This stack will work and perform really well for a lot of applications, but that doesn't mean it's the right answer for every single problem. For instance, my new app requires storing billions of rows of data. Queries must return in just a few hundred milliseconds (max 1 second), no matter the value queried. The data is related. Now this would seem like a great fit for a relational database until you take into account the size of the database, which is currently sitting at 350GB. Using MySQL or even PostgreSQL, on a single machine, would require &gt; 350GB of RAM in order for it to return results in under a second. I don't really want to pay for 350GB of RAM. The solution in this case was to use LevelDB. It's a simple key-value store, and through manually correlating the data through 3-4 queries, I'm able to send it any value and all results return in &lt; 300 milliseconds. It's running on a single machine with 3-4 GB of RAM and 1TB regular spinning disk. Point is, pick the right tool for the job
Why is that the opposite of what you expect? If you pass a pointer, all you are passing is an address. If you pass a slice you are passing the full value which actually means that the value is being copied into a new slice to assign to your parameter value. 
Okay I'll stop but I wasn't inferring anything negative about you. We were talking concepts and no it's not a one size fits all but it is born out of frustration of older languages and dynamic ones. I'll end the in-depth talk there but I think you really should relook at how it uses types. It is very expressive even for large projects. That's was it's point. https://youtu.be/7VcArS4Wpqk Sorry if this information offended you but I seem to come across this a lot from people in other languages. It's that new hump that for some reason runs people mad. 
Haha so true lol
Thanks! I'm not familiar with the testing package.
I expected passing a pointer to a slice to be the same speed or slower. In c/c++ if you pass in a vector it makes a full copy of the vector, but I don't think that's what happens with slices. You can manipulate elements of a slice and those changes will remain outside of the function. How could changes remain if it copied the slice? My reasoning was that by passing a pointer to a slice you're actually passing a pointer to a pointer to a slice, and every time you update an element you'd have to de-reference twice. 
Just curious. How did you manage to store related data in a key-value store? What about complex queries? Also won't there be problems with duplication of data for such a large database? What about updates? 
&gt; I wasn't inferring anything negative about you Saying that doesn't make it true. I'm not "offended", you're just wrong, as well as failing to actually engage with anything I said. I really think we mean different things by "expressive". For example, you can't do this in Go: http://silverwingedseraph.net/programming/2017/02/15/session-types.html
I think we're misunderstanding each other. I think you CAN do this in small projects, but you CAN'T do it in large projects. I wasn't saying anything about whether you should or not.
&gt; I think we're misunderstanding each other. It is possible so I am going to clarify. You've said: &gt; but it does make the type system nowhere near a useful level of expressiveness for large projects. Sure I agree the level of expressiveness of Go's type system is limited. But what you are claiming with that sentence (and where I disagree) is that large projects need an advanced level of expressiveness. No they don't. In fact having that advanced level of expressiveness can potentially harm a large project in the long run.
From a gaming point of view, having a GUI backed into the standard library is good, and there are a bunch of established third-party libraries that allow you to write OpenGL, so I think Java has a leg up on Go in that department. I would be curious to see how Go's garbage collection compares in a gaming environment, though. I've done some game programming in Java, and I have to be very careful to prevent the garbage collector from running. I wonder if that would be necessary with Go's lower-overhead GC.
For me, the things that attract me to Go -vs- Java are: 1) SIMPLICITY 2) Go's CSP style concurrency primitives 3) Tiny, single file executables
Non-Mobile link: https://en.wikipedia.org/wiki/LAMP_(software_bundle) *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^62588
It's a good thing Docker is just some scripts thrown together man. 
The big thing for Java is existing libraries and services. Elasticsearch for example is 100% Java and is used by... everybody. There are also a couple B-tier game engines in Java that are probably the best free and open game engines out there. 
IMO, you give something up when you switch to Go. The best thing you gain is cross platform, but you lose generics, tooling, and some other stuff you might be used to. Pointer handling in Go will feel weird. JSON parsing (I think) is a drag. Go favors "simplicity" at the expense of basically everything else. The hard part about that is that complex problems remain complex and you only have simple tools to solve them. This leads back to boilerplate, code generation, and other things that you might have considered using Go for to get away from in the first place. Those are just my two cents. 🙂❤️
Oh wow, there's so much to unpack here. &gt; Well if generics are really really precious to you I didn't say that, I made no value judgments about them. I just said that Go doesn't have them. &gt; use azure functions, How is using a specific cloud platform going to help? Why not AWS Lambda, or Google Compute, or just spin up a server somewhere? What if I'm writing a desktop app? This is totally orthogonal to our discussion. &gt; don't even need to code authentication lol When did we start talking about authentication? &gt; watch out for version control months later, which you don't have to worry about in go cause almost no generics Wait... I need to watch out for version control, if I'm using Azure Functions, but in Go I don't need version control? What am I watching out for? Or do you mean that I only need version control if I'm using generics? If so, why? &gt; if not, use one of many go libraries. If not what? If generics are not so precious to me? Why are you suggesting a library to change something about the language? This whole comment makes no sense at all.
I'm a fan of strong typing. Go lacks generics. When you get a collection it's up to you, the developer, to know what's in it. This works while the code is small. As more layers or users arrive you have start paying attention to it. 
For web dev, low memory consumption, short startup time duration and no needs to use frameworks.
These points are more what Java __is__ rather than what it __does__. But yeah, good point!
Lucene, which is the underlying engine behind Elastic and just about any other modern and popular search stack, is 100% Java, as are many other big data tools e.g. Hadoop, Cassandra, Spark, Storm, Kafka. That being said, most of the newer DevOps tools are written in Go: Docker, Kubernetes, pretty much all of Hashicorp's tools, etc. 
&gt; That's a preference, not an objective fact. I'm currently in the process of writing a compiler I thought it was clear we were talking about [large scale programming](https://talks.golang.org/2012/splash.article). Sure for a smaller project you can use whatever floats your boat.
I don't know about you and your "LOL"ing but many people refer to VMs as hosts, having avg 2 CPUs with 10c/20t per piece you have 40 "servers" per machine, but I've seen people running even more VMs per one machine. Now if you divide 100k/50 = 2k. Lets say this are 2 nodes per 1U servers, lets say besides network equipment you can get 40 machines per rack which means you have 40 * 2 * 50 = 4000 hosts per rack but you can squeeze that even more with more specialized solutions (like for example HP moonshot where you can get 1800 real small servers per rack). So in only 25 racks with average solution you get your 100k hosts. This was a real problem with real requirements. Just because you don't work on this scale or don't know what host can mean doesn't mean other people don't. I've seen much weirder requirements from clients in this industry, if you think this could not be a real req then you are very new to this industry. &gt; But even if we pretend it was and the only solution was the incorrect one prescribed, want double the capacity? Double your client pool hardware instead of creating tech debt by micro optimizing C++ while paying an engineer many times the cost. Depends on what you work on. Doubling anything in highly distributed systems doesn't magically solve everything, benefits are not linear, in some cases only costs of synchronization are so high that you can't just double the hardware because you can't meet the deadlines. In those cases highly optimized C/C++ solution is a lot easier and cheaper solution. 
I try never to say Perl.
Yeah very true. I was debating which verb to use actually but then I noticed that each bullet technically needs a different verb so I was like screw this. :P
Thank you for your through explanation :) 
Linux, Caddy, PostgreSQL, GopherJS? Caddy in there specifically because the analogous MEAN and LAMP setups assume a separate webserver, though you could argue that since you can just build Caddy in to your project if you need that sort of thing that Go only needs a three-letter initialism.
 I'm not saying that it just "floats my boat"; for some kinds of projects, it is useful and can help catch and prevent errors. For some kinds, it's not. Go is good for the latter, bad for the former. Those distinctions are orthogonal to the size of the project. What is there in that statement that you disagree with? I honestly think we're on the same page.
Thanks! I'll look into this. A problem I've found with Go is that due to its implicit inheritance, it's hard to find implementations of interfaces and therefore would likely not have found ServeMux for a long time. Do you know of any method of finding existing implementations?
You mean lower latency. Go achieves such low latency (aka low pause times) at the cost of higher overhead (aka lower throughput). In theory, Java can be configured to use a similar low latency garbage collector like go's, but I don't know how it compares in practice for game development. 
Java's concurrent collections are stellar. It would be fantastic to have something similar in Go but probably not terribly practical given lack of generics. 
This is nice stuff. I take it that when the log lines are initialized, the format/string is dumped to the binary file, which makes inflation of the log possible. When you change writers, does it re-dump all those formats? Windows has this thing called ETL/ETW logging, that uses the C preprocessor and some tools to map every log line format into a GUID, and then it writes a structured log just as your nanolog does. The downside here is that you now have logging "symbols" that you have to keep track of, or your log is unreadable. This was a constant thorn in the side, as it was very difficult to keep track of these files, and old log files essentially were uninterpretable once the build symbol files had been deleted. One other "gotcha" here is that in large organizations, with lots of long-running server processes that just stream one big long stream to some centralized service, the embedded formatting data in your stream is likely to get deleted/lost/separated. Do you have any ideas how this could be integrated into a larger system without necessarily embedding the log schema? 
&gt; I'm not saying that it just "floats my boat"; for some kinds of projects, it is useful and can help catch and prevent errors. For some kinds, it's not. Go is good for the latter, bad for the former. Those distinctions are orthogonal to the size of the project. I have a very hard time comprehending the above comment. What exactly is orthogonal to the size of the project?
I'm not sure I know of any usage model where NoSQL is preferable except as the equivalent of an in-memory hash table. What I was referring to is stopping doing whatever makes NoSQL seem preferable though.
It's a minor thing, but it would be nice if there was a way of denoting that a class is an implementation of an interface like Java does.
&gt; Since they don't have a way to.. spin up a new vm on each rack.. and have each rack aggregate it's machines results into a larger payload- adding an additional layer of aggregation if needed. Reducing the payloads if possible at each aggregation point if data allows it. We can't then have our small pool of machines keep a connection pool to each rack and read results in large continuous buffers. We can't avoid all the tcp overhead cascading through our infrastructure. He wrote in his post that he do not have any influence on the rest of the system, you make assumptions without knowing anything about the problem besides what he revealed, you don't know the constraints but you still make assumptions just to prove you have a golden solution. &gt; but adding new hardware can't meet deadlines.. it takes too long or something. My assumption about your experience in this domain is accurate. &gt; Nope, we better just hand roll c++ and for loop our way through with epoll. Thanks for opening my eyes. Happy coding. As I wrote before, client can ask you to do something in the system on which you don't have any control and he will not change anything to help you because this would incur additional costs/complexity on him. Sometimes you need to glue two systems and you don't have any control on both of them and architecture at your disposal is heavy constrained.
That already exists and it's called [Go Guru](https://docs.google.com/document/d/1_Y9xCEMj5S-7rv2ooHpZNH15JgRT5iM742gJkw5LtmQ/edit).
Basically, instead of relying on whatever SQL engine you use to do the heavy lifting of performing table JOINs, GROUP BYs, and other functions to link columns and output the final, desired table... you do all of that heavy lifting yourself. For instance, say I'm making a price tracker. There will be millions of products tracked, and every day, the current price of that product across different platforms needs to be recorded. You can see how this would add up to billions, if not trillions of values that are linked to individual products. You now need to decide what the main, majority-used queries will be, and design your key-value structure around these queries. For instance, we know that products will be searched, so the prefix of each product entry could for instance be the SKU number: **[sku]** = {json blob of product data} We know price changes need to be tracked by product, from a given domain, at a certain date. The key for price changes could be (where : is the key delimiter): **[sku]:[site]:[date]** = 47.99 Now with that structure, pulling the last 50 price points from a given site for any given product is extremely fast, no matter the size of the database (if using a key-value store optimized for disk reads). This is just an example, but something I came across while developing my current SaaS. You can see also how this doesn't allow a lot of room more ad-hoc type queries that you can normally execute pretty quickly using MySQL/PostgreSQL. **Edit:** About data duplication and updates, afaik, most key-value stores will simply overwrite the existing value for any given key you use when saving.
You can use strings.Split on a slash or just remove the "/user" prefix to get the id.
Thanks, I'd never heard of this!
I see thanks for the explanation. &gt; You can see also how this doesn't allow a lot of room more ad-hoc type queries that you can normally execute pretty quickly using MySQL/PostgreSQL. Yes that's has always been my main concern with NoSQL. It really depends on the requirements. If the project has very clear and specific requirements and you can design based on your queries the way you described then NoSQL can shine. On the other hand what you described could also make a very useful and smart "cache" layer. For example you could have all your data stored normally in traditional SQL and on top of that you add key-value store optimized for disk reads that stores products exactly as you described to achieve the less than 1 seconds results. This way you can get the best of both worlds (with some extra work to keep everything in sync).
You nailed it. One thing to note, this code is changing very soon. If you check tip, they recently improved pool performance.
Thanks! :) You as well.
Right, latency. The Java GC is actually swappable, and you can drop in a version that does the "right thing" for your peculiar situation, but I don't have the kind of knowledge required to fuck around with it.
* Generics
I admit that is noisy, but if you take time, you can tell what that is going to do with just that line. You might need to go see what ListenableFuture is, but that line tells you everything you will need to get more information. You won't need to dive into some internals to see what's what. The strong, noisy typing, provides that info. 
&gt; If you start having complex systems, or just want to decouple instantiation, you'll want a DI framework. Why? I've maintained projects with literally millions SLOCs, and never needed one. Why would I need a DI framework?
This will assert that someImpl complies with someInterface when you compile: `var _ someInterface = (*someImpl)(nil)` 
The group of students i am working with are enthusiastic in understanding and testing different things go can do and the data structure manipulation. We wanted to push one output to the website. We are all a bit lost and have run through the tutorial. Our understanding of how this flows is poor
Okay but what exactly are you trying to achieve? Mixing the input and output between the console and the website is inconsistent and confusing. You should choose one and stick with it for both input and output.
&gt; Show me a game written in Go. http://blockbros.net/tsugunai/en/ &gt; Go has nothing on java in regards to game programming. I don't disagree but in my comment I wanted to emphasize that it is the Java *ecosystem* that has had more years to develop better tooling for games. But as *languages* they should be pretty much equal when it comes to writing games. And by equal I mean that both languages are not particularly amazing for writing games but they are not totally unsuitable either. &gt; If Go had a decent graphics/gui tool kit it would have leaped past java years ago. I agree.
java can do them all. people cry about its verbosity but 20 years of java programming has made it a non-issue for me. Go can do most of those(with the right bindings). I can easily find work in java. Go is a bit tougher. With Go I have a hard time finding work outside of the bay, or new york, or denver areas. However, my highest paying project to date was done in Go. Clearly, java has the edge, and will for some time. Edit: it is okay, down vote the factual but unflattering comment without retort.
No problem. If you have any questions feel free to ask.
So you can break your layers apart. Say you have a controller layer and a DB layer. If your controller instantiates your DB classes, you're coupled. If you have a constructor for test and a default constructor, you now have two flows. If you use DI, you only have one flow and full decoupling. 
http://i.imgur.com/iE1spq1.jpg
&gt; There's nothing left here to add, the conversation is no longer technical. I think loling every paragraph is not very technical conversation also. &gt; Why another personal attack towards my experience after insinuating it wasn't appreciated in my prior response? You may be much more experienced than me, maybe not. Conversations should be about technical merit, things you can measure and back empirically. You can't infer my experiences over the course of my career by a reddit thread, even if you could, it's not polite. Happy coding. Probably you are right but in this case we do not have all the details, we can't prove anything here empirically because we have only data supplied by third party, incomplete data - knowing that, we should look at prior experiences in that domain. The thing is that a lot of people seems to have simple solutions for complicated problems which doesn't really fit the problem because there are so many constraints and additional hidden complexity. Especially a lot of people that do not have enough experience in certain domain tend to simplify things based on their experience in similar but different domain, which doesn't work most of the time. And about politeness you are totally right, I apologize if I offended you. I wish you happy coding too, I really do. Take care.
 package task // DataᐸTᐳ where T is int. type Dataᐸintᐳ interface { IsCollection() bool GetCollection() CollectionᐸDataᐸintᐳᐳ GetElement() int } // Java's CollectionᐸEᐳ interface (partial). // CollectionᐸEᐳ where E is Dataᐸintᐳ. type CollectionᐸDataᐸintᐳᐳ interface { IsEmpty() bool Iterator() IteratorᐸDataᐸintᐳᐳ Size() int // ... more methods are available in the real Java CollectionᐸEᐳ interface, // see http://docs.oracle.com/javase/7/docs/api/java/util/Collection.html. } https://github.com/shurcooL/play/blob/9ee6a378d9541f5ef9d36b295915bd0818dfdaa9/103/given.go
This looks great, hadn't heard of it
&gt; . . . not offering anything means that every user of your package has to learn and re-implement the same stuff. Why not solve the problem once. Because you can't possibly know how your type will be serialized. What if I want to serialize it into a base64 JSON string? Into a relational DB? Into ASN.1? If you want to provide helpers, you can do so: func (t *Type) Base64() string { ... } func (t *Type) ASN1() []byte { ... } func (t *Type) Insert(db *sql.DB) { ... } // oops, this is a layer violation! don't do this &gt; If you implement a Store module that returns a Store type then even if you use interfaces to define dependencies those interfaces have to depend on the Store types . . . You're super confused :) Let me illustrate with an example. Here's your repo structure: repo/ pkg/ widget/ widget.go store/ store.go mysqlstore/ mysql.go filestore/ file.go Here's your domain package, widget.go: package widget type Widget struct{ ... } Here's your package store, defining only the abstract interface necessary to put/get widgets. Note it imports widget: package store import "github.com/my/repo/pkg/widget" type Store interface { Put(widget.Widget) error Get(id uint64) (widget.Widget, error) } Now you have the concrete implementations of that Store interface, a MySQL implementation... package mysqlstore import "github.com/my/repo/pkg/widget" type Store struct { db *sql.DB } func NewStore(db *sql.DB) *Store { return &amp;Store{db: db} } func (s *Store) Put(w widget.Widget) error { ... } func (s *Store) Get(id uint64) (widget.Widget, error) { ... } ...and a filesystem (disk) implementation, say... package filestore import "github.com/my/repo/pkg/widget" type Store struct { root string } func NewStore(root string) *Store { return &amp;Store{root: root} } func (s *Store) Put(w widget.Widget) error { ... } func (s *Store) Get(id uint64) (widget.Widget, error) { ... } — You should _never_ need to have core types like Store return empty interfaces. It's a huge design red flag.
There is also the fact that typical go programs tend to generate less garbage than idiomatic java doing the same thing.
The JVM does expose lots of black magic knobs for tuning the GC, but I think you can almost always just fiddle with the target GC pause time and it will mostly do the right thing. The JVM maintainers have tried hard to make GC tuning simpler recently. (Disclaimer, I'm not a java GC wizard, I've just read some stuff written by one).
What's so terrible about instantiating your class differently in a test? I don't see how "having two flows" as you put it is a problem. If my normal constructor takes no input, and my test constructor takes a mock db, it's clear and explicit exactly which external dependencies this class has. With a DI framework, it's all implicit and hidden away. No thank you. 
Do you have a source to go with that fact? Legitimately curious.
Unless you're a maintainer of ES the fact that it's written in Java is inconsequential. 
It does decouple the code from the instansiation. If you didn't pass the DB layer in, you'd always have to run tests against the service layer with the DB on. 
Go is old Java, simple, no generics, has garbage collection. It's better at brining nostalgia than modern Java.
Interesting!
I think this isn't in a stable release yet, i guess you should have edge (monthly release) of docker to run this? Reading up, it shouldn't work before the 17.0.5 version.
1. Go has clear separation between data and control logic rather than imposing the OOP-centric paradigm. You don't often see the Builder/Factory/Manager things in Go, which would tend to make the program more complicated and bloated than necessary. 2. Go has value type so composite values can be allocated in stack explicitly. 3. Go generally has smaller memory footprint because of a) no JVM required b) the mentioned in the above 1 and 2 points. 4. The startup time of Go program is shorter. This might be an exclusive problem that only JVM languages have. 5. Go is more readable than Java for various reasons. It's a simpler language after all. And the case-for-visibility is also very consistent among different projects (all Go project actually). 6. Native concurrency primitives. In Go you have the choice to expose a channel to user code. For most other languages, callbacks or virtual function overriding is the only choice. And they are not as elegant and convenient as channels. 7. (If you are a Vim user) Go has exceptionally decent Vim support thanks to vim-go. 
"no needs to use frameworks" means I understand every part of my project. I don't like DI, this is another reason I don't like web dev with Java. DI hides too much.
And reflection. Java is a perfectly capable language, yet somehow no one can seem to use it without adding at least one or two frameworks that use reflection extensively.
You don't need a DI framework or IOC container to achieve dependency injection or testable implementations. You can just have to write decent code.
Nothing like reading through a codebase and having no idea what code will actually execute until you flip back and forth between the actual code and the DI wiring, until you give up and just debug execution to see where it goes. DI frameworks turn everything into "and then something mysterious happens".
Given the way that interfaces work in Go, having a bunch of interfaces in the standard library is unnecessary. If you want to refer to something I'm the standard library by an interface, you can just write the interface you need and the standard library implements it implicitly. Struct tags aren't hacks, they're part of the language, so I'm not really sure what you mean there.
I didn't say you needed them. I said they are useful. You don't need many of the features of golang, but they are useful. 
yes thats correct. i was just talking about a future version.
yup, there is a bunch of people really excited about this.
Yep. Well it would be fine if the posts would say where you could get it :) I did wonder lately why I'm still using 17.0.03 when some other instance has 17.0.04. I didn't realize I was on 'edge' there, and TIL that you'd effectively have to enable both stable and edge, because edge will not include the stable release (ie, 17.0.03 is available only on stable but not on edge, if you're on edge only you will skip 17.0.06, .09, .12 etc.).
Having a version indicator/release in the post would be great, thanks :)
yes that will make it clearer, thanks for the comment i will update the post to reflect that info.
Edge is released monthly, and stable quarterly. Is there any documentation declaring that edge would skip some releases? https://blog.docker.com/2017/03/docker-enterprise-edition/ and https://docs.docker.com/docker-for-mac/faqs/#stable-and-edge-channels
A slice contains 3 things: * pointer to the underlying array * len * cap Go, always passing by value, will copy this data structure and allocate on the stack for all three items, which is a greater allocation than just allocating for the pointer. The changes remain because you are manipulating the underlying array. 
I think it is correct to say, that go doesn't have pass-by-reference, but it has reference types (pointers being one example of a reference type, maps and channels another and I'd probably call slices a reference type too). &gt; I'm willing to bet I'm technically wrong here but I've read the post a few times and I still don't know why. Don't be gaslighted. He might have a reputation and he posted this with a tone of authority and determination, but that doesn't make him right in any meaningful way.
I know what DI is for. But that was not my question. Why would I need a framework for that? Decoupling is just using other objects by behaviour (i.e. interfaces), and having the objects resp. the instantiation function provided from the outside. That's trivial to do yourself without requiring any kind of framework.
I am curious about how golang can be used in academic settings, and in particular how to visualise data. Seems like you did? How do you plot and visualise your data?
&gt; Yes, every exported func needs a comment. Do you not use godoc? I do, but I'm of the opinion of Robert C. Martin's Clean Code, which says (among other things): &gt; The proper use of comments is to compensate for our failure to express ourself in code. Note that I used the word failure. I meant it. Comments are always failures. We must have them because we cannot always figure out how to express ourselves without them, but their use is not a cause for celebration. Forcing comments on every exported symbols seems crazy to me, and I've seen it lead to superfluous comments like `// object.New creates a new object`, just to make the linter stop complaining. We should strive to write code understandable without comments. In the case of a func to be published in a Godoc, the package name + the func name + the params and returns types and names can tell a lot. (I say that but I sometimes fail to apply it myself. It's just that if I have to chose a dogma I prefer this one to the golint one)
Nice find, thanks for sharing. 
&gt; denoting that a class is an implementation of an interface You mean struct? Go doesn't have classes. I typically see this done in documentation, like "A is a Reader".
yes that is the huge benefit of WxWidgets , it use native widgets for your platform , i do WxPython and it is awesome
Maps and channels are pointers themselves (if we look inside Go source code). Slices are structs containing pointers, some built-in wrapper around arrays. Since they point to the underlying array, their semantic is the same as of a reference type. It does help in the same way we say Go is Object Oriented. Go does not have the notion of reference type/value type because it is much more explicit about ram layout and it does not compile to an intermediate language - the pointers are really pointers despite that there is no pointer arithmetic. Yet their semantic (usage) resembles reference types (and value types) very closely as Go resembles an OOPL - again despite the fact at no point in specs Go is introduced as an OOPL. 
For info on no reference value in Go http://www.tapirgames.com/blog/golang-has-no-reference-values
Minecraft was a popular, good game, not necessarily well-engineered. There's also an important distinction between client-side and backend - game clients tend to be written on whatever the platform best supports, and backends often follow suit due to reuse of code. C++ rules the roost in professional AAA circles. That said, I know of multiple large studios using some Go in some form (usually not exclusively).
You took on something challenging with massive performance constraints and now you're deciding that the tool to solve that beats all other tools for all problems? It seems like you're making the same mistake again.
Thanks for the link. I've encountered many entries on this topic all over the internet. If we go deep down the source code of any programming language, we will find things very different even if they are bootstrapped. We should not mix the implementation with the final provided semantic.
we'll give it a plug on GoTime.fm this week!
Even after 2 years of Go (a year and a half full time) I still get surprised from time to time by Go. Don't get me wrong. Go is a pretty well engineered PL. But there is a Go way of things which is different from others. Here I assumed the audience would be from C# developers who used C# for some years and now are looking into Go - like myself. But probably you are right. Thanks for the hint!
Thanks!
the fact that struct tags are strings is in the spec what is IN the tags themselves is not in the spec. many libs inject arbitrary instructions into tags. as for having more interfaces in the SDK...of course not required, but would help focus the community. don't you think `io.Reader` is valuable?
The byte slices are attained from a direct mmap call instead of by calling make().
&gt; what the supported and intended behavior of the code is I think the func signature should tell you exactly this. Ideally you should never need a comment nor to peak at the implementation. Comments should be the exception, not the rule.
I totally agree with this - limiting your choices to SQL can be just as silly as picking NoSQL because it's "webscale". Pick whatever matches your needs and competency, and architect to match how you're supposed to use it.
I think part of the problem is that the C++ programmers redefined what the term meant. Back in the 80s before C++, whether something was pass by value or pass by reference was a matter of whether you put the thing itself on the stack, or a pointer to the thing on the stack. This, usefully, told you whether the thing might be altered by the called function. Then C++ came along and popularized references as a specific different kind of pointer that didn't require explicit dereferencing. The term "pass by reference" got redefined to mean only passing values using C++-style references, and passing a pointer to a thing instead of the value of the thing started being referred to as pass-by-value, or (at best) "C-style pass by reference". See [Hacker News discussion](https://news.ycombinator.com/item?id=14226216).
Your expectation is unreasonable. Consider [the recent changes to the Go SSH API](https://bridge.grumpy-troll.org/2017/04/golang-ssh-security/). Based on looking at the code, leaving `HostKeyCallback` blank was entirely supported and resulted in accepting all host keys. However, it turned out that [that was a mistake](https://github.com/golang/go/issues/19767), and it was never intended that people be allowed to leave it blank and perform no host key verification at all.
Currently I use it for a school project where we have to do multiple regression types, clustering correlation and predictions. I handcrafted most of the algorithms myself using Go. We were allowed to use whatever language we wanted and create an application. I used vuejs together with chartjs for the visualisation and go as the backend with a rest api. I could share some statistic code maybe but it is under a schools NDA. 
IMO if the `HostKeyCallback` must not be blank, then you should not be able to instantiate a `ClientConfig` without one. It's something the Go language doesn't make easy, though it's kind of doable (with an unexported type, an exported interface implemented by that type, and an exported "constructor"). I don't like relying on runtime checks described by comments. They are not part of the API you expose to your users. And this issue is actually a good illustration of why: if I'm reading this https://go-review.googlesource.com/c/38701/13/ssh/certs.go correctly, the comment was incorrect before the fix: it described a behavior different from the signature **and** implementation. ----- Now, I understand this ideal is not always reachable in a clean way. Some other languages offer better type safety than Go, but from my small experience it comes at a cost of a much more complicated syntax. It's a question of trade-offs. There is a middle ground between the two dogma. This discussion started with me complaining about Golint requiring comments everywhere: I am simply against this extreme, and prefer to tend toward "*self-documenting*" code.
I would comment to the author that they look into wavelets, not because that's what this is, but because they may find it has interesting relationships to this idea.
Nice work. It might be interesting to see the before and after file sizes for the example images.
The following mentions a list of tech migrations. Please have a look at the number of them that migrated to golang: http://kokizzu.blogspot.ca/2016/12/list-of-tech-migrations.html Among them was paypal. You did not give complete source code examples of where you had obstacles and why it drove you insane and abandon golang. The TRUE REALITY is golang rocks. Yes depending on how you do your interfacing with C, you will get memory leaks and lose performance, but don't place the blame on golang. Garbage collection in golang rocks and getting better with every release. 
&gt; then I decide to rename testfoo to looksliketherealthingnow Ah, yes, if you're talking about `GOROOT` rather than package name, agreed. I would like to draw parallels to what e.g. Maven does in terms of (more or less) dictating a directory structure, but I don't know if people use other tools now. &gt; Javadoc Thanks for the example. I definitely agree godoc is harder to read.
Yeah, good point. It's possible to change the format such that the logs are identified by a large number, e.g. a UUID, however this would increase the log size because each one would use 4x the bytes to identify a log line. I did mention in the post about log rotation possibly writing all the log line definitions at the beginning of each file if something was rotating them by calling SetWriter. This would probably be a better idea because the logs would be self-contained. For centralized log storage / processing, I don't have an easy solution at this point. It would be possible to inflate on the fly with some code changes or something else I haven't thought of (which, of course, is correct).
Not Iris, really no. Between the ones you listed, Gin and Echo are the most popular and used in production, if any framework is being used at all. Gin has proven itself. I hear Echo is production ready as well but I only played with it a bit. Gin may have a bit more than Echo in terms of middlewares and such. Not sure. /edit ah and also gorilla is quite popular with those who don't like using a framework and instead prefer to integrate different parts with the http module from the standard lib, which is a good approach. Depends on your needs.
Be mindful that the originals are lossy jpegs and the processed images are non-lossy pngs, that explains why they are larger
Yeah, same here, but the C++/Java terminology seems to be winning, even though to me it's a much less useful distinction.
``stdlib`` Although at this point I'm starting to advocate implementing everything in GRPC natively because then you can autogenerate a JSON HTTP1.1-compliant server **AND** api docs (Swagger) [at the same time](https://github.com/grpc-ecosystem/grpc-gateway).
No, Go does not have pointer arithmetic in it's syntax. It does have unsafe pointers, with no pointer arithmetic in it's syntax. There is a package named unsafe that one can use to get around this. From Go website FAQ: Why is there no pointer arithmetic? https://golang.org/doc/faq#no_pointer_arithmetic
No IRC? Blasphemy! :P Cool stuff dude, really well documented comments. I'll pick through it.
Good article! I am curious on what type of development environment you used. Could you tell us a little bit about that?
I imagine that in some instances producing a jpeg, instead of a png, would reduce the file size further. It would depend on the amount of jpeg compression, the input image and the threshold value. I assume the purpose carre is not only to reduce file size, though. It looks cool too.
I think interfaces in Go are very much like interface in C#, not extension methods. Interfaces in C# is basically a contract. ie: Here's interface IShape, it have one method called Area() which returns a double. Any object that wish to have the IShape interface needs to implement the Area() method. You can then do neat little things like create an array or collection of IShape objects even if the objects that it contains are of different classes. From what I read, this is pretty much how it works with Go too but I haven't personally used them. What do you think? Btw your website is serving mixed content (http stylesheets over https). You should fix that because browsers that enforce https will simply not load your CSS.
Go would choose a better syntax. For your example Go would choose something like the more readable func [I, O] chain (inp ListenableFuture[I], fn func[I:, :ListenableFuture[:O]]) ListenableFuture[O] to convey the same information. Though of course Go would convey different information, not needing to convey *extends* and *super* with prefixed and postfixed colons, for example. If ListenableFuture was defined in a different package, you would have import u "somedir/future" func [I, O] chain (inp u.Listen[I], fn func[I:, :u.Listen[:O]]) u.Listen[O] where short names *u, inp*, and *fn* make reading it easier. 
Standard lib with a third party router. I like [Chi](https://github.com/pressly/chi). It's idiomatic and fast as hell. I also use some of Gorilla's middleware.
[Generating code](https://blog.golang.org/generate) by Rob Pike.
You've commented out the line in your requestor where you wait for the answer by recv on Request.c. Notice that c is an unbuffered channel, and therefore you can't send without a recv call. This makes your workers send on req.c block forever. Either make the request channel buffered (size 1 will be fine), or uncomment that wait for answer line. (Note you will have to recv on that channel eventually, or else the buffer will fill after 1 worker has done its job, and you'll be right back where you started).
Oops, I should definitely add an Adapter for IRC integration. Could be an external repository if IRC specific dependency is added. One thing that I like about creating bot framework is that I can learn variety of protocols and those implementations.
Also it looks like a new work loop goroutine is spawned every time a request comes in. But by the look of the for loop, it would seem the workers would want to be spawned once during construction of the pool, so that they can continuously handle requests and signal when each one is done. 
I only ever set $GOPATH and $GOBIN, unless I have done a custom installation of go from source, in which case I would also set $GOROOT (but less common). But none of this has changed for me since go 1.0 *Edit* : And I only set a single path on $GOPATH
haha yeah, i figured you probably glazed over the question at first look. Thanks for the updated answer!
Thanks for looking at it. I had tried putting the channel creation in the loop where I instantiated the the work functions, but I think I had a similar issue.
Seconded. Chi + net/http is pretty much all you need
I know of a major financial services company which has exactly this problem right now with their C++ web application hitting the 4GB limit. Apparently the build takes a _long_ time.
I tend to avoid gonum projects because they tend to have complex dependencies. [This float64 operations](https://github.com/gonum/floats/blob/master/floats.go), for example, which should be technically simple right, somehow needs internal/asm/f64. Maybe it's faster, but uh..do I really need to worry about asm for adding floats? And the deal breaker for me is that they don't version their changes. They introduce many breaking changes in the past, without tagging, without versioning. Check their [matrix](https://github.com/gonum/matrix) library. No versioned branches, no tags. I once had to refactor a great deal of their code, finding out where exactly the breaking changes happen, and only to discover their deeply nested dependencies, all with breaking changes. So it's one breaking changes after another.
I use vim, so [vim-go](https://github.com/fatih/vim-go) is pretty good. It does go fmt automatically every time you save. It has a bunch of other shortcuts for common go commands. I am still waiting a good Go IDE (looking at you, JetBrains), that can refactor, remove unused imports automatically, insert imports automatically, insert `if err != nil` templates. edit: apparently I put the wrong link.
Gonum is on its way to 1.0 (as is Gorgonia). I can say pre-1.0 one can expect a lot of breaking changes.
 func bar() { var fib func(n int) int fib = func(n int) int { if n &lt; 2 { return n } return fib(n-1) + fib(n-2) } r := fib(10) fmt.Println(r) } 
thank you and @gargamelus this is exactly what i am looking for.
Care to elaborate? It would seem to me, that maps, channels, pointers and even slices check every single box in [this description](https://en.wikipedia.org/wiki/Reference_type) of reference types and that, indeed, go has reference types. What (specifically) makes them not reference types?
Any editor that uses Go plugins with support for `goimports`, `goreturns`, and the like can insert and remove imports automatically. Visual Studio Code has template inserting capabilities, and I believe the Go extension even comes with an `if err != nil` template by default. Refactoring is another story. VSC helps with features like "Find all references" etc, but so far I don't know of an Editor/IDE with full refactoring support (disclaimer: I do not constantly observe the current state of Go IDE's and editor plugins.) A couple of command-line tools can help with refactoring, see e.g. [here](http://talks.godoc.org/github.com/rogpeppe/talks/refactoring.talk/refactoring.slide#1).
I guess the reason lies in the "crash early" principle. If a process triggers unexpected errors, it may have gone into an unspecific state. Letting it continue to run may cause more damage (such as writing wrong data into the database) than crashing right away. 
Gogland is pretty good although still in early development. There's also the Go plugin for IDEA
* Gogland + its built-in terminal window bound to F13 key (full-size mac keyboard) * Lots of middle-clicking on symbols, reading godoc comments and code in external (or standard) library sources that way.
&gt; [Go] has reference types What is your exact definition of "reference type" in this context? *It seems that all the confusion occurs because we all carry different definitions of the terms "reference type" and "pass by reference" in our heads.* See also the comment thread started by /u/metamatic.
Locking is necessary when multiple goroutines may be accessing the struct (or, more accurately, its members) concurrently. But without more context, this is not good code, because you generally shouldn't be manually calling Lock and Unlock like this. Where did you find this code? 
You have to implement C# interfaces explicitly. Go interfaces are implemented implicitly. They are more like duck-typing in other languages like Python, but only statically type, hence much more safer. That's essentially why Go has attracted so much Python programmers. The website is hosted by GitHub pages. Those settings is basically out of my reach (or it could possibly be that I do not know GitHub pages well enough).
sure. I've used Visual Studio code. You can get more details about it here https://code.visualstudio.com/docs/languages/go
Inside the "Authors" file you can enumerate the copyright holders, which could be a different entity from the one which made the commit(s). Ex: I can commit as "vimishor" but the copyright belongs to my employer "Dummy Inc.", so "Dummy Inc." will be added to Authors file. 
+&gt; refactor, remove unused imports automatically, insert imports automatically, insert if err != nil templates. Learn to use Vim and vim-go. They can do all that. 
I use vim and vim-go because it's the most feature complete editor/plugin. Using it inside tmux I can use delve, but no one at the company I work for uses a debugger. I've tried sublime, atom, and Visual Studio code and none of them even come close.
I use Gogland, though I hope to switch back to IntelliJ + the Go plugin, once it is at parity with Gogland. The main thing that is keeping me from using IntelliJ right now is the lack of the ability to run `gofmt` on file save, like Gogland provides.
Atom in 2017? Ouch.... Move to VS Code plz :)
Built this for a personal project and thought I might share. Hope it helps!
Built-in terminal is a great feature. VSCode also has it.
Try Crystal. 
I think Gorilla is still pretty popular, but I never realised how much faster some of the other routers can be! Looking at some benchmarks, Gorilla's Mux is considerably heavier and more resource intensive: https://gist.github.com/pkieltyka/d0814d5396c996cb3ff8076399583d1f Gin seems to do really well in everything, but I don't like the fact that it's a "framework", and deviates from the interface of the stdlib. Chi seems like a great bet.
Examining this code, I don't think the locks are necessary. It doesn't look to me like the `Main()` function they are embedded in is expected to be re-entrant, so normally I'd expect that this is using, for lack of a better term, the "initialize read-only and-then multithread" pattern. That is, it is common (I find) in Go for a particular goroutine to set up a struct without using locks on the struct and without sharing that struct, and then for there to be a single point at which all that initialization is done and then the struct is multi-threading safe, because all the values are read-only after that point and therefore don't need locks. In that case I wouldn't expect `Main()` here to be using locks, because at that point I would expect that only one goroutine could possibly be running. Part of the reason I expect that is that otherwise that code above is, if not wrong, at least very dangerous. If multiple things are running through `Main()` at once, that code above runs the risk of having the tcpListener from one goroutine win, while the httpsListener from another goroutine wins. Because of the fact that listening ports are themselves a sort of a lock (as the OS enforces that) and the fact the rest of the code in that function will `os.Exit(1)` if acquiring the port fails (which is reasonable on its own for a server), I infer that in practice multiple goroutines are not running through this code as that would cause the program to fail intermittently, but routinely, at startup. Personally, I'd remove those locks and document more clearly what is being used when. You could justify the use of locks that way with a handwave at being paranoid, but I'd personally rather see it correct and well-documented than merely paranoid. YMMV (no sarcasm; there's a time and a place for paranoia).
&gt; My rough definition is "a type that refers to some data". That's my point. You disagree with the specific definition of "reference" in the article. But to discuss Go's reference types, or rather, the absence thereof, we first need to have a common definition of "reference". 
Have you also read the rest of my comment? I think I give pretty good arguments of why a) the definition that Dave gives isn't universally accepted, b) even if it was, his arguments don't make a lot of sense and c) even if it was and they would, it's still dickish to tell people they are "wrong", if they are obviously just thinking of a different thing than you, without actually taking *what* they are thinking into account, *especially* if there isn't a very good universal definition anyway.
I wouldn't call this "portable" when you have to depend on a couple of python scripts and a complete python environment just to run them.. When I did a small mail project I used https://godoc.org/bitbucket.org/chrj/smtpd with great success. There's also https://godoc.org/github.com/bradfitz/go-smtpd/smtpd, which is a simpler SMTP server.
I like Atom a lot actually. Its just simple, VS Code is quite nice as well i guess it was just which I used first.
oh I just googled Gogland and its the new in work JetBrains IDE. Yeah, im pretty pumped for that, but ill probably wait until they work out most of the bugs.
yeah I installed the Atom terminal plugin, built in terminal but seem to always default back to two monitors and iTerm on one and Atom on the other.
I use it daily at work, and I've found it to be rock solid. 
Vim-go should be using goimports instead of gofmt. That pretty much takes care of most of what you just said.
Yes, I did, and I first wrote a lengthy reply but then I figured it might not lead anywhere, as our standpoints are just too far apart. But now that you ask: a) The definition is indeed only one of several, but C++ is not exactly a niche language, and I believe that many who struggle with the term "reference" in Go have a background in C++ or Java, so the definition used in the article absolutely makes sense in this context. If your point is that the article should have used a different definition of "reference" in the first place in order to address a broader audience, then maybe you are right, but this does not make the whole article wrong. b) I beg to differ. Based on using the C++ definition of "reference", the rest of the article does make sense to me. c) I don't want to start an argument on this point. Maybe you have better senses for emotional nuances than I have. I have read the article with a nerd's mind, as I always do with technical articles, filtering out only the factual content while giving not so much attention to the tone of the article. I only can say I did not notice any dickishness, nor did I read "you are wrong" between the lines. In summary I think we can safely agree to disagree.
Nice to hear that. You are welcome to ask for features If you find the library lacking.
Thanks!
I am working on my own version of server sessions and have a slightly different design. If the session middleware is used it always creates/retrieves session for the client. That allows me to track anonymous sessions as well as authenticated. If a user logs-in then it associates user data with the session. Logout clears the user data from session or reissues a clean session depending on configuration. Just an idea that you may find useful. 
Where is this code from, out of curiosity?
Interesting, I like the idea of using anonymous sessions. Probably has some pro's / con's to simply logging anonymous usage.
Ah yes! It's a hugo theme I've just used and never actually thought about https, it's a blog without any special user interaction. From around 2001 till late 2015, I've enjoyed C# and .NET in general! And I like the idea of Extension Methods because they made LINQ possible. There was a time that I was telling to myself "What would I do without LINQ?"! And wrote some LINQ providers, actually a bit obsessively, triggered by (say) LINQ to The Simpsons and posts/videos like that. The only similarity between Go interfaces and Extension Methods here is, you do not have to implement them explicitly. And that's a big deal, the implicit implementation; not "some difference". You can write an interface that an existing type in another package have already implemented it, without explicitly implementing it. That's not possible in C# (or Java or most of statically typed languages today AFAIK; maybe except for some languages like Haskell with complex type systems - disclaimer: I've just played around with Haskell many years ago, when was obsessed with Monads and Cats!). That fundamentally changes how we design our software. And essentially this especial form of interfaces is one of the things that makes Go such a capable programming language, despite being so simple. I've once read James Gosling said he wishes interfaces in Java would be like interfaces in Go - but I could not find it; I would appreciate it if somebody helps with this. Combined with Go's data structure composition (embedding structs), you can actually open many different possibilities to a problem at hand to achieve a nice solution that allows you to treat many different existing types in a homogeneous way. That's another interesting aspect of Go which eliminates the need for Generics to a great extent - but I would not mind some tiny bits of generics! Or maybe I do not need them! 
Systemd is pretty straightforward and your service config file will be short. I am using that to deploy my `go` projects. I am proxying with `nginx`but also tried `caddy`. The latter works perfect to front `go` projects but caused slow downs when fronting PHP over Symfony behind it. That's why I went `nginx`. Do try `systemd`, it's worth it.
My point wasn't that Java is/isn't the best JVM language. I'm saying that consumers of ES don't care that ES is written in Java. Programmatic interaction with ES can come from anywhere that can make an HTTP request.
And the semantic we are experiencing? The final usage? We are speaking about the implementation. We speak about the acting semantics. And slice is a built-in wrapper type for array. And here a, b and c are some wrappers for an underlying array. The fact about their implementation has literally no effect on their usage - in Go context.
I just wanted to add that at pressly.com we've been using upper.io/db in production for the last 2+ years and its been absolutely solid and a pleasure to work in. Our engineering team also made numerous contributions to the project and Jose Carlos Nieto (the author of upper) is one of the friendliest, open to feedback, and supportive maintainers I've met that also cares a lot about design and quality.
*Semantically* a slice is different from a reference type because you can modify the length and capacity of a slice assigned to a specific variable and that modification does not affect any other variables. That is, *semantically* it acts like both a reference type and a regular 'value' type: a reference when you modify it by index assignment and a value type when you modify it any other way. The *implementation*–both the spec and the current GC compiler—are not references. Because of this, the only way a slice can accurately called a 'reference type' is if you use the word in the loosest sense (layman's terms) possible.
This was really interesting. I hope this catches on and there will be more videos of people doing code reviews.
Left this bit here to describe the workaround https://github.com/dontpanic92/wxGo/issues/23
&gt; Or you can simply accept, that just because a prominent Gopher said something with authority, doesn't mean that it's actually correct and sensible and adjust your notion of a reference type, when you speak to someone about this the next time. And value helpfulness and common ground over trying to be technically correct at all cost. Yikes. It's a bit presumptuous to assume my notion of what constitutes 'references' and 'reference types' is solely based on what a 'prominent Gopher' said. Further, admonishing me over a relatively benign technical discussion seems a bit much. I've always appreciated your insightful and polite posts on /r/golang, GitHub, etc. but I take issue with this mischaracterization of me.
Did you consider any other ORM/orm-like packages? xorm, gorm, etc. Really interesting in a comparation.
I suppose it's application-dependent. I'm inclined to give my handlers the benefit of the doubt and let them finish.
you can try intellij idea with golang plugin installed.
I got the Eclipse working with golang plugin, but it was pretty messy to get it to work. I guess things will mature over the years. That's why I was curious on what they used though.
Also using Gogland on Mac, its pretty solid.
Explanation: This is a rare case in Go where something like a C prototype is needed. At the time you call fib inside the function you are defining, the compiler does not yet know what its signature is. By making the fib variable first, and letting it start with a zero value, when you come back to set it later the thing you set it to (the anonymous function) can refer to it, since it already has a type set. -jeff
In the README.md's screencast there are some duplicated authors, you may want to filter out entries with @noreply.github.com if the author name duplicates. 
Not anymore. https://spatialos.improbable.io/games/grpc-web-moving-past-restjson-towards-type-safe-web-apis
I'm learning golang, this really inspired me.
We have been testing Flashphoner WebRTC-RTMP converter. Worked stable on our tests. If WebRTC endpoint uses VP8, it requires video transcoding because RTMP generally works with H.264. https://flashphoner.com/webrtc-as-rtmp-re-publishing 
I would say there is noticeable difference between eclipse and intellij idea, I would strongly recommend it as it got huge community out there
Sure, the substance being drinked and the amount of tears collected in the bath, depends on the libraries and languages. But I've yet to see language/library to completely eliminate the pain. Of course when you don't have to deal with them there isn't a problem.
I had read that the dev for gogland was then intellij plugin dev too and he no longer planned to maintain the plugin. Hope I'm wrong here.
I'm lucky to have not had a SOAP endpoint to talk to in two years now. I'd probably be fine with using something on Github. I tend to have good experiences with high traffic libraries such as those used in communications since they get so much testing as soon as you turn it on. The only thing I deal with a lot that I don't want to use go for is talking to Active Directory, but for that I maintain an application in C# which produces a change feed the goes to the Go application (and some .Net Core stuff running on Linux Docker containers).
One other interesting feature for K/V stores is the ability safely do multi-tenancy. With SQL you need to ensure that all queries have a filtering query: SELECT * FROM users WHERE account_id = ? If you forget that limiting *WHERE* clause then you potentially expose data to other accounts. However, if you prepend the account id to the key then you ensure you always work within the context of a single account: accounts/X/users/1 accounts/X/users/2 accounts/Y/users/1
I rarely use gorename on exported identifiers, since it causes a full scan of GOPATH and often fails
Lol..no," doesn't make much difference with what is currently available"
I don't totally agree with the code, but the locking is fine. The locks are encapsulated within the struct. The code creates a new listener, and upon successful creation locks a race vulrenable resource(the resources encapsulated in the struct), then assigns the listener to the struct, and unlocks - all the functionality is contained within the struct. Why add another wrapper func within this initialization func? For more overhead? Or for more indirection? Edit: You know what works better than a downvote? A counter argument...
I fully agree but do not forget that enterprise companies are mostly concerned about being able to quickly hire/fire people. They need you to be replaceable and in certain parts of the world it's difficult to find Go programmers hence most of the companies will want to stick what is defacto standard (C#/Java)
There is no odbc driver for Informix?
[ and ] instead of &lt; and &gt; feel much better IMO
Exactly. It's certainly true that there can be bad boilerplate (and maybe even the majority of boilerplate in the wild is bad), but I've found that boilerplate which comes from Go's syntax is very thoughtful and more helpful than harmful. It's too easy to try and get rid of _all_ boilerplate carelessly, so it's important to counterbalance that instinct.
Well written, I would add the confusion that results if you do len(str) which gives the number of bytes, not runes, vs len([]rune(str)) or the likely more optimal RuneCountXXX() functions in utf8
It did take me a while to figure out how to get freetds and unixodbc working on my mac with SQL Server but it works great. i'm using this ODBC go library github.com/alexbrainman/odbc 
there's a line between simple and simplistic....Go's syntax is simplistic and we constantly pay the copy-paste tax as a result
I've found that when working in enterprisey environments it is often beneficial to isolate the "shitty" parts and then use these isolating services from the rest of the services being actively developed. Using event streams or message queues can be a way to "liberate" otherwise hard to reach data. (I am also a big fan of decoupling services by using JWT:s)
Brilliant point that I completely forgot, I'll be sure to add it in!
This is why I'm driven further and further away from Ruby as time goes on. There's this sense in some groups that if you took three lines to do something you could have done with a single line, you've done it wrong. It doesn't seem to matter how much mental overhead is in the one-liner; brevity is LIFE. I think Object#tap was where I finally realized Ruby and I had to part ways: http://ruby-doc.org/core-2.2.3/Object.html#method-i-tap. A new thing to keep in my head in order to ensure my statements can always be chained, rather than using a temporary variable when needed.
If copy-paste is a tax, then so is building abstractions. There is a sweet spot between always copy-pasting and always abstracting. Abstracting can often be premature (and it's hard to tell when it is until it's too late), and having some _reasonable_ and useful/proportional amount of copy-pasting can help avoid premature abstraction as a counterbalance.
&gt; And it is possible that I'm using the phrase in it's loosest possible form Oh, and that's fair enough. :-)
Just FYI - The link goes to a playlist, so I'm not sure how well the embedded player in reddit is w/ the 2nd video.
When you re-slice an slice it does not need to behave as if it's the original slice. That is not mark of being a reference type (or not being one). Re-slicing is like calling a method on a reference type instance that may return another reference (not necessarily the object instance itself - in C# terms) like say `var newSlice = originalSlice.Reslice();`. However when we assign the variable to another variable like `b := a` and if when we modify `b` it affects `a` then this type has reference type semantics.
&gt; Binary downloads ... Bitbucket Need an account ... :( Is it possible to download without login? ( anonym? ) 
This was a good write up overall, I think a really clear summary that helped me is [runtime/HACKING.md](https://github.com/golang/go/blob/master/src/runtime/HACKING.md). Is the opening statement that the scheduler manages garbage collection accurate? My understanding is the direct relation of the scheduler and GC does not go beyond STW and maybe some gc state that lives on various structs. I know the gc is concurrent and runs goroutines, does gc have dedicated or privileged priority and that's where your statement comes from? It isn't clear to me if gc runs like any other normal goroutines or not, I would be interested in knowing the high level of how (or a link to where) they relate if you get time to share! Thanks.
Interesting article.
This is pretty cool. I really like the idea. can you add a license? And perhaps a link to the lentil program that is referenced here and in the readme?
It has some but it's cumbersome. Looks like a lot of people resigned to use proxies.
I really appreciate the style in which this post is written and how it conveys a leadership philosophy that values people first and code second. Great work!
I didn't mean in regards rewriting your library. I meant did you agree with his conclusion(i.e using io.Reader instead of buffer)
There are a few things that really bug me about Go's syntax, but its simplicity is definitely not one of them. The cognitive overhead of Go is so low that it allows me to focus on solving the problem instead of trying to remember different language constructs and how to fit them together in a way that still makes sense when I read my code again a month or two later. The explicit error handling ensures that I can reason about where errors can occur and how they should be handled instead of worrying that an exception could rear its ugly head at literally any moment. It's such a relief to have that guarantee, so I really couldn't care less about writing `if err != nil` over and over again.
I use a text editor that I wrote and a shell or two. (About half the time sh on DragonFlyBSD and half the time rc on 9front.) I suspect I'm in the minority.
Thanks for motivating me to try again. Updated unixodbc to a newer version, found some a hint on SO from someone who had gotten it working recently (UNICODE=UCS-2), and it's working! Just had to wait a bit for smarter people than me to hit the same problems and come up w/ solutions.
After ten years of programming, someone discovers that code golf is not a "best practice". 
&gt; That is not mark of being a reference type (or not being one). Is it? In the C++ example I gave calling `std::vector`'s `resize` method on `b` and `c` (the two `auto&amp;` references) modified the original, yet nobody disputes that in C++ `auto&amp; = ...` is a true reference type. &gt; if when we modify b it affects a then this type has reference type semantics. Right. And previously I'd said: &gt;That is, semantically it acts like both a reference type and a regular 'value' type: a reference when you modify it by index assignment and a value type when you modify it any other way. Lots of types have similarities with reference types, but aren't true reference types (strictly speaking).
Re: sorting, were you aware of the new sort.Slice function: https://godoc.org/sort#example-Slice
Use an httptest.Server if you need to test a client. Otherwise, if you're testing your handler function, just call it directly.
Thanks for the alerts. /u/imresamu, the repo had been created as Private -- it's public now. Sorry about that. /u/localextremae, added a link to lentil in the README, as well as a license.
And graciously goes out of their way to put their experience in writing to help others learn this lesson much earlier. What a dink!
Perhaps Donald Knuth's notion of teaching programming using assembly language was not actually such a bad idea. 
last time I checked was ~2 years ago, project seemed dead. good to see it's alive. Question about ID, mongodb usually uses bson.ObjectID, while SQLdbs use auto_increment and int. How does this work, does it autoincrement the ID field in mongodb? Also, unrelated, I really want to like pgsql but even the base setup is a PITA. Idk how people are able work with it. Permission problems all over and no real guide.
It is during these times that I look to a few years back when I decided not to learn Ruby, despite all the hype, and congratulate myself on a good choice. I think I'll go grab a beer.
benbjohnson creator of boltdb (a "storage engine") knows what he's talking about. :) To add to this example there are efficient binary encodings which allow encoding "composite keys" such that using memcmp compares the same as element-by-element comparison of the parts which compose the key. It's the same exact principle that Ben explained above. A good/simple example of this is orderedcode. https://godoc.org/github.com/google/orderedcode
Anyone using it in production?
Especialy as Pythons try catch would need a new block for every check.
I dare say that forgetting the WHERE clause is an absolute beginner's error. The WHERE clause is so essential when constructing a SQL query that I cannot imagine that anyone who has reasonable SQL skills will ever forget that part of the SQL query that implements the desired filtering. So while the data leak problem does exist in SQL, I think it is mostly theoretical.
Looks great, I tried the dep alpha and it worked as intended, but most libraries don't have releases tagged so it's still a little pointless. Again, great work, it's just a real shame it's taken so long I think it's really damaged Go not to have this for so long. If we get a good Go version manager as well then we might be able to bring it out of the stone age. 
Do you have a reference for this The_Sly_Marbo? If you do I'd like to update the article with information from that reference. Thanks.
It's covered in the first few paragraphs of [the blog post you linked to](https://blog.golang.org/strings).
Without dependency manager we have to take care of dependencies and try to don't have to much of them, keep the master branch safe... I hope we will not loose that.
Just out of curiosity, why not just use Goconvey? 
&gt; Without dependency manager we have to take care of dependencies and try to don't have to much of them, keep the master branch safe... &gt; I hope we will not loose that. We *will* lose those unless the dependency tool does something about it but as far as I know it doesn't (except maybe listing the dependencies).
So far I've been fine with just adding a few helper functions. Usually just 6. I made them into a package on their own after they were successful in a project I worked on earlier, but I'm certain there are other similar things out there that are more popular. IIRC the ones I made were based on some from Mitchell Hashimoto. Anyway, this is what I use: https://github.com/SeerUK/assert Then I just use the built-in testing framework, but use sub-tests to make the descriptions a bit easier to read, e.g. func TestSomething(t *testing.T) { t.Run("should foo the bar", func(t *testing.T) { // ... assert.Equal(t, "foo", foo) }) // ... more tests }
It seems like it's been an interesting tool for you to create. But I do think that this is a solved problem thanks to vendoring now. If you're hell-bent on not using vendoring then something like this could be pretty cool, but the main thing holding this back I think is that you have to pass it all of the commands you want to run as a string. This is seriously limiting, because it will prevent things like completions from working when you're using it. That's a HUGE usability detriment over even handling this _manually_. If you could make it so that it just switched your `GOPATH` environment variable, that would make more sense. You would be able to still use the idea of "workspace"-like things to keep some repos together in on `GOPATH`. Something that looks trivial came up on Google as the first result here: http://tammersaleh.com/posts/manage-your-gopath-with-direnv/ The interesting thing with that solution is, you don't have to actually do anything once you've got it set up, it's all automatic. Anyway, I don't mean to crap all over your idea here! I just don't think this is the best way to solve this problem, if you do even consider it a problem anymore. Edit: Also, is this specific to MacOS? Surely Linux support would be super easy too?
You can use interfaces to build very testable code. In your case, `archive/tar` and `compress/gzip` use `io.Writer` which means that you can get very far by just passing your code a simple Writer implementation in your test cases, for example to generate an error immediately or after n writes. You shouldn't be unit testing the standard library code, though, so in your case I would only use it to verify that errors are propagated and ultimately handled cleanly. If you have a particular strategy for dealing with the permissions error, you should of course make sure that you test that, but in some cases it is OK or even preferable to deal with error cases more generally. For some applications, just logging and exiting is a viable general error handling strategy.
Alright, that sounds sensible. For tarring, at the moment I've abstracted that away behind another interface and a "factory" to build that interface. I'm not sure how horrible that sounds, but it has greatly simplified the code where it is being used. This is that file as it stands: https://gist.github.com/SeerUK/97c438b778a3e39dcd07333c65b5a926 This is an example of where it's used: https://gist.github.com/SeerUK/58c1d5d5545b104495e5e859b0ec451f So, you can see I've already created that wrapper for the filesystem, I suppose this is a similar thing I'm doing now with archiving. Though in this case, the abstraction does feel a bit more useful, because I could make it possible to choose an archive format easier this way and share the interface. That function in the second file is totally covered by tests now, and I believe it should be easier now to test the tarring in isolation, as you'd mentioned, potentially by using a different writer. I believe the tar.Writer type does have some special methods on for writing the header however... I just wanted to make sure I'm not going insanely over-the-top by making these interfaces and abstractions for what feels a little bit like the sake of coverage.
I will admit that I have simplified the post considerably. I would hope that most people would read the full post at golang.org, and maybe I should have made that hope clearer, but I have aimed my articles at those (like the friend I targetted the post at) who prefer something shorter. My belief is that most people reading my article (as opposed to reading the full one) would only be interested in operating on the UTF-8 version of the characters. If a person isn't interested enough to read the full article but after reading my article understood the potential pitfalls of operating on the raw bytes, then my article has achieved it's purpose. I do understand the point you're making but my feeling is if I was to go into all the context involved, it de-values the worth of the post to the intended audience as they may as well read the one at golang.org. This post is meant to just fill some gaps in the potential pitfalls without repeating what's already out there in a more verbose and complete form.
Looks really cool. Great job. I just followed the getting-started and sample project however ran out of "too many open files" when importing the csv files. I am on mac and the ulimit -n is only 256 will try to adjust. Also is there any cursor or paging function in the query methods, i cant find anything about it but seems useful. Anyway, looks very useful, thanks =)
This is an excellent write-up. Thank you for taking the time to do so! The `compress/gzip` usage is only for writing at present (though I may expand to reading in the future). Did you get a chance to look at the files I linked in another comment? They show how I'm handling the interfacing and abstraction at the moment - it might be close to what you mean here. I feel like I've been unable so far to use more generic interfaces like `io.Reader` / `io.Writer` / `io.Closer` (and the combinations) effectively, because of methods like [`Writer.WriteHeader`](https://golang.org/pkg/archive/tar/#Writer.WriteHeader), but perhaps I'm just trying to abstract this at the wrong point...
Cursors or paging is not supported yet, but we are considering ways to limit the data in the response in an efficient way.
Thanks! I haven't seen *orderedcode* before. That's cool. I typically build my indexes by hand with a K/V store. That might sound crazy but it's pretty straightforward. For example, in Bolt, I'll use a bucket as a foreign key one-to-many index where the key is a 16-byte byte slice -- the first 8 bytes for the parent ID and the second 8 bytes for the child ID. You can loop over a list of the parent's relationships like this: prefix := make([]byte, 8) binary.BigEndian.PutUint64(prefix, parentID) cur := bkt.Cursor() for k, v := cur.Seek(prefix); bytes.HasPrefix(prefix); k, v = cur.Next() { childID := binary.BigEndian.Uint64(prefix[8:]) // do something... } 
&gt; But I do think that this is a solved problem thanks to vendoring now I feel like vendoring is totally orthogonal to this. Vendoring is a way to manage dependencies, project based workflow is a way to organise your source code the way *you* want instead of how Rob Pike has decided is supposedly best.
I almost always use *httptest.Server*. It doesn't add much overhead and it lets your requests go through the full server lifecycle rather than trying to construct the *http.Request* yourself.
Use systemd / upstart / supervisord for that.
We are one of the largest game companies in the industry. I've centered my entire org around using golang for infrastructure automation, monitoring, and orchestration. It has worked very well. The cross-compilation is a huge win for our needs as is the quick compile time and binary distribution of said packages. The language is easy to learn and thus even those that have never programmed before are able to pick it up and start making contributions. To me Go is a better C with an python-like ease of entry.
It doesn't look like you actually need a WriteCloser on that level of abstraction; you only ever use the Writer functionality on the `os.File` in `Build`, immediately passing it into the tarball writer. You only Close the actual file in the caller. I think it's correct to only let the caller close the stream, since it is also responsible for opening it. As for comments on the level of abstraction, I think it's easy to understand the intent and follow the code, but instead of using a factory interface I'd prefer a slice of builder+extension pairs indexed by an identifying enumerator. That obviates creating empty struct types like `TarGzArtifactFactory` for each artifact type and implementing the Extension method, while clearly listing the Artifact backends and their respective extensions in one place.
&gt; We are one of the largest game companies in the industry. Which company?
Yeah, and that is a completely subjective thing. I suppose that's just how I personally deal with multiple projects (... by not doing, in a way). I can definitely understand the attraction to working with different GOPATHs, but for me, vendoring is something I've done in other languages too (or at least something similar), so it makes a lot of sense to me.
Again, with respect, I don't think you've "simplified", I think you've introduced errors. I'd actually rather someone have the "error" you're trying to correct and think strings are basically []byte than to think they're basically []rune; the error in the former is mostly runtime behavior related and will generally treat you better than thinking they are []rune, because at least you'll understand what they can contain, the amount of RAM they will consume, and the computational cost of the various operations you can perform on them correctly _except_ range, whereas thinking of them as a []rune will deceive you about all of those. Even, as evidenced by your post, range, as in your model you expected that to be "free", but it's not. I say this partially because when I first read about Go, the authors of Go made a big deal about strings being UTF-8 encoded. It was therefore a surprise to me when I could stick any ol' bytes I wanted into a string, because a truly UTF-8 encoded string type does not permit that. A UTF-8 encoded string would have to replace non-UTF-8 characters with the [Unicode replacement character](http://www.fileformat.info/info/unicode/char/0fffd/index.htm), or do some other form of normalization like reject it entirely. Strings don't do that. They are therefore not a collection of Unicode codepoints, in _any_ encoding. They are a sequence of bytes. I also, again with all due respect, want to point out that a number of claims I'm making in this reply are _objectively true_. Strings _can_ contain arbitrary byte sequences that are not any correct Unicode codepoint in any encoding. To falsify this statement you'd have to produce a []byte string that can not be contained in a string. Strings are therefore not any sort of Unicode string due to the fact they do not enforce any Unicode property in any way, because any sensible definition of "A unicode string" would have to encompass having _some_ sort of validation of the properties of Unicode. Strings _do_ have memory consumption patterns more like []byte than []rune, which is easy to verify by runtime inspection. The only point of opinion here is how to interpret string's behavior in range statements; almost everything else I'm saying is objectively true. I do apologize, I'm not trying to be a jerk, but there's only so much sugar I can wrap around this sort of thing, and this is exactly the sort of thing that has a way of getting out into a community and becoming urban legend.
There's no XPath and no XML normalization, which means you can't properly implement XML signature and encryption, which means you can't implement SAML, which is commonly used for enterprise single sign-on.
Love it! I noticed there is an option for protobuf responses, any chance of a full gRPC setup in the future?
Very interesting. Is there any chance you'll extract the 64bit implementation of roaring bitmaps? i.e. make it available as a standalone package or contribute back to upstream?
In your own code, with your own objects, you can always replace a use of some object with an interface. Even statically-accessed values can be routed through a "getter" instead.[1] Where you do end up in some trouble is if a foreign library absolutely insists on taking its own type, and you're stuck in your test code either setting up whatever that expects, or skipping the test. For file system stuff, I tend to go with the former, grabbing a temporary directory and mangling it with whatever I need and deleting it with a "defer" to ensure I don't miss it. For most other things, I do the latter. In one case I cracked open the target library and made a local modification to make it take an interface, though. Because, per my first paragraph, a library can always be made to take an interface instead of a local concrete instance. I like external libraries that come via source, and while I try not to modify them at the drop of a hat because that causes its own problems, it is OK to sometimes reach in and hack them to do something else you need. With just a bit of care and git knowhow, it's not even necessarily that hard to stay up-to-date with minor release changes. [1]: "Getter" can get a bit of a bad rap. One pattern I've had a few times is that something will have a "Name() string" method of some sort, and in _many_ implementation that will be a "pure getter" that just "return obj.Name"s. But then I always seem to end up with an implementation that does something more complicated. So, anyhow, don't be afraid to put the odd "getter" into your interfaces.
Ok, but this class of error is only impossible because K/V queries lack the expressiveness of SQL. (Correct me if I am wrong - maybe I underestimate the features of the latest K/V database models.) What I mean is, you have to trade in power for safety. 
It should be possible to use the same approach. Lambda's API is a fair amount more complicated, so more would have to be implemented in Go.
Something like that indeed, though I would still define the builders outside the array initializer. I'm not sure that I understand your access concern, but I would just make `builders` public. One nasty effect of this approach is that you need to make sure that the indices match the enum values manually. There's nothing like designated initializers in C99, where you can name indices during initialization and present them in any order. This can be solved by making the array a slice and initialize it in a function, or you can use a map instead.
I hope at some point they actually do release this officially. It would be so useful.
The go view point is to treat errors as part of your code and program around and with them, so yes you should treat and test it just like you would any other code.
Yeah I guess I just wanted to hear that from someone else. This means that I will have to setup and teardown a database within my local mysql installation then delete and create a table to test these two little error handlers. As this is a personal project, I find this exercise valuable. Thanks for the response. 
I'm working on a small project that uses elasticsearch and MongoDB. I realized pretty quickly I could drop the second dependency and just use elasticsearch for persistance, so I made a small library to facilitate that over an existing elasticsearch client library. This is an initial release so please go easy on it :).
In AWS lambda you can use https://github.com/eawsy/aws-lambda-go-shim
Yes, you should be building a package to be used by a package manager, and you should be putting that package into a local repository for your Linux machines to reach. Installation on the servers should be handled by "yum install mypackage" or "apt install mypackage" and nothing more complicated. That package should include any needed systemd/upstart/whatever files to make all the magic happen, and should have dependencies properly specified. You want ease of installation and repeatability for the people who admin the servers 
I've done it two ways: an additional `install.sh` and self-install. The latter is `sudo` running executable with respective arguments (`install` commandl and options) to create a respective service file for `systemd`. It's not as flexible as one could wish but, given a limited set of environments I deploy to, it works and reduces number of files to deploy. You also don't need to run it like that and can configure everything manually if you wish. Using target system packaging (deb, rpm) is better because: - you may have dependencies on other packages - you can perform a clean removal or reinstall
Thanks!!
HA! Brilliant. I'm using [httpmock](https://github.com/jarcoal/httpmock) for some request tests, but it didn't occur to me to look for a sql mock. Thank you very much. 
Didn't sound rude, don't worry. It does matter because if (hopefully when) I have to hire more Go developers, if a consensus for this exists, it is more likely that they will already also know how to deal with it. And yes, I've been leaning towards TOML but not for the same reason. I will probably use it because dep also uses it and it is on its way to become an official tool, meaning that if it is preferred by an official tool, it, probably, is doing something right.
It's more of the right tool for the right job. If you want great performance, then I would say go with golang. Most compiled languages will going to be good for this. If that's not a key thing for you, then any interpreted language is for you.
Absolutely not! Go is really easy to program in.
I don't really blog, so no. The reason for the performance difference is that a `string` is the same as a `[]byte`, so casting doesn't involve much work (although a copy is taken, so it will normally allocate). Casting to a `[]rune` means parsing the data and building up the slice sequentially (or in two passes, which is what the `utf8` package does IIRC). This also means allocating (and is almost always less memory efficient), and involves actual work and take lookups.
If you're OK with it, I'll post this as a kind of follow up blog in the coming weeks and I'll link back to you and this thread as the source.
Sure, fine by me
Althought the OP asked specifically about ruby, I think is worth mentioning that Python is very easy to learn, has a great community and because is more popular than ruby easier to find answers to problems/questions.
&gt; then we might be able to bring it out of the stone age Not before we get generics. But it's a step forward.
I find Cobra and Viper to be very nice to use. They're idiomatic and used by some of the big names in the community.
One thing TOML has going for it is that, at the moment, it is the config syntax choice for dep, the candidate for the official dependancy management tool. If that all sticks, TOML would likely make it into the stdlib. It isn't much, but it is a thin edge.
Thank you!
I've always felt that Python and Go are quite similar in their approach to programming and design philosophy, even though it's obviously a very different language. "The Zen of Python" applies equally well to Go and its community: &gt; Beautiful is better than ugly. &gt; Explicit is better than implicit. &gt; Simple is better than complex. &gt; Complex is better than complicated. &gt; Flat is better than nested. &gt; Sparse is better than dense. &gt; Readability counts. &gt; Special cases aren't special enough to break the rules. &gt; Although practicality beats purity. &gt; Errors should never pass silently. &gt; Unless explicitly silenced. &gt; In the face of ambiguity, refuse the temptation to guess. &gt; There should be one-- and preferably only one --obvious way to do it. &gt; Although that way may not be obvious at first unless you're Dutch. &gt; Now is better than never. &gt; Although never is often better than *right* now. &gt; If the implementation is hard to explain, it's a bad idea. &gt; If the implementation is easy to explain, it may be a good idea. &gt; Namespaces are one honking great idea -- let's do more of those! That being said, I like Ruby as well. 
Seconded, this looks great. Nice job!
I don't think so but it depends on what you mean by harder. In terms of the language itself, I think go is more explicit and overall an easier language. Ruby has WAY more libraries and support around it, so the environment is easier.
I'm pretty sure I want to attend, but the Gophercon site is making it hard to decide. Is there somewhere I can see the speaking schedule? Is there one place I can see all the topics being presented? Clicking through to every speaker is getting old fast. What's "community day"? It's never explained, just mentioned as a perk in a couple places.
We're always open to issues for discussing possible concrete approaches to this :)
This is how things should be done. If you want to rewrite x in x language like a post made only weeks ago, do it. Don't force it on the original product maintainers to do it. You rewrite it and give it only the features you need.
[Another Curl alternative](https://github.com/astaxie/bat)
a map isnt the right structure, because maps/dicts are not ordered usually (or its not guarenteed ordered in all langs, not sure about go tbh) for ease, typically you would use 2 maps `multiCharStrs` and `singleCharStrings`, or use an array, or use an ordered map the reason is you have to match the multi char first and replace them first, then you can process the single chars [so you need ordered map] so simply: multicharmap := map[string]string { ... } rest := map[string]string{ ... } for k,v := range multicharmap { // match, replace } for k,v := range rest { // match, replace } basically u need an array or order-guarenteed map
I wasn't looking for contributors originally. But I will accept pull requests if people are interested.
This was the most helpful resource in getting me started with the golang fundamentals https://gobyexample.com/
I understand, it's important work that needs to happen and thank you for your time and dedication to it. Do you think that a successful dep tool will spark other official tooling projects like a centralised package repository or a Go version manager or a $GOPATH-ectomy? My impression is that just getting consensus that dep needed to happen was a non-trivial task and I'm worried that no one will want to go through the grind of getting agreement on those other things. 
Wait.. Go time #46 recorded on your 46th? 
yeah awesome, i've been looking for non-shitty BB software package for ages, and thought it would be ridiculous to write my own :D
Are you sure that apex project does this? They appear to use child processes.
I found that the best resource was the official Go tour and the Go PKG documentation. Once you understand the basics (slices are awesome, pointers doubly so), then the PKG documentation of the standard library becomes a joy to read, and makes coding in Go extremely easy.
No, it definitely doesn't.
Thanks. The impression I get is that the go team would like to keep the stdlib as concise as possible (which I think makes sense). If community packages aren't suitable then potentially the go team could create a TOML package that lives outside the stdlib. The dep tool currently uses https://github.com/pelletier/go-toml and why not? 
I answered a similar question just 10 minutes ago, so I'll copy+paste: My theory goes that you should only enforce test coverage where the error actually originates from. When you're just returning an error from another function, you should assume that function is properly tested. That's why I created courtney, which: * Runs tests in multiple packages with coverage * Merges the coverage files * Excludes blocks with panics * Excludes blocks that return an error that has been tested to be non-nil (see the readme for more details about how this works) * Excludes blocks annotated with a "notest" comment What you're left with is the really critical code-paths, and once you reach 100% code coverage you can add the -e (enforce) flag to the courtney command - this will throw an error if there's any code without coverage. Let me know what you think: https://github.com/dave/courtney
Maybe not, but if dep gets rolled into the standard toolset, and dep uses TOML config files and therefore has a TOML parser built in, it'd be a pretty strong case to include the TOML library in stdlib. It'd need to be in there somewhere to build dep, but, yeah, they could have the library built into the toolset and yet not accessible to developers.
This does look very useful! I must admit, I still wouldn't be able to shake the feeling that I'd be sort of cheating by doing this. It's strange though because when you do think about how errors are handled in other languages, with things like exceptions, you don't have to "cover" those in your tests when they're being propagated up... I'll have to give this some thought, but I tried it out and it works great. It's very nice having all of the packages' coverage reports in one place!
can easily recommend Viper