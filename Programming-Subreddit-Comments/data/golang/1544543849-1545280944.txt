[removed]
if your build requires the internet say good bye to your ISO-9000 certification
[removed]
Autocert does have a Cache interface which allows someone to coordinate with a loadbalancer. 
Those two approaches do different things though. Go build will build the project with the dependencies currently defined in go.mod. It will add any missing dependencies but will not update any existing dependencies in the go.mod file. Go mod -u ./... Will update all dependencies. 
The main thing missing from this article is explaining the fact that semantic versioning is assumed for all projects and that go get -u will only update dependencies up to the latest for that major version. Changing major versions feels more like changing what package you depend on more than it feels like updating, and it really should be viewed that way because a major version bump changes the packages API in some way. 
While I can agree that error handling is a fundamental, it makes sense to teach a newbie in Go how to handle there errors. Later I would expect them to know they need to handle errors and give them code exactly like this to just show them how to do a task. This clearly isn't much more than reference material. Which is fine for what it is. 
I believe it is not sufficient for coordination and synchronization; only for storage of assets.
I see vendoring being helpful if you have, e.g., a repo that you don't update for a year at a time, but don't want to break when you do come back to it. But for repos you use regularly, if someone pulls a leftpad and removes a package you depend on, you can just fish the last stable version out of your go mod cache and put it up in a fork yourself, so vendoring just adds a lot of git noise for little benefit.
There's also https://github.com/rogpeppe/gohack
&gt;That being said, the whole point of modules is to not have to put your code in the gopath, so don’t do that. This is not true.
How would you feel about a bare-bones, boltdb/bbolt (atomic) interface? It's small enough it might be worth including inside the repo given how battle-tested the engine is. Then again, the existing [FileStorage](https://github.com/mholt/certmagic/blob/master/filestorage.go) is close enough for a small number of sites. It's conceivable a large install would have thousands of `.local/share/certmagic/*` files.
There's a much better article which also explains how to update modules: https://roberto.selbach.ca/intro-to-go-modules/
I'm going to talk to both sides here, but in summary I agree with you: **From the authors perspective:** examples such as printing "Hello, world!" or displaying the name of a cat are too far removed from "a real project" to feel real. It's very rare for a project to be as simple as the aforementioned examples. **From your perspective:** there is a *very* legitimate concern that something as minor as the misuse of terminology could teach newer programmers / Gophers that hashing = encryption. &amp;#x200B; I don't think you're wrong; terminology is vital to communicating and I would argue any tutorial / article should be written with the care that all information contained within is accurate at the time of writing. That being said I do feel you're final sentence is unnecessary and potentially hurtful. Perhaps the author genuinely didn't know any better? We were all new once, and while it's important to step up and correct misinformation it is entirely within our hands to do so on a polite and respectful manner. Just my two-cents as a dude who saw value in the core concepts of the article, considering the example was mostly arbitrary :)
separate if statements? it's bad practice though
You can have it on two different lines of you avoid using the format utility: https://play.golang.org/p/hc5WAHqplMA But... I don't think that's what you want, so I think the actual answer for what you want would include different format around the brackets too. In that case: No, I don't believe so. Go will insert an implicit semi-colon so that you don't have to. That changes the meaning of the if statement if you don't give it a syntactical reason to look further. Go has taken the approach of being somewhat opinionated about the fairly unimportant decisions so that we can spend most our brainpower on the complex ones, while letting our brains rest on uniform syntax stylings. The community doesn't make any statement that this specific choice is "right" or "better", but the choice to make it a uniform format has been seen as important.
Aye, good points: shut up and put up ;)
The default FileStorage is sufficient for thousands of sites, if not more -- and has been used in production to that extent already by several instances I'm aware of. Shouldn't be a problem. I'd like to keep extra storage and sync implementations out of the repo at this time, but definitely tell me if you write one, and then I will link to it so people can find it! I'll add a section to the readme for it. Consider making it a Caddy plugin, too. :) I'm adding first-class plugin support to Caddy for these kinds of things today. I'll have instructions soon -- will be very easy, just a few lines of code to plug it in.
Seriously though, unlearning the indoctrination of a stylistic choices is the hardest shit. If i was forced to actually write the code that go fmt generates stylistically, I just simply would not. Luckily I can just write the code however and go fmt just makes it perfect. Rebelling against stylistic choices chosen for it misses the bigger picture: you can stop caring because it's such an unimportant part of programming as long as its consistent it's fine.
There are no room for crap in engineering. Shall I repeat, "Seriously, it is not that hard to use the correct terms."
This horse has already been beaten to death: https://groups.google.com/d/topic/golang-nuts/rzLzp_Z74ik Please, there's no need to bring back yet another discussion. Read the reference one above, instead, please. 
there’s a good reason for that and it has to do with how Raft works. When 2 out of 3 nodes go down, there’s no way to reach a consensus anymore (the one left doesn’t know if the others went down or if it’s just a temporary network issue). What if the other two are actually fine, and the one server left is having network problems (a netsplit scenario), imagine if the one guy left decides to become the leader, and at the same time, one of the two servers on the other side of the netsplit also decide the same! it’s best to have no leader at all than two leaders (and end up with inconsistencies). If you need to down two nodes at any given time, you solve that by having 5 total nodes. Read more about “raft consensus” to get a better idea of how it works, it’s actually pretty cool and useful if you want to build distributed, resilient services!
what are you trying to benchmark? just timing of specific functions? 
You can use switch/case instead. I think they look better.
Can someone explain to me the benefits of doing this (building inside the image) versus just building locally and packing it into an image. In the case of a service that doesn't require TLS, you don't even really need more than that. If you do need that, then just dropping the binary into a slim alpine container works fine.
I've gotten really good at having my code style preferences be contextual. Part of that might be that I've had jobs where I've used a large array of languages, so I've had very different look-and-feel between Python, Go, C#, and TypeScript code sometimes all in the same week of work if it's a crazy week. Also, I was a marketing major, so my career was built less neatly than some. However, I have a lot of peers that hate syntax choices when they jump languages (for instance, placement of Python's doc strings, or forced bracket alignment in Go), so I know it really bugs some people, but there's just too many opinions out there to be happy unless you put your need for consistency in boxes.
While I think the comment "The introduction of gofmt is precisely to avoid discussion of relative merits of each one's style." is a great summary, I'm not sure what someone would Google to realize it's a widely discussed topic, and I don't mind rehashing the topic. :)
your dependency \`[github.com/xenolf/lego\`](https://github.com/xenolf/lego`) should release a new version with current changes in order to switch your project to Go modules.
It's a very simple language with great tooling. I'm not entirely sure what you want to know from us that's not already googleable, so check these out. tour.golang.org gobyexample.com play.golang.org
If you haven't written any C/C++ then pass-by-value and pointers might be confusing at first.
Can you provide more context, even some code? &gt;I need to be able to work with the data in items that will come to me in a slice, and I will not necessarily know the types of what is actually in the slice until it arrives! How does the data "come to you"? You say it's a slice, so obiously there is some Go code creating that slice. Does it come through a method/function or a channel? Reflexion is rarely needed. Also, in your case, it could be enough to do just a [type assertion](https://tour.golang.org/methods/15), but I'd avoid even that if I can.
[removed]
[removed]
Hey, thanks for replying! :) Well, the trouble is that the company I work for is using code generation (custom generation at that! :( ) in order to arrive at this. &amp;#x200B; I've had real problems asking this question for some reason, I think because it is such a weird problem to be having. &amp;#x200B; Essentially I would even be happy with being able to just get an answer to the following : &amp;#x200B; If I have the following code, which detects the "kind" to at least see the slice I am working with : &amp;#x200B; `switch typeKind{` `case "slice":` `fmt.Println("THIS IS A SLICE, AND I NEED TO DO SOMETHING!")` `case "int":` `value := reflect.ValueOf(&amp;st).Elem().FieldByName(column).Int()` `fmt.Println(value)` `case "string":` `value := reflect.ValueOf(&amp;st).Elem().FieldByName(column).String()` `fmt.Println(value)` `default:` `fmt.Println("not a kind I am handling yet!")` `}` &amp;#x200B; In the block above, I'd like to be able to be in that slice section (which works, I do get it there when dealing with a slice - I am using reflection to get that value) - but then in this code, I don't really know what types I am dealing with - I need to be able to iterate this slice and dump the data.
I don't think this can be answered definitively, so I'll share what I've noticed as relates to me. Golang would have been a bad first language, because the beginner books, at least the ones, I've seen, are of the we assume you know how to program and will be focusing on the language type books. Same thing with community, this group is very helpful but the threads seem pretty much of the know how to program already kind. So if you are brand I new, I'd suggest you pick up Python first, because it's now lingua franca for getting in to programming for number of good reasons, and the available resources on web and on the book shelf reflect that reality. It's also an extremely useful multi-purpose language. At that point, you most certainly \*can\* learn Golang. &amp;#x200B; (For one, I'm really happy I learned C and Java first because those languages feature prominently things that are more subtle in Golang, and sometimes it's easier to wrap your head around concepts when they are front and centered) &amp;#x200B;
It does show it.. go get -u &lt;url&gt; same way you get lib, you get its update. Is that not right?
I'm glad that I learnt and got my hands dirty with C before trying out on any other language. Personally, I find it to be the best to learn how computers work. Maybe not the best choice for amateurs/people without background in computer science
Then what is?
So I am very new to Go still..but if you change the major version.. would you basically replace (or remove then add) the new major version.. then build to ensure your project still builds/runs with the updated version and nothing broke?
I've used [go-critic](https://github.com/go-critic/go-critic) and found it very useful.
One goroutine to fetch the items on the desired schedule. A context.Context for the timeout for this batch. A select statement feeding an (unbuffered) channel with more work, or catching the timeout and handling it appropriately. The puller can put the work back, or a worker goroutine can time out and put the work back. Depending on what you're doing, you may need a "wrapper" goroutine watching for that case. &gt; - When you get X items, how would you ensure N goroutines have them in a fair manner (some might be busy, and it might be blocking) Unbuffered channels already provide this functionality. An item can't go down the channel unless someone is actively taking it. (It is often a mistake to use a buffered channel, because you lose this guarantee, and it's a big loss.) Depending on the nature of the work, you may need to spin up more goroutines than you might expect to do the job. Most of the things you'll cite as disadvantages for such a "naive" approach are actually advantages, or the possibility of doing it better is illusory. There's a lot of crazy things you can do to try to "improve" the situation that won't actually improve the situation when you're running real code.
Ouch, it's out [https://blog.gopheracademy.com/advent-2018/go-webgl](https://blog.gopheracademy.com/advent-2018/go-webgl/)
[https://blog.gopheracademy.com/advent-2018/go-webgl/](https://blog.gopheracademy.com/advent-2018/go-webgl/)
Go has no covariance or contravariance, which means that if a function takes `[]interface{}`, all it can receive is exactly that type. It's impossible using the Go type system to write "a function that takes a slice of 'something'" at this time. That will change with generics but those are a ways off yet. You can, as you see, use reflect to bypass the Go type system, but it's a pain. Sometimes you can solve this by restructuring your code and clever use of closures, though. Or sometimes you can just unwind the processing loop at the level that has a `[]ConcreteType`. For example, a "map" operation should just be written with a loop. You'd have to be more concrete about your exact structure to get better ideas. Abstractly I can only offer you [this blog post of mine](http://www.jerf.org/iri/post/2945).
HOLA Y SUBSCRIBANSE A MI CNAL DE YOU TUBE PORFA
You need to replace all import statements of that package with the new version (append or update `/vX` to the import path) and update your code to conform to the new API of the package. Don't forget the imports in your tests as well. The next time you build, the new dependency will be detected, downloaded and built. If you have removed all dependencies of the old major version then running `go mod tidy` will remove the old package version from the list of dependencies. If it is still listed after running go mod tidy then it's still being imported somewhere or it is an "// indirect" dependency by being used by another package you depend on that isn't using go modules yet. 
The question is one of build environments. Is my local build the same as yours? Do I have the same compiler version, libraries, etc... Moving to a build in a container (ideally having it pull source rather than copying from local) produces a build system that is repeatable. My build in a docker container is identical to yours. Local variations from developer environments don’t impact the build. 
Wow you obviously habe no idea what you are talking about and are very narrow minded. 
I see. So, if I'm using Docker purely for production deployment and I don't care about the build (i.e. I'm the only one ever building or the build server is the only one ever building), then it doesn't seem like there's much benefit. But, if there are many people who might run a build, then helps to ensure that the entire toolchain is identical (compiler, dependent libraries, etc...). Am I understanding that right?
I care
That is correct. I’m mostly Java and doing a dockerized build from source means that local installs of libraries, or differences between jvm builds are a non issue. Sure, can have everyone always pull artifacts from the build server, but making it so that the build server and developers build the same way always is even better. I’ve had more than one occasion where one developer had an updated file in a snapshot dependency and that build wasn’t the same, or was working from an older build file and hadn’t updated from version control... things like that. If you are just grabbing the artifact and deploying that, it isn’t as much of an issue. 
These are indeed issues and vendoring was effectively the only way until recently. Project Athens looks to be a better way once it is embraced: https://medium.com/@arschles/project-athens-c80606497ce1
Got it! Thanks for the clear explanation.
I think what you are looking for is var elemT reflect.Type = reflect.TypeOf(input).Elem() So for an []int you get a Type value wrapping int. Notice that Elem here is a method of reflect.Type and is not the same as reflect.Value.Elem which dereferences a pointer.
Still seems like [type assertions](https://play.golang.org/p/KyLX4U2LeXB) are enough. I don't know the details of the surrounding code, especially the generated code, but existing code can be a hassle to work with. &amp;#x200B; I am maintaining a code base where someone thought it could be good idea to use `map[string]interface{}` instead of structs to pass data around, then using type assertions without error handling everywhere.
What [shagieIsMe](https://www.reddit.com/user/shagieIsMe) said is exactly the main reason for building the code within the container. We have around 25 Teamcity agents in our company and none of them even has Go installed. With this technique, no matter what language we use, we only need to make sure that all the build machines have Docker installed on them. And you are absolutely right, if "you are using Docker purely for production deployment and you don't care about the build" you can simply pick any base image, chuck the binary in, and you are good to go. :)
&gt; kablamo.com.au/blog-1... Next request: a *simple way* of generating [semantic versions](https://golang.org/cmd/go/#hdr-Module_compatibility_and_semantic_versioning) direct 'requires' for package fubar that don't have tags, or have tags like 'previous_version', or tags like 'v.2.1.2 on repos that aren't called fubar/v2. Versions like *v2.0.0-20180326061214-4fc5987536ef*. Currently the way I do it is setup a new project that will use fubar as an indirect require, and go modules will calculate it for me when it generates the '// indirect' 
You can read rsc's blog series about it for the full story (https://research.swtch.com/vgo-intro), but the primary motivation is handling package versioning. Taking the opportunity to address frustrations with GOPATH was incidental.
Just what kind of questions do you ask them, I'm more a .NET person so wondering what are the basics you're asking. "What is a goroutine?"
does the tidy command go through your code and figure out what module you may import that is not used in your code anywhere, to remove it? Wasnt aware it was that capable. I come from Java where there is a special maven plugin that can do this, but its pretty common to see bloated unused libs/code. Would be awesome if go had the ability to completely remove code not used at all at build time.
beowulf_71 search for __'+incompatible' when importing non-module v2+ packages__ to understand better the issue. It can be messy...
Isn't Athens just a cache server that I can run myself and configure go mod to point to it? At the end of the day it's just another cache, except now I'll have another unreliable point of failure in my build system. Don't get me wrong, it is useful in large teams but by no means a replacement for /vendor. If memory serves me right, months ago I heard talks about Athens also becoming a central repository like npm but for Go. But haven't heard anything since.
My mistake. I saw the linked post, but did not initially make the connection between webgl (which I have no interest in at the moment) and network layout. Thanks!
Thank you for the heads-up. I added a note to the article to clarify the main point of the writing which seems to be impossible to comprehend for some people for whatever reason. I heard your feedback and I am grateful that you spend your time reading the article. My feedback for you, you could still share your opinions without calling people's work crap and stay polite. Shall I repeat, "Seriously, it is not that hard to be polite and not hurt people".
No worries, I see that post received little attention, probably for the same reason. :)
Ah.. but they have to be removed from the source for tidy to do its work. So it basically scans the import section of the source, it doesnt navigate the source code to see if any refs to the imports are used and remove it based on that. Gotcha.
&gt;TBPixel Thanks for the clarification mate. I updated the tutorial to clarify the in-my-opinion-super-clear fact that the article is not about cryptography. Hopefully "engineering" will have a better day today ;)
Thanks for the feedback dude. Appreciate it.
Thanks mate. :)
Sure. The web page describes this as a prep/setup step, though. And if you want to update versions in go.mod, you can also achieve that a couple of ways without downloading all of the history of all of the dependencies. 
I can relate to this post. Some additional video material that helped me *massively* from the Just For Func YT channel (English lang). I hope pasting YT links isn't bad etiquette (?)... Intro to Go Modules and SemVer: https://www.youtube.com/watch?v=aeF3l-zmPsY Migrating Go Modules to V2+: https://www.youtube.com/watch?v=H_4eRD8aegk 
Basing your image from scratch is usually not the best thing to do. I'll just link to my most recent comment on this from 2 weeks ago in this sub rather than typing it out again. https://www.reddit.com/r/golang/comments/a0ae41/comment/eaghbue
Right. If you want help modifying the import list for a file use goimports 
I think it makes a lot of sense. Specially the security aspect of a minimal image like scratch. I will do a bit of research on that and see how can I word it in the article to make people aware of the possible risks. Thanks for sharing mate.
go toolchain's zealous approach to having properly formatted code does that for you. &amp;#x200B; You can't compile with unused variables and imports. &amp;#x200B; Therefore go mod tidy has an easy job to figure out which dependencies are unused.
http://xyproblem.info
Ugh. Forgot about that. Barely using go as I am learning on what little time I have e at the moment. 
\&gt; a generical type is determined during execution It's the other way around. They only exist during compilation and erased in runtime (with some exceptions). That brings many issues, but performance isn't one of them. As for the question, well, that's the purpose of generics. No generics or language built-ins behaving like generic functions – no solutions without ugly hacks like type casting/reflection all the time.
Your requirements are incomplete. Numbers matter quite a lot. Are you dealing with 10 items/sec or 10MM items/sec? Is your timeout in ns, ms, seconds? &gt; The items have maximum T timeout for processing, otherwise they should be returned with put() I'd also say your requirements are faulty. The producer needs to handle timeouts without help from the consumer, especially when producer and consumer live on separate nodes.
@[mkishere](https://www.reddit.com/user/mkishere) it works for \*NIX OS :) How about getting the value for \*NIX systems? 
It's still weird to me to not only see an open source project from Microsoft, but also one not written in a Microsoft language as well as it being cross platform. 5-10 more years, I expect, before that feeling subsides. Looks like a cool project. I'll need to give it a spin sometime. 
The best part is using the simple and logical _go mod_ instead of the imbecilic _vgo_.
Nice! Nice to see the familiar termbox-go which is used for the gui layer.
I don’t think there is a way (at least a reliable way) of doing it.
Please don't post responses like this. These responses give Go a bad community reputation for new users. Just because something was "beaten to death" doesn't mean new people know the history. More importantly, the previous discussions don't necessarily mean the decision is correct now or impossible to change now. The ultimate Go proof of that is the generics discussions for "Go 2." If you're bothered to the point of needing to post (some comments do pop up a lot), an alternate style might by to link to the discussion and simply say that the link contains insight that, while not giving the answer they want, may help them to understand the history of why.
[removed]
Religion is not circumscribed by time but is rather an interpretive orchestra of its minutia.
Is it necessary that a programmer should know c/c++ to learn other languages? If I learned Python am I good to go with golang? Thank you
What about reading a book? I learned a *lot* from W Richard Stevens "Unix Network Programming." It's outdated now but Stevens has published an update (split into two volumes and pretty expensive.) I'm not sure I would recommend learning another language to learn network programming but if I did, it would probably be using BSD sockets in C on any convenient \*nix. That gets you closest to the underlying mechanisms. Otherwise I'd suggest learning Go on something simple and when you get comfortable with that, add network programming into the mix. A better question might be to ask how to get started programming using Go.
Sure it's possible. 
Bad news, friend: [https://forums.aws.amazon.com/thread.jspa?threadID=291106](https://forums.aws.amazon.com/thread.jspa?threadID=291106)
I use [https://github.com/mattes/migrate](https://github.com/mattes/migrate)
thanks I'll check it out :)
Dude. What? This is effing awesome!
It's not a sending to a channel, it's receiving. time.After() is a function which returns a channel.
Ahhhh Thanks for the clarification! 
Im looking for Go-bengaluru meet-up !
There is one https://www.meetup.com/Golang-Banglore
s/Golang/Go/g
Why not? They also sell a popular game that is cross-platform and written in a non-Microsoft language...
&gt; Another common scenario for the Platform is ingesting broken HTML from source CMS systems, parsing the HTML to be valid, and sanitizing the HTML. Go was initially used for this process, but because the Go standard HTML library expect a valid HTML input, a large amount of custom code was required to parse the HTML input before sanitation. This code quickly became brittle and missed edge cases, and so a new solution was implemented in Javascript. This is unfortunately the one big downside of `text/html`, violating the first half of *"be liberal in what you accept, strict in what you emit"*. Still, as the article says: &gt; Go will not always be the right tool, and that's fine. The Economist has a polyglot platform and uses different languages where it makes sense. Go is likely never going to be a top choice when messing around with text blobs and dynamic content, so Javascript is in the toolset. However, Go's strengths are the backbone that allows the system to scale and evolve. 
Meh, it’s like “flat screen” vs “flat panel” — a lost battle.
I see you already made use of the http test package. This package also contains functionality to setup a test server see https://golang.org/pkg/net/http/httptest/#NewServer if you pass your router (which is essentially) a http.Handler in most cases you can make requests to the returned URL of httptest.Server
I appreciate it when people use Golang because frankly it's just so much easier to search for
Thank you
Shameless plug of a tiny opensource library I wrote: [https://github.com/hazcod/gosecurity](https://github.com/hazcod/gosecurity) It uses a multihash-like approach so you can change hashing algorithms later on, and \`needsRehash()\` will work.
What is your experience with lambdas? How is it setup? I've been running my apps in docker on baremetal, but been thinking about moving to AppEngine or AWS.. 
If you're talking about Minecraft, it's a pretty big stretch to say that was Microsoft's idea (not to mention, 12/18 platforms were made by the time the acquisition happened.) That would be a bit like giving Oracle credit for cross platform Java. Not to mention Microsoft has had a long history of anti-competitve behavior towards others in similar markets as well as anything open source. Really, it's nice to see this type of thing from Microsoft (and others like LSP, VSCode, open source of C#, etc.) I may still be a bit sceptical, but they seem to be moving in an overall positive direction. 
reflect.Value has methods to [get the length of a slice](https://godoc.org/reflect#Value.Len), [index into a slice](https://godoc.org/reflect#Value.Index) (that you can then use `Set` on to modify the slice), [slice a slice](https://godoc.org/reflect#Value.Slice),… i.e. anything you can do to a slice in the language, you can also do using a `reflect.Value` of the slice :)
&gt; The ultimate Go proof of that is the generics discussions for "Go 2." You're wrong on this: the Go team never stated there will be no generics in Go; instead it stated (multiple times, over the course of several years and many discussions) that they simply failed to come up with a solid design for them and do not want to add a feature "just because"—as many other programming languages did, unfortunately. Many designs (admittedly not well thought-out) were presented, evaluated, and rejected. The one being discussed now is just something which—though not without warts and pain points—at least looks like it could fly with the whole Go paradigm. That's basically all there is to it, and this is in contrast to `gofmt` which was created almost right from the start and clearly documented and articulated. As to &gt; These responses give Go a bad community reputation for new users I don't buy this argument: I did not merely reject the OP (like in "STFU, we have it right") but pointed them to what I think is the most representative discussion of the topic which was galvanized several times by the newcomers (10 pages in the Google Groups interface BTW). I do think that so-called "lurking" and an ability to perform a minimal research of the topic are crucial skills to attain¹ so I see no problem with telling a poster that there were no real need to post—especially to touch upon a topic which may quickly spark another local flame war, which is totally not needed. ---- ¹ I mean, don't rush to ask something until you have read what's already there. 
I know, right? Even Go's official website is [`golang.org`](https://golang.org/)
Thanks! &amp;#x200B; To answer your question. We needed an api to let our cms and other third party tools directly configure certain redirects. But I also have a question for handling thousands of domains with caddy. How did you overcome the let's encrypt rate limit obstacle?
Maybe because go.org is something else. golang.org also makes sense because it's "go language", but when talking about programming languages "go language programming language" sounds stupid.
Who in their right mind append "language" or "programming language" after the name they cite? It sounds stupid whatever the context is I'm using an _iPhone_, not an _iPhone smartphone_ I'm driving a _Honda_, not a _Honda car_ Etc...
Microsoft has got to be the only company that gets credit when their Java apps work cross-platform.
&gt;There is no room for crap in engineering. If that were true we wouldn't call both BCrypt and md5 hashes, given the disastrous results of confusing fast and slow hashing.
Do you call Java javalang?
I think this kind of project is a good way to get familiar with the language. That said, if you have GNU diff, `diff -qr` will do almost the same thing, but recursively and listing only files that differ.
You can use Onion right architecture with domain driven design. You can have layers which handle your web service logic: 1. API layer: You have your HTTP handler function in this layer. This layer's main job is to do validation, receiving the response from other layers and returning final response. 2. Domain layer: This is your main business logic. API layer can call this layer but not vice versa. There are different aggregated structs here which does one task each. 3. Repository layer: This is your data logic layer. Fetch data from DB, REST Api, Caching layer etc and returns to any layer wants to know it. Mainly Domain layer makes the call to this layer to fetch data from different sources. 4. Independent Modules: This is separate helper classes which do some specific jobs like sending BI events to some service, handling events triggered by domain layer etc. This has independent code which does some async tasks invoked by domain layers. 
if your \`Config\` struct big enough, you should approach with the 3nd, it'll reduce copy cost.
I also thought about splitting my Config struct into multiple structs each containing related fields to reduce copy overhead. Deep down I think I know that the first approach is the best but I feel that it is slightly unclean since it implies that there can be multiple copies of the config present at a time. The main advantage would be that my config would become immutable at the cost of having to pass it along to every method.
yeah, but just think about practical, is it a normal way for intending change the config during runtime code? I don't think so! It should be initiated at the beginning of the program and people just want to read from it. so why should you care about immutable in this case? :D
[removed]
Really like your design for REST API and adding layers using interfaces in between. There are some suggestions which can guide you to make it extendable. You can follow layered architecture with a clear separation of responsibility. 1. API layer: You have your HTTP handler function in this layer. This layer's main job is to do validation, receiving the response from other layers and returning final response. 2. Business logic layer: This is your main business logic. API layer can call this layer but not vice versa. 3. Repository layer: This is your data logic layer. Fetch data from DB, REST API, Caching layer etc and returns to any layer wants to know it. Mainly Domain layer makes the call to this layer to fetch data from different sources. In your case calling data from CockroachDB. 4. Independent Modules: This is separate helper classes which do some specific jobs like sending BI events to some service, email using some service etc. Some suggestions for your code: 1. Move all config params to a config JSON file, Read this JSON from the file at init of the app. Read params from the command line (or ENV variables) which override params from JSON file. 2. Move log init (so you can easily change log library in future) and sendgrid email code(core logic should be independent of email provider) to a separate helper module. Access them using an interface, init them during app init, pass them to required modules. 3. In class FoodAcidityAPIInitialize, add logic to handle SIGTERM signal to gracefully close your HTTP server. 4. No need to have a separate interface folder, move this to a specific layer folder or accessing layer like API layer can have the interface of domain layer. Although no harm in having it separate. 5. As you are using GoPkg, no need to push the vendor folder in the repo. 6. Not sure why main server logic is in infrastructure folder, this name looks little confusing to me. Maybe service or server or something more intuitive. There are some suggestions from a quick look in the code. For small apps doing them in one place is fine, but as the app grows big in code, this kind of design helps. 
"I feel that it is slightly unclean since it implies that there can be multiple copies of the config present at a time." You don't want to block that unless you need to, because in general it is very difficult to be sure that it won't be valid someday. For instance, consider a future migration script where your old world needs to copy to the new world. It's easier if they can be separate, and it doesn't take much work. &gt; The main advantage would be that my config would become immutable at the cost of having to pass it along to every method. If you [do it right](http://www.jerf.org/iri/post/2929), it turns out that's not the case. You only have to compose it in to your "base" objects. Once you have a composition-based system, you in fact do not end up passing the config all over the place. This is one of the reasons to go with the non-global config; the costs are less than you think in Go.
A lot of programming languages to this, even ones that are easy to type and search for. Do a search for Scala on Google, and there's a good chance that it'll come up with https://www.scala-lang.org/ as the top result. It seems like this is more of a convention than anything, but doubles up as making it easier to search for. That being said, if they had the domain go.org then I'm sure their ranking would still be fine if you searched for Golang the same as how you have to right now. My point is, I don't think they made the domain name golang.org to make it easier to search for specifically.
I don't think that's their point. I think they're saying golang.org tells you more about what to expect from that website than just go.org would, i.e. *lang.org domains are usually used for programming languages: * https://www.scala-lang.org/ * https://www.rust-lang.org/ * https://crystal-lang.org/ * https://dlang.org/ (Imagine, d.org?) * https://www.dartlang.org/ Of course there are also plenty of exceptions: * https://secure.php.net/ * https://fsharp.org/ * https://isocpp.org/ etc. I don't think they're saying you should append "language" onto the end of every language when you're talking about it. When I'm talking about Go I don't call it Golang, I don't call it Go Language, I don't need to in person, it's redundant in context.
&gt; However, the project wasn’t without struggles in achieving consistency. The first major challenge for the platform was managing dynamic content from unpredictable backends. The platform consumes content from source CMS systems primarily via JSON endpoints where the data structure and types were not guaranteed. This meant the platform couldn’t use Go's standard encoding/json package, which supports unmarshalling JSON into structs, but panics if the struct field and incoming data field types do not match. Why do people say stuff like this when it's not true? http://eagain.net/articles/go-dynamic-json/
&gt; This is unfortunately the one big downside of `text/html`, violating the first half of "be liberal in what you accept, strict in what you emit" Reaching an entirely satisfying level of being liberal in what you accept is a daunting problem when it comes to HTML. `net/html` does an excellent job doing what the tin says—parsing HTML5. In most cases I'd prefer explicit parse failures over having the parser silently guess and assume what various badly formed constructs mean. Personally, to scrape botched HTML I deal with it as any other botched, inconsistent text data: a combination of regular expression matching and procedural code. If there is some subset of the document that I can parse with a clean parser I'll do that. There's some infamous StackOverflow question about parsing HTML with regular expressions with a hilarious and appropriate response. But in these cases I'm not looking to parse HTML, I'm just looking to get the data I'm interested in out of there, and a combination of procedural code and regular expressions can skip you past some of the caveats.
The "makes testing difficult" should be thought of as a symptom of what the global state does. When you have a function with an input that gives a deterministic output, your code is easy to reason about. If your inputs are mixed with data from a global location, however, it becomes much more difficult to reason about some related functions when the global data is mixed into the state in the middle of them. This problem can take a little time to emerge since you might be, at first, able to keep the entire code of your application in your head. Additional complexity of non-pure functions might be trivial while you are able to think about everything your application does at once. However, after some time, or after adding other developers, you begin to have confusion. Tests require you to either write a lot of setup code which feels silly since you're re-inventing a lot of your application--perhaps incorrectly--until you start to pass everything you need through parameters. In that way you will be freed from worrying about setup because you only need the input for what this function does. From that statement, you might correctly guess that the best configuration to pass would also be the small section of configuration relevant to your current code.
lang.java, obviously
So in conclusion it mostly looks like composition is the way ahead. Make small structs with related fields and compose them together to form the total config and pass only as much as needed by value instead of having global state.
Exactly why I did it :)
Anyone familiar with these? Are they worth it? Work has me micro-optimizing large data structures these days and this book sounds tempting. Thoughts?
You can still work with the others and save the copy cosy by returning a pointer
Use wildcard domains. (Autocert won't do that though.) Or if they're not subdomains, then the rate limits probably don't apply.
\`pos, err := [r.Seek](https://r.Seek)(0, io.SeekCurrent)\`
Oh thank you, perfect answer!
Clear and concise example for new Go programmers. I would maybe add a part that uses a bufio writer as well. 
hi [u/bhagvank](https://www.reddit.com/user/bhagvank) This looks exciting. I've been looking for an algo book in Go and yours looks the part especially seen that it includes algos that other books usually neglect(like memory management algorithms) I have however, in the past, bought books that I ended up regretting. As such, nowadays my policy is to buy books which have a free chapter included that I can download in advance to gauge whether the book is for me. Does your book have a free chapter somewhere?
[Maybe because it's never been posted here?](https://i.imgur.com/hNbza3A.png) I've been working on this exact problem as a learning project and I've never seen those articles through hundreds of Google searches and a few comments on reddit about JSON being a pain to deal with (with universal agreement). That's an awesome read and I'm going to do some serious cleaning up of my project based on it but it should definitely be spread around more.
After just a quick look using my phone, one question: Why bother with `args`? The handle function could simply be this: ``` func (...) handle(fn func()) { defer ... fn() } ``` It could then be invoked with an inline function: ``` inst.Handle(func() { ... The actual call ... }) ``` 
Really interesting and just in time for our project. What do you use to convert office documents ? Headless OpenOffice ?
Are they?
keep paying for your reddit ads, triplebyte, I see enough of them without posts like this.
Terrible, not using defer, possibly leaving file handles open on write failures and what not. Lots of terrible code patterns/mistakes I would flag for review (and no, it's not for simplicity sake, sometimes they are costing them complexity). I wish sites like this didn't exist.
For the record, I totally don't work for triplebyte. I saw this posted over on /r/programming and was interested by the fact that go programmers do significantly better in their interviews than any other language. In retrospect, my title is a bit too click-batey
Relevant bits: ...so might we merely be seeing the result of a correlation between specific editors and specific languages? To investigate this, I looked at interview pass rates by language as well: [Graph](https://d25hn4jiqx5f7l.cloudfront.net/file_attachments/files/original/2d91c7bc54323641aa5e69ca602bdd01935d21ee.png?1543937547) ... Also, what's going on with Go? Go programmers are great! ... Engineers who use Go are also especially strong. If you know why, please let me know.
Not necessarily, but they do noticibly better in triplebyte's interview process than any other language. Ruby and Python take spots 2 and 3 so it sounds like they really like straight forward, readable code.
&gt;"be liberal in what you accept, strict in what you emit" Funny enough this is fairly descriptive of The Economist's political philosophy.
I think the answer is pretty straight-forward (if I had to guess, that is). When a programmer is learning to program, they ask themselves "what language has the most jobs". Java is the language used in the AP exam, and C# is the equivalent in Microsoft, so lots of people learn this. If you asked those programmers why they didn't learn Go, they'd probably say there are no jobs in Go, so why bother. But clearly some people do learn Go, and those folks have to be willing to say they are learning it because they really like Go, and even if there aren't a lot of jobs, they think those jobs would be more interesting. There's also a calculation based on the other side, which is to want to learn a more obscure language like, say, OCaml or Elixir. So Go is at least supported by Google, so maybe it hits a nice sweetspot of being popular enough that serious programmers would try to learn it, but not so popular that everyone feels they need to learn it.
It is not correct to defer close on writable files as close might return errors. This will lead to bugs which are difficult to trace. The simplest way to solve this is not to defer close when writing files. Please read [https://golang.org/pkg/os/#File.Close](https://golang.org/pkg/os/#File.Close) and you can find that it returns an error.
https://golang.org/pkg/plugin/
This library seems too small to justify using. Leaving aside preferring errors over panics, there's maybe a dozen meaningful lines of code in this package. This goes against Go's principles of avoiding small dependencies, and reminds one more of javascript's many tiny utility libraries. I know suggesting the package shouldn't be used might not be helpful in terms of how to improve the package, but if you haven't listened to the talk on go proverbs, maybe I could be helpful in pointing you to it for later packages: [https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=2m48s](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=2m48s)
The huge problem for binary data writing is a nessesary of byte slice as parametr. For sample, if have slice of doubles, then need to convert with memmory realloc to bytes slice.
Yes. It looks exactly what i need. Thanks
Just be aware, plugins are still kind of a pain to use, they cannot be unloaded or reloaded, and they [only work on Linux.](https://github.com/golang/go/issues/19282)
That's not strictly true. You can mutate errors in the defer. Often people ignore the error in close as there is little you can do. You can read more at https://golang.org/doc/effective_go.html#defer. But even if you don't use defer, you should make sure after a successful file open/create, you ALWAYS close the file. Also, do you notice you are doing things in later examples like calling `fmt.Fprintln` without checking if it failed at all? There are lots of mistakes in your post.
I never said Minecraft was Microsofts idea. But after aquisition they did not turn it into a Windows/XBox-only game, that's the point. Yes, they seem to move in a positive direction indeed. Fingers crossed!
This example from the article is a bit strange: func reprocess(searchResult *http.Response) (int, error) { responses := make([]response, len(searchResult.Hits)) var wg sync.WaitGroup wg.Add(len(responses)) for i, hit := range searchResult.Hits { wg.Add(1) go func(i int, item elastic.SearchHit) { defer wg.Done() code, err := reprocessItem(item) responses[i].code = code responses[i].err = err }(i, *hit) } wg.Wait return http.StatusOK, nil } First of all, they must be using some custom `http` package, because `http.Response` doesn't have a `Hits` field. Second, this code will deadlock, because they call `wg.Add` both outside the loop and inside it. Lastly, the `wg.Wait` call is missing its parens. 
The Go dynamic loading story is pretty sad. You might have more luck writing a base C implementation of your plugin interface and then linking that from Go than actually providing a pure-Go plugin story.
The chart that plots language usage vs. years of experience does not include Go in the languages. That seems odd. 
I’m order to learn Go, you have to teach yourself; it ends up being a self-selecting crowd of people who 1) realize why learning Go might make them better able to solve problems 2) are capable of teaching themselves a new language Both of these bode well for one’s ability to learn other parts of programming Java and C#, on the other hand, are often the first languages taught at school, and, if you don’t see any reason to learn another language, or you just aren’t that good at teaching yourself new things, you’ll probably stick with one of those
And they must be compiled with the same Go version (last time I checked at least).
How is this better than pandoc?
Never used pandoc but after looking on the web: - pandoc does not seem to preserve style for docx files - HTML (and Markdown) conversions should look better with Gotenberg because it relies on Google Chrome for rendering (pandoc relies on external tools lile wkhtmltopdf which are not up-to-date) - CLI vs API?
I’m kinda disappointed to read they used Go for the new version because it’s slow as all fuck compared to the old site. A lot of the slowdown is doubtless due to all the new JS they’ve stuck in the frontend, however. It’d be interesting to know how much of the loss in perceived performance using the site is due to which factors. But in any case, as a user of the site, the new version is a big step backwards performance-wise. 
Love the name btw
https://stackoverflow.com/a/1732454
Fair. I tend to use pandoc for rendering LaTeX-extended Markdown into PDF.
It's because you need to pick an encoding. Use encoding/binary, encoding/gob etc
they somewhat work on Darwin too, though.
Hi guys, wanted to share and ask for a little feedback with the new exporter written in go for website and speed monitoring. Basically it's a simple exported, with an out of the box example. I'd like to hear if anyone has some nice ideas or anything regarding that, so that I could improve the exporter! Thanks!
I strongly recommend using an RPC based plugin system like [https://github.com/hashicorp/go-plugin](https://github.com/hashicorp/go-plugin) over the stdlib plugin package. For more details on the very rare case when the stdlib plugin package would be preferable, check out this wonderful video. [https://www.youtube.com/watch?v=x-LhC-J2Vbk&amp;t=2127](https://www.youtube.com/watch?v=x-LhC-J2Vbk&amp;t=2127)
Nice! I will test it tomorrow :)
Thanks, hope you lile to logo too haha
Enjoy prison
It sounds like each file has it's own "main" function, is that right? Each app you have should be in different directories. You have multiple go files in the same directory but they must all have the same package name and your "main" package can't have more than one of the same identifier which in this case is probably the "main" function.
Thanks man!
Ok, that would make sense I guess. Learning go isn't just about the syntax, but lots of other minor things! Thanks
No problem. It took my a while to get a handle on as well. Good luck.
Thanks, looks awesome. Good job!
`json.RawMessage` is of course also documented officially with an explanation and a couple of examples. Pro tip for learning is to read the documentation thoroughly first, it really is great. Random tutorial blogs and google binges should be a last resort.
I'm pretty sure the most likely explanation for this is a statistical aberration - like sampling bias. It's hard to tell without the raw data. But it seems that the total proportion of Go interviews they do is pretty small, compared to other languages ([it certainly was last year](https://d25hn4jiqx5f7l.cloudfront.net/file_attachments/files/original/6f4483a664ac5c11e5c558a886dffc4816ad8595.png?1505780899)), which would magnify outliers. You also don't know what kinds of companies use them for interviews and how that relates to Go usage and qualification - if, for example, a couple Go-using startups and a whole lot of Java-using industrial enterprises (that don't *primarily* develop software) would use Triplebyte, then it would be expected that *on average* the Go candidate pool fares better in coding-interviews. Lastly, they are clearly doing post-hoc data-analysis - they are first collecting data, then slicing it based on whatever criteria they can think of and looking for correlations (and of course only publish those slicings that look "interesting"). That's exactly why good science formulates a hypothesis *before* doing the measurements - or at least separates the data into an exploratory set and a test set, the former to find candidate correlations and the latter to test those correlations. Sorry to burst anyone's bubble on this :) I love Go and use it almost exclusively, but really, I think this is just noise. And I'm a little bit annoyed at Triplebyte for publishing the data this way and *explicitly* posing that question. The internet-wars over what programming language is best are already toxic enough without this.
I like this, only had a brief play. be interesting to get it hosted my k8s cluster, have you got a helm chart for it?
Good idea! Mind submitting an issue? Thanks! &amp;#x200B;
Greetings from Gothenburg! 
Your feedback has been applied to the article. Once again, thanks for sharing.
The article also fails to even consider relative difficulty of the challenges in each language - if their test involves the same set of problems, some languages will naturally handle them far more easily than others, and if the challenges are tailored to the languages, then that would be a factor that would throw doubt on the direct comparability of the languages.
I think overall it's a good starter article for using the Docker API using the Go language, I think it provides and show very succinct concepts to get started hacking away. &amp;#x200B; Now some friendly criticisms. I greatly dislike Medium as a publishing platform, makes for a not-great reading experience with those huge top and bottom. I find the fact that it recommends `glide` as the package manager for "getting started" as a downside considering that we've had `dep` and now Go modules as a way to do package management, the only circumstance where I would consider using glide now are if your project (s) are a bit old and transitioning to either `dep` or Go modules requires team buy-in and coordinating the update of such tools (like it is where I work). The other parts which could be improved would be the source snippets; many of the functions return an error yet the snippet panics when an error is returned by the Docker API client calls, I think this might be confusing for those that are not familiar or are getting started with Go as a language. &amp;#x200B; &amp;#x200B;
You might wanna check out this previous submission: https://old.reddit.com/r/golang/comments/9wn8pm/things_to_avoid_while_using_golang_plugins_alper/ As mentioned, I'd probably avoid them and opt for RPC-like mechanisms instead.
Yeah, no need to express your wish against the guys site. It is flawed code indeed, but why not come up with the suggestions before cursing the whole site?
If the majority of people have this misconception that JSON is a huge pain in Go then obviously the docs are inadequate or insufficient. You don't get to say that the information is there and easily understood when it seems to be so commonly misunderstood. I've read the encoding/json official docs front to back multiple times. There are no examples that explain the unmarshaling of arbitrary JSON in the way that blog did. The Go way to make docs is great and extremely helpful but it's bred this obnoxious-ass brand of "the source code is the documentation" from the Linux oldbeards of years past.
Thanks I'm working ont it, I will put my code if I can make it work
Maybe you need make gopher parts in the logo to gray as well. :D
[Delayed until tomorrow](https://groups.google.com/d/msg/golang-announce/D4sE5tGvhe8/sVJSIEtFCAAJ): &gt;Hello gophers, &gt;The release is still in progress. For today, we are now outside the time window in which we are comfortable completing it. &gt;No details of the security issue have been made public yet, so we are rescheduling the release for tomorrow, Thursday, December 13 at approximately 8 pm UTC (12 pm PST, 3 pm EST). &gt;Thanks, &gt;Dmitri on behalf of the Go team
This wasn't someone approaching with humility asking for help. Rather, this is a site with SEO potential proliferating these kinds practices and defending them. There are too many of these supposed teaching sites out there that are bad. Tolerating teachers with bad code, teachers with bad science, etc have consequences. Cursing the site is in defense of the ecosystem, not intended as a personal insult to the author.
Ok thanks to forfunc, I tought that TestMain() was called @beforeEach Test function, so yes my router was always nil by looking deeper into "httptest.server" I changed my "router" to "Router()" like this example https://www.thepolyglotdeveloper.com/2017/02/unit-testing-golang-application-includes-http/
I don't know Ruby, but based on the similarity here to many other languages (Python, Java, JavaScript, Haskell, Scala, Kotlin, etc.) it looks like the first line: `file = File.open("../input.txt", "r").readlines` opens a file and reads the lines into a collection (e.g. an array or slice in Go), and the second line: `puts file.map(&amp;:to_i).sum` maps each line to an integer value (`to_i`), sums those integers (`.sum`), and prints out the result (`puts`). That look right, drum?
You are correct, but you are harsh... this community is small, no need to scare people away.
Just curious, what's the use case for it being a docker powered API? Like for ticket websites to email tickets as pdfs?
Thanks, I agree that as of now it seems to specific and small task the library is handling. As the speaker says in the talk you had shared, hope people copy the code and use it, even if not the library as such.
Right. Let me try to modify the same.
One alternative for now is templating, like [https://github.com/ernesto-jimenez/gogen/tree/master/cmd/gospecific](https://github.com/ernesto-jimenez/gogen/tree/master/cmd/gospecific) \- to reduce the boilerplate of creating a type wrapper for every possible type (in your example, "int", "float64", etc). There are many other such libraries with different pros and cons.
Possibly this could be some help: https://itefix.net/cwrsync
What the fuck, people build serious awesome software in Go!
Being an ass is not the correct approach to teaching others. 
Yes “What is a goroutines” is a good example of a starter question that leads into a few questions about GOMAXPROCS, the goroutine scheduler, and what differentiates them from posix threads. I will also cover a few other basics topics like zero values for built-in types, channels VS mute some VS atom is, how errors are handled, some questions about interfaces, how basic data structures can be made in go... 
I doubt the salary is the issue. For these positions the salary is very competitive even with financial tech jobs. I think the biggest problem we get is a mass of Python and Node developers that have either never worked at a substantial scale or don’t really understand some basic computer science concepts. That is t a slam on Python or Node developers. There are just a good number in the area that have been pretty successful without having to know that knowledge. 
Looks great, I'll definitely give it a try! Only thing missing at first glance seems to be a simple way to deploy it to a cloud function instead of Docker. Most people won't be needing a 24/7 PDF converter.
Exactly! Or invoices, reports etc. My main use case for example: - use a template engine like Twig or Jade for generating HTML from database values - send this HTML to gotenberg and serve the resulting PDF to the user
I wanted to go serverless actually but there are some limitations currently. For instance: max post size, limited space for external dependencies and so on!
Good catch hehe
&gt; If the majority of people have this misconception that JSON is a huge pain in Go then obviously the docs are inadequate or insufficient. That's a fallacious conclusion. It could as well be that the people yapping about it don't represent the majority of users. "Universal agreement" doesn't matter if the agreed upon fact simply isn't true, but let's pretend that it is so you can give me the numbers. I also have no interest in discussing whether using JSON in general is a huge pain in Go, so maybe let's stay on topic? &gt; You don't get to say that the information is there and easily understood when it seems to be so commonly misunderstood. I get to say that the information is there because it is. I get to say that it is easily understood because that was my experience reading it. *You* get to say that you think the documentation sucks even though the "hundreds of google searches and a few comments on reddit" obviously got you nowhere when reading https://golang.org/pkg/encoding/json/#RawMessage and https://golang.org/pkg/encoding/json/#Unmarshal would get you somewhere, approximately where this blog post leaves you: knowing how to use json.RawMessage and that it can unmarshal values into empty interfaces and how it does it. &gt; There are no examples that explain the unmarshaling of arbitrary JSON in the way that blog did. I've read the encoding/json official docs front to back multiple times. You missed the sections relevant to this blog post. Reading the documentation front to back you'd likely come across it. &gt; The Go way to make docs is great and extremely helpful but it's bred this obnoxious-ass brand of "the source code is the documentation" from the Linux oldbeards of years past. Okay, but what does this have to do with me recommending to read the documentation? I didn't recommend that you read the source code. I recommend that you look at the documentation before you start googling. I mostly recommend this because "learning-by-blogging" is increasingly becoming a common practice and because the documentation is so good. That said, I don't think there's anything wrong with the blog post above. The author gets it right.
Really interesting article. My only critique is the casual use of sync.Map. It seems like almost everyone recommends against using it, instead preferring to use a normal, type-safe map and a mutex. Even the docs recommend against hastily choosing it: https://golang.org/pkg/sync/#Map With that said, this is about as close to an appropriate use case as I've seen... so maybe I'm just wrong.
I think Cobra makes programs follow badly, which is not idiomatic to me. Check out flaggy. (I wrote it) https://github.com/integrii/flaggy
I will use this.
I'd be curious to know if, for the author's benchmarks, the sync.Map were actually better. I know that Map does some fun stuff to avoid locking everything fully, but it by definition only accepts `interfaxe{}`, which means that anything you give it gets boxed. The article talks about the optimization on a map lookup like `d[string(s)]`, which I'd think is lost when moving to the sync.Map.
This looks amazing ! I might change from wkhtmltopdf to this. I still have one question. As far as I understand, you need to send the file location to the service. But as I generate HTML on the fly, I never write them on the disk. Also in a microservice architecture, filesystem is not shared. Is there a possibility with Gotenberg?
Actually you do not send the file location but the file itself! Is the documentation is unclear about that? Sorry, english is not my mother tongue :(
thanks golang
[Actual link](https://jfrog.com/gocenter/) instead of the marketing stuff.
Genetically, true cobras are members of the genus Naja, but according to Viernum, often the name cobra references several species of snakes, most of which are in the venomous snake family Elapidae.
I didn't understand it that way sorry :) But still, is there a way without writing the file on the disk ? Like a second method accepting a \`\[\]byte\` maybe
Indeed, I could update the go lib to also accept bytes
The actual project page is [https://jfrog.com/gocenter/](https://jfrog.com/gocenter/) but the press release contains more information than the website right now :)
Yes. Also, every language has some pros and cons. That's all right. The point is, Go is popular, powerful and will open you many doors. Plus I honestly think you will have a competitive advantage in doing Go rather than Java/PHP or language with already established developers especially in the world that moves towards distributed/decentralized applications. Also, I always learn by creating a fictional real life project and then programming it. I learned PHP 7 years ago by creating a poker social network replicating every single important Facebook feature (not just the easy ones as devil is in the details). IMO. Enjoy the ride.
Wow that sounds very interesting, by the way I really like the docs of Go, very complete. I don't know, I guess I should just jump into Go. The thing is though, what if I want to work as a Go mainly developer? I'm pretty sure not many people are into Go in my zone (and I mean real life).
There is a package for that: https://godoc.org/modernc.org/strutil#Pool
Hi, &amp;#x200B; I'd say Go is great for a first timer, it's relatively simple to understand and won't limit you very much. I've spent some time teaching my sister-in-law and she picked it up pretty quickly (from no knowledge of anything, even HTML). &amp;#x200B; About the only thing that really screams out as missing a standard go-to for Go is GUI programming, but even there are options including some really good libraries that have recently been made public. &amp;#x200B; I'd say just give it a go, write a simple HTTP server (a quick search will turn up multiple tutorials), or a basic calculator or something. Get used to the actual process of writing code, compiling and running it. See how you go and ask here if you get stuck. &amp;#x200B; That said, there are plenty of other languages good for beginners and which may be better suited depending on where your interests lie (e.g. C# with Unity might be good if you're into games), but Go is as good as any to dip your toe in :) &amp;#x200B;
Your sister's case sounds interesting, as she picked it up without any previous knowledge. I am not interested in games, so you can discard that. I am interested in computer science, and other miscelaneous things. Even if I could, I wouldn't know what to use the GUI for, there's pretty much a thousand programs out there that do everything I could imagine.
I'd say Go is a really good language for a first-timer. Since you don't have a IRL problem you wan to solve, I'd recommend doing these: [https://gophercises.com/](https://gophercises.com/)
Wow that link has a lot of useful content, I'll check it out, however I should first read the Go tour completely. By the way, is Go better on Linux? Just asking out of curiosity.
Any version of the article without the paywall?
It doesn't matter really. Linux in general is just more convenient for developing but you can do pretty much all on Windows anyway
Go is really good. I started to use Go after many years with PHP. And now , after Go learned, my PHP code looks much better. With Go you must do good code by default. Especially, working with errors. ON every function/method call you think what error can be returned and what do to.
Make a text-based console game, that how I started programming. After that, you can look at automating some task that you do regularly.
"Eventually, everyone has this goal to only use a terminal at some point in their career." Really? For me that's definitely not true. How do you feel?
I know about encoding, and I used it. 
Fantastic work dude. Good on ya :)
That's exactly right my friend
Tongue-in-cheek advice but please don't start Go, it will make it incredibly difficult to pick up any other programming language. YMMW
Routines and channels. These are must when you learn go. 
Found non-paywalled version: http://bet365techblog.com/the-impact-of-golang-on-systems-development-at-bet365
from 2013. I used this back then. Then VSCode came along...
Yea, go for it (pun intended) I'm one of the worlds worst programmers, and I recently moved from Ruby to Go. Mainly because ruby feels like it's dying and Go is the future. I don't understand too much, but I've been able to build things I need quickly and I'm pleased with the performance. 
It really doesn’t matter much what language you start with. Knowing the vocabulary and how to google your problem will make all the difference. Let’s say you learned PHP and knew about the explode function, you could then google “explode equivalent in Google Go” and find your answer pretty quick. Since Go isn’t as popular as, say, python, it may be better to do the python tutorial, then do the go tutorial, then do the python tutorial using Go. Go is a great language, but sometimes hard to Google since it isn’t as popular as python. If you decide on learning Go and get stuck, another trick would be to google “Python separate string by character”. You’d then learn that you’d use the split function and the word “character” is better defined as “delimiter”. Then google “google go split delimiter” and you have an answer.
As much as I love Go, if you're worried about finding a job really quickly I would advise you to take a look at the [TIOBE Index](https://www.tiobe.com/tiobe-index/); They provide programming language usage statistics The rule of thumb: the higher a programming language is, the bigger the job demand is
I thought we had github for that?
While the documentation recommends against using sync.Map, it also mentions that a cache is a valid use case: "The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow". 
You are right, with sync.Map you loose the d[string(b)] optimization, if you need to intern []byte, you should use a regular map + mutex. For interning strings sync.Map is faster on parallel benchmarks with 4+ CPU cores.
I usually try to find more applications or design my own that are just in a terminal. I am a sysadmin/ software engineer by day and live in a terminal so stretching my abilities in a terminal makes my life better when go-between machines and operating systems. So in my situation, it would make my life easier. 
You should post this in another programming language sub, just to have a non biased opinion, I feel. 😎
Last time I tried creating big png images using standard library it was faster on linux. But I'm sure it would be possible to use bindings to a C library instead.
anybody knows when nexus going to support go modules as well?
Check out www.adventofcode.com for some fun language agnostic puzzles
For your case then I'd definitely say Go is a good fit. Build some command line programs to do various things, some ideas: simple guessing game, generate a colourful image and save as Jpeg, basic web server, simple calculator, compare two text files, simple web scraper. Follow some of those problems and tutorials others have listed and you'll soon be there. &amp;#x200B; Even if there aren't many jobs in your area you can work on some open source projects and build up a small portfolio to show potential employer. You'll be in a better position to pick up further languages - it is about 1000x easier to learn another language once you've learned one! &amp;#x200B; (disclaimer: all statistics made up on the spot!)
But... Why
Go is a reasonably good choice for a beginner. One warning, though: A lot of documentation intended for programmers will hype up the concurrency elements, the goroutines and the channels. That's because in the field of programming in general, those were the things that _distinguished_ Go, and were easy to explain to programmers as such right away. (There are other things, like defaulting to composition instead of inheritance, but even to programmers that can be a subtle distinction. So don't worry about the fact that means nothing to you now. :) ) I recommend avoiding those for a while. I mean, don't be scared of them, and if a tutorial covers them go ahead and do the tutorial, but when you start doing your own stuff, I would avoid them for a while. While trying to understanding programming in general, those things add an entire additional dimension that you're not going to want to try to swallow all at once. The only thing to worry about is if you want to write a web server, just make sure that no two handlers try to write to the exact same value, or try to use a service not designed to be used concurrently. (e.g., databases are generally designed to be used concurrently without you having to think much about it.)
Yes. Go is great for beginners. No. You are not handicapped. Compared to most popular programming languages, Go is much simpler and minimalistic. No black magic. Being simple is Go's strength. You can use Go for many things, especially server applications. Since, You've never programmed before, I suggest to learn Algorithms and Data Structures using Go in Hackerrank. If One thing I regret the most being a programmer is I didn't learn Algorithms at early days of my career. But if You're impatient and You want to do something with Go, You can check the following tutorial on Web Development: https://astaxie.gitbooks.io/build-web-application-with-golang/en/ Happy Hacking
Thanks for reading the article. Yeah, I wanted the post to be succinct, I'm so glad that it did the job. Yes I should have used `dep` as package manager, I received this feedback from everyone. The only reason I used `glide` is, I've been using it for long time in my side projects so I just sticked with it. I will definitely change it to `dep`. I just left the code to panic to keep it simple. The repository which is linked at the bottom of the post has the refactored code already. But what you say makes sense, the function should align with its signature, and this pattern might mislead newbies, I will change it too. Thanks again for the feedback, I really appreciate it.
There is a helm folder right now so you might want to check it out! More documentation is getting added, but the helm should work already!
I just tried it - awesome. 
Good call on the tour. It's fantastic and well put together. :) After that, I started writing code and used https://gobyexample.com/ when I wanted to see the syntax for specific things. As I gained understanding of syntax, I then began to appreciate the standard library's documentation. I develop at work on Windows, but in my opinion, developing on Linux is better in all languages, even C# from Microsoft. That's just my personal preference though, and the easiest for you will probably be the OS you know best. 
If you need string representation, try something like that: [https://play.golang.org/p/qhunLOSw9R3](https://play.golang.org/p/qhunLOSw9R3)
I tried that, all I got was the hour
It works as expected: [https://play.golang.org/p/T7Gl83ToJ2M](https://play.golang.org/p/T7Gl83ToJ2M) `ar := fmt.Sprint(`[`t.In`](https://t.In)`(location).Format("15:04"))` `fmt.Printf("Full time: %v, part: %v",` [`t.In`](https://t.In)`(location), ar)` Output: `Full time: 2009-11-10 18:00:00 -0500 EST, part: 18:00`
The news talks about protecting trust of packages via providing immutability, but it seems like that's what the lock file in goo modules provides. Given that, I don't know why this would be more trustworthy than Github. It is probably still a great project to provide a private proxy, but I believe a couple other projects are providing the same thing. Is there anything new here really?
... I don't know what you tried, but you can literally run what _sealed_ posted and it works. here's one with a constructed time to show that it works: https://play.golang.org/p/lCybfRERu34
Perhaps someone more knowledgeable can correct me if I’m wrong, but as I understand it, if you’ve specified a commit hash in go.mod, you get exactly what you’re expecting or nothing\*. The code lurking behind a tag can be manipulated, though. \* Assuming hackers haven’t compromised your network/DNS.
Can it also be used as a library? And without Docker?
previously discussed here: https://old.reddit.com/r/golang/comments/a30hnq/go_interfaces_considered_harmful/
Its the first of the big asset management companies to provide something tailored for go modules for private packages. If your code is all on github, that would not benefit you all that much, but for internal packages an easy to setup modules repository would be quite useful 🙂
Awesome !!
Two more options: https://github.com/natefinch/pie https://github.com/starlight-go/starlight
I've read Go lack standard GUI library, what can you say about this?
Fetching go modules from a private repo isn't all that complicated... Is it?
i imagine it also helps the case where someone decides to delete a popular repository on github. if you had used a proxy, that module for forever be available even if the source was removed from github
The lock file is called `go.sum` and it has checksums of the downloaded code: ``` github.com/BurntSushi/toml v0.3.0 h1:e1/Ivsx3Z0FVTV0NSOv/aVgbUWyQuzj7DDnFblkRvsY= github.com/BurntSushi/toml v0.3.0/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU= ``` If you manipulate code behind the version tag, the checksum won't match anymore.
So the key is that it's hosted? Project Athens allowed someone to do this for themselves, and a lot of companies would prefer to control their own proxy because if Github repos disappear, they could also fear an externally hosted service shutting down too.
When you become a more experienced developer you'll improve in a lot of ways, usually that comes with time, but learning different _kinds_ of languages helps too. The way you code in PHP, Perl, FORTH, Lua, Go and ML are all different. Once you get this experience you'll be better for it.
But how does that differ from Project Athens, or backups that build servers will cache, etc? It doesn't seem to be providing a new solution. It's fine to have more alternatives, but between go mod proxies like Project Athens, build server caches, mirroring repos within the company controlled git provider, and developer computers, that's already 4 types of backups for the code that disappeared from Github.
Why do people post to Reddit asking for permission to learn something? I have zero understanding of or sympathy for this behavior. Just try learning the thing and if you don't like it, stop????
I set up some infrastructure to do that at my company. It really isn't that complicated. The only hard part was setting up auth in CI. Dev machines already have all the credentials they need to access code.
It suggests one possible answer is small sample size for Go programmers, so some normally-irrelevant effect is being magnified by coincidence. As much as I'd like to pretend otherwise as a bona-fide emacs-using Go programmer, this beats out almost any other explanation.
[removed]
&gt; I mean, what can I do with Go? There are 1,000,001 YouTube videos, blog posts, whitepapers, even physical books dedicated to computer programming. What value is there in anyone answering this question, yet again, in some shitpost on Reddit?
https://community.sonatype.com/t/go-support/305 im also waiting for this since our company use nexus for internal java and js artifacts.
&gt; iv tried many things Then share what you've tried. http://www.catb.org/esr/faqs/smart-questions.html
I've got it to work, thx
FWIW, I don't view build caches as a solution for that problem, as thats not really a permanent storage type thing. But why does this have to be different than Athens? It's great to have options and competitors. Java has several open source repositories that can be used. There are different features available in them and they drive each other to be better. So yes, it does more than just a lock file, same as other go mod proxies, and is another open source option in the space. I imagine as modules become more fully baked, some of these proxies might diverge a bit in feature set but they all have to start somewhere.
Because options and competition are good as long as they support the same standards
True. I just have a gripe with maven and gradle I guess lol. Flashbacks.
How is this asking for permission exactly? I am just asking if Go is basically a good language for a beginner like me, I could have definetly googled "top 10 programming languages to learn", but now, I read there was this thing called Go somewhere, I could have also googled "Is Go worth a shot?", but why didn't I? well maybe because I want answers from people who like it (aka here), I want answers that are updated (it's not the same to ask that in 2009 than 2018 is it?). You're just grumpy cus you don't like new ppl into go.
String literals are UTF-8 encoded. Otherwise, strings can contain any sequence of bytes. What substring do you need to find? There are many scenarios where the substring can be found by examining the UTF-8 bytes.
its kinda pointless to go to a community and ask if the reason for that community existing is any good. did you expect a bunch of people interested in the Go subreddit to say dont learn go?
Go (somewhat unfortunately) follows the model where a `string` is really just a view on an immutable `[]byte`, and can contain any sequence of bytes. So strings aren't (known to be) anything by default. However, all of the standard library functions in [strings](https://golang.org/pkg/strings/) *assume* UTF-8 strings. So for instance, using `strings.Contains(a, b)` is correct when `a` and `b` are UTF-8 (and only then). Conversion of `string` to `[]rune` or using `range` over a string also make this UTF-8 assumption (if they encounter anything that doesn't decode as UTF-8 they spit out a U+FFFD). So strings are usually UTF-8, and they're most useful when they're UTF-8. But you can have other encodings, unmarked, in a string, you can pass those strings through I/O functions, you can convert freely to and from `[]byte` with zero loss, and everything will work fine until you pass the string through something that assumes UTF-8 and makes a mess. You might in fact *get* such strings from I/O functions; when you make an HTTP request, no one guarantees that the `response.Body` is UTF-8; it's up to you to check the `Content-Type` and decode appropriately. But Go makes it easy to ignore that and write code that works as long as the server gives you UTF-8, and correspondingly hard to do the right thing ([golang.org/x/text/encoding](https://godoc.org/golang.org/x/text/encoding) isn't even standard lib).
Sorry, my bad. I completely misinterpreted that announcement. You are absolutely right. I’m not sure I see the use case for GoCenter since Athens exists.
&gt; String literals are UTF-8 encoded. Nit: This is strictly speaking true (as in, a string literal is part of a Go source file and thus UTF-8 encoded), but a bit misleading, in that string literals can still [represent non-UTF-8 byte secquences](https://play.golang.org/p/Ugbxj4GVb63).
What a weird list! VB.Net at #5, assembly quite high as well. I would not use this as a guide for what to learn to get a job, particularly if you're looking toward a future career.
&gt; So for instance, using strings.Contains(a, b) is correct when a and b are UTF-8 (and only then). Really? I can't think of a scenario where it would be incorrect with non-UTF-8 text and [it seems to work fine](https://play.golang.org/p/eRwFeTX-KUZ). You are correct for unicode-specific functions (like `TrimSpace` or `IndexRune`), though.
But it doesn't support concurrent access
You're right, that's a bad example.
I did it like this: //go 1.6 package main import "fmt" import "unsafe" import "encoding/binary" import "bytes" type SliceUnderground struct { buf unsafe.Pointer len int cap int } func main() { data:= []float64 { 10, 11, 12, 13, } p:=unsafe.Pointer(&amp;data) px:=(*SliceUnderground)(p) fmt.Println(p, px) var buf bytes.Buffer binary.Write(&amp;buf, binary.LittleEndian, data) b:=buf.Bytes() p=unsafe.Pointer(&amp;b) px=(*SliceUnderground)(p) fmt.Println(p, px) } data and b use different memory blocks. I think if writing directly to file result will be equal - allocation new memory block.
Go comes with almost everything you need. It offers a powerful HTTP server with a good template engine and JSON can be handled easily. It depends on the storage you want to use if you need some third party plugins like a mysql driver. But its as easy as "go get xyz" and youre good to go. I recently built a small REST Api and its absolutely fun doing it in go.
I don't think this differs from an athens public proxy at all in the problem it solves. JFrog is just trying to become the de-facto central package repository for Go like npm is for javascript. I expect the majority of gophers will prefer Athens proxies since they're not controlled by a single company like this is. Shops that already use JFrog's Artifactory as their internal proxy will get GoCenter by default. Hopefully they'll be able to configure artifactory to use an athens public proxy if they want, but if GoCenter doesn't suck, many wont bother. Since they both use the same underlying standard, it shouldn't be a problem. If anything, having some competition might even help drive some extra innovation.
If you have basic understanding of Go , I would suggest use a framework like Beego. It makes api development a cake walk.
The first one.
Definitely the variadic definition at the top. Similar to the definition of [fmt.Println](https://golang.org/pkg/fmt/#Println)
What do you think about the empty Add(), though? It bothers me somehow
The thing I am asking myself though: A call to `fmt.Println()` with no arguments makes sense, to only print a newline. On the other hand, a call to `mystruct.Add()` does not really make sense, does it?
I suppose I should have used `fmt.Print()` rather than `fmt.Println()`. A call to `fmt.Print()` is the same as `fmt.Print("")`, i.e., nothing happens. So a call to `mystruct.Add()` would be equivalent to `mystruct.Add(0)`
\#3 is definitely not the right one. What even add the first parameter 'item' when the variadic 'more' would handle it? \#2 not the best... \#1 would be the way to go Also, as a side-note... you keep questioning other's reply to a question you asked. You're the one making the call, as it's a function in the software you wrote. Either handle a nil 'item' and have it return something line an 'int' with the count of items it added (which would be 0 in this case), or simply don't call the method at all until you have something to add. 
I wouldn’t worry about it. But I might call it ‘Append’
well, of course I am questioning their replies. I want a discussion, not someone to just tell me what to do. I want to be convinced :) \#3: I think I used to see that often in Java. I would say it makes sense, as you are forced to specify at least one item (this would prevent the empty Add()). However, I agree with you that this is the worst of the options
Agreed!
As a programmer, if you do anything besides web front ends, you'll eventually need to get comfortable with the command line interface. Windows makes the command line hard to use and most Windows apps are GUI based. Conversely, on Linux the CLI is the primary interface for many things. If you learn how to use tools (like Git and the Go compiler) from the CLI you'll be in a good position to better understand GUI interfaces for those tools. If you learn the GUI first it may not help you learn the CLI (which again, you'll eventually have to deal with). So if you're up for it, making Linux your primary dev environment is a good idea, but it may make your initial progress slower.
Get over it
You’re adding nothing, it makes sense.
Any word on how long the golang Docker images usually take to be uploaded? We have an application particularly vulnerable to the x509 validation problem :( . They're listed on https://hub.docker.com/_/golang/ (e.g. 1.11.3-alpine3.7 is there), but it's currently not pullable. 
I'm kind of prepared to move to Linux soon though, I've read quite a few introductory guides/tutorials about GNU/Linux, Bash and CLI. 
I said "It's fine to have more alternatives" so I was responding more to its claim that it's the first of it's kind. A build server might not keep all versions used (though one might configure a build server to keep source versions for all released builds) but compared to Athens, it's meant for a much more related role, and I just wasn't sure it added a lot new. I might even say it's better to have more alternatives. I just don't like when marketing uses hyperbole to say that they are solving a problem never solved before.
I agree that more options make better software. I just wanted to point out that the marketing of this as solving an unsolved problem is a little exaggerated.
VSTS / Azure devops allows you to get an auth token an place it in the repo url so that your build server doesn't need to get an auth challenge at all. I assume Bitbucket does the same (but I used a credential manager for the service account user), and Github I don't have any CI, but I'd be apt to investigate the token approach to see if they support that.
That approach would involve checking credentials into source control, which is less than ideal.
I use the stuff in the standard library to serve my Angular app for my personal site, an in-process key value store (Badger), and an upside down index (Bleve) for item retrieval (querying). It means I only have a few dependencies outside the standard library and the Angular app itself.
Am I the only one that really dislikes the name? "JFrog GoCenter" sounds so bad and I hope I would never have to say it in a professional environment.
 Add(item Item, items ...Item) This guarantees one item and a variadic amount of other items 
That x509 one is nasty. In Go 1.11: $ go build client.go &amp;&amp; ./client 2018/12/14 11:48:32 Get https://l: x509: certificate signed by unknown authority 2018/12/14 11:48:32 1m1.168207449s vs in Go 1.11.3: $ ./client 2018/12/14 11:50:20 Get https://l: x509: signature check attempts limit reached while verifying certificate chain 2018/12/14 11:50:20 212.126102ms 
Github does support internal packages with private repositories.
&gt; It needs to be able to add both single items and slices of items. A single item is also a slice of length 1. Study SOLID principles, this concept is I ❤️
Other than the simplest explanation: great developers appreciate go. 😎
In addition, great developers don’t need to pick popular languages...
💯
I hate timezones, but it’s not worth the effort to try and fix the world. Go is, in many respects, about giving up choices. It helps keep you focused on the solving problem rather than choosing the form of the solution.
Try out WSL (Windows subsystem for Linux) on windows if you don't want to make the full jump to linux. It allows the use of almost every Linux program (even UI ones) within windows. if you'd prefer to learn the Unix terminal semantics to windows it's a great tool.
no, never do that; use a CI application that lets you configure how you're cloning repos. There is no reason to check credentials into source control
You must prepare for more "persistence" and "hard working" than other normal scripting language like Ruby,Python,JS. With normal scripting language you could "hack together stuff and do things" in like, a week. But for Go it takes a bit more than that. However, that will benefit you in the future because you actually do "programming" ( a lot of ppl only use scripting language to hack together stuff to work, not really "program")
Please see [https://blog.golang.org/strings](https://blog.golang.org/strings). It will answer many questions you might have about strings in Go. &amp;#x200B; To answer your direct question: you do not need to convert to rune. Use strings.Index, which works whether or not the strings are UTF-8
I'm talking about cloning the dependencies of the repo you're building in CI
[removed]
&gt; On the other hand, a call to `mystruct.Add()` does not really make sense, does it? It depends. Often it does. While you may not literally get a `mystruct.Add()` in the code, you may get a items := []Items{} // logic to add items to the list mystruct.Add(items...) In which case it can be convenient for an empty items list to not require a special case to deal with. Most sensible data structures can define an "Add" of no elements to be a no-op. (In fact, even in the imperative world, I'd call it a code smell if that's not true. Possible exception for logging.)
Note one of the security fixes for `go get` broke wildcard support: https://github.com/golang/go/issues/29241
Note one of the security fixes for `go get` broke wildcard support: https://github.com/golang/go/issues/29241
You have to use gomobile to compile your Go code into a lib that you can use in iOS / Android. Then you have to build a native module to bridge your go code with your frontend - or - you can expose a webserver from your go code and connect to it from the RN frontend directly. &amp;#x200B; The above is an oversimplification, but that's the gist of what you'd need to do. &amp;#x200B; It's worth pointing out that gomobile does not produce bitcode for the resulting library. Apple may soon start requiring bitcode for app store submissions. gomobile will likely never produce bitcode. There are, however, some projects working on compiling go with llvm in order to have bitcode and solve this. Not sure how far along those are.
[removed]
If it helps any, I posted [a thread](https://www.reddit.com/r/golang/comments/6bghma/can_i_reduce_the_boilerplate_in_this_code/) dealing with this same problem, so that might be helpful to read through.
My 2c: Definitely func (m \*MyStruct) Add(item Item, more ...Item) Why? Because the intention behind calling Add with no arguments is confusing. This form says, "You need to have at least one thing to add", which makes sense from a user's perspective. The implementation is almost the same between one and three, but the use is definitely clearer with 3.
They are part of same package so there won't be any circular dependencies.
Seems a bit of overkill and redundancy to have a Cell struct w/ (X,Y) coords and a bool. I think it's more typical to just have a grid of bools, and since you are iterating over the grid, you know the X,Y coords during the traversal (ie. cells don't need to know their location). &amp;#x200B;
[removed]
Never underestimate the mountains of legacy code that the world depends on..
I'm using go modules in new mini project and i must say they are much improvement as i don't need go install paths. So as sceptic i was i like them and will use for everything now.
shouldn't stuff like this be easily catched by a test suite? I mean the stdlib is rather well tested, why not the tools?
Honestly I wouldn't suggest go as the first language cause it is not object oriented nor functional, so if one starts with it they don't learn any set of key concepts around which most modern langs are centered. But the best suggestion is learn and master Go if you already started that route. It shall be useful anyway. Golang is okay for most things except maybe real-time work low level manipulations. Still not that it is useless even in these areas though.
Looks useful
This is brilliant - this will make it way easier for me to work on my new project! - Thank you!
Jupp, it‘s not a great name. Kind of on the same level as GoLand 😞
It is my guess that a wildcard cert has recently been added to the test suite. 
Option #1 or #2 (sort of). It depends on your needs though really. If you don't care about people being able to pass in an empty list of values, then I'd go for option #1. If you do ever care about people passing empty slices, then just don't let them pass slices in full stop, and force them to add each item 1 by 1. I'm not a fan of runtime programmer checks. In this case, if you did want to enforce a non-empty slice, you'd either have to return an error too, or panic (panic is probably more appropriate if it's caused by a developer using the API incorrectly).
I would never! I've bushwhacked my way through a good deal of heavily trafficked classic ASP, for example. But maintenance mode legacy projects aren't staffed like newer projects under active development.
Are you bothered by 7+0? No? See.
# THE IMPACT OF GOLANG ON SYSTEMS DEVELOPMENT AT BET365 ## WEDNESDAY NOVEMBER 14TH 2018 **Alan Reed, Head of Sports Development, Hillside Technology, part of bet365, explains the tools and skills needed by his firm, including programming language Golang** *Originally published on computing.co.uk* ## NEW PROBLEMS DEMAND NEW TOOLS. The challenges we face in 2018 are inherently complex. Delivering an always on platform that supports real-time applications for 100,000s of concurrent users at peak, has meant consistently breaking new ground in both the way we work and the technologies we use. The result, bet365′s betting platform is powered by an intricate web of systems that must work in harmony. What’s more, each individual system is a marriage of technologies that have to integrate effortlessly. As technical complexity has increased, so have the challenges of integration and maintenance. You need more people to consult on and support the code base, which results in knowledge becoming fragmented. We have platform specialists with a deep understanding of our legacy stack. Technologists who specialise in each of the technologies we use and subject matter experts who are authorities in the different elements of our offering. With so much diversity and specialism, trying to write good code becomes much more difficult. More people are needed for every project. Each with their own specialist skills, who then must communicate with others who have a different mindset and most likely speak a different technical language. When developing a new system, there’s a high degree of complexity in just trying to unpick the problem at hand. ## THE IMPACT OF COMPLEXITY ON DEVELOPMENT Generally, we have a traditional Software Development Life Cycle. We take the specification, write code against it, test for performance and then implement. Despite the increased complexity, developing new systems has been largely unaffected. The real issue is integration and maintenance. We found that maintenance cycles were becoming much longer than the development cycle. Support queues were increasing. There was no such thing as a minor change. Many of the challenges we faced were inherent in the way we write code. We have to write a lot to make it both performant and resilient. Resilience is where the volume really increases. You’ve got to be prepared for the unknown of the live environment. The ‘What If’ scenarios. ## ENTER GOLANG Our Golang (Go) adventure began like many others. A couple of people within the organisation gently nudging us towards a new technology. We were aware it was trending, but we’ve learned to wait a little. We want to make sure the new tech isn’t a passing fad and the platform is stable. Go was attractive because many of the challenges we were facing involved highly available, concurrent and performant systems. Problems for which it was building a good reputation for solving. Once we’d started to play around with it, we found it to be incredibly performant. You don’t have to write as much code to solve a problem. Not only that but it also integrated very well with the other technologies we use. It’s like a glue that binds everything together. One of the challenges you face in software development is there’s often multiple ways of writing the code to achieve the same result. Because of this, you can be up and running quite quickly but then you spend time optimising, to ensure it performs well. Optimisation is one of the hidden costs of development. Everything we do is real-time, so our systems have to be optimised to avoid latency. Golang was different. No matter which way we wrote the code it was performing well. We had less code, less changes and yet the run time was generally faster. ## THE IMPACT OF GOLANG ON DEVELOPMENT One of Go’s strengths is its simplicity. Because it’s a relatively small language, you can spin up systems relatively quickly. Rather than procrastinating over the syntax, you can spend your time writing. This has meant we can specify, develop and test very quickly. We can iterate at pace, tweaking and ironing out problems as we go. We’ve also found it’s enjoyed rapid adoption amongst our developers. Because it has a low barrier to entry, people feel comfortable with it very quickly. There’s a willingness to share. And because several teams were going through the same journey at the same time, there’s a greater spirit of collaboration. Knowledge isn’t held in one place. Everyone is taking the journey together. In just a few weeks, people were very conversant in it and were able to speak with people who had been using it for some time. It also works across Linux and Windows, which makes it a great leveller. As we take on more Linux systems, it provides a stepping stone. It is a great join between people and technologies. For the first time in quite a while, one team can talk and the other understands. ---- source: http://bet365techblog.com/the-impact-of-golang-on-systems-development-at-bet365
Hi @xdruppi, For Desktop UI, there are some community's GUI libraries for Go like https://github.com/asticode/go-astilectron and https://github.com/therecipe/qt And for Web UI, You can always use Go Libraries like net/http and html/template. However, it's more common to use HTML5, CSS, and JavaScript to develop UI applications. There are JavaScript frameworks like React, Vue, and Electron that allow You to easily build Web, Desktop, and Mobile UIs that can integrate with Go server applications. 
ah, I have not had that exact case since go.mod became a thing, but I would probably look at using a replace directive in the go mod and having the private dependency next to my package in both dev and prod, cloning it with the token in the same way I did with my package `replace example.com/me/packagename=&gt; ../packagename`. That might not be bulletproof for versioning, so I'll have to think about that next time I need it.
The release script only runs a subset of the full tests. https://github.com/golang/go/issues/29252
This is unrelated to wildcard certificates.
Then use Add(items ...Item) (err error) and return an error about it if you want to be able to deal with it later. You can just ignore the error otherwise All the fmt.Print functions return an error that is almost always ignored
very unfortunate... 
Thanks a lot for that reference! That helps.
&gt; I am just asking if Go is basically a good language for a beginner like me We have no way to help answer that for you. We can tell you what tutorials or books we like or what kind of person they'd be good for, but we don't know who you are and how you like to learn. Anyway, who cares what we say? There are more free learning materials than you could possibly read all of. Try something and if it's interesting finish it, and if it's "not worth a shot" just drop it. There are no grades; you will not be penalized. Since I left school, I have made no progress in learning Haskell because I find it frustratingly weird but I've successfully learned Python, Javascript, Ruby, and yes, Go. I didn't ask anyone if I should learn any of them, I just started reading something one day and then at a certain point I was good enough at those languages to consider myself no longer a beginner. 
I use https://github.com/DATA-DOG/go-sqlmock very happily
Liberal usage of interfaces solves a lot of headache here. It's probably worthwhile to wrap all of your IO access with adapters that have appropriate interfaces and then substituting it out where appropriate. Mocks are okayish but I have a hard time suggesting this when you can just use interfaces.
Thanks for sharing, /u/dgryski! Author here, happy to answer any questions folks may have.
Nice article, do you have any additional resources to expand upon this knowledge? 
No unit tests?
Good starting points: [Training · golang/go Wiki](https://github.com/golang/go/wiki/Training) (full disclaimer: my own course Master Go (for Go newcomers, no advanced topics) is listed there) [Learn · golang/go Wiki](https://github.com/golang/go/wiki/Learn) One advanced course that comes to mind is Jon Calhoun's course at usegolang.com, focused on Web development.
You're assuming a lot about the underlying representation there, what you're doing won't be cross platform.
I know that [@davidcrawshaw](https://twitter.com/davidcrawshaw) is writing a mail server/client in Go. He may know the answer.
I assume it was caught but that they felt it was too high of priority to wait. The release notes mentioned that this was broken but would be patched in a followup patch shortly.
I think it greatly simplifies the code you need to write, and makes my life easier if I want to pass a slice, which would be a huge pain in the ass with the `Add(item Item, more ..Item)` version.
Check out: Go: Complete Bootcamp https://www.udemy.com/learn-go-the-complete-bootcamp-course-golang/?couponCode=LEARNGO-REDDIT
I've become a big fan of just hitting a real DB as opposed to mocking. Go-Buffalo (which I love) has a similar methodology to Rails, using Migrations and a tool to seed/build the DB if necessary. You could pretty easily use this to hit an actual real DB with your actual read schema and see how it works.
Very cool. I did a similar project but in Python. This is what that code looks like: https://www.mattcrampton.com/blog/query_an_ntp_server_from_python/
Even though you're already an experienced programmer I'd recommend to start with the [Go Tour](https://tour.golang.org/list). While some concepts like loops are explained it at least gives you an initial feel for the language and you can progress fast. Additional resources on how to write idiomatic go: * [Effective Go](https://golang.org/doc/effective_go.html) * [Language Spec](https://golang.org/ref/spec) * [Just for Func](https://www.youtube.com/playlist?list=PL64wiCrrxh4Jisi7OcCJIUpguV_f5jGnZ) - very good YouTube series with a lot of different topics. The code review videos can improve your understanding of idiomatic code. 
I'd definitely like to contribute to this. This is incredibly valuable to some ideas that I have myself. Do you have guidelines to contributing? But can the name change to wormhole instead of blackhole given it's bad connotation to DBs and a wormhole is more closely related to what this is doing. 😄
I would recommend trudging through what is a for loop and what is a string because the answer might be different than you are used to and expecting.
I've been reading golangbot (start from the beginning, it builds up). I've found it more detailed than the Tour.
To be honest, the documentation is pretty good and there's enough that's different to give you a good few "Oh, that's nice" moments. It's not very long either.
Seems cool, but also seems dead
Just get the book. The Go Programming language doesn't waste a bunch of time on basic programming, but it does teach you about Go programming specifically.
Go is really easy to pick up (granted, I came from other compiled languages, so I don't know exactly your experience). What was helpful for me was to rewrite in go, a well-defined program or library from another language. That way you avoid worrying about *what* to write, and can concentrate on *how* to write it. Go is a simple enough language that an experienced dev can pretty much just sit down and start using it. Going through the Go Tour, as others have said, is a good way to get a feel for how the language works, but then, just start writing code. That's your best bet, IMO.
Another year, another FOSDEM, another extremely crowded Go room :)
Wonderful stuff! It's great to see devs replicate ideas in another language. 
And what I do? All unsafe things was did only for seeing internal mechanics. Memmory relaocation and more. Buffers transformation processed with standart packeges. 
Yeah, we are going to need a bigger room....
In particular, a string is immutable in Go, (You're likely to use a Byte Slice or a Rune Slice if you need mutability)
The main contributors have unfortunately been busy with other parts of their lives, feel free to join in on discussions (or code) though!
So true. If happens to inherit a monolith application where mocking database doesn’t exist. You can try open db transaction if your function accepts it. Like this example https://youssefkaib.github.io/2018/05/03/got-99-Go-problems-but-testing-database-layer-ain't-one.html
I'll just leave this here. [Rosetta Code](http://rosettacode.org/wiki/Rosetta_Code)
Maybe this? https://www.pluralsight.com/courses/code-school-on-track-with-golang Although, the language is really one of the simpler statically compiled ones - I’d just jump in and try develop something, and look at some open source projects for inspiration for what is a go way to do things (it’s closer to python than ruby/rails)
&gt; I'm an experienced programmer *fails to RTFM* Something doesn't add up here.
I've been doing adventofcode (https://adventofcode.com/) and implementing everything in Go. Learning by doing is getting me basic skills in Go fast.
I am new to Go myself.. wondering if tutorials around Modules is the way to go today.. given that it bypasses the most often problematic issue with Go that most of us from other languages dont grasp and struggle with.. it seems like any sort of new tutorial that teaches about modules, project setup, etc and then goes further would be the way to go. I find the whole GOPATH thing a nightmare to work around and am thankful that 1.11 and soon 1.12 resolve it.. at least partially.
Never test the actual database. Mock the adapter and make sure your code is behaving itself...
https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Some really cool topics. I'm mostly interested in the talk about GUI, gRPC and debugging. I know that the person talking about GUI has a repo for GUI apps that got a lot of attention from the Go community when it was published, so hopefully it's good.
What I've learned: 1. Don't test the database. Test the SQL. 2. Write each test so it can be run on its own. Running a whole suite of tests every time is a pain the arse. 3. Write some helper functions to create test data (`createRandomUsers(n int) []User` etc) 4. Test every SQL statement, even the stupidly simple ones. Typos are easy to make and hard to spot, and won't fail until you try and run the statement. 5. Create interface(s) for all the data access methods, so you can mock them in your business code and not test the database when you're supposed to be testing the business code. My tests look like: func TestLinkCRUD(t *testing.T) { pg := CreatePostgresStore() users := createRandomUsers(pg, 1) cats := createRandomCategories(pg, 1, users) tags := createRandomTags(pg, 3, cats) files := createRandomFiles(pg, 1) document := createRandomDocuments(pg, 1, users, tags, files)[0] tl := bizrules.Link{ ID: uuid.New(), DocumentID: document.DocumentID, Key: []byte("some random text"), AccessCount: 1, } err := pg.SaveLink(tl) // Data Access method on the Data Store interface if err != nil { t.Error("failed to save the link: ", err) } tl2, err := pg.GetLink(tl.ID) // another Data Access method if err != nil { t.Error("failed to get the link: ", err) } err := pg.DeleteLink(tl.ID) if err != nil { t.Error("failed to delete the link:", err) } } I don't bother clearing down the test data for individual tests, but do clear it down when running the whole test suite. 
This is very odd, I have several different projects with: go: verifying github.com/grpc-ecosystem/go-grpc-middleware@v1.0.0: checksum mismatch downloaded: h1:Iju5GlWwrvL6UBg4zJJt3btmonfrMlCDdsejg4CZE7c= go.sum: h1:BWIsLfhgKhV5g/oF34aRjniBHLTZe5DNekSjbAjIS6c= That's correlated with: github.com/grpc-ecosystem/go-grpc-middleware v1.0.0 h1:BWIsLfhgKhV5g/oF34aRjniBHLTZe5DNekSjbAjIS6c= in the go.sum file. Since upgrading from 1.11.3 to 1.11.4, I'm getting a different version: github.com/grpc-ecosystem/go-grpc-middleware v1.0.0 h1:Iju5GlWwrvL6UBg4zJJt3btmonfrMlCDdsejg4CZE7c= Is this a case of the upstream moving a tag around since I last updated code, or is there potentially a further regression in 1.11.4?
Apparently being tracked in [https://github.com/golang/go/issues/29278](https://github.com/golang/go/issues/29278)
Okay, i've understand the principle of the intertools package provide by yanatan16 on github. I've forked this repository and change some stuff for fun. [https://github.com/Protoc0d/stream](https://github.com/Protoc0d/stream)
Gopl.io
the wording of that title makes me a little sick.
&gt; https://gophercises.com/ I just started dabbling in Go yesterday, so thanks for that. Coming from Python, I have found Go to be a maddening and incomprehensible affair, so far. It's as if at every possible turn, the language wants to get in my way by making every little thing more difficult that it seems like it ought to be. I'm certain that if I stick with it, the reasons for this will make more sense, so working through those sorts of beginners exercises should be enlightening.
Too crowded. I had such a bad experience at fosdem last year I decided not to go anymore. You'll have a better time watching the talks online IMO
Thanks! Love to follow your reasoning, very useful when my 30 year old skills get in the way of idiomatic Go :)
Classics never die
It is not. It just has pretty much the base layer implemented – no need to change and break it constantly. I've shared my experience with Vecty [here](https://divan.github.io/posts/animatedqr/) and [here](https://blog.gopheracademy.com/advent-2018/go-webgl/). It's really awesome, and also main contributors are extremely active and helpful in Slack.
``` package main import ( "bytes" "fmt" ) func main() { bs := []byte("hello, world!") sep := []byte(",") var ret [][]byte for len(bs) &gt; 0 { i := bytes.Index(bs, sep) if i == -1 { ret = append(ret, bs) break } else { ret = append(ret, bs[:i]) ret = append(ret, sep) bs = bs[i+len(sep):] } } for _, part := range ret { fmt.Printf("%s\n", part) } } ```
Thanks, it works!
Just a little? I've got malignant herpes from it. 
"Contributes"
When will the evil of symlinks stop?
Thanks, I'll try to fix it. 
leveraging \`split\` and in-place seperator update: &amp;#x200B; package main import ( "bytes" "fmt" ) func main() { b := []byte("Hey you how are you ?") s := bytes.Split(b, []byte(" ")) s = append(s, make([][]byte, len(s)-1)...) for i := len(s) - 1; i &gt;= 0; i-- { if i%2 == 0 { s[i] = s[i/2] } else { s[i] = []byte(" ") } } for _, x := range s { fmt.Printf("%s\n", x) } } &amp;#x200B;
Out of the loop: since when CoreOS is part of RedHat?
Didn't they buy CoreOS a while back.
Then I was reeeally out of the loop then? Don't Bash me, I haven't looked out my \*ss from Debian for a while. :)
You should have two kinds of tests, unit and integration (or whatever name you want to call it). For unit and unit-integration tests, your adapter interface should be kinda like a model interface. `GetUser(userID int64) (*User, error)`. A DB has nothing to do with it. You should be able to switch it out to a user gettter that gets a user from an http API call or a DB or a fixture. This is easily injected and tested against and you can make unit tests that verify the error handling. You would create a fakeUserGetter or similar that matches the interface and you control it in the test. But the real implementation, the real UserGetter, that gets initialized in the prod code, it needs to be tested too! For that, you need integration tests that runs the actual SQL and verifies functionality. You can either test that module or test against a running copy of your service. I prefer a dedicated DB instance per test to prevent cross-pollution between tests and test runs. The test case inits a DB instance and drops the DB after (or truncates it before use). Using both kinds of tests is important to ensure the code behavior for error cases and for real functionality. Mocking the DB makes assumptions, I'd avoid it.
Why the scare quotes?
Why's that?
Similar issue to dotwaffle, but this the checksum mismatch occurs between a go.sum file generated on macOS with Go 1.11.4 and Windows also with Go 1.11.4: go: verifying github.com/knative/build@v0.2.0: checksum mismatch downloaded: h1:BkBXjJb3ugETV9Jfk97Aa7aIjnhRRuI6EnfQ7du0QCU= go.sum: h1:+bmR2edXNnc8l4zTZ1QEsy8R37ariWyaNGuahHSj+Tg= Looking in the module cache on each OS, I notice that the zip files are different sizes. Is this to be expected? If not, that may be why the checksums are different.
Official docs? I mean if you're experienced developer who's familiar with couple of languages you don't really need courses for getting into new language.
Raised https://github.com/golang/go/issues/29282
I tried GopherJS and generated js file sizes could be an issue you need to compress the output files to be usable and have a lot of unused code in your file. Also give a quick look to Webassembly go project and a simple button hangs up my browsers. IMHO these solutions need more work until the can get its way into production sites, but I didn't have the time to dig deeply into them maybe I am wrong.
Did this "transfer of stewardship" get started well before the IBM buyout or what?
So clear, thank you for this post
Thanks to you for feedback
This does not allow it to be called easily when the caller has a slice. Compare: var stuff []Item foo.Add1(stuff...) // if defined as Add1(items ...Item) foo.Add2(stuff[0], stuff[1:]...) // if defined as Add2(item Item, more ...Item) 
indexing and range are different in what they do
is there a reason for using maps and not structs?
If the structure of the data is irrelevant, you could just flatten the map to have just Direct key, value access
Red Hat developed etcd and the CNF came down with it. What’s not to understand?
&gt;structs Nope, I'm just a newbie so I dont know anything else.
The room this year holds 446 people. Is that bigger than usual?
Or are people getting allergic reactions to the word "cloud", because hur hur webscale Mongo?
- Reduce the amount of anonymous functions. - Reduce global variables.
usage _ perhaps could be replaced with either - (for package names) or camel case (for variables)
I'm using GopherJS to run `go fmt` on the output of [https://mholt.github.io/json-to-go/](https://mholt.github.io/json-to-go/)
Make a function that takes a function as an argument and runs that function on every leaf of the tree.
Hey, havent looked at the code, but i'd love to add a key for "topratedcomment"
Don't remember what it was last time, but we got room upgrades before and that just attracts more people :) 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [String interning in Go, grasping the handlerfunc wrapper, future of GopherJS](https://www.reddit.com/r/programming/comments/a6ijt6/string_interning_in_go_grasping_the_handlerfunc/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Hey, congrats on your first go program. There's a lot of things wrong and the code is not very idiomatic. * Package names: Should be "catcher" instead of "reddit_snapshot_catcher", "storer" instead of "snapshot_storer", etc. Keep the names short and choose names that show the intent of the code. For a project of this size removing this 3 package hierarchy might be worth it. * Global variables: Try to avoid them whenever possible. snapshot_manager/config.go is a very good example of what you should not do! These are configuration parameters. Pass them as parameter to functions instead. Additionally, instead of environment variables you might want to use a package that supports program parameters such as go's pkg/flag or more advanced version which support environment variables too. If I see this config.go file I have no idea which parameters are used and do not know about potential side-effects of using and changing them. * Error handling: You handle the errors (good!). However, you might want to at least add information to the errors. For example, if in reddit_client.go your login request fails then why not add something such as: log.Fatalf("could not authenticate against reddit: %v", err). In general, you logging an error is often the wrong choice. Go offers you to use multiple return parameters. Just pass the error (with added information) upwards to a more appropriate place where you finally handle it - e.g. by logging it. * Structure: This is a result of the previous 3 problems. The structure is not very good right now. For example, how would you test your code? That's gonna be difficult because of the global variables. If you write idiomatic code then testing is easy. * fetcher.go: That's almost how you want to do it - but not quite. You're currently fetching a few snapshots. Then after everything is fetched you process the results. Idiomatic code would fetch and process snapshots in parallel. I refactored this part slightly. It still uses global variables but that's up to you to change. The result could look more like this: func fetchSnapshots(subreddits []bson.M) { var wg sync.WaitGroup wg.Add(len(subreddits)) ch := make(chan reddit_snapshot_catcher.SubredditSnapshot, len(subreddits)) for _, subreddit := range subreddits { go takeSnapshots(subreddit["subreddit"].(string), geddit.PopularitySort(subreddit["sort"].(string))) } go func() { wg.Wait() close(ch) }() for msg := range ch { snapshot_storer.StoreItem(msg, dbUrl, dbName, snapshotsCollection) } } func takeSnapshots(wg *sync.WaitGroup, subreddit bson.M, sort geddit.PopularitySort, ch chan reddit_snapshot_catcher.SubredditSnapshot) { defer wg.Done() snapshot := reddit_snapshot_catcher.TakeSnapshot(reddit, subreddit, sort) ch &lt;- snapshot } 
Hi, thank you very much for your feedback! I'll look into every point you made once I get home.
Show us your code. In general, though, if your data structure isn't working out for you, you just store the data in a different structure that works better for your case. Also don't forget that you can take pointers to deeper parts of the structure and stick those in a slice or any other data structure.
In short. Go is pass by value 
Have your functions return the value that you're assigning, because when you pass by value like that it's making a copy for the function, not the same copy that the caller has.
When you pass variable to scanOperator() and number() they are passed by value. You need to pass by reference if you want main() to observe changes to them. Like this: func main() { var ( operator string number1 float64 number2 float64 ) scanOperator(&amp;operator) number("Enter first number: ", &amp;number1) number("Enter second number: ", &amp;number2) result := process(operator, number1, number2) fmt.Print("Total: ", result) } func scanOperator(value *string) string { fmt.Print("Enter operator (+, -, /, *): ") fmt.Scan(value) return *value } func number(msg string, numValue *float64) *float64 { fmt.Print(msg) fmt.Scan(numValue) return numValue } func process(operator string, number1, number2 float64) float64 { var ( result float64 ) switch operator { case "+": result = number1 + number2 case "-": result = number1 - number2 case "*": result = number1 * number2 case "/": result = number1 / number2 default: fmt.Println("Unknown operator") } return result }
Who will need this shit?
Try this: https://mholt.github.io/json-to-go/ It might not be exactly what you need depending on what you're doing with the data but it should show you a good way to structure your JSON data in Go.
Redhat bought Coreos. IBM bought Redhat.
Just use structs
Just spent today playing around with this. Had some difficulty setting up a mongodb storage for the proxy. The documentation was close to what I needed, but I ended up having to do my own experimentation to get this working. For instance just setting the URL of the mongodb isn't enough. You also have to create the db and collection. This might be an issue with the driver or maybe I missed something. Another minor critique is adding better docker documentation for setting up a storage backend (other than disk). I'm confused which EV's did what, and how to set the config.toml. Eventually I just ran docker exec -it [container name] /bin/sh Then I edited the file in the container and rebooted it. The file location is: ~/config/config.toml Startup was a little slow but once I got it going it worked like a charm. I'm very impressed with this project I hope it succeeds. 
You: to see a snapshot /r/golang before and after your comment :-)
That's precisely one of the situations accounted for by minimum version selection. I highly recommend reading the blog series Russ Cox wrote on the ideas behind it.
You sir, are awesome. I don't know if the Reddit programming community is usually like this, but this kind of feedback is amazing. I'm starting to learn golang and I hope my journey will be as good as OPs. :) 
https://blog.golang.org/package-names explains the why around package naming. 
In idiomatic Go code, you should not use underscores in variable names, use `colorVector` instead. To answer your question, use an array, rather than a slice: type vector struct { dimension int values [3]float64 } 
If I do that, then my vector becomes constricted to just 3 dimensions. I may later need a `Position4Vector` which can be a vector of 4 dimensions.
Line 12 says. How can I add a constraint so that a color vector will only be of 3 dimensions? But then you say you don't want the constraint cause you might need 4?
I want baseVector to be as generic as possible. It may be used to store coordinates, or colors, or even other things. As such, I want it to be flexible. However, I wish to impose the 3 dimension constraint _only_ on `colorVector`, not on `vector` itself.
Not sure if this is what your looking for but it will enforce the number of calls to match the specified dimensions and return the struct https://play.golang.org/p/9v2RGNxtrBs
So you want to have vector be a slice (extendable) and colorvector be an array? https://blog.golang.org/slices 
Yeah, this suits my purpose, and I am currently going with this. I was just wondering if there was any other way to convey the information that a `colorVector` is "a vector of 3 dimensions".
Yes
The only way to enforce 3 dimensions is specify the array length as provided in another comment.
Alright. Will do that.
Mattermost could use some features, it doesn’t have everything Slack does, currently.
i don't understand your question . would you like contribute in golang projects then visit gitcoin
Fuck yes this looks great, thanks OP!
I'm not a Go developer, just started to explore the language, but to touch on your point about package names, I was just reading: [https://talks.golang.org/2012/splash.article](https://talks.golang.org/2012/splash.article) (section 8) which reinforces your statement about using short names. I'd almost liken this to the naming and importing of JavaScript modules (kind of...).
Thank you so much for feedback! I hope you find Koazee useful, &amp;#x200B;
I didn’t test your code but atvfirst glance using loop parameter *subreddit* as variable to closure used as goroutine in a loop is not a good idea. See https://github.com/golang/go/wiki/CommonMistakes
Nice post. We use a similar setup, but employ a graphql server as api endpoint. Gives us a well documented and flexible api surface. Everything is running smoothly so far and exploration of the api with graphiql is really convenient. However, the developer experience with graphql and go still leaves some things to be desired. I constantly feel like we are writing more code then should be necessary, schema stitching is somewhat of an afterthought – although we built a simple in house solution that works for our current usecases – and it would be nice to get information about the complete request query in a grahpql handler, so that we can optimize data fetching without falling back to something like a dataloader. 
[Relevant](https://www.youtube.com/watch?v=b2F-DItXtZs)
Could you go into more detail on your implementation and what problems you and your team are facing? We tried a similar thing using Go for Microservices and a Go graphql gateway. We ended up having a chain of adapters in all layers to translate between databases/external services, grpc model structs and graphql model structs. We were thinking of solving all this with either schema stitching or code generation of the gateway from a graphql definition. I'd be happy to hear some more opinions on this topic.
We do a very similar thing as the OP. Works really well. We also generate swagger from the protobuf definitions which is used to generate HTTP clients (e.g. JS) and documentation. The only thing that slightly annoys me is that there is no way to expose the GRPC services as HTTP directly.. You always need another network hop (albeit over localhost) to translate HTTP to GRPC. So in our case both servers are running in the same binary and it just sends the request back to itself. For this reason I'd think it would be unsuitable for very high performance applications (though I have no numbers to back this up).
Sorry I fell asleep. Arrays "—but their most common purpose in Go is to hold storage for a slice." Please reread https://blog.golang.org/slices because it describes like 5 different ways and they allow for customization. Basically if you want robustness use "make" and if you want to the easy copy pasta API version then use "copy" (no pun intended). https://play.golang.org/p/I5hNHoRY7VZ https://gobyexample.com/slices
http://www.firsttimersonly.com http://up-for-grabs.net/#/ 
Hi there, once again thank you very much. I made some changes according to your comment and what I read online which I believed made some great improvements, however I am still uncertain about how to exactly deal with configuration. I made a branch called "configuration" and added the changes there. I believe it is now much better, but I'm not sure if that's truly the Go standard as I've seen various ways to do it. I used a package that is meant for environment variable configuration it looks quite well to me. 
Hey, code already looks better. I think you can agree that shorter package names helped readability a lot. You can handle the configuration in this way. I'd move the configuration as far away from business logic as possible such that I have a clear separation. I do not want to care about how configuration parameters are loaded, my business logic expects specific parameters to function properly. As such, you'll find that most go programs load the configuration inside the main function. Aside from that - make changes to your error handling as recommended in my first post. Finally, lets talk about the code structure (this applies to all software development independent of Go): *snapshot_storer.go* constructs a new MongoClient for every call. *fetcher.go* has the *dbConfig* and passes this information to *snapshot_storer.go*. Now a new "customer" comes in and wants to store the results in a file instead. *What do you do (what changes/additions do you have to do)?* This would be an ideal case where you want to use **interfaces**. You can have an interface called **Storer** with one function **Store**. Then you have different implementations that satisfy the interface - one that stores items in a database and one that stores them to a file. What you get from this change is that your business logic for fetching items is independent from storing items. Especially, fetching does not need to know how items are stored and how to connect/create the storages. To illustrate that further: A second customer comes in an wants to store items in memory. What do you do? With the interface in place you'd provide a new "memory storage" implementation and you're done. Finally, a third customer requires an item to be stored in all three storages (database, file, memory). Again, this is simple to achieve because you have a good code structure now. In this case you create a new storage implementation that combines a set of storages. To some extent using interfaces everywhere can be an "over-engineered" solution - so always make sure you understand why you're using an interface now.
https://gitlab.com/xacrimon/swc2
Where is the Why of it ?
I have implemented a simple example \[here\]([https://play.golang.org/p/GMYMc2GnJ41](https://play.golang.org/p/GMYMc2GnJ41)). I think it is correct. But it is incomplete since it only shows how the multipart headers are created. The complete header fields are not shown, as well as the appropriate encoding. Note that the main header fields of the mail need also to be encoded. 
Awesome 👍 
Thank you so much! 
You might want to start grpc proxy on localhost using unix sockets if the overhead of TCP is a bottleneck.
More than welcome to stop by my little 3d engine https://github.com/thegtproject/gravity i just added Dear IMGUI to it, i'll commit in a bit
http://eagain.net/articles/go-dynamic-json/ is another good post on the topic.
thanks for your help 
These are all excellent suggestions. The problem I face all the time is the lack of domain specific knowledge. A lot of these projects require some level of understanding or require one to have used the software. In such a scenario how do you approach making contributions ? Is it necessary to understand everything about the project ?
This is really good. Thank you. IPFS looks really promising (found it by filtering for Go repos)
How exactly would I approach contributing in this project. I understand there is always documentation and other non code related contributions but I am specifically looking for substantial coding projects. I do a lot of devops and Kubernetes administration at my new job,but I don't want to lose touch with my coding side. 
This requires a good grasp of opengl right?
Would be cool to see you use typescript as well. 
And while he's at it, why not "upgrade" golang to C#?
Because this is a Golang sub... ? Vue has excellent support for typescript, it's with demonstrating.
Hello! I have a created small niche project that lets you see all docker logs in your browser. The backend is written in Go with the front end being in VueJS. The logs are streamed using event streams to an EventSource in javascript. It was also interesting to use packr to compile all assets in the final binary creating a &lt;10 MB file encapsulates the whole thing. Feedback is greatly appreciated! Thank you. 
You know what, you're right, that was unwarranted and that was mostly just my bias (I'm not a fan of TypeScript because it makes functional programming far more difficult.
You can try to make some PR in github.com/MontFerret/ferret. It's a declarative web scrapper written in Golang. There are several good first issues: https://github.com/MontFerret/ferret/issues/16 https://github.com/MontFerret/ferret/issues/34 https://github.com/MontFerret/ferret/issues/54
I think Go is terrible for beginners. Practically speaking, you should start with something like Python. Get comfortable expressing ideas in code, writing simple algorithms, using control flow, error handling... Python will put less in your way to learning these concepts, its more popular and more mature. Personally, I don't really care for Python but this recommendation is for learning purposes. FWIW I write Go professionally. Prior to that I came frame a background of Haskell, elixir, erlang, java, python et al. Of all the codebases I've worked on, codebases with Go tend to be the most problematic as they grow. I can really only recommend learning Go as means to learn pointers for the first time, but thats not a strong recommendation.
They have an open source server component which I’m sure has tons of open tickets. https://github.com/mattermost/mattermost-server/issues Check out the ones tagged “up for grabs”. 
You can do something like that, but you need to create the second "inner" map.
Hey, I am working on a library to make life easier when working with arrays, https://github.com/wesovilabs/koazee Would be great have feedback for someone who comes from other languages I hope this can be useful for you 
&gt;3 comments I know this comment was "hidden", not sure why. However, /u/trenno I find your response interesting. I have been trying to embrace typescript with reactjs, and man, I find it harder to do things.. get lots of odd issues. I like the overall concept.. and Flow, the alternative seems to be going out of favor and more leaning to TypeScript. But I find I spend a lot of time trying to figure out how to use TypeScript (havent formerly learned it..just learning on the job which slows me down). I find what you say interesting because lately I have been seeing more people post about how they feel similar to me.. it slows them down, its great idea, but makes things more difficult. &amp;#x200B;
I am still trying to grok the "best way" to set up a top level project that uses multiple languages and stacks in it. I like the idea of a top level folder, and then below that I have folders for web (for css, react, js, etc), and then folders for things like microservices, docker, etc. Below microservices I have the languages, in my case, java, python and golang. Then below those I try to set them up like a typical project in their language. For java, it is a maven setup, and for golang basically the package structure with a main.go in the "root" of the golang folder. Does that seem wrong by any chance? I see in your case you have .go in the root of the project, plus client, db, etc. I too was going to add a db/ at the top project level, namely for any sort of schema/migration routines. I am not well versed in this. In Java we use Flyway, but not sure if that can apply to a project that a) is microservice based and b) is in two+ languages (on the back end). 
I hate to ask, but can you show me an example of what you mean? It's just not clicking with me how to do this. For example, I tried this: func main() { Classes := make(map[string]string) Grades := make(map[Classes]string) } That seems kind of intuitive, but it fails because `Classes` is not a type. This is becoming so convoluted that I'm losing track of what the heck I'm doing. Perhaps I'm making it too complicated. It seems like this should be a simple thing to accomplish.
&gt; I clearly cannot do something like this: You can, but you have to initialize each map before. Like this: https://play.golang.org/p/QCmqrUd-FDK &gt; I think maybe I need to use structs for this Maybe, but a Map and a Struct are very different things. &gt; Should I be thinking about this completely differently in Go? Yes, you have to. Most, if not all, scripting programming languages _(Python, Ruby, JavaScript, PHP, etc…)_ allow you to dynamically allocate these arrays/slices/maps/dicts because the interpreter takes cares of the types. However, in a compiled programming language like _(C, C++, Go, etc…)_ you have to specify them explicitely, and consequently initialize them. What you were doing with the `map[T]T` before was correct, you just forgot to initialize each sub-map before inserting another key. If you decide to change your code to use a different data structure, then you’ll have to change the way you are inserting data, it will not resemble a map anymore. This is the `struct{}{}` approach: https://play.golang.org/p/AIaIMOY4aW2
[See this playground posting, with comments](https://play.golang.org/p/HMTJYYX3chp). I'd probably actually make separate types rather than strings. Grades in particular should be some sort of enumeration-y thing, and even classes probably should be. But one thing at a time, right?
[This comment could be copied and pasted here](https://www.reddit.com/r/golang/comments/a3yqf9/wich_open_source_projects_are_good_to_start/ebb76so/)
&gt; I'm not a fan of TypeScript because it makes functional programming far more difficult How?
Go is not python. You are going to have to throw out some of the ways you have learned to work with python to become an effective go developer. One of the major features of go over python is go has very strong typing where as python has dynamic types. This makes what you are trying to do with python dicts a huge pain in go. So don't. Your example is close to the python equivalent, though for each person you need to `make(map[string]string]) before you can assign the grades: https://play.golang.org/p/XZu9Vip2RV_f But this is terrible go style so don't do that. Instead it is better to think about the data structures you want and how you want to use them. It is quite hard to come up with a better one for your example since you have no details about how it might be used but one way is to use a list of Students instead: https://play.golang.org/p/p3Phz3l-jOP Though that might also not be the best for your use case.
Thanks! I appreciate the help.
A close translation of Python is: \`\`\` func main() { grades := map\[string\]map\[string\]string{ "John": map\[string\]string{"History":"A", "Math":"B"}, "Sarah": map\[string\]string{"English":"A"}, } fmt.Println(grades) } \`\`\` And maybe this would be good enough for your use case. &amp;#x200B; A more "typey" would be \`\`\` type Student struct { Name string Grades map\[Class\]Grade } type Class string type Grade string &amp;#x200B; func main() { grades := \[\]Student{ Student{Name:"John", Grades:map\[Class\]Grade{"History":"A", "Math":"B"}}, Student{Name:"Sarah", Grades:map\[Class\]Grade{"English":"A"}}, } fmt.Println(grades) } \`\`\` &amp;#x200B;
Go's type system is _awful_ if you try to embed traditional mathematics into it, and I extremely strongly suggest not trying. You will, for instance, discover that it is impossible to write a generic dot product function that at compile time ensures two equal-length vectors, and that's just the beginning. So I've seen this sort of thing four or five times on /r/golang, and the summary is: If you are doing this to _learn Go_, I extremely strongly suggest switching tasks. Perhaps a nice web server with some handlers or something. If you are doing this because this is the _primary problem you have_, and you want to solve it with Go, I would extremely strongly suggest either switching to another language that can actually do these things, _or_ waiting until Go generic support is released. I am only suggesting, because of course it's up to you, and fully your choice. But... trust this random Internet dude... trying to embed compile-time type-correct vector math into Go right now is simply not possible. The tools aren't there.
Thanks! That extra idiomatic version is giving me a lot to unpack. I appreciate the help!
Just so you know, backticks don’t work in the old Reddit UI [1]. [1] https://i.imgur.com/4fnTmLQ.png
Once I'm up to speed, which will be a while, I'm tempted to come up with a resource like an intro to Go for python programmers who are more like me, scripters rather than real programmers. There are a lot of concepts that we need to learn and be aware of before Go makes sense.
[removed]
What kind of odd issues? I’ll never use React without TypeScript again. Any specific things giving you trouble?
I do think you should use structs for this. Go is a statically typed language and it works best if you make use of structs and Interfaces. In your case though you'd need a map[string]([]Classes). With this you can map student names to a slice of classes. Or in your example on the bottom give the student struct a member like ClassesAttended []Classes Which would again be a slice of classes per student but this time the classes are tied to the student type
Due to the way SPA's work using HTTP calls to raw data, I personally like to separate my front end code base from my back end (at scale, at least). My rational is that, though I may be building a full stack application, I will see more return value out of treating my API as an external system on the front end than as one I have control over. The same is true the other way around. I don't think my back end should always be providing data based on the needs of my front end. Now, I think of all that as a guideline. There are arguments to be made for back end data being transformed or arranged specifically for front end use; but I think it increases coupling if this is always our mindset.
`type Student map[string]string` `func main() {` `grades := map[string]Student{` `"John": {` `"History": "A",` `"Math": "B",` `},` `"Sarah": {` `"English": "A",` `},` `}` `fmt.Println("Hello, playground:", grades)` `}` &amp;#x200B; &amp;#x200B;
We have been using Golang and Vue.js together for quite some time. Although they're separate technologies, I think they go well together. :) Would be interesting to see if there were a way to combine gopher.js and Vue...
We almost exclusively use GraphQLGen ([https://gqlgen.com/](https://gqlgen.com/)) when creating APIs in Golang. 
I'm curious how to deploy app like this (frontend + backend in single repo) using Docker? Separate Docker image for backend and frontend or single?
Show us the code so we can replicate the behavior
The most likely beginner error is using the wrong working directory. Do you have any logging or error messages? The standard way is to use the os provided service management features. 
I'm not getting any error messages so I'm not exactly sure what's wrong. I'm on Ubuntu 1604, would this be like systemd services? I need to start up to 50 of these servers all of which on differing ports and be able to close individual servers. For context, I'm then going to try to try to send requests to these servers to simulate load, and see how they respond when some to down.
The default behavior of exec.Cmd is to output stdout/stderr to /dev/null. If you aren't checking your output properly, you won't know why your program is deciding to terminate earlier than expected. A quick check would be to set cmd.Stdout = os. Stdout cmd.Stderr = os.Stderr That way you can actively see what your process is telling you. 
Take a look at https://godoc.org/github.com/ConradIrwin/font/sfnt, it can parse quite a few formats, and mentions Type 1 font format at https://godoc.org/github.com/ConradIrwin/font/sfnt#TypePostScript1. I'm not sure if it's fully supported. You can try searching further, or consider implementing a parser by reading the Type 1 font specification.
Ohhh ok. I will give that a try and see what it is spitting out. Thanks
Separate repos/projects would be my preference. Repo for the API, and another for the front end 
Yes, systemd, but only for one server, not to manage a cluste. // Stdout and Stderr specify the process's standard output and error. // // If either is nil, Run connects the corresponding file descriptor // to the null device (os.DevNull). // // If either is an *os.File, the corresponding output from the process // is connected directly to that file. // // Otherwise, during the execution of the command a separate goroutine // reads from the process over a pipe and delivers that data to the // corresponding Writer. In this case, Wait does not complete until the // goroutine reaches EOF or encounters an error. // // If Stdout and Stderr are the same writer, and have a type that can // be compared with ==, at most one goroutine at a time will call Write. Stdout io.Writer Stderr io.Writer Sorry for the formatting, I'm on mobile, but that's a section of the docs
My preference is two containers, one for frontend, one for backend. This matches a server git repo and a client git repo. This just seems cleaner to me and allows updating versions independently.
I think that's a worst of both worlds approach, and I think the only reason it exists is because Elixir lacks a decent WebAssembly compilation target. "kweb" is a similar project for Kotlin, and I know I've seen others, but I don't think any of these are used by many (if any at all) "real" companies. So, even if someone is working on something like that in Go, I wouldn't recommend it. Vanilla, modern JS and CSS are plenty fine for adding the small bits of interactivity that these projects offer without the network latency or wasted user bandwidth.
Unfortunately doesn't seem to be supported. I guess either I'll need to implement Type1 parsing, or use something like [https://github.com/adobe-type-tools/afdko](https://github.com/adobe-type-tools/afdko)
Agree with this. I usually serve the client from the server and use an environment variable to determine where the client folder is located. That way, the server binary is portable and does not care about the location of the client folder. I use the following folder structure. ``` / /server /httpd main.go /handlers index_get.go ping_any.go /client ...client_files ```
I usually serve the client from the server and use an environment variable to determine where the client folder is located. That way, the server binary is portable and does not care about the location of the client folder. I also use a makefile to build/run the project. I use the following folder structure. ``` / makefile /server /httpd main.go /handlers index_get.go ping_any.go /client ...client_files ``` Extra: I tried to use node's concurrently and watch packages to build/watch the client and server. I haven't had any luck ``` export APP_CLIENT_DIR=$(pwd)/client npx concurrently \ "cd server &amp;&amp; npx watch \"go run httpd/main.go\" server" \ "cd client &amp;&amp; npm run watch" ```
I would like to think I could look at the project as a whole in my IDE of choice. Are you saying each and every service has its own repo.. but then somehow I put all those under a top level folder, and open that folder up in my IDE, for example? Is that how you would typically open up the entire project even if the sub-folders lead to separate repos?
I haven't made it to learning interfaces yet. Based on what I can see so far, dealing with these sorts of data structures without using structs is a giant pain in the ass, totally unlike what I'm used to in Python. Structs seem like they might be the best way to manage this kind of thing and keep track of what's going on.
You could use “expiration time” as a field. Or use the creation time + lifetime. 
Where I work we have them as separate repos because we have people who focus on the React frontend and others who focus on the (mostly) Go backend services. It helps keep the pull requests targeted as well as the deployments. This requires more communication to make sure everything's synced correctly. For a team less than five, that may be overkill. That's the rough rule I'd suggest, but every team is different, so that may need to happen sooner, later, or not at all. 
You could spin off a go routine that waits for time.After(...) to complete. This may not be ideal if you need to watch a large number of records though.
I typically use a two stage build and have all the Node stuff as a separate stage that then has its files copied into the other app’s static files directory. 
yes. ie. Go uses git tags for versioning... so everytime you cut a tag on your front end your Go project version goes up. anything above v2.0.0 and you have to explicitly import the version in your source files. repos for front end and API, then mkdir myproject &amp;&amp; cd myproject git clone .../myapi.git git clone .../myfront.git atom . or if you reeeeally want git functionality, just open two project windows.
S3 with Cloudfront cache for front end. Whatever docker based tooling AWS has for the backend. I forget what it was called. AWS Lambda and API Gateway work well for certain apps and can cut cost and raise reliability significantly. But that's a whole other can of worms.
URL?
[removed]
I've been using Python since version 1.4. I'm also now fairly decent at Go (though I have a background with C and C++ also). So I have an experience that I hope allows me to say that what you are experiencing is an impedance mismatch with trying to thing of Go as Python-like. Coming from Python, Go at first seems to have some superficial syntactical similarities (built in dictionaries, slices and iterating over a range, channels/goroutines that feel like generators, etc.) but as I got better at Go, in many ways it still feels more like C. It is \*semantically\* very different from Python, and so I think you'll fare better by realizing that although some of the nomenclature sounds like Python, it's best not to try to think of it from a Python-like language. You may go farther (no pun intended) by accepting that it's best to not compare it too closely to Python, and just be open to the way that it does things. This is especially true for slices, imo, but also for maps, channels, and other language features. That said, I really enjoy both Python and Go; once you get the hang of Go, you'll see that it does live up to the promise of not having very many "surprise" language constructs. You can look at an arbitrary piece of Go code and have a pretty good idea of how that code should execute, even if you don't yet have the larger picture. Python has traditionally been like that as well, so I feel it's one strength they both have. &amp;#x200B; Now, as to nested maps, I use them all the time. I find it convenient to make new types and aliases to help indicate what's happening. type Student = string type Subject = string type Grade = string type SubjectGrades map[Subject]Grade type StudentGrades map[Student]SubjectGrades Here we see that we can indicate that student grades are a mapping of names to subjects and their grades, with each subject having a grade, etc. Here I use (and I'm sure many would say "abuse") type aliases to indicate what the 'string' type in each map represents. It's a bit overkill (comments might be preferable), but shows how the explicit typing of Go can really document the abstraction. Once you get the hang of using Go types, you may discover that Go can be \*way\* more easily refactored than Python, and even C or C++. It's a type system that I've really come to enjoy using. Go dicts are a bit like Python defaultdicts, so that that you can for example access a non-existent entry and get a default empty value. \*But\* the default value for a map is nil (kinda like None), not an empty map, so you still have to be sure to initialize your maps before using them (in the above case it means you have to make() each SubjectGrades type). Adopting the Go idioms, having come from Python, will take a little time, but after about a week it'll start to make sense and become second nature. Just don't expect them to map too closely to the Python way, and instead be open to the Go way of things.
That helps a lot! I really appreciate the help. And since you use the term "impedance mismatch", I'm guessing you may be a fellow audio engineer or musician, as well. lol Coming to Go from Python can be pretty frustrating. I spent the first day or so saying, "WTF? Why? This is convoluted and way harder than it needs to be." However, that's because I'm coming to Go with the wrong mindset. As you say, I need (and want) to learn the Go way of doing things. Is there a Go version of the word pythonic? lol
Hey, I've been going through the package and wondering if it's safe to expose directly to the internet using certmagic.HTTPS()? I've been going through the package and it seems like no, just want to make sure I'm not missing anything.
The defer statement basically moves the done to the end of the function, after the send. Since you're receiving after the wait group finish, and your wait group cannot finish without send to return, you have a deadlock.
If you add an ExpiresAt time field you won't need to update the database and you can just check when fetching rows.
Yep, I just figured it out. I guess it should have been obvious, but my brain is fried. Now I'm pondering how to handle this in a better way. I was just wondering if instead of waiting for the channel to be full and closed, could I write another goroutine as the reader?
wg.Wait() blocks before anything has an opportunity to read from a channel which introduces a dead lock. i guess you could close the channel asynchronously like: go func() { wg.Wait() close(fooVal) }() &amp;#x200B; or you can cluster your worker function startup in one go-routine which i would consider functionally equivalent but keeps all of the relevant code in one go-routine instead of spreading it out across a global variable and multiple functions: `import (` `"fmt"` `"sync"` `)` &amp;#x200B; `func foo(c chan int, someValue int) {` `c &lt;- someValue * 5` `}` &amp;#x200B; `func main() {` `fooVal := make(chan int)` &amp;#x200B; `// spawn workers` `go func() {` `wg := sync.WaitGroup{}` `for i := 0; i &lt; 10; i++ {` `wg.Add(1)` `go func(i int) {` `foo(fooVal, i)` `wg.Done()` `}(i)` `}` `wg.Wait()` `close(fooVal)` `}()` `for item := range fooVal {` `fmt.Println(item)` `}` `}` &amp;#x200B; &amp;#x200B; &amp;#x200B;
This is not the normal way of doing this. You should just set an "expires_at" timestamp and then see if that's after the current time. Or, you can compare the "created_at" to the current time and if the difference is over a certain amount the record is invalid.
&gt; I guess what I could do is write a reader that also runs as a goroutine, right? Yes, move your reader into a goroutine, spawn it before creating your producers (or at least before the call to `wg.Wait()`).
The simplest way is to remove the wg and just count 10 times in your receive just like in your send, or you could do the waiting and closing in its own goroutine. You want to start receiving before all the calculations are done, otherwise, you are queuing all the data even if you didn't specify a buffer size.
Why exec instead of just exporting the relevant code and starting the server in the new app?
This is what I just tried and I'll be damned...I got it to work! This makes me unreasonably excited. package main import ( "fmt" "sync" "time" ) var wg sync.WaitGroup func foo(c chan int, someValue int) { defer wg.Done() c &lt;- someValue * 5 } func main() { fooVal := make(chan int) go func() { for item := range fooVal { fmt.Println(item) } }() for i := 0; i &lt; 10; i++ { wg.Add(1) go foo(fooVal, i) } wg.Wait() } 
Not go specific, but instead of calculating the shortest path on every pair, calculate the shortest spanning tree for every node.
People just say “idiomatic go” mostly in place of pythonic I think.
I'm currently using a Python module called `dijkstar`. I feed it the nodes/edges first so it can build the graph. Then I pass it pairs of endpoints to calculate the shortest path. There are roughly 1400 endpoints, so I end up with almost two million calculations. I found a Go module that does something similar. It has a method to add the nodes and edges, then another function to calculate the shortest path. The downside is that it uses integers as node names, whereas my data and Python script use strings (router names). I guess I'll have to build an index to match node names to an integer, then map it back to a router name before I save the results. 
I need help on this web app that spawns go-ethereum nodes in the cloud https://github.com/WeTrustPlatform/blockform I plan to add IPFS nodes support too
https://github.com/WeTrustPlatform/blockform can spawn go-ethereum nodes in the cloud The base of the project is well established, with CI and auto deployment on Heroku. There is a list of issues that are simple enough for beginners, and more advanced issues too.
User name checks out.
https://en.m.wikipedia.org/wiki/Shortest-path_tree It's a very simple algorithm to implement. The shortest path algorithm is basically the shortest tree with all the branches to other nodes thrown out. With the correct implication, you should easily get your algorithm to finish in a few seconds. 
Non-Mobile link: https://en.wikipedia.org/wiki/Shortest-path_tree *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^224903
Could you open an issue and detail more what you mean?
Looks fine to me, though you probably still want to `close(fooVal)` after the `wg.Wait()` - even though this particular program exits here, if you were to go on to do something else, you want to close the channel so that your read loop exits and everything gets cleaned up. The `for` loop is idiomatic. I'd probably move the `wg` declaration into the `main()` scope and pass it to `func foo()` as an argument rather than making it global, but it's fine either way. If your reader was more complex, you might move it out to its own function, but for a couple of lines the inline anonymous func is also fine.
The pattern which keeps the reader code inline, which I find to be easier to read, is to run the Wait() in a goroutine, rather than the read, and have that same goroutine close() the channel, thus indicating the end of the input. I'm suggesting something along these lines: func foo(c chan int, someValue int, wg *sync.WaitGroup) { defer wg.Done() c &lt;- someValue * 5 } func main() { c := make(chan int) var wg sync.WaitGoup for i := 0; i &lt; 10; i++ { wg.Add(1) go foo(c, i, &amp;wg) } go func() { wg.Wait() close(c) }() for _, item := range c { fmt.Println(item) } } &amp;#x200B; &amp;#x200B;
why it emulator called?
Is this intended to replace the, IMO ugly, XMB inspired frontend used by most retro arch implementation?
Old post, but maybe someone else like me stumbles upon this. In case you have a non Linux machine and want to compile for Linux with CGO it's easily possible with Docker. In the example below I compile my deltajournal-project with golang 1.11 and install systemd C-libs necessary in my case. build script (no dockerfile needed) #!/bin/bash set -euo pipefail IFS=$'\n\t' docker run --rm -v "$PWD":/go/src/deltajournal -w /go/src/deltajournal golang:1.11 bash -c " set -euo pipefail IFS=$'\n\t' /usr/bin/apt-get update apt-get install -y libsystemd-dev go get go build"
Sorry, my bad. [https://github.com/3timeslazy](https://github.com/3timeslazy).
If expiration time does not change, add another field to your structure with a timestamp and calculate time period on access. If expiration can occur at any time and is performed by an external entity, you have to verify the current state by querying the database. This is usually done also on access, but can be cached.
...what?
Well not exactly replace, as RetroArch support multiple menu systems anyway. But Ludo is a small hackable codebase, so it's a good place to do UI experiments that can later be implemented in RetroArch after they are proven successful.
Postgres. No ORM, 90% of data writing queries are stored procedures to protect data integrity, others are optimized select queries. jmoiron/sqlx and golang-migrate/migrate. Tried it as a different approach to symfony/doctrine and found it pretty slick, easy to document and down to earth.
Start playing with something and make small contributions. You learn along the way. 
I would recommend echo not only because of the vast and useful documentation and the results of my benchmarks. I am getting 8k RPS with echo vs 6.xk RPS with Chi for a very old machine of mine. To me, the selling point is documentation. &amp;#x200B;
MongoDB with globalsign/mgo, but I’m waiting for the official MongoDB driver for go to support go modules
 "For example, a number variable cannot be changed into a string of text or vice versa." What???? What kind of piece of data is that?
I use gorm because I am a scrub. :D
PostgreSQL and GORM. I've found that GORM is great for quickly setting up basic CRUD without the crazy verbosity of SQL + manually mapping fields, and it helps with managing migrations. Later on, it's trivial to swap out GORM queries for optimized SQL where necessary (those queries have turned out to be in the small minority for me). My reasoning for using GORM was that I am generally not a big fan of code generation, and the cost of reflection is pretty insignificant in the context of anything DB related.
postgres + gorm, working pretty cool
&gt; This means that the next wave of blockchain developers will be able to do just about anything with CX: smart contracts, decentralized apps, machine learning, video games, even CX itself will be developed with CX. What the fuck are you smoking.
I mostly use Postgres 
For the status I would rather use an int for quicker comparison. Or even a byte if they are no more than 256
|Type|Project|Database|Migration|Backup| :--|:--|:--|:--|:--| |personal|simple RSS feed reader|SQLite + handmade SQL toolkit (sharing on GitHubsoon™)|none|cron job: 1) pause crawler 2) copy SQLite file 3) resume crawler. rsync transfers the copy| |personal|cryptocurrency arbitrage monitor|SQLite + GORP|schema doesn't change often enough to justify migration|app generates one 5GB .sqlite file per day. rsync backs them up| |consulting|Intranet web app|MySQL + GORM|https://github.com/rubenv/sql-migrate|&amp;nbsp; mysqldump | |consulting|API for mobile app|K/V storage https://github.com/dgraph-io/badger|none|&amp;nbsp; https://github.com/dgraph-io/badger#database-backup| 
All my interviews so far have been pen and paper or whiteboard
Postgres Driver only [lib/pq](https://github.com/lib/pq) No ORM, just some generators I wrote for basic CRUD operations, then more specific queries as needed. [pressly/goose](https://github.com/pressly/goose) for migrations.
I tried a couple non-sql with the goal in mind to use one that was written in go. I find myself either going for [https://github.com/HouzuoGuo/tiedot](https://github.com/HouzuoGuo/tiedot) if its not very complex or [https://dgraph.io/](https://dgraph.io/) if its more complex data. Although something like cloud sql would be very interesting too.
Oracle (legacy) with gopkg.in/goracle.v2 and generate the structs from tables with a fork of xo/xo (go-goracle/xo). Easy to customize the templates.
Postgresql lib/pq jmoiron/sqlx no orm For migrations i've a table version where i record the current version and Go code (in the same app) with handmade sql to upgrade to the next version.
MySQL, and dbr which we have a wrapper for to add some ORM like functionality. Migrations are also handled by a package which one dev wrote. 
Are the procedures created through migrations as well?
I have tried posrgres with go-pg for personal projects, it's working great for me. You can use the ORM or use a plain SQL query.
Is gorm bad?
Sure. Everything related to the database is in migrations, down to the point where specific addons are enabled and configured.
Not bad at all. Use whatever you want.
Buffalo's pop &amp;&amp; soda, but without buffalo. Switched from GORM, pretty happy.
No its pretty good. The times you don't really want to use it are when you gotta eek out performance or are dealing with legacy tables. I meant scrub because I'm not that good at SQL XD
This is literally golang with int32 renamed to i32 and some built in bitwise functions. Thats it
I learned a small lesson on sqlite, which is use the backup API, don't pause/copy. It guarantees a sane output file and deals with the details around the WAL for you (if you use the WAL, which after initialising datasets you pretty much always want to in my experience) Almost all my little sqlite based things are in the &lt;500Gb range, and I typically just go with a cronjob of `.backup foo.db` I do wish it was able to output to stdout while doing a backup so I could pump it through gzip / zstd / 7z / whatever.
* PostgreSQL and MySQL, * database/sql, github.com/jmoiron/sqlx, github.com/lib/pq and github.com/go-sql-driver/mysql * No, but we tried using Buffalo's Soda/Pop in the end we went back to using sqlx with explicit SQL statements. * github.com/golang-migrate/migrate
We are currently developing an application to manage quality documents for clinical research. This is comprised of multiple modules relating to organization of groups, training records, job descriptions and particularly controlled documents such as standard operating procedures. The user interface consists of a single page vue.js application and we have a graphql api endpoint that is written using the graphql-go/graphql package. The schema is "stitched" at compile time of the graphql endpoint. All services are implemented in go, use grpc for communication and have an envoyproxy sidecar to form a service mesh. For this, we developed the utility kolumbus, that allows us to connect from our local dev-machines into the test service cluster (https://github.com/dkfbasel/kolumbus). To avoid writing additional models/adapters for the repository layer of the services, we wrote a small utility ([https://github.com/dkfbasel/protobuf](https://github.com/protobuf)) that will transfer Golang tags to the proto structs. Permission-management is implemented separately in each service, but authentication is managed on the level of the graphql-api. We are then using grpc interceptors to automatically transmit the authentication context to the services via grpc meta-data. The main drawback of this solution is the amount of code that we are writing in the graphql layer. We do like the concept of first writing the graphql schema and then implementing this in code, but the current setup with graphql-go/graphql is very verbose in terms of having to write one method for every graphql property. I think that code generation could really help in this area, but I do not yet see a clear path that would allow the necessary flexibility while also taking care of all the superfluous steps for resolving simple properties. Maybe some sort of Frankenstein meta-language mashup of go and graphql could work. &amp;#x200B;
I write my own db system for each project. I find it easier to handle when it's me myself that made it. It's not much work if you make it to do one thing and one thing only 
Postgresql. [jackc/pgx](https://github.com/jackc/pgx) as the main interface. I've used several database-first code-generation marshaling / unmarshaling helpers such as [xo](https://github.com/xo/xo), but now use my own for that ([mro](https://github.com/wttw/mro), but I'd suggest looking at better maintained packages instead). I use [pgoutput](https://github.com/kyleconroy/pgoutput) for streaming changes from the database to the app. I store a schema version in the database. At startup the app applies a series of patch&lt;n&gt;to&lt;n+1&gt;.sql type scripts to bring the schema version up to date. There's a little bit of tooling to embed those in the app. If I were doing something more complex with the schema - such as supporting features rather than versions - or were running it solely on my own servers rather than distributing it I'd use [sqitch](https://sqitch.org) to manage the change sets.
I would love to help here. How can I get started on picking up the knowledge ? I have started reading up on IPFS and playing around with the CLI. Never worked with any blockchain or ethereum based technology. 
Use a generating ORM such as sqlboiler. It generates the model code by looking at your database schema. It is way more performant than GORM and it's type safe(no reflect stuff). I highly recommend it. 
go-pg has pretty good code, while GORM is horrible internally. And some postgres-specific features are nice as well.
Thanks! I'll try that. Not having to pause the crawler should simplify things.
What do you think of annotating the schema with directives to add the information necessary to resolve the fields from http/grpc backends. Then one could introspect this schema and generate the resolvers plus the final public schema.
&gt;jmoiron/sqlx This, I've tried the raw sql package and full-blown ORMs and I've found that sqlx adds just the right amount of convenience without forcing me into any specific patterns. Otherwise, I've been using [https://github.com/etcd-io/bbolt](https://github.com/etcd-io/bbolt) lately and have found it really enjoyable to work with. Not a standard database but for anything that can use NoSQL persistence it works really well.
I've been happily using [https://github.com/go-pg/pg](https://github.com/go-pg/pg) and [https://github.com/go-pg/migrations](https://github.com/go-pg/migrations). If you don't need cross DB support, go-pg works pretty well for Postgresql and has a compelling feature set.
Nice, would like to see more patterns involving concurrency :) Would it make sense to set the "size" of a channel, eg. `make(chan string, 3)` or `make(chan string, len(urls))` in this particular example? One minor note - in the `main` function you could omit variable `i` in the for-loop by simply doing `for _ = range urlsToScan`
postgres, lib/pq, jmoiron/sqlx and my own wrapper around sqlx, [femaref/dbx](https://github.com/femaref/dbx). 99% of the usage is for `Create`.
Interesting. Thanks for sharing. I don't know of something similar for Go yet.
[CockroachDB](https://github.com/cockroachdb/cockroach/) as the database. [GORM](http://gorm.io/) as the ORM. [golang-migrate/migrate](https://github.com/golang-migrate/migrate) for database migrations. Not 100% sold with using GORM over doing queries by hand, but it's worked good enough for now. 
You can simply make it `for res := range ch { ... }`.
Postgre + go-pg for the last 2 projects. Only one that worked for me. I'd like to try some kind of SQL builder + pq in the future but I doubt it will be better. go-pg is really fast and I can live with its ORM.
SQLite for small projects + gorm Would love to use cockroach + gorm in other projects too. I use gorm because I’m not really good at sql and most of my uses are really simple CRUD too. 
&gt; Which database you use? PostgreSQL &gt; And what libraries you use for the database? lib/pq + `github.com/jmoiron/sqlx` helpers &gt; Do you use ORM? No - just basic CRUD implemented on model structs &gt; How do you manage migrations? https://github.com/pressly/goose
- Aurora (locally MySQL), redis - dbr, redigo - kind of, dbr, but it's not really ORM - github.com/golang-migrate/migrate
I'm surprised I had to scroll so far to see SQLite! SQLite is a great system which works very well for the small projects I manage - 50,000 inserts a day, or something of that order. Anything larger than that and I'd be reaching for postgres.
It requires more work, but you can also use the SQLite internal backup API to do that and have your application do the backup itself. It will automatically write new data in the backup while it is being performed, you can control its rate, print completion information, and it makes your application even more self-contained because then you don't have to worry about the compatibility between the sqlite cli tool and the embedded sqlite. It's a bit clunky to do though because you need to register a connection hook so that you can get the *sqlite.SQLite3Conn of the main connection, then you need to open a second one to the backup file, also get its *sqlite.SQLite3Conn, and finally do the backup.
I'm good at SQL it's just actually writing it is the ultimate turn off for me. ORMs, while they have their downsides, are so much more pleasant to use. It's all about knowing what your tools are doing at the end of the day.
&gt; Which database you use? I use ElasticSearch (note: I didn't necessarily *need* ES for this project, but figured ES would be a useful skill to have.) in one project and Postgres or Sqlite for everything else. &gt; And what libraries you use for the database? I use [this lib for Postgres](https://github.com/jackc/pgx), [this lib for Sqlite](https://github.com/mattn/go-sqlite3), [and this lib for ElasticSearch](https://github.com/olivere/elastic). &gt; Do you use ORM? No. &gt; How do you manage migrations? I do migrations manually because I'm a scrub.
Cassandra with gocql. No ORM. Built our own db migration with series of cql files.
Exactly the same setup, but with mariadb (and the mysql driver). I'm in the process of learning postgresql, but not confident enough to put it in production yet. Works like a charm. I'm curious though: do you use golang-migrate as a lib in your app or as an external tool ? 
I use mysql, sqlite and have occasionally used postgres. I use `github.com/Masterminds/squirrel` to build queries. I try to avoid ORMs as well as forcing database schemes into complex structs. Both provide decreased complexity in the beginning but tend to grow into headaches rather quick I find. Instead it has served me well to have a struct merely be a complete table scheme or a combin ation of complete table schemes with methods for extracting data which depends on multiple factors. I try to avoid stored procedures and instead treat databases as stupid data stores. I have worked with projects implementing large parts of business logic in the database and found them extraordinarily difficult to reason about and maintain.
Do any of those tools create generate go code? Essentially a set of funcs calling the stored procedures, with correct types and so on? 
I found it pretty easy to work with Postgres and [SqlBoiler](https://github.com/volatiletech/sqlboiler/). Used in my [Wanderinglunch](https://github.com/peppage/wanderinglunch) project.
Ranging over a channel executes until the channel is closed. This would cause the program as written in the example to never terminate. 
Don't forget the \`func Butts() ()\` extra parens
Have you tried go-pg/pg? I just started working with databases and would love some feedback on these tools. I like writing my own queries instead of using the built in orm though.
Just tested it, it throws a deadlock error, "all goroutines are asleep". Closing the channel makes it work. huh, TIL
I read in the protocol buffer documentation that there is a possibility for data loss on files bigger than 1 MB. Did you have any complications because of that?
Yes, EF is a Microsoft product for a different runtime (.Net) so there wouldn't really be a way to support it in a very different language like Go. There are still ORMs like GORM, the one built into Beego, and others, and a lot of people prefer to stick to the standard library with raw SQL to keep dependencies minimal. A lot of people that do that decide they then like the additional helpers available in SQLx. Still others use Bbolt or Badgerdb key value stores and often use bleve to enable querying / searching.
Entity Framework is an [https://en.wikipedia.org/wiki/Object-relational\_mapping](https://en.wikipedia.org/wiki/Object-relational_mapping) (ORM) for C#. There are several ORM's for Go, like [https://github.com/jinzhu/gorm](https://github.com/jinzhu/gorm). I don't know if it's any good or much about competitors since I've never needed to use an ORM in Go, but they do exist outside of the standard library.
Thanks a lot!, I'm amazed by how little documentation I found on implementing a proper REST API server architecture in pure Go (stdlib only), no wonder why people develop frameworks and why users rely on frameworks to do webdev. I'm actually prototyping a REST Server in Go (I know this post is very old, I had to put the project on hold and got to it past week) But I was thinking to migrate it to Echo, thanks for your suggestion, I agree, echo is well documented and I rather develop a not so fast product than getting lost amid of developing a product which would run amazingly fast but that I could not finish due to the lack of proper docs. Best regards
Are you calling stored procedures from Go? If so, can you share an example? I am asking for this because many threads on the Internet shows that Go did not support calling stored procedure or provided examples that are not very helpful. Thank you in advance. 
I haven't been using ES with go yet, but I do use it for work. How has working with Go been going for you? 
I regularly use GORM or sqlx with MySQL or SQLite (often if I use GORM I'll add both adapters) &amp;#x200B; I seldom work on existing datasets but if that is the case, migrations are usually pretty easy to handle in ORMs.
&gt; would like to see more patterns involving concurrency I suggest, at the same time, you seek out bug reports / stories about race conditions. Concurrency is one of the most heavily romanticized bits about golang, but it's also one of the most difficult things to get right unless your system is as simple as what's in OP's blog.
Can you link that? I'm not aware of such an issue. There are performance issues parsing large messages, but that's all I can think of.
Most recent project: I'm using badgerdb, which is an embedded key-value store. I do not use an ORM. I wrote [my own migration helper](https://github.com/vipnode/vipnode/blob/master/pool/store/badger/migration.go) which is quite simple. It's not very specific to badgerdb, so I might generalize it later. Overall fairly happy with this setup. Some of the data is "relational" so using a key-value store is a little more arduous, but the scope of the data storage is failed constrained so it's not a big deal. For a larger less-narrow project, I'd use PostgreSQL with no ORM. Personally, I avoid stored procedures unless the entire design of the app is naturally dependent on some nature of the underlying storage driver.
As lib inside the app, just doing a migration on startup before I spool up the gin http server. Not a huge project myself, just trying what is possible and what feels good and under-control in a small setup.
Nitpick: You should write "manner," not "manor."
Hey thanks for the feedback, good catch. I have made the change and will roll out when I next build
My personal preference is to use sync.Wait() to close the goroutine. It makes the code a bit more wordy, but consuming the function is easier if the channel is closed when empty.
[https://developers.google.com/protocol-buffers/docs/techniques](https://developers.google.com/protocol-buffers/docs/techniques) &gt;Large Data Sets &gt; &gt;Protocol Buffers are not designed to handle large messages. As a general rule of thumb, if you are dealing in messages larger than a megabyte each, it may be time to consider an alternate strategy. &gt; &gt;That said, Protocol Buffers are great for handling individual messages *within* a large data set. Usually, large data sets are really just a collection of small pieces, where each small piece may be a structured piece of data. Even though Protocol Buffers cannot handle the entire set at once, using Protocol Buffers to encode each piece greatly simplifies your problem: now all you need is to handle a set of byte strings rather than a set of structures. &gt; &gt;Protocol Buffers do not include any built-in support for large data sets because different situations call for different solutions. Sometimes a simple list of records will do while other times you may want something more like a database. Each solution should be developed as a separate library, so that only those who need it need to pay the costs. &amp;#x200B;
Pretty good, the library I linked has everything needed for most usecases implemented and feels pretty natural in Go.
Why not just use the word itself as the map key? You've turned a O(1) search into a linear scan through all the words with the same first letter.
I have been thinking of using CockroachDB. It is on the same level as Spanner (same group of people I believe). It seems like it was built for high scale and speed in the cloud, but I think (hope) it can be deployed locally in a minikube/docker setup so that instead of being stuck using an internet only "dev" Spanner DB, I can build/run DB on any dev machine so they can work offline, as well as QA.. e.g. the whole env can be run on a local box with no internet connection, and in production should hopefully scale nicely. Anyone have experience??
golangprojects.com
No and honestly I like it this way around. Not having all this magic made a huge impact on how much I trust the code. I use both worlds but giving control to a lib/tool that does code generation always leads to BC breaks sooner or later, forcing you to refactor the core components to make it work again. SQL on the other side almost never changes and all you have to deal with are some minor db engine quirks. If I want a specific type for IO, I define them in go and try to work the result into it. Maybe thats to naive, not sure.
&gt;github.com/mholt/... done [\#9](https://github.com/mholt/certmagic/issues/9)
Add a few more and you can call it a Lisp derived language!
Hm, it looks ok but I do not know the specific differences to lib/pq. Most times I work with the features jmoiron/sqlx, allowing me for easier marshaling of rows into structs and some other nice features. Most differences seem to boil down on specific implementation and how compatible it is towards database/sql.
Hm, traveling right now, but I know I had to fiddle around a bit myself. I'll try to get an example of code asap.
because searching through all words beginning with 'a' is better than searching through all words starting with any character or number
Find a simple problem you want to solve. Something you'd typically write a script for. Write it in Go instead. You'll be done pretty fast. However, don't stop there. That's just the appetizer. You've solved the problem using a full fledged programming language, so set high standards for what you want to accomplish - performance, usability, portability. Now modify your code to get there. This is where the real learning happens. 
I use the same set of libraries, except I don't usually bother with sqlx.
I believe @dgryski is talking about [something like this](https://play.golang.org/p/bnaLFp_irC1)
a map is not a array, it is a hashmap and has O(1) ish indexing, and it usually faster to just add another key to the map than to mess with lots of arrays that way. &amp;#x200B; For deduping try \`\`\` var dedupMap = make(map\[string\]struct{}) \`\`\` then to check if it is in, try: \`\`\` \_ ok := dedupmap\[key\] \`\`\`ok will be \`true\` if it is already included 
When I looked through the available options I thought pop looked very good, but it looks like (from the responses here) very few people are using it. Could someone reply why he did, or didn't, go with it?
Thanks everyone! Yep a small change of perspective and it makes sense - thanks!
I think this is another one of those guides posted as a question type posts. Good answer though.
github link: [https://github.com/proio-org/go-proio](https://github.com/proio-org/go-proio)
Awesome project only Fullscreen mode gives me headaches...
Thanks for the recommendation, I'll be checking this out!
also handy `str.print` 
Thanks! Yeah, looks like an cool solution to the current focus on heavyweight JS frameworks and completely sidesteps so much complexity and especially state replication to client. Also allows updates to be pushed down to multiple browser windows.
I wouldn't call it re-invention of turbo links, though it does do some similar stuff. This is the virtual dom on the server side as well, so only changes need be pushed. Looks like an amazing compromise for so many applications that need a decent network connection to operate. In the talk he mentions that an Atlantic hop is very performant for regular use.
Migration support that comes with GORM is pretty basic. It can actually only migrate up not down. And it doesn't keep track of schema changes. If you need to do a rollback you have to do it yourself.
I use BoltDB exclusively, with the regular bolt client: `github.com/boltdb/bolt` I don't use an ORM. I don't care for them very much as the usage of Bolt necessitates doing a lot of hand-rolled code to keep performance consistent and reliable. Data migrations are done with custom one-off programs, they run over hours/days while chewing through GB of JSON.
There are so many problems with this. First that comes to mind is if the process is killed before the time elapses....
I use the repository/service pattern where its very easy to swap the used library just by implementing the given interface. 
The #jobs channel in the [Gophers Slack group](https://invite.slack.golangbridge.org/).
I swear they have changed the words since I first saw the docs. The idea here is that if you use a stream you end up with multiple protofiles grouped into a single bucket. Each bucket can have a multi MB size, but the protofiles stay as small as possible
Go on
It's nice, long time ago I used it in one project that kept SQLite db in `:memory:` for performance but periodically dumped it via backup api for persistence
Yes, exactly what you say. CoachroachDB works fine with deployments as small as a single container, no replication.
Often it means "we are not interested in developing it anymore"
DynamoDB with the standard aws-sdk-go and no ORM.
Well that is great to hear. Does it scale well as inhave read and would it be a good way to go vs something like Cassandra. Pgsl. Mysql or mongo?
I am a fan of CRDB and have some production experience. It eventually didn't fit our use case because we have multiple datacenters and syncing across those, while possible, is a huge PITA. Writes are, obviously, not as fast as say PostgeSQL. Other than that I really like it and would highly recommend it to anyone who has a need for a relational DB. It also seems to work well in Kubernetes.
`dep` works, you need to build it for arm. 
Is the syncing across data centers an issue with crdb itself or just in general a problem. Obviously if an application may scale well and need high demand the need to work across data centers becomes necessary but the db data needs to be replicated across all data centers right? Does it out of the box support that and is just slow doing so? I vaguely remember either Mongo or mysql basically replicating writes as they happened in real time which I assume in most cases is what is required. Dont want a person in Europe ordering an item that shows in stock when dude in us just ordered last item. 
Calling the language "GO" and "golang" and recommending to install it via brew. Stopped skimming the article there.
If you're using PostgreSQL functions then you just use sql.Exec() as normal as you SELECT functions. I use this in several (company internal) projects using PostgreSQL.
Postgres. No orm. Only igor: https://github.com/galeone/igor
Interesting approach, Why don't you use constraints and checks to make sure the data integrity is protected? It would be weird for me to have stored procedures that are more hidden in the database then normal insert statements 
Yeah, was just think one time code generation, just to get boiler plate code, names, types and parameters wired. Probably more suited to a code editor plugin. 
Why not `go-billy`? [https://github.com/src-d/go-billy](https://github.com/src-d/go-billy)
Lol. Should have followed the link.
Postgres (with stored procedures), lib/pq and the stdlib's database/sql. I avoid ORMs like the plague, the law of leaky abstractions always comes back to bite you when you least need it, and the supposed advantages are oversold anyways. VividCortex has an excellent guide on writing DB applications. You have to register to download it, but it's well worth it: https://www.vividcortex.com/resources/the-ultimate-guide-to-building-database-driven-apps-with-go
For CRDB, all the nodes have to be able to talk to all the other nodes. If you have multiple datacenters that are well connected then CRDB will do fine. We did not. However, your example of a single set of inventory shared around the world could be a problem for CRDB. There are good partitioning schemes to handle the global scale, especially in the paid version. Remember that all consensus happens through raft. There are documented ways to deal w/ this in the CRDB docs, which is pretty good.
I haven't used any SQL databases from Go, but I've used BoltDB along with [gob encoding](https://golang.org/pkg/encoding/gob/) as a simple object store in a couple small projects. There's some gotchas using gob, because it omits zero values, so when you decode it'll leave the previous values intact where ever there was a zero, potentially dangerous if you're reusing a local variable in a loop. Then using bolt you have to be aware that all the byte slices it returns point directly to the memory mapped data file and take care not to modify them.
Sure, constraints are a way to make sure that an end-date might not be before a start-date, but there is a certain limit to them. Lets say you have a simple requirement that a certain group should not have more than 5 members: You can do that in code, but it comes with several problems: a) You need to wrap it in a transaction, several queries need to travel from the code and back to the server (start transaction, select sum, insert into, commit transaction) each of them having to do a full TCP roundtrip from the server and back again. Having them on the serverside reduces the time the transaction needs to live and roundtrip-times. It also documents them in the right place, at least from my current perspective. b) You could just do a raw connect with any framework/language and insert whatever you like, not recognizing what your code should've prevented in the first place. This way I can just do a GRANT permission on the user_group_join and user_group_leave procedures and be fine with it.
Any particular reason you use the regular bolt client over the bbolt fork (https://github.com/etcd-io/bbolt)? I'm using bbolt, but only because it's still (somewhat) maintained and I'm not sure if that's the right choice.
I am not familiar with data loss being an issue with large messages, but I can provide a little bit of information. For the work in this paper, the protobuf messages were typically no larger than a few 10s of kB. The "buckets" collect a number of these event-scale messages together for efficiency of compression and random access of events. On a related note, the buckets also provide the opportunity to recover from corruption with the use of "magic" words, so that corruption is (in principle) confined to a bucket. &amp;#x200B; I can also say that this approach has been used for datasets up to \~30GB, without any apparent data corruption (and this in by no means a limit). For more context, this is the size of a typical dataset being used for a particular work on machine-learned reconstruction of physics events, where the datasets are read repeatedly for many epochs. In such work, there hasn't been any indication of corruption.
Then run these commands: ``` $ go get -u github.com/nomad-software/vend $ vend ``` Because `go mod vendor` is hideously broken and only [cherry-picks certain files](https://github.com/golang/go/issues/26366) and you don't want your dependencies taken offline do you? ;) Once everything is nicely vendor'ed build it like this: ``` go build -mod vendor ```
EF uses generics extensively which Go doesn't support. Go does have many ORM libs but nothing like Entity Framework.
Your example makes sense, I would also go with a stored procedure here, because you have to check multiple rows. But you said 90% of data writing queries are stored procedures. For a "normal" insert I would never write a stored procedure. The app makes sure that the data makes sense from the "business" perspective, the database makes sure it is valid. I also go with the approach that one app has one database and the app is basically owner of the DB
It's kind of hard to read the code without the indentation.
&gt; I also go with the approach that one app has one database and the app is basically owner of the DB I'm totally with you there, but I've been betrayed many times trying to enforce that. Connecting other services in other languages to it, people running "just select queries" and many more horror scenarios. Many times the current language is just not the right tool for the job and you still loose the whole layer once you do not have time to build a full set of API endpoints for your newly bought analytics and statistics software and just connect it directly to the database. On the other hand you have almost no drawbacks having clear views / procedures in place. Maybe I'm to confused in my thoughts, but why is there a need to have any business logic in your app if you can avoid it? Given the worst example, an user registration with payment subscription and one-or-two mails going out of the system: The most important parts can be done with procedures (creating users, subscriptions, subscribe, active features) and the app can still implement the flow (tying together payment gateway, mailer, http server and ajax/api endpoints). Sure you could also do all that in the app alone, but you could also choose *not* to.
sure it also comes down to management and how big the company is and what the app actually does or the database holds. As already said, stored procedures are too hidden for me, it's for me just an exception rather than the norm, but thanks for explaining your concept, I will think about it for a bit :)
I know this thread is pretty old, but for the sake of people searching, I've found a couple of updates not mentioned in the comments here. Firstly and most importantly, there is a P5.js binding for GopherJS, this can be found here: https://github.com/bregydoc/PGoJs There is also a standalone binding to P5.JS discussed here, https://medium.com/@as27/gop5js-using-p5-js-with-go-b1d7d7cf542b which isn't complete yet but looks very nice. 
[removed]
Yeah I had a hard time finding anything concrete in how bbolt is better. They say "stability improvements" or whatever but there aren't any real numbers. I went with regular bolt and it's been good enough. If I run into issues then I'll check out bbolt.
Blogspam. Link to \*properly\* formatted code, and original blog, was submitted here 4 days ago: &amp;#x200B; [https://www.reddit.com/r/golang/comments/a5o3la/string\_interning\_in\_go/](https://www.reddit.com/r/golang/comments/a5o3la/string_interning_in_go/)
I haven't had a chance to scale it outside of my test environment. Tests look good though.
In the spirit of making you feel better, what you were originally doing is the beginning of a structure called a [trie](https://en.wikipedia.org/wiki/Trie). It is particularly helpful for storing lists of words in small amounts of memory. (But just using a map is the correct answer in your case, unless you _know_ that you have some performance problem, which would be pretty weird because anything that can run Go at all shouldn't have a performance problem with using a map.)
Thanks! I didn't know about go-billy. I will investigate.
&gt;I'm totally with you there, but I've been betrayed many times trying to enforce that. This is a tenant of microservices. If multiple apps talk to the same DB, it **requires** co-ordination in order to roll out changes. If only one app talks to the DB, it's trivial to roll out changes. Sure, sometimes it takes multiple commits. But there are never road blocks caused by waiting for another team/application to make changes. Studies (such as the Puppet Labs State of DevOps report) have shown that "faster iteration times" lead to healthier teams/companies. &gt;On the other hand you have almost no drawbacks having clear views / procedures in place. Sure, drawback are: \- stored procedures can't always be written in the same language as the app. That can end up constraining choice for the app developers. \- stored procedures often 'live' far away from the app. (i.e. in a different file). That makes them harder to follow as the 'logic' threads between different contexts. \- stored procedures are often de-coupled from the app. (i.e. rolling a commit forward/back \*must\* also roll forward/back the stored procedures, but that is hard to do). Developers rarely test "what happens when we rollback and the old version of the code is using the new version of the stored procedures?"
The aspect ratio?
Thank you! 
Interesting. By `vend` you mean https://github.com/nomad-software/vend ?
&gt;Otherwise, I've been using https://github.com/etcd-io/bbolt lately and have found it really enjoyable to work with. Not a standard database but for anything that can use NoSQL persistence it works really well. &amp;#x200B; What's your primary use case? What's the advantage(s) over mysql/postgres?
BoltDB (bbolt) is a key-value store so it's good in scenarios where you don't need a lot of joins and just need to shove data somewhere. Also, BoltDB consists of a single file like sqlite making it ideal for projects with smaller persistence needs although it appears to scale pretty well. 
Any chance you've tried this with bazel?
I'm using Mongodb, more convenient.
We use go-kit
Because it uses a single local file, it can't be shared between web servers, I found it a bit difficult to use. It might be good for caching or batch jobs (where all data is loaded when start) I wonder. Do you have any concrete example?
I found some tricky puzzles here: [Go Puzzles](http://devmethodologies.blogspot.com/2018/10/go-puzzles-not-interview-questions.html)
See https://www.reddit.com/r/golang/comments/a6yo8k/do_you_use_database_in_your_go_project/
Sorry I've never used bazel.. I will have a look at it
Yes; OP is assuming that $GOPATH/bin is in the $PATH, I think.
The accompanying blog post has more details: https://scot.coffee/2018/12/monitoring-go-applications-with-prometheus/
Would this pattern work if I want to check 1000 URLs? What about a million? Is it problematic to spawn a unknown potentially huge numer of goroutines or will go handle the "limiting" in this case by itself? 
would you now consider using something different in response to you hand rolled code to keep performance consistent?
Just jump in, and you will learn on the go. It's good to get the workflow up and running, and small bug fixes are excellent for that. Also get comfortable with writing tests, and running automated unit tests all the time. A lot of open source projects seem to neglect this a bit, and having someone add some tests would be most welcome. You will also get to learn about the project incrementally.
TIL: blockchain developers come in waves.
Is this for a personal project or work? If it's for work, you should ask if your company has standards for code deployment, if they don't help them come up with them. It may be as simple as making sure you've hit all requirements, make a checklist and checked all of them off, to a continuous integration system. It all depends on what kind of software and how quickly you can patch and maintain it. If it's a personal project you may want to implement the same checks but be aware that when it comes down to it you have to decide if you're comfortable releasing or not.
Do what others suggested (map\[string\]), but as per your original question about slowness, if this happens with random lookup keys you might be reaching the point where the L2 or L3 cache no longer holds your working set.
Can you expand on this? I though go mods would stop us from having to have third party libs for vendoring :/
If you care about tooling and linters working for your project, don't migrate yet! https://github.com/golang/go/issues/24661
&gt; Everyone should have to pass this kind of situation I guess, so what are your opinions? Yes, but the definition of _“production ready”_ differs per project. My strategy to consider a project ready for production is to ask myself _“What is the worst that could happen if the code has a critical bug?”_. If the project is handling sensitive data, then I consider it ready for production once I have reviewed the security of the whole application and have designed a plan to prevent data leaks. If the project is intended to stay online even after being hit by massive amounts of traffic, then I consider it ready for production once I have reviewed the infrastructure and have designed a plan to scale on demand. If the project is supposed to be super responsive, then I consider it ready for production once I have checked the performance of the whole application using a profiler or other tools. I can continue on and on with different criteria, but I hope you have taken the gist of my explanation. &gt; 95% of the time, they work as intended […] If your definition of _“production ready”_ is “the code works” then your statement seems to imply that your project is ready to be deployed to production. Unless you have some secret sauce in your code or are managing super sensitive data, I don’t see a reason to hold yourself back, go ahead and deploy it.
I built an ORM library on top of gocql at my last job. Never did open source it, though. *shrug*
I think security is most important. So that's something if would check and optimize a lot.
Go modules still have a ton of issues (just look at Github) but one that is relatively minor but is lack of pruning like `dep`. What I mean is, the `vendor` directory after `go mod vendor` is way, *wayy* bigger than a `dep` project with [prune] go-tests = true unused-packages = true non-go = true
Hey thanks for asking, **Would this pattern work if I want to check 1000 URLs? What about a million?** Each go routine that is spun up costs 2kb, so spinning up 100 go routines would cost your OS 2mb, not too bad. That means if we spin up a 1,000,000 go routines your program would need to find 2gb of memory, depending on your setup this may not be a problem. &amp;#x200B; **Is it problematic to spawn a unknown potentially huge number of go routines or will go handle the "limiting" in this case by itself?** I my self have never come up against the limitation of spinning up too many go routines, however that doesn't mean such as problem doesn't exist and it would be best practice to use some kind of worker pool idea to limit the amount of http requests that you will be firing at one time. I would strongly recommend look([https://brandur.org/go-worker-pool](https://brandur.org/go-worker-pool))\[here\] for a deeper dive into this. However if you have a scenario where your program will need to do 10 - 100 requests at once, the above code should work just fine.
Not a nitpick at all! Thanks for the catch.
[removed]
It's production ready when you can handle a breakage. How I will handle the errors. Is it logged with enough context ? will I receive an alert by mail ? can I revert quickly to a previous version of the code ? Of the data (point in time recovery with Postgresql) ? 
Sounds like a cool learning project - if you need a hand with anything please feel free to message me, I've done some software rendering code using Go (rasterizer, ray tracer etc.) and used it to try out some 'non standard' kinds of things like irregular z buffers and forward rasterization. Typically I rendered to simple rgb or xyz (float) buffers rather than using image but that works just as well and probably more suited to interactive gfx. &amp;#x200B;
No Goland? Really? 
[removed]
[removed]
I used to just eval a sql file against a sql database. The migration files were version controlled. psql blah blah -f 20181201-my-migration.sql 
I use postgres. For ORM, GORM has been reliable and kept me productive for years. 
Already raised an issue on GithHub thanks for the reply!
It is actually listed under *Honorable mentions* near the bottom of the page.
Thanks for feedback but to be honest I am really supported of linters and so far I Haven't found any issue in really big projects
They seem to have dinged it for having a commercial license option. Is this an article about the top 5 completely free IDEs? I'm surprised Goland wasn't actually one of the 5. 
Although I found it smaller than after switching from a Glide project. Also I think Go mod has an issue with vendor over-pruning in the way it won't copy non-source files such as resources that may be important. There are logged issues about having it copy all of the files from the source repo. 
The linked issue expands on it. The mod vendor command prunes anything that isn't source needed for the dependency to compile. That means non-go source resources, or directories. The external vend tool is offering a vendoring process that copies everything. 
Testing and benchmarking. You have a few areas of major concern when releasing production code: * Functionality * Security * Performance * Observability * Scalability * Availability You can assess functionality and security with tests. You can assess performance with benchmarks of different kinds (if it's a web service, even using something like `wrk` is a good starting point, but you may want to get more advanced than that to mimic real use). For observability, you will probably discover this as you release more applications into production, but generally you'll want logging and metrics, and hopefully tracing too. Scalability is an interesting topic, and it really depends on what you're working on, and how it needs to scale. If you're not going to have a huge volumes of traffic then that might not be too much of a concern. Otherwise, you might have to think about how your application handles state, etc. Availability launches off of scalability in many ways, but it'll depend on your infrastructure. Generally in production, I have multiple instances of services running at once, at least in different physical datacenters. This means if a datacenter goes down I don't have to worry about my app going down (as much). All of this depends on your needs though. Maybe your application isn't critical, so availability isn't a huge concern. Maybe you'll have a very small number of users, so scalability and performance aren't concerns. I think the others are unanimously necessary though, you need it to work, to be secure, and to be able to see what's going on when you need to.
None of these are even IDEs
You are correct about not being able to be shared across servers. My comment about scaling well was more around the ability to manage more data than being able to be shared across more servers. I use it in my command line tool here: https://github.com/alittlebrighter/coach
I have some suggestions. Replace NewCustom with func that takes *tabwriter.Writer so that you can use any io.Writer, not just io.Stdout. Move common code from AddLine and AddHeader to let's say buildFormatString. Also add \n to the format string so that you can call fmt.Fprintf instead of fmt.Sprintf + fmt.Fprintln. dashes can be replaced with strings.Repeat("-", length). AddSeparator doesn't need to be exported. Flush would be more logical name for the Print method.
Thanks!
&gt; And this is almost the first time I am doing this kinds of things Then the answer is simple: your code is most likely not ready for production, and you need reviews from developers with more experience.
Thanks for the feedback on this guys, I have updated with all your suggestions
is this copying the book 'Writing an interpreter in Go' ?
That's what I thought for a second, but it seems like this is a Go interpreter written in Go. The approach taken is fairly different as well.
That code formatting is awful, but it was explained well beforehand. Maybe see if you can fix that!
I used bolt for a CLI time tracking utility. I didn't want to use sqlite because it required CGo at the time (not sure if it still does?), and bolt was a native Go solution. It worked really well, but I never put it under any sort of stress.
Oh man this is needed so badly as part of the standard library, having to manually write a function to do what should be a oneliner! Thank you for this
I use vscode. Very nice editor.
\&gt; Which database you use? Definitely depends on my exact use case and the read/write-patterns of my app, but I tend to go for either Postgres or MongoDB. When my data is not truly relational data, I use MongoDB - otherwise defaulting to Postgres. &amp;#x200B; \&gt; Do you use ORM? &amp;#x200B; ORMs are a tricky topic. I do like to have an abstraction for data access in my code instead of writing raw SQL. \[Prisma\]([https://www.prisma.io](https://www.prisma.io)) gives you a lot of the benefits of ORMs without the common pain points (performance, expressiveness). There's a Prisma client in Go that: &amp;#x200B; \- is auto-generated based on your models / database schema \- enables type-safe database access \- has a powerful API with filtering, sorting, pagination and everything else you need for modern application development &amp;#x200B; Here's some links that help you get started: \- [Golang Quickstart](https://www.prisma.io/docs/-g002/) \- [Golang GraphQL Example](https://github.com/prisma/prisma-examples/tree/master/go/graphql) \- [Golang REST API Example (with Gin)](https://github.com/prisma/prisma-examples/tree/master/go/rest-gin) &amp;#x200B; &amp;#x200B;
Thank you so much for your feedback
Looks good. I did something very similar to this with a python script we use in our CI pipeline, as a lint before applying the changes to the cluster, and have wanted a more mature solution. Some of the things we check for: - With resources separated by namespace, we keep each resource YAML for a given namespace within a folder named after that namespace. Make sure that any YAML files within that folder have a `namespace:` field which matches the folder name. - Ensure that specific resource types (deployments) all have expected labels set. - Ensure that podspecs (deployments, cronjobs, etc) always have resource limits specified. - One of the more useful ones; if you're using `base64`/`base64 -D` on the command line to create secret values, its really easy to accidentally allow an errant newline into the encoded string via an accidental copy-paste of the newline at the end of an unencoded secret string. The linter will detect that and re-encode the value without the newline, then gives you the option of replacing it with the new value. Its been really valuable for ensuring the sanity of our resources across multiple environments. 
I would move your queries into stored procedures and write some unit tests there, then you call them in your go code. I suppose you don’t necessarily need them to be stored procedures as long as you are able to factor out every sql query into a testable atomic operation. Moving functions to sql server just makes things easier and more efficient.
Neat. Also needed: https://i.redd.it/0lg04ovga0m11.jpg 
What do you want to store? The string or the represented data inside the json into matching columns?
If you don't need to do any db oprtations on it other than store and retrieve, could just store it in a TEXT column, otherwise there are JSON or JSONB column types.
&gt; JSON or JSONB column types. show me
my question isn't what I want to store.
No
Original post here: https://blog.beeceej.com/blog/4
You are right, that was my question to you, trying to help you with your question. But well: Use SQL.
well, if you don't answer, we can't really recommend the storage type, but in terms of dependencies, you need the standard library package you mentioned and a third party postgres driver. The third party driver package you pick will probably be affected by whether you want to use the api that is the same for all database types or if you want postgres-specific data types to be supported.
yes
I believe `sqlx` has a JSON type that implements the sql interface, but really it's just []byte under the hood so it's your choice.
I believe `sqlx` has a JSON type that implements the sql interface, but really it's just []byte under the hood so it's your choice.
re-read my question
Huh, that article reads... like this is an ongoing disaster? Is he stuck in converting 260k commits in svn to git on the fly? This whole process reads and feels so bloated. Why not export rev by rev git commit for commit it back into the new repo; and even that sounds like the worst way to go about it.
Nobody wants to help someone with a demanding, negative attitude that won't even google the suggestions given. Best thing to do is ignore this person now.
You came here to tell that you'll ignore me? :)))))
[removed]
I'm not aware of exactly what he's doing or at least not enough to criticize, but 64 GB RAM not being enough makes me think something could be more iterative instead of however it's happening now. Yikes!
Immature, selfish, insulting, and a poor use of English is all you have displayed. What's the point? You obviously have deffieciencies programming and need assistance so I see your attitude as counter productive in getting the help you are asking for. One day you will be a man, hopefully, and not display such depravity
[https://medium.com/@eminetto/clean-architecture-using-golang-b63587aa5e3f](https://medium.com/@eminetto/clean-architecture-using-golang-b63587aa5e3f)
[ESR chronicles](http://esr.ibiblio.org/?tag=reposurgeon) the things he's done getting reposurgeon to work on bigger and bigger and older and older repositories. [Ugliest…repository…conversion…ever](http://esr.ibiblio.org/?p=5634) documents some of the issues that crop up in old-repository conversions. There's also [this](http://esr.ibiblio.org/?p=7792#comment-1923216): &gt; &gt;I do wonder if the reposurgeing is inherently serial job, or if there are any trick that would make it possible to parallelize it. &gt; &gt; I’ve been studying the problem closely since 2010, and I don’t think so. &gt; &gt; &gt;Graph operations like breadth-first-search, or pagerank, etc. can be parallelized (even on GPU). &gt; &gt; Yeah, unfortunately those aren’t the ones I need. &gt; &gt; Most of the things reposurgeon does can be broadly characterized as: grind through a time – or topologically-and-time-ordered list of commits doing something with each one. The thing that makes these tasks intrinsically serial is that the “something” may – often does – require lookback arbitrarily far into ancestor commits that may have been modified by previous steps of the operation. Anything that needs to know about the DAG structure is like this; “know about” unpacks to looking backward for branch splits. &gt; &gt; In some cases you have the same non-locality problem going forward in time. Any operation that needs to query or modify branch merges will be like this. Those are much less common than the operations that are nonlocal backwards, though. &gt; &gt; This is also why you can’t section huge repos into chunks to process separately. Your lookback (or lookforward) fails at the chunk boundaries. Algorithm fall down go boom. &gt; &gt; The few exceptions are the operations for which there’s no lookback or lookforward, notably search or search and replace.
Actual title: ESR moves his SVN to git migration tool from Python to Go, to handle the GCC code base.
Hi. I am building one project in go with help of clean architecture: https://gitlab.com/getstash/goshokan There I have a DAO(data access object) for Elasticsearch, BoltDB and Bleve. So I believe you can catch general idea of implementation of data interface layer. Also in this project I use swagger to generate rest api for my server. And here is example in Python: https://github.com/astoliarov/azamuku with storage and web framework (falcon)
Really curious why this is "nice to hear"? &amp;#x200B; Surely Go developers aren't of the mindset that their language is the greatest thing in the world and everything deserves to be re-written in it. I love Go as much as the next person, but sometimes it's not the greatest option.
this necessary comment on the top.
Should `url` continue to be a string or be a net.URL? It always makes me feel dirty to convert back and forth.
yes but they are beyond me because I don't actually know what a lot of those things are doing
Thanks for the feedback and I will take you up on your offer once I get the base code down a bit more. I think you're right about separating this initial GUI code and the graphics code, sounds like a plan. Yes....testing.... :) I definitely want to do more with testing as Go has made it super easy to do compared to other languages. Cheers.
Sorry, I meant it's your choice to look at the code to re-implement the sql interface yourself on a []byte wrapper of your own. But apart from that I believe this is no longer a Golang+Postgres integration question: query the DB with hand-written SQL (even on a json/jsonb field) and leave parsing []byte to the stdlib's json package. 
I’m sure this has been discussed somewhere but do any concepts from fast-http come over? 
See also: [https://medium.com/@eminetto/clean-architecture-using-golang-b63587aa5e3f](https://medium.com/@eminetto/clean-architecture-using-golang-b63587aa5e3f)
Thanks for the code review kwtw. I agree, those are good suggestions, cheers, i'll implement some of those today. Thanks again
This is an interesting comment on why GOPATH is actually great: &gt; The final entry in our trio of tribulations is the dumpster fire that is Python library paths. This has actually been a continuing problem since GPSD and has bitten NTPsec pretty hard – it’s a running sore on our issue tracker, so bad that were’re seriously considering moving our entire suite of Python client tools to Go just to get shut of it. &gt; &gt; The problem is that where on your system you need to put a Python library module in order so that a Python main program (or other library) can see it and load it varies in only semi-predictable ways. By version, yes, but there’s also an obscure distinction between site-packages, dist-packages, and what for want of any better term I’ll call root-level modules (no subdirectory under the version directory) that different distributions and even different application packages seem to interpret in different and incompatible ways. The root of the problem seems to be that good practice is under-specified by the Python dev team. &gt; &gt; This is particular hell on project packagers. You don’t know what version of Python your users will be running, and you don’t know what the contents of their sys.path (library load path variable). You can’t know where your install production should put things so the Python pieces of your code will be able to see each other. About all you can do is shotgun multiple copies of your library to different plausible locations and hope one of them intersects with your user’s load path. And I shall draw a kindly veil over the even greater complications if you’re shipping C extension modules… Compare that to GOPATH, which is pretty simple to understand. There's an env var that defaults to ~/go; you look for packages in ./vendor/ and then in the GOPATH paths, and finally GOROOT. 
It's mentioned in slide 32: &gt; _Overwhelming_ API, good performance. Opaque types are key.
[removed]
Ah, I thought mod had it's own vendoring built-in
It's a good Python replacement, and that's what OP probably meant.
\&gt; But I think I have to first learn the framework before I understand the architecture. This is the dark path, where people get stuck in frameworks and become "Spring Developers" for life and can never leave. You're reading the book so you should be understanding the principles behind them. If you understand the principles you can build it. 
Why wouldn't Go be a good fit for a command line tool that converts SVN repo to Git? It's fast, crossplatform and simple. From all the possible missuses of Go, writing one-off commandline tools like this clearly isn't one.
[removed]
what's wrong with installing go using homebrew?
/r/titlegore
Even though I agree, I did just complete a project that would make Russ himself probably want to slap my face off. A DLL injecting, thread freezing, opengl function modifying (in live memory), to hook an external opengl app's render pipeline so i could put my own diagnostic render overlay on top. 100% Go and it feels just really wrong.
if you have a large number of these things, you'll get a goroutine explosion, putting unnecessary strain on the scheduler.
Yeah this is the golang sub, what would you expect? Moving to ruby?
&gt; Sorry Yeah, you must beg me for forgivness. 
Oh, yes, that's me.
With white skin and small pеnis, who likes to waste water for no reason, stupid and short, with big eys brows and small eyes and terrible Portuguese. One day you'll grow up and pay for all that. Ahahahahahahah 
I put a comment on this post, https://medium.com/@ismail783/i-think-some-elements-are-missing-from-the-diagram-4f24f2c57a4c
this
\&gt; make sure the code is behaving itself... &amp;#x200B; just not the sql code you wrote?
I am now following both of your projects. But, it is hard for me to compare the code with the diagram https://cdn-images-1.medium.com/max/800/1*Amv74nfUdirQYlRmSyEMDA.png Where is presenter, view model, view, Input boundary, output boundary, request model, respond model, interactor, entity gateway etc. Can you please write a blog post or create a YouTube video discussing your projects. Mainly the golang project, and shine some light on the questions I have asked.
TLS 1.3 is looking mighty handsome in there
Make a table with email plus random string. Uuid is ok. Then when the user clicks just compare. It adds a more levels of security. Not that guessing a uuid alone is easy in an hour. You also want it to expire so verify the time 
Good old tool, thank you for reminding other people about this. I wish my colleagues would take struct padding more seriously though. Maybe one day I’ll land a job with more caring people 😌
That’s because the owner of that website “gophers.postach.io” is ripping off content from other sites. For instance, this article was originally posted here [1], there you can see the code is well formatted. [1] https://www.codeproject.com/Articles/1268396/Solving-Triangles-an-Approach-with-GO-Language
Right, I don't think most Go programmers realize their structs almost certainly have padding holes, which are just consuming space and can get fixed by re-ordering the boolean/byte/char members.
Abstractions and patterns should reveal themselves organically, not by fiat. Clean architecture is awesome if you have some very good reasons to implement it. Its awful if you do it because it just sounds like a good idea and Uncle Bob said to.
Google Groups is broken on iPad. ¯\\\_(ツ)\_/¯
Da good stuff: https://tip.golang.org/doc/go1.12
Thanks for the tip about pgoutput. Seems to be a better approach than the listen/notify path I was starting down. Are you using that to eventually stream realtime updates to clients? If so, any other tips?
[removed]
Currently using xo, but plan on switching to GNORM (https://gnorm.org/) for database interaction. I would be interested in thoughts by anyone who has used both the new fork of goose (pressly/goose) and golang-migrate/migrate, and why they prefer one over the other.
Python has a PYTHONPATH which does the same thing. GOPATH doesn't solve this part any better. Go is better for packaging/the end user though because of the single binary... Don't have to set the user's path manually or place things somewhere specific.
Yes, the book is still relevant. The language has not changed much since the time it was written. 
Holy fuck, finally we can delete key from expvar. It bothered me greatly that cmdline was exposed by default.
If this is a web app check out go-chi/chi middleware recoverers. https://github.com/go-chi/chi/blob/master/middleware/recoverer.go You don’t even have to use chi. Just use the internals to build a wrapper for your handler.
You do have the option of recovering from a panic, but it would also be good to determine the source of your panic and try to resolve them. I would avoid triggering panics manually throughout your codebase and use errors instead, they are easier to recover from and safer. Errors should be logged with enough context to help resolve them (if possible). When handling errors, I would suggest logging them to stderr or stdout so they can be shipped off to a central log store and also track the error in some sort of application monitoring system (Prometheus, InfluxDB, Sentry, etc). You can then have alerting run off these systems notify you of a rise in error rates. 
I may have missed it..but I thought there would be more on go modules in 1.12? 
`runtime/debug`'s BuildInfo is going to be really nice for module users to get the version at runtime without needing anything special in the build chain to talk to Git. I think it's a fantastic little gem.
[My response](https://link.medium.com/7SRePIyzLS)
Interesting. Does package main have a module version?
Indeed fuck python
Check out https://github.com/spy16/droplets
yes it is, the exercises are worth the price of the book
Great
[removed]
The thing that caught my eye is we do not need to spin up our web server to work on the business model. I also agree with him on the point that MVC was originally created for small GUI elements. And it also seems to be true that software architecture should not be centered around web and database. Database and web should be add-on to our business process. Clean architecture also seems to be very flexible. He encourages to apply boundaries and layers keeping the concept intact. The thing I do not agree with him is he compared rails'es top view with the architecture of a library or church. Building architecture is just a drawing on a paper. Rails is a building. However, I am willing to cut him a slack on that because maybe, he did it just to make his point that by looking at the code we should be able to know why it is build instead of what mechanism it uses. Disclaimer: By reading you may have the delution that I know a lot. No, I am a lazy software construction worker, who is trying to get things right the first time, so that he is not condemned to redo it. 
&gt; TLS 1.3 cipher suites are not configurable. All supported cipher suites are safe, Crap. Now I cannot add `ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384;` and feel like hacking into a mainframe.
1. User clicks forgot password 2. User fills in captcha (!) (e.g. google recaptcha v3) and his email 3. Message thay says 'email has been sent to the account', even if the email was not found (prevent user enumeration) 4. System generates a 64-long alphanumeric token and stores this, along with a TTL of 10 minutes 5. User receives email with [https://reset.account.com/](https://reset.account.com/)&lt;token&gt; 6. System validates if token is still valid for current time 7. User fills in new password 8. System invalidates token and replaces old hash with new salted hash You can either store it in cache with a TTL or store it in DB with a column TIMESTAMP. e.g. out of my head: \` user (usr\_pw\_reset\_timestamp TIMESTAMP WITH TIME ZONE, usr\_pw\_reset\_token varchar(64)); SELECT WHEN usr\_pw\_reset\_token IS NULL THEN 0 ELSE WHEN NOW() &lt;= usr\_pw\_reset\_token - INTERVAL '10 minutes' THEN 1 ELSE 0 END \` And then check the valid value.
I've been hearing about it for years. Those kinds of books oftentimes have a website that tracks errata or the small changes that accrue over time. You could check if that exists and consult it for recency concerns.
&gt; I searched for good packages for it but without success What keywords did you use for your search? I searched _“golang text to speech”_ and found plenty of packages [1]. I personally have used this one [2] for a couple of personal projects. [1] https://golanglibs.com/search?q=tts&amp;sort=top [2] https://golanglibs.com/repo/pqyptixa/tts2media
I see, I guessed I missed it, I will look on \[2\] thanks! appreciate the help 
TTL of 10 minutes is too short. If user is using POP3, their client can fetch new mail every 5-30 minutes and believe me, many users don't know how to trigger sync manually. Also, email servers can be overloaded, may have temporary problems etc. which causes delays in delivery. People even type URL from a phone, where they have email client configured. 1 hour is a good value for these kinds of TTL, with 24 hours maximum. I've seen password reset tokens with 3 day TTL (SMTP servers retry failed transfers up to ~5 days before purging message from queue).
&gt; Is it just for text to speech or also vi-versa? It’s only for text-to-speech. For speed-to-text I recommend you to use this [1]. That said, audio recognition requires a lot of data and time to formalize it. That’s why so many people use online services that are already trained to recognize sounds reasonably well. If you are planning to do this offline, you’ll have to spend a considerable amount of time building a good data set. [1] https://github.com/xlab/pocketsphinx-go
It's a very good book and Go hasn't changed much. Please correct me if I'm wrong, but the syntax is stable until at Go 2.0 and breaking changes have only introduced in 'x/' packages which are not supposed to be stable. The only other changes were speed, security fixes and more functionality.
... for now.
I became a bit tired of doing the mundane task of upgrading Go, so I made this little tool that helps doing it. Not depending on packaging managers because their packages are most of the time outdated and not getting the latest version. The tool downloads the latest package straight from Google if it finds your local version is not up to date. The tool is cross platform at least I test it works in Windows and Linux. Feel free to review it and leave comments :)
&gt; is this book still good No. This book is not good and never was: This book is exzellent.
Well, that one is dead simple: Any panic is a programming error. Just fix them and the panic and the crash goes away.
Instead of having three files with their own main files in a single directory make a package and then create a directory that imports the package in a cmd folder. You could also make the CLI have subcommands and flags to choose which action to take. cmd/goanime/main.go goanime.go concurrent.go scraper.go 
interesting to see `wagon` -- with no real optimization -- isn't *always* the slowest :P
I don’t even know where to start. Read some articles, read some blogs, do some tutorials, read some well know library code, read the go source code. Then rewrite it from scratch. 
I think that would be a nice approach. However, the problem that I see with it, is the definition of more complex resolvers that might have some logic or permission checking involved. In additional mixing implementation details into the graphql schema might not be the best idea (separation of concerns). Maybe there is a way to use schema introspection to auto-generate "simple" resolvers and combine this with user-defined more elaborate resolver functions. The idea would be something as follows: \- Start with a graphql schema `type Group {` `id: ID!` `name: String!` `members: [User]` `}` `type User {` `id: ID!` `name: String!` `email: String!` `}` &amp;#x200B; \- Auto-generate respective resolvers with interfaces to resolve the context `type GroupResolver struct {` `content: GroupResolverInterface` `}` `type GroupResolverInterface interface {` `GetGroupId() string` `GetName() string` `GetMembers() []UserResolver` `}` `type UserResolver struct {` `content: UserResolverInterface` `}` `type UserResolverInterface interface {` `GetId() string` `GetName() string` `GetEmail() string` `}` &amp;#x200B; \- Auto-generate methods on the GroupResolver to match the graphql specification `func (r *GroupResolver) ID (string, error) {` `return r.content.GetId(), nil` `}` `func (r *GroupResolver) Name (string, error) {` `return r.content.GetName(), nil` `}` `func (r *GroupResolver) Members ([]UserResolver, error) {` `return r.content.GetMembers(), nil` `}` `... // same for UserResolver struct` &amp;#x200B; \- Extend structs generated from proto to match the resolver interface `type MyGroupContentResolver struct {` `myStructFromProtoGroupDefinintion` `}` `func (r *MyGroupContentResolver) Members() ([]UserResolver, error) {` `members := rpc.fetchUsersForGroup(r.GetId())` `// ... transform members to UserResolvers` `return membersAsUserResolver, nil` `}` This would help resolve the simpler information while still allowing for flexibility in resolvers. However, the mapping of proto structs to resolvers would still be somewhat tedious - i.e. members to UserResolver, or group to groupResolver. Maybe a respective mapping function could also be auto-generated.
It’s typically from nil interfaces or nil pointers (struct, slices, maps especially). Look for them and initialize them properly or check that they are. Also channels if you’ve got em. 
Might be a lot to take in but go-kit examples show a lot about good architecture: [https://gokit.io/examples/](https://gokit.io/examples/)
Dependencies: https://github.com/golang/go/wiki/Modules https://dave.cheney.net/2018/07/14/taking-go-modules-for-a-spin https://ukiahsmith.com/amp/blog/a-gentle-introduction-to-golang-modules/ Project structure/layout: https://github.com/golang-standards/project-layout Go introduction: https://tour.golang.org 
&gt; On Linux, the Go runtime now releases memory back to the operating system only when the OS is under memory pressure. This is more efficient, but means a process's RSS (resident set size) won't decrease unless the OS is running out of memory. Any way to turn off that misfeature ? We got a bunch of tiny Go daemons and I don't want them randomly reserving memory used for OS to buffer IO.
Really? Python is the second best of anything. It's such a versatile language. Don't get me wrong, I love go. But go has a long way until one can go data analysis in it.
[http://www.gopl.io/](http://www.gopl.io/)
The wording is bad here. The runtime will now automatically use MADV\_FREE instead of MADV\_DONTNEED (if available) for madvise(2). The memory itself is still freed but MADV\_FREE is more efficient. See the [CL that introduced this change](https://go-review.googlesource.com/c/go/+/135395/) (the CL number is always in the HTML of the release notes, in comments) and the description of MADV\_DONTNEED and MADV\_FREE in the [madvise(2) man page](http://man7.org/linux/man-pages/man2/madvise.2.html).
Uh, indeed that's pretty bad wording. So if I understand it correctly the net effect should be same just RSS number will be slightly inflated ?
That's correct. I'm not sure how much the RSS numbers are affected, but all changes in RSS just come from the lazy freeing and are not a problem.
Yes, it does. 
Actually, I have a few questions for you since I wanted to do something similar. 1. OS? Win? Nix? 2. Patching method? Library used or custom made? 3. Static linking? 4. Performance impact after calling Go from C and back? Thanks for the answers in advance. 
Sorry, I missed this comment :) For librdkafka implementation sync producer was able to produce up to 10k messages/s. With 0.2.0 release (https://threedots.tech/post/watermill-0-2/) we reimplemented Kafka Pub/Sub with Sarama Kafka client and it is able to produce up to 75k messages/s. In our use cases we are not always producing messages, and when we need to we want to do it synchronously to be sure that the message was persisted. If you need it won't be hard to add async producer implementation ;) Of course submitting PR with this will be great!
you should try an `io.MultiWriter`.
Very good approach! Just 4 the fun... your Storer structs wont pass to that interface :D (hint: Put vs Set)
 package main import ( "flag" "io" "log" "os" ) func main() { input := flag.String("i", "/dev/stdin", "input file.") flag.Parse() inf, err := os.Open(*input) if err != nil { log.Fatal(err) } openFiles := func(paths []string) []*os.File { rc := []*os.File{} for _, path := range paths { fh, err := os.Create(path) if err != nil { log.Printf("error: %v", err) continue } rc = append(rc, fh) } return rc } fileToCloser := func(fh []*os.File) []io.Closer { rc := []io.Closer{} for _, f := range fh { rc = append(rc, f) } return rc } fileToWriter := func(fh []*os.File) []io.Writer { rc := []io.Writer{} for _, f := range fh { rc = append(rc, f) } return rc } closeFiles := func(f ...io.Closer) { for _, fh := range f { fh.Close() } } files := openFiles(flag.Args()) mw := io.MultiWriter(fileToWriter(files)...) io.Copy(mw, inf) closeFiles(fileToCloser(files)...) inf.Close() } 
Thanks I already wrote down the steps. I'll proceed to code. Cheers! 
on the lowest level, you can use a `[]byte` field.
Use `encoding/json`. It's part of the standard lib.
Your tiny Go daemon memory doesn't grow, so RSS won't grow.
You can using JSON in query like string type and use Unmarshal for this var (with encoding to bytes)
something like https://github.com/joewalnes/websocketd ?
Postgres has a jsonb type you can use. You can scan a jsonb column right into a struct with the sql package iirc.
how exactly? a) write json/b data b) and retrieve it
There would be a size difference between 386 and amd64. It would be nice if the website could reflect that as well.
You're repeatedly stealing content without permission and with no copyright info, even without a link to the original blog post. You're only linking to your spam newsletter at the prominent position. I'm reporting you again and I hope someone is finally going to sue a fortune out of you. Also, I hope moderators ban you for life. CC /u/drgryski 
There is still some time before the docs are going to be complete. Checking tagged issues would be more comprehensive at this point. If there isn't more there, it's also possible they looked at the state of tooling and wanted it to catch up with modules before making decisions on some more changes. The new BuildInfo struct under runtime/debug might also enable some nice things, and that data is only available when modules are used in building.
Wants your email before accessing the article text. How about no? 
oh -- sorry, i didn't read your code carefully. it looks like you're writing different info to each file. in fact, you're simply writing a comment that includes the filename to the file. is there a reason you need this comment and if not, may i suggest that you simply don't do that?
Hey thanks for the suggestion! I will definitely change that. As for the code in of itself, is it really that bad (I’m looking at the other reply in this post)?
[removed]
No it’s not terrible, the other comment seems to just have come from a grumpy person. There are a few places where errors were not handled, they should be taken care of if possible or wrapped and returned from the functions in your packages. The main function can then log the error and exit. I’m guessing his git comment is referring to checking in the bin directory, usually that’s added to a .gitignore since git isn’t great for binary files and is more for source code. Of course his suggestion to continue learning isn’t all bad, and often times a complete rewrite is a fine way to exercise your newfound knowledge. Especially for small projects like this it’s easy enough to try many approaches and learn through trial and error. One more suggestion would be to add tests and benchmarks for the package functions. Go has really great tooling that makes it easy to unit test, benchmark and profile or debug your programs. 
This is close to what I'm looking for, but I had a different project in mind,. Thanks for the reply anyway!
Cool thanks for the suggestions. I will add some of the things you have suggested, package goanime, and then add tests/benchmarks. Thanks again for taking time to look through this for me. Have a wonderful day!
Heya - you don't need to put the compiled binaries into git, you can attach them when you create a 'release'
I would implement an HTTP API that when called, uses the "os" package to run the scripts. If you can't find a utility you need, make one.
They have now added a section about modules.
Not golang specific, but I've gotten some Hex/Binary reading skills from looking at wireshark network traffic. You can see the headers and data in the raw format and wireshark will translate as well. Not sure how useful it is in everyday life but I have memorized 192 = C0 and 168 = A8 lol
Barely touched on at [grpc.io](https://grpc.io/docs/guides/auth.html#go) and an example [in the repo](https://github.com/grpc/grpc-go/tree/master/examples/oauth) can help too, but essentially for any custom auth, you can impl [PerRPCCredentials](https://godoc.org/google.golang.org/grpc/credentials#PerRPCCredentials) to set whatever metadata you want and use [WithPerRPCCredentials](https://godoc.org/google.golang.org/grpc#WithPerRPCCredentials) on the client. On the server you can grab that metadata w/ a [UnaryIntercepter](https://godoc.org/google.golang.org/grpc#UnaryInterceptor) to check it.
&gt; We are working on a new service, the Go Module Index, that will provide a public log of packages entering the Go ecosystem. Is it a separate initiative from [Project Athens](https://docs.gomods.io)? Is there any public info about it?
Author of Asmble here, nice writeup. I tried to keep the WASM instructions pretty close to the JVM bytecode to get the best speeds I can. Is there anything you did in your fork I can put back in? Or in general is there something Asmble can do to make it easier to use? I know I need to cut another release and provide the built package for the latest master.
if you're interested in learning more about bytes, binary, hex, etc, check out youtube. If you're interested more in incorporating it in go, check out a godoc on a library using it (i.e. bytes)
&gt; We are planning to launch a mirror service for publicly-available modules in 2019. JFrog’s GoCenter and Microsoft’s Athens projects are planning mirror services too. (We anticipate that companies will have multiple options for running their own internal mirrors as well, but this post is focusing on public mirrors.) Public Go modules proxy by Google/Microsoft? I like it! We get free redundancy, caching, CDN, checksums. All drama-free, run by serious organizations.
HN: https://news.ycombinator.com/item?id=18716329
Found it! https://github.com/adnanh/webhook
You are being downvoted because your questions are low-effort. As soon as you put in a bit more effort, people will be more than happy to make the effort to help out. This is true in every part of life also. How to ask smarter questions: http://www.catb.org/esr/faqs/smart-questions.html#intro Right now it looks like you are asking people to just write your code for you, and you are not really exact about what you need. It also doesn't look like you are willing to look at the documentation (it has examples) which should be the first thing.
You might want to check out https://github.com/Jeffail/benthos
Its a no from me Jim
Man, put you advice into your ass. I am downvoted, so what?
cool
&gt; For publicly-available modules, we intend to run a service we call a notary that follows the module index log, downloads new modules, and cryptographically signs statements of the form “module M at version V has file tree hash H.” The notary service will publish all these notarized hashes in a queryable, Certificate Transparency-style tamper-proof log, so that anyone can verify that the notary is behaving correctly. This log will serve as a public, global go.sum file that go get can use to authenticate modules when adding or updating dependencies. If this notary is always running, indexing all Go projects, what would happen if a repo author made a mistake and force pushed a repo, or were to otherwise change the history in some way? Would all users of the notary break? I'm just thinking of cases like: - I have a very old Go project nobody uses, and remove the repo in Github. Later, I want to bring it back again fresh or no longer have the source, and make a new repo with the same name. (I've actually done something similar to this one, replacing an old IRC library I wrote years ago with a proper one.) - I change my Github username, and make a repo, but it just so happens that the previous owner of this username also made a Go repo that got indexed. - This one's actually very similar to the go-bindata problem, where the author disappeared and deleted their account, so someone recreated it with another go-bindata repo to prevent users from failing. In this case, it was recreated with the same history, so I think it'd "work", and I definitely understand wanting to prevent this sort of user-swap to prevent dangerous code from replacing good code, which sums/the notary prevent. - I "oops" and commit a password, and quickly force push to try to limit its exposure, but the notary has already grabbed the revision and entered it into the index.
great post! I am wondering whether anybody tried (or is thinking to try) creating a package that translates Go SSA (say, from `golang.org/x/tools/go/ssa`) into LLVM IR, run the LLVM optimization passes, and then output a binary...
The original article: http://bet365techblog.com/the-impact-of-golang-on-systems-development-at-bet365
Some things are platform specific, but all completely transferable. I've done this on Windows for the moment which I imagine is actually more difficult. Patched with a 64-bit RIP relative addressing mode push/return method. No library used, but pretty hacky as you can imagine. Im not sure what you're asking about in regards to the static linking, but I get the address of the wglSwapBuffers with a syscall to GetProcAddress, and from there- hotpatch wglSwapBuffers with a trampoline and hook into a callback (which takes care of the c/go abi stuff). And finally since i'm just hot patching the code in memory, its not much of a perf impact at all, just a couple jump instructions + whatever GL i call in my hook function. Here's the debugging output to my console of my gl program (target) which is just another side project im doing at github.com/thegtproject/gravity i think the output will answer most, if not all, further questions: https://pastebin.com/mHiLeDG3 When it says "Cassini attached!" is when my hooking app successfully injects itself into the remote process and starts execution. I named my little injector cassini Let me know if you have anymore questions. It is actually on my todo list to clean up the code a bit more and post this on github, but i'd be embarrassed to show off some of the code as it stands right now ;)
Thanks Sebastien! &gt; I am wondering whether anybody tried (or is thinking to try) creating a package that translates Go SSA (say, from golang.org/x/tools/go/ssa) into LLVM IR, run the LLVM optimization passes, and then output a binary... This seem to be the approach taken by TinyGo. From http://tinygo.org/compiler-internals/pipeline/ "The Go SSA is then transformed into LLVM IR by the compiler package." It also seem to be the approach taken by llgo. From https://github.com/llvm-mirror/llgo/blob/master/irgen/ssa.go "This file implements the top-level LLVM IR generation from go/ssa form." Also mentioned in Alan Donovan's slides on Static analysis tools for Go, which gives a great introduction to go/ssa among others. From https://talks.golang.org/2014/static-analysis.slide#9 "The llgo project is using go/ssa as a front-end for LLVM" Those are the only two projects I know of.
[removed]
Python is just far easier to write. I mean you can create a list or dictionary and store whatever I want inside, theres just so much flexibility. 
&gt; EDIT: Actually, thinking about the go-bindata example after rereading my post, I don't think there's a way to prevent someone from making an account with the same name as a popular user (after a deletion), pushing the exact same repo up ("passing" checksums), then pushing new minor versions with malware. Unless the commits to the go-bindata repo were/are also signed by the original author.
Nice discussion. I've been using Go professionally for several years now and this bit rings very true, unfortunately: &gt; Contemptuous scorn seems to be the officially-sanctioned strategy for responding to reasoned critique or even questions about "the go way" within the community. In this sub, newbies who simply ask "why is it like this" get downvoted to hell before anyone even bothers replying. Contemptuous scorn indeed.
&gt; what would happen if a repo author made a mistake and force pushed a repo, or were to otherwise change the history in some way? Would all users of the notary break? I hope so.
great! so, with `llir/llvm/...` one could imagine removing one of the C++ dependencies :)
If they are using zlib compression in a binary file, you can use [https://golang.org/pkg/compress/zlib/](https://golang.org/pkg/compress/zlib/) to reverse that. However, and this is key - you need to figure out the order of operations. They could be either: A. preparing a complete binary file, and running it through zlib to compress it. or B. using zlib to compress chunks that are then saved in a binary file format. In the former case, the whole file is zlib compressed, and you can simply feed the entire file to the zlib decompressor. ``` r, err := zlib.NewReader(file) io.Copy(os.Stdout, r) r.Close() ``` In the second case, you will have to work out where compression begins and ends, extract those segments from the file, and run them separately through zlib. For more information on zlib, see: https://tools.ietf.org/html/rfc1950 For general learning of binary file formats and how to parse them, I would recommend temporarily stepping away from your proprietary sample, and start by parsing a file with a documented format. Starting with an image file format that includes fairly simple uncompressed or losslessly compressed data makes for a good testbed, because you can have a visual feedback - either in taking existing files and parsing them to render the image, or in the reverse of attempting to write a valid image file and get it to be read by a regular image viewer.
I don't see how that changes anything. I can clone someone's repo, which will have those signed commits (it's the same tree), then push my clone somewhere else as-is, and tack on my own.
I don't see the point why they wouldn't make it configurable... This way you must update the go core.
Maybe, but I think it'd be pretty frustrating as a developer to make a mistake, then basically be told "your import path is now unusable, make a new repo" because some outside service indexed it. Compare it to now, where these sorts of things can be worked around by having consumers re-do their go.sums. For example, the latest Go releases fixed issues with symlinks and modules, where some versions of Go produced incorrect sums and [required manual intervention](https://github.com/golang/go/issues/29278) to fix. In my examples, it's not the Go tooling making a mistake, but a user, but now there's some extra service going around which seems to set sums in stone.
not with this package, but this is what https://github.com/llvm-mirror/llgo is doing
&gt; one-off Nitpick: [reposurgeon](http://www.catb.org/~esr/reposurgeon/) is on version 3.45, and the `externals` directory in it is six years old, at least. (I tried scrolling back on GitLab's history view and got bored after a minute having only gone back two years.)
Now if someone make a module mirror based on NPM, we can have an option of drama also :-)
…which is why reposurgeon was written in Python first.
Calling it officially-sanctioned is not too dissimilar to call Go critics paid trolls. Needlessly aggressive way to malign people or community. About 'Reasoned critique' I am afraid is mostly used as $10 phrase for 10c 'In my opinion'. From what I have seen here it is not some rigorous analysis of situation but more of "I know 2 language they do it in this way, then why go does not do same thing?"
Well, I guess we have to agree to disagree. In my opinion, Python is slow and clunky for no reason, and Go is fast and slick. I already program in Racket which is faster than Python and batteries included, too, so using Python would be silly for me.
thanks for your reply. i do understand what you mean, but i was looking for a challenge, thats why i started reversing a proprietary file format. i'm now able to decompress the file. the key thing i was missing was, that i have to create the data structures first, before loading some data in. i was thinking the wrong way, i expected that i'll create the data structures while reading the data, if that makes sense!? the thing i figured out is, that all the informations you mentioned are basically stored in the file header. i was able to extract the compressed and decompressed block size, this was i know how big my uint8 arrays have to be and how big the decompressed is. compressed := make([]uint8, fileHeader.CompressedSize) binary.Read(file, binary.LittleEndian, &amp;compressed) uncompressed, err := zlib.NewReader(bytes.NewReader(compressed)) if err != nil { panic(err) } defer uncompressed.Close() var data bytes.Buffer _, err = data.ReadFrom(uncompressed) if err != nil { panic(err) } its working this way :D there's still some more work to do, but i think i'm now on the right track, at least i know that zlib has a hex header of 78 :D
https://www.merriam-webster.com/dictionary/vice%20versa
One of the thing that's always been a bit off-putting about the Go community and leadership is that it seemed that when I came across things that I perceived as flaws in the tooling or language, I often felt told off and was made to feel that it's me who is wrong for a variety of reasons. Examples of this include GOPATH, the package infrastructure, error handling, lack of generics. Rob Pike disagrees so I must be wrong. It's kind of satisfying to see that the "Go way" wasn't the best way after all and that some of these things are actively being addressed. I hope it makes the community a bit more welcoming as well.
We will pay for all our water usage?
You'll want a good hex editor for your OS. [Synalyze It](https://www.synalysis.net/) and [Hex Fiend](http://ridiculousfish.com/hexfiend/) are good options on macOS. On Linux, you could try [Okteta](https://utils.kde.org/projects/okteta/).
i'm on linux, i'll give okteta a try.
[removed]
&gt;blog.golang.org/module... Not entirely sure if I understand your response.. as a Go noob who despises GOPATH, are you saying those of us that come from languages like Java and find GOPATH difficult to grasp.. because we ask "why is it this way" are downvoted/shamed? I assume that is what you mean, which if it is, I too have felt the wrath of some of the Go community where they either like it, or just say "it is how it is, too bad, deal with it.." so to speak, in which case I take those responses as people who are not wanting to see something (in this case GOPATH) changed, for the better preferably. To me, Go Modules seems like a much better solution so far. But I dont do any coding in Go yet, just dabbling/learning still when time allows. &amp;#x200B;
[removed]
I'd start here: [https://golang.org/pkg/go/build/](https://golang.org/pkg/go/build/)
Now, *this* is exciting! 
&gt; "I know 2 language they do it in this way, then why go does not do same thing?" Which is a perfectly fine question *to ask*. That's my whole point. People asking questions shouldn't get derided for it. If you don't want to answer them that's fine, just move on. But instead, people downvote them and attack the OP in comments. *That* is what I'm arguing against.
&gt; are you saying those of us that [...] ask "why is it this way" are downvoted/shamed? Yes. It applies to the GOPATH question, but isn't limited to it.
The fact that your comment is downvoted is proof enough that you are right, unfortunately. Apparently if you are not preaching the gospel, you are not welcome here.
yes
This is an amazing error message. Almost ripe for /r/softwaregore Don't know the answer though
We invented solar panels and we live on the water planet. You can distillate all the clean drinking water you could possibly need.
I agree his use of break/goto is not great. Per #1, why do you think this is a spin loop? The first channel receive on each outer loop iteration is blocking, while the remainder are non-blocking. None of these ops should spin. I have posted my improved version here: https://play.golang.org/p/G4GB4cTIRh2 
&gt; In this sub, newbies who simply ask "why is it like this" get downvoted to hell before anyone even bothers replying. I read literally every single submission to this Subreddit (have it RSS subscribed) and I haven't ever seen that. Things that get "downvoted to hell" are usually people who curse and unconstructively snap at anyone responding. I'd be fine to be proven wrong on this, but ISTM that this is a preconception not based in reality - which doesn't make it better, necessarily, because if the community has a *reputation* for that, the harm is done either way. It just makes it a harder problem to address.
&gt; We are planning to launch a mirror service for publicly-available modules in 2019 About time! Honestly, the current situation we've had for 10 years is terrible.
&gt; We also want the service to allow looking up packages using simple queries, to allow goimports to add imports for packages that have not yet been downloaded to the local system. I find this… concerning. `goimports` is already painfully slow on a large GOPATH whenever you typo an identifier - if it now has to timeout on a network request, working offline is going to be an absolute pain.
a bit old, but still interesting :) - https://blog.gopheracademy.com/advent-2015/gopy/
One person's opinions doesn't design a language. I really like the package infrastructure and error handling (although I could see some things to improve here). GOPATH took me little over a day to get past. I do miss some stuff the generics bring to the language. The important thing to note here is that it's a developing language, that a large amount of people agree with and equally many dont. Now.. just because it keeps developing and adding new features doesn't mean that it was wrong or right beforehand. It's just developing.. I've never experienced what you described, but to be totally honest almost everything about the language just clicked for me. So we definitely have different experiences :) 
There’s more downvotes on this comment than people who actually responded to the guy. Hypocrites
[removed]
Now if someone could just teach docker about semver and fix case sensitivity when a repo changes it's name.
This might give you food for thought: &amp;#x200B; [https://github.com/golang-standards/project-layout](https://github.com/golang-standards/project-layout)
Well there is nothing to disagree with you. I feel whole internet is nowadays like this. Interpreting other person's argument in worst possible way seems default behavior.
Hey thanks, I've made that change. &amp;#x200B;
[removed]
Yeah. Also I really do want to thank you for the feedback! At first I was confused because I didn't necessarily know what I should do to immediately improve the code. I will say that a total rewrite may be in the cards. I did write most of the code 4-5 months ago when I knew nothing (well I still don't know anything). After some of the suggestions in this post I have a better idea on how to go about making this better. Thanks for the tips about reading more blogs, and doing more tutorials to get caught up to speed. &amp;#x200B;
Thanks for posting this up here! We've also got a CFP online here: [https://www.papercall.io/goconca](https://www.papercall.io/goconca)
I really want to be able to get the "go.sum" line for the existing project. There's no way to do this that I'm aware of and all the libraries are behind an internal package to the go tool. 
Inb4 sirupsen
yah I'm trying to fix that dependency now as well as docker's nightmare versioning. We also got screwed by the whole docker =&gt; moby thing.
Are there plans to handle the evil package problem? Will the Go team deindex harmful software? What about cases like copyright violation or Chinese censorship?
Psst, this change doesn’t get rid of GOPATH, it just buys new PR. There’s still a path on your computer, where Go looks for caches of modules. They just let you ignore it in Go 1.11+ (which you could always do with `go run file.go`) but it’s still there. 
Maybe a system specific call to see if you’re offline before the request?
good boy
Hey all, still relatively new to Go, so any project feedback at all would be most appreciated.
https://www.safaribooksonline.com/videos/complete-introduction-to/9781789349344 
They're deprecating GOPATH with 1.13, so yes. They're getting rid of it. How it stores the code/module is a separate concern from GOPATH itself, it could easily be done similarly to python or just throw all the packages into the GOROOT.
That'd be the intended way to fix, if the checksum fails it requires someone to inspect if it's still good.
Sure, but the notary's not going to go changing things.
My last example, for sure (so long as no client attempts to checkout a revision which no longer exists but is still in the notary), but I don't think that really effectively handles the other two. In the first case, it means that anything you re-do is (at best) forced to pick a major version higher than what the previous project had. It'd kinda suck to have to start a project at v2 when it's v0 quality. At worst, the Go tooling may choke because it goes searching for versions, finds that the notary already has some v1, then attempts to check it out (which fails, because the old commit hashes are meaningless in another repo). All this does for me personally is to make me not want to publish code I don't want people to start using for fear of wanting to redo things from scratch, or to prevent a bunch of stale repos from sitting around to prevent history from being rewritten (normally, I'd delete repos I don't think I ever want to revisit). I guess we'll see when this notary gets implemented and is available for testing.
The only thing that has worked for me when using modules with the Docker repos is to give up trying to use any specific version, and instead specify revisions for each (or just `@master` for the latest), forcing the tool to use a v0 psuedoversion. It works, but then if I want to update their repo it means recreating the go.mod file, because it tries to update to semver releases which doesn't work.
It's an error from the Delve golang debugger. "nexting" refers to the "next" command in Delve, for single-stepping through one expression at a time. It's saying that it was trying to single-step and it failed. Here's a discussion of one case where that would happen: https://github.com/derekparker/delve/issues/387