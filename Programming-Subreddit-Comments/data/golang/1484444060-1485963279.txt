Cool, it will probably work for Caddy sites as well, since it now serves static .gz content (out of the box).
Probably one of those smaller rooms again like the last few years? Was always packed, so was never actually able to attend a talk there...
Plugins don't work on macOS or Windows? Hmm, not sure they'll get much use until 1.9 then. At least not for open source projects. The beauty of Go is that it works on all platforms.
I'm currently working on a Pi project. This is awesome news. I'm hoping that memory consumption also went down. Will try it out today.
exec.Command is just calling the fork/exec syscalls. Globbing is done by the shell (before it does fork/exec). You can invoke the shell and tell it to execute a command with the -c option and the shell script to execute as a single string: exec.Command("bash", "-c", "mkdir -p {bar,baz}")
There is a [writeup](https://github.com/google/fchan-go/blob/master/writeup/writeup.pdf) in the repository.
The Lesson; Dear Reader: It's there because it was put there once and now can't be removed. Lets check blame... the flate decompressor struct was given a Close method in this commit: https://github.com/golang/go/commit/07acc02a29ac74e7c0b08b4cd382bf71acd262dd Before that commit, flate.NewReader returned the reading side of an io.Pipe. You can see that [here](https://github.com/golang/go/commit/07acc02a29ac74e7c0b08b4cd382bf71acd262dd#diff-206fa45b94395c28494b1845f689e7a7L627). This is most likely why flate.NewReader returns an io.ReadCloser. The new (as of 2011) flate decompressor non-op Close method is due to the evolution of code and requirements of API compatibility. The gzip package is unaware of this and continues to use the flate reader as-is.
To my knowledge, support for macOS and Windows has been postponed because of bugs that need more time to resolve than what was left until the planned release of 1.8. I don't think this indicates a "Linux first" attitude in any way. 
Err... Is that the best name for a project? My friend says you should consult with google 
there's no support for `select`, so it obviously covers different use cases.
This was a very well written post! As someone who has a background in C# I found the interface in Go to be very confusing at first, and while I have been writing in Go for a few months now I just kind of avoided them... Reading this definitely cleared some things up, time to *Go* change some code.
This is listed as one of the future work with items in the write up. It looks promising. Hopefully the go team will consider it 
Well, _Google_ has to consult with Google this time.
`interface{}` doesn't affect performance in any way you should worry about. Anything you're gonna do *after*, that's worth having an argument as `interface{}`, is likely to be slow (like reflection).
why?
This is great, thank you! But if all interfaces reduce performance, why are they recommend? Is it because the code is cleaner/more intuitive? Or is the slower performance negligible for most uses? In your second benchmark it takes like 11x more time per op, but I guess it's still pretty fast
&gt; This is because interfaces introduce a level of indirection. &gt;They are basically pointer pairs, one for the value itself, and another for the corresponding type. thanks! imho this is important for understanding ! 
Most of the time using an interface will not be the limiting factor in your app. Something else will bottleneck you and it simply won't matter. This is roughly akin to people trying to find the fastest web router when they use a single threaded DB that could never keep up with any of the routers. It rarely is a performance hit that is worth considering if it makes your code cleaner, and if you are in a situation where it does matter you likely know that already. As far as why, there are lots of reasons. You could use an interface to easily swap the implementation of something behind the scenes without the rest of your code needing to know about it (eg switching from one DB to another). You could also make your code much easier for others to use. fmt.Fprintf() is a good example of this, where the first argument can be anything that implements (I believe) the io.Writer interface. Similarly, the http.Handler interface allows tons of third party packages (routers, middleware, etc) to all write code that plays nice with each other because most are designed to work with that interface. PS - on mobile so sorry if this is sloppy.
Thanks, it means a lot to read comments like this :)
The number of readers here who directly benefit from this might not be huge, but it would be great to get this some upvotes so that anyone considering a proposal sees it. Having the best talks possible at gophercon likely will affect everyone here as many of us watch them online after the fact and learn from them. TL;DR - upvote this plz
Thx. More articles are always welcome as a reference :)
[removed]
That should be in the readme
From the README.md: `This is a proof of concept only. This code should not be run in production. Comments, criticisms and bugs are all welcome!` Also, I didn't write this, I just found it.
Faster bound channels.. http://github.com/itsmontoya/mailbox
Ah, so you mean that the logger has some method that returns a vendor'd type? Well, you could also leave that type out if it's not necessary for any outside library to access. Which still begs the question why your library needs to expose it's logger. IMO it should be sufficient to implement a simple "EnableDebug" method and a "SetOutput" method to redirect logging output to a writer. Vendoring is not perfect, that is true, but sometimes the issue just requires a different approach.
&gt;It's a ticking time bomb for anyone that wants to import my project. [](/lunapoker) If it fits it sits. *pokerface*
[removed]
Not very much like channels. https://www.reddit.com/r/golang/comments/5bukub/mailbox_an_alternative_to_go_channels/
RE: read/write timeouts, you'll want to set the read/write values for your server to 1 or 2 minutes, and have the client automatically retry on a timeout error. It would be nice if you could customize the timeout by endpoint, but I'm not sure if that's possible.
Unbounded channels are not a good idea, but the writeup does end up talking about constructing bounded channels too. For the equivalent of `make(chan T, 1000)` this thing is slower for low contention, and only gets 50% more ops/sec for 5000 goroutines. And as far I understood, it needs to allocate regularly, even for bounded channels. That's.. not impressive.
Can one say it's the equivalent of a void* in C?
From this comment I am assuming you are the author. Under the first code example it reads "some of which aren't necessary rock." I think that is a typo and should be "necessarily" Great article though, I am new to Go and this was really helpful.
I am and thanks. I'll check it out when in back at my computer.
I am not a fan of the pocket in the middle of it. I would rather it just be a flat stomach. But either way I will most likely buy one.
It was my pleasure.
I thought the same thing when I saw this repo, also isn't zap supposed to be better than logrus these days anyway, which is exactly why you shouldn't depend on a specific logging library because your choice may not be my preferred choice.
... It's an immensely complicated subject. If you're interested in the mechanics, you can read the writeup. If you're not, "it's faster" should be enough for you.
Many thanks, @dahlama, Can you help me review and give some advice to improve my example.
Very grateful for your comments, I'll improve and ask you review 
I'm not sure I understand what the IDE should do in this case, can you please expand on the idea? Thank you. 
I do not know C well enough to say. Sorry :(
42 and 420 in the version number, nice
small useful dev tool to share stdout over secured network (tls).. enjoy. feel free to open issues.
Oauth doesn't protect against bad passwords... They now just have the weak password on Twitter. After one breaks that we can easily just log in, providing essentially no added security. You just transfer the issue to another company, not making it better. Password/2 factor with SMS/auth token would be harder to circumvent (and harder to implement/ distribute)
Technically yes; in Go, the term "variable" applies to anything which can be assigned a value. I'd say its more semantics than anything, though; the distinction isn't horribly important unless you're planning on contributing to the language lexer. 
Cool, so, like netcat but with TLS.
yep.
Very cool. But, to be honest, I'm more interested in the Literary Style. Very cool and I'd never come across it. 
interesting! do you also have the Wayland backend in the pipe ? :)
For the first time in my life I have seen as someone writes in a literate programming style. It is so strange and unusual! :)
No. In C, casting a variable to void* causes all type information to be lost. With interface{} in Go, you can use type assertions, type switches, or reflection to get the original typing back.
I liked. Do you have a plan for an initial release? 
No for a map or string variable **x**, **x[i]** is not addressable, so **x[i]** can't be viewed as variable. 
Yeah, a completely valid argument, but my goal with the article was to help make your web app as secure as possible, not try to fix everyone's issues. And, as I understand it, SMS tokens are a very bad Idea, they are easily intercepted. However, each of the 3rd party providers (Google, Facebook, and Twitter) all provide two factor authentication. I'd love to write an article on building 2FA into a site someday, but currently I haven't done more than play with it. And even if you did implement 2fa into your site, do you really think you could do a better job than Google, Facebook or Twitter?
SMS tokens get a bad rep because some attackers have learned how to convince a cell phone company to somehow start giving them texts for a number they don't own. I'm not 100% clear on how but that is what happens as I understand it. This in itself isn't bad. It is only half of your password, and the other half is the password you type in by memory, so this should not compromise security completely. Attackers still need to learn your password, so it basically just becomes a regular auth system. Where this becomes problematic is when companies will let you "recover" an account with nothing but access to SMS messages. I believe this is where the actual issue stemmed from in nearly every "SMS tokens are bad" post, but correct me if you know otherwise.
go spec says &gt; A variable is a storage location for holding a value. . &gt; Structured variables of array, slice, and struct types have elements and fields that may be addressed individually. Each such element acts like a variable. It neither deny my opinion nor your opinion directly, but I feel it prefers to mine, :)
It's been a while since I used awesome, but IIRC isn't it more similar to (not)ion where you need to predefine the tiles for windows to live in, and then tag windows to move them between them, rather than dynamically resizing the windows to make room for as many as you have open?
I've thought of it... not being able to click on the errors from "go build" to plumb them is annoying, and I don't find the 9term implementation from p9p very useable. Though I'll probably approach it by trying to improve the "Shell" command in de (it's pretty buggy/unusable right now, and the work is the same either way..)
https://wayland.freedesktop.org/docs/html/ch04.html I started the work some time ago based on this, but never made significant progress, because it just wasn't high priority enough. But the wire-protocol is pretty simple.
It's something that becomes a fad every couple years for about a week, and then dies out again. I think I first heard about it in the interview with Brad in [Coders at Work](https://www.amazon.com/Coders-Work-Reflections-Craft-Programming/dp/1430219483/) and I'd been meaning to try it. To be honest, I'm not sure if I'd start any new project this way now that I've tried it, but I'd recommend anyone who considers themselves a programmer try to do something with it, for the same reason I'd recommend trying out any other programming paradigm that they're not familiar with..
Awesome writeup on the subject. Simple enough so that it's easy to understand, but it captures the nuance of the topic at hand.
And that is how it looks with javascript turned off... http://i.imgur.com/UwgzDB0.png
has the memory gone down?
FWIW, the main issue I'm having with Wayland is that a lot of important details weren't hashed out when I last checked (e.g. what a "Window manager" actually means in that context, how lockscreens/task bars/notification areas/… work...). Also, doing it in go might mean having to implement a full compositor. Most existing tiling wayland compositor so far use a library provided by wayland, AFAIK, which does most of the heavy lifting (but can't really be used without cgo, of course). The architector of wayland seems to be just very different from X and might prevent doing it in go without significant overhead. If I'm wrong about this, that'd be great, of course.
A tiling window manager! (http://i.imgur.com/4xpa5uO.jpg) 
Not the author, but thanks for making me curious what my own site looks like w/out JS. It is useable, but could def use a little CSS love. 
This looks cool. It would be cool if someone built a 2D tiled graphics library/framework on top of this.
When I say about an initial release, I say about distro created packages to dewm. Very distros don't packaging when don't has a version. I try dewm using go get and I liked!
That's the impression that I got while looking into it this weekend, too. (Not that "what a windows manager" is isn't hashed out, but that it's simply not part of the architecture at all.) The link you provided gives me a little hope, though, because it seems to imply that the API for compositors is autogenerated from an XML spec (never thought I'd say that..) and the wire protocol is documented, but I think that's a lower level than what libweston provides for C programmers, so there's probably still quite a bit of work involved. It must be possible to support both X and Wayland, though, because KDE, Gnome, E, etc do it..
Yes, it's definitely possible. But all of them implement their own compositor on top of OpenGL (even on X, AFAIK). The Wayland API itself is not so much a problem, it's that you *basically* are implementing the equivalent of the X Server, not of an X Client (AFAIK). libweston contains all of that code (which is a bunch. Basically most of what's making up weston anyway). And yes, the wayland API is generated from an XML spec, fairly trivial to parse and generate appropriate code (as I said, I got ~80% there in the space of one or two days, IIRC). Anyway, best of luck with that :) If you actually end up doing it I might piggy-back on the effort (though who has the time, tbh…).
There's [go-wlc](https://github.com/mikkeloscar/go-wlc), which could get you started. The author started has [flis](https://github.com/mikkeloscar/flis), which uses the library so you can take a look around.
I would never ever switch back to neither Node nor PHP
Go back to Node? Crazy talk. ;)
So I take it you've found the stdlib and package ecosystem to be more than sufficient for your needs in comparison?
I really appreciated this, and the first article in the series: http://tech.townsourced.com/post/anatomy-of-a-go-web-app/ Thank you for writing these, they are very helpful and informative! You're doing good work!
Seems like a cool project at first glance, although it's difficult to say what it is / exactly how it works without looking through the code. Maybe add some general docs to describe the project and features? For example, is it comparable to something like [bacula](http://blog.bacula.org/) in function, or is it meant to be called from code to backup a generic dataset, or ... ? What is the difference between a node / server; is that something like a master/slave replication setup, or are nodes the clients that connect for backups? Etc etc, just general FAQ stuff like this. Seems cool though, if it is what I think I may start using it.
Rewriting my personal website to use Caddy instead of Nginx is next weekend's project. :-) (The main tricky bit are all the rewrite rules I had in Nginx.)
Awesome allows for a multitude of window layouts that can be cycled through with a meta-space. There's even a floating mode where you can freely move Windows around. It's been a long time since I've used ion, after finding awesome id never go back.
Sometimes it's better to change the name. I had a bunch of structs which returned the s-expressions of their children... `ChildSexper` doesn't sound good at all
It prevents the Go compiler from giving an error about unused imports. 
That seems silly in a context where you could get rid of the compile error about unused imports by just not importing things that you don't use.. 
&gt; visual Has no screenshots.
I see. Three people saying the same thing is obviously a problem. I'll write something here and I'd appreciate some feedback on this as well, if you guys don't mind. It's an automatic backup daemon. There is a server daemon running on the machine you want to backup things from, and node(s) running on separate machine(s) querying the backup server for its file "index". The index is metadata about the files on the server, including a hash, last modify time, file or directory, etc. The server root can be specified in the server configuration file. Nodes can only access the index and sync files/directories below the server's root directory. The nodes update their own index with the server in an interval, say every 12 hours. When the node gets an index from a server, it will index its own files, and compare the result. If there are files on the server that the node doesn't have, the node will request the files via the /sync api endpoint. If there is no difference, there's nothing to do, so the node does nothing. Additionally, you can specify what directory you actually want a node to sync. Say you have your server watching /home/user on one box, and your node running on another box. You can have the node only sync the /home/user/pictures directory. I guess this pretty much makes the autobd a 'fileshare' of sorts. The server also has a list of nodes and their status (offline/online|synced/unsynced). This can be accessed via the /nodes API endpoint. Of course this exposes the IP addresses of the nodes, so this is insecure. I've been using it for debugging purposes. This endpoint can be disabled completely via the server config file. The main way I envisioned this running is mainly inside docker containers. You have one server container, and multiple node containers (on the same machine, or on other machines.) Each node can sync a different directory from the server. e.g: server indexes and serves /home/user{A,B,C} node A syncs /home/user/A node B syncs /home/user/B node C syncs /home/user/C Thanks for your feedback. I really appreciate it. I had no idea how dense my readme was, and couldn't understand why I was getting no interest despite tweeting and 'marketing' it, even just a little bit. Anyways, there you have it, tear into me. Edit: formatting 
That makes sense. Thanks!
I stumbled across that when I was looking, but it uses cgo. (Though I think this might be one of those rare cases where you don't have much choice but to suck it up, eat the compile time, and use cgo.)
Originally I started this project after a hard drive failure. I was writing it in C and using inotify descriptors to recursively watch a directory. Of course this was a terrible way to do it, so I scrapped that idea. Then I started learning Go, and decided to pick it back up, except this time with a more consistent and well thought out RESTful API. I guess my rationale now isn't really because I couldn't find a good backup solution I was happy with, (I still honestly can't) but because I want this to be a gem on my resume I can point to in interviews. "This is my project, it works, it has a userbase, I've stayed committed to it for a long time, I've used x, y and z technologies to build it, give me a job." I realize now that might not be a good reason to do anything really. It hasn't worked out at all, and all I've gotten so far is blank stares and dime a dozen interviewer type responses. I guess I'll do a little more soul searching on this matter. I appreciate your comments. Edit: I should also clarify. Yes I do still have a need for this project, and I do feel that 'itch', but I would still like to see at least one of my projects to 'succeed' and see at least somewhat wide usage, even if it's short lived. Maybe that's a little out there, though. 
i'd insert a meme, but the google/meme-generator requires `go get` and `go run`
Cool, so it is basically a file synchronization daemon then, does it have any support for versioned backups, change tracking, things of that nature? This seems like automated rsync or btsync in Go, which is nice - although, I wouldn't call it a backup unless you are actually storing old versions. Example being - if I delete a file on the server, or an application corrupts my files, will the nodes likewise delete / corrupt their copy of the file? Allowing roll back of sets of files would instantly increase the usefulness of this as a backup architecture. From examining `node/node.go`, it seems files are overwritten whenever there is a change in checksum, correct? A couple questions: Are nodes carrying read only copies of the data? It seems to me they are, though unsure. Do nodes replicate changes with each other, or is data repeatedly pulled from server for each node? Modes I could see this being used in (with some additional features not present (I think)): #### Backups Servers `sA sB sC`, each has directories that need to be backed up. Nodes `nA, nB`, each receiving a complete read only copy of all replication directories on `[sA, sB, sC]`with version history. One goes down, you still have a viable backup of all three servers. Every file change on any server should trigger a new version of the file to be saved onto each node (something like [inotify](http://man7.org/linux/man-pages/man7/inotify.7.html)) *or* periodic rescans. Configurable, periodic culling of too old versions to cut down on storage usage. Client software to revert changes / pull specific historic states / general stuff you would do on backups. A web interface would work well for this (probably running on nodes). Example workflow: Install client software on servers that connects to a node and syncs. Node syncs to other nodes. Occasionally log in to interface, select server, browse filesystem, download as tar or press 'revert here' to automagically push the old copy of a file / dir back to the server. (Sysadmins hate him for this *one* weird trick!) Keep the newer version on the node just in case. Or use a cli tool on the server to do the same (seems there is already one). #### Sharing directories ala btsync Server sA, replicating dirs `/home/a/files`and `/home/b/files`. Nodes nA, nB, each receiving a synchronized copy of `/home/a/files`and `/home/b/files`, respectively. Nodes then use other software and access files through local filesystem for whichever purpose. It seems as though this is geared more towards the second approach. To be perfectly honest, as it stands, a cron job rsync over ssh accomplishes what this does. With some extra features it would be an awesome tool. File versioning, web interface, revert capability, and you have a solid product that would be seriously useful in a lot of places. Encrypted storage on nodes, more efficient replication (torrent / delta compression or somesuch) is just icing on the cake. Maybe cache indexes persistently in a sqlite db / something so there doesn't have to be so much overhead on each compare. Option to dump to cold storage or cloud would be awesome too. &gt; Anyways, there you have it, tear into me. Ask, and ye shall receive :p
I think your current setup is master syncs to all slaves - is that correct? Could the reverse be useful as well? Where you have one "master" server (pretend it is your file server) and then your "slaves" (which could be any other server) use this to push data written locally to the master server. I'm not sure if you would need to have a full copy of data on each slave to make it useful, and it might be up to each server to avoid file conflicts, but it might be worth at least thinking about if it doesn't add a ton of complexity. Just a thought, and probably not very great one :)
&gt; it have any support for versioned backups, change tracking, things of that nature? This seems like automated rsync or btsync in Go, which is nice - although, I wouldn't call it a backup unless you are actually storing old versions. Yes. That's what I'm going for. Backups always running so you don't have to worry about if if rsync or another package updated and now your cron script is broke. Things like that. Versioned backups are definitely a feature I'd like to have, although it seems to be a bit beyond my capacity right now. Of course I'm doing this to make myself look good, so I suppose it'd be best if I ventured outside of my comfort zone and gave it a swing. ;) Change tracking I hadn't thought of. I will definitely try to work that in. The closest thing I can think of is that windows restore feature, where there's points in time you can revert to, just with your files. Neat stuff, especially if it was feasible to sync every 30 minutes or so. There would be almost no data loss in the case of failure. &gt; Example being - if I delete a file on the server, or an application corrupts my files, will the nodes likewise delete / corrupt their copy of the file? Allowing roll back of sets of files would instantly increase the usefulness of this as a backup architecture. From examining node/node.go, it seems files are overwritten whenever there is a change in checksum, correct? Correct. The nodes will keep all files, even if they are deleted on the server. Once the node has the file, it won't touch it unless there is a change on the server. I want to do delta compression, but again, a bit beyond me at this point, and I really don't want to reinvent the wheel only to have it be a buggy mess. &gt; Are nodes carrying read only copies of the data? It seems to me they are, though unsure. The permission bits are transferred to each node, and are not change (as far as I can tell, I haven't tested this extensively.) &gt; Do nodes replicate changes with each other, or is data repeatedly pulled from server for each node? Data is repeatedly pulled from the server. The main idea I had is that there is one server, serving a directory tree, and multiple nodes that sync different parts of the tree. So say you want to backup your pictures on one server, and your source code on another. You could have two autobd nodes running on two servers, and each would only sync the directory you tell it to, or it could sync the whole directory tree. I think this would be the best way to do it, since you can switch out nodes easily, and don't have to fsck around with the server. &gt; Servers sA sB sC, each has directories that need to be backed up. &gt; Nodes nA, nB, each receiving a complete read only copy of all replication directories on [sA, sB, sC]with version history. One goes down, you still have a viable backup of all three servers. Every file change on any server should trigger a new version of the file to be saved onto each node (something like inotify) or periodic rescans. Configurable, periodic culling of too old versions to cut down on storage usage. This was my original idea, but the last time I tried to use inotify with Go, it was buggy. I can't recall the exact bug I ran into, but it was a show stopper. I'll have to look into it again. &gt; Client software to revert changes / pull specific historic states / general stuff you would do on backups. A web interface would work well for this (probably running on nodes). &gt; Example workflow: Install client software on servers that connects to a node and syncs. Node syncs to other nodes. Occasionally log in to interface, select server, browse filesystem, download as tar or press 'revert here' to automagically push the old copy of a file / dir back to the server. (Sysadmins hate him for this one weird trick!) Keep the newer version on the node just in case. Or use a cli tool on the server to do the same (seems there is already one). This is why I opted for a RESTful API, to make it easy for myself (or someone else) to extend the usability of autobd, and do different things with it. The web interface would be great. I didn't even think about the ability to download a tarballed snapshot of a directory. That'd be pretty freakin neato. The revert part would be neat as well. I guess I envisioned a more manual scenario like. "Welp, lost a bunch of files, better go manually tarball all my stuff and wget it back to my server". The one button press would definitely be great. &gt; Maybe cache indexes persistently in a sqlite db / something so there doesn't have to be so much overhead on each compare. Option to dump to cold storage or cloud would be awesome too. Yeah. That's my main barrier to progression right now. Indexing a whole filesystem takes a lot of memory, a lot of cpu time and really just isn't feasible. I'd hope that a user wouldn't point the server at their root and wonder why it's taking 3 hours to index, but you know, PEBKAC. SQLite I haven't thought of. That sounds like it would be a good solution. My SQLfu is weak, but I've been looking for an excuse to really get into it. Thank you so much for your input. You've really relit the flame I had when I started this project. My mind is really going now. I'm gonna get to work. :) 
Perhaps they don't have auto-goimports set up. Or don't feel like introducing extra churn in diffs.
As someone lives in Shenzhen, what's the relationship between the city and this project?
I don't know, but I do know there's precedent for using cities as codenames: https://en.wikipedia.org/wiki/List_of_Microsoft_codenames#Windows_3.1x_and_9x
I don't use auto-goimports either, but I don't have much problem replacing '"fmt"' with '// "fmt"' when the compiler complains, and removing the '//' when I want it back..
If anyone wants a place to start, use the [JSON format](https://github.com/bjorn/tiled/wiki/JSON-Map-Format) for [Tiled](http://www.mapeditor.org/). It seems like [this bloke](https://github.com/slightair/goobbue-prototype/blob/master/goobbue/map.go) has already implemented the format, so look there if you need any pointers.
FWIW, you can click on the line number to create a [direct link](https://github.com/papertrail/remote_syslog2/blob/master/remote_syslog.go#L23).
Check out the "Properties" section!
Have a look at restic too, this sounds quite similar. If you lose heart on this particular project, you might consider trying out their tool and contributing there, as it sounds like it is fulfilling a similar need, and they would probably welcome contributions: https://restic.github.io/ I'm not sure there is a requirement for a background daemon for backups because they can be run periodically, and in many ways that would be preferable (you can schedule at a non-busy time on the server for example). You don't want backups to be running at times when the machine is otherwise busy. If you want to run as a service you might consider using fsnotify to only send files when they change, however I'd consider designing it to run instead at specific times.
&gt; Hi, I'll brain dump exactly what comes to mind after visiting the github. Thanks, that's exactly what I'm looking for. :D &gt; A program for backing up my data, oh.. typically I would just hit the back button. Not because of anything personal, because I lack respect for you or think there is not room for another backup program. It's just not realistic for me to spend valuable time I could otherwise use for my own projects to get up to speed on a program to replace solutions that are already battle hardened. Brtfs lvm snaps, rsync, dd, tar, Luks, you know them all. Right. That is to be expected. The one thing I think Autobd does better than those you mentioned (unless I'm uninformed, if so let me know) is being able to deploy it easily via docker, and have it run constantly in the background. Little to no configuration needed. Just unpack, run containers, done. &gt; But if I pretend to desperately need a new backup solution and I needed to review yours, the very first thing I have to research is security. Since its a daemon there is a server, this means surface area, it's not clear where the daemons live but it appears to be remote and listen on a public port? But there is zero mention of security, protocols used, hardening, data privacy, etc. Security is a big deal, I agree. I will admit I didn't think into it as much as I probably should have. &gt; This makes it seem like those where not at the forefront of the authors mind. Other than HTTPS/node verification/node authorization, what would you recommend? I will admit i'm not super security inclined, but I of course will be sure to brush up. &gt; are you using it today? If not then how could you expect anyone else too :) I guess I kinda made my title a little ambiguous. I was going for more of a "Hey guys, do you think there's room for my project, what do you think? and what do you recommend?". I guess it's obvious at this point that my thinking isn't super clear at this point. Maybe I will take a break. :) Thanks for your input. Definitely helping a lot on this sub.
I agree with him, I could never go back to Node or Python. The main advantage of Golang is that it's statically typed, while still being nice to use due to fast compile times and good tooling. Deployment and runtime environments are way less of a hassle too. And it's faster.
I'd rather go with v8worker (embedded chromium engine) than adding node to my stack.
Happy to report that this also works on gomobile targets on iOS
it's used in autogenerated code a lot - not really sure of the intention though
Just my two cents - don't worry about other peoples interest when you think about continuing your own projects - is it still fun/interesting to work on for you? That's really all you should care about :) 
I've had this snippet in my bashrc since I started writing Go. It assists in making it work with the same project-oriented workflow that most other languages cater to. cd () { builtin cd "$@" &amp;&amp; export GOPATH=$(pwd | awk -F "(src|pkg|bin)" '{$0=$1}1'); }
Hopefully, someone will convert it to written docs ([go#16526](https://github.com/golang/go/issues/16526)).
Instead of reading an HTML file at runtime, and thus needing to process a lot of text data regularly, this engine takes in an HTML Template as an input, and pushes out a Go file that can be used alongside your project. It should be considerably faster than a traditional template engine because it doesn't have to read and processes large HTML files. But that's just in theory; I'm not sure how good `hero` really is.
It's called gb - https://getgb.io/.
&gt; Not having to worry about declaring types or mapping data to structs, pointers, or other data types is a big bonus to me, it allows me to focus on solving the problem and not getting lost in programming minutiae. Says the Javascript programmer lol. I don't ever seem to have that problem. I can actually code something quicker using Go than NodeJS and actually not only have I been able to port my previous code from Javascript/PHP to Go. I have been able to introduce type safety and massive gains in speed and lower memory use.
&gt; My main concern so far is ecosystem size. It seems like there is a package for pretty much everything on npm. There is nothing stopping you from coding your own missing package. That's what I do, if I find something I want from PHP, NodeJS, Python. Of course, it's nicer if someone else has done it for you. But give it time!
You can versioning that for free by using ZFS or similar snapshot-supporting filesystem. Alternatively, you can hack it using hardlinks (what rsync and time machine uses to achieve this), or by using some custom internal representation that just stores files as object identified by their hash and a path-&gt;hash mapping, but having it in-filesystem is nicer.
That's actually a very good observation. One particular situation which immediately comes to mind is code generation that might use, but isn't guaranteed to use, certain packages. Take for example a code generator that allows a --verbose flag which inserts logging messages using the fmt package. It takes 30 seconds to modify the static template to include the fmt package as well as the hack described above. The generated code will now compile without having to run the output through "goimports" and without having to manually manage package imports. TL;DR: laziness
That's why I said in this context. (I looked at the code, and I didn't see any notice that it was autogenerated, so I assumed it wasn't.) In the context of autogenerated code, where code is held to a lower standard, it makes sense because you're often not really sure if it's going to be used in the generated portion of the code or not.
Yeah, Graylog is still ES in the end.
Pretty impressive that it can be transpiled to JS so effectively.
I'm curious what operational problems people have with elastic. I maintain a fairly complicated data pipeline and by far elasticsearch is the most stable piece and least likely to wake me in the middle of the night. That being said, I'm excited to see where this project goes. This space doesn't have enough competition IMO.
We welcome your questions, comments and rants. Please join our Slack group discussing the Tendermint and Cosmos, the Internet of Blockchains. https://forum.tendermint.com:3000/ Happy hacking!
I'll push to github after work for ya.
I've been looking for a simple log management solution like this for a couple months! My first attempt was graylog, but it was overkill (I just want to grep my logs!) This seems like exactly what I need. I'm running a small docker-compose setup with ~8 services and I'd prefer to keep log management as another container. Any insight on how to set up log forwarding in a docker environment? My initial plan is to use a [logspout](https://github.com/gliderlabs/logspout) raw adapter to gather logs from all containers on a host and forward them to a (local/remote) oklog ingeststore.
at that scale I think it's worth just paying for a cloud solution, as hardware, networking and other operational headaches become even more pressing than software I implemented something at at this scale using Go, DynamoDB and S3...replacing those in-house would have been painful and expensive
I find that one GOPATH per project is much more manageable. However I don't see the need of any tool to maintain this as to change the GOPATH it is literally one command. &gt; export GOPATH=/path-to-my-project/ Just my opinion :) 
My approach is to have shell scripts in the project that handle building. They use the correct gopath.
I tried to make a tiled graphic editor and then I found Tiled! It looks fantastic, but I haven't had the chance to try it. From what people say, there might not be another free competitor. It has a lot going for it.
What you are basically talking about I guess is web hooks? You would probably setup an http server with an endpoint that would accept POST with the notification and then check against your data store for subscribers and then just send it on to those subscribers. I don't really have any experience but have some interest in this so will subscribe for further comments.
That could work. We went with node for a recent project because we had a UI person that knew React/JS really well, but not much about backend. Node was a good idea because he could understand most of the backend which made it easier when I wasn't around. That's probably the one benefit I see to Node.
&gt; My consultancy? Lol. Your personal branding? Lol. But I guess it's working for you. Congrats. 
&gt; I'd like to know on the server side if the best thing (maybe the only thing, I don't know) to do is to build an API ? The term API is soooo overloaded these days ... I suppose you're referring to a RESTful API. And whether that's a good idea is pretty much a "business" decision more than anything else. It depends on whether you're planning to serve different kinds of client applications and whether you want partners or other external systems to interact with your service. If not a RESTful API is of questionable benefit because in addition to implementing the API itself you have to implement some kind of workflow on top of it. But maybe that's not such a big issue with a dashboard type of thing.
Thanks for your answer dAnjou. Yes, it would be a RESTful API. It would only serve the dashboard in my case. Is there another kind of API that would be more appropriate ?
Look, it's just HTTP. You can call the endpoints whatever you want, like `/gimmethatstuff` and `/gimmethatotherstuff`. You won't get it perfect the first time anyway. So just go ahead and get your hands dirty :) **UPDATE** Of course you can make it your goal to write a proper RESTful API. That's reasonable. Then the whole thing will probably take longer but what's the rush, right? As long as you learn something.
I know how a RESTful API works, I've already developed a small one (sorry, I should have precised it earlier). I was wondering if there's another type of service that I can use / develop and that would be more appropriate in my situation (but yes, in my case, performance isn't very important as long as it doesn't take too long to load and display all the data) ? Thanks !
As with many other similar approaches, the problem is that it falls down in the details. For example, you install https://github.com/nsf/gocode; now you have that code in your src folder that needs a special .gitignore entry. If you're using something like `go-plus` you'll have a whole suite of files to ignore and re-download every time you start your editor. GOPATH was a solution to too many complicated problems (dependency resolution, binaries, cached object files); the only real way forward is to change how it works. I honestly think the best thing we could do with GOPATH is make it like PATH; ie. rather than: &gt; GOPATH=/home/foo/go You'd have: &gt; GOPATH=/home/foo/go:/home/foo/whatever:. (Notice the trailing '.' to include the current folder) ...but that would break a lot of things. 
Ah. Imagine you have services *Foo* and *Bar*. Foo's API exposes data about cats and it's latest API version is 3, so their endpoints might look like this: `/v3/cats/&lt;ID&gt;`. Similarly, Bar's API is on version 1 and exposes data about locations like this: `/v1/loc/&lt;X&gt;/&lt;Y&gt;/`. Then you could expose the endpoints `/foo/` and `/bar/`. Requests to these endpoints would look like this: `/foo/v3/cats/&lt;ID&gt;` and `/bar/v1/loc/&lt;X&gt;/&lt;Y&gt;/`. You can configure your webserver to simply proxy those requests to the 3rd party APIs by dropping the prefix. Just a thought experiment. No idea whether it's any good. If it is however, you wouldn't even need any application code.
I am not adept with http requests. Will look into it now.
I did say until I was more comfortable with Go, I would continue using Node. But hey, let's have yet another programming language flame war.
Even if it's beyond my current knowledge, that was beautiful written. 
&gt; There is currently no mechanism in place to ensure a node is the original node that generated that UUID. What would be the best way to go about ensuring proper identification among nodes? Public/private keys on both sides.
&gt; You may want to look into how slices allocate when they are appended to. I'll definitely check that out. Thanks.
Can you find a source that supports this?
&gt; an http server with an endpoint that would accept POST Or PUTs to avoid duplicate notifications...
I'll read about it, thanks. I've got a service running at the moment which deals with a lot of string concatenations and have seen a massive advantage using WriteString() rather than String + String. As far as I understand it, both need to perform the resize, copy. The specific metric that went down was "runtime.memmove". Perhaps I am reading into this incorrectly? I'm running go v1.7.3
OK, thanks for that.
I just looked for a fairly recent article I read that indicated that in many cases, string concatenation isn't as slow as it used to be. Unfortunately I cannot find it, so I retract my statement, and apologize for stating something I cannot back up.
Thanks! That helped me track down the issue I was facing. Now onto the next set of things to learn.
I am also a system (and network) engineer and I completely agree. Go is the best candidate to follow up C. It is fast, safe and simple. It really is a dream come true for DevOps/NoOps type of engineers.
Not sure what C has to do with this conversation, but to answer your question, my point was that -- wait for it -- Go doesn't have inheritance and instead relies entirely upon composition, which I consider to be a very good thing.
I get your point. It's nice if you only need one language. Sidenote: + All my backend is in go. + My v8worker performs twice as good as node. + I can pre render react views and cache them in go + go http handling is much faster than node's + I'd rather go for compile time errors than runtime exceptions / lots of testing.. + with good connections I get DOMContentLoaded under 200ms which is nice for a 100kb react app I guess.
How about instead of downvoting /u/tmornini you read [the spec](https://golang.org/ref/spec) and show us where it talks about inheritance or object orientation or classes. We'll wait. And no, the sentence starting with "The declared type does not inherit any methods bound to the existing type" is not it. Go _does not have inheritance._ Everything is about [method sets](https://golang.org/ref/spec#Method_sets); with composition you don't have is-a relationships – more like "does-this" (`io.Writer`), if that makes any sense. Interfaces (i.e. method sets) declare what something can do, not what it is.
Rust is probably the next C. I mean I like Go well enough, and it's absolutely great for e.g. network-facing projects or anything where a GC and a simpler type system won't be in the way. Having a runtime and/or a GC just doesn't work in certain scenarios (e.g. device drivers or operating systems in general). Rust has no runtime and no GC, but it also has no manual memory management as such, it encourages functional patterns (and makes most of them very cheap), it has an interesting and powerful type system, _and_ it makes it easy to interface with C.
yup, webhooks. the question is more about what you'd use as your stack to make this happen. having a http server accepting POST was something from the get-go.
&gt; Go doesn't have inheritance and instead relies entirely upon composition This is the same meaning as the OP's the inheritance by composition means in his context. People didn't downvote you because you were wrong, they did because you're nitpicking.
Also the rust development team really care about their product and their community which certainly can't be said about Go. If Rust weren't so hard to learn I think that it would overtake Go in a couple of years, even for network programming.
AFAIK the improvement comes from this: s := "" for i := 0; i &lt; 10; i ++ { s += strconv.Itoa(i) } First step, "0" is appended to "". A new string with length 1 is allocated, "0" is copied into that one, the string "" is gc'd. Second step, "1" is appended to "0". Length 2 string is allocated, "0" is copied, "1" is copied, "0" is gc'd. Third step, "2" is appended to "01", Length 3 string allocated, "01" copied, "2" copied, "01" gc'd. ... etc. for i := 0; i &lt; 10; i ++ { buf.WriteString(strconv.Itoa(i)) } s := buf.String() bytes.Buffer starts with a capacity of 64 Bytes, i.e. "0" is copied to the buffer, "1" is copied, "2" is copied, etc, etc. When those 64 bytes are full a new slice with 2 * 64 Bytes is allocated (+ the length of the write that triggered the expansion). Everything is copied to the new buffer. After that 2 * 128, 2 * 256, etc. Each string append causes one allocation and creates two strings for the GC. b.WriteString causes exponentially less and less allocations the more you write to one buffer (which could be further optimized if you have an idea about the final size, use b.Grow to set the buffer capacity in that area - might save you a couple alloc's) Hope this makes sense ;)
Don't you think that's unnecessarily harsh? Sure, I think there are several issues with both the language and governance in general, but I don't think it's really fair to say the Go team doesn't care about the product or the community just because the direction they've taken Go is not to your liking. I do agree about Rust, though. I've started learning it on my free time, and it's definitely on the challenging side of the spectrum. It's not quite Haskell, but Scala comes to mind pretty often.
Aren't they building a new operation system to replace Android (or Chrome OS)? I think it's highly possible but not soon.
I don't even program in Rust but judging from what reasonable people say on reddit and on the web in general it does seem like the difficulty level of Rust decrease the popularity alot. Perhaps it is hard to make the language easier and still have the important features still in the language.
**TL;DR:** Type in ¯\\\\\\\_(ツ)\_/¯ for proper formatting Actual reply: For the ¯\_(ツ)_/¯ like you were trying for you need three backslashes, so it should look like this when you type it out ¯\\\_(ツ)_/¯ which will turn out like this ¯\\\_(ツ)\_/¯ The reason for this is that the underscore character (this one \_ ) is used to italicize words just like an asterisk does (this guy \* ). Since the "face" of the emoticon has an underscore on each side it naturally wants to italicize the "face" (this guy (ツ) ). The backslash is reddit's escape character (basically a character used to say that you don't want to use a special character in order to format, but rather you just want it to display). So your first "\\_" is just saying "hey, I don't want to italicize (ツ)" so it keeps the underscore but gets rid of the backslash since it's just an escape character. After this you still want the arm, so you have to add two more backslashes (two, not one, since backslash is an escape character, so you need an escape character for your escape character to display--confusing, I know). Anyways, I guess that's my lesson for the day on reddit formatting lol ***CAUTION: Probably very boring edit as to why you don't need to escape the second underscore, read only if you're super bored or need to fall asleep.*** Edit: The reason you only need an escape character for the first underscore and not the second is because the second underscore (which doesn't have an escape character) doesn't have another underscore with which to italicize. Reddit's formatting works in that you need a special character to indicate how you want to format text, then you put the text you want to format, then you put the character again. For example, you would type \_italicize\_ or \*italicize\* in order to get _italicize_. Since we put an escape character we have \\\_italicize\_ and don't need to escape the second underscore since there's not another non-escaped underscore with which to italicize something in between them. So technically you could have written ¯\\\\\\\_(ツ)\\\_/¯ but you don't need to since there's not a second non-escaped underscore. You ***would*** need to escape the second underscore if you planned on using another underscore in the same line (but not if you used a line break, aka pressed enter twice). If you used an asterisk later though on the same line it would not work with the non-escaped underscore to italicize. To show you this, you can type _italicize* and it should not be italicized.
No? Why would Google throw out all the effort they put into the JVM on Android for very little benefit? 
Sorry, but no. Rust is next something, but definitely not C. And type system, while being interesting, is definitely a problem, because of the complexity. And while some projects may benefit from it, I say safely say right now that systems programming and language complexity do not mix together. More importantly, most of the C developers this days are actually very good at managing memory and handling threading. The tooling also progressed. You may point me at examples like OpenSSL but those software was written long before Rust, Go, Nim or D. It also made to support tons of hardware configurations which LLVM didn't even heard of. The C is also relatively simple to implement for the target hardware. Short story - I believe that Rust will find it target audience when it stops comparing itself with C and C++. 
Java is fining other companies for using JAVA. Moreover, Java has been suing Google for using JAVA in android ,and JAVA said they are going to change those open source to not for the next law suit.
Go is the next C, Rust ~~is~~ may be the next C++
Taking "punting the diamond inheritance problem" to the next level!
https://godoc.org/golang.org/x/mobile/app soon...
I can see that having quite a performance saving if you're dealing with large amounts of string concats. (Which we do)
We have been using https://www.sumologic.com/ from some time and it has been doing okay. Wondering if OK Log is in same space or I am confusing two different solutions?
According to almost all statistics, Go is already orders of magnitude more popular than Rust. If any language is more likely to replace C it's Go, simply because no one is using Rust. 
Rust is significantly and irreducibly more complicated than C. There are good reasons for that, and it gets things for that complexity that are impossible to get without it, but it's hard to see it completely replacing C's niche because of that. Not everyone is a professional programmer, and I've seen professional programmers balk at Rust's complexity too. (We can criticize them for that, but that doesn't change much.) Go, it is true, also does not completely replace C. But Go is mostly much _simpler_ than C (at least to program in), and does the vast bulk of what people use C for, with a 21st century solution. Neither one is, strictly speaking, a "replacement", but between the two of them, the vast majority of what you might want to do in C is covered by the two of them. After all, languages are complicated things. If you get particular enough about your specification for your C replacement, you just end up specifying C again. You do have to grant your replacement at least a little wiggle room if you want to avoid that outcome. 
I need _long-running_ (maybe forever) jobs. That's why I asked this here.
some usage for example btw .. https://github.com/yaronsumel/piper
I'll happily be downvoted to avoid a single person believing Go had inheritance.
If you're not a professional programmer, then you probably shouldn't be writing in C. If you're not a professional programmer and C is your only option, them Go likely doesn't work on the platform you're targeting since it's GC'd (hard to have a GC on a microcontroller). I don't think Go's niche is to replace C, but to be a faster alternative to Python, Node.js, Ruby, etc for threaded applications. That's essentially what we've used it for, and we really appreciate the low learning curve as we tend to train a lot of our programmers.
Show me a microcontroller or OS running Go. The GC alone disqualifies it in many cases, much less the threading. If you can't use goroutines or the GC, Go doesn't make sense.
Thanks for your answer, that's interesting. I'll dig into that.
Where do I get my free bitcoins?
[removed]
[removed]
To this day I still don't understand the "rivarly" between Go and Rust. As far as I'm concerned, they are vastly different and can/should co-exist.
I specifically meant Go's governance
Ah, I misread. I guess we're on the same page then. I do think the Go project is well run, but the are lots of things I'd like to see that the Go team is unlikely to entertain, such as: * Destructors * Genetics * Required field values in interfaces * Adding methods to types that you don't control (you can do this with type aliases) * Default implementations for functions in interfaces (like Rust has with Traits) * Subset of Go without a GC (e.g. for embedded work) I have all of those things in Rust (well, they're still deciding on what to do about fields in Traits), and I feel like the core team is open to well reasoned arguments for inclusion, unlike the Go team, which seems really opinionated (which is good in its own way, but you need balance).
I need to distribute these jobs across different physical machines.
Docker + AWS ECS or Kubernetes is your friend. :-)
We went with socket.io and of course nodejs. At the time, socket.io was nodejs-only. If I started a new project that needed websockets today, I'd definitely pick Go for the back-end, but I'm not sure what the front-end would be. Maybe socket.io, as I believe it's no longer so coupled to a particular backend.
It's pretty simple. Start a bitcoin exchange and then, once it gets popular, claim to be hacked after you transfer all the coins to your own wallet.
&gt; I must be able to read it and "parse" in my head on the fly And Rust is very good at that, but it takes some time to get familiar with it enough to do so. The benefit of Rust, IMO, is that it takes away many of the commonly missed memory errors and frees you to focus on the logic errors. &gt; Rust doesn't protect you from logical mistakes True, which is why it's awesome that it eliminates entire classes of errors and lets you focus on the logic. &gt; As for performance - it depends Exactly. Go's GC was a huger problem at launch (almost prevented us from adopting it because it's imprecise nature cause issues on low memory systems), but it's gotten way better. I expect the same from Rust, that as it matures, so will performance. Just recently someone landed a patch for `sort` that dramatically improves performance (based on TimSort). &gt; Valgrind can catch most of the memory bound errors Only if you hit that code path in your testing, which you should, but you won't necessarily do. I'm still finding problems with Go's race detector in code I haven't touched in over a year, because it's not as commonly hit. Rust prevents nearly *all* classes of memory issues so you don't need tools like Valgrind, which simplifies testing. &gt; unless unsafe part is proven, but that's entirely different subject I think that's exactly the subject. If you have `unsafe` code, that's a red flag for an audit/unit tests, and should be the most well tested part of your code. You still get checks there, so it's at least as good as other languages in `unsafe` blocks. &gt; Rust doesn't protect you from thread starvation True, but that's not a memory error, and you can always use a async library to solve the same problem (like [`mio`](https://github.com/carllerche/mio) for sockets or [`tokio`](https://github.com/tokio-rs/tokio-proto) for other I/O). [In Go, tight loops can block the GC](https://github.com/golang/go/issues/10958), so it's also a problem in Go (but I think it will be fixed in 1.8 since a commit seems to have landed). [Rust also has channels](https://doc.rust-lang.org/std/sync/mpsc/index.html), so you can get similar benefits. They're not as nice as Go's channels (can't use them in a `select`), but they're there. &gt; it starts to slow down (RC is not free) You don't have to use reference counting, it's opt-in with the `Rc` and `Arc` types. By default it essentially works like C++ using scope to determine when to destruct things. If you want smart pointers w/o reference counting, use `Box`, which essentially just allocates on the heap and deallocates when it goes out of scope. In this case, it's better than Go in many regards because: - you can choose the costs you want to pay (copying, `Rc/Arc`, `Box`); I've heard rumors that there are some WIP garbage collectors you can add if that's your cup of tea - no built-in garbage collection means you never stop the world &gt; First version's of Rust were entirely different language True, but the core reasons for its existence never changed: memory safety without compromising performance. Go also had quite a few major design changes since it was introduced, and it spent far less time as a public beta than Rust did (Rust was essentially developed in the open, Go only became public within a year or so of hitting 1.0). I *do* miss green threads, but I also like the direction it's gone since those things can (and are) be developed as libraries efficiently. &gt; Trait system and implicit conversions Examples? Rust has a more strict definition for implicit conversions than most languages, so you won't get the same issues that you'd have in C, C++ or Java for example. I can see this potentially being a problem in crypto, for example, but the memory guarantees really offset that minor issue. YMMV of course. &gt; But I honestly tired of this "Rust is our salvation" spam I'm not saying that at all. I use Rust, Go, Python, C, JavaScript, etc all for different purposes. My argument is that Rust is a more likely shoe-in for the types of problems most people use C for, and Go fits more as a replacement for higher level languages (like Ruby, JavaScript, Python, etc) when performance is needed. &gt; "This would be better it was written in Rust" I would like to see "We saved N amount of money\resources\manpower by writing this piece of our infrastructure in Rust. And here what we learned" I'm sure we'll get that in time, just like we got with Go. It took a year or two for larger companies to switch to Go and blog about it, and I'm sure the same will happen with Rust. Mozilla switching Firefox to Rust will be a fantastic boon to these kind of anecdotes (and they've already landed code in Firefox). So yeah, that'll come in time, and I'm eager to read them. I love Go and I love Rust, and before I push for it in a larger project, I'll need more proof that it scales well. For now, I'm enjoying using it in smaller projects that I hope to ship to actual users.
&gt; almost nobody should be writing in C I didn't say that and I think C is a fine language, it just doesn't scale well (the larger it gets, the more likely bugs are). For microcontrollers and projects with only a few hundred lines of code, I think it's a perfectly reasonable choice. I think we need something safer as a replacement for C, and I think that language is Rust, but like any new technology, it needs to prove itself so it can replace C.
yay for any improvements that can be made regarding immutability. it would be awesome if we had something like `let` which allowed us to say, "this var will be set once and never again", which is something different than a `const`. i would be willing to accept a low performance penalty in order to gain safety here. indeed, programs could become simpler since you don't have to provide the same concurrency protections to variables that can only be read one thing i would like to see: `prepend`...if we have `append`, why not `prepend`? indeed i would like to see built-ins for adding and removing items from both ends of lists. don't see any fundamental reason why this could not happen...think like Perl's `shift`/`unshift`, `push`/`pop`...very useful, even if weirdly named. these are all doable with what's there now, but it seems like it would be a useful place to get some better syntax
How would prepend implement efficiently? People may think it's efficient, like append, when it's really not, if it's built in.
well, does it matter that much? its something people probably need to do a lot, i know i do from time to time. if it is a built-in, at least there is the opportunity to hide the details and try to do some optimization...if i have to directly type out the steps involved using existing syntax, there isn't much in the way of optimization possible, since my intention now spans multiple statements. i would be able to live with documented shortcomings. if i chose to use `prepend` then its on me to deal with the implications. my code would be a lot cleaner and since it is declarative, the Go team would have the opportunity to optimize the implementation
Great to know the core team is very lucid and pragmatic about Go's opportunities to improve and pain points that the community wants gone. &gt; Work outside GOPATH should be supported nearly as well as work inside GOPATH That, package management, along with `go vet` integration on `go build/install` would be a great way to improve Go devs experiences! 2017 has the potential to be the best year for Go development yet. EDIT: wording.
Yes, it is like how chickens come from eggs come from chickens.
And the original chicken was some kind of chickenosaur
you can use a sync.Waitgroup (or sync.ErrGroup) and go routines to fetch those HTTP requests in parallel - it'll speed up your application quite a lot. Also, I think your http client instances don't have a timeout - so they could run forever if you have network problems/problems with DO's API servers.
Thanks for the tips, I'll look at updating the code and see what happens.
Very cool, I met the authors/instructors of the course during [Scaling Bitcoin Montreal](https://scalingbitcoin.org/event/montreal2015). The Bitcoin libraries they use within the course are written in pure-go and can be found at the [btcsuite organization on Github](https://github.com/btcsuite/). 
Isn't that more or an argument to include it than exclude it, though? I think the core Go team is less likely to implement prepend in a way that it becomes accidentally quadratic than every Go user not making that mistake. This is a common way to prepend for new Go users today: foo := []string{"foo"} for _, v := range bar { foo = append(foo, v) } before they (hopefully) learn that `foo` should be created as: foo := `make([]string, 0, len(bar) + 1) (I know I certainly made that mistake when I started using Go, and I've seen other newbies make the same mistake on Slack..)
Is that loop actually quadratic? I thought slides didn't just grow one size at a time.
IIRC it doubles each time. Depending on the size of bar, that's still a lot more than 1 pointless re-allocation/move.
The Go compiler was written in C until Go 1.5. Go 1.5 and above are written in Go. So, yes, it originally used some old version of the Go compiler to compile the new ones.
Any plans to support structured data to allow for more granular querying? I agree with your thoughts on ES but being able AND/OR specific field values is pretty handy.
Go 1.4 was used to compile the Go 1.5 compiler and each new version is compiled with the previous. 
shameless self promo: [here](https://github.com/chewxy/gorgonia/tree/master/examples/logisticregression) is an example logistic regression written with Gorgonia. Best part is you can swap out `float64` for `float32`. It comes with a variety of gradient descent optimization algorithms that work with either float types. Coming soon: Unified Tensor interface, and also GPU computation support will be landing soon.
With my gonum hat on, I must say it's great to see (design) work being expressed. Having a nice linq-like facility would be great for data processing and analysis. The chan T processing à-la MapReduce sounds great too. And I long for a few numerical generics facilities (matrices of float64, float32, ...). Interplay with the multi dimensional slices proposal will be fun, together with reflection (especially StructOf and NamedOf) :) I humbly think that bringing the community on board *during* the process of the research space investigation (blog posts, proposal documents or just GitHub issues) would go a long way for the perception of the Go community wrt generics. 2017 sounds like a great year for the gophers. 
and forgive the naive ignorance, but afaik, `append` will "reserve" some space so new items don't necessarily induce allocation (per item)...couldn't we just reserve some space at the head of a list too? (I understand I could actually implement something like a PrependAwareList but it would be cool to have something built-in) and if not `prepend`....why not `reverse`? then i could just append and append...then reverse the list. `reverse` is pretty simple to implement so it seems like a trivial enhancement and a nice built-in
Thanks for the writeup. I greatly respect productive Rustaceans; They excel in a complex space that I want little to do with. That being said, I hope to learn Rust as a matter of personal refinement. It's an admirable language.
&gt; I really don't remember the last time I've encountered use-after-free or data race error in my cpp apps. YMMV But that's not the only thing it prevents, and misses arguably the most important one: data races. When I first started building a large project in Go (I was lead developer), I made some unfortunate assumptions in Go and I ended up having to throw mutexes in a lot of places for operations that I thought were atomic (map reads/writes). On Go 1.4 and before, Go only used a single execution thread, so we didn't have any bugs, but once Go 1.5 came out, all kinds of threading-relate bugs surfaced. I then realized my error and have been adding mutexes everywhere to make sure things are safe. In Rust, such code would fail to compile. &gt; Rust uses JeMalloc which is neither young nor immature 1. the allocator isn't the only thing that can be optimized 2. Rust [has accepted allowing a custom allocator](https://github.com/rust-lang/rfcs/blob/master/text/1183-swap-out-jemalloc.md) and [it's being worked on](https://github.com/rust-lang/rust/issues/33082) &gt; In critical systems? You wold not only test it, but will prove it be correct. Not everyone works on critical systems, but if you do, it would be far nicer to catch those errors in development so the review goes faster. &gt; There was an article about use after free in Rust There's also an article from someone on the Go core team about [Go not being memory safe](https://research.swtch.com/gorace) and [relatively recently confirmed](http://blog.stalkr.net/2015/04/golang-data-races-to-break-memory-safety.html), so it's likely not fixed (though the Go bug mentioned is hard to trigger). Both compilers have bugs, but I haven't been able to find the one you mentioned, though I'm very interested in reading it (the things I've found are from over a year old). &gt; You are comparing SPSC queues with MPMC. That's not the same thing. Sort of. Go's channels are MPMC, Rust's channels are MPSC, but [there's a library for MPMC channels in Rust](https://github.com/BurntSushi/chan) from someone who is quite big in the Rust community (author of [ripgrep](https://github.com/BurntSushi/ripgrep)), so I'm fairly confident in its quality. So you're right, Go and Rust don't quite do the same thing, but with a library they effectively do. &gt; You can't use object graph with Box Yes, there are limitations. See [this blog post](http://featherweightmusings.blogspot.com/2015/04/graphs-in-rust.html) if you haven't already that gives solutions here. There *has* been talk about having an external GC (used much like `Rc`) to make these types of things easier, but I haven't seen anything concrete yet. There is [this project](https://github.com/Manishearth/rust-gc) and I'm sure others to solve these types of problems. &gt; I need specific examples - games - kernels/drivers - microprocessors (assuming you have compiler support) &gt; It has been almost two years since the release And [here's a list of organizations using Rust in production](https://www.rust-lang.org/en-US/friends.html), among them is Dropbox, so it looks like Rust's market isn't necessarily so different from Go's. &gt; we had better C dialects (I'm not talking about C++) with safe memory model. Didn't get much traction The problem is that nobody wants to switch unless they're sure the thing they're switching to has long term support. Go took off in large part because it's backed by Google, and I expect Rust to take off because it's backed by Mozilla. D, Vala and many others are not backed by a large organization, so people are a bit more hesitant to switch. The good part about Rust is that it's easy to port part of your application to Rust (since you can use Rust as a C library), whereas for Go, that wasn't possible until 1.6 or something like that, and even today, working with C++ is very difficult in Go and hasn't been a huge focus from what I can tell. From [Rust's 2017 roadmap](https://github.com/rust-lang/rfcs/pull/1774), this will hopefully be a focus. Under ["Areas of Exploration"](https://github.com/rust-lang/rfcs/blob/master/text/1774-roadmap-2017.md#integration-with-other-languages): &gt; - Continuing work on bindgen, with focus on seamless C and eventually C++ support. This may involve some FFI-related language extensions (like richer repr). &gt; - Other routes for C/C++ integration. I really hope this gets attention this year as it's one of my biggest complaints about Go. I'm not sure what I'm expecting though. &gt; I don't love languages - they are simply the tools for making things done And I do, but I use the right tool for the job. I wanted to build a game and I really wanted to do so with Rust, but the tools just weren't there for the platforms I wanted to target, so I'm building it in Java (this particular game isn't very CPU/graphics intensive) using a framework that works on all platforms I want to target. I really don't like Java as a language, but it works well as a tool. I opted for writing the server in Rust because I want to make sure I don't have any concurrency-related issues as it would really suck to have to take the game server down for maintenance because of a data race. For smaller web-based projects, I use Go because the library support just isn't there in Rust yet (well, it's there, but not 1.0, though that's a focus for 2017). I expect C/C++ programmers to flock to a variety of different languages, and if I had to give a prediction today, I'd say the main contenders are Rust, Go and Swift.
Russ Cox gave a presentation about the conversion of the Go compiler originally written in C to being written in Go. https://www.youtube.com/watch?v=QIE5nV5fDwA
[It's interesting that people still want to compare Go and Rust](https://dave.cheney.net/2015/07/02/why-go-and-rust-are-not-competitors) when they really aren't all that comparable. 
All pretty exciting stuff. Regarding generics, I've probably said it before, and I'll say it again. I don't want generics because they're the cool modern feature that ticks off checkboxes on the feature list. I want generics (or something like them) because there are too many things that *can't reasonably be put into libraries*, because a library can only deal with third-party types by using interfaces — and interfaces aren't good enough. They add verbosity, they strip away compile-time safety, they hurt performance, and sometimes you can't just up and make your type conform to someone else's interface without adding *more* types. This leads to a situation where too often the answer to "how do I do X?" isn't "here, use this library", it's "here, copy-paste this code". And that ain't good, for so many reasons. It makes Go feel like a language that's hostile to code reuse, and encourages people to write bugs. I don't think that code generation is a panacea either. Yeah, it works, but it comes at a maintainability cost, and I don't think it's a cost worth paying most of the time, especially to do things that *should* be entirely possible without it. So I sincerely hope that the great minds will get together and come up with a way to provide more powerful polymorphism in a way that keeps as many static guarantees as possible, keeps as much runtime performance as possible, makes it easier for code from different packages to play together, and makes Go a better language. In addition to the other cool languages out there, I would be inclined to (*carefully*) plunder good ideas from C++ Concepts. C++ is a bit of a crazy foundation to build on, but if you look beyond that, Concepts looks like a pretty good transfer of the Traits idea to a static language, and Traits are (IMO) inherently better than interfaces.
trace things back far enough and you must eventually find a piece of software handwritten for the specific machine architecture
https://golang.org/pkg/runtime/debug/#SetGCPercent &gt; SetGCPercent sets the garbage collection target percentage: a collection is triggered when the ratio of freshly allocated data to live data remaining after the previous collection reaches this percentage. SetGCPercent returns the previous setting. The initial setting is the value of the GOGC environment variable at startup, or 100 if the variable is not set. **A negative percentage disables garbage collection**. So you would do: debug.SetGCPercent(-1) You can then trigger a garbage collection "manually" with: runtime.GC().
can anything be the "next C"? its one thing to write the tools themselves....another to produce something from them like the Linux kernel, Postgres, etc etc i predict a hugely lucrative market in maintaining C code that the world simply cannot replace as all the kids move on to their Better Languages likewise for Java...thirty years from now it will still be providing Null Pointer Exception job insurance
Scaling is only one aspect of containerization and orchestration. Others are distributing work and managing failover, so Docker and friends seem a nice fit for your needs.
&gt; the Rust people seem to be sticking to their guns with their policy of favoring the community over blessing a single reference standard I get very strong D vibe from Rust, and I get deja-vu that Rust is making same mistakes that killed Ds chances of wider adoption. I was in D software companies for almost 10 years, and in majority cases language choice ultimately failed (all that could be migrated to Go/Java/etc. was, all new projects stopped being done in D). I personally went to Go. Among many reasons D lost were: - community packages, of varying quality, at expense of/instead part of standard lib (in Ds case 2 "standard" libs) - overall growing complexity (lets add this new thing) and breaking changes, with documentation always being inadequate and cost of keeping up-to-date with latest language version too high - community driven design (loudest group steers direction) instead of fewer number of more qualified/experienced people with clean goal and ability to say No to bloat and distractions Bottom line, what suffered the most was productivity and maintenance cost. There are better alternatives. I fear Rust's complexity is growing too much, while lacking in other fields (rich standard lib, IDE, syntax readability etc.) that may justify high cost of mastering language. Memory safety at expense of everything else may just not be worth it. 
Another option is https://play.golang.org 
Hear hear. Why does everything have to be the next version of something else? They both solve different problems in different ways with differing opinions.
It's worth noting that Rust _does_ bless crates, just not by putting them in the literal stdlib. Crates can be uplifted into https://github.com/rust-lang-nursery/ , from where they can go to the rust-lang org (e.g. github.com/rust-lang/regex), though staying in the nursery is also acceptable. For async IO tokio will basically be the "blessed" abstraction to use given that there's buy-in from the core team and community. The optics around this aren't great yet; the community is aware of these crates but there's no easy way to know what crates to use when you start using the language. We're working on improving that. There are currently some proposals to both broaden the scope of this and to make this more explicit. https://github.com/rust-lang/rfcs/pull/1824 is the recent one for crate recommendations, and https://aturon.github.io/blog/2016/07/27/rust-platform/ is an older one that didn't go through (but we are interested in exploring that space again) for having a "Rust platform" set of libraries. So we're hoping to improve here :)
Missed the opportunity to name the project *pantsu*.
I just got hit by this exact problem now. Wow, this is really annoying.
I wrote up something as a learning exercise when I was starting out with Go, having only used languages which choose what you'll pass for you before. This might come in handy: https://gist.github.com/jamesrr39/84b6d6c65c3d16a6aa47
Decent article, clickbait title.
&gt; overall growing complexity (lets add this new thing) and breaking changes, with documentation always being inadequate and cost of keeping up-to-date with latest language version too high Rust devs are constantly dropping "new things" if they bring not much value to the table other than "being a new thing". Rust is pretty conservative in this regard, so no worries here. Rust is heavily propagating [Stability as a Deliverable](https://blog.rust-lang.org/2014/10/30/Stability.html) and despite bringing a new version every 6 weeks i've never encountered any problem that breaks my code. And don't worry about documentation a recently accepted [RFC](https://github.com/rust-lang/rfcs/blob/master/text/1636-document_all_features.md) states that every new feature needs to be documented to land in stable. &gt; community driven design (loudest group steers direction) instead of fewer number of more qualified/experienced people with clean goal and ability to say No to bloat and distractions Just look at the [RFC](https://github.com/rust-lang/rfcs/pulls) section of Rust. Plenty of RFC gets rejected due to lack of value bringing to Rust or Rust being not ready for that Feature yet. There is no "loudest group steers direction" Rust has a clear vision and if one of the "loudest groups" propose something not in line with that vision it get rejected. Rust has a very good overall vision and especially a vision for [2017](https://github.com/aturon/rfcs/blob/roadmap-2017/text/0000-roadmap-2017.md) so there is no such thing as headlessly adding new features that the "loudest group" demands. It is planned to use tools such as [surveys](https://blog.rust-lang.org/2016/06/30/State-of-Rust-Survey-2016.html) on a regular base to find the needs of the (non)community and every body else that is interested. So i see none of your worries applying to Rust.
&gt; In practice, I found Rust painful to the point of near unusability. The learning curve was far worse than I expected; it took me those four days of struggling with inadequate documentation to write 67 lines of wrapper code for the server. &gt; &gt; Even things that should be dirt-simple in Rust, like string concatenation, are unreasonably difficult. The language demands a huge amount of fussy, obscure ritual before you can get anything done. This sounds exactly like what's happened every time I've tried Rust. I really want to like Rust, as I really like the idea of automatic compile-time memory management, but I run into problems every single time. A week or so in I start thinking about how much more productive I am in Go and find myself losing interest. A few months later the cycle repeats. I have a lot of respect for people that are productive in Rust. I really want to use software that's written in it, but I find myself losing interest in writing that software myself. On a side note, why in the world doesn't crates.io host crate documentation itself? It can all be generated by Cargo anyways, so... Not to mention that half the documentation links they do have are broken or, worse, for the wrong version of the crate.
I don't think it's a matter of trying to state which is better, period. I think it's a matter of trying to state which is better for a use case. Both are better at different things, and figuring out which to use *in a given situation* isn't a bad thing at all, I think.
The downside to `runtime.GC()` though is that it does a full, stop-the-world garbage collection immediately, so you have to be careful about how it's used.
Documentation gets hosted (automatically) on http://docs.rs/, fwiw.
Well there is a certain "which better for the job, a hammer or a screwdriver?" aspect, and there actually are a few tasks where you can do a good enough job with either... But most of the time, if you know a little bit about the languages, the choice will be obvious. This of course takes for granted a rational actor, who chooses based on pragmatic reasons. Sometimes you write a program in a language for impractical reasons.
or ponzi.
&gt;Having a nice linq-like facility would be great for data processing and analysis One thing that would really set Go apart is being able to scale up analysis to datasets bigger than memory. Would be really useful and get more buy in from Python and R users.
On registration some token is given back to the node. This can can be used to generate a HMAC-SHA256 signature for the content of all further communication. When a request comes in you get the UUID, and a signature for the content. The server knows the secret used to generate the MAC and can then validate that based on the content of the message and the key for that UUID, the signature is valid. The key here is that each node gets a registration key that can't be shared between nodes.
That's sad "C" is in there multiple times. 
Hey this looks pretty cool! Good job. I wish there were more go related posts though but hopefully that will come with time. I've only done some searching and clicked around so I can't provide very useful feedback but everything looks good already. One thing I saw that I personally am kinda against is the downvoting feature. Learning is good and should always be a positive experience. I am not thrilled with the idea of creating a post about learning some language and getting downvoted maybe because the language isn't popular or something. Just let people upvote and the best ones will still come on top. If you believe downvoting is truly required then you could at least 'unlock' it only for experienced users of the platform. Also searching based on certain 'smart' tags or categories might be useful.
The usual process is to first write a compiler (most of the time a MVP; see LISP which only requires few primitives to implement the REPL) and once you have that you write it again in the language you compile, then compile the compiler to native code and use that to compile your language with itself.
&gt; And even if you did implement 2fa into your site, do you really think you could do a better job than Google, Facebook or Twitter? With the new "U2F" standard, I think it could be at least as good. [U2F](https://en.wikipedia.org/wiki/Universal_2nd_Factor) is super-secure, easy to use, and easier to program than OAuth. The big downside is that it's mostly Chrome-only, with a FireFox plugin.
This is a security concern with the "trusting trust" attack which was popularized by Ken Thompson who is a creator of Go. https://www.schneier.com/blog/archives/2006/01/countering_trus.html I've not seen anyone in the Go community really talk about this as it relates to Go. Has anyone spent any effort addressing this in the Go community? 
I still don't want generics. They aren't orthogonal enough to interfaces, they promote premature abstraction, and every statically typed generics implementation I've ever seen makes code more difficult to read.
&gt; I think the core Go team is less likely to implement prepend in a way that it becomes accidentally quadratic than every Go user not making that mistake. The point wasn't, that prepend might be accidentally quadratic. But that other peoples code will become accidentally quadratic because they assume ammortized constant cost, which just isn't possible to do efficiently. If they have to write it out themselves, they'll at least *see* what is happening. Anecdotally, I was a teaching assistant in an algorithms and datastructures course which used python. Probably 80% of deductions on exercise sheet solutions was due to people using things like `if x in y` in loops, where `y` was a list, without realizing that this is a linear search, thus `O(n)`. This quickly made a `O(n)` algorithm into an `O(n³)` algorithm or worse. &gt; This is a common way to prepend for new Go users today: Exactly. You can clearly see that they are ranging over bar and that this is an `O(n)` operation. A bit more concise (and less clear in this regard) would be `foo = append([]string{foo}, bar...)` - but even there, I'd argue, the `...` is hitting you enough in the face to see that this is `O(n)`. The danger is, that people will assume `prepend(bar, foo)` will have the same cost as `append(bar, foo)`, which just can't happen (I mean… it *could*, but that would mean significant overhead). &gt; before they (hopefully) learn that foo should be created as: In practice, that won't make a whole lot of difference. If it does, the compiler should just get a tiny bit cleverer. FWIW, I don't preallocate for that reason, unless it's very non-obvious what length the result will be. That is not, where the hidden cost lies.
It's not. The concern is not, that `prepend` is going to be quadratic, but that algorithms *using* `prepend` are going to be quadratic, because people assume that `prepend` is O(1) (like `append`).
I can relate. I went into Go thinking I'd hate it, but I _love_ it.
Demand-driven specialization? I guess doing it at runtime would be a little too complicated and un-static for Go, and doing it at compile time based on profiling from previous runs isn't exactly the kind of thing that Go has embraced thus far either, but there's places where eliminating the runtime cost of interfaces would definitely be worth the code size cost. Usually there *aren't* hundreds of types seen by any one function. Usually there are only a few. Often there's only one or two that do most of the work, and then a bunch of rare exceptions. In any case that's looks like an optimization question to me, not a language-design question. You can put features into the language that can compile down to either vtables or specialized code or some mix, and make the user-visible behavior the same. Then the compiler is free to do what's best, and to change its mind about what's best 10 years from now without invalidating any code.
Maybe. Not officially, though. And there is more that just golang.org/x/mobile efforts to do that.
Instead of whining, do something on your own. And I will promote it, so you get your consultancy exposure.
Among my friends who have learned go (but not worked extensively with it), the most common complaint is how redundant the error checking is. Having worked a lot in Python, though, I'd rather check 1000 errors that are always nil than to not realize that one third party library function can throw a particular type of exception and have that blow up my program. There's a lot of comfort for me knowing that if an error occurs, I am either going to be aware of it and have the opportunity to handle it...or I was a dumbass and assigned an error to `_` in which case I deserve everything coming to me, lol. Thankfully, that case is extremely easy to avoid.
It's not necessarily a singleton- if there's a need to provide a different logger to portions of the program, you can swap it out in the fork of the context given to that portion which will swap the logger out for all children. That said, I do see your point. How would you handle something like different components of an app, say, prefixing the log statement with a different string? (I'm a fan of structured logging and often include a field for which component generated the message, a similar problem) Using the standard log package, that would require manually adding the prefix to each log message, creating some set of wrapper functions, or using multiple loggers.
Accept/use interfaces. But be careful, some log packages (like github.com/alexcesaro/log/stdlog) use their custom types in interface definitions which don't really work if any of the packages are using vendor/. So, the most usable interface definitions are the ones which only use native types. If none of the available interfaces suit the use case, just define your own.
I wasn't suggesting using the std log pkg, sorry that wasn't clear. The approach I'm taking at the moment is a single log pkg, which is called on startup with log.Add(log.NewStdErr) and log.Add(MyStatsLogger) - this adds to an internal chain of loggers which will receive log messages. Then those who want to send to the log import log, and call something like log.Log(data map[string]interface{}), which accepts a map of inputs to send to all registered loggers. So a sort of simplistic pub/sub approach - the app sets up subscribers (loggers), and the handlers/middleware publish to the logs. Publishers don't know about subscribers, they just log, and subscribers can filter messages so they might look at keys like level or sender (if you want to tag them with a sending pkg). For tests you can set up a simpler logger which writes to a buffer which you can read before running tests, again using the same pkg. I don't see much advantage to threading what are in the end often global variables/singletons through the context. I've never needed to change the logger for all children. The same thing happens with dependencies like db access - having tried threading various dependencies through a context (both my own and stdlib), I now tend to isolate those dependencies in packages and import them directly where they are used. It's clearer and probably faster too. 
Hey no problem, thanks for the detailed explanation. I'm going to give this a try with my next personal project, it's definitely appealing and would simplify a lot of things. That's a good point re:db access and the like, I've spent quite a bit of time trying to handle that sort of thing through contexts and...well, I'm ready for a different approach. Thanks again!
It's hard to critique your code when I don't really know what you are trying to do. You say: &gt; Currently it's a simple find and replace tool that works in the directory program resides. This is vague. From reading your code and making some guesses, I think you are trying to: &gt; Make a copy of all files with the extension specified by `-e`, prefixed with the string specified by `-m`, replacing all occurrences of the string specified with `-i` with that specified by `-o`. The code you provided does not do this, but it looks like what you intend to do. Often, the hardest part of programming is figuring out what the program needs to do. Only after knowing what to do can you figure out how to do it. I put your code on the [playground](https://play.golang.org/p/tRL1HEPIvH), and use those line numbers for reference. My version is https://play.golang.org/p/ubOL-fk2Wl ## Flag Variables I think the main reason to use flag variants like `flag.StringVar` is when you need to associate the flag with a variable outside of the current scope. In this case, it is better to use `flag.String` because it reduces the number of lines by two and reduces the risk of referencing the wrong variable. Line 21, for example, uses `fileOutputMod` when it should use `textOutput`. I would change lines 13-21 to: fileExtension := flag.String("e", "nullExtension", "Default extension") fileOutputMod := flag.String("m", "nullPrefix", "Default prefix") textInput := flag.String("i", "nulltextInput", "Default input text") textOutput := flag.String("o", "nulltextOutput", "Default output text") While this forces dereferencing to get the values, it reminds me to separate the configuration and actual functionality of the program. Therefore I split `main` after line 38 (where the command line processing ends) into a separate function. Having a second function focuses `main` on the problem of dealing with the user (e.g., parsing and validating input) and the new function on the problem the program is intended to solve. To maintain this separation, I also move the declaration of `dirname` (line 41) to `main` and pass it to the new function. Keeping these separate helps in testing. Changing the variable declarations also results in some compile errors: # command-line-arguments ./findr.go:15: textInput declared and not used ./findr.go:16: textOutput declared and not used In this case those variables are not used or validated. The previous code did not have this compile error because the way the variables were set used them. Since I am trying to improve, but not change the functionality of your code, I comment out these two lines. Also, the descriptions and default values for these flag variables are not helpful. You can check if a string is empty by comparing it to `""`. This avoids magic strings like `"nullExtension"`, and lets you validate what actually matters, e.g., that `fileExtension` is not empty. I don't make any changes related to this, even though it is really annoying, because I am trying to not change the functionality of your code. ## i, Looping Over `fileList` * defined on line 39 * first used on line 60 * weird machinations in lines 68-73 * ends up being (line 75) the length of `fileList` + 1 It seems as if you don't know how to get the length of a slice or how to use range to loop over a slice. * Get the length with `len(fileList)` * Loop over the slice with `for _, eachFile := range fileList` If you actually needed the structure you used for `i` then: * declare the variable as close to its first use as possible, in this case right before line 56 * have a better name * if the name is not sufficient to indicate the use, write a comment * weird machinations should always have a comment describing what they intend to accomplish Keeping these in mind will either simplify the code or justify it's complexity. ## Other Notes * It might be better to not assume that `dirname` is always the current directory. * Line 70 prints the number of files process before the processing takes place. If this output is not needed or can be done after processing, then the loops on lines 57 and 75 can be combined, removing the need (and the allocations for) `fileList`
I'm a mathematician/QA specialist turned developer. I worked with MATLAB when studying applied math and used Python for several years doing machine learning research. You may not be typical but you're definitely not alone! I love go. There are some things it doesn't do well. There are some areas of the ecosystem that are not as developed as I'd like and some areas where it just isn't suited. But almost every time I start thinking about a project that isn't heavy on math, I turn to go. Sometimes I end up rewriting a project in another language, but for most applications? Go is just fine. The simplicity is the biggest feature for me. I like the idea of, say, Rust. I've done some big projects in C++. Hell, even Python is pretty complex once you get past the basics. I've learned, however, that unless that complexity provides a significant benefit because of a particular constraint, I would much rather work with a language that has a low cognitive load. When I'm writing Rust or C++ code, I'm often thinking more about the language and its ins and outs than the application I'm writing. That significantly slows down development and requires more effort. if I'm going to deal with a language spec the size of War and Peace, I *better* be getting a big benefit to my application for that And most of the time, I'm just not. I don't want to have to remember more about constraints imposed by the language than constraints imposed by my problem unless I have to, and I rarely have to. Certainly much less often than many go critics might lead you to believe.
AFAICT it would work, as long as all the log-using packages were also expecting the logger/interface in the GOPATH (not vendoring their own)
Yeah. C has an odd sort of simplicity, somewhat like Python in my experience- it's easy to pick up and write a basic application in, but it takes a lot of work to master the languages. Rust definitely takes a lot of work to master- but that work has to be done up front in many cases. A concurrent application you could whip together the first day or two with Go could require dozens of hours of time with Rust before you get something you can run. I don't think that's inherently a bad thing, especially considering the safety benefits you get in exchange, but it's certainly going to hurt adoption. The fact that there are 20 different solutions in crates for any conceivable problem with no reasonable way to determine the quality or stability of each makes it an unappealing choice for business applications, too. I want to see Rust, or something like it, succeed. But I don't think "success" for Rust is going to look like it being a C killer. Not yet, at least. Too high of a barrier to entry, the main ecosystem of packages being unstable by definition just to get important compiler features...idk. I don't know the answers but I don't think C is in any danger of being replaced soon to any significant degree.
Ah, yeah, that's a good point- thanks. 
For many people, it's more than enough. They're addressing different spaces, and different goals. Rust is a language that you can write an amazingly efficient program, at the expense of programmer effort. Go focuses on being an easy to use language, which can hurt efficiency at execution time, but still outperforms other languages in its space. Rust makes you think about every memory allocation, ownership, lifetimes, borrowing. Go uses scopes and garbage collects when convenient. There are use cases for the anal attention to allocations and such. An app that is currently running in Javascript is almost surely not one of them. You're talking about things that need to run in confined space and confined time, such as device drivers, game engines, simulators, analytics engines. That's a different space from web services, network servers, system daemons. There is overlap when the task at hand has significant memory and processing aspects. A web service that does image processing on high resolution images at high volume, there is a point where your transaction rate suffers because Go isn't managing your memory as efficiently as you could do it by hand. A common message in /r/rust is that if you're deciding on what language to use for a project, and an "easier" language is able to do the job, use the "easier" language. If you can use Javascript or PHP to write your app, you're not doing something that you need Rust for. This is where most Go projects fit in. 
&gt; The section after this one includes a report from practice. 
Everything is passed by value. You (usually) use a pointer for structs. And never a pointer to an interface.
I can totally relate to this. I'm a mathematics-economist, and I really got into programming during university. I mostly coded Haskell, but I also coded a fair deal of Java, JavaScript and C++. Every day at work, I'm coding in Delphi and the language puts up so many artificial barriers for me. When I'm home, I code in Go. It has quickly surpassed Haskell as my favorite language, because I have to think very little about the language and idioms. The idioms feels natural and simple, and I can write code an order of magnitude faster than I ever could in Delphi. If I had a good drag-n-drop Desktop UI tool for Go, I'd be so happy.
In fact, Go doesn't even care if it's a struct at all ;)
&gt; I still don't want generics. They aren't orthogonal enough to interfaces, they promote premature abstraction, and every statically typed generics implementation I've ever seen makes code more difficult to read. Go will evolve whether you like it or not. After all, it was designed for engineers at Google, not for you.
Don't use context.Context to pass shared state, i.e. loggers or database connections Just explicitly pass a Logger interface around (like the go-kit log interface, or log15 does), as it's an explicit dependency of your functions and should be treated as such
&gt; I get very strong D vibe from Rust, and I get deja-vu that Rust is making same mistakes that killed Ds chances of wider adoption. &gt; What killed D momentum when it was created was the same thing that killed most C competitors at the end of the 70s : unclear compiler licensing. You didn't need to pay to implement your own C compiler unlike the competition. Any language that doesn't make its license clearly FOSS is doomed to failure. Rust has another problem. People willing to experiment with new languages because their current language is too slow (Rubyist, Pythonists, PHP, JS devs) don't care about memory management, especially when they never used C or C++. Rust ownership model just isn't going to make them want to use Rust, they just want to write code that executes as fast as possible, not correctness. 
if you want something more complex, i have an in-progress Nintendo DS emulator written in Go: https://github.com/rasky/ndsemu
But you can't deny that this statement is true. Go will always be whatever the "Go team" at google wants it to be. Did Cheney and the people that agreed with him stopped the "alias" effort? no they didn't. Because their opinion don't matter when colleagues from GCloud or Appengine come at a member of the Go team demanding feature X or Z. (and P.B ? f.u.)
Omitting fields can also be done via the json struct tag. Password string `json:"-"`
Go is pass by value, meaning that the value passed to the function is copied. When you pass a pointer to a function, the pointer is copied but it still references the same original value. I worked this up to show you some use cases. Feel free to ask any questions if you have them. https://play.golang.org/p/a-IXqPhNxw
I understand that but the nature of Go (simple, concise language) is very similar to C as compared to C++ (complex, a lot of language features) which resembles more to Rust.
Nice work! I remember writing a GBA compiler many moons ago for kids in school. CHIP-8 was really just a something-I-could-complete-over-Christmas-break-from-work project for myself. But I just kept adding features, and coding up simple games in C8 assembly is very... cathartic. ;-)
You mean like https://github.com/RichardKnop/machinery ?
Well you can check using gccgo, which is a different compiler, backed for gcc, optimised differently etc.
Exactly.
I use a similar approach using the `json.Marshaler` interface: http://choly.ca/post/go-json-marshalling/
Thanks for taking the time to reply. I'm going to re-read your post and digest as best as I can. Given what you've seen and what you know, is there a better design way to implement a find and replace tool? If so, it would certainly help me be more efficient with any future programs I practice writing. When you say length of slice, does that mean how many elements (if that is right word) are in said slice? Line 70 gets the number of files with the specified file extension in current directory. I haven't figured out / done the part to list only files that contain the text or phrase to be searched and replaced. Thanks again!
&gt; Embedded etc: Only x86/x64 are tier 1 platform for Rust Rust uses LLVM so every plattform that is Tier 1 by LLVM is Tier 1 for Rust also.
You could reserve space at the head, but then slices have to keep track of that too. Right now, slices are a pointer, a len and a cap. They would have to become a pointer, a start, a stop, and a cap. It's not just an implementation of prepend, we'd replace the underlying datastructure of slices-as-stacks with slices-as-deques everywhere.
Check the even better https://github.com/rsc/benchstat 
Check the error of rename perhaps ``` err := os.Rename(path, "TEST"); if err != nil { fmt.Println(err) } ```
Totally, I was more speaking to turning GC off. You are right. I do this in many systems as soon as they detect they have zero outstanding user requests.
Note that you can visualize the output of benchcmp with benchviz (http://mindchunk.blogspot.com/2013/05/visualizing-go-benchmarks-with-benchviz.html) 
You could use a fallback type if trying the first one yields an error: type APIResponseFallback struct { Object *APIObject `json:"object"` } But that could cause other difficulties depending on what you're trying to accomplish with the data, and is a bit of an ugly hack.
That would be fine, if I could use those new language constructs when they were useful. Rust feels very complex for the sake of it. Like, why do I *need* to know about lifetimes and get fucked by the type system from day one? IMHO that's a sign of bad design; if a language's new ideas (like Go's channels and goroutines) can be used only when they're needed, and the rest of the language can stand alone, then that means that feature is 1) easy to use, and 2) unobtrusive enough to not fundamentally affect the productivity of the language. Rust seems to foist all of its complicated ideas on you all at once, rather than giving you, e.g. sane defaults for string concatenation and let you screw with the type system later.
Nice thanks, wasn't aware of that one!
an oldie but a goodie
Good point, thanks. 
oops, that should have been an 'http' link, not https. Thank you for pointing it out. The cert is both out of date and for the wrong domain; long story. My Saturday morning plan is to finally get letsencrypt on there, so hopefully it will be https soon.
monorepo
https://golang.org/doc/faq#exceptions
Thanks for the feedback. Yeah really sad that no one is learning go right now. Probably someone from here should create a post. Yes down voting is kind of bad if users are not using it for its intended purpose and you are right downvoting will only be allowed to experience users in the future. Also we are also adding tagging feature soon. Thanks again for the amazing feedback.
govendor with code in vendor directory. 
What's a valid use case for wanting to get a *hopefully* encrypted password out of the database?
Just curious, any sense of how these results compare to other language implementations on the ARM RasPi?
glide, just because "Glide or Govendor should provide a reasonable upgrade path" https://gophers.slack.com/archives/vendor/p1484175713000359
Raspbian offers a very outdated version of gccgo (4.9) and I also can't get 'go test -bench' work with gccgo. But anyway by using the [g711enc]( https://github.com/zaf/g711/blob/master/cmd/g711enc/g711enc.go) command compiled with gccgo and enconding a 64MB sound file we get the following: build with: 'go build -compiler gccgo' $ time ./g711enc alaw long.raw real 0m10.869s user 0m10.090s sys 0m0.670s build with: 'go build -gccgoflags '-march=native -O3' -compiler gccgo' $ time ./g711enc alaw long.raw real 0m3.587s user 0m2.870s sys 0m0.680s The native gc build gives us: $ time ./g711enc alaw long.raw real 0m3.469s user 0m2.720s sys 0m0.700s 
Oh, right. Of course! I'm still getting to grips with interfaces (I'm pretty sure I should be building my libraries around them, but haven't quite figured out how yet), but I really like them. 
See Turing Complete
This is a little tricky. Made trickier by the fact that Golang isn't consistent across its data types. Slices are passed by value, but they seem passed by reference, because the content of the slice isn't passed in that "value" only the "header" is. But then to make it worse, you still need to pass a pointer to a slice, if you plan on appending to the slice, as that modifies the value that was passed, as that change wont' be communicated back up to the caller. But maps have no such issue, and always passing its value (which is also a reference of sorts) is just fine. Interfaces are similar. Passing the value is okay because that value itself won't change, and is small. Then there is pointer and non-pointer receivers. Which has nothing to do with whether your passing pointers of the object to other functions or not, only to its own methods. **Rules** I have a few general rules I follow first, and then wait until later, or until the situation calls for it, before I think to deeply about how to pass any data into a function as an argument. 1. If it could be changed by the callee, and its one of those reference datatypes, then pass the value anyways. 2. If it could be changes by the callee, and its not one of those references types, pass a pointer to it. 3. If its small (a few bytes), pass the value, 4. If its not smal, and its not a reference datatype, pass a pointer to it But #4 has an addendum to it. I tend to choose a single "owner" for any large piece of data. It might a function that owns it, or a another struct that contains it. And that owner will have the data as a "value" and never a "pointer". Then when it passes that data around to other things, it passes a pointer to the data. This means there is no data in the application that is referenced only by pointers. Someone somewhere has the value itself. I.E its on someones stack somewhere, and not in the HEAP. For functions this means it can be tracked up to some function-call high up in the call chain thats long lived. This is less important in Golang with its escape analysis and good GC. But its still a good rule. 
trash - because of how simple it is. Tried glide, govend, govendor and godep - trash just works. And cuts unused stuff from vendor folder. 
After having a quick read, they actually do both. Correct me if I am wrong, but the procedure indicates, compiling Go 1.x with Go 1.4.x, then compiling Go 1.x with the Go 1.x you just compiled. So the relased binary is: Go1.x\_{Go1.x\_{Go1.4.x}} where Go1.a\_{Go1.b} is the Go 1.a compiled using Go1.b.
Is this on ARM64? What RasPi model are you running this on?
I use ginkgo but don't have a solid argument for one over the other. Both are good choices for BDD 
Can someone point me to the select/epoll a ailability in Go?
&gt; Rust ownership model just isn't going to make them want to use Rust I miss having Rust's ownership model when I write code in any other language, including Javascript or Python. Don't discount the value of affine types (e.g. taking `self` by value) in designing a good API.
[removed]
No you don't, otherwise you'd be using Rust and not Javascript nor Python.
I use `godep`
I didn't make the demo. And I prefaced using a password to demo this wasn't the best way to express the idea. I would never do this with a password field. 
MySQL isn't *that* "heavy"
If you are not using interfaces, how do you test your applications?
Yes, this. But you are forgetting the comment where you rail about the injustice of how idiotic the format your partner is providing to you, and how if the son of a bitch how specified it was in the next cube you would fart in his general direction, etc.
`govendor`, it' vendor.json is IMO better than the other tool's files and it has a fairly good shortcut syntax. I can use `+missing` to address only missing packages, `+local` for project only, `+external`, etc. That makes it more versatile than the other tools. glide is also good but I had some problems with nested dependencies that glide doesn't seem to have at all. edit: I mostly use the commands `govendor list +missing`, `govendor fetch +missing`, `govendor sync +external`, `govendor list +unused` but the composability enables everyone to mix and match what they need.
~~You're gonna get a nil error then unless you initialize the variable.~~ ~~I prefer `var xxx = someStruct{}` for that.~~ As pointed out this is not a problem on a direct struct I actually use `var xxx = &amp;someStruct{}`, got that confused.
Your statement is entirely equivalent to the one in the parent. What nil error are you referring to? 
Sorry I was refering to a pointer struct, got that a bit confused. I'll fix that in a sec; I usually don't use `var xxx someStruct` and rather `xxx *someStruct` so I can pass it through validation/authentication after unmarshalling it without having to get the pointer to it all the time.
Sorry, didn't mean it to come out as an attack, I was just curious as to if there were a valid use case or it was merely hypothetical :)
And as a bonus, I guess it will be possible to extend types from other packages or built in types (create new methods on alias).
I'll stand up to be counted here too. Independent consultant and have been writing an increasing amount of Go code for clients.
Isn't that the case with any language with builtin GC ?
I'm stuck in the Modula2 school of variable declarations, so I do them explicitly using the var keyword and type just as soon as a func is declared. And the package globals at the very top. All huddled together to keep nice, snug and social with eachother. They are also given proper names. Same with variables declared in a funcs args and return list. Temporary variables however are strewn all over the place using the := method with implicit type and seldom consist of names longer than one char. Makes it easily readable in my opinion. No need to scour a func to the very end to get an idea of what it does. the first few lines will do. Yup, it takes this data, uses internally these representations, and outputs that. Good. Next.
Hi, noob here. No offence, but why create new MUX when there are multiple existing ones. 
In this case you'd need to define err outside of that scope too and use a normal '=' instead of ':='. In my functions, "err" is often reused so I sometimes declare that explicitly at the top of the function like: var err error
This project was a really good opportunity for me to learn golang. A hobby project. So no special reason. I know that there are many other request multiplexers.
The [new alias proposal](https://github.com/golang/proposal/blob/master/design/18130-type-alias.md) targeted for Go 1.9 does not allow defining methods on aliases of built in types or types from other packages. It says: &gt;Since T1 is just another way to write T2, it does not have its own set of method declarations. Instead, T1’s method set is the same as T2’s. Where T1 is the alias and T2 is the type it aliases.
glide
Thanks for the post and example. Why do you need the lock here? I don't see the race condition.
Context key's type is fixed.
I have changed the HandleFunc method's signature to something like this: muxer.HandleFunc("/login", loginHandler, "GET", "POST") 
Thanks for this. The JSON library defaulting to testing for interface satisfaction is a perfect example of the Open-Closed principle, and this is why that principle exists.
Yeah that's the one shadowing case I've heard of being common. There's nothing really funny going on though - the compiler is just doing exactly what you're telling it to and in many cases the shadowing is an intentional effect. The thing is using long decls here doesn't avoid the bug - not using a long decl here is the bug. You may find it necessary to avoid the bug completely wherever possible, but I think it'd be easier to just add `go vet --shadow` into your toolchain - for example with gometalinter. Using long decls everywhere without knowing what you're doing also leads to the reverse issue - variables not escaping the loop. Why not just learn and pay attention?
There is only a handful of methods. So it makes sense if it's something the compiler can check.
Cool
Beego also included? 
[HERE](https://github.com/golang/go/compare/go1.8rc1...go1.8rc2) are changes since RC1.
Interesting ! But I assume any server that relies on other services, especially something like a database, would not be a good candidate for this ? Because each time the api is called, the connections would need to be initialized again. A relatively time consuming operation. Or do I miss something ?
Checking it - thanks! 
gonna have to check out those extra imports. The code you posted is ridiculously light (which is freaking awesome!). Those imports must be a big help too, right?
I configured my editor to run [goimports](https://godoc.org/golang.org/x/tools/cmd/goimports) on save.
You can use the following steps to avoid this: open Code | Show Reformat File Dialog then check the Optimize imports box in the popup. Now, every time you'll use the builtin formatter of the IDE it will remove the unused imports. You could also run goimports by using the shortcut assigned to it, see Code | Go Tools | goimports file from time to time, it will save the file then run the goimports tool (the IDE will help you install it if it's missing from your system). Hope it helps. Edit: there's also an issue opened on the tracker to make this the default option in the IDE, please vote / star https://youtrack.jetbrains.com/issue/GO-3147 to know when this gets solved. Thank you.
I followed your suggestion and found out Goglang offers Reformat Imports as an option in the push dialog too. Problem solved. Thanks!
Also please know that you should run gofmt on the commit step if you want to ensure that your files are formatted accordingly as currently the internal formatter may have a few differences compared to it. Have fun using the IDE.
Lol, [2017 is the year of the gopher](https://github.com/golang/go/commit/787125abab968ed681106146b68afa2c06b1cd69)
Yes, but if the plugins are distributed independently by third parties... It gets tricky.
That's going to be a tall mountain to climb as there is certainly work being done in both languages to address this issue. It can be done in Python (DB access, Dask) and R (DB access, ffbase) right now. It's not always pretty, but it works, often very well. I am learning Go at the moment as a hobby (potentially some practical uses), and although I am really liking it, I cannot see it making any serious inroads in the data analysis space.
Well they took all the fun out of it.
This is exactly what I need right now. 
Also Glide
Because learning something new is it's own reward. Seriously though, it's not our responsibility to convince you to try something, do the Introduction to Go and convince yourself.
&gt; Well they took all the fun out of it. ░──▓██████▓██▒─▓▓▓▓▓▒▒▓▓▒▒░▒█▒▒█▓▓▒▒░░▒▒▒███ █░─███████▓▓█▒─▓▓▓▓▓▒▒▓▓░▒▓░▓▒▒██▓▒▒▒▒▒▒████ ▒░▒████▓███▓█▒─▓▒▒▓▓▒▒▓▓░▒▓─▓▓▒██▓▒▓▒▒▒█████ ▒▒▓█████▓███▓▒░▓▒▒▓█▒░▓▓░▒▓─▓█▒██▓▒▒▒░██████ ▒▓██████▓████▓▓▓▒▓▓▓▒░▓▓──▓░▓▓▒██▓▒░░▓██████ ▓█████▓█▓▓████▓▓▒▓▓▓▒─█▓──▓░██░▓█▓▒─▒███████ ▓████▓▓▓▓▓████▓▓▒▒▓▓▒─▓▓─▓▓─▓█▒██▓░▒███████▓ ██████▓█▓▓█████▓▓─▒▓▒─▓▒─▓▓─▒▓░██▒▒████████▓ █████████▓▓█████▓▒▒▒▓─▒▒─░▓─▓▓░██▒▓████████▓ ▓▓███████▓▓███▓██▓▓▓▓─▒▒──▓░▓▓░██▓█████████▓ ▓█████████▓▓██▓██▓▒▓█▓██▒─▓▒▓▓░▓████████▓██▓ ▓█████████▓▓█████▓█████████░░▓▒▓███████▓▒██▓ ▒████████████████▓▓──────▒█▓██▓█████████▓▒██ ▓██▓██▓████████▓░──────────▒▓▒▓██████▓▓▓▓▓██ ▓██▓███▓█████▓▒────────────░▒▓██████▓▓▒▓▓▓▓█ ████████▓█▓▒▒░───░───────────▒▓▓█████▓▓▒▓▒▓█ ████████▓▒▒▒░──░▒▓▓░░──░────░░▒▒▓████▓▓▒▓▓██ ████████▒▒▒▒▒░░▓▓▓▓▒░─░░░░░░░░▒▒▒▒███▓▓▓▒███ ████████▒▒▒▓▒▒▒▓█▒▒▒▒▒▓▒▒▒▒▒░░░░░▒▓████▓▓▓██ ████████▓▓▓▓▓▓▓██▒▒▓▓▓█▓▒▓▒▒░░░░░░▒▒▓███████ ████████▓▓█▓▓███▓▒▒█▓▒██▒▓▒▒▒░░░░░░▒▒▓██████ ███████▓▓▓█▓████▓▒▒█▓▓██▓▓▓▒▒░▒░░░░▒▒▓████▓█ ███████▓▓█▓████▓▓▒▒█▓▓███▓▓▒▒▒░░░░░░▒▒▓█████ █████▓█████████▓█▓▒████████▓▓▒░──░░░░▒▓████▓ █████▓█████████▓▓▓▒████████▓▓▓▒░░░░░▒▒▓█████ ████▓▓█████████▒▓▒▓███████▓▓▓▓▓▓░─▒░▒▒██████ ████▓▓█████████▒▒▒▒███████████▓▓▓▒░░▒▒▓█████ ████▓██████████▒▒▒▒██████████████▒─░░░▒█████ ████▓██████████▓▒░▒████████▓▒░███▓─────▓████ ████▓███▓██▓███▓──▒████████▓▒▒█▓██▓░────▓███ ████▓███▓██▓███▒──░█████████▒▓█████▓░░───▓██ ███▓▓█████████▓────▓████▓▓█▓▓███████▒░░░─░▓█ ███▓██████████▒────▓█████▓▓▓████████▓▒░░──░▓ ███▓█████████──────░█████▓█████████▓▓▓▒░░░░▓ ██▓▓████████▓▒▒░────██████████████▓▒▒▓▒░▒▒░▒ ███▓████████▓▓▓▓▒───░█████████████▓▒▒▒▒▒░░░░ █▓▓████████▓▓█▓██────▒███████████▓▓▒▒▒▓▒░░── ██▓▓██████▓▒▒▓█▓▒─────▓██▓█████▓▓▓▓▒▒░▒▒░░░─ ██▓▓▓████▓▒▒░░▓▓░──────▓██▓█▓▓▓▓▓█▓▒▒░░▒░░── ███▓████▓▒▒▒▒▒██▓░──────▓██▓▓▒▓▓▓▓▒▒▒░░▒▒░── ██▓▓▓███▓▒▒▒▓▓▓▓█▓░──────▒▓▓█▓▒▓█▓▒▒░░░▒░─── ██▓▓▓▓▓▓▒▒▒▓▓▒▒─░▓▓───────▒█▓▓▓▓▒▒▒░░─░▒░─── ███▓███▓▒▒▓▓▒▒▒▒──▓▓░░───▒▓▓▒▒▓█▓▒▒▒░──░░─── ██▓▒▓▓▓▓▒▒▓▓▒▒▓▒▒░░▓▓▒░──▓▓▓▒▒▒▒▒▓▓▓▒░─░──── ███▓▓▓▓▓▒▒▓▓▒▒▓▒▒▒▒▒▓▒▒░─░▓▒─░▓▓▓▒▓▓▓──░──── ███▒▓▓▓▓▓▒▓▓▒▒▒▓▒▓▒▒▓▓░░▒▓▓▒▒░▒▒▒▒▒▒▓▒░───── ▓▓█▓▓▓▓██▓▓▓▒▒▒▒▒▒▓▒▓▓▒░▒▒▒▒▒▓▓▒▒▒▒▒░─────── ███▓▓▓█▓▓▓▓▓▒▒▒▒▒▒▒▒▓▓▓▒▒▓▒░▒▓██▓▒▓▓░─────── ███▒▓▓▓█▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▒▓▓█▓▓▒────────── ███▒▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▓▓▓▓▒▒──────────── ████▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░────────── ████▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░░░░▒─░░──────── ████▒▒▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒░░░▒▒░░─░░░░──────── ████▓▒▓▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒░░▒▒▒░░░─░░───────── █████▒▒▓▒▒▓▓▓▓▓▒▒▒▒▓▒▒▒▒░░░░▒▒▒▒░░░───────── ████▓▒▓▓▓▓▓▓▓▓▓▓▓▓▒▓▒▒▒▒▒▒░░▒▒▒▒░░░───────── ████▓▒▓▓▓▓▓▓▒▓▓▓▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒░░─░───────── ████▓▓▓▓▓▓▒▒▒▒▓▓▓▓▓▓▒▒▓▒▒▒▒▒▒▒░─░░░───────── ████▓▓▓▓▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒░░░░░▒░───────── **Good!**
So will Gogland, as described above. Please follow the instructions and the magic will happen. If you have any issues, please let me know. Thanks. 
One could say because it's an easy to learn, fast, static typed, compiled language, that feels like a dynamic one and has an awesome community but Go might not be the answer to your problems sometimes. So, like others said, it's better if you can explain more about what would you be looking to solve after learning Go rather having a very generic question like the current one.
This is exactly what I will need when my team find out I'm unilaterally switching our stack to ago from python. 
[removed]
because you know you want to be hipster 
Can anyone explain what Kafka is? I keep finding results for Franz Kafka, which probably isn't it
It's a distributed messaging system implemented as a persistent, append only log. But more importantly it is a very useful building block for several scenarios in messaging and queue processing.
Excellent job, Iris web framework is also compatible with this!
Hey all, author here. Happy to take any feedback, in particular "I tried and it didn't work out of the box" stories. I will *not* tell you to RTFM.
...and sometimes automagically removes imports that you need. Had that exact issue last week with os/user. It's rare but occasionally happens. Solved by aliasing the import. Whilst it's a great tool to have available, and one that I'd recommend to everyone, it still pays to keep an eye on what it's doing.
Personally I would love to see `must(..., [func(error) error])` or the likes of it in 1.9 or later.
I'd rather see a `must` keyword. I also think it considerably complexifies the code (someone could miss the `#`)
It's actually less. Writes work the same, because in both ZK and Raft writes go through a single leader which are replicated to the rest. In Jocko, for reads the state is replicated to each broker so they just look up local state whereas in Kafka they have to hit ZK. There theoretically might be a higher initial cost, but in the real world whenever the state changes in ZK, the brokers are told to look up the change anyway, and then on-going they hit ZK after different events to check the state. Whereas in Jocko that data is already local.
Not really, the imports are only helpers for certain things like colouring console output or expanding a path, etc.
True about CI, I never start Kafka/ZK in my tests, I generally use a mock broker. I agree it would be better not needing ZK, I just think it's not the thing that will make people switch over :) Anyway, good luck !
 Great article on why https://hackernoon.com/why-go-ef8850dc5f3c#.gqw0x9wft https://changelog.com/gotime - podcast on go https://gobyexample.com - let's you run examples Wiki https://en.m.wikipedia.org/wiki/Go_(programming_language) https://www.jetbrains.com/go/ - ide for go 
Hey all, I needed USB access from Go for a crypto wallet and had a hard time finding a good enough solution. Most were abandoned attempts and the only one looking promising enough was `gousb` from Kyle Lemons, alas that project also seems unmaintained (had open PRs for multiple years) and depended on the preinstallation of libusb before you could build it. Lacking a better alternative, I've forked `gousb` into my own repo and started to patch it up a bit. A few missing features and bugfixes that have been pending on the upstream repo have been merged in; as well as the main feature being that `libusb` was vendored into the Go package, making it fully stand alone and go gettable. This way you can do USB communication from your Go projects without requiring any external libraries. It works well on Linux, seems to work well on macOS too, Windows and Android build fine, though I haven't tested much. Figured I put this out here in case anyone is looking for something like it. Feedback, contributions, etc are welcome :) If Kyle decides to pick up support for the upstream repo, my changes are free to merge upstream too, though I don't see that happening anytime soon based on the PR list there. Cheers, Peter
That's pretty much my main gripe with the Go community right now. Everybody's writing great tools for various purposes but non-Gophers have a lot of trouble using them because most instructions just say "Yeah, simply do a `go get ...` and that's it!" ... well, not everyone has a Go environment set up! And almost nobody releases binaries either. Sorry for the self-plug but it's not that hard to include a [Dockerfile](https://github.com/dAnjou/goup/blob/master/Dockerfile) and a [Makefile](https://github.com/dAnjou/goup/blob/master/Makefile) to make it easy for others.
yup. Gopath is the main pain point for new adopters IMHO
&gt; someone could miss the \# That would be a syntax error. I like the proposal: I've got some code (like saving the output of an http request to a zip file) that consists of mostly error checking, but most of my code almost doesn't contain error returns that can be passed on so easily, so it wouldn't benefit me much, I guess.
Are you saying it's easier to have docker installed, cloning the repository and then running docker build than setting GOPATH having go installed and running go get ? because it sure isn't to me 
Not necessarily easier but it's simply much more likely that Docker is *already* installed. Of course it would be ideal if authors provided binaries to avoid this issue altogether.
I know where you're coming from and in another context I'd agree with you. The point however is that the tools I'm talking about are often not necessarily for programmers but for example for network admins. Those people might have a little programming experience but not necessarily in Go, and why should they care what language a tool is written in? As another example, I'm totally fine with using GitLab and Piwik even though I have almost no experience with Ruby or PHP. Same for my little file server which is written in Go, I want non-Gophers and even non-programmers to be able to use it easily.
I just stumbled over [Serf](https://www.serf.io/intro/index.html) and remembered this Reddit thread. Could this be what you are looking for? From the intro page: &gt;Serf is a tool for cluster membership, failure detection, and orchestration Sounds like this would meet at least some part of your needs - distribution, healthcheck, and controlling job lifetime. The only thing missing is a persistence layer. 
I think you should change you domain, because .xyz is block for spam at some organizations.
Could be fine if the solution append the stack in the same times.
Re: must operator In my opinion, reducing a handful of lines of code is not worth introducing the incongruity of an operator which can can return an altered amount of values. Re: must builtin This sort of minimization can obviously be performed without changing the language (https://play.golang.org/p/F-ZZySWZ5P). v1, v2, err := valsNoErr() v3, errx := valNoErr() must("valsNE and valNE must", err, errx) useful(v1, v2, v3) must("jE must", justErr()) useful("should have bombed already") vs v1, v2 := must(valsNoErr(), "valsNE must") v3 := must(valNoErr(), "valNE must") useful(v1, v2, v3) must(justErr(), "jE must") useful("should have bombed already") In my opinion, reducing a handful of lines of code is not worth introducing the incongruity of a function which can return a varying amount of values.
Do you have any numbers that could back this up? E.g. number of lines eliminated in the real world code thanks to the must operator. I don't think handling errors by panic is any useful in real code, it just looks nice in phony snippets.
I wish I could upvote this 100 times.
Read this https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying It's a really nice introduction to the concepts of what Kafka is used for - the author is/was one of the original developers of Kafka. 
Actually I believe the intent of `must(...)` would've been to return the error much like what `if err != nil {return nil, err}` does now, hence why it would have to be keyword with its own logic rather then a simple method (which honestly anyone themselves could make using reflect and panic())
Tiobe change their methods from time to time and that does affect the rankings. In this case I suspect they changed their set of search terms to more accurately capture Go related posts.
This is absolutely true. I have my reservations about Go, but it felt comfortable in no time flat.
Im teaching myself Go right now and just wanted to say code wise it looks solid. Though i have a question on what this "topics map[string][]chan []byte" means? Is it a map of channels where the channels are of byte array type? 
not anymore after 1.8
"This project proposes an alternative to github's trending page, by exposing projects with high contribution rate, instead of daily stars (similarly to github's pulse page). The krihelimeter of each repository is calculated using the number of authors, commits, pull requests, and issues of that project, from the past week. Krihelimeter = 20 * authors 8 * merged and proposed pull requests 8 * new and closed issues 1 * commits ...." http://www.krihelinator.xyz/about 
It is a map that lets you define a topic(by string) that points to a slice of channels of []byte. Basically one channel per subscriber per topic and the data sent is in a generic []byte form. I hope that clears it up a bit instead of muddling further lol.
Aahh sweet that makes sense.
This really covers projects which need a lot of work. Sometimes that may be a good indication against bitrot. But this metric entirely missed out on projects which are simply finished and working as intended. They have no use for active contributions, yet can still be hugely useful.
the recursive approach will eat memory here...the parent still has instructions to complete so it must be available when the children terminate my advice is to not index all the files. just find the ones you actually want. and look for a non-recursive solution 
I love the idea of must(f(x), "additional error") since I find error handling in go to be a repetitive PIMA, however I understand that it would be pretty "anti-go". Hiding an implicit function return in a built in is pretty cryptic and hurts readability... i would 100% take it over what we have now though. 
I have a couple of questions that might be good to ask here. Why do nodes elect new "leaders"? Is it when one starts to get too bogged down that the network tries to shift the load? It seems like all nodes can "find" all other nodes easily (just connect to them) if you just mention what IP's they are on so I don't quite get this process of discovery. What else is going on? Is this like an nmap for new nodes without configuring their addresses?
I was so confused. Thought it said gosub.
Hmm, could you explain what the failure state would be?
&gt; Go doesn’t allow dynamic linking, this forces Go libraries to be open-source. Is that correct ?
I'm pretty sure it isn't. I would assume you could put non OS libs in pkg and it would work just fine. Although I haven't tried it so don't take my word for it.
Was just about to go to sleep, but googling buffer reuse crypto would give some material I'm sure. In short it boils down to this, what's better in a security context in your opinion: 1) me explaining the infinite ways that a reused buffer which was not zerod out may leak? 2) us both immediately agreeing that when you allocate directly before, and zero directly after this particular buffers usage is correct? In security assume future you screwed up something current you got right. Relying on as few things current you does to prove a thing correct future proofs you, from you bro. Leave me alone I'm tired, it made sense when I said it. Still does. Happy coding friend!
certbot is your friend :)
Visual Studio code has a go plugin which does this automatically. Edit: It has only one plugin for Go, which does this too.
To aid mobile users, I'll link small subreddits not yet linked in the comments /r/rust: Anything related to the Rust programming language: an open-source systems language from Mozilla, emphasizing safety, concurrency, and speed. --- ^I ^am ^a ^bot ^| [^Mail ^BotOwner](http://reddit.com/message/compose/?to=DarkMio&amp;subject=SmallSubBot%20Report) ^| ^To ^aid ^mobile ^users, ^I'll ^link ^small ^subreddits ^not ^yet ^linked ^in ^the ^comments ^| ^[Code](https://github.com/DarkMio/Massdrop-Reddit-Bot) ^| [^Ban](https://www.reddit.com/message/compose/?to=SmallSubBot&amp;subject=SmallSubBot%20Report&amp;message=ban%20/r/Subreddit) ^- [^Help](https://www.reddit.com/r/MassdropBot/wiki/index#wiki_banning_a_bot)
This just does a panic, that's not what the proposal is about
This is a good point. It also doesn't factor in the size of the codebase. I would expect kubernetes to be up there because of its huge codebase. Stars give an indication of interest, which could be for a massive project or a really useful, tiny command line tool. EDIT: I'm not claiming stars are better but it's not as simple as looking at the numbers. There is something qualitative to the stars.
First I would like to say that on CPU intensive operations Rust will always win, even on parallel case, because of - lack of GC - better type system - LLVM backend Having sad that, I found several "performance" wise errors in Go which didn't present in Rust version. For instance - the last example creates 8*256 goroutines that are contending with each other, while Rust version contains thread pool, so there is only 8 at the time. Another example would be passing array by pointer and not directly copying it, thus lowering pressure on GC. Personally, I don't like this kind of articles because you are left to guess, which parts of code are "eating the CPU". It would be easier to argue about article correctness if we had some profiler data for both versions, but alas. EDIT: lack of tests also doesn't make it easier. 
I don't think I've ever seen a reasonably sized java project that didn't consist of mile long class hierarchies, massive try-catch blocks, and code nested so deep the indentation was thicker than my neck.
&gt; SUMMARY: gorm needs improvement not bashing without any evidence! r/golang is a small subset of the "go community", I wouldn't pay attention too much on what is said here. You don't have to feel compelled to listen whatever is said here, me included. This sub community is heavily biased against anything that isn't in the standard library, ORM and "frameworks" (like a basic http router is a Framework ...). Plenty of people like gorm and find it useful. Is there room for improvement ? always, but don't waste your time listening to people here. They represent nothing but themselves. If people really wanted to contribute they would open an issue on github instead of trying to shame your project publicly. 
Makefiles are pretty great if they are simple. And the latter part is obviously the developer's responsibility.
&gt; If you want to compile something in go it's probably better to setup the development environment **properly**. Who defines "properly"? For me it works pretty great to have Go in a Docker container and compile in there. &gt; I think more library projects should be encouraged to ship some **simple** binaries to enable users to test it and wet their toes before installing go for their project. "Simple binaries"? Is there any other kind?
Your car analogy is flawed. Of course I have to know the traffic rules and how to handle the car itself. But I don't have to know how to assemble a car or how to build an engine. Have a look at [Caddy](https://caddyserver.com/), a popular webserver. Next to developers they are even targeting designers and bloggers. Of course they should know about HTTP. But why should they care that Caddy is written in Go? The Caddy website doesn't even mention that itself. &gt; [...] so why would we strive to make go packages work for the uninformed? You said that in a comment earlier and it's really that mindset that **I** frown upon. The things I'm talking about are **not** *Go* packages. They are everyday tools for people who might or might not be programmers.
The NTP article was written solely by Eric S Raymond, as far as I know, not "the NTP guys", and he spent a lot of time complaining about how hard it was to concatenate strings in Rust (which is not hard) and how the language had *too many libraries* in its ecosystem (really?), whereas he wanted to avoid research and rely on other people to make decisions for him through the standard library. I wouldn't consider those NTP articles to be very worthwhile. Go has its advantages, but I would recommend people go to more properly researched articles with a balanced opinion driving them to learn about what actually makes Go great for them.
People who click bait are the lowest of the low on the internet.
Isn't the whole point of Go that it schedules the goroutines onto a thread pool for you?
It defaults to ~/go
I don't think using make ever made anyone's life easier. Anyway, the only reason make would be "easier" than using the go tool is that it is installed by default on linux, whereas someone would have to install go manually. But it's not hard, and on Windows, you don't get make anyway.
[removed]
&gt; Isn't the whole point of Go that it schedules the goroutines onto a thread pool for you? ... and it does exactly that... but when you start N goroutines that are all CPU-bound and N is some significant number more than the number of CPUs you actually have, they're going to spend a lot of time fighting for resources. I wouldn't be surprised if that overhead counts for a large amount of the time the program takes to run because they not only have to fight with each other, they also have to fight over contention and the Go runtime/scheduler overhead as well as the OS' scheduler, etc, etc. An easy way to test is to set `GOMAXPROCS=1`.
&gt;I have never heard of projects providing two different kinds of binaries for testing and production. Any examples? I'm not talking about providing two binaries per se, rather that most project will trend towards one of these options. As you mentioned, Caddy has sane defaults and you can pretty much drop and run it for testing purposes without having to think about configuration. On the other hand, something like Camlistore which generates a default config and creates folders in your home directory when first run or mysql which sets up administrative accounts during setup and basically starts with the production ready settings sans application/user accounts. Neither is bad, but I prefer the Caddy style, adding that at worst changes should be confined in the current directory unless specified otherwise.
&gt; Database support &gt; ql Killer feature for me :) 
So, I updated the post with new images from the updated version of this. I made this post so there is a "separate thread" about this in this post. http://imgur.com/4Am1iX1 http://imgur.com/FaE7DY0 http://imgur.com/qtXVgNE Let me know your thoughts. Nothing is set in stone yet, and can always go back the the first version, although I like this upgrade as then the gopher looks nice without the phone. Thanks!
This is standard way of Java business application. I work on java application where 700 line code provides equivalent functionality of say one `struct` with six fields and may be 4-5 methods in total 100 lines of code in Go.
Or you could just use a better ORM and call it a day.
That sounds like a great use as well. Configurable/extensible middleware too.
I suggest to also look at: https://github.com/upper/db
Take your pick: https://github.com/avelino/awesome-go Here's some benches of the most popular ones including the one I use (SQLBoiler): https://github.com/vattle/sqlboiler#benchmarks
This doesn't look correct. 0 B/op and 0 allocs/op indicate to me that the compiler is optimizing away any work that might be done. I changed the code to used a 4kb byte array instead and got 42400 MB/s, which is nonsensical. It looks like gotest just multiplies whatever number you give it in `b.SetBytes()` by the execution speed without doing any measurement of its own. EDIT: I still don't think the bitrate is accurate, but I started to think that maybe the array was being passed by reference. I put together another benchmark that writes to an array from inside the goroutine reading from the channel to verify that data was flowing. gotest still reported 0 B/op and 0 allocs/op, so I guess this can't be used as proof that the compiler is optimizing away all of the work. Gist [here](https://gist.github.com/quells/3d9fcf5d5a81e94dd7d2e909ff75e91f)
I use `tig`, which can do the same, but how would I check out the stage? Stashing unstaged changes isn't good enough, because untracked files aren't stashed.
Very interesting post, I'll save that for future reference in projects.
If they are everyday tools, give people binaries. If they are go source, go get it. You do a disservice to "designers" by assuming they cannot overcome the great difficulty that is using a GOPATH. When you dumb people down, they are dumber. When you teach them to use their tooling effectively, they will amaze you.
You may add them to fake commit, and then checkout previous commit.
"Fake commit"? How do I make a fake commit with stuff staged that I _don't_ want to commit?
Easily with git on localhost and "gitk" . Some-times I do two-three alternative branches + control points in a past. But if you should work inside a console, it will be not as convenient. Though, probably I'm not familiar with tig.
Yes, it is. It is about an operator or builtin which has varying amounts of return values, combines multiple control flow operators with a relational operator, has limited/predefined values, and can behave one of two ways implicitly (one of which includes calling panic). For returns, this fits only some cases which don't carry the weight of the addition. For panics, the verbosity can already be minimized, and that is what I addressed.
One of the curses of Makefiles is that they're very project-specific. `go get`, `go test`, etc is the same for all things.
&gt; If they are everyday tools, give people binaries. That's what I'm complaining about! Almost nobody does that ... &gt; You do a disservice to "designers" by assuming they cannot overcome the great difficulty that is using a GOPATH. &gt; When you dumb people down, they are dumber. When you teach them to use their tooling effectively, they will amaze you. May I ask what OS you're using? It sounds like you're running an LFS ... because it's really not that difficult to compile your own kernel! Sorry for the sarcasm but I really don't know how to react to someone telling me people should know how to make a tool when they just want to use it. How far does this go, where do you draw the line? PS: [*How to Make a $1500 Sandwich in Only 6 Months*](https://www.youtube.com/watch?v=URvWSsAgtJE)
The key is to solve one of your own problems. Make it small and something that you can get a quick solution that works but that you can keep adding to for as long as it keeps your interest. That way whenever you get bored of it you at least have something useful. 
An either type does not need generics. It can be special cased. That said, returning multiple values does not have a type either...
Sorry, I guess I was exaggerating. But while makefiles are fine for toy projects, my experience is that makefiles in any big project will be a gigantic tangled nightmare, and that it is inferior to pretty much every other build system in existence.
Ubuntu and a little bit of Windows. Using a GOPATH is nowhere near as complicated or involved as rolling your own LFS. Do not equate the two. Refrain from trying to "psychoanalize" me from a couple of comments on a website. You do not know me, and this exercise is far from the best use of your time. Edits: added then removed word. Also spelling. Oy vey.
&gt; But while makefiles are fine for toy projects, my experience is that makefiles in any big project will be a gigantic tangled nightmare, and that it is inferior to pretty much every other build system in existence. Yes. That's something I would tend to agree with although I'd replace *toy* with *small*.
Interesting article. A friend of mine started off with that graphql-go/graphql library, but eventually ended up switching to neelance's library instead as it was more complete (his words, not mine). However, he did find that neelance's library lacked documentation a bit, they just have the one massive starwars example and leave you to mostly figure it out from there. Edit: link to neelance's library https://github.com/neelance/graphql-go
You can already sorta do your negative example already with variadic function options. So if kind of a mute point. That being said I don't like must() it is ugly and smells bad. Edit1: Err NM, read the code not your comments. Carry on. Edit2: NM the NM. My original post makes sense I think. Having a hard time grokking your message for some reason
You do not really need multiple versions of go, unless you are doing some strange stuff with unsafe or cgo that you are not willing to update. But at this point, you have a not-very-remote idea as to why you are doing what you are doing regarding maintaining different versions. If you do not know what is going on entirely, I will be glad to inform you that (as far as I have experienced) you can just install the latest stable version of go and run with it (I use unsafe and cgo, mind you). And I keep my computers cleaner than many things IRL. If you are gonna go get sources, you MUST know what you are doing. If you do not care for sources, or are not willing to understand a GOPATH, then do not go get sources. Find a way to obtain a binary if a GOPATH is too complex for you. Many windows devs will look to pre-made installers for some libraries that may take quite a bit of effort to get going from scratch (Qt, for example). The same applies here. Dumbing down go get is not a solution to any problem, because go get is for DEVELOPERS to leverage for DEVELOPMENT.
May be some folders are required but all extra folders seems over organization. 
I'm glad you were able to notice this. The point was to be able to know what happens where, this way moving things around will be easy.
Brad Fitzpatrick made important point about package granularity which has to with single concept rather than number of files. e.g. `net/http` with dozen of files is a package and `flag` with just 1 code file is also a package.
&gt; [...] executable binary files for most popular operating systems are freely available in release page. Thank you!
With respect to this, he might be right. I consider packages as a way to group similar functionality. The number of files doesn't dictate anything, just a mere breakdown of logical units!
Right. Think from perspective of package users. if some new packages you are creating are just for organization purpose and not package consumer concern then they can be organized under `internal` 
Was I unintelligently arguing with you about being in agreement? If so, I apologize.
Missunderstanings happen. [Also ... :D](http://i.imgur.com/7M4n8o0.jpg)
Flag `--eta` should be simple. 1. It reads all jobs at once. This needs more memory to store before sending them to command channel. 2. and estimate left time by statistics of average running time of finished jobs in real time. Am I right?
Feel free to contribute :)
Here is one I got stuck on. Read R's rdata files into Go. That would enable a much better bridge between the statistics of R and the scalability of Go.
Also any write that waits until 50%+1 of the cluster has returned will have a higher chance of having issues without a cap on the number of members that are involved in concensus work.
yes.. as title said, it's a lightweight GNU parallel like tool in Go. I wrote it for learning and added some features, mainly custom replacement strings. I mainly use it in my Bioinformatics pipeline.
&gt;This is a bug I see frequently in Go. If you don't see the bug immediately, here is a playground link. &gt;Rust will protect you at compile time from this mistake; attempting to compile the equivalent rust code yields the compile time error: &gt;error[E0373]: closure may outlive the current function, but it borrows `i`, which is owned by the current function &gt;This is a result of Rust's ownership system which is covered [here](ttps://doc.rust-lang.org/nomicon/ownership.html) in detail. The costs and benefits of the ownership system could be a book so I will leave that out of this post except to say: Rust’s protection from this has a cost. I think that this bug is actually horribly dangerous, and I'm surprised that the compiler allows it. It actually get's worse. Take this, for example: package main import "fmt" func main() { var intArray []int for i := 0; i &lt; 1000; i++ { intArray = append(intArray, i) fmt.Printf("i= %d\n", i) } fmt.Println(intArray) } Simple code. Adds all numbers from 1 to 1000 into a 1000 element array. Now, I don't need it in order, so I can put the middle loop into a go routine, right? Like this, right? package main import ( "fmt" "sync" ) func main() { var wg sync.WaitGroup var intArray []int for i := 0; i &lt; 1000; i++ { wg.Add(1) go func(i int) { intArray = append(intArray, i) fmt.Printf("i= %d\n", i) wg.Done() }(i) } wg.Wait() fmt.Println(len(intArray)) } Bam. A Heisenbug. It will work on play.golang, but not on my computer. I get size 700 arrays. Why? Because append isn't atomic. I'm surprised golang lets you shoot yourself in the foot like that.
Interesting suggestion. Thanks
Goroutines are not threads. The context switch might be smaller
Hey man, it is quite simple actually. There's simply no guarantees as to the order of execution when you fire off goroutines. In your case you might have found the second function to be the one that got started first, but executing the code over and over again might lead the first function to get executed as well (especially on different platforms etc). Non-determinism man, it's a bitch. If you do want the first function to execute first though you could use sync to ensure the order, or use a separate channel for each async function and send them work in order, one at a time. 
Good idea. I tried building something like this (without the "magic" `GOPATH`, very good idea) a [couple months ago](https://gist.github.com/disq/b4a4c4e39ee6dc97197a6e7128d67c39) mainly to simplify TechOps deployment scripts, to able to manage updated dependencies or build order/flags/instricacies by the developers who -in ideal cases- don't have sudo on production. Simplifying Capistrano/deployment scripts was the primary goal. But the standard Go tools have so much different uses/options/variations that every project tends to be a little different. Writing a makefile to fit all didn't really work for our case. It was slowly becoming Capistrano-script-in-a-Makefile so I kind of gave up on it.
Learn a language that fits you the most. Because you dont want a job just because of the coins. Do it because you're also enjoying it. 1-2 years in a job you hate will take it's toll on you. 
I wondered about that too, and I think it might be a consequence of how the compiler works. Try this: Create a "hello" package that exports a single function Hello that returns the string "Hello". Now write a program that imports that package, prints the result of "Hello()" and exits. This will compile and run fine, but there's nothing you can do to compile the hello package, remove the sources, and still have the main program compile and run. That is, if you write a library and don't want to share the source code, you have to also compile all your library's user's programs for them.
What do you like? Do u like Go too? Do you also like other language?
aliens
I love Go, I like Kotlin, Java, Python, PHP and Delphi.
so are u learning python ,java ,and go at the same time and use it? 
&gt; if only because Rust's libraries are immature. This is ultimately most of what swayed the language decision. It wasn't even that libraries didn't exist, it's that some core things (non blocking io) were handled y multiple third party options, rather than having a mature and reliable official solution. The up-and-coming one had only just had its initial release, and wasn't obvious that it was more than Yet Another Library compared to the others. When you're writing software in the space of netsec, having to guess which library will still be around in a decade and won't break your code in that time is a pretty big deal. I've said this a few times, but Rust I think sits in an interesting niche of the programming space. If you need Rust for a project, it should be prety obvious that you need Rust. If you don't need Rust, you should probably use something else. Now, a lot of people will still use Rust, because we all love our favorite languages and don't always make the most rational decisions, or maybe we're just not all language aficionados who learn every language to make the most practical choice every time. When all you have is a hammer, everything starts to look like a nail. Both languages were largely designed to be able to replace C++. They chose very different definitions of that statement, though. 
Indeed, but in the article you linked it states the Wheeler's trick. You only need two different compilers. Though the bit for bit output of each compiling the same compiler source is different, they are functionally the same. Thus compiling the source with each of the output should be bit for bit identical. So why would that be any different here?
It's a toss-up. Go might be fad; though it's not the kind of fad to last 6 months and fade away. There's plenty of software being written in Go right now, and plenty of companies who've staked a significant portion of their platform on it. Maybe in 5 years no one will want to use Go anymore, but it will take a lot longer than that to be rid of the legacy software written in it. It's impossible to predict what languages will be popular that far in the future, so I recommend not picking a single language, but always be ready to jump ship when necessary. So the disadvantage of Go is a lack of supply: there just aren't that many companies using it. But the advantage is a lack of expectations. I interview 2-3 engineers a week, most of whom will, if hired, write software in Go. I've been doing this for months, and in that time, I've maybe seen 2 candidates who I'd consider very knowledgeable about the language, a few who have the "I played around with it for 2 weeks" experience, and a whole lot who knew nothing about it. At least for me, I'm far more interested in their ability to build a solution in the technology they already know, since I know Go is a relatively easy language to pick up - much easier than most programming languages. But, once again from my own experience, when interviewing for a Java position, you can expect a lot higher expectations. You're competing with a much larger pool of potential engineers - and companies are often expecting knowledge of the minutia of the language (ie how do you compare strings in Java) and using it as a barrier to entry. All that said I don't think you should choose. There are plenty of software companies out there willing to take on a developer from a different technical world, if they can demonstrate an ability to solve problems and deliver. 
You do understand that assignment is not an atomic operation? 
* Since some time it does allow linking of *static* libraries which are shipped without the source code at build time; see [this](https://github.com/golang/go/commit/af6aa0fd745d48c2db70712ebfe6833d30a9a85d) and [this](https://github.com/golang/go/issues/2775). * Since some more recent time it implements limited support for *dynamically* loading of Go code built using a special "link mode" "plugin". See [this](https://tip.golang.org/pkg/plugin/). At preset, this works only on `GOOS=linux`.
Please don't. The framework is known for using code from other projects without even mentioning them.
Your best bet is probably [shiny](https://github.com/golang/exp/tree/master/shiny). Take a look at the examples folder. Also for something more complete and complex there is the [de editor](https://github.com/driusan/de). &gt; why isn't it possible? Unfortunately I have very little knowledge of how native GUI works but I imagine that /u/driusan (who wrote the editor) will be able answer your questions.
You should specify what operating system, display server and the like you are talking about. For X11 under linux there is [xgb](https://github.com/BurntSushi/xgb), which can do, what you want. Shiny (experimental GUI toolkit for go) has a [driver that uses it](https://godoc.org/golang.org/x/exp/shiny/driver/x11driver). In general, go can do everything, that C can do (there are some limitations around use of the `clone()` library call due to the way scheduling works in the runtime, but even they can be worked around), so, everything is *possible*. In the end, C code is also just user-level code that uses the syscall-interface of the operating system (usually wrapped by a standard library). There is no fundamental difference. It's just that, for C, most of the work has already been done in the form of C libraries that you can use. Part of the reason is, that most languages can use C libraries, so you can avoid duplication while still doing the brunt of your work in a high-level language. This is, why so many GUI toolkits use C libraries; because they are there and you don't need to reimplement them in go. It's not that it'd be *impossible* to do.
As /u/neoasterisk pointed out, [shiny](https://godoc.org/golang.org/x/exp/shiny) is probably as close as you'll get. It's part of the Go `/x/exp` tree, and the question of if `/x/` will continue to exist notwithstanding, it's written and maintained by core Go members. Most people want something higher level than just drawing into a window and getting events, but if that's all you want the [basic](https://github.com/golang/exp/blob/master/shiny/example/basic/main.go) example should show you enough to get started. That's pretty much all it does: opens a window, draws into it, and prints the events as they come in. The reason I say "the closest you'll get" is because for most proprietary operating systems like Windows or Mac, they define their API for interacting with windows in terms of C, and don't really publish enough of their ABI to do it directly in a language like Go. So your options are: either have a little cgo glue, or compile your glue to asm and hope they don't change something under the hood without changing the public facing API which breaks your raw assembly syscalls. Open source OSes are less likely to have this problem since there's either a spec defined for new contributors, or you can just look under the hood if not. If all you care about is X there's [xgb](https://godoc.org/github.com/BurntSushi/xgb) written in pure Go as /u/TheMerovius pointed out.
https://www.reddit.com/r/golang/comments/4tt16b/is_this_a_reasonable_set_of_choices_for_web_dev/d5kbvjz/
Thank you for answering my question. I guess i will focus on the languages that i have learned since it is always go to learn multi-languages.
Yes it is. This is basically why Google made Go.
Yes! I have and it was great! Thanks, I hope so too but my mission seems to be accomplished!
[awesome-go](https://github.com/avelino/awesome-go/blob/master/README.md) is a good place to find relatively stable and maintained libs. 
This is really cool! I'm poking around to see how you did this. I have tried to implement tree tool so many times and failed.
For all intends and purposes, the default HTTP server will be good enough for production. As another comment mentions, you might want to tweak some parameters to get that extra push.
`mov` read instructions guaranteed to be atomic, but there is a catch - it depends on where the variable is stored. [See also](https://stackoverflow.com/questions/3349859/how-do-i-atomically-read-a-value-in-x86-asm). `mov` writes are even less so. And this is only about x86 instruction set - I can't say anything about ARM and MIPS. The slice header is 3 machine words long (pointer, current len, and capacity), so even if `mov` instructions would be guaranteed to be atomic for all reads and writes, the 3 of them would still not. So yes - you can get the garbage even in simple assignment to the slice variable without proper sync. P.S. It doesn't address you, /u/joushou, but overall I'm quite disappointed that anyone would expect this thing to be correct in the first place. It's computer science 101, and most of the Universities (well the decent ones) are still giving the introduction course to the assembly. I'm mean - come on! 
video.mail.ru serves video files with builtin http server :-) if you need for ultra-super-fast-API-endpoint, carefully explore https://github.com/valyala/fasthttp
We run it behind Nginx mostly because our DevOPs team is more familiar with managing SSL certificates that way.
It's right in the linked repo. https://github.com/google/enjarify/tree/go
Bit of a nitpick, but I wouldn't consider "how do you compare strings" to be minutia. It's a common task, and if you get it wrong, your code will blow up later. I guess the Go equivalent would be "how do you compare an interface against nil"
What other examples do you have where this is done? I've never heard this about Go
It can be tedious in Go, but hopefully the article highlights some ways around some of the boilerplate. And just reminds people to give errors a proper context in order to make them easier to reason about. I've not actually looked at Rust in that much detail. Do you have any code examples to show what you've just described?
What a great writeup. In the end "Go is easier" and Rust is safer. I love writing software in Go, but most things that plague software development still haunt me there. I hate writing software in Rust, but most of the things that plague software development don't haunt me there. It is a trade off I hope becomes less prominent as time goes by (for both projects) EDIT: More words, same meaning.
Yes. We are using it in production at Alpha Hat http://www.alphahat.com/ 
I've never heard of anyone panic()ing because error handling is too tedious. The article's stack information criticism was valid, but Rust suffers from the same problem. `if err != nil {return err}` is a non-problem, and I spend more time debugging Rust's `try!()` expansion than I do writing the Go equivalent.
Somehow I've missed sqlboiler! This looks like a fantastic package. Fo fun a while back, I had taken the approach of DB first and code generation with common queries made into models (so you would have users.Insert(&amp;User{}) or user := users.GetByID(id)). It auto generated GetByX for each key (and update, delete, etc). But I did not get as far as making any relational models. I also avoided a query builder. It was just for fun though. I'll be giving sqlboiler some more investigation. 
https://blog.cloudflare.com/exposing-go-on-the-internet/ I suggest you to read this article about make the http ready to production
I think they're called sub repositories https://github.com/golang/go/issues/17244 reading the issue I get the feeling the problem is exactly the fact the bonduary is not well defined
See https://github.com/golang/go/wiki/SubRepositories They are separated from the standard library so that they can be developed under looser [compatibility requirements](http://golang.org/doc/go1compat.html) than the Go core.
I highly doubt Google runs frontend servers on net/http directly, they use loadbalancers like everyone else. I think it's better to run Nginx / HAproxy in frond for many reasons: - Easier to manage logs - Easier to manage certs - Easier to restart your app / do rolling deploy - You should always put a LB in front of your webservers 
Go-kit industrial grade toolkit
As far as I understand, the question wasn't asking whether it was OK to expose the Go HTTP server directly to clients without a load balancer. Also, the person you're replying to created [Caddy](https://caddyserver.com/), so I'm fairly certain he's aware of the benefits of load balancers.
I don't have that much of a problem handling the errors every time. Its the if condition itself that bothers me. The fact that I incur an if check every time I call a function - that is what bothers me.
Not necessarily the most elegant solution, but it could be accomplished using `defer`. Something like: tx, err := db.Begin() if err != nil { return err } defer func() { if err != nil { tx.rollback() } }() err = doSomething() if err != nil { return err } return tx.Commit()
This is a big ask and probably out of scope, but a cross-platform screen capture tool/library in Go would be awesome. I'd switch to using that, rather than a bunch of OS-specific code.
[removed]
&gt; My guess is most working Python developers are still incapable of answering a simple question: does all Python2 code work in Python3, yes or no? You'd be wrong. The answer is 'no'. I'm not a full time Python programmer and even I know that.
&gt; I think that this bug is actually horribly dangerous, and I'm surprised that the compiler allows it, ... It may be a common trap for new gophers, but it is hardly to say it is a bug. After all, some programs may use this trap as intended.
There are many reverse proxies and LBs written in go. [Traefik](https://traefik.io/) and [fabio](https://github.com/eBay/fabio) are two others that are very powerful. Both of these give you significant advantages over nginx or haproxy (unless you dive deeply into the lua support inside both of them (at least the newest version of haproxy)) if you have not looked at these two LBs i strongly recommend it. The ability to tie your RP directly to etcd, marathon, consul, zookeeper, k8s or even docker and expose services by simply starting them (provided that is what you want to do) and get free tls and everything is pretty frakking awesome (fabio only supports consul and i don't know if it does acme) 
All our backend APIs are written in Go and use the built-in HTTP server. We had no issues exposing them to the public internet, although most are nowadays sitting behind some kind of cloud load balancer or CDN.
That's a possible solution, but still doesn't feel as simple as it should be - or maybe I just need to get more used to Go. 
Does that work? What if you want to return on rollback? 
Sorry, you are asking the wrong person. I'm a linux guy
I'm not seeing what defer does better then try ... finally in Java?
Rust: * `std::sync::mpsc` is multi *producer* single *consumer* - meaning only one thread can "receive" communications. But there is no `std::sync::spmc` for a single consumer putting work on a queue for multiple consumers to consume as they become ready - hopefully this deficiency in the `std` library is rectified * various libraries provide various additional functionalities, the `tokio` crate provides [`futures-cpupool`](https://tokio.rs/docs/going-deeper/tasks/) for thread pooling.
By module I assume you mean Go package? If so the maybe https://github.com/jroimartin/gocui or https://github.com/gizak/termui might help.
I haven't use SQLBoiler yet, how does it compare with sqlx, I was about to start using sqlx in a project you see...
I had no idea this was a thing. I'm trying to build for linux and developing on OSx. It looks like build constraints is exactly what I need. Still newish to the language, thanks for the help! Edit: After doing some addition research it seems like build constraints aren't quite what I want. They restrict what files can be built on any os. I want to build targeted at linux `GOOS=linux GOARCH=amd64 go build` created from my OSx machine. I would like to run `go generate` to do the build then deploy the application. This is what I want to do: ``` //go:generate GOOS=linux GOARCH=amd64 go build ```
yes go package thanks
Isn't this type of thing better exposed as a "Tree" interface and then the library only needs to handle the "drawing" in ascii. Something like Tree interface { Root() Node } Node interface { Children []Node } Then the user just needs to implement "Tree" and can easily expose existing tree structures without needing to rebuild the hierarchy.
If you want to see how cloudflare does it I have a simple repo you can look at: https://github.com/Xeoncross/secureserver
I think most people are missing one thing here: making the distinction of does net/http is stable vs should I use net/http for public facing services... It's more the later that is interesting.
Only if it's done in a separate block, no? Named returns don't really help in that case either. That's why I said it's not the most elegant solution.
Termbox is meant to be very good https://github.com/nsf/termbox-go. I did however used goncurses for my Moria port and that, as you would expect, works a treat for ascii games: https://github.com/rthornton128/goncurses Other than that, you shouldn't need any other external libraries.
@DanChm net/http is ok for production but its client side doesn't have a timeout by-default so you should NOT USE the http.DefaultClient, make a new &amp;http.Client{} with a setted Timeout field instead and you'll be OK.
I don't think my small static site needs acl, API or caching. Everything has to start somewhere, and not all sites need a load balancer. 
thanks
SQLX is very bare bones (basically just a struct binder), it's not too distant from just the stdlib. SQLBoiler is a fully featured ORM, it was designed to minimize development time by reducing the amount of SQL boilerplate in a project. It's also just as efficient (if not more efficient) than SQLX because it uses code generation opposed to heavy amounts of reflection.
aww. I lost my gopher recently only to find it in my dog's bed missing its eyes.
The blog post states 3 problems: * tight coupling at compile time between "foo" and "mylogger" * tight coupling between "mylogger" and any package that imports "foo", due to the 1st problem * fiefdoms of projects As far as I can tell, the proposed solution doesn't resolve the 3rd problem. Unless there's a common, stdlib interface definition of a logger _that fully satisfies the various logging needs of projects_, you'll just have each library declaring its own logger interface definition, which may be different than each other. It'd almost just be less messy for libraries to accept io.Writers as loggers.
Just curious, with $GOPATH getting a default value in 1.8, what changes would you make for this project?
I had problems doing that and then running the generated binaries across different linux distributions. Maybe whatever was causing my problems has been fixed now but I switched to using docker for mac (which runs on OSX in a linux vm) and building using a go container instead and no problems since then. Definitely cool when your approach works though, you can even target Windows EXEs from your Mac this way!
The gopher and unicorn have seen some stuff...
I downvoted your comment for misinformation. The Go programming language was created to reduce the complexity of programming on modern computers. Today, modern computers are interconnected, yet the language does not take advantage of this fact - the designers left that role to be filled by a standard library. The Go standard library tries to implement the basic standardized protocols within the net package. I highly doubt anything directly connected to the internet is written in go. It is not that go is bad, its that go is new. I'd bet the farm that most of the google monorepo is c, c++, java, javascript, and python(easy enough to check, I guess). With all that said, google is grooming go to take the reins. EDIT: The sad thing is everything I said is true, yet a group of go fanboys downvoted the comment without a reply. go figure.... 
That article hints at user-facing services. However, there is a big difference between user-facing and internet-facing. I'm sure most of the low level stuff is implemented in c and c++(load balancing, redundancy, scrubbing, intercommunication). Most of the services written in go are probably run on such abstractions.
I rarely tell someone when I down vote them but this is one of the rare cases I do.
OP's question was: &gt; Would it be acceptable to make a web application, for a client, using the HTTP library? So I also can't for the life of me understand why people are talking about frontends/load balancers/reverse proxies.
Do you also rarely elaborate as to why?
This seems like a misuse of the `go:generate` tag, but you could probably get what you want by wrapping `go build` in a script that takes arguments.
One common solution to this problem is to provide an auxiliary function which tells you something about the opaque error value. For example, to test if an error on a file was because the file doesn't exit you use: os.IsNotExist(err) Similarly, in gRPC you use: switch grpc.Code(err) { case codes.DeadlineExceeded: case codes.NotFound: // etc } And such codes are wonderfully documented: https://godoc.org/google.golang.org/grpc/codes#Code A good library API will document the errors returned by functions, and this doesn't seem all that different than a typed exception (though I much prefer the straightforward linear `if` to the out of order try/catch). It doesn't solve the lack of stack trace though. Because I work on servers handling lots of requests, I actually very rarely want a stack trace (when you have thousands of goroutines it becomes overwhelming to decipher). A single structured log line that includes the source is usually adequate and also gives me the opportunity to include additional information (like the values of various variables which wouldn't show up in a stack trace) and track changes over time.
I would take a look at https://github.com/gdamore/tcell. I've used it for some stuff and I liked better than the other choices.
I do appreciate when a library has helper functions, like the `os` and `grpc` modules; I just wonder why that's better than returning a more specific error type/interface from the function that has that method built-in. That'd breadcrumb the library's users into knowing where to start, rather than having to read through every function in the library to realize it comes with a helper function. &gt; A good library API will document the errors returned by functions I agree with you, but I also see very few examples, even in google code and the golang stdlib, that documents their errors well. (The grpc module you linked, for example, doesn't even discuss the errors that can be returned by its functions, nor how they'd get triggered, except indirectly if you happen to peruse the module and see the Code() function and then follow it through to the _other_ module where the codes are kept squirreled away). It just still seems weird to me that there is this golang obsession with "programming around error cases" but the ecosystem is simultaneously so opposed to returning error types that make it easier to _discover how to program around your error cases_. Especially since, as-is, a function can change what sorts of errors it returns without breaking compilation, and without breaking any backwards compatibility guarantees. You essentially always have to be ready to handle an arbitrary, unknown error condition. &gt; I actually very rarely want a stack trace I'm with you on the logging aspect, when it comes to code that I (or my team) has written and we can control what gets logged at the point the error is created. Unfortunately, it isn't always enough to help figure out why a library is giving me an error, or where that error even came from. I feel like I have to constantly walk through every branch of library code to figure out what kinds of errors I _might_ get back - with no guarantees that it won't change if I do a minor library version update to pick up a bug fix or new feature.
The phrase everyone is looking for is error monad, but unless that gets put in as a core type or go implements generics we aren't getting it any time soon.
What do you do with golang ,and why do you like golang?
The library handles a bit more than just drawing. The tree structure implemented is a bit more complex than just `[]Node`. Exposing such API means the tree would have external memory implemented somewhere, but the memory is the most complex thing here to do right, not printing. In order to build tree faster, there are helpers to build a tree from nested structs, `treeprint.FromStruct` and `treeprint.FromStructWithMeta`, in other cases (`map[]`, `map[]map[]`, etc) the code required to build a tree with this API is TREEvial :D
It's clearly that you don't know what you're saying and you just recycling a big lie. If something like Iris exists before why is it the fastest?
I thought the non existant timeout was fixed?
I think the stdlib having a logger interface could only have positive benefits. Assuming you can get everyone to agree on a common interface.
Saw this article when u first posted it. Was thinking just now and came back to it. Saw you just updated yesterday as well. I would love to purchase a few of these. Hope to see them available soon. If for any reason in the near future they aren't, I would still be interested in buying some directly :)
&gt; Since I don't believe in heresy, Heresy or rather hearsay? (Honest question from a non-native speaker. I might just have missed some context- or culture-related subtleties here.)
:-)
Jesus this sub is hostile. I've seen racist shitposts with a higher karma score than your on-topic, politely phrased opinion here.
https://changelog.com/podcast/100 At 31:25, Rob Pike explains how dl.google.com is net/http.
To a certain extent I agree with your point about lack of clarity on errors. I don't think its possible to use the type system to enforce this. Are you suggesting that instead of: func x() (int, error) You'd return: func x() (int, *Error) Where `Error` is: type Error struct { Code Message string } And it would implement the `error` interface? Then we'd just write a switch statement to handle all the codes? I'm not sure how else this could be done. For more in-depth logging and exploration of errors check out: https://backtrace.io/ 
I would put this in /r/learngolang
Does any Go code run? You should rule out a bad development environment before you move on to trying to use code generation.
Only page that works is the ticket sales. Tickets price is in $ so presumably not in 'SG$'. They target an international audience ? I messaged the Meetup Golang group in Singapore, which seems to organize this, but got no reply. So still not sure if this is for real. But I like the logo ! Someone did make a good effort on that one to relate it to SIN.
termbox is a very fine library. One thing to keep in mind is that key presses are events in termbox. I had problems to implement keystates for a small toy game. See also https://github.com/nsf/termbox-go/issues/83 
Ranging over a string does need to interpret the string as runes. These loops don't do the same thing. 
They will, but using range on a string will return indices of runes. So for a string of multi-byte runes range may send back indices 0, 3, 6, etc. 
GoLangish
thanks i will 
dam thanks
How do you pronounce that?
GcLagish, one may insult in comments
Looks quite interesting. One thing that I still keep having to come back to Python for is Sympy, its CAS library. 
The phrase you see all over Go Reddit replies, books, and blogs is "idiomatic Go". If there is something more specific to Go, it is not in common use.
Three big benefits: * It's a single line * It is (usually) written right next to the associated action * It doesn't either force you to indent everything an extra line, or just ignore indentation
Go doesn't have generics.
ofc..
Not OP but I imagine it's pronounced "exp-reduce", as in "reducing expressions".
I think it's a pretty real problem. Start a transaction, do some business logic, and then either commit or rollback based on an error.
Where did you buy it? 
Woah. This is awesome. What is the purpose of the time.Sleep in addition to the subsequent WaitVisible calls? Does navigating to a page not block?
thanks for sharing my post here - suddenly a lot of people started visiting my blog. I didn't realise there's so many Golangers in here. Glad the language is getting more popular! cheers
Nice work. Looks like it requires Go v1.7 or higher to get the "context" package.
Offtopic: what your function should do?
[removed]
I actually do really like this
Thank you. It will take a while to get these produced, so if you tips on how I could update people here when it's getting closer, do tell. Regarding the updated gopher. What do you think about it? Better with that version, or you like the original better?
given "idiomatic" denotes an expression that should be "natural", I'd say "go natural".
Log levels predate Java by quite a bit. If anything, it's more of a syslog thing. Further, "logging when you actually have to" is extremely relative. When I have a complex integration that translates data from one third-party application to another, I need to differentiate between "patrons won't be able to use this app until we fix this error" and "this is a known problem, but if it happens a lot, we need to look into a fix". And then all the debug which is ignored 95% of the time, and very necessary when a new bug crops up due to one of the third-party applications changing in an unexpected way, and that bug is so unexpected that we deliver invalid data from A to B without any expected errors being logged, and need to know why. I want to have logstash use fairly generic rules ("error" means something needs attention, "warning" may not), not have one-off rulesets for every application. It's all fine and dandy if you've never run into a use-case where you need verbose logging, but that's just not the real world for many people.
[&lt;insert suppressed squeal of excitement&gt;](http://i.imgur.com/7drHiqr.gif)
I am not quite sure what endpoints is or why it is important but it sounds like it is a google cloud service and as such it should have an API for all supported languages. I don't see what this has to do with frameworks.
I try to follow [these best practices](https://peter.bourgon.org/blog/2016/02/07/logging-v-instrumentation.html) for all newly written code and I am quite happy with them.
Another year, another go dependency tool to migrate to! 
**Error:** End tag had attributes.
Yeah fabio looks really cool. I've got traefik running on my personal servers (the docker integration is nice.) just waiting for something to do tcp loadbalancing before i can kill off haproxy :) 
WTF? No Firefox?
This sounds great. Next month I will be wanting to drive through websites and do submissions. I'd love to automate this process in the background. Will definitely be giving feedback! Would be interesting to see if this can use proxies out of the box. Or can be grokked to. Before you ask. No, this isn't used for spam.
External client connections that are not over http :( (this is pretty much 90 odd % of all of our external traffic)
https://github.com/eBay/fabio has configurable SSL cert sources which are updated without restart. Our ops team has built a simple integration which pulls certs into a directory and fabio picks them up automatically and uses them for routing.
Either that or something that wraps various religious texts in io.Reader.
I think the problem is that most people using go don't use any frameworks, they just use the standard library to achieve their API endpoints. In other languages, making endpoint frameworks is rather easy, people can just use it, in go everyone cooks their own beer, so to speak.
I have nothing more meaningful to add other than I WANT THIS
Can I execute Javascript with this? That's what I always missed in Selenium, I'm forced to use PhantomJS which is a bit heavy on cpu+ram.
The gopher way...
The nature of the Chrome Debugging Protocol means that it is completely async in nature, and it may be because I am not the greatest expert with the actual protocol yet, but there are times when events do not come in in time, so I'm not aware of a better way to handle this at the moment. The simple workaround is on a task list to do a short wait after a navigation, to allow the first page load event to be fired.
Finally Go might become a real modern language. 
This is pretty difficult to read. It's not grammar, but it's comparing a database in which (I assume) the author has little expertise to a database that they are actively involved with creating. The fact that it's on the Dgraph blog does little to establish credibility of the findings. This reads like marketing material. No, this *is* marketing material. There's also some misinformation about Neo4j, e.g. that it's a single server architecture. 10 seconds looking at their website provides information to the contrary: http://neo4j.com/docs/operations-manual/current/clustering/ You should have led with this line: "Note: We are not Neo4j experts" p.s. I have no interest in graph databases, this just struck me as a bit too much to avoid responding too.
I recommend [Vue.js](https://vuejs.org/) for the client-side. This lets you bind JavaScript data to a statically-served HTML template. Then you can fetch/update your data with AJAX requests.
Thanks. This looks great. I see there are no functions for tables. Do you intend to add them. A different way to handle this would be to develop a renderer for blackfriday. IMHO a better approach and building up on a good foundation.
&gt; a common corpus of Go code to be used for evaluating possible changes to Go, Go libraries, and Go tools.
Is this official tooling? It is under golang github org.
Perfect birthday gift! Thank you!
I'm curious how they are going to handle "versions", since all the dependency management so far has been based on pulling the head of master of some git repo. I know that `govendor` and `gb` both let you specify a version, but that's still just a Git commit SHA. You can still get the "just get head of master" functionality by adding `branch: master` in your manifest file. I guess if you use the version it's going to look for a Git tag with that name? 
Wow, this is VERY impressive! Unless I am mistaken, this looks like it is built on top of shiny which makes it (hopefully) cross platform. Correct me if I am wrong.
'Idiomatic' is the term used most often, but others extend this notion with the 'go proverbs'. the python community uses the term 'pythonic' to promote the notion of best practices in regard to python. Somewhat interesting is the fact that 'pythonic' is a real word with varying meaning, none of which relate to how the python community uses the word - they didn't coin a damn thing. 
[removed]
&gt;&gt; it was refreshingly... Boring. I mean, it just worked... &gt; That is what we want, no? Yeah! It was great, it did crash once, but it was because I Ctrl+C'd it (man, dep init takes a *long* time!) That left some things in a bad state. But error messages were helpful, the fix was quick and otherwise it just worked. I didn't have to do anything and *go build* automagically pulled from the vendored requirements. &gt;&gt; Lockfiles and errything &gt; Sadly I don't think there is a way to avoid those pesky lockfiles. I was hoping for a solution that keeps the Go source code as the only source of truth (no manifest files and stuff) but after following the discussions, it didn't seem possible. :( I wasn't being facetious! As Pythonista I really appreciate the lockfile. Just having requirements isn't enough when you're trying to hunt down an issue introduced in a dependency between x.x.1 and x.x.? &gt;:| If you don't have a lockfile you have to go pull your asset from production, crack it open and get the version number of your dep. Lockfiles help get rid of the extra steps.
Because it supports Edge also and I think Firefox supports Chrome Debuggging Protocol
Hmmmm..... strange. Firefox supports Chrome Debugging Protocol but it might be that it does not support it as a server. I can debug Chrome from Firefox DevTools. Why dump WebDriver and use CDP? I know WebDriver protocol is getting standardized at W3C.
Go is probably the best general purpose language right now. Oh and it's definitely modern. Go has had package managers before this. 
How would you guys provide vendoring for a repo with mulitple commands (e.g.: ./cmd/foo, ./cmd/bar). Are we supposed to run `dep init; dep ensure -update` inside each cmd directory?
Go will look for a vendor folder in the current directory first. Then in the parent directory and so forth until it can no longer shorten the path without leaving the gopath of the current project. (IIRC) In practise this means that if you have `example.org/project/cmd/foo`, then the go tool will look for the following folders in that order: * `example.org/project/cmd/foo/vendor` * `example.org/project/cmd/vendor` * `example.org/project/vendor` * `example.org/vendor` If it finds any of these vendor folders, all imports are interpreted as being relative to this vendor folder, the tool will also take the longest path with a vendor folder. So if you have `example.org/project/cmd/vendor` and `example.org/project/vendor`, the go tool will use `cmd/vendor` to compile anything under `cmd`. &gt;And if so, does that mean that dep init would gather all dependencies from all sub directories and put them in the manifest? As far as I can tell, yes, the dep tool will look for dependencies from the current directory downwards and write a vendor folder into the current folder. So you can execute it inside `cmd/` and at the project root.
Yes.
Does anybody know if it possible to have the manifest and lock file in your `$GOPATH/.`, and make `dep` vendor to `$GOPATH/src/vendor`, while the rest of your code is just in `$GOPATH/src/main`, `$GOPATH/src/businesslogic` etc.?
What's the speed gain over regular WebDriver/Chrome ?
Does anyone know what improvements are planned for the 'dev.inline' branch? The first thing I associate the word "inline" is function inlining in PL context. Is that the case? Does anyone know if there is any changes to function inlining being planned in Go?
Why do you need generics to perform very simple rotations on images?
For a lot of my projects GOPATH is my git root. Will experiment with it. Thanks :)
It's certainly better than a commit SHA.
Looking at [the commit history](https://github.com/golang/go/commits/dev.inline) it looks like that's exactly what it is. There's lots of refactoring regarding line/position numbering in the compiler. Also a new `//line` pragma.
[removed]
That's fair. I tried that at first but then just setup a single GOPATH and put my projects into it instead. I prefer that to changing GOPATH as I move around 
[removed]
I hate how much gophers are ok with SHAs... I've tried to open issues to ask for changes to semver and multiple projects have replied that it is "just not how it is done in go"... /me facepalm 
[removed]
They claim generics would slow down compile times considerably, yet I see no work that they have done to support this claim. However they request that people prototype and explore options, but never give the community the chance. The depressing thing is they pushed so hard for aliases, even with resistance from the community, then found out it was seriously flawed. The core go team are bigots. They talk a bunch, but get very little done, then when the community tries to help they shut them out. Then the community creates a debugger without them, and they realize the community is leaving them behind, so they backtrack and do some pr damage control in attempts to mend fences. But they have yet to give the community the things they need, still not playing nice with most projects outside the control of google. 
True. Gas guzzlers still sell in market where fast efficient vehicles are available. My point is if we have fast efficient vehicle, we tell in big bold letters. If many users do not care that is just fine.
Thanks. I like your xo package by the way - I used it before when I was looking for ways to interface with a legacy oracle database. These kinds of tools are so useful at work.
Thanks! The reason I didn't use blackfriday is because every time I've tried to use it (including this time), the documentation isn't very good for people who aren't already familiar with its weird callback based API (which seems to be a legacy from its origin as a port of a C library.) I wasn't sure if doing this would work at all, so I just threw together without it. Since it seems to work, I'll probably eventually take the time to move it over to blackfriday since, as you say, it's a better foundation and saves me the effort of handling all the markdown edge cases and extensions (like tables). What I'd *really* like though, is a library that provides some kind of generic Abstract Markdown Tree..
404
[removed]
Besides autogcd, I'm not aware of any other chrome debugging protocol implementations in Go. I searched fairly exhaustively... It's entirely possible I missed it though. Any links would be greatly appreciated! This has the benefit of being pure Go, and can be embedded. In future, I will package a headless version of chrome so testing/driving can be done extremely easily. First though, a critical mass needs to throw this against real scenarios to help flesh out any issues, and to help figure out what missing features need to be implemented.
and also, Scala never really caught fire with FP people, who perceived it as a wannabe Haskell
[removed]
ITT: people not realizing this is not a help request, but the name of the blog post linked.
You don't really, [versions are problem zero](https://www.reddit.com/r/golang/comments/5i47ha/the_saga_of_go_dependency_management/db6bn20/) in my opinion. They are also the easiest to solve so I am still perplexed we are so determined to engineer our way through them from the other end.
go-od. "The good way of doing..."
I did one contract with scala. After trying to hand off the project, I realized it was a mistake for the company. Developers, rightfully so, complained how difficult it was to read and maintain. I shall stand by this. Scala is horrible. Great ideas with bad execution. This is my private opinion, not the opinion of anyone else. :) 
I should point out that I want generics, but I'm fine seeing them stay on the back-burner for however long the Go team feels is necessary. I'd rather see dependency management done properly first, 1.4-level compiler speeds, and other "housekeeping" work done long before generics. I was simply pointing out a real-world use case to point out that code generation will continue to be necessary in some cases due to lack of generics.
Yes, libs can declare dep constraints, and can even check in vendor dirs, if they choose to.
dep ensures that the entire dependency graph is solved with a single solution, and that transitive vendor folders are 'collapsed' to the root vendor folder. That's the problem that motivates the advice "never vendor deps in libraries", and one that dep solves. But perhaps I'm talking past your concerns, can you clarify? &gt; Honestly, if we have a good lock file and all Go packages are defining a proper dep lockfile, i see no reason to even use vendoring in the majority of the cases. Vendoring in its current form is best understood as an implementation detail of how we ensure (heh) the deps declared in the manifest (really lock) file are pulled in to the compilation unit. The dep tool currently leverages the vendor dir, but there's nothing saying it will stay that way in the future.
Best solution - copy the functional init script, however for those doing 12 factor app - you log to stdout, so here is a better solution: http://stackoverflow.com/a/21029952/1182721
https://github.com/golang/go/issues/17566 is related: cmd/compile: improve inlining cost model
I'm using httprouter, with a simple call like this: router.Handle("POST", "/", HandleWordSearch) HandleWordSearch then looks like this: func HandleWordSearch(w http.ResponseWriter, r *http.Request, _ httprouter.Params) { word := r.FormValue("word") anagrams, err := SearchDBForAnagrams(word) if err != nil { // Render an error in the template instead panic(err) } RenderTemplate(w, r, "index/home", map[string]interface{}{ "WordsEnglish": anagrams, }) } The issue I feel like is RenderTemplate (in the OP), which is rendering the entire template (as opposed to only the part that is changing). If I prevent the submit on the form that triggers this POST, wouldn't that prevent the POST request from happening? Thanks for the resources by the way!
You want your HandleWordSearch to just return some JSON rather than rendering a template. I recommend having an `/api/` group for your JSON endpoints to separate them from the ones that render HTML. The prevent statements will stop the browser from visiting the submit URL so you can handle things in-page with AJAX requests via vue-resource, axios, JQuery, etc. 
Nevermind I found the solution using the reflection package thanks to this example. https://play.golang.org/p/8zwvSk4kjx
That makes a lot of sense, I'm not sure why I defaulted to having that function call render when I can just return the data (as you said) and pass that to a Vue component. Thank you for the advice!
There are areas where resource efficiency is very important, and those where it isn't. By having an efficient language you can target both.
Yes, and thanks for the heads up! Seems to be a relatively new project where they port over nuklear to be in pure Go, which is just amazingly cool! https://github.com/aarzilli/nucular (https://github.com/golang-ui/nuklear) I hope this becomes huge and active so it doesn't die down like other GUI toolkits seems to be doing.
You have great taste in whiskey
Looking at Meetup.com I didn't see it in searches within 25 miles of Nashville. Could you include a link?
Rewriting actually :) I wrote it as my first Go project, and am revisiting it because I've learn a lot about better practices 
Here's the USENIX paper: https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-melara.pdf
Cute. None of the pieces match, though. D:
&gt; I hate how much gophers are ok with SHAs... Huh? Who says that? Besides as far as I know, the new tool will use semver.
I would have suggested pulling backOfficeWeb.InMsg off into a variable before the select. If it isn't there, leave the variable (a channel) nil, and it will block and not be used anyway.
I'm not 100% sure of your requirements but I've been pretty pleased with using [jwt-go](https://github.com/dgrijalva/jwt-go) for token-based authentication For an example on how to use it, you can refer to [here](https://github.com/boxtown/meirl/blob/master/api/user_api.go#L194) and [here](https://github.com/boxtown/meirl/blob/master/api/lib.go#L60). Feel free to ping me with any questions
If only this was open source and we could contribute more articles to play with :D
It will be. https://twitter.com/ashleymcnamara/status/824353119920410629 edit: https://github.com/matryer/gopherize.me
[Hey it's me ur brother.](http://i.imgur.com/3rMxMQr.jpg)
 {"error":"loading images: error processing images"}
My god, it's uncanny the resemblance. 
Looking at their desktop example, it does have some dependencies, but it all seems like standard stuff: $ ldd nk-example linux-vdso.so.1 (0x00007fff511a7000) libGL.so.1 =&gt; /usr/lib/libGL.so.1 (0x00007f31844b6000) libX11.so.6 =&gt; /usr/lib/libX11.so.6 (0x00007f3184177000) libXrandr.so.2 =&gt; /usr/lib/libXrandr.so.2 (0x00007f3183f6c000) libXxf86vm.so.1 =&gt; /usr/lib/libXxf86vm.so.1 (0x00007f3183d66000) libXi.so.6 =&gt; /usr/lib/libXi.so.6 (0x00007f3183b55000) libXcursor.so.1 =&gt; /usr/lib/libXcursor.so.1 (0x00007f318394a000) libm.so.6 =&gt; /usr/lib/libm.so.6 (0x00007f3183646000) libXinerama.so.1 =&gt; /usr/lib/libXinerama.so.1 (0x00007f3183443000) libdl.so.2 =&gt; /usr/lib/libdl.so.2 (0x00007f318323f000) librt.so.1 =&gt; /usr/lib/librt.so.1 (0x00007f3183037000) libpthread.so.0 =&gt; /usr/lib/libpthread.so.0 (0x00007f3182e1a000) libc.so.6 =&gt; /usr/lib/libc.so.6 (0x00007f3182a7c000) libexpat.so.1 =&gt; /usr/lib/libexpat.so.1 (0x00007f3182852000) libxcb-dri3.so.0 =&gt; /usr/lib/libxcb-dri3.so.0 (0x00007f318264f000) libxcb-present.so.0 =&gt; /usr/lib/libxcb-present.so.0 (0x00007f318244c000) libxcb-sync.so.1 =&gt; /usr/lib/libxcb-sync.so.1 (0x00007f3182245000) libxshmfence.so.1 =&gt; /usr/lib/libxshmfence.so.1 (0x00007f3182042000) libglapi.so.0 =&gt; /usr/lib/libglapi.so.0 (0x00007f3181e13000) libXext.so.6 =&gt; /usr/lib/libXext.so.6 (0x00007f3181c01000) libXdamage.so.1 =&gt; /usr/lib/libXdamage.so.1 (0x00007f31819fe000) libXfixes.so.3 =&gt; /usr/lib/libXfixes.so.3 (0x00007f31817f8000) libX11-xcb.so.1 =&gt; /usr/lib/libX11-xcb.so.1 (0x00007f31815f6000) libxcb.so.1 =&gt; /usr/lib/libxcb.so.1 (0x00007f31813cd000) libxcb-glx.so.0 =&gt; /usr/lib/libxcb-glx.so.0 (0x00007f31811b1000) libxcb-dri2.so.0 =&gt; /usr/lib/libxcb-dri2.so.0 (0x00007f3180fac000) libdrm.so.2 =&gt; /usr/lib/libdrm.so.2 (0x00007f3180d9c000) libXrender.so.1 =&gt; /usr/lib/libXrender.so.1 (0x00007f3180b91000) /lib64/ld-linux-x86-64.so.2 (0x00007f3184728000) libXau.so.6 =&gt; /usr/lib/libXau.so.6 (0x00007f318098d000) libXdmcp.so.6 =&gt; /usr/lib/libXdmcp.so.6 (0x00007f3180787000) 
Do what /u/Redundancy_ suggested, or add a method to `backOfficeWeb` (or a function, if you don't control the type) that returns nil, if its receiver is nil, like func (w *whatevsType) getInMsg() chan T { if w == nil { return nil } return w.InMsg } func whatevs() { select { case bw := &lt;-backOfficeWeb.getInMsg(): … } } Do *not* use reflection. The vast majority of go code should never touch the reflect package.
There's a reason - API compatibility. Right now you may not need it, but in future the struct may grow beyond a point it's feasible to use a value. You can't just make it a pointer then, without breaking API.
Cute! :)
First, I love the idea :) Wish there was a way to turn off that animation every-time I add add something to the gopher. 
[removed]
Yeah I've used it before for another project. It's a really nice library for building CLI tools.
I'm not the author of any of those, but I wish I had more time on my hands, and I would gladly help out on that as I agree with you. I really like nuklear. Simplistic and nice, and totally skinable too. If you ever used the node system in Blender (https://www.blender.org/) you know what I talk about. Such as nice UI... Would for sure be a great thing for Go if this existed as pure Go.
Make a MD5 cracking program! I love to do that when I learn new languages.
Author here - happy to answer any questions or fix anything that seems inaccurate/misleading. I believe I have a majority of the issues cleaned up at this point but you never know. The goal of this post was to help explain the difference between length and capacity and how they came to be in Go since I see a lot of beginners not really understanding make and append until it bites them.
The new tool will, which I love. Numerous projects that I use as dependencies at work are against switching to semver and cite the community as a reason 
What goals are you trying to achieve, or what is your desired flow? Can users log in via Google, FB, or other accounts using oauth? Do you need users to create an account inside your application and securely store their password and then hand out JWTs to the mobile apps? Something else? There are a lot of potential solutions, but its hard to point you in the right direction unless we know more about what you want the final outcome to be.
The new tool allows users to place version constraints using semver (tags only), branches, arbitrarily named tags, revisions (commit hashes), or the same 'default branch' behavior that go get currently uses. semver strongly preferred :) Absent any constraint, there's an [order](https://godoc.org/github.com/sdboyer/gps#SortForUpgrade) in which versions will be attempted.
This isn't the intended use pattern, but it should probably work (once we fix [this](https://github.com/golang/dep/issues/148), anyway). It'll end up meaning that dep tries to compute a single dependency graph for EVERYTHING in your GOPATH. If you do try this, please provide feedback on your experience in an issue on the repo - it'd be great to hear more :)
Neat! Really useful!
[I just bought 2 from Amazon for 30$](https://www.amazon.com/TCs-Tee-Golang-gopher-tshirt/dp/B01FTDI9WI) Bigger logo, decent shirt. Just looked down an realized I was wearing it. 
Go with BSD-style license like Go project itself (https://github.com/golang/go/blob/master/LICENSE). If the code was written by you, then you get to pick the license, Amazon has no say in it. Also, .mobi format is not owned by Amazon. It's not owned by anyone because you can't "own" file formats. The only control one has over a file format is a choice to not describe it. Mobi format is an extension of PalmDOC format (which was a file format for simple databases for Palm OS) which basically added html-like tags to plain text. A company called Mobi Pocket came up with it and used it in Mobi Pocket Reader, but it was also used by many other applications. Amazon then bough Mobi and used mobi format with DRM scheme. There are plenty of closed and open source software and devices that use the format (https://wiki.mobileread.com/wiki/MOBI). Amazon doesn't get to dictate who uses it or what is the license of the software for reading or writing it. 
Hi, 1) you don't need to have 1 db.Open() - it doesn't directly create connection, and is goroutine + thread safe, you can call db.Open() directly in the function that needs to do DB operations... 2) no need to call defer db.Close(): https://golang.org/pkg/database/sql/#DB.Close. 3) I recommend separating handlers from db operations by writing separate functions for DB - func getMessage(msgId string) error {}. This way the internal API is cleaner and you can split the database operations into separate package. 4) most people use Gorilla toolkit for writing web applications. It is not directly a framework but rather collection of tools. You can't go wrong using it. There are several "frameworks" that do most of the boilerplate, but they are not as extendible - Echo is one of those for example.. About the security - it depends on the usecase. If you have users that need to log-in before read/write operations, JWT are fine, but you have to write client JS code to use it correctly.
Hmm, I haven't heard about it, I'll take a look but it looks fine on first glance. One more thing, maybe the most important - create a custom http.Server{} instance instead of the default. By default they have all Timeouts set to 0 - infinite, which is not a good idea. You should have something like this: s := &amp;http.Server{ Addr: ":8080", Handler: myHandler, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, MaxHeaderBytes: 1 &lt;&lt; 20, } log.Fatal(s.ListenAndServe()) You can find more information here: https://golang.org/pkg/net/http/#pkg-examples
Check the https://github.com/gopherds/resources/tree/master/tooling 
I knew there was a blood y simple solution my tired brain wasn't getting. Not sure how I missed that, ah well code facepalm.
This first mistake is the one I made most when learning go. Great article 
One proven way - Use (s)ftp site watchers (e.g. https://github.com/LDCS/ftpwatcher) to bring incoming files to your disk. For never-before-seen file types, use/write a cleaner to normalize to gzipped hcsv. Generate a golang loader for that hcsv ( 2 minutes using https://libraries.io/go/github.com%2FLDCS%2Fgencsv). Write golang funcs to process as needed, add them to the generated loader code. Output to hcsv again. The filesystem is your database. Scales to hundreds of incoming files of dozens of types using just single-threaded golang. 
We are looking for fetching data from Kafka, pass the data across various stages and finally write to SQL DB. However when the data is being processed we need certain rules to be applied on the data. Also we need references to SQL Tables during processing.
The readme has a link to a document that says don't use a regex, and then the code uses a regex. Just look for @. Follow the advice from the linked document. 
Yes, a regexp is not enought, that's why the pkg provide a method to validate the domain and the mailbox. I prefer to follow the advice of the W3C for the regexp, which gives us a simple regexp, a little more than just '@' : https://www.w3.org/TR/html5/forms.html#valid-e-mail-address
Ah, thanks! I somehow missed this ... oh god, this happened with http.Client not returning error on non-2xx statuses as well :D gotta pay more attention to the docs! :D
I'm totally agree with that guy http://www.florinpatan.ro/2016/10/why-you-should-not-use-iris-for-your-go.html and there is also proofs https://www.youtube.com/watch?v=e7ZnHH30zgo
Yea! I got mine at Gophercon in Denver last year. As far as I know, the only way to get one is at a convention right now (since they don't sell them directly anymore)
Should just be on load only if at all if you ask me 
Yes, I read the source code, and saw that comment. But there is no http.ContentServer, just http.FileServer. I'm really trying to understand what the intended flow is here, not just get a workaround answer. As I said, it's quite obvious how I could hack my way around this.
[removed]
You said that there was no code in http.FileServer that handles a dir-&gt;index.html, but that code is reached through FileServer(...) -&gt; *fileHandler --&gt; fileHandler.ServeHTTP -&gt; serveFile If it is a directory, it tries to open index.html, and if there are no errors doing that, it passes it on to serveContent. Unless I'm missing something, this is the special case handling that you were asking for? Why you get a 404 is a different question I can't answer... FileServer should return a directory listing if it doesn't find an index.html, which can be quite annoying behaviour not to be able to turn off. Is it possible that it's a mux issue and that it's actually hitting another handler?
I'll have to give this a try at some point! I've been really looking for a player that works with GPM. 
I'm also planning to implement integration with last.fm at some point, so you can scrobble while listening, if you are interested in that
Read that comment more carefully, and look at the code that follows it. Here's a sample execution with values on the right. // use contents of index.html for directory, if present | if d.IsDir() { | true index := strings.TrimSuffix(name, "/") + indexPage | "/index.html" ff, err := fs.Open(index) | {File index.html}, nil if err == nil { | true defer ff.Close() | dd, err := ff.Stat() | {FileInfo index.html}, nil if err == nil { | true name = index | name = "/index.html" d = dd | {FileInfo index.html} f = ff | {File index.html} } } }
See his [previous post](https://dave.cheney.net/2017/01/23/the-package-level-logger-anti-pattern).
I've got another idea for doing a compile-time assertions; use consts and under/overflows. https://play.golang.org/p/D_eqq0r9KY
That can be expanded to test for equality with: // Check that Hash length equal to md5.Size. const ( _ uint = hashLen - md5.Size _ uint = md5.Size - hashLen ) Hehe.
I just learned about this technique last week. I'm still impressed by what the interface and assignment mechanisms can do when combined. It is cool that you can assert a certain expression will comply to the interface you want/need at compile time. It works are documentation too. But I must admit that the first time I saw this technique I thought it was weird at best - that is, until I understood the language's mechanics that made that possible.
This doesn't cover the same use case. Yes, he discusses how to inject a logger into a generic struct, but he doesn't discuss the core problem that leads to storing a logger in `context.Values`. 99% of the time when someone is storing a logger in `context.Values` the logger is one specific to the context. Typically this is context specific because of a unique request ID being attached to the logger, making it easy to call something like `log.Println("blah")` and it will output `&lt;uniq-req-id&gt;: blah` or something similar. One alternative to this is to require the `requestID` as the first param to any logging functions. The downside here is that you need to have the request id available anywhere you might also want to log a message. Another is to write logging methods that accept a `context.Context` value and try to get the requestID from that. Chi kinda does that here: https://github.com/pressly/chi/blob/master/middleware/logger.go#L78 but this isn't a great example. (I'll hunt for a better one later) Again, this approach requires you to have that context available anywhere you want to log, but this might be more common since contexts are useful for cancelling those functions anyway. Another solution is to create a custom context interface that embeds `context.Context` but has extra methods for setting and retrieving a logger. This makes it more explicit what you are trying to do, but the downside to this is that your methods are no longer `http.Handler`s which means you need to write custom middleware code and can't easily use something like Chi. You also need to implement your own context interface and make sure you don't screw anything up there, so it might be worth demonstrating how you can do this. There are probably countless more that could be considered. My point isn't that either of these posts are bad or that they don't help educate people. They are great posts. My point is that if I were new to Go and I read both of these posts I still wouldn't know what to do. It is hard to take action when someone says "don't do X", even when you understand why X is bad. It is much easier to take action when someone says "Here are some alternatives to X. Give them a try. See what works best for you."
How so? Even a more robust logging library wouldn't address the fact that being context-specific (eg prefixing logs with a request id) requires that each request has either (a) a custom logger instance w/ this value set, or (b) passes this value into the logging functions. People tend to store a logger in `context.Values` because they want to store one with this request-specific information inside of it. Not because they dislike Go's logging API. Perhaps I am missing something? Could you elaborate further?
What makes you say that?
I can't read minds, but I think Dave is pushing against using `context.Context` like that for anything. It shouldn't be a grab bag of random things that may or not be there (is how I read it). For my stuff, as an example, the context is used only at the highest http handler layers. As soon as feasible, I pull the relevant parameters out of the context and pass them into a function that requires specific inputs. Generally, this is right after finishing up the handlers that trigger on every request, and get into the handler for the specific endpoint.
I messed up the initial link (wasn't going to the correct line) but fixed it a minute or two later. Glad you got to the bottom of your problem.
This might help you see what's going on: https://play.golang.org/p/qKGCbl1Vqc In almost all languages, you generally can't trust `==` on floating points, as float operations tend to result in things getting rounded in ways that are hard to predict. For that sort of precision, you end up needing a fixed point type/helper class. [More info](http://floating-point-gui.de/errors/comparison/)
Love linux. But I have to say the web app for google play music is pretty good too.
My understanding of that paragraph is that Go doesn't want to have assertions because they tend to be checked at *runtime*, and more precisely at runtime during the testing/debugging phase. Apparently, they are also thrown away using a compiler option for production code (because they are "slow"... whatever). I can see how that approach is a substitute for proper error handling. However, a compile-time only assert would make sense and take a saner approach to what was shown in the article (let's call it "property" if "assert" is a too much loaded term) .
Author here. The problem here is that we're decoding a large object (an [Index](https://restic.readthedocs.io/en/stable/Design/#indexing)) directly from a `[]byte`, so we already have all data in memory. The `json.Decoder` is designed for processing streams of JSON objects and buffers a lot data internally (so it can check whether the JSON is well-formed before modifying any structures, I think). `json.Unmarshal()` on the other hand mostly just uses the buffer passed to it, and does less internal buffering.
Did you just assume my gopher's gender? \#thisjokewillnevergetold
(Severe) bug: current implementation is limited to UTF-8 sites only. *) Solution: incorporate [net/html/charset](https://godoc.org/golang.org/x/net/html/charset) into your tool. *) The asteroid to kill all single-byte-encodings is still in orbit.
it seems everyone agree that if you publish an open source library, you should be returning descriptive errors, not logging if we all agree on this, then logging is the domain of our private codebases. why not just embrace ugliness and just use whatever suits our environments, sanitary or not? most of the (private) production code I have found effective is riddled with logging, even in libraries. yes this is "gross" from a sanitation perspective but the output is very useful. is it really so wrong to just have a global logger? I guess my point is, why are people trying to combine what seems to be private concerns with the standards for public code?
you need a language with modern handling of rational numbers...Perl6 is one #!/usr/bin/env perl6 use v6; my Rat ($f1,$f2) = (0.1,0.2); my Rat $f3 = (0.1 + 0.2) / 2; say ($f3 == ($f1+$f2)/2); output: `True` of course to embrace this direction you also need to be willing to accept a higher-level of abstraction, and lose some efficiency as a result.
I can imagine using it on a mac, but windows? do you really need a CLI player in windows?
ANYONE LOOKING FOR GOLANG WORK?? 6 month+ contract in San Ramon, CA 2 spots available Big Client, great to work for
Thanks for the explanation !
well the `big` package doesn't really address this issue because `Rat` types are still limited by fixed width integers since Go's `big` pkg does not work on Go's standard mathematical operators, your answer isn't satisfying. Go's `big` package is cumbersome and limited in any case I assume this was all an intentional artifact of Go's design and its focus on efficient representations. I personally do not see the program listed at the top of this page as a "failure" of Go but I also feel like most people don't want the expected behavior of IEEE floats
&gt; why the equivalent C code prints true? Because you only tried it on one particular configuration. You're relying on implementation defined behavior and that the compiler doesn't perform optimizations that it's fully entitled to do. It will not be true on i386. $ cc -o foo foo.c &amp;&amp; ./foo 1 $ cc -m32 -o foo foo.c &amp;&amp; ./foo 0 Pop quiz: what particular feature does i386 use that amd64 doesn't that makes things behave this way?
&gt; and for some reason /u/Redundancy_'s anchored link showed me the bit of code I'd already been looking at, and not the bit of code I needed to look at. That's why it's nice to highlight selected lines when displaying source code. golang.org's source code view doesn't do this, but gotools.org does: https://gotools.org/net/http#fs.go-L405
golang.org can do it, but it uses character position instead of line position for highlighting: https://golang.org/src/net/http/fs.go?s=12366:12422#L405
Himago is a command-line tool that downloads high-resolution images that were originally taken from the Himawari 8 satellite. I wrote this as a way to learn Go. I've learned a lot already but my Go-fu still needs some work. Any feedback is would be gratefully received. PRs and Issues on Github are also welcomed. There are similar tools out there already. There are many like it, but this one is _mine_. Enjoy!
Why not have `W` include the interface?
How did you create that link?
This is how you give feedback. Thanks! I'm glad you like it. I was aware of the relative import- amazing how "tactical solutions" become permanent ones. It was a workflow hack as I didn't want to have it refer to the GitHub path while I was working on himago.go. I _think_ I would have to push changes to GitHub, go get and then go run/build without a relative path. Any suggestions on a better workflow? Great suggestion on the flag usage. It felt wrong when I wrote it but couldn't put my finger on it. Your fork looks considerably cleaner as a result too. I'm very interested about the solar eclipse. The satellite is geostationary over south east Asia. Would it be day time there during the eclipse?
&gt; go1.7.5 (released 2017/01/26) includes fixes to the compiler, runtime, and the crypto/x509 and time packages. https://github.com/golang/go/issues?q=milestone%3AGo1.7.5
Ah, I did not really read the wikipedia page it seems. The total solar ellipse will be over North America this time around. Though I am sure you could look up a solar eclipse times for the area the satellite is above and plan to get an image then. My solution to the relative imports is just to organize your $GOPATH the same way you are going to push code. i.e. I store all my code on github in this fashion $GOPATH/src/github.com/adamryman/... I also have my own personal git repo store $GOPATH/src/git.adamryman.com/adamryman/... I did not even think about your use case, though it does make sense. The GOPATH is kind of odd. It is a highly opinionated code organization, which I personally like because it is really easy to find where source code is. To quote ["How to Write Go Code"](https://golang.org/doc/code.html) &gt; If you keep your code in a source repository somewhere, then you should use the root of that source repository as your base path. For instance, if you have a GitHub account at github.com/user, that should be your base path. &gt; Note that you don't need to publish your code to a remote repository before you can build it. It's just a good habit to organize your code as if you will publish it someday. In practice you can choose any arbitrary path name, as long as it is unique to the standard library and greater Go ecosystem. There are downfalls of course, one big one is how do I move a package? There are a few tools like [gomvpkg](https://godoc.org/golang.org/x/tools/cmd/gomvpkg) but I have not actually gotten it to work well. My current solution is I wrote [a little script](https://github.com/adamryman/dotfiles/blob/master/scripts/ag-replace.sh) that uses [ag](https://github.com/ggreer/the_silver_searcher) and sed to replace text and I just replace the imports with new imports.
Hey guys, I'm adding the link to the sample for a simple go app/web service with a Vue.js front-end. The app is meant to demonstrate a port binding example (7th factor), while also using a backing service (4th chapter). The app doesn't follow all 12FA guidelines, mainly because the Redis service isn't configurable outside of code, yet. I'd be very happy if any of you guys could take a look at the sample code and add any comments you might have. Edit:The book is available on Leanpub: [12 Factors of Docker and Go](https://leanpub.com/12fa-docker-golang) and I generally post lots of Go-DevOps/Dev things on my blog as well (https://scene-si.org).
* you should have a consistent error handling struct that includes request data. defining anon structs for every error isn't ideal * if you're not doing streaming json, you should use unmarshal/marshal instead * consider wrapping the response writer with methods like Respond(interface{}) error, Header(key, value string), and Status(int) so your code reads like what you're actually doing rather than like raw http code. * sanitize your input data. message/{id} can not possibly be valid for any value but an int64 value, but you basically allow anything to be specified * don't panic in your handlers. sending invalid json to POST /message will crash your service * GET /message is unbounded, appends to a zero sized array (requiring substantial growth over result size), and doesn't support range queries. Once this db has a large number of messages the query will cost an insane amount of time/memory to aggregate the results per request * DSN is invalid if environment variables aren't set. You should be providing safe defaults for each variable (assuming a localhost db instance for example) * You should provide handlers for unspecified routes, etc. that return valid json responses and status codes.
&gt; Not sure what you mean by that. Meant that: https://github.com/kovetskiy/manul &gt; Those are cool but they are not a good dependency solution for the whole community. I think you are right. Don't know other VCSs well and whether they support similar. It just felt fitting to have something, like the VCS solve that issue as a way to reuse tools, rather the re-implementing them. I don't know, but to me it seems strange, that editors and VCSs don't have to be reinvented, but somehow dependency and package management gets redone over and over. I can see some reasons for that and it's certainly not something that Go stands out with, but while the things that get done are similar, they are re-implemented over and over. Would love to see if something like Git or something smaller and generic could become the default solution. But again, it's a more general topic and looks like the right way just hasn't come up yet.
There's two `l`s. https://en.oxforddictionaries.com/definition/cancellation
[removed]
Might find some interest for this as well in r/Marketing or r/seo
[removed]
It's been a few years since I've written a Go server so I'm sorry if I'm in the weeds, but what's stopping people from having a request specific typed context object that can contain the logger or anything else? Why does it have to be this untyped bag of values?
If that is still confusing, this might help: https://play.golang.org/p/RIcoUiUxuh
Little Prince reference?
I would say that a method *has* a pointer or value receiver, not that it *is* one. The "receiver" is the parameter that gets the object the method was called on. Also, [here's](http://stackoverflow.com/questions/33587227/golang-method-sets-pointer-vs-value-receiver/33591156#33591156) something I wrote a while back on the question of when you're able to call each type of method, and how they go towards satisfying interfaces.
I maintain Debian's sparc64 port, so it's always great when there is upstream progress.
You can always to assert yourself (with a bit of ugly hacking, though): func assert(cond bool, val string) { if !cond { panic(val) } } func main() { fmt.Println("Hello, playground") assert(1 == 2, "1==2") } 
Typically you'll define a method on a struct receiver when you're implementing an interface, or when the behavior is specific to the struct. By writing a function that accepts a struct as an argument, you're limited to calling that function with only the one struct type, unless your function accepts an interface{} Additionally, writing the method using a struct receiver is useful when embedding that struct type into another struct, which then gets to also use the methods of the embedded struct. Whereas a function written with the struct as an argument can only be used with the type defined in the function signature. In your example, "MyStruct.New" is most likely referencing a package, called MyStruct, and an exported function, New, which returns a pre-initialized instance of some struct in MyStruct package.
I understand that a lot of programmers may be thinking "shall I learn Go or Elixir?" - but this is still a really weird thing to compare (to me). 
Do I need to install Portaudio? How many linux users have it installed? The thing with pulse is that it is present on pretty much every linux desktop nowadays (except for some extreme cases). Initially, I wanted to use ALSA, I struggled with it a lot, trying to figure out correct buffer params, period size, etc, so I rejected this idea and used pulse instead. Another advantage of pulse is that it is present on BSDs, and ALSA is absent
Take a look at how it's done in moggio https://github.com/mjibson/moggio/tree/master/output
How so? Both languages have very powerful and yet different concurrency model. If you worked with or about to start a project that deals with concurrency, its very reasonable to come to a time where you need to make a decision between the two.
 When a method is a value receiver, it means that you cannot modify the struct fields because the struct is being passed by value. You can, it will only modify that method's struct fields. It is also best practice not to mix pointer receivers and value receivers; use one or the other depending on your use case (as mentioned by /u/jancalhoun). 
Hi, What you described looks like needs to be more similar (in terms of architecture) to a framework rather than a CMS. I'd go for an MVC pattern, where users will be able to extend the three fundamental parts of your web content application, the data model, the routing model and the frontend/rendering module (facultative, I'd rather implement only REST ep's and create some template layering on top of it that can be optional and some users may opt to implement their frontend solution) 
It's from the Rifleman's Creed- I don't know why. It's from Full Metal Jacket too.
Because it needs to traverse APIs. If you have, for example, a package which does auth for you that you wrap your `http.Handlers` in, it's perfectly fine for it to take a `context.Context`, but as it's a generic package, you can't just pass anything else instead (or rather, you'll need to unpack it anyway). If the `auth` package doesn't know about your `log`-package or the `foo` package containing your application code, how is it supposed to pass your loggers through?
Golang bindings for http://www.raylib.com/ , a library to learn videogames programming. Raylib is highly inspired by BGI lib and XNA framework. It is written in plain C and by default compiles to single static library. Depends on GLFW3 (for desktop only) and OpenAL, both libs can also be easily compiled statically. All raylib examples (60+) are ported to Go and there are a few more, for [raygui](https://github.com/gen2brain/raylib-go/tree/master/raygui) (immediate mode GUI API) and for [easings](https://github.com/gen2brain/raylib-go/tree/master/easings). Physics engine is on TODO list. Android support is implemented with native_app_glue and NativeActivity, without any Java code. Go bindinds also support RPi, but I tried only with cross compile, not on a real device.
You could take a look at [awesome-go](https://github.com/avelino/awesome-go). It is a list of open source go projects. I'm sure you will find some great projects you can dig into
thanks for the tip. with a list that extensive, I'm sure I'll find something :)
Python seems like the right fit for this project because of the matured ecosystem. I'm considering GoDES https://github.com/agoussia/godes. Anyone with experience using it?
Are there any areas that you're interested in and want to work on?
If you are looking for a Mobile Application you can check http://docs.kingofapp.com 
That looks awesome. I am looking to contribute more to the stats and ml space in Go.
https://github.com/corylanou/oss-helpwanted
a discrete simulation would probably fit better
I like to use Golang for simple stuff, but this line right here: &gt; Goroutines can pass error cases to channels in the same way. However, if panics occur, each goroutine is responsible for having its own recovery condition met, or it will crash the entire application. Is the reason I always use Elixir over Go for something that might be complicated. The fact that the supervision tree makes sure my entire app doesn't crash keeps my stress low.
It might sound odd, but having immutable data helps reduce errors in your code.
thanks for the detailed feedback! I did not know all that special info about slices.
Thank you!
As someone who is fluent in Go, Elixir, Erlang, Java and many of its derivatives, I can honestly say that Immutable data structures are godsend. This along with the fact that nil doesn't exist. Elixir programs are cleaner, much easier to follow and reason with, and much less prone to errors and hard crashes. And yes, finding Erlang/Elixir programmers are hard but the chances of finding good ones are really high because they are all seasoned developers who have jumped many hoops to get to Elixir. 
I think you can recover outside of the goroutine (I think the std lib HTTP server does exactly this, but I'm on mobile and can't confirm). I believe there are a few implementations of supervisor trees for Go; no idea how they compare to Elixir.
You might be surprised to learn that your way is not The One True Way, and other people think about problems differently than you do. Personally, I like Go, but I also see a lot of potential in Elixir.
As someone who has learned both (currently using Go for my day job, dove deep a year and a half ago in Elixir for about 4 months), my experiences and of course opinions: * I absolutely adore Elixir and wish I could use it every day. * Go was far, far easier to learn and be productive in (if you are coming from the C world). I'm talking days vs. still-not-productive-after-weeks-of-learning with Elixir. * Go is no fun at all to use, and I have no interest in improving my knowledge beyond what is required by work. I'm really hoping Elixir gains traction but not optimistic based on all the charts I've seen. I'm really hoping it gets bolstered w/ some Ruby/Rails folks falling in love w/ Phoenix (awesome Elixir framework)
"The philosophy is not just to write code without error checks and expect higher-level supervisors to save the day; it is to avoid defensive coding, namely to detect and correct what is appropriate, and allow other errors to cause process termination and propagate up to the supervisor. If the supervision hierarchy is well-designed, you can end up with an extremely fault-tolerant system. That's in addition to other fault-tolerance techniques such as hardware redundancy." - http://wiki.c2.com/?LetItCrash the idea being that if you can miss a surprising failure, was it really a failure? everything in erlang is immutable so no state is really lost: if the process that dies was supervised, it can redispatch its terminated child or &gt;terminate itself&lt; propagating the error up to wherever the programmer felt it necessary to add the actual error handling (if deemed necessary)
pointers are also values, so the terminology of **value receiver** is not good. A better alternative is "non-pointer receiver". Receivers are just special parameters, which means they are also passed by value. 
Go gives me the awesome and productive feeling. Elixir gives me the "this is so elegant" feeling. 
[removed]
True, but asserts in other languages (java) are simply conditional throws.
&gt; Go is no fun at all to use, and I have no interest in improving my knowledge beyond what is required by work. Why tho?
definitely not true: https://golang.org/src/encoding/json/stream.go?s=4115:4152#L169 they do the same thing in that regard. one just writes to the response for you rather than returning encodeState.Bytes()
Good idea, i will do it! Thx
recursion is just a hylomorphic exofunctor, how is this more complicated than an induced group homomorphism?
I think you can do better, how about why is elixir more fun to work with? 
Author here! I was curious about vecty the gopherjs toolkit. So I experimented on this. I don't do frontend so the UI is guaranteed to be ugly! But this can be a good project if you are looking to something more than todo list example to learn from! This is for learning purpose only,!
to iterate is human, to recurse is divine
As others have said, there's little difference technically. The three main reasons, in summary, to use the method-on-struct approach are: 1. To ensure the struct (or pointers to the struct) implement a desired interface 2. As organization/namespacing (you can only have one `func funcName(t T)` in a package, but you can have a `func (t T) funcName()` and a `func (s S) funcName()`, etc. 3. Ease of use, particularly for editors with autocomplete. If I'm using a `T` class, it's easier in many cases to write `t.FuncName()` rather than `pkgname.FuncName(t)`.
You really should get familiar with how FP works before writing comments as aggressive as that. Calling a language a "garbage pile" out of pure ignorance is really unnecessary... 
I've been playing with both too and I agree Go is much easier to learn (never used C in my life, I'm a talentless hack and slash javascripter and had no problem picking it up) but maybe it's because I never got into Ruby but Phoenix /Elixir doesn't seem all that much fun to me at all. I discovered a Go library this morning that lets you use jQuery syntax, and another that imitates Underscore - *that* to me sounds like fun. Yeah two books and several weeks playing with Phoenix and I can barely Hello World. The pipes make me want to keep trying though. 
Not the original poster, but Elixir is more expressive, which translates to less boilerplate so it's more fun to write.
Thank you for that site, I didn't even know it existed. I updated the master from dev (master had outdated code) and now it shows 100% everywhere except on the golint (no comments on functions and the mysql driver is imported as blank) and on the license. I'm still not happy with the structure, so I'm hoping someone has suggestions there.
So I noticed from the other comment that you saw the `golint` notice around mysql driver imported as blank. When I went to look at your code, I saw this https://github.com/dhenkes/forum/blob/dev/mysql/boards/get.go#L18 That had me do a bit of digging into your sql layer, and I have some suggestions, in no particular order: * Get rid of `mysql/config.go`. It's generally not good practice to store usernames/passwords in source control; usually you want to pass those in at runtime via environment variables, command line arguments, or a config file (json, yaml, toml, or other format) that you read in. (It _can_ be ok to have a `config.go` with very generic defaults, for dev/testing, but you'll want to be able to override those when you go to some form of productionized environment). * You're creating a `*sql.DB` object on every db request; that's not generally how you'll want to do it, since establishing the connection is expensive. The golang `sql` drivers usually know how to do connection pooling, wherein a _single_ `*sql.DB` will open some number of connections to your DB, then your handlers will use those as needed to make requests. So what you want to do is something like add `*sql.DB` to your `server` struct, then have your handlers pass it into your DB functions when they want to make a query. (Doing this also means you only have to run `CheckTables()` _once_ on startup!) * Once you do the previous, you'll notice that you resolve the "mysql driver imported as blank", since you'll be able to move that to your `package main`, where you'll be creating your shared `*sql.DB`. As `golint` noted, doing the `_` import in main isn't a major problem. * You also shouldn't really need to do `db.Ping()` that often; just make the query. `db.Ping()` is mostly useful to run right after you've constructed your single `*sql.DB`, as a way to verify your connection info was correct. * If you get bored of building sql commands by hand, look into the [`sqrl`](https://github.com/Masterminds/squirrel) package; it's really flexible at constructing SQL queries in a way that looks more like `go`. Also, you can probably drop your `utils` pkg; the functions there aren't really doing anything - you should be able to call the `brcrypt` functions directly from your other code. Finally, **DO NOT RETURN PASSWORDS** (even if it's bcrypted) in the User json. That data should never leave your server/database.
I will keep a close eye on vecty. Something that I would like to see happening is a good test framework around vecty. If there is any discussion around this I would like to keep tabs and maybe help! `vecty.If(someBool, vecty.Class("my-class"))` there is already `prop.Class` why `vecty.Class`? . I'm rusty when it comes to HTML, if there is any other property that can act like `class` i.e it can contain multiple values then instead of `vecty.ClassMap` we can have `vecty.PropertyMap` so it can work for both `class` and the other properties. I needed a way to add classes on top of existing ones hence `vecty.AppendProperty` which you have already mentioned and I agree it can be implemented using `vecty.ClassMap` Going through `vecty.ClassMap.Apply` i noticed it operates on the supplied classes only.It would have been better to be able to preserve the state of the class if need be. like `AddClass("a"),AddClass("b c")` and what is applied to the element is `class ="a b c"` 
Awesome to hear that. - On the topic of testing, it's a known issue / TODO: https://github.com/gopherjs/vecty/issues/29 - Why `vecty.Class` -- you're right -- `prop.Class` is basically already this. I was confused when I wrote my previous response as I was distracted with work. :) I see now why you needed the way to append properties on top; I will think about how to resolve this cleanly further in https://github.com/gopherjs/vecty/issues/80 :)
Just a quick comment: go-underscore uses empty interface parameters to achieve generics. This can be a performance killer and annnoying to factor out later on. There are a couple other similars out there too, but they also use empty interfaces. I ended up using clipperhouse go gen but it's a code generator. Great performance but somewhat non go like. Depends on your application and your preferences of course.
You buried unsubstantiated facts (garbage pile) and derogarory statements in your opinion. It made your comment seem like it was more intended to be a slam on Elixir rather than a real question.
the features are different but their usecases are somewhat similar.
Cool! I have never heard of raylib before, but seems promising! Thanks for the work! I'm trying to compile it on my mac and seems that I I'll also have to compile raylib itself, right? Anyway, I don't have any experience with CGO, but I hope I manage to run some examples. If I do manage to do the setup, I'll send a pull request with setup instructions for mac at least :)
Oh, and why did you call println and then fmt.println? Are they printing into the same i/o buffer?
Ah. Here is your answer: http://stackoverflow.com/questions/14680255/whats-the-difference-between-fmt-println-and-println-in-go To summarize, println prints to stderr, fmt.println prints to stdout. (I'm a go n00b, so it was interesting for me to find the answer... :)
It is documented at https://golang.org/pkg/builtin/#println
fmt.println was there already and then I decided to try stuff I read here: https://www.reddit.com/r/golang/comments/16t661/go_a_nice_language_with_an_annoying_personality/ &gt;You can use print and println instead of fmt.Print. It is actually better because it is easier to find debug print statements. I was able to see in my tries that println has a different format for floats than fmt.println I see in https://golang.org/pkg/builtin/#println that println is deprecated. How likely is it to be removed? Is fmt.println better and why?
By "11 times", I mean this program: package main import ( "fmt" "math" ) func Sqrt(x float64) float64 { z := x for i := 0; i &lt; 11; i++ { z = z - (z*z-x)/(2*z) fmt.Println(z) } return z } func main() { n := -0.5 r1 := Sqrt(n) r2 := math.Sqrt(n) println("result") fmt.Println(r1) fmt.Println(r2) } Only change is "10" changed into "11". It gives this result: 0.25 -0.875 -0.1517857142857143 1.5711659663865545 0.6264654836111277 -0.08583154272441196 2.869766350671885 1.347768069278103 0.4883921791049566 -0.26768761926971896 0.8000805933017697 result 0.8000805933017697 NaN With "result" at the right place this time.
You can write your own unmarshaler using xml.Decoder, or use go1.8's new property of allowing assignment between same structs with different tags.
indeed. But there is not a definition for "value receiver" in spec.
I did not really want to write my own unmarshaller, but structs in 1.8 sound worth pursuing. TY
fmt.Println goes to stdout, while println goes to stderr. So, stdout is buffered, and stderr is not. That means when you print to stdout, it doesn't actually appear until the buffer gets flushed. It's more efficient that way. Whereas writing to stderr appears immediately. If you write to both, that means stderr stuff can randomly appear in the middle of stdout stuff, at a spot between buffer flushes. 
I have no advice, but I can tell you this from a long experience: visualizing the process is probably going to take most time, both during programming and during runtime. Choose your language, library and development environment based on that knowledge, i.e choose a combination that makes visualization easy. If go doesn't offer that, move to another language.
While this is definitely a good post, it leaves out how to reuse a TCP connection. The method discussed is useful if you only send large messages in bursts with long pauses. If the messages are shorter or you need to send continously you need to also include a header or method to know when the message is over. One solution which is employed by HTTP is to treat a special character sequence as the end of a message (`\r\n`) The other is to send a small header that encodes the length of the message so the client knows when to stop and start receiving a new message from the stream.
Thank you for the suggestions, I will start implementing them as soon as I can. Is the folder structure ok? I'm still not quite happy with it but we wanted to build it as modular as possible so we could swap out MySQL for MongoDB or Couchbase later down the road if we wanted to.
If you only want a single type for both APIs, you could give the type both fields, and during runtime check if one is empty? type Response struct { RedProducts []Product `xml:"GetRedProducts&gt;Product"` BlueProducts []Product `xml:"GetBlueProducts&gt;Product"` } This way you can infer the XML mapping by checking if `len(resp.RedProducts)` is 0 or not. Honestly, I think the Unmarshaler should have some kind of syntax to deal with multiple fields, but that's unfortunately not the case (Not as of 1.7.5, and neither does 1.8rc3).
Yes, for now you need to compile raylib, it is not difficult. I will later try to include raylib C source in Go code. I saw a couple of examples for that, in glfw3 and in libusb bindings I think.
This doesn't happen normally. It's a playground bug. Please file an issue. Thanks. 
Put the C files in your package's directory and Go will take care of compiling them to .o, saving the .o in the compiled Go package, and passing them to the final link. 
Yes, I know about nuklear bindings. Raylib also have something similar https://github.com/gen2brain/raylib-go/tree/master/raygui. It is a single header in plain C version, in Go it is just rewritten.
Thanks, I will try. Say I want to move C version to internal/ dir, can I just add that dir to include path -I and include .c files. Will that be the same, it will still compile them?
Thanks a lot, it works! It does look a little messy, but more convenient.
A general point about the decoders in the encoding library: they are quick, convenient decoders for when they work. However, it is simply unavoidable that sometimes you will have to write custom code. That's not really about Go per se, its just that the format's are too powerful to be convenient mapped anywhere, so a convenient mapping __must__ also oversimplify, and combined with fact people do crazy things with these formats, you sometimes will have to do manual work. This is especially true when you get things like keys in JSON that have different JSON types, depending on the mod of the emitter. Or an array of heterogeneous types. Or tag soup in XML.
We can have varying options. We just can't pretend we're simply "stating an opinion" when there's enough subtext to know otherwise. Unless you're an Alt-Right Trumpeter. Then you can just pour crap out your ass-mouth and state it's the truth. Just stating my opinion. *(See what I mean.)*
Well, here two prints to stdout appear before a print to stderr, when code order would suggest otherwise.
I would like to but my github account has identifying information while this reddit account doesn't and is meant to stay that way.
Ok, there is no need anymore to compile raylib. It is now bundled together with Go sources. You only need to install GLFW3 and OpenAL. I will add instructions for that in README for some common platforms. 
Thanks! I got inspired when reading a elixir book, this was one of the exercises. Thanks for linking to your source I'm going to take this at the base for expanding my issuetable if that is ok with you?
Having the handlers split from the mysql / database pkg is a great start. Swapping down the road will always be some amount of work - there are things you could do now to help (using interfaces instead of concrete structs in your http handlers, for example) but you won't lose much by putting off that sort of switch - it's the same amount of work now vs later, more or less.
According to the README: &gt; gocryptfs uses OpenSSL through a thin wrapper called stupidgcm. This provides a 4x speedup compared to Go's builtin AES-GCM implementation - see openssl-gcm.md for details. 
That seems like an algorithm awfully prone to swastikas..
The recovery is not "outside" the goroutine.
Pigosat does this, by compiling in the picosat source https://github.com/wkschwartz/pigosat
I mean, take any logging framework from Javaland, except for logback which seems simpler and easier to setup. They are all a frigging nightmare to use, then you have dependencies which take over logging control (like Spring Boot) and you just set yourself up to a world of pain when the subject is logging in your project. Logging should be easy to use and configure, it isn't that complex of a problem domain most of the time. I had to setup a project with Hibernate, Spring Boot, and 4 other dependencies that all had their preferred logging systems, yet they supported all of the major frameworks through slf4j (simple logging facade for java, which is anything but simple with its horrendous documentation). Setting up logging was a horrible experience, and in the end, Spring took over logging control once loaded, giving me control over it via a set of convoluted classes. Compared to that, logging in Go is a programmer's paradise.
I'm glad you did something cool and interesting in Go, but here's my complaint about structured logging libraries (in general): my code base comprises more than just Go. I also have Java, Ruby, JavaScript, Python and a bit of C#. I need logging in all of these, and I need the logs from all of them to fit the same schema, 'cause ES and Kibana don't care where the logs come from. I either need a library that goes across many languages, or I have to fall back on standards that devs follow when logging. 
Perhaps. I've found there's always something that I want to log when debugging in development, but that would generate too many log lines in a production environment (e.g., logging every message coming off a socket). The levels also provide convenient alerting levels - error messages trigger alerts (or at least trigger a bug creation for investigation). It's _also_ useful to be able to send, say, detailed log info to file, but only info level items to stdout, when debugging/dev'ing. That lets you organize things so the info level logs "tell the story" of what's going on, but you still have all the crusty debug info if you ever need it.
I think you can't go wrong with picking Go here, its really excellent for writing back-end services. I recommend you invest a day or two into looking into the language, write a simple web back-end and take a decision from there. A good start would be to follow the official tour at https://tour.golang.org/ 
Thanks, doing that now!
Good advice I think and something I am considering as well. There is no codebase yet and I am actually interested in learning Go (and even my python skills are not up to scraps for this job). Looks somehow good to start with a clean slate. It will take longer to ship out an MVP and that may or may not come back to hurt me. Fact of the matter is that this particular product hinges on scalability (even without taking 100,000 users into consideration) so Python might be the bottleneck really quickly. Hope I am making the right call, but walking away from this with a solid knowledge of Go would still be a (bittersweet) win.
s/[Gg]olang/Go/g
I figured that python's weakness (apart from general scalability, which may not be an immediate concern) would be in async operations. I my case that would be having a stack of API calls to third parties being executed and reported back when complete (or failed). It seems that Python (edit:-core) recently added an event-loop for async operations (https://docs.python.org/3/library/asyncio-task.html). Would that be a viable option? This might not be the right place to ask :)
async/await syntax was added in Python 3.5. It works really nicely and solves the async callback nastiness of the past. Might also be worth pointing out that Go doesn't have an equivalent so async calls must be handled explicitly within your goroutines. Finally, two new Python libraries sanic (web server framework) and asyncpg (postgres database driver) base themselves on the new syntax and outperform native Go implementations in some benchmarks. 
Well I don't know what your web app does in detail, but unless it's doing a lot of processing then I would expect your database to be the bottleneck for scalability. In general I would advise against premature optimisation. As long as your approach isn't fundamentally flawed (and choosing Go over Python or vice versa is not going to create a fundamental flaw), best to develop as quick as possible and solve problems as they arise and not beforehand. 
Great pointers, looks I will stick to what I know for now and save Go for a later date. This was actually my biggest concern, but I have not followed Python development for a while. Seems like it may the right tool for the job after all ;) Y'all have really gone above and beyond what could be expected from /r/golang. Really hope this thread will be helpful to others as well. Now if you excuse me, it seems like I have some catching up to do.
No problem. I don't want to put you off Go; I would definitely recommend learning it at some point and there are reasons why you might choose Go over Python. It's just that async operations and scalability are not in those reasons, so it wouldn't be correct to recommend Go over Python when you already have a head start with Python knowledge. 
I maintain a small todo list manager, any modifications are welcome :-) https://github.com/thewhitetulip/Tasks
Still figuring out what it will do in detail myself ;) Basically registering items with users and some reporting based on that. There will not be that much processing and it will be roughly lineair with growth. Sticking to Python/Postgres for now and will start optimising or switching out pieces as need arises.
I had this same confusion a long time ago, you don't have to do anything more than vueTemplate.Execute, take a look at https://github.com/thewhitetulip/Tasks-vue I am writing a tutorial, but haven't got time recently to work on it, the link is here, http://github.com/thewhitetulip/intro-to-vuejs/ Do ping me if you need any more help! With Vue, the thing is, you render the html template and you run the RESTful API. Then, the Vue frontend will take responsibility of placing http requests and stuff you don't have to do that (routing etal) in your Go templating syntax
Learning Go is great idea, however beginning what may be a critical app as your first Go codebase may not. Take a look at your first few weeks of Python, do you want to be working with that guy's code for the next few years?
So, you want to make an anonymous bug report? Why don't you make a new GitHub account just for anonymous bug reports? I fail to see why anonymity is important with such a harmless bug report though.
If you don't want to leave 2.7 gevent, twisted (pythons equivalent to netty), thespian (actors for python), tornado are all options. But I mean let's be honest here no matter what you do cpython's concurrency and parallelism story is never going to be very good no matter how many work arounds the GIL people come up with. I like python it's a great learning and prototyping tool but it's just wasteful as hell to use it at scale, but assuming that you don't have a lot of computation going on and everything is just IO, yes the options I gave you for python scale well enough. 
I agree that existing knowledge may outweigh any performance benefits. It doesn't sound like the OPs load is going to be problematic. We ourselves use Python for our web application with gunicorn, and it does just fine. Throwing a couple more machines at the problem is perfectly reasonable. I was just speaking from experience having worked with Python under load. In my opinion if you know Go, you're better off using it from the beginning. Async programming also has the issue that it introduces an entirely different programming model to your code. As your program grows the diversity of programming models makes for very complex code that ends up being largely unmaintainable for new developers. Ruby, nodejs, Java and c# all have the same problem. (ie am I in async world or blocking world? Do I just write two implementations of everything?)
Just how? How do you even need to debug `try` macro?
I tried to use vim but I got terribly confused by the package manager and extensions for go. Is there anywhere one would suggest pointing me towards for a good "start from scratch and learn it to be effective" type tutorial? Also, is it *really* good to use on the Mac? Because I tried to install it on Mac through brew and it constantly complained about missing dependencies and such. Sublime -- installed it and it worked. But I don't feel like I'm a power user. I see what people do in vim and I'm jealous for sure.
As `try` expansion is really simple, and there are now new error messages I do not see how would it come that Go boilerplate would be easier https://is.gd/29G7NY
Use node.js. Go is imperative programming.
Anonymity is something I want for this reddit account.
Keep the politics out of this subreddit, please.
&gt; Might also be worth pointing out that Go doesn't have an equivalent so async calls must be handled explicitly within your goroutines. I'd argue that goroutines *are* Go's equivalent of `asyncio`. They're super-lightweight, so you can easily start hundreds or thousands of them, which is the same problem with normal threads that async is supposed to solve. The main advantage async has over goroutines is that async programs are single-threaded, so you don't need to worry about locks and other cross-thread synchronisation issues.
Ha! 
On it! 
Sure! 
A screenshot of the config and some of the commands in action: https://punpun.xyz/sg9y.png This is my first "big" Go project, not a lot of people use CRUX Linux so I was hesitant to post it, but I'm quite proud of it and I'd like feedback, so whatever. CRUX is a source distro, and makes use of ports like most BSDs. The default CRUX "package manager" only builds and installs ports, but there is no real dependency management. There is a tool called `prt-get` that does most of what my tool does (and more), but I'm the kind of person who like to write his own tools :). Anyways, since this is my first project I'd love some feedback/criticism. For example, am I using packages right, or is splitting a project up in smaller packages not really something you do for smaller projects?
It looks great! The only thing I noticed is in main.go, where you can move all of your `os.Exit(0)`'s to a single one _after_ the switch case. You also have too many comments [in](https://github.com/onodera-punpun/prt/blob/master/cmd/depends.go#L30) your [code](https://github.com/onodera-punpun/prt/blob/master/cmd/depends.go#L49), with [some](https://github.com/onodera-punpun/prt/blob/master/cmd/depends.go#L20) of [them](https://github.com/onodera-punpun/prt/blob/master/cmd/depends.go#L37) being [redundant](https://github.com/onodera-punpun/prt/blob/master/cmd/depends.go#L78). 
Just use a desktop toolkit. I'm currently using lime-text's fork of go-qml, it's working fine for my usecase. There are other options as well, like andlabs/ui for native widgets, therecipe/qt for Qt bindings, golang-ui/nuklear or aarzilli/nucular for nuklear bindings/reimplementation respectively... and these aren't the only ones.
This is awesome! However, you may want to add some restrictions when hitting the randomize button. I created a [monster.](https://storage.googleapis.com/gopherizeme.appspot.com/gophers/98129bded0dd8c7a49395c95cfb0664362b27566.png)
&gt; You can't simply replace bits of a Flask app with asyncio. You have to either run them separately or run Flask app instances in an asyncio thread pool. Uhm yeah, I was wondering. Have to wrap my head around that one. edit: looks like there is something like that out there, but not sure about potential tradeoffs: http://flask-aiohttp.readthedocs.io/en/latest/coroutine.html
Yeah, something with 4 arms? 
What do you mean by clashes? Naturally, most of these things use lots of cgo, although Nucular is pure Go outside of its dependencies (gomobile and OpenGL interaction, although the former doesn't affect desktop apps). Lime text's QML frontend (if I understood correcty from a quick glance to their code) seems to do a lot of the UI logic in the Go code. This is a bad QML practice even if you're using C++ due to the big call overhead. In my case I keep communications to a minimum and it works fine. But then again, I don't have much going on yet, I might hit a performance roadblock at some point. For the moment, it laughs in the face of Electron performance-wise.
&gt; without needless changes Counterpoint: In my experience the best time to learn a new language is at the beginning of a project. Learning a new language is a huge benefit -- even when you don't like them. Best way to learn about programming concepts, independent of language features.
This is so silly. I love it. 
Apparently I'm a hipster.
&gt; Have to wrap my head around that one. The fundamental issue is that Flask expects to handle one request at a time (a lot of request state is process-global) and that you'll run multiple instance of the app to handle multiple requests at the same time. asyncio (or any other async framework) by comparison, is designed to run hundreds or thousands of requests in the same instance, and thus needs request-scoped data. &gt; http://flask-aiohttp.readthedocs.io/en/latest/coroutine.html The [GitHub repo](https://github.com/Hardtack/Flask-aiohttp/) says EXPERIMENTAL in rather large letters. I wouldn't… There is also [Klein](https://github.com/twisted/klein), a Flask-like framework based on Twisted (i.e. async). Unfortunately, its documentation follows the long-standing Twisted tradition of being, well, shit. To understand Twisted/Klein documentation, you must first understand Twisted/Klein…
Thanks for this, I will give it a go!
As a library, the API is too much geared towards your CLI. If used as a library, I'd probably not want to write it to some fixed path. It's not even making sure that paths are not conflicting. IMHO, it should look more like this: func (d Dither) Apply(input image.Image) (output image.Image) I then also wouldn't do the processing in Apply itself, but instead do it "live", when calling one of the `image.Image` Methods. This would allow the user of the library to then decide themselves to select parts of the image, to pass it to an encoder of their choice (or display it directly on screen), apply other transformations on it… In short: It would facilitate the power of go interfaces.
There's a button missing: "Order stuffed gopher now"
Can you also add a FreeBSD Beastie shit?
Please comment with feedback!
P.S. I'd appreciate if someone with more rep could edit my images in the stack question.
You can use mod_proxy in Apache as you did with PHP. If the 3 "apps" do the same thing you can simply use mod_proxy_balancer. If you have different "apps" you can setup virtual hosts and setup proxies for them. Same thing in Nginx. EDIT: I assume of course that you use http.ListenAndServe() :-)
This was a great intro to serf for me! Is there a reason not to use serf custom events for the notifications?
OMG... We need a Three Gophers shirt so bad. 
I decided that, when you'd wanted to extend the database, it's good to keep everything contained. Basically -&gt; don't make the membership module replicate data too. Just use it for membership and related things. 
Well, by having a good API, you can serve both purposes :) Note, that there is really nothing preventing you from doing *both*, i.e. also adding a helper that then writes out the image. And if you don't directly do the "lazy evaluation", it should also be fairly simple to implement the more general API :) FWIW, I'd be fine sending you a PR with those changes, if you were willing to accept it but are not interested in doing it yourself.
Give https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1#.jhvas7vrr a read, the post describes the de-facto way that projects are structured in Go (not the kubernetes way, which is different)
What a surprise the SO nazis have put it on hold. I'd use Docker and Docker Compose to create your stack. It takes a little learning to do but in the long run, it would be much simpler to develop and deploy.
I think https://jwt.io/ could be handy. EDIT: With https://github.com/dgrijalva/jwt-go for golang.
I used jwt in a previous project (not written in go) and wasn't quite happy with how it worked. I want to manage expiry date per token basis and make them invalid if I chose to do so. I was hoping for an easier solution there. I did some research and found the crypto/rand package, so what I was thinking now is to generate a random string (256 bits) and save that with the username in a cookie. Every time the user sends a request, the random string (token) and the username are validated in the database and from then on the api does it's magic.
You still can do the same thing with jwt and https://github.com/satori/go.uuid `uuid.NewV4()` Your user claims to be `foouser` with an UUID. When you want to invalidate this token you just have to add it in a blacklist for the duration of this JWT token. Your middleware, after checking the JWT claim can check if this UUID is blacklisted in your database. Other solution : use short live tokens
&gt; I want to manage expiry date per token basis and make them invalid if I chose to do so Ok, so do that! No reason to re-invent something considerably less good than JWT to add a tiny bit of functionality atop it.
I disagree. Pitting them against each other helps understand how large the speed advantage is to weigh properly against the drawbacks.
Don't use JWTs as session keys; they can't be revoked. You could, I suppose, use a JWT to _sign_ an existing session key — but that's pretty useless if you're already using a cryptographically secure key, which you should be doing anyway.
Thanks, this worked and now I don't get the runtime error. But the browser displays `open test.txt: no such file or directory` instead of the `/view/test.txt` contents. And I definietly have the `text.txt` file inside the `view` directory
That's exactly my concern about JWT as well. It's basically a signature for a payload and not a login/session token. If you'd use it for database-less authentication, you'd be forced to use whatever expiry time you would set into the JWT payload, and couldn't expire a session before that time. Well, technically, you *could* as you have the complete payload,... but then what's the point of JWT if all you care about is a session ID and have to actively check blacklisted sessions or whatever. I'd also drop the username from the cookie, and just store the UUID. It seems redundant when having a server-side session service.
I use nginx with fastcgi, that way I can lean on nginx caching if needed, or running multiple instances of the same app when deploying so there is zero downtime on a single server. I also use supervisord to manage the state of the applications as well.
In my experience you do not want to check in vendored code for non-main packages, as this can cause type conflicts between types in vendored code for difference packages when you try to combine them. You DO however want to leave around a metadata file that contains the external packages used and what revisions they were on. They have a `glide.yml` and `glide.lock` checked in which provides this metadate. If their was a main package, then that should have the vendored code checked in, as you want all the code to build that main package to be around. They are using glide, but the [govendor page for package developers](https://github.com/kardianos/govendor/blob/master/doc/dev-guide.md) has a pretty good explanation of how to vendor when you are developing a non-main package.
I changed it to `filename := "./view/" + title + ".txt"` instead, and it works now. Not sure if that's a good idea. I wonder why the exercise is so inaccurate. 
Hi! I don't have a ton of time at the moment to do a full review. But this looks really cool! I wanted some way to get my Google Analytics data in a golang. I will probably use this and so I will do a bigger review. Two initial things, I don't really like that the repo path and the import are different. i.e. you got the repo as import "github.com/santacruz123/go-googleanalytics" but the package name is `ga`, so you must refer to it by `ga`. A rename might be good. Two, looking at the `godoc` of your code does not explain much, it might be good to add a few doc comments. https://godoc.org/github.com/santacruz123/go-googleanalytics Three: your naming is also a little confusing. What is a `ga.HelperRequest`? Think of `http.Request` or `bytes.buffer`. Names can be really useful when you choose good ones. See this page: https://golang.org/doc/effective_go.html#names That is all for now. Looking good! Please let me know if this info was helpful! I love seeing small cool go packages like this.
It is not inaccurate, you have not gotten to the end of the example yet. They specifically talk about checking errors part way through it. Once you get to the end you will not have these problems. They are showing you what problems you will run into as you develop this kind of "wiki". See the code at the end of the exercise: https://golang.org/doc/articles/wiki/#tmp_13 https://golang.org/doc/articles/wiki/final.go
what specific courses did you find the most useful for Docker?
&gt;What I don’t know is why types 8 bytes or smaller aren’t stored directly in the second half of the interface{}. Anyone know why? They were for the first couple of versions of Go, but at one point it was decided to improve the GC by keeping track of what was and wasn't a pointer, and the simplest way to do it was to make interfaces uniform. I'll search and update if I can find a link to something more concrete. Edit [Go 1.4 release notes](https://golang.org/doc/go1.4): &gt; The implementation of interface values has been modified. In earlier releases, the interface contained a word that was either a pointer or a one-word scalar value, depending on the type of the concrete object stored. This implementation was problematical for the garbage collector, so as of 1.4 interface values always hold a pointer. In running programs, most interface values were pointers anyway, so the effect is minimal, but programs that store integers (for example) in interfaces will see more allocations. 
Name should be parsed carefully. 
I plan to do that in the near future, at the moment I feel like I don't even know what I don't know. Going through exercises step by step helps to understand the entire process.
Have you looked at [Exercism?](http://exercism.io/) it's a rather awesome project it doesn't do the step by step process but runs small exercises over various topics.
I doubt your bet, show me the code.
Does this get into any trouble with the garbage collector? I would have been worried that only having the elements refer to each other might end up with the GC dropping them after adding a few elements. 
I guess l: i-shell or is-hell
You weren't _inspired_ by godash's code, you strait up copied it. D:
Create elements on the heap, store them in non-consecutively on the heap, and name them a stack!
Anyway, it's not a good idea to have a reference to the stack in each element. 
Haha. It's i-shell.
That's an old trick; it doesn't work: the chore to prove "Y is better than existing X" lies on the Y's inventor, not the other way around. So yes, it would be cool to see comparative benchmarks. This way, one puts their money where their mouth is because surely anyone can claim anything in the title of their source code repository. Hence I find /u/pdq's questioning to be perfectly valid.
Good document. &gt; Handle Errors &gt; See https://golang.org/doc/effective_go.html#errors. Do not discard errors using _ variables. If a function returns an error, check it to make sure the function succeeded. Handle the error, return it, or, in truly exceptional situations, panic. There are simple cases where ignoring the error makes sense. Example: `strconv.Atoi` and `strconv.ParseBool` returns `0` and `false` if an error is returned. So you can ignore it if `0` or `false` is the default value you want in case it could not be parsed (user input). &gt; Do not define interfaces on the implementor side of an API "for mocking"; instead, design the API so that it can be tested using the public API of the real implementation. I like this one.
Interesting. What is rendering the HTML/CSS?
probably a `WebView` listening to JS messages. this feels like react native, but i'm wondering how much of the code written actually ends up being go as opposed to JS/HTML/CSS. regardless, it's really cool that it's actually being done.
It would allow you to do the heavy lifting in go and treat it like a locally running "server".
You can inject what ever storage you like. The Router writes to an interface because an io.Writer must be registered with the Output method. Doc: https://godoc.org/github.com/szxp/log#Router
There is more than one way. The following pseudo code it's just an example. With a structure, like the Rob Pike's bufio.Write http://bit.ly/2jRquT1 type runOrRollback struct { Tx *sql.Tx Err error } type runFunc func() err func (ee *runOrRollback) Run(f runFunc) { if ee.Err != nil { return } ee.Err = f() if ee.Err != nil { Tx.rollback() } } // Then use it r := &amp;runOrRollback{Tx: tx} r.Run(someMethod) r.Run(someOtherMethod) r.Run(aFinalMethod) if r.Err != nil { return err } tx.Commit() With a function: // Function type type runFunc func() err // Implementation func RunOrRollback(tx *sql.Tx, funcs ...runFunc) { var err error for f := range funcs { err = f() if err != nil { tx.rollback() return err } } } // Then use it err := RunOrRollback( tx, someMethod, someOtherMethod, aFinalMethod ) if err != nil { return err } tx.Commit() In a weird but very compact way: type runFunc func() err for f := range []runFunc{ someMethod, someOtherMethod, aFinalMethod, } { if err := f() { tx.rollback() return err } } tx.Commit() 
Download a release candidate, or build Go from source using the `master` branch.
we need more Objective-C!
Could write it all in Go and build the frontend bits with [GopherJS](https://github.com/gopherjs/gopherjs), especially with something like [Vecty](https://github.com/gopherjs/vecty). :P
Isn't this the premise behind electron and react native? How does this differ (besides being platform-specific)?
What about RubyMotion ?
Isn't that how most Go programs do user interfaces? Especially considering all the servers. Not that the web stack is a pleasure to program in, but then, I don't know any GUI framework that is. Being interaction is just a more complicated design space, and nothing else is as well supported and easy to deploy on all the different platforms. The downside of having different browsers with variable support is a bummer, but I already paided for most of it by making webpages since ie 6. Other platforms, such as Android, are equally plagued. I have found html doable for layout, if I convince the boss for it to look more like a webpage than a native app. I have found js to be a stable language, as long as I keep the latest and hottest away from any serious work. I do not use any frameworks, transpilers, or js processors of any kind. All my js are written exactly for what that piece of GUI need. The view source feature will always have a special place in my hart, more so than any short comings it may have. 
There are some similar things available with RAML (http://www.raml.org/blogs/mocking-service-walkthrough) and other specs that might be worth looking at.
Admittedly, it was about 5 years ago now. I did a really small goofing around thing last year, but that doesn't count. Does screen size just mess with everything?
Wonder what kind of filesize overhead this produces
I am curious for the use case ? Because its a one off dyno anyway. So any static element (file or db server) is outside the dyno anyway ? Then why not run the script(s) locally ? 
http://gopkg.in/santacruz123/ga.v1
I got all of your art requests up. Thanks for all the love btw. 
Use of Golang and all its awesome feature right out of the box: - code formatting - unit testing (with code coverage) - benchmarks - memory profile Potentially portable on IOS, Android, Linux and Windows. Note this is a very young project but it had to start somewhere.
I have a test app which do some web request and display photo content, the .app generated is under 10MB. Here is the link to the .pkg: https://github.com/maxence-charriere/jubiz/blob/master/bin/jubiz/Jubiz.pkg (might be blocked by gatekeeper) 
This is a fantastic collection of tips. I have been trying to prevent test bloat and it is good to have a single place we can point to. Subtests were missing, which can eliminate the need for "suite" packages. Perhaps, it would be good to add a wiki page to the golang project, similar to "Slice Tricks".
Writing any useful test helpers in testing.go should instead be placed in the _test.go file with the proper package name, which gets conditionally compiled when running the test program. This trick gives you tremendous flexibility because you can export details that you wouldn't have done if it was isolated to non test code. It is also a trick that is used a little bit in go standard library.
This is pretty amazing if it can create a single binary portable app that is self-hosted.
The difficult thing in windows is I want to use the Edge engine which is available only in UWP apps. The reason for this is the rendering performances is better in Edge, animations are smoother. I also want it to be available for the Windows store. The problem with UWP is the api is very closed. I can't call it directly from Go. But I hacked something and I'm currently able to make Go call Microsoft's strange C++ functions. Now need to find way to make this same c++ able to call my Go functions. THis would bring good hope to make it works this way. Otherwise, using Chromium Embedded Framework or Webkit would works too.
it does what it does but its a wrapper around cocoa touch which is really what you end up working with/against, not the obj-c language
It will not. They can optimize the memory allocation, but they can not make `[]string{}` return a nil slice; it would be considered a break of the Go1 compatibility promise.
This is the case on MacOS right now.
They did not fix that? I'm surprised. If I remember correctly there was an issue for this.
Of course you can revoke them, either by requiring them to be free freshed frequently and/or blacklisting.
Which part are you disagreeing with? The advice I linked to specifically talks about the memory allocation.
Thanks to have indicated the link to msackman/gomdb, I had forgotten it.
https://tip.golang.org/src/encoding/json/stream.go?s=4115:4152#L169 seems unchanged on tip as well, so it doesn't look fixed. You might be thinking of these issues: * https://github.com/golang/go/issues/11046 * https://github.com/golang/go/issues/7872 which have been constantly punted since they were filed back in 1.4, so I wouldn't bet on it making 1.9 You can see in the tip code they added a Token() method for doing incremental parsing though.
Requiring refresh means you can't revoke them except after a delay. You'll want to keep the TTL low enough so that you actually can revoke them, but by doing it this way you're essentially turning the JWT into a cache. The only way to revoke, without any delay, a JWT would be if you embedded, as part of the claims, an actual ID that could be revoked, and then check that ID on every server request. But if you're doing that, why are you wrapping it in a JWT in the first place? The whole point of a JWT is that the claims can be trusted independently of a central authority (the signer) — i.e. so don't need to ask the authority whether the JWT is valid. If you need ask the authority whether the embedded ID is valid, you have defeated the point of the JWT. My preferred solution is to force all outside traffic from browsers and API clients through an API gateway, which uses cryptographically secure, revokable session keys. The gateway turns the key into a very short-lived JWT, which can then be used freely between the internal microservices (where traffic can be trusted to a larger degree and where you want to avoid having to look up the identity of the caller on every request). It's a nice, secure, scalable solution. 
I see what you all mean. I commented out the last two lines in the main function then ran it again. The program exited without returning anything. So to be clear fmt.Println() writes to stdout fmt.Scanln() reads from stdin Thanks again!
Thanks, that's awesome! I'll definitely try the project for my next Mac app
&gt; by doing it this way you're essentially turning the JWT into a cache. Or a stateless authentication token for a stateless application layer... &gt; The only way to revoke, without any delay, a JWT would be if you embedded, as part of the claims, an actual ID that could be revoked The JWT or a hash of it would suffice. &gt; If you need ask the authority whether the embedded ID is valid, you have defeated the point of the JWT i.e. Throw the baby out with the bath water...
I am here to learn, can you expand on that thought? Maybe provide a link
I don't have any more excuses for not knowing what a stack is, but curious if you write blog posts as well to help share your knowledge. It would be nice to more existing programmings pay it forward as well, perhaps you could provide some more explanation for people like myself eager to learn.
The “golden files” trick is actually pretty smart. I made a small helper program at work to generate text files, and it felt awkward including the _exact expected output file_ in a multiline string in the test file. With a golden file for each, this would have been much simpler. It is, however, quite difficult making a good error message that shows _where_ in the file your problem is. I found that when a test failed, it was helpful to write the actual output to a file, and then just open both files and compare them. "Test XXX failed. Actual output did not match expected output. Actual output written to file PATHTOFILE/XXX.act."
You can compile it from source as well. 
Sure but you can at least write Ruby in whatever editor you choose. Yes it's not objc but at least you do not have to deal with xcode.
[SQL Boiler](https://github.com/vattle/sqlboiler) is a Go library that generates models in Go based on your database schema and enables you to query them. It sounds like this could be pretty useful for you. 
xcode actually is pretty good i like it. more than sublime. i just wished apple let u customize it more. theyr not in the code editor business though. and for mac os app development xcode is terrific imo.
100% agreed regarding testify/assert (and testify/require), they avoid so much boilerplate.
Seriously? I was building bsd jails and zones before docker was invented and I can tell you we do not want to go back to that. Firstly chroot is, by design, not secure. There are well known ways to escape it and Linus himself has said they will not be fixed. Secondly the whole mechanism of building and distributing containers is flipping awesome. Zones came close, you could build them on a zfs filesystem then export them as a tarball but they were nowhere as easy to build and rebuild as docker is. Finally namespaces are useful for seperating processes and network stacks. Zones again had this, but none of the manegement tools and APIs that docker has. Without this one process can access or interfeer with another.
To me this sounds like a work-around of a deeper rooted problem: your package structure and dependecies need work. If you have circular dependencies, restructure your packages. If you're really unable to fix the problem elegantly (I doubt it), you could resort to this trick, but try to structure it neatly first.
testify/assert is not a framework, it's a library. Not really any different than those helper functions they link to.
It have the same feeling. Just because you can fix your circular dependecies with borkers, doens't mean you should. It does not feel zen to me. Code becomes harder to read and reason about. 
If you are interested into Stacks in Go, you might want to check [piladb](http://www.piladb.org/), a small in-memory database written in Go that stores data in Stack data structures.
Hey, can you give example to this? Because as I understand idea behind testing.go files is that other people importing your package can use your mocks. For example, you are writing a DB driver and so you created a DB mock, let's say in memory DB variant for your tests, putting it into testing.go file allows your DB driver user to use this mock in their own tests. 
If you just use assert you could take it from Ben Johnson published functions ([link](https://github.com/benbjohnson/testing)). There is also *ok* and *equals* functions. As the go proverb goes "a little copying is better than a little dependency".
The "check for new version" feature is a nice idea. Using github to do it is even better, because it doesn't come across as spying on users (if it were phoning home). 
By "apps" the author means programs. No connection with mobile, Android, etc., in the article.
I like the motivation, but I'm not sure that this is the approach I'd like best... it seems like it would be very hard to read your code before generation. Now, my typical approach of using text/template doesn't exactly look readable before generation either, so I concede we need something a bit nicer.
For simpler examples templates are for sure the way to go. I think as the complexity of your generated code increases, something like jennifer will start to make more sense. I had a couple of goes at this before settling on the current architecture. Perviously I tried to enforce more compile time checking of code, but it proved too complex. I think this strikes a reasonable balance of using the Go syntax to enforce as much integrity as possible... You build statements more or less token by token, but anything that could be expressed as a list is handled by group functions, so you get nicely indented code, and it's impossible to miss a closing bracket. This is by no means a solved problem though, and I'd love to hear your ideas on how it can be improved!