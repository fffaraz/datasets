Does this work with Firebase cloud functions?
I think your quick start code has a bug... if it fails to acquire &amp; returns an error it will still call .Release().
 for item := range iReturnAnChanOfItems() { # do something with item }
This was the answer I was looking for , all I got was downvoted and humiliated
Not sure if this would help: https://gist.github.com/kkirsche/a2243352c46e93459bb643c397f56d1c
without node.js shim? WoW! great news!
Thanks for clarifying! Yes, going to bed was the best decision :) I completely overlooked the `/internal/` part of the import paths used in the test files... 
This is a simple tool. Let's keep it simple. For my local development, I use [http-server](https://www.npmjs.com/package/http-server). I would want `serve` to be like that. Pass ssl certs and keys through a flag, enable https. Done. Why does port become tricky ? This tool is for local development. I should be just able to create certs using mkcert and pass them to this tool. Do not do any magic under the hoods. - Ignore letsencrypt. - No need to redirect. Enable https if flag is set. Otherwise http. Don't overdo things. - If you want others to import this, then sure, go ahead and expose `server`. But I think that is not needed. 
I completely agree. With security in mind, the best option would be to construct the query on the server, with all levels of taint-checking applied. Remember [little Bobby Tables](https://xkcd.com/327/) :-)
üëè Congratulations on the release :)
Thanks for clarifying. I was thinking of some hard limit due to the use of the LSB(s) only. But you are right, if the carrier is a jpeg, I cannot tell in advance how large it gets after uncompressing.
thanks guys!, I hv found a solution for this
503 :(
Nice! Anyone using this for non-Single Page Apps? (e.g. angular, vue, ...)
Hello, great article. It is small typo in auth method section PublicKeyFile which point to private.key I assume for auth on remote system you need to provide private.
This will probably get down voted into oblivion, but honestly... If we're going to be talking about an "understanding of Go", I think you also are missing the boat by simply ignoring the [Golang Code of Conduct](https://golang.org/conduct#values). You're not going about actually providing criticism or trying to help, you're just saying how wrong I am, and how bad this code must potentially be because of it. I always appreciate learning things, and would love to improve my code and libraries overall, as well as my general skill set and knowledge as a Gopher, but rather than be constructive and point this out to me, you're trying to utilize Reddit as a forum to explain how wrong I am, though mostly baiting me with your initial question, and prove how much more you know. Then, disqualifying something I tried to build and provide to the OSS community, off 3 lines of code that literally don't matter. To answer your question without more thought, ultimately I took about 0.2 seconds of thought to write this particular code, and it was a convention that I'd [simply seen](https://github.com/unrolled/render/blob/v1/render.go#L124-L130) in the past, by much more popular package(s), and had followed the convention. Additionally, it made logical sense to do this, do to an understanding of variable shadowing I'd had, which was ultimately incorrect (you'll see more on this in the thread with @Tserkovish, who was able to provide me constructive information without attacking me). Thank you for taking the time to make your point though, and I'll be sure to improve my package because of this.
Thank you for this. I'll make the change to this package shortly, and be sure to correct my thinking going forward.
There are couple of free books which explain this pretty well. One of them is the following: https://thewhitetulip.gitbooks.io/webapp-with-golang-anti-textbook/
Does your second server keep hold of the linux session or does it get forked off into another process?
I think you misunderstand what I'm saying here. I'm not saying it does not have an initial value, just that I am not setting any particular values to be the initial value. In this particular case, the zero value just happens to also be the value intended, and I intend to address this.
I don't think so, it only runs as long as my first program is still running, once I close that they both close
I mean almost no other language has an ssh implementation out there other than C and Go. That‚Äôs a non-starter for many new devs. New devs can‚Äôt be expected to understand openssh and code in C to call into it. But like all Go stdlibs, crypto/* packages are just delightful implementations. 
I'm not sure about weather this works, nor if it is a good practice, but you could try to `defer` the exec method? But then you won't be able to tell, whether it was successful or failed, I think.
What are you doing in your http handler after spawning that go routine? Are you explicitly returning anything with the responsewriter?
[http://www.paramiko.org/](http://www.paramiko.org/) is python implementation of SSH, and then there is this [http://www.fabfile.org/](http://www.fabfile.org/) "Fabric is a high level Python (2.7, 3.4+) library designed to execute shell commands remotely over SSH"
&gt;I've tried putting the exec method in a separate function and calling that, to create a goroutine separate to the handlers, as suggested in the following article, but it had no impact I'm not sure if you are using the std library correctly but without any insights into you code I can only guess. Try running your command like this in a separat go-routine: ``` func startServer() { cmd := exec.Command("go", "run", "main.go") log.Printf("Running command and waiting for it to finish...") err := cmd.Run() log.Printf("Command finished with error: %v", err) } func handle() { ... go startServer() ... } ``` If your handler never returns something else is blocking.
I would recommend reading gin readme page in section "Using BasicAuth() middleware" [https://github.com/gin-gonic/gin#using-basicauth-middleware](https://github.com/gin-gonic/gin#using-basicauth-middleware) It is a good start to have a peek. It is basic auth i know. But gives you short example to try to understand how it should work.
I‚Äôm not 100% sure what you are doing but I‚Äôll make some assumptions here anyways and clarify some things. Each time a handler is invoked it‚Äôs in its own goroutine. That means multiple things can respond at once. Exec is blocking. So if you put exec in a basic handler, it will launch that and block the request. If you don‚Äôt write anything, you will just get a timeout. So I think what you are doing is calling exec in a thread and it‚Äôs causing your HTTP request to timeout. That makes sense. So, you just want to prefix your exec run with ‚Äúgo‚Äù and it‚Äôll spawn a new goroutine, where you can then continue responding. But why are you running ‚Äúgo run‚Äù in exec? That‚Äôs a bad idea. Just launch a new one with raw go, and don‚Äôt put it in another binary. Go run will compile the code. If you really really want a different binary, go build it before hand and then go exec the resultant binary. But generally, just run go code within the actual process. 
Thank you, that makes sense
This has fixed it, I had tried this before but hadn't put `go` before calling the method. I'm still a bit confused by go routines, I thought by creating a separate function and calling it it would be already called on a separate go-routine.
http://www.jcraft.com/jsch/ is one for java
This has fixed my problem, I'm still relatively new to go, I thought calling a function would normally run it on a separate go routine, but I guess most package functions have "go" prefixed so they run in a separate goroutine. Basically I'm trying to create a go playground that allows you to run http servers in it and forward it through a proxy endpoint. So say I'm at localhost:9000 (playground) and do `POST localhost:9000/start/app1` and this will start a file `main.go` in a subdirectory called 'app1' and run it on localhost:9001. Normally you would open a new tab and go to `GET localhost:9001/foo` to use that server, or using the "proxy" (I don't think its really a proxy it just seems easiest to describe it that way) you can use `GET localhost:9000/apps/app1/foo` to perform the same request. This is only for development and testing, for production I would just compile app1 and run that normally, my grand idea is that I can build a playground server with hot reloading like this and link it up to my github repo and run it all from a server (or just docker) and not have to worry about setting up go and organise projects etc on my desktop and laptop, 
[removed]
Cool article, I am just starting out with Go. This seems perfectly normal to me: ``` func NewEndpoint(s string) *Endpoint { ``` However, could someone explain: ``` func (endpoint *Endpoint) String() string { // or func (tunnel *SSHTunnel) logf(fmt string, args ...interface{}) { ``` What is `String()` in that case and why is there `logf()` in the other one?
Awesome, thank you for the information! I've opened a PR with the basics of the feature here: [https://github.com/syntaqx/serve/pull/4](https://github.com/syntaqx/serve/pull/4) I still need to add test coverage and I want to play around with it a bit before I get to merging, but thanks for your feedback! Hopefully I can get this merged relatively quickly for you.
These are methods on Endpoint and SSHTunnel types.
No worries. Take your sweet time ! This is your project. The best of things take time to build.
Thanks for the answer! Your solution is more or less what I'm trying to do, having a map / stack / whatever where put the current Tx and check later if Tx exsits, if not put it there, and at the end remove it. What I see is that you're implementing the transactions by yourself, I mean, you're defining your create methods and returning the "rollbacks" instantiating the delete querys for each one. For my educaction, what's your motivation/goal to do it on this way instead of using the tx.begin tx.rollback tx.commit ? However, the "prob" that I'm facing with the DB initialization outside the repo layer I see that you don't have it using that approach delegating to the repo the tx management.
Although not directly a tutorial on `html/templates`, if you're used to working with other languages and templating, I'd recommend checking out [unrolled/render](https://github.com/unrolled/render) for a bit more comfortable feeling. Their examples also help you get a grasp of what's going on with variables/functions. Basically, this package is an implementation of the points expressed in the blog post [Approximating html/template Inheritance](https://blog.questionable.services/article/approximating-html-template-inheritance/), which is often the desired usecase for people. Once you've gotten a grasp of working with templates and variables, check out `template.FuncMap`, as this is where you *really* get powerful with Go (even unrolled/render's yield method is just a `template.Func`). You can see some common ones I personally use, borrowed from the Hugo, here: [https://github.com/syntaqx/funcs](https://github.com/syntaqx/funcs). Good luck!
Loaded and created the schema only once obviously and all validations are done using that instance. &amp;#x200B; In any case, I did a benchmark by writing a func that does 1000 validations in a loop and then spawned 20000 go-routines for concurrency. The gojsonschema is about 3.5-4 times slower than this one. [https://github.com/santhosh-tekuri/jsonschema](https://github.com/santhosh-tekuri/jsonschema) &amp;#x200B;
Absolutely, glad I could help!
Ah okay that makes sense! So you can do SSHTunnel.logf and Endpoint.String() :) 
What *is* polished, 00s or 10s language?
If anyone has any questions, feel free to ask away. üôÇ
Dunno yet. Takes a while for these things to shake out. Possibly D, possibly Rust. Definitely not Haskell, though I'd love to see the "polished Haskell"; not convinced Purescript or Elm are it. (Not that Haskell is "bad", but as an experimental language, while it has pioneered a lot of interesting things, it also has a lot of failed experiments in it, or just plain things we'd do better now.) Definitely not Clojure or Scala; it may be cool that they integrate into the JVM but they pay for it. Same for Typescript and similar languages; having to constantly limit themselves to "what works well in Javascript" precludes them from being "polished". They may be _good_, but they aren't and can't be _polished_ in the way I mean.
For new developers, the power of SSH is often overlooked. For slightly less new developers, the ability of the power of SSH to be abused is often overlooked. I've spent the last year ripping SSH out of things that we couldn't secure properly, because SSH is just _too powerful_. It's a great tool for logging in to a remote server when you're already effectively an admin, but if you've got less-trusted people using it, securing it is often a real problem. For instance, have you thought about the fact opensshd allows users to open arbitrary port forwards? It has a lot of power in it, and there's other things that can be a problem with it as well. Use it with care. I still use it a lot, of course, to log in with systems, but I've learned to take a much, _much_ closer look when it is proposed as part of some larger system. It's usually _too_ powerful to be casually used like that.
Reading through others comments they said what I was thinking about. Basically you have a client server model here and your client was waiting for a response from the server. In this case it looks looks like it was blocked by the exec command and it was not clear if you were responding back to the client. Anyways seems like you fixed it now, cheers.
What are your main benefits in comparison to existing libraries? It seems like it's near identical to e.g. https://github.com/eapache/go-resiliency/tree/master/retrier
Wow that's a mind bending lib. Great work on the face recognition 
The `String()` method is implementing the [Stringer](https://golang.org/pkg/fmt/#Stringer) interface, so most of the time you won't need to explicitly call the method.
Oh, and one more thing. Generically parsing the JSON with a decoder/unmarshal, and then modifying it based on transformations, has the issue of messing with JSON key ordering (see https://github.com/golang/go/issues/27179). Which isn't a _huge_ deal, but it'd be annoying enough to where I wouldn't want to use this package if it messed with my JSON key order due to human readability. So that's another reason to not re-parse the JSON. üôÇ
Wrt "to run another go server". That probably means the new server process does not exit. Then you probably want `exec("sh", "-c", "go run main.go &amp;")`
Is there a practical application for this technology?
No offense but there are tons of articles about the subject, some pretty complex. Whats the point in writing another one? 
There are a number of reasons I chose to write about this: &amp;#x200B; \- It addressed a need at my organization which was constantly biting us \- I would like to practice writing in order to get better \- I don't see many people talk about analyzing 3rd party libraries for concurrent correctness (something that also bit my organization) \- I present Candidates and Contexts which is a heuristic that I've successfully used and taught which helped to reduce race conditions \- Concurrency may be easy for you but my experiences differ: over 10 years I have yet to be in an org where even half the engineers truly understand how to prevent race conditions \- I've read about this issue in larger orgs too (dropbox, google) and have seen it first hand in a number of hashicorp projects 
&gt;There are a number of reasons I chose to write about this: &gt; &gt;\- It addressed a need at my organization which was constantly biting us &gt; &gt;\- I would like to practice writing in order to get better &gt; &gt;\- I don't see many people talk about analyzing 3rd party libraries for concurrent correctness (something that also bit my organization)- I present Candidates and Contexts which is a heuristic that I've successfully used and taught which helped to reduce race conditions &gt; &gt;\- Over 10 years I have yet to be in an org where even half the engineers truly understand how to prevent race conditions (using python, javascript, go) &gt; &gt;\- I've read about this issue in larger orgs too (dropbox, google) and have seen it first hand in a number of hashicorp projects &gt; &gt;\- \*Concurrency is kinda easy in go compared to other languages\* is the exact point I was trying to make: engineers with zero concurrent programming experience outside of school are thrown into the deep end of concurrent programming &amp;#x200B;
Why not use 0 as the port local port? With this you are sure to get a valid unused port. Call `AddrÀã method of the listener, you get a `net.AddrÀã, assert it as `net.TCPAddrÀã, and you get the port by accessing Port.
TL;DR: 1. Add binary integer literals, as in 0b101. 2. Add alternate octal integer literals, as in 0o377. 3. Add hexadecimal floating-point literals, as in 0x1p-1021. 4. Allow _ as a digit separator in number literals.
I honestly never found this useful. You can always just put integer, and add a comment for other representation
Binary literals, ok. Octal literals, meh. Hex floating point, definitely no. Digit separators, no.
Why not?
Being able to write `300_000_000` was one of the small things I enjoyed a lot about Ruby. I‚Äôd welcome this in Go. 
&gt; 0O600 // second character is capital letter O This evil is truly +Inf
Automatically generating responsive images for different viewport sizes. using [`&lt;picture&gt;` and `srcset`](https://html.spec.whatwg.org/multipage/embedded-content.html#embedded-content) one could have a 16:10 source image displayed to desktop users and automatically generate a 1:1 intelligently-cropped image for mobile devices in portrait mode. 
Why not just think choreographic programming? Go has channels, so it comes rather natural if you use it in Go. It's kinda complex, but then again, concurrency isn't a simple case to deal with anyways. &amp;#x200B; Does it slow down your software? Yes. But I find it easier to read, when implemented properly, and it also helps decoupling (depending on your design/code). &amp;#x200B; You can then even prove that you don't have deadlocks on paper (given that the code is correctly implemented).
Awesome :)
All sensible.
If we talk about numbers, I would really like if unary `+` was the complex conjugate as in APL. It's really a nice way to make this otherwise pointless operator useful and doesn't change its meaning for integers and floats.
Digit separators are good for human brains to be able to read numbers and associate some magnitude to them by seeing how many groups there are. I get that, but it seems to be like that's an output-formatting issue, not a source code feature. Do you really put that many hard-coded 6 to 12-digit numbers into your source code that adding a feature to the language for display purposes might increase code readability? That sure seems like an edge case to me.
Floating point is notoriously hard to get right, and a single period character could cause unintended consequences for hard-coded literals. I don't see the value in adding that kind of a feature to the language. Just my opinion of course. 
Yeah some people do that. Really if your logging itself is causing performance problems, you should just log less. But you can use buffering. To make it less likely to lose data, you can buffer each part of the program differently. A lot of times there is just one part of the code written by someone who was a little too liberal with the use of logging, and you can actually buffer just that part of the code and flush when leaving. You can also buffer per request, per second, or other more tricky things like that.
... or you can have your code self documenting ;)
Digit separators are very useful feature I've come to like in Ada. About the rest I agree. Stupid question: Who uses octal numbers and when?
Digit separators are a useful safety feature that I enjoyed them when I was programming Ada. They increase readability of literals a lot.
&gt; Do you really put that many hard-coded 6 to 12-digit numbers into your source code that adding a feature to the language for display purposes might increase code readability? That sure seems like an edge case to me. I don't write large numbers often, but when I do, it's very useful. I'm not very good at counting and I don't want to make any off-by-one errors that end up being order-of-magnitude errors.
There are readability benefits, but it makes grepping harder. In some (most?) contexts, readability can be fixed with your editor. In emacs, I like to just color by thousands. So 300,000,000 looks like this: https://imgur.com/a/de89hDz Even better than separators, IMO.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/FZ2eglt.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20eeaoy7o) 
One thing I couldn't gather from the proposal: What sort of programmer is likely to find hexadecimal floating-point literals useful?
Same as for any command line based resizing - to produce thumbnails and the like. The difference is that seam-carving preserves the most information-dense image regions, sacrificing the less valuable first. So by using seam-carving to square a collection of images before using simple scaling to produce thumbnails, you can produce a good view of a large number of images where the salient features are preserved with less shrinkage, making it easier to pick out the one you want. This implementation seems to be missing one component from the original work, which was the ability to mark certain areas to be preserved and others to be sacrificed (though it is using this tech to do the face preservation), but this is not a great loss, since that is not terribly applicable to a command line batch usage anyway.
I don't quite fully understand your reply, especially the "DB initialization outside the repo layer" bit, so I'll take a stab at it while sharing my thinking and the important, unsolved issues. The guiding goal for my project organization is: **my business logic should only change for business reasons**. One step I make towards achieving that goal is to have no external dependencies. In Go, this means inner layers describe the behavior of outer layers using interfaces and outer layers to write adapters as needed to fit these interfaces. That is potentially unneeded ontology/abstraction and so you may be interested in hearing from [a great devil's advocate](http://250bpm.com/blog:133). I think it's [worth the cost](https://www.youtube.com/watch?v=mVVNJKv9esE&amp;t=296) for my use case, however. In my root/`core` layer, to avoid dependencies, I even have my [own error implementations](https://play.golang.org/p/LC5OaMo41A9), as well as the `sagaStack` and `multiError` types I [shared before](https://play.golang.org/p/a39oH2KrFZD). Then, I have the main consumer of this logic, my `monolith` layer (eventually various microservices) that imports and constructs the `core` types, calling their methods to do things. In the next layer, I have write adapters for my monolith. That was the [`mariadb` package near the bottom](https://play.golang.org/p/a39oH2KrFZD). Finally, in a `cmd` directory, I have the `main.go` that loads the adapters and wires them into the inner layers. How about an example? Let's say we have a Todo app where every `TodoItem` must be a part of a `TodoList` but `TodoList`s cannot be empty. So, if we want to create a new `TodoItem` that doesn't belong a `TodoList` yet, we'll create one for it, one we can't create on its own first because then it would be an empty `TodoList`. In this example, then, if we need to create a `TodoList` for a `TodoItem`, we want these two actions to happens together or not at all. In database terms, we would want a transaction. However, this is a business need and exists independent of any storage implementation. It still would be true if you were keeping track of them on pieces of paper. My current idea solving the *business need* of atomic recording keeping is a port of the [saga idea from distributed transactions](https://www.youtube.com/watch?v=xDuwrtwYHu8). My implementation (sagas in general? I haven't done the research) still has a few weaknesses, however. * Sagas rely on a `compensating` action that can undo a failed action. So, for a `CREATE`, you can `DELETE`. In a normalized schema, most `UPDATE`s can be eliminated by querying an event log. For example, you can derive the number of `TodoItem`s by `SELECT ... COUNT` on them in SQL databases. There's a race condition, however. If a role escalation saga fails, you don't want a situation where the user is able to use an `admin` privileged function before his role is rolled back. As a stopgap, we can mitigate the fallout by delaying the most important steps (role promotion). * If a compensating action fails, your data is corrupted. You can keep retrying with exponential backoff but what if the master you're writing to dies? Either way you have to deal with the cleanup. Alas, I'm busy adding features and don't have time to deal with these edge cases, among others. Please note that I have neither professional experience nor mentorship. Instead I learned from videos, open source contributors, and those kind enough to respond my emails/messages. So, be very discriminating to my ideas!
Amazing! Wondering if there's something like this for YAML
This is....exciting....stufff......yeah..... I'm finding it really difficult to care about such low-hanging fruit. How often do inconvenient number literals come up in people's day-to-day interactions with Go? To me this is like "optimizing" comments or reducing the -&gt; channel operator to \^ to save a keystroke. I'm not trying to be a dick, I swear, I just find it fascinating that such low-level fruit is even on the radar when there's 2-3 big glaring omissions to tackle still. 
With awesome, pathetically out-of-date versions for everything! (Hi I'm on Ubuntu LTS, of \*course\* I want a version from 2 years ago installed today because it's more "stable" according to random-guy-who's-not-the-dev). 
Reasons for them are definitely imagined. Code readability does matter. Number of opportunities does not. * who really need octal literals except 0755 and 0644? * who really need hexadecimal float point (and imaginary) numbers? * who don't know that 0xf0 is 11110000 (and can't `fmt.Printf(%b, 0xf0)` in the playground)? * `const K = 1000`, `const M = 1000*K`, text editor highlighting (see blow)
There are command line interactive libraries for Go already. Perhaps one of them would help? Maybe readline - https://github.com/chzyer/readline or go-prompt - https://github.com/c-bata/go-prompt or prompt-ui - https://github.com/manifoldco/promptui Or look at the source for Gosh. https://medium.com/@vladimirvivien/gosh-a-pluggable-command-shell-in-go-cf25102c8439 It implements a shell. Possibly look at https://github.com/moul/sshportal - it looks to me like when you ssh into it, it provides an interactive command line environment that is not just passing through a unix shell, so it might have more applicability to what you want to do (I don't mean to use it, I mean look at how it implements that interface).
It's not a hashtag.
So if you have two modules `host/remote` and `host/local` and you want to import `host/remote` in the module `host/local`: Open the `host/local` `go.mod` file, should look something like this: module host/local require ( ... ) Edit it to look like this: module host/local require ( ... host/remote v0.0.0 ) replace host/remote =&gt; ../remote This should work. For more info: https://github.com/golang/go/wiki/Modules#when-should-i-use-the-replace-directive
Yes but you need to call the whole path. There are ways using ./ but it‚Äôs not idiomatic. It‚Äôs something that annoys me a lot about go, but I live with it. Eg, say you have your main package called: GOPATH/src/hosts You can just import ‚Äúhosts‚Äù. Inside you have ‚Äúremote‚Äù GOPATH/src/hosts/remote Inside hosts you would import ‚Äúhosts/remote‚Äù Personally, I put my code on my own repo (technically aws code commit), and use ‚Äúdev.domainname.com/project/repo‚Äù. Then got checkout to there. It doesn‚Äôt matter that it‚Äôs not the ‚Äúreal‚Äù location except if you are doing a hit pull, and I understand there is some aliasing capabilities there anyways. 
&gt; I have an http handler in my golang server, that calls exec("go", "run", "main.go") to run another go server from a different directory on a different port. When making the request to this endpoint it successfully runs my second server on the correct port and works as expected, however the actual request in the browser or postman will be stuck on pending until it times out. &gt; &gt; I think this is due to the fact that I am making a request to a handler, that launches a new http.ListenAndServe method which never finishes or returns anything, thus starting the new server but preventing the handler from finishing, and leaving the request on pending until timeout. &gt; &gt; I've tried putting the exec method in a separate function and calling that, to create a goroutine separate to the handlers, as suggested in the following article, but it had no impact &gt; &gt; https://stackoverflow.com/questions/31116870/goroutine-execution-inside-an-http-handler &gt; &gt; Author: /u/dr3wy98 Don‚Äôt do this, I repeat ‚Äî DO NOT DO THIS! &gt; This has fixed it, I had tried this before but hadn't put go before calling the method. I'm still a bit confused by go routines, I thought by creating a separate function and calling it it would be already called on a separate go-routine. Taking this other comment that you left as a reply, I think you are completely misunderstanding what the keyword `go` is and what a goroutine is. Using `exec` doesn‚Äôt open a goroutine, it simply executes an external command, then the code that is running `exec` will block until the external program finishes running. What you want is to cut the code that‚Äôs inside the other `main.go` file and put it in a function in the code that has the `exec`, then use the `go` keyword to call that function. Also, please do not delete your posts, other beginners could benefit from this thread.
Completely possible! I tried it out and it worked! You can do so by making use of the **replace** directive supported in Golang Modules. FAQ from Golang Modules wiki: [Can I work entirely outside of VCS on my local filesystem?](https://github.com/golang/go/wiki/Modules#can-i-work-entirely-outside-of-vcs-on-my-local-filesystem) You can create the host with local and remote subdir's, and create go.mod file for both packages: `module host/remote` and: module host/local require ( host/remote v1.0.0 ) replace host/remote =&gt; ../remote where ../remote locates the remote package code. The v1.0.0 is for sake of correctness.
Someone writing a check for the Pentium bug where it failed to multiply numbers correctly.
hmm. So I should convert each package into a module? I thought that since modules can contain packages, that I could have a single `mod` file inside `host` (`host.mod`) and then have `host/remote` and `host/local` packages contained inside the `host` module. &amp;#x200B; I have done this inside host.mod: module host require ( host/remote v0.0.0 host/local v0.0.0 ) replace host/remote =&gt; ./remote replace host/local =&gt; ./local However, I get an error: can't load package: package host: unknown import path "host": cannot find module providing package host &amp;#x200B;
I'm kinda surprised this isn't built in to any TVs yet. Could be good for scaling 4:3 to 16:9.
I see, i though you meant you had two separate modules. If that is the case you don't have to use modules for the packages to "see" each other, it should "just work" without any problems.
First let me thank you for your answer again! My sentence "DB initialisation outside the repo layer" was referred about if I have to manage the db transaction directly in the SVC layer, I should move the DB to that layer instead of being agnostic as it's being now, bc the SVC layer calls a "repo" but could be as you said even papers. Anyways, after your explanation I see more light in the tunnel and I was also reading about the Saga pattern, and it's basically what you did in the first example (and explained extended in the second comment). I'll try to do this approach or a similar one but with that idea as a goal. If you open source something just ping me, I'm always trying to improve myself and also learn from/teach to other ppl.
What glaring omissions? Inb4 generics
&gt; Hi I'm on Ubuntu LTS, of *course* I want a version from 2 years ago installed today because it's more "stable" according to random-guy-who's-not-the-dev ‚Ä¶yes, that's the *whole damn point* of installing Ubuntu LTS. Don't use LTS if you don't want that.
You gain a little here, you loose a little here. If the feature is either a wash or close enough I don‚Äôt think it‚Äôs worth the added complexity in the compiler. That time could be used for something better. 
That looks like a good tool. However, if you want to keep it all in your Go code you won't be able to use that.
On other subtle thing. If an entity starts with a capital letter (such as String) is will be exported so that other packages can use it. The reverse is also true, so logf cannot be called from outside the package.
It's really a non-issue IMO. Just allow optional `_` in your numbers and don't enforce any kind of grouping. In much of Asia, numbers are in groups of 4 (one million is 100_0000, or 100 ten thousands), so it's _best_ to not force a specific style. I'd happily do the work of adding in an optional `_`, as it wouldn't really take much time.
I usually only do this for even multiples, so I tend to do something like `1e6` or `1e9` (usually in time math, but not always). However, I occasionally use it for large constants, like the diameter/radius of the earth in meters, or distances between planetary bodies. And the best part is, it's _completely_ optional, so you don't have to use it if you don't want to. It's pretty harmless and makes _no_ semantic difference.
Quite often I do it like this: `1 * 1000 * 1000`. That way it's self documenting, but it's a little verbose. I would _much_ rather do `1_000_000`.
That's an awesome tip! Thanks, I have updated the article.
Honestly, these could probably be added now, so it's not really a Go 2 thing, but a "hey, I like this feature, please support it" thing.
Yes, you're right. That is confusing because it uses the public key, but it expects the path to be for a private key. I've updated the name of the function to be more clear.
Can you still not access the page?
&gt; who really need octal literals except 0755 and 0644? `0600, 0400 and 0700` are also quite nice, so are `0777`, `0640`... Yes, their primarily for file permissions, so what's wrong with having a syntax to make that nice? I deal with those quite a bit.
thanks :) ended up with a 39 degree fever on Monday! all better now though. &amp;#x200B; Anyway, we had a look at the skew\_ratio. It does seem you are correct, duty\_cycle is indeed \`1 - skew\_ratio\`. I'll update the documentation at some point (and my photons library, which does the skew\_ratio transformation incorrectly it seems!) &amp;#x200B; Thanks for pointing out the inconsistency!
A programmer that wants exact values expressed in a way that the computer represents them internally.
[removed]
So instead of expressing your floating point values in a base that can be exactly converted into the base that will be used internally you prefer to express them in a base that can't be converted exactly and hope that you've correctly remembered how the compiler is supposed to perform rounding. Could it be why it's so "notoriously hard to get right"? Floating point is not hard to get right. Floating point is just hard to explain because people insist on doing base conversions all the time. Once you start thinking in the right base floating point becomes surprisingly simple. Incidentally this is something I understood within a day from seeing hexadecimal floating point literals in C for the first time and trying to understand what they are good for.
&gt; Honestly, these could probably be added now That's why they're being considered for inclusion in Go 1.13: &gt; At the release freeze, May 1, we will revisit the proposed features and decide whether to include them in Go 1.13. 
Super informative! Definitely worth the watch.
I'm a bit conflicted about this, because on one hand I agree it's useful, but on the other hand, is it really useful *enough*? I only used it perhaps two or three times in my years as a Ruby programmer. One of the great things about Go is that it's easy to write tools for it due to its fairly simple syntax. This is a real value to the language as a while. More syntax means that writing tools will be harder. Yes, they're fairly simple features, but adding a bunch of "simple features" does add up. So the question isn't "is this useful?", but rather "is this useful enough to justify the increased load on tool authors?" Personally, I'm not so sure it is.
You can also already write 3e8 or 300e6 in Go. (Minor caveat: these are floating point literals, so their default type would be float64 instead of int. But because they're integer values, they're still assignable to integer-typed variables.)
justsaying. My x11 + gtk with cgo bindings works beautifully. If windows &amp; osx cannot or will not enable similar, they are awful choices
Rob Pike's take on APL: [https://github.com/robpike/ivy](https://github.com/robpike/ivy)
I thought that calling any method would run it on a new goroutine, not that exec would create a new one but I was wrong. Like I said I was attempting to make a go playground that would be able to run any project I have on github that contains a http server, my theory is it would greatly speed up my development time for many reasons. I've made 2 posts on reddit because I was stuck on something each time I couldn't figure out, both times it was something very simple I overlooked, both posts had 1 or 2 answers that actually solved my problem and were helpful and the rest were not constructive and said I shouldn't do xyz because even a very progressive language like go theres still a lot of dogma on doing things "the right way". Considering my problem got solved straight away and all I was getting was downvotes I figured there was no point keeping them up
Yes, you should, you will save around $ 1,200
For example, here are a few lines from the Go compiler: // f is valid float if min &lt; f &lt; max. (min and max are not themselves valid.) maxfltval[TFLOAT32].SetString("33554431p103") // 2^24-1 p (127-23) + 1/2 ulp minfltval[TFLOAT32].SetString("-33554431p103") maxfltval[TFLOAT64].SetString("18014398509481983p970") // 2^53-1 p (1023-52) + 1/2 ulp minfltval[TFLOAT64].SetString("-18014398509481983p970") The significance of these constants is a little bit clearer as: 0x1ffffffp103 0x3fffffffffffffp970 and of course even the original values are easier to read than 340282356779733661637539395458142568448 179769313486231580793728971405303415079934132710037826936173778980444968292764750946649017977587207096330286416692887910946555547851940402630657488671505820681908902000708383676273854845817711531764475730270069855571366959622842914819860834936475292719074168444365510704342711559699508093042880177904174497792
Pretty sure there are some outstanding bugs around this functionality, though I can't recall the issue IDs off the top of my head.
Cgo is a completely different thing and can be done on any OS. But to use it you have to use C toolchain. Read the article again, the author uses syscall capabilities to call external libraries. For that you don‚Äôt need cgo. Go syscall on Windows is actually a way to call DLLs because syscalls are undocumented and you have to go through DLL. Same on macOS where syscalls do not have compatibility guarantee. That‚Äôs why Go on Darwin now uses libSystem dylib instead of raw syscalls. And no cgo needed. Justsaying. Even if you couldn‚Äôt do it on macOS or Windows, the problem would be with Go. OS can do pretty much anything, it‚Äôs Go that has to provide implementation. For example, no plugin support on Windows - not Windows‚Äôs fault. Go just doesn‚Äôt implement it, the ticket is still open and anyone can contribute.
Rob Pike and rtsc (going off memory atm) have expressed being in favour of not adding the uppercase versions while deprecating 0X.
Why \_ might seem great at first for clarity. I feel like its probably more the concern and responsibility of the editor to do the work in separating the number tries however the user sees fit (be it comma, dot or half width space). &amp;#x200B; If 1\_000 doesn't work for some or becomes a distraction, then it's just not worth it. Better it be up to the editor or display.
The only thing (in a busy enough system) increasing a buffer size inside Go will do is decrease the number of syscalls (and increase the risk of lost log entries on _app crash_, as opposed to operating system/hardware crash). Your written log data is getting buffered in the kernel page cache, and written to disk at its leisure. In an otherwise reasonably busy system, it won't be written to disk much more often, either way. Only fsync causes a disk write, otherwise it's a kernel decision based on RAM pressure. There's all kinds of funky designs for minimizing syscall overhead while also minimizing lost log entries (shared memory dumped to disk by a second process, in-memory ringbuffer that can be extracted from a core dump, etc). Most of the time, those tricks aren't worth it.
[removed]
Looks interesting, it looks to me like a scripting language that basically uses the same syntax as Go? What's the proposed advantage over other mature scripting languages like Python?
15 open issues? That's your argument? lol Jesus. Nobody show this guy any real CVE list for any common software.
Thanks! I updated my code to [no longer do `1-SkewRatio`](https://github.com/fishy/lifxlan/commit/8d18a874fa9bce8771535e88f3a52a35f3490a98), and tagged v0.1.0 release. 
The other thing to note is the reading point of view. It may suit the writer, but not always the reader or maintainer.
‚Ä¶Tengo que bailar contigo hoy‚Ä¶ Despacito üòú
This is really neat
Pretty cool. FWIW I'm working on a project and using [Starlark](https://github.com/google/starlark-go) as scripting engine.
If you don't mind appending a "namespace" to your imports, you can just organize everything under the same go module (with a root `go.mod` file). For example say your "namespace" is `github.com/company/go`, then you just have a `go.mod` file with `module github.com/company/go` and you import using `import "github.com/company/go/host/remote"`. Otherwise use `replace` as others pointed out.
I could see this as an interesting way to provide a mechanism for plugins or even a way to create user defined rules. Something like a rules engine that lets the user provide an evaluator. 
And that's what code style guides and code reviews are for. It's such a simple feature, it's almost silly to not include it.
&gt; Yes, their primarily for file permissions, so what's wrong with having a syntax to make that nice? I deal with those quite a bit. That's nice. Didi you say primarily? Did you mean only? Lol. I hate to break it to you, but having the only way to do something is really important.
I've used it in some other rare cases (e.g. bit-packing using nibbles instead of bytes), but yeah, file permissions are pretty much the biggest use case for octal.
[https://github.com/avelino/awesome-go](https://github.com/avelino/awesome-go) [https://golanglibs.com/](https://golanglibs.com/)
&gt; Is there a master list/repository of Golang libraries on the web/GitHub? Do you mean a package registry? No, there is not. But some people use a mix of these projects: * https://godoc.org/ * https://golanglibs.com/ * https://docs.gomods.io/ * https://gopm.io/
Hm, looks BS. As all proposals for Go. Never need, nobody need. - They really this that ``` a &amp;\^ 0b10000 ``` is more readable then ``` a &amp;\^ (1 &lt;&lt; 5) ``` - They really think, someone want zero-o combinations in numbers. Let eyes bleed. - Hexadecimal float point numbers. Tell me the reason isn't far-fetched. Tell me again. - Etc. Etc. Let's make Go ugly.
My most recent project is a simulator to test voting methods. It runs thousands of simulated elections and being able to do this concurrently speeds up the process by a ton.
Consider this : when you are building a web app, each time a user request some data from the back end. The back end takes the request and responds to it. If you write a node or a python app using the standard package without any reverse proxy or whatever, your back end will respond to the apps one by one, even if you are running the app on server with 4 cores they will use just one core. To overcome this you have to add some extra stuff to handle this, like use node cluster module, or add a reverse proxy like Nginx to spin a whole new process for each core. By doing so, you have your app running 4 times rather than once, and because of this, you can‚Äôt really use a global variable in your app tos toe stuff because each process is independent and running its own world. For example, If your app is handling server side sessions, you will have to set a common separate database where you can store sessions. Otherwise, a new request from the user may end up in another process than the previous one. All that stuff, like Nginx and outside database all come with overhead, running 4 separate instances of the python app consume resources. Also imagine if one of the processes error out, then that instance of the app would die and you have to have built in some kinda solution where your nginx or cluster module identify and restart the dead instance, which means more monitoring overhead. Compare that to go: The standard http package spins a new go routine (which is a light weight thread requiring only a few kB in memory) every time is receives a request, this is done from the same app instance, so you don‚Äôt have to run a server, or a separate database to allow your various threads to share common knowledge. All the Go routines can access the same shared variables from your apps so it is rather safe to use a global variable. So you ‚Äútheoretically‚Äù can just store all your session data in a global variable, and all the Go routines can access it. You can deploy that app to a sever with 2 cores or 20. It doesn‚Äôt matter it will use them all without you doing anything. And because of that you don‚Äôt need to have a reverse proxy, or any complicated mechanism to share data, it is all done inside the same instance of the app. If a request ends up causing a runtime error, only the Go routines it is running in will be affected (if it doesn‚Äôt screw up your global variables). When this go routine dies, it will be discarded (if you handled the error correctly, which go kinda encourage/forces you to do). This also alleviate the need for having a some extra process management. 
Awesome! Thanks
Thank you!
I‚Äôll give you an example I used. We had a service API that would tail off logs, where I needed to process them to get some context. We would then also take action based on that by sending commands back up to the service API. The service wasn‚Äôt doing a good enough job of being configurable so we were doing this all in a separate process. So far no need for concurrency. We had a web page that users could open up and see the real time results of that processing. They would open a websocket and it would push live updates to their machine. With some basic fan-out patterns, we had all clients connected getting real time updates. You can do that with redis pubsub as well, but that would require running redis. Instead, the whole binary ended up being something stupid like 75k, and a single file (minus the HTML/CSS/JS), and ran as a background windows service. Nice little standalone package. Another project I had it opening a LOT of files, processing them, and outputting them. Originally it as in Ruby that doesn‚Äôt have a great concurrency model (it‚Äôs better than it was but not the best). So I used a makefile to spool them all up in separate tasks, then spool off another task to merge the files at the end. With Go, it was all within one program so I could run them in batches and have them all write to a single channel that merged the results into a single file. One less step. It was also monstrously faster than ruby or many interpreted languages. 
One simple example is generating workers to render PNGs or do some other cpu intensive work. Here is an example from one of my pet projects: [https://github.com/adamryman/radialwave/blob/master/main.go#L166](https://github.com/adamryman/radialwave/blob/master/main.go#L166) Otherwise, if you are using the "net/http" package, then you are already using golang concurrency features, though indirectly. As the "net/http" web server that golang provides in the standard library is using concurrency to process requests. See here: [https://github.com/golang/go/blob/master/src/net/http/server.go#L2884](https://github.com/golang/go/blob/master/src/net/http/server.go#L2884)
Look, dont switch to golang if you dont need to. Everyone makes the same mistake of trying to impose a new language in the business. Stick with what your team is comfortable. It takes time to write high performance code in any language and sometimes trading release time its not worth it.
I would guess the advantage is speed over some of the more mature scripting languages. 
Now I can. Rear it, thought it was awesome. 
Let me translate this for you: &gt; who really need hexadecimal float point (and imaginary) numbers? "I never wrote any numeric code and am too narrow minded to comprehend that someone else might do." 
It's nice that syntax resembles Go itself. Makes it easier to switch between reading/writing Go and Tango. What is the compiled size of Tango runtime?
Thank you OP for the question, and the insightful comments. &amp;#x200B; I'm thinking go should well suited for ML as well due to the analysis required. However, python seems to have the popularity here...in face that's true for all data analysis projects. Would have expected go to perform better with large data-sets. &amp;#x200B; I am looking at a hobby project to analyze and diff 10000s of documents. One use-case is to find docs that have similar text strings in them (think student plagiarism copy-check). So, it's a n x n diff-score for n documents. Would really like to use go in general, but python seems to be the easier way to do this...and then using flask would allow me to easily build up the web stack as well. Being inexperienced in both, I can' think why go would be a better choice (outside of my personal choice). &amp;#x200B; &amp;#x200B;
I don't know that plugins vs well-defined service boundaries is a great pattern. Especially in golang. Although I'll admit it's a well trodden path, go code should attempt to avoid potentially runtime incompatible code. If you need something akin to plugins check out the patterns laid out for compatible interfaces by such libraries as `"database/sql"`. AFAIK the closest other thing would be modules, which are absolutely not plugins, but provide a compile-time way to release many versions (which might include variants) of your application. What you'd need would be a set of core API's which the plugins and builds would share in order to communicate, and what you'd receive would be a single binary for distribution.
And lack of backwards-compatibility / pre-made choices. 
&gt; "I never wrote any numeric code and am too narrow minded to comprehend that someone else might do." You can rest. I've worked with fixed-point numbers you've never heard of. And I have no problems with Go. Hexadecimal float-point numbers are almost useless. And 0o-octal numbers too. And 0b-binary numbers too. Etc, etc. 
Example: I am working on a backend CRM like system. I need to query several legacy systems to determine if a customer is valid. In python, I might do this with an object oriented model and a list comprehension or lambda(), but effectively it will run sequentially. In Go, I can fire off a goroutine, controlled by a context, per system with a channel, and a listener goroutine waiting for the valid customer response. Upon the first such response, I could cancel the context, killing the goroutine and continuing on knowing my customer was valid. This means instead of the sum of latencies of the backends, I'm going to approach the latency of the fastest backend that knows about the customer.
[removed]
Thanks.
Nice... Now I won't have to Google while writing scripts :-P
No tests ? 
Kudos for making the "Run in playground" thing!
Thank You so much!! You've been very helpful üòú
https://github.com/golang/go/wiki/Projects
yes, not finished yet, will add soon
Python is not readily embeddable, nor it has features one would want from embeddable language. I would like to see a comparison to lua for example.
Nice üëå
Jesus for the love of god make anything other than capital case illegal 0O600 // second character is capital letter O needs to be 0O600 // illegal
The answer is yes: a &amp;\^ 0b10000 is way more readable then: a &amp;\^ (1 &lt;&lt; 5)
I use Go for CLI tools. I used to write them in node.js. It was nightmare. At least once a week I had to explain which version of node should they use. Even after explanation they installed it wrong. With Go you just say ‚Äúhere is binary, use it‚Äù and that‚Äôs it. Life got easier.
Looks and feels very fresh and professional, nice designer skills, mate. I'll make sure to check it out! [ndabAP](https://github.com/ndabAP/vue-go-example) is another example project blending Vue and Go for anyone interested in getting the first grips.
Author here. If you have a question, feel free to ask me!
Interesting tool, but how does it handles multithread scenarios and complex values (for example if err is not nil)? 
In web dev context, go is great in contexts similar to java/spring boot/microservices - it has very similar libraries, is more light weight, faster, and better encapsulated (no jvm). It‚Äôs as concurrent as java, and more so that java - although not faster on warmed up processes. There is more boilerplate code (on par with java) with go, and language is pretty limited, but in real prod systems these are not downsides. If you write microservices in java, try building one in go. Other than that, cli tools is another area where it‚Äôs great (and various backend daemon type processes). 
This looks like a really nice addition to my performance tuning toolbox.
Every Go server uses these features. It may be interesting to look at server.go in the net/http package to see how it is used. 
Thank you. It traces only the go routine which called the tracer.Start() function before. Also, it understands the struct type, slice type, map type, and so on. For example, if you build &amp; run this program: package main import ( "errors" "github.com/ks888/tgo/lib/tracer" ) //go:noinline func f() error { return errors.New("test") } func main() { tracer.Start() f() tracer.Stop() } It shows the actual value of the error type: % ./err \ (#01) main.f() / (#01) main.f() (~r0 = *struct errors.errorString(&amp;{s: "test"})) 
I think you didn't see the return at the end of the if scope. So as far as I can see it never reaches the .Release() and everything should be good. (I'm not the author and never used the package)
&gt; The point is, I think, that adding that new syntax as an option is valuable in lots of instances Lol, Tell me again how you like to count zeros. Never forget, that Go is not language of individualists. But social. And if you are young and your eyes works good, it doesn't mean, that other Go developers are young too. And, ```go func unsetBit(u uint32, bitNo uint) uint32 { return u &amp;^ ( 1 &lt;&lt; bitNo) } x = unsetBit(x, 5) ```
Hi, again thanks for your time :) I've run into a slight problem which might just be me not understanding the docs. Is there a way of using Param("") and .Field() through a pointer? I've got: &amp;#x200B; `Package("`[`github.com/jamiec7919/vermeer/core`](https://github.com/jamiec7919/vermeer/core)`")` `TEXT("intersectBoxes", NOSPLIT, "func (ray *Ray, boxes *[4*3*2]float32, hits *[4]int32, t *[4]float32)")` `Doc("intersectBoxes evaluates the given..")` `// MOVSS (AX),X3 // X3 = ray.O[0]` `rayOX := Load(Param("ray").Field("O").Index(0), XMM())` &amp;#x200B; The Ray type (in core) is something like: &amp;#x200B; `type Ray struct {` `O [3]float32` `}` &amp;#x200B; But I can't work out how to get a reference to O\[0\] etc. via the Param. Keep getting 'not struct type' etc. I tried various combos like Base() and Index(0) just in case but no good :) &amp;#x200B; Also it didn't seem to like me including the package name in the func signature: `TEXT("intersectBoxes", NOSPLIT, "func (ray *core.Ray, boxes *[4*3*2]float32, hits *[4]int32, t *[4]float32)")` The asm code is not in the core package, but another package that references a public type from core. &amp;#x200B; Errors out with: &amp;#x200B; `intersect_asm.go:12: eval:1:12: undeclared name: core` `intersect_asm.go:16: unknown variable "ray"` `intersect_asm.go:20: unknown variable "ray"` `exit status 1` &amp;#x200B;
How does it handle (mid stack inlinng)[https://github.com/golang/go/issues/19348] that is going to be even more prevalent in Go 1.12? 
So I shouldn‚Äôt use channels across functions? Also, this is no API, but as internal and specific as it can get in application development
Just my 2c on writing style - I think the content is good but I was a little confused by the flow of the article. I think if you had started with the Dangers of Concurrency section and then explained the Candidates/Contexts model it would have been a more natural flow to the following examples. The article is rather long so by the time you reach the introduction of the C&amp;C model, I was questioning why even mention these concepts when you're *essentially* repeating the content in the Race Conditions example, albeit with a different vocabulary. &amp;#x200B; You could also consider splitting the article into two chunks as well. The first would be the Candidates/Context model and how you can use that paradigm to identify race conditions in concurrent programs. The next would be how to do that using the Go toolchain. One is very high level and introduces the problem - the second finds a solution using best practices. Remember your audience - not everyone has the time (or patience) to read long blog posts! &amp;#x200B; Hope this helps.
[https://www.reddit.com/r/golang/comments/3qemic/exposing\_channels\_or\_abstracting\_into/cweiw2b](https://www.reddit.com/r/golang/comments/3qemic/exposing_channels_or_abstracting_into/cweiw2b) &amp;#x200B; Might be useful &amp;#x200B;
[https://www.reddit.com/r/golang/comments/4ri2ng/what\_is\_best\_practice\_api\_for\_returning\_an/](https://www.reddit.com/r/golang/comments/4ri2ng/what_is_best_practice_api_for_returning_an/) &amp;#x200B; Found this, which is basically what you are saying (I think), but this is my question is not about returning a single result somewhen, but multiple results, but at call time, I don't yet know how many (will edit question)
Actually it doesn't handle the inlined functions very well (it just traces actually called functions only). But it seems mid-stack inlining is the good motivations to support it. I hope the DWARF section provides the enough information for this.
The executable is just 3.3mb on Mac and is fully standalone. Single binary executables reduce all the friction. This looks promising. &amp;#x200B;
To the people here who would rather see us do generics first, I would recommend rereading [https://blog.golang.org/go2-here-we-come](https://blog.golang.org/go2-here-we-come), especially this text: &gt;We feel that this is a good plan that should serve us well but it is important to understand that this is only a starting point. As the process is used we will discover the ways in which it fails to work well and we will refine it as needed. The critical part is that until we use it in practice we won't know how to improve it. &gt; &gt;A safe place to start is with a small number of backward-compatible language proposals. We haven‚Äôt done language changes for a long time, so this gets us back into that mode. Also, the changes won‚Äôt require us worrying about breaking existing code, and thus they serve as a perfect trial balloon. The point of these minor changes is to get some experience with the process and effects of making even small Go language changes again. It's been a few years since the last real language changes: there are many more Go users now, more implementations, and so on. We are going to do our best with these small changes and find out what unanticipated problems arise so that when we get to bigger changes we can roll them out as smoothly as possible. We picked some small, obvious things that are worth cleaning up but at the same time non-critical enough that it's OK to make mistakes and need to try again.
Just the editor, or also the source code viewer of the SCM, the source code viewer of the review system (which might not be the same), your favorite diff tool, etc. ? The nice thing about language support is that all the other tools can stay the same while you are still benefitting from it.
don't we have the `plugin` package for that?
This looks awesome! Can you explain how it works? Thanks :)
Given a scale where `a &amp;^ 0b10000` is a 1 and `a &amp;^ (1 &lt;&lt; 5)` is a 10, how would you score `a &amp;^ 0b10_000`?
If you‚Äôre compiling your go code as a plugin, that‚Äôs one thing. But if you want something you can store in a database or what have you, that‚Äôs another. 
Could you elaborate on your experiences ? Is Starlark a good choice to express complex configurations ? 
I had previously thought that someone should port Lua‚Äôs interpreter to Go to serve as a plugin system v
It's too early to say yet, the system is using starlark scripts to process a dataset that has a lot of "business logic" that is very dynamic and should be editable/testable by a different team. We don't have that many rule files yet to be able to say what the downsides are, but we expect we won't have any problems because starlark is basically a rich subset of python (which is a very expressive language) - we expect we'll be able to express anything with it.
The stdlib plugin library isn't perfect for many use cases. - Once you load a plugin, it's loaded for good. You cannot unload a plugin. - You can't load a plugin at the same path twice, even if it changes. - The plugins are loaded and executed into the process, so any plugin must be trusted. It's often better to embed a language (this post, goja, starlark), or communicate with another process (hashicorp/go-plugin).
Ah, this is an interesting case that unfortunately `avo` doesn't support right now. If it's okay I've migrated this to an issue on the github repo, so we can continue the discussion there. https://github.com/mmcloughlin/avo/issues/53
Thank you so much for asking this question. Sorry, I am not answering your question, but want to make sure this question gets an answer because I belong to the same camp as you, OP! The only thing I would add to your question is: what is the best editor/IDE for writing Go code?
[removed]
&gt; For example, what "package manager" is to be used? I think go dep, but I also saw vgo? Not too familiar with this so far so I may be misunderstanding. dep is experimental, Go now have [module](https://github.com/golang/go/wiki/Modules) concept as replacement of "package manager", vgo is like an alpha version of it before being merged to main Go repository. &gt; What formatters, linters, debuggers, other tools are widely used? I prefer [golang-ci](https://github.com/golangci/golangci-lint/), due their great performance over `gometalinter`. For debugger, most said [`delve`](https://github.com/go-delve/delve) is great but I never have I need to use debugging (never used it). &gt; web development (routing, serving, w.e) I have unpopular opinion about this one, which will not resonated will on this sub. If possible, pick library over framework. &gt; logging. For example I'm aware of logrus, but then zap came out and then zerolog Also unpopular opinion, I use fmt for stdout, log for stderr.
The best editor/IDE is an easy question. It boils down to three answers depending on who you are: 1. The hard core command line guys that grew up using vim have a vim-go plugin that is extremely popular. 2. The developers that are want something with more features but is still light weight tend toward Visual Studio Code. 3. The programmers that want a full-fledged IDE tend toward Golang from Jetbrains. These are, of course, generalizations and simplifications. There will be exceptions. There will be those that strongly disagree, but I believe the statistics and surveys will support this list. 
I was fairly active with God about 4-5 years ago and getting back to it just now. For web/API stuff, I would definitely recommend Chi. It hits all the sweet spots while being minimal. Other than that, I'd stick to the standard lib as much as possible.
Not at all, that was going to be my next question whether you wanted an issue raised :)
are the ones you mentioned better than the built in `go fmt` utility? I'm a noob.
TIL I'm a hard core CLI guy ;-)
I've been actively using Go for the past 3 years now. I will tell you what I go with and tried, more than trying to tell you do this or that here. My main editor is Atom, I tried VSCode a year ago and to me it was still lacking a few things back then so I sticked to Atom which is really great when you have \`go-plus\` installed for lint and other error/testing triggers it's really good and comes with a lot of configuration. &amp;#x200B; As it was mentioned by \`rv77ax\` modules are now the way to go to vendor your code, tho \`go dep\` came a long way and is still relevant to me I'd say. &amp;#x200B; Personally when it comes to web dev you have many options, if you only need simple things but don't want to bother writing a full fledged router, I'd go with something simple la \`gorilla mux\`, if I need to build a full website or a more complex API where I want to avoid redoing everything I go for \`[gin](https://github.com/gin-gonic/gin)\`. It has all the geature you'd appreciate to have to build an API or web platform quite easily. But again, it really depends on what you need and the standard library is good enough for a big scope of apps. &amp;#x200B; When it comes to logging I use \`logrus\` simply because it has everything I need and I never had to look for more in terms of logging in my Go apps. For debugging my state I use \`[spew](https://github.com/davecgh/go-spew)\` to print the whole content of my variables, including bytes array which are nicely printed. &amp;#x200B; Other than this, it's super easy to develop standalone microservices and build a complete ecosystem, thanks to the \`protobuf\` implementation for go and \`grpc\` but you can also use HTTP or any message queues that have a great support for the language most of the time. &amp;#x200B; I've been using \`[gorm](https://github.com/jinzhu/gorm)\` when I had to handle heavy and redundant SQL. Tho it's very complete, it can be a pain to find a balance between clean code and useful code when going with it. And I strongly recommend vendoring when using such library especially if you mostly rely on it will have a few breaking changes at times where you won't have time to follow the changes. &amp;#x200B; Other than that, \`awesome-go\` is a very good source to find and explore what's out there and if you are curious you should have a look at most of what's on it. &amp;#x200B; Hope it helps!
Wouldn't speak up over a typo if this weren't a newbie/returning thread. The JetBrains IDE is GoLan**d** with a "d".
And for that, you have my respect. :)
Nice first go project, I have taken a brief look and have a few questions/comments: 1) By using JWT with a single claim, you can never revoke tokens and the only way to revoke a cookie is by deleting it on the user's computer. So logout does not invalidate any claims. That's a problem with JWT and most authentication methods using JWT use two tokens: One permanent token that can be invalidated and one autogenerated per request with a timeout. That allows you to still process authorizations at lightning speed in your endpoint AND at the same time, validate the permanent JWT token and generate a new request token that you add to your header. Because these happen in parallel, it shouldn't slow down your user requests. Check Amazon Cognito for an implementation 2) snippets-page-backend/endpoint/authorization.go you're signing the token with "secret". This should be moved to the config file 3) Consider allowing overrides from ENVIRONMENT variables to your config. It makes deployment much easier (There are libs for that) 4) Consider using middleware instead of calling getUserId in every endpoint. That way a user struct can be ready for you in the endpoint without any efforts 5) addPaginationHeaders points to localhost/. You can probably get away not specifying the FQDN. 6) Well done with the front-end, it's clean and responsive. &amp;#x200B;
I don't think it's about speed -- if you look at the Tengo benchmarks, you'll see that Python is somewhat faster that Tengo, and Lua is significantly faster. I think this has two advantages over those: 1) it's written in pure Go, so easy to integrate/embed into Go projects, and 2) its syntax is very similar to Go syntax, making it familiar for Go devs.
I use vim so I can code on a different system. I miss having an IDE like Xcode that can code complete with arguments. But not enough to make me want to run everything on my local system. 
Thank you. Fixed.
\+1 for dark mode ;)
&gt;I was fairly active with God about 4-5 years ago Was this a typo, or is there a package with a somewhat controversial name? üòä 
&gt; I was fairly active with God Go, with Christ
Your post is objective and factual on this topic, but It should be mentioned that there's something of a schism in the Go communtiy right now. On one side are the folks who are fully onboard with modules; on the other are people who don't agree with the approach of modules, think dep is better, and/or believe the way modules was introduced was poorly handled. Outside of outright failure of modules to deliver a robust solution, I can't see much future in dep, as it becomes increasingly marginalized; regardless, the division is a bit of an elephant in the room at the moment, and the dep advocates are still quite numerous, and dep is currently a viable alternative to modules.
I noticed that you already updated the doc, but this part is still incorrect: &gt;Where `skew_ratio == 0.25`, color will be set to `color` for the first 25% of the cycle period, then to current color until the end of the cycle It should be either `skew_ratio == 0.75`, or `duty_cycle == 0.25`.
Just curious why fmt for stdout and log for stderr? seems like it could be a bit weird to read through the logs?
No prob, mate. Just looking out for the newbies, trying to make their googling a lil bit easier.
Ahh, I must have been looking at the wrong speed comparisons the first time I checked out the docs. 
(I did not make this) Worth comparing, a different person created a timesheet app using Vue and Go. [https://github.com/valasek/timesheet](https://github.com/valasek/timesheet)
tl;dr on Flutter? I've researched it only scratched the surface and most of the focus seems to be on hot reloading. I've been watching gomobile but it's nowhere near ready to be used any time soon so I'm interested in other Go-on-Android possibilities. Is Flutter just a UI framework I can use to make a Android/iOS apps with other languages without Java bindings?
Agreed. Just use fmt.Fprint(os.Stderr, ...)
https://weberc2.bitbucket.io/posts/go-getting-started.html might help you.
Atom also works really well with go.
I recently wrote 3 starter blogs. More coming... https://marcofranssen.nl
For me right now the killer feature from `dep` that the modules system is missing is the ability to specify the repository from which to load packages. This enables plug-n-play of package implementations. I don't believe this can be done using modules.
My very personal opinion here: For api development, gorilla mux + sqlx is my usual goto solution and should cover most of your needs. Gorm is also a handy library but it can get on your nerves very quickly when working with complex db queries. And I prefer Goland over any other solution (probably because I also use IntelliJ tho)
Flutter is native UI frameworks for building cross platform apps using Dart language. The main target by Flutter team is iOS/Android mobile apps, but there are projects to bring the framework to work on desktop such as Mac and Windows. The link project is one attempt to use Go instead of Dart for programming the UI framework. Internally Flutter is using a C++ Skia graphic engine and does not make use of UI widgets provided by iOS or Android. Typically one would use Dart for Flutter apps and there are many live Flutter apps on the App Store or Play Store. This Go implementation is targeting the desktop. For mobile Dart is the way to go. 
Damn. Thanks for the rundown. Not what I was hoping for.
Some minor nitpicking: if this snippets page were a real application, I'd prefer changing "username cannot be less than 3 bits" to "username must be at least X characters long." Anyway, nice job. Vue + Go is my favorite combination. I use the same tech on one of my real projects: [https://crashtested.co/](https://crashtested.co/) &amp;#x200B;
I'm using Emacs and the Go support is fantastic. Out of the box, it uses the formatting tool automatically when you save which a bit of getting used to but is great. &amp;#x200B; Of course, that probably only makes sense if you're already comfortable with Emacs.
Can you explain what you mean some more? Sounds like go mod‚Äôs replace directive, but maybe not. 
I'll give you a real world example. I run this site which has a backend written in Go: [https://crashtested.co](https://crashtested.co) CrashTested serves as a source of aggregated helmet safety data. In order to display all of the safety data on the page, I need to do the following: 1. Scrape several different government websites and pull out relevant safety data 2. Call an API to get price information for each product I'm listing on the site 3. Find images for each helmet and put them on a CDN If I tried to do all of this synchronously and for each request to the page, it would take hours to render each page view. Instead of doing this, I decided on an approach where I use a background worker to pre-render all of this information on a nightly basis, and said background worker is implemented using Goroutines and channels. With this approach, I can simply push an item onto the channel for each URL in item #1 to scrape, and then read results off the channel. This works great because I can let Go worry about efficient allocation of threads, which URL should be parsed by which thread, and so-on. After this process runs, I then output the results of the scrape to a denormalized database table that is efficient to query on, and let the frontend call an API to read the denormalized data. Comparing results, I used to use a synchronous process (i.e. without goroutines/channels/etc) and it would still take hours to run; using channels I'm able to finish the entire process in \~5 minutes. Hopefully this helps clarify things.
Why not? Method is the same regular function, just the first argument is a bit special.
go fmt only does formatting, you should always use it. golang-ci is a [linter](https://en.wikipedia.org/wiki/Lint_(software)), it analyzes the source and gives options on what to improve/fix.
Am I correct that go pkg can only load data from csv?
You are absolutely correct - it hadn't dawned on me that the go runtime would map the original import path to the new one.
I don't understand what you mean by asking about using functions as goroutines. Compared to what? Your choices are to use named functions or anonymous/function literals. Either way you end up calling a function in a goroutine. Maybe you are meaning to make that comparison, in which case I would offer that using a named free function or a method means the logic is reusable compared to a local scope anonymous function. However the latter offers the benefit of closures over the local scope. 
ah, yeap, fixed, thanks :)
Everyone on my team uses VS Code with the go plugins
I think he is asking if there is anything different/weird when you do it with a method instead. I think it's a reasonable question if you don't have a good mental model of what's going on under the hood.
What does it add to the Unix/Linux split and cat programs?
Are you questioning the existence of God in your despair?
Ah thanks, was wondering how to do this. Our code is hosted in VSTS which has an underscore in the path (/_git/...), so I've had to mess with import paths and my package manager (glide) to get it working.
[removed]
Oh wow. I misread the question. 
Its really too bad that your post was down-voted. Its a legitimate question and isn't easily "Googleable" since **it doesn't exist yet** but **it is being worked on**. The Go team, and some others, are actually working on a "Module Index", according to the recent blog post about modules: https://blog.golang.org/#TOC_4. &gt; We are working on a new service, the Go Module Index, that will provide a public log of packages entering the Go ecosystem. Sites like godoc.org and goreportcard.com will be able to watch this log for new entries instead of each independently implementing code to find new packages. We also want the service to allow looking up packages using simple queries, to allow goimports to add imports for packages that have not yet been downloaded to the local system.
Fun project :) Did you consider using the "image/color" and "image/png" packages instead of generating a PPM?
I'm trying to walk the line between remaining faithful to the original text while also writing idiomatic Go. I'd never before considered streaming stdout to a PPM and I love the simplicity of that option (vs adding a dependency). That said, using modern compressed image formats is certainly more practical for anything that isn't a toy :)
Would be silly to create a method for just a few lines of code. An anonymous function works just as well, and is much more readable in this case.
Yes, I can absolutely understand wanting to keep the code aligned with the original text. The packages I mentioned is part of the Go standard library, so at least they aren't third party dependencies :)
Thank you. It's similar to a debugger: attaches to the tracee process, sets the breakpoints and continues until the tracee hits the breakpoint. One difference is it sets the breakpoints to the next possibly called functions (rather than the next instruction or line).
I recommend cross compiling to Linux locally and/or on CI and building your docker image FROM scratch, like this: https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/ 
Re-post
Could not disagree more. go doSomethingNamedSomethingUseful() Is far better than an anonymous function. Readable code is all about getting the name abstractions right.
&gt; because of this, you can‚Äôt really use a global variable in your app Lost me right there. Not being able to use a global variable is a very good thing!
It depends on the app and what it does. But this is common wisdom in python and node and such. But because go handles concurrency internally from the same app process, the use of global variable is safe (as long as your app runs on one server) 
Have you tried Qt bindings for Go, I didn't try it yes but I have seen nice Qt applications On Android
It‚Äôs not a good idea to store a nil value. A bucket cursor uses a nil value to indicate a nested bucket when seeking through the key-value tuples. Use an empty slice instead.
I feel really odd in this camp too - I have it working wonderfully with delved and go-debug too. Have you given vscode a shot and decided to stay?
Thanks, noted.
I tried visual studio 17 with c++ and c# and I absolutely hate it. I havent tried vs code yet.
i know enough to say it is a gross departure from studio so install it and give it a whirl for 1 hour and i‚Äôll do the same and report back
BTW, how about empty struct like \`\`\`struct{}\`\`\`?
You could just use a blob and then json.Marshal(obj). 
True! One of the issues I've run into with the standard image/png package is that it unfortunately doesn't respect gamma and color space metadata... so colors end up looking inconsistent between viewers and usually flatter than they should look from the HDR source data. I've considered fixing it myself but haven't found the time yet to do a sufficiently good job.
how?
Jsonb is better than json if you need do query on that field. bs, err := json.Marshal(map[string]string{...}) // check err _, err = db.Exec(`INSERT INTO ...`, string(bs)) // check err
`var data map[string]string = make(map[string]string) byteData, err := json.Marshal(data) ... error check... ` Then just insert like a standard record. 
Postgresql has native json field type and you can access object fields like foo #&gt; '{key1, key2}'. 
I don‚Äôt use Postgres. It‚Äôs just an option. 
Sigh. I use Sublime. I'm on macOS. I like having a contemporary fast, light weight editor that integrates well with the OS. VSCode feels... weird. Vim is nice, I like it, but I like to just do things like drag and drop files on Sublime icon in my dock and use my mouse to quickly highlight, cut/copy/paste, and probably most importantly, when I used Vim I would often times find myself endlessly tweaking my .vimrc, hehe. 
[removed]
This is awesome. Great job 
[removed]
&gt;We use \`dep\` for everything that has already been set up to use it, and modules for new projects. They both work well, but it's rarely worth it to move a mature project to modules if dep is already doing the job.
So a couple thoughts. This may sound a little harsh, but I‚Äôm unsure of how much experience you have with programming in general. Please use the standard library testing suite (testing) it‚Äôs a lot easier to use than the setup you have now. Reading up on how ‚Äúgo test‚Äù works would be a good start! This has the added benefit that you can do ACTUAL performance testing via. benchmarks, giving you detailed performance info. Good practice is to usually handle the errors instead of just printing them to the console. Currently in your program, if you can‚Äôt get a network connection to something like localhost your program continues running, which shouldn‚Äôt make sense. Additionally, you seem to be repeating a LOT of code. While code repetition isn‚Äôt always a bad thing, a lot of your packages seem to be nearly identical, which is usually a bad thing. I feel like a lot of your behaviour could be simplified by using something like an interface. Structurally, your project is a little disorganized. Your project layout is a lot similar to something I‚Äôd see in a Java/C#/C++ project in regards to sub folders. That structure works better for classes, but Go doesn‚Äôt work like that due to each nested folder being a package. I suggest https://blog.golang.org/organizing-go-code as a good resource for how you should structure your project. Aside from that, there‚Äôs a lot of stuff that really could be improved just by becoming more familiar with the language (stuff like not using the ‚Äúrange‚Äù keyword in looping, having ‚Äúvar k int‚Äù and ‚Äúk = -1‚Äù immediately following it could just be reduced to k := -1). Additionally, you should familiarize yourself with more general best practices for software development. Make sure to check out the tour of Go if you haven‚Äôt already to pickup some of the special forms used, and then make sure to read the ‚ÄúEffective Go‚Äù docs. Hope some of this helped! I wish you the best in your project. You‚Äôve decided on a really ambitious first project with a new language, so try not to worry too much about it! Feel free to PM me if you have any other questions / follow up, I‚Äôd be happy to help.
Thank you!! I'll be in touch for help and try to incorporate all the things you've mentioned! 
Terrific feedback. I found it useful as well. 
[removed]
Assuming you wrote this article; how do you deal with [moire patterns](https://en.wikipedia.org/wiki/Moir%C3%A9_pattern)? If at all.
This is an equally bad idea. Do not store the password in plaintext no matter what, even if the files permissions are okay. The correct method would be to salt and hash the passwords, then store the resulting hash and salt. More info here: https://stackoverflow.com/a/1054033
The print statements are a bit strange. There are many fmt.Printf calls without any format strings. I would either add a format string or switch to Print/Println. For example: fmt.Printf("Root server: ") should be fmt.Printf("%s", "Root server: ") or fmt.Print("Root server: ") Also, I would remove the plus sign to concatenate strings inside Printf. fmt.Printf("Mapping received: " + receive + "\\n") can be changed to fmt.Printf("Mapping received: %s \\n", receive) While the first one does work, I believe the second example is more idiomatic.
Thank you! 
I though you could get full code completion in ViM too?
The actual image resizing is handled by this package [https://github.com/disintegration/imaging](https://github.com/disintegration/imaging) . I'm not an expert on image processing, the aim of the article is more to demonstrate a simple use case of GCP http cloud functions with golang.
Check out some of the stuff source{d} puts out. They may have what you want in terms of automatic review, but their product is relatively new IIRC
Guys I finally found the problem. I was wrong when I was counting the size need for each smaller chunk. I've reduce the number of smaller chunk per time and now it works as intended. Sometimes math is hard.
Found an older post about this, but specifically ‚ÄúAI &amp; ML‚Äù. Hope it helps! https://www.reddit.com/r/golang/comments/8g32lw/question_from_a_student_regarding_learning_ai/?st=JR39ZPHA&amp;sh=c913c050
*Thanks* for the f*eedback. I will consider it.*
Thanks!
if only the view online would work on mobile :(
Nice work. What do you use to host the app ? I see docker container and it runs on Digital Ocean server ? Can you add some details on that ?
Yep always [cool](https://i.imgur.com/e2jaqoI.mp4).
i believe spotify uses the chromium embedded framework instead of electron
I don't think that's a well formulated question. Hence it cannot be really answered in a way that would solve the proposed problem. To begin with, let me point out, that there is a difference between data science and machine learning. However, both of these have one staple requirement, main requirement, to be applied effectively. And that's mathematics. Probability and statistics are dead on requirement. And shallow understanding of it won't be enough. You actually will have to dig deep with all the glory of high level abstractions in maths. To ask, what programming and language to use for it to become a data scientist is to aspire to become a chemist and ask what language should I use to do molecule modeling. That's entire the wrong end to start. Now it's sad that this is not pointed out in rational manner. And a lot of programmers who work with web development, which is to say, they work with I/O devices which manage application state, have no clue about it either, other than knowing it "pays well". Fact that there is plethora of courses which tries to advertise / hype themselves to you aren't very helpful either. &amp;#x200B; Once you get the math part correct, whatever programming tool to use to help you to do the calculus according to mathematical algorithms you come up with be a non-issue. [https://www.youtube.com/watch?v=9cISuEW2T\_M](https://www.youtube.com/watch?v=9cISuEW2T_M) a take on "hypes" generally. It's particulary dangerous to newbies.
You're probably better off using python for ML but if you're dead set on using go, Apache beam is probably relevant to your interests https://beam.apache.org/documentation/sdks/go/
Well, thank you for answers. I am aware of prerequisites regarding all of that. I would like to apply at sourced.tech for a machine learning position when I finish my education, and i've seen that they also use golang for some of their projects. You could not give better answer. Thank you very much :) 
Let the downvotes commence: If you aim to learn a language which could supplement your current stack without taking away anything, Go the most optimal solution. For the reasons other Gophers already pointed out: &gt;In web dev context, go is great in contexts similar to java/spring boot/microservices - it has very similar libraries, is more light weight, faster, and better encapsulated (no jvm). Go is a high level language, and while it provides a bit more control, like attempts to differentiate between stack an heap memory, it's not C++, it's nowhere near C++ in terms of performance. It doesn't have a runtime in terms of virtual machine (jvm, v8 etc), but still runs quite resource expensive process like garbage collection. This makes it not optimal for any kind of FFI (like CPython stuff, when your language calls other language from inside it's context) or even web assembly. If you want to learn additional tool, which would aim to expand your capabilities by integrating without intend or need to replace some of them, give a shot at Rust. Despite what some people may think, Rust and Go are not competitors. You would actually call Rust from Go context where performance is important [https://blog.filippo.io/rustgo/](https://blog.filippo.io/rustgo/) (more about it). Also it's a bit slow to develop with and is fairly complex. If you found Go to be: &gt;it's pretty different from any other language You're in for a surprise. 
Ok. Take a look. For example I need unset 5-th bit of some uint32 flags. For what I should count zeroes? The `(1&lt;&lt;5)` means 5-th bit. I understand mans who want `0b01_00`, because I wanted it a far time ago. But in reality, it never need. More than that, it is less useful. All you need is understanding of this two functions https://play.golang.org/p/kQy4R1ylTH_z 
May be I'm wrong about hexadecimal float point numbers. But I'm sure that all other numbers-proposals don't really need. It's just pulling some other language to Go. In reality, it is useless. And I keep talking, that Go is social language. And Go code have to be understandable. And easy to read. This way, number of opportunities should be minimal possible. One way to do something is best way.
At my work once a while I‚Äôm moving python and R services to go (it‚Äôs much cheaper and easier to support). Cannot really say that golang has anything that allows you in 3 clicks get your result.
That URL is very fishy
Yes, actually 5 is 4. E.g. to unset 5-th bit `1 &lt;&lt; 4` required, since `1 &lt;&lt; 0` is first bit.
&gt; I have unpopular opinion about this one, which will not resonated will on this sub. If possible, pick library over framework. The popular opinion of what separates a library from a framework is that you call a library, a library calls you. By that definition, the `http` package is a framework, in that it calls your handlers, so it is true that most will advocate that you use a framework. If your opinion unpopular because you have a fringe definition of framework, or do you advocate handing web requests in a different manner?
Consider not falling back to an external "tar" command, just use the tar package in the standard library ([https://golang.org/pkg/archive/tar/](https://golang.org/pkg/archive/tar/)).
the argv line is incorrect, try changing the plus to comma eg: `exec.Command("tar", "-cvzf", archivePath, dir)`
While all above is true, still - the toolkit matters. Python has a lot of amazing libraries that would allow just to compose the functions to get the results. Same does Scala. In Golang OP would probably start from scratch. And we are not talking about frameworks/platforms like Apache Spark or Hadoop, that allow a developer to focus on the modelling while hiding the mundane tasks of data sharing, partitioning, shuffling across the nodes and handle failures. Golang is cool, but it is not ever close to anything that is suitable for modern ML industry, not talking DS day to day job duties.
Golang's static typing and great multicore performance really helps in such endeavors. Here are some resources to get you started. https://github.com/sjwhitworth/golearn http://gopherdata.io/post/deeplearning_in_go_part_1/ https://github.com/gorgonia/gorgonia https://github.com/glycerine/CloudForest https://github.com/gonum https://github.com/gonum/gonum https://github.com/gopherdata/gophernotes https://github.com/cosmos72/gomacro 
Maybe. I haven‚Äôt seen it tho. Vim can be a nasty beast for figuring it all out. 
Doesn't tensorflow support Go? And if you google, you will see Go has a few ml libs. So if he wants to completely understand ml in Go, to better fit into the company.. go for it. In general I guess it comes down to how quickly a language community implements new ml concepts and the most important one: which lang is more convenient to you? In which are you can quicker provide a result. It also can depend on project sizes tbh as Go is way faster than python I would seriously research the Go options before I decided to do a large project in python. That being said, combining languages is also a great option. When I was writing a project in a bio informatics course I used bash, R and python. Bash to handle terminal arguments and executing R or python with ease, R for graphs and python for more math related tasks.
Yea that should work just fine. You could do it entirely functionally with a closure but this works well too. Relying on sync objects for scaling can be slow too, so just be aware of that. But this pattern certainly will work just fine for small or medium loads. 
Why its weird? I think its clear enough. When I am inspecting the log, I can expect that the log only provide any unexpected behavior in my programs. So, in case I want to pipe the error to viewer (e.g. Mattermost), I am not drowning in any noise, caused by non informative text from stdout.
I wouldn‚Äôt focus on learning ML in Go. The ML space for go is not very mature like it is for Python and C++ (tensorflow specifically). Google has an intro course. Brilliant.org has another. Amazon has another but it‚Äôs tailored to their services. MIT and Standford have online courses you can take for ML taught by some of the brightest and most accomplished ML people out there. I would focus on these. 
When you have to scroll to a different section of the code just to read the few lines that would go in the anon function, you break readability. Naming doesn't fix that.
I doubt tar commands/flags change much across systems, but this will definitely avoid headache in the future by not having to worry about those potential changes across versions and platforms. 
That's fast enough to spin one up per web request, if you're not being picky about performance. :D
There are several Lua implementation available for Go. Just do a quick search on GitHub.
Contributor here. Questions and feedback welcome!
Is the map of pointers vs variables being faster a trick question? I recently read that pointers are slower due to golangs method of searching the pointer.
A closure also works, for example: https://play.golang.org/p/PABCLbO5FbB
[removed]
[removed]
So this is like mage? https://github.com/magefile/mage
Not to be harsh, but I'm not sure you understand the problem you're trying to solve. DNS is a very well-defined protocol that is feature-rich and quite complicated. Your first steps should be trying to understand the protocol. You don't need to write a DNS client; in fact, you should be looking to interact with clients (dig, nslookup). The repo you referenced ([https://github.com/EmilHernvall/dnsguide](https://github.com/EmilHernvall/dnsguide)) outlines a much cleaner methodology for developing a basic DNS server; I suggest you understand that process before writing a line of code. The approach you're taking now is going to result in a complete rewrite. As others have pointed out, your code is a mess, and not just idiomatically. Why do you want to host every zone as a separate go routine, for example? You have at least 4 packages that do the exact same thing; this makes me think that you haven't thought about how you are going to host your zone records. You also should look at how you're logging; you use both "log" and "fmt" to print your code progress. It's pretty messy right now. If you want to see DNS implemented in go, I suggest you checkout [https://github.com/miekg/dns](https://github.com/miekg/dns) This is a widely adopted library that is fully RFC compliant. It also illustrates just how complicated DNS is. I don't want to dissuade you from taking on this project, but I suggest you take on a more manageable project to build your experience with Go. It will help you actually achieve your goal of building a DNS server.
Kind of. In Mage you'll write your tasks in Go, which is way more verbose, but potentially very powerful since you can import libs and do some complex stuff. In Task you write tasks in Bash inside a YAML DSL, which makes the task file shorter. Task also has some features that Mage doesn't like file watcher, and Make-like up-to-date resolution (i.e. you can set it to don't run again if a set of files haven't changed since the last run) and others. Another difference is that Task was also made to be used on non-Go projects. In summary, these tools can have slightly different use cases, and you can even decide to use both.
My code: package main import ( "log" "github.com/gin-gonic/contrib/static" "github.com/gin-gonic/gin" ) func main() { gin := gin.Default() gin.Use(static.Serve("/", static.LocalFile("./src", true))) PORT := ":5000" gin.Run(PORT) log.Println("Listening on port localhost" + PORT) } The error: `Failed to load module script: The server responded with a non-JavaScript MIME type of "text/plain". Strict MIME type checking is enforced for module scripts per HTML spec.`
great. Not that I will be doing it now, what are some good patterns for larger loads? I guess use a distributed task manager?
I searched _‚Äúgolang gin static file content-type‚Äù_ on Google and found this: * https://stackoverflow.com/a/29439630 * https://stackoverflow.com/questions/43113649/a * https://github.com/itsjamie/gin-cors#getting-started * https://skarlso.github.io/2016/02/02/doing-cors-in-go-with-gin-and-json/ * https://github.com/gin-gonic/gin/issues/1595 Let me know if you need more information.
Depends what you‚Äôre doing. If it‚Äôs just an integer (I assume it‚Äôs not) then you generally don‚Äôt need to lock that, and just copy the value on use. 
After using Task for a while I switched to Alfred for one simple reason, Alfred allows passing command line params to tasks. Task only allows using environment variables (at least it did when I used it). In fact I use a combination of Alfred and Realize (for restarting http servers in dev): [https://github.com/kcmerrill/alfred](https://github.com/kcmerrill/alfred) [https://github.com/oxequa/realize](https://github.com/oxequa/realize)
You should probably introduce them to the fact that it is named Go, not golang.
Hey! Thanks for your thoughts! But as I've mentioned in the wiki I first wanted to get familiar with the language and implement a crude version of how I know a DNS works as Phase1 and then get on with the repository I've mentioned. I will be continuing considering all the comments :)
Looks like the trick was adding the line ` mime.AddExtensionType(".mjs", "text/javascript") ` in my app.go.
Regarding #1, are you able to point to the AWS docs or a write up explaining the auth flow?
Concurrency. That‚Äôs the biggest reason to use go over something else. Simplicity. Composition. Speed vs competitors. The fact you can compile it and have a zero dependency application, which is amazing for docker. 
[https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-access-token](https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-using-tokens-with-identity-providers.html#amazon-cognito-user-pools-using-the-access-token) They call them access and refresh token.
The usage on the site shows examples of commands with arguments as well as commands that interpolate env vars. Am I missing something? 
Fantastic, thank you. 
See also my package: https://github.com/carlmjohnson/flagext
I thought it had to be a hack site when I accidentally clicked. It looks like it might be mundane, but the url subdomain choice is awful.
TIL. Thx. 
Sure it does. Plus modern editing means zero scrolling.
Almost every language is popular in Chain: Rust: https://trends.google.com/trends/explore?q=%2Fm%2F0dsbpg6 Node.js https://trends.google.com/trends/explore?q=%2Fm%2F0bbxf89 Scala: https://trends.google.com/trends/explore?q=%2Fm%2F091hdj Haskell: https://trends.google.com/trends/explore?q=%2Fm%2F03j_q Java: https://trends.google.com/trends/explore?q=%2Fm%2F07sbkfb 
Thank you!
fantastic
No tests, hasn‚Äôt been touched in a year. Why share this?
Tanks for the tip, i tried it id didnt recognize the archivePath as file fkag, /u/dejot73 's comment helped, anyways thanks again!
Tanks! This actually solved my problem, while being somewhat complicated i managed to archive files in dirs. While its still missing empty directories it's a progress. Thanks again!
If you want to make it kubernetes native I'd take a different approach. You could extend the kubernetes API with a CRD and implement all the logic in a event driven style with a custom kubernetes controller/operator. The operator could store Benchmark results as secrets. On top of the operator a REST service could run which uses the CRD to interact with the service. A Front-end might be developed on top of that API. All in all that's a few loosely coupled components that might make a good application. It should scale really well because you can issue new benchmarks as separate k8s jobs. It's a bit like brigade from azure but more specific. If you don't want to develop a complete new thing you could also just use brigade as the execution engine and build something on top. Brigade does a lot of things like garbage collecting old jobs and secrets or webhooks to create k8s resources.
Is there something like this but for concurrent writes to the same file?
Maybe the docs are not clear enough about it, but you can also pass variables with a environment-variable-like way: ``` task foo:bar SOME=thing BAR=baz ```
You can just use [WriteAt](https://godoc.org/os#File.WriteAt) for that.
Thanks
For now its only int . &amp;#x200B; My intention is to consume the result and compute a value periodically. Not sure if I should put in the same struct (Work) or have a separate Compute struct which will take the values. &amp;#x200B;
the population of china is 1.5 billion. For comparison, the USA has a population of 330 million. China has nearly twice as many internet users as the USA has citizens.
and not a single word about data races or the built-in race detector
How's the performance compared with other tools? What's the advantage of using Task over anything else besides having better cross platform support?
Where can i get more information on such cases?
It really depends on what you want: If you want to learn whatever is most likely to land you a career, go with a more popular language/framework combo like Ruby/Rails, Java/Spring, or PHP/Laravel. If you want to pump out personal projects without having to learn another language, then just go Node/Express since you already study Javascript. 
There is a tiny gotcha in the html/template docs, [the 1st sentence of introduction](https://golang.org/pkg/html/template/#hdr-Introduction) reads: *"This package wraps package text/template..."*. I skipped over that myself when 1st learning about it, when really that is the entire key to understanding this package: [https://golang.org/pkg/text/template](https://golang.org/pkg/text/template) \- that should give you all the information you need to use html/template effectively. Cheers!
Please share me those usecases. I'm also still pretty new to go. Would love to learn.
No offense, but if you're still learning and don't know enough about goroutines to know about races and race detection, should you really be writing informational pieces such as this?
See eg. * https://golang.org/ref/mem which describes the Go memoryt model is more or less the basis for all this. Quite technical but should be pretty understandable * https://golang.org/doc/articles/race_detector.html describes the data race detector The following are blog posts about the subject. * https://www.sohamkamani.com/blog/2018/02/18/golang-data-race-and-how-to-fix-it/ * https://medium.com/@val_deleplace/does-the-race-detector-catch-all-data-races-1afed51d57fb * https://yourbasic.org/golang/data-races-explained/ But if you have any questions, ask away. Lots of people here willing to help
Why shouldn't he? It's a great learning experience researching such an article. And we as a community should not be condescending towards such posts, but encourage them while pointing OP the missing resources.
Check out my [other comment](https://www.reddit.com/r/golang/comments/ahwca4/concurrency_in_go/eejhz7e/) in this thread for some sources
Just had a look at links you shared. It basically happens only when not using routine properly at first sight. Might be nice to write about this in a follow up blog. Thanks for the heads up.
There is no norm or standard, and it really depends on the purpose and what is consuming it. Personally, I use all lowercase and underscores because I use Protobufs for all object serialization and gRPC-go does this by default. Just aim to eliminate ambiguity throughout your project, and document it well.
Because theres a plague of bad/misinformation out there already. But... be my guest. Continue on. Make a 3rd-party package too and share to Github while you're at it that deadlocks and panics. There's a time and place. If you can't understand that simple concept, good luck on your development endevours. Once you have the rep of pitting out bad stuff, you can't undo that.
Even Ruby is not Ruby on Rails :) FWIW... In fact, Ruby is very similar to Go, where you have Net::HTTP ([https://ruby-doc.org/stdlib-2.6/libdoc/net/http/rdoc/index.html](https://ruby-doc.org/stdlib-2.6/libdoc/net/http/rdoc/index.html)) as the "default" (if one can say that), and then there are many frameworks of which Ruby on Rails is just one, and arguably, not necessarily "the default".
read the chapters in the go programming language on concurrency. 
I don't really understand why you are so bitter about this. &gt; Because theres a plague of bad/misinformation out there already. OP forgot to mention race conditions, while this is certainly an important part with concurrent programming it's not exactly misinformation. &gt; Make a 3rd-party package too and share to Github while you're at it that deadlocks and panics. This is actually a great idea in my opinion. Because it's open source, pull requests can fix this easily, while the repo maintainer will, again, get a great learning experience. That's what an open source community is for isn't it? Also nobody forces you to follow OP's advice, or any blog post for that matter, let alone use any "deadlock-ridden 3rd-party package" &gt; If you can't understand that simple concept, good luck on your development endevours. How are you supposed to learn if not by making mistakes? Imagine OP is the only one in his peer group who is working with Go, which other place should he turn to for help than this community? &gt; Once you have the rep of putting out bad stuff, you can't undo that. Of course you can! Own up to your mistakes, correct your statements in an edit or follow up post, move on. This is an essential skill which everyone should try to master.
You would be better to start with php. At this moment there are a lot more jobs for junior php programmers. 
The code is extremely simple, [you can check it out yourself](https://golang.org/src/net/http/server.go?s=87455:87501#L2795). As you can see there's a for loop with basically accepts the connection and starts a goroutine. Everytime, no max connections limit check or anything like that.
Those are generally pretty self explanatory. The hardest, and frankly dumbest part of the time library, is custom parsing and formatting. Give me normal strftime values like a normal fucking language. 
There‚Äôs no norm in Go to name JSON fields as there‚Äôs no norm in the JSON spec [1]. --- That being said, most of the projects that I have seen use either: - **snake_case:** popular among C programmers or C-like languages. - **camelCase:** popular among Java programmers, or Java-like languages. - **MixedCaps:** the convention in Go is to use MixedCaps or mixedCaps rather than underscores to write multiword names. This is true for variables, function names, and public struct fields. [2] I remember working in a project with a massive API based on JSON. Because there was so much code, the programmers decided to never write JSON tags, instead, they used the exact name of the struct fields and since public struct fields use MixedCaps they used that through the entire project: JavaScript, configuration files, documentation, etc. [1] https://www.json.org/ [2] https://golang.org/doc/effective_go.html#mixed-caps
People are saying PHP. Don‚Äôt do PHP. It‚Äôs reaching its end of life. It would be like learning ColdFusion 10 years ago. Nobody is building anything modern and serious in PHP anymore. Node can get you a job today, but I personally don‚Äôt believe Node is a good option for backend development, primarily because of a lack of concurrency. It‚Äôs package management is a shitshow too. Even the creator of Node stopped using it and used Go instead. A year ago he started to write a new one like Node based on typescript. Java is a good option as it‚Äôs used in a lot of enterprises who won‚Äôt let go of their monolithic codebases. I‚Äôm not a big fan due to the system footprint to get it online. It just doesn‚Äôt work well in a microservices architecture. Ruby, well, it is sort of falling off is the feelings I‚Äôm getting. I‚Äôm a big fan of Ruby on Rails. It lets you stand up a secure, robust, and scalable monolith very rapidly. The hardest part is design. It‚Äôs an extremely compact language, but extremely slow. It works as a good platform to serve frontend data as well due to its inbuilt asset pipeline. It‚Äôs also nice that it has built in support for web sockets. The job market is reasonably good for rails devs. Microservices work really well with Go. And they‚Äôre becoming extremely popular. CI/CD is big. Focus on those as scalability WILL find you a job regardless of the language you chose. If you want to do web development, I would recommend staying away from learning frameworks, and go directly to learning how to use the language for the web. The exception would be Ruby since there really is no alternative to rails. The reason I say this is that frameworks change all the time. Half of the other recommended frameworks, I‚Äôve never even heard of. They will get you a job today, but it‚Äôs entirely possibly they won‚Äôt even exist in 4 years, or be considered the ‚Äúold way‚Äù. So learn the language and how it does it natively. Learn how those frameworks operate. Learn how to secure web apps, like OWASP. Then at the end, that‚Äôs when you should learn the popular frameworks. At the end of the day, those frameworks are just libraries that make life a little easier instead of writing the raw code. You won‚Äôt learn quite as much. This goes mainly for backend code, but also for frontend stuff. 
I never did any performance comparisons with other tools. In theory, Task itself is pretty lightweight. How much time your tasks will take depends on the commands you're going to run. About the second question... it depends a lot on your use case. What are you looking for in a build tool? You can have a gist of the features [here](https://taskfile.org/#/?id=features) and [here](https://taskfile.org/#/usage).
Not bitter... just frustrated, especially when you come in here and tell individuals it alright to write the book before they learn to read. There's thousands of ways to learn... and IMHO, that's not even close to the proper way. Also, open-source works properly in the way you describe if there's branching (dev, etc.) set properly and peer review. If you just shoot your code out there in master, not knowing what you're doing, people are going to assume... at least for the most part... it works. If your 3rd-party import panics on errors, deadlocks, etc. then it obviously isn't ready for that stage yet. If you're relying on feedback to tackle those issues after your push/merge to master branch... you're, again, doing it wrong.
I was basically in the same situation about 6 months ago. The first thing you have to understand is that no matter how much a language could be/sound good, if the market doesn't care about it, you're doomed (from a working perspective). That said, fortunately Golang is ranking up and coming out from the grey area; many devs are picking it over Node, Python and others, but most of them are probably high skilled devs that works for companies with high budgets and other high skilled devs. The little company of the neighborhood will just stick with the current tools, because they lack budget for improvements, foresight and devs. &amp;#x200B; You'll like to do some personal projects, maybe build a portfolio with those and sell yourself? Golang. You'll like to know if Golang is a good hit for a new backend dev? Sure is it! You'll like to join a crew and board into a new work? Maybe... MAYBE, not Golang. &amp;#x200B; Just keep in mind that PHP, Java, Ruby and Python are widely used and have a HUGE ecosystem, and beside this, believe me, you'll probably don't want to get involved with Python/Node ecosystem. Also, Golang is catching up everyday and coupled with the docker-everything mindset, is a safe bet for the future. &amp;#x200B; In the end, i've choosed Golang over the rest, composition over OOP, single executable over messed upd clusters of scripts, performance over dumb and easy picks. &amp;#x200B; While i can't say to choose Go blindly, i'll definetely suggest it.
Lol the rest of the world is a small village compared with China on terms of population.
I'm sorry but who made the awesome muscular gopher. It looks hilarious
Great work! I am sure that a lot of people will find this useful.
preshing's blog is a great start for concurrent programming :-) https://preshing.com/20120612/an-introduction-to-lock-free-programming/ After that, Golang specific would be a ease. Book "The Art of Multiprocessor Programming" also has great information. https://www.amazon.com/Art-Multiprocessor-Programming-Revised-Reprint/dp/0123973376
How does this differ from https://github.com/klauspost/readahead ?
Hehe, yeah, sure. Just used RoR as synonym for the framework approach.
Fleet is officially discontinued. CoreOS is going to be discontinued this year together with what they developed around it. It'll become Redhad CoreOS/ Fedora CoreOS which has nothing to do with CoreOS. It won't even have rkt instead it'll be bloated with a lot of redhat rpms like NetworkManager and etc.
I did not provide any additional information to go on, just venting my frustration, so thank you for taking it in stride and trying to learn. You are the better person today
It is just amazing. Too bad I can't manage to find the original author... 
Only fags workout.
No problem, I have those days often a well üòâ for 2019 I decided for myself to start my blogging again and therefore learn a lot myself and able to share that with others. Sometimes my writing will be more junior level sometimes it will be more advanced, but that is totally fine as I have both junior and senior readers on my blog. Although the tone of your feedback wasn't really fair, I recognized myself a couple of years ago üòû. Don't worry about it. I now learned the first steps about race conditions. Keep rocking and looking forward to any more feedback.
I always go for camel case, because often the consumer is Javascript. When parsing the json on Javascript side you will then also be compliant with js standards when using the Javascript object.
Thanks, that's the intent !
What?
&gt; It's a great learning experience researching such an article Maybe, but it's a terrible experience reading one and then later finding out that it's incorrect ... and then what do you do when /r/golang links to another article you are interested in next week? Get ready to re-research everything? Just unsubscribe and move on?
You need to read the docs, honestly. Just go to the website and poke around. 
PHP is no where near dying, statistically speaking it is a healthy choice still but not as easy to get a job doing professionally these days. You have to know major frameworks like laravel to really get a job using php. PHP still powers the majority of the internet homie. Rails and Python are still as popular as they used to be. Which is to say they were fairly niche to begin with. You can still learn some Django and get a job working Python and there's still plenty of rails listings out there. Right now from my perspective Go is the only language I can't find a job doing. It's the only language I really like to use these days, but no one is hiring to use it except startups or DevOps / SysAd roles. It's still super niche I think, if you just want a job writing code in go. 
^ correct answer without feelings injected. 
Engo is an ECS game engine written in Golang; maybe it could help: https://github.com/EngoEngine/engo
Honestly with an attitude like yours I would've never started writing. I would've never even started mentoring. I learned more in the process of writing to and mentoring others than I did during my initial learning journey. Part of the beauty of open source is you can submit a PR to fix poor code and help teach someone in the process. Even better, you're not restricted in options of repos to choose from so you have the freedom to choose another package. Now, since you've laid thick your criticism of several things here, here's my criticism for you: someone with your attitude should _never_ be teaching people. You're not forgiving, you lack the ability to reason about a simple mistake versus deliberate misinformation, and you lack ability to communicate without impunity. Your words seem to drip with the idea that someone is out to get you by posting code that doesn't measure up to your quality assessment online, or you know, the fact that some random person posted an article you didn't find comprehensive enough. After typing all of that, I actually think a different career might suit you better. I would never want to work on a team with someone like you, much less be in danger of having someone like you have any sort of influence over my team.
I have a huge respect for all people who deal with SAP software on their own volition without getting mad.
\&gt; let me know if golang would be a good option as a new developer entering and learning back-end Yes. Python/Node are a tiny bit easier to 'get started' because there is no compiler, their language isn't as picky, etc. On the other hand, to fully master those languages is quite complicated. (Most JS programmers have no idea that they aren't using integers and can't store a 64-bit number.) Go has a *very* simple spec. Once you learn the language and master a few concepts (channels/goroutines), you have mastered the language and can go on to higher-level concerns (modularity, etc). The language choices (no unused vars, must declare dependencies per-file, etc) feel like barriers at first, but actually are a godsend when you are reading someone else's code (such as code you wrote 6 months ago.) \&gt; your personal thoughts on golang for web dev Ruby On Rails made a big splash with great ideas on making "getting started" simpler. On the other hand, Ruby the language has far too much "magic" (and even the Rails developers fell into that trap and spent years digging out.) It's worth skimming how that ecosystem works, to get ideas, but I would not advise going that route. Django is similar, but Python has less "magic" to trip you up. Node handles concurrency, but in a strange way ("callback hell"). Newer "promise" libraries + language features help with that. But (IMHO) there are way too many quirks of JavaScript lurking to trip you up. It is easy to find that you need a half-gigabyte of code dependancies required in order to build your code. Nobody understands what is 'underneath' them. (See "leftpad" and NPM) Javascript rules the frontend now, but it's dominance **will** wane once WebASM takes off. Go doesn't have a 'standard' web framework (many are trying, like Gin, Gorilla and Micro). The usual advice is to avoid frameworks and just use the standard library until you find you *really* need one. I find that Go is not just "easy to program", but also "easy to understand" when I come back later.
I like that idea. I was considering doing the same, but my confusion was with the k8s **job** object. My idea is to launch **parallel**, **synchronized** attacks against a target (params specified through the CRD), leveraging multiple node resources. With a *master* (operator) - *worker* (pods) pattern I could achieve this, using **daemonset** worker pods, each hosting an HTTP/gRPC service, receiving commands from the operator, allowing the attack to be launched in sync. How exactly would I manage the synchronization with a **job** object, is what confused me. Since jobs are at the mercy of the k8s scheduler, which could cause the multi-pods to be launched at staggered intervals. (*Maybe this is not a problem, but it makes me wonder*). In any case the first phase of this project is create the HTTP server backend and then proceed to a UI component by leveraging the REST API and also make use of some sort of TimeSeries DB like InfluxDB &amp; a monitoring options like Grafana. PS: Thanks for introducing me to azure/brigade though. I will definitely look into this. &amp;#x200B;
&gt; wants to learn how to program &gt; writes an enterprise database driver from scratch. Kudos to you dude.
Daemonset doesn't scale well. Jobs could synchronize during a init phase via the master, just like you would do with the daemonset. You could also use anti affinity to schedule jobs across the worker nodes.
And he said "litterly"
Well I was scripting before, so I consider this as my first real program. But I had the basics.
What would that *init* mechanism be ? Would the worker pods talk to the master? The other way around would require a *service discovery* solution, for the master to find and connect to the right job pods. Maybe something like, 1. Create CRD -*watcher*\-&gt; operator -&gt; create job(s). 2. (Each jobs) : container-pull -&gt; state ready -&gt; pause for synchronization \[*wait till master says SYNCHRONIZED (poll/event)\]* \-&gt; start 
Node will land you jobs as well
True. OP should really look into what's most popular in the place they want to live after graduation since it varies region to region. 
What is an indicator of compromise?
I wrote my own ECS in Go. From what I recall, there are two main paradigms for ECS: (1) Each entity would be a struct that has an array/slice of some component type. When you add components to that entity, you'd add them to that slice. (2) Each entity is simply an ID, when you add a component to that entity, you are really adding it to some global "component Manager" that manages the lookup and assignment of components from IDs Your solution for using struct embedding to create entities from components is neat, but I think it has the following downsides, mainly: (1) You can't dynamically add/remove components from an entity and (2) you can't easily store your entities, because they are all different types and (3) If you had a way to store all the entities together, it'd be difficult to filter the entities by the component your system needed. FWIW, I went with paradigm (2), Go has the unique challenge of not having Generics, so there was extra work to develop a component manager that could store/retrieve generic components.
Usually on malware reports, the authors specify files hashes, C&amp;C address, etc. These are called indicators of compromise, or IOCs.
Can you help me undertake why JS will wane once WebAsm takes off? What will be driving development in webasm? 
OneOf is a horrible idea. Please return an error message to the user if they aren't using your flags properly, instead of doing something they won't expect.
If they render in a different way intentionally then that's great. Unintentionally, different renderings is probably a drift of some larger kind. Just like colour themes, indentation, highlighting and font ligatures. Font ligatures is probably the best like equivalent comparison here. 
The projects you suggest could vary depending on the level of knowledge of general programming of your students. Given I don't know anything about your target audience, I'd suggest working on a Golang web app. Go does very well when it comes to web and has some excellent documentation. Not to mention, web apps will introduce a variety of basic concepts including goroutines, file management and code organization. In terms of must-haves, the Go doc and Go fmt are generally a good place to start when you're learning Go. Good luck!
I was referring to the thumbnail
Besides China's huge comparative population, decent utf8 support probably helps. Also, there is an inherent distrust of Microsoft which might reduce the use of C#.
&gt; What will be driving development in webasm? The entire rest of the industry. Right now, any front-end framework must be written in JavaScript, or a thin layer on top (i.e. TypeScript). It must deal with all the oddities of Javascript (no way to store 64-bit numbers, makes you think you are using Integers when you aren't, etc.) Once WebASM is stable, it will be "just another target" like OSX or Windows. Almost every language will support it, which means everyone will have a choice in front-end language.
I find this very suspicious that this is your first program / library...
Yes, we developed this tool to reduce the resources required to get the 3,000 service containers and 500 timers off our bare-metal fleets and onto Kubernetes hopefully before spring! :)
Meaning any language would be able to manipulate the DOM like JS? What benefit is that, are applications going to be that intense it requires more on the front end?
Thank you for your recommendation, I'll definitely check it out. Seems a great approach as my image is, to me, hugely sized around 700+ MB.
No it's not. It's a very common pattern in unix programs. For example in gnu ls, `--si` and `-h` works the same way as `OneOf`.
Why are people new to Go publishing blog posts about the language? I don't know anything about car mechanics. You don't see me writing blogs about the internals of the engine.
fuck off
Does it really matter?
When someone claim he's learning to program and release a DB library with serialization, buffer pool and 7k cloc yes it matters because this is definitely not the work of someone "learning programming".
[https://mholt.github.io/curl-to-go/](https://mholt.github.io/curl-to-go/) you should add this to your toolbox!
&gt;Reply Hey thanks for responding but I don't think that program works with all cases [https://imgur.com/a/cjeP6VC](https://imgur.com/a/cjeP6VC) &amp;#x200B;
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/cUzWL8o.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
&gt; It's a very common pattern in unix programs. Even if that were true, that wouldn't mean it's a good idea, especially in applications which take many flags for one invocation. In fact, -h and --si are a perfect example of why it's such a terrible idea, as this one has personally bitten me in the butt before! Appending `-lh` is pretty much instinct at this point, so when I do `ls --si -lh`, it's giving me the incorrect units from what I was expecting (and it's very easy to gloss over K vs k when you don't usually care to look).
Hello! Resorts the `net/url` package, you can easily do this. Here is the demonstrative code snippet. &amp;#x200B; ```go raw := "page\[size\]=10" values, \_ := url.ParseQuery(raw) fmt.Println(values.Encode()) ```
If you apply `-lh` "by instinct" without knowing the exact meaning, that sounds like your problem. No? In unix world it's very common to define aliases for "default" args that you use most of the time, and still allow those default args to be overridden, and that's why this is a common pattern. If your program is complaining about every "wrong" flag combinations, it's both bad for the users (their aliases are much less useful) and you (you have to write a lot more code to check and complain). Also for Go's `flag.Var`, there's the `usage` string to explain what it does. 
for post request ``` payload := url.Values{} payload.Set("page[size]", pageSize) payload.Set("page[number]", pageNumber) req, err := http.NewRequest(http.MethodPost, rawUrl, strings.NewReader(payload.Encode())) if err != nil { // handle err } req.Header.Set("Content-Type", "application/x-www-form-urlencoded") req.Header.Set("Accept", "application/vnd.api+json") req.Header.Set("Authorization", "Token token=" + token) resp, err := http.DefaultClient.Do(req) if err != nil { // handle err } defer resp.Body.Close() // handle body ``` for get request ``` uri, err := url.ParseRequestURI(rawUrl) if err != nil { // handle err } values := uri.Query() values.Set("page[size]", pageSize) values.Set("page[number]", pageNumber) uri.RawQuery = values.Encode() req, err := http.NewRequest(http.MethodGet, uri.String(), nil) if err != nil { // handle err } req.Header.Set("Accept", "application/vnd.api+json") req.Header.Set("Authorization", "Token token=" + token) resp, err := http.DefaultClient.Do(req) if err != nil { // handle err } defer resp.Body.Close() // handle body ``` 
I honestly have no idea why someone would want to go back to the nightmare that is strftime. I would be happy to never have to read http://strftime.org/ again, but life being what it is, I know I will consult it probably a hundred more times between now and when I retire. Go‚Äôs format: can you remember a single arbitrary date? Everyone else: guess what, we made up something called ISO years just to fuck with you. Have fun remember which M is which. 
\&gt; you'll probably don't want to get involved with Python/Node ecosystem. &amp;#x200B; Do you mind elaborating on saying that about Python? I use Go and Python everyday and really enjoy them both. I've been using python on and off for over 10 years though, so I'm probably biased. Just curious as I think its a pretty solid choice. 
thanks! 
thank you! 
&gt; If you apply -lh "by instinct" without knowing the exact meaning, that sounds like your problem. No? Surprise surprise, but users tend to fuck up‚Äîit's actually their specialty. And _when_ they fuck up, they should be notified instead of the application author assuming they know best, because they don't. Ever. It doesn't matter whose fault it is, assigning blame doesn't help when the end result is unexpected (and potentially incorrect) output. &gt; In unix world it's very common to define aliases for "default" args that you use most of the time, and still allow those default args to be overridden, and that's why this is a common pattern. If your program is complaining about every "wrong" flag combinations, it's both bad for the users (their aliases are much less useful) Default flags or common combinations, yes. So if you're straying away from those defaults and are about to use an uncommon set of flags, don't use those aliases. Receiving potentially incorrect data does _far_ more harm than letting the user know that they've screwed up. &gt; (you have to write a lot more code to check and complain). That sucks, but we're engineers. We need to walk the walk. Writing something that can give bad output is simply bad design. It's also not "a lot" more, and it's actually worrying that you'd consider conditional statements a large burden at all, to be frank. I mean hell, it would be a couple more lines at most in your very own package to check if any other flags in that group are also set, and return an error message instead. &gt; Also for Go's flag.Var, there's the usage string to explain what it does. Usage strings: a) rely on the developer to be kept up-to-date without any actual logic to enforce it b) don't stop users from using your application incorrectly c) require users to always remember what's written about the flags (instead of enforcing it), since you've now added special cases
I have to refer to the documentation just as much for go, except I also need to google around because the godoc doesn‚Äôt explicitly say which ‚Äúnumber‚Äù is which field. I‚Äôve put in incorrect date/month too many times before. 
You can never stop users from using your application incorrectly. So there are two styles of defining flags: allow overriding or complain about bad combinations. I provided a **library** for developers to use one of the styles easier, which is already commonly used in mature and battle tested tools, and explained why that style make sense for **some** users; and you keep saying "no that style is horrible and no one should use it". I'm not forcing you to use my library and for developers who may or may not use my library, they'll make the decision by their experience and use case and their user base. I don't really have anything else to say here. ¬Ø\\\_(„ÉÑ)\_/¬Ø (in case you didn't read what I wrote, I showed an example of how to communicate with end-users in the usage string in the docs: https://godoc.org/github.com/fishy/go-flagutils#example-OneOf )
* Bad formatting. * Campaign-links in the links? Spam.
Ah that makes sense, thanks for the help. Looking at Go for gamedev it seems somewhat limited, every game engine doesnt even have controller support, seems its still in its infancy.
Isn't it inefficient to create a new pubsub client on every request? Is there a clean way to perform initialization for cloud functions?
How could it be more explicit? They tell you the reference date and have a couple of different examples you can read too. What else is left to google?
I guess they could add a breakdown like: 1. Month 2. Day of month 3. (Or 15) Hour 4. Minute 5. Second 6. Year But it doesn‚Äôt give you much versus understanding the reference date. Maybe suggest a doc improvement. Still better than strftime by a million miles. 
mad
Readability and no magic. No guessing what function is actually invoked. (And please: Call the language Go.)
If you use postman, it'll give you curl and code examples. It's a pretty useful tool for dealing with rest APIs. I've been using it to tackle some Azure stuff lately. 
I think he was just coming up with an example about how you would communicate with the background function aka the event driven function. Normally for that you wouldn't just use a single standard req/resp Cloud function for the job IIUC
How about in general? How should you handle initialization?
Never used this package but I will definitely be looking into it in the future. 
There is no buffer pool. You don't have to believe me but I take that as a compliment!
Python maybe is the best choice, programing language should not be your limit.
When was the last time you used php for any significant project? You seem out of touch with it.
The operator could inject an ID into the env of the job. The Job could then connect to the master via grpc and call a getInstructionsForID method. Master waits for all jobs for that ID to connect and then instructs whatever it desires via responding.
A while. That‚Äôs my point. 
Then you‚Äôd be unfamiliar with how far it‚Äôs come and how fast php7 is and definitely shouldn‚Äôt be giving advice on it. Many company‚Äôs are polyglot and it‚Äôs a fantastic language for the web. 
I didn‚Äôt say it was slow; facebooks JIT is pretty quick. People are moving to more modern languages for new things for a reason. If you don‚Äôt see that, then I can‚Äôt help you. 
No you said it‚Äôs soon to be dead. Which had been said since 2011, yet still powers the overwhelming majority of websites. 
Thanks for the info! &amp;#x200B; is "*but most of them are probably high skilled devs*" because they work for "*companies with high budgets and other high skilled devs*"? (golang is more commonly applied in large companies?) or is it because golang is intrinsically harder to learn? &amp;#x200B; " *you'll probably don't want to get involved with Python/Node ecosystem* " is it possible for you to expand on this? &amp;#x200B; &amp;#x200B; &amp;#x200B;
Because Wordpress... and most of that is people bolting on plugins and making a total mess. 
Again, I don‚Äôt see it going anywhere. But to each their own. 
A single commit two years ago - is this package actively maintained?
Pull requests welcomed ;)
Composition over OOP - makes no sense as a sentence. Composition is one of the main OO patterns. What you probably are referring is class based OO feature: inheritance. Which is sparsly used if at all. OO itself only suggest that you compose code via software entities which hold data (fields) and or behaviors (methods). 
I don't quite follow. Handle in init in the same file as his Send handler.
Thank you!
That's true, was a typo, thanks for pointing out. I'm so fucking pissed and overwhelmed by my coworkers with their "oop = inheritance" mindset that I've forgot to make it clear for the op! 
thanks :)
thanks a lot
thanks 
You can try [Beeceptor.com](https://Beeceptor.com) as well. It gives proxying capabilities where you can define mocking rules. Well, this technique us about wrapping an external domain in to another. &amp;#x200B; The go-github library takes an argument \`defaultBaseURL\` where you can put Beeceptor endpoint. In the Beeceptor endpoint, add "https://api.github.com/" as Target URL. That way you can inspect the payloads as well as mock some calls.
&gt; Meaning any language would be able to manipulate the DOM like JS? Correct? &gt; are applications going to be that intense it requires more on the front end? Are you serious? We past that point many _years_ ago. The *average* web page is delivered with [1MB of JavaScript code](https://medium.com/@addyosmani/the-cost-of-javascript-in-2018-7d8950fbb5d4). Specialized pages like Google Sheets, Facebook, or LinkedIn are in the 5-7MB range. Yes, Megabytes of *source* code. If that's not intense, I don't know what is.
[removed]
As I understand it, that URL critizises browsers for hiding or downplaying parts of the URL that are treated as less important (like 'www').
I pretty much only use go modules as it's just quick and easy for me. Can't really talk about dep unfortunately
Just use new Modules
The first one I ever used was godep. Then I switched to glide. I've since switched to the official modules support and it works fine for me. My only gripe is the way it vendors only the Go source files and leaves out extra resources and non go source that may be needed. It's a current pain point for me and the tickets tracking it don't suggest a fix is coming soon. 
I worked for SAP for couple of years, what you're saying is just the tip of the iceberg.
Variables declared in scope outside the handle itself are kept in memory as long as the cloud function is warm. In practice, this is used for database connections etc. A common pattern is "if null, block and initialize, otherwise continue". When cloud functions have a lot of traffic, they will spin up 2nd, 3rd etc instances behind the scenes to handle all the requests, so you can have multiple connections remaining open until the instances are sounds back down, similar to having multiple Docker containers going at a time.
Golang didn't have a good solution for a long time, which is why you find so much information on the community projects. Nowadays, use modules. 
It is seemingly very popular in china and not just based on google trends. Many of their big corporations including heavy weights like alibaba for example use golang. Also its very agile nature coupled with startup and cloud friendless probably is a factor. There are many golang projects from china with some having documentation only in Chinese. Also, many of the proxies to bypass the great firewall are written in Go. 
out of curiosity, where do you think Gonum could be useful for you?
Welcome to social media - a never ending race to the bottom, fueled by negativity and conflict, rewarded by upvotes and likes.
Thank you for your comments. To clarify: In development and test every service talks to its own database. In production all services talk to the same database instance (i.e. the same Postgres instance), but use a completely isolated database schema inside the instance. You are absolutely correct that the one database introduces a single point of failure. We only use the one database in production because from a purely operational standpoint it is currently easier to manage one database instance with a failover architecture instead of managing multiple separate database instances for every service. As soon as performance or other constraints require it, we can move each of the services databases to a completely separate database instance. Also, the benefit of true "micro-services" and the limit of what can be classified as micro-service is debatable. We use our GraphQL API gateway to provide a single frontend endpoint for all the backend services. This makes it easier to explore the api and get an overview of what is actually available on the system. In addition, it provides us with the means of authentication so this does not need to be implemented for every service separately. The actual services are rather easy to implement: \- The service interface is specified using proto definitions (see the grpc framework at [https://grpc.io](https://grpc.io) for details) \- This is compiled to a Go interface using the protoc-generator. Additionally we created a small utility that allows us to set custom tags on the structs generated from the proto files ([https://github.com/dkfbasel/protobuf](https://github.com/dkfbasel/protobuf)) \- Each service will start a grpc server that we pass a custom server struct with a db connection \- The server struct implements all the methods specified in the proto-definitions. However all direct database interactions are encapsulated in a separate "repository" package. This allows us to test the respective "use cases" with mock databases or change the database that is used (i.e. Postgres, RethinkDB, Bolt, ...) without actually needing to change any code in the use cases. There are quite a few talks and books about micro services. There are also nice frameworks like go-kit and go-micro that may be a good fit for you. A comparison can be found here: [https://medium.com/seek-blog/microservices-in-go-2fc1570f6800](https://medium.com/seek-blog/microservices-in-go-2fc1570f6800) In the end you have to find something that works for you. &amp;#x200B;
Just out of curiosity from the title, how much are config reads typically a performance critical hot path?
I kinda like the way errors are handled in go. For me, there‚Äôs elegancy in simplicity. 
Thanks a lot. Super helpful. I will go through all the links posted. &amp;#x200B; As per go-kit, I tried it but I ended up abandoning it as it was too verbose and it required you to use a lot of \`interface{}\`. I will take a look at go-micro. I think there was a topic on it on \`r/golang\` last week or something 
All these things have been discussed hundred times already. Just search and you'll find plenty results on both subjects, a way to handle repetitive \`if err != nil\` blocks and discussions on proposals to avoid this repetitive behavior. There will be no \`try/catch\`.
Basic question: What problem does hot config load solve? Eliminating server restarts, and this is important when you are doing several pushes a day and want to minimize user downtime? I'm trying to understand when would I need this, and if my conjecture is correct. Thanks
Not that this helps much but it saves a bit, instead of: &amp;#x200B; err:=doStuff() if err!=nil{ return err } &amp;#x200B; the shorthand can be used: if err:=doStuff(); err!=nil{ return err } &amp;#x200B; Only saves 1 line per check but has the added side effect of containing the error within the block. 
I am new in GO can you give me links about that ? 
You are referring to template nesting, right? Go already supports that
Gravwell's Community Edition license might work for you if there's less than 2GB per day. You can sign up for the free license ([https://www.gravwell.io/download](https://www.gravwell.io/download)), then use our docker container ([https://dev.gravwell.io/docs/#!configuration/docker.md](https://dev.gravwell.io/docs/#!configuration/docker.md)) or just install the debian packages ([https://dev.gravwell.io/docs/#!quickstart/quickstart.md#Debian\_repository](https://dev.gravwell.io/docs/#!quickstart/quickstart.md#Debian_repository)). If you're already dumping the logs to files on-disk, the file follow ingester can pick them up easily. We also have an ingester that can listen for syslog messages directly if you prefer. &amp;#x200B; Gravwell's got a built-in JSON parser so extracting values can be really easy, but exploring the data is primarily done through our query syntax (which is bash-style). Once you have the searches you care about you can drop them in a dashboard for easy monitoring.
I searched and everything I found was just a different type of repetitiveness. What I have done in my own code was to isolate everything in functions that would encapsulate other functions and all those would just return the error in a tree like structure from each component of my app, and then have the error management done only at the route level. It is not a bad solution. I am already getting used to glossing over the error lines and just reading the lines in between them. So it is not bad The best I could find is that in some language like node putting a bunch of stuff in try-catch would allow the lines after the error to continue executing which is understandably bad. But I don‚Äôt see why the Go designers didn‚Äôt include a version of try-catch that would stop the entire block executing if an error occurs in one of the lines. In a sense, the error checking would still occur but hidden as far as the written code is concerned to show up only in the catch. I guess that is my real question. Especially that one of the stated goals of Go is avoid unnecessary verbosity as far as I have seen. 
Generating a hash from a password, returns an error, I guess may be too long of a string can cause the function to fail Also comparing a hash and a password returns an error rather than the simple Boolean value of true or false. 
Go is well-suited for GCP Cloud Functions due to their fantastic performance and GCP's very thorough (and performant) Go SDK.
It's common practice to handle errors, if your function can fail then it should return an error. You can stop the execution by simply returning T, error or just plain error. &amp;#x200B; In the future, maybe you'll work as a programmer. When you're writing code, think about the next person that's gonna work on that code. 
&gt; I have even noticed that some functions that should really have no common reason to fail are designed to return the errors like bcrypt or uuid. If something can fail, no matter how uncommon, those failures should be handled. A function signature does not change whether or not errors can happen, only whether or not that function tells you when there is an error. When creating or comparing a hash errors can happen. Sure they won't most of the time, but you should be building for what can happen and not just want you hope will happen most of the time.
Your view about errors is wrong. Errors are used to identify the exact nature of the problem and log them. Take a look at [https://github.com/golang/crypto/blob/master/bcrypt/bcrypt.go](https://github.com/golang/crypto/blob/master/bcrypt/bcrypt.go) and you'll see why a simple bool cannot be used.
You can have globally scoped variables, declare them outside of your main func. Lazily initializing them is the best practice. https://cloud.google.com/functions/docs/bestpractices/networking
It is a good practice. I don't think that most people question what is being done, but how.
https://blog.golang.org/gopher
I wrote a blog post specifically for people who are new to Go about how to reframe thinking about boilerplate and repetition like this, maybe you'll enjoy it: https://medium.com/@shazow/code-boilerplate-is-it-always-bad-934827efcfc7
One possibility is to have a func catch(err error) that contains the if err != nil {} block, but it would have to be very generic and obfuscates how you‚Äôre actually handling the error. As others have said, you should have proper handling in place when errors occur that handle the cleanup of each specific situation. Personally the if err != nil {} blocks have grown on me, and they might for you too. Be explicit in your code paths, and don‚Äôt obfuscate too much.
If your able to do more on the front end you inevitably will do more and keep pushing the limits of the front end. There will always be more user tracking and monitoring. I‚Äôm sure using something other than JS will be incredibly beneficial I‚Äôm not disagreeing but it feels user network connectivity speed serves a much larger benefit. 
I have the same questions as the other guys. Just leaving this comment to come back to it later. 
According to your link, they're not lazily initializing, they're using `init` functions which is fair enough.
https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md Just wait for Go2
There are quite a few cases where you might want dynamic configuration. Several stacks that I've worked on have had config that users can change on the fly to change things like logging levels, maintenance mode etc. You can also use it where you might not have DNS or a service mesh etc handling auto-discovery, maybe in cases where you need to list out all IPs for potential connections to a message bus that can scale up or maybe even down.
At my place, they use ELK stack but it would be probably overkill for your case.
Oops, this is one with lazy client initialization. https://github.com/GoogleCloudPlatform/golang-samples/blob/master/functions/tips/lazy.go As mentioned in the networking best-practices section, there are non-zero resources used to initialize a new client and these resources can be exhausted.
In other languages, you usually rely on your web framework having a giant "catch(err)" around your entire web request. &amp;#x200B; Only after running for a while will you realize that some things need better control of the errors, so you go back and add your own "catch()" within your routine for the 'dangerous' routines. In Go, you are forced to think about all of it when coding. It is a bit annoying, but leads to more robust software overall. (Just like Go complaining about unused vars/imports -- other languages allow them, but that is literally just technical debt that is likely to cause someone to waste time down the road.)
Zero-downtime hot config reloads are the use-case. Granted this would be better suited by a distributed key-value store (eg: etcd) but having similar functionality served by file-based config files is also good.
&gt;No need to be patronizing. Especially when you might just be less competent professional. I'm not trying to be patronizing. What part did seem patronizing?
&gt;In the future, maybe you'll work as a programmer. When you're writing code, think about the next person that's gonna work on that code. &amp;#x200B;
How does this compare to [https://github.com/micro/go-config](https://github.com/micro/go-config)?
I was serious. No insult intended. 
As mentioned elsewhere there is the ELK stack. ElasticSearch would be your central store for your logs. Logstash can ingest log files or you can use a Logrus Logstash hook and pipe logs directly to Logstash via HTTP. Kibana would be used to read a live-feed of the logs themselves, you can also produce time-series visualizations in Kibana. The ELK stack can be resource intensive (ie: RAM and disk space usage) though. Prometheus + Grafana is also an option.
Languages that have exceptions tend to result into gross misuse of the latter. Consider parsing numbers in C# where parser signals error (string is not a representation of a number) as an exception. The only reason it's implemented that way is the language did not have multiple return values at the time (now it can return tuples). This propagates into other code and one has to wrap blocks of code into try/catch because anything can throw an exception unexpectedly. The entire application then is a house of cards. You can, of course, log an exception, including the call stack and nested information. However, troubleshooting it will be a big headache: you have the stack and line numbers but you do not have any idea what specific values were used. To record these values to the log you have to handle the error/exception at the source - exactly where it occurred and before any other action potentially changing values happened. That's what Go advocates with its error handling. To log errors properly in the language with exceptions, you'd have to wrap each individual line that can throw an exception with a try/catch. And that would result into a lot more boilerplate than you nave in Go. Your end-user will also thank you for informative error messages. There is nothing more frustrating than seeing "Oops, something went wrong!" in an error message for the user. The first thought is developer is hiding something or has no idea what he/she is doing. And to provide an informative error message to the user you have to handle it at the source. I enjoy Go error handling and predictability of errors.
Come on, PHP is still cool. &amp;#x200B; I'm not so sure about Go, swift is backed by Apple &amp; Intel and they'll optimize the s\*\*t out of it. It's tricky because Crystal also seems to gain/have lots of traction.
The idea is that if it‚Äôs cheap you can push them into hotter paths, essentially implementing live configuration updates. 
Looks like this works with vault while `go-config` does not yet.
Sumologic is solid and hosted, you can ship 500mb/m free
That is very interesting, essentially it creates a default error function that executes whenever an unhandled error occur unless over written by something else This would be extremely useful for function bodies that return a result and an error. So instead of internally checking each step and returning nil, err you can just have that at the top of the function. And it would propagate down stream. 
&gt; If your able to do more on the front end you inevitably will do more and keep pushing the limits of the front end. Agreed. Many websites today are no longer "HTML", they are real applications that dynamically render pages locally based on JSON data from the server. &gt; There will always be more user tracking and monitoring. That is only a small part of it. &gt; I‚Äôm sure using something other than JS will be incredibly beneficial Correct. &gt; I‚Äôm not disagreeing but it feels user network connectivity speed serves a much larger benefit. Can you elaborate? Are you implying that WebASM files will be bigger? That is to be seen, but the size will be similar to compiled binaries, which are usually smaller than the source code for large projects. Let me walk you thru what I am saying: 1) Programmers use hundreds of languages today. 2) Front-end programmers can only use *one* language today. This limits the number of programmers making frontends, _and_ limits the things they can do. For example, JS is terrible for numerical calculations because the language is so inefficient. (Makes it hard to use Integers, has no control over memory layout, etc) 3) WebASM will let any language be used on the frontend. 4) Therefore, many programmers will start using other languages on the frontend. This will cause a [Cambrian Explosion](https://en.wikipedia.org/wiki/Cambrian_explosion) where new programmers, new ideas, etc will start flowing into the web frontend space.
Have you looked at Nim? Crystal looks promising but they look like they're kinda behind everyone else, and Nim is Python what Crystal is to Nim (and much more once you dig beneath the surface). Go is great for concurrency but I just can't stomach it for much else.
I admit that PHP7 is cooler, and is getting better, but I wrote this to warn IT architects about investing in what I see is a rickety, bloated mess vs. a lean and mean server machine.
Thanks. This is a good explanation 
One pattern I saw was to create a ‚ÄúMust‚Äù function. You wrap the standard function inside the must, which returns the single value and will panic or throw an error if it contains an error. Eg: func A() (interface {}, error) {} func MustA(interface {}, error) interface{} { if err != nil { panic(err) } } I‚Äôm on mobile so excuse my formatting. 
Yeah, you're just intentionally demeaning of other people based on your imagination of what professional software engineer does. That's the problem I was calling out. Making baseless assumptions about other people, when projecting them based on whatever you imagine something is.
Still, how "hot" does a config update path actually become? I'd recon the reconfiguration will take a lot longer than loading a config?
It's enough drama for me...
Personally, I think no. Main reason without even going into language specifics: there's nowhere near as many Go developers as Python developers. Sure its a nice language to pick up, but realistically Go is better used elsewhere, and doesn't possess anywhere near the same quantity of libraries yet.
I've checked Nim a long time ago, it was called nimrod(if I'm not mistaken). It was really similar with Pascal and loved that but was something about the standard library that sucked. I think it was really thin, without some features that were a must for me at that moment. &amp;#x200B; It's more mature now?
It's hard to compare those two languages. Python is an interpreted language, good for fast prototyping, multiplatform (scripts), can be used interactively and easily modified. Go is compiled, binaries are platform-dependent, fast. Too many differences. 
Yeah, that's the one. There's quite a rich stdlib now but it's not all imported by default, like Go. I'd urge you to check it out again - progress is steady and the community is solid.
Even I do love Go very much, i wouldn't say it's a waste of time to learn a new of programming language. Even if PHP isn't a fancy language anymore it's not fair to blame it, tough Go is more elegant in many aspects. 
Do you use IntelliJ or vs code for it? Can you recommend an IntelliJ plugin? 
I use VS Code but I'll ask in the IRC and Telegram about IntelliJ
Go v2 is likely to have a more "sophisticated" form of error handling - there is a draft out for public review and discussion here: https://go.googlesource.com/proposal/+/master/design/go2draft.md. A fairly typical case is a sequence of "if successful, continue down the chain, if not return the error", and the above draft solves that issue (among others). That said, Golang has always been explicit before implicit.
&gt; optional errors &gt; more robust Mate
Define new. I'm reading about go for more then a year. Since couple of months also coding hands on. I have more the 10 years experience with design patterns and architecture and hands-on experience in 3 other programming languages. At the end it is the same trick with different syntax. As I love agile, I also love to share my gained knowledge in an agile way. It would be greedy to keep all of this for myself. Furthermore by writing these blog posts I force myself to get even a better I understanding of the subject myself. Any how if you don't like it, I am open to feedback and improve. But statements like you just made do not add any value for anyone.
I don‚Äôt think the article suggests against learning something new. It‚Äôs just that at this point your energy and time is better spent elsewhere.
I use both Golang and Python extensively and have experience in machine learning and data science as well as "traditional" software development. I really wouldn't recommend Golang as a language for data science due to the following shortcomings: \- Lack of good library support: Python has many amazing libraries for data science and excellent support for numerical computation via numpy (and all other libraries that build upon it like scipy, scikit-learn). It also provides great tooling for data visualization and data cleaning / transformation. \- Lack of interactivity: Golang is not meant to be used interactively (e.g. it doesn't provide a REPL), whereas Python is very-well suited for interactive computation as an interpreted language. Also, with Jupyterhub it provides a very well-designed environment for interactive and exploratory data science. \- Community: There is hardly anyone who uses Golang for exploratory data science, so you will find much less documentation and help on many topics as compared to Python. It can make sense to use Golang for running ML models in production, Tensorflow for example provides Go bindings that let you load and execute models. I wouldn't do the model development in Golang though. If you're interested in that you can check out the documentation at [https://www.tensorflow.org/install/lang\_go](https://www.tensorflow.org/install/lang_go), but note that the Tensorflow API is not covered by Google's stability guarantees so it might change. If you're concerned about executing speed please note that most Python data science libraries like numpy make heavy use of C/C++ code internally, so most of the computing-heavy stuff happens in a fast language (granted most operations are still slower when compared to a hand-coded Golang or C codebase). Julia might be a better alternative if you're looking for a modern language with great support for data science that's not Python.
I dunno, i have mix feelings related to such articles. On one hand i am really happy because Go gets so much traction because i am using it a lot in my day-to-day tasks. On the other hand, i really don't see why people are bashing languages(php in this case) which they have used for years and which helped them quickly build stuff and get where they are now, i don't think it's the tools to be blamed at at this point. 
well, you deleted your original comment that i was replying to, so the whole context of my statement is lost. good job. but to answer your question: at least part of the definition of "new" to Go would be not knowing about data races and the built-in race detector. and please spare me the spiel about how you're just a selfless knowledge sharer. you're not fooling anyone. blogs like these are pure self-promotion with the added benefit of ad-revenue (which i'm sure gets a little boost from sharing links on places such as reddit). you can force yourself to get a better understanding by reading blogs and books written by experts and putting it into practice. writing your own posts does nothing to make you better. 
Yeah, but PHP is a shit language. It's one thing to be a Go zealot, but it's a different thing to not like PHP because it's crap
It feels like if I'm reading config in a loop so tight that the time spent on config reads is significant, then something jinky is going on and my expectations for the latency of some of these config systems is off from the start? I'm having a deficiency of imagination, I think.
This article is great! Just for the concept of 'proportional code' alone.
Well, languages don't have feelings, do they? The point of my article is to guide IT architects AWAY from PHP and towards Go. If someone is thinking about deploying app servers for the cloud based on PHP, and you're betting your company or livelihood on it, then you better not be a dumbass and use Go instead.
Is that the only difference?
Thank! Glad you like it. :)
Your warning is about as useful as just saying "Warning" There was nothing in the article of substance, nothing that would "warn IT architects". It was bland enough you could replace "PHP" with any other language and it'd read the same.
Thanks for replying You are right, but I mean the managing of templates like the set of "master.html, foo.html" and of "master.html, hoge.html" So I shoud rewrite the readme
I've learned a lot from every mistake in my life. But I would go that far to say PHP was one. I earned a lot of money with it, so I feel like saying: it wasn't all that bad ;-) But PHP vs Go is a completely different story alltogether. Eventually we will say in 10 or 20 years: langage X is far more better then Go, but until then: let's enjoy the ride, learn (even from mistakes) and GO forward ;-) (I burned some eeproms back in the days...)
Python, being interpreted language, is great for prototyping. Besides, the critical code is in C/C++, not Python. The latter just uses the libraries. Given that Microsoft is actively building ML.NET, I'd expect something like F# has a better chance than Go. However, if you really like Go and want to do ML in it, nothing is stopping you. Plenty of bindings to ML libraries and great packages built on top of that. Just check [Awesome Go](https://github.com/avelino/awesome-go#machine-learning)
You might be interested in this: https://github.com/purpleidea/mgmt/ Disclosure, I'm the main author.
The unix standard for this is to listen for a signal which then triggers a reload. 
Concurrent Read Safe, but I cant find anything about concurrent safe when the config is getting updated
I've used [go-bindata](https://github.com/jteeuwen/go-bindata jteeuwen/go-bindata) - generates a .go file with all of the contents of a directory, and lets you reference the data using natural paths. Code is feature stable, but looks like it's up in the air as to whom has taken over ownership. 
You might try the new [Loki](https://grafana.com/loki) project from the Grafana folks.
Faster is always better than slower isn‚Äôt it?
Thank you so much, I‚Äôll be looking into this!
&gt;Can Go beat python for ML? You're asking in /r/golang. Are you really expecting representative results? &gt;I wanna see the snake go down. Why would you say this? How is this relevant? Or is it just supposed to be funny? Seems rather immature to me. This whole way of thinking "one thing dominates them all" is just not how it works in reality. &gt;Who‚Äôs going to do it? Go? Rust? Julia? Again, you're asking in /r/golang ... &gt;What‚Äôs your take for reigning ML champ by year 2022? What's your motivation behind this post? Languages hardly matter at all, it's the concepts that are important to know if you want to exceed in a field.
Thanks for the replies. Changing Logging and debug levels are ones I see using.
We read from configs frequently, in some HTTP handlers we may read at least 5 different config values. They come from Kubernete ConfigMaps or Secrets which are mounted in the container, they come from Vault and Etcd and we're also making a MySQL implementation. It's definitely better if it's faster. We also need those to be observable, we don't want to deploy all the time and because we have a lot of pods, a complete deployment can take several minutes. 
Yes you are correct. Our use case is that we load configs from multiple sources, Kubernetes ConfigMaps and Secrets (which are files mounted in the container), from Vault and Etcd, and we want to update these values without reloading, for things like debug mode, print sql queries, timers, pricing configurations, you name it. Because we read these frequently, we need it to be performant. 
As a chinese and a go group creator, I can say: yes ,go is really popular in china.
https://golang.org/pkg/sync/atomic/#Value The example is an http handler.
Two comments: Look into the `httptest` package. It provides what I believe you are looking for. Don‚Äôt use the default `GET` etc methods. They use the global DefaultHTTP client which prevents thorough testing You should pass in a HTTP Client.
Hey, I'm the author of the post. Excellent Question! &amp;#x200B; I realize that I may have made it look like using `syscall` and `unsafe` is the *only* way to interact with the Windows API from Go. I've updated the post to reflect this as an option (with some caveats). &amp;#x200B; Thanks for the feedback!
I don't have too much experience with doing fancy `syscall` stuff on Unix-likes, but I suspect that loading libraries without CGO is only possible on Windows. I don't see a `NewLazyDLL` or similar in the Unix syscall package source. &amp;#x200B; If you find out though, let me know!
You're right, sorry not the package, but the interface for a client (I think). I am actually using an http client called \`resty\` for now. I'll check to see if they have a mock package, though it shouldn't be too hard to create. If I am writing an API, should I create the http client in main, pass it down to the route handler then into the function that needs it? 
Yes, Konfig uses atomic.Value internally. Maybe you should the read the README... :)
I still don't understand how this helps. When I write error messages, I'm almost entirely writing unique error messages for each case of failure.
So you're saying is that they can stick with whatever feature set they like best, and match the performance for just a little bit of code.
Happy to see that they avoid exceptions. It‚Äôs a dreadful design choice as you have no idea how errors are *actually* handled when looking at the code. 
there already is \`try/catch\`: \`panic\` and \`recover\`
Almost 100%, for instance if you choose to enable "debug" logs on the fly, you'll be adding it practically everywhere. And being able to toggle this on the fly is honestly a very good feature. So the more performant it is, the better.
"All other things being equal..." is the bit you're missing.
Disclosure: also working at Lalamove. &amp;#x200B; To expand a bit on this answer, one of the primary drivers for this was the Vault use case. We use Vault to dynamically provision short-lived individual credentials for each application instance to our databases and these rotate faster than our instance life-cycles, so to ensure that the application is always connected, we need to do dynamic reloads. &amp;#x200B; We run on top of Kubernetes and there's a native concept called ConfigMaps that can be mounted as file into the container file system. The way these are mounted are through a series of symlinks and it does a delete/create cycle rather than "overwrite" on the file descriptor, so we decided to go for a pure polling implementation rather than something that uses inotify as noticing when to re-resolve all the links became pretty involved and error-prone (the reload cycle for Kubernetes is also 1 minute on the file itself, so polling every 10 seconds doesn't add "significant" time penalties). ConfigMaps can also be exposed as individual environment variables, which is why we've implemented reading environment variables. &amp;#x200B; The third important source implementation in this package is that you can also read flags given at command line. &amp;#x200B; In the end, this gives you a single interface to be able to read config variables from a wide range of sources. For us, this is the ultimate anti-bikeshedding library for configuration reading. The performance claim is mainly from what we consider "good engineering", rather than something we actually aspired to when writing this package. &amp;#x200B;
The Google trend data must have some problem.
Hi, one of the authors of [gorgonia](https://gorgonia.org/gorgonia) here. It's very important to be explicit about what you're asking. /u/aboukirev has the majority of the ideas right though I disagree one one point. The majority of ML work relies on libraries written in FORTRAN with a C/C++ interface. That is not going to change in the mid run. Python is great for prototyping, I agree, but absolute shite for productionizing. Which is why I got to writing Gorgonia in the first place. It's about as performant as Tensorflow, given that both Gorgonia and Tensorflow use the same backends (i.e. CUDA). With my code I can deploy with a single compile that takes less than 10 seconds to produce. Try doing that with any TF programs. I highly disagree with /u/absdevops' comment about having not enough libraries. As someone who works in machine learning, I will argue that ALL the fundamental libraries are already here. Gonum is the foremost library you'd use for any numerical computing work. Gorgonia provides multidimensional tensors of any types. These two libraries, augmented with the standard library has allowed me to do all sorts of machine learning, from your standard linear regression to fancy stuff like Gaussian processes, not to mention the already obvious deep learning. Go CAN beat Python for the purposes of machine learning. But we cannot do it alone. Come forth and contribute to the libraries, by using them.
I understand ‚ÄúCrystal is to Ruby‚Äù but I‚Äôm curious what dog do you referring to?
Analytics for traffic on my server
Encrypting TCP is precisely what TLS is for: [https://golang.org/pkg/crypto/tls](https://golang.org/pkg/crypto/tls)
LMAO php is fine and has it's place as does go. There are things I would easily use one over the other for. This though that a language is superior is just the same as fan boys battling about windows vs Mac or iOS vs Android. Ideology is moot. Use what works best and move on. 
Yep, was just going to say this. It's a giant security trap to implement this stuff yourself, so do as much of the heavy lifting with TLS as possible. For public certificates you can get your own signed certificates at [let's encrypt](https://letsencrypt.org/). For personal use, you can generate (and sign) your own certificates.
Oh, and don't use `InsecureSkipVerify` if you really care about the connection being secure, it opens you up to man-in-the-middle (MITM) attacks.
This comment reply me happy.
You're saying you don't have lots and lots of instances of: if err != nil { return err } 
Yes, am familiar with configmaps and secrets...makes sense. Thanks for the clarification. &amp;#x200B; On a different note, are you cycling through credentials ("short-lived individual credentials") for security reasons? That seems to be a good best practice to enforce. So, every container instance runs for time t, and has (say) 4 DB credentials that are valid for interval t/4 each. That would be a good module to open-source too ;) &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
[removed]
Disclosure: I also work at Lalamove. Correct. This however provides a generic API to all of the different config sources, so the "end-user" doesn't have to care about the source. This is a part of a bigger effort to open source core libraries that we are using in a large and distributed environment (both in terms of engineers and in terms of scale). It won't suit everyone, but at least you don't pay with performance to get a generic API to be able to get config from any source.
This is a very interesting project that I've followed for a couple of years! I'm really happy to see that it is still alive and kicking! However, in our environment, the problem of "publish and notify" configuration changes are managed by Kubernetes, so this library only really solves the "what to do after configuration changes" part. These two could be perfect partners in crime however, if you aren't running in Kubernetes!
Before I learned Go, I knew JavaScript, where mocking and dependency injection is fairly easy. With Go, I find it pretty hard to mock classes, so I just do those difficult tests in e2e tests. I learned Docker, which is a necessity for good e2e tests. Running the program in a simulated environment lends to realistic and simple to write tests. I unit test as much of the code I can, by putting anything unrelated to http in testable functions. The example is simple enough such that I wouldn't write a test for it, other than the e2e test, but if your code is more complex, you might have a message encoder/decoder struct which can be tested on its own.
Security is definitely one aspect. The other is for tracing. To be able to tell which application instance connected to what instance and ran which queries. Each credential is provisioned for a T we deem reasonable - which is a balance between average application instance life-time and "risk" of one leaking, we do not provision all credentials up front but the application needs to request new ones before the old ones expire to verify that it still has access past its current lease. This is where the hook implementation comes in. We also do not have a fixed t in your example, so we would not be able to tell how many we need to provision up front. Some application instances may live 5 minutes, others may live 1 week. &amp;#x200B; There's actually not any more libraries for managing the Vault secrets, but we are working on a blog post on how we use this library together with Vault for this purpose as soon as the internal documentation is complete. Should be within the next few weeks! Stay tuned :)
I'll definitely have to look into both the OP and this - I've just started a new golang project and was unimpressed with a few things in viper. The project is essentially dead, the main maintainer hasn't touched it for months and there are multiple pull requests for a bug affecting me that just aren't getting merged (search "safewriteconfig" in the GitHub issues). That and the fact it's not documented at all outside of the absolutely not comprehensive readme.
I like `check` and `handle` keywords, really describing what it does perfectly.
What really nice (but abusable) is you can put multiple `handle` blocks and they will run upwards until they found a `handle` block with a return inside it. You can clean up resources easily with this.
I feel like you've got your opinions mixed in with your facts here. Go is a wonderful language and I feel that I have become a much better programmer while learning, it's conventions and style. That being said, as someone who works with PHP professionally I've taken much of what I've learned from Go and applied it to PHP. At this time, one of the biggest benefits of this is the ease on my company that I'm developing with a widely known language. It's a lot easier to hire new or replacement PHP developers than Go one's simply because of popularity. No language is perfect. Go isn't excluded from this. Go is *very* good at web development, but you're shooting yourself in the foot to put down other languages simply because Go is well structured to your use case.
Yep, in general that‚Äôs a good practice for all types of dependencies. For http clients in general, but specifically Go‚Äôs, you only need to make one for the whole API. 
I love go-bindata. There‚Äôs the assetfs package that uses it for embedding html assets into the binary for serving on http. Super handy if you want a single binary http server with html/image/JavaScript assets. 
I'm a fan of changed Cs at the beginning of words to Ks. The Mortal Kombat method.
Crystal is an expressive, statically compiled language that takes syntax features from Ruby. When I first saw it, I thought it was going to be my chosen one languages but it still seems a bit too early. Then I found Nim, which is also an expressive, statically compiled language that takes a lot of styling and syntax from Python (whitespace instead of braces, `for x in y`) or Pascal. There's a lot more to the language under the covers, like a powerful macro system for metaprogramming, but on the surface it's a 'Python that spits out fast &amp; efficient compiled binarys.
&gt;restapiexample.com/golang... Just wondering if you could give an example of why the golang way is so bad in comparison to strftime, I always remember fighting with strftime, yes it is feature complete, and very flexible, standard date formats are really the go, and easily supported. However, very keen to see an example of why the golang way is bad.
Really excellent article. I think your Python example at the beginning is a great example of murdering readability with cleverness and it's all too common.
Yeah, PHP is not my favorite language by any means, but I do like it's frameworks, and I can sure crank out a working prototype in Laravel faster than anything else I know.
What is a usecase for this type of cloud functions? It needs to be heavy enough to not be a good fit on server and not big enough to not timeout in cloud. So ? When is this better than eg. side server with go consumer and rabbitmq?
Great questions. My concern is an open source language is necessary to create ethical AI. I do not see ethics being a cornerstone of the python ML community as a primary goal - more an after thought. So I want to contribute to which ever community of ML programmers already support more ethical human values as the goal and purpose in using technology. 
Exciting! Thank you for your insight and contribution. I want to create ethical ML solutions to real world problems like hunger and education inequality. Perhaps the go community is the one for me. 
Try fetching and downloading images from a gallery. Try both spawning a goroutine for each link, and creating a pool of workers which you feed links as you find them. 
Downvoters please explain your reasons. (45% upvoted as I am writing this.)
There's an example of testing some code that uses http client here: [https://quii.gitbook.io/learn-go-with-tests/go-fundamentals/concurrency](https://quii.gitbook.io/learn-go-with-tests/go-fundamentals/concurrency) &amp;#x200B; Re dependency injection, there's plenty of examples in that book if you want to see that more, including a dedicated chapter on it. &amp;#x200B; Hope it helps! 
GitHub message on the top-level code page: "Sorry, we had to truncate this directory to 1,000 files. 44 entries were omitted from the list." ü§î
This library could definitely support that method of reload as well. The primary feature here is that it provides a common and merged interface for all different sources of configuration and allows you to reload keys that could be read directly from the config object at runtime and/or trigger hooks when certain variables change. An example could be connection details change and that could trigger starting up a new database connection pool that would then be gradually swapped over to.
[removed]
Without checking the sub I thought this was a Kotlin library. Fast to be Gonfig!
The readme says it's just the Swedish word for "config", so I guess it's just a weird situation.
Yea exactly. They need to be far more specific. The documentation leaves a lot to be desired formatting wise. 
How do I parse microseconds? Many standards need that. 
this is ok, all files are there, just not listed on github page
You can use concurrency to speed up even simple and small projects ^^ The good thing is that you can actually *see and measure* the improvement of your program, and you can strive to get a better and better solution! - Encrypt a simple (4 or 5 characters) password with an algorithm (can be something simple as crypt, just md5, or something more advanced). Use the hash to try and bruteforce-guess the original password back. How would you use concurrency? Would you use any specific concurrency patterns? [spoiler!](https://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem) - Implement a [simple ray-tracer](https://github.com/ssloy/tinyraytracer). It's hella fun, and can be done in &lt;300 loc. Now, it's easy to make it concurrent! - You could implement the [Sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes), Matrix Multiplication, or Conway's Game of Life for more math-oriented problems - Build a log aggregator that gathers files from various logfiles in your computer and parses them. - A sudoku solver - Your own http.Server
awesome article. &gt; I‚Äôm glad that I was tweaking my own implementation iteratively rather than spending time working around whichever limitations a generic library might have had. This is so true. And why I really don't like importing dependencies. 
I'll be sticking with Go1 error handling if I get any choice over it. I don't notice the `if err != nil` lines any more (a bit like I don't notice "they said" when reading prose, it might get repeated every other line and I wouldn't notice). I only notice them when they do something unusual or interesting. Likewise, I have an editor snippet for creating them, so it's a couple of keypresses and writing a meaningful error message Knowing that every possible error is at least caught, and given a meaningful error message, is worth some boilerplate. Errors bubbling up to somewhere without any context is a nightmare to debug.
Manually download the HTML of ~50 sites. Try to read every file in memory, then write them to new files that you create. Benchmark the timing. Fairly trivial to do in a single thread. Then, optimize it concurrently. Write the files to disk in a goroutine for each of them; see your benchmark go down. Perhaps add even downloading the HTML files from a given URL concurrently, too. 
Dining philosophers problem is a classic one that's relatively easy to get started with.
looks auto-translated from C to go.
The project indeed looks like a straightforward conversion from C: Go solves what C programs use `libevent` for in a way more programmer-friendly manner, and Go stdlib implements TLS and zlib natively (or one may use github.com/klauspost/compress to go faster, if needed). If this is just a start, and a proper "porting" to native Go features is planned, it's a good start; if not, I still wish it best luck but fail to understand what would be wrong with providing plain `cgo` bindings to `libtor` \+ a higher-level interface, maybe.
&gt; Knowing that every possible error is at least caught, and given a meaningful error message I know, I love this consistency too, but sometimes it's **that** day.
It definitely is, ugly but functional.
&gt;My concern is an open source language is necessary to create ethical AI. Python is open source, it uses [Python Software Foundation License](https://en.wikipedia.org/wiki/Python_Software_Foundation_License). And I'm pretty sure the other languages you mentioned are as well. &gt;I do not see ethics being a cornerstone of the python ML community as a primary goal - more an after thought. What makes you think that, can you elaborate? &gt;So I want to contribute to which ever community of ML programmers already support more ethical human values as the goal and purpose in using technology. I really don't think this has anything to do with a particular language though. Actually, case in point, the PSF License I mentioned above is a very permissive licence, so users and communities can use Python for whatever they want, ethical or not. So, would you rather have a less permissive licence for a programming language that only allows ethical usage?
It's a complex space, and since people won't agree on the same definitions, it's hard to discuss. But there's a lot of overlap. I'm in #mgmtconfig on Freenode with a bunch of others. Feel free to drop by with questions or ping me on here. Good luck!
&gt; This is a very interesting project that I've followed for a couple of years! I'm really happy to see that it is still alive and kicking! Awesome! Yeah, I left RH and am just living off my savings to work on it. We landed an "mcl" language and a bunch of new things. Have a look. &gt; However, in our environment, the problem of "publish and notify" configuration changes are managed by Kubernetes, so this library only really solves the "what to do after configuration changes" part. &gt; &gt; These two could be perfect partners in crime however, if you aren't running in Kubernetes! Yeah, so Kube solves one part of the problem, but not nearly as big of a piece as is needed. Whether you use both together, or just mgmt, is up to you!
This is pretty cool, you can also check out [seerene.me](https://seerene.me) \- seerene follows a similar approach to visualization. 
I think his point was that there are 1044 files in one directory.
Spawn a couple of go routines doing something relatively trivial, handle a signal and gracefully stop all of the goroutines. Simple and often useful. 
Yes. 
I thing the best way to learn concurrency is to read and understand good concurrent programs. There Go website has a copy of a concurrent prime sieve that is really good. I would take that program and tinker with it. Rob Pike wrote some papers on concurrent windowing systems that are also very good.
agree, it looks not nice when you need to scroll-scroll-...-scroll to see the readme
Assuming this was auto-translated to Go from C, what tool was used?
If you're looking for a more Cgo approach, see https://github.com/cretz/bine which uses https://github.com/cretz/tor-static. In fact, later today I am updating Bine's default and tor-static's master to use Tor 0.3.5.7 which, on non-Windows, uses an embedded control socket instead of opening one on a port. 
Thanks! So what would this looks like in my scenario? Since my project establishes a peer to peer connection between two machines any of them could be the server or client. Since there is no dedicated server will each machine running the program have to get their own certificate?
So, we have had this project kicking internally for a while and when we started out, go-config only had file and env as a source. In terms of differences today, go-config has no 'hook' concept, which means you cannot have custom behaviour for when a config actually changes. A good example use case is when db credentials change, you want to actually trigger the creation of a new connection pool and transition over to using that one instead. It also does not use \`Atomic.Value\` underneath, so it has allocs even during get. This gives it performance that is slightly worse than Viper still. We've added them to our benchmarks!
This. As a beginner, or intermediate, or even senior, crypto is not something you wing from scratch. TLS is the only sensible answer.
Oh, I was talking about our library rather than mgmt. For us, the reason we're using Kubernetes-native concepts rather than a 3rd-party tool, such as yours, or plain etcd for configuration is because we deploy with Helm charts. This allows us to tweak all variables in relation to our applications "in one file". If you want to be the first configuration management tool that captures the Kubernetes crowd however, I could recommend looking into allowing to tweak/create configuration using CRDs by writing a Kubernetes operator for mgmt! Since the native configuration management is pretty limited (and so one of the main drivers for our library), there's definitely a need for better solutions that integrate tightly with Kubernetes.
We share some of the blame. We should've said "config handling' rather than 'config management'!
Great post. Good code teaches its reader rather than confusing them with syntactic sugar and terse magic. Go is readable by design.
I had to do it for a take-home interview once but building a load balancer was a fun little project. 
Go Config includes a Watch interface which allows you to observe when changes occur and then act on them. The atomic value point I guess depends on how much of an issue performance is for you but at the same time contributions are always welcome. Obviously rather than contribute you felt building something from the ground up influenced by Viper and Go Config made more sense.
I find it very unlikely that a dedication to ethicality and the implementation language are going to be highly correlated for any combination of ethical position and implementation language. Any ML community that gets large enough is going to regress to the mean.
It can be useful for doing static inspections of go files.... but I don't think it's actually useful for building go code. I would recommend [Mage](https://github.com/magefile/mage) as a build tool (I would... I build it :) It does what it sounds like you want to do - write some go code that builds the rest of your code. Checkout [magefile.org](https://magefile.org) for docs. Basically it's Make, but you write Go instead of bash. So a build.go file might look like this: ``` // +build mage package main import "github.com/magefile/mage/sh" func BuildLinux() error { env := map[string]string{ "GOOS" : "linux" } return sh.RunWith(env, "go", "build", "./...") } ``` Which you could then run by executing `mage buildlinux` in the directory where build.go is. 
The future is now
If the connection could be opened by either machine, then yes, you will probably need to implement a way for each side to both listen as a server (including having a certificate) and to reach out like a client. If you can make an arbitrary choice about who will start a conversation, you don't need to do this in both directions. It's pretty typical that over time a web application will eventually have to reach out to other web servers, thus a lot of websites probably have and http client somewhere. Make sure you look at the docs to see when you should reuse an object vs create a new one. Otherwise you'll have alot of waiting connections sitting around hogging resources without doing any work if you're very chatty and making a new http client each request. (See http://tleyden.github.io/blog/2016/11/21/tuning-the-go-http-client-library-for-load-testing/) Also, you don't necessarily need LetsEncrypt to make sure you're verifying a certificate, but I do agree that you should never skip certificate verification. You can get a cert for something not listening on port 80 (for challenges) if you can do a DNS challenge, but all that might be too much still, and it might not be appropriate to use your domains cert in these applications. You can also add a certificate authority to the trusted certs. See https://forfuncsake.github.io/post/2017/08/trust-extra-ca-cert-in-go-app/ for how to do that in Go. This allows you to keep verifying certs even though they are from a CA you control. You would then need to make sure you guard your CA. Also, I've probably used a lot of terms out of your familiarity zone. I'm sorry, but certs can feel complicated. I can certainly answer questions, though. Someone might point out that other technologies might feel more symmetric or might be more appropriate to the problem if you're sending large files, sending data very often with little pause, or if you're better off streaming etc. However, I have considered those for a team without a lot of experience and chosen the route you're choosing because simple web requests are very well understood and might have more tutorials than anything other than hello world. In the future you might look at net/rpc, grpc, all manner of sockets, etc, but if you need to go there, you will probably also have grown into a more experienced team by then and will know more about what you're looking for.
I'm going to talk about server and client here, but don't get hung up on those terms since all are peers in your scenario. By server I mean the machine getting the starting connection request at the beginning of a conversation (request response cycle of http or perhaps a socket or whatever you use). The server (even if that's all the machines) needs to be listening on a port and that a firewall isn't blocking (machine firewall like ufw on Linux or Windows Firewall or a network level firewall). Clients can generally reach outwards, though sometimes corporate networks will stop you from connecting to specific ports to stop things like a specific game, pings, or maybe other reasons. Another thing to think about is that, depending upon the network, you might have an easier time establishing a connection from the client side. From the server side you might need to open a Windows Firewall rule on the server and you might need to open something on the network depending upon where you are in relation to each other and the type of network hardware / software. If you're on a home network, you're probably going to have no barriers. If you are going across subnets in a commercial setting, you're going to need to ask a sys admin. If everything is a peer but you have a device that's somehow more accessible than the others (a machine sitting in a more public spot to be a web server), then it might be easier for all clients to connect to that server as a central hub for communications since it might be harder for them to connect to each other. Just because it's a web server doesn't mean it can listen on any port and get connections. You'll still need to check the firewall to see that it allows tcp connections.
Discovery is an interesting topic. You might not be able to discover everything because a device needs to want to be discovered. The network hardware will know all connections, but you're trying to find this out as a peer. If you're counting on your application being installed everywhere, that makes it much easier because the devices would be able to all report themselves to a listening application. However, you might find that a lot of devices are accessible. Is it a home or work setting? Operating System? Are you assuming every computer has your app or wanting to also discover machines without your app? If a device doesn't want to be discoverable and doesn't have your app, is that okay, or do you need to know everything your router knows? (That last question is a bit loaded... it would probably require a router with an admin API and you'd need to have the credentials available or you'd be looking at installing your own firmware from an open source project--probably not really what you're looking to do)
I would love to see someone build a [data-source](https://github.com/mholt/timeliner/wiki/Writing-a-Data-Source) that could use CDP/Chrome to actually crawl Facebook and get my friends/family posts as well.
Oh, that's interesting! I missed that concept when going through the documentation even though it is one of the main bullet points! I see it documented here now: [https://micro.mu/docs/go-config.html#watch-path](https://micro.mu/docs/go-config.html#watch-path) if that's correct? Maybe I got confused because of Watchers in the internal implementation of each source vs Watch in the public interface... I do appreciate the use of `Scan()`, feels familiar. Keep up the good work :)
I won't give you my answer outright, since you asked for guidance. Think of it as a graph, with your starting point being a single large address book that leads the finder to one of the nodes in the graph in constant time `O(1)`. Also recall the fact that your data type for both is `string`, which should make it easier to craft the address book, even if there are collisions between `tag` and `id` types (think: what differentiates 2 strings that are nearly very similar?). Hope this helps! If you need a more direct answer I will post my solution. 
You could download a large file in concurrent chunks using HTTP range requests. Should result in a faster overall download.
When building the example code I get the following errors. ``` /usr/local/go/pkg/tool/linux_amd64/link: cannot create /tmp/go-link-950545976/001008.o: open /tmp/go-link-950545976/001008.o: too many open files /usr/local/go/pkg/tool/linux_amd64/link: cannot create /tmp/go-link-950545976/000937.o: open /tmp/go-link-950545976/000937.o: too many open files /usr/local/go/pkg/tool/linux_amd64/link: cannot create /tmp/go-link-950545976/000998.o: open /tmp/go-link-950545976/000998.o: too many open files ``` I'm not quite sure how to fix this. Maybe it's because there's more than a thousand files in the source directory.
Currently my app discovers other Peer's in the same network using mDNS. So as long the application is open on a machine it makes that machine discoverable by other machines running the app in the same network. Once a machine finds another, it attempts to establish a TCP connection using the net package. This all works great so far, but the data transferred between the 2 peers is not encrypted. This is where my confusion and lack of knowledge comes in... Both peers act as a client or server (depending on who initiated the TCP connection). How would I go about using TLS to secure the network traffic? Been reading about it since all responses on this thread point me in that direction, but all I can find online mentions the usual https in a regular client server set up.
It seems like tor-static's build requires mingw, which kind of sucks. I didn't look more into it though.
Thanks. I will git it a whirl. 
All Cgo does, it requires gcc. This is Go's fault, not mine. Granted, there may be issues with Tor on MSVC, but I didn't even try because Go [doesn't support it anyways](https://github.com/golang/go/issues/20982). Per the README, the linked project doesn't support Windows, but if it did, it would require MinGW too.
Fair enough. Although I do have GCC installed and the build still fails. I haven't had time to look into why, but I'll let you know when I do. 
Take a peek at the 0.3.5.x branch btw, I am going to merge that to master sometime today (or real soon).
 type ThingGetter interface { Get(uri string) (*http.Response, error) } type Thing struct { g ThingGetter } func NewThing(g ThingGetter) Thing { return Thing{g} } func (t Thing) DoSomethingUseful(uri string) ([]byte, error) { res, err := t.g.Get(uri) if err != nil { // yadayada... } } &amp;#x200B;
I left a few replies, and I might be repeating some of them, but in short, you "the usual https in a regular client server set up" is correct. You just do it both directions. You'll also be using the server examples in both to receive / respond to incoming messages. And to send messages you'll use an http client https://dlintw.github.io/gobyexample/public/http-client.html So you implement both. You might wind up running the server in a goroutine so that you aren't blocked and can then spin up the logic for the requests (make sure you have delays etc to not DOS each other). Since all the server implementations need a certificate, you need to have one for each, and then the clients need a way to validate the certificate (see people recommending letsencrypt for something chained to a root cert trusted by the operating system OR... see my reply about adding a trusted root ca if you want to use your own). There is a problem of generating certs specific to each machine and then trusting them because they will then need a central place to coordinate with an authority it can always trust with a machine trusted / otherwise preshared certificate. But... if you just need encryption, not authentication, then this is as much as you need.
family friendly task: 1. download bible 2. map out how many occurences each word has into a structure that can easily lookup any words you query it for, but can also answer the question which words occour 10 times 3. now do it concurrently 4. now do it even faster by utilizing a suiting concurrent pattern 5. use pprof to analyze weak spots in your program 6. with knowledge from pprof make it even faster 7. ??? 8. no profit backend developer friendly task: 1. read big csv file 2. serialize it into a structure (for example json) 3. save all serialized data into new file 
Also, if you're on a small enough network that it allows mDNS, you probably don't have to worry about much of the firewall stuff except machine level ones, and if you can already test without encryption, you have those correct, so nix any other worries about that stuff.
On the golang http package docs: [https://golang.org/pkg/net/http/#Request.ParseForm](https://golang.org/pkg/net/http/#Request.ParseForm) &gt;For all requests, ParseForm parses the raw query from the URL and updates r.Form. &gt; &gt;For POST, PUT, and PATCH requests, it also parses the request body as a form and puts the results into both r.PostForm and r.Form. So i assume the FormValue method takes the values from r.PostForm. Check the values in r.Form. &amp;#x200B;
Thanks for all the replies. I appreciate it. As you can probably tell this is the first time I am having to set up TLS myself. I guess a lot of my confusion comes from the fact that the package I am using to discover peers exposes a Connect() method that returns a net.Conn after finding and connecting to a peer. I am then directly using this connection to transfer data. Not using http. I may need to rethink a few things
I think they *are* asking for outright suggestions, particularly because they do already have *a* solution. 
what's the package you're looking at?
While being proficient at it is all well and good, but as several industrial programmers will affirm - if you can avoid writing parallel code, avoid writing parallel code. Note that it‚Äôs probably best to still write code so that it‚Äôs concurrent (in Rob Pike‚Äôs version of the word) Having said that I think the most important things to train yourself for, in addition to the exercises given by other fellow gophers, are: 1. Reasoning about how your goroutines will be destroyed/GCd 2. Reasoning about channel usage and how they will work with or without a buffer. 3. If you want to take your parallel Go code to production and if you‚Äôre remotely under a latency sensitive environment, you should try to understand how your parallel code will interact with the GC. Last thing you want is your GC pauses increasing latency because you wrote shitty parallel code. Pprof is your friend. Good luck!
https://github.com/alabianca/godrop
SQLite is such a good match for this.
Ease eating up your CPU, that's why your system locks
All of your send operations on the channel will block until the receiver is able to read. This will result in 10000000 blocking go routines. Your system doesn't handle that particularly efficient (which depending on the system resources would be expected). Consider that a send operation will block until a corresponding receive operation is ready to receive. When using a buffered channel, the send operation will succeed immediately if there's room in the buffer.
&gt; crashes Linux That's not what it does; it merely exhausts the system's resources. [This](https://en.wikipedia.org/wiki/Magic_SysRq_key) should be your first read for cases like this one.
You should probably set MAXPROCS as well, unless this isn't an issue anymore. 
By what metric are you hoping to improve your solution? Because we're entering the land of tradeoffs. Memory? Performance (read heavy / write heavy)? Is there a specific use where your solution is inadequate for you? That you have sharded your solution suggests you're having *some* kind of problem, unless it was premature optimization. Do you really have that much write contention? It's quite likely that simple code under an RWMutex or even normal Mutex will outperform more complex code. And be much easier to maintain. One possible issue that depends on your implementation. When you return a map (eg a set of tags), are you perhaps going to concurrently modify that same map reference while they try to read it? 
Yeah, except it took me about 2 hours to cross-compile it for my Raspberry Pi last night.
Looked into doing this for obtaining location information for Google Photos, but unfortunately was unable to get CDP profiles to carry over into headless mode, after authenticating in non-headless mode.
This seems like it has similar objectives to perkeep. 
One thing worth pointing out that isn't mentioned from the README is that `ListItems()` from a data source doesn't return just a plain list of items: it returns a list of "item graphs" which can draw relationships between multiple items at once. These relations are stored in the DB and can be rendered in a visualization. For example, you could know which items are replies to other ones, or which items were attached to an email. That's one feature of the design of Timeliner that really excites me. If you're interested in writing a visualization tool, feel free to open an issue to discuss it. I have some ideas, but don't have the time for it right now.
Tangential: have you tried to run this exact same piece of code without any concurrency and seeing how it fares?
Basically, I require the best possible performance for look-ups, inserts and deletes which all happen concurrently. Looks ups will be in much higher quantity, but inserts and deletes will also be happening concurrently. Unique Ids will be around 50,000 and a rough estimate for unique tags is 1000. There will be tags among them which will be associated with all or most the Id's. Sharding was implemented when I required a concurrent map for a different feature and it was done based on necessity at the time. &amp;#x200B; In any case, I am exploring trie now. &amp;#x200B;
You can use the standard library package \`encoding/gob\` for handling the slice of bytes if you don't know the data what format it has. A great post about from the official blog is in [here](https://blog.golang.org/gobs-of-data). &amp;#x200B; If you know the source of the data (eg: json, xml, a text file with Carriage Return in the lines, etc), you can handle it via the standard library that golang provides. 
‚Ä¢ What type of variable is `e` ? ‚Ä¢ How did you read the file into `e.Data` ? ‚Ä¢ Post your code on https://play.golang.org/ so we can reproduce the bug?
e is just refrencing to a struct. I am getting this data from redis storage. And I need to unmarshal it. For refence check the link. [https://play.golang.org/p/xvl85U-gE9z](https://play.golang.org/p/xvl85U-gE9z)
Because of compile errors or because of slow hardware?
No, I was asking you to post a functional code with the error. Like this: https://play.golang.org/p/NSmxgtG-g6D In my version of your code the input is `17 lorem ipsum dolor`. The size is read correctly, as you said, but the data is not. With this code, people can debug and tell you why it is failing. The code that you shared doesn‚Äôt provide enough information for us to say anything useful. I will leave the link here and let other people help you. Good luck.
I have a 2017 MacBook Pro. No compile errors. Just put on a movie during the compilation steps.
Needs a video giving people a primer, IMO
I know, but it seems a bit weird to have 1000+ source files in one directory. 
How does this compare to [Perkeep](https://perkeep.org/)?
There is also a Raylib port for Golang that supports controllers, it is good for prototyping [Raylib-go](https://github.com/gen2brain/raylib-go) 
Regarding the graph side was it all the [memex](https://hyfen.net/memex) talks, reddit and ycombinator posts for doing the rounds last year that inspired you to make this project? 
Yep. Right now it's very early stages, and for technical audiences only at this point.
See the readme.
No, independent inspiration.
I'm a professional developer for 30 years and intrigued, but I'll guess I'll wait :)
Ah, thanks. Sorry, missed that part in my first skim of it
&gt; 10000000 Hey, that's just ~20 GB of system memory! It should run fine on any laptop!
It looks like the MuPDF library is written in C, so it'll probably require some C debugging.
Might just be me not understanding it, but are you getting a segfault while compiling or when running the compiled program?
At run time, at the moment the fits.New line runs
The videos might be worth a quick skim if you are looking for viewer ideas.
So, how much memory does one go routine consume? 20 GB / 100000000 would be 200 bytes? It probably depends on the size of the execution state.
Thanks, I'll check them out!
Thanks for this suggestion. I only have to enable it next time: https://wiki.archlinux.org/index.php/Keyboard_shortcuts It isn't enabled by default in Arch Linux.
If you literally mean that you have `[35 67 114` and so on as your input data, that is, literally a right square brace, a 3, a 5, a space, etc. and you want the byte values, Fscan will not scan that into a []byte. Looking [at the source for scanning](https://golang.org/src/fmt/scan.go#L980), putting a `[]byte` in to the scanning functions will simply copy the input. Fscan is not the inverse of printing in general. If you generated this data in the first place, and you have _any_ ability to do so, the best thing to do is output it better, in a way that you'll be able to read later, as that is not an output format amenable to being read very easily. But if you're stuck with it, you're probably best off just bashing through byte manipulations the old fashioned way, accumulating slices of digits until you have them all and using strconv to convert them or something. There's a whackload of ways to do it, most of the equally annoying, which again goes back to the way this isn't a very convenient data format for pretty much any input method.
why do so many go projects roll their own command line flag handling? i like the elegance of what `urfave/cli.v2` has built to such a degree i am nearly becoming a contributor with my limited usage and frankly i can‚Äôt see why it isn‚Äôt a goto start for anything CLI
So how can devops swap different implementations of interfaces (see my comment further above) with go modules? I haven't had the chance to try it out.
&gt; Helm charts I'm curious how that works out in the medium to long term. I looked at them briefly, but I was not convinced. Can you convince me? &gt; Kubernetes operator I am thoroughly convinced that the "operators pattern" (as conceived by CoreOS) is a huge design smell. And I explained why early on in the process. Nevertheless, it is being pursued. It won't end well IMO.
Generally in these cases, I implement a "perfect" solution with unit tests first, then create the optimized version if required, I try not to prematurely optimize if I can help. But also providing a suggestion, string comparison is always a thing I try to remove out of hot code paths if possible, maybe convert you maps to map of int to int, and store and id (int) for a string, this way, when retrieving a set of tags for example, one lookup to get the int version of the id, and then the results are all retrieved using integer lookup's which are much much faster. Anyway, just my 2 cents worth ¬Ø\\\_(„ÉÑ)\_/¬Ø
I'll admit that I was very skeptical towards operators as well, especially as conceived with the Prometheus one. But with operators even service dependencies become simple yaml statements. With this you can make a helm chart be a template for what you expose to your developers and give them easy toggles in the values file whether they need a MySQL database, how large it is, etc. This depends on a few things. First of all you need a CI pipeline that builds this helm chart independently, then the application developers need to add it as a dependency for their CI pipeline and have a values file that contains the customisations for their project. We use spinnaker to render the correct container tags into the values file. This allows infrastructure to define "allowable ranges" whilst still allowing a large degree of autonomy for the development teams. Operators allow us to define much more granularly things like version upgrade behaviour, to provision users and schemas inside the database as if they were features in Kubernetes. This works especially well for shared infrastructure such as Kafka, where the operator exposes topics and users as well as a cluster through CRDs.
&gt; I haven't needed any concurrency This statement is odd. Concurrency isn't a need, it's the way you structure your program. True, it often helps with Parallelism (which _is_ something you "need" in order to speed things up). But often, it helps to structure your program. Let's say you are ingesting a list of filenames. - You could say `for filename := range filenames { process(filename) }` which reads each file and does some work on it. No concurrency - Or you could say `for filename := range filenames { chan &lt;- filename }`, then `go { filename := range channel { process(filename) } }`. This lets you spawn the number of goroutines you need if you want to add parallelism later. - Or you could say `for filename := range filenames { go {process(filename)} }` and let Go add parallelism, trying all the files at once (probably only OK if you know the number of files is strictly limited) This all seems trivial, but imagine "what files do I process?" is complex and might change. (e.g. maybe it's helpful to start working on the first file before you finish getting the list of files.) Imaging "how do I process files?" is complex and might change, and "what do I do when done with a file?" is complex and might change, etc. Channels let you de-couple your program (similar to moving work into a function call), but in a way that makes tweaking the concurrency trivial.
JSON, [the specification](http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf), doesn't define a strict requirement for object key/field/member name styles. However, as others have already mentioned, there are common "conventions". In fact, there are style guides that dictate styles across different companies and their stacks: - **Google**: https://cloud.google.com/apis/design/naming_convention#field_names - **Microsoft**: https://github.com/Microsoft/api-guidelines/blob/36224ba86f6a85c11ac5ae8e0a19830b2ff58bb1/Guidelines.md#172-casing - **Heroku/Interagent**: https://geemus.gitbooks.io/http-api-design/content/en/requests/downcase-paths-and-attributes.html - **Zalando**: https://opensource.zalando.com/restful-api-guidelines/#json-guidelines ---------------------------------------- With that said, I'd suggest checking out my recent project ["conjson"](https://github.com/Rican7/conjson). Its entire purpose is to handle automatic transformations of JSON representation of Go structure fields into a consistent style. üôÇ
Can you post a bit of code?
 `for _, sheet := range srcFile.Sheets {` `newExcel.Sheet[`[`sheet.Name`](https://sheet.Name)`].AddRow()` `newExcel.Sheet[`[`sheet.Name`](https://sheet.Name)`].Rows[0] = srcFile.Sheet[`[`sheet.Name`](https://sheet.Name)`].Rows[0]` `for r, row := range sheet.Rows {` `newExcel.Sheet[`[`sheet.Name`](https://sheet.Name)`].AddRow()` `for c, cell := range row.Cells {` `if c != 0 &amp;&amp; cell.Value != "" {` `sourceFileHeader := srcFile.Sheet[`[`sheet.Name`](https://sheet.Name)`].Rows[0].Cells[c]` `if _, ok := sourceHeaderMap[`[`sheet.Name`](https://sheet.Name)`][sourceFileHeader.Value]; ok {` `columnIntToUse := sourceHeaderMap[`[`sheet.Name`](https://sheet.Name)`][sourceFileHeader.Value]` `newExcel.Sheet[`[`sheet.Name`](https://sheet.Name)`].Rows[r].Cells[columnIntToUse].Value = cell.Value` `}` &amp;#x200B; `}` `}` `}` `}`
you could assign the list to an unnamed variable: _ := []int{1,2,3} but that's usually a last resort. 
For http functions you can think about iot devices that either send nothing or suddenly huge amounts of data. Or maybe you callbacks from a payment or sms provider and want to streamline that into a queue. For background, processing image or video uploads or something. The advantage is that you don‚Äôt need rabbitmq or a consumer up 24/7 and able to scale in and out more flexible.
&gt; for i := 0; i &lt; len(row.Cells); i++ {
I'm getting an error that says "no new variables on left side of := (build)" 
Oh range row.Cells seems to work, thanks for the help. 
oh sorry, my bad.. use just = and not := 
Go was designed to force conformity. Love it or hate it, everyone's code is written in the same style. You can simply use this btw `for range row.Cells {`
Awesome tool
One added file and one added line to main.go, and you can have a gui where you can tweak those parameters on the fly. Throw this in gui.go // +build gui package main import ( "flag" "fmt" "log" "runtime" "strconv" "strings" "time" rv "github.com/TheGrum/renderview" "github.com/TheGrum/renderview/driver" ) func ParseConstants(value string) []float64 { constants := strings.Split(value, ",") var c []float64 = make([]float64, 0, len(constants)) for _, s := range constants { val, err := strconv.ParseFloat(s, 64) if err != nil { log.Printf("Error parsing %v as a float64", s) } else { c = append(c, val) } } return c } // If people are going to be typing these values, // we need to be more tolerant of invalid values func getFractalFunctionTolerant(fractalName, colouringFuncName string, constants []float64) func(float64, float64, int) (R, G, B, A float64) { fractalFuncUnasserted, valid := fractals[fractalName] //Asserted after validation because if the fractal function's wrong, we'd try to assert nil. if valid != true { fmt.Println("Invalid fractal function.") return nil } fractalFunc := fractalFuncUnasserted.(map[string]interface{})["func"].(func(interface{}, []float64) func(float64, float64, int) (float64, float64, float64, float64)) if len(constants) != fractals[fractalName].(map[string]interface{})["constants"].(int) { fmt.Println("Invalid amount of constants.") return nil } colouringFunc, valid := fractals[fractalName].(map[string]interface{})["colourfuncs"].(map[string]interface{})[colouringFuncName] if valid != true { fmt.Println("Invalid colouring function.") return nil } return fractalFunc(colouringFunc, constants) } func main() { flag.Parse() m := rv.NewBasicRenderModel() m.AddParameters(rv.SetHints(rv.HINT_SIDEBAR, rv.NewStringRP("fractal function", "mandelbrot"), rv.NewStringRP("colour function", "default"), rv.NewStringRP("constants", ""), rv.NewIntRP("iterations", 128), rv.NewIntRP("samples", 1), rv.NewFloat64RP("zoom", 1), rv.NewIntRP("routines", runtime.NumCPU()))...) m.AddParameters(rv.DefaultParameters(false, rv.HINT_SIDEBAR, rv.OPT_AUTO_ZOOM, 0, 0, 2, 2)...) fnP := m.GetParameter("fractal function") cfnP := m.GetParameter("colour function") iterP := m.GetParameter("iterations") smP := m.GetParameter("samples") wP := m.GetParameter("width") hP := m.GetParameter("height") lP := m.GetParameter("left") // rP := m.GetParameter("right") tP := m.GetParameter("top") // bP := m.GetParameter("bottom") rtP := m.GetParameter("routines") zP := m.GetParameter("zoom") constP := m.GetParameter("constants") m.InnerRender = func() { m.Rendering = true // Collect current parameter values //xc := ((rP.GetValueFloat64() - lP.GetValueFloat64()) / 2.0) + lP.GetValueFloat64() //yc := ((bP.GetValueFloat64() - tP.GetValueFloat64()) / 2.0) + tP.GetValueFloat64() xc := lP.GetValueFloat64() yc := tP.GetValueFloat64() f := getNewFractGen(wP.GetValueInt(), hP.GetValueInt(), rtP.GetValueInt(), iterP.GetValueInt(), xc, yc, zP.GetValueFloat64()) consts := ParseConstants(constP.GetValueString()) finalfun := getFractalFunctionTolerant(fnP.GetValueString(), cfnP.GetValueString(), consts) if finalfun != nil { f.generate(finalfun, smP.GetValueInt()) } m.Img = f.fractImg m.Rendering = false } go func(m *rv.BasicRenderModel) { ticker := time.NewTicker(time.Millisecond * 250) for _ = range ticker.C { m.RequestPaint() } }(m) driver.Main(m) } func handleError(err error) { if !(err == nil) { log.Fatal(err) } } And at the top of main.go add // +build !gui then do go build -tags gui and you'll have an interactive version of your program. &amp;#x200B; The zooming and mouse movement is not as smooth as it could be because taking the center point and zoom level is not as good a fit as just taking the coordinates of the containing box - but it does work, in spite of that. And could fit better with a custom zoom function, but this was just a quickie.
I liked this video very much: https://www.youtube.com/attribution_link?a=UJoshk6Ab4M&amp;u=%2Fwatch%3Fv%3D1B71SL6Y0kA%26feature%3Dshare Give your errors a lift ;) 
I would really appreciate a benchmark against built-in Go map.
This doesn't really answer your question, but this is an example of bad parallelism. Compare with this modified version of the program: package main import ( "fmt" "math" ) func main() { fmt.Println(calcpi(10000000)) } // calcpi starts n Go routines to // caluclate an approximation of Pi func calcpi(n float64) float64 { f := float64(0.0) for k := float64(0.0); k &lt; n; k++ { f += 4 * math.Pow(-1, k) / (2*k + 1) } return f } On my computer, when I run the original code I get this: $ time go run orig.go 3.14159255358979 real 0m5.141s user 0m18.364s sys 0m3.770s When I run the single threaded version above I get this: $ time go run single.go 3.1415925535897915 real 0m1.657s user 0m1.287s sys 0m0.198s The single threaded one is roughly 3 times faster, and uses 2 MB of memory vs 60+MB (and the code is shorter and simpler). The smarter way to parallelize this code would be to break it into some small number of workers (roughly 1 per core on your target cpu) and have them use some variant of the loop that goes through one little section of the whole problem space.
Nice code! Now that `go test` has a `-json` flag this tool doesn't need to parse the output itself anymore. Although maybe in this case it's not much of a difference. https://github.com/gotestyourself/gotestsum has colors, but not for the default output. Seems like a possibly improvement.
Machine learning is just a tool to learn a nonlinear decision boundary. If you want it to be ethical feed it ethical data. The techniques and languages largely have nothing to do with ethics. As always, it's people that are the problem, namely, the people that create the training data.
No judgement on the library, it's a good thing that you're trying to make it usable in as many situations as possible, I just wasn't a fan of that claim and its prominence.
A goroutine starts with a 2kb stack, but this can grow if necessary. So 10,000,000 goroutines that stay alive concurrently would allocate 20GB right off the bat. You can find this in the source code at golang.org/src/runtime/stack.go (line 71)
:üëç
Not sure how correct this is or where I remember getting the idea exactly, but this is what I did in the last JSON API Client I wrote: // client.go type Client struct { *http.Client BaseURL string UserAgent string key string } // client_test.go type roundTripFunc func(r *http.Request) (*http.Response, error) func (rt roundTripFunc) RoundTrip(r *http.Request) (*http.Response, error) { return rt(r) } func TestMyClient(t *testing.T) { // ... client := New("apikey") client.Client.Transport = roundTripFunc(func(r *http.Request) (*http.Response, error) { return &amp;http.Response{ StatusCode: http.StatusOK, Body: ioutil.NopCloser(strings.NewReader(body)), }, nil }) // ... } 
üëçüèª
I want to solve this problem at any cost. What do we do? 
Ahhh right. I'll post it soon.
Screenshots in the repo would be really helpful.
Tough question. There doesn't seem to be a clear "Golang" way of structuring files. https://youtu.be/oL6JBUk6tj0 If you look at other answers people have made up their own domain specific methods, copied from other projects, or just used other structures from popular languages/frameworks. 
What about concurrency ?
Race conditions must be handled at user's side as per his/her implementation. However I will try to implement a mutex based lock for read operations i.e for concurrent read. About concurrent write I think it needs to be handled at user's end.
PS :- Concurrency needs to handled at implementation end.
Loud and clear! We will definitely focus more on telling the story of "why we wrote it", rather than hitch announcements on overt claims of performance in the future. :)
[removed]
I would be _really_ surprised if this toy implementation came even close.
Have more patience, the system isn't crashed, just thrashed :) X is kind of an architectural nightmare, and a thrashing system in X can *look* like it's hard-locked because even just moving the mouse cursor takes a bunch of client-server interactions, and memory pressure is preventing the two sides of that communication from actually being loaded at the same time. If you were already *in* a text console, or if you tried a different test like pinging the machine, you would be able to see that the machine is in fact still up, and trying desperately to free up every last little bit of RAM to give to your program (which is in the process of making a zillion allocations), which means that it has dumped its disk caches and any other nonessential reproducible data, swapped out other programs, and started swapping out bits and pieces of your program's data that haven't been used recently. Eventually, either the program will finish, or swap will be exhausted and you'll get a nice out-of-memory error... but progress towards that point gets slower and slower as time goes on, as the system spends more of its time waiting for data to be read in from swap, waiting for data to write out to swap so that it can make room for data to be read in from swap, waiting for common executables and libraries to be read back from disk after they were evicted from cache, etc... All of which is one reason why it doesn't pay to give a system more swap than it really needs; it only increases the amount of time that a runaway process can make the system unusable before it finally OOMs :)
This starter kit might be the closest answer : https://github.com/ribice/gorsk
I strongly disagree on some of this. Spikes is traffic / usage are not good example. If you have a malicious traffic spike you can get into mega costs scenario. For background processing of image, video, pdf and then uploading it to s3 this might be a good scenario. It is a lot of computation force needed on demand. But this has one but. But handlers have timeouts. So it can‚Äôt be a massive job. Also startup time which indicates small jobs are also a waste. Rabbitmq is a queue so it should in theory be good in absorbing traffic and if you are doing payment processing you need to update some source of truth like dB. So spike here could be less fun or you need a queue but this is simply going back to rabbitmq or kafka or any other queue engine. So in reality the amount and level of jobs is not so big for this application. 
Reminds me of myself compiling QT on a Mac Mini 2012 for three hours with all four cores/eight hyperthreads at 100%. Dear C and C++, thank you for giving us nice long coffee/movie breaks.
Awesome! can't wait to take off Lua (Prosody), lol
Multiple narrow interfaces is preferable. OO 101.
Maybe I was not clear but what I meant is that handlers basically only take care of receiving requests and putting it into a queue or bucket and don't do much processing. For the background functions it's to do more heavy work. The advantage is that they can spinup on events like a message in a queue or a file placed in a bucket. So you can start or continue processing.
Doesn't support Go modules yet, does it?
Well in this case it would be good to have a comparison in cost between this usecase and simply having rabbitmq spun up on a box. Because it might be cost effective or might be not. The only job i ever saw good fit for cloud functions was PDF generation. But it was predictable, took some time but not crazy (1+ hours etc). But im not an expert, just only fit i ever used cloud functions for ( and deemed reasonable).
Even if it means passing the same struct as a parameter multiple times?
Thanks for all the replies so far, I understand now that the reason for the unresponsiveness of my system is most probably memory exhaustion because the first loop tries to start too many go routines that all need some state and stack space. I also must mention that the original code in the Wikipedia entry has set n to only 5000 which should run on almost all systems, even with unbuffered channels. I am now surprised that it runs with n = 100 000 000 and a buffered channel with the same buffer size which takes up an additional 800 MB of memory. That means that the garbage collector of Go must be very quick to reclaim the memory of already finished term() routines while the first loop is still starting new ones.
I wish it became part of the standard tool. Nice and useful work. 
Pretty sure I follow her on Twitter
[this](tour.golang.org)
thanks 
&gt; I'll admit that I was very skeptical towards operators as well Here's my reasoning on why I'm not ecstatic about "operators". While they might be helpful at accomplishing certain tasks, they're ultimately incredibly limited (and possibly dangerous) for one very simple reason: They run from a single point in your infrastructure, and therefore their perspective is always biased towards their current "world view". IOW, you can't necessarily make intelligent infrastructure changes, or recover from failures, if the operator is in the wrong place. Fundamentally this is a difficult problem to solve. It requires build algorithms that are _not_ centralized, and moving away from tools that are topologically simplistic. They're attractive because they're easy to understand, but as cluster complexity increases, and as we want to build more intelligent infrastructures, we need better design patterns. If you're convinced, check out my work in this area. It's still early: https://github.com/purpleidea/mgmt/
For example you can take a look for existing project: [https://github.com/umputun/remark](https://github.com/umputun/remark)
They way you like them?
I used https://github.com/apex/up for deploying to AWS &amp; I hope TJ will support GCP, though it's fairly easy for migrating my code to GCP since my entry point is standard request/response 2) Go test https://github.com/kaihendry/goserverless.sg/blob/master/main_test.go works offline for me 3) I use apex logger WithFields like crazy https://github.com/kaihendry/ltabus/blob/master/main.go 4) Up does this for me, I haven't figured it out for GCP yet
you aren't benchmarking correctly. You need to use the `b.N` parameter to execute the code multiple times. Good article on it: https://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go
Thanks.
Am I missing something? C:\Users\SpaceCat\Desktop\romanesgo&gt;go build -tags gui # github.com/mattn/go-gtk/pango C:\Users\SpaceCat\AppData\Local\Temp\go-build891292734\github.com\mattn\go-gtk\pango\_obj\pango.cgo2.o: In function `_cgo_c5b1fe599b84_Cfunc_g_object_unref': C:/GoProjects/src/github.com/mattn/go-gtk/pango/pango.go:58: undefined reference to `g_object_unref' collect2.exe: error: ld returned 1 exit status &amp;#x200B;
this is cool, I was just thinking about making something like this
This is cool, so far I've been using [https://gist.github.com/joncalhoun/d0d765b9485de9cbd6949afbcde9ee04](https://gist.github.com/joncalhoun/d0d765b9485de9cbd6949afbcde9ee04) to get a similar output.
Thank you, I think I have it now: func Benchmark_closest(b *testing.B) { for n := 0; n &lt; b.N; n++ { bs.closest(Point{}) } } https://github.com/kaihendry/ltabus/commit/8cbb3b373c71ad94904a49c5dec85e1b2dfdd55b So 18710 ns/op means 0.18s per lookup?
I wrote something similar in bash just yesterday. Wish I saw this before. 
1ns is 10^-9 seconds.
Not sure why it can't just be one file?
&gt; 18710 Ah so 0.01871 milliseconds. Perhaps it's not worth optimising.
I can recommend Jon Calhoun's courses (both his free one and https://www.usegolang.com/), where you learn by developing something actual, using good, idiomatic Go principles. Other than that, I'd suggest picking something you use every once in a while and re-writing it in Go. It can be a VScode plugin, a perl tool, a small weather javascript api, a markdown-to-html script, or whatever. Having used the tool is important, since you'll be more familiar with the possible pitfalls and the general usability and UX, which will allow you to concentrate on the design philosophy, and make the most out of a clean implementation from scratch.
I'd say it depends on how many stops are being loaded and whether that number is likely to grow, it looks like you're doing a simple double loop to get the closest - nothing wrong with that but with millions of bus stops it might be worth it. &amp;#x200B; Also personally I'd say the way your test is set up is slightly awkward, I'd load the data in the actual test function (or a wrapper), then do b.ResetTimer - that way you fully control the benchmark (or test) and not relying on a global state which may change. 
If you have that you're doing it wrong.
But in my case the distance is calculated again and again without remembering previous values so I guess there is no need. I thought the closest function was slow, to my surprise it isn't really so I don't think I will optimise it.
It does try its best to coordinate but its not perfect. See https://github.com/golang/crypto/blob/057139ce5d2bdbe6fe73c53679e24e9cf007f637/acme/autocert/renewal.go#L83
And only if the file in question exists. (Yes, I pulled it all in to see if I could figure anything out.) If it does not exist, it gives a proper error and the code panics and exits normally after reporting the file being missing. Oddly, I did not get any notice at the command line about the crash - it just silently went away. I instrumented before and after with print statements, though, and it clearly printed just before, and printed nothing after that line, so I'm pretty sure I was getting the same behavior. I tried also with a fake pdf file (contents were just 'Nothing. Invalid PDF.') and got identical results, so I think the problem is probably somewhere in the startup of MuPDF. (The no such file error is prefixed 'fitz:' so I think that is getting short-circuited before the MuPDF code gets called.) If it was successfully calling into the MuPDF code at all, I would expect the rejection of a file lacking the %PDF header at the start would be very quick and should avoid the vast majority of MuPDF code, so if it (the problem) was somewhere in the parsing code, I would expect it not to be hit by a file lacking that header. Hence my theory that it is somewhere in the basic call structure. I used Mingw64's gcc - maybe there is some incompatibility there.
Are there any ERP systems that AREN'T a hot mess? It feels like there's so much money to be made off of support and consulting that they don't have the business case to not suck
How is this different from the venerable https://github.com/stretchr/testify ?
I really like the William Kennedy's approach. [https://github.com/ardanlabs/service](https://github.com/ardanlabs/service)
[removed]
Excellent! I have a prototype running using python/libtorrent, but metadata harvesting is really slow. Can‚Äôt wait to see if this is any better. 
[removed]
Cool! I am working on something similar but this gives me ideas :)
Ignoring unused variables might let coding errors slip through and cause wrong behavior at runtime. This is way harder to find and fix than a clear compile error. 
[removed]
You could try and accept interfaces as parameters instead, and the while testing mock those interfaces
This blog post is quite light on code examples to be truly informative.
Hey, this `gotestsum` package is pretty cool! I've been looking for something to add readability &amp; summary output to my CI pipeline. Any similar packages? Would be great if there were something that also provided some sort of execution framework (for e2e testing)
So how long it should take with default flags. Started it like a half hour ago on my older laptop and it's still going without any feedback(besides saying that it may take a few minutes) and not using any significant resources. Is it possibly something on my side or maybe it's normal?
You can extract part of that function into a function variable to return the input reader. Then you will be able to swap it out for testing: var inputReader = func() io.Reader { return bufio.NewReader(os.Stdin) } And then in your test, for each case: inputReader = func() io.Reader { return strings.NewReader("hi") } 
Are you sure the port is open and forwarded (default is 6881 according to the docs) ?
When you mean swap it out, do you mean in the function being tested? Another user suggested I check out interfaces and I think that might be the way to go, as I can mock the input on an interface and then not have to change the underlying function being tested (aside from constructing the interface)
It starts almost immediately if firewall passes tcp/udp for the port you run on. 
That was needlessly verbose.
Thanks for replying!
Thank you!
Yup, I guess it was something with a laptop it wasn't updated for a long time it works on my PC.
Don't think I fully understand what you want to do but it seems you want to execute an external go app from php with apache. In the setup you've mentioned, it does not make any sense. Why would you do that? What would you gain? And again, why? There's no benefit...
No problem! üôÇ
So you want to build a reverse proxy in a language that you do have access to in order to run a language that you don't. [These already exist in various forms.](https://github.com/michaelfranzl/no.php/blob/master/no.php) For a hobby project it's probably fine, but I doubt there's anything proven and tested for security. This one only has limited HTTP verb support, for example. 
What's the structure of Point? &amp;#x200B;
legend
Hello u/luqku Thanks for sharing your software with us I'm trying to use the WMS downloader but without success. I'm using the binary wms-get-linux-amd64. When I run it, all downloaded PNG images have the same size (433 bytes) and are invalid. Seems that I'm not able to give the correct URL. Here is the command I'm trying: ./wms-get-linux-amd64 --url 'https://www.geoservicos1.segeth.df.gov.br/arcgis/services/Imagens/FOTO_2015/ImageServer/WMSServer' --layer FOTO_2015 --zooms 11 --bbox -48.386143,-16.302271,-47.246812,-15.403790 Could you give some help? Thanks.
Better to ask for a reverse proxy config for the Apache. You run the Go process on another port (e.g. 8888) and the Apache proxies port 80/443 to it.
Good stuff! However, I notice that you are looping over the dictionary, and reading it from a flat file. Any reason you're not building a [trie](https://en.wikipedia.org/wiki/Trie)? It will make your lookups much faster, and the overall size of what you have to store will be smaller.
thank you!
No, I don't really know much about Go, this is my first project. I'll take a look when I get home. Thanks
No, I don't really know much about Go, this is my first project. I'll take a look when I get home. Thanks
This is _great_. I've shared it with my team at work too.
Right. The intention is that in your test before your call get_master_key_from_console() you can set the gopath inputReader to another function. But it also works to use interfaces. That means you need to refactor get_master_key_from_console() to either accept an io.Reader or make it a method on a struct that defaults to os.Stdin but that you could change. 
[Formatted for the playground](https://play.golang.org/p/O2N0Xv_lBQW). I see two major possibilities: 1. They're going for style issues. The var declarations can be easily disposed of. I'm assuming the "all-on-one-line" functions is because you pasted it in and the original code was at least syntactically-correct. 2. They've made a mistake and assumed that this will crash Go or that it is bad Go, because in C that syntax will allocate a variable on the stack which can't be returned to another function like that. It is, however, both legal and idiomatic Go. The compiler is responsible for ensuring that it works, and garbage collection picks up the pieces. I've seen the latter mistake made on /r/golang before, so it's at least a possibility. I hesitate to ascribe that to anybody, but it is rather suspiciously like a very standard C interview question.
Thanks. I was struggling to search for someone with a similar problem, but "reverse proxy" seems to be the word I didn't know I was looking for! It seems the "normal" thing to do with these reverse proxy setups is to host the core web app on a computer different from the computer forwarding the request. Are you suggesting to contact the administrators of the web server to request a "personal" configuration that makes Apache forward HTTP(S) requests made to my page on the server to "localhost:port", while I run a Go HTTP server on the **same** computer listening to that port? The web server hosts web pages for many users, and while I don't have deep knowlege about web servers, I suppose Apache has functionality to filter the HTTP requests it receives so it only forwards the requests made to my page and not the ones made to others' pages.
I would expand on this that if you correctly benchmark simply incrementing an integer, the benchmarking code will happily report on fractions of a nanosecond. (Based on what I saw last time I tried this, it looks like the entire loop is under test, which is ~3 instructions and easily pipelineable by the processor, so a single iteration of such a loop can be less than 1ns on a 2GHz+ CPU.) So the claim that the code is taking 0.00 nanoseconds implies that it is literally finishing in _less_ than one cycle.
Imho it's overly complicated - easier to just pass by value here. &amp;#x200B; \~ package main &amp;#x200B; import ( "fmt" ) &amp;#x200B; func g() int { var i int i = 5 return i } &amp;#x200B; func main() { var j int j = g() fmt.Println(j) } \~
I do think you understand what I'm trying to do. I am considering doing it since I want to write the core of the web app in Go instead of PHP, and since I am restricted by being unable to run a Go HTTP server on the web server. I could, of course, create the web app in PHP, but I want to write it in Go for the purpose of learning to create a web app in a language I like. Thanks for your honesty. I do appreciate it :) If it is impossible to avoid it becoming a mess and deviate too far from the intended way of writing Go web apps, I want to know!
I just formatted it for you &gt;package main &gt; &gt;import ( "fmt" ) &gt; &gt;func g() \*int { &gt; &gt; var i int &gt; &gt; i = 5 &gt; &gt; return &amp;i } &gt; &gt;func main() { &gt; &gt; var j \*int &gt; &gt; j = g() &gt; &gt; fmt.Println(\*j) &gt; &gt;} Oddly though, I think it is correct since i can even compile and run it? The only thing that is special here is that when you return a pointer to a local stack variable, the compiler performs escape analysis and allocates it to heap. But there is nothing wrong with that.
Yes, thats exactly what I suggest. OSI layer 7 HTTP Reverse Proxies like nginx, Apache or HA Proxy can filter by Hostname / servername / vhost, meaning they look at the `Host` header of the HTTP Request and depending on that and maybe depending on other information (like static filenames, where the request comes from, etc), they can forward the request to the specific backend. That way you can host multiple websites with different technology stacks on one server. The reverse proxy often also is able to act as a load balancer, which basically means the same app is running in multiple processes and maybe on multiple computers and the load balancer tries to share the load fair between the backend pool processes.
"Reverse proxy" was the words I was looking for. Thanks!
Thank you for the detailed run-through! I will definitely consider going this route!
Spot on. The interviewer was a low-level C programmer.
Really neat! I was just thinking about sharing my OnionShare implementation in Go that I just created the other day. https://github.com/ciehanski/onionbox. 
Just to be clear, that's not a Go concept, it's a computer science concept. :-)
The interviewer was literally looking for the "escape analysis" explanation. But since it is legal and managed at compile time I began to think it was a trick question.
Have you considered walking through it with a debugger, such as delve? I find that to be very helpful when trying to force myself to slow down and see what the problem is. You can also take the type-directed approach; change the two 32s to an input variable, change the type of c to `[]Series` (which is a different type than `[32]Series`), and then just keep fixing the code. For instance, you'll need to `make` a new slice to make up for changing the constant array to a slice.
What happens if you connect to the database from psql using the same login/pw and dbname and run the query? If you did the exports in your example then I believe this will get you in: `$ psql --dbname=$DBNAME --username=$DBUSER` (it will prompt for password) Then you could paste in the query and see if you get the same error (which would mean you need to create the repositories table) And sorry for asking the obvious, but there's nothing in that tutorial that I see about creating the table and populating it, you *did* do that right? &amp;#x200B; &amp;#x200B; &amp;#x200B;
Yeah, I saw that after checking the link. I thought go implemented it as data structure by default.
I can access database and run the query just fine from the psql shell. Something that might factor in somehow is that I never set a password for postgres and when I login I don't need to supply one. In my Go code I just submit an empty string for the password field
I‚Äôm baffled honestly. Yes it can be cleaned up (:=) and doesn‚Äôt do anything meaningful, but it doesn‚Äôt show anything actually wrong. I won‚Äôt ascribe to some super clever reason for this question. Occam has better explainations. 
In my day job I do a lot of Java stuff and dependencies are the bane of my life. &amp;#x200B; \_Especially\_ when you are using extremely common libraries like Jackson (json parsing) or Guava (extended functionality/utils), these become problematic if you bring in dependencies like the amazon SDK or run in a hosted environment that requires you to use classloaders for running your own code - which also has its fair share of problems. The common solution to all this is to employ dependency shading, or excluding transitive dependencies in favour of something higher on the classpath but it just feels like one massive hack. How does Go handle this? Say for example &amp;#x200B; * I'm using library A version 2 in my own code * I bring in library B which has a transitive dependency on library A version 1 &amp;#x200B; How does go resolve this conflict? &amp;#x200B; &amp;#x200B;
Looks cool!
OP did say it was terrible
That's very fair, but hey we're here to help right?
Let me know if you run into any difficulty with it, happy to un-jargon some stuff and provide some Go pointers.
Lol, not saying your suggestion was inappropriate! just a shitty joke
I find it very hard to digest your question and therefore not sure what I should answers. Could you try rewriting the question in different words?
I'll try: in terms of name casing... Go has mixedCase for variable names and function names. Go has snake_case for package names and file names. JSON has mixedCase or snake_case. Database columns or field names use snake_case (if relational database). I'm wondering if other people notice this, does it bug them, and how do they deal with keeping all of the casing straight in their head when looking at code. 
If I understand correctly you would have to vendor the version 1 of library A in library B's source. Not the most elegant answer, but ensures compatibility across the board as the package will only ever use the vendored source.
&gt; Oddly though, I think it is correct since i can even compile and run it? FTR, that alone isn't a good enough reason :) In C, it's undefined behavior - meaning *in particular* it's allowed to work. Just mentioning that because "I tried it and it works" is a common pitfall, it can still be incorrect. (it's fine in Go, yes)
So what did you say and what was his response? 
This has nothing to do with Tor. The name confused me too.
Though not widely adopted yet, because every library has to introduce module support, go modules introduces a concept called [semantic import versioning](https://research.swtch.com/vgo-import) that allows importing multiple versions of a package by effectively making them different packages.
Maybe hackerrank? They have a bunch of easy to hard problems that can be completed in Go. 
Try prepending the schema name to the table name. 
I said the code would work and that it is handled by Golang. I myself have written C or C++ in over 13 years, most of my production experience is with C#, JavaScript &amp; Python. Go is something I am learning in my own time.
Thank you! I maybe should have added a request for an actual Course Text from an introductory course using golang. This should be useful no matter what. I will see what I can accomplish. 
curious what did you see here that wasn‚Äôt obvious?
Yeah, just dug through the code and was kinda disappointed lol.
This is some pretty funky code: // CheckFor500 checks if the given http status code equals StatusInternalServerError // Input: // t *testing.T The testing object, so we can call the return functions on it // statusCode int The http status code you want to check func CheckFor500(t *testing.T, statusCode int) { if status := statusCode; status != http.StatusInternalServerError { t.Fatalf("wrong status code: got '%d' != '%d' expected", status, http.StatusInternalServerError) } } 
One possible (partial) solution to this problem is distributed reviews for packages: https://github.com/dpc/crev
"The issue is CVE-2019-6486 and Go issue golang.org/issue/29903."
I would try to become a little less focused on whether the intro course is in golang or not. You have two easy options: find a good course in whatever language and get better at programming. Just use that language, you can come back and everything you learned will apply to go as well (to close approximation). Or find a course in some other language and just port the problems over to Go. This will take a little time referencing the Go docs and experimenting but it is instructive, useful time anyway. &amp;#x200B; perfection is the enemy of good here. &amp;#x200B; anyway you might like [https://gameswithgo.org/](https://gameswithgo.org/) which isn't \*exactly\* what you are looking for (its a video series) but I do give some homework problems, and if you get to the evolving pictures project we do a lot of cool comp sci stuff (parsing, lexing, abstract syntax trees, graphics) 
Are your opinions about Go the same now? I'm a mech engr who took a C++ class in college and it was my favorite. Almost switched majors because of it. Wish I did... Anyway, now I self learning comp sci to get a job in dev ops/back end. Front end and JS don't seem appealing to me. Some of your comments were relevant or I shared the same opinion as I am learning go. My first project is creating a personal website to host all my projects and I wanted to build the back end from go so I could learn the fundamentals. Everyone seems to push the MERN stack but I'll pass. Being I want to get into the back end and dev ops do you have a recommendation fro which language to lean? Java vs Go vs C++? The only hesitation going with Go is the job market share. 
It doesn't work for me on Windows, but it does work just fine in WSL on Windows.
The go modules solution is to allow major revs to coexist with different import paths. A compliant module (most aren't, since the ecosystem migration is still in early stages) includes major versions &gt;1 in the import path. So, v0/v1 are imported as `my.url/my-project/package` and v2 is imported as `my.url/my-project/v2/package`. Your dependency is always expressed as `my.url/my-project`, but multiple majors can be imported.
Is the linux (tar.gz) package messed up or is it just me? Has tmp and gocache directories in the tarball.
[removed]
My hunch is that the built-in one will be faster, considering it has optimized cases for string keys and that it already uses a very fast hash... But agree, let's wait for the benchmarks....
Issue CVE-2019-6328 - ‚Äúlol, no generics‚Äù remains unresolved
There was a followup post about an issue with the tar.gz files. &amp;#x200B; &gt;The following commands can be used to extract only the necessary ‚Äúgo‚Äù directory from the archives: &gt; &gt;tar -C /usr/local -xzf go1.11.5.linux-amd64.tar.gz go tar -C /usr/local -xzf go1.10.8.linux-amd64.tar.gz go &amp;#x200B;
This issue is just particularly bad in Java because in Java you can only have a single version of a particular symbol in the built jar. In most other languages (C/Go/etc.) there's no such restriction. This is mainly a side-effect on how JVM works, sadly.
 type Point struct { lat float64 lng float64 } 
Looks good to me. 
My take on it: unless the compiler does something smart to optimize this, that variable will be allocated on the heap. So, while this is legal Go code, we can expect a performance hit here. From a low-level perspective, it would be more efficient to allocate on the stack. 
I figured out that gse breaks text into words (not a trivial problem in Chinese or Japanese), but is that it? The examples don't show output.
 review: thoroughness: high understanding: high ... and probably also claims: exaggerated 
Thanks for the feedback, please give me a detailed code
Thank you
I really like the [Ben Johnson](https://medium.com/@benbjohnson)'s approach: [https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1)
Thanks. It was more a fact that it contains 50MB+ of files that are not needed. Not sure what that means for the .tar.gz size total (looks like it is 14MB more than 1.11.4).
Random delays don't stop timing attacks: https://stackoverflow.com/questions/28395665/could-a-random-sleep-prevent-timing-attacks/28406531
Run it statistically over time and you can work it out by calling sleep. BUT. That‚Äôs a different approach. That‚Äôs taking N time, used to do the processing, and then sleeping R random amount. This is uncoupled entirely from the actual work, and the time is run in parallel. It would be more akin to taking the nanosecond time before the process, then the time after, and sleeping for a random time between the start and total time. One could even drop the random time as well. This is all assuming, of course, that the actual libraries have unknown flaws, and I‚Äôm certainly not writing my own crypto library. 
I expect there will be a follow-up 1.11.6 soon. There is already a fix for the build script.
Thanks. It's all working either way! 
https://gophercises.com/
Have you heard of Amazon web services? You can get a nano server for free for a year (I think? It‚Äôs been a while since I‚Äôve been on the free tier). Then you get a public IP, DNS, and a host where you have cart blanch. You can proxy requests in, but is it viable? Not really. You may even be better off using cgi for the app over proxying, but even that is dying/dead. If, on the other hand, you‚Äôre curious about pushing the bounds, then this could be a totally fun little project that‚Äôll piss off your admins. 
The general approach to solving timing attacks is to use constant time methods and avoid branches, the former of which golang provides in the ["crypto/subtle"](https://golang.org/pkg/crypto/subtle/) package.
Gotcha. But that doesn‚Äôt exactly help when you‚Äôre checking if a user exists in a database and then not checking the password that simply doesn‚Äôt exist. The issue is time invariance. The randomness in my post is a bit of a red herring. It‚Äôs not important to the overall approach. This simply adds time invariance above all the other layers that may add it when dealing with a complex system. 
Ok. Create a local Point and assign it values and be sure the func returns the value. Assigning it locally, you make sure it does not escape the benchmark.
Go will create a binary. I guess you are using a shared web hosting, it‚Äôs not possible in the way you want it. Stick to php.
Rust has recently implemented a great way to quickly print variable name, value, file and location with a 3letter macro `dbg!`. This fits nicely into some workflows when you are trying to debug something quickly and don‚Äôt want to use a full blown debugger. Simply `import . ‚Äúgithub.com/tylerwince/godbg` and now you have the same dbg functionality! See the README for details. If you write python, this also is implemented in pydbg on my github as well. Cheers! 
Nice! I love the dbg! macro, good idea to implement it in Go, will definitely use!
A lot of stuff in there in how I do dependency selection in the first place. Always good to read, but... I must admit, I never puzzled my way into GO itself :-) The Russ'es in this world have prooven my trusts somehow.)
Unfortunately, we can't fully reimplement the dbg! macro, since we won't be able to get an arbitrary expression, print it out verbatim, and return its result.
This is the thing that makes the dbg macro so great in my opinion.
Perhaps a test would be appropriate ;-) Anyways: good to see some interresting stuff. (Perhaps you can find the sourcve of a spellchecker in some programming language and bend it to your needs.)
&gt; since we won't be able to get an arbitrary expression, print it out verbatim, and return its result Provided the source is at a known location (ie. binary is at root of the source directory) you can easily get the calling function file path and line number with `runtime`, it's just a matter of printing that line.
I will never ask such shitty questions. Main reason: my compiler will tell me if it will run or not. But let's assume it runs, what the f\*\*\* is it going to do? What really is wrong with it, that it lacks documentation ;-)
Within a JAR yes. The classloader can choose which JAR file it loads bytecode from and in which order so in practice this isn‚Äôt an issue. 
Those are fair points, thanks for the feedback! About the exit status and the use of \`CommandContext\`, it's what I had done initially but I ended up changing it like this because I prefer returning an error containing nmap's \`stderr\` output rather than the error status; and as for the context, I wanted to catch it in my side of the code to return my own typed error. Does that make sense?
https://golang.org/issue/29903
It doesn't have to be failed to compile. It could be not efficient or taking the wrong approach or even hidden runtime error possibility.
yeah... horrifyingly, that's what this package already attempts to do.
Unfortunately this doesn't work if you don't have the source code with you, which would typically be the case in production.
That isn't an array. It's a slice of C doubles. And the memory is owned by Go so you can't free it with C. It should be garbage collected 
wat
I'm not sure this package has any real use if the source code must be present too...
https://github.com/99designs/gqlgen
Okay, so my memory leak is somewhere else? Thanks! 
graphql-go works well. I did consider gqlgen but wasn‚Äôt sure about the code generation side (how it will cope with a constantly evolving API and not overwriting modified resolvers). 
Great
The API-bindings generator generates the code based on your schema file and replaces anything that might already be there. Yes you can consider that overwriting but that just seems common sense to me. Your code however is untouched. So if some resolver bindings have been changed, you still have to adapt the ones you wrote yourself.
The use case of the function is during debug, it's shouldn't be used in production.
I've run your benchmark locally and I get similar results so would say it's running ok, there's some things that you might want to think about. First I'd write the benchmark this way (no claim its the 'best' way, just how I'd do it): &amp;#x200B; `var foundStop BusStop` &amp;#x200B; `func Benchmark_closest(b *testing.B) {` &amp;#x200B; `bs, err := loadBusJSON("all.json")` `b.Logf("Number of bus stops %v", len(bs))` &amp;#x200B; `if err != nil {` `b.Fatalf("unable to load stops: %v", err)` `}` &amp;#x200B; `b.ResetTimer()` &amp;#x200B; `for n := 0; n &lt; b.N; n++ {` `foundStop = bs.closest(Point{})` `}` `}` &amp;#x200B; This also matches what /u/ianovici is saying about assigning the return value of bs.closest() to a package level variable so the compiler cannot optimize it away (it doesn't seem to in this case anyway but.. best practice etc). Note it doesn't use the bs var from package level but is a local one. You could extract or make up some data if you didn't want to use your production data - this might be useful if the production data changes over time and you want to be able to compare versions as you optimize the closest() function. &amp;#x200B; As for optimizations, I was wrong about the algorithm, for some reason my brain went straight for a double loop when all that's needed (and you're doing) is a linear walk over the slice of stops. TBH this is probably optimal for the 5000 you've got, it's very cache friendly. You could probably use the index instead of copying the value in the for-range: &amp;#x200B; `func (bs BusStops) closest(location Point) BusStop {` `c := -1` `// fmt.Println(c)` `closestSoFar := math.Inf(1)` &amp;#x200B; `// log.Println(c.Description, closestSoFar)` `for i := range bs {` `distance := location.distance(Point{bs[i].Latitude, bs[i].Longitude})` `// log.Printf("'%s' %.1f\n", p.Description, distance)` `if distance &lt; closestSoFar {` `// Set the return` `c = i` `// Record closest distance` `closestSoFar = distance` `}` `}` &amp;#x200B; `return bs[c]` `}` &amp;#x200B; But that's almost clutching at straws, it seems to shave about 500ns off :) Also note there are several failure modes in the function above (what if there are no stops? should there be a maximum distance?) which might be worth considering before worrying about optimization. &amp;#x200B; Hope that helps.
Assuming a reference to that slice isn't kept elsewhere, yes, the memory leak is somewhere else. There are a few things into, like having to keep in mind that slices have a backing array, and re-slicing a slice will keep the backing array in memory until all slices have been garbage collected. Furthermore, look into pprof, it allows some extent of heap inspection.
[https://github.com/davecgh/go-spew](https://github.com/davecgh/go-spew) is much more suitable for debugging purposes 
I can't really be sure of anything since I haven't seen a more complete bit of code. But from what you presented it doesn't seem the source of a leak. The leak would be caused by something either doing a malloc or new with C memory 
I've checked my whole code and there isn't anything else that isn't freed I'll look into pprof
Thanks!
But issues can still happen in production and full debug info is just as important then. That's why I would prefer an approach that works equally well wherever it's used.
The link you posted passes the database details via environment. Also, we cannot see what the values are. It is possible that you are not connected to the correct database. In the example the database name is 'dbname'. make sure this * set as environment variable * read correctly by your program * passed correctly to the pg driver 
Go 1.0 can't introduce generics due to the promise that they'll remain backwards compatible within major versions. There is a proposal for generics in Go 2.0, and you can find it (and others) here https://go.googlesource.com/proposal/+/master/design/go2draft.md For future reference, that "joke" sounded a lot better in your head than it actually did. You're not original or funny.
I've been liking gqlgen so far. I'm also coming to really like auto-generated code.
Yeah, that doesn't mean there aren't better ways to debug in production
Spew for life
this is so good to read. Bookmarking it to show to all the folks asking in here about why Go devs hate dependencies so much :)
&gt;There are approaches that work equally well in production and dev - log.Debug I agree, my point is that this package isn't one of them.
https://research.swtch.com/deps contains an example of exactly what I talked about. Malicious code injected into a dependency and not spotted for months.
Why not use spew.Dump?
Does it follow pointers, or just print their addresses?
Spew isn't exactly the same, but I would strongly suggest to /u/tylerwince that it be integrated, rather than re-implemented anew in this package. If nothing else, at least fork it and modify it to do whatever rather than starting from scratch.
It wouldn't take much preprocessing to make that work. Since we're talking about a debug stage it shouldn't be too difficult to do a "build debug macro" stage up. In this particular case, I don't even mind if it modifies the source code inline; it's going away anyhow. Per the discussion below, this simply isn't going to be something you leave in production. In fact, if you get to the point where you're building a preprocessor to expand the Dbg calls into having the original expression, I'd suggest including a subcommand that allows us to assert across a set of Go packages that this package is not imported, so we can include that as a linter/assertion in our CI tools on our production builds.
Here are over 500 Top PDFs posted to Hacker News in 2018 [https://live.godiscourse.com/topics/c733fe04-f110-4679-9072-c9be68d763bf](https://live.godiscourse.com/topics/c733fe04-f110-4679-9072-c9be68d763bf)
Yup makes sense. Thanks for the input !
There is the nice saying in Russian "–í —á—É–∂–æ–π –º–æ–Ω–∞—Å—Ç—ã—Ä—å —Å —Å–≤–æ–∏–º —É—Å—Ç–∞–≤–æ–º –Ω–µ —Ö–æ–¥—è—Ç". That literally means that when you are at some place other than your own home (office, country etc), you should follow the rules, order, customs that exist there. &amp;#x200B;
What is logrus? What is pgk/errors? What's wrong with debug.Stack to get the stack?
I did not actually read through the code. I stopped when I see "fast" in title and no benchmark in readme.
The major problem with this approach is that you don't know how long your code is going to take to run. The channel is giving you the amount of time you grant as wall clock time, but your code may be scheduled out by either the Go scheduler or the OS one, resulting in taking even longer than your planned time. As a result, you generally end up having to set your time to be _multiple_ orders of magnitude larger than the expected execution time, resulting in things like authentication code going from a significant, but user-imperceptible amount of time, to a user-noticeable amount of time, degrading your entire system. Plus you have to assume an attacker can throw enough load at your system that they can make your stuff take longer than your channel timeout. Remember security measures have to be analyzed in terms of how they do under active attack, not just casual script kiddie scans, and timing attacks in particular generally involve an active human attacker, I suspect. This will slow them down a bit, sure, but I'm not convinced it'll stop them. So, it might not work under active attack, and it causes all your code to be slowed down, all the time, making the best performance you can hope for to be very pessimal from the get-go. I can imagine situations where it may be the only mitigation you have available, but it's not a very good solution, which is why this isn't what is used.
I would like to see more easily in `go.mod` which dependencies are only for tests. Often when I look for a new lib in github I first look at `go.mod` file and it's the opposite, a lib with a lot of tests seems to have a lot of dependencies, a lib without a big `go.mod` maybe because it has no tests !
Thank you - I shall have another look at it!
Seems like a repost of https://www.reddit.com/r/golang/comments/a93ncr/using_service_objects_in_go/
There is no way of murmur3 being more fast than xxhash or cityhash which is there in inbuilt maps of go. Maybe he is taking about the distributions etc etc. 
I am working on the benchmarks and will soon share it here.
If you want to keep executing, but have the stack in the logs, you need to generate a stack yourself (`debug.Stack`) and `WithField` it to your log entry. Alternatively if the application should completely halt you can use `logrus.Panic` which prints the log, then panics (which outputs the stack).
Yeah, this only works when the source is on disk (and should only be used when this is the case, although it won't fail spectacularly if it isn't). This way we can just grab the line out of the runtime.Caller and parse the text to get the expression that was passed
That kind of approaches have already been considered for over 15 years now. You can for instance see this being quickly discussed at the end of the "[Remote timing attacks are practical](https://crypto.stanford.edu/~dabo/papers/ssl-timing.pdf)" by Brumley and Boneh, where they quote Matt Blaze's so-called "Quantize Wrapper Library" and mention that all decryptions should be taking the same time for it to work correctly. It is sometimes named "time quantization", as in this [Golang issue](https://github.com/golang/go/issues/20654) discussing the need for constant time maths in Golang. On my side, one problem I can see with your approach, is that you can still use statistical analysis on the timing data, and using a low percentile filter on the timing data, you would basically be able to filter out the case where the random time d was 1 second exactly, and if you are able to work out a case where the processing would take more than the min random time, you would still be able to collect data about the actual processing time. Another problem I can see is that constant time crypto is also usually mandating that memory accesses are not directly related to secret data, and such things, which means that you are also trying to take care of other possible sidechannels when doing constant-time crypto, while it wouldn't be the case there. Finally the biggest problem with these kind of methods, which explain why they are not often considered, I'd say, is performance. You want your CPU to work as fast as possible and not just wait idling when work has already been done. Usually constant-time crypto also means optimized crypto, which means it rarely implies a large performance trade-off, but there, you have a systematic performance hit, which is really sad. It's true that for other usages, such as the one you mentioned (for example looking up an entry in a database), you'd also want to have a "constant-time" lookup, ideally, but this is a hard problem. Even hash tables can have degenerated case where the lookup is in Œò(n) instead of O(1)... I don't remember ever seeing an effective solution to have constant-time table lookups, and using tricks such as time quantization might be an option there, if you can afford the performance hit.
Haven't heard of go-spew but looks neat! 
Right now it just prints their address -- would welcome a PR to follow them and print the actual value instead of the address. I'll make an issue for that
`dbg!` also returns the value that the expression evaluates to. 
Logrus - [https://github.com/sirupsen/logrus](https://github.com/sirupsen/logrus) is a logging framework to add structured logging to your application. For example, you can create a UUID for a request with a handler and add it to every log entry. Now you can trace the entire request flow from start to finish. &amp;#x200B; pgk/errors - [https://github.com/pkg/errors](https://github.com/pkg/errors) is a drop in replacement for Go's error system. It automatically creates a stack for the error. &amp;#x200B; Theoretically someone has already created the proper integration between the two to print stack traces as part of the structured log.
Super cool team, which I'm happy to have worked with a couple times, and it's always a pleasure to meet them in conferences, or at EPFL when I'm visiting. I recommend it, if you are looking for a job in Switzerland :)
This is very true. I will make a caveat on the readme, but this is really intended to be used temporarily. 1. Drop \`dbg\` into a function that I want to find out what my variable is equal to 2. Fix my stuff so it matches 3. Remove the dbg call Just like someone would do using printf. This is definitely not intended to replace a logger or even traditional print statements where needed in production code
this
Reddit clich√© noticed: this Phrase noticed: 3043 times.
Thanks!
Cross-posted from [this](https://stackoverflow.com/questions/54310175) and [this](https://stackoverflow.com/questions/54310884/) (where it was answered in [the comment](https://stackoverflow.com/questions/54310884/#comment95442467_54310884)).
Tip: always give the full import path of a package, e.g. github.com/sirupsen/logrus instead of just logrus or github.com/pkg/errors. This makes it clear whether it is a package from the stdlib and there is no need to provide URLs. For your question: github.com/pkg/errors.WithStack lets you annotate any error with a stack trace, so where exactly is the problem?
This title is not representative for the issue you are highlighting.. You should simply be careful about having an object call itself recursively through printf. This has nothing specific to do with errors.
I've used it in production for about a year now. It's great, however without dependency manager it can be quite a challenge at times. especially for project that have more than one contributor.
[removed]
Yep - this does as well! :thumbsup:
No, your function doesn't return anything at all.
I saw those. I don't see how the comment answers the problem. The blog post didn't show the errors getting handled in output. The issue is specifically getting the full stack into the log message. Is the comment saying to use emperor? Is it to use github.com/goph/logur?
‚ÄúWhen in Rome, do as the Romans‚Äù is a saying in English with that meaning. 
exercism.io?
[removed]
Agree completely. I just figured that if I was going to "relearn" to program that I would try doing so using golang. In my case I VERY much need the structure of a book or challenges that build somewhat upon themselves, AND the feedback that is inherent to said books/exercises. &amp;#x200B; I will ABSOLUTELY give your my best effort. Thank you!
O! Thanks a lot.
There are a few interesting things you could do, but I'd say that one of the first is to make some benchmarks so that you can quantify the improvements to memory or performance, and use the profiling tools (including the race detector and blocking profiler) to make sure you are looking in the right place. For memory use, you can trade CPU by making your adjacency list a bitset. You can either do it yourself or use `math.Big` I think. I'd set it up so `adj[i][k]` is at bit `i*N+k`. Another potential memory improvement would be to see if you can move static state into a "write only" slice, or possibly an "append only" slice with cooy-on-write when you have to expand it beyond it's capacity. You could replace pointers into this slice with smaller integers to save some bytes too at the expense of a bit more CPU. The CoW approach should let you have zero locking within the static data, only having an rwlock or atomic load to get a reference each loop. As for the concurrency piece, probably what I would experiment with would be a work stealing queue. It won't necessarily reduce the locks (each goroutine needs a lock on it's queue) but it should reduce lock contention, which should help a lot. To test that your concurrency is beneficial, I again suggest benchmarks, along with using the -cpus flag to go test, so you can plot out the performance characteristics and potentially choose the right amount of parallelism.
Oh, also, use the benchmark ReportAllocs functionality and the memory profiler to see if you can cut down on garbage; that should help with performance if you can find anything to improve there.
Are you trying to compile Go, or just use binaries?
"Avoid unbounded recursion"
The phrase &gt; "Set $GOROOT_BOOTSTRAP to working Go tree &gt;= 1.4." can only be said by `./all.bash` or `./make.bash` run in the `src` directory of the Go's _source code tree._ That's because since version 1.5 Go is written in Go (i.e. it's self-bootstrapping), and hence to build a source tree of the version &amp;ge; 1.5 you need to have a working _binary_ installation of Go &amp;le; 1.4. The name of the tarball includes the `linuxamd64` suffix which suggests the tarball contains binaries, not source. This, in turn, suggests, you unpack it and then maybe for some reason try to build the source code _it includes_ again. If yes, this is not needed: just make sure the `bin` subdirectory of the tree you unpacked that tarball to is listed in the `$PATH` of the user which is supposed to call your new Go installation.
Ah - I misunderstood. Didn't realize `dbg!` returned anything. What's the use case there? Something like `returnedMyVar := Dbg(MyVar)`? What is the point ... same value as `MyVar`
the blog post announcing the latest version of rust goes into detail on why it's helpful, since it doesn't require restructuring your code to wrap a few expressions in `dbg!` and begin to see the output.
Yea that‚Äôs always the issue. What happens when someone starts basically flooding the system with requests. Suddenly all requests take way longer, giving some kind of indication that‚Äôs way longer than the timeout. But the hope there is that under and active attack, there‚Äôs enough other noise added to make detecting timing changes very difficult. Under a low load, systems act pretty predictably; but under heavy load, unless one controls all of the routing between services, and all user requests, it‚Äôs difficult to even make a statistical argument. I‚Äôm not sure how one would approach it otherwise tho. Perhaps make a sliding window that uses the max of the actual work to set the timeout. But then that‚Äôs prone to attack as well, as an attacker can just throw a million identical requests at the system and make a statistical assumption about that request, wait for the load to die down, and do it again to another request, and guess based on the differential time. 
Good bot.
All very valid points. I try to use proper constant time libraries where I can, but not all processes that can be vulnerable to a timing attack are crypto processes. Under a heavy load, one doesn‚Äôt even really need to consider the low end of the random time; simply increasing the load with more requests would likely push it beyond the maximum time and then you could just directly make differential inferences between two requests. Eg, stress the database out so it takes 2 seconds to respond to queries, then you‚Äôre able to detect if one is checking a password or just returning because the user doesn‚Äôt exist. One way I can see of combating that would be adjust the timeout dynamically, but even that has more major problems as you can simply repeat the number of iterations, then detect the change in window start/end. Another way is to fail fast, and always ensure database lookups fail long before the timeout. In essence, context.WithTimeout(500*time.Millisecond). It‚Äôs more complex, but ensures an attacker can only make the service unavailable and never glean information from timing information. But that‚Äôs a whole other problem in itself. I‚Äôm not so worried about delaying the responses. That was one of the reasons I tried this approach. It‚Äôs OK to delay sensitive things that happen rarely, like a login. Adding rounds to Bcrypt or similar is fine, and adds safety. The nice thing about channels is that goroutines don‚Äôt block the CPU, so that it‚Äôs not stopping the CPU, only handing it over to other processes that need it. I wouldn‚Äôt add this to everything, as that starts to get into making the UX worse, but sensitive functions would make sense. I‚Äôm not sure what other approach I can use, or if there is any enhancements that would make it safer. 
As mentioned elsewhere, you will have to manually format the `pkg/errors` value before feeding it into `logrus`. As per [the documentation for `pkg/errors`](https://godoc.org/github.com/pkg/errors): type stackTracer interface { StackTrace() errors.StackTrace } err, ok := errors.Cause(fn()).(stackTracer) if !ok { panic("oops, err does not implement stackTracer") } st := err.StackTrace() fmt.Printf("%+v", st[0:2]) // top two frames // Example output: // github.com/pkg/errors_test.fn // /home/dfc/src/github.com/pkg/errors/example_test.go:47 // github.com/pkg/errors_test.Example_stackTrace // /home/dfc/src/github.com/pkg/errors/example_test.go:127
I suppose I can provide example of a car accident. And then try to use that as an argument for going on foot everywhere. These type of risks are handled by developers and good tooling, not absence of tooling. Providing official tooling is generally better as it adds an additional level of control and usually aids transperancy. Some good practices like immutable repos helps too (Rusts Cargo). Besides this argument on supposed safety is bit disingenious. Given the context of Go being owned by Google and pretty much managed by it in authocratic way in the light of recent NSA scandals. 
I believe I'm trying to use binaries. To be clear. I want to run "go version" and it should be there. To do this on the air gapped network I moved the tar over via scp and attempted to run it and this was the result.
Like others said I don't think this has anything to do with errors. a := A("hello") &lt;- this isn't returning an object or a call in memory. It calls the sprintf fn and then attempts to printf said function again. I think you could change the error type and get the same result. 
How does this compare to [davecgh/go-spew](https://github.com/davecgh/go-spew)?
Both links now say "question removed by author"...?
Or just use %v like normal people
They literally warn ablut this ‚Äúissue‚Äù in the tour of go.
Why are you using float64s for your embeddings?
I just used this for my implementation of OnionShare in Go: https://github.com/ciehanski/onionbox. Really fantastic package, thank you cretz!
What's an air gapped network? Sounds interesting :)
A network not connected to the internet. An internal network. 
Dbg provides file context and expression name by default. go-spew ‚Äòspew.Printf(‚Äúline: 12: myvar %v‚Äù, myvar)` godbg `Dbg(myvar)`
Um, what do I have to look for when analyzing the memory allocations?
Thanks for the reply! Is there a good way to track progress on benchmarks? Or do I have to write them down and compare by hand?