This is my favorite article on the internals of the scheduler: [https://rakyll.org/scheduler/](https://rakyll.org/scheduler/)
&gt; Was a proposal draft ever published? &gt;&gt; No. FTFY Thank you for all the work on dep. Russ made it clear that significant mistakes were made on his part. It sucks that this ended as it did, but I think the new plan is genius.
I‚Äôm far from an expert in this subject, but I personally agree with Russ that disallowing multiple major versions of the same package is a showstopper. I personally would go further; I think that from the start this issue should have been sidestepped by doing something similar to what NPM does, where your dependencies can all depend on whatever versions of whatever packages they want without enforcing any requirements whatsoever on your main project because imports are effectively namespaced. The fact that in NPM I can depend on Lodash v15 and my dependency can depend on Lodash v3 and another of its dependencies can depend on Lodash v0.5 is a huge feature, in my opinion. The go modules proposal is a step in the right direction from that angle. ‚Äî Also, at the end of the day, I‚Äôm honestly not very impressed by all the complaints I see from the dep group. I know, it sucks to not have your expectations met and to feel ignored. Maybe this is just an outsider‚Äôs perspective, but ever since I first started seeing dep it was always my understanding that it was an experiment, but it seemed somewhere along the way the dep group decided it was more than simply an experiment. Meanwhile Russ comes along and does one of the things that so many of us say we love about Go: he chose an opinionated way to do something, using lessons observed from dep, and implemented it. It‚Äôs not perfect. But it‚Äôs good, and it works for most cases, and it‚Äôs The One Opinionated Way. If that‚Äôs not classic Go design I‚Äôm not sure what is. But when it comes to dep now we don‚Äôt love it? How many times have we all heard ‚ÄúGofmt‚Äôs style is no one‚Äôs favorite, yet gofmt is everyone‚Äôs favorite‚Äù? But this is different, why exactly? This may just be an uncharitable opinion from the outside looking in. But honestly, it just sounds like a lot of hand wringing because ‚Äúmy design wasn‚Äôt chosen‚Äù.
Great response, good for you!
Me too. Write it once and throw it away is a pretty solid design pattern.
The thing that the dep fiasco (and type aliases before that) has taught me is that the go team is good at designing a language, okay at evolving a language, and are spectacularly bad at accepting feedback that doesn't come internally. The core of the problem is really that rsc is a great engineer, makes great technical decisions, and would be a great BDFL, but Go doesn't want to market itself as a Google-only language with a BDFL, it wants to market itself as a community driven open source project, and the two just aren't compatible. In the former, the community defers when there's a technical disagreement that can't be reconciled, and in the latter the leader does (even if they disagree, and even if they *are* right.) Doing things your way and then saying "mea culpa" only works so many times before people stop trusting you and either go somewhere else in the best case, or fork in the worst. 
Really neat feature. TIL.
\&gt; I'm having trouble plainly pointing the finger at the Go team for not communicating clearly I'm not. I think it's extremely clear that the core team should have stepped up and clearly stated that \`dep\` was never going to be anything beyond an experiment and would never be the official solution. I don't know where that messaging originally came from, but people were actively talking about \`dep\` as the solution, not just an experiment, and it went on for *months* with that messaging gaining traction. You might say, 'but they did...', but they didn't do so effectively. You can't be wishy-washy about these things: Just step up and say it. \&gt; "Hey guys, I see there's some misconceptions about dep, to make things clear, we're moving it out of the golang/ repository space (which offered the illusion of legitimacy), and clearly stating that it is an **experimental tool that should not be used in production**." That was never done, and the fault lies directly at the door of the core team for it. Peter and Sam were open from the beginning on what they were doing and how they were doing it... clearly, if no one can easily see what *they* could have done better, then the fault lies else where...
I really wish someone would create a package manager that had even half the power of CPAN
I think they could codify something like Swift: https://swift.org/community/#community-structure &gt; At project launch, the team is composed of Apple employees due to Swift‚Äôs origin within Apple. Over time, exceptional community members from a much more diverse background will be appointed based on their record of community involvement and contributions. However based on behavior of Dep team I do not think they would be able to make it to hypothetical Go core team if it accepted people from outside Google. They have shown themselves to be incapable of taking high road in case of rejection.
Cue the Fred Brooks quote.
Design by committee is rarely a good idea. Any choice you make is going to anger some percentage of users, but that's the price of progress.
It could also be construed as "Ford Motor company asked a bunch of horse-buggy operators their opinion". Community input is important, but sometimes it will hinder more than help due to people's desire to stay with what already exists.
Hi, I'm sorry to hear 2018.2 is behaving so badly for you. Please ping me at florin at jetbrains or open an issue on our tracker https://youtrack.jetbrains.com/issues/Go and we'll do our best to figure this out. I'm not sure what happened but I'm sure that without your help we won't be able to replicate this and fix it. Thank you, and once again, please accept my apologies for the issues caused.
What problems?
&gt; but Go doesn't want to market itself as a Google-only language with a BDFL, it wants to market itself as a community driven open source project, and the two just aren't compatible. That is a very black-and-white answer. The truth is much more in-between. Go originally was conceived to solve problems that Google engineers were facing. That much is very clear from Rob's early blog posts. It was really a language made by Googlers to solve Google's problems. And then down the line, it was made open source. Contributors started to flock in, component leads formed, and outside people were allowed push privileges to the repo. But still a very huge chunk of the project runs on Google's infrastructure. The trybots, the build dashboard, gopherbot, gerritbot .. mostly everything is run by Google. Even golang.org is hosted on GCP. But does that mean Go project is not welcoming of the community ? Far from it. Look at the no. of github proposals accepted originating from the community. Look at the no. of people given push privileges outside of Google. Yes, there is a singular vision of the project which needs to be held by the original stewards of the project (who are from Google). So one cannot just cram in every feature they like into the language. And I don't think it's such a bad thing. 
Default usage of a library will be with an obsolete version
&gt; Cue the Fred Brooks quote Thank you! I knew the quote, but not the source. üëçüèª
explicit is better 99% of the times, even more when in doubt
Looks great! Definitely going to read through your source code :) 
Good argument for not using single character variable names! You'd have spotted out of it were "child" and "node"
&gt; They have shown themselves to be incapable of taking high road in case of rejection. ... and the Go team has? 
In practice, Sat solvers are not really slow, and they can always provide an explanation of why the problem is unsatisfiable (through the use of MUS).
That can become the start of many cool things
What was the TLDR of the controversy with type aliases?
It seems to me that both parties have valid arguments. But I also think both parties didn‚Äôt do the design process in an open way. The proposal should have come much earlier than it did. IMO even a bad proposal puts all the cards open on the table. I would also urge both parties to resolve this situation in a way so that our valuable contributors don‚Äôt feel sidelined, which is the most important thing here. Thank you for the all hard work. 
Ping Larry Wall 
For anybody, like me, not remembering or knowing what this is: https://tour.golang.org/basics/7
Also, John Carmack: &gt; I used a common pattern for me: get first results with hacky code, then write a brand new and clean implementation with the lessons learned, so they both exist and can be cross checked.
Also, John Carmack: &gt; I used a common pattern for me: get first results with hacky code, then write a brand new and clean implementation with the lessons learned, so they both exist and can be cross checked.
Let's think the problem in other ways. Will dep die because vgo is chosen as the official go dependency tool? Will vgo solve all dependency problems? Isn't there any space to other dependency management tools? Isn't it possible that multiple dependency management tools coexist and are used at the same time. One the other hand, personally, I hope the official Go SDK can provide more low level tools, so that 3rd parties can make their own custom tools more easily. Currently, Go SDK only provides three binary: go, godoc and gofmt. From my (may be not correct) experience, go and godoc both assume there is src subfolder under GOPATH. This assumption may look like a small detail, but it really prevent me from writing some my own tools by wrapping the go command. 
In reality are there any languages with multiple accepted dependency managers? Picking, or even using, dep managers is not something I enjoy at all. It seems to me that this is exactly the kind of thing Go is good at, just let me get on with coding and solve all the chores for me.
yes, Python and C++ worlds both have many dependency tools. You need a dep tool when your projects become large. Even for small projects, dep tools are also important for long time maintenance.
I've only ever seen pip in the python world. Common lisp has a fe,w but they tend to have one in fashion at a time. Even node seems to be moving back toward npm with yarn losing ground. I use them because I have to, I'll be glad when I don't have to choose one over another.
thanks your suggestions and I have improved some aspects of the code style. Still lack of comments and I will improve them gradually. I also open some issues which are some goals in the future. Please free free to open an issue if you have other ideas :)
Thanks! I already do as your suggestion and please feel free to open new issues if your have other ideas :)
I mainly name my returns if for some reason the function need to return more than two variables for documentation clarity. Like others in this thread, I never use the naked return. 
&gt; I think it's extremely clear that the core team should have stepped up and clearly stated that `dep` was never going to be anything beyond an experiment and would never be the official solution. For the umpteenth time: [They did](https://groups.google.com/d/msg/golang-nuts/PaGu2s9knao/Bq4vmFh7AgAJ). That message is from *March 2017*, and it makes abundantly clear, that a) dep is not intended to get merged into the Go toolchain, b) that the messaging by the committee is far too optimistic, in regards to the future of dep. The message also pretty clearly brings up the main differences between modules and dep that are the source of contention now and make Sam feel animosity towards the chosen solution as show stoppers (with the one exception that Russ changed his mind on lock files in the more than half a year between that message and the design of modules). Most importantly, it is very consistent with what is being said now and with the actual process as implemented. I'm sorry that apparently that message wasn't clear enough, but IMO it's just not enough to claim that it wasn't. There are people who *did* understand it very clearly that way. So it would be helpful, if there would be some example of a) where what Russ or anyone on the Go team is saying there and elsewhere doesn't align with this outcome and b) what *specifically* it should have said to make more clear, that what has happened is mostly what was intended. &gt; I don't know where that messaging originally came from, but people were actively talking about `dep` as the long term solution, not just an experiment, and it went on for months with that messaging gaining traction. Okay, then let me be perfectly blunt: To the best of my knowledge, that messaging originally came from Sam, in direct contradiction to what he's been told by Russ and Russ did his best to make that clear, publicly. I don't like pointing fingers in that way, because I don't believe Sam acted maliciously; he clearly did his best and as much as it doesn't seem like it, I *empathize* strongly with him. Something clearly went wrong here, but again: There are people who *did* get the message so it isn't helpful to just claim it wasn't there. Where *specifically* was the messaging of the Go team to the public wrong and inconsistent with the actual outcome? And what *specifically* gave the dep team this confidence? My impression is, that there where two parties talking to the public here: a) The dep team, making overly optimistic claims about the future of dep and b) The Go team, absolutely clearly stating that it's meant as an experiment that isn't intended to be merged into the go tool. And yes, I *can* point to something that I'd call the root cause of this problem and it did turn out to be a mistake by the Go team, but it was a good-faith mistake: Believing that it would be better to talk directly to the dep team and let *them* do the messaging to the public. This seemingly was a mistake, because due to some misunderstandings, their messaging was directly contradicting the wishes from the Go team. But I also think it was a reasonable course of action. Doing differently would've undermined the efforts of the dep team completely and thus also would've gone counter to the goals of the Go team - which, AFAICT, genuinely wanted to support and empower the dep team to experiment and learn from what is happening. Letting the dep team do the communication with the public was well-intended. From what I can tell, the Go team has been very consistent here. They wanted the community to step up, experiment and explore the problem space and learn from that for the eventual integration into the go toolchain - but not to actually give them a free reign and final say on how that integration will look. They thus did their best to empower and support the package management committee and to not undermine their authority, to work together with them and to explain the plan. Unfortunately, somewhere on the way between the Go team and the dep team, that message was lost. This much is clear and I *can* except that this is more the responsibility of the sender than the receiver of the message - but to be helpful, the conversation has to be more specific than that. What *specifically* could they've done better? "You did it wrong" is not actionable criticism. &gt; to make things clear, we're moving it out of the golang/ repository space (which offered the illusion of legitimacy), and clearly stating that it is an experimental tool that should not be used in production." But that's counter to what they thought and intended. The intention was for people to use it in production. The legitimacy wasn't an illusion. It was an officially endorsed, supported and empowered experiment to learn about the problem and solution space for an eventual integration into the go toolchain. Experiments have to be *used* to get useful data, advising people against that is completely bonkers. They *did* say "Hey folks, I see there's some misconceptions about dep, to make things clear", they just didn't follow it up with your suggestion (which is diametrically opposite to what they wanted) but with an *actual clarification* of the intent. &gt; clearly, if no one can easily see what they could have done better, then the fault lies elsewhere. That is a false conclusion. It's human to want to assign blame to someone, but sometimes, everyone can act in the best intentions and do everything right and you *still* don't get the right outcomes. If people want to learn from this and actually figure out how to improve future outcomes, the finger-pointing and blame-assigning needs to *stop*. There needs to be agreement that everyone acted in good faith and did their best and some dissection of what specifically made Russ' well-meaning actions and statements gave Sam and the others the wrong impression. If you've ever heard about blameless postmortems - what we need is one of those. The specific idea to shift the view from attributing failure to humans to instead attribute failure to systems. If an engineer pushes the wrong button and deletes a database in production, the fault isn't with the engineer for pushing the wrong button, but it's with the system that let a single mistake by a single human cause an outage. Assigning blame to humans just triggers their defensive reflexes. Assigning blame to systems lets you figure out how to improve them to prevent the failure in the future.
python has Poetry too. The node world is a sad world. I never installed npm. I only run node for my js files. I really think npm is not an essential tool.
This happens. All the time. All around the world. Especially so with software engineering which is so heavily biased with opinion (/experiences). Ultimately, someone has to make a decision - as disappointing for some that may be. Watching from the (very) distant sideline has been both interesting, and concerning. At this point; mistakes have been made, people involved have documented the process (and feelings) from their perspective, and we are now in very real danger of getting stuck in a damaging vicious circle. We need to move forwards from this and learn some lessons. Continually rehashing things is certainly not making positive forward progress. My 2 cents would be that - to support a healthy Go community: - the core Go team needs to commit real time, energy, and, openness to the community. - the community needs to accept that this is a very personal project for the core Go team, and that may result in situations such as this.
"Everything is a mistake, until it works." - Seth Godin
I was going to say the same, and while it may be seen as a bad advice (most languages have unreadable codebases and standard libraries, but Go is very readable). That is my primary source of information when I \*really\* want to go deeper and understand how it works under the hood. Of cours, articles that elaborate on internals in more digestable form are also extremely valuable, but in the end it's just someone else who read the code and write a blog post.
&gt; But that's counter to what they thought and intended. The intention was for people to use it in production. That's blatantly false, and the core of the issue here. Using it? Trying it? Sure, they wanted that... ...but using it *in production*, means using it as though it was a *long term supported official solution*. That's what 'in production' means. That's not what they wanted at any point, and that's the problem; that wasn't communicated.
If I remember correctly, it was people wanting to keep the language simple on one side and people arguing that type aliases are absolutely necessary to do certain large-scale refactorings on the other side.
Have you seen how many generics proposals Ian Lance Taylor wrote that got rejected and have you noticed how he talks about that?
There is nothing that can't be undone. There are different levels of pain you have to endure and if the pain is large enough and the payoffs are low enough, it won't be worth it. But even that I can't see happening here.
The problem isn't SAT failing, the problem is SAT succeeding with a bad solution. i.e. the versioning problem is *at least as hard* as SAT, but in actual practice, it's harder. Because not all solutions are equally good.
Well, to be precise it's a maxsat problem (optimisation version of sat), ie you must run several calls to a sat solver. It still works well in practice, although np hard.
If you don't have a lock, there isn't a lot we can do for now. dep's design is around the assumption that you always, always, commit both lock and manifest. If you have the lock, but don't commit vendor, that's way more doable, though I omitted it for this release. Without any significant changes to architecture, we can make the system grab zip balls (similar to vgo) rather than full clones when we're just exporting one version of a project. 
&gt; using it in production, means using it as though it was a long term supported official solution. Okay, we have different opinions about what "using it in production" means then. But that's semantics. The fact is they a) clearly stated they wanted people to use it and b) they also clearly stated that it's not going to be the actual final solution. So, at best, you are making an argument here that they *did* actually clearly say what you wanted them to say. i.e. with your interpretation of "using it in production" they clearly, plainly, openly and *early* stated that you shouldn't use it "in production". &gt; that wasn't communicated. Can you clarify how these quotes from Russ do not communicate that clearly? &gt; You make it sound like dep is just going to become 'go dep' in Go 1.10. That's not the plan I thought we discussed. &gt; I don't see it, for example, as a prototype of the eventual go command integration (since it's not integrated at all). &gt; It's important to note that I do not expect projects using dep to automatically work with the new go command integration too. &gt; There will be iteration and revision and almost certainly rethinking on the way into the go command proper. My concern is that the roadmap and some recent Reddit comments do not reflect that level of uncertainty. Or can you tell me where [this doc](https://research.swtch.com/go-pkg-june-2017.html) deviates, as far as this is concerned, from what actually happened? In particular: &gt; Although the two are necessarily different in detail, it is an explicit goal to allow library authors to publish packages compatible with both dep and the go command integration and to allow developers to continue to use dep during a transition period, with the eventual goal that everyone is using the go command integration. The basic approach is that where dep and the go command integration either agree or coexist on each detail of the data they consume. In particular, they agree about the format of version tags (v1.2.3 as a repository tag pointing at a specific commit), and they coexist as far as manifest and lock files, by using different file names. It is possible to publish a library that works with both systems by publishing pairs of manifest and lock files. We expect that a tool will be written to convert between the two formats to aid in this transition. To me, it seems obvious that it has been made *abundantly clear*, that 1. The Go team wants people to start using and experimenting with dep and that if you do so, there will be a clean migration path to the eventual Go command integration 2. The Go team does *not* want to merge dep with it's then-existing semantics as-is and that there will be changes 3. The Go team is considering dep as an experiment that will inform future decisions. Don't get me wrong, I agree that there *was* a message sent that dep is going to be merged into the Go toolchain mostly as-is and that it was the blessed solution and people should use it in production (for *any* interpretation of the word). But it certainly wasn't sent by the Go team. And the only way I can see the Go team having done more against that, would be to put a post on blog.golang.org saying that the package management committee is completely misunderstanding and miscommunicating the intent of the Go team and that you shouldn't listen to them. Which seems *incredibly* counter-productive to the actual goals of empowering the community to experiment and learn from that. &gt; By comparison, the release of vgo used the correct sort of communication: Your quote is not only compatible, but in large parts just a restatement of the communication of &gt;1y before the release of vgo. Note, in particular, that it says that vgo *is* the prototype, whereas they previously clearly said that dep *isn't* the prototype. Again, not only am I unable to find anything the Go team said that *contradicts* the process that actually was implemented, I can find tons of examples where they *specifically* said what you say you wish they said. I understand that you feel left in the dark. I *agree* that the community was largely mislead and left in the dark. But that's because the Go team thought it is best to let the package management committee speak with one voice - to empower them to make the experimentation needed. And that one voice then communicating things that where not in line with the clearly stated intentions of the Go team. This is what Russ [is saying here](https://twitter.com/_rsc/status/1022592076691775489). Yes, it was a mistake to not correct this earlier. But it still was a good-faith mistake and personally, I wouldn't have done any differently. I still don't see how it would've been possible to do this without undermining the effort of dep as an experiment altogether. It speaks for Russ that he is taking the blame for this, I respect him for that. But IMO he shouldn't. He would've been the one that had to act differently, but I can't *blame* him for that, unless I am confident that I would've done any different, given the same data. And I can categorically say that I'm *not* confident. On the contrary, I'm very confident that I would have acted exactly the same and I can also say that I'm pretty confident that a different course of action would've probably been *worse*. If you think people are complaining about the power of the community in this case, just imagine what they would've said if Russ had publicly denounced the package management committee before it even had a working implementation of their ideas. I have mad respect for Russ for weathering this and putting the blame here on his shoulders. IMHO he shouldn't. *If* he does, then that's one thing, but articles like this, where *other* people do it, just seems incredibly unfair. IMHO everyone involved was stuck in a no-win scenario, did their best and sadly, it turned out badly. There's no use making each other feel worse. Personally, I hope that we can use this as a model for future community involvement. Not how it went, but how it *might* have gone. I think it could be an incredibly effective model (far more than the current processes), to 1. Have working groups of community experts who are passionate - and involvement from the Go team 2. Have them explore and discuss the problem and solution space more or less privately (too many cooks and all that) 3. Present the findings - in the form of a proposal or in the form of a summary of the discussion - to the Go team and community at large. However from the Go team was involved in the group can act as a steward and "translator". 4. Let the Go team, who has a track record of coming up with excellent and coherent designs - a track record that is reflected in how much we love the language that resulted from it - make a decision informed by that. IMO the misunderstandings here where mostly about the role of the committee - the Go team perceived them as informers, the committee perceived themselves as deciders - as well as probably the low engagement of the Go team itself with the committee. I can't really blame the Go team for either of those, though, as IMO they made the first one clear (not to "the public", but to the committee) and in regards to the second‚Ä¶ I can't *really* judge that, I wasn't there. Personally, ISTM adg was pretty involved in the beginning. And 2-3 meetings, several long-form essays and eventually weekly meetings with Sam seems actually a lot of involvement by Russ too. But I respect that Peter feels more involvement was necessary. As i said, I have limited insight into what happened.
&gt; The core of the problem is really that rsc is a great engineer, makes great technical decisions, and would be a great BDFL I think talking about a BDFL at all here, is misleading. rsc's role is "the tech-lead of the Go team". At some point, rsc will move on to other things and someone else will take over his role. So the "for life" part in BDFL isn't accurate. His role also isn't to *dictate*, but to *steer*. His role is to provide and enforce the technical vision of Go. Dictating is counter-productive and not part of the culture he's working in - even if he technically has that authority. But if the TL is making decisions against the team, they lose their trust and can't do their job. Working *with* the team is an essential part of the role. I think there *can* be made an argument that *the Go team* has the role of a BDFL - and they chose to organize in a certain way, with proposal review meetings, managers, a TL‚Ä¶ But those are details. In terms of governance of the project, they act as one body and that body has that role for life. And it also actually *does* dictate. And while in smaller teams (like the Go team internally) dictation is counterproductive and consensus is valuable and leads to great outcomes, it is the most effective tool in a large, amorphous group like "the Go community". Where consensus isn't possible, both because of the sheer number of people and different opinion, but also because it's entirely unclear who is "part of the community" and "should have a vote". And IMO, the Go team is fulfilling that role pretty well. They are actively persuing inputs from the community and taking that input seriously. And sometimes they dictate, benevolently, to resolve impasses or steer the project where they want it to go even if the community doesn't see it yet. But I agree that hasn't really clearly been communicated like this before. I think [this can be seen as a start](https://twitter.com/_rsc/status/1022591332441890816) of that, though.
Why would it be MAX-SAT? MAX-SAT is about finding, for unsatisfiable formulas, the maximum number of clauses that *can* be satisfied. But in versioning, unsatisfiable formulas means the package can not be installed, we don't really care a lot about whether some other set of packages could. I agree that it might make the error message in the failure case more useful (i.e. "I can't install X, *but if you upgrade this one package Y, I might*"). But what I said is specifically, that the base issue isn't the *failure* case, but it's the success-case choosing poor solutions. MAX-SAT isn't helpful there, as it would just output N (with N being the number of clauses). &gt; It still works well in practice, although np hard. If it works well in practice, I'm wondering why no package manager has implemented it that way then. Because certainly all *practical implementations* of SAT solvers in package managers I've ever met behave very poorly.
Right?
Sounds a lot like the goals of knative
Feels to me like this has all arisen as a result of a fundamental difference of priorities between the two groups. This article (and others written by members of the dep group) focus around the social side of the process; they feel that the process of creating dep was done well and that's the most important thing. Unfortunately the core Go team attach less value to that and were hence less happy about dep. Or, to put it another way, the dep team would rather have a less optimal design as long as most people were happy with it, but the Go team would prefer a better design even if people were unhappy as a result. That's a bit of a caricature but I think it strikes pretty close to the choices made by each side. I can see how it's not a pleasant experience for the dep team, and I sympathise, but I'm firmly in the latter camp; I want the best (and most "Go-like") package manager and am less bothered about who writes it or what got thrown away to get there. That's obviously a lot easier for me to say than someone who had skin in that game though.
[removed]
&gt; Can you clarify how these quotes from Russ do not communicate that clearly? I've never seen those comments before today. I guess... maybe, other people didn't either. What I did hear and see, was people rallying behind dep, and no clear, authoritative public counter narrative, until Russ dropped the first vgo post... for a long time after that post. So, I would say, that communication was not effective. Not in *what he was saying*, in, as he has pointed out in his tweet storm, *communicating that to the community*. &gt; And the only way I can see the Go team having done more against that, would be to put a post on blog.golang.org saying that the package management committee is completely misunderstanding and miscommunicating the intent of the Go team and that you shouldn't listen to them. That would have been preferable. I less confrontation approach would be an early post on Russ's blog say, outlining his position. &gt; Personally, I hope that we can use this as a model for future community involvement. Not how it went, but how it might have gone. I think it could be an incredibly effective model... Well, all we got this time was a fait accompli implementation to replace dep, rather than engaging with the working group. ...so, if you want it to work better next time, it's not the working group who has to step up and do something different. 
man looking at a qualified engineer struggling with installing Python and Tensorflow is the exact issue with General Programming entry bar :(... I am trying to get my younger brother, who is Chemistry major, to pick up Python on his free time and things like this has not been making it easier.
&gt; That would have been preferable. Okay. Do you think the way chosen - namely, to talk to the dependency management committee directly, to not undermine their efforts - was *unreasonable* though? I agree that there might've been reasonable alternatives, but to *blame* Russ, the thing he chosen to do would have to have been unreasonable, bad-faithed or predictably worse than the alternative. I find any of these an incredibly hard case to make. And I think it's a pretty easy case to make, that it wouldn't even have mattered, if the public communication that *did* happen, by the dep team, didn't directly contradict or at the *very least* completely omitted the opinions expressed by the Go team. The only reason Russ had *at all* to choose between "engage with the committee, let them speak to the public" and "publicly denounce what the committee says and clarify the position of the Go team" is, that the dep team publicly pushed a narrative that went against the wishes of the Go team. And if, after that, the dep team decides to cry foul and be surprised that the Go team didn't like dep, strikes me as ruefully unfair. *You* might not have seen those comments before, but the dep team did. And they still chose to provide you with the narrative that you where living with. &gt; I less confrontational approach would be an early post on Russ's blog say, outlining his position. I don't believe there is much of a difference. It is still a statement by the TL of the Go team that directly contradicts the statements of the dep team and it would still have undermined their work. &gt; I'm utterly mystified that you seem to feel like it worked / was fine. I never said that. On the contrary, I specifically and repeatedly said that things went wrong. I just find it completely unfair to blame Russ. And I take issue with claims that he didn't make his positions clear. He didn't advertise them broadly to the community (and he had good reasons and did it in good faith, whether you *agree* with them or not), but they were not a secret and anyone involved with the actual process was aware of them. &gt; Well, all we got this time was a fait accompli implementation to replace dep, rather than engaging with the working group. And I believe that this is a conclusion that directly contradicts the facts. Your criticism, in its core, can actually attributed to the fact that he *did* engage with the working group and took their effort seriously. &gt; ...so, if you want it to work better next time, it's not just the working group who has to step up and do something different. For sure. Which is why I think this it's important to talk about that, actually. I think at its core, there was disagreement about what role the working group was playing. Personally, I understand to be Russ' vision of the role of working groups to collect and discuss, in collaboration with members of the Go team, the problem- and solution space and provide input to the Go team about the outcomes. Note, that under this idea of a working group, all of Russ' actions are explainable, rational and reasonable. Under this vision, the experiment of dep was a success, because it provided valuable input to the Go team and shaped the actual design of modules in Go. Sam's and others vision of the role of working groups seems to be that they are the decision makers on that problem and be given authority to decide (otherwise I can't explain phrases like "his arguments failed to convince us"). They are the experts and the correct solution is to be whatever they decide as consensus. Note, that under this idea of a working group, Russ' actions where nefarious and arrogant. He ignored the authority of the working group and decided to go over their heads and instead implement his own solution. This is why I think that no one really was acting in bad faith - there simply was a different understanding of what the role of the working group is. It explains why Sam and the dep team feel steam rolled and treated unfairly and it explains why Russ considers the outcome (sans the conflict at hand) intended and positive. And if that's the source of conflict, then we - as a community as a whole - should talk about what role we *want* such working groups to play in the future - instead of talking about who was in the wrong this time. That's the postmortem style of blaming systems, not humans. The issue was a lack of definition of the role of working groups, leading both sides to act counter to each other. The action item is "define the role of working groups for the future". *After* that, people can decide what they think of that role and whether they like to contribute under that banner or not. Personally, I tend to find what I outlined to be Russ' vision preferable; it's in line with existing processes and the role of the Go team as owners and stewards of the project. It enables the Go team to scale better past their limited size, while also making sure that Go remains the great project they made it so far. But of course, there can be different opinions; it's still more productive to talk about how we prevent such conflicts in the future than to ensure the blame-finger is pointed at the right person.
A byte buffer is used to improve performance when writing a stream of data. Rather than writing data every time you can, you wait until you build up to a designated buffer size and then flush it all out at once. This is useful for things like writing to disk where it is inefficient to write small chunks of data.
It's just a handy wrapper around byte slice, with \`io.Reader\` and \`io.Writer\` interfaces implemented. There is a good article from Go Walktrough series on \`bytes\` package: [https://medium.com/go-walkthrough/go-walkthrough-bytes-strings-packages-499be9f4b5bd](https://medium.com/go-walkthrough/go-walkthrough-bytes-strings-packages-499be9f4b5bd)
I've used it quite a bit as in-memory replacement for a file. It's also quite handy to use as a builder similar to a string builder.
Maybe your thinking about bufio?
I realize this is a few months old but is there anyway I can interface with a go process thats like a daemon over gRPC or a websocket locally from the native java application? The use case is I have a relatively complex alg. written in go for mapmatching against a dataset from a gps point. Could I have the java app be effectively the client to send point data to the daemon running locally that sends the output map context from that point back into the java application. Hitting an actual backend isn't viable as it will be used in places lacking cell phone service. I have effectively no java experience but I feel like I can hack out GUI, android API stuff relatively quick, as what the app does isn't complex at all but rewriting the alg. would be learning the require actually learning language. 
Essentially just a `[]byte` with some methods to make it usable with other components. Like, you can write to it (which appends to the slice) and you can read from it (which returns data from it). Think of it as an in-memory file. An example of how to use it, is in HTTP handlers. Say, you want to write out some JSON. But encoding the JSON might fail (because a nested field is invalid or somesuch). If it fails, you have to return a different status code. You can't just write it directly to the connection to the client - because if you do, and encoding fails in the middle, you can't set the status code anymore, as it has to be set before any data has been written. Instead, you can write it to a `bytes.Buffer`, which will just collect the encoded data in memory. Once you've verified that you can indeed encode the JSON without errors, you can set the status code to success and start writing the buffered data to the connection. func ServeJSON(res http.ResponseWriter, req *http.Request) { someData := businessLogic() buf := new(bytes.Buffer) // write to buf if err := json.NewEncoder(buf).Encode(someData); err != nil { res.WriteHeader(res, "whoops", http.StatusInternalServerError) return } io.Copy(res, buf) // reads from buf, writes to res } (though this is probably not the *greatest* example, as `encoding/json` also provides an API to directly return a `[]byte`, but maybe you can imagine another package which only provides an API taking an `io.Writer` :) )
I believe you're thinking of [bufio.Writer](https://godoc.org/bufio#Writer) and [bufio.Reader](https://godoc.org/bufio#Reader).
I use it often when I want to write a bunch of data and turn it into a single string. greetings := \[\]string{"hello","hi","hiya", "hola", "howdy"} buf := &amp;bytes.Buffer{} for \_, greeting := range greetings { fmt.Fprintf(buf,"%s is a greeting I use\\n",greeting) } return bug.String()
I use bytes.Buffer for similar reasons. For those who may not know for string building there's an actual strings.Builder now https://golang.org/pkg/strings/#Builder which is a fairly recent addition to the standard library.
&gt; Why would it be MAX-SAT? MAX-SAT is about finding, for unsatisfiable formulas, the maximum number of clauses that can be satisfied. But in versioning, unsatisfiable formulas means the package can not be installed, we don't really care a lot about whether some other set of packages could. Not necessarily. MAXSAT is an optimisation problem, so you don't only answer "is there a solution to that problem" (which is what "raw" SAT does), but "what is the best possible solution to that problem", which is, indeed, identified as a number of unsatisfied clauses. For instance, let's say you have the following set of constraints : - package b and c must be installed - package a exists in version a1 and version a2 - package b exists in versions b1 and b2 - package c exists in versions c1 and c2 - b1 requires a1 or a2 - b2 requires a2 - c2 requires a1 - there is at most one version of each package - whenever possible, the most recent packages must be installed it can be translated as a weighted MAXSAT problem, where each line is a clause where at least one literal must be true; each clause is associated with a weight, and the cost of the solution (we want to minimize) is the sum of the weights of all non-satisfied clauses (it would be 0 if the problem was totally satisfiable). The cost 1000 is chosen as an arbitrary number to indicate a clause must be satisfied, no matter what. b1 or b2: 1000 c1 or c2: 1000 not(b1) or a1 or a2: 1000 not(b2) or a2: 1000 not(c2) or a1: 1000 not(a1) or not(a2): 1000 not(b1) or not(b2): 1000 not(c1) or not(c2): 1000 a2: 1 b2: 1 c2: 1 There is no "perfect" solution with cost 0 here, because a2, b2 and c2 cannot all be true. The best possible solution is a2, b2, c1, with a cost of 1 (because the clause "c2: 1" is not satisfied), and a MAXSAT solver will eventually find it (maybe after finding correct but poorer solutions, like, for instance, b1 and c1). &gt; If it works well in practice, I'm wondering why no package manager has implemented it that way then. Because certainly all practical implementations of SAT solvers in package managers I've ever met behave very poorly. Hmm, have a second look. I know for sure eclipse's package manager is based on a MAXSAT solver, because it was developed at my workplace (SAT4J). Russ Cox actually lists several other package managers that are based on a SAT solver https://research.swtch.com/version-sat, but I can't know for sure, because I've not worked on them.
&gt; Russ Cox actually lists several other package managers that are based on a SAT solver https://research.swtch.com/version-sat I think you misread :) I didn't say that no package managers are based on SAT solvers, but that all the ones I came in contact with behaved poorly :)
yeah, I agree, but those preliminary practices are also crucial parts of the learning process itself.
My bad then. This is a very subjective opinion, though ;) Thanks for the interesting conversation.
Go compiles to ARM, Android is an open platform so I guess you could package a Java application together with it but is could more trouble than its worth. If you have JavaScript experience you could look at NativeScript (uses typescript and angular) or React Native. I would seperate the work load and let a web service deal with the hard stuff and let mobile devices just consume it over an API. I have had a few beers so sorry if any of your message was read out of context. Po
Think about it. What language has done the same? I can't think of one. There is a reason for that. It's a bad idea.
I think part of the problem is that we never learn that process i college. Most of the time class projects go, ‚Äúhere‚Äôs a install.sh file that will NEVER fail, as long as you run it on a lab machine.‚Äù
You should give it a name if it is long, you want to attach a special meaning together with documentation and ofc if you use it in multiple occasions. I almost always name my interfaces only if there is type assertion on maybe temporary errors and I only need to check for it in one occasion I type `interface{ Temporary() bool }`.
Scan it into a []uint8 first, then convert it to the appropriate type for your struct.
maybe checkout https://github.com/markbates/goth
Your answer is correct. To boil it down some more: it‚Äôs an adaptor that lets you use a byte slice as an io.Writer and turn strings/byte slices into io.Readers. 
I made an issue to request the removal of naked return from Go 2: https://github.com/golang/go/issues/21291
I think you have been downvoted for merely mentioning Node. Oh well. 
Thanks. How do I implement native authentication using goth?
Npm vs. yarn. 
Please note for future readers: while I understand this is an example, nobody should be buffering JSON before writing it back in a server or any other streaming scenario. The json.NewEncoder().Encode() method in encoding/json already buffers internally while it encodes for exactly this reason. You should be doing something like what I have demonstrated here: https://goplay.space/#ByWjS0_LM1X
The \`interface{}\` type with zero methods is used to represent something that can be any value. It's often used by packages that will use reflection to determine what to do with the actual underlying type. I suppose you could call it a rule of thumb that one generally doesn't replace it with a named interface like \`type AnyType interface{}\`. I would consider renaming the empty interface to be considerably more difficult to parse.
Hm, this made me curious. It turns out that behavior is not documented. Maybe it should, I wouldn't want to rely on it else.
True. Although it is documented in a roundabout way. [https://golang.org/pkg/encoding/json/#Encoder.Encode](func (*Encoder) Encode): &gt; Encode writes the JSON encoding of v to the stream, followed by a newline character. Technically that would necessarily mean that if the encoding fails, nothing is written. Also, it's clearly [https://github.com/golang/go/issues/7872](intentional and known functionality), so I personally feel safe using it. To each their own though! :) 
Either way, thanks for letting me know, I genuinely had no idea :)
No problem! I‚Äôm glad I could contribute some extra knowledge somewhere! :) 
dep people are just bunch of hipsters with typical startup mindset (we'll do something and sell it). The problem is `dep` is a mediocre piece of software. Poorly planned, poorly executed.
[removed]
&gt; the way the README was worded hipsters love blah-blah-blahing. That's all you need to know.
[removed]
[removed]
[removed]
From: https://golang.org/doc/effective_go.html#allocation_new &gt; The expressions new(File) and &amp;File{} are equivalent. Dito. the map example. Personally I almost always use composite literals, unless I want to use the extra arguments to make() ... I never use new (and I rarely see it used).
`t := &amp;MyThing{}, t := new(MyThing)` They're essentially the same. `t` holds a pointer to `MyThing` in both cases, and they're ready to use without any kind of initialization. `m := map[string]string{} and m:= make(map[string]string)` Same thing, but the result of these two operations do not return pointers. https://play.golang.org/p/0wy0TnmuJZ3
FWIW, I tend to use `new` if the type I'm creating is opaque but used as a pointer and composite literals if there are fields that *could* be set (even if I don't). For example, I use `new(bytes.Buffer)`, but `&amp;http.Server{}`. But it's a matter of taste, of course.
I think you are comparing two different instance of varibalem, that's why it print false.
If only all threats were so productive! "I'll also learn more math and start working out, _that'll show you_!" :-)
I did the Ubuntu 18.04 snap update. The first launch had missing highlighting but then it just wanted to update the entire suite of plugins. Things were back to normal for me after that second restart. I also did a manual update on a 16.04 at work with no trouble. Just noting that here since your report wasn't consistent for me. 
Use named interfaces when you want people to be able to read your code, unnamed interfaces when you don‚Äôt want them to be able to.
Yes absolutely, I totally forgot to remove that print. Thanks for the heads-up!
I did this exact thing except generating a CSV report
A webhook is basically an endpoint that is expecting a request from a third party. For example, lets say you upload a giant document for processing at on some service "awesomedocprocessing.com". On your website you'd have an endpoint like "/doc_status" and then in your account on awesomedocprocessing you'd put in that "/doc_status" is your webhook. When the doc is done being processed they will hit your endpoint with some info about the process, how long it took to complete, any errors, etc. Then you can do what you want with this data.
Whoops! You are right.
Tbh I think that unless you are attempting to do 10,000+ lines from different sources I think speed isn't a concern. Reason: your http request is really your bottleneck with small sample size requests. If you are doing a TON of analytics, and can benefit from concurrency, go will be something to target, otherwise it's a simple enough script that speed is a non issue due to the bottleneck being http not your script, and whatever language gives you less developer investment is the better choice.
Try Gorgonia! This morning I literally just spun up a new EC2 instance with `ami-aff750cd` as the AMI, and typed the following commands: 1. `sudo cp /usr/local/cuda/include/cudnn.h /usr/local/cuda/include/cudnn_v7.h` 2. `sudo add-apt-repository ppa:gophers/archive` 3. `sudo apt-get update` 4. `sudo apt-get install golang-1.10-go` 5. `mkdir -p ~/go/src/gorgonia.org` 6. `go get -u gorgonia.org/gorgonia gorgonia.org/tensor gorgonia.org/cu gonum.org/v1/gonum/...` 7. `cd ~/go/src/gorgonia.org/gorgonia` 8. `go test -tags=cuda -run=.` Granted, I'm working ON Gorgonia itself. But likewise I have worked on projects where I just get an executable and it runs. 
I started using delve for debugging and it is awesome. Its a lot like GDB. I'd recommend it to you when you run into some fun runtime issues in the future! https://github.com/derekparker/delve
Neat. I tried to do the [same thing with JVM bytecode](https://github.com/cretz/goahead), but the shear size of the stdlib [blew up the Go compiler](https://github.com/golang/go/issues/18602) (several hours, several disk gigs) so I abandoned it. But they've made compiler improvements since so I should revisit it. But the main issue was the large amount of exported identifiers and the fact that, since Java allows circular import refs and Go doesn't, I was forced to put most of it in one huge package. I should revisit that again too since modules now exist that disallow that.
Why don't you email Fransec and see how it goes? He is generally a very nice person and if you offer help perhaps there is a chance to make a Gorgonia video after this one. Dm me if you want to know email...
https://github.com/avelino/awesome-go I'd pick something in that list that sounds interesting. Most of those packages are really well done. If you have any questions feel free to hit me up or join the golang slack https://invite.slack.golangbridge.org/ and ask the questions there.
The first source are the sources of the Go itself. Then if you wish to learn how to write good library it may be sqlx, go-micro. NATS is a good example of a service. A big ones I've had dealing with are azure-sdk and YouTube-sdk.
Username checks out big time
An interface variable has a dynamic type and a dynamic value. It is nil only if both the type and value are nil. In your case it's got the type \*main.S and the value nil (use reflect TypeOf &amp; ValueOf). Try printing it before assigning it to s. Read: [https://golang.org/doc/faq#nil\_error](https://golang.org/doc/faq#nil_error). 
Well done!
Interface is a pointer itself that point not nil like to a pointer that points to nil https://play.golang.org/p/MWelPSJO9op 
I would like to add some thoughts too. Let's start by agreeing that package management should have been present from start (v1.0). The amount of packages out there, that are not following some guidelines about package management, is overwhelming and create a very bad ecosystem. So our first objective should be to put out some guidelines that are acceptable by everyone (e.g. semantic versioning) and push the community to adapt them in order to make the ecosystem more healthy... If we can prove that one is better than the other, based on requirements, then we should be able to make a "fact based" decision. I agree that in a a tie situation the ones making the decisions should take over. 
Although I really like the project and want to thank you for your effort, I have to ask: Why Python 2? :)
I believe gorgonia is the next installment of the Go4ML series :) (I would have preferred a linear regression with Gonum before going with tensorflow but I am probably biased :P)
periph.io It's really great. I've found the API much more Go-ish than gobot.io (but ymmv)
In Go, nil doesn't just represent a null pointer but also a zero value for several types: slices, maps and interface. A zero value of interface is, by definition, an interface that has neither type nor value. When you assigned a typed nil pointer to an interface, it no longer has zero value so it no longer equal nil. Or consider this: if you assigned int of value 3 to an interface, comparing it to nil would be nonsensical.
Here is great explanation of nil in go, including the nil interface: [golang.org/s/nil](https://golang.org/s/nil) But basically, (\*YourType)(nil) != interface{}(nil)
Personally, I suggest that if anyone wants to learn Go by look it's source code, to install an IDE (like Atom + Go Plus plugin etc) which can let you (Control-)Click to navigate. It saves me a lot's of time from digging through those source files to find which function is in which file, and that actually make source code reading fun again.
What‚Äôs the difference with the old project?
Vscode works like a charm in this respect
That's what's used inside Google. Python 3 only recently became supported, I've heard. Grumpy was started in Google.
Oh wow, wouldn't have thought that. Thank you. :)
IMHO the most annoying thing about the Python world... I guess those who use python2 for new projects are just lazy to learn (probably not the right word) python3. 
Adding to the comments above, this is a highly recommended read on how interfaces are implemented in Go: [https://research.swtch.com/interfaces](https://research.swtch.com/interfaces) It really helps to understand those cases in the future. There is also a part on interfaces in "How to avoid Go gotchas" post with visual explanations of your nil case, but it's heavily based on previous one. [https://divan.github.io/posts/avoid\_gotchas/#interfaces](https://divan.github.io/posts/avoid_gotchas/#interfaces)
You guess wrong. It's not always a matter of being "lazy". Python3 did a number on its community, and some companies have incredible amounts of legacy python2. Being a dynamic language, the situation is complicated. 
https://github.com/gothinkster/golang-gin-realworld-example-app For any new web thing, I've been looking at this project to check it out. There's some other go related projects that haven't been promoted yet too.
me too.
here is the Gonum version (using `optimize.Minimize`. one could probably just [mat.Cholesky.Solve](https://godoc.org/gonum.org/v1/gonum/mat#Cholesky.Solve)): ``` func minimize(xys plotter.XYs) (m, c float64) { xs := make([]float64, len(xys)) ys := make([]float64, len(xys)) for i, xy := range xys { xs[i] = xy.X ys[i] = xy.Y } res, err := fit.Curve1D( fit.Func1D{ F: func(x float64, ps []float64) float64 { return ps[0] + ps[1]*x }, Ps: []float64{c, m}, X: xs, Y: ys, }, nil, nil, ) if err != nil { log.Fatal(err) } m = res.X[1] c = res.X[0] fmt.Printf("cost(%.2f, %.2f) = %.2f\n", m, c, res.F/float64(len(xys))) return m, c } ``` https://gist.github.com/sbinet/89a2806481c53244a25351d00a7b1696
In addition to the great info already in this thread, here's [a good article on it by Dave Cheney](https://dave.cheney.net/2017/08/09/typed-nils-in-go-2).
Why link to this one over the official repo ? https://github.com/google/grumpy
[An interface value is a box to store another non-interface value](https://go101.org/article/interface.html). If an interface value stores nothing, then it is called a nil interface value. An interface value storing a nil pointer/slice/map/channel/function value still stores something, so it is not a nil interface.
The one truly great gotchya in Go! Everyone gets bit by this once. I second the recommendation to read https://research.swtch.com/interfaces. But the very short answer is an interface is two things, a pointer to the type that implements the data, and a pointer to the instance of the type. So even if the *instance* is nil, the pointer to the *type* is not, so the overall value of the interface is not nil. It's very confusing when you first encounter it, but it actually makes sense and is the behavior that fits best w/ the rest of the design of Go. (This should be a FAQ somewhere, and warned about more prominently.) 
This is great advice, the docs around functions in the Go source are usually really good and helpful. Having an editor that lets you bounce around instantly makes for some fun spelunking! 
Check [this issue](https://github.com/google/grumpy/issues/406).
I really like the code and structure of matterbridge. https://github.com/42wim/matterbridge
Congrats, you stumbled over the only quirk in the entire language. The first place would be the Go faq but there are tons of recourses on this topic. The essence however is that the literal `nil` is an untyped constant. Different nil types may not compare equal or some can't be compared at all.
[SentimensRG/ctx](https://github.com/SentimensRG/ctx) could use help with writing some unit-tests. The library code is very simple.
Go dep's Gopkg.toml/Gopkg.lock are probably the closest thing to package.json/package-lock.json. It seems like the go.mod would be kinda like index.js exports but with package management baked in. 
Works for me: https://play.golang.org/p/Jqv1hT6NVlk From the error it sounds like your raw values aren't valid JSON.
Though this was quite a while ago, I seem to recall the docs being specific about the expectation of slow performance and mentioned that it would be improved in the future, so I interpreted that as meaning my issue of very very slow performance was not unknown. Perhaps it was meant to mean slow but usable and I misunderstood. It was a very simple project of my own running on git protocol and I had been working on it previously with only go get, so I don't think it was due to an unusual workflow.
‚Ä¢ Variable `a` is an slice, in the example, `[]byte{}` ‚Ä¢ Variable `i` is an integer representing an index in `a` ‚Ä¢ Variable `x` takes a chunk of data from `a` from index zero until index `i` ‚Ä¢ Variable `b` takes a chunk of data from `a` from index `i` until the end of the slice ‚Ä¢ `append(b, x...)` merges all the items in `b` with all the items in `x` Here you can see the code in action ‚Äî https://play.golang.org/p/RuIuJpg--1s
The code in general is doing slice manipulation: ‚Ä¢ Variable `a` is an slice, in the example, `[]byte{}` ‚Ä¢ Variable `i` is an integer representing an index in `a` ‚Ä¢ Variable `x` takes a chunk of data from `a` from index zero until index `i` ‚Ä¢ Variable `b` takes a chunk of data from `a` from index `i` until the end of the slice ‚Ä¢ `append(b, x...)` merges all the items in `b` with all the items in `x` Here you can see the code in action ‚Äî https://play.golang.org/p/RuIuJpg--1s
first line gives x and b the two parts of the a splice / array. The round brackets aren't doing much, a[:i] means all elements up to i and a[i:] means all elements from i to the end. Second line changes the order of the first parts. You need the elipses ... to split up the splice into single element arguments. Here is a playground: https://play.golang.org/p/yBbvOA9Re6Q 
instead of `rec = nil`, you could do: `rec = rec[:0]` to reuse already allocated memory. (not that it would matter much here, though.)
Note that the parens around "a" are unnecessary, which contributes to any confusion.
These two lines are splitting a slice into two variables, x and b, at index i and then putting them back together in opposite order. The parentheses are unnecessary in line 1, which may be causing some confusion. It stores the portion of the slice starting from index 0 up until the item in index i in the variable x. It then stores the contents of the slice from index i to the end of the slice in variable b. Line 2 then uses the built in append method to add the contents of x to the end of b, resulting in these two sections being swapped. (Here is an example)[https://play.golang.org/p/Qv9hW52yi7J] on the go playground. Sorry for any sort mistakes, this was all typed on my phone. 
`&lt;trolling&gt;`perfect fine syntax`&lt;/trolling&gt;` I wonder if this is something that could be addressed with Go 2.0, since this kind of code is hard to read.
If this is in a real program it's leaking memory
Are you able to break the import graph into strongly connected components? Could help, as long as it isn't all just one big component.
[removed]
&gt; it took the vgo papers to collapse the quantum state I like how you keep a sense of humor in this rather difficult retrospective. Kudos for that!
yes, i, too, find this easier: (let ((a '(1 2 3 4)) (i 2)) (append (subseq a i) (subseq a 0 i))) 
I‚Äôm using these bindings for some debug tools at work and some personal projects. The author is doing an amazing job, keeping the bindings alive. Depending what you are doing but modern Qt apps are mainly QML code, the bindings may be a small concern. 
Exactly. I forget to mention that. VSCode is my main and only IDE.
old project had no progress. But one individual had enough energy to move fork forward. Now this fork became new base. 
Devs who do this are sort of a pet peeve of mine. If someone puts in some syntax like parens without an immediately obvious purpose (clearing up order of operations confusion, etc), I feel like I *have* to check and see if there's some esoteric feature of a language that I wasn't aware of.
Not sure if you're being sarcastic, but even though it's been two years since I last touched List, I still find your example very easy to understand.
pseudo inverses should be faster than any `optimize` versions IMO. Then again, I'm a guy who owns [this shirt](https://twitter.com/chewxy/status/986803321619951616)
Yes, I was being snarky. (Emacs for 20+ years, Go since before 1.0)
I'd use an array instead of a map for this specific case.
How?
probably since a, b and x are not freed, but go has garbage collection so that doesn't matter.
Go has garbage collection
Ahhh. Exactly what I was looking for. A real world example, with descriptions for environment config, package management, and useful tools. Thanks!
Thank you for the suggestion! I will check it out.
That's probably a healthy attitude on your part; I actually removed the parens first in the Playground code before commenting, just to make sure. :-)
&gt; NATS Thank you for the suggestions. sqlx looked great as it explained how to write services and functions with examples. I will go from there. The other suggestions are good, I will keep them for future reference. 
&gt; https://github.com/avelino/awesome-go Thank you for the suggestion. That is a long list! There are a lot good projects to learn from, especially ones that are well documented and explains why things are done a certain way.
thank you for your suggestion!
To clear up some confusion in this thread, Grumpy has been around for a while. It was started as something like a 20% project inside Google to help port their huge Python 2 codebase to a more maintainable language. The project was ambitious and attracted a lot of contributors, but the original author stopped maintaining the project for some time. The big news here is the community has moved on without him, putting the code in the grumpyhome organization, hence the title of this post.
Not quite, it's because it's slicing, not copying. We have an array a of 17 first, which ispointing to the first element. We get pointers into this array, x and b where b points to the middle and X to the beginning. We then set arr by appending b and x in reverse order. This extends arr by len(x) and appends x to it. arr is now set to where b was pointing to in a. So if we never touch a again, we end up with a managed leak as that is kept but not refered to. An example: https://play.golang.org/p/QgJdQ9oJXhi
The two lines rotate a slice by i elements. It can be written in one line: arr := append(a[i:], a[:i]...)
Honestly only the last line is what was the equivalent of the go code. Go would look like ``` arr := append(a[i:], ...a[:i]) ``` Which honestly isn't unreadable at all. A poor naming scheme is more to blame here
Thanks! 
Woah, you don't even know how on-topic this is for me. I was just wondering about practical ways to do just this.
I generally like to make sure functions fit on one screen, because they're easier to understand when you can see all the code at once. I'm more permissive with switch statements, because there is usually a pattern of only a few lines of code that is repeated over and over; understanding one case means understanding them all. So a switch statement with a large numbers of cases doesn't necessarily bother me...much. That said, if you need the switch statement in more than once place, a factory method is the way to go.
Awesome, glad it was helpful! 
is it meant to smoothen the integration testing process?
I never knew about this "real world" resource. Thanks for this bud.
Thanks I have already have similar setup in fact what I did was create two volumes one which shared code from host to container and the second volume which shared the binaries from a buildbox which only had golang installed and post final binary output 2 second volume which was shared among containers and like a Jenkins box it post all the build binaries to containers which reloaded. what why was unaware of was that there is a compile demon or something similar available which can auto reload
So you missed part of the exploit which is filling up the sendbuffer which means the output isn't being written to bash before the curl call finishes. This seems to work: https://pastebin.com/pZzPnD1b 
Interesting. Makes sense. I thought filling the buffer was part of the timing method as opposed to the phone home method. Thanks!
Yes you're right in that the filling of the buffer is part of the timing method in the original post, but it is also the phone home method by signalling that it has executed the delay. The idea is that, * you send a chunk with a sleep in it and then send enough to wrap over into a second chunk * wait to see how long the client takes to read that next chunk * if greater than an approximate latency and close to the innocent code with the sleep in it, it means that the client is executing each line in bash This means you don't need any callback like you are doing which could potentially give yourself away.
You should listen to Dave Chenneys talk on first class functions and how you can design code to not be switch statements as much. https://youtu.be/5buaPyJ0XeQ Happy watching 
Are these helpful? 1. https://godecl.org/?q=x%2C+b+%3A%3D+%28a%29%5B%3Ai%5D%2C+%28a%29%5Bi%3A%5D 2. https://godecl.org/?q=arr+%3D+append%28b%2C+x...%29
In addition to the source of Go itself, I would highly recommend [upspin](https://upspin.io/). It‚Äôs a very high quality Go codebase by some of the people who were on the Go team, including Rob Pike.
I'd link QT into the application only if its open source or for internal use only. Well or if you are shelling a vast amounts of $ every year to the QT company for a commercial license.
This code is problematic. If `a` is a subslice of something larger (i.e. `cap(a) &gt; len(a)`) then the append operation may silently overwrite memory in the larger/parent slice. Fix: `x, b := a[:i], a[i:len(a):len(a)]` Now append will always allocate.
Built this as a joke! Welcome to any criticism and of course, any PRs!
Thank you for this! I will use it to get into Docker/Go/and API's at the same time, i wanted to do all three anyways. Are you available for any upcoming questions (just so i don't annoy you in case you're busy)?
I was going to investigate this question before. It doesn't make sense now :) Thanks!
Hello mate I was following this guide and I fail when I run make up: Step 3/5: COPY ../.. . COPY failed: Forbidden path outside the build context: ../.. ()
This arcticle is about `bufio`, but it has `buffer` exemples and might be usefull (and give more understanding about bufio too in the process) https://medium.com/golangspec/introduction-to-bufio-package-in-golang-ad7d1877f762
One following question why port should be :5000?
This's cool. Thanks!
Nice post. We actually built a specific hot-reload container specifically for this purpose and have been using it for about half a year. It has an integrated file watcher and some pre-installed packages for testing and grpc connections Docker-Container: dkfbasel/hot-reload-go Code-Repository: [https://github.com/dkfbasel/hot-reload](https://github.com/dkfbasel/hot-reload)
So basically; - It takes as inputs: a slice `a`, an index `i` - It swaps everything before i with everything after i and stores it as x I wonder, is this the most efficient way of doing such an operation? Is there a better way to do it? Or would it be wiser to avoid doing this kind of operations and just using `a[:i]` and `a[i:]` when needed?
I think grumpy transcompiles to "series calls to runtime" instead of 1to1 Go code, which means zero readability. How does that help maintainability?
You aren't drawing anything, so you're getting whatever arbitrary uninitialized data there is in the framebuffer.
‚ÄúDepends‚Äù is a commonly advertised brand of adult incontinence diapers in the US. 
There seem to have been _so_ many of these popping up recently, and only [Google's "wire"](https://github.com/google/go-cloud/tree/master/wire) seems to make some sense IMO (but even then, I still wouldn't use it). This still has the problem that many of the other libraries like this has, you're sacrificing compile-time type safety, and heading towards runtime panics. There is no way to avoid that with a library like this, you can try guard against some of the ways that you might run into panics, but you can never guard against all of them - like for example, not defining a dependency. You couldn't check that at compile time without code generation. The problem of course being the use of `interface{}`. For example, say you update a type to need a new dependency. You update your constructor, all good, but you forget to `Register` that new dependency - it happens, but instead of failing to compile, or even failing unit tests potentially, it fails at runtime instead. If you have integration tests that might catch it, but nonetheless - why put yourself in that position? $ go run foo.go panic: Injection of argument 2 failed since the type 'Bar' has not been registered vs. $ go build foo.go # command-line-arguments ./foo.go:17:14: not enough arguments in call to NewWibble have (Foo) want (Foo, Bar) I know which I will always pick.
More the development process. As soon as you save a file, the change is quickly made live on the docker container so you don't need to manually build/run.
Thanks for posting!
It's 2018, under no circumstances should you recommend Atom as long as VS Code exists
I think the time to compile Python to Wasm is nigh.
Ah, thanks.
I like this simple design https://github.com/josephspurrier/gowebapp
Thanks for the comment! Yeah, I pretty much agree with that; I will generally always prefer compile time safety to run time safety. That said, every case is a tradeoff, and there may be times when there is a net win to be had. For instance, if dependencies are injected pretty early on in an application to initialise things, any registration issues will be caught quickly anyway. On the other hand, some obscure dependency that we forget to register is injected somewhere late on and *boom*.
Posted on: Mon Jan 01, 0001 Man, this article was pretty ahead of its time.
Haha, ah I did have a quick Google but I was mainly trying to avoid already-taken Go package names! 
¬Ø\\\_(„ÉÑ)_/¬Ø
Cool, I think a warning like that is a good idea :), especially for new Gophers.
Like: `arr = append(a[:i], a[i:])` ?
"I just read the title and didn't bother clicking on the link" LOL - so did I.... I like your explanation though
Also a tool for looking at executable static dependencies in Windows, which probably fits with that theme.
Nice. For folks that aren't using Docker, check out [reflex](https://github.com/cespare/reflex). I run it with one conf line to watch bin/web (with --start-service=true), and another line to watch for source code changes and trigger a rebuild.
Thanks for all the replies, guys. Much appreciated.
I think you meant https://github.com/DeedleFake/signage ?
Woops. Fixed.
Jesus! That's a long time ago. 
Great idea, hope it goes well!
&gt; Is this the most efficient way of doing such an operation? There is no efficiency gain on doing this operation with that syntax. &gt; Would it be wiser to avoid doing this kind of operations and just using a[:i] and a[i:] when needed? Yes, you can see your idea working here ‚Äî https://play.golang.org/p/V-OxJZU7j4E The syntax `a, b = [x, y]` is very common in Python, maybe the code was written by a Python programmer.
There is a third way. You write UI part in C++ using Qt, and create a DLL/so in go, exposing function you want to use in UI part.
It was an official experiment. **Experiment**. But since the core team was so hands off it was impossible to differentiate neglect from approval of the implementation decisions being made. For what it is worth, the core team finally learned an important lesson about community work.
No wonder no one understood its true value for the next two millennia.
Reddit got a chat feature for a few months now.
Same for me. I'm integrating this on my current project!
Agreed. I'm going to stick to the native implementation (go modules) and see how well it works, but I hope \`dep\` keeps being actively developed. I'll try it every now and then too. One can benefit from the other, specially since they target the same problem domain with different approaches.
great and clear writing.
I really dislike the use of a dedicated src folder. I think it'd just be easier to have top level folders for each service or just use the cmd,pkg,pb project layout on the top level of the project much like kubernetes.
Takea a look at tools like Bazel.
It's rather flexible, though.
I feel like anywhere willing to hire you to do GoLang isn't going to be the type of place with a lot of bureaucratic bean counters who'd care about meaningless certs. Check back in 30yrs. Those kinds of places might be starting to adopt it by then.
Bazel?, indeed it is. I'm in no way disputing that Bazel is an amazing tool. Its just rather heavy for what I want to achieve.
Don't add to the shared `Waitgroup` inside your `yelpReq` function. Instead, just create a new one specifically for the `yelps.Businesses` loop.
Try starting another waitgroup inside of `yelpReq()`, it looks like your nested go-routines are running over each-other.
Try starting another waitgroup inside of `yelpReq()` for your concurrent calls to `yelpReview()`. Also, `defer wg.Done()` will never get called since `wg.Wait()` will prevent the func from closing. This is a deadlock.
This is what i've come up with, if i'm understanding correctly, and it's still getting stuck after writing about 100 rows, which means it's looping through the main() for loop once then sitting. func main() { ... for y := 0; y &lt; 20; y++ { wg.Add(5) go yelpReq("https://api.yelp.com/v3/businesses/search?location=new+york", token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=hoboken", token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=miami", token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=los+angeles", token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=chicago", token, f, rev) wg.Wait() } wg.Done() // Make a final request to get daily limit amount client := &amp;http.Client{} r, err := http.NewRequest("GET", "https://api.yelp.com/v3/businesses/search?location=chicago", nil) r.Header.Add("Authorization", string(token)) res, err := client.Do(r) rheaders := res.Header var n int for header, value := range rheaders { if header == "Ratelimit-Remaining" { n, _ = strconv.Atoi(value[0]) } } fmt.Printf("\n%d yelp calls remaining today.", n) } func yelpReq(urlpath string, tokenauth []byte, f *os.File, rev *os.File) { var yelps Yelps var wgYelpReq sync.WaitGroup client := &amp;http.Client{} r, err := http.NewRequest("GET", urlpath, nil) if err != nil { log.Fatalf("\n%s\n", err) } r.Header.Add("Authorization", string(tokenauth)) res, err := client.Do(r) if err != nil { log.Fatalf("\n%d: %s\n%s\n", res.StatusCode, res.Status, err) } defer res.Body.Close() rbody, err := ioutil.ReadAll(res.Body) if err != nil { log.Fatalf("\nError: %s\n", err) } _ = json.Unmarshal(rbody, &amp;yelps) for _, j := range yelps.Businesses { fmt.Fprintf(f, "%s,%s,%s,%s,%t,%s,%d,%s,%.2f,%s,%s,%s,%s,%s,%s,%.9f\n", j.ID, j.Alias, j.Name, j.ImageURL, j.IsClosed, j.URL, j.ReviewCount, j.Category, j.Rating, j.Coordinates, j.Transactions, j.Price, j.Location, j.Phone, j.DisplayPhone, j.Distance) wgYelpReq.Add(1) go func() { yelpReview(j.ID, tokenauth, rev) wgYelpReq.Done() }() } wgYelpReq.Wait() } 
In what sense? If you're building a project with many services in a monorepo, Bazel or a similar build tool would be perfect for that. Buck might also be nice. I've found it to be very good on resources and once you get past the first build if you cache it, everything is very smooth.
No, there aren't official certifications for Go Developers, yet. You can check this page in a few years ‚Äî https://developers.google.com/training/certification/ Meanwhile, you can grow your skills by following these courses ‚Äî https://github.com/golang/go/wiki/Courses &gt; There are various online sites, not affiliated with Google, that are doing this. In reality, if you want a ‚ÄúGo Language Certificate‚Äù equivalent that is recognized by actual employers, put up a github account that solves a large and non-trivial problem in Go. &gt; &gt; When Google does start offering such an official certificate, that probably means that Go is entering the phase where there are too many ordinary programmers using it; making it harder to discern who is actually skilled with it. &gt; &gt; ‚Äî https://www.quora.com/Is-there-a-Golang-exam-or-certification
Call me crazy but I just don't like caching the entire deps for the build in golang especially when I'm already vendoring all the deps to begin with. All the deps twice can be very large, millions and millions of lines of code in larger projects. I'm well aware of the benefits and features of Bazel, but I'm only interested in deploying what's been modified in this use case. 
For $20 I'm willing to give you a Golang certification. No exam needed.
ya after reading more about it, they really should have avoided the word "official" in any way. I understand the meaning now, however when i was just glancing over it that came off as a strong endorsement to me (and im sure many others) that said, the issues with dep and the strengths of the "vgo" concept make vgo seem like a worthwhile endeavor to me. i hope this author of dep stops trying to stir up drama 
I think the default, when you add a new dep, is to use the latest version.
Re-add the original `wg` to `yelpReq()` and call `wg.Done()` underneath `wgYelpReq.Wait()`. None of the `wg.Done()` are being called and they need to be called. Also, move `wg.Wait()` from the loop to where `go yelpReq()` calls are being done to where the `wg.Done()` is. The `wg.Wait()` has to be outside of the loop while it ticks down from 100.
Well you're not just caching the deps per se, you're caching the builds and it only rebuilds what has changed assuming it can determine that deterministically, which is what Bazel is built for. If you change 5 lines of code from one build to another, the second build will just recompile those files with the 5 lines, all other deps if unchanged will be unaffected and be pulled from cache. In practice it's not that big of a problem, and quite honestly when starting out the cache will be rather small and you could then outsource it to a remote server if needed. Bazel will not rebuild everything from scratch, unless you clean it or the cache gets corrupted by some odd means. 
I admit I'm not that familiar with the inner workings of Bazel. A few things I don't fully understand about it yet. So let's say I use circleCI where I can cache the builds on the server and thus not need to commit them. If the new commits include new deps how does that update the cache.
Are you sure about that? My understanding is that dependencies are added via the import statement and that if you import a library without providing a version number it will default to v0 or v1. Read the proposal https://github.com/golang/go/issues/24301 and check out the section "Why are major versions v0, v1 omitted from import paths?". It seems pretty clear to me that it will not default to the latest. 
Memory leak... and eventually you will probably see oom kill from OS.
More importantly, I'm not really sure how to get a list of changed golang packages from Bazel. Which is the main and only output of my tool
Well for new deps new build rules have to be added, and when something includes that dep they get added to the cache automatically when you build or test. It doesn't disturb anything else unless of course it changes something in other deps. You should be careful though, only cache on head. Genereally each build rule gets it's own file and folder in the cache seperate from other cached artifacts.
This worked the best so far after trial &amp; error based on your feedback. There's still something off with the reviews csv. If i'm getting 1k rows in businesses I should be getting ::minimum:: 3k rows in the reviews csv, unless my thought process is wrong. Here's my updated code: ... for y := 0; y &lt; 20; y++ { wg.Add(5) go yelpReq("https://api.yelp.com/v3/businesses/search?location=new+york", &amp;wg, token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=hoboken", &amp;wg, token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=miami", &amp;wg, token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=los+angeles", &amp;wg, token, f, rev) go yelpReq("https://api.yelp.com/v3/businesses/search?location=chicago", &amp;wg, token, f, rev) wg.Wait() } // Make a final request to get daily limit amount client := &amp;http.Client{} r, err := http.NewRequest("GET", "https://api.yelp.com/v3/businesses/search?location=chicago", nil) r.Header.Add("Authorization", string(token)) res, err := client.Do(r) rheaders := res.Header var n int for header, value := range rheaders { if header == "Ratelimit-Remaining" { n, _ = strconv.Atoi(value[0]) } } fmt.Printf("\n%d yelp calls remaining today.", n) } func yelpReq(urlpath string, wg *sync.WaitGroup, tokenauth []byte, f *os.File, rev *os.File) { var yelps Yelps var wgYelpReq sync.WaitGroup client := &amp;http.Client{} r, err := http.NewRequest("GET", urlpath, nil) if err != nil { log.Fatalf("\n%s\n", err) } r.Header.Add("Authorization", string(tokenauth)) res, err := client.Do(r) if err != nil { log.Fatalf("\n%d: %s\n%s\n", res.StatusCode, res.Status, err) } defer res.Body.Close() rbody, err := ioutil.ReadAll(res.Body) if err != nil { log.Fatalf("\nError: %s\n", err) } _ = json.Unmarshal(rbody, &amp;yelps) for _, j := range yelps.Businesses { fmt.Fprintf(f, "%s,%s,%s,%s,%t,%s,%d,%s,%.2f,%s,%s,%s,%s,%s,%s,%.9f\n", j.ID, j.Alias, j.Name, j.ImageURL, j.IsClosed, j.URL, j.ReviewCount, j.Category, j.Rating, j.Coordinates, j.Transactions, j.Price, j.Location, j.Phone, j.DisplayPhone, j.Distance) wgYelpReq.Add(1) go func() { yelpReview(j.ID, tokenauth, rev) wgYelpReq.Done() }() wgYelpReq.Wait() } wg.Done() } 
That I have no specific answer for.
Depends on the program, if you have a single net.Listen that survives the entire life of the running program then having no Close() doesn't not matter as memory is freed when program terminates. On the other hand if your program opens up net connections and closes them after a short time, meaning multiple connections are opened during the lifetime of the program running, then not having a Close() would result in it leaking memory.
So it's something like Apache Foundation, but for Go packages?
Maybe! The Apache Foundation is much larger and more structured, and full of Java. üòâ I think in general we share similar ideas behind helping maintain important projects, but we're hoping to be a little more bespoke and closer to the Go community.
The bigger problem than memory leaks (a listener does not consume a lot of memory) is file descriptor exhaustion. There are only finitely many file descriptors that can be open at the same time per kernel and to cope with that, it limits the number of file descriptors per process. You can show that number with `ulimit -n` - on my system, for example, it's 1024. After you've run out of file descriptors, you can't open any new files or listeners. At that point, most programs will die one way or another (for example, you can't `accept` new connections, so if you have an HTTP server, it will get an error and return to main, which will usually exit).
I always think of the Apache foundation as where software goes to die. I don't know if that opinion is based on reality ¬Ø\\\_(„ÉÑ)\_/¬Ø
While they are not needed in the parents code, [parentheses might be required](https://play.golang.org/p/PHAGciXwzJ-) when ranging over custom types. Please continue your paranoia. 
&gt; *Personal, annual plans
Wow this is really helpful. I had been wondering recently why Go would be any slower than C especially if the garbage collector is turned off. It was helpful to see how some of the safety checks and memory conveniences impact the performance.
They could keep the word "official", since it was an official experiment. Words have power, I thought it was going to get integrated with the `go` tool, but again, being an official experiment, it could also fail and make way to a tool that leveraged the learned lessons and gained knowledge.
I'm always looking for more ways to optimize code out of the gate to minify the number of various things like bounds checks but ultimately I need more articles like the above to help understand what's going on at a lower level.
The grumpyhome forked version compiles only the imported packages, not the whole thing. This may be enough for you JVM stuff.
This post explain the difference: [https://labs.getninjas.com.br/released-grumpy-runtime-v0-3-0-a05f1cf8e111](https://labs.getninjas.com.br/released-grumpy-runtime-v0-3-0-a05f1cf8e111) (disclaimer: I wrote it) tl;dr: - Installable via pip - Better command line API nearer of CPython' `$ python` - Better support for 3rd-party code discovery - PEP-3147 support (\_\_pycache\_\_ folder) - Works on Android Termux (via 32bit ARM support)
Woah! Thanks for the catch!
Also note that all the write calls aren't safe automatically. You can use O_APPEND and then they'll "probably be fine" or have a dedicated business and review goroutines that are the only things writing to the files (pass the data to them via. channels).
Yep, as /u/theghostofm said, it's great to help the development process. I have also found that it can help the integration testing process as well though, for similar reasons. It let's your infrastructure stay running while you make code changes, so when you want to re-run your tests, they execute much faster since they don't have to spin up infrastructure.
&gt; optimize code out of the gate ü§®
Sure, feel free to message me
&gt; Hadoop &gt; Kafka &gt; Apache HTTP Server &gt; Cassandra &gt; CouchDB &gt; Mesos &gt; Zookeeper If by dead you mean supporting organizations worth billions of dollars, then yeah. 
If it's your every day style and way of thinking, is it premature? Doesn't cost me any extra time and generally not much (if any) cognitive overhead as I keep everything very readable. /shrug to each their own
What‚Äôs the reason for that? What would you advise b/w channels or o_append?
Right before we were thinking of a name for it I made a very similar joke: "It's like Apache Foundation but without funding" :-D
I'm not saying they don't have successful projects, because they clearly do. There are some that seem to end up with Apache when people don't know what else to do with them. Stuff like Wave, Velocity, mod_perl, NetBeans (...maybe), etc. Some of this software might just be OBE, but a lot of the projects haven't seen releases in years. Of course any software foundation with a variety of projects will have projects that are no longer "hip" and in maintenance mode, but the Apache Foundation seems to get a lot of them.
That uuid library looks like a prime candidate for scuttling, not rescuing...
There is no intention to stop when reached full Python 2 support. The missing parts will be needed for Python 3 support too. On the roadmap, Python 2 is just planed before Python 3. For exemple, `import sockets` is still missing and will be needed for Python 3 too. _(disclaimer: I am a member of grumpyhome)_
[removed]
actually this is the issue with all of these package manager . (rubygems, npm, pip, cargo, vim, fdroid...) IMHO for Go, it should been centralized, i know it is against the main idea but leaving it in the wild, for code, it is not reasonable or without a way to asses quality/reliability/safety... 
Not related, but set the timeout on those [`http.Client`](https://godoc.org/net/http#Client) instances. Without it, they'll wait forever.
Memory leakage. 
Thanks for the feedback
Is it worth it? I edit using VS Code at the moment with plugins and I'm not sure what else an IDE could offer me
[removed]
if you're curious to see, it has a free trial. I haven't done Go programming for awhile, so I don't have any opinions to offer on Goland.
Oh neat, I didn't know there was a trial. Might check it out, though I'm reluctant because if I like it I'd want to buy it :P
I am not sure forking popular Go libraries is a great solution. As a user I now have to investigate two slowly diverging forks of the same library. Wouldn't it be better to work together with the original author? Maybe talk to him about giving commit access to other people.
If you have questions or you need some clarifications how to get best of the NFF-Go for your apps, please, let me know - I will try to help.
I really like it. All of the JetBrains IDEs are very clever when it comes to understanding the environment, and they push updates pretty regularly. If you're a student you can get all of their IDEs for free btw.
refactoring capabilities are pretty amazing. i'm an emacs addict, but i keep it around just for the occasional automated refactor.
i use vscode and goland. The main difference ive noticed is that Goland is 1,000% better at "Find Usages" or "Find Implementations" for interfaces and methods. I'm sure theres other differences but that is the glaring one in my day-to-day use
I haven't found it any better than vscode with plugins. I am wary using a IDE with a language like go. That said, if you come from the IntelliJ background and are used to the ergonomics, it will fit like a glove for you. I am sure dlsniper will be here shortly to tell you why it's better than vscode
It's how open source works though. Forks are always (and should always be) a possibility, indeed it's how some of our most cherished software and libraries have come into existence: https://en.wikipedia.org/wiki/List_of_software_forks
I used both VScode and Goland a lot. They are both great. Goland has the edge because its auto completion/suggestion is very precise and fast. Vscode is terrible with auto completion especially if the project has more than a dozen dependencies. At some point both speed and precision degrade to: completely useless. I'm very lazy. I usually never hit more than two keys before I hit auto completion. Other than that, there is no real difference between the two. The annual plan thing annoys me, work pays for it though.
Try Vim
With vim-go
I don't think the plan is to take over packages that are being actively developed and accepting of fixes. In this case, the satori uuid library had an outstanding serious issue for several months.
It depends. The proposed fix is slow when it is unnecessary.
[https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-a-perpetual-fallback-license-](https://sales.jetbrains.com/hc/en-gb/articles/207240845-What-is-a-perpetual-fallback-license-) for those interested
Yes I understand all that. My point was go has garbage collection and therefore should eventually free the part of a that is no longer referenced.
I am not sure if https://github.com/oxequa/realize is relevant here but I use it personally. A lot more customization and come with default, easy to use config template.
Try the free version first. A general rule of thumb: If you hate Eclipse, then you'll probably dislike Jet Brains as well.
Personally I would use two goroutines and channels, because the code looks very similar but is safe for free (instead of writing you just send the object down a channel and do the file writes on the receiver of the channel). Go makes this change really easy to do. As /u/tv64738 said you can instead use a mutex, which is almost certainly slightly more efficient.
Yes, you are right, it will eventually get garbage collected. But as long as there is a variable that holds on to even just a byte of an another array or slize, that memory will not get garbage collected and that is a bit of a gotcha that some don't know about and most likely what the person meant by "this causes a memory leak" Unless you really need the performance and know that you will dispose of everything that is referring to data into the array, you are better of copying the data.
Keep the meaniness certs in the Java ecosystem. Go doesn't need certs. It just needs you to be a good programmer which no cert will ever prove
See https://research.swtch.com/vgo-tour. The initial version of rsc.io/quote is v1.5.2. You may be thinking of how pseudoversions use major version 0, and how a path that doesn‚Äôt specify a major version is intended to mean v0 or v1.
For real, do these kinds of things do anything vim or emacs can't? Am I missing something?
I use the "Find Usages" multiples times a day in Goland. It's one of my bread and butter tools. 
here's a good candidate: https://github.com/google/gxui
Okay, I will take an entry and senior level certificate üòÇ Both dated one year apart please
khm.. No. thank you. 
The first question in the exam is: &gt; What is the actual name of the language?: * A) Golang * B) Go Lang * C) Go * D) GOlang * E) GoLang * F) go-lang * G) go_lang If you want to demonstrate your knowledge: Start by using the proper names. No, seriously: Professionals are hired by other professionals even without printed sheets of paper. (If HR is involved they might be impressed by paper, simply because they cannot be impressed by actual knowledge. Think of 3 year old child: You can impress it with a large and shiny battleaxe but not with your complex analysis knowledge.) 
i don't think so no
[removed]
Still glad they reverted back to this license model after changing it back in 2015. Lot of backlash tl;dr for those that don't feel like reading: Every new license adds +1 year of updates to my perpetual license essentially. So if I bought a license in 2016, I can use 2017.x updates until my license runs out, but until I update that license all my updates fallback to the 2016 perpetual version. 
I'm just spreading information, what's the problem? If you don't need it cool, but it adds nothing to the conversation.
&gt; Try Vim If vim is your tool of choice more power to you, that editor is in a league of its own.
Also, they give you a [continuity discount](https://sales.jetbrains.com/hc/en-gb/articles/206386064-What-is-a-continuity-discount-), reducing the follow-up subscription price over the course of the first few years.
If you're looking to build a Web based CRUD API, I would suggest [golang-restful-starter-kit](https://github.com/qiangxue/golang-restful-starter-kit) It uses minimal magic to tie-up well tested libraries and still allow to easily swap other library as the need be. I'm using it for a fairly large size project along with [Modl](https://github.com/jmoiron/modl) with good success.
I love your code. Quite readable. I've been looking around for a DI library for a while, but never really got around to using them. lately I'm trying to see if I can leverage good design to mitigate the manual dependency wrangling I need to do at program startup, but nothing particularly good has come out of that venture. Might give this a try sometime.
Vim wins hands down for editing but can‚Äôt compare to goland‚Äôs debugger
I don't like Gogland, I do prefer VSC. Is it better? Or you prefer to see only IntelyJ fans here? 
Oh yes. That is the good stuff I was after. Thank you very much for this! I should have started my thread with asking for a CRUD API example. 
Thank you, this is very helpful. I am assuming blue jay is the go to, current version of the project?
Which plugins do you use with vscode? 
Bultin debugging, I suppose. But even there vim-go does a good job - though I rarely use more of its features than completion and tagging.
Having not tried Go modules yet, where are they downloaded and cached locally? I'd definitely want to be able to cache dependencies in CI to avoid having to fetch them every time the build runs.
There are several things wrong with this. &gt;However, now we know that arguments are passed on the stack, this means that any function that calls other functions now must ensure there is some stack space to pass arguments to its callees. This is what we see here: &gt; // Before the call: make space for callee. 0x48065f 4883ec28 SUBQ $0x28, SP // After the call: restore stack pointer. 0x48069b 4883c428 ADDQ $0x28, SP This is not exactly what's going on. Go functions allocate all the space they need for their local variables plus the largest call on entry (the SUBQ) and clear it on exit (the ADDQ). In this example it doesn't make any difference, because the function doesn't have local variables and does nothing besides making a call. In functions that do more you would see that there is a single SUBQ after the prologue and one add before every return, not a SUBQ/ADDQ pair around every function call. &gt; Because Go has exceptions (‚Äúpanics‚Äù) it must preserve the ability of the runtime system to unwind the stack. So in every activation record it must store the difference between the stack pointer on entry and the stack pointer for callees. This is the ‚Äúframe pointer‚Äù which is stored in this calling convention in the BP register It's true that the go runtime needs to retain the ability to unwind the stack at all times but: 1. it's not just for panics, GC and stack resizing also need this 2. the frame pointer doesn't have anything to do with this AFAIK the frame pointer was introduced to help non-intrusive debuggers, like dtrace, that want to produce stack traces but can't afford loading debug symbols. The runtime doesn't use the frame pointer to do this (although it mostly could) but a table stored in the executable file (which is called pcsp or spdelta in different parts of the code). &gt; the goroutine struct, which itself can always be found at address FS:0xfffffff8. The actual address where the goroutine struct varies depending on the version of go, use of cgo, architecture and operating system.
Technically, you just need a ‚Äú.edu‚Äù email address... 
Spreading information about a paid product is called advertising and I wish it have no place here except as being properly paid for.
A dissenting point of view is useful when something is claimed to be better than something else. It's not really useful when something just claims to exist. I use vsc but I have no problem with announcements of other solutions. If you try them, and they don't convince you to swap, all good. If, on the other hand, you were convinced, then this is a useful post as it could save you money. 
Nice. However.. Their pricing is completely borked. e.g I updated the PHPStorm at the end of april... and if I want to do an upgrade to all pack right now (to also get the access to GoLand). They are offering me just 39‚Ç¨ of additional discount. WTH? 89‚Ç¨/12\*3 is not 39‚Ç¨!
I'm really not sure but seems gowebapp is his most popular. https://github.com/josephspurrier To be honest I mostly just throw it all into one file first then spread it out as I see fit. If the project seems like it's more on templates then I just make a file of requests and another of the server. Because there isn't going to be as much logic that is uncoupled. If it is all apis then I tend to almost do the same cause well ctr +f is just easier. If there are other people you need to leave a trail for them so files it is. Just depends on the size. Go tends to make this easier when you start utilizing types. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Is goland built with electron? I'd replace vscode if goland is lighter
Java
I use VSCode on Ubuntu and have never experienced the performance degradation you describe, even with large projects. For those of us who don't suffer performance issues with VSCode, is there anything else that Goland offers?
Yes, the indexing that JetBrains does is it‚Äôs secret sauce. It makes a huge difference on large projects, especially on ones where they are too big to know the whole thing in your head. BTW, the ‚ÄúCall Hierarchy‚Äù feature is pretty awesome. Like Find Usages, but n levels deep. Hugely helpful at times. 
You can always uninstall the Terminal plugin if you don‚Äôt like it :) I get what you‚Äôre saying about it not being as good as something like iTerm, but it‚Äôs gotten some improvements lately that makes it pretty darn close. Have it context with the project has really won me over. 
Sublime for speed. With the right combo of packages, led me to ditch GoLand even.
Small protip: If you‚Äôre using multiple JetBrains IDEs, you‚Äôre generally better off just getting IntelliJ IDEA Ultimate and then installing the others as plugins. They don‚Äôt really advertise that you can do this, but it‚Äôs the same exact thing as the standalone IDEs, but all in one app and costs leas. 
What plugins do you use for Golang in VS Code?
It‚Äôs amazing how much it can do all for free.
I think Vscode golint is better than Goland, which was missing that plugin. Coding, running tests (file/package/individual), debugging, coverage is all the same. I think Goland has better shortcuts for 'Find implementation' and such, but someone else already mentioned that. If I didn't have that auto completion issue ( I literally wait 15 seconds to get a completely irrelevant suggestion) I'd go with Vscode
Java as /u/justinisrael pointed out. Start up is a bit slow, but the app itself when running is fairly speedy because of the indexing feature they have in place.
I'm looking for this. I need to use SNMP to discover the network topology. I found a library to do it, [github.com/soniah/gosnmp](https://github.com/soniah/gosnmp). But right now looking if somebody has already implemented a network discovery golang app using snmp. Any suggestions?
They are cached locally, so they'll only be fetched if not present. If you want to fetch from a nearby cache, rather than going to GitHub etc you can run a proxy. More details here: https://research.swtch.com/vgo
If you don't want to pay for the product no one's forcing you, but those that have tried the EAP's and were waiting for a sale then here is one at an affordable price. Have a good day, I wish you the best.
You can also get it free if you're working with open source. 
Why do you have a wg.Wait() in the last line of yelpReq() ?
You never have to check errors returned from `strings.Builder`. They are all documented to be nil.
Suggestion: Embed `strings.Builder` directly and make the methods pointer methods. That way, the zero value of your `FluentBuilder` remains a valid value (no need to initialize separately) and you save allocations when passing it as an `io.Writer` or the like.
I wrote this when I was making some pretty complex SQL queries. So the amount of lines that I would have written without the fluent methods, that would have made the file such a mess. Plus this provides a bit of organisation, in the sense that I could have related appends in one line. But I get the point when you say the former is more readable for "less" appends.
Knuth writing back in the day wrote in an environment in which programmers writing in Assembler would go absolutely crazy and write incredibly convoluted and fragile code dependent on every quirk of a particular machine in order to squeeze out meaningless levels of performance. It doesn't help that this was actually necessary to make programs run reasonably, so any serious programmer of the time had to learn these techniques, making it very easy to not realize when you should and should use them. In this environment, decrying excessive optimization is appropriate. Here in 2018, at scale, we face the complete opposite problem. We have professional programmers working in slow languages that can't help but be slow, like Python, who write with lots of cute-but-expensive tricks like layering things seven layers deep in various object adapters and slow (in Python) functional constructs that involve taking a 10,000 element list and construction several more 10,000 element lists as intermediate results, and then at the end of this process wonder why asking the database two questions and doing some "simple" processing takes 1.2 seconds... or worse, _don't_ wonder why something so simple takes 1.2 seconds and just think it's the nature of things! It's become very rare for me to see a programmer doing premature optimization nowadays. Nowadays we need something a lot more like "Casually using expensive constructs is the root of all slowdown". (Not sure I want to call it evil per se.) I see _way_ more code bouncing through seventeen layers of abstraction, each adding their own expense, to do something ultimately very very simple. A modern programmer is well advised to be constantly looking at the stack of abstractions they are sitting on top of, and being sure that they are all _providing actual value_. I like functional programming in general, but there are some people who will do things to avoid result := []Something{} for _, value := range input { if value.Method(arg) == 0 { result = append(result, value.DoSomething(arg)) } } so that they can "write it on one line", but if one looks at the actual instructions the CPU is executing can well be literally hundreds of times more instructions than the Go will be executing. One of the reasons I like Go is that the combination of the language and the community ends up with code that strikes a very good balance of good performance, readability, and simplicity. A single interface call in Go, for instance, is a bit expensive compared to a static function call, but very often, that single interface call is as "deep" as Go goes with the abstraction. It's unusual in my experience to either see or write Go code that's slow because it's just buried in too many layers of abstraction. It isn't _that_ hard to spend a bit of effort thinking about performance before you bury yourself in pointless abstractions. It's why I keep producing systems at work where people are like "OK, you're going to need a cluster of like 5 beefy systems for that and we need grand plans on how to expand that cluster rapidly, right?" and I'm all like "Well, actually, I'm kinda overprovisioned with two cores and 4GB of RAM; the CPU spends a lot of time idle when I run a simulation of 10 times the workload you expect me to have in the next two years". (But, yeah, we do at least need redundancy.) (Go isn't the fastest language exactly; you can optimize C or C++ or Rust to go two or three times faster if you work at it. But especially with C++, it's really easy for the naive code you write to end up really slow due to accidentally copying too much stuff and such. I find the first naive Go I write can generally be sped up by 5 or 10x without much work, and that once I do, we've got a pretty fast system for just about the minimal effort you could expect for it. The _bang for the buck_ is very good, even with modern language competition.)
well, Goland is a paid tool while vim-go is made by the community, so, as it should be expected, Goland is always up-to-date with new Go features (i.e. Go modules) while vim-go and other tools need some time to readjust
It's pretty inexpensive. I prefer the more accessible / less cluttered / fewer actions till push approach of the VS Code Git integration, but Goland doesn't break often like the VS Code extension. With the poor reliability of VS Code's extension and the annoying habit my VS Code as of restarting shortly after I open it (probably some extension resetting it, but I haven't narrowed it down) I've considered using a combo of Sublime Text and Goland. For now it's Goland and then I do my Angular in VS Code. And if I'm only making simple changes to the Go stuff, I stick to VS Code for the quicker Git commands. You might not have the same opinion on Git. JetBrains has a TON of functionality designed to make Git easy even for someone who has never used a command prompt, and for those who have, it still has some gorgeous polish. It's just more clicks and tends to take me quite a bit more time than the half second I spend committing in VS Code.
Sure. FWIW, if I had to dispatch many calls to a string.Builder, I'd probably do it somewhat like this var b strings.Builder w := func(ss ...string) { for _, s := range ss { b.WriteString(s) } } w("foo", "bar", "baz") w("qix", "qex", "qux") without declaring a dedicated type. But whatever works for you, of course :)
Hit up their twitter/contact sales people and see what they can do. I just did the same thing to the all tools pack myself and it dropped to $106 for the first year and they dropped my yearly all the way down to $150 (skipping the 2nd year pricing) $106/149.99/149.99 instead of $106/199.99/$149.99. idk if it was because i've had PHPStorm since 2014 or not which is why they changed it.
Speedy is subjective. When I installed it on my 4790k, I might as well burned my house down. 
Not all those plugins have 1:1 features as the ide's. Just thought i'd chime in. They can get you by though, most ide's like go started as a plugin so you'll probably be okay. Try it (the plugin) and see if it meets your criteria (tangent: my guess is rust ide is next because their developers have been working with that plugin a lot as well)
The terminal in a Jetbrains IDE is your terminal, they just run it in that window. You can change it to be whatever you want.
[https://www.codetriage.com/](https://www.codetriage.com/) 
Gin already used port from envvar, you don't need to fetch it yourself
I get they are cached locally, but on CircleCI that's not useful unless you tell Circle to cache the directory. I don't want every build in CI to download from Github, when Circle could persist a cache between builds.
Then google ‚Äúhow to close vim‚Äù.
That might be true for some, but at least for Go, they state: &gt; This plugin extends IntelliJ platform with Go-specific coding assistance and tool integrations, and has everything you could find in GoLand. I moved from the standalone GoLand to IDEA+plugin, and I haven't noticed anything missing. Of course, there might be something I haven't noticed. However, I've found IDEA much better for the projects I work on because they are rarely just one language, so I've found this a better workflow/environment for ployglot projects.
I think the length of variable names has nothing to do with how idiomatic your code is. So I'd suggest you do whatever you think is right.
Readability is always super subjective. That makes it impossible, basically, to convince anyone of any existing conventions, on its basis. It's a bit easier to agree, though, that uniformity between code basis *does* increase readability and editability. i.e. even if an individual convention might be bad, if it's *universal*, that at least means you don't have to argue about/get used to it, when reading/writing code in a foreign codebase. &gt; but how is the good vs bad example given here: The "how" is given on the slide linked: It emphasizes control flow. The less space is taken up by identifiers, the more the control flow stands out and makes clear what the code does. But see above: As you obviously know this argument, it won't *convince* you :) i.e. the answer is "it might not, for you, because readability is subjective. But it's a convention that is mostly adhered to in the Go community". &gt; I also feel like the whole debate is often held with each side deliberately giving horrible examples for the sides code. Things like insanely long variable names or one letter variables all over the place without any reasonable way to derive meaning quickly. I hope I am breaking that :) Usually, the effects are subtle. And it becomes a lot less contentious, if you stop framing it as "one letter names vs. Java names" and frame it as "the length of an identifier should be inversely correlated to the distance between its declaration and use". I'd argue that most people won't, *in practice*, care about either of the two, as long as the short names are only local and the long names are only distanced. &gt; Who would want to use a package for example, that doesn't even follow such basic language standards. Personally, I don't usually look at the code. I *do* look at the API and it's definitely sensible to follow naming conventions there. But then again, in the API the conventions aren't to use too short names anyway, because the identifier are non-local :) If the implementation code uses whatever identifier it wants‚Ä¶ I mean, I might get slightly annoyed when preparing a pull request and even more slightly annoyed when reading your code, but in general, it wouldn't have any influence on whether or not I'd use a package TBH. IMO it's better to use the language in a way that works for *you*, than to not use it at all. I prefer code with long variable names over no code at all.
I think the idea is that by using small variable names, you're probably thinking a lot more about what your code is doing. The way I see things is that if I'm struggling to follow the logic of something with small variable names, it wouldn't really make much difference if the variable names were longer. I care more about the type of a variable than what it's called, so I guess the most important thing is to name your types descriptively, and the rest should come naturally.
Thank you for telling me this :) I will apply that soon.
Free for non-commercial use though.
Variable names are a matter of style. Style is subjective, but straying too far from the common idioms of a community will be jarring to other members of the community. In my opinion, there is wiggle room within the idiomatic style. Use your judgement and write your code in a way that communicates its intent clearly to others. There are two key points of the "keep them short" advice about variable names. 1. Let the scope of a variable provide context. 2. Shorter names reduce clutter, especially if the variable is referred to several times. Regarding your specific question, router := mux.NewRouter() could be fine. But depending on the rest of the code, a shorter name might be better. Use your judgement.
Its been asked multiple times. Please do not feel that short variable name is hard requirement. You should use the way you like. E.g I write Java in very anti-java way like multiple classes in one file. Not using abstract classes, exception hierarchy and whole bunch of design pattern and so on. Think a good working software is better than no or non-working software following all idioms.
I honestly didn't expect so many answer's so quickly. I'll read every one carefully when I come home from work, but so far it seems like it may be less of a problem than I initially thought, as long as I try to conform to the way most people write their code at least a little. Thank you everyone for their input so far :)!
This is the longest response to an emoji I've ever seen! :p
[removed]
I agree üíØ I believe the ‚ÄúHow to Write Go‚Äù document says to avoid long variable names. I find that a travesty and disservice to our future selves and anyone else reading our code in the future...
Unfortunately the ‚ÄúHow To Write Go‚Äù document says otherwise...
Define ‚Äúbetter.‚Äù
We are currently working on a large project with over 50'000 lines of code (fortunately split up into several micro services) and had a similar discussion once or twice. The question basically boils down to why you would need long variable names. If the method or the scope were you use the variable is very short ‚Äì i.e. only a few lines of code ‚Äì then it is very quick and easy to find the declaration of the variable and understand the context and usage of it. On the other hand, if the scope were you use the variable is very long ‚Äì I would personally say something like more then 20 lines ‚Äì then it can be difficult to quickly grasp what a variable is actually used for, unless you have a good descriptive variable name. Therefore, short variable names could somewhat encourage you to write code with a smaller variable scope and small methods instead of writing huge methods and referring to variables that have been defined at a long "distance" of the current code. In practice, we use rather short variable names, albeit not the ultra short names usually found in the official go packages.
The idea is that you keep names short and keep their lifetime short. This means short functions, generally, so that the use of `r`, for example, is close to the declaration and initialization of `r`. If you find yourself confused between `r` and `rr` and `re` and `rx`, then you should probably consider using better names. But in all likelihood, your code needs actual refactoring, not just renaming stuff, to become idiomatic.
&gt; then you should probably consider using better names Or, perhaps, from the beginning! üôÇ P.S. It‚Äôs not about confusion, it‚Äôs about cognitive effort. No need to play a small time translation game for every line of code you read.
Why did you choose this project structure/layout? I am just curious what was your reference.
[removed]
Fair enough. I could argue the same point for short names, too, though. Inevitably a name here or a name there will be poorly chosen (long or not), and so your mind will need to keep track of all that regardless. My main point however: Short functions is the goal, and short names are an optimization (or regression ;) ) that stem from that goal. As you said, it's all about cognitive effort-- short functions with long names would still be considered idiomatic in my book, fwiw.
&gt;In my last article, I have created a service which was unorganized and only for beginner. So why would you tell a beginner to structure code bad in the first place?
What would you say to claims that you have dastardly plagiarized the one true database able to store the entire internet (and all written text which may ever exist), The Library of Babel? For proof, I found where you copied the readme line by line in Volume 5 on Shelf 5 of Wall 1 of Hexagon ID#gw,xpvqfg_mqcbcrvaxva109 in the library. Clear as crystal, bright as day, your crimes have nowhere else to hide. [Proof of your misdeeds.](https://libraryofbabel.info/bookmark.cgi?gw,xpvqfg_mqcbcrvaxva109) And you would have gotten away with it too, if it wasn't for an the existence of an infinite library algorythmically storing all possible text. 
Good names depend on context. Within a narrow scope, a short name may be perfectly descriptive. In a larger scope, it may need more disambiguation. In a small group of 5 people, I'm "Luke", and it would be needlessly and harmfully verbose to insist that I be "Luke Thomas Shumaker"; in this group "Luke" is a good name and "Luke Thomas Shumaker" is a bad name. In a group of 10,000 people, "Luke" is a bad name, and "Luke Thomas Shumaker" is a good name. In many short functions, `r` or `re` would be a great name. When the parent wrote "If you find yourself confused between `r` and `rr` and re and `rx` in one function, then you should probably consider using better names.", what that means is that your function has grown to the point that `r` *is no longer* a good variable name. &gt; "The length of a name should be related to the length of the scope. You can use very short variable names for tiny scopes, but for big scopes you should use longer names. " &gt; &gt; -- Robert C. Martin, "Clean Code"
You cannot append to a map, only to a slice. A map is a key-value data structure, so you _"append"_ by inserting a new key. Here I fixed your code ‚Äî https://play.golang.org/p/B8OsPti1qcp
Try this: testdata["test4"] = { /* ... */ }
&gt; If you're a student you can get all of their IDEs for free btw. linky?
That appears to be what I was missing. I kept looking at the example in the documentation and seeing an append in there, but I missed the type declaration above it. From the documentation: type Person struct { Name string Likes \[\]string } var people \[\]\*Person likes := make(map\[string\]\[\]\*Person) for \_, p := range people { for \_, l := range p.Likes { likes\[l\] = append(likes\[l\], p) } } Thanks. You have gold incoming.
Validating input is something every website/API has to deal with. Looking a the [c.BindJson()](https://github.com/velopert/gin-rest-api-sample/blob/master/api/v1.0/auth/auth.ctrl.go#L62) usage though, it doesn't appear the response provides information about what exactly failed which would be really frustrating if the API documenation wasn't up-to-date and the API simply returns a 400. type RequestBody struct { Username string `json:"username" binding:"required"` DisplayName string `json:"display_name" binding:"required"` Password string `json:"password" binding:"required"` } var body RequestBody if err := c.BindJSON(&amp;body); err != nil { c.AbortWithStatus(400) return } Digging deeper, it seems that [BindJSON returns](https://github.com/gin-gonic/gin/issues/815) a [go-validator.ValidationErrors](https://github.com/go-playground/validator/blob/v8/validator.go#L187) which means you can cast it and then range over each FieldError in the map to get separate fields to report the actual problem. 
Thanks for your assistance. Its fast responses and examples like this is that make the GoLang community such a wonderful thing to be a part of. Sorry I could not gild you as well, but my wallet is only so fat. :(
I am a programmer with Node.js background. I used the similar directory structure from my Node.js projects. - https://github.com/velopert/bitimulate/tree/master/bitimulate-backend/src - https://github.com/velopert/velog/tree/master/velog-backend/src
Ah, don't you worry, glad things are working now :-)
Thank you for your advice. 
I don't like organizing code by layers. 
Rob Pike is one of the designers of Go, and it received input from Brian Kernighan. Perhaps insightful would be this excerpt from their book *The Practice of Programming*, which they wrote before Go. Their taste has influenced what idiomatic Go is: &gt; **Use descriptive names for globals, short names for locals.** Global variables, by definition, can crop up anywhere in a program, so they need names long enough and descriptive enough to remind the reader of their meaning. ‚Ä¶ &gt; &gt; Global functions, classes, and structures should also have descriptive names that suggest their roles in a program. &gt; &gt; By contrast, shorter names suffice for local variables; within a function, `n` may be sufficient, `npoints` is fine, and `numberOfPoints` is overkill. &gt; &gt; Local variables used in conventional ways can have very short names. The use of `i` and `j` for loop indices, `p` and `q` for pointers, and `s` and `t` for strings is so frequent that there is little profit and perhaps some loss in longer names. Compare &gt; &gt; for (the ElementIndex = 0; theElementIndex &lt; numberOfElements; &gt; theElementIndex++) &gt; elementArray[theElementIndex] = theElementIndex; &gt; &gt; to &gt; &gt; for (i = 0; i &lt; nelems; i++) &gt; elem[i] = i; &gt; &gt; Programmers are often encouraged to use long variable names regardless of context. That is a mistake: clarity is often achieved through brevity.
Nice, I didn't expect to get gold for this. Thank you.
Your explanation is way more lucid than mine. Thank you for that!
Your explanation is way more lucid than mine. Thank you for that!
The video have been corrected with the slide and demo.
Video updated!
Sorry, I missed the "where" and thought you asked "are they cached locally". If $GOPATH is set, they'll go in $GOPATH/src/mod/. If $GOPATH is unset I think it defaults to $HOME/src/mod/.
In this documentation likes is likes is a map of a slice. So the append is happening to the value of the map, not the map itself. (ie `likes[l] = append(....` vs `likes = append(...`)
After more reading, it seems [Gin uses the same](https://github.com/gin-gonic/gin/blob/master/binding/form_mapping.go#L92) reflect type-checking as [Gongular](https://github.com/mustafaakin/gongular/blob/master/parser.go#L155) when populating the object (the first step) then assuming that goes well, they both move into validation steps. - Gin uses gopkg.in/go-playground/validator.v8 - Gongular uses github.com/asaskevich/govalidator
I like to try and write as idiomatically as possible but I always err to the immortal wisdom of Zed Shaw: &gt; Do whatever makes you chill out the most. Unless the team you work with has strict guidelines, there is a happy medium between idiomatic and descriptive naming, although I do agree with /u/LukeShu in that local variables can typically be reliably shortened and maintain their significance.
https://www.jetbrains.com/student/
Coming soon: Writing An Operating System In Go
I think its performance would be poor as compared to builder. 
Just a guess, but it sounds like you are hitting your thread limit. Does doing this: func someBenchmark(b *testing.B){ runtime.GOMAXPROCS(runtime.NumCPU() * 2) b.ResetTimer() //your benchmark code here } Or: func someBenchmark(b *testing.B){ b.RunParallel(func(pb *testing.PB) { //your bench }) } before you run your benchmark help? One sets the maximum number of threads. The other allows the benchmark to run with multiple threads executing.
The search term you are looking is "devirtualization". There recently was [a golang-nuts thread](https://groups.google.com/d/topic/golang-nuts/pr0ywVMHlmw/discussion) that might be of interest too. Personally, I'd argue that cases where this is easy don't give huge wins. ISTM it's not very common to assign a concrete value to an interface and then immediately call functions on it. It is far more common that you pass concrete values as interfaces to different functions, which are (usually) compiled separately. But it's definitely on the radar of the Go team as a thing. I guess having some real-world usages where there are significant wins and the analysis is reasonably easy would help push the priority.
Wtf is monkey?
Thanks for this response. I‚Äôm just starting to dabble in Go, in large part because I‚Äôm interested in its performance-to-skill ratio. 
Monkey is the example programming language created in [interpreterbook.com](https://interpreterbook.com).
Don‚Äòt give me any ideas...
GOPATH works just as it always did [https://www.programming-books.io/essential/go/10-gopath-goroot-gobin#gopath](https://www.programming-books.io/essential/go/10-gopath-goroot-gobin#gopath) If you need dependency management then you can pick any tool you like but just stick with [https://github.com/golang/dep](https://github.com/golang/dep) until go modules are officially released, in preview form in next release (\~2-3 months) and in full form in release after that (\~9 months). But really if you're just writing small programs then you don't need to obsess with managing your dependencies. go get is good enough in many cases.
[removed]
It's not devirtualization (although I'm excited about that as well), it's escape analysis. Devirtualization is primarily about dispatch, not allocation. Specifically, I wasn't expecting the following to allocate anything: var i Int var s fmt.Stringer s.String() Instead, I figured `s` would contain a pointer to `i` on the stack. Instead, escape analysis seems to move `i` to the heap unnecessarily.
tl;dr; not worth it. Longer: The Go core developers really messed with proprietary IDEs like Goland because they didn't just write the language spec and a compiler, they also provided from the start tools like gofmt, golint, etc (and the community added others too) that all allow every editor out there (vs code, etc) to have the same, consistent experience. I come from using Scala at work, there, there is no way I would use a text editor like VScode, so use intellij IDEA, but for Go code, VS Code and the normal plugins are all you need and get stuff like go to definition, find usages, run tests, etc. BTW, I'm **really** happy the Go core team thought of developing the tools I mentioned instead of picking one editor they would work on. 
Our benchmarking code is unfortunately still written in Javascript/nodejs. Now I need to decide if it's worth rewriting into Go. hmm...
Almost certainly your code. Start by profiling your code [https://blog.golang.org/profiling-go-programs](https://blog.golang.org/profiling-go-programs) It's unclear to me which part you say is slow. If I read this correctly your Go program does HTTP calls to a server and that server returns slowly. In which case the issue seems to be in the other server, not Go code.
This. Also, if it's really this the problem, there's a reason why circuit breaking and deadlines are important in production-level services.
You can just try adding this to your main function: &gt; runtime.GOMAXPROCS(runtime.NumCPU() * 2) and running the benchmark in nodejs and see if that helps. It could also be something you are doing in the code itself which profiling can help with. 
I've often read the opinion that languages with Pattern Matching should be the first choice for compiler programming, since they'd make the whole process a lot simpler to implement. Any points in which aspects Go would be the right choice when writing a compiler?
[removed]
Mostly the same answer though. For that to work, the compiler would need to know that `s.String()` doesn't modify the value. For that to work, it needs to know what code that is dispatched to. For that to work, it needs to devirtualize. Ironically, the best way not to incur extra allocations when using interfaces, is to use pointer-methods.
What‚Äôs the alternative?
Yes, I agree. Pattern matching takes a lot of verbosity out of writing a compiler (or a parser, for that matter). But the reason why I choose Go is because I think it's a great *teaching language*. I don't want to dive too deep into what I mean by what, because that would be much too long and probably worth a blog post, but the short version is this: Go doesn't hide anything, it doesn't have any "magic", it's equally easy to read for Go programmers as it is for people who've never written Go in their lives. The standard lib contains enough so that we don't have to get into the whole packaging/module circus when trying to learn something. A testing framework is included, which iss super handy, because both of my books are written using TDD. You can write idomatic Go code without using abstractions you don't know from other languages. You have gofmt, which means readers don't have to wrestle with the personal taste of the author. And... Well, let's keep it at that. Yes, there are other languages that are more suited to writing compilers, but I think Go is a fantastic language to teach in.
I went the other way around. I absolutely love Sublime but I found the available Go plugins a bit flakey. I started with GoSublime but it was unmaintained. Then I switched to AnacondaGo, and then back to GoSublime. I still use it for quick editing of Go projects. But I became more productive after switching to Goland for bigger work. Right tool for the job, is all. 
While this may be true, the best language for beginners isn't always the best language for experts. Sure, maybe using a monadic parser combinator may work best for parsing in the real world, but then you have to explain monadic parser combinators. What's nice about languages like Go or Java is that they need minimal introduction and have minimal incidental complexity. Plus, terseness can hide a lot of the underlying mechanisms. By using a more explicit, less "smart" language, the book can be more thorough and clear.
I went through the first book ‚ÄúBuilding an Interpreter in Go‚Äù and loved it. Excited for the follow up!!!!!!
Why is it at r/golang ?
Great article!
Thanks for this. Didn't realize but this makes a lot more sense than buying each IDE if you have to work with multiple languages.
Your problem might be using too much concurrency when calling the WSGI server (and thereby the process running behind it) from which you're pulling data. Here are some questions that might make it easier to help: * What WSGI server are you running, and are you overloading it with concurrent requests? * How long does it take for the payload to be generated by the code the WSGI server is running? * Are all of the clients pulling the same data, or is it client specific? * Are you making 40 calls every second to the WSGI server when using 40 clients? Could you pull data from the WSGI server once every second and send that same data to \*all\* of the clients?
As @kjk said, until the new version of Go will be released officially you don't need to worry about the dependency management more than you have been done when you coded before. Also, the news that you've read I suppose are about the new "Go modules" but this will be an optional tool, and only if you use it the GOPATH will lose his sense, but if you don't want to use it the GOPATH will work as usual, so don't worry for that. However, if you're interested in go modules I recommend you read https://groups.google.com/forum/#!msg/golang-dev/a5PqQuBljF4/61QK4JdtBgAJ
Algebraic data types are not "monadic parser combinator". And writing parsers in Go is a major pain for the sole reason its type system doesn't cover the usecase.
I believe the advantages of pattern matching languages are superficial. Good to show off quick and attarctive AST Node type matching, but much of the grunt work in compilers has nothing to do with this.
&gt; Can anyone provide a quick overview to catch me up So we don't know who you are, what you did or when you did it, but we need to catch you up?
To be fair in this example the long name should have been a variable named 'luke' while the way Go is often written in it would've been ' l '.
Ah, fair point. Ironically indeed. 
I loved the interpreter book, so I was really keen to get the compiler book. As soon as I got the email this morning that it was available, I bought it. I can't wait to dig into it. 
There's a good talk by Rob Pike on writing a tokenizer using goroutines. In the end it's really slow, but the design is interesting (and doesn't rely on the slow goroutines).
I just bought the interpreter book and am excited to read it. What are the new concepts that I would learn from also getting the one on compilers? 
[dupe](https://www.reddit.com/r/golang/comments/93fgjn/beautify_your_golang_project/)
check out this post of golfing project structure [https://www.reddit.com/r/golang/comments/84a1q6/go\_project\_structure\_is/](https://www.reddit.com/r/golang/comments/84a1q6/go_project_structure_is/)
Totally agree. It‚Äôs imperative almost to a fault, which makes it very nice for teaching. 
https://memegenerator.net/img/instances/53807948/dont-mind-if-i-do.jpg
CircleCI uses keys for cache. Is there a a file or something that could be used to determine when the cache should be invalidated?
You mentioned you're using this to build SQL queries in another comment. The string concatenation is probably going to be a tiny fraction of the time it takes for the SQL query to complete. In other words, it will matter little if you're using `strings.Builder`, `fmt.Sprintf()`, or just a regular `+`. In addition, it's always a good idea to actually measure the performance, instead of guessing ("I think its performance ..."). Often times the results can be surprising!
I'd rather have a two-arg overload of new(); e.g: a := new(int, 123) to make these cases more ergonomic.
I saw this one at a book store the other day but wasn‚Äôt sure if it was good for a beginner. I‚Äôll check it out.
It takes a while, but the key thing for me was using "dep init/ensure" to build the vendor packages. After that, autocomplete was as good as GoLand. But definitely agree. I think each to their own on preferences. I code go, c++, python and a mix of other languages in the same day, and having a single ide (even if it isn't specialized) makes a difference -- especially in memorizing key strokes and peculiarities. I have both GoLand and CLion, for example, and if needed will switch to those with no second thought. That said, I have a bunch of colleagues that swear to emacs. To each their own. Lol.
&gt; Why aren't all expressions addressable? Can't the compiler do what a human does when an unaddressable expression is referenced and insert a temporary variable to make it addressable? That would lead to super surprising behavior. e.g. m := make(map[int]int) m[42] = 23 p := &amp;m[42] *p = 1337 fmt.Println(m[42], *p) // 23, 1337 Why would this behave this way?
Usually, with got/want, got is first. Here are some general examples: [src/bytes/reader\_test.go (lines 39-60)](https://github.com/golang/go/blob/fe8a0d12b14108cbe2408b417afcaab722b0727c/src/bytes/reader_test.go#L39-L60) and [https://blog.golang.org/subtests](https://blog.golang.org/subtests) Data-driven tests are optimal for computational units, but can sometimes help with semi-clever behavior testing in functional tests. Subtests are useful for namespacing iterations of data-driven unit tests and subsections of functional tests.
We no-doubt agree to disagree. My context is the code base. I see ZERO benefit in EVER maintaining any in-brain, continuously shifting with context, translation table.
üëçüèª
Agreed: should be able to handle far more than 1 request per second for 40 clients, even with large body payloads, on a $5 RasPi...
Probably the only thing you can't so in go (I await being proved wrong on this).
Does this book build on knowledge from the other book, or is it a standalone book?
What if switch statements were fancier? Boom, new paradigm. 
Any special discount for redditors?
The book specifically states it is not for beginners unfortunately.
That is true, about needing to make sure all the packages are built for good completion to work. I still had trouble with documentation not always populating. As for GoLand, I ended up getting a sublime keymap profile and slightly tweaked that :-)
https://github.com/gokrazy/gokrazy
From the website: &gt;We're picking up right where we left off and write a compiler and a virtual machine for Monkey. &gt; Runnable and tested code front and center, built from the ground up, step by step ‚Äî just like before. &gt; But this time, we're going to define bytecode, compile Monkey and execute it in our very own virtual machine.
It builds on the Monkey language that you create from the first book! That said, you can just download the code for the book and start directly in with this one if that's what you want to do.
That's pretty cool, but still go the Linux Kernel. Maybe someone can write a go compiler for Redox
To expand on that just a little, when Python 3 became mainstream, Google has a ton of Python 2 code that didn't easily convert with tools like 2to3. They had to decide on whether or not they want to move that code base to Python 3 or do something else. This is that something else.
That would be cool. And yeah, it still uses the Linux kernel, so it's not a 100% go OS, but it's reasonably close.
The test template from the VS Code plug-in does most of these automatically. üéâ You can mark functions that get passed testing,t as helper functions, using the T.Helper() function. They will remove the stack of the helper function, ending the stack in your test. Super nice feature.
I've not tested any of these suggestions, but they are some things that I noticed: You need to do a make() on the channel to actually create it. Just declaring it in the global context isn't enough. That should take care of your second issue. c = make(chan string, 1) As for your first issue, you are saying that sendReminder() is being called twice per message. Have you verified that is the case and it's not a problem with getting multiple messages from the API? Do you have some log output from your program that we could see? Use the "log" package to do some useful logging or use a third-party package like [logrus](https://github.com/sirupsen/logrus). Also, in your for loop at line 48, you are checking if channelrecv == channelCount, however, you have two problems with this: * channelrecv is never incremented anywhere * The very first loop here should result in the program exiting nearly immediately because they are both equal to 0 on program start and since no event has been received by the bot, it should always evaluate to true and break the for loop. You're wg.Wait is probably the only thing keeping the program running.
These comments make sense if we are looking at this code in solitude. However it tool me 5 minutes to write a fluent builder which can be used throughout my organization. Even though it is not a bottle neck, I think 5 minutes we're well spent, given the reusability of it.
I had fun [extending the language](https://github.com/skx/monkey/) in various ways, and I've also dabbled in a [simple virtual machine](https://github.com/skx/go.vm/) so this should be a good follow-up read.
Does this book assume knowledge of Go, or can it be used to learn Go along the way ?
It does assume prior knowledge of Go, yes, meaning that I don't explain how to setup and use Go and that I also don't explain Go language construct. That being said, the required level of Go expertise is low. We only use core language features, barely something out of the standard library, no concurrency. With a huge disclaimer of this-comes-without-any-guarantees: I think if you worked through [tour.golang.org](https://tour.golang.org) and read through the "Getting Started" and "Effective Go" documents on [golang.org](https://golang.org) and have prior knowledge in other programming languages, you should be fine. Lots of other people have read the book without programming Go before and by all accounts, that worked fine. Some even translated the code into their favorite language while following along.
https://github.com/achilleasa/gopher-os
I really do recommend starting with the first one. Not because I want to sell more books, but because I don‚Äòt want anyone to get lost in the second one. These books are about building things from the ground up, without any 3rd party libs, without any magic or black boxes. So while it is definitely possible to start with the second one and treat the parts from the first one as given (the lexer, parser, AST, REPL), I personally think that it goes against the grain of what I wrote and thus might not be the best experience. Hope that makes sense!
&gt; Use want and got `want` and `have` share the same number of characters, which makes some alignment things nicer. I prefer them for that reason.
Ops... thanks :)
Your example makes sense to me, though. Consider how &amp;myLRUCache.Get(123) and &amp;&lt;-myChan are similar to map elements, and why it also doesn‚Äôt make sense to use an address within the data structure in those cases. Should the special casing of slices, arrays, and structs really preclude doing something useful in the general case? We could still achieve the same thing for those types with &amp;(mySlice[123]).
Why is that more ergonomic? What if the expression spans multiple lines?
&gt; Your example makes sense to me, though. I don't understand how. Or at least how you can disagree that someone learning the language would find it majorly screwed up. `&amp;` is the address-of operator. You're telling me it's fine that `&amp;` doesn't actually take the address of what you apply it to? That you take an address of a thing and then, when you modify what's pointed at, that thing doesn't actually change? Or that it's fine that `&amp;expr` might allocate new memory on every call? And that `&amp;expr == &amp;expr` returns false? None of this makes any sense. That's just not how pointers are supposed to work. &gt; Consider how &amp;myLRUCache.Get(123) and &amp;&lt;-myChan are similar to map elements, and why it also doesn‚Äôt make sense to use an address within the data structure in those cases. Yes, but that's exactly *why* these things are not addressable. They are not addressable, because you can't actually safely get a pointer into them. The term "addressable" isn't just a random, made-up term. It means "something you can get the address of". &gt; Should the special casing of slices, arrays, and structs really preclude doing something useful in the general case? What you are suggesting is to overload `&amp;expr` to *sometimes* mean "take the address of expr" and *sometimes* mean "allocate a new value and initialize it to expr". They are very different operations, why would you use the same operator for them¬π? Note, that it's not really about enabling things you can't already do. There is no code this would enable you to write that you can't already get with a simple `tmp := expr; x = &amp;tmp`. So I don't quite buy the "doing something useful in the general case" argument. You are introducing a lot of confusing situations to get a tiny bit of convenience. --- BTW, all of this is only concerned with one occasion where addressability is used. There are more. Another implication of "making every expression addressable", is that this code would reasonably have to type-check: var b bytes.Buffer fmt.Fprintln(b, "Hello world") io.Copy(os.Stdout, b) // Doesn't write anything Another way to look at this, is that it makes pointers pretty much obsolete altogether. In a way, Go would behave like python - some things are references, some things are values, but there is no real lexical or programmatic distinction between the two. I don't like that; Go is supposed to give you control over memory layout. --- [1] You could make the argument that we're already doing that by special-casing `&amp;` for struct-literals. Which is fair - in fact, I'd argue that it was probably a mistake to do that special casing. Though it works fine in practice. Doesn't mean it's a mistake we have to replicate to more cases.
I should add that, if you're proposal would be "make any literal addressable" (i.e. extend the special-casing of struct-literals to more value literals), I'd be less opposed. It's also something that has been proposed before. I'm pretty sure that it's on the Go team's radar to simplify things when you want that, though they might not do it *exactly* like you are proposing.
Hey, im from a node background as well I would suggest a more "component/library" based layout for go projects and probably any project going forward This is the style suggested by go them selfs and all the standard libraries comply to this kind of standard [https://www.youtube.com/watch?v=spKM5CyBwJA](https://www.youtube.com/watch?v=spKM5CyBwJA) (supporting blog)[https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html](https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html)
Introducing Go from O‚Äôreilly.
WTF is that? Run a freaking _documentation server_ **as root?** The way to do that is merely: 1. Create a per-user service: $ mkdir -p ~/.config/systemd/user $ cat &gt;$_/godoc.service [Unit] Description=The Go documentation server [Service] Type=simple ExecStart=%h/devel/go/bin/godoc -http [::1]:6060 [Install] WantedBy=default.target ^D $ systemctl --user daemon-reload 1. Run it: $ systemctl --user start godoc 1. Make sure it's up: $ systemctl --user status -l godoc 
Please use our issue tracker to report issues instead of reddit as I cannot ask you to publish your logs and performance snapshots of the IDE here. Even if you are in the trial period, we'll do our best to figure out what's happening. The issue tracker is here https://youtrack.jetbrains.com/issues/Go We never ask you to disable completion (not that it's possible to do it anyway) nor can you turn off document parsing or anything else you described. I'm sorry that your experience is not good, but I can assure you that your machine configuration is more than enough to run the IDE on some huge GOPATH/projects. Thank you.
I was talking on forums here and there, but you're right that I did not submit a ticket about it. So to be helpful, I submitted one with all the details I could gather. https://youtrack.jetbrains.com/issue/GO-6023 Have fun. :) I did pay for my version though. :)
Thanks for the detailed report on this, let's see what my colleagues can do about it.
[removed]
This looks promising. I think I‚Äôll buy this one. Thank you.
Tangential to the original post, I would just like to say, that this post and the comments, is a great example of the go community. My team is about to start building a new product, I know go, but the rest currently don‚Äôt, but I‚Äôm planning to move our current development from Kotlin and Spring boot to go. - the community is one of the reasons. üëç
I don‚Äôt think I understand. Where are the context values flowing from and to? Why don‚Äôt you have access to the request?
You may have to split it up as a return in the function. example: [https://joeshaw.org/revisiting-context-and-http-handler-for-go-17/](https://joeshaw.org/revisiting-context-and-http-handler-for-go-17/) This was a good talk on it. [https://vimeo.com/115309491](https://vimeo.com/115309491) If you need more context. [https://blog.golang.org/context](https://blog.golang.org/context) [https://golang.org/pkg/context/#TODO](https://golang.org/pkg/context/#TODO)
I am currently working on a simple HTTP proxy. I have 'on' events to catch responses and alter them. However, as I am piping a big file consisting of several GBs, I've wanted to flush the response in chunks. Since the entry point is ServerHTTP method, I want to be able to both perform an io.Copy for small payloads (because this blocks until the src is fully read into dst) and 'flushing' that will flush the payload as it's read in chunks.
Write your own ResponseWriter implementation and add middleware that injects it in at the first layer of routing. In your implementation you can add buffers and flushes as you like. Check https://godoc.org/net/http/httptest#ResponseRecorder for an example implementation. 
I am struggling with this idea too, I am new to Go and trying to do everything "right", but I don't understand why super short variable names are easier to grasp than a more descriptive one. You can use it sometimes, when they aren't that important on a business rule perspective, but using it as a rule seems to me as just following a trend. And yeah, I know Rob Pike's opinion about it.
Erlang doesn't have useful one.
You know, you can just ignore things that you objectionable, rather than post something inflamatory?
Anything that ties up a port I tend to want tied to root
&gt; I've wanted to flush the response in chunks to avoid blocking caused by io.Copy... I want to be able to both perform an io.Copy for small payloads/or in demand (because this blocks until the src is fully read into dst) io.Copy does not buffer, or at least not at that scale. You can [look at the code](http://127.0.0.1:9000/src/io/io.go?s=12621:12681#L378). io.Copy, if it can't use one of the zero-copy implementations and the special-case LimitedReader case doesn't apply, uses a 32KB buffer, and the semantics of io.Reader is that if only one byte is currently available, even if your buffer is larger than that it will return that one byte and tell you there's only one byte, so even if there is only one byte available it will immediately copy. Plus, one of my main projects for the last few months has been a system that uses io.Copy to forward both HTTP bodies and shell sessions. The latter in particular we'd notice if io.Copy was buffering, because it would destroy the usability of the shell. We were just so happening to look at the Docker TCP proxy implementation yesterday too, [which uses io.Copy at its core](https://github.com/docker/libnetwork/blob/master/cmd/proxy/tcp_proxy.go#L43). I have a question; is there somewhere you read that io.Copy buffers? I'm curious because this is the third time I've seen this claim in the last three months now and I'm wondering if there's some misinformation that needs to be fixed somewhere.
"Yes is forever" resonated with me hard. It took me many projects before I started to get a feel for properly selecting and planning feature requests. When you're slapping a keyboard late at night supporting a feature you don't even think anyone's using (or ought to be) it's painful enough to thicken your skin the next time a feature comes up. Also thanks for gore leaser, it's an awesome tool!
Sorry for the late comment... even I'm on the same page....heavily thinking between nats(with proto) or grpc for req-reply pattern in a microservice architecture.... i can see that NATS will probably be more performant - but the grpc ecosystem is also crazy - for example, service meshes like istio and linkerd can do a lot of stuff without any changes to code - the one feature which is very valid is canary deployments. With NATS, one can do rolling upates easily, but how to do canary deployments (without code changes if possible) is a pressing question... this can be done easily with grpc and a service mesh
I am not. In fact I love vim. Emacs though not so much. :-D I know vim-go. Been using it until vscode came around. :-)
We are building some internal tooling that have no business being a spa app. Ive realized through this process a bunch of engineers don't even know how to build an app like that anymore. So here you go. This is how you build an interactive go application without javascript.
I guess it's a matter of personal experience
&gt; gore leaser Not sure if intentional but I lol‚Äôd. 
On the other hand, IntelliJ IDEA understands Go HTML templates, and will index your CSS and autocomplete element classes, for example. And if your project involves a database, the SQL tools are excellent. VS Code is great, but even so I decided it was worth upgrading to IDEA (with the Go plug in that makes it equivalent to Goland).
Great write-up, Carlos. This was very well thought-out and well written. There is a lot of really practical advice and valuable knowledge wrapped up in here. +1
Yep I do. But it was also doing this with the retina display. :-/
Probably. I told my team to go build a app without javascript and they had no idea how to move forward.
[https://i.kym-cdn.com/photos/images/newsfeed/001/393/665/483.jpg](https://i.kym-cdn.com/photos/images/newsfeed/001/393/665/483.jpg)
Muito bom, Carlos
My team has just had this reminder as well. We have started to discuss that ‚Äúmaybe all of our apps don‚Äôt need to be React, people.‚Äù It‚Äôs honestly been refreshing. I quite enjoyed the conversion of one of our apps to just Go templating. 
Awesome article.
Change the gg declaration like this : func gg(f func() error) error { return f() }
If they're all golang, then just use go routines. Watch out though, because your app might exit before all the children are finished, so look at sync.waitgroup too.
Don't think about go for devops as being about being able to complete tasks. Tasks implies a descreet job you can do, and once it's done you can either throw it away or save it again for the next time you do that task. Go for devops is more about creating services and APIs (as you have already done) which make your life easier. For instance, have a look in to the hashicorp tools Terraform and Vault. These are both written in go, and they provide a suite of functionality to make your life easy. Vault is more your traditional service, and Terraform is more descreet, though it's extremely pluggable making it completely essential in the devops tool chain. Docker as well is a great service written in go, which should give you an idea of how it can be used for devops (though I don't suggest you try to write an application of that magnitude)
Use supervisord or a cron. If you just want to run a bunch of long running programs or rerunning on a schedule, you don't need a special server. 
Not OP but I like to organize my project mostly by dependency, like this: [Standard Package Layout](https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1?source=linkShare-2614aef8e201-1533152648). 
That's just bad practice, at least let `godoc` listen only on localhost (e.g. `godoc -http 127.0.0.1:1234` or `godoc -http [::1]:1234`). Using `godoc -http :1234` binds the service to *any* interface/IP address, which makes you vulnerable to network attacks. You may argue, that you're alone in your current network, or that you have complete trust in any other host on the same net. But this only applies for now (because tomorrow your collegue/family member/flat mate/smartwatch catches a trojan), and since you've installed it as a non-vital service, the point in time *will* come where you forget to have this service running. How often do you check for updates? How often do you actually update `godoc`? Best practice dictates to run services with the least privileges possible, so that, should a vulnerability become exploitable, an attacker can do the least amount of damage. Also, side note: Why do you need to restart `godoc` upon code change? For me it works without restarting `godoc`, see here: https://imgur.com/r0YYVI5
Even more mind blowing is when I tell people you don't need Redux and 300 NPM dependencies to build a simple UI with react either. They always look at me with a puzzled look.
the only downside is that the current logo would not be good enough for a black metal band haha
Docker, Kubernetes, Terraform and many more tools are written in Go. For me, the most useful properties of Go are the simple deployment (one static binary) and cross compilation. But Python is certainly as useful as Go.
Throw some blood tears on the gopher and sharpen its teeth. 
Thank god. This is one step closer to a easy to use and modern packaging manager. 
Ah, good question. The answer is because I'm calling a function I don't have control over. In reality my code looks like: func Baz(...) (...) { vals := package.Func(...) m2(vals) .... } In this case, `package.Func(...)` returns `[]A`, so that's what I'm trying to process. I've tried fiddling around and doing something like declaring `var vals []b` before the assignment, but it doesn't like that either.
those template files look so confusing. i assume they were generated by that template package. i did something similar to this. [here it is](https://github.com/v36372/dienlanhphongvan). But end of the day, i have to rely on some javascript chunk to add reponsiveness. The most fun part when working on it was the templating, partials, etc. nice work! 
I watched a good talk on vgo today actually and it was the reason I went ahead and invested into goland. I'm ready to give go another shot :) https://www.youtube.com/watch?v=F8nrpe0XWRg
This is only because in Go you can't auto convert slice of type A to slice of type B, even if you can auto convert type A to type B. If `pkg.F()`'s return type is `[]A`, your best bet might be just write a helper function to convert `[]A` to `[]MyA`, something like https://play.golang.com/p/0IolgpSGj7B
Ah, ok. Well that at least explains my confusion. Unfortunate! So I suppose the best way really is my little loop (or your helper function). Thanks!
Less than ten years have passed, haven't?..
Excellent! I love good Lessons Learn writeups! I would love to see some more in-depth write up about \`artifact\` type and what design problems it solved for you and good practices for noobs like me :).
See [this FAQ entry](https://golang.org/doc/faq#convert_slice_of_interface). It talks about `interface{}` vs. concrete types, but the same applies for different interfaces. &gt; But that seems... bad. Inefficient at the least. Yes, it's inefficient, which is why the compiler doesn't do it implicitly for you :) That would hide that inefficiency from you. `A` and `b` have a different memory layout, so you can't just convert them blindly, but have to convert every value individually - which is the loop you wrote. If Go would allow doing it, it would *still* have to write the same loop. There is also a more fundamental issue with doing that, because it is unclear whether `[]A` should be assignable to `[]b` or the other way around. i.e. it is *fundamentally* not possible to do what you want in a type-safe matter. I recently wrote [this long-form explanation of why](https://blog.merovius.de/2018/06/03/why-doesnt-go-have-variance-in.html).
I'm really glad they went with vgo instead of dep, dep is too smart (or dumb) for its own good.
I understand your point about different memory layouts (which I didn't originally realize, but suppose I should have), and that it'd be hiding an inefficiency, but: &gt; There is also a more fundamental issue with doing that, because it is unclear whether []A should be assignable to []b or the other way around. i.e. it is fundamentally not possible to do what you want in a type-safe matter. Why so? In this case, every `A` can clearly be used as a `b`, given that the method requirements of `b` are a strict subset of `A`. Since that's true, shouldn't it be type-safe to treat `[]A` as a `[]b`? I must be missing something...
well, godoc is managed by DNF and I run update pretty much any time there's a new package, so within ~24 hours. My wife is more technical than I am, odds of her introducing malware are basically zero...and even if that weren't true, I run a pretty restrictive UFW. None of this concerns me even a little bit. It's a how-to article I wrote in like ten minutes...I think you should consider the possibility that you're taking this way too seriously.
hey, I'm needing this right now, any progress on it? was the code published? I'd rather use your library than creating a new one
&gt;d for you and good practices for noobs like me :). hmmm, good to know... I didn't want to enter in much detail because I thought it would be too much to read... I can do another post on only that subject though :D Anyway, the PR link may help to understand why it was bad before... maybe I can add an example of how bad it was before on the post as well :P Thanks for the feedback!
Ah, hadn't thought about that. I hadn't considered that slices are effectively just pointers to a section of memory. Thanks! Appreciate it.
This is only true for types, but not interfaces. A and b do not have different layouts. They are both stored as a pair (type, value). You can actually convert them blindly as long as you know that the type in question implements both A and b. Compiler actually could (and should) do this for you.
This is correct. It should be noted this is specifically for arrays. A bit more detail: [https://en.wikipedia.org/wiki/Covariance\_and\_contravariance\_(computer\_science)#Arrays](https://en.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science)#Arrays)
Yes, I wanted deep to work, but I had as much trouble with it as it solved. Go modules have been painless; they just work, without fussing. With dep it seemed that I couldn't pick up a project and develop without first spending hours fixing dependencies.
&gt; One benefit of having a single organization we do our work in, is that it makes it easier to manage access for people to commit to the projects. Managing access is a non-issue if you only grant access to the team members with the knowledge and qualifications to maintain any given repo. &gt; If we want to have some tooling or CI change take effect across multiple repos, it's easier within a single organization. Why is it easier? 
The results: https://blog.m4dfry.space/posts/go-wasm-benchmark/
&gt; (Stand-alone distributed module repositories, such as [Project Athens](https://github.com/gomods/athens), are in the works.) Way to bury the lede, holy crap!
I just wanted to point out, that table driven tests are especially helpful for pure functions, meaning the return values are always the same for a specific set of input values, without any side effects. Maybe this was implied or already known, I just wanted to point it out.
So, I use screens and run the go files using infinite while/for loop? 
They are actually same script with different params being passed. 
Do not think of Go programs as "scripts" or "files". Once compiled, they are stand-alone binaries, responsible on their own for whatever they are meant to do (including infinite looping). The require no pre-installed virtual machine, no "Go server" or other Go-specific helpers at runtime. Just pick a general scheduler of your choice - as /u/justinisrael pointed out, supervisord or good old crond are probably a good choice. systemd also comes to mind.
I guess this attitude comes with experience. Way too often I have seen users (professionals, at that) screwing up their and others systems, running outdated software with too much privileges - because it was easier to setup. If you feel comfortable running `godoc` as root‚Äîfine. But distributing this as public advice to anyone (including novices who have no idea about the security implications) is grossly negligent. They might get the idea to do the same with other or their services, and *don't* run a firewall...
That's perfect for a go routine then, and you can simply modify your current program.
No, it is true for interfaces too. The code actually has to dereference `value` and the tables it's pointing to will be different, based on what interface it is. You can imagine the types working like type A struct { t *itabA v unsafe.Pointer } type itabA struct { t *commonType Foo func(unsafe.Pointer) string Bar func(unsafe.Pointer) int // ... } type b struct { t *itabb v unsafe.Pointer } type itabb struct { t *commonType Foo func(unsafe.Pointer) string } func foo(a A) { fmt.Println(a.Foo()) // rewritten as a.t.Foo(&amp;a) fmt.Println(a.Bar()) // rewritten as a.t.Bar(&amp;a) } So, while you *could* order the itabs so that subset-interfaces work (by having the common methods at the beginning), this would break down as soon as you add `type c interface { Bar() }` to the mix . So, in the end, yes, different interfaces have different memory layouts.
&gt; This is only because in Go you can't auto convert slice of type A to slice of type B, even if you can auto convert type A to type B. That's not Go specific though. You can't do that in any language, unless that language a) doesn't allow modifications of arrays/lists/‚Ä¶ or b) is not type-safe.
I'm a bit worried about that `go get .../cmd/foo` works differently inside module repos than outside it. I feel not a lot of thought has gone into that fairly common command, when it comes to modules. Personally when I go get a tool I would expect to install it as part of my toolset, not add a dependency to my current project, but some texts I've seen indicate some people think adding the dependency is correct. Probably go get gas to be split in two here or given a flag to force the behavior if they really want to support both effects. Other than that I like modules a lot. We've used it for a few weeks now and it's much easier to work with than dep. I especially was never fond of the vendor directory, even if I understand why it came about. 
Thank god. I wish they‚Äôd add a script runner too
It‚Äôs nice to have development tools versioned with the project. They could always add a global flag to force installing into gopath
yes, the HENP community - and probably communities from other physics or science fields - needs more CS literacy. I was rather pleasantly surprised by how quickly the LHC experiments adopted `git` and GitLab, after decades of RCS/CVS and a brief (&lt;10 years) stint with SVN. IN HENP, the need for more education wrt CS is something that is recognized and addressed with a couple of hands-on workshops or computing schools, targeted at PhDs, post-docs or, really, anyone who feels like it. This trend started with the realization that we needed to refit our software stack with the advent of multi-core machines. Of course, I'd argue that while teaching parallel programming and concurrency concepts for C++2x is a laudable endeavor, teaching the same concepts with Go would be just easier and less painful :)
Looks nice, just by a glance I like it more than gorbac.
Oh, whoa. My mental model of how all of this worked must be totally wrong then. Thanks for the info.
Ah right; that makes sense. Not sure if it's worth changing it now, I don't find the single character difference that much of a hassle.
&gt; Usually, with got/want, got is first. Why does this matter?
It will loop forever if `z` always is greater than `1e-15`.
Z is set to sqrt(2) forever thus the break statement never gets executed.
Actually a very nice presentation. But what worries me is the relation done between 'a new release' -&gt; 'a broker release'. This scenario really happens in real world, were a broken release of a library can break the users of this library, but most to of the time the new version is already fixing bugs in the code. With the current proposal new users will still use the old library, and so including already fixed bugs in the new code, that IMHO makes the vgo approach a very dangerous one.
It's not only pattern matching, it's sum types and especially parametrically polymorphic recursive data types that allow for some really nice development of compilers.
The first example works because s changes. It stops because eventually z and s becomes close enough. After you changed it, z changes in the same way, however, with s is set to 0 and keeps at 0, it can never brak the loop.
But how to version development tools written in Go? Mind the gap
I get it now thank you.
Finally. Now they just need to add generics and Go will be a viable language to use at my workplace.
go modules system is simply brilliant, congratulations go team! thank you for not taking the "complicate it until you can't explain it" approach. 
With other systems it's exactly the same when in real world you'll use a lock file. In production you never want to build a randomly best combination of dependencies like when you use Dep without lock file. In dev of course you upgrade to newer version like with others systems, you test it and record/lock the minimal versions, the versions that you actually tested. I don't see where is so much difference...
&gt; Right, is again the same point: fixing the problem of 'what if the new version of the library is broken'. Maybe I'm misunderstanding you, but if a new version of a library gets released nothing in your application would break even if the new version is broken. Back to my A-B-C example. You control A and need B 1.4. B relies on C 1.4, Developers who made B release a patch and push B 1.5 and it's broken, your application will not use 1.5 because your application only needs the minimum version of 1.4 which isn't broken and it'll sit with B 1.4 and all its dependencies at the time for that version. What if dev updates C to 1.5 and C 1.5 is broken, your app still only relies on C 1.4 because B only needs 1.4. At this point your application should be running, now if you introduce another library D 1.2 which relies on B 1.5 and you compile then yes vgo will error out at that moment because now you introduced a library that relies on a broken version and B 1.5 will be the new minimum version of B your application needs to run. At this point your feature that uses library D 1.2 that requires B 1.5 isn't complete (on another branch most likely) and you can't use it which in then you report the conflict issue and either revert to an older version of D that uses an older version of B or not add that feature, but never at any point should your application break until _you_ introduce a new library or change the dependencies for A. Which then gives you enough time to revert changes before they become a problem so you can figure out a solution w/ library owners to send a patch. Hopefully I didn't misread you, but that's pretty much what I got from that vgo talk. You really have to take steps on a surface level of your application in order for it to break at the library level because of how minimum versioning works with vgo.
&gt; A secure, blazing-fast, cross-platform WebAssembly VM in Go. Life.. uh... finds a way.
&gt; Maybe I'm misunderstanding you, but if a new version of a library gets released nothing in your application would break even if the new version is broken. I get this point. I understand that a the new broken version of B or C will not break A, as the oldest compatible version is always selected. That is what is explained in the video (that I liked). My point is just the contrary: what if the new version of B and C are not broken. In this case they are not updated in new compilations of A, or in new code that use the same version of B. I am worried about this second case: most of the time new versions of B and C will bring new fixes that can be recommended, or even required.
You are right that in production you do not want random combinations of dependencies. And this is something that vgo is fixing very elegantly. But I am not sure that during the development you have the same freedom that with other systems that use a lock file, where you can select the versions of direct dependencies (like B in the previous example), or the ones not under direct control (like C). New code that requires the same version of B will drag the oldest version of C with vgo, but in other languages you will have the latest one for B and C (direct dependencies and indirect ones). So I see a big difference between vgo and other systems. If I understand vgo correctly, you have full control of direct dependencies: ``` require ( github.com/kardianos/vtest/v2 v2.0.2 ) ``` but not over deep dependencies, as they are not directly required by your code. With Python PIP, Java Maven or Rust Cargo locks I can influence in my dependency graph, and force updates of packages at any level. I am not sure that this can be done in vgo, as there is not an external metadata to store this information like in the other three solutions. My intuition tells me is that in the long run this can be a problem, as you are delaying (in production and in development) a minor upgrade that can be critical. I am sorry if I am misunderstanding something about vgo.
Perhaps have all the goroutines write their response from the github api into a channel?
Hmm can you use something [sync.WaitGroup](https://golang.org/pkg/sync/#WaitGroup) to count all goroutines and block until all have finished executing? So something like func main() { var wg sync.WaitGroup wg.Add(1) go func() { // goroutine code wg.Done() }() wg.Wait() // blocks until wait group counter is down to zero fmt.Println("All goroutines done!") }
&gt; https://www.programming-books.io/essential/go/ So far, the best book i've come across, straight to the point! No "bullshit" and explains everything in a few lines!
implied, but I should probably clarify that.. Thanks for the feedback :)
I am not 100% certain on what you want to archive. Receiving the error is easy either have a separate error channel or wrap the result in a struct together with the error. To cancel goroutines it is common to have a 'done' channel of a zero type like `struct{}`. You close it from the main routine and check in the subroutines (closed channels yield the zero value immediately). What you should also look into is Context from the context package (https://golang.org/pkg/context). It offers cancellation and timeouts but is better suited for more complex tasks with nested levels of goroutines like in servers.
Or just use waiting group
I suggest to use [WaitgGroup](https://golang.org/pkg/sync/#WaitGroup) to achieve this. 
Ever heard of processes? Just execute the binaries in the background. In any Unix shell you would do: (related commands: bg, fg, jobs, kill, pid) $ ./goprogram1 &amp; $ ./goprogram2 &amp; Or execute them in different shells.
I agree completely. On the other hand, `if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...} if err != nil {...}` 
Then you'll have to go through the same workflow as with a lock file - update the dependencies. Imho it doesn't matter if you're pinning a specific version in a lock file and a range (which is also mostly just the lowest possible version) in a dependencies file, or if you only define the lowest possible version in a single file. When you update your dependencies you'll have to touch at least one file, for dependencies at least one as well. The approach to take the oldest possible dependency also fixes problems with dependencies defined too loosely in deep dependencies - instead of a deep dependency suddenly breaking because a new version of its dependency was broken you have a consistent state of all dependency (deep or no). With dep (and pip) I've had the workflow to run my tests before updating, then updating all direct dependencies and create the lock file, then run all tests again. If nothing breaks I'm good. With go modules I can just run the tests, update the mod file, then run the tests again. (I'm excluding vetting the changes and changelogs now for brevity). So all in all - its the same workflow with less clutter.
When web-devs go crazy! Why would you use this if Go compiles to any architecture imaginable naively?
For example to dynamically execute logic that can be supplied by the user and is written in its favorite language. That's what comes to my mind after seeing what Life can do
I imagine security. Do you want to run arbitrary binaries from people? Depending on how sandboxes and exposing permissions is done, WASM can mean a lot more than just your favorite language on the web. See [Ryan's talk](https://www.youtube.com/watch?v=M3BM9TB-8yA) for a similar idea but for Deno _(not WASM)_.
Thank you for the corrections. By the way [here](https://stackoverflow.com/q/51639548/720999) someone just recently experienced a problem with accessing the TLS block from Go, and exactly hit the problem of &gt;&gt; the goroutine struct, which itself can always be found at address FS:0xfffffff8. &gt; &gt; The actual address where the goroutine struct is located varies depending on the version of go, use of cgo, architecture and operating system.
I did this for the JVM, hit me up if I can help you with confusion on the test suite, some things like post-unreachable stack logic can be tough. Also, I assume this is an interpreter? Have you given any thought to compiling direct to Go as well?
I thought Go only compiles to a handful of architectures? Does gccgo allow compilation to others?
Feedback welcome
FYI deno is no longer written in Go
`errgroup.Group` is quite good for this kind of thing as well.
This is awesome, I was looking for ways to extend go with JavaScript (I know, but sometimes you just want to be dirty and have in just) this may be my key.
That wasn't my point at all - Deno's security model is targeted at a mobile phone -like permission based system. Sandboxed, with explicit allowances for various system access like filesystem, network, etc. WASM could potentially be the same, though I'm not sure offhand what the model is currently. These technologies and sandbox concepts are much bigger than Go explicitly. They're a very meaningful step. To be able to import libraries and not have it erase your hard drive or run crypto mining on your computer would be, you know, nice.
Since you're trying to support libraries that are almost the natural progression of what the stdlib would cover, I would've gone for the name "understd" pronounced as "understood" but maybe that's just me 
&gt; Also you can use builtin SaveJSON function to save to a file: You almost never want to provide an API that manipulates files. You should only accept an io.Reader or an io.Writer. And for JSON encoding, it's more likely you just want to document that certain structures can be safely serialized with the default JSON encoder, as you do, and provide no code support for it whatsoever. There's too many ways in which what the user wants could differ from what you assume, the largest one being that I probably don't want to write these to files anyhow, I probably want them in a database. It isn't even _that_ convenient to provide a function that saves to a file, because you have so many assumptions written into that function that are likely to be wrong (permissions on the file, for instance).
Ah, I see it is a WebASM-VM in Go not a Go-VM in WebASM.
There is a switch in the toolchain but I can't remember it's name. It allows no module, force module and auto detect module.
so you dont have a microservice for logging? you connect to fluentd on all microservices?
You don't need to use a type assertion, a cast should be just fine.
smh
Wow, is this a new era of browser wars ? Browser runtimes are already competing to improve wasm performance and now non-browser runtimes are coming out too. Amazing !
&gt; but we're also working on a few experimental JIT backends, with direct x86-64/ARM code generation most likely to be the final solution. I think it'd be neat if it compiled to Go code AOT, then if you want a JIT, just carry the Go compiler around (statically compiled of course, I don't mean the distribution). There are a lot of benefits to doing this as opposed to targetting specific arch's with a homemade JIT. Also, even though Cgo is limited, WASM only takes/returns numerics which Cgo supports, so you can even c-shared that thing and export the WASM func exports w/ a C ABI. But I guess if you have to use a made-for-JIT lib, you can use existing ones like [Cranelift](https://github.com/CraneStation/cranelift) (nee Cretonne) over Cgo or just use the [one already done](https://github.com/sunfishcode/wasmtime) granted it would obviate the need for this project.
Ueah, we also use this approach and it's working nicely. We send logs to mongodb, errors to sentry and derive metrics to feed prometheus (errors, requests count...)
This seemed to be a pretty level-headed look at things. 
Here's another option that handles your use case. We use this hundreds of millions of times per day. https://github.com/nozzle/throttler
We're looking for collaborator for our websocket abstraction library [github.com/qbeon/webwire-go](https://github.com/qbeon/webwire-go) We open-sourced it because we believe that WebWire can be very useful for building modern high-performance real time (web) applications enabling low-latency communication with only little overhead and an easy to use, intuitive API for both Go and JavaScript. If there‚Äôs anyone out there willing to help us and get his/her name engraved into it, please don‚Äôt hesitate to contact me via [roman.sharkov@qbeon.com](mailto:roman.sharkov@qbeon.com) or @romshark in [https://gophers.slack.com/](https://gophers.slack.com/)! 
This project is cool and props to you for making it work. Out of curiosity, what deficiencies did CarPlay and Android Auto have that led you to going down this route?
&gt; Go is probably the most opinionated language I‚Äôve ever used. Yes! And this is completely intentional, and for good reasons. The strong opinions that Go's design is based make Go an ideal language for teams - everyone knows what to expect. 
Using both on a daily basis, I frequently oscillate between which I prefer more but in all honesty, they do nearly completely different things for what we use them for. Go is our primary MSA/Serverless language, if it needs to be small, safe and well tested, Go is the tool. When it comes to larger projects, especially maintaining monoliths, we typically go Python because some things are easier to think about in terms of Objects. There are things I dislike about both and things I quite like about both, glad that they are well supported and documented. Now if I could get my team to start using Elixir...
Yeah I never know when to stop with documentation, so I know where you're coming from there.
I'd rather work with an opinionated language than opinionated developers.
The same reason any style guide matters. More so since this convention, or "expectation", is established in the standard library.
The standard `tt` variable name for the test case makes it easier to copy code, and means I won't have guess what the variable name is (saving time and effort). I'm not so sure what the concrete advantage is of defining a standard got/want order? I can't think of any, but perhaps I'm missing something? Establishing style guides for the sake of it seems a pointless to me, if it doesn't add a concrete advantage.
Yeah, I agree. It isn't that tons of time is wasted, but that you sit down to do something and, off the bat, you encounter a distracting speed bump. Something which you *left* working suddenly doesn't work any more when you return to it. Less commonly, but more time consuming and far more annoying, is that dependencies of dependencies can force you to have to rewrite your code just because you use the same library as one of your dependencies; and that conflict can be hidden and unknown to you until you encounter a version conflict, and then you have to waste a bunch of time upgrading *your* code to use a new version of a library that you otherwise don't want to upgrade. The more I think about it, the more I realize that this situation is what made me actually start to hate dep's algorithm just a little. I think it's pretty strong evidence that dep's approach is wrong. Plus, I have always disliked the `vendor/` directory, even before dep. It made using your own shared libraries a bit of a PITA, and I found having several complete copies of commonly used libraries (your favorite flags library, for example) somehow distasteful and spendthrift. I've become quite fond of modules and Russ' theories. Maybe it'll all come crashing down and a fundamental flaw will be exposed, but so far it's only made my life easier, and dependencies are no longer a source of frustration, or a roadblock.
It is probably easier to use a multidimensional slice. If you really care about cache locality create an appropriate long array then slice it. You still have an indirection over the slice header but it's way more convenient this way. If you know you only need one size just use a multidimensional array. If you have a huge array pass it around as pointer.
&gt;Now if I could get my team to start using Elixir... Could you briefly elaborate on what merits you see with Elixir? Honestly interested, don't know much about it except it being a functional language on top of the Erlang VM and am always keen on trying new languages.
I'm sorry for not having been more clear. I thought my usage of the term "expectation" would make my point more obvious. The advantage to meeting expectations, in this case, is that parsing of failed tests is eased. Having to look at whether the left or right value was "got" or "want" is an annoyance and could lead to a sort of stuttering of comprehension. While I don't think test data var names are highly important, I do appreciate you calling attention to the common naming scheme used in the standard library. It's likely that I will be changing my own habits to more closely match the stdlib (which seems to be "tests" for the table and "tt" for the row). I am wondering, however; What does "tt" mean that it makes sense for the name of a test row/case? Table test? But it's not a table, it's a row from a table. Maybe it's an alternative form of simply "t" because "t" is used for "testing.T".
Improved the post, hopefully it is more clear now :) 
improved the post :) 
Too bad Python and JS support are a long LONG way off. That said, maybe as the target matures, we can just force our users to script in Golang.
the opposite of "worse"
In this context, of course.
Yeah, we evaluated otto and goja, but the lack of ES6 support meant enriching the environment with any decent libraries was a tremendous pain. Ended up going with augustoroman/v8
We also do this, everything prints to stdout/stderr and our log aggregators ship it all to elasticsearch. We use fluentd inside Kubernetes and filebeats on standalone hosts, etc. This way makes it so no code needs to be aware of the logging mechanisms which simplifies development. Developers can print out messages for debugging locally and not have to worry about changing behavior when moving to dev/stage/prod.
Almost every part of code could be rewritten better. But what the cost? Both examples could read without any troubles, so why do you want to spend more time?
what does it mean to be opinionated? what does make a language opinionated?
The lack of ES6 is definitely a issue... But If you just want some way to run simple scripts and call some Go functions from there it's not too bad
&gt; It has worse raw performance than c/c++/rust/Java If by worse you mean comparable. &gt; demands quite low level coding. In most cases lower than c++/Java. If by lower level, you mean simpler. The Go languages has far fewer idioms and features to learn. Just because it's not object oriented, that does not mean it's lower level. In many ways, it's higher-level especially when it comes to concurrency (when was the last time you managed your own thread pool?). &gt; Simplest things in this languages - a lot of code. That's not necessarily a bad thing. I wrote about it here: https://medium.com/@shazow/code-boilerplate-is-it-always-bad-934827efcfc7 &gt; Also, still there isn‚Äôt much good libraries. Go has, by far, the best standard library of any programming language I've used. There are [*tons* of amazing third-party libraries](https://github.com/avelino/awesome-go), especially considering how young the language is, but there are far fewer unnecessary libraries because of the strong standard library. &gt; In python I just make pip install In Go, I just `import http` and get a full http/2 implementation of the latest spec with all of the features maintained in the standard library, including concurrency support. What package are you going to pip install to do that in Python? (Hint: It's not requests, which uses urllib3 which I originally wrote.)
Both tools are excellent tools to have in your toolbox. I don't think you should say "goodbye" to anything. It's like saying you want to replace your pliers with a monkey wrench. 
Yeah absolutely, I think this is a great step toward possibly unifying programming for different platforms. No complaints here, a wasm vm host that split off new instances for wasm programs would be pretty sweet! It is still funny to me that we're Benjamin Buttoning the JVM though
You might already have an appropriate tool for your job then.
TBH, I just like it, I like OTP (Erlang's Orchestration Protocol) and I enjoy the syntax and I like functional programming more because I feel like it makes you think more about the code and less about the stuff that we hand wring over all day otherwise. I would highly recommend "Elixir in Action" or "Programming Elixir 1.6" if you're interested, they are both great books and TBH I worked through both of them to solidify concepts that one was weak on or the other.
I‚Äôm an EE in Silicon Valley and id say I do about 7 to 7.5 hours a day total. Which for me is fine. I used to commute and work way more and I was always just completely exhausted when I got home.
Probably. I did an interview for a hardware test engineer position and the whole thing turned out to be a Python test. I‚Äôm not sure why since I said Python is a small part of what i do and a small part of the position. I think they just interview too many people so they just fall back on programming quizzes because so much of their workforce can give those.
You forgot the buses that will pick you up anywhere from SF to Santa Cruz. You have almost 100 mile range you can live and commute via bus. My friends who do it all really like that system.
It seems really unfortunate that there is no comparison to the industry-standard WebAssembly VMs, which are the ones built into Chrome and particularly Firefox. It would also be nice to have `native` in the benchmarks as well, so we can see how much slower `Life` is than just running a binary locally. Ideally, Firefox is approaching native-speeds with their WebAssembly VM. Virtually everyone besides Firefox and Chrome is as slow or slower than JavaScript VMs, and Chrome is only slightly better.
As I know, Java is faster. For golang even 10k problem is hard, whereas Java can handle ‚Äú3m problem‚Äù. The same for row performance.
&gt;https://goswagger.io/ Thanks for the responses. I like gojsonschema but my user base really wants a UI for the REST API, thats why I have to stick with swagger. If you are aware of any other UI API tools like swagger let me know. I am willing to try it out
&gt;https://github.com/google/go-cloud what tool(s) do you recommend to create APIs? 
People compare performance of golang and c/c++/... not because it‚Äôs comparable. But because all these languages offers similar abstraction level. Compiling time? Really? Maybe ten years ago it could be a real advantage. But now? Ssd and a lot of ram - and even large c++ project compiled in a trice. Writing code is a bad thing. Less code - less bugs. More code - more bugs. It‚Äôs terrible to write code for simplest operations. And you even can‚Äôt move it to separate function due to ‚Äúwe don‚Äôt need generics, there‚Äôre too hard‚Äù. Yes, golang has the best standard library I ever know. I like golang. It has a lot of advantages, but also a lot of problems. But I don‚Äôt like meaningless praises and yellow headers. 
CarPlay just recently opened 3rd parties map, Android Auto is very limited too. It‚Äôs basically a poor screen display. Both map systems force you to have a network link, sounds like a terrible idea for a moving vehicle which can go in remote area... Also connecting an external composite camera to android is probably painful. 
If you need a place that‚Äôs more of a ‚Äòcity‚Äô than SF you basically have New York and maybe Chicago left?
&gt; Also, still there isn‚Äôt much good libraries. In python I just make pip install, in go I have to write required libraries myself or fork/update something from github. What's missing? These days there are a heap of Go libraries out there - I'm sure there are a few esoteric things, but I don't regularly find I'm missing anything that I'd expect to find in other languages. And the standard of many of them is pretty high - I'm impressed at how many libraries I chose with only a little research that remain pretty close to the optimum, I've seen many more cases in other languages where we made what proved to be extremely suboptimal choices.
At my work, we use agreed Linter that forces formatting, and throws error during CI if it doesnt confirm. There is no question you have to use linters, but gofmt removes the argument/discussion as its just there. Sometimes you're just happy to apply what is there without argument, sometimes you wish you can change, but gofmt does good job.
Golang will throw warnings if you name with a convention other then camelCase, it will also complain about missing comments and stuff of that nature. More annoying it won't build if you have unused variables, or an import. That's not even the surface but what comes to mind.
Yeah, my only complaint is that it's a bit annoying when someone who doesn't claim to have any experience in a language with generics "doesn't see the use for them." 
Annoying? I consider this a feature. And a good one at that. 
I find SF boring in comparison with smaller cities. Also super expensive, which has lots of side effects.
I get carsick in those buses, so I can't work on them. It's really terrible to commute that long, that's not a situation I want to live in.
The go compiler is like your mom. It will yell at you to clean your code before you can play.
I like the I wish you could override this on a temporary basis. Sometimes, I want to isolate something while troubleshooting and would love to be able to just comment out stuff I don't need
[removed]
You mean, an ideal language for teams who don't already have their own opinions..
Afair gopher-lua is extremely slow. I solved the problem of having scripted and dynamically reloads le requests with Tarantool.
[removed]
For the projects I was working on I would say the opposite is true. Anything above 1000 lines in python was a bit of a pain, trying to understand what data type something is, or where it comes from exactly, just like with any dynamic language. Go worked better on larger projects for me, where having static types helped. But then the largest application I worked on had 15K CLOC, so I don't know what happens at even larger scales. I guess learning Go before Python made me aware what Go was trying to fix when it comes to python problems.
Yeah not very fast. However I use a branch (I hope soon merged) that lets you compile files into bytecode and reuse those compiled files, that makes things a little bit better
Funny. This branch is made by my colleague. But it‚Äôs performance is still far away from Tarantool.
Please post your evidence for such claims.
Bytecode cache will only save startup time, not the actual execution time.
It actually helps on execution time since you dont need to parse a file on each request to be able to use a lua state for that file. But yes, its not the fastest thing out there
Why would you parse files on each request. You initialise Lua vm and than make a thread (copy) of it. Take a look at nakama game server - it‚Äôs a good example of how go + lua can live together.
[Here's some](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/go-gpp.html). "But..." No. It's evidence. If you're not going to accept that as _evidence_ there is nothing that will prove it for you. [I wrote up 20 days ago why it would be _weird_ if Rust wasn't faster than Go](https://www.reddit.com/r/golang/comments/8ym8lf/why_is_this_simple_benchmark_3_times_faster_in/e2c8ih1/). 
Well I have some opinions about that (honestly), but I'll keep it short: Opinions are fine and are reasonable to mention in a code review provided that: * Generally speaking your opinion improves the code's behavior, performance or limits side effects. One of the main points of code review is to make improvements before something lands so opinions are warranted but they shouldn't be something that's based on 'feel'. * If it's a style change, which often are based on 'feel', you're adding your opinion because: * It keeps the code consistent with other parts of the project (reduces cognitive burden when switching between a dozen different sub-projects) API or a defined style guide for the team. * It makes it harder to make a *human* mistake in the future (ex. use a constant instead of a string, limit variable scoping, etc) * It reduces operational load in some way (ex. log with this style of message instead of this one because it's easy to parse and read) * When there are differences of opinion, majority should generally win. Only exceptions to this rule are: * Security. If you have a real security background and the majority does not agree with your opinion and it's a real problem then you should fight for what's right. * Operational experience. If the person with the opinion has actually seen shit in production go wrong because of X then majority should likely yield. Ops guy better have a detailed example though that applies to this situation and the target environment. * Reasonable future proofing. If someone decides to do something differently just because that's how they're using to doing it/it's easy for them at the time and it's going to clearly create more work later on then you should fix it now because we do not always have the luxury of time later.
Okay well I wish you could turn it off temporarily while hunting for issues, I do agree it's a good feature I just have run into that allot while troubleshooting.
I said goodbye to Perl in favor of Python, and I think we can all get behind that.
vscode is OK, but is still lacking a ton of stuff. Last time I checked you couldn't even have floating windows so the terminal always had to be attached to the main editor and you couldn't take advantaged of multiple monitors.
Bison is already a very popular LR parser in c++ fyi. 
You can set up almost every editor to perform `gofmt` and `goimports` on every file save. This will add/remove imports as necessary and (depending on your editor/plugins) will usually serve as an indicator of an error when you save - it either will or will not format automagically. Note that it can only add imports for packages in your GOPATH. So if you know you ran `go get [some-repo]/uniqpkg`, you can just use `uniqpkg` in your code and it will automatically add the proper import when you save. 
Because being able to write idiomatic Go is probably going to be important if I stick with it :)
Here is information on how to test that package. https://github.com/GoogleCloudPlatform/google-cloud-go/issues/592#issuecomment-406099221
technically, rewriting it would be a lot more code written, hence more bugs
&gt;Goodbye Python, Hello Go Later... Goodbye Go, Hello \_ \_ \_ \_
More gross bugs but less net bugs
I think you are confusing the Go compiler with a non-official supplementary linter for the first two. Maybe you have something like that installed as an editor plugin without realizing? The Go compiler has no warnings, only errors.
Haven't heard about steering committees and advisory groups for Athens. So it might just work after all.
I did that too, but now I have a handful of text-processing [macOS Services](https://www.macworld.com/article/1163996/software-utilities/how-to-use-services-in-mac-os-x.html) written in five lines of Perl. `while (&lt;&gt;) { $_ =~ s/‚Ä¶/‚Ä¶/; print; }` is fantastically handy and has less fluff than the same thing in Python would have. 
I still like Python as a desktop calculator.
[removed]
The circle of life
this
Welcome to Java.
I've added an example to README file.
Thanks for message. Now that message is: &gt; Also you can use builtin `SaveJSON` function to save to a `io.Writer`: Replaced file operations with `io.Writer` and `io.Reader`.
And usually they have different opinions, good luck as a team leader.
You can definitely get in direct touch with the team on discord: [https://discord.gg/dMYfDPM](https://discord.gg/dMYfDPM), if you'd like to discuss more about it with the team. 
Opinionated means to do things a specific way, and therefore also have the developers do things in a specific way, instead of offering a truckload of different ways that ultimately only lead to mishmash code and help no one. It also means to have, and in some cases also enforce, certain conventions outside the technical specs. It also means to intentionally keep certain features out of the language - either to avoid feature bloat, or to avoid complex or unclear semantics, or to not sacrifice other features (e.g., compiler speed). "Clear is better than clever", as a Go proverb says. Some love this way, some don't. Those who embrace this way discover that they can now focus on what is really important, rather than endlessly discussing whether or not to put a space between function name and parenthesis. Or in a more drastic way: Team players love Go. Coding divas want to look elsewhere. 
World 
I've used languages with generics extensively and Go's lack of them is incredibly refreshing. I'll mourn if Go 2 adds them.
I really dislike inheritance and hate when I inherit a codebase that uses it heavily.
Salut Qu√©bec !
Oh god this is so wrong
This solves the specific case I mentioned, yes, and I believe there are cases where this doesn't work. One example would be taking over a single repo in an organization. To manage things like the third-party applications that we use (think CI, code coverage, etc.), we would need to become administrators of this organization as well to fully manage this single repo. For something like the gorilla organization, would it be acceptable to ask for administrative access only to manage the websocket repo? I'm not sure.
It's just a mindset thing though, not really a sine qua non. If you have spent time outside Java/C#/C++ world your muscle memory is used to dealing with the same problems with other "tools" and you won't really miss them apart from the odd case where they truly are the only natural method. That is why large amounts of Go users (who either come from C or dynamic languages} don't really see it as a big problem. 
&gt;run with the latest Java, to be sure I'd recommend you to use Java which is shipped together with the IDE. It's not the latest one for sure but we maintain our own fork of OpenJDK which has several critical fixes including performance related ones.
What we do using apache kafka. Send all logs from the microservice to there and then plug logstash into it. It comes down to how much you value your logs really after that, as kafka can be configured with multiple brokers to ensure high availability 
You should also give F# a try https://fsharpforfunandprofit.com/ it's not as scary as it sounds. It has the feel of python but with better pefromance and access to a huge ecosystem of libraries in the .NET world. Works cross platform with .NET core. Im not saying to ditch Go for it but its good to know many languages.
I found a typo, `dmseg` should be `dmesg`, other than that: nice article! ;)
Ideally, a package registry is append-only. Nothing which has been added can be modified or deleted. GitHub's mutability is a threat to the reproducibility of code builds, as seen with leftpad.js. Anyone can unpublish repos from GitHub and break everyone's code, and it has happened in the Go community before. If Athena isn't supposed to do what I mentioned above, then I also have no idea what the benefits are. I haven't had a chance to research Athena.
I don't like these pointers to models, smells like active records(which i don't like). Also, in Update method, what's the point of returning p, if it's already modified inside of method(because it's being passed by reference) ?
I remember the talk by Itay Weiss from [PyconUA 2018](https://www.youtube.com/watch?v=_y00S29mK1A) (video itself from Pycon Israel) - and what he said doesn't sound nice for Grumpy. Generated Go code works, but it's so unoptimized. 
That seems like a question for the Gorilla people.
I use a map of string keys to data constructed in each handlerfunc, specific to the data required by that view - that way the view only knows about data chosen by the handlerfunc, you don't have a global structure, but you can pass in several structs as required (as a simple example you might want user details, page details and details of some tags for that page). Something like: `data:= map[string]interface{}{"mykey":true,"mystruct":page}` You lose type safety in the template this way for the keys (not a huge problem IME), but gain flexibility and can use the same mechanism everywhere. Alternatively yes you can construct an anon struct like this: `data := struct { Page *Page flag bool } { page, true }` but once this gets complex it gets really ugly, and I find the map mechanism scales better when you have say 20 things you want a template to know about (for a complex web app). I think personally that some sort of global struct which contains all keys used in all views is the worst of all worlds and should be avoided. This depends very much on your target - if you're making an api or service, you can often use just one resource struct per view (this is the use-case it seems they targeted with go templates), if you're making a simple page with a few elements, an anon struct us fine, if you're constructing a page which refers to 10 different structs/lists of resources (i.e. a full web page), I think a bag of values with string keys works best. 
Is it rust? Did i win?
Yes :)
By the logic of your work, I've tried myself in different steps and I can't understand this case: Basically at the start you have this: ```go func _run(program []Op, tape *Tape) { for _, op := range program { switch op.O { case INC: tape.Inc(op.V) case MOVE: tape.Move(op.V) case LOOP: for tape.Get() &gt; 0 { _run(op.Loop, tape) } case PRINT: fmt.Printf("%c", tape.Get()) } } } ``` Which gives me a score of 5.4 seconds on my computer. And here is the solution I first thought would be the one. ```go for i := range program { op := program[i] ``` Which gives me 3.7 secondes. `op := program[i]` actually copy the struct which makes sense since it's directly a struct. (doing `op := &amp;program[i]` actually gives me 2.7 seconds which is I guess as good as your pull request) But I would like to understand why `op := program[i]` and `for _, op := range program` gives different times ?
From [this intro](https://medium.com/@arschles/project-athens-c80606497ce1) and the general description of the project, I gather it's a borderline proxy intended to be deployed by teams to have their dependencies cached persistently somewhere between their dev infrastructure and the set of places these deps were fetched from. That is, in my understanding, there _could be_ a thing like `godoc.org`, but presently there are none (at least, I failed to find one during my quick dive).
There‚Äôs a good chance that [golang.org/x/time/rate](https://godoc.org/golang.org/x/time/rate) package may cover your needs. 
The project is both a proxy *and* a registry. The proxy is what you are referring to. The registry is supposed to be a `crates.io` equivalent AIUI.
&gt;Where are the tests? Inbound. I'll probably add them this weekend.
ok. That's a good point you got. Thanks. I can return the payload without sending form repo. It's same meaning.
[removed]
Perl is more like an abstract art form more than a programming language.
I think taht this kind of subject and title end up not being constructive.
&gt; Anyone have experience with Grumpy? No, I haven't met Rob Pike in person before.
All of my personal projects use the ‚Äú1 VM, 1 Zone, 1 process‚Äù model, and I concur that it makes working on things so much easier and more fun. So far, I‚Äôm well within the scaling limits.
And we've come full circle
If only it supported Python 3, I would be all over it.
if A if an interface of pkg you can juste use pkg.A in your function signatures
hex(), ord(), bin(). I also test bit shifting and all that **int &amp;= ~(1&lt;&lt;3)** stuff when programming in C.
I experimented with Grumpy about a year ago when I had a Python program that started up too slowly for me and I was hoping that transpiling it to Go would fix that. The experiment was unsuccessful (at two levels; the transpiled program didn't start any faster and then it didn't work because of unimplemented features in Grumpy), and making it work at all required a pile of hacks. At the time I ended up concluding that Grumpy was an ongoing experiment, not something that was ready for anyone to actually use. One of the big issues with Grumpy for me is that it doesn't actually attempt to translate Python into equivalent Go. Instead what it creates is much closer to CPython bytecode that's been turned into Go code (calling various support functions and so on). This faithfully preserves the semantics of CPython (which is explicitly one of Grumpy's goals), but it means that Grumpy has a lot of overhead compared to native Go code that does the same thing. If what you want is something that will take straightforward Python code that could be turned into generally equivalent straightforward Go code and do this translation for you automatically, Grumpy is not it and probably never will be. It's a pity, because such a thing could be quite useful even if it had clear limits on what Python code it could handle (these days you might want to start from Python 3 code with mandatory type annotations and perhaps a bunch of assert()s, to make the translator's analysis of the code easier).
[removed]
I just went through chapter 10 on microservices, and the resulting program that was made does not work. Even if you download it from the repo, it does not work, it hasn't been updated. I also found around 10 typos in the chapter, including some in the code itself. I see this book posted on here often and I want to advise against it. It's more expensive than any other book I've bought and it's the only one featuring programs that just don't work. Also, it's not an advanced or topic specific book. 
Is ‚Äúevolutionary optimization‚Äù replacing the term ‚Äúgenetic algorithms‚Äù?
go misses a lot of stuff in the machine learning department. Yes, even basic stuff like logistic regression or random forests. It has very little stuff for semantic web, too. It's not as powerful as pandas for dealing with tabular data, too. It's impossible to do simple/basic GUI programming with Go, √† la Python's tkinter, unless you link to big libraries.
Do not care to much about spawning gorutines. Either limit a pool with semaphores or just let the scheduler do its thing.
I wrote this out fully, so I can hopefully refer to it in the future: [Here's the playground code, with comments](https://play.golang.org/p/eABQICmDBNX). Here's what I posted there: package main import ( "fmt" "sync" "time" ) In many languages, you need a "pool" mechanism to handle threads, because threads are expensive and you don't want to start many of them, so once started, you want to get as much value out of them as possible. Since that can be a pain, you often use a library to make it easier. People coming to go from other languages then wonder where the pool libraries are in Go. The answer is that while Go, strictly speaking, does not have a built-in "pool", the primitives that it does support are so close to what you need that there is not much room for a library to help you out. This code snippet will demonstrate how to create a "worker pool" of goroutines, dispatch jobs to those pools, shut them down properly, and then continue on. At the end, I'll comment on the things to watch out for when using this technique. const ( NumberOfWorkers = 3 ) func main() { // make the tasks channel tasks := make(chan string) wg := sync.WaitGroup{} // you often see people adding them one by one as they spawn goroutines // but you can add them in one shot if you know in advance. wg.Add(NumberOfWorkers) for i := 0; i &lt; NumberOfWorkers; i++ { go func(workerNum int) { // in real code, a defer function to recover is // a good idea here, because any panics would // otherwise crash the entire program defer wg.Done() for { // pull tasks from queue until done task, ok := &lt;-tasks if !ok { // we're done return } fmt.Println("Worker", workerNum, ":", task) // JUST FOR THIS DEMO, give the other workers a // chance to catch jobs; normally this is unnecessary // of course! time.Sleep(time.Millisecond) } }(i) // in Go, if you try to close on the i above, you'll have a race } // we now have NumberOfWorkers running. Give them tasks: for i := 0; i &lt; 10; i++ { tasks &lt;- fmt.Sprintf("This is task %d", i) } // Signal that we're done with our work: close(tasks) // Wait for the tasks to complete: wg.Wait() // You're done! } It is tempting to say "But I could use a library for some of those things up there". However, look at what you're actually saving. Is it really an advantage to type "Pool.EndJobs()" vs. "close(taskChan)"? Every Go programmer will understand the latter, and its precise semantics. The former? Not so much... does it immediately terminate the pool or wait for jobs to finish. Does the call synchronously wait for the jobs to finish? Is there any sort of context involvement? You'll have to document this all in your new library, and people will have to learn it, and it won't carry over to somebody else's library, whereas `close(taskChan)` is completely obvious. The biggest traps I see in this pattern are: 1. Watch out for the amount of work your workers are doing. The pool may be cheap, but it is still not free. You want your workers to be doing enough work that the coordination of spinning up goroutines and using channels is a negligible fraction of the time. Something like "printing a single string" or "adding two numbers together" (a common beginner test task) is too small. (A simple solution is to be sure to bundle up enough work in one message to make it worth it.) However, generally, if your work tasks are so small that it's too expensive to spin up some worker goroutines, they're too expensive to be dispatching across cores via *any* mechanism. Don't underestimate coordination costs; for small tasks it can be fastest to just do them on one core in one goroutine regardless. 2. Certain request patterns could make this problematic; if you have *highly* bursty requests, then you may grind your process to a halt trying to spin up a lot of goroutines for each request when a pool could have worked out. In that case, you still don't need a library per se; you just take the above code and spin the pool up once for that task. There still isn't much use for a "generic worker" pool in Go; it's cleaner code and except in rare cases, not that much more resource-expensive to just go ahead and spin up a pool per task, which keeps the tasks from being coupled to each other. 
So now if a library was depending on gago, that library is broken because it can't find its dependency?
Why should I use this library if I can do it myself with like 10 loc.
good about go, there isn't much language-advanced features, with other language you can write books about their obscure features and call it advanced, the topics you mentioned you could read about in any language.
There's not another header called `X-Service-Ratelimit-Reset`? Usually that would be included so you know the timeframe for the rate-limit (minute, hour, day) and can assist in the math needed to successfully rate limit your outbound requests. Here's how I would handle it using `time.Tick(time.Minute)` which returns a channel that will block until a minute has passed: rateLimiter := time.Tick(time.Minute) for req := range requests { &lt;-rateLimiter // make request } 
I'll also be sad if that happens. Won't be able to just dismiss gophers with a simple `lol no generics` anymore :(
I tried it a while ago and couldn't get it to work.
To be honest I don't follow books cause they tend to be placed away. I follow these. ‚ÄúA series dedicated to deeply understand Go‚Äôs specification‚Ä¶‚Äù https://medium.com/golangspec And his stuff is really broken down. ‚ÄúHow I write Go HTTP services after seven years‚Äù @matryer https://medium.com/statuscode/how-i-write-go-http-services-after-seven-years-37c208122831
Thanks for the info. ‚ÄúGA‚Äù has always grated on me, because when you use that term with outsiders, its easily confused with bioinformatics...
Convenience, composability (namely of jittering methods), reliability (esp regarding testing, which is hard for stochastic functions). But by all means, you can absolutely do it yourself.
Opinion from a new user to mongoDB who had to make a choice between mgo &amp; official mongodb driver. mgo driver and mongodb official driver doesn't serve the same purpose. mongodb is (at least for now) a low level driver. It allows more functionnalities but requires a bit more code to use it. I had trouble understanding how to make Bson Document (the lack of real example made it harder). Once I understood, I created a little wrapper allowing to easily create Documents and mongo Filter. Since then I am very happy with this driver. I encoutered some cases with a lack of log that could have helped debug some situations, but I believe that this is due to my lack of mongoDB knowledge in general. Hope this helps.
That's a cool project to have but I think documents about the whole structure and design would make much cooler.
I don't understand how you can have "extensive" experience with generics yet find their nonexistence in a statically typed language refreshing. It's not like a dynamically typed language where it doesn't matter. Go literally has no answer for the problems generics solve. There's no language level feature that softens the blow of generics not existing. There's just people using `interface {}` and people using external codegen. Both of which suck.
&gt; I'd be willing to extract this into its own repository if there's any interest in that. Definitely. A pure Go rsync library would be very useful.
Then you haven't done enough research to understand the arguments of people against generics being added to Go.
Sounds like a plan then. It shouldn't be too difficult, though I may just extract the core `Engine` component for now to minimize the API surface that needs supporting.
IDEA (and I assume Goland) supports dep as well as vgo, so don't let lack of enthusiasm for vgo dissuade anyone from trying IDEA...
We just had a presentation about this at Gophercon UK. I'm super pumped about it. It's not really a "registry" like npm or pypi. It still relies on github/gitlab etc. It's more of a public caching proxy that's federated and append only, with trust built in. Check out the presentation: https://cda.ms/B6
Warning on naming, there is an existing Mutagen project in Python for editing metadata on audio files. Pretty old now I guess, but I have some commits on it üòÅ
Care to enlighten us?
I own this book and have found it to be an excellent way to get started within different topics such as http, concurrency, mutexes and whatnot: Go in Practice: Includes 70 Techniques https://www.amazon.com/dp/1633430073/ref=cm_sw_r_cp_apa_fFizBb9D825A4
The only arguments I've seen are those saying they add complexity. I haven't seen any arguments saying they aren't necessary or they don't solve a problem. 
https://www.manning.com/books/go-web-programming
Would you feel even more refreshed if they took away the generic slice and map?
If you've found an issue with https://bitbucket.org/kardianos/rsync , file an issue please. As far as "not being maintained", it is an algorithm...
No, that's the old home; no more active development is happening over there.
It seems like there are plans. I would be very interested too; I'm concerned that my company is going to find that Python doesn't meet our performance goals, and we'll find ourselves in a place where we have to choose between rewriting in another language and introducing a bunch of C (and probably actually slowing it down, since "just write the hotpath in C!" usually misunderstands the cost of marshalling between C types and Python types). It would be great to have an option that allows us to port to Go over time.
Yep. Im just very frustrated with the lack of progress in this area. SDKs for frameworks like Apache Beam are being written in Go, and they are suffering a lot because of the lack of generics. I really want to use Go in our projects, but it is just not feasible at the moment. Structures would have to be referred as "interface{}" for it to work.
Please do. Any critiques are especially welcome. If there's something that's not working, not working fast enough, or not working easily enough, I want to know about it. If there's some barrier to usage, I want to fix it.
Homebew, yum and apt please!
Definitely thought I was on r/Witcher for a sec there.
TFW a 4chaner builds a privilege checker app
I'm on a project right now in Python for the hardware libraries. I wish I could write it in Go instead. So many little things about Python bug me. I feel like I'm constantly working around it.
TL;DR it'd slow down compilation and increase the overhead of the run-time and they don't see the value in generics given those trade offs. They're still open to the discussion. 
You didn't offend and I appreciate the issue you filed. Thanks!
You're a funny dude. What's your opinion on taking this approach? [https://clipperhouse.com/gen/overview/](https://clipperhouse.com/gen/overview/)
Why would you do this? what problem are you solving? What problems are you introducing by doing this?
I was sitting in the audience, thank you :)
What kind of hardware libraries? Do you know about https://periph.io ?
I don't quite understand why the writer for unchecked errors is stored as an unsafe pointer. Can you elaborate on this?
Well, the big problem in that code is the global "Context". Passing the "whole context" around is not that big a deal. Compare the effort of copying 12-16 machine words to a function call to the difficulty involved in "parsing the entire HTTP request", and you'll quickly see this is premature optimization concerns. Heck, even just "looking at all the bytes in the HTTP request once" is going to thoroughly outclass that in terms of expense, let alone actually handling them.
It won't even compile if you dare place your { on a new line and not on the same line as the block declaration... I mean, I get that Google is enforcing their own style convention, but to throw a compile error? Imo that's s being a bit too much opinionated
It‚Äôs cool but code generation when dealing with structures serialization is always outperforming traditional methods. When high-load and high availability is a matter, I would use easyjson + go-redis to achieve the best serialization/deserialization performance. It would require just a little wrapper around the standard methods to begin with.
Compilation - yes. Runtime overhead - wut?
But I can actually use [atomic.Value](https://golang.org/pkg/sync/atomic/#Value) to avoid direct usage of unsafe.
But I can actually use [atomic.Value](https://golang.org/pkg/sync/atomic/#Value) to avoid direct usage of unsafe.
For sure. I‚Äôm working with protobuf and go-redis for a project right now, and it‚Äôs lightning fast. 
Okay! First time experience: Installation was a breeze. `brew` support is much appreciated. Started up first sync easily. Process was very straightforward. Awesome `--help` support. I set up sync between my git repo and the git repo on another machine. This did not play nicely; I got a bunch of conflicts. I paused the sync then deleted the remote folder. I expected that the remote folder would get a copy of what I had in my local. When I resumed the sync, about half my directory was deleted from local :( But we're professionals and use version control, so nothing was lost. I deleted that sync session and created another, this time with the remote folder not there yet. This worked infinitely better. I finally was convinced when I was running `go fmt` in the terminal then glanced at the PS1 and realized I was actually doing this on the remote, and could notice no difference in my IDE. In short, this is awesome stuff, thanks for sharing! I will definitely be using it going forward.
Generally speaking, just don't buy Packt books.
pretty much, yeah
[removed]
&gt;You're telling me it's fine that &amp; doesn't actually take the address of what you apply it to? That you take an address of a thing and then, when you modify what's pointed at, that thing doesn't actually change? It can either take the address of the thing named in the expression, or of the value of the expression. I'm talking about the latter, in which case you're dealing with a copy, so you wouldn't expect the original to be modified. &gt;Or that it's fine that &amp;expr might allocate new memory on every usage? It can be allocated on the stack, depending on escape analysis, like it is now. &gt;And that &amp;expr == &amp;expr returns false? &amp;MyStruct{} == &amp;MyStruct{} already does that. &gt;Yes, but that's exactly why these things are not addressable. They are not addressable, because you can't actually safely get a pointer into them. &amp;MyStruct{} proves that's false. &gt;The term "addressable" isn't just a random, made-up term. It means "something you can get the address of". Yes, *of*, not necessarily *in*. See &amp;MyStruct{}. &gt;What you are suggesting is to overload &amp;expr to sometimes mean "take the address of expr" and sometimes mean "allocate a new value and initialize it to expr". They are very different operations, why would you use the same operator for them? (You could make the argument that we're already doing that by special-casing &amp; for struct-literals. Which is fair - in fact, I'd argue that it was probably a mistake to do that special casing. Though it works fine in practice. Doesn't mean it's a mistake we have to replicate to more cases.) Yes, struct literals were what got me wondering about this. I see your point about struct literals being the exception, and everything else about &amp;expr relying on knowledge the compiler has about built-in types. &gt;So I don't quite buy the "doing something useful in the general case" argument. You are introducing a lot of confusing situations to get a tiny bit of convenience. I agree. While &amp; currently only works for special cases (except for struct literals), they cover most cases in which you'd want to use it, and adding a general case that wouldn't be needed that often would be confusing. Thanks for your thoughts!
Sorry to hear about the initial conflicts, though I'm curious to know where they originated from. Were you using the `--ignore-vcs` flag with `create`? Maybe they were originating from inside `.git` if not? Or maybe the repos were sitting at different revisions? It's definitely easier to have one copy of the repo be the "master" of sorts, the one where you running `git status/commit/...`, and the other be a replica of only the working tree (i.e. with `.git` ignored using `--ignore-vcs`). Stuff can propagate back and forth in the work tree obviously, but it's better to let `.git` exist in only one place. Clearly the documentation can give better guidelines here. Perhaps some examples for common use cases (e.g. "So you've got a Git repo and want to edit the code locally and run it somewhere else..."). I've been using it for so long that I have no reference point for what's obvious and what's not, so this is super valuable feedback. Thanks! Please feel free to open up any issues on the issue tracker if they come up. P.S. Thanks for the gold :)
Any plans of support other remote development features such as invoking remote commands (compile/debug/tests etc)?
&gt; The Go ecosystem only has one vulnerable library that we found which was fixed within two days of us disclosing the issue. Note that the Join command concatenates the two path parameters and returns the shortest path possible after being resolved. &gt; https://github.com/mholt/archiver/pull/65
&gt; The Go ecosystem only has [one vulnerable library](https://github.com/snyk/zip-slip-vulnerability) that we found which was fixed within two days of us disclosing the issue. Note that the Join command concatenates the two path parameters and returns the shortest path possible after being resolved.
&gt; The Go ecosystem only has one vulnerable library that we found which was fixed within two days of us disclosing the issue. Note that the Join command concatenates the two path parameters and returns the shortest path possible after being resolved. // Example Vulnerable Code: func (rarFormat) Read(input io.Reader, dest string) { rr := rardecode.NewReader(input, "") for { header := rr.Next() writeNewFile(filepath.Join(dest, header.Name), rr, header.Mode()) } } // Example Validation Code: func sanitizeExtractPath(filePath string, destination string) error { destpath := filepath.Join(destination, filePath) if !strings.HasPrefix(destpath, filepath.Clean(destination) + string(os.PathSeparator)) { return fmt.Errorf("%s: illegal file path", filePath) } return nil } 
You do realize that Go's usefulness is fit only for light weight system programs with specific use cases in a unix environment, yes? If Go *did* add generic support it would become a true canditate for the enterprise software, which is corrupted by fucking Oracle Java whore mongoring.
&gt; or of the value of the expression. A value does not have an address. Addresses point to storage locations and storage locations are allocated to variables, constants, functions‚Ä¶.And storage locations *contain* values. But it doesn't make sense to talk about "the address of 42". Much less if that address changes every time you get it. &gt; &amp;MyStruct{} == &amp;MyStruct{} already does that. Yes, it's an unfortunate decision to overload that operator for this. As this discussion proves, that decision is often confusing people. AFAIR one of the early Go team members also expressed that at some point. &gt; &amp;MyStruct{} proves that's false. No, it doesn't, on the contrary. The spec says "**As an exception to the addressability requirement**, x may also be a (possibly parenthesized) composite literal" (emphasis mine), specifically saying that composite literals are not addressable. Honestly, I just think that the `&amp;MyStruct{}` syntax was a mistake. Digging a bit in the archives confirms [Russ thought the same in 2011](https://github.com/golang/go/issues/1445#issuecomment-66054257). Unfortunately, the reasoning behind it seems lost to time. It took some digging, but this is the commit [introducing the behavior to the spec](https://github.com/golang/go/commit/37ab838d3a6544d3661f978a0a9305e61f447403) (with a couple revisions to the phrasing later) and this is the commit [introducing the behavior to the compiler](https://github.com/golang/go/commit/beee6915f82633e5aed82297201a80920cc0c647). Neither contains any justifications. I tried digging some more (there are other references to the syntax in examples at that commit), but TBH I can't really be bothered right now :)
Someone is teaching me an important lesson by spamming new search requests at the live site, thank you stranger. I am currently looking at how to implement some form of rate limiting.
IDK mate, don't ask me. 
Looks good. I can see this as very useful for development and also maybe some devops emergency situations. A couple thoughts: 1. Looking at the docs on the main sight, I was a bit confused at the terms alpha and beta. I deduced that it's the source and destination, but something a touch more explicit might help. 2. Very cool idea to auto-install the agents. What would you think about having the cli download the appropriate agent from github if the agent tarball isn't found? I dropped the binary into the bin dir in my home directory and this broke it until I also put the agents in there. Good work. Thanks for sharing.
How does this affect compiled code? Have you tried benchmarking the two approaches? I think something like this is needed in Go. Even after years of using Go, I sorely miss using e.g. `@Required` argument annotations from Java.
I think I was unclear; I'm not looking for Grumpy to be a faster Python implementation, but rather, I'm excited at the potential of being able to incrementally move to a more performant (yet still maintainable) language.
Yes but Rust's mom didn't completely stop learning new things in the 60's Timmy. 
Exactly. I want my language to take a strong stance against code reuse, type safety, and strongly embrace repetition and verbosity. 
So I guess to be a team player you must want to massively repeat yourself when coding, ala "if err != nil" and copy paste implementing genetics.
I think most of the time you probably don't really need a pool. Maybe you do want to limit the number of goroutines running at once, though. E.g. if each goroutine is CPU intensive and you want to echo progress on the tasks in a reasonable manner, rather than having all of them complete around the same time. An easy way to limit how many goroutines are runnning at once is to use a channel as a semaphore. E.g. something like sema := make(chan struct{}, numCores) and then in your worker goroutines: sema &lt;- struct{}{} // will block if there are more than numCores goroutines doing work right now // ... do work ... // &lt;-sema That'll ensure you don't have more than `numCores` goroutines running at once. IMO much easier than a pool, but you still have the nice property that you're not making tiny progress on many tasks at once, rather just completing tasks as quickly as possible.
Page is really slow for me. Anyone have an alternative link to release notes?
https://tip.golang.org/doc/go1.11
Thanks!
I think you shouldn't use Mongo. seriously, just make a single JSONB column table in Postgres if you really want schemaless.
Read about "Go Cross Compilation": ‚Ä¢ https://stackoverflow.com/a/20830892 ‚Ä¢ https://github.com/golang/go/wiki/WindowsCrossCompiling ‚Ä¢ https://github.com/golang/go/wiki/WindowsCrossCompiling ‚Ä¢ https://dave.cheney.net/2015/08/22/cross-compilation-with-go-1-5 ‚Ä¢ https://www.digitalocean.com/community/tutorials/how-to-build-go-executables-for-multiple-platforms-on-ubuntu-16-04 ‚Ä¢ https://golangcookbook.com/chapters/running/cross-compiling/
Read about "Go Cross Compilation": ‚Ä¢ https://stackoverflow.com/a/20830892 ‚Ä¢ https://github.com/golang/go/wiki/WindowsCrossCompiling ‚Ä¢ https://github.com/golang/go/wiki/WindowsCrossCompiling ‚Ä¢ https://dave.cheney.net/2015/08/22/cross-compilation-with-go-1-5 ‚Ä¢ https://golangcookbook.com/chapters/running/cross-compiling/
Read about "Go Cross Compilation": ‚Ä¢ https://stackoverflow.com/a/20830892 ‚Ä¢ https://github.com/golang/go/wiki/GccgoCrossCompilation ‚Ä¢ https://github.com/golang/go/wiki/WindowsCrossCompiling ‚Ä¢ https://dave.cheney.net/2015/08/22/cross-compilation-with-go-1-5 ‚Ä¢ https://golangcookbook.com/chapters/running/cross-compiling/
Problem building with go.mod (outside GOPATH): "build main: cannot find module for path main" This didn't happen with the previous beta.
https://github.com/golang/go/issues/26798
Yes, it's the same thing. Everything working fine. Thank you! Do you happen to know anything about the state of plugins on ARM? Waiting desperately for this. 
If GOCACHE=off support is going to be removed, how do we solve the situation where there are c/cpp source files that are edited but don't trigger a new test? I have had to set the cache to off for my cgo project 
spend extra 10 min writing verifier, high five yourself 3 months later üòé
If you have Go installed on the linux server then simply `go run main.go` on the linux server and it will run it. You could also do `go build` and run the resulting binary. If you want to compile the source code .go file to a binary on the windows machine and then transfer the binary to the linux server you can cross compile it with go build by setting environment variables `GOOS` and `GOARCH`: `env GOOS=linux GOARCH=arm go build`
Raise an issue on the tracker or the mailing list, as this is not really the best place to ask for it.
God forbid you elaborate on why
As a shameless plug, you can use GoLand in trial mode to get those things to work outside of the GOPATH as we have builtin functionality similar to them. We tested it with Go 1.11beta2, and we'll see what needs to be changed for 1.11beta3.
Hm. Why the `os.UserCacheDir` not in `os/user` package?
I wouldn't say that Mutagen is an alternative to rclone. I think I should have been clearer about Mutagen's use of "rsync". Mutagen uses rsync the algorithm, not rsync the command. rclone is essentially like the rsync command, i.e. it does unidirectional pushes of data from one endpoint to another, but it doesn't reconcile the contents of two endpoints and identify conflicting changes. It essentially just paves over one copy with another (albeit with an efficient transfer protocol). Mutagen is closer to Unison, i.e. it uses hash-based snapshot of the common ancestor of two directories, does a three-way merge to reconcile any changes and identify any conflicts, and then uses the efficient rsync algorithm efficiently propagate changes, this time in a bidirectional fashion though. Essentially they serve two different purposes. rclone would be useful for things like data archiving. Mutagen is better for things like remote development, where you want to edit code on your local machine but have it run in a remote environment and potentially have output files generated on the remote system be synchronized back to your local system.
Dev vm on the same laptop? If yes look at NFS/cifs setup for dev vm
Thanks for the feedback! Regarding the alpha/beta terminology, this is something that definitely needs some improvement. The problem is that they aren't really "source" and "destination," because they are equal in terms of synchronization (i.e. changes are propagated bidirectionally with equal precedence). Over time, the alpha/beta nomenclature has become more of an internal artifact, and there would probably be a better way to expose these names externally. I'll have to brainstorm on this a bit. Maybe something like "Replica 1" and "Replica 2," just to emphasize equality. Regarding auto-downloading agents, this is something I've considered. Actually I was originally going to have the Mutagen compile agent binaries on-the-fly using Go's cross-compilation, but once it became clear that a bit of CGo usage was going to be necessary for filesystem monitoring, that was ruled out. I also didn't want to make Go a dependency. But, I have realized that the agent binary bundles are getting just a little bit bigger each release, and each Go release makes things just a bit heavier still. I've thought about just posting the less frequently used binaries on GitHub releases or somewhere and having Mutagen auto-download them as necessary. If the bundles start getting up in the 75 MB range, I may look at doing this. I like everything available offline though... Maybe I can have different bundle variants, one for the 5 most commonly used platforms, one with everything. On the other hand, if people can ship 150 MB of Electron runtime to support a basic app, I'm not sure where a reasonable cutoff is anymore. I'm sort of willing to tolerate 50 MB to support 25 platforms. The biggest benefit of getting the agent binary size down is quick copies to remotes, but since this cost is amortized over time, it's not that big of a deal. I'm hoping though that [issue 6853](https://github.com/golang/go/issues/6853) will see another "beast mode" effort from David Crawshaw or someone equally talented in the compiler team, but I think the gains to be had at this point may be minimal. The compressed DWARF information coming in Go 1.11 will definitely help, but I think most of the benefits there were already present in Mutagen's case by gzip'ing the agent bundle.
If unidirectionality (i.e. just a mirror of the files) is all you need, and you don't need to propagate anything back, then the pure rsync command is going to be your best bet. I think there's a Win32 port as well, but if not you could probably use rsync via Cygwin. Mutagen and Unison are both bidirectional, i.e. each synchronization is bidirectional, and it doesn't sound like this is what you need. The rsync package inside Mutagen is very low-level, it would be for embedding into a large program, not for end-user use cases.
If you want to disable it in the `go test` command you can also run it with `-count=1`
Well, to begin with if you use golang well, ‚Äúnot using golang because some things are easier with objects‚Äù makes you go like ‚Äúwut ?‚Äù. Golang does work with objects. Secondly, golang is made for large projects, python is made for small projects. Maintaining a monolith with python is worst idea.
Just what I needed! thank you :) 
You could always see what the tool authors need help with and help make it happen! :) 
As an enterprise dev (especially one who mainly worked in Java and PHP) DI/IoT containers are a habit that I really had a hard time breaking out of. In PHP, autowiring with a DI container is 100% good practice because of the performance advantages of lazy-loading and dynamically creating an instance of the service since every new request is a new process. In Go when using the `http` package, I really think that DI containers become an antipattern. DI can be handled without lazy-loading or autowiring, because it's all wired when the application is invoked instead of on-demand, so you don't have to worry about some uncommonly-used service being fruitlessly loaded a million times, and you get the added bonus of more simple code, less boilerplate, and no added magic for injecting dependencies.
I don't quite follow. Could you tell me how that combination makes it easier to store/retrieve/modify json members directly without having to read the entire object from redis and rewriting it after manipulating a member ? I emphasize "members" here !
I prepare myself to debug :)
You can compile a go package into gomobile bindings and use it as a library in an android studio project, the process is relatively straight forward but took forever for me to the first time, be sure to import the .aar file and not the .jar. Just remember you might have to obfuscate unsupported types in gomobile by only using supported types in the input and return parameters.
Will smart Go people thing, "This person is an idiot and this is a bad idea" if I tell them that I want to write go on mobile using this technique?
It's also painful that most the common tools don't have a version subcommand to determine which version you have.
go test count=1
Not type safe, won't use.
I think this is one of the hardest things I have had to deal with in my position. So many developers have a mindset of quickly creating and shipping ideas, thinking that they can always iterate and improve it later. Once it's into master though it's forever, whether it's a good feature or bad. 99% of the time they move onto other features or worse, they continue to build onto it and run into larger problems later. Once it gets to that point you're basically paralyzed as the feature is now too complex to refactor. But sometimes if you're able to create a low risk environment to iterate on something, you can get great results (e.g. shared libraries or tooling). It's really a hard problem to balance those challenges - the health of the codebase vs individual contributors. People get their feelings hurt all the time. It sucks, but it takes a lot of respect and responsibility to make that call.
I haven't used this library but I was very impressed with the write-up. I'll have to check it out now. Great job!
Add a project readme that explains how to use this, structure of the code, etc.
``` If we put it in os/user then it's harder for cmd/go to use it (it cannot depend on cgo for bootstrap). I don't believe os/user is necessary for XDG anyway - the spec very clearly says $HOME not "the user's home directory". ``` -- RSC
Good advice, but maybe ARM is not be best default suggestion ;)
You‚Äôre right, OP specified use on a server so if they are using a Linux distribution like Ubuntu on AWS they would want to use `GOARCH=amd64`. I‚Äôve been developing software for my raspberry PI so I just went with `arm` out of habit. 
Would reading the book benefit me if I have already read all the official docs and understand the sync and atomic packages well?
\+1 on the README. The marshaling of the limit to a value could be simplified [https://sourcegraph.com/github.com/rqk89h/scrubber@1287e1b6a3d23e13c4188fd761c2ee870c6f139e/-/blob/size.go#L24:11](https://sourcegraph.com/github.com/rqk89h/scrubber@1287e1b6a3d23e13c4188fd761c2ee870c6f139e/-/blob/size.go#L24:11) A string is converted into \[\]byte, then in the unmarshalText func the first step is to convert it back into a string to check if empty, then it converts it back into a \[\]byte to call v.UnmarshalText
This book is more around concurrency patterns in go. It does go into a brief explanation of how it works but mostly focuses on examples and use cases. 
I generally avoid using regular expressions in any programming language I use. They are generally slow and unintuitive during future reviews. What I usually do is simply identify the edges of the text that I want to find, and leverage simple string manipulations to get there. In your example, you can read the file line by line, and check if the end of the SQL statement is contained in the line that you are currently reading, if not you append this line to a collector variable. Once you find the edge of the SQL statement, you add the last piece to the collector, then append the collector to an array, and finally reset it to start collecting more SQL statements.
I do not think dependency injection containers are a bad practice in go. In my first go applications, I used to create the services manually. I had a `Context` object whose fields were all the services of the application. I works well, but when the number of services increases, the code that instantiates the Context object becomes complicated. There are a lot of lines of code. And the order in which the services are created is important, because the dependencies need to be created first. In the end, the services are not sorted by their features, but more by their depth in the dependency tree. I was not fully happy with this solution, and that is why I created a dependency injection library. I think that using a dependency injection container is a tradeoff between adding complexity with another external library and a possibility to have a clearer way to declare the services. Note that there is no autowiring in `sarulabs/di`, so the code is really close to the one you would write to instantiate the dependencies manually. Also in go, the dependency injection frameworks do not create the services for each http request. There is only one container for the whole application, so the usage is very similar to the `Context` I mentioned before. The only difference is how the `Context` object is created. In `sarulabs/di`, it does not work that way though. There is the notion of scope. If a service is created in the `App` scope, the service is only created once for the whole application.But if the service is in the `Request` scope, there will be a new instance of the service in each request. I implemented that because some services can not be reused in each request. For example, in the car api described in this post, the mongo connection need to be created in each request. I do not think a mongo connection can execute two queries concurrently, so you have to use a pool of connections to retrieve a free connection for the http request. And there are other cases where a service may need to be created in each request. For example it is obvious for a service representing the user session in a web application. I would also be true for any service that depends on the `http.Request`. That being said, if you have an application that has a very small dependency tree, or an application that requires a very low latency, do not bother using a dependency injection framework.
Quote with `&gt;`, not `\`` &gt; If we put it in os/user then it's harder for cmd/go to use it (it cannot depend on cgo for bootstrap). I don't believe os/user is necessary for XDG anyway - the spec very clearly says $HOME not "the user's home directory". -- RSC
I read both and I think both are excellent! 
The RE2 regex engine native to Go doesn't really like these kinds of loose matches--that's one of the tradeoffs you get for linear-time pattern matching. To solve this problem in a PCRE-based regex engine you'd use look-arounds (specifically I think having a positive lookahead of `\[ORM]` after your `.*`). This log file doesn't look structured enough for me to want to use regular expressions, I suspect that you'll end up fighting them more than having them help. My suggestion is to start with `strings.Split(res, "[ORM")` instead of a regex and see how far you can that way. 
I see the difference between dependency injection and dependency injection frameworks. But at some point I have to create the services. Let's say that you have a web application and that the services you need are only created once for the whole application. Where and how do you instantiate the services ? And how do you access them from the `http.Handler` ? If the service need to be created only once, you can not call the constructor from the handler. The only way I see is to have the service declared as a global variable. But it is exactly the same thing as the `Context` object. The `Context` object is just a way to add a namespace above the services. Do you have a better way to create the services ?
Why is this flagged as NSFW Spoiler?
Not the same laptop, ESXi. I have a coworker who has tried NFS for this purpose and it didn‚Äôt work well for him. Thanks for the suggestion though!
It‚Äôs mostly bad practice if you‚Äôre going to be exposing it to the internet or internally to clients of unknown provenance. If it‚Äôs internal only with well-behaved clients you should be okay.
You almost always want to configure your http-server unless you operate in a debug environment. Look into the [http](https://golang.org/pkg/net/http/) package for details on defaults etc.
Thanks. I'll have a read at that. 
In main [https://gist.github.com/quii/5fb4d2fbd7eb96002e5149e18338d2b4](https://gist.github.com/quii/5fb4d2fbd7eb96002e5149e18338d2b4)
[Creating a constructor to return private type is a bad practice and you should try to avoid that.](https://github.com/rqk89h/scrubber/blob/master/scrubber.go#L33) It also hides type's methods documentation. Missing README and not very verbose [GoDoc](https://godoc.org/github.com/rqk89h/scrubber).
[removed]
[Something like that? ](https://play.golang.org/p/NJS6Dp6Nibj)
link to the talk?
According to [this comment](https://github.com/golang/go/issues/26366#issuecomment-405683150), as long as there are Go sources in the same directory as the C ones, the build process should refresh them correctly. So perhaps what you encounter is a bug and it should be reported/fixed?
Something like https://github.com/mattn/goreman or https://github.com/ddollar/forego would fit well with go, but you're probably better off just using systemd if you are on linux.
Are you having an issue, or just looking for efficiency? If it's the latter, you could just add all of the todo's to the newNote as you move through the todo rows... ``` newNote.ToDo = append(newNote.ToDo, newTodo) ``` Also, why are you declaring it as a pointer? `var newTodo *todo` and then using the `&amp;` operator. I may be missing something, but that doesn't seem right.
This is really neat! I'd love to play around with this eventually. Just need to find the time. Maybe the author can post up some simple examples of use-cases, I'd love to see what kind of shit can be done. The fact that it's portable (at least intended) is one of the more intriguing parts to me. 
I have problem when I call this method it crashes all, I am declaring this `var newTodo *todo` because my slice is of type `*todo` (in "note" struct), and I thought I have to declare slice as well with the same type. As for that &amp; operator in Scan function idk why but I have to use it like that !!
Thank you for your example. It is what I used to do. The `Context` approach is very similar. The only difference is that the handler depends on the whole `Context`, instead of depending only on the services it needs. Using the `Context` makes the dependencies of the handler less clear, but it is still the same idea. I guess I started using the same `Context` in all my handler by laziness. All my handlers were declared with the same `Context` field, and I did not have to think about their dependencies in their constructor. The problem I had was with the `Context` creation. In your code, it is only one line of code: `myDependency := &amp;HardcodedDependency{}` The problem begins when you add more services. Let's say 100 services. This part of code can grow quickly. And most of the time, the constructors do not have only one line of code. They take other services as parameter, but also configuration objects. Splitting the creation of the services in different parts is difficult. Because the services depend on other services. And as I said before, the order in which the services are declared is more or less imposed by the dependency tree. It means that you can not order the service declarations according to what they do. With `sarulabs/di`, I can create the definitions in any order, and split them into different files. Sure it is less safe, but it can greatly improve the organization of this part of the code. And even without using a dependency injection framework, you can always forget a dependency and you will only see the error at runtime. So it is not bulletproof either. The second reason I created `sarulabs/di` is for the services that need to be created in each `http.Request`. In this case you have to instantiate the service inside the handler. I like my handlers to be short, but with this they can become more complicated. In the car api described in the post, I need to create a `CarManager`. The logger and the pool of connections can be defined as fields of the handler. But I would still need to `Copy` the connection from the pool of connections. I would also need to `Close` the connection at the end the request (forgetting to do this would cause trouble). If one day I had a service that uses three different databases, the code would becomes ugly. It is also more likely that there would be duplicated code. For example if the `CarManager` or the `CarRepository` are used in multiple handlers. In the end, the problem is the same as the one in the main file. But now it is in all the handlers. I tried many things, but using `sarulabs/di` is the most elegant solution I came up with.
Question is, why this doesnt work ahahaha, my code just crash when I call this, and thanks for the tip!
``` var newTodo *todo if err := rows.Scan(&amp;newTodo.ID, &amp;newTodo.NoteID, &amp;newTodo.Title, &amp;newTodo.Done); err != nil { return nil, err } ``` This is wrong. In this case newTodo is pointer and it is nil. And not only it is nil pointer, you then use &amp;newTodo.ID which in that case is then pointer to pointer, which is nil BTW. Try something like this: ``` var newTodo todo if err := rows.Scan(&amp;newTodo.ID, &amp;newTodo.NoteID, &amp;newTodo.Title, &amp;newTodo.Done); err != nil { return nil, err } ``` and make ```ToDo []*todo `json:"todo"```` to ```ToDo []todo `json:"todo"```` this is just by quick look, you might have other issues, but start with this one. And when your program crash it does report why it crashed, so submit the output of panic as well next time, it might help. ;) 
Yea I was thinking of removing that pointer form stuct "note", honestly I dont even remember why I did put it there :D .... Hmmm what do you mean panic ..I know what it does but I dont know how to use it here ??
https://gobyexample.com/panic
&gt; It is what I used to do. The Context approach is very similar. The only difference is that the handler depends on the whole Context, instead of depending only on the services it needs. I would not recommend this approach. You lose type safety and your dependency graph is unknown. All of your handlers now need to know how to construct their dependencies from a Context. Way simpler to just do simple DI. &gt; The problem begins when you add more services. Let's say 100 services. This part of code can grow quickly. How likely is this though? I have not worked on every project ever obviously but even if a project does have 100 services there should be some kind of broad "scope" to have some logical grouping. &gt; Splitting the creation of the services in different parts is difficult. Because the services depend on other services. Interfaces should alleviate that. &gt; And even without using a dependency injection framework, you can always forget a dependency and you will only see the error at runtime. Not in a statically typed language like Go. My function "NewFooService" takes 3 parameters, i cant "forget" to pass one in. Anyway It is often said the reason you need a framework to manage dependencies is because it becomes overly verbose otherwise. Typically the manual wiring up you have to do you'll write once and forget about it. But if you do come back to it, because it's plain Go code you'll be able to understand Secondly the justification is that dependencies become complicated. In my experience that usually points to a flawed design. The usual other reasons are they are superficially "easier". Less typing, etc etc. The problem is they usually also bring with them an extra layer of things to understand plus they usually lack type safety. I have worked on many projects, some very large and not once have I thought a DI framework would've improved things. Yes dependency trees have got complicated but that can be fixed by improving the design of the code and refactoring. Not laying on another thing on top of it all.
When program crashes, that is panic. You do get some output when it crash right? It looks like garbage but it contains some crucial info for finding the bug in your program.
You can handle the timeout in the handlers. Sometimes it makes more sense. 
Works great on same laptop with vagrant to set it up
Regex is NSFW
[https://www.youtube.com/watch?v=CB\_VfgwPmxQ&amp;t=1788s](https://www.youtube.com/watch?v=CB_VfgwPmxQ&amp;t=1788s) around minute 30 you have a great example of importance of timeouts
[removed]
In the book mentioned in the title, one learns to make gifs of [lissajous curves](https://en.wikipedia.org/wiki/Lissajous_curve). It's just an exercise to introduce some of the characteristics of Go. Pretty darn cool stuff. 
Now add some colors to it :)
They aren't in the same directory as the Go source files so I can't imagine Go would directly know about them. I have one cpp file in the root next to the Go files which includes all the cpp files from another directory. 
https://github.com/bnkamalesh/webgo Or you could try finding something from here too https://github.com/avelino/awesome-go
Beego is a framework that is popular in Asia
read wikipedia
so then the standard library has everything needed and you have decided to retract your question? cool.
&gt; then don‚Äôt worry about it. if I keep spawning a lot, wouldn't i run into memory issues?
&gt; or just let the scheduler do its thing. can you explain this bit? or by scheduler you mean Go runtime?
&gt; I think most of the time you probably don't really need a pool. But maybe you do want to limit the number of goroutines running at once. you know at first I thought, having a pool and limiting number of gorutines is same... then I kept thinking and realised the difference.
... Good luck getting your answer mate. Oh and read the Go documentation.
Very good points! Thank you very much!
Awesome feedback, thank you very much for taking the time. I did not know about goimports. Goland seems to have built in support! It just wasn't enabled. &gt; Third-party packages. I recommend this not for my own sake, but for your own education within the Go ecosystem. That's what I have read a lot while researching. My first goal was to get the project up and running. Now you just gave me the motivation to refactor out all the dependencies! &gt; I hope those were constructive comments - good luck with the rest of your journey into Go! They sure were, thanks again!
Thank you very much for your feedback! &gt; Missing README and not very verbose GoDoc. I'll definitely take a look at that. &gt; I think there's no need to read config manually and then decode it. You should be better using https://godoc.org/github.com/BurntSushi/toml#DecodeFile for this purpose. Good point! I must have overlooked that function.
&gt;I would not recommend this approach. You lose type safety and your dependency graph is unknown. All of your handlers now need to know how to construct their dependencies from a Context. Way simpler to just do simple DI. I do not think I was clear enough about the `Context`. The `Context` is not a `map[string]interface{}`, it is a structure. In your example it would be `type Context struct {HardcodedDependency: HardcodedDependency}`. Dependency injection happens when the `Context` is created, not when it used. You do not necessarily lose the type safety. &gt;How likely is this though? I have not worked on every project ever obviously but even if a project does have 100 services there should be some kind of broad "scope" to have some logical grouping. Concerning the number of services in an application, I checked a small personal project and I counted 43 services. For me a `Repository` is a service. So if you have 100 mysql tables, you already have your 100 services. I also have one main service by handler. In a big monolithic application, it is very likely that the number can increase even more. The number of services is linked to the number of structures in your application, so 100 is not that much. &gt;Interfaces should alleviate that. Interfaces have nothing to do with the creation of the services. Interfaces are useful in the business logic. Here we are talking about the creation of the services. It is at this moment that you bind the interfaces to a specific implementation. &gt;Not in a statically typed language like Go. My function "NewFooService" takes 3 parameters, i cant "forget" to pass one in. It is true if you have a `NewService` function. But some services do not require that if their dependencies are public: `repo := &amp;Repository{Mongo: mgoSession}` If you add a logger in the repository structure afterwards, you can still forget to add it in the initialization code. Even if it helps a lot, the type system does not guaranty that your code will not break at runtime. In go, the dependency injection frameworks are also plain go. There is no annotation like in java. The `Context` is already is dependency injection container. It is just that creating it does not require an external library. Dependency injection frameworks are like everything else (eg: the interface in your example), you should not use them if you do not need them. Stay away of anything that can bring complexity in your application as long as you can. And if your reach a point where you need more, it is not too late to change. Especially if it does not impact your business logic. I still disagree that dependency injection frameworks should be considered harmful in go. I think the arguments against them are similar to the ones against the ORMs, that are also controversial. It is true that they add complexity in your project. But at some point they may become beneficial. Go still lacks frameworks like django, rails or symfony that can bring more efficiency in small and large projects alike.
Thank you for taking the time and looking at the code! As someone who has no experience with programming languages that use pointers it's sometimes hard to decide whether or not to use one. I'll definitely check out the faq and try to simplify my code. Thank you!
Then my advice would be to comment in that issue and see what's best to do.
Russ makes some good points. Time will tell if he's right. I suspect he is
Looks like it isn't necessary to comment any further about it in that issue since they have already committed to the path of saying its not recommended to have non-go source files in subdirectories. So I will just end up changing the project layout to suit. 
Found used in this git ui tool that seems lovely: https://github.com/jesseduffield/lazygit ps: HN thread https://news.ycombinator.com/item?id=17689014
A goroutine allocates 2kib of stack-size initially. On 2gib you can spawn 2048mib * 1024 / 2kib ~ 1 million. So absolutely no problem unless the stack size of every goroutine growth.
A lot of context is missing. Did establishing a TCP connection succeed? How do you know? Do you ignore errors? Did you try using DROP instead of REJECT? Did the receiver receive anything? If you assume it doesn't, why? 
Just practice good hygiene on your functions, like cleaning up resources if necessary, and handling panic conditions to prevent leaks and you‚Äôll be fine. 
Thank you!
&gt; most of those cases want exponential backoff too When all you have is a hammer, every problem looks like a nail. Not all resource contention problems look like network requests. Case in point: mutex contention is a very common thing for which random jitter can do wonders. Just because you haven't encountered the problem doesn't mean it doesn't exist.
One more question I'd like to tack on: - did the other end receive the data?
I think you're confusing the source code (i.e.: the `.go` files) with the compiled binaries. Go is not like python/ruby/js in this respect. It's more like C. You write your code, compile it, and then run the resulting binary.
lissajous.go!!!
What is required to connect the gap? Higher floating point precision? Period with a better fit to the canvas width?
You should not use pointer variables if you plan to use the same variable in JSON. Here is a simple example which should help you understand the issue package main import ( "fmt" ) type note struct { ID int `json:"id"` UserID int `json:"userId"` Title string `json:"title"` Description string `json:"description"` Archived bool `json:"archived"` ToDo []todo `json:"todo"` } type noteP struct { ID int `json:"id"` UserID int `json:"userId"` Title string `json:"title"` Description string `json:"description"` Archived bool `json:"archived"` ToDo []*todo `json:"todo"` } type todo struct { ID int `json:"id"` NoteID int `json:"noteID"` Title string `json:"title"` Done bool `json:"done"` } func getNote() (note) { return note{1,1,"Note Title-1", "description-1", false, nil} } func getTodo() (todo) { return todo{1,1, "ToDo Title -1", false} } func getAllNotes() ([]note, error) { todos := []todo{}; var newTodo todo; newTodo = getTodo(); todos = append(todos, newTodo); notes := []note{}; var newNote note; newNote = getNote(); newNote.ToDo = todos; notes = append(notes, newNote); return notes, nil; } func getNotePointer(note_input *noteP) { note_input.ID = 1 note_input.UserID = 1 note_input.Title = "Note Title-1" note_input.Description = "description-1" note_input.Archived = false note_input.ToDo = nil } func getTodoPointer(todo_input *todo) { todo_input.ID = 1 todo_input.NoteID = 1 todo_input.Title = "ToDo Title -1" todo_input.Done = false } func getAllNotesPointer() ([]noteP, error) { todos := []*todo{}; //todos is array of type "address of a todo variable" var newTodo todo; //newTodo is a variable of type todo getTodoPointer(&amp;newTodo); //calling getTodoPointer with address of newTodo todos = append(todos, &amp;newTodo); //appending address of newTodo to todos notes := []noteP{}; //nores is array of noteP variables var newNote noteP; //newNote is a variable of type noteP getNotePointer(&amp;newNote); //calling getNotePointer with address of newNote newNote.ToDo = todos; //assigning todos to todo of notes notes = append(notes, newNote); //appending newNote to notes return notes, nil; } func main() { notes, err :=getAllNotes(); if err == nil { fmt.Println(notes) } notesP, err :=getAllNotesPointer(); if err == nil { fmt.Println(notesP) } }
**[Slowloris (computer security)](https://en.wikipedia.org/wiki/Slowloris_(computer_security))** &gt;Slowloris is a type of denial of service attack tool invented by Robert "RSnake" Hansen which allows a single machine to take down another machine's web server with minimal bandwidth and side effects on unrelated services and ports. [Image](https://upload.wikimedia.org/wikipedia/commons/b/b8/Slowloris_DDOS.png) ***** ^[About](https://www.reddit.com/user/ultimatewikibot/comments/90r969/about) ^| ^[Leave](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[me](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) ^[alone](https://reddit.com/message/compose?to=ultimatewikibot&amp;subject=Blacklist&amp;message=Me) 
Forgot to add the repo: https://bitbucket.org/dragosbudan/raveena/src/ If anyone has any pointers I would really appreciate it.
great, will do!
thank you!
I think it‚Äôs the first chapter. It gives you a broad view of the language.
It would help to stick "Amazon AWS" everywhere before the word "Lambda" ‚Äî both here and in the project's README file. The reasoning is simple: most folks familiar with computers take the term "lambda function" to mean [not what you appear to think it stands for](https://en.wikipedia.org/wiki/Lambda_function). Thanks.
What's the role of go in this project?
Building the process that sends input to the pi gpio, takes input from the controller, takes care of the various states the motors are in etc with go. Initially picked it for the cross compilation and one-file deployment, but I'm really impressed with the language as a whole now. Oh and it does not need any dependencies which comes in handy when you swap a corrupted sd with a fresh one.
Yeah I believe it has to do with the frequency and size of image. It has to be a certain fraction of the width. I could be wrong.
Im always thinking like i should do something with my raspberry, its just sitting there now, collecting dust
If its alright with you, id like to look through your source code because i honestly didnt know raspberries could be put up for this stuff, i thought it was more of a micro server
Yeah of course. The repo is posted in the first comment.
Nice job! You might want to take a look at [gobot.io](https://gobot.io) which could simplify things a lot since it will abstract the low level stuff (you will learn less too)
Generics are not the only thing differentiating Go from Java. The major one here is inheritance: Go doesn't have a class system, and it doesn't have inheritance. Neither are required for generics to work, but they're both critical parts of the Java enterprise abstraction nonsense. A good implementation of generics in go would not usher in a dark age of enterprise bullshit in go, unless go also added a lot of other features that nobody wants. 
That looks pretty neat! I'd like to make a CUI application at some point 
this probably won't help much in learning, but try this. Be careful on pointers etc... [https://play.golang.org/p/saCuYUMzLNx](https://play.golang.org/p/saCuYUMzLNx) took that from [https://blog.golang.org/laws-of-reflection](https://blog.golang.org/laws-of-reflection))
https://play.golang.org/p/pYei9H9AJg6 The problem is that you pass a reflect.Value to the function when recursing. Then it starts to print fields of reflect.Value instead. You might be tempted to have a simple fix to the code by changing it into field.Interface(). However, doing so will panic when accessing unexported fields. The appropriate approach is change the signature to only process reflect.Value and let the caller calls reflect.ValueOf. Note: the code ignores field3 because there is a continue in the if.
[removed]
This is a great book! I actually didn't finish it but read up to the last two chapters and which cover reflection and low level programming. 
He certainly has a good track record.
&gt;Generics are not the only thing differentiating Go from Java. Of course not. I never said otherwise, and that wasn't the point I was making either. &gt;The major one here is inheritance: Go doesn't have a class system, and it doesn't have inheritance. Neither are required for generics to work, but they're both critical parts of the Java enterprise abstraction nonsense. This is true, but enterprise software doesn't require that level of abstraction necesssrily. &gt;I don't agree that adding generics will clearly usher in a dark age of enterprise bullshit, because i think enterprise bullshit is the result of inheritance, not of generics. This should be obvious. &gt;A good implementation of generics in go could still respect the simplicity of the language, too. A big point here is that without an inheritance system, there's no need for type variance, which is the worst part of java generics, imo. Java inheritance whore mongoring represents a subhuman developer incapable of prioritizing business goals and hence producing brain damaged implementations of a feature request, all in the name of "maintainability". 
Same, and I even have 12 relays attached to it. I should get some really cheap lava lamps and then feed it CI result data or something. Or just play 1D game of life on them, every time somebody pushes a commit.
It doesn't look like you invalidate the cached results as you add new plugins, so the quick links on the right are kind of misleading. re2 seems pretty trivially DOSable. The results aren't sorted ... so it makes comparing search results very annoying. Might be nice to be able to get a diff. of two search results too.
0x00AF82B1
Sweet &lt;illegal_memloc&gt;
Thank you for taking the time to give feedback, I appreciate it. The whole front end is mostly just prototype at the moment while I try to get my head around what is valuable and what is not. You are right about the file viewer not being so useful as it only loads the latest version of files. Perhaps I could check on load and display a warning if there have been changes since the search. I thought RE2 was less prone to that than other forms of regex, but I am not very familiar with regex. Other than a few issues (like a lockup caused by competing mutexes a little earlier) I have not yet seen any problems with search length. Is there an easy method to make searches last a long time? The search page was a copy of how the currently used CLI tools generated a summary for convenience. I am working on a revamped search page now and your feedback is very useful. The current summary does make it very difficult to view the actual matches and I love your suggestion about diff's between searches too, I had considered a type of repeating search which might have fulfilled a similar function. This has given me a lot to consider, thank you again for the feedback.
Wrong subreddit?
Heya, I've done this before /w a friend, here's our repo: https://github.com/vnemes/BLECar
go get uses git, so you can just clone the repository from everywhere and use git pull in later stages for updating package. For example, clone package from bitbucket: ``` mkdir ~/src/myproject/pkg-name cd ~/src/myproject/pkg-name git clone git@bitbucket.org:mileusna/mypackage.git ``` and later, for updating package ``` cd ~/src/myproject/pkg-name git pull ``` and in code you use it like ``` import ( "myproject/pkg-name" ) But if you are going to share the code with teammates you should made agreement on directory structure. I like using domain names for directory names, just like go get does, but I use my own domains for projects, since the projects are usually associated with some domain, like ```mydomain.com/pkg-name```. That also helps distinguish my own packages from standard library like "net/http" etc. 
Very cool! I'll look at integrating with this. I'm going to use a wireless controller until I get to actually build the car.
Retropie is always a good go-to project. 
Thanks for sharing. Always curious what people are using go for. 
I've taken some heat here on /r/golang a couple of times in the past couple of weeks for daring to suggest that Go is not likely to ever be as fast as C++ is, or Rust will be. Stuff like this is why. Choices were made to favor certain simplicities over performance. That is fine. But when those choices are made, the result will because catch up to the languages that chose to work for speed. For what Go is, it is quite fast. I use it in many situations where I would not use Python or something. But it will never be the fastest, or at least, not without major changes 
Also have a look at the DeepEqual implementation, or start reading through the JSON encoder/decoder. They may appear complicated, and, well, they are, but once you start using reflection, that's what you end up with. As you get into it, those functions will start to make more sense, as you encounter the problems and start to understand the solutions.
I don't think that's 100% true. The server can be starved of input during the headers. Past of the point of these timeouts is to prevent the slowloris attack. (Google if you have not heard of that.)
I mean, it's garbage collected. Of course it will never be as fast. Don't let the heat get you down!
master: `func NewV4() (UUID, error)` v1.2.0: `func NewV4() UUID` v1.1.0: `func NewV4() UUID` v1.0.0: `func NewV4() UUID` Make vgo use master version. Haven't used vgo before so can't help there.
Check the mod file about which version your code is using. Base on github src code v1.2.0 returns only UUID, however \_master\_ branch UUID and error for NewV4. also in context of uuid package consider of reading this thread: [https://www.reddit.com/r/golang/comments/934xzi/keeping\_important\_go\_packages\_alive\_announcing/](https://www.reddit.com/r/golang/comments/934xzi/keeping_important_go_packages_alive_announcing/) as there is risk that satori is not maintaining his lib any more. 
Quote from link I just shared: &gt;(...) (about the fork) The decision was made to do a major version bump from v1.2.0 to v2.0.0 as breaking API changes had been made in the master branch of the upstream project after the v1.2.0 release. Please see our v2.0.0 release notes for more details. 
http://blog.campoy.cat/2014/03/github-and-go-forking-pull-requests-and.html
Thanks, i've screwed up because of unexported fields. I'm working on struct validator(for frontend requests etc) and all fields are supposed to be exported(because of \`json\`). I just need to comment on the function that any unexported field will panic.
I am not sure, but is there a community expectation that Go would be as fast or faster than C, C++ or Rust? I thought most Gophers were content with having simplicity over performance? 
This is really cool man. One project idea I wish I had thought of to learn more about Go. Seems like it would have been really fun to build. Nice work 
What are you loving exactly
since the dawn of Go times, various talks quoted "performances should be within 10% of C" (meaning +/- 10% within that of C, of course.) see: - https://talks.golang.org/2009/go_talk-20091030.pdf (p37) so there is some expectation that Go performances should be closer to C than closer to Python :)
Cross compilation, one file deployment, duck typing, go routines and channels to name a few things.
yes, indeed! 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/gin-gonic/gin) - Previous text "gin" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
To be fair. If function call overhead becomes a performance problem, solution is not to make it faster, but to remove it. Which is inlining, which is not that great in Go. But whatever, I think Go's performance is decent.
Treat the jobs as REST resources. For example: POST /jobs creates job GET /jobs/123 returns information about job DELETE /jobs/123 deletes job and releases resources. You can cancel a goroutine by giving it a "cancel" channel (or via context) that you check for closure ever so often (commonly in a for .. select loop).
thanks for the reply, but I still cant wrap the idea of how to cancel the job using Id. I mean how do I keep track and pass the id to the goroutines to stop them. 
You can control a goroutine from the outside and there are a few ways to handle this. 1. Use a channel to signal the goroutine to quit. https://medium.com/@matryer/stopping-goroutines-golang-1bf28799c1cb 2. Use context: https://blog.golang.org/context 
1. Before spawning a goroutine to perform a job with ID `N` you create a channel which you pass to that goroutine. 2. After spawning that goroutine, you put _its_ channel into a (shared) map keyed by the job ID `N`. 3. When a cancel request comes in, you extract the job ID supplied in it, look up the associated channel in that map, and `close()` it. 4. The goroutine performing the job has to somehow "poll" the supplied cancellation channel for it having transitioned to the signaled state. How exactly to do that, depends on what the goroutine really does. In the simplest case, this might amount to periodically performing a non-blocking read from that channel, like in select { case &lt;-cancelChan: return // Exit processing default: // Do nothing, get back to doing // another round of job. } ---- Since this approach is particularly useful, the concept of "context" was born, and then was [included into the standard libarary](https://golang.org/pkg/context/). The upside of relying on context for cancellation instead of hand-crafting a solution is two-fold: - Contexts implement "cancellation trees" by being able to derive child contexts from parent context‚Äîwith cancelling the parent one resulting in propagation of the cancellation signal down through the children (and all the way down‚Äîto the "leaf" contexts). - Many parts of the standard library have context-aware API, so basically they are ready to be cancelled w/o any additional work. In particular, stuff in `database/sql` and `net/http` is context-aware, so you're able to easily cancel in-flight queries to RDBMSes, client HTTP connections and on. 
That's right and that's why there is a timeout just for the header. You set the timeout for the header and handle the rest in the handler
What you looking for is: [https://godoc.org/path/filepath](https://godoc.org/path/filepath) from a standard library. &gt;Package filepath implements utility routines for manipulating filename paths in a way compatible with the target operating system-defined file paths.
also if you are not troubled with extra dependency: [https://github.com/mitchellh/go-homedir](https://github.com/mitchellh/go-homedir) (or just copy-paste something like this). 
No, that's not it. I know the how, I'm looking for the where. with Unix systems you use the \~/.config folder in the users directory. I want to know the windows equivalent of \~/.config.
Golang is ideal for distributed systems for the following reasons: - ability to send messages from a goroutine on one node to another one on another node without having to install a third-party package or deal with *how* it is done; it's mostly transparent - a goroutine can't block an whole OS thread, if it goes over its allotted "budget" it is switched for another goroutine - each goroutine is garbage-collected separately; combined with the previous point, this allows for the system to maintain very low latency even under high load, when "stop the world" gc will begin to raise latency - it comes with a whole framework for easily creating distributed and fault-tolerant systems; you don't have to write your own restart logic of long running goroutines with backoff, limit no restarts, etc., golang already has a module for that! It is common to have goroutines organized in a tree. - excellent logging support; you don't need to bother with manually logging everything just in case there's an error, there's already a module for that that will give you very detailed reports about which goroutines needed to be restarted and where the error happened - if you're ready to work for it because you want very high uptime, golang's framework for writing distributed and fault tolerant systems comes with a system of releases that allows you load new code while the application is running, convert the data structures to their new format (you have to write that yourself of course, it's not magic), and even rollback updates that fail (you also have to write code to ensure this goes well). - a small but very technical, mostly hype-less community that's full of very experienced people Erlang, while touted by its younger and less experienced fans as a mature language and platform to write distributed systems, isn't coming close to any of these points, and it's unlikely to change. Don't waste your time on this language.
I think this is gonna be one of those situations where the old adage, "The best programming language is the one you know," really shines. All the options you've posted are modern, powerful languages. Each of them will probably be able to attack the problem with more or less the same amount of support behind their solutions. I think that things like personal preference, QOL features (Dealing with a Gradle file vs Go Build), and the design philosophies (functional for elixir+scala, imperative for Go) of the languages are going to be bigger than a direct comparison if "what is best for my use-case"?
I did this recently although did not implement stop functionality which wouldn't be too hard. I started with a JobQueue struct with a field jobs which was an array of *Job structs. You can Add a *Job to the jobqueue which assigns an id of `len(jq.jobs)+1` to the job that was given. The job has a status. When telling the jobqueue to run it loops for a new job with status of pending and calls run on that job (this could be a goroutine) The Job struct handles the running by calling a callback field called work. I used a factory method for each different kind of job I needed each which populated the work callback with the things I wanted to do. I didnt care about stopping, but you could add a stopchan to the job struct.
The ecosystem is getting bigger with go and distributed systems, projects like ethereum and ipfs are written in go. concurrency is a first class member in go (but erlang/elixir might have that too), no significant advantage other than that. If you understand distributed systems deeply you would probably get it done well in either language.
While I do agree that Go is a great choice for distributed systems, I think this comment is somewhat disingenuous. * If you want to send messages between physically different nodes you \*\*do\*\* need to use a package (otherwise how does the system know which nodes are available?) * If you meant sending messages to other gogroutines within the same node, Java and Erlang can both do something similar. * Erlang can hot-reload code. Not sure about Java and didn't know you could do this with Go. * Sure you don't have to run your own "restart" logic for goroutines, but in a distributed system that is not the issue. You \*\*do\*\* need to write your own backoff logic, etc. for nodes within your system. I think you are conflating goroutines with nodes in a system. A system consisting of 1,000 goroutines on a single node is very different from a system consisting of 1,000 nodes each using zero goroutines. The latter is a distributed system, the former is just a program that uses concurrency. Like /u/theghostofm says, pick the language you know. These are all great options. I personally would pick Go because it is easy to learn and is growing in popularity. A large number of modern distributed systems use Go.
This looks great! I guess I'll see how well it runs in a Cloud9 terminal panel.
Yes, only grv is developed entirely in Go. I'm using mostly in case i need to make diff-s.
Seriously, one nanosecond difference is peanuts. One would need a billion of such operations to see an execution time difference of one second. Go is fast enough for now. It's good to know we could shave a nanosecond here and there, but I won't loose my sleep on this. I recently rewrote a Go routine in assembly to make it faster. It became 33% faster. Instead of 3 ns it took 2 ns. I first pestered the Go compiler to be so inefficient because it wasn't that hard to get the speed optimization. But then, when you step back and look at the picture in its entirety, you understand that no one would see the milliseconds of execution time I saved. The application domains where speed is so critical is very small. It's the same early debate between Unix job control and JCL of the IBM operation system. The unix job control system was much much simpler than the JCL. It covered 80% of the needs. The JCL was powerful and allowed fine grained control of jobs but it was so complex that people would only use 10% of it. They would just copy and reuse the recipe that worked. The end of the story is that unix won. The rule to retain is that simplicity is trump. Using registers to pass results is still possible as an optimization. For now Go has more urgent and important wars to win. E.g. generics.
As others have said you can't "kill" a goroutine but you can tell it to stop using channels or context. To coordinate between the server endpoints you can create a global map. Here's an actual example doing what you describe using `context.WithCancel`. https://gist.github.com/montanaflynn/020e75c6605dbe2c726e410020a7a974 You can test it by running the server and then using cURL from another terminal: curl "localhost:8080/start?id=1" curl "localhost:8080/start?id=2" curl "localhost:8080/stop?id=1" In the server terminal you should see the following: Doing job id 1 Doing job id 2 Doing job id 1 Doing job id 2 Cancelling job id 1 Doing job id 2 Doing job id 2
You can either do this: var foo [16]byte = [...]byte { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } or this (nicer) var foo = [...]byte { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }
FooArr := []byte{ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }
I am not sure which library OP is talking about by I usually use the logrus logging library
Thanks!
You seem to have animosity against Erlamg programmers.
This is purely my opinion... From a development flow, the nicest thing is its simplicity. There is no extra fluff in the language which makes it really easy to come up to speed quickly on, and the language is very fast. Scala is on the other end of the spectrum. I really like Scala, but the learning curve is pretty steep. The other big thing for me is the operational simplicity. Compiling to window/linux/osx as a statically linked binary is amazing. It makes a fun workflow where I can build a program on my mac and rsync to a server and it works the same without configuration. 
Java can hot reload code (have not personally done it, but know it's doable, also in Scala). And for distributed systems, Erlang is what I'd do if I started freely from scratch and no pressure. Since it's not the case, I use Akka (an actor library/framework) over Scala. Passing from local Akka to distributed Akka is 'relatively' easy, and since it's a whole actor system you carry around you can basically work with backoff, backpressure, monitoring actors/roots and all that without much additional work. I'd only use Go either if I had a library that added some of these bits (retries/acks probably would be the most painful/needed) or if the system was relatively easy to understand and implement "in one go, in go". Once you hit the network, message latency, delivery guarantees and all that can quickly blow in your face, and although using actors doesn't fix that, the way you design distributed code with actors takes it into account when you follow standard practices.
Actually I made a shitpost by listing erlang's advantages as if they were go's, and the reporting library I was thinking of is actually the [SASL application](http://erlang.org/doc/man/sasl_app.html).
Go sounds like a good option, but already know erlang/elixir. The main reason I was thinking about switching is because I erlang doesn't have all the libraries I want, while go and java do. I think I'll just stick with that I know. Thanks for the help
To do that check /u/macpla's comment. https://github.com/mitchellh/go-homedir does exactly that.
OpenCV uses bitwise operators applicable to images, for example, e.g. [this](https://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#bitwise-and). Looks like a charm and is really useful.
I‚Äôve been using Uber‚Äôs zap library for a while and I like it better than logrus (which, don‚Äôt get me wrong, is a fine library). 
The comment is not disingenuous per se... it's satirical. Those are advantages of Erlang over Go, not advantages of Go over Erlang. It is written as if Go is the one that had those features rather than Erlang. It seems to have not gone over well. But if you unwrap the satire, it is accurate.
Depending on what libraries you're talking about, you might not need to switch. For example, if you want to implement JWT in limited scope, you don't need whatever is the go package for it, it should be done in a few pages of code (even Erlang code). Definitely stick to what you know, if it's some small library that can be reimplemented or partially implemented to suit your use case. Erlang isn't a bad language for distributed / HA systems.
If you're feeling a bit saucy, I've implemented [basic supervision](https://github.com/thejerf/suture) and [Erlang-like message passing](https://github.com/thejerf/reign) in Go. The former at this point is fairly well tested, and despite not having as many features as the Erlang supervisors, people seem generally not to miss the features. The latter is used in a production product, but is certainly less well tested out of that particular context and likely to be missing some features. (It probably has bugs too, but the production deployment running it has at least squeezed out the worst cases of bugs.) The intent of this suite is to make it relatively easy to port Erlang code into Go. Whether it's a good idea for an Erlang programmer to use this to work in Go without having to change mindset... well... that's a much more complicated problem.
The static linked library thing usually isn't true as soon as you're using CGO libraries. From the top of my hand, at least mysql (one version of it?) and sqlite are like that, possibly others as well. If you rely on the stdlib, that's not an issue, but usually people go outside of it pretty quick when it comes to various clients/libraries that just have a CGO bridge.
For the Mac, ~/Library/Preferences (or ~/Library/Application Support/YourApp) might be preferable.
he is trolling, his comment is about Erlang, not Go
Thanks, I did not know about cross compilation issues when using os/user.
I've got [an article about struct reflection](http://lpar.ath0.com/2016/04/20/reflection-go-modifying-struct-values/) that you might find useful.
You don‚Äòt get it do you? 
True sometimes, but in many cases it's still easy to keep stuff cgo-free. E.g. Prometheus (which is a pretty huge code base with many dependencies) looks like this when built using normal `go build`, only depending on libc and the like: $ ldd prometheus linux-vdso.so.1 =&gt; (0x00007fff8879b000) libpthread.so.0 =&gt; /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f44047c5000) libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f44043fb000) /lib64/ld-linux-x86-64.so.2 (0x00007f44049e2000) And when using the official build system's binaries, it's completely static: ldd prometheus not a dynamic executable
It'd say "Compilation time is effectively free *unless* you're Google and have dedicated build servers" because common application won't be higher than several thousands sloc and you have your dependencies precompiled (that's true at least for Rust). So it's kinda free lunch (almost). On the other hand, if you're google than heuristic that your app it not 10M lines of code doesn't work and then you're in trouble.