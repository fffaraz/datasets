A member of the go team put this together to demonstrate how go works with multiple routines/processes. You might find it helpful. https://github.com/nf/goto
IMHO you shouldn't do this now that HTTP/2 is out, many files are what you want now.
the &amp; gt; in your blockquotes isnt working -- and unfortunately its on the most important line the channel read and write: ch &lt;- data
Thanks! Actually all the non alphabet non numerical characters were encoded. I guess that happened, when I last updated my post on my mobile and had a bad internet connection. So could not verify that all was good. Thanks again for pointing out. I have fixed it.
Thank you so much! I'm going to try to PoC this over the next couple days. Mind if I ping you if I run into any odd issues? I figure I'll have a few since i've only been digging into Go for 3 days lol.
would you care to publish the code for that struct and methods?
Not sure of Rust advantage but so far Rust does not offer an http client/ server implementation. TLS is still further away. Rust preferred way is to use existing C/C++ libs binding. IMO Rust is at 3-5 of years away for general users who want to write business / application software as oppose to systems software..
As Ignacio Grande noted in Change 3430, a lot of the perf gain was due to not using defer. Adjusted testcase showing the difference: $ go test -bench . testing: warning: no tests to run PASS BenchmarkSync 10000000 227 ns/op BenchmarkSync2 30000000 59.0 ns/op BenchmarkAtomic 100000000 12.4 ns/op ok blah 5.582s package blah import ( "sync" "sync/atomic" "testing" ) type Int struct { mu sync.RWMutex i int64 } func (v *Int) Add(delta int64) { v.mu.Lock() defer v.mu.Unlock() v.i += delta } func (v *Int) Add2(delta int64) { v.mu.Lock() v.i += delta v.mu.Unlock() } type AtomicInt struct { i int64 } func (v *AtomicInt) Add(delta int64) { atomic.AddInt64(&amp;v.i, delta) } func BenchmarkSync(b *testing.B) { s := new(Int) for i := 0; i &lt; b.N; i++ { s.Add(1) } } func BenchmarkSync2(b *testing.B) { s := new(Int) for i := 0; i &lt; b.N; i++ { s.Add2(1) } } func BenchmarkAtomic(b *testing.B) { s := new(AtomicInt) for i := 0; i &lt; b.N; i++ { s.Add(1) } } 
I don't use gdb to debug my go programs. I just use print statements. I think that you may be in over your head when trying to convert a dotnet shop over to Go. I've tried at my work and the problem is deeper than just the IDE. Dotnet programmers want their hands held for them. They want frameworks that do the job for them. They want templates that scaffold most of their app for them. Go is the do it yourself language. Your task requires you to take your team of programmers and put them in a position to be uncomfortable. Best of luck.
I started my professional career and used C# for about 10 years straight. I then switched over to Obj-C, Ruby, Node, and now I'm doing a lot of Go. Of the three languages besides Obj-C, debugging support is limited if not non-existent (better_errors in Ruby rocks though). I was initially of the mind that I couldn't work without a debugger and breakpoints, but honestly, once you learn print tricks you start to get past it. I've also worked as a consultant to transition teams to new languages, and as soon as the team starts seeing the benefits of the language they get past the debugging and lack of an IDE. The key is that there has to be enough value in the language change - don't just do it to do it otherwise you will constantly run into the "We could have fixed this x hours ago in y language." To answer your question directly, for the Go code I have in production I log pretty much everywhere. It's fairly easy to find the issue when you have coherent and comprehensive logs. 
The flie cli.go should go in your main package.
I would think this way too.
I'll take it one step further: The Go language itself, let alone the core library or lack of IDE support, will punish these developers. .Net languages like C# provide an enormous amount of capability in the language itself by being aggressively multi-paradigm. In one grammar, there's functional, procedural, object oriented w/generics, and set-theory based (LINQ) paradigms. Go, on the other hand, is deliberately minimalist. You get structs, interfaces, and functions, with some nice things thrown in like 'range', user-defined types, maps, and slices. You are routinely discouraged by trying to author something that is anything other than Go's brand of procedural composition. But that's a good thing since it means the result is simple, straightforward, and likely correct.
Generally, I think that dotnet has trained its developers to follow the path to the point that straying from the path becomes such a difficulty in understanding the guts of the framework that its just not worth it to diverge. Having full control over your application code is a scary thing to a lot of my coworkers. They do not like Go or even writing raw javascript. They need the structure or they suddenly forget how to program. I believe this to be a psychological dependency that is created by following frameworks too often. edit: s/dottiness/dotnet
Dropbox has a pretty nice idea on how to do error messages: https://github.com/dropbox/godropbox/blob/master/errors/errors.go And here's my take using their approach but modifying it to fit my taste: https://github.com/alexkappa/errors 
What drew me to Go originally is how real my coding experience feels. Go is like writing C code with a powerful standard library. C#, especially in writing web servers, feels like I'm traversing a big class hierarchy and filling in the blanks. It's almost as if I'm programming a school project. If I need to stray from the path, I end up writing more code than if I just did it the Go way and wrote it myself. Try to program your own auth provider in C#. It's a huge pain. C# die hards will tell you to just download and use someone else's library. Go enthusiasts would point you to third party libraries and explain the concerns of authentication. You can actually discuss the pros and cons of different architectures instead of trying to put puzzle pieces in place. Go is like writing simple, isolated, imperative pieces that make up your algorithm or business logic. It is simple to grasp, which makes the big picture also simple to grasp. It reminds me of Rob Pike's book on Unix, which converted me to become a Linux user. Go is the embodiment of the Unix philosophy of making simple isolated pieces that do their job well. 
I would love to comment to each and every one of you, but I will make this comment global (to my post) to address most everyone I didn't comment to directly. Printing has never been a "bad" solution to debugging to me, oftentimes (in my experience as an iOS developer) I preferred a custom logging utility with a file and line number inclusion over break points for speed. Instead running the program, stopping at the breakpoint, inspecting the information I would just print that data where I needed to see it, run the program - let it crash (if that's what it was doing) and then return to the editor logs and make the fixes as necessary. I don't really see more use of the debugger to speed that process any significant amount. That's not say I didn't use the debugger, occasionally I would but it was rarely used over, what I would call, "better logging." I, personally, see a mixture of printing and better test coverage as a very decent replacement for the lack of debugging utilities and I don't really see the lack of GDB support (or similar tools) as a downside to the language. I've already started using Go personally with tools that I write, even rewriting tools I've written in other languages like Ruby (mostly for learning). I thank everyone for the information provided so far!
&gt; C# die hards will tell you to just download and use someone else's library. Go enthusiasts would point you to third party libraries and explain the concerns of authentication. I think ruby is fairly similar to C# in that regard. Though i think Go will likely get to that level eventually, as it ages and people collaborate on good projects &amp; modules.
I'm not sure, and it depends on how much you want to manage. I know you can do things like "exit after 15 seconds", but I haven't heard of being able to say "only use 10% of CPU".
All of my debugging is done with various print statements. With that said, debugging implies there is already a bug. I know 'dont write bugs' is obviously bad advice for several reasons, but what is good advice is this: Start small and stay small. Don't get into a giant monolithic app that is too complex for its own good, start with modules that do all of the 'hard work' of your app. These modules are easy to debug and easy to keep bug free by making sure you have good test coverage. Once you've verified all of the components of your app work with proper test scripts, the rest of your app becomes simple glue code of putting it all together. That code is now much easier to understand, and has much less need for debugging -- at this point you'll find that just the occasional printf("%+v\n", variable) will often tell you exactly why what you're doing isnt working. I do hope delve gets better and becomes something I routinely use in my workflow, but frankly I'm not missing debugging nearly as much as I thought I would. 
In my experience with Ruby I found that, while gems are recommended over architecting your own solutions, third party choices were less specific. The most common that I've used across all the projects I built was devise and cancan (now cancancan). Devise is authentication but is built so it can be modified easily, even the views can be changed quickly. And cancan simply provides a mean for you to define access privileges and verify those privileges, and the only predefined usage is how you define those privileges, not what method you use internally to decide those privileges. Basically, I found the ruby community to provide libraries that were more like libraries should be written - and that is they do one small thing and they do just that, which lives alterations to that process very simple to architect.
In almost any language I use, I try to order the functions/methods like a text that can be read. First the more important function, then the functions called in the previous one, etc... If I have some more generic helper function I may place it after the first one that calls it or in the end of the file. This may depend on how important is that function. The order of the tests doesn't matter in my opinion. I find myself writing some test before writing code, and then adding more tests after the code is all written up. This results in tests a single piece of the code in more than on Test functions - in more than one places in the test file. This can be a problem only if you need to change the tests, but if you refactor so much that you need to change your tests - they have served their purpose and should be removed and rewritten. Someone pointed out about the errors, but here are my 2 cents: * If you will handle the error in your package - a simple string is fine. * If there is a change that the error will get out of your package - adding a prefix (package name) may help. * Adding some more context about the error (specific error struct with more information) may be more useful than a prefix in the message - then you can add function name, even file name/ line number if you fell like it. * I still prefer simple messages for most cases, Tracking it should not be hard in Go, just because the way the error handling is done.
&gt; Dotnet programmers want their hands held for them. That's total and complete bullshit. Using a modern IDE with an integrated debugger is not "handholding", you're wasting your own and your employers time by litering your code with print statements. Print statements are not a good way to debug anything other than the most trivial of software. 
Agreed. I recall some very tricky bugs in our software where only going slowly through the debugger and evaluating the state of many variables were we able to pinpoint it. Having only print statements would have made this task much harder.
I really don't understand why people are down on debuggers. No one who has been doing this for long will be impressed that you work in notepad or whatever, you're wasting time and money when you refuse to use superior tools for god only knows what reason. 
I'm not sure if your 3rd party developers would go for this, but a safe way to do this might be to use JavaScript. See https://github.com/robertkrimen/otto This project would basically let your 3rd party developers write plugin code in javascript, with appropriate calls to your API, while at the same time being entirely isolated. It's worth checking out.
I couldn't agree more. I am a C# developer by day and a Go developer by night, and they both have their places. You are 100% on-point with print statements being an incredibly-crappy way to debug anything. There is simply no more effective and productive a way to identify a bug than to look for it in Visual Studio's debugger. Just brilliant. 
Idiomatic is to name error *values* `Err…` (i.e. `ErrReadHeader = errors.New(…)`) and to name error *types* `…Error` (i.e. `type MyPackageError …`).
Don't use gdb, [it's known](https://golang.org/doc/gdb) to not work with Go. After POCing, don't use print statements, use the builtin [log package](http://godoc.org/log) or [debug build flags](http://dave.cheney.net/2014/09/28/using-build-to-switch-between-debug-and-release).
Anytime anything sits outside of someones comfort zone, they are uneasy with it. I have no issues using a debugger, or print debugging, or writing out the code and stepping it through it manually. They all work, and they all work for different problems. Sometimes I don't care to step through every line to find out where one value is incorrect when I can print it at the exact point it's not accurate and see it's value. This alone has generally been sufficient for me to track back to where the error happens. Sometimes it's not, when it doesn't I use a debugger and step through from where it's correct to find where the value is distorted. So, in the ideal world I should be able to debug with a tool and by printing - but Go (at the moment) is obviously not part of this ideal world. So whether debuggers are superior to print debugging is a completely irrelevant discussion (and opinion based*) to the question at hand. * Quick side question, since this topic is being addressed. Why does it matter what method of debugging someone chooses to use? If I print debug and you use a debugger and we can fix issues at the same speed? Who really cares? Most issues with print debugging come from poorly handled print debugging utilities supplied and not educating developers making the mistakes. These are problems with obvious (and simple) solutions; however, the lack of debugging tools for many languages that are actively used is a problem without an easy solution - both methods are valid. Use the one you're fasted with.
Yeah that's fair. For me, i think i just haven't needed something that extensive.
If you really feel that way, you can use GDB. You can then do step through debugging and inspect many variables. It works. The issue, so I'm told, is when you have GOMAXPROCS set to more than one, it does not handle things well. The issue that I have had with GDB is when using many go routines, there is no good way of debugging them. I have read that the Go team is working on a better debugger for 1.5. They usually deliver on their promises. 
So the go implementation for google app engine does some pretty tricky stuff which sounds very similar to what you're talking about. Check out the talk that was given at gophercon last year: http://confreaks.tv/videos/gophercon2014-gophers-on-a-plane-the-story-of-go-on-app-engine This is also similar to what backs the go playground (a NaCL sandbox). Unfortunately it's probably not going to be easy to implement, since it looks like they actually modified the go source code to make a purely single-threaded implementation.
I'm interested to know where you read that. Their defense for poor GDB support is that it's not in their interests to work on debugging capabilities (unless they are adding something to the go toolchain). I would be interested if you could potentially find that article.
Serious question here: If my project is BSD licensed, but i `go get` some dependencies that are GPL3 licensed, what does that do to my project license when I push the whole mess (plus vendored deps) back to github?
&gt; I personally do Windows development in a VM on OS X and 90% of the other things I do I do from command line or via a simple text editor (Sublime Text, personally). *slow clap*
I haven't seen any standardized way to do this, but I usually put all of my public (uppercase) functionality at the top and leave all of my private (lowercase) functionality at the bottom. I then order my public code either alphabetically or from most to least important. I've personally found sorting alphabetically to be the most useful, especially if you have a lot of documentation. It makes it *so* much easier to look through the package's godocs.
Right, but that swings my project over to being GPL licensed, which is what I'm afraid of. It would appear that this is a situation that the whole vendoring approach isn't capable of resolving directly. I suppose I could break my software down into vendored silos of GPL and BSD/MIT software, then require `go get` to pull those down. Is anyone doing this?
I thought the type of linking is the decisive factor for FOSS license compatibility questions.
This looks super cool. I am going to try this tomorrow. Recently I was writing some Go code on Mac. I had to scp to linux VM and compile so I can give build to QA which is linux env. Now I should be able make an executable on Mac that can run on linux. I mainly work in Java and it makes big deal of 'write once run anywhere'. It is amazing Go delivered such a great feature with little fuss.
[AEAD](http://golang.org/pkg/crypto/cipher/#AEAD) interface and [NewGCM](http://golang.org/pkg/crypto/cipher/#NewGCM) constructor provide the same API. Besides, it is in the standard library and not a third-party package like NaCl.
This "might" be an issue but it has never effected tooling in anyway...
I didn't think it was legally decided that LGPL would be in force for statically compiled binaries. That it could be interpreted either way and hasn't been tested as of yet.
On a purely technical level, I don't like how the GPL and LGPL licenses really deeply assume C-style linking in their text. My personal opinion is that you should never use either unless you're putting out a C or C++ codebase. Again, let me emphasize, purely technical, not political. Go check out the text and you'll see what I mean. So I'd suggest that it could be worth asking the original author if LGPL is _really_ how they meant to license their Go codebase. It may be the case that they would be willing to clarify what they mean. Which may still be copyleft in the end, but at least it might be more clearly so.
Most of the times prints are enough, because of the language simplicity, but when they are not you are pretty much screwed.
I feel like you misunderstood my point. I had nothing to say about why anyone was making any decision. The goal of my post there was to say that so long as someone were to be productive in either scenario what difference it made overall. This discussion was turning into a debugger vs print debugging, which i interjected by trying to say it doesn't matter. I use print debugging very effectively. I can't say that it's slow. I use fm debugging tools the same speed. Either way the program has to et to the appropriate spot and either way I'm going to inspect the code as it is whether that be what was printed or what I told the debugger to print when it got there. Yea, that's specific to me, and everyone is different but ultimate I don't care which someone thinks is better. I asked what tools people used, a very non-subjective question. I didn't ask I for the merits of one vs the other. 
This. I've built a few things on GAE using Go, and the only library I've used across multiple projects was Gorilla Mux for simpler routing and easy URL variables/slugs (e.g. `/api/search/{query}`). The [encoding/json](http://godoc.org/pkg/encoding/json) package has a [NewEncoder](http://godoc.org/encoding/json#NewEncoder) method that writes a struct or map equivalent object to an io.Writer. With this, you can have a variable of type `map[string]interface{}` for your API response that you populate. Then write that variable in proper format to your http.ResponseWriter. For instance: data := map[string]interface{}{ "field1": 12, "anotherField": "test", "results": map[string]interface{}{ "nestedField": [2.0, 1.4, 2.1], "anotherNestedField": "anotherTest", }, } json.NewEncoder(w).Encode(data)
If by they you mean the golang team I believe they are. Another article posted in this thread makes reference to it. In the mean time there is delve, which I linked to my original question. 
I agree with you.There are ide lovers and editor lovers.Choose handy tools for you to get the shit down.Java world have powerful ides(intellij idea) but the editor support is so poor(and c# is heavily rely on the visual studio monster).Go has good editor support(gosublime,vim-go and official command toolchains),but why not be more friendly to ide support either?Dart is doing right things(dart editor,intellij-dart plugin, dart analyzer,dart formatter(just like gofmt),vm debugger and standalone command-line debugger,etc). Both ide users and editor users will be happy.
TBH I'm pretty new to go as well, but 've used the cgo module to expose some low level libc functionality (getting a fd and passing it to isatty()). Initially it sounded like passing an fd over a UNIX domain socket would be a quick and easy solution to the problems you're having in your app. However it starts to sound like I've dragged in a new module and a whole new language! Perhaps not the best approach. For me C is no big deal and it's easy to reach for this type of thing. If it isn't for you it may be just complicating things. If you're really interested I'd try to write up a simple example. Edit: Right as I submitted I realized I wasn't even sure if the "net" module would support UNIX domain sockets. I looked and it turns out it does. Hey, at least you don't have to get down and dirty with cgo ;)
My debugger replacements for Go: * Thinking hard about the code I write - and about the code I just wrote. * Writing unit tests. (I love [goconvey](https://github.com/smartystreets/goconvey) for easy test writing and immediate feedback each time I save a file.) * Dumping data (using [go-spew](https://github.com/davecgh/go-spew)). Did I miss a debugger so far? No, at least not for the small pieces of code I wrote so far. If Go gets a debugger, will I use it? Definitely, but only if absolutely necessary.
My understanding is that the FSF sees the central compromise of the LGPL as you get to use LGPL'd code in a not-GPL/LGPL-licensed work, but must allow the user a feasible means to replace the LGPL'd component with their own version, which excludes static linking in non-GPL/LGPL works. As far as if it has held up or will hold up in court, I have no idea. But I do think I have the intent correct.
Ah, never mind then. Both the (FSF's interpretation of the) GPL's claims about other source becoming a derivative work and speculation about how they'd actually hold up both confuse the hell out me. Much as I'm annoyed that ZFS will never be mainline, the CDDL's file-based claims seem a lot clearer.
The Invasion of Normandy was still an invasion.
&gt; You might want to write more idiomatic Go with respect to your variable names. It looks very Java-like with verbose "facebookUserDetailsChan" variables. Yeah I completely agree. I would try to be more terse with my variable names. Thanks!
Remember that it could always have been worse. 
Copying all dependencies into your own project instead of `go get`ting the deps and share the same version across all your projects.
If a programmer wishes to release their code &amp; binary under a non-GNU license—which is the context in question—interacting with GPL and in particular LGPL code is a labyrinthian exercise with non-obvious implications. "Infect" is a common and perfectly apt description of how all viral licenses work, be they in the interest of all humanity or something akin to the Sleepycat gambit. 
Ah, that makes sense. Thanks!
XML is kind of a mixed bag. On the plus side, it's a mature technology which brings us a handful of strong advantages: * Robust validation * Well-understood grammar * Usually, at least one good implementation per modern language On the negative side we have technical flaws and the typical uses/abuses of the tech itself: * Massive, sprawling specification, requiring large engineering efforts to reach 100% compliance. The BNF of XML 1.0 alone, is huge. Writing a naive parser is easy, but getting XML completely right is hard. * Validation schemas come in two completely different flavors and have an unfriendly learning curve * XML data comes on multiple axes (attributes, nodes, namespaces, etc.), so APIs are very broad. * The W3C's standard XML API is incredibly clunky, and has all kinds of concessions for things that are rarely used, like swappable parsing backends. * Mapping a namespace prefix to a URI usually does not contribute additional semantic information since they're typically terse, and the corresponding URI can converge on gibberish - which is a form of compression, and not an improvement in human readability (See: Java Seam). * Constant confusion between which is best for data representation: attributes, or tags. Using the wrong one makes documents unwieldy. This seems to happen a lot. * Repetition that degrades human readability and maintenance, in the form of closing tags. It's possible to use XML in a way that's not a complete pain, but if you ask me, that doesn't happen very often. In contrast, JSON, YAML, and TOML all have one way to do everything, and the syntax is less cluttered with stuff that's not data, when compared to XML. That said, I do not like JSON since it's rather inflexible and does require a lot of symbolic "noise" that other formats do fine without. YAML seems to be closest to the balance point of "human readable yet nuanced."
&gt;There is a reason html uses xml nowadays (xhtml). XHTML is pretty much (if not fully) deprecated and HTML5 is the recommended markup language for the web now. Also, most websites never really used XHTML, they served XHTML documents as text/html instead of the proper application/xhtml+xml type. So they never actually used XHTML, just broken HTML.
Another happy customer
Excellent Read. The more I read Go and about Go I can not escape the conclusion that it is having similar kind of impact that iPhone first had first time on contemporary smart phones. It was claimed by industry experts and many users that all features pre-existed on one or other phone. Same with Go all features may existed in parts in many programming language but not all together in such orthogonal manner. With Go compiler and runtime in Go it is the only boot strapped language in top 20 other than C/C++. It shows more about expressivity than so many features that critics claim lacking (error handling, generics etc)
Yeah. Thanks! I got a comment explaining this http://whizdumb.me/2015/03/03/matching-a-string-and-extracting-values-using-regex/#comment-1293 As I said, I had no idea about query parser.
Vendoring doesn't mean keeping all in the same place, at least not to me. It just means maintaining your own branch that you know will work. I would just fork the library at the version you know. This allows you the ability to maintain or patch it in anyway you need to.
You may want to check out https://github.com/PuerkitoBio/gocrawl
(to be clear, I saw this on r/programming and I thought there would be insightful reactions at r/golang. me posting this doesn't mean at all that I agree with it, on the contrary...)
While I do log a lot, I find writing the unit test first and getting the test to pass has made debugging less important. 
Go-spew rocks. And go test is such an easy to use testing framework especially with testing.M in a TestMain function. 
[Non-mobile link](https://groups.google.com/forum/#!topic/golang-dev/nMWoEAG55v8)
Eventual advantages will be runtime speed and better control over memory and no garbage collection. Current advantages are an awesome package took called cargo that fixes the dependency nightmare inherent in go. But, it's quite immature at this point. I use go, not rust. 
Yet another case of regex (ab|over)use.
 The problem with the CDDL is that it's GPL-incompatible so there is no legal way to distribute CDDL/GPL combined works.
I'm not sure about those solutions, but the problem comes from users who may intentionally send an infinite loop. Obviously there has to be a solution though - otherwise how would the playground work?
&gt; But when you think about the xml schema and extensibility it really shines. If you need that. I've never once seen that used in config files for example, but I've seen XML config files. &gt;XML is a compromise that is easy to read for both humans and machines. I think anyone who says that should have to write a complete XML parser. It's really not that easy for machines to read. It's easy if you're just using a pre-made library of which there are many, but then you get into situations where you're trying to interface with a .NET or Java shop that used their specific library everywhere so everything works fine for them, then you go to produce XML for them with your equally valid XML library, but because they expect a certain namespace or whatever you end up needing to manually write your XML just to be compatible. I think XML has its purpose, but it also became the go to solution for people because its what they knew, so they applied it even when it really didnt fit the problem at hand. Theres also just so many different ways to do things that it just feels like too open ended of a spec. Which of these is right? ``` &lt;stocks&gt; &lt;stock name="ibm"&gt;312.5&lt;/stock&gt; &lt;/stocks&gt; ``` or ``` &lt;stocks&gt; &lt;stock&gt;&lt;name&gt;ibm&lt;/name&gt;&lt;value&gt;312.5&lt;/value&gt;&lt;/stock&gt;&lt;/stocks&gt; ``` or ``` &lt;stocks&gt;&lt;stock name="ibm" value="312.5"/&gt;&lt;/stocks&gt; ```? Compared to something like json where you'd just use {name: "ibm", value: "312.5"} and chances are if another dev wanted to represent the same data, thats exactly how they would do so as well, there is no interpretation .
First I did not have setup for cross compilation so If I had tried I think it would have worked. Second bunch of those linux VMs are our dev machines. So quite a bit of scripting, building of Java code happens there. Installing Go also was not a big deal. And sometimes I just changed code on VM and compiled there or just run using `go run ..` command. Unlike Java writing Go without IDEs is quite manageable and fun :-)
&gt; Yeah, it's a sticky area. Another redditor in this thread mentioned that it's technically multi-license, but given GPL's aggressive nature, I get the gist that it could be viral even in source form. You could go to /r/fsf and ask to clear any doubt...
One of the best-looking gophers so far.
 { "_comment_": "I tend to do this if the program digesting the JSON doesn't care about extra keys." }
&gt; what have you done in your larger projects to get around the lack of a debugging utility that supports Go programs? Nothing. I'm with Linus on this one: http://www.linuxtoday.com/infrastructure/2000090700221OSCYKN Just like having cell phones causes you to forget phone numbers, having a debugger causes you to forget details and weakens the code simulator in your head.
Hmm .. really strange. Which OS are you on? This is what looks like [Imgur](http://i.imgur.com/NFmIvvo.png)
so someone else gets paid to post Dave's original content?
It was my ansi library which I refactored (don't fix things which aren't broken). Doh. I fixed it on Windows so I hope it works. Please try go `get -u github.com/mgutz/logxi` which should update the ansi style issue
Sorry, I didn't know the post was published by accident. Here is the other I wrote https://www.reddit.com/r/golang/comments/2xufjb/cmdrun_returning_short_write_as_error_why_does/
Here's what it looks like on [Ubuntu](http://i.imgur.com/mQl3lby.png)
I think if you have good unit testing it certainly minimizes the amount of step-debugging you should conceivably need to do. Also, +1 on GoConvey, I love that framework. If you couple that with Logrus or perhaps go-spew I think you're in a pretty good spot.
Are all files in the same folder with a '.go' extension concatenated into a larger one at run-time (conceptually)? How does it know which code comes before others, or does it even matter? Do you have to call an 'import' command anywhere, or is it all just assumed?
I have a collection of amigurumi on my desk at work my god has made me. So I was excited when I saw this post, but disappointed when I saw the felt... Felt just makes stuff look cheap to me. Still cool though. 
Indeed! I'm returning `len(p)` instead of `1` and now it works!
&gt; It would be nice if all pages were only allowed to be xhtml5 and would not render unless valid. We have that, it's called Content-Type: application/xhtml+xml. You can start using it right now. But what do you gain from doing so? Absolutely nothing. That's why everybody uses Content-Type: text/html.
Thanks for your try, I will tweak the width of the autocomplete window later. And other features will be added in next release :) 
I love our mascot. My Gophercon Gopher went to my son, who sleeps with "Gophie" every night.
Invalid xhtml pages render anyway afaik. It would be nice if they only were rendered if they were valid.
Unless you're using docker for source code distribution, which is very unlikely, you should be putting a binary in it. Having said that, nothing prevents organize your dependencies the way you want - as you just realized, it might be a godep limitation, not Go's. Have you tried other vendoring tools, like third_party.go (from etcd guys)? 
Agree that it's used badly in places but it's just a tool. A fool with a tool.. Etc :-) The thing I'm against is people bashing xml by just seeing it as something verbose without understanding the benefits of it and where it can be used and be a good format. Both libreoffice and Ms office use xml nowadays. For rest services it feels bloated. Config files can be good for xml files depending on size and complexity. 
Wow. That's harsh.
I can't tell whether you, OP, both of you, or neither of you are trolling.
err := crochet() if (err != nil) { panic ("adorableness overflow") }
Another gopher crochet pattern is available at https://jteeuwen.nl/crafts/gopher.html
we're doing the exact same thing as you except we opt'd for NSQ since we're moving to Go for many of our microservices.
Good suggestion and I'm very well aware of this. I have used Redis at few places for queueing where it matters but its not complete. - I think at some point we have to do it.
Finally! Thanks!!!
They render like this: data:application/xhtml+xml,&lt;?xml version="1.0"?&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml"&gt;&lt;head&gt;&lt;title&gt;Hi&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p&gt;Hello!&lt;/p&gt;&lt;p&gt;Hi there&lt;/body&gt;&lt;/html&gt; Firefox tells you you've got an error in your XML and renders nothing. Chrome renders the document partially with a big red banner at the top saying your XML in malformed. So if you want your (X)HTML to be subjected to draconian error handling go ahead and start using that mime type.
Yes, that fixes it. Thanks! Looks like a nice logging library. I've been trying to decide which one to go with, and I think I'll give it a try. I like that it's high performance, has sensible default behavior both in console and when redirected, has level guards, is easily reconfigured at run time, and requires almost no code to set up.
The non technical person should probably not use html in text format but rather a html editor. If someone tries html they are going in to technical domain. Word document has a spec. Programming languages follows a spec. They don't allow interpretation. Either you follow the spec or your doc is invalid. 
&gt; Word document has a spec. Hahahaha, oh, I see you've never tried to read a Word doc before.
Here is a list of the videos and descriptions. * [Go at CoreOS *This session will discuss using Go to build products that make distributed computing as stress-free as installing a Linux distribution.*](http://video.fosdem.org/2015/devroom-go/go_at_coreos.mp4) ([description](https://fosdem.org/2015/schedule/event/go_at_coreos/)) * [Finding Bad Needles in Worldwide Haystacks *Experience of using Go for a large-scale web security scanner*](http://video.fosdem.org/2015/devroom-go/go_web_security_scanner.mp4) ([description](https://fosdem.org/2015/schedule/event/go_web_security_scanner/)) * [Moving MongoDB components to Go *We love Go and this train is unstoppable!*](http://video.fosdem.org/2015/devroom-go/mongo_go.mp4) ([description](https://fosdem.org/2015/schedule/event/mongo_go/)) * [CockroachDB *Towards an Open-Source Spanner*](http://video.fosdem.org/2015/devroom-go/cockroachdb_go.mp4) ([description](https://fosdem.org/2015/schedule/event/cockroachdb_go/)) * [HTTP/2 for Go *Overview of HTTP/2 and the design of Go's support for it*](http://video.fosdem.org/2015/devroom-go/http2_go.mp4) ([description](https://fosdem.org/2015/schedule/event/http2_go/)) * [Go and the modern enterprise](http://video.fosdem.org/2015/devroom-go/go_modern_enterprise.mp4) ([description](https://fosdem.org/2015/schedule/event/go_modern_enterprise/)) * [bleve - text indexing for Go](http://video.fosdem.org/2015/devroom-go/bleve.mp4) ([description](https://fosdem.org/2015/schedule/event/bleve/)) * [The State of Go](http://video.fosdem.org/2015/devroom-go/state_of_go.mp4) ([description](https://fosdem.org/2015/schedule/event/state_of_go/)) * [Go Lightning Talks *The Go community on Go*](http://video.fosdem.org/2015/devroom-go/go_lightning_talks.mp4) ([description](https://fosdem.org/2015/schedule/event/go_lightning_talks/)) 
&gt; about 1/3rd of the time I handled errors, it was not just "return err". That's pretty much what I'd expect. Generally when an error occurs, there is useful debugging information available in that context which should be logged -- information which won't be available to the caller. So at the very least, you ought to be logging each error carefully before passing it back up. In fact, in Java it's not unusual to catch an exception, log the circumstances that made it happen, and then throw it again.
Do you happen to know if NaCl helps prevent these issues with race conditions? I'm going to assume it does since this article (saying that there was no solution yet) came out in 2010 and NaCl came out after that (along with Google AppEngine), that they likely solved that issue. Is making Go single threaded as easy as setting GOMAXPROCS=1? Thanks again for all of your help -- it has been great!
Maybe this: http://goconvey.co ?
I know this is negative, and everybody should be doing what provides the most utility and happiness, but it's a joy having a language that is so delightfully free of the sort of fads that have infected other communities. There are so many followers and few leaders that one day someone will adopt something, and the very next you'll see it blindly copied in every job (mistyped as "mob"--seems appropriate) posting, making it unavoidable if one wants to work.
You ever figure it out? I'm having similar issues.
Cool! There is also: https://github.com/yosssi/ace - If I would have seen your project earlier might have use used that instead of ace. (since you forked Amber I'm guessing you know why it didn't quite cut it)
There's a blog post related to the release: https://www.shopify.com/technology/17605604-announcing-go-lua
Now someone just needs to check that luje ( https://cowlark.com/cgi-bin/fossil.cgi/luje/doc/stable/doc/index.wiki ) works in Lua VM in Go, then Go can run a VM that can run Lua that can run a VM that can run Java to finally build some proper enterprise apps instead of all the silly scripting! (on a serious note I find it bit odd that Lua is needed for this job, a lot of people have been replacing "scripting" solutions with Go successfully..)
This wants me to now learn Lua.
I enjoyed reading your post (I assume you're the author). Had a couple questions about traffic flow, if you don't mind. So you created three microservices in GO. I assume each has its own independent REST API and HTTP listener. Is that right? Does the Ruby application still provide the end-user-facing user-interface and then simply forward requests to the back-end GO microservices via AJAX calls or similar? If this is the case, then it would make sense that the Ruby app would contain all the API login code to keep it hidden from the client-side. Are you using the GO services to communicate with your back-end database? Or is that still done with the Ruby part of the application (for now)? Thanks!
Forgive my ignorance, but when you introduce an async messaging system into the mix, how does the client-side handle updates? Is the content delivered to a long-running web socket once it's ready? The way I understood it is that you submit the request to the messaging system, then the back-end system(s) pick up the events/messages, process them, and spit out the results. The results to have make it back to the client somehow and that's the part I'm always fuzzy on.
You may want to consider [gopher-lua](https://github.com/yuin/gopher-lua) for scripting, which is mentioned in the link AYBABTME posted. The main reason being that there's a [reflection library](https://github.com/layeh/gopher-luar) for it which makes working with your own datatypes simple.
I'm writing Go code for a living, been doing so for 2 years now. I've done projects that are both small and somewhat large, of CLI apps to distributed services. Of that experience, I've managed to effectively debug pretty much anything I had to. For local development, using `log.Printf` and `log.Panicf` (panic for the stack traces) for most cases. Also, a combination of testing and coverage reports can help a lot directing your effort. Tools like `go test -race` are excellent, so are static analysis tools like `golint` and `go vet`. For debugging deployments, the `net/http/pprof` package exposes HTTP endpoints to get stack traces and profile memory/cpu/contention, and `expvar` registers memory statistics. Combined with good logging, it's possible to debug a large number of issues in production system. Combining log traces with stack traces is very helpful in figuring out what's going on. Getting periodic stack traces of your deployment can help characterize the typical paths taken by your code and detect anomalies or deadlocks. You can also write tools to work with the `pprof` profiler, collecting profiles from many servers. I have a crap tool like that https://github.com/aybabtme/dpprof So this is the rose part. The bad part is that there's no debugger to speak of. Most of the time, I don't need one. But it's been getting on my nerve, I'm getting a bit tired of inserting `log.Printf` everywhere when I could normally just set a breakpoint and step the program. It's also annoying that I can't connect to a production service and debug/step through a single request or, inspect the process, or pause goroutines and make them step. This is somewhat alleviated by using a centralized logging solution, having a metrics pipeline and distributed tracing, although this means you need to manually instrument a lot of your code. Still, those are all things that will be solved in the short-to-medium term, as far as I know. I'm a giant Go fan, but I can also see where its limitations are. Lack of debuggers is one issue I have. I'm still super happy that I'm working in Go everyday, and I wouldn't change it for another stack. Even with the comments I said above, I feel Go makes my life as a developer much better than other things I've used before.
I noticed the readme mentioned another library. Interesting... yes, being able to work with my own type is pretty important :)
Very nice of them to open source this, but its odd to focus so much on performance: when integrating something like this, I'd be more worried about compability with the default implementation, if its possible to use the most popular libraries, then stability/memory usage, and then performance. I couldn't go get the library. 
what sites?
https://groups.google.com/forum/m/#!msg/golang-dev/nMWoEAG55v8/iJGgur7W_SEJ
Having logic that doesn't require a compile phase to change is nice. 
What is BDD? Why do people keep using acronyms for all kind of stuff even where it's not needed?
Based on the rest of the post, I'm guessing behaviour-driven development.
How does one go about learning how to implement a Go microservice? I know enough Go to get started but tying it into a Rails project seems daunting but since that's what I work with it's the only way I'll be able to learn more Go on the job
Am i the only one who can't get the GoOracle plugin to function correctly? None of the commands work and this is the output in console when invoking any GoOracle command. Traceback (most recent call last): File "goOracle in C:\Users\John\AppData\Roaming\Sublime Text 3\Installed Packages\GoOracle.sublime-package", line 46, in on_done File "goOracle in C:\Users\John\AppData\Roaming\Sublime Text 3\Installed Packages\GoOracle.sublime-package", line 115, in oracle TypeError EDIT: Nvm, Windows not supported.
I didn't know that, will make sure i add a note about that! Thanks
Genuine question about the approach they've taken. They wanted a scripting language so they could add new flows to their load testing tool. I'm wondering if the same could have been achieved by configuring the Go program to periodically read config files to update its list of flows. It would be easy for the web frontend to spit out json and easy for the Go program to parse that. Does this approach achieve the same things with less engineering effort?
I think that's an interesting question. In languages with fewer concurrency features I would probably expect something like an embedded scripting language. I don't see why your idea wouldn't work well in Go though. 
`go get github.com/Shopify/go-lua` works fine here, what error did you get?
No, you don't need to call import, for more info check https://golang.org/doc/code.html
Being able to reload parts of the code without shutting down the software and possibly reconnecting clients is **awesome**. That's why I still use Java with JRebel for most servers that handle long-running connections (think real-time games for example).
Thanks for the reflection pointer! I was going to point out that GopherLua also has Go channel support and so can nicely blend Goroutines into scripting..
Worked on mac, failed on Windows.I got: c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:12: undefined: CheckType c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:23: undefined: MetaField c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:24: undefined: CheckType c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:41: undefined: CheckInteger c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:42: undefined: CheckType c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:95: undefined: CheckStackWithMessage c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:101: undefined: Errorf c:\users\hugo\go\src\github.com\Shopify\go-lua\base.go:326: undefined: SetFunctions c:\users\hugo\go\src\github.com\Shopify\go-lua\bit32.go:32: undefined: CheckUnsigned c:\users\hugo\go\src\github.com\Shopify\go-lua\bit32.go:43: undefined: CheckUnsigned c:\users\hugo\go\src\github.com\Shopify\go-lua\bit32.go:43: too many errors
I wish it had the popularity of JS :(
We had K&amp;R C, and now we're going to have K&amp;D Go? Sounds great, if you ask me.
I watched that presentation and it left me with a rather bad impression. Every time I heard "we need more of this and more of that" I had the feeling he wants Go to become more like Java (frameworks, frameworks, frameworks..) and my perception is that Go is intended to be "more libraries, less frameworks". I see no problem if Peter (or someone else coding on behalf of the "modern enterprise") writes the code he feels is missing and publishes it on github to see if it catches on, but personally I would not enjoy if this "enterprise" current promoted by disappointed Scala/Java programmers becomes standard. I guess this will be the next wave in Go lifetime after the current "Python/Ruby programmers rewriting their old frameworks in Go" wave. I still hope the boring pragmatism of Rob Pike survives these waves.
I second this. It's like Lisp with hash tables instead of lists and an exceedingly [minimal syntax](http://www.lua.org/manual/5.1/manual.html#8). (Compare _that_ to the [Python syntax](https://docs.python.org/3/reference/lexical_analysis.html)) Also, using [LuaJIT](http://luajit.org), you get _the_ fastest scripting language experience there is. I'm not even kidding.
I disagree, Peter had the guts to get up on stage tell people where our shit stinks and what needs to be done for Go to be accepted by large companies, like the one he works for. 
I disagree too, let's wait and see what comes out of this :).
Is this real or an early April fools prank?
Exactly my thoughts
Perfect, super thanks!
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**The C Programming Language**](https://en.wikipedia.org/wiki/The%20C%20Programming%20Language): [](#sfw) --- &gt;___The C Programming Language___ (sometimes referred to as ___K&amp;R___, after its authors' initials) is a well-known [computer programming](https://en.wikipedia.org/wiki/Computer_programming) [book](https://en.wikipedia.org/wiki/Book) written by [Brian Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan) and [Dennis Ritchie](https://en.wikipedia.org/wiki/Dennis_Ritchie), the latter of whom originally designed and implemented the language, as well as co-designed the [Unix](https://en.wikipedia.org/wiki/Unix) [operating system](https://en.wikipedia.org/wiki/Operating_system) with which development of the language was closely intertwined. The book was central to the development and popularization of the [C programming language](https://en.wikipedia.org/wiki/C_(programming_language\)) and is still widely read and used today. Because the book was co-authored by the original language designer, and because the first edition of the book served for many years as the *[de facto](https://en.wikipedia.org/wiki/De_facto)* standard for the language, the book was regarded by many to be the authoritative reference on C. &gt;==== &gt;[**Image from article**](https://i.imgur.com/w7gbqHW.png) [^(i)](https://commons.wikimedia.org/wiki/File:The_C_Programming_Language,_First_Edition_Cover_\(2\).svg) --- ^Interesting: [^The ^C++ ^Programming ^Language](https://en.wikipedia.org/wiki/The_C%2B%2B_Programming_Language) ^| [^CppCMS](https://en.wikipedia.org/wiki/CppCMS) ^| [^C ^\(programming ^language)](https://en.wikipedia.org/wiki/C_\(programming_language\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cp553nw) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cp553nw)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Oh I can't wait till /r/programming starts talking about this /s
definitely the next must-buy book!!!
rite faster
Table of contents is here http://www.informit.com/store/go-programming-language-9780134190440
Wow, that's quite an endorsement for Go. . .
Kernighan and Rob Pike have written a few books together, so it's not super surprising... though this does seem to be Kernighan's first book since 2002, so I think it's not entirely something that should be discounted, either.
So no standard library or material design? Thanks. 
I hope it's a great book. There's always room for more books in the tech world, but K&amp;R is the gold standard and it would be awesome if K&amp;D matches that.
&gt;even if other books are better. I doubt such a book will appear. Kernighan's *The* *Awk* *Programming* *Language* is still the most concise and informative programming language I have ever read. *The* *UNIX* *Programming* *Environment* and *The* *C* *Programming* *Language* are likewise classics decades after their original publication. The announcement of this book is great news for Go.
I did something very similar. Any reason you chose bit.Int instead of big.Rat as the underlying type?
Via the second option you can do material design on the Java side, business logic etc on the Go side.
Peter has the right design goals, IMO. If you're trying to build a distributed system you need certain tools. There's work to be done to author and/or polish those tools and make them available. Check out gokit.io
Unless something really big changes, you're not going to see the Android development libraries made for Go, simply because the work of porting them over would be enormous. Nobody is trying to make Go the standard language for Android development as of right now.
Pre-orders must be doing ok. It is currently sitting at number one in programming language books.
Read Hoare's book?
Start of an interesting project. Many more data structures to come. Request for feedback. 
Because https://github.com/oguzbilgic/fpd used big.Int, I think. There are alternatives, [[1]](http://godoc.org/speter.net/go/exp/math/dec/inf) (uses big.Int, too), [[2]](https://godoc.org/github.com/opennota/decimal) (uses big.Rat).
No, you can only restrict access at the package level. It's not necessary to restrict access at a more granular level than that.
Isnt necessity determined by the requirement? If the min access level is package I have no way to ensure a property is never changed after being set or have control over what happens when setting a value
I'm not a Go expert but what I'd do is have a package name private and public and add the public interface to the public level. That's how of the Eclipse code is. It's mostly Java but the concept is transferable 
Well you can always put a comment that explains in what circumstances this field can be changed. Go is not object oriented in the same way as other popular languages. Unit of encapsulation is package. And package should be small enough so that problems you want to resolve by more granular control are not an issue.
very good downtempo-dub **and** computer science? nice!
What's Tokenizer? &gt; I believe this can be made even faster Yes. 
It's being well received http://www.reddit.com/r/programming/comments/2y105x/the_go_programming_language_by_brian_w_kernighan/
Goto [isn't bad](http://fuz.su/~fuz/structured-programming-with-the-go-to-statement.pdf).
Use two `const` blocks. It's better for clarity, too. const someOtherConst = "some other type" const ( a = iota b c )
You could put your struct in its own package, with a constructor, members you want package private (lower case names), and provide public access-only functions to get the values of the private members. I don't think that's very idiomatic, but it would do what you want. The reason Go doesn't provide that natively, at least the way I see it, is that you can make things private to a package. The package is all *your* code, so you can make sure that you don't change the values anywhere. You don't have to worry about anyone else, as it's your package. This is a different approach from OOP where you apply that principle to individual objects rather than whole packages.
Weird, I sorted by publication date on Amazon and somehow missed that. My bad... but glad to know he's still writing :)
stick with cucumber if it's a web app.
&gt; Of the three languages besides Obj-C Node has an excellent debugger.
You are right that some of the structures are exactly the same and we simply provide a wrapper around those natives map and slices, e.g. HashMap, with utility methods that avoid writing boilerplate code. However having other structures, e.g. TreeMap, TreeSet, are backed by red-black trees, and provide a solution for a problem where ordering of elements in a collection is important. Stacks are not part of native go type, but can easily be implemented using natives, e.g. ArrayStack. The implementation thereof has to worry about dynamic array allocations, specifically growth factors, which can be slow if not optimized properly. There is another implementation using linked lists, i.e. LinkedListStack, which from benchmarks is slower, but uses less memory. In other words, choice of a data structure depends on the problem and it is good to have this flexibility and not having to worry about writing boilerplate each time. Additionally sets are not part of natives, but can also easily implemented using a map, i.e. HashSet. On the other hand if you need automatic sorting in a set, you could use TreeSet mentioned above. More structures to come, queues, priority queues, dequeues, lists (array and linked lists) and of course, trees. A common interface and structure in this library allows us to easily communicate between the structures. Excuse the lengthy reply.
The spec clearly [states](http://golang.org/ref/spec#Iota): &gt; Within a constant declaration, the predeclared identifier `iota` represents successive untyped integer constants. It is reset to 0 whenever the reserved word `const` appears in the source and increments after each ConstSpec. It's not really that hard to understand, and IMHO a block of these constants should usually be declared apart from other values anyway. Having the counter reset each time `iota` appears instead would probably be more confusing than the current behavior in some circumstances.
Why? Is there a reason other than performance? I thought big.Int's API was very hard to use, and was that way only for performance reasons. I wanted to create something that was very easy to use correctly, and if you're using Decimals, you probably care more about correctness than performance anyway. With big.Int, you have to do: z := new(big.Int).Add(x, y) Lots of boilerplate, and it's not immediately obvious how to use the API correctly - which is an issue on larger teams where new people are being hired all the time. Whereas with Decimal, you can do z := x.Add(y) less typing, and impossible to use incorrectly EDIT: check out this https://play.golang.org/p/SchlXvWV9q for an example of a subtle bug caused by misusing the big.Int API.
I agree with the general idea of your comment. I also preferred other solutions instead of import path rewriting. However, I do not agree it is such a big problem. In practice, using a tool to rewrite import paths should not be more problematic than modifying an environment variable. It also has some advantages. For example, since it modifies every file which uses the vendored dependency, it makes clear in the log which are the affected files. I think it will be great to agree on a common format for a dependencies file, this can be useful for non-vendoring tools too. It will also be great to agree on a common location for vendored packages, for those who use it. I do not like the idea of encouraging vendoring as the de-facto approach to dependency management. The general opinion on golang-dev appears to be more or less in this line, so let's see how this finally turns out.
I feel your pain. But my advice would be to just go for it. I submitted a document change a month ago following the contribute instructions. In the end the process was quite painless. I learned some new git commands along the way and now I'm all setup to contribute anything I want Edit: I didn't actually make aliases for the git-codereview tool.
I am not a lawyer and frankly ignorant about licensing. Which license is more preferred in your opinion and why? Thanks.
Thanks! Is any of it open source?
Thank you for clarification, it is highly appreciated. Indeed, it is not my intention to limit the use of this library to GPL projects only. My intent was to create something that others can use anywhere as long as it has a reference to the original author. That's the reason I choose LGPL instead of GPL to lift restrictions on open sourcing, however, after your explanation, even LGPL still seems limiting. I will most likely switch to BSD license after reading more on it. Thanks again!
Yes, that's what I meant. I work mainly with Windows machines.
I knew someone was going to bring that up. It's helpful to go back and read [Dijkstra's original paper](https://files.ifi.uzh.ch/rerg/arvo/courses/kvse/uebungen/Dijkstra_Goto.pdf) and understand the context it was written in. At the time, goto was how you jumped around in a program -- subroutines/functions were not common. Think BASIC back before `GOSUB` was a thing. In the time that Elements of Programming Style was written it was still necessary to explain to programmers that subroutines and functions should be used instead of `goto` for basic control flow. We all take this for granted now, which is why I mentioned that aspect of it being dated. `goto` is fine in a C program where you need to bail out of a function early and do some resource cleanup. It can make sense in some state machine implementations. But it is not an adequate substitute for subroutines generally. Edit: I'll quote from the Knuth paper you cite: &gt; First, there are several kinds of programming situations in which go to statements are harmless, even desirable, if we are programming in ALGOL or PL/I. But secondly, new types of syntax are being developed that provide good substitutes for these harmless go to's, and without encouraging a programmer to create "logical spaghetti". Fortunately the world we live in 40 years on is considerably nicer with these new syntaxes.
Dude, it's literally the [second google hit](http://www.slideshare.net/cloudflare/a-channel-compendium).
Javascript vm in Go ? :=)
&gt; Why? Is there a reason other than performance? I've already internalized `math/big`, and a decimal type seems like it belongs in that package anyway. You make some good points, though. I'm not sure it's something I want any more, but I still have a few suggestions: 1. Use pointer receivers to [ensure your method sets are consistent](http://golang.org/doc/faq#methods_on_values_or_pointers). 2. Reduce stutter by [renaming the package](http://blog.golang.org/package-names) to dec, or the Decimal type to Dec. Right now, users of your package have to type `decimal.Decimal`, but it could easily be `dec.Decimal` or `decimal.Dec` without losing any clarity. 3. IntPart -&gt; Digits, Significand, Mantissa, or Coefficient 4. NewFromFloatWithExponent -&gt; NewFromFloat (delete original NewFromFloat) 5. d -&gt; z 6. d2 -&gt; x 7. value -&gt; x or v 8. decimalBytes -&gt; text 9. precision -&gt; prec EDIT: I know you didn't ask for a code review, and most of my suggestions are bikeshedding, so I just want to reiterate that I think this library is great. I've already started using it in one of my projects, and it seems correct and complete, so bikeshedding is all that's left IMO.
i like the name XD
Interesting I had not heard that, and Im glad to hear it. However I think if you look at the examples I think there one major difference between builders goqu and others like squirrel, dat, and dbr which is the concept of a expressions being a first class citizen. When exploring the different builders it seemed that most of them relied on the developer providing the different fragments of SQL and the builder glueing them together. Which is one major difference between this libraries and others. While you can use raw sql the standard is to use one of the expression types such as an identifier which can then can be used to create your more complex SQL. One major benefit of taking this approach that we can hide differences between dialects for example, the LIKE clause is different postgres and mysql and if I switch between them I would rather focus on just creating the LIKE clause not remembering syntax. Expressions can also be composed of each other and reused, allowing a complex query to be broken down or even reused between datasets. Also, having concrete type for identifiers, while it may seem trivial it can save headaches when trying to figure out why a query isn't working as expected just because it wasn't quoted. Just my thoughts and some reasoning behind the library.
I should note I would be up for a discussion on merging these in to a single project that would be best for the community, after all projects live and die by community use.
I have to spend some time playing with Hystrix and Hystrix-Go. If you connect Hystrix-Go to a Hystrix-Dashboard, or whatever other management services are part of Hystrix, and open a circuit breaker for "ResourceA" on one service/host, does that open it for all services on all hosts? For example, if my "SendEmail" service is acting up, I'd like to trip the breaker for all of my microservices, not just in this one service, on this host. Edit: Looks like the circuit breaker is managed by the service making the remote calls. You hook a bunch of their feeds up to the Hystrix dashboard via Turbine, which just aggregates them, summing count values, and averaging timing values. Not sure how it aggregates boolean values reporting whether the circuits are open. 
Hey, author of dbr here. Glad you like what we're trying to build, and sorry postgres support isn't available right now. We are working hard to get postgres support going in the near future. It's our current #1 priority.
They are using a wrapper around their API calls which I am not found of and seems excessive. The goal of this exercise was to just use net/http outside of the router.
I may be a little biased as the author of dat, but I addressed many things * dat is built on sqlx * interpolation can be disabled and IS disabled by default * not all SQL should be interpolated, see benchmarks around large sizes of text and binary images * safe handling of constants such as NOW(), DEFAULT * builder is orthogonal to runner. I have a pgx branch which is not based on database/sql. * scopes * ordinal placeholders instead of '?' * everything is explicit, there is no magic like autoupdating of IDs in a record. Why just the ID when other fields liked created_at and updated_at and other fields have default values? What if your ID is a UUID? I am working on a metrics dashboard and all you have to do is pipe your app to a collector (12 factor app way). `LOGXI=dat*=INF yourapp | metrics`
&gt; The most powerful feature is the absense of classic objects with methods. How is the lack of classes/inheritance the most powerful feature? I can see this as a design choice, but this is not a feature or selling point.
Another redditor made this: [MongoDB API Boilerplate](http://www.reddit.com/r/golang/comments/2uhqb0/mongodb_rest_api_boilerplate/) I have been using that and some other api tutorials to cobble together something for work. I just really started to learn Go within the last month or so. Resources I am using: [JSON to Struct](http://mervine.net/json2struct) [JSON API for MongoDB](http://nicolasmerouze.com/how-to-render-json-api-golang-mongodb/) [Clean Architecture for Go](http://manuel.kiessling.net/2012/09/28/applying-the-clean-architecture-to-go-applications/) [Making a restful API in Go](http://thenewstack.io/make-a-restful-json-api-go/) 
When you've worked on large projects that abused inheritance to the point of making the code nigh-on incomprehensible, this is definitely a feature. Even if everyone on your team is competent, you might still have a manager who thinks quality is synonymous with Enterprise Java, and Go's lack of inheritance protects against the realisation of such a manager's twisted dreams. You can't be blamed for not making sufficient use of AbstractFooImplFactories when your language doesn't support them.
I do work on large projects in Java. The fact that classes/inheritance etc exist doesnt mean that its a bad language design. It means that people are trying to solve problems in the wrong way. With java you can also accomplish composition rather than inheritance quite easily, and most good developers use inheritance sparingly anyway. 
Didn't you ask the same question about Rust just recently? Compared to Rust, Go has a garbage collector which could complicate things. Rust's allocation is more C++/C-like (i.e. malloc/free style). If you can accept adding a latency equal to the GC pause time to packets being passed through, then I guess Go is acceptable. Alternatively you could try to avoid allocations/deallocations completely in Go by using preallocated buffers. However, I don't know the libraries well enough to say whether this is possible in Go.
Wouldn't it make sense to use Erlang in this situation? Seems like its tailor-made for exactly this kind of thing.
It certainly doesn't ship with this functionality built in. I don't know if there's a module somewhere, but the asynchronousness of its messages actually makes this sort of thing trick to implement properly (sending a message never has backpressure). (I thought somewhere I had read that it would slow down messages if they were sent to mailboxes already full of messages, but when I wrote a sample program to try to explore what the parameters of that behavior were I could never get it to provide any backpressure.)
Well put; hit the salient points quite nicely
It's simply personal preference. I prefer the SQL Fragment builders (like dbr) myself because Go's syntax simply has too much package/type noise when building literals to be able to accomplish this in a super beautiful way. It ends up being harder to read than you want it to be. This is coming from experience trying to port an html-creating DSL-like library to Go from Python. You could definitely clean it up, but there's an upper limit because of Go syntax.
FUZxxl has a good point. * Anytime you're using iota, the constants are probably related. * Anytime you have related constants, clarity/coherence is improved by grouping them. * By the same token, anytime you have an unrelated constant among a group of otherwise related constants, clarity/coherence is decreased.
Not quite sure what you mean. You can handle timeouts elegantly in Erlang in the same message loops as you handle any other message type. If a producer does not get acknowledgements from a consumer within a certain time in its mailbox, it can set off whatever behavior's are appropriate. I may not comprehend what problem you are trying to solve, but check out section 9.4 in the OTP docs below: http://www.erlang.org/doc/design_principles/distributed_applications.html#id75077
Having a makefile for fetching dependencies and testing seems **very** unlike an idiomatic go project. You could replace it with a two notes in the readme and that would likely make the project easily portable to windows as well. Also, check out [go-restful](https://github.com/emicklei/go-restful) for an example of a high quality package in API development.
I see no reason why not - go is freakishly fast. The one problem I see is the stop-the-universe garbage collection, but you can work around that by having little (preferably no) allocations, which can totally be done by for example reusing the same allocated memory in a buffered []byte channel.
? I really would never use something like that. Go net http package is pretty awesome and magic free. The point of this was to make an api without a bunch of external help. I dont see the issue with the makefile. It's pretty convenient for myself and if you are on windows you can just ignore it.
I think the first answer here might be what you're looking for: http://stackoverflow.com/questions/11354518/golang-application-auto-build-versioning Example: $ pwd gotest $ cat gotest.go package main var x string func main() { println(x) } $ go install -ldflags "-X main.x boom" $ gotest boom 
Go programmers are usually misguided and almost brain washed to believe "simple is better" or something. With their logic, they should've been using Forth or LISP instead of Go. It's a bit weird culture. But essence of their claim is that absence of many common features is good. And they truly believe that. 
That... looks like callback hell. Exactly what I started using Go to get away from.
That works only with string constants and it happens at link time. For numeric constants you want to actually be `const` you need a different solution. 
Not to take an antagonizing tone, but you posted under the context of a sample json api, nowhere in the op or readme did you state that you wanted to use just the standard library and re-implement the wheel. Both of those are completely fine when explicit aims, I would rather not assume them to be implicit. The problem with makefiles is that it may be much more complicated when you make it a central part of the development cycle, avoiding that is desirable for supporting more symmetric cross platform deployments.
Are you trolling here because you believe that Go is encroaching on the popularity of your favourite language? Go's popularity is justified, since Go now has a destiny with success.
I've written some Go on pretty high spec machines with 10gbit cards doing some relatively trivial work. We could actually push 10gbit not too badly but absolutely everything else about your post is correct.
What's wrong with https://godoc.org/golang.org/x/net/context? To me looks much more idiomatic than mix of configuration structures + callbacks; like the next step of this invention would be to have JSON file to configure them.
Excellent, I've been waiting for these. 
Use strconv on the string the linker puts in.
Probably the safest route is to use NaCL: http://golang.org/misc/nacl/README The implementation of the playground is described in more detail here: http://blog.golang.org/playground
I agree that there may be other use cases for Hystrix-Go, but the timeout issue is not one of them and for that reason, this was not a correct example in my opinion.
Go is my favorite language as I said in previous chapter about Go being secret sauce of web scale cloud. And Go is already a success. Just not as successful in academia as Haskell.
&gt; Readability. I always found the Go code I encountered quite easy to read and understand, both our code and external code. I find this amusing. I've written some pretty hairy Go code that is very un-idiomatic (think lots of `interface{}`, abusing `sync.WaitGroup`, and copious amounts of buffered channels), however after refactoring it ended up being quite beautiful. &gt; the &gt;8=3 operator This is also amusing because it looks like a penis.
thank you very much for taking the time to give me some awesome feedback. I did look into gorm but i felt that i would use the native sql package till i really started to see an issue with using the build in one. I can see once i get into accessing some more complex things how this would become tedious. goji does look nice I am going to take a look through and see what it all has to offer although the middleware is the part that is most interesting to me.
You can take a look at this [project](https://github.com/dmtar/pit) that we wrote with a colleague of mine at the university for a mongo course. Keep in mind we did not refactor the code a lot, so it is poorly written, but you can see the use of goji and some middlewares. After finishing with that project I then decided to extract the gojison middleware.
We use [gorp](https://github.com/go-gorp/gorp) for the ORM and [goose](https://bitbucket.org/liamstask/goose) for migrations. Would recommend both. As far as I'm aware, there's not currently any Go ORMs that have migration support built-in.
This is a pretty good summary. I looked at the original discussion on Golang-dev mailing list but that's hard to follow. 
I do have one question about your comment on unmarshaling in the controller. Where would you propose the unmarshaling occurs? I find that it was much easier to do everything else i.e. saving, validation, etc when you unmarshal right into the structure such as User in this case. I was thinking you could do it in a middleware but then you get into using interfaces and type checking.
I think you probably have more experience than me in this area. Can you give me some more information on why you are moving from Erlang to Go. At my work we were thinking of moving from Python to Erlang, instead of to Go, because Erlang seems to have more tools out of the box for building distributed applications. But we have just started our evaluation. Several people on the team are very familiar with Go ... but everyone is checking out Erlang by starting from programming books and tutorials. Would be very good to hear your perspective.
What will happen if you need to support partial updates of the structure? You may check if the value is the empty value of the type, but then what will happen if someone wants to update something to the empty value? I prefer (keep in mind this may not be the correct way) to have the input parameters and based on what was those parameters update/create the new structure. I have found that unmarshaling user input in a structure may introduce a lot of new structures in the code that are used only for the purpose of unmarshaling a request. Unmarshaling in map and then working with that map is a little bit more flexible in my opinion. You can create a new instance of the desired structure once you have that map. And you won't need to create an instance for unmarshaling an Id for example. I have nothing against using interfaces. For me, working with user input is one of the cases where the empty interface is helpful. You won't need to check the types (most of the time), you only need to parse the input to the appropriate type when working with it. If you want to work with nested json objects you will be able to do that by checking if the value is map[string]interface{} (for example). Take a look at [whatever.Params](http://github.com/ndyakov/whatever). This (combined with gojison which unmarshals the request to whatever.Params in a middleware) is what I think I would end up using in my next small project.
&gt;No inheritance. I’ve personally come to view inheritance-based OO as somewhat of an antipattern &gt;Sacrificing type safety. We use extension attributes for the various protobuffer messages that the server handles, and I originally intended to distinctly type these, so that for instance a FooExtensionAttribute could not be used on a Bar. Go’s lack of parametric polymorphism and generic types however meant that this would have involved a significant amount of code duplication The author simultaneously bashes OOP and the idea of inheritance, then complains that he had to opt for less type safety because he then realizes that the whole idea of inheritance is to reduce code duplication and increase type safety. He could have "subclassed" the Attribute struct and gone on his merry way. If the author wanted to have less code, better contracts, and type safety, he should have gone for more OOP.
Hey, sarama contributor here. Some points of clarificarion: - The Kafka protocol allows concurrency; the server will only process one request at the time, but you can line up multiple requests while waiting for the response to the first one. - Sarama handles errors (leadership elections, network issues, etc). The error handling has been heavily tested, and can be configured quite a bit (number of attempts, backoff duration after a failed attempt, etc). I'd like to clarify why we have opted to use a channel based API for the producer. For the consumer it's more a matter if taste, but for the producer you will always end up with a concurrent implementation if you require a decent amount of throughput. The first realization is that messages normally do not occur in batches, but you usually want to produce one message at the time. This works great with a blocking API, but the performance of this approach is pretty terrible. Which is why Kafka's API supports batching. (Another reason is that compression works much better if you batch messages.) With your API, you leave the batching completely up to the user. Batching is quite tricky though because there are conflicting requirements of low latency, high throughput, and staying within the maximum message size limits of the broker. For any batching implementation that wants to keep latency low (by forcing a batch flush after e.g. 250ms no matter how many messages are queued up), you have to use a goroutine. Sarama implements this batching goroutine for you. You provide messages to a channel. A goroutine reads from it and queues up messages. It will flush batches either after a given number of messages or a given amount of time. It will also make sure it flushes before the batch goes over the maximum request size the broker is willing to handle. While it is sending the request to kafka and waiting for the response, the input channel is still accepting new messages that will be queued up for the next batch. This means that your application will not be blocked for a long time, e.g. when the Kafka cluster is in an election. This is important if you want short response times when handling HTTP requests. Sarama will try really hard to produce the messages you provide, but in some cases it is impossible (e.g. the complete cluster is down). When this happens, the messages will eventually be returned on the errors channel. Your app can read from it and handle the failures any way it wants. If you really need a synchronous way to produce messages, Sarama offers a sync producer: http://godoc.org/github.com/Shopify/sarama#SyncProducer. By using its SendMessage method, you get the result returned in a synchronous way. The nice part is that it is safe to use concurrently (e.g. when producing messages from different goroutines, common in HTTP servers). Internally it will still use batching to achieve higher throughput.
That's fine, until someone opens the pandoric closure.
Oh, because he likes generics, I get it, that was funny...
I have written a sample code that use gorm with multiple database, here is it: https://github.com/jinzhu/gorm/issues/328#issuecomment-75730515 and sure, it support migrations ;)
Whoa. I didn't realize dot notation would be that simple for maintaining multiple database connections. 
A constant through an environment variable would be a good idea to get information from the user - for example their login token. This has the added benefit of keeping sensitive info out of source control and fits in with 12 factor apps. A constant through a build variable would allow at build time to determine how specific binaries should work although I'm not sure if this is a good practice in general - the file level package structure and build tags should satisfy many scenarios that explicit checking is used. For example if you want to test different builds
I do that [here](https://github.com/dmikalova/go-watch) in the debug_*.go files, although I'm not convinced that testing such a small function is worthwhile. Build tags determine whether debug_on or debug_off is used and either declares a const which is then used in the test so I don't bloat such a small function into 4 separate files. If it makes sense to bloat the binary with all functionality and use command line flags, then check out the [flag](https://gobyexample.com/command-line-flags) package.
I'm pretty sure that comment was meant to riff on and extend one of the best jokes of the entire article...
What I do, for example, is make a generic library, and then have a subfolder that uses the library - ie a CLI wrapper that passes in command line flags and defines the defaults. This helps keep my code modular and documents how to use it with a simple example for other people.
This thread has been linked to from another place on reddit. - [/r/erlang] [Trying to decide between Erlang and Go for a project being ported from Python--this post by an experienced Erlang developer got us a bit nervous.](http://np.reddit.com/r/erlang/comments/2yb0j3/trying_to_decide_between_erlang_and_go_for_a/) *^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote. ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
That is actually a bit frightening for us--the parts you say don't work are exactly the parts that make Erlang attractive to us. Thanks for the info.
Oooh, I love seeing Dave Cheney in absolutely every corner of the Go community, this is going to be a real treat to watch :)
Pipedream?
Reading this it seems kind of obvious that he was trying to port the code over instead of trying to solve the original problem in go. I think the second way would have been easier and cleaner for him, though he doesn't give many specifics so I will never know.
Overloading is perfect for mathematical domains but it will never happen in Go. The closest you could get is writing a dsl in go and having go generate turn that into actual go - which Go does have great tools for doing. Check out how [GoConvey](http://goconvey.co/) wrote their's.
A few things I saw about styling/naming: You can group your dependencies (internal an external), source: http://golang.org/doc/code.html#Library You can shorten your receiver names (because you have to write them a lot), source: Go Source Code Add comments for godoc, source: http://blog.golang.org/godoc-documenting-go-code Sites I like to use for reference: http://golang.org/doc/code.html https://github.com/golang/go/wiki/CodeReviewComments
have you thought about mangos (nanomsg) for inter node comm ? been toying around a lightweight concept of distributed event emitters for some time (code on github.com/gleicon)
Could the SyncProducer work for your use case then? That one offers a blocking interface. Not saying that you should change to sarama, but I am interested in any feedback on the API we provide to make sure we cover as many use cases as possible. &gt; This means that there is no real difference between sending 10 requests at once and waiting for responses and sending 10 requests one after another but only after response to previous one was received. The request pipelining is important when doing batching. You can line up multiple requests that stay below the protocol message size limit, so your application can continue to accept events without blocking. Side note: I agree on your point of testability; this is an area where sarama currently lacks. I am working on adding some mock objects that make it easy to test application that use the producer or consumer: https://github.com/Shopify/sarama/pull/324
SynchProducer could do the work I guess, but there are two strange things about it: * it's still using sarama's partitioning mechanism, which is not what some may want, * it is abstraction on top of abstraction to make it synchronous again. This might be all great when you stream big chunks of data. But I found that when you process "live" data, consume and produce always not more than few messages at a time, sarama is way slower than my lib.
Are you aware that webhooks are not at all related to Git hooks? Yet your tool seems to be specifically for Git. With the actual definition of webhook in mind and with no introduction of your tool in the README it's hard to figure out what your tool wants to achieve.
http://play.golang.org/p/j29TH5CYB- There you go, for the love of Pike.
&gt; prog.go:4: imported and not used: "log" http://play.golang.org/p/CdLhmm92WV - fixed, for the love of Pike.
Thanks for your feedback, I really appreciate it! Yes, I am aware of that. Please note that this tool is still work in progress, and back when I started developing it, I did it with Github in mind at first because I needed something to run redeploy scripts when I pushed to release branches for some of my projects. However, I'm planning on doing a major overhaul of the architecture to allow the "vendor" specific handlers and options for hooks, and to make code less ugly, more Go idiomatic etc. At the moment, you can still achieve pretty agnostic webhook handling, ie. I've built a Slack logging script using their outgoing webhook integration. I'll make sure to update the README with what the tool is actually trying to achieve, add some real life examples and move this current stuff to a wiki page... :)
I did not think about that... But even then, there should be a better way of prepending an element. This is creating a lot of garbage. [Here](https://gist.github.com/ndyakov/9feaf9f89baa38ec2c36) are some benchmark of different variants for prepending a string to a slice of strings. s = append(s, "") copy(s[1:], s) s[0] = word allocates a lot less memory than `append([]string{"the string"}, someSlice...)` Performance-wise they are almost identical.
Hi everyone, This package is very early in development. I am looking for some feedback and whether it is something people need. I am working on a project currently that could benefit from this package, so that's why I wrote it. I encourage you all to have a quick look at the `/examples` directory to see how easy it is to use. Any and all feedback welcome. Thanks!
You can disable Go's GC entirely if you're sure you don't allocate in the fast path. The scheduler, however, will quickly become your biggest problem after that. For real-time stuff, we've mostly been working in C as opposed to Go because of scheduler issues.
In the first case regarding the `tags` variable, I had to prepend its content with a `timeBasedTag` or `latest` because the following execution is position-based, I probably need to document it in a comment though :P And I will change that function, `debug` mode was an afterthought and I just implemented it right away without too much thinking, it's pretty ugly :/ It's strange that go-vet hasn't warned about any of that as I'm pretty sure that `goxc` runs go-vet as part of its build process. I'm really thankful for all the comments, If I might ask a little bit more, how should I go about writing an unit test for some cases [like this one?](https://github.com/victorcampos/harbor/blob/master/execute/execute.go#L39)
Well, if Erlang can't handle my message size, goodbye Erlang. They're limited to a 10MB, on a fast local network, where they should be on the order of 2s tops to send, and the vast bulk are smaller than that. But that's not the real problem. The real problem is that it just _breaks_. No messages. No "I couldn't get a ping through". No "Your message from X to Y was 7MB and that's a bit large". And quick asides in some optional docs aren't good enough... this ought to be in metaphorically-flashing letters in the core documentation. (But documentation missing important caveats has been a repeated experience for me in Erlang.) Just, pow, gone. And it doesn't seem to restore itself, either, it takes manual intervention, which is really un-Erlangish when you get down to it. And, then, I can't _fix_ it. As I said, I am well aware that I can't necessarily expect to "replace" Erlang clustering right off the bat better than the original. But if I want to turn my socket into a [multi-channel connection so that pings get their own "channel"](https://github.com/hashicorp/yamux), I can. I can't fix Erlang's clustering. It's all built in. I'd have to _fork_ Erlang and I'm not going to do that. This goes a great deal beyond just Erlang: That's the problem with "built in" functionality. You can't _fix_ it without going far beyond just "replacing a library". For a Go example, do you not like how the scheduler works? Do you want to be able to prioritize threads? Well, too bad. It makes it such that, ironically, having something built-in can almost be a _negative_.
The thing is, A: that's what I'm doing anyhow and B: once I do that.... _why am I using Erlang at all?_ Supervisor trees weren't that hard to replace. The clustering wasn't that hard to implement. The language itself is terrible (i.e., syntax and semantics). (That's an opinion after 7 years, mind you, and from someone who thinks Haskell is just fine so no "you just don't like FP either".) Library support for things is probably already worse than Go and the gap is only going to open. Once I rewrite the code to use my own messaging layer anyhow, Erlang's not offering me anything anymore. This "solution" to my Erlang problems doesn't help Erlang.
I found the answer here: http://stackoverflow.com/questions/8034515/facebook-graph-api-jsonp-format-what-does-the-in-first-line-signify It turns out that Facebook does this same thing and Google has a different technique. "We added this to protect against an attack where a third party site bypasses the content-type of the response."
&gt; If you get to the point of feature parity between your go and erlang codebases, you should do a line count and benchmark, and post the results. I may. It would be a complicated post prone to misunderstandings, and I'm not sure it's worth it. After my post on Suture I got quite frustrated with people hearing things from my post, then posting angry screeds about the thing they learned from my post accusing me of not knowing the thing I told them about. In this case, I would be explaining the precise differences between the two systems (since of course despite my goal of a drop-in replacement it's still not _quite_ identical in functionality) and then I'd get to be subjected to a couple dozen people angrily explaining back at me how I failed to account for the thing they only know even exists because I told them. But, hey, here's one of the more interesting ones from PL theory perspective. It turns out Erlang has a unique combination of features that makes it very difficult to lazily parse a complex message. Suppose you have a TLV format, which stands for a "tag-length-value" format; every value carries its type, then a length, then the content. It's a very simple format. Suppose you want to parse the message enough to see where to send it. You'd like to just parse the "header" and leave the rest of the message unparsed, and you'd _like_ to not double-parse any element of the message. In Go, you can easily define a parser that parses down one layer at a time, saving what work it does but skipping what it can. In Haskell, you can naturally explain "how to parse the message" and depend on Haskell's laziness to only instantiate what it needs to instantiate. In Erlang there's no easy way to do this. You can define an API that reparses the message every time you ask for some bit, or you can fully parse the message up front (paying for constructing everything), but there's no good in between because of the way Erlang is strict and immutable. This is just an interesting observation more than anything else. The consequence is that Go is probably actually going to come out with more lines of code, because there's actually a fairly nice lazy parsing API for the messages that ends up taking up a lot of lines, and it's doing something the Erlang side really can't. It also has more lines because the messages are _typed_ and I have code to marshal and demarshal into those messages. On the other hand, if you look at similar-to-similar code, it's not that different on the line count. Once you have a typed message in hand and are processing it, it's the same. However, the Go lines are much _simpler_, because the code to pack records over and over for the gen_server states are really nasty stuff to read.
Thanks for sharing this, haven't seen much posted in the web-sockets/syncro department for Go (imho the "real-time" term is bit confusing; often means something quite different in programming circles, associated more to QNX and timing critical embedded systems than web-sockets).
He sort of says that in the Cons section. I didn't get from the article that he was trying (too hard) to bash anything. I read a lot of other people's Java code, so I too would like to take OO/Inheritance out back and shoot it sometimes. But I also share the author's frustration around Go not including generics or general inheritance. I'm not stomping my feet and demanding they be added to the language, but I am weary of the choice between writing type switches on interface{} and implementing an interface on umpteen similar struct types.
That's a good point. "Remote synchronization" or "web synchronization" maybe?
/r/GitHub
Background info in case anyone is interested: http://misfra.me/state-of-the-state-part-iii 
I would take it with a grain of salt. We run a 45 node cluster with 1 billion api requests/day and lots of data flowing around, on AWS. Works great. 
Thank you for doing this. I've wanted to see how time series databases work / index / store and this seems like a good start. An obvious question is what are the major differences considering existing time series databases like Influxdb
Nothing forces you to use those tools; you can just as easily open a socket in a one-liner. The manual quite clearly tells you that, and where and when to do that. You seem to be one of those people that thinks that everything should be obvious despite not having read the manual.
&gt; Oh, and ignore almost everything about the support for "live code reloading". Apparently the Erlang community knows it doesn't really work and everybody "just knows" to not use it, I use it without trouble. Quite a few of us do. Please stop spreading FUD.
No. It might be in a future but there one simple library which I build to make calls to twilio and mailgun https://github.com/nexneo/easyreq example: https://github.com/nexneo/easyreq/blob/master/form_test.go#L41
What about "end to end synchronization".. or "browser to browser synchronization"?
Thanks guys, did not know you could just drop your own code on play.golang.org !
That's true and BTW it's all written down already at [SliceTricks](https://github.com/golang/go/wiki/SliceTricks) (hint: prepend is a special case of insert :-)).
I already agreed on that :-). And the copy way is explained on SliceTricks as well.
I dwelled on that capital R for a very long time. I wasn't sure how it would be accepted by others. Perhaps I should remove it. I am glad you could potentially find it useful though :)
&gt; Having had similar discussions in the past already many times, please do not cite "ETS". ETS is implemented under the hood as messages to an "owning" process, it is not shared. The API may make it look like it is but it is not. It's still in a process, somewhere. This is false. ETS tables marked as 'public' acts like tuple spaces and have no process tied to them underneath. They also support RW-mutex locks and usually have sub-microsecond lookup time.
&gt; Suppose you have a TLV format, which stands for a "tag-length-value" format; every value carries its type, then a length, then the content. It's a very simple format. p(&lt;&lt;Type:8/integer, Len:32/integer, Data:Len/binary&gt;&gt;) -&gt; {partial, Type, Len, Data}. That is a partial parser for TLV data. The `Data` field becomes a sub-binary (Go-users, you should read this as a "slice") which refers the underlying contiguous memory block. Heck, Erlang was created to parse layered binary protocols partially.
&gt; I'm re-implementing significant chunks of the OTP in Go. The "circuit breaker" pattern does not ship in the OTP, and certain elements of it would be difficult to implement in Erlang in a performant manner, as it would require routing all requests through a single "circuit breaker" process for a given circuit breaker, which is an anti-pattern for Erlang if you want to scale. FWIW, fuse, https://github.com/jlouis/fuse uses ETS to avoid having to factor through a single process. It has linear scaling up to *at least* 8 cores and probably has no trouble scaling up to 64 cores given ETS is pretty scalable in the parallel situation. The current overhead is a couple of microseconds, but then you also get statistics on the circuit breaker. Replacing the counter with something faster is also possible, but I haven't bothered since at 500k+ calls per core, I'm well above typical circuit breaker request rates. Oh, and fuse also has a complete QuickCheck model to build confidence in its correct implementation. So I can explain to you exactly how it is race-free and correct even for massively parallel operation. And I can explain exactly how its read consistency breaks down and why you don't have to worry about that.
find your ip address, type "what is my ip address" into google. Give your parents that, append :portnumber if your not running on port 80. Alternatively you can get a temporary domain name from people like noip.com and point it at your ip address. Dont forget to open port 80 or whatever on your router/firewall for incoming connections.
http://localtunnel.me/
&gt; I can tell I'm torturing Erlang a bit by sending around multi-kilo- or mega-byte sized messages intermittently rather than single-digit-kilobyte-sized messages frequently, but still, I have a lot of problems I just really shouldn't have. I am not using Erlang correctly so "fuck Erlang! It is a piece of shit, use Go everyone". Really? Passing large megabyte sized message over the same channel as distribution control is just asking for trouble. &gt; I can create something that is a great deal less opaque and that I'll be able to far, You can create something less opaque with Erlang's TCP or UDP socket as well. &gt; If I "had" to stick to Erlang at work, I honestly don't know what I'd do next to fix my system. Create a separate network channel to shuffle large messages through it? Have you even asked the community for help? How many questions have you posted to mailing list or the IRC channel? 
https://ngrok.com/
Author here. Happy to answer questions. I've answered a few questions on [Hacker News](https://news.ycombinator.com/item?id=9163044) about this so I'd prefer to not repeat answers.
I'm looking for a similar thing, and after a bunch of searching, what I've started using is: https://github.com/thcyron/graphs Not sure whether this is what I'll continue to use, whether I'll patch this, or whether I'll learn enough about graphing in go to have someone point me to something better. In any case, my current goal is to implement https://en.wikipedia.org/wiki/Topological_sorting and get more familiar with go. If anyone has an implementation, please feel free to share.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Topological sorting**](https://en.wikipedia.org/wiki/Topological%20sorting): [](#sfw) --- &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science), a __topological sort__ (sometimes abbreviated __topsort__ or __toposort__) or __topological ordering__ of a [directed graph](https://en.wikipedia.org/wiki/Directed_graph) is a linear ordering of its [vertices](https://en.wikipedia.org/wiki/Vertex_(graph_theory\)) such that for every directed edge *uv* from vertex *u* to vertex *v*, *u* comes before *v* in the ordering. For instance, the vertices of the graph may represent tasks to be performed, and the edges may represent constraints that one task must be performed before another; in this application, a topological ordering is just a valid sequence for the tasks. A topological ordering is possible if and only if the graph has no [directed cycles](https://en.wikipedia.org/wiki/Directed_cycle), that is, if it is a [directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph) (DAG). Any DAG has at least one topological ordering, and [algorithms](https://en.wikipedia.org/wiki/Algorithm) are known for constructing a topological ordering of any DAG in [linear time](https://en.wikipedia.org/wiki/Linear_time). &gt;==== &gt;[**Image**](https://i.imgur.com/Z1jHxCm.png) [^(i)](https://commons.wikimedia.org/wiki/File:Directed_acyclic_graph.png) --- ^Interesting: [^Directed ^acyclic ^graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph) ^| [^Dependency ^graph](https://en.wikipedia.org/wiki/Dependency_graph) ^| [^Tsort](https://en.wikipedia.org/wiki/Tsort) ^| [^List ^of ^graph ^theory ^topics](https://en.wikipedia.org/wiki/List_of_graph_theory_topics) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cp8rg0f) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cp8rg0f)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Ty, this worked great for what I needed! (a quick presentation) I did some research and it seems that just doing this isn't too safe. A random 5 digit port should be chosen and gone through a VPN as well would make it much safer is that right? Just putting this here incase other people need this information
Oh man this looks good. Would you know what the difference between this and ngrok is? (in terms of security) (beginner here)
How lame. I can reduce this to just 3 DSL's built on top of lenses! (I don't grok Haskell)
"Gocassa"? Why not " Gosandra"?
&gt; Yes, and if you pass that partial to two different things, those two different things will have to parse them twice, because there's no way to lazily instantiate a second level of the parse tree. (Bear in mind "laziness" as a concept does not just encompass 'doing it later' but that a given thunk is evaluated once.) Pattern matching is so fast in practice you usually don't need to worry about this. If that turns out to be your major bottleneck, your other code has to be almost non-existent for this to matter. At least that is my experience in protocol handling. As for the reference passing in Rust, it *is* a nice scheme. Some of the same ideas is to be found in the ATS language and it does speed up some computation to know that you have linear access to data. Immutability/persistence on the other hand is a key player for another important Erlang trait which is data safety and isolation. Handing over data from process to process breaks that abstraction. And it also breaks another important trait which is to be able to report a non-destroyed state in an error report. 
For me this: func ParseConfig(conf cmap.C) { // get string value on key `key1` or return default value (`some default` in this case) setting1 := conf.StrOrDef("key1", "some default") // the same, just getting int setting2 := conf.IntOrDef("key2", 1234) } is much more cleaner than this // parse config func ParseConfig(conf map[string]interface{}) { // default value setting1 := "some default" if val, ok := conf["key1"]; ok { setting1 = val.(string) } // default value setting2 := 1234 if val, ok := conf["key2"]; ok { setting2 = val.(int) } } First example is common in languages like Python and Scala for example, and I wanted the same in Go.
It's similar. ngrok is most like an SSH reverse tunnel. It establishes a secure, TLS-encrypted connection to the ngrok.com servers and then forwards all traffic for a particular hostname through that connection to your local server. (I'm the creator of ngrok)
I have been in the same position, I have been learning go and experiment so there very well could be exploits against my site. Common practice seems to be to create a user with no shell and run your server with his privileges. Another although seemingly broken in go is to run as root and then setuid to a low privilidge user after binding port 80. Randomising port will lower the number of attacks against you, but it's not true security.
But.. That's how you do pipelines in Go. Spawn a goroutine for each step function. This package just removes the overhead, which is especially nice if you want extras like multiple goroutines to handle a step, etc. I wouldn't call this a callback, just as I wouldn't call a function you pass to a goroutine a callback. I understand where you are coming from. I despise unnecessary callback spaghetti, but I assure you that's not the case with go-piper.
Obligatory downvote. Let him use MongoDB if he wants.
Capital R immediately associates it with [R](http://www.r-project.org/) (the statistical progamming language) - just a thought from someone using R almost full-time.
Not a solution to your exact problem, but if the tunneling options don't suit you you can try [koding.com](http://koding.com). They provide a free VPS with a subdomain so you always have the same environment available, and you can leave it on while your PC is offline.
Well then it's a matter of preference. To me idiomatic library is the one I embed in my code and not the one I need to embed my code into. The latter is an approach that frameworks take - I won't be locking in my design just to use goroutine wrapper.
I'll humor you despite your trolling...why would we migrate our entire database, retrain our entire team, and go back on months and months of perfecting our infrastructure, just because of a benchmark test run in September that wasn't done in anything resembling our environment and is now moot with the release of WiredTiger? The answer is: we wouldn't.
It may have been golint that warns about such errors. I can't help you regarding the test.
Ok so it sounds like I'd be fine since I had to go to 192.168.1.1 log in as admin and change a setting to forward a port. As a side question though, would tunneling be even safer? I see there are options like ngrok and localtunnel which seem to both add another layer of indirection.
Yeah, that was sort of my plan. I was just hungover and still asleep when I wrote that. ;)
Or fork it to write to mondash https://github.com/Luzifer/mondash/pull/2
Fair point. :P
Library is more like convenient way of passing configuration to other libraries (when configurations are strings, ints, booleans). That's my use case for it, and serves me perfectly ;). As you described for your case is not good, for someone else may be good. It is about finding right tool for particular situation ;).
I recently wrote something similar that pushes directly to StatsD: https://github.com/ahamidi/negroni-statsd-middleware
Any reason you went with `peterbourgon/g2s` instead of `quipo/statsd`? Just curious.
ah, this is something i was looking for. One of the main features for node-webkit is that it allows DOM manipulation from js. How would one do such a task using go? Is there any go tool that allows updating DOM content. Another strength of node-webkit or nw is that you can use node modules. This module approach allows developers to build big application and divided it into small node modules. For example, i can have a my_protocol module, a database read module and a serial_port module. With nw, you can update DOM with results from these modules. Plus, you can reuse the modules from npm community. Now coming to go, most of the module use cases fits with go environment. But how to update DOM in async way using go module?
My intention was to just build a traditional web application and use something like React to manage the front end. So far I've just had specific scripts for each page which works alright when you are prototyping. I know absolutely nothing about nodeJS and npm. I've used it for some basic stuff and for building, but that's about it.
There's https://vimeo.com/115940590 that gives quite good overview. You can use wrapping functions instead of decorators to get the same effect.
Personally I go for "if its stateless then use structs otherwise use pointers" type of pattern. Although you have to be aware of the possiblilty of reduced perf due to memcpying all of those structs around.
How would one go about securing expvar for production? I can't find a way to pass it any config. 
Ultimately devs decide what is idiomatic and what isn't, not the Go dev team. If Go allows something and it works for you do it.However a middleware stack, like nodejs web frameworks is better suited for the thing you want to do.
On mobile, code snippets seem to be a bit too large
10k line of codes isn't that large. But It may translate into 50k lines of code in Go, you need to be aware of that. The first thing you should check is look at the packages you use in python and see if you can find equivalent in Go. If you can't , you'd be better off sticking with Python.
Is this a hobby project or for work? Why do you want to rewrite it? 
It is a work project, but rewriting it would be a personal exercise. I think deployment and distribution would be easier with GO, but otherwise there's really no tangible benefit. It's low usage so speed and performance increases would be negligible. The network is the bottleneck anyway.
Yeah I'm having an issue getting horizontal scrolling working :/
From my experience with Go, I have found that Go and its community emphasizes simplicity. Therefore many Go devs suggest just using the net/http package instead of an entire framework. The same mentality applies to ORM's, most recommend against ORM's and instead suggest using the sql package. As a beginner, I really enjoy this simplicity since, I really understand a lot more about the backend of a web app 
Ah, cool. I haven't made a full-featured website in Go yet. My big project was an SSH reverse proxy for Git and Mercurial. That was a perfect project for Go. I'm looking forward to tackling something like what you're considering. I imagine you'll learn quite a bit. Good luck, have fun!
I've been using LiteIDE for a few months now and I'm very happy with it. I'm curious though why it wasn't written in Go. 
More specifically, when you say "real-time" are we talking time constraints measured in microseconds? milliseconds? or does real-time mean "reasonably up-to-date processing of a stream of data"?
I think it's awesome. 
yeah they should just d/l the script and *then* run it
I actually started out using that package but switched to g2s. I can't remember the exact reason at the moment, but I vaguely remember struggling to get it to work with the datadog agent that I was running or something like that.
I think Dave's point here is extremely relevant to both the success but also the misunderstanding that outsiders of Go have. There isn't a lot of features in Go, and that itself *is by far it's best feature*. Many come to the language comparing it to others with features X, Y, and Z, without factoring in simplicity. I can look at any Go code and truly know what is going on without taking much time, something that can't be said about many other languages. 
Oops! Thanks for precising that. we have ML solution that get data from different resource to apply this model on it. The model is already there, now, we r trying to work on options to make this scalable. However, the real-time that we are working on could be noted as "reasonably up-to-date processing of a stream of data" between second and couple of seconds if that makes sense. But I am just curious what solutions are there for microseconds? milliseconds? in case you wanna point to it.
I'd stick with bleve - that way when someone asks you about it you can show them [cool explosions](https://www.google.com/search?site=&amp;tbm=isch&amp;source=hp&amp;biw=1366&amp;bih=639&amp;q=bleve).
yeah i was being sarcastic at the guy's 'disgust'
golang-nw = Call a golang web application from node-webkit to get a native looking application. that's all there is to it.
I also want to add that since the script is wrapped in a function curl actually downloads everything before anything is piped it into `sh`. So, by the time the script is run is just you, git and go.
Unfortunately _just_ bash does not guarantee a package manager, and what about a brand new machine?. Which is why I actually use this with [git.io/getdarwin](https://git.io/getdarwin). Oh, one more thing, this will also setup your `$GOPATH` and even try to create a workspace _base path_ if you have a github user configured on your machine.
There are a lot of entire web apps written in Go based on Go web frameworks like Beego or Revel. I chose Beego for [this basic site](http://60plusadventures.com/). The [source code is here](https://github.com/emadera52/sixty). I've gotten side tracked by some actual work, so I'm not sure when/if anything else will be done. I don't make full use of the Beego ORM, but as ORMs go it seems adequate. Beego handles sessions, context, auth, CSRF issues and a lot more out of the box [(Docs Here)](http://beego.me/docs/intro/). Adding custom access restrictions should be easy using middleware functions in a route's controller. 
Keep this up! This is awesome, I feel the Go community would love it.
Okay, good point. I can see where your script would fit in certain use cases.
Yes it is, but that of course depends on the complexity. So is it a Go idiom, yes; is it appropriate for all situations, no. PS. it's "Go" not "GO" :D
When you use slices of structs, keep in mind that every time you retrieve an element or put an element, a new copy of the struct variable is created. - when you `range` over a slice of structs, you get a copy of the element. Any changes made to the range variable won't affect the slice: http://play.golang.org/p/sNiothjTTa - when you append an element and change the original struct variable afterwards, you do not change the slice: http://play.golang.org/p/QR8hdt1VAq - etc When you do not mind this and your struct is small, use slices of structs. Otherwise, use slices of pointers.
You can also take a look at [negroni](https://github.com/codegangsta/negroni) with [oauth2](https://github.com/goincremental/negroni-oauth2). It allows you get up and running faster, without locking yourself too much into a framework.
slides seem to always be 15-30 seconds behind what they were live, but I think it's still understandable
For some reason, the blog post has moved to https://sourcegraph.com/blog/live/gopherconindia/113241457917 and the original link is dead.
I'm not sure if it's possible (or wortherwhile) to remake the video, but the organizers have graciously said they would take a look at it.
REST/JSON backend written in Go: https://github.com/xyproto/scoreserver 
There's a Go talk from fosdem on the diameter protocol and how they got Go to do some seriously real time processing and another on an efficient backup solution. My takeaway from them, is that with a fair amount of optimization you can get really good results. On first try you'll almost certainly get the speeds you need.
Nicely written ! Although I would have expected a reference to the 12 factor app.
We are :)
why 1.6? are you referring to planned improvements in the GC?
Cool project, thanks for the reference.
30-100ms is easy in Go. The biggest issues you'll find are GC, which you can profile away with some work, and slow standard library implementations of things that you wouldn't expect to be slow, which takes more work but may or may not be necessary depending on total data volume through the pipeline.
all I see is that voxxed.com doesn't work without javascript turned on.I'd like to read the article,really want to, but a blog shouldn't require javascript. to bad, I with developers stop doing that,or what's the point of webpages?
I have just completed ~3k SLOC full-feature web app in Go (minimal JS, form submits + page reloads everywhere, closed source), using gin-gonic framework and gorilla sessions. All in all, it's been a pleasure. Lack of generics and higher order constructs like Enumerable in Ruby was kind of annoying for me, as it required some code duplication. But all the practical aspects of Go, easy deployment and good readability had much bigger positive effect. Things like user access restrictions to sections of a site were easy to implement with gin-gonic. 
Your loss mate. You didn't get to experience a sweet and slick pop-up window that asked me to join some newsletter or whatever. Who needs no-nonsense static content when you can be interrupted while you read instead?
Unless something has changed, the reduction in complexity alone might be worth it. 
 Behaviour("Driven Testing", Is() { the.Most("Awful way of writing", Tests() { in.Go() }) })
The plan is for about 275 pages.
thanks
1. Implement some feature in Go 1. Use [net/http](https://golang.org/doc/articles/wiki/) to make it accessible over HTTP 1. Call that HTTP service from Rails using your HTTP client of choice 
I don't mean to sound rude, but, do you have an expected timeframe? Go in Action (Manning) seems to be moving along at snail pace...
Will the 25% maximum CPU utilization be set or will it be available as an environment variable like GOMAXPROCS that can be tuned for the given machine/application? Also thanks for the explanation, very informative.
angularjs is going to ruin your life.
I like the idea, good job putting the work in. I can see where it would come in handy as an easy, automated way to quickly compile go from source on new machines. It does make the assumption that you have git installed though, which is something that might not come on new machines. To install git you'd probably want to use your package manager since it has a few dependencies, and at which point its just three more keystrokes to add ' go' to the end of the command. You could add a check for `if has git` is false, then curl and unzip a direct link to the src[0]. Also, I think that using the branch `release-branch.go1.4` instead of using the tag `go1.4.1` will get you the latest 1.4 release. The current release of go is 1.4.2, and your script is grabbing 1.4.1. I _think_ using the release branch instead of the tag will grab the current release. That should keep you from having to continuously update the tag at every minor point release. [0] https://github.com/golang/go/archive/release-branch.go1.4.zip
And how the fuck is this a problem?
Argh, sorry, I was thinking of 1.6 as "the next release", but the next is 1.5. Once 1.5 is released it should be okay with limited GC pauses.
Only if you're developing with it.
"Softbound print: Fall 2015 (est.)"
I'd say it depends. If your interface has one method, it should go on the godoc for the interface. If it has two or three, this might still work. If your interface gets larger I start putting the individual specifications for what the interface implementations should be as comments in the interface specification itself, though. Either way the user ought to be looking at the interface's documentation to figure out what's up. Idiomatic Go is that interfaces should be kept as short as possible. However, I find that within an application interfaces sometimes grow somewhat larger than in reusable libraries, which tends to happen with lots of things (applications are often dealing with exactly the details the libraries abstracted away so the libraries could be nice).
We are pushing to have the Go In Action book in print for GopherCon. I agree this book has taken a long time :(. I have had to write several chapters twice, which in the end is a good thing. It was more important to have a book that was as accurate and helpful than just getting it out on paper. The Go community has really been really helpful in this regard. Even after it is in print, there will be things I wish I could change or write differently. Nothing is ever perfect.
This is an extremely poor article. Please refrain from making random posts about anything.
Blog post by the presenter that touches on the same ideas: https://inconshreveable.com/07-08-2014/principles-of-designing-go-apis-with-channels/
Very nice write-up &amp; code. Does this LCS implementation work with binary data?
I quite often write something like: // Write implements io.Writer.Write by [doing something]. func (w *myWriter) Write(buf []byte) (int, error) The interface is the most important place for your doc comments, as it documents the contract that you are expecting implementations to fulfil.
Oops sorry. Submitted too quickly from my phone without realising it was content-free.
Finally got some time to play with this. On a very small data set (~1 million hashes), using simstore a search comes back in 37us, while using the VPTree from https://github.com/DataWraith/vptree a search comes back in 134ms. I'm sure the vptree implementation could be specialized and speed up, but that's still a serious performance difference.
Very. I've moved (almost) everything I was managing from python to go. Its an almost because I only have so much time and haven't been able to get to some items, yet.
Garbage collection seems like one of those solutions that creates a big problem in itself. Keep it simple for users by requiring a complex internal implementation. But then it seems like performant code needs to work with the collector in mind and minimize garbage creation, so there's still a user complexity load. I'm no language/computer science guru, but Objective-C's automatic reference counting is the happiest I've been with memory management. I did have to dig into the compiled assembly to find memory bugs a few times though, so perhaps "you are working in programming, memory management must always be taken into account by the user" is a valid statement. Or "memory management in high level languages is inherently complex and must always be spread between the language implementation and user". My question then is there a solution that totally pulls all memory management complexity into the language implementation while still enabling performant code? Probably on the minds of hundreds in academia for decades already...maybe I should go back to school.
I do miss puzzling over 'clever' things. There's something human about code easter eggs or strange formatting, even if they can hurt the work. Humans aren't perfect, which should be celebrated. But it's worth it to remove a lot of those avenues, for every neat trick there are a million frustrating ones. Go can be kinda boring...but for getting shit done that is great. And there's a ton of exciting tricks in concurrency and interface composition anyway.
I suppose that by that definition the languages in the opposite side of the spectrum should be called feature-hungry languages. Can we characterize most contemporary languages with that description? I can only think of C++ and Scala -and possibly C#, but I don't know much about it- in that way, most other languages are pretty conservative about their featuresets AFAIK. Take for example Rust, they have taken features like green threads and GC out of the language. They simplified the use of pointers and focused the language around its most unique feature, memory safety without a GC. I don't expect it to change much as a language for some years after 1.0 is released. Or Javascript, yes they added classes to the language, which is probably its most disruptive feature in ES6. But the reality is that it's just syntactic sugar around prototypal inheritance, so nothing changed under the hood. And Java has just recently added lambdas and added generics almost a decade after 1.0. You can say that they have added features that changed the language over time and were unrestrained, but Go 1.0 is not even 3 years old so we can't really make a serious argument about its feature hunger. Most languages don't change much in that space of time.
To answer your first question, you can sanitize inserts by using placeholders in your VALUES statement: db.Exec("insert into tbl VALUES (?, ?, ?)", var1, var2, var3) If you are inserting a lot of values, such as from a csv file, you have a few options: * Use your database's data loading. In MySQL this is the LOAD DATA statement, in sqlite it's the .import statement, etc. This usually is preferred if you don't need to be portable. * Build up a template of "(?, ?, ?, ...),...)". Some databases like sqlite have a limit to the number of placeholders you can have in a statement (999). Here is an example: http://play.golang.org/p/YOBOJYBKs_ 
That is one of the goals of Rust. 
Absolutely gorgeous. Saved as my new go-to introduction to commenting code. 
How do you find the http2 package fares at this point? I know it's still experimental and on draft 14 but, any major hiccups or gotchas that you've encountered?
Cool stuff. Might I recommend bundling in [LiteIDE](https://github.com/visualfc/liteide)?
Very nice!
I have tons of examples in my structs package. Check it out for usage: https://github.com/fatih/structs/blob/master/structs_example_test.go
 Instead of this: . ├── diff ├── doc ├── git ├── go ├── mercurial └── workspace Zip single directory, don't allow unzipping your distribution create random number of directories. Keep all executables in a single directory, so it's easy to add your distribution to the %PATH%. If keeping all executables in one place is not possible, do what Git distribution does - create cmd/ directory and keep there alias files, like go.cmd, git.cmd, hg.cmd etc. The batch scripts you have in workspace/ are useless, no-one sane would invest time in learning how they work, especially when they're not just a straightforward wrappers around go toolchain: workspace $ cat _Build.cmd @ECHO OFF Setlocal EnableDelayedExpansion CALL __Global.cmd ECHO *** Go Build *** ECHO Build compiles packages and dependencies ECHO. FOR /F "tokens=*" %%A IN (Packages.txt) DO ( SET PACKAGE=%%A SET FIRSTLETTER=!PACKAGE:~0,1! IF NOT !FIRSTLETTER!==# ( ECHO Building: !PACKAGE! cd "%GOPATH%\src\!PACKAGE!" go build -v %LDFLAGS% !PACKAGE! ECHO. IF !ERRORLEVEL! NEQ 0 PAUSE ) ) Portable Go distribution for Windows should allow for normal Go workflow. I believe I wrote you (or someone that had similar project?) all this last time you posted your project here, nothing has changed.
I completely understand the need to rewrite chapters or whole sections of them. For Go in Practice we've already had to rewrite sections and even all of a chapter. In my limited experience (this is my second book) it's not uncommon. For those paying money I think this is a good thing. It's not like writing a series of blog posts. There is more of an investment in quality.
Link in the description appears to be incorrect. First for some reason I had a bit of trouble copy &amp; pasting it out, and second, it's just wrong. Correct is: https://www.hakkalabs.co/articles/flatbuffers-golang-fast-fun-serialization
&gt; I'll leave this up in case anyone else was confused about this. you da real MVP op
So this looks almost exactly like [capn-proto](https://capnproto.org/) to me. I wonder what if any benefits it has over the that project?
So far, it has behaved as expected, without any surprises or hiccups. The most unexpected thing was that HTTP/2 and HTTPS are expected to be used together, by clients and by browsers, while unencrypted HTTP/2 is fine according to the specification. Browsers even complain when HTTP/2 is used without TLS/SSL on localhost. Also, there are frequent log messages about timeouts, but this may be completely normal. Everything has worked great so far.
Thanks for the info. I've seen the time out issues too when reading client preface, I believe. Not sure yet if that's normal. Might open an issue and ask.
https://capnproto.org/news/2014-06-17-capnproto-flatbuffers-sbe.html
Yeah. No. Seriously? Push out *Java*? The most "I-refuse-to-touch-it-without-an-IDE-generating-code-for-me" language, being pushed out by a language whose idea of an "IDE" is some vim/emacs syntax highlighting and stringing together 4-5 external programs? I love Go, but we gotta have some realistic expectations here. 
I have been on that page so much while figuring out mysql stuff and I don't know how I missed that. Thanks!
Ok, so prepared is for when you need to reuse it and Exec is for when it's a one off case then?
I've finished the wiki pages with specification and introduction (https://github.com/adnanh/webhook/wiki) and started actual work on the new version (in development branch) that will implement everything that's in the wiki pages. It should now hopefully be more clear on what this tool will be, and how to use it :-) Thanks for your feedback again, it's been helpful!
I definitely agree that some middleware that works with raw net/http as well as some common web routers would be pretty useful. I'll add it to my list; alternatively, I welcome pull requests.
Promising. Sure would be nice to see a Go alternative to Djatoka
damnit. i literally just built my own (much more basic) version of this last night! will definitely look into swapping it out for this, the error/stacktrace handling in particular looks great.
Does it provide drill down capabilities ? In my world view of the log I would like to see just the request / response, to identify which response I should look at. But then I would also like to be able to drill into that response to see which task within that job was the holdup.
There is no plugin that supports debugging variables in go &gt;1.2 so get used to using a good logger :-)
I just added LiteIDE so you don't have to use the batch scripts. In Windows, there is an "Extract All..." item in the right click context menu which extracts to a new folder already. The folder structure follows the Go recommendations for a workspace, I even called the folder workspace to make it easy for the "no-one sane". And the batch scripts are wrappers - they just have a few necessary features that make them much easier to use. But I think you're missing the point of this whole project: Go is easily portable now.
Yes, it does. It's not baked into healthtop yet but it's in healthd and the overall architecture. Within each job, you can drill into the timers/events/errors to see what the issue is. Here's an example of the JSON from healthd: "jobs": { "/api/v2/attachments": { "timers": { "dbr.select": { "count": 35, "nanos_sum": 91145762, "nanos_sum_squares": 1.329194811437408e+15, "nanos_min": 189257, "nanos_max": 28714776 } }, "events": { "load_session.get": 7, "starting_request": 7 }, "event_errs": {}, "count": 7, "nanos_sum": 97677709, "nanos_sum_squares": 1.894270321203881e+15, "nanos_min": 2521777, "nanos_max": 32055426, "count_success": 7, "count_validation_error": 0, "count_panic": 0, "count_error": 0, "count_junk": 0 } }
Nice...
&gt; I feel like overall I'm trying to go against the grain by implementing these SOA patterns Your code is your own, do what's good for you but in no time you'll find yourself fighting the language because you can't apply this or that pattern easily. Why are you using Go at first place? that's something you should ask yourself. I like the language but it is clearly not for every programmer out there.
A screenshot is always very helpful ;-)
(Rust core here, sorry for butting in, just wanted to clarify a thing or two.) In general, for its lifetime, Rust has been trying to figure out how to achieve a safe systems programming language. A few years back, it was determined that you didn't need a GC to do so, and so it became "memory safety without garbage collection." But, over its lifetime, Rust has grown and thrown away more features than most languages have. Tons and tons. While it's true that Rust is not the simplest possible language to use, I think it may be very close to the simplest possible language within those constraints. It's just an inherently complex domain.
Are all the stats persisted in memory or does it flush to disk at some point?
This looks solid. Great work.
You might think about changing the name since there is a CMS already called [webhook](http://webhook.com)
... most especially for (visual) tool ...
Although I agree with you, the go devs have stated that name collisions are fine because canonical imports remove ambiguity
Sourcegraph tools are awesome, but the UX is not good. I'm always struggling on where to click, what to do. It's not obvious and simple. Just improve the UI/UX and it'll be awesome, trust me. It seems like there is tons of huge stuff but the UI can't show the abilities of it. You might ask if I have some suggestions, no I don't (I'm not a UI/UX designer). But using a lot of other tools I just felt to comment on this. Keep up the good work!
I'm curious how this might boost Golang adoption among the STW haters. This is commonly a major issue from systems language developers investigating go. A paced concurrent garbage collector means that Go takes another step towards real time applictations, no? You can now rely on responsive goroutines!
For an (IMHO) absolutely valid example of how large interfaces are used in a library, check out some [gopacket interfaces](https://godoc.org/code.google.com/p/gopacket#PacketBuilder) 
The server example you linked only decodes one `P` per connection. You need to wrap that in a loop too. You're also creating a new encoder each iteration of your client's for-loop. Move NewEncoder outside the loop. And **don't ignore errors!** (the example you linked isn't good in that respect)
I think I understand, so since in the server example he's doing go handleConnection(conn) He's got full control of the connection? What exactly would need to be looped over then? I understand that in the example, the for loop blocks on conn, err := ln.Accept() and continues once he has a connection, but does the decoder work in a similar way? I'm still unclear about what things are running synchronously, what things are (I think?) spawning a go routine and just waiting for things to happen.
On the server you've created 1 `P`, and you decode into it once. That's all you see. You should have something like: for { err := dec.Decode(p) if err == io.EOF { fmt.Println("done") return } if err != nil { fmt.Println(err) return } fmt.Printf("Received : %+v\n", p) }
don't worry, it fixes another problem you haven't got to yet ;) 
Thanks. You're right, that's a great example.
&gt; This seems ok to me. Each connection hits this, and creates a single decoder and a single packet (the fact that they are just overwriting p each time doesn't bother me...unless it should?). Now, within the for loop, the blocking is happening on the decode? So when a packet is actually sent in that matches a connection I already have established, the first place it hits is that decode line in the for loop, correct? Basically yes. Inside Decode is where conn.Read is being called, so that's where it blocks. &gt; I'm also a bit fuzzy on what actually causes err to be equal to the io.EOF. It happens after my last packet is sent, but I don't entirely understand why. Something to do with the conn.Close() on the client side? conn.Close just closes the tcp connection. Go wraps the network sockets into a fairly nice api, but you still need to understand networking, and sometimes warts from the berkley sockets api leak through. io.EOF is used to signal that there will be nothing else to read form an [io.Reader](http://golang.org/pkg/io/#Reader). It happens here because the client Closed the connection, the decoder received EOF from the conn.Read call, it finished up decoding and then returned that EOF up the call chain. 
&gt; I thought maybe wrapping him up and calling him as a goroutine would sort of put him aside, getting called as needed (when the server sends something back), but all that does is causes the client code to quickly reach the end of it's execution, never actually (as far as I can tell) receiving or decoding packets returning from the server. Yes, when `main` exits, the program ends. You need to wait somehow for the receiving goroutine to do what it needs to do. Back up and start reading... You're on the right track, but you need to cover the basics fist. Get a grasp of Go's concurrency primitives. Get familiar with the stdlib, and it's common interfaces. Get familiar with common go idioms. - Do the [Tour of Go](http://tour.golang.org) if you haven't. - Read [Effective Go](http://golang.org/doc/effective_go.html) if you haven't. - Read the [standard library docs](http://golang.org/pkg/), and check the source (definitions link to the source) when you have questions. - Definitely read the [Language Spec](https://golang.org/ref/spec), and maybe even the [Memory Model](https://golang.org/ref/mem) when you get comfortable. 
Higher level languages provide memory safety for free(think buffer overflow exploits). Something that in C needs strict auditing. Not saying that auditing is not needed to call something Secure... but projects like these are so small and very clear code... someone could audit it in a single evening if they wanted. A larger project like OpenVPN would take months and even then not knowing if some buffer overflow somewhere is still uncaught...
Must have been a temporary problem on their server.... this is not my server, it's the generic godoc.org site. It seems to be working fine now, btw.
You should make an issue at gddo and ask. Better to find out than to assume.
I will, thanks.
1.4
totally agree , it will be interesting to see how Go evolve in the future though. But right now ,it's clearly not a language for everybody.
&gt; I'm no language/computer science guru, but Objective-C's automatic reference counting is the happiest I've been with memory management. Me neither :-), but that still sounds like a horrible approach to me if you have multiple threads. Besides wasting cache bandwidth, you get increased main memory bandwidth (because that's how you communicate your reference count changes) and may have to use atomic operations for the whole thing to work correctly in the first place. GC-based runtimes don't write into memory locations all the time while just accessing values (and applications ought to read values from memory more often than they write them). &gt; My question then is there a solution that totally pulls all memory management complexity into the language implementation while still enabling performant code? Well, I don't know but languages such as Common Lisp always seemed very performant to me even without allowing for manual tweaks. Go ought to be even better in that respect even if you just consider the compact layout of its values in memory. Plus, the more cores (and finely threaded applications) you get in your new machines, the less problematic the automatic approach becomes compared to any manual solution. Even if you get slightly higher performance with manual resource management, forcing you to scale down on your application's architecture doesn't seem like a good trade-off.
Shouldn't one have some special grammar for that? It's not like processing code ought to be alien to the Go workflow.
Thanks! That's what I figured. Is authentication between apps something I should be concerned about?
WAT?!
Can someone explain what this is? Are they making a JVM port in Go?
I guess, but it's really badly documented and there's basically no comments at all so I'm just guessing. It's probably really early in development.
Or someone is just doing it for class or something and wants to share
It's not. These comments are just really silly. Much better discussion [here](https://news.ycombinator.com/item?id=9203045)
While that is a pretty dank meme you've posted, this implementation uses Go's native GC only.
Why not copy the entire file, open the copy for reading, open the original for writing. Seek to the start of the offset in the copy, and seek to where you want the new start to be in the original. io.copy from the copy to the original and done.
Because that's a lot of redundant reads and writes that don't need to happen.
Because writing a virtual machine in a GCd language - impossibru. /s
No, but only the bits after the offset need to be shifted. Copying the entire file means that you're reading and writing everything before the offset when it's completely unnecessary.
&gt;copy and paste Can you be more specific? That could mean a lot of different things when we're talking about low-level file operations. The contezt of the problem is editing embedded metadata in a file. There isn't any shortcut, really.
In your original question I thought this was a one time simple task, so you could ctrl-c ctrl-v the file and just do a little copy to simplify the coding part. I didn't think you were concerned about optimally doing this. I apologize for any confusion. If you're looking at minimal reads/writes there's no shortcut as you said. But it's not a particularly complicated for loop. 
Great so far! Just unzipped, ran the .cmd and the IDE popped up. Get, Code completion, Type hinting, Compiling, Testing; all working in LiteIDE straight out of the box. 
No worries, thanks for the help anyways!
The article is 3 months old. Plans to bootstrap Go have been known for a while. Most recent news on the topic is: Go now bootstraps itself. C has been eliminated from the compiler implementation.
I ask because of interest in using Go for embedded systems or video games, where timing and quick responses are critical. Agreed completely on not giving up the wins of garbage collection. It removes a whole swath of bug sources and reduces your own brain load, which fits well with what Go is about (C languages +- all of the lessons learned in the last 30 years). All of those well thought out Go lifestyle features (gofmt, no runtime library dependencies, syntax, interfaces, package scoping, compilation model, go get, etc etc) I want anywhere I use a C language. Which means timing critical applications, where garbage collection blips may not be ideal. Of course it depends on the collector implementation. It could be a different style of collector (e.g. with well known timings and parameters all facing the user) is the correct solution for those arenas. So the hypothesis is there are no memory management solutions that give the niceties of GC without user facing effects in all applications that can be written.
that's interesting. had there been any documentation I would have known that :/ (but I wouldn't have missed the joke opportunity regardless)
Because author likes Java and that probably amounts to being mentally challenged in a funny way
Because you can't use generics
And for Go there is http://golang-sizeof.tips/
As much grief as I may get, I like PHP's way of handling this. You can pass an int to continue or break and it will break out of that many control structures (at least, that is the way it worked years ago). That aside, I find that if I have to use goto or labels, then I can usually refactor the code to call out to a function that returns instead of jumping to the label. 
If used properly (how Go basically forces you to use them) goto and labels aren't hard to understand, and can help readability. Obviously goto/labels should be used sparingly as they directly affect the flow of your program, but a goto is basically a jump whereas a function (usually) requires a new stack frame, pushing parameters, etc.
Cause var VARNAME VARTYPE [ = VAL ]. If U want init with VAL, do array := [10]byte{'a',... or var array [10]byte and only after init add VAL's.
thanks!
not relevant to the error but I'd let the compiler do the counting and do: `var array = [...]byte{'a',` //etc
Instead of the ugly syntax you have in the example with flag, why don't you just implement `flag.Getter` (or at least `flag.Value`)? (I.e.: Just copy the few small mostly one-line `*boolValue` methods in $GOROOT/src/flag/flag.go over to your type.)
Thanks for the tip. Just did it.
Shouldn't the compiler optimize to minimize padding or does having access to the true memory structure matter more? **48 bytes:** struct { a string b bool c string d bool } **40 bytes:** struct { a string b bool d bool c string } 
Why you're putting empty lines almost every second line of code? 
It is another feasible approach.
If the files aren't very big (i.e., in general under about 100MB or so, exact numbers may vary depending on your goals), I'd suggest pulling them into RAM, manipulating byte slices (probably a slice of byte slices so you can easily break the file up into pieces), then safely writing them back out atomically (usually by writing into a new file, then renaming the file into the original place). Direct manipulating files is certainly possible, but if you get that code even slightly wrong in a way you didn't expect, _including writes getting interrupted halfway through for any reason including system failure_, it starts destroying files irretrievably. "Oops". Note that the point here isn't really to make your code easier to write... that's a happy side effect. The point is not to perform dangerous operations on files non-atomically. I think you'll have to write this functionality if you do need to directly manipulate files (hope you have good backups...), as io.Copy doesn't have any provisions for when the src and the dest overlap. Use bigger chunks, though; try to read ahead much farther than you're writing ahead. It'll perform somewhat better. (Disk caching will pick up the pieces after you if you use chunks that are too small but it'll still most likely be better to not stress it in the first place.)
it's bad when everyone expects it to work like Gnu flags, i.e. `tar -xvf` means `tar -x -v -f` not `tar --xvf` Screwing with people's expectations is bad. However, fixing that would screw up backwards compatibility. But fixing the help output at least makes it look nicer.
I've been using Nginx to both redirect http to https and as a reverse proxy that terminates https so my Go server can just handle http. A lot of Gophers have suggested that it's overkill to do so, but the nginx config is just so mature. I was wondering what other Gophers prefer to do in production.
Gotta leave space for comments on the printout /s...I hope
[goSQL](https://github.com/quintans/goSQL) might interest you . It is based on database/sql. It has everything you ask and more. It can also be used to execute sql directly. It works with MySQL, PostgreSQL, FirebirdSQL and Oracle. It has SQL DSL, Versioning, Optimistic Locking, easy Joins, Pagination, etc Disclaimer: I am the author
We still use nginx to do that at my work. TBH it's mostly just for legacy reasons, but it does have some upsides: If your go backend crashes, you still have a webserver up and running to log requests and serve error messages. This is especially important if you have clients that would rather get an error message and know to try again or do something else instantly, rather than sit around waiting for a failed tcp connection to time out. You can also have one copy of nginx routing to multiple go servers. You could kind of do this in Go, but you'd need a separate Go project just routing to other Go projects and at that point you're just reimplementing nginx so you need to question if you'll do as good of a job at it as they do. Also having nginx(or something else) terminate SSL instead of your Go code means that your go code doesn't even need access to your SSL keys. So theoretically you could have all SSL stuff handled on a dedicated machine and even if your Go code gets compromised, it can not leak your SSL key. This also means updating your SSL cert can be made easier since you have less places that need to be updated.
I think it would be very doable provided you were ok with having a web interface.
&gt;If you want to build a Go app with serious DB capabilities you will need an ORM or the logical equivalent. I have to disagree. You can (and I would say most do) build a Go app **with** serious DB capabilities **without** an ORM. 
~~start as root bind and then setuid to a lower privileged user. the same as apache and nginx do it.~~ ignore this it's apparently not reliable https://github.com/golang/go/issues/1435
This is essentially the ngrok2 architecture, albeit somewhat in reverse. I'd suggesting throwing away all of the HTTP stuff, though, it's totally unnecessary for defeating firewalls when you encrypt everything in TLS (and use port 443).
Unfortunately, I'm dealing with arbitrary media files that can easily exceed 100MB in a lot of use cases. You're right in that it's irresponsible to be directly modifying files non-atomically; perhaps the best solution is to (disk) copy the file, modify it there, then overwrite the first one if the modifications are successful (though I wonder about filesystem permissions and whether this might introduce a whole new class of errors and edge cases). I do plan to use large chunks. I wanted to query the system's block size using syscall.Stat, but it looks like it needs to know the path to the actual block device, and I would have no idea how to figure that out cross-platform. After some research, it sounds like a lot of naïve I/O buffers use 8192 bytes as a rule of thumb, so I might just go with that. Thanks for all the info!
It's interesting to contrast with Oberon, which doesn't have break, continue, or goto: you "need more context" in the sense that you have to use these logic variables (as in the example) but you also need less context in the sense that you don't have to analyze the loop body to know under what conditions the loop may end or return to its start.
This is a good idea - while the Go TLS stack is pretty solid, it's immature. There may be security or compatibility issues with it and the range of clients you wish to serve. Fronting it with something like nginx or Apache is a pretty good move and also gives you a static service if you need it.
Can this handle "too many open files" errors?
Handle? You will receive that error if you surpass your systems open file limit.
All of our prod servers are behind AWS ELB which terminates the SSL with a proper, signed cert. The ELB connects over HTTPs to our backend Go services which have a cert generated on startup. I'd prefer not to have ELB manage our certs but it vastly simplifies cert management among the backend hosts. Nginx is a solid solution but it doesn't provide enough benefit when you are using ELB to justify having it in critical path of serving requests.
Yeah, I know. It's something that I and other devs keep bumping into with file monitoring libraries; just wondering if this one had some way to crack that nut (maybe a way to watch without using file descriptors). Still could come in handy though - thanks for making it!
Not a crypto expert, but if I remember correctly OFB mode is not authenticated. An attacker could flip bits in your streams by just flipping bits in the ciphertext.
True, although data would become invalid, it would still be private. I'll swap to GCM when get some time verify the performance.
There's no way around it really, since you have to open a file to know if it's changed. You can poll for changes, though this has much worse performance. How many files make up a typical project for you? It might be easier just to observe only the portion that you're actually working on?
Luckily there is [ogier/pflag](http://github.com/ogier/pflag) - a drop-in replacement for the flag package for everyone (including me) who favors POSIX flag style over Go flag style.
You're right. It's situation-dependent. (Actually, the polling solution has worked quite well performance-wise, but it did drain the battery a little quicker than we'd like.) Anyway, I like little packages like this that are easy to dissect. Good learning tools/models to build upon.
Nginx as a front end, all day, every day. Go just communicates with it via plain http. This is the right way to do it. Let Nginx do what it's good at. You don't need to have your web app manage TLS. 
Seriously, why?
I am just to make extensible, use interface is because you can't wrap a structure then pass it again to next component, i have no any other idea about this other than interface.
In theory. But as Tacticus said, it's not reliable (yet): https://github.com/golang/go/issues/1435
Any docs/writeup? 
It's annoying, especially on mobile. 
screenshots of widgets? 
http://godoc.org/code.google.com/p/go.crypto/nacl It's a lot easier to use, and far less configuration ( think certificates, picking ciphers, picking encryption modes, etc). http://nacl.cr.yp.to/ 
I don't trust myself to do what you're trying to do from scratch. TLS will come with some other things like Perfect Forward Secrecy, too, which having a symmetric key in hand can't provide. I started with what I started with for a reason... it's the right answer.
Thanks, I'll take a look
And I'm listening, I'm aware TLS is superior, I'm aware this scheme won't have PFS. However, the question is, **given** we have is pre-shared key – what's the best we can do?
&gt; Splitting code into model, service, and usecases cmd/ apiserver/ worker/ admin/ lib/ queue search ... model/ person/ payment/ ... service/ persons/ payments/ ... This code organisation is not idiomatic and must be irritating to work with for experienced developers. Yes, I can imagine it makes architectural decisions pretty straightforward: "Just throw new source file to either model, control or the usecase directory and we're done".
Hey Craig, I would like to get the visualizer levels from a particular song. Is that possible with this library ?
nice, this looks really promising. 
The more we say "don't roll your own" the more I fear we'll discourage people from, well, rolling their own. *Rolling your own is not bad; it's good!* - it means you learn something, even if you don't know what you're doing, you're gaining experience. People that roll their own end up becoming major contributors to established security projects. It's the only good way to get started! Imagine if budding programmers - and experienced ones alike - stopped implementing sorting algorithms or matrix libraries because it's all been done before, better. So why bother? *To gain an understanding* of how they work and to *think smarter and more critically* about your own code in the future. I still think it's a fabulous exercise to build a chess program, even though it's been done a hundred different ways and computers are already better at chess than humans. "Rolling your own" is very different from relying on a false sense of security. We need the former, but can do without the latter. Common sense goes a long way. So seriously, *do roll your own*. It *is* a good idea. Just don't use it and pretend that you're secure. We should not discourage hackers from hacking. But I know your intentions are good, and I agree with you that we should stick to mature crypto libraries, even though they themselves are not impervious. This is why we need people to roll their own, to find and fix and refine the best of what we already have.
Thanks for commenting! HTML element was a bit different than the rest and it slipped my scrapping - fixed now altogether with new binaries: https://github.com/rjeczalik/gh/releases/tag/1.0.1
They said that the project is experimental and does not have any kind of docs yet.
Why not improve on go-qml?
Well it could if the transfer speed fluctuates a bit too much, but in normal scenario's it shouldn't :)
Actually there are reasons for not putting nginx in front of it. You might want something like [hipache](https://github.com/hipache/hipache) infront of your services. (i'm slowly building something like that in go to handle small daemons that self registe)
Thanks for all your replys and advices, very helpful, and i will continue learning Go and contribute to the community.
&gt;My biggest worries being native toolkit support Hmm... what do you mean by this ?
I assume that the apps you reference are using what I called "the logical equivalent" of an ORM; that it to say they access data using raw SQL.
Well I'm sure that's not the case here, since it does all the rendering logic directly upon opengl from what I can tell, thus drawing buttons etc on it's own. That said, do toolkits like Qt actually draw using native system widgets on systems like Windows/OSX or does it just 'skin' it's own widgets to look native ? On *nix such as Linux and BSD, there is no native toolkit to begin with, so no problem there. Personally I have no problem with UI appearance looking different on different apps due to toolkit variation (much like web pages look different), but then again I'm a long time Linux user so I'm used to it.
&gt;That said, do toolkits like Qt actually draw using native system widgets on systems like Windows/OSX or does it just 'skin' it's own widgets to look native ? Yes, Qt does that (EDIT for clarity: native toolkits instead of skinning). It's *very* important in this day and age where UX is everything. On Linux Qt has its own themes but can be set to use Gtk2 ones. Things like Chrome/Chromium read your environment variables (like XDG_CURRENT_DESKTOP) to detect what DE you're running and therefore what file picker to launch (for example).
Well this project is extremely bare-bones as of now so it's probably stupid to make any predictions, but from what little I've seen it does not seem to be a solution sitting on top of a system's native toolkit (if it has one), but instead it draws the ui components itself using opengl. Anyway, if I'm correct then instead of having the benefit of a 'native' appearance on those systems which has a native toolkit, this will have the benefit of looking the same across all platforms.
I'm not sure what visualizer levels are. What does that term mean?
This may help you: http://en.wikipedia.org/wiki/Object-relational_mapping You are grasping at straws here. 
Hopefully without sounding like too much of a vim convert/fanboy, I don't suppose you would consider switching to vim? Vim-Go is just incredible and is so much nicer I have found for Go dev (I started with Sublime too). Simple key presses for testing, building, running and switching to terminal. Plus it comes with all of the tooling you could want (gorename, golint, etc).
Also, I see no reason that a pointer should be returned to Manifest and JarInfo. Manifest is a map, which has a reference to the underlying data structure, and the same goes for the Files filed in JarInfo.
I use Sublime as well for development, but mainly for the fancy colors and a few features that I like. I generally ignore the whole building system because it's complex enough that it's not worth to invest time into it IMO. Call me old fashioned, but why not just keep a terminal open when coding? Repeated commands are really just [arrow up]+[enter]!
This is the article I _thought_ I was promoting earlier. 
There seems to be a [paucity of organisations advertising projects in Go in GSoC](https://www.google-melange.com/gsoc/org/list/public/google/gsoc2015?tag=go). lowRISC is a project to produce a fully open source System-on-Chip. We're acting as a mentoring organisation in collaboration with a number of our friends in the wider open source software and hardware community. The [tavor](https://github.com/zimmski/tavor) delta-debugging and fuzzing framework is included udner our umbrella (and is of course implemented in Go). Please do help in spreading the word to any students you know who may be interested, particularly those with Go experience. For those not familiar with GSoC, see [the homepage](https://www.google-melange.com/gsoc/org/list/public/google/gsoc2015) for more info - essentially it gives selected students a stipend of $5500 to work on open source over the summer.
D suffers from a terrible reputation,because it was promoted as a C++ replacement. C++ developers are extremely religious about their language so it got a lot of backlash in the industry. One "can't touch" C++ period. I tried the language itself, and all the memory safe part is great. The syntax is great, it has quite a lot of features , generics , stuff like that. I don't know about the unsafe part. As for libraries,unfortunately, it doesn't seem like there is a lot of stuff available. It's stupid but my first try at Go was a image converting tool.I was amazed that Go core lib supported jpg,png and gif compression out of the box. I didn't find anything for that purpose in D for instance , and I wasn't ready to link unsafe C code to my project. ( I'm not very good at C ). Go IS easy to learn and has builtin easy concurrency. The only problem i have with go is the lack of generic and a proper default package manager. 
Is there an idiom for Go Web project organization? I've not seen one generally accepted. As the presentation says, "Structuring code is hard." (Though it might be appended with "in a way that satisfies everyone.")
GoImports adds a small layer on top of `golang.org/x/tools/imports`. That `imports` package takes care of [parsing Go files](https://github.com/golang/tools/blob/master/imports/imports.go#L38), so be familiar with parsing and ASTs. The layer that GoImports adds is just some directory walking to find Go files and invoke the import tool, so you'll also need to be familiar with traversing the file system, opening and writing files, etc.
This is why I describe Go more as a scripting language 2.0 that happens to have been built with more attention to speed than the 1990s scripting languages... because while it is "compiled" and it is a bit more verbose than Python or Perl, compared on the other side to D or Rust or C++, it's a lot more like using a scripting language than using D or C++. If you don't _need_ all that power, and you often don't, then you really shouldn't be using D or C++. On the flip side, if you really _do_ need all that power, you'd be crazy to use Go. But, again, you "need" that power less often than people think, and now that Go offers something like a scripting language for only ~25-100% speed penalties (while at the same time grabbing some low-hanging fruit like reusable byte buffers and by-value structs, laid out like C), as opposed to Python's 1000-20,000% speed penalties, it certainly chews into the D/C++/Rust language's niches. Neither will eat the other, both will coexist, but I suspect over time the C++/D/Rust niche will shrink a bit relative to their historical size.
&gt; Yager No thank you. Why do I even open infoworld links.
I think the flipflap over CLAs is overblown. It's honestly what all open source projects *should* be doing... otherwise there's a rat's nest of copyright assignments for every contributor and the lines they've touched. All the CLA does is formalize what you should expect to happen to your contributions anyway - they becomes part of the project, not owned by you specifically.
You should be fine if you throw a fancy [moving average](https://en.m.wikipedia.org/wiki/EWMA#Exponential_moving_average) into the mix. :) [Cloudflare](https://godoc.org/github.com/cloudflare/golibs/ewma) has one that looks solid and I bet there are others. 
Non-mobile: [moving average](https://en.wikipedia.org/wiki/EWMA#Exponential_moving_average) ^That's ^why ^I'm ^here, ^I ^don't ^judge ^you. ^PM ^/u/xl0 ^if ^I'm ^causing ^any ^trouble. [^WUT?](https://github.com/xl0/LittleHelperRobot/wiki/What's-this-all-about%3F)
Have you looked at tools like http://www.liquibase.org or http://flywaydb.org ? They seem to have had the same idea. I prefer the later. 
The thread started by Alexandrescu had potential for constructive discussion, but too early was turned into holly rant: [ "&gt; +" stands for Go's advantages ] [ "&gt; #" for D disadvantages, posted by the OP ] &gt; + very small language, very concise &amp; simple A limited, inflexible language &gt; + feels like a better C (mostly) Feels like C &gt; + enforced style (indentation, exports) Ridiculously restricted for no reason other than developer arrogance. &gt; # big language An intuitive language that actually does things. Followed by a clasic FUD: Google does abandon significant projects now and then, such as this one: Really?
[**@ID_AA_Carmack**](https://twitter.com/ID_AA_Carmack): &gt;[2015-03-17 17:02:08 UTC](https://twitter.com/ID_AA_Carmack/status/577877590070919168) &gt;I just dumped the C\+\+ server I wrote last year for a new one in Racket. May not scale, but it is winning for development even as a newbie. [**@touristtam**](https://twitter.com/touristtam): &gt;[2015-03-17 21:25:36 UTC](https://twitter.com/touristtam/status/577943893800562689) &gt;@ID\_AA\_Carmack what guided your choice of Racket vs Rust and Go? Just curious. :\) [**@ID_AA_Carmack**](https://twitter.com/ID_AA_Carmack): &gt;[2015-03-17 22:46:27 UTC](https://twitter.com/ID_AA_Carmack/status/577964240511848448) &gt;[@touristtam](https://twitter.com/touristtam) If I run into catastrophic perf problems, I may try rewriting in Go. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2zim29%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
You don't describe any advantages over other solutions (including, most importanyl, `net/http` which is more than enough for most people). Overall the amount of information in the readme/on the site isn't much.
- I'm putting this out there for notice, for anyone interested. I am not making a sales pitch in the sense of wooing or wowing, except in the fact of making the merest effort, implying minimal salespersonship. - I've seen enough golang webframework announcements to know where the arguments come in and from where, so I've somewhat attempted to sidestep those with only the facts. Anyone who wants to review the code is welcome to, and to be blunt I'm really only interested in feedback from people who are willing to read the code. - There are no advantages to using flotilla over raw net/http, except as a preference for having some established methods for doing things that become tedious &amp; bothersome. The whole `you need to use net/http only` argument that pops up every time someone exhibits their own tools gets annoying. Some people do like to go into the woods naked with just a knife to hunt for dinner, others might not and there should be a wide range of tooling that evolves to help anyone who wants to work in the go ecosystem. 
*May*. He may also give up computers and become a farmer.
At least quote the quote right
&lt;shrug&gt;
I'm not sure the code here works in a sensible way: https://cgansen.github.io/sxsw-go-talk/index.html#/6/3 Near as I can tell, the "healthy" variable will just get set to the exit status of whatever check ran last. So if checks 1-9 fail but the last succeeds, you'll think everything's fine.
This looks very promising! It already has over 1,000 stars on Github! Some basic documentation would be nice. Although, there's a `Samples` folder and from the examples one can get started.
Agreed. There's a high bar for a web framework because anything that's not compatible with net/http starts fracturing the ecosystem and you should have a really compelling reason for people to want to use yours. If you're going to make a new search engine you should tell people why it's better/different than Google. 
Also, you should be familiar with what sirseal said.
It's not about the amount of traffic you get, it's about the amount of caching you can do. 
I gave you a thumbs up because of the "go into the woods naked with just a knife to hunt for dinner" comment. We all create our own frameworks as we build out applications and there's nothing wrong with showing it to other people. But, you've got to realize this is the "reddit" Go community, and everyone is into the "we only take kindly to little packages with purpose" kick. I'm not saying the Go mentality is the wrong approach - I fully support the encouragement to build solid interchangeable packages because it helps grow the number of solid Go developers...sort of like how Catholics don't believe in birth control so they can increase the number of Catholics :-) We especially don't want Go to have any of those icky framework-reliant PHP developers.
So I don't think net/http has all the tooling needed for a web server but I feel like the community has largely rallied around http://www.gorillatoolkit.org/ as the best net/http-compatible toolkit. Ideally, the go team would just adopt all the features from the gorilla toolkit. I think the issue here is that new frameworks should ideally be interoperable with net/http and if not, should clearly articulate why that design decision was made. The OP refused to explain his/her design decisions instead directing us to "read the code". He/she initially said "any input is appreciated" and then later said "to be blunt I'm really only interested in feedback from people who are willing to read the code". 
This thread has been linked to from another place on reddit. - [/r/programmingcirclejerk] [John Carmack likes Go too you guys!](http://np.reddit.com/r/programmingcirclejerk/comments/2zjng8/john_carmack_likes_go_too_you_guys/) [](#footer)*^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote. ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
"Appreciation" &amp; "interest" are two separate concepts, it is theoretically possible to evaluate communications on numerous levels...saying that "input is appreciated" is a thanks for your time in getting that far and a recognition of your effort beforehand, while saying that I am personally interested in more detailed feedback related to reading of code is something altogether different, and in no way obviate one another. 
Sure, You can even download it: http://arclanguage.org/ But the install is a bit tricky to get right.
Let me know how did you go! It works fine for me but wouldlike to hear your suggestions.
[Why is my nil error value not equal to nil?](http://golang.org/doc/faq#nil_error) (Go FAQ)
Does it matter if they're parsed and formatted differently in godoc? Your point was that because the comments aren't treated specially, you should put comments on the implementation, and that's not entirely true. It's idiomatic to put comments inside of struct and interface definition blocks. godoc specifically shows those by displaying the struct/interface definition along with any comments (which will be highlighted in green).
John Farmack
BTW: on Windows, after installing a version of LiteIDE - upgrading by simply copying and pasting the new versions on top of old LiteIDE programs folder has worked fine for me (backup first..etc.)
Avoid leaving memory to be garbage collected and the garbage collector will almost never run, and when it does its timed in microseconds.
Or a road maintenance contractor!
http://i.imgur.com/3RF2RPI.jpg
And you have to write a lot of libraries yourself. 
I've forgotten most of what I once knew about signal processing (though I still have a high level understanding), but mpg123 can be used to decode an mp3 (probably other formats as well--I'm not very familiar with this lib; I just needed an easy way to decode mp3s) into a byte stream and get the number of bytes per sample. If I understand correctly, you should be able to use the samples to do whatever sort of digital signal processing algorithms you would like; however, neither of these libraries (AFAIK) expose any DSP methods/functions, so you'll have to roll your own or find an existing lib. EDIT: This is an interesting project. PM me the details of your project/use-case and maybe we can find some C library for which we could write Go bindings (well, I probably won't have time to do much of the binding writing, but I could be a consultant if you don't have much CGo experience).
 func g() { // nop } func f() { return g() } 
Just added support for targeted events!
This surprised me when replacing a bunch of code followed by a break inside a for loop with a return. i.e. I had func f() { Loop: for { // a select, and lots of code do_stuff() do_more_stuff() break Loop // more code, other cases in the select } and changed it to func f() { for { // a select, and lots of code return do_stuff_and_more_stuff() // more code, other cases in the select } so instead that's got to be do_stuff_and_more_stuff() return 
That isn't quite true. A significant factor in garbage collection time is the amount of memory you have allocated not just the amount of garbage you generate since all that memory must be scanned to detect garbage.
Yes, I can see how that's a slight edge case, which I don't see much reason to exist. I wouldn't be surprised if you filed a bug about that it would get fixed at some point, given that you can do func f () (int, err) { return ... } func g () (int, err) { return f() } just fine. You can "return" through a return statement that returns 1 value, one that returns 2, one that returns 3, but not one that returns 0.
I seem to remember testing just that, allocating quite a bit of memory, using it heavily and then asking the GC regularly how much time was spent on GC. During the tests the GC did a pass every 2 minutes for some extremely small amount of time. Cant remember the exact specs for the test though.
It's entirely possible. I may not be alone in wanting to read about John learning horticulture and agriculture from the ground up, like he did with Armadillo and rocketry.
And PCRE vs. RE2?? Really?! I hope they go to the all the hassle of avoiding the trivial worst case performance of PCRE that can bring it to it's knees.
I'll never forget the day I asked my grandmother, after she told me about all my farming relatives in her generation and before. It seemed that everyone could play an instrument, fix machines, work with wood and metal, raise crops, market them, sell them, etc: &gt; Was everyone a Renaissance man like my great grandfather? She looked dumbstruck at the very question. Then she paused, and answered: &gt; Well, that's just it: you *had* to be one when running a farm. It's us people in the city and suburbs that only know how to do one or two things well that are the backwards folk. When you're alone with your family on a farm, not having many talents is a liability.
https://github.com/golang/go/issues/10200
I can't be the only one who thinks that 100% vanilla HTML forms are just sad and should be put out to pasture. It's good to know how to handle them, and there is merit to this article but I always end up straying from ParseForm. I usually end up just using js to post the values as a json object. In any non-trivial form I've ever worked with (all of them), you end up using javascript for pre-submission-validation anyway, and there is no lack of options for effective ways to skin the form-parsing cat (e.g. [jquery.serializeJSON](https://github.com/marioizquierdo/jquery.serializeJSON)).
Really enjoy people recommending that Carmack consider other languages... I don't get the sense that he is unaware of what tools are available to him.
I don't think we're going to agree. I'm not saying that I expect to be able to return a value from a function that is declared as not returning a value; that is clearly wrong. And I don't think it has anything to do with “knowing what is going on in your code”. If you think of all functions as returning a list of 0 or more values, why is it that only for the trivial case is return g() an error? 
http://npf.io/2014/05/intro-to-go-interfaces/#toc_4
Me either. Note, I wasn't criticizing you, I was instead criticizing the "article" that got published, which is really just a transcript of a video. It's shoddy journalism.
Fair enough. I don't know that we need to agree. If it's something you find confusing that it's unlikely you're not the only one and it's good to raise the issue because clarity of the language is important. I just wanted to add that I think some folks aren't confused and leave it up to the Go contributors to figure out if it's a deficiency or not. As to your question I think you hit on the fundamental issue I was trying to raise. Should the conceptual model Go ahears to be what you just said or should should it differentiate between those cases. I'm not sure there is a right answer, there's only how opinionated Go is going to get about it. I'm of the mind that I prefer that Go enforce the difference between nothing returned and a list of 0 or more returns. I think this is similar in concept to reinforcing the difference between &lt;literally nothing&gt;, nil, undefined and 0. Since Go is already differentiating between these, I'd assert it should also differentiate between "nothing should be returned" and 0 or more items. That said, it isn't critical in either case but I do think that's fundamentally what we're talking about here.
&gt;Secondly, it also lacks a regex (regular expression) with good performance, and because using the Go-Redis library wasn’t enough; therefore, the team uses PCRE (Perl Compatible Regular Expressions). I couldn't continue the article after reading this. PCRE should die already. Anyone who's taken an automata class should know this. For those who don't know, PCRE uses a backtracking algorithm that is not convertible into a DFA. A DFA is a state machine that has one transition for every input symbol read. If the DFA ends on a final state, the input is accepted. This means a regular expression converted into a DFA runs in O(n). PCRE runs in exponential time on bad input expressions. /u/rsc has an amazing article about this here http://swtch.com/~rsc/regexp/regexp1.html
While this is a useful practice to have up your sleeve, I don't understand why this interface required a separate goroutine to be running, vs. simply implementing a "recorder" type of object that records notes and returns them when asked, in a single thread. This is a useful technique, but not something you should reach straight for unless it's solving a goroutine coordination problem. In my [suture](https://github.com/thejerf/suture/) module implementing supervisor trees, which is all about cross-goroutine management, I implemented a [test service which could be coerced into demonstrating whichever failure case I liked](https://github.com/thejerf/suture/blob/master/suture_test.go#L484) by sending it messages.
Yup, I figured it was likely something like that. One bad thing about blog posts is that they only admit a certain size of example. You could solve it by just saying up front "suppose we have a goroutine coordination problem, which I don't want to complicated the following with because it'll just messy up the code". Then I won't complain anymore. :)
Let's not be pedantic here. Libraries are as important as the language itself when vetting a language. I'm not going to choose a language for a specific job if there is no robust library for the task I need to perform. I wouldn't choose Go for web dev if Go didn't have an http library.
To be fair, Go is often complemented on its standard library. It is certainly one of the reasons I choose to use Go over other languages. So it doesn't seem too unreasonable to criticize holes in the std lib or ecosystem.
I'm also a programmer/farmer!
Damn. Here I am worried about how to design my blog.
Read this to start... http://blog.golang.org/strings
Simply.. the package is useless without accepting the `*relayr.Relay` instance that my package provides. I guess no one _actually_ cares by the looks of it.. as long as the package works.
No, no, no. _Please_ don't deviate from the [install instructions](http://golang.org/doc/install#tarball) on the website and _please_ do not continue to promulgate the requirement to set GOROOT.
Have Topcoder made any attempts to work with Go Challenge organisers?
http://golang-challenge.com/, they've been quite visible on Twitter and Reddit
It's interesting, when I used angularjs with PHP I'd have to explicitly set the header to not send the data as JSON back to the server so I could read as POST values. When I started an app with martini and binding I found that the martini binding can read the JSON data without any extra work, which is much cleaner to read in debugging since I can send actual arrays of objects over to the server and Go reads it correctly and Chrome debugging tools shows you a tree of your JSON a when you send it. It's the future I tell you, the future!
thank you for this ! edit: just one thing, I found out I didn't have freetype on my MacBook so I had to add this to the list : go get code.google.com/p/freetype-go/freetype and now it works in both Linux and MacOSX :-)
Cool! Love the fact that most Go projects are cmdline tools with it's core functionality in library-form, so you can re-use it in your own projects.
These kind of comments usually stem from developers that work alone. Everything is restricting to them and they resent any effort by other people to implement guidelines or standardization so community can work together. They are usually smart but poor collaborators.
Yea, this library started out as a side project when I was learning Go. Mistakes (that in retrospect were SUPER dumb) were made.
Braintree has a Go library as well. You might be interested in [this thread](https://www.reddit.com/r/golang/comments/2qdvfj/has_anyone_used_golang_and_braintree_successfully/)
There is an [official](https://wiki.ubuntu.com/ubuntu-make) and easy way to install the newest [go version on Ubuntu](http://blog.didrocks.fr/post/Ubuntu-Make-0.4-starts-the-new-year-adding-Go-support): sudo add-apt-repository ppa:ubuntu-desktop/ubuntu-make sudo apt-get update sudo apt-get install ubuntu-make umake go
I value the effort, but I don't think any gopher (myself included) will ever use anything other than `godoc` for their code documentation.
"Never get involved in a land war in Asia"? :)
I think I tried to explain this elsewhere in the thread, but wasn't clear enough. I was refactoring code, changing a bit of code and a break inside a case inside a select inside a for, for a function call and a return. My first instinct, because it works with all other return sigs, was to just to write it as “return otherfunc()”. It was surprising, so I made a note of it. The change in question is http://bazaar.launchpad.net/~ubuntu-push-hackers/ubuntu-push/automatic/revision/382 if you're interested.
I think this tool needs a better example... I *think* it's trying to be documentation for a REST API or something similar, but I can't tell for sure. My first thought was "why would anyone use anything other than godoc", but I'm guessing this is not for code documentation..... again, better examples and use cases would be helpful.
I could see this being an addition to godoc if you made this an auto-generator for REST API docs, clients, etc... like natefinch said
Yeah, it would be awesome to see people create API wrappers for existing web UIs!
Good idea. It can easily cooperate with `go generate`, example like this: `//go generate apidoc -f api.md [file/dir] ` It will generate all REST api docs for files under this directory. 
Are you trying to have RSpec in Go? To me it looks you try to build spec for each method. You introduced two types of syntax and a tool to translate between them. Why not have ~Markdown in the comments instead of annotation-like something? This way you would have only one syntax and additionally godoc users would benefit from non-cryptic comments.
What license is this released under?
&gt; Turns out the go tool version of nm, doesn't use the debug package either Hey, nice article. Mind elaborating on the quote?
*whistles* you can in a docker container. *prepares for downvotes*
Can, but from my pov docker is overengineering. //Don't worry, i buy the beer for Budda, so now my karma not in reddit :)
It only build docs for annotated comments, not each method. It isn't output markdown only, other formats is also possible, but currently, there is only one choice. Further, it also can be used in other filetypes or languages, ont only golang. And a important thing is that if you use only one syntax to write both code comments and REST api docs, it may seems too ugly. My original intention is that once we completed a REST api, then add a annotation to describe it, at last use this tool to generate the whole documentation, maybe it's similar with RSpec. 
hey there, are you the author? pretty awesome tool, and thanks for the credits re goxc (my own project). I just ran cloud-gox on goxc itself, and it did the job - great stuff. You know, I was hoping someone was going to do something like this, so, well played... I am also wondering what to do with goxc after 1.5 - seems like cross-compilation itself is about to become much easier, and I'm better off breaking the individual pieces into their own libraries. I started breaking out 'debber' as a standalone .deb generator, but, you know, it's not complete and free time is at a premium. BTW, I had a checked out your 'backoff' library last week for a project at work. I ended up using the 'go-resiliency' project for now, but I may come back to your project - looks promising. Cheers
Just an idea, you could use swagger or separate schema file for that.
It's not need to close the opened file. `os.File` already provide a `Truncate` to reach this. You can read the documentation at `http://golang.org/pkg/os/#File.Truncate` to get more info.
I am and thanks, and thanks for writing goxc :) I mainly wrote this for myself, to automate Github releases, which has been very handy. Splitting up the code base sounds like a good idea, though I guess we should wait and see what 1.5 holds, I'm interested in improving the UI and making hg available, though as you mention - it's hard to find free time
Sounds like you want something like: https://github.com/tv42/alone I don't think you are crazy. I am actually curious about this as well. There are several places this can be very use full. For example enables hyper scaling, think not having to have you app up until a request comes in. And then dynamically launch it and have it serve. 
+1 on markdown, or godoc style comments
Absolutely not! That package is completely non-idiomatic and pointless. Not worth spending one minute looking at much less using. Starting from using pointers to a reference type everywhere, to tons of methods that *print* "to be implemented" to stdout before returning the wrong answer, to crappy non-Unicode versions of IsDigit (and other classifications; what's wrong with unicode.IsDigit? Nothing).
Why Github only??
I am; I "truncate" the file to make it larger and then continue using it. It seems to work fine without any errors. Can you explain why it's bad to do so?
Thanks. Sure. If you have a look at the go tool nm source: http://golang.org/src/cmd/nm/nm.go You notice it isn't using the standard library debug package, but a cmd/internal/objfile package. If you jump into the objfile source http://golang.org/src/cmd/internal/objfile/objfile.go you find that there it uses the debug/gosym package from the standard library. http://golang.org/pkg/debug/gosym/
Ah, my mistake. I assumed `f.Truncate(0)`; but of course extending is a different story as that doesn't put data at the earlier location at risk. &lt;aside&gt; The reason I responded is because I just happened to be re-reading an [old comp.unix thread](https://groups.google.com/d/msg/comp.unix.bsd.freebsd.misc/ic6iJRN1i0s/XieP6UYVVAQJ) the day before, trying to find the source of a favourite quote, and the thread was related to doing bad things to files while saving data. The quote: &gt; *DON'T DO THIS*. It is *BAD* engineering. *BAD* engineers *DESERVE* to &gt; be unemployed, living under park benches, and feeding off of slow moving pigeons. &gt; &gt; -- Terry Lambert, in comp.unix.bsd.freebsd.misc :) (edit: and to be clear, that quote is unrelated to *extending* a file with truncate)
People should read other posts from this person's blog to understand where he is coming from... Another case of Go bashing coming from FP world. 
Quite unfortunate indeed. I used to have a Lisp job, and while Go is clearly not a FP language, the first thing I noticed that made me very happy was that it has full closures/anonymous functions. And my experience is that you can anything with those, so that made me curious to check out the rest.
Thank you, сomrade. Seems im not only one who mean about it.
Awesome! I loved using Dropwizard for my java code, and have in fact yet to reach my productivity in java and Jax-rs services in go.
I've got a simple wrapper for 2 calls to the Dwolla API. I think there aren't many released simply because Go already interacts so well with remote JSON/XML APIs that there's not a lot of complexity in rolling your own (not-invented-here syndrome notwithstanding...).
About the system limits, what does a simple `go version` do, that the default limits prevent and what are the defaults anyway? What would be the minimum for `go version` and why? Because it's a rather large static binary?
The author has only unfounded claims about Go: &gt; Go seems to have trouble building on some systems like Raspberry Pi, Worked perfectly when I tried it with Arch Linux ARM on a RPI. &gt; and even Windows seemed a little off. Wat? &gt; In the end, I thought Go was a little unreliable, A little unreliable? How? Did the program work or not? &gt; not particularly fast, Right after saying &gt; I was proud and happy with the result. Then: &gt; I didn’t especially like the syntax, and I thought that it had a few other flaws. Ok, why? And what flaws? &gt; I actually think that Go is one of the least interesting languages I’ve tried. Completely missing the whole idea of Go here. He couldn't even bother to read the [FAQ](http://golang.org/doc/faq)?
I'm the opposite. Having never used a BSD, I really like the look of those process limits...
It's nice to not bind it to a specific language, though. 
Okay, phew! Thanks for explaining!
Hey thanks for posting. This is still a work-in-progress although it's pretty solid now. Just got audio working over the past couple days.
You should get together with https://github.com/nwidger/nintengo and join projects (or both works towards one)! :)
These restrictions on OpenBSD are so tight for good reason. If you don't understand, or don't care to find out why then, yes, maybe just use a linux distro.
Make sure you document your code! There are exactly 0 comments in the entire package :)
Oh the package was named something else in the beginning. Thanks, I will fix that.
Maybe on main.go, but all three of the .go files in helpers/ are modified by `gofmt -w *.go` run in that directory. I just double-checked and it's even worse than it looks to the naked eye because the mongo.go file seems to be indented with spaces instead of tabs so nearly every line is changed. I'm assuming your editor is configured to indent with spaces and converted all of it? You only need to use one of the two commands, by the way. The main difference is that `goimports` also updates your `import` declarations by adding missing ones and removing unused ones. (It also groups imports slightly differently by separating the standard lib from external packages)
Then tell me what the security reason for limiting the memory usage to 512 mb by default instead of something a bit more reasonable might be. 
thanks !
http://play.golang.org/p/qOV7_tzo03 * We know that the only valid inputs are objects and arrays * We know that whitespace at the start of the JSON input can be ignored With that in mind we can safely read the data, we don't need to peek at it. It's also safer because a bad client cannot send up garbage data and make us buffer the whole thing in memory. I ignore the error to UnreadByte because AFAIK, it cannot fail unless the ReadByte failed, in which case we'd already be returning with an appropriate error. *As always: Assume this code is only compile-tested* 
Use flags for config strings. e.g. the database. Leave the connection to mongo open, don't dial every time.
OpenBSD ships with several login classes in login.conf(5): - default for regular user accounts (memory capped at 512M per proccess) - daemon for services (like postgresql) it doesn't have a memory limit - staff - for more privileged users (capped at 512M but able to raise limit without editing system files) - two custom roles for bgpd &amp; unbound You can add your own classes or change limits on existing ones. Regarding the CD-ROM. I also doubt anyone needs that medium for installation (but who knows) I personally order them each release for two reasons: - to support the project as that's the main income for them - I like the art work so you can say it's a collectible
&gt; From my point of view, this just cements the view of *BSD being stuck in the 80's/90's That's cool, if you've already got your opinion sorted out I won't bother trying to express why some people have respect for OpenBSD's approach to stuff like this. If you're rocking a couple of 8 core Xeon's with 192Gb of RAM then yeah, the defaults are probably going to be a bit too conservative for you. Then again, maybe you're running on a VPS, maybe you're running on an old-ass SPARC box or perhaps you're on a low-power embedded system, in which case you might want to tweak it in the other direction. That's why its in a configuration file. IIRC there are some hard limits on processes that facilitate OpenBSD's security features like ASLR and W^X, but not sure what they are offhand (or if they even apply to amd64). If you're actually interested in working out how and why these defaults are there's a huge pile of documentation in the FAQ, the man pages and the mailing list. If you're more interested in concern trolling, then keep up the good work I guess.
What do you need more than 512 MB of RAM for, anyway? At least in Go's case, it's actually quite clear: lots of virtual memory, but relatively little resident memory. So the only thing you can blame on OpenBSD is that it looks at virtual, not resident memory in that case.
Here's another one: https://github.com/scottferg/Fergulator
If you're looking for the "rails for go" you'll want to look towards beego, revel, or martini. Once you're comfortable, you'll find that you don't really need an entire framework and you probably can get by with just a few libraries. There are many good routers, database tools, etc.; you'll just pick the ones you like. Go strives to be simple and frameworks do lots of tricks and magic to hide that. 
It means the latter, i.e., domain-specific function
I think you're the troll here. "8 core Xeon's with 192Gb of RAM" is an exaggeration. 
For that exact reason you have the daemon role which should be used for exactly that use case. It's common to run applications as different system users with different limits.
I wrote a gameboy emulator (https://github.com/djhworld/gomeboycolor) It was my first "emulator" as such so I was pretty much stabbing in the dark most of the time, but with persistence it paid off. I think the recommended path is to start off with simpler systems like something based on the 6502 chip This is a good resource http://stackoverflow.com/questions/448673/how-do-emulators-work-and-how-are-they-written
Just slap this in /etc/login.conf developer:\ :datasize-cur=infinity:\ :datasize-max=infinity:\ :maxproc-max=infinity:\ :maxproc-cur=infinity:\ :ignorenologin:\ :requirehome@:\ :tc=default: then run `cap_mkdb /etc/login.conf` Is that really hard?
Compared to `pacman -S go` and then start developing, it's not hard, just completely unnecessary and inconvenient. Why would you want to do this to yourself when all you want to do is develop Go applications? For deployment, yes, sure, secure all the things, but for development?
thanks dude .... let me try these out ... 
Seriously, this is one time setup. You're comparing to Arch which also includes a lot of preliminary setup before you get to a point that `pacman -S go` is everything you need in order to develop. In both cases it doesn't matter - it would if you had to do it every time before starting any development.
NES and Game Boy are probably similar in difficulty. The first thing to do is study documentation to figure out how they work. I used these heavily: http://nesdev.com/NESDoc.pdf http://wiki.nesdev.com/w/index.php/NES_reference_guide The PDF is a good high-level overview and the wiki has all the low-level details needed to implement an emulator. 
I dont mean this to sound rude, it's great you're putting code out there. But there is one inevitability when you build "simple wrappers" around an existing library and I have seen this happen time and time again. At first it suits your purpose, until it doesn't. You then expand it's functionality. You keep doing this until you have written a layer over the original lib that doesn't really offer anything new apart from more code to paw over. 
I'd appreciate support for reading, modifying and writing back .torrent files.
&gt; Secondly, it also lacks a regex (regular expression) with good performance, and because using the Go-Redis library wasn’t enough; therefore, the team uses PCRE (Perl Compatible Regular Expressions) Wait, what? Redis has nothing to do with regular expressions.
Author of Fergulator here. I profiled against a giant switch (my original design) and found that the CPU usage was effectively cut in half by using a func dispatch like the author. That was around Go 1.2 that I did that optimization. I don't believe much has changed in terms of switch performance since then but I could be wrong.
NES is a bit more difficult given that you have to deal with more colors in the palette and there's far more variance in the cartridge mappers. They are both very similar in their design though. Gameboy is just more of a "standardized" NES in a lot of ways.
goimports uses the same library as gofmt to write out the code, so you shouldn't need to run gofmt after goimports. Adding a pre-commit hook to run gofmt is of course a possibility, but I don't have much experience with that. However, there's a script in [$GOROOT/misc/git/pre-commit](https://golang.org/misc/git/pre-commit) that will remind you to gofmt your code if necessary. It won't do it automatically, but that should be rather easy to modify if you want it. For goimports that's not recommended though, as it could break your code in some (rare) circumstances. Since you use Sublime Text though, [this blog post](https://blog.golang.org/go-fmt-your-code) mentions the [GoSublime](https://github.com/DisposaBoy/GoSublime) plugin which claims to be able to auto-format on save, among other features. Personally, I just added a tool shortcut (ctrl+0) to my editor (scite) to run goimports and several other tools (including golint, go vet, and go test) in sequence. Since using it also saves the file, I then just press ctrl+0 instead of ctrl+s :). This has the added benefit of being source-control-system agnostic and not needing to be set up separately for each repository.
Sorry for being harsh, but we're not here to talk about http.Client. I was pointing out that zero value of httpclient.Client is not usable. 
Good to know, I should try profiling again. Mine was on integers (the opcode itself).
[Inner platform effect](http://en.wikipedia.org/wiki/Inner-platform_effect), just for reference.
On a completely different note, if you control the endpoint fully, make it take an array all the time. Even in the world of pure Javascript it's more convenient to return the same "type" of thing all the time, and as Go is showing you, anything that interacts with it using a static type system is going to have even more trouble. Taking "maybe an array or maybe not" is really an antipattern, even from the perspective of a dynamically-typed language. I must have 20 or 30 instances of the moral equivalent of if typeof(arg) != arrayType { arg = [arg] } buried in all the dynamically-typed code bases across various languase I've had to work in over the years... Of course, if you don't control it and you're forced to do this for some reason, _c'est la vie_. But you're entitled to feel a bit grumpy about it, and if it was a coworker or something, go give them a bit of hassle about this. :)
Yes, collaborating would be awesome!
I don't suggest using any framework. The go authors made net/http great. Just pick a router and context engine then you should be good to go. 
Looks good! Might try this out instead of bolt for a small project I'm working on. Only feedback I'd really offer is adding examples for more of the operations, would lower the entry barrier for others wanting to try it out.
Hey, nice project. May I ask how does this integrate with CoreOS, etcd, fleet?
I've always wanted to understand how emulators worked. I dug in to some C/C++ ones a couple times but they were very complicated. This is much more approachable in Go. Awesome!
I went down this path initially, looked at Revel, a bit at Beego, then discovered you actually don't want to use a heavy MVC framework with Go, so I looked at Martini at that point. However, please read this before choosing Martini: https://stephensearles.com/three-reasons-you-should-not-use-martini/ and the followup post by the Martini author: http://codegangsta.io/blog/2014/05/19/my-thoughts-on-martini/ After that, I switched to Negroni + Gorilla Mux instead, however you can just as easily just use net/http as others have already suggested. 
Nice, thanx for work &amp; sharing. But the project is not covered by tests, no benchmarks. A little scary to use this code in some kind of production :)
It does, thanks for the write up :)
(OP here) I saw a talk by [Jeremy Shlatter](https://github.com/jeremyschlatter) about this last week at the GoSF meetup and I wanted to share it with others because I think it's a super cool idea (effectively, it works by modifying your Go source code as opposed to e.g. looking at DWARF debug info). EDIT: he posted the slides to his talk [on his GitHub](https://github.com/jeremyschlatter/godebug-talk).
Yes, of course. This is not production version currently. I hope to finish all the tests in the near future. I appreciate your feedback and I need to know, how interesting this project. Thanks.
Looks pretty promising!
Wow, TopCoder is a mess... it's so hard to find things there. I registered. One question, where are the files they're talking about in the description? I can't find them! edit: found them! the files are in the forum. edit 2: damn, that challenge is pretty hard...
Nice idea. However what about data inconsistencies between nodes? By sending modifiable requests to all nodes when any kind of UUID or timestamp is used data will get out of sync, or did I missed something?
That's awesome! Out of curiosity, will cross-compilation this simple for programs using cgo ever be a reality? I'm not really familiar with what makes this difficult, so a why/why not would also be appreciated. Thanks!
Question: would this approach make line numbers in stack traces inaccurate while debugging?
main.go: helpers is a confusing name. main.go: Why does someone need to open /cron in order to get an update? Shouldn't it be called like "update" (or refresh)? helpers/mongo.go: Dont write the consts all uppercase, also use flags and pass the configuration into a "repos" object. You should not dial and close all the time. You panic on errors? Really??? Don't return "bool" but simply an "error" (this way you dont need to panic). Make the "GetRepos" "next_day" maybe configurable. Exists also suffers from using bool and not error. There is a lot of duplicate code for mongodb connection + session setup. (also dont use log.Fatal unless you really want to. Fatal logs and then calls os.Exit(1)). helpers/*.go: See above. 
looks like petname https://github.com/dustinkirkland/petname
I think it's pretty hard to set up (Docker, Cassandra), but very easy once the application is ready. Its a simple API application in the end. Also, feel free to ask questions in the challenge forum (best way to clarify your doubts) - or drop me message and I can respond. Will you be submitting?
So, this is different way of clustering. If you use uuid/timestamp generation on the database side, you should use clustering on the database side. If your application do not use uuid/timestamp generation on the database side or do not have database at all, this is right way. So many small applications have REST API, but have no way to clustering approach.
Great point, I'll see what I can do about standardizing on sending arrays.
Well, to the author's credit, there is an excellent and thorough README for the project.
What isn't, good sir, what isn't? 
&gt; Will you be submitting? I think so! :-) I've made couple RESTful APIs in the past, so I think I could make it work. The only challenge for me is Cassandra, I've never worked with it :-) Thanks!
It will be a few hundred people. There were only 50 blind bird tickets though as those are sold way below cost-price.
So excited to see more Go Conferences sprout up. Congrats &amp; Good Luck!
Looks neat but doesn't really scale well as you safe all file names in a single hash table.
Technically yes--mpg123 has the ability to decode from a file handle, but I would have to write the binding for that API--right now the only API for which I've written a binding is the one to open from a file path. If this is something you're interested in, feel free to file an issue and I'll look into it.
If you have a website where that is a blocking problem, you're ___well___ beyond grabbing random modules off of github.com anyhow. $ sudo find / | wc -lc 913,806 59,367,007 (Commas added by me for clarification.) 60MB to store my entire native file system names. That's not a lot, considering what it would be doing.
Thanks, added to the README.
Not to mention how unpredective filesystem and the many layers of cache between your program and the actual disk/chip is.
I think you took the previous comment literally without looking at the code. It's not just file names in the hash. &gt; …safe all file names in a single hash table… should have said something like &gt; …save all tar *file data* in a single hash table keyed by filename …
I wasn't trying to imply "magical code segments," but to quote the language specification on type switch guards: &gt; When that form is used, the variable is declared at the beginning of the implicit block in each clause. (https://golang.org/ref/spec#Switch_statements) Look under "Type Switches" Thanks for pointing out the multi-option (proper name?) case, which I assumed should have worked. Although it does make sense why it's failing.
Greatly appreciate your reply, I suppose I never thought too much about the case being the problem - although it makes sense. I'd like to avoid usage of the reflect package but at least I have the solution to the issue I was having. (That is not to say that your example is not beneficial, it's interesting to see the solution implemented this way)
I think it's mildly confusing the way you use your `file` type for two different things. First, for only storing just file data and fileinfo in the map, and then later that plus an io.Reader and another slice as a return from `Open`. At first glance I thought this wasn't safe for more than a single HTTP client requesting the same path until I noticed you where storing this as a value and not a pointer so the map look up was doing a copy. I think it'd be clearer if you added an extra type that added in the reader and slice when needed by `Open`.
Please take a look at the rkv_test.go. Thank you for the feedback. I will add separate example directory later.
ping gophercon@gopheracademy.com if you have questions or need advice, etc. happy to help!
+1 for Beego. I feel it has the _right balance_ of features, performance, simplicity and flexibility. As others have mentioned, you can easily _get away_ without having a framework. You just need to consider middleware management (e.g. negronii). You should consider carefully your reasons for switching over to a new language and a framework though. Your post doesn't say much about your use cases and most of what you want may be achieved in a framework such as Laravel. Unless of course, you are just interested in Go and see this as an opportunity to pick it up then I think it's a great decision.
The existing state machines I've seen all seemed pretty large... they managed the entire tree of options and were generally kind of complicated. I wanted something simpler.
Thanks for taking a look! * I definitely like the idea about moving a lot of the types out of the db package and into their own. * At this point is there much benefit from moving from gorm to sqlx? I'll probably give it a shot just to try out sqlx though. * Any pointers on NLP approaches to this?
In one of the latest versions they added a checkbox next to the toolbar buttons that lets you "pin" a particular package. By default if you build or run, it will do so in the folder of the current file. If you pin a package though it will always run the pinned package. This is useful for me when I have a main in a package that does very little, and a lot of code in a library package that I primarily work in.
In memory was an intend behaviour and keeping a file open throughout the time that the server up makes cleanly returning the resource kinda difficult. And I use this with tar files that are stored in boltdb and I really didn't want to copy the returned byte slice all over again to use outside of the transaction and so forth.
what about tigertonic? How is this different / an improvement?
Well, if it is concreete type switch, system understands only one concreet type name for type case. What if you write: i.(int8) = 1; i.(int64) = 2143134212342135324532; What should system do? It's invariant violation. Quite obvious.
It sounds like the author is trying to compile code ON the raspberry pi which isn't something I would do myself. I don't have pi, but I have a Odroid C1 and a Beagleboard XM, I cross-compile on my workstation then debian package my app and install onto the ARM board. The downside is you have to compile Go from source in order to cross-compile, not too difficult to do, but I believe Dave Cheney is working on making that easier in future versions of Go. Also the pi (at least the first version) isn't ARMv6 which is why I didn't get this board myself, but you can set the ARM version when you cross compile quite easily.
Anybody considering implementing a high-performance state machine should probably look at http://www.colm.net/open-source/ragel/ too.
Why?
What are generics if not templated types that are filled out at compile time ? Before answering, remember that Go does not support inheritance.
How is it compared to martini/revel?
Start out with net/http. If you think you need something more look at [Gorilla Toolkit](http://www.gorillatoolkit.org/). *Hint:* You probably don't need gorilla/mux package. You can do almost all things without a 1.000 lines library.
Don't know if you've seen this but it looks like a good practical intro to go web apps... http://codegangsta.gitbooks.io/building-web-apps-with-go/ Personally I use just the standard net/http library along with a couple of gorilla libraries.
When implementing a state machine in a real world setting there'd be benefits to using an input type that's most appropriate and having some logic to decide where to go from with given input from each state. At least in most use cases I can think of, where I'd be writing a state machine by hand.
http://play.golang.org/p/diBEjPAi3b
I get what you mean, i have to prevent the main function from exiting. But instead of using WaitGroup i just added select {} at the end of the main function and now it works. But thanks anyway!
because rails/django/cake/play do so :)
I was interested until they made a seperate tool to download packages. No thanks.
Beego seems to be the most mature of the three.
It takes longer to learn a framework than to just do it yourself. Especially if you become familiar with the specs and protocols and never have to learn a framework in any language again. Amirong? 
try https://github.com/ivpusic/neo. Easy to start with, minimal but powerful.
Just a heads up, select will block forever. Your code won't terminate without you manually stopping it. This isn't always a bad thing, but it's something to keep in mind.
I don't think this is quite right. Both C++ templates and go generate "generics" are "type checked" during compilation. Traits further extend what these other 2 cannot. You explicitly mark types as satisfying a particular role. This is not available in Go or C++ (through templates anyway), although it has been proposed numerous times for the latter. Go intentionally avoids it with its implicit interfaces. 
He/she doesn't know the language yet. I'm not shitting on frameworks; I think in a lot of cases they make sense (more mature codebase, fewer security holes, etc). In other situations, they can be a great way to just save work when a little extra weight isn't a huge deal. But I think it's a bad habit to look for a framework before even learning a language. In the case of Go, it has so many packages and built-in features that require frameworks to get in other languages. One might find that there's something that Gorilla has that would take a lot of code and testing to do on one's own, or they might find that Go works fine for their web app on its own. I just think it's strange that people look for frameworks before even knowing what's missing from the core language.
For Go, "go generate generics" are checked at compile time after type parametrization, and each version must be semantically checked independently, because that's the only place they can be checked. For C++ it's a little more complex. Types are checked at instantiation. This is perfectly legal C++: template &lt;class T&gt; auto add_one(T const x) -&gt; T { return x + 1; } However, templates are not code. They are templates. They only become code during instantiation. Until you fill in the types, you will never know if the function is actually usable or not. If I passed a type without operator+ defined to add_one, the compiler would report the error at the "x + 1" expression instead of where the template was used. This is why you can end up with thousands of lines of error messages when passing one wrong type to a templated function. Traits (and Concepts or Concepts Lite) solve this by enforcing constraints when the template is first seen, not when filling in the types later at the call site.
Thanks for this link. I already know most of what's in there but its such a great resource to keep on hand to show others.
There are plenty of reasons. Asset tooling. Node is better supported, more mature and faster than Otto. We had problems running our Javascript code with Otto and we're not risking our production site. I don't mean to be harsh on Otto but it isn't a node replacement at this time and likely will never be. In the end, use the right tools for the job.
Just a digression not really related to this project specifically, hopefully being academic and not something to be used for real. With goroutines or other languages with decent concurrency/continuation/async syntax, I don't want to see finite state machines again. Large projects employing state machines are very very hard to reason about. Compare a finite state machine where you change the state from different functions that you can access due to different events and you can't clearly see the flow unless you have a very clear and up-to-date diagram, to a single simple flow in a single function that you can read top down. FSM nowadays for me have only sense for compiling something into a parser (like regex), nothing else.
Thanks to you, TIL what Bikeshedding is!
I'd say start out with net/http and get a better understanding of how it works and how everything ties together. That way, when you do feel like moving to a framework, you'll have a better understanding of what is happening behind the scene. I eventually moved to Beego since you can scaffold quick and get something working in minimal time. It does have the ability to reload your code as you make changes.
Ha, true. It's faster than expected ;) http://play.golang.org/p/VraNUExbL9
Sorry, I realize my post was not very clear... he had this code: for true { time.Sleep(paus) fmt.Println(text) } I merely meant to replace it with for { time.Sleep(paus) fmt.Println(text) } on the assumption he wanted a loop that does stuff forever. This was not intended to be used as a way to block forever. Definitely select{} is the appropriate way to simply block forever (although, as others pointed out, it's usually not a good idea to block forever with no way to ever unblock.. you're wasting resources for this goroutine if you do so).
As with any language, I strongly suggest starting out with the core first, then as you find areas that are lacking, include packages that you need. You'll learn how Go does things, as opposed to how 'Framework X' thinks you should do them. It will also give you a keen sense of what the language has, and what it hasn't. For routing, [HttpRouter](https://github.com/julienschmidt/httprouter) is a dead simple router that plops right on top of Go's existing libraries so perfectly that it feels like it's part of the standard library. 
A lack of apparent choice does not necessarily constitute a vacuum for your needs. What payment gateways do you need that are lacking in Go? Are you making business decisions based on the language, or language decisions based on your business?
Did you not understand that third parties could sell your code when you first released code under an open source licence?
Before even thinking martini see: [Three reasons you should not use Martini](https://stephensearles.com/three-reasons-you-should-not-use-martini/) and then perhaps [the author's response](http://codegangsta.io/blog/2014/05/19/my-thoughts-on-martini/). (tl;dr: martini is *extremely* non-idiomatic Go; there are many betters ways of doing similar tasks with Go.)
Try this https://github.com/reusee/ccg 
I used Beego for a learning project and found it useful. Not nearly as "heavy" as Rails. Generally speaking, it makes good use of the Go std. library. Like pretty much every ORM, the one included in Beego is fine for apps with simple DB needs. It supports raw SQL if your needs are more complex. The presently abandoned result [can be seen here](http://60plusadventures.com/). Complete [source code is here](https://github.com/emadera52/sixty).
That's a viable option. One issue that concerned us with that approach is you need to replicate all the queries (from actions or stores) for a specific route in Go to build the props. By letting node handle it, the react components to be rendered follow that route's flux flow in the client.
3 year support? No api changes? Do the bolt db authors agree to this? If the upstream makes a breaking change, will stablelib just refuse to update, and we will miss out on upstream bug fixes? No thank you.
If there isn't a need for a framework, why do they exist? I think frameworks do more than just get in the way. They're a way to encapsulate both code and conventions (ideally practices best). I use frameworks as a cheatsheet on learning a language. It moves the low-level stuff out of my way. Once I'm comfortable enough with the language, I start to peak under the hood. 
Much obliged. 
Many thanks.
Exactly my thought. Also, I don't know what "support" means if it's not your product.
I don't know why I feel like this is not very ethical. It's reselling open source packages by giving a fake-guarantee* of stability to people who won't follow the best practice of _vendoring your code_. At this point, it should be understood that you need to _vendor_ your dependencies if you care about them at all. Don't think that throwing money at a 3rd party makes that responsibility go away. So all together, this feels like its encouraging bad behavior by making users wrongly feel appeased, while charging a fee for distributing OSS. So yeah, it rubs me the wrong way, a whole lot. *fake as in, if they go away, their stability is worth nothing. If internet isn't working, they're not solving anything.
&gt;If there isn't a need for a framework, why do they exist? I wasn't saying this at all. I clearly pointed out that there are places where frameworks are necessary or make sense. &gt;Once I'm comfortable enough with the language, I start to peak under the hood. Why not learn the language first so you know everything that's available? It seems totally backward to learn some subset of a language inside a framework, *then* learn the language.
Dreams = realized
It's allowed, but it still shaddy as a practice. At least in my opinion.
Library not problem for first version. I more vorry about design pattern. Like how implement DDD in Golang?
best Linux ide ever. Been using it since v6.
A lot of the devs actually use linux as their main platform :)
Right, so in your example, you're fetching the data in the express handler and rendering the react template. The confusion was, I thought you were fetching the data in go first and then passing the data to a node endpoint to "reactify" it. What you have is basically what we do except we take a snapshot of our flux container to bootstrap the client.
Gold? For me? Thanks so much! :D I can finally ditch liteIde now
Thank you! My first gold!
&gt; I thought you were fetching the data in go first and then passing the data to a node endpoint to "reactify" it. Passing the data to a node endpoint would have the same effect, would it not? func showDetail(w http.ResponseWriter, *r http.Request) { data, err := getSomeData(mux.Vars(r)["id"]) // pass data to node endpoint, render the response reactify(w, "detail_route", data) } with "reactify" something like this: func reactify( w http.ResponseWriter, r *http.Request, route string, props interface{}) error { t := &amp;http.Transport{} reactClient := &amp;http.Client{Transport: t} propsJSON, err := json.Marshal(props) values := url.Values{} values.Set("route", route) values.Set("props", string(propsJSON)) resp, err := reactClient.PostForm("http://127.0.0.1:3000/react/", values) // skip error handling content, err := ioutil.ReadAll(resp.Body) return writeBody(w, content, http.StatusOK, "text/html") }
Looks really weid. For example bolt seems to be fork where they made a "stablelib" branch yesterday from HEAD. So just from master they cut out a branch and are telling us its "stable"? I would recon the stable is the latest release which would be the "v1.0" tag in bolts case. Only commits they did to the branch was rewrite all the imports to point to their fork. So... yeah our "stable" guarantee == whatever was head in the dev branch when we decided to fork the repo. Looks like the people running this dont know what they are doing or I'm confused about their guarantees. Sorry, but smells like bullshit to me. I'd much rather continue importing "gopkg.in/boltdb/bolt.v1" that actually fetches me the right tag/branch curated by the original repo/author.
I can't find the license installer on the "My Account" page from ActiveState. Someone here with the same problem?
Ok, there is no link at the bottom of the page. I'm going to contact the support. Thanks for your help.
I just downloaded Komodo Edit (on a Windows machine), and when I type anythin in a Go file I get the following message: `process.py: can't execute None (gocode -f=json autocomplete ....` I tried a JS file, the autocomplete works there. Any ideas?
[Go Concurrency Patterns](https://blog.golang.org/pipelines), section entitled "bounded parallelism". What you want to do is spin up a set of N goroutines (in this case 2) for servicing findMatch requests.
The biggest question here is why you only want two concurrent instances of findMatch running at a time. Goroutines are very light and so you don't need to worry about running 10s or 1000s of them like you would with threads in other languages. If you really want to limit the the number of times that it's running, the simpler way to do it would be to have a function that pulls values from the entCh and passes them to findMatch synchronously, and just run that twice in a couple of goroutines, or have findMatch use a [semaphore](http://www.golangpatterns.info/concurrency/semaphores). I believe the first way would be the idiomatic way to do it: func passEntToFindMatch() { for { ent := &lt;- entCh findMatch(ent, &amp;entities, matchCh, 0) } } go passEntToFindMatch() go passEntToFindMatch() If that's all your program is doing it will exit after that unless you use a waitgroup or an empty select to block the main goroutine however
From the looks of this code, it looks like you want a "bounded concurrency" system where you have x number of workers that all process work in parallel. Instead of having one channel per worker, they can all share a channel. When multiple listeners are listening on a channel, only one of them will receive a send, so you can launch each worker in a goroutine. Try this: http://play.golang.org/p/rcnOsnqpV4
I don't see the Google+ 'Go+' community listed (hope I didn't miss it), it has ~19000 members and stuff is posted every day: https://plus.google.com/communities/114112804251407510571
&gt; It takes longer to learn a framework than to just do it yourself. Especially if you become familiar with the specs and protocols and never have to learn a framework in any language again. But most people aren't familiar with the intricacies and limitations of HTTP cookies, headers, request contexts, graceful HTTP server shutdowns, authentication middleware, sessions (and how those tie into auth + use of cookies), parsing POST form values cleanly into a struct, etc. There are so many "gotchas" and the repercussions for stuffing up these things quickly escalate from "render a broken page" to "my auth system is compromised". net/http is still a framework—just a really minimal one—but it still gives you a few things to get started. I prefer a "glue it together" approach and regularly lean on gorilla (sessions, schema), goji (router, context, middleware patterns) and sqlx (db to struct). The real problem that many have with *some* frameworks is that they are kitchen sink, they don't interop with other parts of the Go ecosystem (aka the `http.Handler` interface), and are generally obtuse to beginners. The latter is the worst part since, in many cases, they're not learning much of the language and/or transferable skills. But not all frameworks are tarred with that same brush.
Been a customer since the PDK v1 in 1999, and if only they would allow upgrades from older versions. Had version 5, and this is the first time I am willing to pay for an upgrade, but alas, not offered (I contacted sales when v8 came out). 
Version 5 to version 8, 9 is quite an upgrade, it makes sense sales would ask you to buy a new version as upgrading through 5, 6, 7, 8, 9 would be far more expensive than just buying it new. I'm sorry you feel that is unjustified.
Good question. I only took a little time trying tigertonic before creating gomelon so correct me if I'm wrong. I think tigertonic has a different approach. It has everything in one place, compare to decoupling thirdparty and user application code using Command, Bundle, Resource, Task and Managed Object in dropwizard/gomelon. Actually, [Bundle](https://dropwizard.github.io/dropwizard/manual/core.html#man-core-bundles) is my most favourite feature which allows injecting functionality into the application but I couldn't find in tigertonic. As mentioned in [golang-nuts](https://groups.google.com/forum/#!msg/golang-nuts/Ma_V_nHQR_U/3TttbKQ10JMJ), what gomelon is doing is to bring together a set of libraries to build and manage web applications quickly. I have been trying to avoid writing new code on my own, but rather using existing libraries which have proved their value. The project structure as well as configuration are not exactly but similar to Dropwizard so Dropwizard users will find gomelon familiar when moving out from Java world (like I am). Cheers
Looks neat. Reminds me of https://github.com/krisajenkins/yesql - it's nice to get your SQL out of your code sometimes. Having it in separate SQL files can also help with integration testing. Since `purse.Get` returns a simple string, being able to use it with other SQL wrappers (like sqlx for DB-to-struct) is a huge plus in my books too. If anything, some "knowledge" of SQL comments, etc would be useful to allow comments (ala yesql). Otherwise: great stuff. 
Thanks, I'll play around with this.
Try getting intellij Idea and the golang plugin. I was in your boat a couple weeks go, intellij+golang plugin works much better, trust me. The plugin is getting better day by day too, really active project.
Brilliant. Another way to introduce version skew inside large Go projects. I wonder if they are also stripping the [canonical // import comments](http://golang.org/doc/go1.4#canonicalimports) from packages they have forked ?
Good work, I would probably use go generate for this and embed the source files though. Having to shipping sql files along with your binary is kinda inconvenient and error prone.
I guess the real answer is: Tigertonic is "inspired by dropwizard", whereas Gomelon is much closer to a "port" of Drop Wizard to Golang. As an aside, why call it Gomelon? What`s the inspiration behind the name? Why not "DropGOndalf"? hehe
I'm currently developing a sort of custom CRM for a client and created an analytics system in my day job. The analytics system handles a few million requests a day on two web servers and one MySQL server without issue. The front end and backend are using martini and gorm. I've developed a wide variety of web applications using golang without any issues, it's my language of choice now.
Thanks for the input, I use it mainly for CSS and HTML, it is as responsive as editing in the browser developer tools without having to rewrite the code again, it is slightly a different story with JavaScript though.
I agree with the rationale. I'd rather New just took a list of paths so that it could be passed a filepath.Glob result.
You're right, but it's just a partial port at this stage. I'm very bad at naming things and, to be honest, there is no interesting story behind the name :(. I firstly named it gows, but saw some projects mentioning ws as websocket. Couldn't find any names in comics like DW so I just quickly changed to gomelon as I had some melons on my table at that time but still hoping communities can come up with a better name :)
http://4gophers.com/ and https://twitter.com/4gophers
Very much agreed. I already use [go-bindata](https://github.com/jteeuwen/go-bindata) for embedding static assets.
I put together a web ui really quick, sorry if it's not that great: http://heroku-generator.joshualoper.rocks/
It complains about not being able to find the 'go' executable even trough it is in my $PATH, then there's some syntax error in the .py file of the Go plugin and a bunch of other things, disappointed 
wrong sub i think
Isn't it better to keep SQL close to where you actually use it? No need to look further than Go`s backtick. I usually just declare SQL queries as a const string.
No, if you prefer syntax highlighting, auto-completion, Portability-checking and other tools, string literals are not good enough, and it gets worst as your SQL grows. I hope that answers your question,
I don't really like this podcast host. He doesn't ask interesting questions.
You can manually specify your Go executable under Prefs &gt; Languages &gt; Go. Note we use Python 2.7, you'll get syntax errors if you interpret as Python 3
At least the slides were good and quite informative :)
The trial is broken for me on OSX. It is telling me that my license file is not compatible with this version... My machine is brand new. Never had Komodo IDE on it. Can someone let me know how this thing works out for them?
They've also interviewed Andrew Gerrand and Rob Pike in [Episode 100](https://thechangelog.com/100/) (back in August 2013) and the creator of Martini in [Episode 117](https://thechangelog.com/117/) (April 2014).
Yup, you've got to use what works best for you.
Thanks for the help, but that doesn't seem to be the problem, it still says 'Unable to locate go executable' despite me having it set in the preferences as well as in my PATH. [Screenshot - Preferences](http://i.imgur.com/HZhMBC4.png) [Screenshot - Error](http://i.imgur.com/QOLUPGN.png) If this two things could be fixed, (keyword autocompletion and finding go executable), I would get myself a license. Thanks.
Sorry no, that would be quite an undertaking.
Looking into this right now. Note another thing you could do is check your environment variables under `Prefs &gt; Environment`, ensure PATH is properly set. 
boy have you been missing out. It definitely does with the community version. Just download and try it, hope you'll like it :D https://github.com/go-lang-plugin-org/go-lang-idea-plugin/releases/tag/%23201 *the one in the repos does not function with intellij 14. So you can't use that, download it from their github. Download zip, then go to the plugin settings in intellij, then the install from disk, select the WHOLE ZIP! Setup the SDK and you should be good to go :P 
I am also wondering how I can make my DB connection retry indefinitively for better weather.
Ok good to hear. Fwiw opened a bug on the prefs not saving - https://github.com/Komodo/KomodoEdit/issues/58
Are you sure? It seems to have worked for @nathanuk above See where your go executable is located by typing `which go` and ensuring the dirname returned is defined in the Komodo Environment pref (note thats the Komodo environment pref, not your terminal one).
Call a mutex function that retries the connection after every x seconds? Meanwhile you invoke the error 503 page each time a client makes a request? 
It turns out I was a bit misguided in my assumptions. I tried starting and stopping a local database server (postgres in my case) and `gorm` happily continues once the postgres server is back up. It seems like my concern is null and void.
The word terrible is a little subjective, PHP was not designed to be a clean and simple language out of the box, but it's so widely used because of how easy to use and how prevalent it is in the web community. I loved PHP and worked as a web developer the past couple years building in vanilla PHP and a couple frameworks so I'm not knocking the lang. Golang on the other hand is a well designed (built-in concurrency), clean (built-in garbage collection), and simple language (25 keywords) out of the box :-)
Seems like database/sql automatically reconnects if I understood the docs correctly.
Aaaand I submitted! First time in TopCoder, I like it! But I've run out of time :( 2-3 hours more and I would complete everything. Maybe you do know when the next golang challenge will take place?
Very good point. However, I would consider this process very inconvenient during the development stage when any changes to the SQL would require rerunning go generate. I think the best solution would be to implement both use cases under a common interface to avoid much (if any) code change when the program is production ready.
tbh I've listened to the Changelog quite a few times, it's ok. They did a good one with Rob Pike and Andrew Gerrand a few years ago. The thing is the hosts appear to be most familiar with the ruby/javascript scenes, so I'd imagine a lack of familiarity with Go etc bred a less focussed interview. 
Yeah, being able to fast iterate is important.. And that is exactly what I do with resource embedding, use a common interface! it is http.FileSystem to be exact. Here it is if you're interested https://github.com/omeid/go-resources And I wrote https://github.com/omeid/go-yarn to allow embedding sql and other code in the very same way.
Purse is open source and MIT-licensed, so I don't think it's the fact that you forked and modified the project; that's allowed. For one thing, this is reddit, and everything (even [new Go versions](https://www.reddit.com/r/golang/comments/2oy3ls/go_14_is_released/)) get down votes. It might just be that they don't relate to your premise for creating this package, or they think the package introduces too much complexity. Votes on reddit are less valuable/meaningful either way than, say, Stack Exchange or Hacker News. I wouldn't worry too much about it.
I don't expect a podcast host to have specific Go knowledge. I do expect him to have a general understanding and interest in programming and tech. This guy doesn't know enough about anything to ask interesting questions. If you listen to the old show, Radio Free Python, you see what it sounds like when a host is generally interested in technology and knows about a lot of stuff. That podcast is dead though.
[Image](http://imgs.xkcd.com/comics/duty_calls.png) **Title:** Duty Calls **Title-text:** What do you want me to do? LEAVE? Then they'll keep being wrong! [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/386#Explanation) **Stats:** This comic has been referenced 1921 times, representing 3.3530% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cpqy1be)
yea, I would only say the DRY argument was valid. edit: and versioning.
I think the author may have been a bit *too* smug in his article, and some of what he said was contrived, but his comment about DRY and versioning are 2 things I battle with.
I found that I could disregard most of his article, but his critique of DRY and versioning is something I would hope would be addressed in future language updates.
&gt;In my opinion Go has been designed by people who have been using C all their lives and don’t want to try anything new. Uh. Um. Er.
I agree. But I find myself having to learn those things in order to use them in a framework anyway. Without knowing how and what they operate, most of gorilla for example is meaningless drivel.
This is missing the point of versioning. There is quite a few problems where there is no "official" version support, here is the two obvious one Lack of versioning restricts people from making future improvements from the fear of being unkind or angering others by breaking their code. The cost of improvements must outweigh the cost of breaking by a good margin to justify improvements, this isn't ideal. Improvements shouldn't come with an expensive price tag, this also means no back-porting culture. When there is no official versions, there is no backport of fix and improvements. But the current state of the affair is better than having multiple version of the same library in your binary though.
I believe https://github.com/drone uses that lib, or something similar.
I bet you have a path issue but I haven't had a windows computer since XP so I don't know how windows handles pathing. Does go on windows require cygwin? See if you can find where in your filesystem the cuda.h file is, and then make sure that it's in your system's path. 
Different people learn differently. As an old guy with roots going back to Turbo Pascal, with a want/need to build web sites, and wanting to learn Go I started by studying the fundamentals of Go. Then I set out to review frameworks. I wanted one that was used for real web sites and had decent online documentation. I found Beego to be an ideal vehicle to move forward on both web development and learning more about Go. In the process of using Beego I learned a lot about Go... and a lot about how many details go into building a public facing, scalable, database backed web site. Go's std. lib. provides excellent components for handling many of those details. A good framework deals with 1) recognizing the need for a detail and 2) understanding how use existing Go components to effectively and efficiently implement a detail. Many developers interested in getting a site up and running find those things quite valuable. As a plus, having access to the source code behind that composition makes for a real opportunity to learn more about Go. At least is has for me. 
Ok. Have you made sure your c compiler can find the cuda header? Maybe write a simple hello world in C that includes that header and see if you can get it to compile. It might be a path issue with the c compiler. 
Read this quick blog post, http://nicolasmerouze.com/share-values-between-middlewares-context-golang/ It explains exactly that, ways of handling context throughout http handlers My favorite way is the `gorilla/context` way of doing things https://github.com/gorilla/context/blob/master/context.go#L15
Hmmm. Ok, let's assume that's the problem. I'm using [win-builds.org](http://win-builds.org/doku.php) to install gcc, etc. to my machine. I'm using LiteIDE to write and compile Go. How would I tell LiteIDE (or, gcc, I guess?) to include the additional directory? *edit: Seems to be the issue. I get: C:\WinBuilds\bin&gt;gcc test.c test.c:1:18: fatal error: cuda.h: No such file or directory #include &lt;cuda.h&gt; ^ compilation terminated.
I'm sorry, I just don't know modern windows enough to help you with that. :( I'm only familiar with gcc and clang on OS X, *bsd, and Linux. 
Ok, well assume that this is on linux and you're compiling the program via Go. Do you give Go additional parameters that somehow get passed along to gcc or is there a config for gcc somewhere that automagically includes additional source/header directories?
Thank you, I hope it saves you some work. :)
I have the same problem.
Why are we discussing this?
This is not a Go-only gotcha, it used to work the same in C#.
Check out this command line [torrent client](https://github.com/anacrolix/torrent). It uses the context package.
Thanks for the copy editing. I am unapologetic in my views on simplicity and maintain that Go represents the best option for programmers who just want to get things done.
Your projects need to be organized into workspaces, or you won't be able to build them with the go tool. See https://golang.org/doc/code.html.
The best way to respond is to write awesome software and let it speak for itself. .... Or berate the guy for his suboptimal code examples ;)
[Flotilla](https://github.com/thrisp/flotilla) is my own toolkit &amp; solution to the issue, and was built in part with the idea of translating some existing flask applications to go. 
Have you ever tried to convince a Republican to be a Democrat? Or a Democrat to be a Republican. There are many times in life where allowing people to have their own strong and conflicting opinion is far more productive than trying to explain to them why they're "wrong".
Thanks, they do indeed, and this is how they chain the contexts: func ContextMiddleware(c *web.C, h http.Handler) http.Handler { fn := func(w http.ResponseWriter, r *http.Request) { var ctx = context.Background() ctx = datastore.NewContext(ctx, database.NewDatastore(db)) ctx = blobstore.NewContext(ctx, database.NewBlobstore(db)) ctx = pool.NewContext(ctx, workers) ctx = director.NewContext(ctx, worker) ctx = pubsub.NewContext(ctx, pub) // add the context to the goji web context webcontext.Set(c, ctx) h.ServeHTTP(w, r) } return http.HandlerFunc(fn) } https://github.com/drone/drone/blob/aa4b38ceb1e7f5c29ad7e9fd593b231f761fb78f/server/main.go#L167-L172 What's confusing, is that they use both x/net/context and goji context, eg: https://github.com/drone/drone/blob/master/server/middleware/context.go
Thanks. I've read this before but this time I followed it carefully. I can now use the go to to run/build/ get. But eclipse or intellij still aren't playing ball, it seems most ide's don't use the go tools properly?
I generally don't respond. Most of these kinds of articles seem to be from someone who is an enthusiast for another language (in this case D), someone who is just complaining that Go doesn't do it like other languages (usually Java), or both. The two simple thing, is just to silly to comment on. In this case the authors example of int conversions isn't really a good one, this can be done more simply and with a single method if you do a bit manipulation like doing only int 64 with conversions or wrappers for the array in or out. Also the example of circumventing the type system is silly too. There are ways to do that in almost any language. It's a bit ironic because when you get to the level of interface{} (or dealing with bytes or whatever) you need to know what you're doing. So the author complains that the language is too simple then talks about how it's too hard later on. Wierd. I do find these articles useful in 2 ways: 1. It's insight into how programmers might have difficulties adjusting their conceptual models. As a lead engineer I need to ramp up other engineers on Go and knowing where their thinking tends to go wrong is helpful to me in getting them oriented. 2. I do find a mix of things in most articles. There's a lot of fluff, whining or hyperbole in these anti-Go articles, however nothing is perfect and there are legitimate shortcomings to be aware of in the case of any language. I don't find a lot in THIS article in particular but I do see them.
Yes. This can be a very difficult mistake to debug. The easiest way to understand this is: (1) Go reuse variables declared in loops. Maybe, in the future, the go compiler can check to see if there are goroutines in the loop, and if so, do not reuse loop variable. (???) (2) If there are 10 goroutines running at the same time and only one loop variable, the variable can only have one value in the 10 goroutines at any moment. Variables in loops must be passed into each goroutine (so that a new copy is created at the time of passing). Remember this rule and everything will be alright.
We will backport any bug or security fixes to the stable version without breaking API.
I'm not familiar with it on Windows at this point either, but this looks like it may be what you need: http://www.mingw.org/wiki/includepathhowto
Indeed, the tool is optional. The separate tool will do more than `go get`: 1. It will use only secure transport (unlike `go get`, until this [go get](https://github.com/golang/go/issues/9637) issue is fixed). 2. Every package release will be GPG-signed, and `stablelib` tool will check the signature. 3. It will help switch import statements to supported packages (see `stablelib switch` in example.) 4. Possibly other features I haven't thought about yet...
Yes, canonical import comments will be stripped, and maybe replaced with // import "stablelib...". Not sure about version skew — what's the concern?
We're applying the Red Hat model: providing stable versions, support, bug/vulnerability fixes, publishing security advisories, and sponsoring the development of packages. While /u/avrtno is right that [making money with GPLed software is allowed] (https://www.gnu.org/philosophy/selling.html), there will be no GPL packages in StableLib, because they can't be used in proprietary software (our target audience), so indeed, switching your packages to GPL will work. I don't know, though, why you wouldn't want your packages there: we do code and security reviews, contribute code back.
If you only intend to have static urls, then yes. Otherwise you need something like gorilla/mux or julienschmidt/httprouter, unless you want to write your own request router.
* It's indeed not a community effort, it's a business effort. * Currently we select the packages ourselves, but feel free to let me know if you'd like to see some project there (in fact, the sign up form has this field). * I'm interested in running this business as long as there are customers. There's indeed no exit strategy. The business is bootstrapped, not funded, so we're not concerned about exit.
https://github.com/zenazn/goji and https://github.com/gin-gonic/gin seems like very popular and solid libraries/toolkits. https://github.com/codegangsta/negroni is a good middleware library as well.
The github org you're seeing is not the final result of our efforts, and everything is pretty much still in development. (FYI, there were many bug fixes since bolt v1.0, and many more README fixes. If your users are on 386 arch, I suggest you use the current `master`.)
I'm pretty sure on Linux it just uses the environment's for a cgo module. Maybe go read the go pkg cgo to see if there's any configuration?
Then you need to figure out the right flags to pass to gcc. 
Depends on what trust you're talking about: * that we don't put backdoors into shipped packages? The code is there in the open. * that we won't follow our promise to support packages? People pay us for this, so it's in our best interest. * that stablelib.com is here to stay? Indeed, that's a great concern about young businesses, and there can be no guarantee. But there's no lock in whatsoever, so it's less of the concern. * anything else?
What does 'dedent' mean?
Not really. You can have dynamics URLs with net/http default mux. I recommend watching this entire talk, but from 11m45s he starts showing that you don't need gorilla/mux so much: https://youtu.be/yi5A3cK1LNA?t=11m45s
Think of it as providing services on top of open source packages. Does it feel wrong? :-)
https://access.redhat.com/support or http://www.canonical.com/services ;-)
I'm late to the party! StableLib is my effort, nice to meet you all. I'm Dmitry Chestnykh, and I've been using Go since its public release (I think I wrote the first public Go project according to this [Mashable article](http://mashable.com/2009/11/12/gotweet/ ) :-). I also contributed to Go, mostly [/x/crypto](https://github.com/golang/crypto) stuff such as scrypt and salsa, and wrote lots of open source packages — https://github.com/dchest. I tried to reply to the most of the concerns raised here, but if you have any questions, feel free to ask, or email me — &lt;dmitry@codingrobots.com&gt; / twitter — [@dchest](https://twitter.com/dchest). I guess stablelib.com needs a FAQ... StableLib is an effort to help businesses use third-party Go packages without worry (and make profit doing it).
Excellent. Is there a config file for Go that sets this variable or should I just create it the normal way you do on Windows?
Hey, thanks for posting my article! We did discuss it a couple days ago over here: http://www.reddit.com/r/golang/comments/2zltqv/creating_fakes_with_channels/
Ah, oh well.
It was pretty ok, I expected much worse based on comments here.
This which are the same _must_ have the same name, ie, github.com/lib/pq must only appear in the import tree at that location to ensure it's only registered once.
I know what "to outdent" means, just was curious why couldn't the package be named after it.
There's a "go env" command that outputs some flags: set GOGCCFLAGS=-m64 -mthreads -fmessage-length=0 Will creating an environment variable of the same name overwrite the flags that are already in there? Or, I suppose I could just include them as well....
Hey - If what you have in mind is a REST service, then check out github.com/mohamedattahri/rst. It comes with a very interesting approach based on interfaces. "With these interfaces, the complexity behind dealing with all the headers and status codes of the HTTP protocol is abstracted to let you focus on returning a resource or an error."
Host acknowledged that he's never written a single line of Go beyond "Hello World". 
That isn't a complete answer, every transitive import graph which includes a reference to some copy of lib/pq will have to be updated. I don't see this being a simple task.
How does it know what types to substitute for when being used for generics-like functionality? Does it support multiple type parameters? PS. Links in the roadmap are to a different repo. The project was moved, I presume?
Sure, but I think for most projects this won't be a problem. Vendoring has the same issue, but it works for people.
I tried using it with the C preprocessor and it worked out quite well for me - http://adityagodbole.github.io/GolangCppGenerics.html
Very nice. I have to agree with /u/nanodano — this is really nice and readable. I'm an experienced programmer but I'm just picking up Go, and I'm enjoying looking at this.
It _will_ be a problem. Vendoring with `godep -r` does not have this issue. 
i assume the heroku go build pack did not work as expected for you?
Nope did not work, the issue with this is that I have no .go file in my presentation folder, its just a .slide (markdown file, that is compiled into html5 with the present package) file, once running 'present' in the cmd prompt It tells me I can open on localhost:3999, therefore since I have no .go file if I use the go build pack from heroku it tells me that I have no buildable Go source files I thought I could copy the 'present' binary from the $GOPATH/bin directory into my presentation folder and deploy to heroku like that... but I am stuck as to how I can run the binary on heroku instead of building the go app using the heroku build pack
It does analysis on the AST of the template file to see what types need to be provided to translate it and then searches your source file for any types that can be interpreted as 'matching'. For example given the generic code: type K interface{} type V interface{} type Map map[K]V func (m Map) SomeFunc() {} It would search for any types in your source that is a 'map from a key of any type, to a value of any type'. Both of the following would match and `SomeFunc` would get implemented for both type IntStrMap map[int]string type UserMap map[string]*User That should also answer your question regarding multiple type parameters. The goal is to allow for meta code of arbitrary complexity, so use as many types in whatever configuration you need. Thanks for the tip about the roadmap, it's been updated. I did recently move it. 
Can someone suggest a different approach I may take? Other than deploying on Heroku? 
I've been working on this https://github.com/go-goast/goast that might do what you're looking for
I did, in this very thread. Why don't you reply on that point and let me know why that won't work for you ?
i can't see it, which is intriguing. Reddit says there are 5 comments (prior to this comment), but I can only see 4. Mayhaps you could post again?
Wow I actually thought this was a bug with reddit, honestly I'm with /u/letgourearthlytether I don't see that comment as well edit: Am I missing something here... I only see 6 comments but Reddit tells me there is 8 :/ 
Yeh lol, So weird... I had to look into /u/davecheney and his comments section and I actually was able to see what he posted about 4 hrs ago... This would have saved me soo much time if it was visible :( .. Idk why Reddit is hiding his comment ?:| 
Just a quick solution, not ideal but seems to do the trick: https://play.golang.org/p/VL7bd6lC2w
It's still not visible in this thread. I had to look into your profile to see the comment you left idk Reddit is drunk today :/... Thanks it worked!!!! BTW, I got into Go a month ago and just recently stumbled upon your blog... I've been sending your article on simplicity-and-collaboration to all my co-workers at my job... It resonates with alot of my coworkers.. We are slowly switching to GO :) 
So for anyone that might want the answer I am reposting what /u/davecheney posted about 4 hrs ago... For some reason A lot of redditors can't see his post :/
Another happy customer. Excellent.
I will look at that, thanks
*Please* do not use spaces in paths. Just don't do it. Not even on Windows.
Meanwhile, the strings from the example in the README have NO common indentation: s := `Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur justo tellus, facilisis nec efficitur dictum, fermentum vitae ligula. Sed eu convallis sapien.` It should not be unindented. I didn't check if dedent actually removes the indentation in this case, but if so, it's insane. It's like unindenting the following python code: if some_condition: do_something() do_another_thing() 
Most of the "generic systems" for Go have been code generators. Code generators do not cause builder fragmentation because everything can still be built with go build. Of course it does cause issues with readability of packages if everyone is using their own dialect of Go. Of course most code doesn't need generics in the first place - it has it's uses, but can be dealt with. There are some specific domains where it is really useful - in which case you probably shouldn't be using Go.
This looks interesting. I wanted to experiment with Prolog for some time. Thanks for posting!
Sorry, my mistake... should've been more specific with my words - map, slice are sufficient for most cases. Also, people want a lot of things, this doesn't immediately mean it's a good idea. Code generation solves real problems - I can do things with it, that I cannot do easily with generics. To me it seems people are building generics libraries because they are used to solving problems in a certain way and are not willing to figure out other ways of solving them. Alternatively they just have nothing better to do. SQL isn't a general purpose language either - so lets stop using that as well. Go solves a specific set of problems and it is a general purpose language - but it isn't ideal for all situations.
SQL is probably between DSL and a general purpose language. And yes I've seen declarative language used as a server - but can't remember what was the name of it.... (although found something similar https://en.wikipedia.org/wiki/WebQL). Also you seem to be very frustrated with Go not having generics - is there some specific problem you have trouble solving in Go?
You don't need a third party - I explicitly said you could do it with just github. Also you can run your own copy of gopkg.in if you want. Also, you don't have to have it hard coded to gopkg.in. You can use a vanity url that redirects to gopkg.in or your own repo and change that if you ever need to switch where you host your code. All this stuff has been solved, people complaining about it just don't know all the solutions.
Nice interview, thanks for sharing. Was good to hear opinion on Hindley-Milner type inference from one of the Go authors.
That sounds pretty sweet. How does it play with non-empty interfaces though?
Thanks! Out of the box right now it doesn't deal with non-empty interfaces at all. It's something I've spent time thinking about and it's within the realm of things that could be supported without too much extension.
Thanks for taking the time to express your concerns. I've read through this whole comment tree to try and make sure I can address any points that directly have to do with goast. When I first started programming with Go, I felt similarly as you, that there should be compiler level support for Container-of-Type-T style generics. It wasn't a show-stopper for me, but I found myself writing the some of the same code over and over; iterator patterns, sorting, etc When the Go team announced go:generate I was already heavily interested in the AST package. I've always found that interesting ideas come from working within boundaries, so while I was hesitant at first, I decided that instead of sulking, I would try embracing the ideas that the Go team was putting out and see what sort of system I could produce within their boundaries that solved my problems. goast isn't finished yet, but it goes a long way to solving my problems in a practical manner. Points: 1. **Language/build fragmentation**: goast tries to minimize this effect by not requiring you to use a new language or requiring a different *compile* tool. You write goast metacode in Go (not text templates or some other language). You run `go build` on it to test that it's valid code. Once you have generated it using `go generate` you can again test it's validity using `go build`. goast uses Go import paths to locate packages to implement, and `go get` can be used to fetch them. As far as not diverging too far from the language while also providing extra functionality, I think I'm doing ok. 1. **go:generate is not useful**: I'm sorry you feel that way, but you haven't done much to back your personal opinion on that up. For goast, `go:generate` was incredibly useful. Having a standard interface to be able to say 'Do X to this file' and have those actions be part of the standard build chain is a great way to be able to invoke build tools. Don't underrate the fact that `go:generate` lets you put these build instructions into the source it deals with...that's much better than just running arbitrary command line tools on source files and needing some other way to enumerate that. Just the convenience of `go:generate`providing what source file generated the command is useful. Being able to invoke a single command from my editor (`go generate`) and having anything I need done for me is great. Honestly. The ergonomics of it are quite nice, you really might want to try it. 1. **Lack of generics is a flaw of the language that can't be spun any other way**: Let me try and spin that another way. Frequently in projects, I eventually have the opportunity to stop working with the language I'm using as something I'm writing code with, and start working with it as something that can tell me about code that I've written. The lack of generics, among other design decisions the Go team has made, makes this a distinctly easy process in Go. The AST is a breeze to work with and that ease has uses outside of just code generation. A lot of your points and concerns were a little ethereal and not really directed at goast. If you have any further constructive criticism that's more pointed, I would enjoy being able to discuss those with you and to be able to factor those concerns into my design. Edit: forgot a
Hey, I recognize this compiled generics discussion doc. I intermittently would find it and refer to it while developing! Thanks for putting that together. It seems like you've invested some time in thinking about this problem domain in relation to Go, so if you had any thoughts with regards to goast, I would love to hear them.
Because you are copying code everywhere, going against the idea of source control. If you are coming from NPM, this is particularly irksome. Lack of versioning limits the community as stated by /u/londogopher Its not that the current solution does not work, its that the creators just hand waved it as if stuck in an older era. Its an ease of use issue, pain and insanity are bad. Also everything else in that article is just bull.
Short version, as I've said to many before - I'm not completely understanding what the problems are it is trying to solve. Simply saying it implements "generics" for me isn't enough. Basically, the current examples in the package don't outweigh the cost of using this tool. Basically, I would suggest trying to find real-world examples where this tool would be used. Then implement those examples and see how you can improve the tooling. For example https://clipperhouse.github.io/gen/ it already provides a lot of value out of the box, if you are working on some datasets and don't want to include a DB then the slice type writer is quite useful. Few ideas, use the actual type in the go:generate statment, e.g. //go:generate goast "T &gt; []int" github.com/jamesgarfield/sliceops This would rewrite type `T` to `[]int`. Of course using some comments in the package would allow some default replacements, e.g. //goast: default type T interface{} //go:generate goast "[]int" github.com/jamesgarfield/sliceops That would make it more obvious what is replaced with what. Of course this needs some additional checks. Of course, instead of working on generics tool - I would suggest doing something else. There are probably things that would provide more value for people - e.g. a proper static code analyzer (e.g. something like http://www.viva64.com/en/b/0308/ for Go, to catch typos and common errors); some static deadlock analyzer; code inliner; constraints checking based on comments; comment spell checker. Of course these are much harder tasks than a code-generator, but something that would provide value for more projects. If you make it specially easy to add new rules to the system overtime it could build up to a great tool for any gophers toolkit.
Some people think that programming should be an art, every construct should be perfectly expressed and abstracted and beautiful, and things like simplicity, portability, and performance are unimportant details. Other people write programs to consume input and produce output, for various values of input and output. The real value of development is the work the program does, not the work the programmer does.
Are you wanting to test if it's actually random? Are you just salting the bultin rand?
More specifically did you consider - type-generic interfaces - type variables constrained to interfaces?
I would only test that the random generated key matches a regexp pattern. Everything else makes no sense whatsoever.
I know git (far from an expert, but I use it every day). I know separate repos blows, which is why gopkg.in was created. I know this adds an external dependency... but so does github, google code, etc. Is it a pain when they go away? Sure. Is it the end of the world? No. When I said you could run gopkg.in, I meant for your own code, not to replace gopkg.in for other people's code (though I suppose you *could* with the appropriate proxy in place). You also said that smart package managers can avoid having multiple versions of the same code in the same library, which is just keeping your head in the sand. Yes, sure, pip, npm, etc can complain if you import foo.v2 and foo.v4... but if someone renames foo.v2 to bar.v2 ... the tool will never know. There's no silver bullet to versioning... and I personally really like that in Go, the source control is the package management. It's one less thing I have to think about.
It adds an external dependency with no value to little value to provider, the likelihood of gopkg going out is much higher than Github and is a much weaker link in your trust chain but regardless, it is a dependency and trust delegation that can be avoided. It is simple as that. A proxy wouldn't fix the server that is down, sure I could fake it with my local setup and fiddling with my dns but seriously? is this the better solution? come on, the whole idea of running proxies to get your library versions correct is pretty bizarre. A warning is better than none, let alone the fact that Go is already enforcing a lot of stuff, the idea of go tool forcing one version of a library per project isn't that foreign. Now with gopkg.in and alternatives it is much more likely to end up with multiple versions of the same package in your binary without realising it.
Type Variables with constraints: yes definitely. I have two options in mind 1. Constrained to an interface that is defined in the meta code. There is a specific point in the inference analysis that would handle this but is explicitly not doing anything right now. It's a potential future development once I explore the idea more and how the implementation would work 1. Constrained to a specific built-in type. i.e. you define generic code that works on an type and any user-defined int types could generate off of that e.g. `type Pixel int` could generate code that was defined for the meta-type `type AnyInt int` I'm not sure what you mean by type-generic interfaces, could you go into a little more detail?
Cool, my brother wrote that.
Maybe compare the results of two runs of the function, just to check that it does not always generate the same key?
Think of type Adder&lt;T&gt; interface { Add(Adder&lt;T&gt;) Adder&lt;T&gt; } (Borrowing Java's generic syntax.)
I don't know why people are so negative about this. You don't have to use it. The guy is trying very hard to respond criticisms and succeeding. Also note that GPL allows things like this. If you can't manage your own repositories well, you deserve to be forked. There are a number of Go community packages that have an awful track record when it comes to interface stability. Projects like this will at least cause maintainers to care a little more. 
This is the way to do it. But if you're doing your own random number generation (why?) then maybe you can make sure that it returns the same values for the same seeds only...
A reader which always returns 0s (or 1s, or 2s, ...) is even easier. 
I am using math/rand and I just couldn't figure out how to mock it...
No I am trying to make sure that it actually generates and that it is properly placed in the XML structure.
math/rand is not good enough to generate security tokens with. Please don't use it for that. 
Ok, this seems to work. Any idea how to set a path with spaces? Such as: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v6.5\include\
I have go test running against it. The problem that I have is the file is generated with a random value and validating output fails on that portion every time.
Are you sure that you are even injecting into the xml file correctly?
This is the part I am having a problem with. I am not sure how to mock math.rand correctly in my test suite. I haven't dealt with this type of testing before...
Ohhhhhhhhhhhhhh. The test is failing because you can't generate two of the same random numbers, gotcha. How is your generator working? Do you provide it a string to hash or can you seed it?
Fix the seed with a specific value 
How would I go about changing the seed only for my test function? That was my initial thought too but I wasn't sure how to accomplish this, but then have it generate a random value outside the test.
make an interface that math.Rand satisfies for what you need. Hand in the real math.rand in the actual code, hand in a mock up that returns constant values in the test.
Thanks, I really like this approach! I will give this a shot.
Very interesting! Thanks for sharing. Curious to know the performance of other go kv data stores now.
I made a similar experience when benchmarking databases for implementing the storage of [Prometheus](http://prometheus.io). I also benchmarked Bolt, along with [Levigo](https://github.com/jmhodges/levigo) and [native Go LevelDB](https://github.com/syndtr/goleveldb). Bolt was by far the slowest for inserts there as well. I don't remember the details, but I think for inserting a million small keys, BoltDB took 10 minutes where LevelDB took 10 seconds. Read performance was great, of course. Still, LevelDB definitely won hands down for inserts, which makes sense, given its optimization for fast inserts due to the leveled structure. However, key/value stores all lost in comparison to the raw filesystem for storing the bulk time series data in the end. If you think about it, the file system is already a highly optimized key/value store. Right now, Prometheus is using (native Go) LevelDB only for its indexes, while using a single file per time series for the actual sample data. Works brilliantly, even for millions of time series. EDIT: For the first 1.5 years or so, Prometheus stored *everything* in Levigo (C++ cgo LevelDB), even the time series samples themselves. Samples were stored in batches of hundreds per LevelDB key. This performed decently, but the new filesystem-based storage performs better. EDIT 2: Found some old data from these benchmarks on this Twitter thread: https://twitter.com/juliusvolz/status/504315520133652480: https://gist.github.com/juliusv/53fb6742021fd3cbbe15. Turns out, the write speed factor was actually 8x between BoltDB/LevelDB on SSD, and 64x(!) on spinning disk.
I'm planning to continue comparing persistence options to add exactly that. If it's something your interested in, I'd be happy to send you a message on here when the next post goes up?
We benchmarked protobufs, gob, and a custom binary format. In the end, the custom binary format won hands-down, and encoding/decoding speeds actually mattered significantly in queries. In fact, we're now using a format where each file is a series of 1024-byte double-delta-encoded chunks of samples where every sample is addressable by its index without decoding the entire chunk (and timestamps in Prometheus actually don't come in predictable intervals, but can be arbitrary, so you can't just index into a file by timestamp directly). Chunks are swapped in/out as a whole to/from memory. For the low-level encoding, we use a lot of "encoding/binary" standard-library functionality. Have a look at https://github.com/prometheus/prometheus/blob/master/storage/local/codable/codable.go and https://github.com/prometheus/prometheus/blob/master/storage/local/persistence.go. It's already quite highly optimized code, so it's already somewhat complex. EDIT: there's also some more information in our [FAQ](http://prometheus.io/docs/introduction/faq/#why-does-prometheus-use-a-custom-storage-backend-rather-than-%5Bsome-other-storage-method%5D?-isn't-the-%22one-file-per-time-series%22-approach-killing-performance?). Keep in mind that the performance numbers given there are of the entire system (including scraping via HTTP over the network, then ingesting into the storage). Writing samples to the storage without any other external bottlenecks is faster.
tl;dr: Each Bolt DB.Update is two fsyncs. DB.Batch will opportunistically combine concurrent updates. Your "sequential" keys are stringified integers, thus actually almost closer to random writes in their spread. You use batch size 1000. Bumping the batch size size to 10k makes the "benchmark" run 10x faster. Remember to also fix the place where you failed to use your const. 
[RosettaCode](http://rosettacode.org/) [CodeAbbey](http://www.codeabbey.com/) etc. Do a web search for something like "small programming project idea".
http://cryptopals.com/
This gets more interesting when you have idempotent operations and you're banging your head at why the task is being run only once. -_-
Related: https://github.com/omeid/log/tree/master/util
this is cool gj
You can save `database.DB` as a global variable and init it in main function, then access it only in models or services. Commonly, controllers should not access the db.
yes, even i am doing it, but not using in init function. I have created two modules, one is controller where i do my logic part and one model section where every DB thing will be done. Init function redirect url to controller function which calls model function for all db related tasks. Model runs sql queries and return output to controller which is processed by controller to send it back to user in response. Now as db is being created in init function, i need to pass it in each handler so that it can reach controller. One issue is as it passes through controller so even controller has access to call DB query which i don't want to do.
yes, agreed. I am also having same thinking. I read somewhere that global variables are not right way to do it. We should use context, not sure though. Any comments on that? Is it right to keep db variable global?
Define a global db in model package, and expose a initializer for it to be called in main function. I think it's right tp use a single db instance in global scope, it's safety for concurrency. The context itself maintain another scope, is it necessary? Futher, if you store the db instance in a context, where you store the context variable, another context?
Can you please help elaborate why we should not have all models in single package? Just to explain, i want to have users model in user.go and same for others in model package. As model package is only needed so planning to put it in that package only, so that others don't even try to use it. It always help get other's point of view to make better decision.
Go is rising, and that's great, but this sounds like an overstatement.
Can you elaborate a bit what you mean?
&gt;The story doesn’t end here. The above results were for single core x86 machine. If you look at results for single-core 64-bit machine, Go actually wins on this and 2 other benchmarks. Also, if you look at the quad-core 64-bit results (a much more typical one in today's hardware landscape), Go beats Java in 7 of the 11 benchmarks. http://benchmarksgame.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=go&amp;lang2=java&amp;data=u64q
Ah, right. You're saying that there aren't enough levels. The current structure suffices for my own current purposes, but I guess I could make the amount of levels configurable. This would probably require support for migration from one structure to another, though. In general I've been thinking about supporting various migrations. Say one needs to add another size the images should be encoded into. Depending on the nature of the application the engine is supporting, they might want to create additional copies of the original images all at once. But when the older images are not accessed that often it might make more sense to only create the additional copies when they're requested.
Ah, didn't see it was 3 years old, however I think x64 quad core was very much 'the norm' compared to 32-bit single core machines 3 years ago as well, particularly in areas where Java and Go is typically deployed.
Kinda feel like a dummy, but I don't even know how to start with that. I've used echo/curl/cat but I have absolute no id get started on that
and [yet](http://i.imgur.com/VlALgsL.png)
I came to Go from Java, so I have the same instinct to layout my project like that, but back up a bit - do you need different packages? If you're going to have several services with different controllers, but using the same models or database library, then sure. But, in keeping with the spirit of being pragmatic, maybe just use one package. Thoughts?
Sorry, didn't spot that