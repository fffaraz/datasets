If you can handle the error, then handle it. If not, then pass it up.
I definitely will let everyone know!
Yeah I thought that was a really odd choice for the Go logo. I think that was like the first proposed logo for Go.
There is a feedback problem here c &lt;- 1 println("yay, value stored") How do you know if 1 is successfully persisted ? Do you say it's when the next statement is reached ? Maybe. But there are no semantics in Go that say "receive from a channel, but don't let the sender know until I'm ready" -- even if you use an unbuffered channel. Then there is the case if there _was_ a problem persisting the value ? How can you tell the sender that you couldn't store the value (pick the horror story of your choice) ? panic isn't available because the sender and receiver are in different goroutines. I think all you are left with is crashing the processes. So, while this might look like a channel send/receive, it probably isn't a good fit. This is the same reason why we don't have network channels, the semantics and error handling just don't fit.
goimports can also be nice ;)
It works with the github api, not with a checked out copy of the git repository. So you can't exactly do that, but you can use the API to create a new file probably. Or use another library to maintain a copy of the repo.
It looks like I need to use git2go to manage the commits and go-github to push them to the remote branch. I'll put together a more comprehensive write up and post it once I get it all working. 
NSQ is basically built off that idea.
To me, Go feels like the perfect middle between the C family and the Pascal family philosophies. Simplicity, sensible typing, fast compilation, no trap in the language. Well, they are both 1970's languages, so people might argue about that, *but*, it also has built-in concurrency, so we're saved ! :)
&gt; You can try implementing some kind of two-phase commit on the sender. But that breaks the nice fire and forget part of channels. My point exactly.
There is a [blog post](http://commandcenter.blogspot.com.au/2012/09/thank-you-apple.html) by Rob Pike about his few days dealing with Apple support trying to get his hardrive backed up and clean install of OSX and getting the data restored again. There's also a [tweet](https://twitter.com/joeerl/status/505337612513853441) from Joe Armstrong(created Erlang) trying to get some html/javascript slide software to work, he got stuck trying to install grunt and eventually gave up. It's pretty scary. 
How can you need 12 weeks for microservices?
Additionally what other said here, there is always: * [go vet](http://godoc.org/code.google.com/p/go.tools/cmd/vet) * [golint](https://github.com/golang/lint) To automatically perform some analyse of your code.
go amqp package returns a channel for consuming messages
0mq is persistent?
+1 - nsq configured to have write persistence would accomplish this nicely.
Found this one out the other day! Was going through the tutorials and decided to split up files based upon the topic. I had func main(){} in each file, and when I tried to GoRun it threw the error. Really interesting! 
(note that I do not, actually think Go is ugly, but I do enjoy watching people complain about Go in a kind of masochistic way)
Yes, I do think go is ugly. But, I love it! Having spent a fair amount of time in languages like Haskell which strive for "elegance", go is meant to get things done. Go's ugliness makes thing like cache locality, control flow, error handling, and concurrency present in the syntax rather than abstracted away behind layers of leaky abstractions of "syntactic sugaring".
It consumes more memory, because you're copying values between stack frames to get work done. By using pointers, you create an object on the heap, and reference the single object on the heap. On a small scale, it doesn't really matter, but if you start dealing with large numbers of transactions (web apps, database processes, etc.), you're gonna realize how far a little memory will go.
It's definitely not *bad* so long as User is not a huge struct. I generally prefer functions that return a modified value, rather than modifying a pointer in-place, even if the thing they take in *is* a pointer. It makes it a lot more obvious that something has **changed**: func DoWork(u *User){ /* stuff */ } // somewhere far away user := &amp;User{} DoWork(user) // Is user the same here? Maybe it is, maybe it isn't. // You'd have to look at the implementation of do work to know for sure. This is much more obvious: func DoWork(u *User) *User { /* stuff */ } // somewhere far away user := &amp;User{} user = DoWork(user) // much more obvious the user might get changed 
To add to what everyone has already said, it isn't [idiomatic Go](http://golang.org/doc/effective_go.html#pointers_vs_values), but do what makes you happy. The idiomatic way would be: func (user *User)DoWork() error { // Do some stuff return nil } u := User{} err := u.DoWork()
Well, I wouldn't say it's non-idiomatic. I think it's just fine as-is. Saying it should be a receiver function is probably looking too closely at what is obviously just example code. DoWork could easily be a function in a different package... I don't think the point was Receiver vs. No Receiver, I think the point was "modify in place, or return a new value".
On the flip side, it might be faster because you don't have the pointer interaction. In this particular case it's hard to tell because we don't know how long the string is, but for something like type Point struct { X float64 Y float64 } The extra memory cost is tiny. 
It's sure not as "pretty" as Ruby is, for example. But I haven't written a line of Ruby in 4 years, Go is my only language now. So... shipped code is prettier than anything else at the end of the day.
I wonder how the initial six options were selected? In any case, it's good to see Go make a relatively strong showing.
I have a love/hate relationship with their error handling, mostly because it makes writing chainable interfaces difficult. I like that propagating errors must be done explicitly, but it's such a common use case that I wish there was a less boilerplatey way to do it. x, err := DoStuff() if err != nil { return nil, errors.New("Stuff broke") } is a common enough idiom that I wish there were a more compact way to express it. Especially since `go fmt` won't let me turn the if statement into a one-liner. I have functions where well over half the line count goes toward shoving errors up the call stack and it sometimes makes it unnecessarily difficult to tell what the happy path is supposed to do.
I actually have been following this website for some time. It started out with just ruby, JavaScript and coffeescript. I am guessing these were the languages used to implement the app itself. Then people started asking for something functional so Haskell and clojure were added. Then java and python simply because of the large following they have.
More thoughts on this question : https://groups.google.com/forum/#!searchin/golang-nuts/tuple
This is my idea for my current project: .../project/executable = .go files; sources for the server app (has subfolders) .../project/mainsite = for all html files; static files .../project/templates = for all template files; static files .../project/data = for tmp files and other stuff; dynamic files; no problem if these are deleted regularly But I cannot find a way to include sibling folders while deploying to Heroku. As I understand, the only practical way to work with Heroku is having one git with all relevant files. Also, Heroku needs the executable to be in the same folder as the repository. So I do not have much choice: one root /executable with all other folders as sub folders (mixing source and non-source folders). Although I consider to put them together in one sub folder.
I think it is a great way to write more functional-style code in Go. This has many advantages in a language where concurrency plays a big role. In my experience it also makes code easier to test and less coupled. It is one of the things I really liked about Clojure.
I've heard a few people say that go doesn't support tuples, but I don't really know what they want to do that go can't do right now. For example, this works: func main() { bar(foo()) } func bar(s string, i int) { fmt.Println(s, i) } func foo() (string, int) { return baz() } func baz() (string, int) { return "foo", 1 } http://play.golang.org/p/vsxgzyatNj You can even do this: func baz() (string, int) { return "foo", 1 } type bat struct { s string i int } b := bat{} b.s, b.i = baz() So... what's missing? We have multiple returns and multiple arguments, and multiple assignment from multiple returns. I think it's actually pretty great. [edit] I guess the one thing I can think of that isn't covered is sending multiple values over a channel, which is vaguely annoying, but not something I'd want to add a whole host of complexity to the language for, just so I wouldn't have to create a struct to send over the channel.
&gt; But I cannot find a way to include sibling folders while deploying to Heroku [...] Maybe you'll bash me, but wouldn't the solution be not not use Heroku? Any particular reason you would pick Heroku over a VPS or something (except simplicity)? *P.S. This is a biased view as I dislike Heroku.*
That's awesome! Is there a story behind this?
I don't like the notion that if a function throws an error, then the value it's expected to return is immediately bogus. Errors aren't necessarily fatal and sometimes you might want to do something different with a value rather than reject it.
As far as I can tell, Google has an internal acapella group.
Nothing should stop you having a src dir inside a large project, with your other packages within it. In most packages a src dir is pointless (it's all source), but in packages with a lot of other stuff (assets, templates etc), it might make sense. 
I wrote that. I'm sorry for self-posting my blog URLs but I think people might enjoy it. 
* A package is a folder with go files in it * A package foo contains one or more go files (all expected to have package foo at top) * import "mypkg" imports packages (i.e. folders), not files The ridiculous folder structure is there for the go toolchain so that you can go get packages and not clobber other peoples'. If you just want to play with go, you can compile and run a single go file easily enough without any project structure at all and even outside gopath, e.g. a file hello.go: package main func main() { println("Hello world") } go run hello.go Hello world Stick with the typical package structure and location though and you'll find it makes life easier in the long run, your packages will be go gettable, you'll be able to easily find imported code on disk, etc.
I guess my ideal syntax would be somewhere in the middle. Off the top of my head, something like an `or` keyword that executed its right operand if and only if the last return value of its left operand was not nil. Something like this: x, err := DoStuff() or return nil, err Still manual and mostly explicit, but a lot less boilerplate. Admittedly I haven't thought this exact idea all the way through, but I think the level of "magic" here is just about right. I think my annoyance comes from having to copy/paste code. Recently I had to write a function that did the following 1. Fetch an oAuth token from a remote API 2. Fetch a resource from that API using the token 3. Unmarshall the JSON response into a custom struct 4. Parse one string value in that struct as a URL. 5. Build a return value using, among other tings the parsed URL. If any step failed I needed to abort and return a generic error. I couldn't defer error checking to the end since each step depended on the last. As far as I can tell, the only way to handle this is to literally copy/paste the exact same three lines of error handling cruft after every intermediate result. Don't get me wrong, this is still a lesser evil than exceptions, but it is still frustrating to say the least.
Go is a very "get shit done" language. Apparently that rubs a lot of people the wrong way.
 /project/datastore =&gt; models /project/db =&gt; migrations (goose) /project/dist =&gt; debian stuff /project/server =&gt; routing, handlers /project/settings =&gt; shared settings /project/public =&gt; static files to be served directly /project/templates =&gt; html templates (if needed) But we're still exploring, and keep changing our "boilerplate".
but so much easier to deploy :) 
"Who cares what Boost is for?" is an amazing lyric. Love the song. 
The idea is to experience Heroku - to get an idea of the speed and such. Because the first node is free its a good start. I agree it seems relatively very expensive after that.
Lots of people self post, I think it's totally fine, btw.
I'm liking how vim-plug has made things easier on me in regards to YouCompleteMe, *but now I have to deal with vim-plug* something something turtles. 
Why would you return the same error for all these things? Wouldn't you want to give more info - like couldn't connect to api or auth failed or unexpected response....? That's why it's not copy and paste. Because each failure is different.
To me, Go is almost a direct competitor to RuPyNode in OSI layer 7 realm, especially HTTP. Go basically destroys them mercilessly. At almost about the same lines of code too, if counting all the exception handling, type checking, &amp; tests you ended up writing in production environment.
I hate to be that guy but your site is very difficult to read on a phone or mobile viewport. Also, if you're still using PyFlakes raw, I would switch to flake8, which combines multiple "linters" such as pep8, and pyflakes. The biggest thing that Go has for it over Python in general is how new the language is. You're not stuck with setuptools, distutils, pip, easy_install, setup.py, a million test frameworks or runners, etc. The obvious downside to this is the maturity of the community (but I still think Go is very strong here). The Go tooling is amazing. As someone who writes Python every day and Go sometimes (for work or hobby), I find Python faster at writing things with rich/complex domains, and Go better at almost everything else.
&gt; I like the fact that it's just normal code. Error handling **is** normal code. Error conditions are just inputs you don't want to deal with but you have to if you want things to work reliably.
Super awkward.
Oh, heck. Some clue in the title as to what this was would have been helpful. I almost missed this until I happened to click through to the comments because, you know, I've stopped reading the "Go is great you should try it!" articles and that's what I thought this was. Well. I suppose it still technically falls into that genre. But still. You know what I mean.
flake8 is just a wrapper script on top of pyflakes. I use it as a pre-commit hook in almost all my python projects. At the moment I can write python almost entirely without reading documentation but for Go I still have to look everything up all the time. I'm looking forward to getting Go into my bloodstream. 
Wow. It sucks on mobile. Better go and check out some media queries. Thanks for pointing it out. 
Yes, it would work, but I find it odd to have the word "src" in the package name (in the import). It's bad enough that I have to include the hostname of the company that I use for source control!
&gt; RuPyNode I searched for this thinking it was something I hadn't heard of, before realizing what you meant =\
I was referencing to this, http://en.m.wikipedia.org/wiki/OSI_model#Layer_7:_application_layer, which I am sure you already know. For writing application, chat, mail, etc. Go is very pleasant to use. Go shines even more when compared to Java for doing these things.
I am pretty new to go. I am in the process of building a web app with it. I really like it so far. I started with C++ in school and I work with PHP and JS everyday. I am pretty sold on Go and I hope that I can get to a point that I can use it at work.
Multiple, actually. This was the NYC group. 
The litmus test for this assertion is whether or not the language itself was written without these features. In fact it hasn't since we clearly see many areas where multiple return values are supported, it's just that they are reserved for linguistic features rather than for the language users. For that matter, go is full of hypocracy. If operator overloading isn't allowed, why implement string concatenation with the + operator. If method and function overloading isn't allowed, why implement `make` in a __very__ overloaded manner? Why not stick to the language of 'simplicity' and instead provide specific make functions for every type. Anyways, sorry for my rant on Go. I really want to like the language. I learned it in a week and I was/am excited about it, but currently I'm more excited about it's potential rather than the current state because the current state is lacking some basic luxuries of programming, luxuries that the makers of Go have proven to be essential by using them to make Go.
Umm, what? I only worked with it briefly, but I believe MQ's rolling transaction logs and store files are both a proprietary format (ie: not DB2). Can you link me to some information about DB2 being the backend for WMQ?
Ew. 
Brilliant part two 
Few things : There's no doc, no comment. So I may be new to Go, but this code is hard to understand. I could be wrong but maybe it'll be a good idea to split that in more than one file?
Added comments and a few lines on usage. I don't feel like something that simple needs to be split across multiple files, though.
Thanks for the comments! You're right that it works great without splitting it, and even more if you don't feel like reusing part of it and stuff.
Take a look at the [techempower benchmark results](http://www.techempower.com/benchmarks/). They do a bit more than "echo", which isn't really a great test. You may also want to see [the shootout results](http://benchmarksgame.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=go&amp;lang2=php&amp;data=u32), which is frankly more interesting to me (due to the sort of work I do where my "real work" dominates the HTTP request cycle time). Get out of the highly super mega optimized HTTP pathway and just start doing "real work" and suddenly it's no comparison.
Impressive! I wish I could understand the comment though.
Yeah it'll beat php and give nginx a run.
Your comment right there got me to click on it. And I'm so glad I did.
Because it's an amazing company where blue sky research/product dev is allowed. They value smart people and make the best products in many categories. A project like Go would have never gotten off the ground in other companies and while I think it's incomplete, it may eventually be one of the best languages out there.
I'll check it out. Thanks for the hard work!
Yes yes, because *hello world* is all you need to decide to switch to a new language/platform. -_-
It is quite fast, but nginx is very good. I think the core language is faster than php in general, but I saw some research a year ago showing that the built-in http server wasn't as well optimized as nginx. That's not surprising though -- nginx is quite a large body of work. Still, I think go for it. Writing the language is very fun, especially compares to php -- and it'll be "fast enough".
This is a nice looking project and an interesting idea, but this statement isn't quite true. &gt; There are a few of GO IDEs, and no one developed by Go itself, this is a nice try There's at least one other developed in pure Go.
This is fantastic!! Maybe the community can add a debugger to this.
For what it's worth, I've done a number of scientific computing projects entirely in Go. Most of the time its speed is only different from codes written in C by a fairly small fraction (one part in six, one part in four, etc.). This is quite fast. Of course, this will vary from program to program (so benchmark for your use cases!), but there are very few things in the language itself which will slow you down too much, especially when compared to other garbage collected languages.
I would "write in go" but it's not always up to me. :(
Probably Limetext, but that's pretty much a work in progress I believe. 
Pretty sure Wide is a work in progress too. Lime Text is indeed written in Go, although it's more of a general text/code editor rather than Go-specific IDE. What I had in mind was my own project, which is also a work in progress that's very far from finished/usable by general public, but it is written in 100% pure Go and targets Go development only. https://github.com/shurcooL/Conception-go#conception-go
Those are all great reasons to not use not use Go for scientific computing. However, I personally consider every programming language I've ever learned -- including Go -- to be fundamentally unacceptable for scientific computing in some large way or another. Some of the newest languages look extremely promising (Nim/Nimrod, especially Rust, and very especially Julia), but none of them are there yet. Because of this it comes down to knowing what your project requires. If I'm working on a project where matrix operations are a significant enough component that I can't deal with the slowdown associated with CGo calls or my own hand-written Go matrix library, I don't use Go. If I'm working on a project that requires data structures more complicated than cleverly-used arrays and hash tables (which is actually surprisingly rare) which are operating on things other than doubles, I don't use Go. If I'm working on a problem that can be solved in fifty lines via scipy/numpy calls, I don't use Go. If I'm running something on thousands of nodes for a month, I don't use Go. However, a lot of the time what I want is to do implement an algorithm with clean, fast, imperative code: I want to write in C without putting up with all of C's jagged edges. And for times like these, Go is the best language I've ever used.
Because of the lack of a standard widget toolkit in Go web-based UI's are a decent option. It's great to see another Go IDE that took this approach. Also, the team development is a nice touch that also plays well into the technology choice. Another similar IDE is godev: go get github.com/sirnewton01/godev godev &lt;open web browser to the url&gt;
The compiler doesn't see it as an alias because it isn't one. It's a new type. You're probably getting fooled by the way bare numbers constants in the code will take on any numeric type (including not just your new type, but things like int32 vs uint32 without a direct specification), but it's a new type. Yes, you will need to specify how to sort all the types, and yes, it is pretty boilerplate-y. It's not 30 lines, though. 10, sure, but not 30.
I got as far as "I like to use empty interfaces for plumbing..." and write the whole interview off as a loss.
I'd disagree with his definition of a framework - in my mind, a framework is something that dictates a style of development that you can only have one of in a major project. Rails is a web framework, Spring is a web framework, Guice is a dependency injection framework but does not dictate other technical choices in a project. By contrast, a library is non-exclusive. Choosing one library should not preclude you from using other libraries. 
I am the creator, would love to hear feedback and code review comments.
I like passing the YAML through the template engine. That's pretty neat use of templates. A couple of things I noticed... In your LoadFromFile, in your defer func that closes a file, you are accessing logFunc without checking for nil. You "panic" instead of returning errors. Opening files and what not such just return the error vs. panic. Instead of the logFunc, I'd just accept a pointer to a log.Logger. Passing a func like that isn't exactly idiomatic (at least I've not seen that pattern used very much).
The presentation was turned into an article as well: http://talks.golang.org/2012/splash.article
interesting solution. But, IMO, rely on other's people choices with setup/config. will limit you in the future. In this case why centos? I think all of that can be installed via simple shell script with better options. Of course from the box solution may help in many cases when you don't need (want) to get into details. :) 
But... Isn't that a very old article ? Why post it now ?
I've been coding mainly in PHP for 12 years, and writing Go stuff in my free time for roughly a year and a half. The difference between Go and PHP can vary but Go is often an order of magnitude faster. It's going to be true when you write vanilla PHP code instead of relying on C-based extensions. If you mostly use PHP as a glue language than it can be close. Generally speaking, if you ever notice your PHP code to beat Go in any way than you've probably written some non-idiomatic Go code. You should probably still use nginx in front of Go so there won't be a difference in that regard.
Actually, that `?` suffix isn't a bad idea in my opinion. It is immediately obvious what it does and does not encourage improper error handling because you still have to suffix every single instance of a call that can fail.
Having worked in Haskell for a long time, I can totally understand you. It's amazing how some people spend weeks designing intricate abstractions so the actual task they have to do is reduced from 500 lines to just 50. Do you have any chance to understand they resulting 50 lines without going through how the abstraction works? No. Is the resulting code faster? No. Less error prone? No. Easier to maintain? No. I want to get shit done and that's why I prefer Go very much.
It is because people tend to think about how to handle every single possible error instead of throwing every error into a gotta-catch'em-all try-catch block.
Basically what the others said, plus a polite reminder that Go isn't C.
This is an example of a problem that generics/typeclasses would solve really easily. For instance, in haskell newtype Age = Age Int deriving (Eq, Ord) And then you get sorting for free (and it should compile to the same code as sorting Ints). Right now this is definitely one of the ugly parts of Go. Using newtypes in arrays is definitely the most annoying because you have to copy everything into a new array, and you can't write a function to do this generically, so you end up writing the same array copy code all over the place. Most code get's around it by just using bare `int` types for everything, eschewing the easy type safety acquired by using newtypes.
I'm sure I've sent that article easily a hundred times on twitter to people interested in investigating Go.
I have seen the [article](http://talks.golang.org/2012/splash.article), but I wasn't aware of the video until now.
I think others have already explained what's going on here... I don't see why you would need to create a new type just to sort things, though and even worse, why you would create a new type just for the return. IMO, `[]Type` is clearer than `TypeSlice` unless that new type implements new methods. Also to re-word the most important point from other replies: Apart from a few special-cases, there are no `typedefs` or `type aliases` in Go. `type X T` creates a *new* type and it has *no methods*. If you intend to re-use the methods, you should looking into embedding http://golang.org/doc/effective_go.html#embedding but often, that does nothing but introduce needless complexity.
To me, this is a lot like inheritance vs. composition. Frameworks and class inheritance provide a canvas with some holes in it that you fill with your logic. This is limiting to what you can do, and means you have to understand what the great mass of code does that hooks up your logic. Libraries and composition are tools that fill holes. You provide the canvas. This may be more typing, but you have a better opportunity to do exactly what you want, and don't spend time learning someone else's idea of what you should do.
The only real reason to create new types is to define methods on the type or to prevent mistakes where the wrong value is sent into a function... For example, defining a type for Fahrenheit and Celsius, so you don't pass an F value into a function expecting C temps. In that case, you wouldn't want automatic conversion, because the numeric values are not equivalent. In this case, age is not really a good type to define. You're not gaining much unless you want to define one age in years and one age in another unit, like months for babies. Yes, this makes sorting mildly annoying, but it's trivial code and only like 10 lines, so I don't think it's worth worrying about.
This is where http://xordataexchange.github.io/crypt/ enters :)
Thank you for that hint.
HandleFunc doesn't start the handler, it just registers it. Running it in a goroutine doesn't accomplish anything and probably has race conditions. 
Have a look at [terminal.com](http://terminal.com). Desktop sharing is a feature, not the entire product.
In this case, CentOS because I was mirroring an EC2 instance that I was already working with. The point of the snapshot is to have a starting point and this is a good starting point if you want to prototype with Go. You should create a snapshot with some better options and share it here. I'd love to check it out.
Stick with it. Modal editing is a godsend and will make you such a more efficient txt editor. Edit: moral to modal. 
&gt; Learning each library separately, and knowing their strengths and weaknesses, is both easier and more valuable than learning a framework... Learning about the available libraries may be *valuable*, but hardly *easy*. And we should not conflate the two. In order to learn the libraries and examine their strengths and weaknesses, you need to read the docs and write test applications. (You might even go by user reviews, though I think this is dicey.) There are dozens of third-party libraries to choose from. It is extremely laborious and time-consuming to explore all of these library options in the prescribed manner. To begin working with a framework (such as Beego), you don't need to learn the whole thing all at once. I read enough of the docs to get started fairly quickly. Consequently, I wrote a non-trivial application in record time. Had I followed *your* prescription, it would've taken me weeks or months (to read all the docs, to write the test applications, to perform the runtime evaluations). And you don't know which of these libraries will stand the test of time; some may fall into obscurity or be no longer supported. So, yes, learning to use a framework **is** easier than evaluating third-party libraries. If you choose well (make a good bet), the framework will be well-supported for many years. Of all the available Go frameworks, Beego is easily the most mature and feature-complete. I'm making a bet that it will be the next "Django."
That's your opinion. I don't think interface{} is a "last resort." Depending on the type of software you are writing, a good case can be made for using this idiom. Type safety is one of the benefits of the Go language, but not everyone needs it. It is up to the developer to use it or not. Obviously, the Beego developers thought they had a good case. The proof is in the pudding. Beego is a very useful and powerful framework. If you are uncomfortable with using this framework, that is your choice. But I see nothing wrong with it.
Rather than hand-writing your own there is also github.com/gonum/matrix/mat64. Can be backed by cblas if you wish. 
Why are you under the impression that it's "especially bad"? For me, Like many things, it depends on what your tradeoffs are. If you want to be able to say a := abs(b), and have the right thing be done whether b is a float, cplx, or array, then you also have to accept the complexities of function overloading. In Go, you can say math.Abs(b), cmplx.Abs(b), and (github.com/gonum/)floats.Norm(b, 2). Couple more characters, but you keep a simple language.
A framework need not lock you into feature limitations. It depends on the design of the framework. I find that Beego is pretty darn flexible. In general, though, a web framework is intended for a large class of web applications which suits 99 per cent of companies. There will always be companies that need something different, and for them, a custom solution with mix and match is the way to go.
This is true, but the fact that I have this library is mostly a historical artifact. I've been using Go for a while (I don't think you could iterate over maps when I started but I'm not sure where in the version history that falls), but I think gonum has only existed for about a year. At some point when the ecosystem was less fleshed out I thought it would be fun to try to write my own optimized matrix library. (And it was!) I would not suggest this as a best practice, though. Writing a matrix library is not worth the effort unless you're something of a numerical masochist. I'd rather see that type of time commitment go into improving Go's existing numerical libraries (or, heaven forbid, doing actual science).
The sirens's call of frameworks is incredibly tempting because of the countless important details that must be considered and correctly handled when building a website... a real commercial, client facing website. Those who yearn for the open sea and total control over their vessel will not be tempted. Those willing to accept "increasingly bureaucratic interaction of call-backs, configuration settings, and rigid parameters" in return for having all those details handled "under the covers" have a good chance of mooring their craft in a quiet bay with a sandy beach... surrounded by those legendary rocky shores. That doesn't make frameworks the solution for everyone... but for some, a good framework can be the better option. 
Though I'm happy to see people learning Go (aren't we all?) and sharing their experiences, I can't recommend the article yet because: 1) HandleFunc doesn't, and shouldn't, be executed in goroutines. That's all handled for us by net/http. 2) Relative imports aren't recommended for portable, stable, consistent code. 3) Configuration should be kept close to home, or in other words, the scope of the config values should be as narrow as possible, so this: type Config struct { Adapter struct { Server string Username string Password string Database string Collection string } } var Cfg Config seems a little unnecessary. Configuration is seldom needed globally all around the program, available, unprotected, to everything.
Absolutely is possible. One of our production mobile app API framework is written in Go that runs behind Nginx. Nginx is really good for serving static files of a website and SSL Termination. While Go is good at terminating SSL it's often a lot of code that Nginx can beat out in one line. When you use Nginx + Go you still have Go run its own web server but it's bound to a non-publicly visible port and Nginx proxies requests through to Go. So for example we have ports 80 (HTTP) and 443 (HTTPS) bound to Nginx and Nginx proxies all traffic to an internal port 8081 (HTTP only). 
Awesome article to get you started. It's written for Nginx + Apache but just follow the Nginx steps and tell Go to bind to the port you choose and you're golden.: https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-reverse-proxy-for-apache
:( This is definitely not a spam
Ha, no it's not. I could have made a post about this site too, since I use it and I'm happy to have someone answering my questions. There's groups too, it's funny to watch.
1. main() is a function not a method 2. Do not use relative imports 3. goroutine != thread 4. http.HandleFunc() only registers a handler, it does not, itself, wait-for or process requests. There is no reason to start a goroutine for it. 4. mgo is *not* an ORM (since MongoDB is not an *R*DBMS). 5. Having a package "globals" is rather silly. 6. Quote: "Here’s an awesome bit about Go – you may have noticed that the Delete and Save methods are preceded with a set of parameters." This makes no sense. The Delete and Save methods definitions are *not* preceded by parameters. What we have here, is a construct similar to a *function* definition, with an additional parameter before the function name: This is how methods are defined in go. The parameter before the function-name indicates the object-type that is the receiver for this method. If the notion of "receiver object" confuses you, take a look at: http://www.inf.ufsc.br/poo/smalltalk/ibm/tutorial/oop.html Read the first few paragraphs. You also seem to be confusing the notion of a "function" with that of a "method". 8. Quote: "In Go, this is what is called the receiver, and it declares the variable that has parent scope over that function". There is no such thing as a variable with a "parent scope" over a function. It makes no sense. 9. Quote: "remember that Go is not an OOP language, so the ideas of OOP encapsulation don’t exist here ...". The "ideas" of OOP and encapsulation do "exist" in go. 
Related, http://swtch.com/~rsc/regexp/regexp4.html 
We're a guy and a girl working on this project in our spare time. 
All of the individual subreddits you've posted about this: - /r/golang - /r/progether - /r/learnprogramming - /r/programmingbuddies - /r/mentors - /r/csharp - /r/nes Spam: "irrelevant or inappropriate messages sent on the Internet to a large number of recipients." Inappropriate being it's tangentially related to some of those subreddits, and posted to bring attention to your specific project (a la advertising, without pay).
Sorry, I think you're a troll. This is the last time I'm going to feed you. I don't think that 7 posts over a couple of months is "a large number". Also, how is this irrelevant or inappropriate if we got many upvotes? The last thing we want to do is spam reddit(and surely spam should receive many downvotes?)
I'm not trolling; this is the third 'mentoring' project / business that has posted here and in other programming subreddits in the last couple weeks - that wasn't directly related to those subreddit's respective programming languages in any way. Askadev is the most recent one that I can remember. Additionally, if all the posts did so well, how did the other programming language subreddit post go? (http://www.reddit.com/r/csharp/comments/2ghra1/are_you_interested_in_mentoring_someone_or/)
Thanks for the info, loopj never popped up before on my searches. Thanks again. 
An interesting talk. It was nice to hear his emphasis on "in parallel does not mean simultaneous necessarily" and that simultaneous execution is dependent on hardware resources.
I see your point, but this site isn't making any benefice by getting more users. You've probably been using Go for a while, but I think there's still people that wants to learn here, so that site may be relevant. Also self-promotion isn't forbidden nor strictly considered as spam. Looks like a redditor with a website for me.
Just wanted to make sure you knew about gonum. It sounded like you were still developing your own matrix library. The problem with actual science is that my go code works while my science doesn't.
&gt; &gt; A framework calls your code, you call a library. This *is* the basic distinction between framework and library. It is just that people use the term "framework" wrong - perhaps becaue they think this term pushes the meaningfulness of their code (or the code they write about). I do agree with *all* the rest of the article though. There is so much more to consider about the code that you want to use in your project than just, "is it a framework or a library?".
Gotta agree with you. The article says: &gt; Personally I like to use the empty interface for plumbing and only pin things down to specific interfaces or concrete types where I need to for performance or correctness. Using the type system isn't something that you do just when you need performance or "correctness". You use static typing because it allows you to identify problems at compile time rather than runtime. Coming from Python myself, static typing was a *huge* plus.
I Agree with that, although I have bigger issues with not being able to go get from private repo's :P
Same here... And because there is no official (or proven) way to do it I find myself changing it a lot :S 
Thank You, i've already read all of those. For now i'm ended with some temporary buffers, which are creating in never ending cycle which polls socket. But in such case my question would be why memory for this buffers never freed and why in heap profiling i see only 5-6Mb used?
&gt; Frameworks contain key distinguishing features that separate them from normal libraries: &gt; * inversion of control: In a framework, unlike in libraries or normal user applications, the overall program's flow of control is not dictated by the caller, but by the framework.[1] &gt; * default behavior: A framework has a default behavior. This default behavior must be some useful behavior and not a series of no-ops. &gt; * extensibility: A framework can be extended by the user usually by selective overriding or specialized by user code to provide specific functionality. &gt; * non-modifiable framework code: The framework code, in general, is not supposed to be modified, while accepting user-implemented extensions. In other words, users can extend the framework, but should not modify its code. -- source [http://en.wikipedia.org/wiki/Software_framework](http://en.wikipedia.org/wiki/Software_framework)
&gt; There's a sort.Ints() function which takes a slice of ints. When given a slice of Ages, though, I get a compiler error. The behavior you ask for would not be type safe (not in Go type relationships, anyway; it would be if `Age` were a subtype of `int` and slices were covariant). Types are about defining/restricting what you can do with data, not just about memory structure. You most probably want that distinction, as it makes abstractions safer and more explicit. The compiler is _smarter_, not dumber, for understanding that distinction while, for example, C doesn't. I agree, though, that the abstraction is leaky, as you can e. g. do `age1 + age2`, getting the `int` semantics. But the builtin operators and functions are magical in many ways anyway.
Yes, the link to codesearch is at the bottom of the article: https://code.google.com/p/codesearch/ (for the lazy)
I hate to be the one to have to point it out, but if it's so painful to sort that slice of durations (and it sounds painful just reading about it), then it's very likely that you're going about it the wrong way. First and most importantly, if you actually have code that does this, please, please, please go back and check it, and get rid of it if possible. It's broken. `int` is *not* the same thing as *int64* and if you run that code on a 32 bit platform... well see for yourself what's likely to happen http://play.golang.org/p/oSFDgBotPp . I won't comment on what you must go through in order to user that slice of ints after you've copied and sorted it. The code to implement sort.Interface, is literally 13 lines of boiler plate that is so simple it can be partially automated with editor macros/snippets. If that sounds like too many lines, the gofmt' source can be reduced to 6 lines. You can still use conversion to sort a slice `type X T` and with embedding you get it for free. You wouldn't use plain int64 for durations, because you wouldn't have any methods to work with durations. I don't buy the argument about type-safety in context of that example. It's just as easy to make this mistake: `time.Now().Add(time.Duration(s))`. I think it's probably even easier to make the latter, because (I guess) it's more common to use time.Duration everywhere instead of values that represents seconds, milliseconds, etc. I'm not sure what I can say about `[]interface{}`. Yes you will need to copy if you want to pass a slice of another type, but I can only think of two sets of functions that work like this and they are in log,fmt and database/sql and they both take variadic args, not a slice. In both cases I think it's more common (and readable) to pass explicit arguments anyway, because the string in the first arg has a fixed number of placeholders. 
Then leave.
The first complaint is literally "[Go] does not allow brace on a separate line". Some of the complaints are valid, but others show that he just doesn't understand the purpose of the language (for example, he thinks it's terrible that Go doesn't have ternary if).
&gt;&gt; A framework calls your code, you call a library. &gt; This is the basic distinction between framework and library When does a library cross the "framework threshold"? As soon as there's a callback in the api? I think the framework vs library argument is a false dichotomy.
I'm not saying I want to leave. My experience with Go is too limited to form an opinion on my own and was looking for insight from this community. 
Here's a stripped down version of a package I'm using in a current project. Usage example http://play.golang.org/p/HwgjoOhbKY 
A framework is like porn - it's hard to define, but you know it when you see it.
Same, for me, I'm here to discover projects that uses Go, maybe a blog post about a concept.. But I generally don't really care what people thinks of Go. The only time I was interested in those posts is when I wasn't decided to learn Go (And trying it for two hours is a better way). I also like to see questions from beginners, because I can easily understand them and often answer them. But they're rare. (code review are interesting too)
Cool. I look forward to your thread.
If you're sharing the pointer, who's responsible for creating the connection? Who closes it? 
&gt; If you're sharing the pointer, who's responsible for creating the connection? Infinite regression: You can ask the same thing about "who creates the factory?" Whatever you think should create the factory can just create the `*sql.DB` instead, and however you are planning on sharing the factory, you can share the `*sql.DB` instead. Bonus: Since this is probably done during startup, failure to connect to the DB can be immediately fed back to the user, and the process can probably terminate. By contrast factories here don't fail to connect until someone tries to use one, presumably much later. &gt; Who closes it? Along with the same answer as the above, in this case, program termination. There's nothing wrong with closing sockets and such at program termination, if that is indeed the correct time. Especially when talking to things that are themselves transaction-aware, like a database.
&gt;&gt; If you're sharing the pointer, who's responsible for creating the connection? &gt; Infinite regression: You can ask the same thing about "who creates the factory?" Whatever you think should create the factory can just create the *sql.DB instead, and however you are planning on sharing the factory, you can share the *sql.DB instead. In my case the connection parameters are not known at the time the factory is created. &gt;&gt; Who closes it? &gt; Along with the same answer as the above, in this case, program termination. There's nothing wrong with closing sockets and such at program termination, if that is indeed the correct time. Especially when talking to things that are themselves transaction-aware, like a database. For sure. This wouldn't work for my case though. Think ETL server. EDIT: this is very very specific to my use case. That's why I posted it as a gist. 
Isn't this the usual way? func main() { db := setUpTheDatabaseAndStuff() defer db.Close() doThings(db) doOtherThings(db) }
Hah, I just found this post. I wrote this exact implementation a little while ago, and agree - great demonstration of Go channels and select.
Wanted to spread the word a bit about CGDB since it seems to have got way too little attention, given how well it solves, IMO, the problem of finding a robust and easy to use debugging solution for Golang. In my experience, GDB is the only really reliable and robust debugger for Go, but using the standard command line interface leaves thing to wish, especially because of the lack of continuously viewing the context. This is where CGDB comes handy. The few keystrokes needed to handle basic debugging in gdb can be a bit tedious to look up and memorize so I try to go over these as well in this 4 min video.
Nice. I've got a [tracing/timing package](https://github.com/rubyist/tracerx) that's controlled by env vars (inspired by GIT_TRACE). It does not print the goroutine or line numbers, but that's a good idea.
I would be really interested in this as well. Xcode is a great IDE but I could also just find something for the super old versions of Xcode. :( But I haven't given hope up yet :)
Kind of offtopic, but I'll say it anyway: It's nice to see a project break the GitHub monoculture and host its repository on BitBucket.
&gt; Xcode is a great IDE You really haven't spent much time in Xcode, have you? It is honestly one of the worst IDEs I've ever used, just crash after crash. There's a couple of things it does really nicely, like handling iOS provisioning profiles etc., but that is irrelevant for Go. I don't use an IDE anymore, but I played with [LiteIDE](https://github.com/visualfc/liteide) just for the shits and giggles and I was really impressed.
So the event-driven nature of a Web application requires a developer to use a framework and extend it (write handlers etc.) or to write a one-off framework that uses libraries. The most trivial case in Go is using "net/http" framework.
Quoting myself from an earlier post. &gt;If you want to call net/http a framework under that definition, go for it. You can win that argument, but don’t let it fool you into thinking that this is the exception that proves the rule.
Just use dependency injection, defer close before passing it to the places where it will be used. Global state is evil, and we know that.
I actually use it quite often as a necessity that comes with my student job as a iOS Developer and I really love this IDE... And about the crashes... I think over the Last year I had about 2 of em... Sorry for my english....
How would the api for that look like?
I think that is a fair summary, and also highlights the factthat Go is an _opinionated_ language. The options have been enumerated at length, but can be easily started as the inverse of what the author wants. Luckly, nobody's forcing anyone to use the language, it's just a suggestion, albeit one thatis gathering momentum daily.
There is a **W**eb-based Go **IDE** - [**Wide**](https://github.com/b3log/wide), _have a [**try**](http://wide.b3log.org/signup) first!_ ---- &gt;## Motivation &gt;* **Team** IDE: &gt; * _Safe and reliable_: the project source code stored on the server in real time, the developer's machine crashes without losing any source code &gt; * _Unified environment_: server unified development environment configuration, the developer machine without any additional configuration &gt; * _Out of the box_: 5 minutes to setup a server then open browser to develop, debug &gt; * _Version Control_: each developer has its own source code repository, easy sync with the trunk * **Web-based** IDE: &gt; * Developer needs a browser only &gt; * Cross-platform, even on mobile devices &gt; * Easy to extend &gt; * Easy to integrate with other systems &gt; * For the geeks &gt;* A try for commercial-open source: versions customized for enterprises, close to their development work flows respectively &gt;* Currently more popular Go IDE has some defects or regrets: &gt; * Text editor (vim/emacs/sublime/Atom, etc.): For the Go newbie is too complex &gt; * Plug-in (goclipse, etc.): the need for the original IDE support, not professional &gt; * LiteIDE: no modern user interface :p &gt; * No team development experience &gt;* There are a few of GO IDEs, and no one developed by Go itself, this is a nice try &gt;## Features &gt;* [X] Code Highlight, Folding: Go/HTML/JavaScript/Markdown etc. &gt;* [X] Autocomplete: Go/HTML etc. &gt;* [X] Format: Go/HTML/JSON etc. &gt;* [X] Build &amp; Run &gt;* [ ] Debug &gt;* [X] Multiplayer: a real team development experience &gt;* [X] Navigation, Jump to declaration, Find usages, File search etc. &gt;* [X] Shell: run command on the server &gt;* [ ] Git integration: git command on the web &gt;* [X] Web development: Frontend devlopment (HTML/JS/CSS) all in one &gt;* [X] Go tool: go get/install/fmt etc. &gt;* [X] File Import &amp; Export &gt;* [X] Themes
I get this: workspace/Go/src/github.com/sosedoff/pgweb/api.go:27: undefined: Asset workspace/Go/src/github.com/sosedoff/pgweb/api.go:156: undefined: Asset 
Perhaps my point didn't come across as well as I'd hoped. These definitions may exist, but the examples I gave show that they aren't followed in many cases. It's just too ambiguous to assume when someone uses it that they have those definitions in mind.
I use 101loops/clock: https://github.com/101loops/clock /u/jerf brings up a good point: you need to avoid concurrent usage of a global fake clock. 
if you don't need sophisticated math/scientific/ml libs, i find Perl outshines Python for libraries. CPAN almost guarantees 90% of what you need to write has already been written i
 type Country struct { name string `json:"name"` iso string `json:"iso"` } Both fields are unexported. [From the Go blog](http://blog.golang.org/json-and-go): &gt; The json package only accesses the exported fields of struct types (those that begin with an uppercase letter). Therefore only the the exported fields of a struct will be present in the JSON output. 
One of the top 2 talks at DotGo. What I found particularly good about it was how he move through the evolution of the solution to a problem rather than just present the final solution. Definitely worth the time to watch.
https://travis-ci.org/sosedoff/pgweb
I enjoyed this - and it mirrors my experiences. Worth the watch.
Funny. Most of the points are exactly why I like working with Go. Coding style? I haven't had any discussions about where to put braces for 2 years now. gofmt, done. It is liberating and I can focus on actually writing code. Won't go into these discussions anymore. Pick one. Stick with it. gofmt is there to help you with the semicolon inserts too. Has never been a problem. Error handling is great. It may be a little more verbose, but it forces me to think about what can go wrong. As Rob Pike put it: "Errors are not exceptional. Errors are expected." I don't throw exceptions around and essentially say "not my problem". GC. Also mentioned a lot. It is good enough. It is getting better. Go is a GC language. If you want to minimize stress on the GC, create less garbage. Go gives you the tools to minimize garbage, unlike some other GC languages. Love the interfaces. Genius. Seems like the poster has never worked with Go interfaces. I love how the Go devs have set a high bar on new features. Most proposals I see are only syntactically. This is lazy. A real proposal should include how the proposed change would solve a big(ger) class of problems and how it should be implemented. As it is often said: "adding new features is easy. Getting rid of them is hard" There are many languages which just grow and grow in complexity over time. I love how stable go is. &gt; Il semble que la perfection soit atteinte non quand il n'y a plus rien à ajouter, mais quand il n'y a plus rien à retrancher. &gt; It seems that perfection is attained not when there is nothing more to add, but when there is nothing more to remove. - Antoine de Saint Exupéry Go is a tool. After you use it, you are entitled to your own opinions. It helps me greatly to get my job done. That's why I will stick with it. Others might find it a *insert adjective here* tool to use. Then don't use it.
I think we've all been there at least once :) 
I just went through this, and was able to keep my tests parallel. My service had a top-level struct called "Server". Any methods I needed to swap out for testing are non-exported function pointers on that struct. Tests are able to create an instance of the Server struct, and swap out those functions without disturbing other concurrent tests. Worked real well for me. 
Good list, really.
"Go Nitpicks" nitpicks. &gt;It’s sorta like the C `new` C doesn't have `new`, C++ does. They are two different languages with different philosophy, even if one is a descent of another. &gt; I sorta wish `x := range foo` returned the value in x and not the index, but I get that it’s to be consistent between maps and slices, and returning the value in maps would be odd, I think. IMO, this was made not for consistency, but to give you the power to escape copying when you don't need it. I.e. if you want to actually mutate the items of a slice, you'll use `mySlice[i]`. If the index was the second returned argument, that would mean that each element will be copied no matter how big it is and whether you actually need it. Then there is the old `for i := range [1000]struct{}{}` trick. Other than that, I liked the article.
It also isn't hard to do `_, x := range foo`, so I don't really see it as a problem
Better you can take a look node-webkit or http://clintberry.com/2013/html5-apps-desktop-2013/. These are quit fancy and really good. 
Well, first of all, you are doing something other than what I am criticizing. I was criticizing having a function that does nothing more than delegate to a _global_ function pointer. Putting pointers in your _structs_ is a completely different kettle of fish. (BTW, before you say "oh, nobody would use global pointers like that", this is the third time I've seen this pattern on code posted to /r/golang. Yes, they will.) The reason why putting function pointers in _structs_ is a bad idea isn't that it is intrinsically a bad idea, it is that you are reimplementing something by hand that the language already does for you! The best pattern for that is: type PluggableThing struct { somedata interface{} pluggable } type pluggable interface { swappableMethod1() swappableMethod2() } type realPluggable struct { } func (rp realPluggable) swappableMethod1() { // real implementation } // .. and the rest of the methods type testPluggable struct { } func (tp testPluggable) swappableMethod1() { ... } // and so on And so on. Plugging is then accomplished by modifying some `PluggableThing`'s `pluggable` member. Make the interface public if appropriate. The "pluggable" methods may require you to pass in the top-level struct, which is no different than the function pointer method. Also you can put the "testPluggable" implementation in the `_test.go` files, keeping them entirely out of your "real" library. You'll also find this often becomes a way of breaking things down that is useful in some other way, too; this is one of the fundamental Go design tools.
&gt; 1 Bare Returns yep &gt; 2 New: Use the two line version for numbers and strings. what? why? this is a perfect time to use new. &gt; 3 Close I haven't had issues with this really. You can do something like this. select { case &lt;-c: default: close(c) } 
The multi user interface is cool, but I want to see the cursor and the editing done by other users when I am logged in - that would be true multiplayer :D
re: new - Bah, you're right. It's been so long, I forgot. Thanks for catching that. re: copying on range - You can always do for index, _ := range foo { and that won't copy the value... it just seems like, most of the time, people want the value when they range over a slice, not the index, so that should have been optimized for. Plus, you can always do for x := 0; x &lt; len(foo); x++ { if you want to just use the indices.
What exactly is a "visual web scraper"? How does it work? One possibility that may work would be to write it as a Go app that has a HTML-based UI, instead of QT. My best guess is that you're not seriously using QT beyond possibly its web browser view, and you can do that just fine in a real web browser. But I'm not sure.
Care to explain the difference between new and composite literal?
I basically agree, although *never* using named returns seems a bit extreme (they are in the language for a reason), and *always* using the two-line version instead of `new` is unnecessary; that is why `new` exists. Besides, sometimes it's more aesthetically pleasing not to have `&amp;` characters floating around in your code; `new` reads more easily. Totally agree on `close` though. Then again, I see why the Go authors made it panic if a channel is already closed: since only the sender should be closing a channel, closing a closed channel probably indicates a bug and the Go way is to throw errors -- not warnings -- when something might be a bug. I kinda like that. Keeps my services alive in production because I catch them in development.
You're right about new not being used for maps and slices... that was a little cross-contamination of my thoughts on make as well. But I think the conclusion is still true - whenever you can use composite literals, use them. If you can't, don't use new... I very rarely see code where new actually makes code easier to read. Not sure what you mean about range variables... they are in the scope of the range body. See here: http://play.golang.org/p/8Urg57OigN 
you picked the shit out of those nits, good job. Those necessary bugaboos make, append, and delete exist for basically one reason. I'm not actually going to say that reason because I fear the wrath of downvotes. edit: lol.
So, the gc compiler definitely is smart enough to do that (they added that feature in.... 1.2 or something, I forget exactly). Not sure about gccgo. It's true that you shouldn't rely on things not in the spec, so maybe they should add that to the spec :)
Offtopic: Like all the conferences that take place in the northwest United States have really twee music in the introduction. Is the ukelele really this popular there? Or is it an attempt to emulate [twee Apple commercials](http://www.youtube.com/watch?v=jzj7STruKgQ) with [Jeff Goldblum](http://www.youtube.com/watch?v=wJelEXaPhJ8?)
I have a tendency to overuse bare returns because it makes the code look cleaner since I don't have to use "return blah, nil" constantly. I knew I would have to follow execution in my mind every time I read the code, but since the functions I used bare returns in were typically short, I didn't think this would be a problem. I'm glad I read this post. More details about this can be found here: https://groups.google.com/forum/#!topic/golang-nuts/GLjo8zlurZk Basically, for exported functions (or long functions), bare returns == bad.
That did the trick, thanks. 
Gah, not sure why people are misunderstanding #1. The heading says "bare returns" not "named returns". Yes, named returns can help make your code more clear. *bare returns* do the exact opposite. My problem with close is just that it might panic, and gives me no control over whether or not it does. If it just returned a boolean instead, then I could choose whether or not a panic is right for me. For the record, Rob Pike disagrees with me and says that you shouldn't ever be closing a channel if you're not sure it's open.... which is great in theory, but in practice, sometimes a codepath gets called more than once, and having to wrap close in a recover is ugly to get idempotency.
I think bare returns are always bad. I shouldn't have to read up the whole function to see what values are getting returned. Yes, it might not be a huge deal if the function is really short, but short functions tend to grow, and something that is "sometimes" ok, tends to set precedence that it can be used wherever. The nice thing about "return foo, nil" is that it is immediately obvious that you're returning nil there, rather than having to look through the whole function to make sure you're not assigning a value somewhere. It also means that if later someone adds code above your return statement that sets the second value, that the meaning of the return changes.
Are you familiar with web scrapers? Well, my application allows the user to visually select which parts of a website to scrap.
Yes, sorry, you're right; that's what I get for typing tired.
Out of curiosity, I wonder what the running time would of being if [he had parallelized the xargs command](http://matpalm.com/blog/2009/11/06/xargs-parallel-execution/) sorry I should go into more detail since I'm getting downvotes. As entertaining as he is, because he never established a baseline, he never established the fundamental value of writing xargs in go except for the shear joy of it. I know fuck me for saying that right? but throwing out numbers without establishing fair comparisons is horseshit, and you shouldn't tolerate it. "Go sped this task up so much!", except he can't say that. 
Yes, I know what a scraper is in general. (Tone note: Neutral response to a fair question.) So you're using QT to pull open a browser view and then doing something that allows them to select a chunk of the website, I assume ending up with something like an XPath expression? ... well, the problem here is I just have too many possibilities in mind. Using the app to feed a Go application is one good choice in the general sense, but I'm not sure you'll be able to find a good library to extract the HTML in whatever way you are doing it. A web application could work well, but is trickier than it first sounds due to browser permission issues; you'd really want your app to function as a full proxy and I'm not about to talk through that in a reddit comment. Perhaps the ideal approach would be to simply port the whole thing as-is into Go via [go-qml](https://github.com/go-qml/qml), but I have no direct experience with go-qml, and enough experience with QT bindings in _other_ languages to worry about the completeness, so I worry about recommending that. Perhaps someone else can pop up with experience reports.
It seems there's rarely a time where the difference matters. And pointers to slices are pretty rare regardless.
&gt; Admittedly, this is pretty clunky since it's anything but declarative. Wuzza? Go is not a declarative language. &gt; Why channels don't have channel properties like .isClosed or even an implicit function like isClosed(chan), I will never understand. It's impossible to make that not a race condition. In general, you can not: isAvailable := checkAvailability(concurrentResource) if isAvailable { // do something with the resource } because in between the check and the attempt to use the resource, the status may change. You don't simplify the inner bit of that if statement any; you have to check for resource failure even if the isAvailable passes, so you might as well cut straight to attempting to use the resource and dealing with a failure if one occurs. So that is why the channel interface is what it is; you can atomically "Get an element XOR find out the channel is closed", and you can perform that operation as part of a select, but there's no way to do that nonatomically.
I... I feel you didn't get it. I have the visual scraper almost working (Qt offers a WebKit widget and all, I'm just extending it for my needs). What I want to do with Go is communicating with an API, anyone of those available on the web like the Twitter Stream API, instead of extending the visual scraper. And communicate the Go app with the visual scraper through something HTTP. But some questions arise, and I have enumerate them in my first post, I would like to know what are you thoughts about them!
&gt; relying on the compiler's cleverness doesn't seem like a good practice. I completely disagree. The compiler does all sorts of clever stuff that you don't know nor need to know. I would gladly trade simpler code and a smarter compiler for having to make more complicated code and using a dumber compiler.
I guess this is a good point. So if this behavior, though [documented in the spec](https://golang.org/ref/spec#Short_variable_declarations): &gt; Unlike regular variable declarations, a short variable declaration may redeclare variables provided they were originally declared earlier in the same block with the same type, and at least one of the non-blank variables is new. As a consequence, redeclaration can only appear in a multi-variable short declaration. Redeclaration does not introduce a new variable; it just assigns a new value to the original. is something you're not used to, use `var` declarations in critical code instead. The `:=` is just a convenience operator; I can't think of a reason why you would have to use it if you didn't want to.
Is there also a difference between stack vs heap allocation when you do new(MyStruct) vs &amp;MyStruct{} There's a difference in C++. I'm not sure if that dichotomy translates to Go.
Is he correct in the difference between `new(MyStruct)` and `&amp;MyStruct{}`? If this were C, I'd think that the latter would allocate the struct on the stack, versus on the heap for the former one. Where does go actually allocate this struct in each case?
&gt; Redeclaration does not introduce a new variable; it just assigns a new value to the original. I'm confused. Isn't this assumption exactly what caused the bug in the OP, or what am I missing?
Yes. The bug can happen when that detail from the spec is unknown or forgotten.
[According to this answer](http://stackoverflow.com/questions/10866195/stack-vs-heap-allocation-of-structs-in-go-and-how-they-relate-to-garbage-collec), `new` always allocates a pointer on the heap. Every other locally defined variable undergoes escape analysis to determine whether or not it needs to be allocated on the heap. Otherwise, it is allocated on the stack. 
That is not what I meant. What I was trying to say is that the spec says one thing, namely that a new value will be assigned to the original variable. But what happens in reality is that a new variable is introduced in the local 'if' scope, which caused the bug.
Then he should not use Golang. Many of his 'negatives' are 'positives' from my perspective. But hey, we can choose our own language for the task at hand. (I still don't get why people bash the error handling; after I learned how it worked, I was like *ding ding ding* this is *sooooo* much better than try-except blocks.)
`go-qml` seems to be the best option - https://github.com/go-qml/qml
https://github.com/jgrahamc/dotgo
What is the best way to run go vet with EVERY check enabled. -all does not seem to get this for me.
&gt; provided they were originally declared earlier in the same block The inside of the `if` statement starts a new block, so instead of using the parent scope's variable it will declare a new one. This is perfectly consistent, but it trips me up too. It's not too hard to remember what the `:=` operator does, but I keep forgetting that the insides of `if` and `for` blocks are new scopes.
From https://godoc.org/code.google.com/p/go.tools/cmd/vet#hdr-Other_flags it seems like you can pass in -test as it sets -all and -shadow
github.com/lxn/walk for windows only
No love for an option type (aka fixing the billion dollar mistake)? That is easily one of my biggest beefs with go.
sadly at the moment, as far as I know, nobody is working on a native solution for this. You will find a lot of bindings for existing C++ libs which is not really a solution IMO. So the "state" on this is basically nil. 
upboat https://github.com/andlabs/ui
I upvoted you. bare return is a result from named return. And I feel it is not that bad. I always think: "the return value is zero value unless...", and then I can track the control statement where the return values are modified. I agree with Rob Pike. "wrap close in a recover" is a sign where your code needs to be refactored. I always think: "sender closes".
I don't think this is any cleaner..
this is not a problem at all. The lifetime of a range var should be from the start of the loop to the end of the loop, and go compiler does it right. The problem you have is from goroutine.
Genuine question, why not do web app? Go single binary nature allows you to ship localhost app like a desktop app. Super handy for things like internal apps. You can still use embedded persistence such as SQLite or tie dot and avoid remote db connections.
Because most of your webapp won't be in Go anymore.. you'll be writing a code generator for some other language and that is not what many people want to get into. 
Are you getting any error message? What kind of behaviour are you even expecting?
I will modify the error checking there as well. Good point. Take a peek here for what happens if I return and print this data as a string. It's returning as I would expect, a json object as a string. http://www.reddit.com/r/golang/comments/2knnkr/json_object_decoding/cln1ai2
You're not quite mapping the JSON data structure. Have a look at this: http://play.golang.org/p/05m13_rBMv
Finally! That worked. Thank you so much for your assistance. I'll admit I don't fully understand the language yet. That was infuriating. I had been looking at it for so long and just didn't have a clue :(. Thanks again! On to the next speedbump.
html and javascript it's not the answer you want to hear, but it's the only one that works well, and on top of that everything is moving over to the DOM you can use node-webkit and let go do what it currently does well -- act as a server... you can still use WebRTC/websockets/whatever for full duplex edit - or, okay, fine, let's go with heap of hideous, unmaintainable platform-specific garbage built on half-broken bindings instead, 'cause what the hell do I know
that's not true at all you can set up some very simple UI logic in a few lines of JS and handle the rest from the "server" with go templates at most, you would need JS-driven templating for real time stuff
Correct. The introduction was a way of telling a story and getting people interested. The focus of my talk was not in building a better xargs or using GNU parallel.
Why is this not a solution? Its the only practical solution imo
relevent mailing list discussion is on [golang-dev](https://groups.google.com/forum/#!topic/golang-dev/F-ogZjZws2Y)
You get the whole suite of interface-based composition features that Go supports to play with. The real right question is "what does using a function pointer buy vs. using this approach?" and the answer is "not very much"; you throw away a lot of the features of Go for composition for something that is at most a very very tiny smidgen easier, right now, but stands a reasonable chance of becoming more painful later. Go wants you to compose an interface in and will provide paths to move forward; using function pointers is a dead end. I freely admit to handwaving but it is my experience you will often find the bit of the interface you end up pulling out for testing will turn out to be something that other bits of the code will also want to override, and this is how you provide that functionality in Go.
So it looks like you might be writing a Digital Ocean something, awesome! So we actually have a client that you could either use, or steal some code from to learn on your own, choose your own adventure! https://github.com/digitalocean/godo
Yeah, but what if returning nil isn't really an error for that function (a lookup function is the common example). You could check your error correctly and still get a NPE when you try to use the value. You could argue that you should always return some specific error type on nill returns, but the the caller has to switch on the error which has its own cognitive overhead. Most importantly, without an option type I don't know if I even need to worry about nil or not. That means I have to put null checks all over my code just in case even though half of them will never be triggered. Even if the docs say the function never returns nil, or I have read the function implementation and it verified that, I still can't trust that to remain true in the future. Some intern could go in and change the function to sometimes return nil, and they'd be given no warning that their change broke my code. With option types, that would be a compiler error. I would know what could possibly return nil and what couldn't without needing to read the implementation. I'd be able to trust that functions who don't return nil today won't return nil tomorrow. Combining those two things would let me remove a whole bunch of nil checks from my code and end up with code that is more safe, more readable, and more performant.
I just like the fact that it's symmetrical with getting an address of an existing variable. a := &amp;otherVariable b := &amp;MyStruct{} The nice thing about this is that getting the pointer to a zero value of MyStruct and getting a pointer to a non-zero value of MyStruct are nearly the same: c := &amp;MyStruct{Name: "foo"}
I have to admit to not using composition yet in the 3 months I've been writing in Go. I've switched off the Java part of my brain, so I stopped thinking in terms of classes. I know Go composition is great, I just need to spend some time with it. Thanks for the suggestion - I'll tinker with it!
My point was, the difference between a pointer to a nil slice and a pointer to a non-nil empty slice is rarely important. Most functions will treat them identically. see here: http://play.golang.org/p/XRT8MOls_- 
and https://github.com/conformal/gotk3
No worries. I didn't have a structure defined to unmarshal the data into. It looked like this: {"droplet":{"id":3003359,"name":"create-test-generated","memory":512,"vcpus":1,"disk":20,"locked":true,"status":"new","kernel":{"id":952,"name":"Debian 7.0 x64 vmlinuz-3.2.0-4-amd64 (3.2.54-2)","version":"3.2.0-4-amd64"},"created_at":"2014-10-29T10:45:53Z","features":["virtio"],"backup_ids":[],"snapshot_ids":[],"image":{},"size_slug":"512mb","networks":{},"region":{}},"links":{"actions":[{"id":35538783,"rel":"create","href":"https://api/v2/actions/35538783"}]}} I had the correct structure for part of it but not the whole thing. type Droplet struct { Id int `json:"id"` ImageId int `json:"image_id"` SizeId int `json:"size_id"` RegionId int `json:"region_id"` Name string `json:"name"` IpAddress string `json:"ip_address"` Locked bool `json:"locked"` Status string `json:"status"` CreatedAt string `json:"created_at"` SshKey int } There was an additional "droplet" object at the beginning that I wasn't dealing with. Adding type DropletResult struct { Droplet Droplet `json:"droplet"` } gave the correct setup to unmarshal it correctly.
Anyone know what he means by "Slack tool" for tracking progress of Go?
 For debugging purposes, you can paste JSON strings like that into [json-csv.com](https://json-csv.com) and you will be able to view the data more easily.
I upvoted just to see what everybody else thinks of this? I'm dubious.... It seems non-idiomatic, and like someone is trying to bring a pattern from a previous environment.
He means the Gophers group on Slack. http://blog.gopheracademy.com/gophers-slack-community
Find the example mocks and the gomez project at http://github.com/gbbr
That'll be a ":" in your literal there, not a "=".
If the emphasis is on composition then I don't see he could say it blows xargs out of the water, since he literally composed a comparable program at the start of the talk with pipes. my fundamental issue with it was that he called this a worthwhile, necessary exercise, but I didn't see anything to suggest that. well frankly, all this is minutia, all I REALLY wanted to see was how long it would actually take with parallelized xargs.
oops, thanks, I always do that for some reason
Good article. I found it a very pleasant read. I also liked the way you described why you chose go instead of saying "we chose go because it is the best language ever".
I guess what I really want is a Go version of TK or something that is just built in...
For the record, I don't think you're wrong, and if we could get it for free, I'd be all for it. It's not free, so I'm wary of the tradeoffs. The billion dollar mistake is a cute catchphrase made by a really smart and respected guy, but I think people put way too much weight on it without any actual data to back it up. I do wonder if you could write a static checker that could be smart enough to tell if a function can return a nil pointer (or interface, etc), and if so, if you're using it without checking first. I'm a huge fan of https://github.com/kisielk/errcheck but this sounds like it's an order of magnitude more difficult. Worth investigating, though.
All the native GUI stuff just in a sorry state right now.
I worry that I'm the only person that resists using the ':=' operator except in very narrow scopes. To avoid this shadowing problem, I declare my variables explicitly, usually in the top of the method, and then use explicit returns.
John is a self-proclaimed experienced Perl programmer, and i would have loved to see him compare it to doing it in Perl using the forks.pm module. it would have been about the same amount of code .. and because forks pushes all the hard parts of the concurrency work to the operating system, i would expect it to perform as fast if not faster than Go. also, although not the main thrust of his presentation, his comparison to xargs was a little unfair .. if he had sliced his data first and asked hundreds of xargs to run in parallel, the job would have finished not in 18 hours, but closer to surprisingly good ... all depends on your hardware, but so does Go when it comes to concurrency, the Unix os is king. I would be surprised if Go does it better .. but hoping for a pleasant surprise
I'd comment that Goroutines are really [coroutines](http://en.wikipedia.org/wiki/Coroutine), not threads. It's an important distinction for 2 reasons: * Go routines can be scheduled on 1 or more threads at once. * Go routines are not named, so you cannot check status or manage them.
I hate to be that guy but they're not proper coroutines where the main gist of a coroutine is nonpreemptive scheduling.
good point. :)
goroutines have cooperative scheduling in the current implementation, though the spec is careful not to say one way or the other.
There was https://github.com/skelterjohn/go.uik. Unfortunatly it's dead at the moment. However it was pure go and cross platform thanks to the https://github.com/skelterjohn/go.wde backend (which makes interesting use of interfaces and lambdas). The only use of cgo is for the glfw and cocoa backends. There is also an unofficial backend for the html canvas if you really wanted to. One downside is all rendering and drawing code for the widgets has to be written from scratch.
Shouldn't the cache entry only be updated if the resp.err is nil? Otherwise you are updating with an error result no?
&gt; Still looking for info re: Stop the World GC being limited to 10ms out of every 50ms goroutine running time... Really hoping this made it in. "The goal of the **Go 1.5 (June 2015)** Garbage Collector (GC) is to reduce GC latency, making Go acceptable for implementing a broad spectrum of systems requiring low response times. Quantitatively this means that for adequately provisioned machines limiting GC latency to less than 10 milliseconds (10ms), with mutator (Go application code) availability of more than 40 ms out of every 50 ms." http://golang.org/s/go14gc
Can someone explain how canonical import paths affect `go get`? &gt; With this in place, the go command will refuse to compile a package that imports github.com/rsc/pdf, ensuring that the code can be moved without breaking users. &gt;The check is at build time, not download time, so if go get fails because of this check, the mis-imported package has been copied to the local machine and should be removed manually. If I'm understanding this correctly, I cannot import packages which define a canonical path under their old path name (github.com/x/y). If I do so, that will be a compilation error... but if someone does a `go get` on my package, won't they be unable to grab the package with a canonical path? Is this a way to update existing packages to say, "Don't import this package anymore, it's now hosted here and you'll get a compile-time error if you try using the stale package"?
That really doesn't work. JSON is fundamentally a hierarchical data structure format and csv is only a single table of rows. Even simple JSON data structures are hilariously badly mapped to csv (and sometimes data is completely missing). If you want to view json in a clearer format, use a json formatter. Personally I use `jq .`, but pretty much everyone has `python -m json.tool` available.
Ah, right - I had the version mixed up.
It works well for the majority of debugging purposes. In more complicated scenarios of JSON to CSV conversion, it groups the data with header rows and sub-header rows (like you would see in a typical report for example). This type of presentation of data can be very useful for manipulation in a spreadsheet. Would you please send us a sample (through the contact box in the website) of a badly mapped CSV as we want to improve the engine as much as possible.
Yeah, implicit interfaces are awesome. However, I think your gist is a complicating things a bit. Person.ScanFrom is not really necessary. I would probably just do it this way: func ScanPerson(s Scanner) (*Person, error) { p := &amp;Person{} err := s.Scan(&amp;p.Id, &amp;p.Name) return p, err } (you could do it this way, and save a line, but I find it harder to understand: func ScanPerson(s Scanner) (*Person, error) { p := &amp;Person{} return p, s.Scan(&amp;p.Id, &amp;p.Name) } 
They could use the intro music for [Google Talks](http://www.youtube.com/user/AtGoogleTalks) or [PyCon](http://www.youtube.com/watch?v=0Ef9GudbxXY). I'm not annoyed by this video in particular but just curious about the culture of the western US (where it seems this type of music is used a lot).
Looks like that is the intent. I will also make it trickier to work with forks. If you fork someone on github you may need to go get their repository to the canonical path and then add your fork as a remote to work on it. That is not what I do now because I like having both versions alongside each other so I can do a/b testing. 
Along that same line, I wonder if anyone that vendors dependencies will also have to go ahead and change/remove the canonical path as part of that process.
Really good question. I godep save -r all my dependencies, and I suspect this will break that terribly.
Congrats on getting into programming and on this project. Unix domain sockets are very fancy for a relative beginner. :) The code is very clear and straightforward. There is one big issue: * Do not take data directly from the network and put them into an `os.Exec` call. This is what you do with `flip`. Go is safer than a lot of languages (like, say, C) but it's still a good idea to sanitize input from the network. Return an error if you get any value for `flip` that isn't known to be valid. And I have a couple minor recommendations: * `cameraStill()` should probably return an `error` and not `log.Fatal`. Basically your program crashes if it encounters any errors taking a picture. Better would be to return a 500 Internal Server Error HTTP response with some information in that case. Alternatively you could just log it and continue on. * Every request that comes in via the HTTP server is handled by a goroutine, and that means that it's possible that multiple requests to take a picture could come in at the same time. Will the external `raspistill` handle this gracefully? If not, you should probably synchronize access somehow -- possibly with another goroutine and a channel. * I would probably rewrite the `if flip != ""` block to avoid repeating command-line args. Something like: args := []string{"-o", "-"} if flip != "" { args = append(args, "-" + flip) } If `flip` has to be before `-o -`: args := []string{"-o", "-"} if flip != "" { args = append([]string{"-" + flip}, args...) } * In unixclient.go, I'm not sure you need `laddr` at all. You could pass `nil` for that instead, I think. (I am not totally sure because I've not done any unix domain socket programming in Go yet.) * Bravo for writing a good README and including a LICENSE file right off the bat. Overall, very nicely done.
Only for packages that set a canonical path, but yes, those should break.
&gt;Android &gt;Go 1.4 can build binaries for ARM processors running the Android operating system. It can also build a .so library that can be loaded by an Android application using the supporting packages in the go.mobile repository. A brief description of the plans for this experimental port are available here. Woohoo! This is what I've been waiting for!
If you vendor your dependencies and your $GOPATH is your vendored directory, then won't things continue to work? The import path would still be 'rsc.io/pdf', even if it's physically located at $PROJECT/_vendor/rsc.io/pdf
http://embd.kidoman.io has a framework for working on the pi.
So 'godep save' will be updated to rewrite the canonical paths, too.
I was considering this too. In my though process, I started making a distinction that a library that provides a callback interface isn't the same as "calls your code" in this context. "A framework calls your code" implies that you're not just providing a function that gets called piecemeal, but rather you have to set up your code in a very specific way, maybe file locations, objects, namespaces, inheritance, interfaces. The framework requires a specific, exposed, largish surface area for it to interface with. If a single callback is a puzzle piece that fits in a specific area, then what a framework requires you to do is build half the puzzle. In some sense, a single callback is still you telling the library what to do. In a lot of cases, a framework is telling you how to arrange your code. A framework requires more discipline in order to avoid running into trouble (which is why I get frustrated with larger frameworks so often: I know what I want to do, and I know how to do it, but something in the goals/design/architecture/implementation of the framework makes it difficult to do).
wow thank you for the very helpful recommendations and your encouragement! Let me look into them and work on improving the code :)
nice!
In all of those cases, t(i) will be parsed as a CallExp. See http://play.golang.org/p/YXh_UwsSho which is an adaptation of the code from http://golang.org/pkg/go/ast/ Your questions about the type are part of semantic evaluation, which would happen after parsing.
There seems to be a big performance regression about 20%~40% on average.
You should make a blog post documenting the process... Will be a nice start point. 
Is it the case that the applications you design can *run* on Android, but right now there's no support for anything that involved the Android user interface? Not enough for an actual app?
Turns out the answer to my question is right [here](https://docs.google.com/document/d/1N3XyVkAP8nmWjASz8L_OjjnjVKxgeVBjIsTr5qIUcA4/edit), under proposal. Looks like there IS support for Android UI through Java + OpenGL
I was under the impression that go is closed to c speed, but according to this website, it is 1/3 of speed of the fastest framework. Any analysis on why?
Would it be possible to spawn a web server on localhost and use it to server the UI of the application using HTML, CSS and so on?
You just gave me a crazy idea for tonight. It should be possible. Start http server and wrap it inside webview on android. Will try :)
I'm an Android-negated (basically I learnt enough java to pass a databases course and forgot afterwards, didn't have an Android device until a month ago either) but would definitely dig this option. Can't wait to have a "portable" version of VanillaSEO (would involve rewriting some parts I'd rather not touch again, but oh well, rewriting happens) or even better, a "local" AlthingiJS with go backend (as I have it on my machine)
Good app :) There are a lot of instances where you are ignoring errors though. You could run https://github.com/kisielk/errcheck to automate error checking. You could also write some code to analyze how much time was spent on each task, if you want to make the app do more. I wrote something along those lines at https://github.com/minhajuddin/timelogger I use it every day, it is more of a time tracking app for me.
15 milliseconds startup time! That's a decade in dog years :)
True; I just took the claim that you can parse Go without a symbol table to mean that the syntax alone is sufficient to disambiguate all semantic constructs and generate the proper AST nodes.
you could also use it to serve html/css/js and have a webview (or the default browser) serve it via localhost.
I like the idea of using an interface but haven't figured out the details. Will keep working on it. Thanks, Jay
Isn't qml also getting an android port? Which would mean I could share backend and ui across platforms &gt;:D
In other posts, there was a lot of discussion about implementing the same kind of functionality with Go as in C. The result would be access to low-level graphics, but restricted (if any) practical access to the android widgets.
I've found myself using Golang as my go-to language for pretty everything these days. Never learnt Java (Linux sysadmin background), so the ability to write and build applications for Android is awesome.
I wouldn't say 0 - I have a Go server I wrote for my job that is using all the cores. However I do agree that allowing fine-grained control is good.
A link to the source would make it easier to help you.
This is exciting!
Yeah, I need to get better at handling errors. Thanks for the input.
Thanks, those are great suggestions.
Why not? Channels are something I would love to use for UI. Go is like the thing for UI, but nobody has built suitable tools yet.
Yes, and having single-threaded async be the default with true parallelism opt-in is a very good decision. Mutexes are relatively expensive, which means that channels are relatively expensive. Go knows this and cheats; when GOMAXPROCS == 1 it doesn't bother to actually lock and unlock mutexes, it just fakes it. This optimization actually makes single-threaded pseudoconcurency faster than real threads in a lot of use cases.
+1 Go can x-compile from anything to anything it supports for a long time now because it has it's own compiler. The requirement to run the compiler on android to build your android app would baffle me.
Well, TIL
Android project with little go package can be found: https://github.com/MarinX/godroid I know that is not well documented. This is just a quick demo with android project and downloadable .apk file to test. I hope it is enough understandable to get started with very basics. It is on my TODO list to write better documentation :)
I tried with several packages. All compiled OK, only with net and sub packages gives me that error. Well, this is still in beta.
Cgo on android isn't supported yet, don't forget the libc implementation on Linux is not the same as android, and that is what cgo interfaces to. In the mean time, disable cgo, but Im surprised you even need too as cgo is _automatically_ disabled when cross compiling anyway.
generics
hahahahahahahaha. I guess somebody had to say it.
Maybe it would help if you say what you feel is currently missing from those solutions.
I would love a collection that could be accessed by index number at something approximating O(1), while also arbitrarily expanding and contracting as needed. Something like a cross between an array and a list.
Being able to write and build Android apps with Go is going to be awesome.
Parsing arbitrary json
It would be awesome if LiteIDE got the [Go Execution Tracer](http://www.reddit.com/r/golang/comments/2ko52p/go_execution_tracer/) integrated into it. The ability to use breakpoints/pause execution and see/alter variables would be awesome too.
 ./root // &lt;- code run here ./root/tpl // &lt;- template ./root/img // &lt;- images under template for example Go code： http.Handle("/img/", http.FileServer(http.Dir("tpl"))) Html code： &lt;img src="/img/bg_company.png”&gt; 
Automated refactorings (rename anything, extract/inline methods and fields and vars and consts, invert conditions)...
 if err != nil { return nil } if err != nil { return nil } if err != nil { return nil } if err != nil { return nil } Probably not something that can be fixed with a package, though.... 
Particularly nested json structures. json["user"].(map[string]interface{})["name"]
copying/moving files, other basic filesystem activities are sometimes obtuse
An XML equivalent of the great 'github.com/tmc/json-to-struct" library would be great. As taking some raw, large data and constructing a set of structs can be so tedious.
&gt; rename anything vim-go has gorename integrated.
SOAP (sad but true. Would make our lives easier)
This could be done with a simple helper library I should think. I may take that on for fun sometime soon. 
I made myself a quick and dirty lib for this that might help: [gabs](https://github.com/Jeffail/gabs)
Thanks :) It works now. I pushed update on github. Http file server on / directory inside webview. amazing :D
&gt; Cgo on android isn't supported yet, don't forget the libc implementation on Linux is not the same as android, and that is what cgo interfaces to. If this is true, then how is the entire `go.mobile` repository working right now? There is plenty of `import "C"` **[in the code](http://code.google.com/p/go/source/browse/app/android.go?repo=mobile#33)**. EDIT: Oh, is the difference that building a `.so` (with the Android NDK) supports CGO, but building a static binary (without the Android NDK) does not?
There are several packages that try to implement generics for go by generating code. Here is one: http://clipperhouse.github.io/gen/
Like the built in hash map? You can use index as the key.
Based on his description I'd say he wants a slice together with append.
Good news!!! thx
EDIT: No, it is not. Also, IIRC for gorilla mux or normal http handlefunc routers, ~~order *is* important~~. So, the first / is shadowing any query for static content in the last handle. I.e. if you handlefunc / to something, anything below that won't be handled.
You [parse arbitrary JSON by unmarshalling it from the `encoding/json` library into a pointer to an `interface{}`](http://play.golang.org/p/xB4RjL584_). If you mean you want to _unmarshal_ it directly into data structures, the problem you encounter is just that there isn't a general way to do that that works on everything. There's a fun project we do at work that isn't for production but involves getting about 10 languages to speak to each other over a very simple JSON-based protocol, and it is amazing the range of "automatic" JSON serialization that languages ship with and all the amazing issues you encounter trying to get any of them to use the same serialization as any other. Go ships with one, there's already a couple projects that do a couple of other things, that's really all you can have. The "fully generic" answer is that you end up just marshaling it yourself out of a generic JSON tree anyhow.
Identifying problematic variables in templates.
The code examples could really use some gofmt love, if not just for indentation.
Oh nice, that would have saved me so much time. Really nice solution, I like it. 
Thanks for mentioning LiteIDE. I installed it last night and got it configured to my liking. After using it this morning to work on an ongoing project, I'd say it is fine right now and **has the potential** to be great. It lives up to its billing as Lite... which is a good thing. At the same time there are a lot of nice features. I truly hope that it doesn't suffer from bloat as seen in Eclipse, Visual Studio and the like. For those asking how an IDE is different from Sublime, Notepad++ and the command line classics, the difference is not so much in what you can do (assuming the right array of plug-ins and a very good memory), but in how you do it. An IDE is ideal for a developer who thinks, learns and works best in visual environment. These developers realize that "point and click" isn't a sign of weakness... it's just their preferred way of getting the job done. For whatever reason a majority of Go adopters so far prefer, and most likely are most productive, in an enhanced command line environment. LiteIDE has the potential to attract those who are more productive in a visual environment. I'm kind of amazed that this is the first I've heard of it. 
Slice expansion is amortised O(1), which for most things is good enough. 
Aside from exceptions, how would check for errors?
&gt; github.com/tmc/json-to-struct Take a look at chidley https://github.com/gnewton/chidley "converts any XML to Go structs" [Author here]
Error checking is certainly needed. I just often find that more than half of my functions are the statement(s) above. It gets a bit tedious to type. I just wish there was a bit more expressive way of handling this.
I have editor snippets to make these take fewer keystrokes.
It's not, if he do accesses like 0, 10, 100, 1000 etc.
[go-simplejson](https://github.com/bitly/go-simplejson)
Is there something in particular that is giving you trouble or you're not sure about?
drone.io is very easy to use
Do you have a data structure in mind that supports these operations with O(1) time complexity? 
thanks for your recommendations again. Just an update, I've incorporated your suggestions and pushed the changes. :)
Certain functions in Revel do perform some magic as well although its magic is somewhat more predictable. Like the controller.Render(args..) call. It knows the action that was called so it makes the assumption that the template will be the named the same as the action and located in directory y.. Also it takes the argument variable names and uses those names to pass into the template. So if you do a controller.Render("foobar") it will fail and only on the execution of the action, but if you did a foobar="ha" controller.Render(foobar) then runtime will be fine. That said, you do not have to use this magic method you can simply use controller.RenderArgs["foobar"]="ha" controller.RenderTemplate("templatepath") for a more clear style.
you could try something like this for a travis.yml: language: go go: - 1.3 install: go get -v github.com/spf13/hugo script: hugo Haven't tested this myself (and I've never used hugo before), but it should build your site and fail if there was an issue building it (assuming hugo errors out on build failures). Hope this helps!
CalDAV
A hashmap, as was suggested earlier. If you also want ordered iteration, you'll probably need something treebased.
I think you need to actually execute the test in the script step. script: hugo &amp;&amp; go test -v ./...
&gt; https://github.com/cloudescape/gowsdl How did I not know about this. Needed something like this and semi-gave up on using a certain api for a side project because I didn't want to deal with SOAP since I already had it implemented easily using a gem in ruby.
I've never used Hugo or Go or TravisCI, so I wasn't sure how to setup the build configuration so TravisCI would deploy the static HTML to a separate branch, so that GitHub Pages would then serve that content. 
You can already run QML apps on android, but from a UX perspective, it's still not great. It'll be more cost effective, but it won't look as good as a native UI. Bundling all the core logic into libraries and having very small but separate UIs for each platform will give you the look and feel of totally native apps at a fraction of the cost.
I guess mostly configuring Travis. How do I tell Travis to take the HTML generated by running Hugo and pushing it back to GitHub?
It's all markdown and html, so there's no code to test.
http://docs.travis-ci.com/user/deployment/custom/ plus http://docs.travis-ci.com/user/encrypting-files/ plus https://developer.github.com/guides/managing-deploy-keys/#deploy-keys
If the complaint was about O(1) amortised growth, hashes have it too to keep the load factor down. Hash vs slice depends on the distribution of keys going in, although I don't think either contract to reduce space when a highly populated collection is reduced down to a few elements.
Thank you for this :-) We use Jenkins at work, and I'm the sort of person that loves automating all my day to day tasks.
 for _, item := range raw.Data.Rates { r.Rate[Currency(item.Currency)] = item.Rate } What happens if raw.Data.Rates contains only a few currencies ? There is no check that all the expected keys in r.Rate will be set. 
I'm well aware of the mantra "composition over inheritance" but what does that mean in practice in Go code? Or rather, since inheritance is impossible in Go, what is "composition" vs. some other non-compositional approach? Is it taking advantage of the implicit satisfying of interfaces? Automatic access to structs embedded in other structs?
I spent some time looking for Twitter (which is mostly OAuth1) and didn't find anything worth go getting.
There are QML and GTK projects available: * https://github.com/go-qml/qml * https://github.com/conformal/gotk3
I think what the author meant is that composition is better than inheritance in general and hence writing in Go (which forces composition due to lack of inheritance) is better compared to writing in languages like C++ or Java, where, while composition is also possible, inheritance is the mindset of most programmers and therefore most code uses inheritance, not composition. 
Let's also not forget that what it means is that your Go code does handle those rare-but-not-impossible errors (like opening a file failing) and takes proper action in the given context and your Python code most likely kills the program due to uncaught exception. Because if you were trying to also take proper action in the given context for every potential error in Python code, you would end up writing even more boiler plate code because try/catch blocks are more verbose than if (err != nil { return err }. 
Yeah definitely true, and the UI should be separated from core logic no matter what.
Thank you, all of this was enlightening.
Totally agree. I was surprised the other day how well my new service handled "too many open files". LoC metrics just always irk me :)
To be honest, I parsed that title absolutely the wrong way.
You're welcome! If you find any bugs, please do report them so that I could fix them as soon as possible.
Of course, We can check it before like: if value, ok := r.Rate[ecbrates.ZAR]; ok { … ok, it works … } I used it before in "Convert" method, but it had not happened many years in the ECB
The cost of failure is a devision by zero error, I think it is worth adding validation to your package. 
The blog author here. You are absolutely spot on :)
gofmt wouldn't let you program in whitespace. Consecutive empty new lines will be compacted when you run gofmt :) I am the blog author. My point was not to encourage measuring productivity by Lines of code. Sorry if it appeared so. My main intention was to express that I felt more productive with Go (than with C) and one of the easiest way to highlight that is by using lines of code per day on an average.
this was fixed thank you
I don't see the fix. You shouldn't use floats when dealing with monetary values at all. `Rate map[Currency]float32` should not be there.
fixed by errors handling of zero values "Rate map[Currency]float32 should not be there." - What should be there?
Relevant SO: http://stackoverflow.com/questions/3730019/why-not-use-double-or-float-to-represent-currency Either use a decimal library or treat them as integers in the smallest fraction.
It will be useful, thanks
I read it as the European Central Bank allowing programmers to exchange services for currency.
On a different note: consider exporting the URL for the API endpoint and/or use https.
Is it meant to list everything? http://lk.dabase.com:3000/o/
Whoops, it shouldn't list everything. I'll fix it.
Ok, it was corrected, but now it less convenient
Good tip. You could simplify the for loop a little by using for range for _ = range time.NewTicker(time.Second * 1).C { fmt.Println("Files available:", config.files) }
You probably should lock the mutex before printing config.files (else you might print a partially initialized Config).
In 1.4 you'll be able to omit "_ =". http://tip.golang.org/doc/go1.4#forrange Also, since you're leaking the ticker, you may as well just use http://golang.org/pkg/time/#Tick directly. 
Looks Amazing! Gonna try it soon
I agree. I really wanted Atom &amp; Go Plus to work, but without gocode I never found it scalable.
For Atom there is: https://atom.io/packages/gocode
You know, I just double checked my setup and I have it installed. Only I feel it does not work as well as LiteIDE. Maybe, I have it misconfigured, or failed at the Readme. Do you use it, does it work well for you?
go-plus author here... it's completely understandable that you want gocode integration (I do too). Unfortunately to get a great user experience, the Atom autocomplete functionality requires a fairly large overhaul (that I haven't undertaken yet).
Performance seems poor. Ran it through: https://github.com/julienschmidt/go-http-routing-benchmark Here's a snapshot on a single benchmark, with Warp compared to the next slowest and the fastest: BenchmarkWarp_GithubAll 100 36289368 ns/op 10665729 B/op 132133 allocs/op BenchmarkPat_GithubAll 500 4380006 ns/op 1540004 B/op 24972 allocs/op BenchmarkHttpRouter_GithubAll 50000 63335 ns/op 14045 B/op 168 allocs/op It's 8x slower than what used to be the slowest, and 573 slower than the fastest! Also, as you can see, it allocates a ton of memory. 
Oh trust me, I appreciate the work that you've done! Thank you. If I am creating a small Go application, just consisting of a single source file, then I always default to Atom and go-plus.
The main advantages are (IMO): * a single static compiled binary vs. scripts and a complex dependency web * Go lets you avoid callback hell by using blocking IO and goroutines * a proper type system and compile time checks let you avoid common JS errors like typos
&gt; In Go, handling any returned data, as well as an error, is second nature. I cannot begin to think of how you could handle this as simply in an exception based workflow. Simple. That would not be an exception. I don't like exceptions as the next guy, but please lets be reasonable. "If all you have is a hammer, everything looks like a nail". When you shuffle all the logic into the errors mechanics just because we can, it just smells. If there is an error/exception is because the state of the program is in an invalid state, at this point any result that you got should be considered invalid. If there is the possibility of a valid result, then that is not an error and just an indication of some kind of internal state of the program. Using the error mechanics to give that internal state is just wrong.
&gt; Sublime Text + GoSublime is pretty wonderful. For code navigation yes, it's awesome...but when it comes to build system and configuration LiteIDE is top at the moment. I love how easy it is to switch build target platform, build, run, install and so on. I tried many times to switch to Sublime but always coming back to LiteIDE..it's that good, and getting better every new release. 
Doesn't NodeJS have many techniques and/or libraries to avoid callback hell? like loopback.io ?
Yeah, declaring it "out of scope for the article" is a bit odd as it seems like it defeats the purpose of showing how to lock/reload-in-place.
**Go:** * Faster than Node on CPU-bound tasks and a smaller memory footprint in almost all cases. * `io.Reader` &amp; friends are much easier to use than Node streams. * Go exposes a large number of problems as compile-time errors, which usually leads to more stable and dependable code. * True paralellism is readily available and uses the same semantics as single-threaded concurrency and async. * Compiled binary reduces deployment to moving a single file **Node:** * NPM is better than `go get`. It has sensible version management out of the box, which allows it to handle edge cases that `go get` just can't. * Async is either opt-out or mandatory in most places, meaning idiomatic Node will probably be faster than unoptimized Go code in IO bound tasks. * JS is a much more flexible language than Go, which when used properly can lead to more expressive code. * An interpreted language with vendored dependencies prevents the source for a deployed application from becoming lost or out of sync. Honestly, they fill pretty similar niches. I personally prefer Go, but I enjoy writing in Node as well when I find reason to. I would recommend trying them both to see which style you like better.
I have use both in 2 different companies. To be honest, not to sound fanboyish, Go pretty much destroys Node in everything that matters to me. 1. Even without doing anything, V8 leaks memory. 2. Any uncaught errors can bring down node daemon. For devops guy like me, that is unacceptable! 3. Coroutine+channel is so much better than callbacks. I recommend using promise style in node to avoid callback soup. 4. When comparing just CPU performance, Go totally dominates node. Memory consumption is far lower too. 5. Single binary deploy is SO NICE! 6. Truthiness problem in JavaScript sucks! Go type system is not perfect but way better in comparison. 7. Node http server throughput is inferior to go http server. I can pretty much go on and on about these two.
What does this add over the Intellij IDEA plugin? https://github.com/go-lang-plugin-org/go-lang-idea-plugin/blob/master/Missing%20ENV.md
Good job! We created [MeetStranger!](http://meet.divblocks.com/) website using Go and WebSockets
Yeah it does. If you take care with how you design things, callback hell can be avoided altogether without bringing in new packages. The problem is that it's hard to know how it will grow. Callback hell is one of those things that "emerges" in a large codebase, as opposed to something that happens overnight. A well designed application can, and generally does, avoid it. That actually brings up another difference though. The communities (which have about as much influence on how I write code as the language itself) are radically different. I love the hacker ethic but most Node packages seem to patch on top of one another into a duct-taped MacGyver-esque tower that barely stands. It WILL work, but after a good amount of hassle. Alot of my day job revolves around that actually. The Go community, though, seems to be very reluctant to endorse anything that isn't idiomatic and working fairly well. The thing about "idiomatic" Go is that once you are used to the language and the Go way, those minimal but well documented/thought-out packages are super flexible and fit into applications in tons of ways. This leads to a strange thing where I write more lines of code and handle more things myself, but actually take less time to implement and maintain overall than a "plug-and-play" Node module. That's because it's way easier for me to figure out a logic/structure problem, than debugging or figuring out someone else's sparsely documented code. Go is significantly less expressive than javascript (imho), and that reflects in the community and the ecosystem. A _very_ overgeneralized and blunt way of stating my opinion on how the languages and communities differ is: if you are having a problem with something like callback hell, a person who gravitates toward Node would say "That happens with this language, here's a package to help you get around that." A gopher would say "You should restructure things to fix that." Both of those can be good to hear, depending on what you are working on. Though Go and Node fit in the same niche, I use (and enjoy) each one for different projects depending on how I envision myself having to rely on the community for the duration of the project.
More or less. Just another dependency.
Definitely a fair response, but let's be honest: with the decentralized `go get` model you don't have problems [like this](http://blog.npmjs.org/post/78085451721/npms-self-signed-certificate-is-no-more) where you break every app in production. Recovering from a blunder like that is [not very easy](http://blog.npmjs.org/post/78165272245/more-help-with-self-signed-cert-in-chain-and-npm).
&gt; If there is the possibility of a valid result, then that is not an error and just an indication of some kind of internal state of the program. Using the error mechanics to give that internal state is just wrong. In that case, according to the author's logic, wouldn't you choose to just `panic`?
Go is a programming language.
It's a nice way to show channels, but I think a *sync.Cond would be a better choice. The use of a chan bool (buffered or not) is always iffy to me. Channels are great for passing around data. Signalling and control flow benefit from simpler tools.
Doesn't he say that in the actual talk? That everything in webdev has a half life of 3 months. Doesn't matter how much you analyze your needs, in a few months there would be a tool to do the same job better. Edit: never mind wrong post. Ignore fist sentence, the rest stands. 
I tried changing the inner loop to: for i:=0; i&lt;size; i++ { instead of having the len(array) in there (in case that was a slow function call for some reason). But no dice... still takes 90 seconds to touch the array a billion times where C++ and Rust can do it in 8 seconds.
I agree decentralized is great, but there's not much excuse for the complete lack of versioning in `go get`. The fact that there's no safe way for a library to make any breaking changes is the one huge head-scratcher in the basic go toolkit design.
Might be helpful to share the C++ as well. Edit: and version of Go
that'll do it.
Even better... jasmuth@boogieman gobench $ time ./gobench First x = 1000, Final x= 1000999 hello, world real 0m2.973s user 0m2.956s sys 0m0.012s jasmuth@boogieman gobench $ time ./cbench First x = 1000, Final x= 1000999 real 0m3.723s user 0m3.704s sys 0m0.008s My C code #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; typedef struct { int x; int y; } A; int main() { A* array = (A*)malloc(sizeof(A)*1000000); int i; for (i=0; i&lt;1000000; i++) { array[i].x = i; array[i].y = i*i; } int r; for (r=0; r&lt;1000; r++) { for (i=0; i&lt;1000000; i++) { array[i].x += 1; array[i].y += 1; } } printf("First x = %d, Final x= %d\n", array[0].x, array[1000000-1].x); } 
Once you've fixed this, you can probably shave off a little more by using an actual array instead of a slice. see http://blog.golang.org/go-slices-usage-and-internals 
That actually takes .2s longer with my code. It's not clear to me why this would be the case, but probably has something to do with stacks and heaps. Still faster than the C version though :)
Something similar here: https://github.com/nsf/pnoise. Benchmark does simple FP math plus array reads/writes. Results for Rust and Go: rustc 0.11.0 === Rust: 0,079199179 seconds time elapsed go version go1.3 linux/amd64 gccgo (GCC) 4.9.1 === Go gc: 0,379534953 seconds time elapsed === Go gccgo -O3: 0,332014892 seconds time elapsed
On my machine (Windows), after making sure it's actually using 1000000 here's my result: C++ (VS 2013)=0.78s , Go 1.3.3 i386=1.64, Go 1.3.3 amd64=2.38 (using int) and 1.35 using int32. Some interesting things, changing from slice to array (var array [1000000]A) my amd64 time goes up to 1.61. Using range instead of normal for loop doesn't seem to make a difference.. I have a feeling that bound check is still there... confirmed, forcing bound checking off got me to 0.91s with amd64 . I will try with gcc and update. EDIT: Tried GCC and Clang and they come up with the same results as VS 2013... I also tried with C# and it performs like Go with no bounds at about 0.92. 
&gt; 000 Oh my.... I am asleep at the switch here. Yes, obviously this was the problem. This takes it down to 8.6 seconds. Sorry to waste time here, folks. Today I get to be that guy...
&gt; Async is either opt-out or mandatory in most places, meaning idiomatic Node will probably be faster than unoptimized Go code in IO bound tasks. I find that hard to believe. The Go runtime will effectively make your program "async" in this performance sense the instant you hit a system call, so there will be no difference. Or have I misunderstood what you were trying to say here?
It is true that "exceptions" being used for perfectly ordinary (non-exceptional) occurrences is using the wrong tool for the job, but I think claiming an error is the wrong tool as well—in the context of malformed input which is actually erroneous, if not exceptional, for example—seems to overstretch the argument. Sure, it's somewhat unfortunate that EOF is indicated with an error despite not really being erroneous, but I don't think multiplexing it onto the error value is *too* great a sin considering that most things that can return EOF might return an error instead.
Or http://gopkg.in
Aren't you comparing 2 different things? Go is a language and Node.js is more of a platform. It would make more sense to do comparison on Javascript vs. Go.... or Node's express vs Go's Martini.
at last in modern C++ you can always employ ' in numbers like 10'000'000 and lower your chances of commiting this mistake ever again. https://en.wikipedia.org/wiki/C%2B%2B14#Digit_separators Available in GCC since 4.9 and Clang since 3.4.
I'm currently using it and it seems to work fine. The only thing I did was: "go get gocode" and set the gocode:toggle keybinding in keymap.cson as in the README
Just wanted to say thank you. go-plus is awesome
Thanks @karlseguin, experimenting with performance is definitely next on my agenda when I get a chance. Probably starting by swapping the naive hashmap for a trie. Anyway, thanks for the feedback. So far, warp has been to address my gripes about the interfaces other routers provide, their handling of edge cases in ways that don't match the standard lib (that's why warp passes the http.ServeMux tests), or only allowing ascii patterns.
If I'm not mistaken loopback.io is a scaffolder not a control flow library.
No. Panic should be used when the error is unrecoverable.
But I agree that malformed input is an error and should be indicated as such. In that case, the result of your function would be meaningless (because the input is malformed), you cannot trust on it's value. That is my issue of overusing the error mechanic, when you get errors and at the same time valid results. In those cases you have to know all the *type* of errors that the function returns because some of those aren't actually errors and you can use the result. It's not future proof. Using the EOF as an example, imagine if at Go 1.0 it didn't trigger an error. n, err := r.Read(buf) result = append(result, buf[:n]...) if err != nil { return nil, err } Then at 1.1 they introduced as is now. All the functions that use it, now have a bug, because they would be discarding valid input. You had to go each function and handle that case manually. Having said that. Yes, I also don't think is a too great sin. But I also don't see great value in using it.
If this was your intention, then I totally agree. I feel more productive writing go than any other language, even if I need to repeatedly write some boilerplate to chug along. Maybe it is because in other languages I skip the error checking and the cognitive weight makes me go slower (or realise I need to go back) but indeed, go feels "faster."
Notrivial : http://play.golang.org/p/rzlOYSN1gE But then you introduce callbacks again. You could introduce promises and the like, which is a good way but not idiomatic to go. Also how do you know the extra work node is computing (if any) is actually useful?
&gt; Simple. That would not be an exception. I don't like exceptions as the next guy, but please lets be reasonable. You didn't actually answer the question. If you have to return some valid data *and* an error, what do you do in a language with exceptions?
My point is that, in my opinion, there isn't such thing as valid data and an error.
Go is also a runtime which is what Node.js could be described as.
In Go I'd write it 1e6.
But it's right there in the post! if err == io.EOF This means that there has been an error, but that the data is still valid.
Has anyone used this IDE with appengine? Edit: The reason I ask, appengine seeks only to subvert gocode.
You're getting too distracted by the term "Error". Error doesn't mean anything. It's just a signal. EOF signals the end of the file. Another error signals the file isn't there, etc. This is part of the problem with exceptions - people get too focused on what's an "error" and what's not. The point is, in a language with exceptions, how do you signal that the data is valid, but something also went wrong... like, here's the first half of the file, but then the network disconnected? In exception-oriented languages, you have to bend over backwards to produce a function signature that can handle this... and it requires that you handle *both* exceptions (for true "errors"), *and* an alternate channel that signals that something went wrong, but you still get some data back.
This kind of an answer is not really helpful. We all know what he means. Go vs. Node is shorthand for "Go using some web framework (I don't care which one) vs Javascript using Node.js"
Why would reaching the EOF be an error? You should expect it, can handle it, and your data is still valid. This is not an exceptional case and is just normal flow when reading files. 
It's not an error. The file not being there isn't an error either. The network disconnecting in the middle isn't an error either. They're signals. Don't let the name "error" fool you. It's just a value.
What does "expressive" even mean? (like, I know the definition, but I don't understand why people say one language is more expressive than another.... verbosity, sure, that's something I can define and understand)
In a language like Python, which is very much "exceptions based", you could attach additional data to exceptions: raise MyException('Message', additional_data={'thing': 5}) We use this when the exception type isn't enough as you need to provide additional context (for logging, etc) from further down in the stack.
EOF is not an error. If the length of data returned by read is less than requested then the end of stream/file is reached. There is no error there. And Go actually uses state rather than error in "reflect" package, for instance, func (v Value) Recv() (x Value, ok bool) 
If you're familiar in other languages, I coded up github.com/btracey/mpi It doesn't pass goroutines around, but it does help with cluster computation. You should fork it if you're going to use it. 
open source? 
This would do the trick for you: http://nats.io/ You may pass a struct that the client library will serialize for you. Or you could use "encoding/gob" if you want to send binary data to be processed. Keep in mind Go routines themselves don't message between processes but all within the same process/memory, unlike Erlang with the OTP that will handle message passing between actors on a network. In the case of Go, you do this with message queues and the like.
Since you're processing a stream, and you encounter an error at a certain point in the stream, what you've handled so far *isn't* malformed, whether the error is a false error like EOF or a true one. In this case it makes perfect sense to have both a valid result and an error, since everything preceding the error is valid. Certainly, if you change the contract of the function, then code using it will be incorrect, but that doesn't mean that one or the other of those contracts is inherently wrong.
Point and click is inefficient and wasteful and can contribute to RSI. I'm a visual learner and point and click has nothing to do with it. Man up and learn a real editor. 
you really should run your go program on top of a distributed resource manager, like Hadoop or Mesos. it's not just sticking the thing elsewhere, you need to figure out the least loaded node, you need to track its state, restart if it fails, collate the results once done, etc. you are better off leveraging a sophisticated framework that's already built, rather than rolling your own.
RPC, gob are your friend. Natsd, written in go, is also worth pursuing. 
Demo is back at: http://lk.dabase.com:3000/
Yeah, I did similar stuff in C# (which is similarly exception heavy), but that's usually reserved for information about the error itself (like, the filename that was missing). I've never seen anyone actually return data using an exception (though I wouldn't put it past people). It would look really bizarre to have something like try: data = ReadFile(foo) except TruncatedRead, e: data = e.data 
this is fucking legit. so exciting!
&gt; Since you're processing a stream, and you encounter an error at a certain point in the stream, what you've handled so far isn't malformed, Part of a value, is not a valid value.
Thanks for this. I am already using JSON to store my config which was being decoded during initialization, but I had been wondering how to achieve hot reloading. Now, if my app is running as a service, it's as simple as `service serv-name reload`
Except that we have a recover statement. I don't panic except in init functions, unless I have a recover that can turn the error into a value or other useful state. 
That's the point; it isn't part of a value, it's a *stream* of values. The ones that have already been processed are perfectly valid. Whether and to what extent the values processed thus far are useful after an error has been encountered depends on the context and the error.
If those values were already processed, there was no error. What's the point? Take consideration that in the OP example, if case of error it was putting the result to nil. I assumed that the value was all the data from the reader.
I would really appreciate a few comments on the code, for example: "wg := &amp;sync.WaitGroup{}", why the "&amp;" usage? Also, "defer t.Fill().Drain()" what is the mechanism that causes the deference to throttle the "work code", if its CPU heavy tasks then the throttling presumably does very little so the use is, I guess, network only? And if yes.. specifically why is this the case? Simply to allow other requests? (excuse me if all of this is terribly obvious, for me its not as you can tell!)
Instead of using callbacks I think it would be better to launch goroutines and then using select to process the results.
Can't you send the source code for the task (using any means from SMB, RabbitMQ, RPC, whatever), and have the remote computers compile and run the task, and send back the resulting output?
Thanks. Much appreciated. 
Have had tremendous success with ZeroMQ (not with go, but in this sort of application). It's very fast, virtually trouble-free, and acts like a socket on steroids - there's no separate message broker entity, just some libraries. Go bindings are available.
Of course, I was trying to compare apples + apples :)
Indeed.
Having said that, a rest API, possibly with a shared file system, might be simpler to do.
I am writing a tool to automatically add / strip error handling to a go file https://github.com/goerr/goerr
The entire condition system could be replicated by hand by passing in function pointers, flags, etc, but that's rather cumbersome to pass through multiple layers. Unhandled conditions do still propagate (assuming they're errors and not just warnings or errors that have a continue restart built in if it's not handled) so still can work like exceptions in other languages, and there's even a mechanism that works like try/except. Dealing with the error locally though is what conditions give you over exceptions...higher level knowledge of what to do, and lower level knowledge of how to do it. Functions not involved in the call stack, to my knowledge at least, don't have feedback into how to handle errors, but it allows a top level function to tell the lower level function what it wants it to do, which in my mind is ideal in most cases. I'm sure it does have its own class of issues (I'm a professional python programmer, so don't work in lisp every day), but it does seem to give you the best of both worlds of error returns and exceptions. Other than that, I largely agree with the article. Return codes are a much nicer way of dealing with errors than exceptions most of the time.
This was my initial thought.
I think RPC are cool but it kinda feels like you are starting from square one. I was thinking something like celery + MQ like in python. 
Right, something like this would probably be the idiomatic approach: http://play.golang.org/p/JYqR1l4_3m In either case it's fairly simple to implement, but are you really going to go to the trouble for every single blocking call, no matter how small? &gt; Also how do you know the extra work node is computing (if any) is actually useful? Because Node's stdlib forces you to use concurrency patterns in a lot of places where Go's doesn't, so the odds that there happens to be some thread of execution which can pick up while you wait are much higher.
They're not open source. But we leverage their IronMQ and IronWorker in many different locations and they have a free plan no credit card required. EDIT: that said. All they really are is a scheduler written in Go that runs Docker containers for every task. You could roll your own "easily". 
https://github.com/docker/libchan 
That last part, how is it inferior?
Just go through every single section here: http://www.techempower.com/benchmarks/
It was not about the amortization. It was a request (I think) to have a sparse array where you can write at any (say) integer position. Similar to php. If you do this with a standard slice, you are going to use 2^31 words of memory no matter the number of elements you keep.
&gt; You're getting too distracted by the term "Error". Error doesn't mean anything. Of course it means something. It's a logical concept used by programmers to signal that the operation is not permitted in the actual state of the program, or for some reason it got into an invalid state. If Error means nothing then it's purpose is meaningless, it would have the same value as whitespace in code (except Python and the likes). &gt; This is part of the problem with exceptions Exceptions are irrelevant, it doesn't matter what is the error mechanic in use. If the error mechanic is exceptions, it only makes it worse. &gt; here's the first half of the file, but then the network disconnected? What I'm going to do with half file? It's garbage. The programmer has to handle that case, maybe try got get the file again. Or the API can have some sort of logic to resume to get the file, continue where it stopped. In this case, this internal state should not be exposed to the consumer of the API, it should only give an error, and the API would have the concept of retry and continue where it failed. &gt; and it requires that you handle both exceptions (for true "errors"), and an alternate channel that signals that something went wrong, but you still get some data back. Exactly. What I'm saying is to use the error mechanic only for the true "errors" (it's irrelevant if it's exceptions or not). The alternate channel it should be something obvious that API provides, it shouldn't use the error mechanic. If there is a case of getting an error and valid data then that is a bad designed API.
But, wouldn't that mean you'd have to load a new binary on each computer in the cluster every time you wanted to compute something new?
I agree, the original poster probably wants a hash. However, it's not clear if they didn't know hashes existed, or if hashes had some property that was undesirable. For example, lack of in-order key traversal that you would get with an array or a list (or a tree ..) but would require extracting or maintaining a sorted list of keys otherwise.
FYI, this is more a demonstration. Not tested well enough for usage in anything serious. I built it for a part of another side project I'm working on.
Because the error is due to a value that *wasn't* successfully processed and which doesn't appear in the result of the function. In the particular case of the ReadAll function, yes, if you can't successfully read *all* then you can't return a result, so it's nil. However, that's because it's deliberately turning the stream into a single chunk which is incomplete if there's an error. If you're actually processing the data as a stream, then you'll actually be doing something with the data that comes before the error.
Thanks for putting this together. To save the folks at home time, here is a link to the playground. http://play.golang.org/p/gciDdjSJVH
With the standard http.Handle/http.HandleFunc, the order isn't important.
Can you clarify how it's supposed to be used. if there's a top story with the word Tinder in the title, should it be returned if I run 'whatabout Tinder'? In the usage section of Github, it says whatabout &lt;keyword&gt; [&lt;flags&gt;] but what did you mean by &lt;keyword&gt;? for example, at the time i wrote this comment, there happened to be a top story with the word Tinder in the title, but when I ran whatabout Tinder it said No matches found for tinder
Apparently you think and work best in a non-visual environment... to wit Vim/Emacs. Likely you have a very good memory for detail and have developed excellent muscle memory. Good for you. It is worth noting that LiteIDE includes a **real editor** along with many other tools that make development more efficient for those of us without your special skills. It almost sounds as if you're trying to discourage competition. No need to worry. The way demand for Go developers growing, there should be plenty of work to go around. 
Ok, I tried adding -O2 to the gcc line, and that version runs in about 1/4 the time.
A few weeks ago, in an effort to "get the hang of it" I spent a few days using Vim with the go-vim plug-in set. I was never comfortable, never efficient and never came close to learning even the relatively common key combinations. Different strokes my man. 
ah yeah, C, C++ and who knows what can use that too.
In the playground version, to see what would be logged to "app.log", remove the line that defines out and replace "out" with os.Stdout in the call to log.New.
&gt; func main() { tempFile := makeTempFile() defer tempFile.Close() defer os.Remove(tempFile.Name()) ... from [Effective Go](https://golang.org/doc/effective_go.html) , We know deferred functions are executed in LIFO order . so maybe wo should exchange the order of these two lines?
You're right, I fixed that.
A few days isn't long enough to learn vim. It has such depth that you can learn it for years. 
Not discourage competition. I just think any serious coder owes it to themselves to learn vim or emacs. 
Then I think we are in agreement. My only concern is that there isn't valid data and error at the same time. Let's say... If the function would be readLine, then each line of the stream would be valid data. If the next call would give an error, then only in that call, the data would be invalid because there was an error.
&gt;func (this *MainController) Get() { Please get rid of `this`. The beego team have done a great job at creating a full stack Go framework, but `this` is something that's bothering me. If beego becomes popular, people will start to thing that this is idiomatic, and it is clearly not. `this` is not informative. `this` doesn't tell me what `this` is. If I'm working inside a method, and someone have interrupted me, I don't want to scroll back to remind me what `this` I am working on now. Something like `ctr` or `cr` for controllers is much better.
I agree. It does a pretty good job of treating Go like Go (unlike, say, Martini, that seems to want to pretend to be Ruby) but there are a few sore thumbs sticking out.
I am not sure I would ever use an IoC container in a Go web app. I have complete control over the request pipeline when chaining handlers together so dependency lifecycle isn't too difficult to handle. I am curious about the issues you have faced though, so I can better understand your reason for wanting to use one. Also, your example is closer to Service Location than much else. I would be interested to see your approach once its completed.
Please don't do that. Please.
Thanks for you suggestion. I will change the this
On the other hand if it's `func (T) Read(p []byte) (n int, err error)`, then it could return `n &gt; 0` and `err != nil`, since it could process `n` bytes before encountering an error. Or if you had `func (T) ReadTokens(p []Token) (n int, err error)`, the same situation could play out, where the method might not process a given token completely before encountering an error, but all the tokens before that one are complete and thus can be returned.
https://github.com/beego/bee/commit/976602bc019593a46c54010d69e15b90f73ef263 I change this to c or the first letter of the controller. Sublime has the autocomplete suggest use the short name.
Nice! I'd use `ctr` for controllers and `rtr` for routers, but this is fine too. I hope the doc update is coming soon.
I think your choices are sqlite or firebird. Both have supported drivers, and can run embedded or stand alone. I would use sqlite myself.
&gt;that would allow you to register a custom http context (per http request) and use that Both Gorilla context and Google context are already per request. I'm not sure what advantages yours would bring. http://www.gorillatoolkit.org/pkg/context &gt; Package context stores values shared during a request lifetime. &gt; For example, a router can set variables extracted from the URL and later application handlers can access those values, or it can be used to store sessions values to be saved at the end of a request. There are several others common uses. https://blog.golang.org/context &gt;At Google, we developed a context package that makes it easy to pass request-scoped values, cancelation signals, and deadlines across API boundaries to all the goroutines involved in handling a request [Martini++ as a framework already exists. It is called Negroni](http://blog.codegangsta.io/blog/2014/05/19/my-thoughts-on-martini/) Sorry if I'm raining on your parade. It would just suck if you spent a lot of time going do the wrong path and had to backtrack.
Is there a way to redirect all subsequent writes to the default logger to a file? That way any dependency I use doesn't need to be passed newLog; they can just use `log.Println` and it will show up in the log file?
I will update the docs ASAP.
I interested only in native (Go) solutions. Wrapped libs not for this situation.
Bolt is an embedded, pure Go database that has received great care and is used in prod in multiple places. https://github.com/boltdb/bolt
Why do people keep using Go for realtime applications like that? I mean it's a GCed language for one and 2 its GC is pretty crude. What is the point in this ?
 - You don't need `goop` to fetch dependencies. `go get ./...` does that. - Don't use relative imports. - Don't put your tests in a separate package. - If you want to use a tool, I'd recommend something like `godep` which is more widely used. Those aren't really good advices for Go. Go, and developing in Go, isn't like developing in Ruby. Trying to bend the standard structure of Go to match prior knowledge will only lead to pain and confusion.
I've used MySQL and Redis. Both are fine and for you I recommend MySQL.
goerr under developement here https://github.com/goerr/goerr/wiki/Getting-started
&gt; What I'm going to do with half file? It's garbage. You're going to retry the download and not have to re-download the 1.5GB you already downloaded. &gt;the API can have some sort of logic to resume to get the file, continue where it stopped. What if that *is* the code you're writing? &gt; If there is a case of getting an error and valid data then that is a bad designed API. I disagree. See io.Reader's docs: When Read encounters an error or end-of-file condition after successfully reading n &gt; 0 bytes, it returns the number of bytes read. It may return the (non-nil) error from the same call ... 
+1, what AYBABTME said. Don't use goop. If you're just starting out, just use go get. Get used to the language before you dive into dependency management. You only really need dependency management for professional projects, and when you do, use godep. It's the defacto standard for anyone who has been using Go for a long time. Oh yeah, and don't use relative imports. Use absolute imports... even if you haven't pushed your code up to a vcs yet, you can still store it in the directory where it *will* go in a VCS (for example, if I was starting a project called foo, I'd put it in github.com/natefinch/foo, even if that doesn't exist on github yet).
MySQL and Redis aren't embedded databases.
Is there a reason why Goop is inherently bad? Also I get why conceptually absolute imports are better than relative imports. Is there a practical reason why you wouldn't want to use relative imports? Sorry if this post came off as me giving advice :) This was more for experimentation and exploration than anything. I am new to the language and I've seen how most of the community structures projects and wanted to see if there was a better way. Am just trying to better understand why some of these decisions are poor.
I am planning to write a blog post about my experiences of using Go (aptly named Go Vertigo) the past 1+ year. After writing the proposal of possible ways to solve the gripes I have with Go, I thought that I might as well prototype the proposal and then publish the blog post. I'll be publishing the blog post here and on HN once I'm satisfied with the proposed prototype. 
_vec_'s arguments are very insteresting but I would disagree with the one about NPM. NPM is the very reason I don't use node because if your dependencies have common dependencies, those won't be shared. It means you could get that native library compiled 10 times. I admit I didn't try this in a while, so maybe this issue has been fixed. I really love the why go is putting all the code in the gocode directory, and even reuse the same library checkout for all your projects. Maybe it's just a matter of taste ;-)
There is also an embedded graph database. You can choose the backend and boltdb is one of the supported ones: https://github.com/google/cayley
Go noob here. His article made sense to me, but is godoc really a command? I see the documentation site, and I see the GoDoc github repo, but that command won't run for me. Do I need to 'go get' it? 
Thanks for the links and constructive feedback. The aforementioned IOC container is part of a proposal I am writing on possible ways to solve the gripes I have with Go's ecosystem. The reason why I am considering using an IOC container is because Go doesn't have generics (yet); where under some circumstances that would have been sufficient. &gt; In software engineering, inversion of control (IoC) describes a design in which custom-written portions of a computer program receive the flow of control from a generic, reusable library. A software architecture with this design inverts control as compared to traditional procedural programming: in traditional programming, the custom code that expresses the purpose of the program calls into reusable libraries to take care of generic tasks, but with inversion of control, it is the reusable code that calls into the custom, or task-specific, code. A gripe I have with Go repositories is that idiomatic Go is thought of to be short, simple and solves a specific problem. This mindset has heralded the rise of many repositories (some great) that are inflexible as they were not/cannot be written to be extended without copying the source (and losing the benefit of updates) or writing adapters for (anti-corruption) interfaces (which is useful for large projects, but not always for prototyping). I think Gorilla Context is a useful solution, but I dislike the (per request) contention on a global mutex. Despite that, I don't consider type casting all over the place an elegant solution (see the GetMyKey example (here)[http://www.gorillatoolkit.org/pkg/context] workaround). I believe in Scala's philosophy that it should be up to the developer to decide what's useful and what they want to use, instead of having a specific approach forced on them. Well defined behavior is the cornerstone of high productivity frameworks. Why use: func(w http.ResponseWriter, r *http.Request) { query := r.URL.Query() var queryParam int if p := query.Get("queryParam"); v, err := strconv.Atoi(p); err != nil { queryParam = v } } instead of func(queryParam int) {} if you can depend on well known behavior? 
You can spawn your own local go documentation server by running. You'll find it in your `go/bin` directory godoc -http=:6060
If you have Go, you have `godoc`. `go`, `godoc` and `gofmt` are in the same folder.
http://golang.org/pkg/log/#SetOutput I'd provide examples, but I'm on my phone. My applications typically log via logrus and lumberjack (to handle file rotation) if stdout isn't the right option. Keeps things nice and self contained. 
Yes, the channel implementation looks much cleaner. I wrote a simple throttler using this the other day http://code.websrvr.in/2014/11/04/simple-function-throttler-in-golang/ . However, what do you think are the benefits of using sync.Cond if any?
Diversity in dependency management solutions means more headaches with trying to figure out how to work with each one.... and most of them are not significantly different than godep, which is the defacto standard (i.e., if you're going to propose your own, you should explain why and how it's significantly better than godep). I haven't looked too carefully at how exactly goop does stuff, but it seems like many of the other version pinning tools out there where it just stuffs the revisions in a file. One thing I noticed with a quick look at the code is that it is not likely to work on windows (it uses some os calls that aren't implemented on windows), and there's basically ZERO comments on the code, which doesn't exactly instill confidence in the quality of the code. Relative imports means your code can't be used with go get, which means it's basically unusable for anyone but you. Go get tries to convert your import path into something it can download using a VCS... and it can't do that for relative import paths. Sorry if anything I wrote sounded unfriendly... totally not intended that way. Everyone was new to the language at some point. :) Welcome to Go, I think you'll like it here.
When in Paris, you speak French. When in Beijing, you speak mandarin. When learning Go, its probably better to learn Go idioms and best practices instead of shoe horning prior knowledge.
Most talks I'd rather see a transcript, but he talks fast enough with enough information density that I didn't feel the need in this talk.
The margin seems so little
Yes, I believe this will work. appLog, err := os.Create("app.log") if err != nil { log.Panicln("Error Creating appLog", err.Error()) } log.SetOutput(appLog)
Sure. it's nonsense thinking in consuming byte per byte. What I'm saying is, in the batch that provoked the error for those bytes to be discarded. In case there is interest to also provide the bytes with the error, then that info should be provided by the error itself. It's more clean to logically think there is valid data or there is an error. Of course, in case of error, the error itself can provide extra info, whatever that is. And the most important part, there is no risk that one extra data from one error kind to be confused with extra data with other type of error kind (in your example, those bytes). You already have to handle the error, there is no cost of instead to having to use the normal result to use the corresponding field in the error message.
please note, godeps is one thing, godep is another.
Unless you are reading the 1.5GB in one go, which is wrong. What is the problem? If you are coding it, you will call multiple times a read function using, maybe, 16KB blocks. The call that triggers the error (eg. closed connection) then you only have start again in that block. &gt; See io.Reader's docs Why? Just because it's the official API it means that is perfect?
sync.Cond is more flexible. Channels bind together sending and receiving, or specify a single number that is the number of items that can be in the channel. sync.Cond allows you to have arbitrarily complicated conditions. On the downside, sync.Cond can't participate in a switch statement. If you _can_ do it with a channel, you probably should. But if you encounter any times that you can't, you may need a sync.Cond. It's a power tool, with the usual caveats that comes with.
Wow this is my exact situation. C#/.NET at work - Go at home/on the side. I have tried and tried and tried to convince my colleagues to look at Go - so much resistance :(
+1 for goleveldb, it works pretty well.
Which problems do you have with ql, specifically? If you can fulfill all your query-needs with it's driver for the database/sql package you don't have to deal with its internal API at all.
I just get made fun of. But when they need a quick solution that's not part of our core (i.e. Monolithic) application who do they come to? :)
What's the difference?
If you install Go with brew, yeah, you have to go get it.
If `GOPATH` and `GOBIN` are set to somewhere that you have permissions to write to, you wont run into those permissions problems. If you prefer using your distro's package manager for that sort of thing, by all means do so.
Those distros need to sort their shit out. That's an egregious omission.
&gt; Martini++ as a framework already exists. It is called Negroni It's rather Martini--. Minus dependency injection, minus routing...
Looks like a useful tool, if it didn't consume 80-100% CPU when idle. Do you have a tight loop doing something?
Without file container there will be no easy solution. For such issue You better consider usage of some external services like redis or memcached. I've been using bolt db for some time already and can say that it has some issues. Pretty strange and verbose syntax for transactions, its not memory friendly at all, creating new read buffer for each transaction. Also it has some issues with database memory consumption - I had db with only 2k json dumped objects which took ~1Gb disk space and was almost unusable within application because of each db operation took enormous CPU time (I've created issue about that). After that i switched to go-leveldb, yes, its written in C++ with bindings to go. But its much easier to use and much, much faster than boltdb. It has more maintainers and much more mature product. And most important for me - there are no such memory issues.
Congrats!
I believe this relates specifically to the tooling around Go. Much of the older tools were originally part of the standard library/distribution. This became unmanageable and it was all moved to a separate repository. I'm guessing that this move happened rather hastily without giving it much thought. The choice to name them all as some variant of `go.xxx` is not particularly idiomatic for Go import paths and, now that this repository is becoming large and more prominent, is coming back to bite them in the ass. In effect, this second move is just another round of polishing to bring up the quality and consistency of Go as a whole. That's just my interpretation of it though. I may be entirely wrong.
feels monolithic, non-reusable and done only to get those support contracts could be wrong, just read some of the api documentation
I'm not sure I understand what naming issue the OP is referring to... But I wouldn't say much of the older tools were in the stdlib's repo. IIRC only godoc (and govet?) were. All the others and the packages (go.exp, etc.) were split off for Go 1.0. For the packages, I believe the main reason was because of the compatibility promise https://golang.org/doc/go1compat and many/most of the tools didn't exist at the time, so they were never a part of it. As to the `go.*` naming. I don't think there was a decision to name them that way, it's most likely just a side-effect Google Code's/Mercurial's sub-repositories http://mercurial.selenic.com/wiki/Subrepository
Hi there. Yes, I'm afraid I can find the reason :O I'll fix it asap. Thanks for the report!
&gt; feels monolithic, non-reusable i feel the same. a project like this needs a page about how it compares to other such frameworks like revel or beego.
This is why I don't like using URLs for imports...
I am just not sure if its worth it, usually languages have a certain domain where they are the most useful. I definitely think that this is far off GO's domain.
Things were moved out of the standard repository into sub repos to remove them from the Go1 compatibility guarantee. The "go.xxx' is how subreposities on Google Code are specified.
My bad. For that I've used LevelDB and Sqlite. While I really prefer LevelDB, Sqlite is about the only option if you must have SQL.
This is why any serious project needs _some_ form of vendoring, ideally one that could deal with this without requiring any code changes. Not because this is a first-class use case of the vendoring, but because you ought to get this feature "for free" with the tools any solution ought to offer you.
The announcement letter in golang-nuts says that the framework has been under construction for about 2 years internally, so that might explain a few things... it was already being developed as Martini came out and the web framework revolution flourished and fizzled. By then it was probably too late to change design goals relative to what the Go community had learned about idiomatic code.
Were all the talks at dotGo this short, or are they just uploading the short ones first?
I was recently reading the spanner and F1 papers from Google and thinking that implementing something similar would be a perfect use-case for Go. And I was also looking at FoundationDB, and trying to figure out the business case for using something like that instead. FDB is closed source, free for 6 nodes, and very expensive for more than that. And it turns out these guys were thinking the same thing. How marvelous! I'll be trying it out this week.
The all were this short.
Be that as it may, you can expect people to ask this question a lot especially since several popular distros (fedora, debian, ubuntu and others) omit `godoc`.
I have already felt pain that relying on `go get` brings. I don't see why anyone thinks that using a tool the guarantees a build is unreproducible is a good idea. Every single clone of a repo will have a different hash of deps used to build it, and rebuilding an old tag/release will not pull in the versions of those deps that were used at the time. Godep/goop seem to solve this, and using them really should be the more preferable option vs. relying on the go tool.
great feedback, thanks! that's actually our goal, from speaker briefings to video post-production :)
yes we only do TED-style 18 minutes talks, for several reasons: * keeping the audience focused in the theater * making the videos more watchable online * having a decent number of speakers (we're single-track, single-day) * avoiding "bloat" in talks where speakers feel compelled to fill with less interesting content, just to reach 30/45min. If you look on our channel there are also 4-minutes lightning talks :)
While I agree generally, it doesn't look great on mobile. 
Sure but I just cant get the point, the same way for example im missing the point in stuff like server side javascript - node.js
I totally agree. An HTML file instead of TXT one with maybe a few tags like h1, h2, a, p, and stuff like that would be perfect! For example, it would be nice to be able to click on the Twitter link at the end.
This seems like the select 'guts' are leaking out? Could the select logic be put into the get function with added function parameters for plugging in to the right spots in the select portion? Not sure what would be best to return from get at that point though. I seem to see this pattern advocated a lot. But is it not abstracted up a level somewhere in the stdlib so it is less trouble and gets used more often?
I would prefer unrendered, pure Markdown ('pure' as in no embedded HTML) rendered appropriately by the client. I don't really care if it's Markdown or reStructuredText or something similar, as long as embedded HTML and any kind of styling and scripting is forbidden and I never have to write `&lt;p&gt;` ever again (why can't HTML infer `&lt;p&gt;` anyway?!).
Have you looked at the built-in models (rgbaModel, grayModel etc.) in color.go itself? Seems quite straightforward.
No, unfortunately this is as abstracted as you can get it in Go and still have it serve its purpose. The way it's written now `get` will return immediately. The program will still block to wait for the HTTP request to be completed, but it won't do so until it reaches the select. That gives you a chance to do something after the request is made but before it returns.
Here is how I manage my vendoring, I'd appreciate any feedback.. I fork all packages I need into my own github repos and import those paths. Within my local git repo, I add an "author" remote as well as origin so that I can branch and update the repo from the source project, and choose to upgrade my project with the latest code by merging it to my forked repo. Yes, it's a bit more manual work upfront, but I don't have to make any of the changes that this import path update is requiring others to make. Does anyone have thoughts or concerns about my approach? Would appreciate knowing your method as well. 
I started drooling when I turned my phone to landscape and the text width adjusted correctly. How hard can that possibly be?
Yay, validation! I don't have any experience with P2P networking, so it's definitely a lot of fun working out the details. I went with Wendy mainly because it implements the Pastry DHT, which can use a proximity metric for routing. Code-wise it's pretty simple and it should be easy enough to extend, and the specific implementation is abstracted away from the user anyhow. Plus there doesn't seem to be all that many Go DHT packages to begin with; I mainly found Kademlia implementations geared towards Bittorrent
[Motherfucking Website](http://www.motherfuckingwebsite.com)
After you cram all of the buzzword functionality jammed down your throat by the sales and marketing team that they promised to their clients it's incredibly complex.
In light of the recent controversy with Markdown standards, "rendered appropriately" is so ill defined that I would rather stay with HTML.
Excellent, hopefully people inside Apple will be able to get [this bug fixed](http://research.swtch.com/macpprof).
A browser *ought* to assume that it can't just stick arbitrary line breaks into a plain text file. It would be a lot more reader-friendly to publish inside a very simple HTML file.
In theory anyway, in practice we just mashed everything together with tables and in-lined styles. 
Yes, and some people also format word documents using spaces, tabs and line breaks. Are they made for that, though?
&gt; But when I need to do something long and structured, to word I go. A system overview or TDO? Yea better get some formatting. Or use org-mode. Just because it's plain text doesn't mean that it can't be manipulated in structured ways. Or be exported to other formats if those are more readable/someone else wants another format.
I had to look up org-mode. I will stop here to avoid an emacs / vim debate :)
&gt;What I'm saying is, in the batch that provoked the error for those bytes to be discarded. Why? Those bytes have no more to do with the error than the bytes in the previous batches do. I can no rational reason to discard them. &gt;It's more clean to logically think there is valid data or there is an error. But that supposition doesn't match this case. You're dealing with a *stream* of valid values that are potentially *followed* by an error. There is no natural mutual exclusion between them. You're introducing it artificially in order to fit a square peg into a round hole. &gt;And the most important part, there is no risk that one extra data from one error kind to be confused with extra data with other type of error kind (in your example, those bytes). The bytes are in no way connected to the error. They *precede* the error. The nature of the bytes is completely unaffected by the nature of the error that follows them. They don't mean anything different just because whatever followed them produced an error, any more than the bytes in the previous batches do. 
It's probably related to this job at Apple: http://www.golangprojects.com/golang-go-job-in-Senior-CDN-DevOps-Software-Engineer-Santa-Clara-Valley-Apple.html 
Meh on ORMs in general. 
Thanks. I guess I'm making it more complicated than it should be. 
 &lt;!-- yes, I know...wanna fight about it? --&gt; &lt;script&gt; (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-45956659-1', 'motherfuckingwebsite.com'); ga('send', 'pageview'); &lt;/script&gt; 
How would you create a system with the switchable database backends without using ORMs? Would you rather maintain a bunch of queries in all the SQL dialects?
I was trying to reference [this.](http://xkcd.com/224/) And yes, line breaks, htabs and vtabs were made for formatting. Also, yuk, word.
If I'm understanding you, I think our disagreement is only on the fact that I consider that in case of error there is no such thing as valid value at the same time. So answer my question. With the function readLine func ReadLine(reader io.Reader) (string, error) What would be the result when processing the reader you get an error before encountering the end of a line?
The negatives in this video don't seem to have anything to do with Go. How do I trace through multiple processes in any other language? Concurrent logging is illegible in any language. Yes, they're all things that you need to think about, but I just don't see them as criticisms of Go in particular.
Coming from the Python ecosystem, if forced to use a relational datastore, I'd probably gravitate towards something like SQLAlchemy core, which provides an engine-neutral programmatic query API. I don't know if such a thing exists in Go, however.
As I said, I don't really care what language is used, as long as it is sane and there's no styling.
Note, this is Rich Hickey's talk about simplicity at Railsconf 2012. Luckily for us, it really has nothing to do with ruby or rails :) It's an awesome video that every programmer should watch. I don't 100% agree with all his individual statements, but most of them I do, and the overall point is a very very good one.
this sounds cool, and a combination of many ideas like serf/consul libs together with some fast storage engine like leveldb.. but has this gone beyond vapor-ware yet and actually shown real use outside of just proto-dreaming? ...the hype puts me off
Awesome idea! Some interesting techs/projects for you: WebRTC, STUN/TURN, TUN/TAP; coreos/flannel, milosgajdos83/tenus, ngrok; 
Why would you rather not move your dev environment to a Windows box to implement/test a Windows specific implementation? You can put build constraints in the Go source files to include or exclude it in certain environments. Check [this page](http://golang.org/pkg/go/build/) for more information (under the Build Constraints heading). A wrapper around the PSAPI from Windows (`psapi.dll`) sounds like a viable solution, very much like what I did with the Windows [Performance Counters](https://github.com/lxn/win/blob/master/pdh.go) (`pdh.dll`).
You probably wouldn't want to break on max characters, but rather on a max width. And yes, this is easy to do.
You probably wouldn't want to break on max characters, but rather on a max width. And yes, this is easy to do.
I can't think of anything I need word for that markdown doesn't do better. I get frustrated at work when all of our requirements documents are written in word. Files are needlessly larger and you have to wait for word or libre office to open.
Try: &gt; Command("cmd", "/c", "tasklist /FI \"IMAGENAME eq foo.exe\"" 
For the most part I agree. It's why we do a lot of our docs in text. For markdown, I just don't expect most people on our team would learn it or agree to it as a standard. I work in a multi-os environment, we have dedicated windows admins who use notepad and word, *nix admins who love their vi and the crazy guys like me who work across both environments. What I've learned to accept is the Windows guys have their way they like to do things, the *nix guys have their way. Rarely are they compatible and you just do what you got to do. At the end of the day as long we we can all agree that we can read and understand the doc, we're good. The primary bar is can we hire someone and expect them to be able to use the documentation as a tool without having to spend a lot of time learning how to read the documentation.
Hi! Using winapi there are two ways to do what you want: Calling EnumProcesses or calling [CreateToolhelp32Snapshot](http://msdn.microsoft.com/en-us/library/windows/desktop/ms682489%28v=vs.85%29.aspx ) and iterating trough it. If you use the go.sys package, you will already have the CreateToolhelp32Snapshot and related functions. If you want to use EnumProcesses you will have to do it manually or use CGO. I used cgo to do exactly what you want: https://github.com/mozilla/masche/blob/master/listlibs/list_libs_windows.c#L180-L208 You can use that code if it is useful to you.
At around the 22 minute mark he talks about the competitive advantage of simplicity. To me at least, he seemed to say that Go will become a dominant force as complex languages such as C++ fade. At the very end he gets in a jab at Ruby when he mentions that it offers a lot of complex options that are best avoided. As mentioned the talk is about Ruby, though his comments about avoiding gem hairballs could be applied just as well to import hairballs. 
I can do it with CSS easily, but with HTML5 only? Please do explain.
In case anybody wants to follow along and actually look at the slides while listening to Dave talk about them, [you can find them at Dave's site](http://dave.cheney.net/2014/10/17/functional-options-for-friendly-apis). They weren't actually linked to on the dotgo page for his presentation, so I had to search for them. A note to those that produce videos like this... it is always nice to have a split screen for the actual slides. Keep that up all the time, especially when the speaker is going through the code line by line.
He stated explicitly that distributed tracing is how you trace through multiple processes in any language. His gripe with go was that he didn't have a way to implement distributed tracing within a single go process (across goroutines?) in a way that did not impose overhead to developers writing the code being traced. 
Hi. I wrote http://github.com/nictuku/dht. It can easily be used for things besides BitTorrent and I've successfully done so. See http://github.com/nictuku/wherez for example.
I thought my beard would be bigger, I'm working on that.
You can do that with maps in Go already. You can also do this with arrays/slices using len if you're worried. if idx &lt; 0 || idx &gt;= len(x){ return errors.New("index out of bounds") } v := x[idx] 
This is a great talk Around 10 minutes in I was like, what the gopher ... but then it all made sense.I need to think a bit more about this approach but it is starting to grow on me. I'm impressed with the quality of the talks at dotGo in general.
I'm a fan of the accent, fwiw :)
You can avoid the overhead (both in terms of code and memory) if rather than reading the file into a bytes.Buffer, then compressing that, you use io.Copy to pass the file directly... in, _ := os.Open("stuff.dat") // check error, defer Close() etc. out, _ := os.Create("compressed.dat") // ditto compressor, _ := flate.NewWriter(out, 9) io.Copy(compressor, in)
Idiomatic != Interfaces If your code really "works well, is simple, and easy to understand," then it probably *is* idiomatic Go. And little example programs doesn't necessarily need to be rewritten to use custom interfaces. Doing that might obscure the example. If it hurts too much to write it, it probably shouldn't be written that way.
I wonder what effect this has on the line between initialization and post-init configuration. These functions look like they'd apply just as happily after the creation of the server or terminal object, but what about configuration that is not expected to happen after object creation? TLS might actually be a decent example of that. It's probably not *hard* to insulate against this in every configuration function - in many cases, not even necessary. But it seems like there ought to be some concise and idiomatic way, that I'm having trouble picturing.
Don't use relative imports, ever. If you lay out your code in proper $GOPATH style then the tools, like Gocode, will start to work for you rather than _against_ you. 
I think you got it wrong if you assume that idiomatic == interfaces. At least in my mind, idiomatic means, it's done like the stdlib does it. Or like major contributors to Go do it. Or like old timers (fwiw) Go programmers do it. On top of that, I truly dislike saying 'Idiomatic'. That's like a last resort word to say "listen to the elder Gophers".
In java you would instrument the JVM. In dynamic/VM languages, the same. I don't know how it's done in C/C++. Perhaps the same way things like the race detector or `go cover` are done. 
Doesn't rust have concurrency primitives?
It does, they are very similar to go's. They even got a brief mention in the article.
Yeah, I know interfaces are just a part of "good" Go code, but they are talked about a lot. Thanks for your comment. I don't like the word much either. Kinda like an abbreviation for automatic idiot.
Dave Cheney's talk.
EDIT: I added an alternative method for compression to your other posting: http://www.reddit.com/r/golang/comments/2llsvt/compression_example/clwaz3j Recently on the Go mailing list Egon had an amazing point regarding Go. Labeled point 0. &gt; 0. If it hurts, then you are doing something wrong. &gt; &gt; e.g. &gt; &gt; * If you notice that code isn't nice -&gt; cleanup your code / separate concerns. &gt; * You can't specify type hierarchy -&gt; don't create hierarchies, use interfaces + implementers; depth adds complexity. &gt; * I'm not able to understand how code works -&gt; don't use that many levels in code or add/remove interfaces. &gt; * I can't understand how to use unsafe -&gt; don't use unsafe. &gt; * I can't put the folders the way I like -&gt; use the standard Go way. &gt; * I can't format code the way I like -&gt; use gofmt and stop worrying about minor things. &gt; * I can't write a generic code -&gt; duplicate code (its easier to understand) or use interface. If an interface doesn't make much sense to you -- consider that you might not be "getting" it yet. Think about it a bit more, don't blindly try to emulate interfaces, understand why they exist. For example, your compression example (I dug up the post), you need to step back for a moment and think about WHY the io.Reader and io.Writer interfaces work they way they do... a lot of it is to save memory (versus like ioutil.ReadFile, which is memory suicide with multiple GB compressed files). Once you understand the WHY behind an interface, you will understand if you should be using it our not, but don't blindly flail to follow them. https://www.datadoghq.com/2014/07/crossing-streams-love-letter-gos-io-reader/ 
Go's features don't drop from great to good just because another language has them. Languages besides Rust have strong runtime safety and best practices enforced by the compiler, but the author thinks those features make Rust a "great" language. So lets not downplay Go's features just because Rust has them as well. If both languages have a similar concurrency model, then that means there's at least two languages with great features.
 package main import ( "compress/flate" "io" "os" ) func main() { compress("input.dat", "output.dat") decompress("output.dat", "dup_of_input.dat") } func decompress(inputFile, outputFile string) { i, _ := os.Open(inputFile) defer i.Close() f := flate.NewReader(i) defer f.Close() o, _ := os.Create(outputFile) defer o.Close() io.Copy(o, f) } func compress(inputFile, outputFile string) { i, _ := os.Open(inputFile) defer i.Close() o, _ := os.Create(outputFile) defer o.Close() f, _ := flate.NewWriter(o, flate.BestCompression) defer f.Close() io.Copy(f, i) } 
Rust's concurrency primitives are not similar to Go's. Rust 1.0 tasks map to OS threads 1:1. Even libgreen tasks , which is now moved out of stdlib, have very large stacks. You cannot have 100s of thousands of rust tasks running like you can with goroutines, without changing a lot of system limits to extreme values. Rust's concurrency support is very similar to what you have in languages with first-class multi-threading support. While this is required to avoid GC and overhead in calling C libs, it also makes programming network services with high concurrency less straightforward than what Go offers.
Try this out: func isProcRunning(names ...string) (bool, error) { if len(names) == 0 { return false, nil } cmd := exec.Command("tasklist.exe", "/fo", "csv", "/nh") cmd.SysProcAttr = &amp;syscall.SysProcAttr{HideWindow: true} out, err := cmd.Output() if err != nil { return false, err } for _, name := range names { if bytes.Contains(out, []byte(name)) { return true, nil } } return false, nil } Example usage: // returns true if excel.exe is running isRunning, err := isProcRunning("excel.exe") // returns true if any of these browsers are running isRunning, err := isProcRunning("iexplore.exe", "firefox.exe", "chrome.exe") Btw, you're only getting copyright information because it's the output of cmd.exe. Tasklist isn't successfully running because you need to make each of its parameters separate like exec.Command("tasklist", "/FI", "'IMAGENAME eq foo.exe'")
I love how this article is in both subreddits
I wouldn't call them primitives. They are all built as libraries. If it doesn't fit your use case, you can build your own. That degree of flexibility comes at a complexity cost, but it is critical for certain applications. I would assume that most adopters of Go do not need that kind of extensibility, and that's perfectly ok.
"Content aggregation, not cheerleading" is my guideline for what I post here.
It is hard (not sure if impossible) to implement green threading in rust without compromising on its zero-overhead philosophy. Moving stacks is not possible while still allowing raw pointers and zero-overhead calls to C libs. So stacks have to be kept large as segmented tasks have been found to be performing poorly both in Go and Rust. AFAIK rust developers are planning to provide other abstractions for non-blocking IO, like C#'s async..await in some future version. 1.0 is not going to have any language-level abstraction for non-blocking IO.
I find this solution a bit too verbose for my taste. I prefer alternating keys and values (ala Perl) NewServer(Server.Port, 1000, Server.Host, "foo.bar.com" ... ) Each of those Server.XXX's are strings. It is simple enough to have a flag like package to map these key-value pairs to a struct. This meets all the qualifications: extensible, no nils, default values, self-documentation and so on.
Use the style tag? Is there any particular reason you're so opposed to CSS?
By the same logic, we should all be programming Algol 68. http://cowlark.com/2009-11-15-go/
Ada, like C++, is a large and complex language, the complete opposite of Go.
Go has generic slices and maps
&gt; I work in a multi-os environment So do I, but I don't understand why that justifies Word as opposed to a cross platform format. &gt; The primary bar is can we hire someone and expect them to be able to use the documentation as a tool without having to spend a lot of time learning how to read the documentation. Here's what you need to know about Markdown to be productive: 1. Links 2. Bold/italics 3. Lists (unordered and ordered) 4. Headers I don't know what pool of people you're hiring from, but I don't know any computer literate person that can't learn Markdown in under 2 minutes. That's less time than it takes Windows to start up or shut down. It's probably comparable to the time it takes Word to boot. &gt; At the end of the day as long we we can all agree that we can read and understand the doc, we're good. Unfortunately, there's more to it than that. Word is expensive and it (or some alternative program) must be installed. Because it's not a human-readable plain text format, it can't be viewed in a web browser, and the whole suite of unix utilities like grep or sed are rendered useless. Of course, there are use cases for which Markdown isn't the best option, but in every such case I've encountered, there has always been some tool that just solves the problem better than Word.
It's just different environments dude. Just like on the job, the technical best solution isn't always the appropriate one. In our environment I think it's always going to be a mixture of tools that we can all understand and the individual is comfortable composing in.
You aren't supposed to use log.Fatal if you don't want your program to crash... *facepalm*
Have you considered exposing more of the internals (callbacks for node joins, message forwarding and so on ), similar to what Wendy does? It might make using the package for more surprising things like pub/sub trees etc. easier. Excellent project in any case, and thanks for the comment.
pretty cool.
I'm not really oppose to CSS, the discussion was about a pure HTML5 page and what you can do with just HTML. Of cause you can do it with CSS, and that's is most likely the correct tool, but that wasn't the question. The question was: &gt;if there's a way to tell HTML to line break after a certain number of characters. And you lied, there isn't. Honestly the question is bonkers as well, because you can't tell HTML to do anything, that's the browsers job. 
To me, idiomatic means "as the language designer(s) intended". Which means the probability of running into weird edge cases or stuck on problems the language can't solve is greatly reduced.
exec.command("powershell", "Get-Process").Output()
Of course, thank you for your correction.
https://developer.mozilla.org/en-US/docs/Web/HTTP
Here's slides from a university course about HTTP: http://cs360.byu.edu/static/lectures/winter-2014/http.pdf with more slides on related topics here: http://cs360.byu.edu/fall-2014/schedule
What is the function signature of `NewServer`? I'm not sure you can do that in Go.
Is it just me or does everyone think a helper function to avoid repetitive 3 lines in tests and other places is unidiomatic go? I find `assert.Equal(t, 2, 2)` much easier to write and read than if 2 == 2 { t.Error("unequal") } Verboseness is not always good.
To me this talk was like a thriller movie, All through the talk I was thinking the functions would be anonymous and would work on the server struct. And it all fell into place at the end. Nice pattern.
Erlang has goroutines? You would think they'd at least name them erlangroutines.
What is the usage? In any scenario I can think of the tags would invariably be stored in a database which means the setting/pulling of tags would be SQL/DB territory, not in-house Go variable manipulation (hey, I have a cold and may well be on the slow-thinking band-wagon tonight).
I guess it'd be possible with something like this: func NewServer(args ...interface{}) { if len(args) % 2 != 0 { panic("...") } // loop here, panic if uneven element isn't a string, ... } of course that has almost no compile-time guarantees, which I hope is one of the requirements.
Tags may be used everywhere, in-memory DB, NoSQL, any key/value storage, etc. 
if you want to learn go, you should start using the use standard [http](http://golang.org/pkg/net/http/) package, to get a feel how "proper" Go programming works, you could supplement that package with stuff from [Gorilla](http://www.gorillatoolkit.org/), if you need for example a more powerfull muxer But until you know what you are missing, you should stick to the standard package :)
Use net/http which is part of the standard library to understand the basic building blocks, once you get a hang of it, you can start using gorilla/mux or other frameworks.
Also simplest example of using in the SQL DB table: 1.We got some data from table by SQL query 2. Because the data may be big size and SQL is not cover all complex requests, we use tags as filtering of the data in memory.
Go could really do with Python's optional named arguments.
Thanks :)
I think you missed the point of Blake's talk.
I understood his point about loading hundreds of lines of code just for a small code path. But, his examples with assert, and gorilla/mux were stretching it a little too far. The advantage of using a package is that it has been well tested (at least the good ones). If using a package is going to remove a few dozen `if`s from my code, I would definitely use that package or at least copy the relevant code from the package (like Blake mentioned). I know I am just talking about one example in there, but I think we (the go community) don't try to avoid `if`s as much as we should. His example with an if condition checking for `r.Method` didn't feel right either. REST always has different handlers for different verbs. The following code reads nicer to me. Also, since it doesn't have 3 extra branches I don't have to write 3 extra tests and won't have to worry about 3 extra places for bugs to creep in. var verb = struct{ GET, POST string }{"GET", "POST"} //option 1 r := mux.NewRouter() r.HandleFunc("/products", ProductsHandler).Methods(verb.GET) r.HandleFunc("/products", ProductCreateHandler).Methods(verb.POST) //end of option 1 //option 2 http.HandleFunc("/products", func(w http.ResponseWriter, r *http.Request) { if r.Method == verb.GET { ProductsHandler(w, r) } else if r.Method == verb.POST { ProductCreateHandler(w, r) } else { MethodNotAvailableHandler(w, r) } }) //end of option 2 I am still learning Go, so I may be missing something. I really enjoyed working with sinatra when I built ruby apps. And I am reading the doozerd codebase. I am really thankful for Blake's contributions. I don't mean any disrespect.
&gt; you can build your own Or, more commonly, use a library of someone who has already used the low-level control to implement the concurrency functionality you need. :)
My take away from watching Blake's presentation is dependencies are not free, just as every line of code you write is a liability, so too is every package you import. They both have to pay their way. Specifically testing frameworks, sure, it may appear annoying to write an if statement when you can imagine a nice little assert function provided by a library. But what has happened is you have gone from every single go programmer who understands if statements at an organic level to a smaller set of go programmers who have experience with the specific testing framework you have chosen (insert xkcd reference about standards) So while you may want t.Assert(s != "") Someone else will think t.NotEmpty(s) Is clearly superior The bottom line is these are all little dialects, little languages built in go, that don't pay their way over just writing the damn check and knowing that every single living breathing go programmer will be able to understand it, first time, every time. And that is what I took from Blake's talk, that adding dependencies for trivial functions can, and sometimes does not, repay the cost of the complexity they introduce. 
Yeah the accent was a shocker. 
Dave, Great talk. On your final example with Functional Options before you got into the Term example, the code does things like: timeout := function(srv *Server) { srv.timeout = 60 * time.Second } Shouldn't that be srv.Timeout?
That's correct. I don't lose sleep over this particular use of dynamic typing, because (a) it is initialization and it gets caught easily during testing, and more importantly (b args always need some degree of validation, and the dynamic type check gets included in it. Here's a working example of the idea: https://gist.github.com/sriram-srinivasan/282064085554767972ec 
Will do thanks for the help! :)
You can do a simple static blog generator with net/http and go html/templates, it takes a day or so to get everything done. Once you have the basics, you can use blackfriday for markdown rendering. I did this a few months ago, it was fun and easy.
Usually when people talk about HTML5, CSS and JavaScript are implied. More importantly, the point of the article was not to over invest in flashy design, not to limit oneself strictly to HTML. Such a simple CSS declaration hardly violates that principle.
Double post...
I get that, but in those cases there is some other concern that out prioritizes the technical concerns. I don't see any reasonable arguments for word over markdown, technical or otherwise. In the case of my coworkers, it's a case of not wanting to learn a new tool or technology, and that's a bad attitude to have in a technology industry.
I think you might have a better time doing things the "Go" way with support of a few packages friendly to that. I would check out as suggested Gorilla, but would add Negroni to it. Its written by the author of martini after recognizing that martini wasn't conducive to "Go" way but taking much of what it was helpful with (primarily not having runtime type safety because of reflection magic for DI).
Yeesh, calm down, it just speaks a lot to the quality of the article that both sides find it interesting.
Useless answer. This describes how to setup a basic project with another package that has to be imported. This man wants to know how to use multiple subdirectories in a single package. Not split into multiple packages.
You may be gathering, parsing, transforming, or grouping structured data from clients before ever getting it to a DB; or you might be doing operations that are too complex for a DB to reasonably manage (such as conditionally passing a portion of that tagged data onto a different service), but you still need the have tags. I can see plenty of legitimate uses for them. Sure beats writing another implementation.
If a package grows so much that I need to split it into several directories to handle my code (go allows to split it into multiple files in one directory), then I would think about my code organization. Large functions, types (classes in other languages), files, or packages tend to become hard to maintain. So in case of your concrete code create sub-packages and bundle the functionality in a logical way there. Other packages, like also your main package, then can use these packages. Take a look at my private code at http://github.com/tideland or our company project, which really has a large code base, at http://github.com/juju/juju.
check out beego, revel, gondola and negroni (instead of martini) before starting anything from scratch. keep in mind that most big go users will stay away from them and only build on the core packages and maybe gorilla.
In general, Rust doesn't have language-level abstractions for i/o, it's all in libraries.
for a lightweight approach I recommend [hugo](http://gohugo.io/)
I will try and give a practical answer since most answers here tend to be "No don't do that." Essentially, what you probably want to do is organize your code into "sub-packages". Though you might need to change your code structure so that each sub-package doesn't introduce cyclic dependencies. Each package in your project should be either be a leaf package (no inter-dependencies with your other packages), or your root package (your main application). And make sure your set GOPATH to be the root of your project. Your project directory will look something like this: $GOPATH/ projectmain.go src/ yournamespace/ yourpackage1/ file1.go file2.go yourpackage2/ file3.go file4.go code.google.com/ ... github.com/ ... In your code. your imports would be something like: import ( "yournamespace/yourpackage1" "yournamespace/yourpackage2" ... ) 
+1 though it's not really a way to learn go, unless you want to fix bugs (which is also cool)
I don't know enough about what `async`/`await` are from a PLT perspective, I've never written any C#. Wikipedia says it's a promise, which looks like this in Rust: use std::sync::Future; fn fib(n: u64) -&gt; u64 { // calculate some huge number 12586269025 } fn main() { let mut delayed_fib = Future::spawn(proc() fib(50)); println!("fib(50) = {}", delayed_fib.get()) } the `Future::spawn` is the async, and the `.get()` is the await, no? EDIT: my twitter feed says that it's basically syntax sugar for a future, so yes, if you want the sugar, I guess that would require compiler support :)
With the example in the README, {"a","+b","+c"}, why is it "a OR (b AND c)"? That is, I don't see why "+b" and "+c" are getting grouped together. For instance, if I wanted to do "a OR (b AND c) OR (d AND e)", there doesn't seem to be any way.
Warning I only gave this a quick look (and I am no expert in Go yet) but my .02. I would do something like the following (not sure if it'll compile but you get the idea): https://gist.github.com/vhodges/7d4ab1f056e55e3e9390 
Because this is enough to make simple rules, "a OR (b AND c) OR (d AND e)" is to too complex and to achieve this requires parentheses and more complex rules. Now is very simple: 1.if tag with "+" or "-" this is logical operator "AND" between another "+" and "-" , 2.if tag without "+-" is logical operator "OR" between all rest
Abstract the folder traversal and pass a function that takes the input variable that you end up unmarshalling. 
I've spent a couple hours down this path. I can unmarshall the JSON into an map[sring]interface{}, but then I end up back in the same problem I was in. I don't know what kind of struct I decoded/unmarshelled, and I have to either kernoodle with the keys that I happened to decode and feel out what kind of struct it is, or I have to just flat out assume that it's ONE type of struct, and then make 5 unique solutions to solve the same problem (kind of like what I'm doing already) I can't quite cut out the &lt;struct&gt; and paste in &lt;interface{}&gt;, but I was trying to for some time. Unless I'm drastically misunderstanding how to use them, I don't think this can solve my problem.
Great point! I'm not certain how to solve the decoding still, as I wanted to pass in the container as a function argument, and that's the most troubling of all. I can't seem to create an argument that accepts a map[string]Rooms *as well as* a map[string]Item. Once I get *that*, then returning one object should be as simple as using the interface{} right? 
Read the json.RawMessage section of this blog post. He describes how to do what I believe you're needing. http://attilaolah.eu/2013/11/29/json-decoding-in-go/ Definitely avoid unmarshalling into map[string]interface{}.
I had couple iterations that would take in json, and give me an interface{}, however, I couldn't use reflection or any kind of typeOf() function to ask go to spit out what type the interface{} was. I didn't think it was good form to blindly cast, and see if an error occured. Is that what you're suggesting? I suppose I can give it a try!
Here, I did my best at abstracting out the functions. Disclaimer: Written before my first cup of coffee. https://gist.github.com/CasualSuperman/b35793859bc701c824a8
I kinda figured I could always delve into it this way. Decode the json myself, but I wasn't incredibly happy thinking that this was the best way to solve this problem. I have structures that fit the json perfectly, I have the json. If I can find out what what type of structure the json is, then I can unmarshall it with one line, and receive neatly formatted structure. (failure to fit the form of a game-structure simply results in it not being loaded) I think my problem centered around figuring out how to make a function work with a generic container/dictionaries... Am I blabbering on? Or is this making any more sense?
I think my problem centered around figuring out how to make a function work with a generic container for dictionaries. This solution basically would remove that, by figuring out what it's working with (enum, function argument, string scrape on the directory, or whatever, they all work) and then interfacing with the global containers. ... It should work! Any thoughts about the generic container? A post above me threw out a pretty nifty thing that used (abused?) []byte to move stuff around..... I'm looking into it now.
Going back to your problem about figuring out the json type before unmarshalling, you could always add a file extension and just switch on that. 
I'm partial to a micro framework like [flotilla](https://github.com/thrisp/flotilla) -- because I'm building it, but wouldn't recommend it outside of a development level because of a number of uneven or rough parts. If its just a blog and primarily static try [hugo](https://github.com/spf13/hugo). Avoid the larger messes (beego, revel, gondola) for something like a blog. Your best start would be the net/http library though. You can quickly build a blog with just that in a short time as go is really easy to get started with, in fact recommended as a start because almost everything framework like starts with net/http. 
In your implementation, you have &gt; func TraverseDirectories(dirloc string, action1 func(string), action2 func([]byte)) action1 func(string) That's a recursion problem.... action1() would need to be a function(string, action1, and []byte) right? **Edit:** Sorry to talk about *recursion* before coffee... that's probably breaking a rule somewhere...
Not sure why it would be a problem. You already have recursion because your Items parser calls itself iirc. 
&gt; func **TraverseDirectories**(dirloc string, **action1** func(string, **action1**, []byte), action2 func([]byte)) { Not sure if that's a problem... currently turning wrenches, just something I noticed, and haven't messed with. **Edit** I think I avoided it, why pass in action1 as an argument, when you can just call TraverseDirectories() again? I just removed action1(). Looks good thusfar.
Untested http://play.golang.org/p/45yQW1WTwT For a first pass I think the easiest thing you can do is use http://golang.org/pkg/path/filepath/#Walk. It immediately allows you to get rid of most the code in `func RegisterRequirements(dirloc string)`, etc. http://golang.org/pkg/os/#FileMode.IsRegular should be enough to decide whether or not to scan the file. You can also check the file extension if you're using one for your files. With a function like `func WalkJSON` you can avoid the potential duplication that it introduces. A function like `func LoadJSON` allows you to get rid of another chunk of the duplicate code (the ioutil.ReadFile part). You can reduce duplication further, but at that point I think it's mostly a waste of time. 
Well I originally included it because your RegisterRooms functions called RegisterRooms while all your others called RegisterItems. If you just call TraverseDirectories again your Register{Actions,Requirements,Widgets} won't have any way to call RegisterItems.
IMHO, there is only 2 well-defined phases in a compiler: * frontend (at the end, the semantic is correct) * and backend (everything after). All the rest (lexing parsing semantic analysis optimization weeding ..etc..) is undefined, thus bullshit: if I parse A*B as ID(A) STAR ID(B), is that a lexer, a parser ? Should I call that an AST ? ..etc.. 
I'll have to look at Walk myself soon here... I ran across that after I had patched my previous iterations. (I was looking at one folder of json without sub-directories at first, and I didn't think walking would be necessary until the number of rooms got out of hand... then I just patched in the recursive call.) This is the "fix" I settled on, and I like it a lot! I'll see what I can to about walking here in a bit! https://gist.github.com/CptSpaceToaster/03c6692b6c5e75df95d1 
As long as the handler is preserved, everything should be good! https://github.com/CptSpaceToaster/adventurebot/blob/master/robots/adventurebot.go#L44 &gt; TraverseDirectories("../src/github.com/cptspacetoaster/adventurebot/rooms", HandleRooms) I can simply swap out the directory and handler function, and then each handler can interface with the container dictionaries just fine!
No problem! I think that's easy, just pass in the container. I think you can pass the map in as map[string]interface{} and it will work (ie it satisfies the interface requirement. I've updated the gist. I think the pass a function idea works as well (it just changes where the code lives). EDIT The code you have in handlers would live in each of your types (Room, Action, Requirement, etc) to satisfy the interface GameObject in my solution but I see that I've actually I mis-understood the original code! It's really a factory and the handler func idea you have in the other gist works fine for doing that.
Hmm, I see what the issue is there, you might consider using interface{} to hold all the data in the generic container, then have a method on the container object that returns the type enum (which could just be a custom string type to keep it generic), this way you can cast the interface when you use the data, just make sure the data that goes into the interface isn't already set (I.e map[string]interface{} as that will fail), so it would need to go into an interface type as a specific type (when you register it) that way it will cast correctly when you use it - there's basically some metadata overhead in trying to keep the data generic, so you need to make it available to the consumer when it should work with it. I think there's even something you could do with an interface definition to define the function that returns the json type enum and an interface{} object, that way any consumer can work with any of your containers, even if you need to specialise them. Not sure if that is clear, I'm half a bottle of wine in... (It's night here in the UK) :-)
Yeah, I'm happy with the solution either way... I think what you're doing was going to be a couple of extra steps... but a correct solution none-the-less.
I had tried for the longest time to make a map[string]interface{} work with the thing... but the problem was that I couldn't quite get everything to work nicely. I still had to make nasty assumptions in generic places, and needed a lot of what you just mentioned! I can't quite get my jive on with small interfaces to jim-jam data structures around in a non-OO language. It's a little counterintuitive to what I wanted to do in some other places, but I really appreciate you taking the time to sit down, read through, and offer your opinion! Have a fantastic evening!
Well... I don't see a reason why it wouldn't work, but I ended up at a different solution that I think looks a little better. While I didn't accomplish what I had initially asked, the initial problem was solved a different way. I'm beginning to think the only way this can easily be done is to do just that. Try a cast, check for failure, and try another! Thanks for responding!
You are welcome. I'm glad you've found a good solution. Keep going! ;-)
Yeah you'll want to avoid shoving map[string]interface{}'s around, it basically destroys the benefit of strong typing and adds a bunch of overhead and boilerplate that makes it non idiomatic and painful. For a problem like this, where generic implementations seem natural in something like python, I found I needed to rethink the problem in terms of golang, it's kind of a blocker sometimes, I used to develop a lot in python, and the way Json handling works is seriously missed. Golang is OO, you can do type inheritance using embedded anonymous typing and polymorphism comes through loose coupling via interfaces, but inheritance is one-way, implementing a parent type in a parameter means that that's all you have access to, which is why passing interfaces may be easier because they offer a generic method signature structure so you can create getters and setters that behave rationally. You could have your data jammed into a generic interface (IIRC interfaces have a shadow type, so if you put a typed object into an interface{}, it retains it's shadow type, which is why assertion works, but not asserting an interface that was generated by json unmarshalling, as that will shadow it as map[string]interface{} and type assertion becomes impossible). So you can have your generic container keep its data in an interface{}, so long as when you initialise it you do it with a strong type, not the standard json map, that way you can type assert when you need it, and use a separate value in the container to retain type information through an enum. I would recommend looking into re-thinking the structure int terms of functional interfaces (not the type, but the object signature kind), this could offer a more generic approach to the problem by creating handlers instead of strict object types. Then you can pass handlers around and consistently interact with the exposed methods, only casting when absolutely necessary. 
If that wasn't clear ;) it's just one of the many languages you can refer people to that does what people seem to look for when they bash go... Me myself is really content with Go, thank you ;).
Scheme, Haskell, my own toy languages. 
github.com/emicklei/go-restful has a generator. Don't know how it works, other than the declarative API that they use. I'm assuming that has a large part in the swagger generation.
That API is a minefield for the caller, I dont think you understood the point of my talk.
Yup, it should. That is what I get for _not_ using the present tool. 
`.get()` would block the current task, which in Rust's case is an entire OS thread. `async..await` is more than just syntactic sugar, the compiler generates code to handle completion of the future without blocking threads. That is what allows linear-looking code while using non-blocking IO in C#. For network services with high concurrency, this linear code structure is essential for a manageable codebase, IMO.
It's a broad question. In 15 minutes, you could focus on 1 element of Go, maybe its type system, or concurrency mechanisms, or its interaction with C code. I'd be tempted to pick something out of the stdlib if possible. Could look at encoding/json if you wanted to talk about reflection. time or fmt for more straightforward stuff. container/list/X has some nice and simple data structures. net/http is a mini-framework, which might make for a more interesting presentation than one of the countless frameworks built atop it. Also, with things moving to go in 1.4, you could look at like the hashmap implementation or something else like that. If it has to be a framework, maybe GroupCache? 
You've presented the caller with this func NewServer(...interface{}) How are they to know that arguments must be provided in pairs ? How are they to know the _type_ of the values passed in every _second_ argument? If I want the port, is it a string ":8080", or the integer 8080 ? Is it `Port`, or `port`? I think your suggestion is worse as it is not discoverable, and completely abandons type safety. Compare that to [this example](http://godoc.org/github.com/pkg/profile#example-MemProfileRate) which not only documents the configuration parameter, but includes a godoc sample of how it can be used.
I like the point at the end about Apple moving vom Objective-C to Swift. What will Java's successor be? (Scala proponents, I hear you shouting!)
"Idiomatic Go" is not a thing in itself, [don't let anyone bullshit you](http://en.wikipedia.org/wiki/On_Bullshit). If it fucking works, is simple and easy to understand, then go for it!
Have a look at JWT: https://github.com/dgrijalva/jwt-go
Ignoring the rest of it, this: if (ComputeHmac256(at.Info, secret) == at.HMAC) { is a huge security hole. String comparisons will short circuit, allowing someone to steadily determine a new hmac with enough requests. Always compare HMACs in constant time. In general, try not to roll your own crypto system.
I just gave several reasons why word doesn't work, but yes, some people are unreasonable, and yes, I've also found that technical people are often as stubborn as any other user.
Not really a big hole unless the attacker has access to your CPU; the time spent in string comparison is going to be trivial compared to the time spent calculating the signature and doing I/O. It's a decent attack vector if the attacker can monitor the stack frame, but in that case they may as well just read the secret out of memory.
Ah, this is perfect, thank you!
Interesting, so I see now that the hmac package has an Equal method, which doesn't leak "timing information". I'm probably going to use the library pointed out by baijum, but I'm still curious about how this should work. It looks like hmac.Equal just takes byte slices. Does the encoding affect this comparison? Would this fix the problem (ugly as it is)? if (hmac.Equal(byte[](ComputeHmac256(at.Info, secret)), byte[](at.HMAC) )) {
Yes, it is dynamically typed, and is by convention. In production code, I have the kinds of features you mention -- auto-conversion from strings to desired type and case insensitivity I have found that in my production usage, static typing of configuration information was more hindrance than help. This is because config info often comes from files, command-line, environment variables, zookeeper and so on. In a statically typed scenario, the client has to parse the info into key value pairs, change the value format to the desired type, do a switch on the key to map to the appropriate function option, then add that function to an array to pass to the initializer. In the dynamically typed scenario, the config info can be passed directly to the initializer. It is less work for both sides, and one can get on with semantic validation of the parameters without much fuss. If one really wants a statically typed API, one can have helper functions in your style, but personally, I don't have much use for it: NewServer(Timeout(1000), ...) func Timeout(int t) KV { // return key-value pair return KV{key: "Timeout", val: t} } 
[Incorrect.](http://rdist.root.org/2009/05/28/timing-attack-in-google-keyczar-library/)
Note that the attack in the blog post runs locally. It is a vulnerability, but not necessarily a "HUGE" one. Once you throw in noise from the network and give the machine a production load with tasks other than "verify this HMAC a whole bunch", it takes a much larger sample set to perform this attack. Edit: I'm making an ass of myself. All vulnerabilities are bad. This one is bad.
Yeah, you should use the library. But you're correct, hmac.Equals internally calls ConstantTimeCompare from here: https://golang.org/src/pkg/crypto/subtle/constant_time.go and thus doesn't have the vulnerability.
Ahh yes, if it's non-blocking, then this is different. Rust won't have non-blocking I/O for a bit, the relevant libraries are still under development.
Excellent, this makes my day :)
There are also another Beego-like swagger generator: https://github.com/yvasiyarov/swagger Main difference - its not depend on any framework, so you can use it for any API application
Thanks for your answer. Lot's of ideas that I will check. Cheers
&gt;To replicate this functionality in the app I used a map from strings of weekdays into booleans, and rather than use the Storage API to save this (a clear overkill) I thought I'd use a global variable with sync.RWMutex synchronization. Assuming the person is referring to the Datastore, I can't see how this would be a *clear overkill*? This is exactly the type of thing one typically use the Datastore for.
Very nice angle to introducing Go. One thing though, I'm not sure we can say Go is a good of a choice for scientific computing (slide 3) at the moment. Numerical code very often deals with matrix algebra, and I don't see that being a strength of Go, compared to C++ or Fortran, for example. Also, I'd love to hear examples of high frequency trading shops running go, never really heard of that before. It's intriguing.
&gt; And (worst of al­l) java.lang.thread and shared-mutable-state. Go tends to do a better job here, but that's only because data *copying* for the sake of channels is more of a convention than a rule. One can still build all kinds of shared state into a Go program; dare I say, one may actually want that for efficiency. Mistakes of this nature are made all the harder to discover since Goroutines aren't necessarily distinct threads, although they can be under special circumstances.
The go tool will treat your sub-directories as different packages. (The presumption here is that if you're breaking code up into directories, then the encapsulation provided by packages may be desirable anyway, and it makes the package definition rules much simpler.) If you can live with that, then you're all set. It's worth pointing out that there's a proposed "internal package" feature (golang.org/s/go14internal) that would allow you to make your sub-directory packages private, which might be closer to what you're envisioning.
I've had good luck using Go for numerical computing, although truthfully a lot of the code that does the "heavy lifting" still tends to be written in C (or, rather, C that calls into CUDA C.) When people say Python is good for numerical computing, what they really mean is that there are good libraries that bind well-tested and performant C code (e.g. numpy, pandas, etc). Numerical computing software written in pure python would be glacially slow. It's still possible to write acceptably fast numerical code purely in Go if you're careful, particularly since you have the opportunity to link in assembly routines where you need them. However, you're right that the libraries and tooling for numerical computing in Go are not as mature or sophisticated, but I think it's only a matter of time. The problem Go solved for me more simply than any other language could, I think, was networking numerical code. It's possible to write large machine learning applications in one language. If I didn't ever have to actually do something useful with the data, like put it in a database, I would still be writing in C.
To echo the other comments here, I don't think the title is accurate. I think the problems aren't with the Go language or with App Engine; I think it's using the wrong solution to solve your problem. If you're not paying attention to the platform your targeting and it's imposed limitations (to gain you massive scalability capabilities), then they're not gotchas. They're misunderstandings of how things work. Not understanding how caching works between your client and the server or how singletons work (and don't work) aren't gotchas, they're development blind spots.
That's a great, thorough, read - thanks for linking.
This jwt middleware makes it pretty easy to get going: https://github.com/pkieltyka/jwtauth
I figured that much, but this also raises another question. What stops somebody from stealing a token and using it as is to make API calls? Is it just expected that this will happen over a secure connection?
[not true](http://self-issued.info/docs/draft-ietf-oauth-json-web-token.html#EncryptedJWTExample)
&gt;If you use mutable global variables in App Engine you're gonna have a bad time. If you're writing any web application with mutable global state, you're gonna have a bad time...?
Sorry, but I am failing to understand how: self.Bus.ImportMovies &lt;- &amp;msg reply := &lt;-msg.Reply is better than: self.Bus.ImportMovies(c) What benefit does it bring apart from being able to spawn multiple services listening on the same channel?
That's why I said "system". He's using go's built-in crypto, and that's good, but then the system he built on top of it is using it in a way that's incorrect, and subtly so. Using something like jwt greatly reduces the possibility of that happening.
I took a crack at [actors and an Erlang-like OTP framework on top of it, all in Go](https://github.com/arschles/gotp). I like what you did with the react loop. I've seen it in [other projects](https://github.com/mesos/mesos-go/pull/20) too. Not necessarily the whole actor implementation, but it's pretty close. Just my $0.2
"Go makes it easy to not use frameworks. Instead, small tool libraries used together achieve the same utility. The resulting applications are less complex, easier to reason about, and nimble in their modularity." - [source](https://walledcity.com/supermighty/go-frameworks-or-libraries-design-decisions-and-new-project-structure) 
How did you get processes called a.out.exe? Also, Go binaries are generally pretty big—1.3 MB isn't relatively big (in fact, the hello world example from golang.org compiles to a 1.8 MB binary on my box).
&gt; and generates a 1.3 mb file which seems way too large. I can confirm that on my Windows 8.1 64 bit system, when I run *go build* on the following code package main import "fmt" func main() { fmt.Println("Hello World") } The output file is 1.9 Mb
drop the windows part ;&gt;
[Why is my trivial program such a large binary?](http://golang.org/doc/faq#Why_is_my_trivial_program_such_a_large_binary) How are you compiling your program? 
The workspace is simply a directory into which main.go is placed. Main.go was created with SciTE but notepad ++ confirms that nothing is weird in that output. "go build main.go" creates a file called "main.exe" which hangs indefinitely when run. "go run main.go" also hangs. No compiler errors appear at any point.
Sorry, not familiar with the size of go programs hahaha. The file is named "main.go" I have compiled it both by running "go build main.go" and running the produced exe and "go run main.go"
Sometimes I need linux, sometimes I need windows. I would like to have go work on both.
Ah, didn't realize go generated such large programs.
Very strange. Not heard of this happening before. They normally just run and exit.
ctrl+alt+delete shows a number of processes named a.out.exe I have never seen them before and this is pretty much a fresh install of windows. I reformatted this weekend so there is only the base level of programs that I use on it.
Ah, didn't realize go generated such large programs.
It's because the entire go runtime is packaged with the program.
Are you running the programs with `go run`? That could give you output with `a.out`
I believe /u/Testiclese is referencing Hickey's Core.async [presentation](http://www.infoq.com/presentations/core-async-clojure).
Yes, I ran several of them with go run and ended them with ctrl+c
Gorilla mux depends on Gorilla context. http://godoc.org/github.com/gorilla/mux?imports
Your referenced code isn't even a Hello world. Why not include fmt and do a proper println? My guess is that it's acting similarly to if you used select{} to keep a process running. 
I ran hello world too, it failed as well. I figured that I would run the simplest possible program to make sure that it wasn't some issue with the way I was using fmt. I ran hello world straight off of the golang.org, it still hangs
i didn't want to publicly say that...
Nice ! Will take a look.
Did you properly setup your workspace/GOPATH? If not, make sure you read https://golang.org/doc/code.html
Correct, it needs to happen over a secure connection. It saves you a ton of session / database lookups to verify a user if you include the user id and permissions inside the claims. Google/Facebook use jwts for all of their service authentication, so it's far more secure than rolling something yourself.
Porting OTP to Go is a bit of a holy grail, isn't it? [This is my approach](https://bitbucket.org/ulfurinn/gen_proc). It takes [an input file](https://bitbucket.org/ulfurinn/blitz/src/915c13e3e76817af4378aa5e5c503b972296572b/blizzard-lib/proc_group.go?at=default) and generates the [reactor loop code](https://bitbucket.org/ulfurinn/blitz/src/915c13e3e76817af4378aa5e5c503b972296572b/blizzard-lib/proc_group.gen.go?at=default) from the struct definition.
Ooh sweet. I needed this for a couple of other projects
Are you using the regular Windows command prompt?
I haven't but I'd consider moving the logic to a dhtinternal package and exposing things there. That should work, as long as the dht package retains a small API. That said, if Wendy works for you, that's cool.
Yes
I have never had these issues across Windows 7, 8, 8.1, Mac or Linux (Ubuntu). You shouldn't have to `go install` to run it .. you can just `go build .` in the directory where your source is and then run the resulting executable. Are you by chance running Windows 8? I have found that if your `GOPATH` is in your main volumes root (e.g, C:\) then UAC and all sorts of other crap kicks in. You'll have to run command prompt elevated with Administrator permissions for things to work properly. Give that a shot too.
I found go test and "log" package is enough for debugging. Down vote me, but for me it's true.
You should write debugging capabilities into your program.
I don't fully get why it needs to do this. shouldn't go compiler take already care of that? RUN cd $APP_DIR &amp;&amp; CGO_ENABLED=0 godep go build -o /example -ldflags '-d -w -s' 
nice. well written packages. Does anyone has some ideas of applications where this algorithm would really shine ? 
Have a look here: http://go-database-sql.org/accessing.html Specifically the part that says: `Although it’s idiomatic to Close() the database when you’re finished with it, the sql.DB object is designed to be long-lived. Don’t Open() and Close() databases frequently. Instead, create one sql.DB object for each distinct datastore you need to access, and keep it until the program is done accessing that datastore.`
I like that Wendy behaves more as a distributed message queue than as a K/V store (messages are sent *towards* IDs, not *to* them, and you can decide whether you want to forward messages your node receives or not), and that it (in *theory*) supports a routing overlay network on top of the DHT. Unfortunately the project's been dead for a while, so it's not necessarily stable, and it doesn't support things like having a custom routing metric out of the box. This means I'll probably end up switching to another DHT package eventually, since I don't want to have to work on both a DHT and the proxy. However, my messaging component is just going to be a `net.PacketConn` shim around Wendy, plus some structs for the message, address etc.; changing DHTs should be easy as the details of the DHT implementation won't leak out. Well, it'll be easy once I figure out what functionality besides just messaging I need, anyhow.
This package provides a nice foundation for dictionary-based applications, where prefix lookups and fuzzy matching are important. The MA-FSA is a space-optimized trie, so it acts like a set, but with very fast lookups and no collisions. This particular MA-FSA has minimal perfect hashing, so you can also use it as a map from key to value. Plus, this set is alphabetically ordered, which means that traversal is deterministic, unlike plain Go maps. The MA-FSA makes it even more ideal for very large dictionaries. In our tests, we filled up the structure with about 8.2 million words on a 64-bit system, and it only used up 2 GB of RAM. That seems like a lot, but consider that the average length of the words in our tests was 24 characters: much larger than words in a typical dictionary.
Thanks, reading through this site now.
Why would doer need to know the receiver type? Maybe you can achieve the same using an interface instead.
&gt; Don’t Open() and Close() databases frequently. But don't forget to Close() `Rows` and `Stmt`s and Commit() or Rollback() `Tx`s.
I really like the language, this is the only remaining issue keeping me from switching my dev. team over to Go for all web frontend stuff. For you and me, this isn't a big issue. But for a development team that needs to work together and debug each others' code, its a big hassle. We've been using Python with great success, and the tooling for that language is amazing. The IDE support, debugger support, and so on. I really want to switch us over to Go for our next projects, but the lack of a solid debugger and IDE are problematic. I'm not trying to be a buzzkill, just stating that there are still gaping holes that need to be fixed. I read your blog by the way, good stuff.
What i mean is: * Create an interface that defines everything your dog can do. * Pass that interface to doer, instead of a function. http://play.golang.org/p/YNCYpAOj7V 
What I normally do is to have have a global db connection, and a request context object which contains connections and other data. I use a middleware to set the db connection on the request context instance.
Sure, Go doesn't have a strong debugging story, we get that. Just as you don't start a 21st birthday speech by reminding the guests that other more gifted or well endowed children are also celebrating birthdays, it's not necessary to bring up debugging today.
Writing a complete debugger every time you write a new program is probably the least efficient idea I have heard all week.
Please, don't use a license GPL-like for a package
I've debugged go programs with gdb. What's the problem?
Go's default tool chain is amazing (doc, fmt, test, ...) and cross-platform. It would be best with an adhoc debugger, rather than relying on an external tool (never used gdb myself, actually).
[Azul3d](http://azul3d.org/) might be of interest to you.
Work is progressing on a native Go debugger, but it's a lowish priority so the going is slow. But I'm pretty surprised to hear you say you want a debugger for front end web dev stuff. I spent a lot of time doing that work and never felt the need for an interactive debugger outside of the browser. With everything split up into separate calls, the request/response logs always sufficed for me.
I am not 100% sure thats a good idea. Docker is a great idea (I have docker in 7 test production - rhel 7 right now, works stellar) , but there is such thing as the saying "if you have a hammer, everything looks like a nail" What if the application does something specialized? such a custom logging? virus scan? worst yet, plugs into existing enterprise apps. Just some thoughts. Also to nit pick, the docker file is debian/wheezy, in the US , its almost an unwritten rule, fortune 500, RHEL only. 
It doesn't work fully. Try inspecting errors or other objects that aren't primitive types.
Why?
Nope. Code generation, maybe?
Not always. Most of the time for me they cannot print anything at all or cannot find the symbol being evaluated. At a point with with 1.3 you no longer can use gdb to step into anonymous functions. I don't remember if that's limited to those called as goroutines or all. This might of been fixed in a patch but at initial release it was there.
Don't use global variables to preserve state between requests. At the very least use memcache. Datastore would be even better. You can't treat a web server, even an EC2 instance, like it's going to always be around. You will lose state when your VMs get rebooted ... And they always do. You must persist state to some non volatile storage that is separated from your VM. This is almost a law of physics when it comes to any cloud service.
SFML is pretty awesome and have bindings for Go :)
Could you elaborate a bit on the 'debugging hooks'? 
A go package is a library. Nothing to do with classes. No idea how they are making this connection
Been building a small app with Rails back end and using ReactJS+Flux in the front end. I still find the MVC stuff rails gives me to be quite handy, but I can definitely appreciate where the author is coming from. There's a lot in Rails that I am not using, and could probably benefit from something a little bit lighter. Probably not as lightweight as say Sinatra though, as there's a fair bit of security things i get more for free with Rails.
Because the copyleft infects your entire Go program since non-static linking is not an option. 
How about padrino?
Yep could be the answer. I haven't used it, so I cannot say for sure. I started this project for the rails rumble, so i wanted to use a rack-based framework i was familiar with :)
As I said in the post, go build generates an executable but running it hangs indefinitely Running the command prompt as admin makes no difference
The name seems like a terrible missed opportunity to make a gopher pun. I mean, "burrow" was right there! In all seriousness, looks like an awesome project! Looking forward to finding an excuse to try it out.
Dat editable Google Doc.
Right - I should have done a top-down scan rather than bottom-up :)
Nice, one less thing for people to complain about!!!
This is so awesome! Definitely something I have been wanting for a while.
It's actually a pretty big deal for those of us coming from python/ruby with really great debuggers. It's hard to go back to print statements after experiencing the speed at which you can develop with such tools.
*This is a first announcement and request for comments post* I remember looking for a Go library for searching PirateBay and finding stuff that was rather minimal. I was dissatisfied at the time and decided to roll my own, and now I'm finally sharing the results of my work. My two biggest Go-related questions are: * How to better handle testing, given I want to rely mostly on static data files * How to better implement the filters framework, any ideas on loading stuff at runtime? In the mean time go give it a go. I appreciate any and all feedback.
Thanks for the validation, and the tip. I'll check out how `hash` is structured. `whatever.NewFeed` does return a concrete type, but currently none of my services export anything beyond what's necessary to implement the interface. I've tried to encapsulate as many details as I could get away with.
Any idea of its capabilities with 2D? Looks sleek for 2D though
I know, not having a debugger is probably the most legit complaint I've heard about Go.
This confused me too. The closest thing in Go to a class is a struct. Data members, methods, instantiable, inheritance, polymorphism, etc. I mean, a package has data and functions, but that's it. It's not even instantiable.
I have fallen absolutely in love with sqlx in production. It is useful and powerful without getting in the way. It feels like the most "Go" way to approach the problem space. 
I haven't actually used it much, but I remember people complaining that it's not that great. A little Googling found this: "GDB does not understand Go programs well. The stack management, threading, and runtime contain aspects that differ enough from the execution model GDB expects that they can confuse the debugger, even when the program is compiled with gccgo. As a consequence, although GDB can be useful in some situations, it is not a reliable debugger for Go programs, particularly heavily concurrent ones. Moreover, it is not a priority for the Go project to address these issues, which are difficult. In time, a more Go-centric debugging architecture may be required." [Source: golang.org](http://golang.org/doc/gdb)
I guess that's up to you and the requirements, by not having to receive a WaitGroup the function becomes simpler to use.
It just plain doesn't work: https://code.google.com/p/go/issues/detail?id=8256
I got excited, then: &gt; Upcoming features: Support for OS X ... so I will defer my excitement for now. I wish I had time to contribute to the project and get that working. Great start though! 
What about gdb?
This is interesting, I thought about doing something like that when I was reading about debugger implementations. Is this meant as a full-featured debugger? If so, what's the reason for it versus gdb?
This is really good!! Debugger and good IDE are important for any language to be successful. 
I think you will find it easier to maintain your scraper with something like https://github.com/PuerkitoBio/goquery instead of using regexps to parse html.
database/sql. Dependencies are not free, just as every line of code you write is a liability, so too is every package you import. -- davecheney
Interesting blog post, would have expected at least a mention of safety though since it's possible Rust's biggest selling point.
http://golang.org/pkg/database/sql/#DB.Close &gt; It is rare to Close a DB, as the DB handle is meant to be long-lived and shared between many goroutines. 
Is the said C-&gt;Go translator available outside of Google? I would like to use it for some things, too.
[This is what](http://www.reddit.com/r/golang/comments/2lzfas/delve_is_a_go_debugger_written_in_go/clzv79z).
Would have been interesting to throw C or C++ in there as well. In fact you can do it yourself (here)[http://benchmarksgame.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=rust&amp;lang2=go&amp;data=u64q]
What did you mean, saying that &gt; a database connection is created for every request ? Are you calling `sql.Open` in your handlers?
you could try gorm http://github.com/jinzhu/gorm if you want some thing like ORM, usually you need a db package, and it will initalize the database and hold it when initalize your application.
Or https://github.com/go-xmlpath/xmlpath
Nope I call open() in the dbInit() function and assign the gorp.dbMap to a global variable which my views then use to access the database. I wrote that before I knew the main function was only called once. Edited my post.
if the code is not idiomatic, please tell me. I'm trying to learn the good way of writing Go code. thanks
We've been using gorp for a while. It was recommended by other gophers. It's not fancy, but it's been getting the job done well.
I think he's coming from the point of encapsulation. Your unexported fields in a struct are accessible from anywhere in that package. You can't really hide the internals of one struct from another without putting them in separate packages. In most OO designs, you'd generally use classes to control the visibility of private variables. If he sees classes primarily a as a way to hide implementation details behind an exposed API, then it's no wonder he sees go packages as similar because they do just that.
Don't like the name for software - sound too bug ridden. :-)
I can't talk in specifics really, but I've tried using it multiple times and it's usually been more pain than it's worth. 
I've often asked myself that as well, however the idea seems to be that those other data structures can be emulated with judicious use of channels, arrays, slices, maps and lists, so the designers of the standard library don't feel the need to bloat it with them. After coming from java, were there library is unusably huge, and there are like 3 ways to do anything, I don't blame them too much for the decision. However, it is kinda annoying to have to re-invent the wheel, or import it from 3rd party repositories, every time I need something more complex than a doubly-linked list.
Generics 3... 2... 1...
Of course not. A yellow lemon can have a hint of green but it is still a lemon and not a lime.
You should add gorp to that list.
Yeah, while I'm glad the designers have avoided Java-like bloat, it would be nice to have a few more data structures. Have the Go team written/spoken on this topic?
For instance, if you want to do breadth-first-search with a FIFO, you have already exhausted the available data structures (had to do this recently and was glad I wasn't using Go).
Set: `map[T]struct{}` Queue: `[]T` (see https://code.google.com/p/go-wiki/wiki/SliceTricks) Priority Queue, List, Ring: http://golang.org/pkg/container/
Sets are easily implemented as map[T]struct{}. Wrap it in your own type if you feel so inclined. I've done that (and implemented higher-level methods like Union, Intersect) maybe 2-3 times in 3 years of writing Go -- most of the time you just need put, get, and delete, which is what a map gives you, and the wrapper type isn't necessary. Buffered chans *are* FIFO queues. If chans don't work for you, a simple FIFO queue using slices probably takes 5 minutes to implement. If you need a priority queue, you probably want to use container/heap. I've implemented my own fancier queue data structures only once, that I can remember, and I needed special semantics that aren't likely to be found in a general purpose queue library anyway.
I disagree, though I believe there is not definite 'best answer' here. * I'm not parsing the HTML, I'm extracting very specific chunks of data. I don't care about the HTML, and I certainly don't want to parse it to get at the data I'm interested in. * While XPath and other semantic approaches are usually more human-readable than regexes, they are not completely immune to changes in the HTML, which is the biggest concern for maintenance. * Regexps are built-in and fast. Anything else means dependency on external code, and I want the library to be as compact as possible. At the end of the day either approach will present some problems, which is why APIs are so much better than scraping :) Thank you for suggestions though, goquery looks interesting.
So that you don't have a dozen incompatible implementations, most full of memory leaks, from programmers not as qualified as library writers/maintainers?
There we go!
I'm the author of the article. PsyWolf is correct, I'm talking about isolation and abstraction here. A Go struct _looks_ superficially like (e.g.) a C++ class, but it's actually closer to a C struct: it has little of the qualities of a class, beyond grouping chunks of data together. A Go package is _compiled to_ a library, but it seems to be typical to build large libraries out of many smaller packages. My point being, you could build a library out of many packages, one per "class" equivalent, and have an encapsulation somewhat similar to that found in OO languages.
Because most of the time simple implementations are sufficient (e.g. map[T]struct{}). If you want more advanced data structures, you probably also need them customized. Basically, there are N number of different ways for implementing sets/queues etc. and with different trade-offs... without obvious case for including any particular one of them. Also, given the limited amount of built-in structures it makes easier to communicate with other libraries.
I quite literally began writing some code today to interact with coinbase and this will save me some time. Many thanks!
because if you cant implement your own fifo queue or set without 'memory leaks' or bugs you should be using ruby or java or something else. ZINGGGGG!!!!
I'm perfectly capable of implementing these structures. My question wasn't out of necessity, but curiosity, as the Go standard library is, for the most part, excellent, but would be nicer to have included the same set of data structures as C++ does (or a few more, maybe).
Is there an advantage of `map[T]struct{}` over `map[T]interface{}`? I mean in terms of performance, memory or readability. Is it merely than the intention is clearer with the empty set?
 var a interface{} fmt.Println(unsafe.Sizeof(a)) // 8 var b struct{} fmt.Println(unsafe.Sizeof(b)) // 0 
I think Go is just not the right language for you. If you want a C++, Java or Scala, please don't try to find it in Go.
Cool, good to know, thanks.
In almost 5 years of programming in Go, I've been perfectly fine with what Go provided in terms of built-in data structures, i.e. structs, maps, and slices. As others have mentioned, you can use them just like sets, queues, etc., so why even attempt to build thin wrappers around them?
It's better in terms of performance and memory because a `struct{}` takes no space (at least in the gc implementation). But yes, more importantly it's better for readability and clarity of intentions because `map[T]struct{}` has only one possible value to indicate the presence of a key. map[T]struct{}: "map of T to nothing" map[T]interface{}: "map of T to anything" Some people use `map[T]bool` for sets, for convenience, but even this isn't quite a set, as there are two possible values. If you ever get a `false` into such a set, you'd run into problems. Only `map[T]struct{}` really gives you set semantics.
Russ's code is at https://code.google.com/p/rsc/source/browse/#hg%2Fc2go , although I'm not sure if there's a more up-to-date copy somewhere. 
Every Go program using your library will statically link against it, meaning the produced binary would also have to be distributed under the terms of the GPL. If that's something you want, great, but it makes the library a very poor choice for a lot of people.
&gt; Your unexported fields in a struct are accessible from anywhere in that package. You can't really hide the internals of one struct from another without putting them in separate packages. But you wrote this package, don't you trust yourself?
Interestingly, ogle was the origin of the name Go: http://golang.org/doc/faq#What_is_the_origin_of_the_name
&gt; Set: `map[T]struct{}` Not very useful if you need set operations. &gt; Queue: `[]T` I'd say channels are more fitting for a queue, you can do blocking and non-blocking reads and writes with them.
Use a `map[T]bool`, because the zero value of a missing value is `false` not `struct{}`
Thanks for dropping this here. I've had a quick look on GitHub and it looks like something that I will love :D
This is cool. Mostly because its a proper debugger and it blows [my 1-hour attempt at a browser-based debugger](https://github.com/simon-whitehead/go-debug) out of the water. I am looking forward to some better debugger support - but I seem to be going okay at the moment with tests and logs (and my debugger that steps over "breakpoints").
Thanks for the comment. I'm unfamilair with Apache Thrift - I'll take a look!
Go is an easier language to debug, so runtime race conditions will be easier to find. Go is also easier to develop, so the runtime should get better faster.
Makes a lot of sense, thanks. 
Come back when you actually know enough about your language to make a coherent argument, rather than a religious statement. There are plenty of not-stupid reasons why Go doesn't have these components in the standard library; you don't have to resort to being a language snob.
Why not Riemann?
This was developed by Matt Jibson and myself. Matt's primary background is programming, but I'm more on the OPs side. In practice that means Matt hasn't had experienced Go programmers for second eyes on the code (he reviews my code, but I can't help as much by reviewing his code). If you are an experienced Go programmer and interested in monitoring we could really use some contributors to start looking at the code. The project site is http://bosun.org , and we are hoping to get some code help with https://github.com/bosun-monitor/bosun and https://github.com/bosun-monitor/scollector . 
There's an index you can query but you can't replay events to see where events *would've* been triggered. The question is: why weren't the events triggered in the first-place?
Sorry. Day++, It's really day 3.
The example Blake provided about avoiding mux was poor. Yes he avoided the dependency, be he encoded information that mux would have hidden from the handler in the handler itself. In a larger api it would be difficult to change a path prefix as it is encoded all over the codebase. I don't know enough about mux to know what additional problems it may cause. And I'm fairly new to Go. However, I found that example really unsatisfying. I'm implementing a web api that needs to provide CORS headers. CORS is deceptively complex. It is maddening to debug when it's not working. You watch Chrome do the little options dance to get your headers. You look at the perfectly formed headers you provided. Chrome then arbitrarily decides it is not authorized to make the request. No hints as to why. When I used go-endpoints with the intention of deploying on appengine, at least CORS mysteriously started working. I still haven't figured out what was wrong with my implementation. The data I provided was remarkably similar. What I'm saying doesn't invalidate the whole talk. Avoiding importing thousands of lines of dependencies to get just 20 lines of capability isn't lost on me. 
Looks nice! I'm planning on evaluating this today for our needs and if it works, I'll add integration with [FlowDock](https://www.flowdock.com/).
You write the config and can generate a stream of events (instead of needing some pre-existing history) and test your code/config using those. I guess there could be some value in using "representative" samples, but riemann could trivially learn how to do such a trivial thing.
Done http://www.reddit.com/r/golang/comments/2lzkl4/removing_c_compilers_and_removing_c_from_package/
Looked through the polymer demos and they are ALL half broken on newest FF / Chrome setup.. not that impressive introduction.. too hypey for its own good. That being said: API interface via Go, for sure good idea :)
Design by consensus has its pros and cons, and it keeps coming up again and again in Go talks. I love Go and would hate for it to get stuck in a rut because nobody agrees on anything. If generics are added, I am sure there will be people who hate the Go implementation of them. But that shouldn't be a reason for not adding them. They really are useful and would make the language more beautiful in my opinion. Not doing something just because you cannot make everyone happy doesn't seem like a good approach.
writing this file isn't a task I'd wish on my worst enemy: https://github.com/Bowery/prompt/blob/master/ansi_windows.go
I will definitely try it out. One question, why use opentsdb instead of something like influxdb or any of the graphite options? 
I take from that FAQ that Google was the origin of the name for the language. Ogle would use the rest of the letters. Perhaps that's what you meant though.
try https://github.com/quarnster/util/tree/master/container
Any reason why you didn't opt for influxDB or graphite/carbon for storing your time series stuff?
Serious question, how is this different from the other monitoring tool written in Go and which was recently released. Not sure if they do the exact same thing, where do they differ etc? https://github.com/mperham/inspeqtor
You can write a custom type that implements driver.Valuer and db.Scanner. Here's one, for example. https://sourcegraph.com/sourcegraph.com/sourcegraph/srclib@master/.GoPackage/sourcegraph.com/sourcegraph/srclib/db_common/.def/StringSlice
InfluxDB wasn't mature enough when we started the project, both Matt and I talked to Paul at Gophercon about - but we already had a lot of code built around OpenTSBD by then. I don't ever want to roll up my data. I'm sending 15k/sec and it grows about 3GB a day unreplicated. I can do that because OpenTSDB is very space efficient. With graphite I would expect at least 3x that storage, if not more. It is designed around rollups.
Very cool, guys! We started working with Go over here at Fog Creek as well :)
I was recently thinking about creating my own injection package, because [codegangsta/inject](https://github.com/codegangsta/inject) doesn't exactly suit my needs. I don't want to create new types just to inject several ints from a URL into my handlers. I need to be able to inject by variable name too. It seems that this DI package doesn't do that, either. EDIT: sadly, it seems that the reflect package doesn't allow to get the names of function arguments.
Glad you can focus on the more interesting parts of building your application! Would love to see what you end up building! If you have any questions or requests for the library, just let me know!
As an end user, probably not a lot of difference. The Go 1 guarantee means you won't see any changes, but this refactoring is part of a general improvement in the std lib. But, as a bonus, now you know Go, you can hack on the runtime, you don't need to know C as well. 
That's what `_, ok := ...` is for
I keep this ultra simple and have an interface like this: Validate() error I implement this on any structs I receive JSON in, and have a function that decodes and validates.
I could take a stab at it if you have an example showing what you need.
Nice try. &gt; Inspeqtor is licensed under GPLv3. Inspeqtor Pro is licensed under the &gt; custom commercial license in COMM-LICENSE.
If it's so trivially trivial, perhaps it's time for Riemann to learn how to do it? It's easy to see the value of testing refinements to configuration by using your actual history instead of creating a fake series of events based on your inaccurate perception of how exactly your system behaves.
All I'm seeing is that you would just need to have a record of events and feed that back into the system. What else do you need?
It's too late to sanitize input at ORM level. The part of your application which is filling your structures should do validation. If you use encoding/* packages, you can use Marshaller/Unmarshaller interfaces for validation.
Um.... 29 lines of tests, which is just two examples? No thank you. Don't get me wrong, the functionality looks amazing.... but really, how can anyone in this day and age justify releasing code with zero tests? It really doesn't reflect well on the company promoting the code, unless it's surrounded by big warnings about this being a side project of one of its developers that is not production ready yet.
Makes sense, thank you.
Duh, that's why you release it as open source... so someone else can write boring unit tests ;).
But not as type or thread safe. That means more possible ways of runtime failures.
Thanks everyone for all your help. For now I'm just using exec.Command but in the future I'll use the winapi as that feels like a safer way to do it.
Just what I was looking for thanks!
 if _, ok := m["asdf"]; ok { // Value is present } The problem with `map[T]bool` is that it allows for this weird state: davesMap["definitely there"] = false Maybe that's not too likely to happen in practice, but I'd still advocate using `map[T]struct{}` because it can't represent redundant/bad states like that. It's similar to why Go doesn't use `int`s for boolean values.
Thing is that "Like Javascript" isn't really well defined.
That's just Google being Google. I think that web components are great technology, and that they will probably revolutionize web dev, but when working with any Google tech I think you have to expect tons of bugs and most things out-of-date. I remember how surprised I was when I first looked at Google's Android samples - pretty much none of them worked. Even where user's had submitted the needed patches Google hadn't bothered to update the samples.
I trying to make a toolkit instead, less abstraction. https://github.com/squiidz/fur
awesome. I think this will further speed up golang development
[Also check this Gorilla library that does the same.](http://www.gorillatoolkit.org/pkg/Schema)
I was thinking of something like this: injector := inject.New() injector.Map("db", DB{}) // get by name fmt.Println(injector.Get("db")) // invoke function, providing dependencies f := func(db *DB) { fmt.Println(db) } injector.Invoke(f) 
How this affects sub-repositories? Are they still golang.org/x/* ?
YEEESSSSS Im sorry but I absolutely hate google code
Hey, before there was a github, it was better than the alternative ... SourceForge. Ugh.
Yes. In retrospect it is clear that the reason for the move was in preparation for the move to github. 
I don't think it'll affect the golang.org/x/* repos. After all this is how they work at the moment: % curl golang.org/x/net | grep go-import &lt;meta name="go-import" content="golang.org/x/net hg https://code.google.com/p/go.net"&gt;
well, i guess that looking at it that way...
I prefer the issue tracker on google code, but the source browsing is much nice on github.
I found out yesterday that [Microsoft has open sourced the .NET core](http://www.wired.com/2014/11/microsoft-open-sources-net-says-will-run-linux-mac/), and moved it to [Github](https://github.com/dotnet/corefx), and today I find out Go is moving to Github. Such great news, and I have to congratulate the Github developers for making such an impressive product that everyone wants to use.
*heavy breathing* - I am pretty excited for this. I think the entire contribution process will become nicer. Time will tell I guess.
Cool, looks easy to use. Here's a similar library I wrote a while back: https://github.com/mholt/binding
Imagine how amazing the thing that replaced GitHub will be.
Back to Visual SourceSafe 6!
Nothing is wrong, it just makes the project not suitable for commercial use, contrary to bosun. One might consider /u/emmigre's comment as an argument against bosun authors, like they did not do their research first, as something they created already exists. Followed by an example of a commercial product. No, I have nothing against commercial products, just please compare apples to apples, sir.
See my response to /u/mperham. Sorry for being ironic, but you know, it's reddit.
 iter := path.Iter(xmlroot) for iter.Next() { url := iter.Node().String() log.Println(url) } This is not a general struct, but an iterator. You cannot `range` over a struct.
well, if it compiles it's probably good simply deploy and watch the logs for errors then make testcases from simplified real world samples
For me the big news are not the Github movement, but the migration to git! Awesome news!
Visual Source Safe Cloud.
&gt; For me the big news are not the Github movement, but the migration to git! Awesome news! Why? I'm asking because whenever I see news about open source projects migrating from Mercurial to Git (surprisingly, I've never seen projects migrate from Git to Mercurial), the reason is always either "because most contributors like Git more" or "because we want to migrate to GitHub", not actual technical advantages of Git over Mercurial. Yet people are so excited, as if the project has just built a full-fledged AI or something. It feels like GitHub is more like a religion than a hosting site for code. So, why is Git so much better than Mercurial?
&gt; So, why is Git so much better than Mercurial? &gt; "because most contributors like Git more" I'm pretty sure that's the reason. I'm sure there are all sorts of technical arguments, but even if git was harder to use and had worse performance if 90% of your contributors know git and 30% know mercurial it's obvious which one you'd want to use.
Whether Git is better than Mercurial is mostly a coinflip, they are very closely matched. It's just as you hinted at that there is a Github but there is no Mercurialhub. Everybody new to version control has defaulted to picking up Git for a few years now.
&gt; there is a Github but there is no Mercurialhub But isn't^BitBucket^fine^too?
gitweb?
Bitbucket is essentially "MercurialHub" but it's obviously immensely less popular and has fewer features than GitHub at this point.
&gt;if 90% of your contributors know git and 30% know mercurial But if you're migrating from Mercurial, then all your contributors know Mercurial, otherwise they couldn't have contributed anything. Or do people often send messages like "Man, I'd love to send a patch to your project, if only you used git..."?
Well, google is probably not going to be investing in improving Google Code.
Good point. I should have said "if 90% of your contributors know git **well** and 30% know Mercurial **well*".
Butbukcet is lovely for private repos. But has no free public repos like github. Thus, all my private stuff is on bitbucket and my public stuff is on github. 
[Network Effects](http://en.wikipedia.org/wiki/Network_effect) It's the same reason everyone uses Facebook and Steam despite there being (arguably) better alternatives. Having one less site/account to go to to do your job/hobby is a big convenience.
Google Code didn't receive any updates for quite a while now and does not even use the "new" Google design introduced quite a while ago (even Google Reader got that!). I guess it will be discontinued soon.
Not if GOMAXPROCS &gt; 1.