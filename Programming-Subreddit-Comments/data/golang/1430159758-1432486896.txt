Nice idea. If you want plugins for Go, just wrap net/rpc :)
if youre not using vim i think liteide is the best. 
* How does bleve compare with Lucene/ES? * Is it ready for production use? * Can it do date range queries or faceted searches and such queries?
I'm trying to understand how its different to all the other project/dependency managers.
You either make a function for each type that you want to support or implement it using interfaces and use reflection. 
I miss generics sometimes, but then write the non-generic version in lesser time and get on with my programming. :) Also https://docs.google.com/document/d/1vrAy9gMpMoS3uaVphB32uVXX4pi-HnNjkMEgyAHX4N4
Help a brother out so that he's less of an idiot in the future. I've been riding along with the impression that generics were all about reducing manual code duplication by capturing higher level patterns in a single location so they can be modified and maintained easily. My understanding was that various languages handle this in different ways. If look at how C++ handles it (compile-time code generation via templates), and how C# handles it (run-time code generation [[source](https://msdn.microsoft.com/en-us/library/f4a6ta2h.aspx)]) , it seems the generation of code at least comes into play sometimes. Furthermore it also *seems* that the Go Authors are saying that the generation of type-specialized code from a generic package is a reasonable usage of the `go generate` command ([go generate proposal](https://docs.google.com/document/d/1V03LUfjSADDooDMhe-_K59EgpTEm3V8uvQRuNMAEnjg/edit), first page *"macros: generating customized implementations given generalized packages, such as sort.Ints from ints"*). So, like I said, I would actually really like to gain a deeper understanding of your argument, but your sole supporting "fact" of "they're idiots", isn't really doing me any favors.
It completely replaces the `go` tool. Pretty different.
Oh great, I was just thinking about the empty interface, for some reason.
Your type is a slice. Of a defined structure so when you are looping over it "i" is just the index of the slice not the actual values, essentially you are dumping the the individual structures in the slice into Println. You need to delve down another level and access each field.
gb vendor &lt;package&gt; works like Go get accept it puts it into vendor/src/ as apposed to src/ It is then used as a directory to retrieve packages when doing gb build
I now use this solution that makes use of anonymous struct. &amp;struct{ http.Handler } {h}
I take that back. It looks like there is actually a race condition occurring. reqs and errors are both global variables being accessed by multiple goroutines. Instead, I would suggest keeping a set of counters for each goroutine and adding them up at the end. Could you try running `go test . -race` to run the race detector?
Nice, this made a real difference, its now getting between 2.9-3.1k responses per second which may be a limitation on the server side or a coincidence that it's similar to the non-goroutines method https://gist.github.com/vp89/1a6f67486241ec33b769 I played around with the number of goroutines and it seems to work best hitting localhost if you use runtime.NumCPU() as the number of goroutines Using more than this locally actually provides worse performance, but if you go out to the Internet then more is more .. so 20 goroutines to google.com gets me 100 responses a second while 10 gets me 50 .. for example 
Good points on 2 and 3, setting GOMAXPROCS made a real difference I did not know about this before It seems that on local I don't gain much using more goroutines than amount of cores I have, but going out to the Internet you benefit from using more goroutines
Happy to help. Like I said, the time the goroutine can sleep while waiting for io will determine the optimal amount. The effectively 0ms latency to localhost penalizes many goroutines while the high latency to the internet has a much higher ceiling thanks to the &gt;100ms latency. As an aside, sync/atomic is probably a package you'd want to avoid in production code. Higher level primitives or a different strategy that doesn't require atomicity would be preferred.
&gt; For an installed application you'd typically have some well-defined location to store your files. On install you'd extract everything to that location. &gt; Or pass in the path as an env var, flag or config file. Can fall back to a default "same directory" as well for simplicity during testing.
If you go for one gopath per project, why not put the whole gopath in git? You would have a reproductible build for free. Is it because it does not work well with github? Perhaps there is an obvious reason, but I'm always suprised it's never discussed.
hmm, interesting. But i think i'll stick with my custom Gom replacement.
Personally I just tend to use http://goconvey.co/ even with normal tests
I pushed an updated library which can either index by prefixes or by full terms (and use ZRANGEBYLEX for queries). thanks for help!
That's likely because you're not I/O bound when hitting localhost, whilst over the internet your goroutines spend more time waiting for I/O and you benefit from having more requests in parallel. You should also find a better way to not have the last loop in main() burn CPU.
Deferpanic.com It is kinda new but they are making good progress. 
Can you elaborate on avoiding sync/atomic? Is it just slow?
Note that this "wrapper" technique will allow you to use incomparable types in map keys however if you wrap the same value twice it will act as two different keys in the map. In this case, the same HandlerFunc could appear many times in the same map's keys. I ran into this problem when I wanted to create a "set" of functions in Go. My solution was less than satisfying, use a comparable type as the map key. For example, pick a unique string for every function you will use, maybe pair the two in a struct, use the string as the map key. Though this worked for my use case, it was still less than satisfying. I still haven't found a compelling way to create a "set" of functions in Go. I welcome suggestions. 
Having some experience [parsing go test output](https://github.com/smartystreets/goconvey/tree/master/web/server/parser), I wouldn't go that far...
Oh yeah. Right. I was thinking about the duration of the test for some reason.
Yeah, I think I will comment on the mailing lists. Every time I try to get through the contribution guidelines/processes I find myself wishing I could just submit a pull request on the github repo. #lazy
Yeah, I'm somewhat partial to that project as well :)
Gotcha.
 fmt.Printf("%+v\n", data) would output key:value pairs
what you want is to run the output through `text/tabwriter` no?
"404 Not Found"
Sort of, except the go test output uses spaces, not tabs so I don't think text/tabwriter would do the trick here, but that's the idea yes.
In this instance the GC can prove that there are no references between it and the rest of the application and it makes no calls to any "impure" functions such as a file write or syscall or runtime. You are right to say that the goroutines are cooperative in the way they multitask, however, things like channel reads are one of the locations the goroutines will yield. I don't have to show that the go routine has halted, but I can show that whatever it is doing has no affect on the rest of the world. If i can show that it is equivalently a NOP then I can collect it.
First of all, it will make your life easier to not think in "methods" go has functions not methods. You can have your function take in an interface. https://godoc.org/golang.org/x/tools/go/types#Type This allows your function to take in any struct. edit: Said Type meant empty interface "interface{}" Maybe like this: http://play.golang.org/p/Sad8Y1Ibd7
Why do people have such a problem with code generation? Even in C++ shops, code generation is often preferred to templates (which really is just shitty, limited code generation) ... Mike Acton talking about it: https://youtu.be/rX0ItVEVjHc?t=1h11m17s In regards to unused errors and so forth, it is a trade-off that absolutely slows development (depending on development style and editor nimbleness), but improves long term maintenance. It is nice when after some refactor you realize you no longer need those 3 variables because they are no longer used anywhere. It is long-term anti-cruft. 
I suppose my response to /u/nw0428 is also applicable here too. Gotta get out of OOP -- thanks! 
It seems like a lot of people are very quick to resort to using `interface{}`, and then complain about it. I don't think that in all of my programming I've used `interface{}` as often as some people do in posts like this. Edit: for example, his DrawShape program: why type Quit struct{} type DrawLine struct { color Color a Point b Point } type DrawTriangle struct { color Color fill Color a Point b Point c Point } type SetBackground struct { color Color } and not something like type Drawer interface { Draw(Canvas) error } type Triangle struct { color, fill Color a, b, c Point } func (t *Triangle) Draw(c Canvas) error { // ... } Then you could just do func paintingLoop(ch chan Drawer) { // shorthand for a loop over receiving over // a channel for msg := range ch { if err := msg.Draw(c); err != nil { // handle err } } }
I didn't say it's bad to generate code, but rather that having to write code generators for simple functionality (i.e. generics) reflects poorly on the language. I don't come from a C++ background, so I can't state how it's done there. There are tons of different languages however (C#, Scala, Rust), and I doubt any of those generate code like C++. Also, I'm fine with very annoying compiler warnings. But compile errors for unused imports is a no-no. It's a trade-off I simply don't consider "worth it", but opinions might differ.
And even then you don't need a `Quit` type. Just close the channel.
True. I absolutely know to value those keywords / features, all I'm saying that it is great if those (or similar) features are in the core libraries - which facilitates for learning how to do it, instead of implemented into the language, giving the developer a hard time of writing similar stuff. A language I like to take for reference is Ruby. 99% of Ruby and its "keywords" are defined as actual methods, not as magic like `go` or `select`. For instance, `block_given?`, an expression which I believed to be a keyword for a long time, turned out to be a [function](http://apidock.com/ruby/Kernel/block_given%3F) and it really stunned me. I like Go and am currently using it for a private project, I only have a difference of opinion concerning some design choices.
That is not equivalent to Rust enums. That is more like Java enums, witch is very different from Rust.
Usually you would just close the channel instead of sending a sentinel value down it, so the Quit message isn't something that I'd keep either. If we really wanted to support multiple drawing engines, maybe Canvas would itself just be another interface, or you could even just have two pipelines. It's easy to contrive a situation for which a given example doesn't work, but I think that for most situations, you can solve the problem without resorting to sending `interface{}` everywhere.
The Quit was just an example. The idea from what I got from the post was the concept of sending actions to the engine. Instead of Quit, it could be, duplicate Window, CloseActiveWindow, SelectNextWindow, etc... not all MyMessage means the same type of functionality. Regarding the multiple drawing engine, yes, the solution would be the best option. &gt; you can solve the problem without resorting to sending interface{} everywhere. I agree with you. That is why I started mentioning your reasoning is valid, just thought that the example didn't describe the same scenario.
I thought this was a fair and well written article. Given the author's background I wasn't surprised that the general conclusion was that Go had some nice features but didn't give the author the control they needed. Im sure if I were to write this type of article I'd praise rust for the ownership system but probably conclude that the language is too complex for my taste. 
Correct. A project is defined as the parent of any directory called `src`. 
Ah, I see.
&gt; Also, I'm fine with very annoying compiler warnings. But compile errors for unused imports is a no-no. It's a trade-off I simply don't consider "worth it", but opinions might differ. Yeah, it is completely worth it from my perspective, having worked on old crusty codebases with thousands (or tens of thousands) of warnings. The problem is once you get sufficiently behind that it becomes daunting, they just become noise because no one will ever go through and fix them. A lot of Go feels informed by long term maintenance of C++ code. 
Yeah, I think this might have been one of those things where the idiomatic way to do it is pretty much reversed in each language.
Everything is being downloaded as .gz lol
https://github.com/elazarl/gosloppy
I dont get the downvotes - seems like a well reasoned opinion...
Well, I run [goimports](http://godoc.org/golang.org/x/tools/cmd/goimports) after file save. From docs: &gt; Command goimports updates your Go import lines, adding missing ones and removing unreferenced ones.
When you try Rust in Go, it's going to be ugly. And you realize that. Now it would be even nicer if you just say that rather than painting it as if this was a flaw in Go in your post.
I have to say the go imports and unused variables thing is very annoying, especially when you first start learning the language. 
 Is there an implementation of http.RoundTripper that uses the tor network? That would be awesome. 
Hi, loved your article. Quick question: What does the Twitter comment with `[path="/proc/self/fd/0"]` actually do? Could you run it down for me? Thanks!
That was me, and the tutorial is [here](https://github.com/eightyeight/haskell-simple-concurrency), though since I originally wrote it, I've revised it to be less of a direct translation of Go by Example, and more focused on just teaching Haskell's concurrency 'primitives', which seems like a more helpful goal. I admired the unopinionnated and factual tone of GbE, so it didn't make much sense to write a translation that was a direct comparison to another language, if that made sense, though I attempted to keep it factual as well. The version with the 'composable select' you're referring to is [circa this commit](https://github.com/eightyeight/haskell-simple-concurrency/blob/811e2747881ac080b2275f239a1e784d242139b5/src/tutorial.md), and [here](https://github.com/eightyeight/haskell-simple-concurrency/blob/811e2747881ac080b2275f239a1e784d242139b5/src/tutorial.md#composable-select) is the section in question. Since writing the tutorial, I've come to appreciate that `select` in Go works differently to my initial impression, and is also used very differently from the one I implemented. My Haskell version must select over `MVar`s of the same result type, whereas Go allows you to select over a variety of channel types. I'm sure I could define something appropriate in Haskell with some type wizardry, but I wouldn't actually bother. As [this commenter](http://www.reddit.com/r/haskell/comments/30hh4z/simple_concurrency_in_haskell_a_translation_of_go/cpt5grn) noted when I shared my tutorial in /r/haskell, many features like Go's select just aren't meaningful in Haskell because we have different idioms, culture, and primitives. That said, one of the reasons I stick with Haskell, despite sometimes running into tooling, library or performance issues, is because the core language is powerful enough that I know it won't become outdated for a very long time. Yes, there's a lot of complexity and a lot to learn, but I won't need to learn a new language when Go's channel-based concurrency turns out not to be the way of the future, and we all use hardware STM instead. (This is a facetious example, I know the two are almost unrelated, but I was trying to make a point.) So I do agree with your preference for having features in libraries, rather than baked into the language. But still, as I [began to wonder](http://www.reddit.com/r/haskell/comments/30hh4z/simple_concurrency_in_haskell_a_translation_of_go/cq7c7rz) in the other thread - Haskell has plenty of stuff 'baked into the compiler', like `forkIO` (the Haskell version of `go`, essentially) and STM.
Stop using it like one. If you're using interface{} everywhere, of course it gets messy.
It imports a module named "input" from the path /proc/self/fd/0. On some Unix systems (most Linuxes, I think FreeBSD), opening /proc/self/fd/0 will get you stdin, so if you actually tried to compile it with rustc, the compiler would wait for you to type in the module.
Github is a pretty garbage place to do a real code review for such a serious project. The song and dance of contribution guidelines is just to keep people honest and accountable. I like to frame it as: If you're not willing to fight for your change, is it really that important?
Oh, I was missing Dapper-like tool for Go badly. Looks really great. Thanks guys!
Looks great. But why can't I have a $10/month option that gives me alerts &amp; some basic retention? For a startapp app that has very limited funding, $50 a month right off the bat is painful. But what's the point of a service like this if there's no alerts? I may as well build my own (very basic) system.
Wow, that's cool one!
Do you ever have other teams ask you for guidance or hands-on help with their projects? 
&gt; The problem is once you get sufficiently behind that it becomes daunting, they just become noise because no one will ever go through and fix them. I am in exactly this position right now... it's so dispiriting...
Iirc they are checked but go's and c# are not. Meaning they are faster.
Thank you. Its still not complete but its under heavy development. Stay tuned..
I wasn't even talking about go generate. I was talking about code generation, which can be done with go generate but doesn't need to be. In C++ codebases I worked on -- our code generation was in Perl. We would commit the outcome of code-generator to our revision control system, so really only the person introducing the change had to run "perl foo" (or "go generate"). As for "ridiculous solutions"... code generation is exceptionally pragmatic and has been used for decades. It isn't sexy, it isn't a language feature, but it is a solution to a problem. It might offend delicate sensibilities of some, and not be as clean a solution as others want -- but it is brutally pragmatic and works. 
One point no one seems to have brought up yet is that the pain of renaming symbols across files can be hugely reduced by using gofmt or gorename.
No offence taken at all! I am indeed some guy.
Zeus is a language neutral IDE with support for the Go language: http://www.zeusedit.com/go.html **NOTE:** Zeus is shareware, runs natively on Windows and runs on Linux and Mac OSX using Wine. There is also a free *Zeus Lite* version. *Jussi Jumppanen* *Author: Zeus IDE* 
I didn't know what hexagonal architecture was, so for anyone else curious: [c2 wiki](http://c2.com/cgi/wiki?HexagonalArchitecture) [a blog post] (http://alistair.cockburn.us/Hexagonal+architecture) 
I'm sure it can be done better, but our C++ code generation is an absolute bear to change, and it needs to be hooked into our build process. I find templates to be a simpler alternative. The compile errors suck to debug, but it's not significantly easier with code generation. I suspect templates also compile faster. We use code generation because we're coupled to Qt, which dislikes templates--I'm genuinely curious why else someone would prefer code generation to templates.
This is fairly easy to do, though depending on how many different configurations you want to handle, and how sophisticated you want to be it can get tedious and or annoying. Something basic that will work with Tor Browser's tor instance would be: https://gist.github.com/Yawning/bac58e08a05fc378a8cc The meek transport is written in Go as well. At this point I'm not sure if I'll continue to use Go when writing these, it was the pragmatic choice at the time, but time will tell when obfs5 happens.
&gt; and it needs to be hooked into our build process Yours is very different than ours was then, ours specifically was never allowed to be a part of the build process. If you added a new SuperWidget, you would generate the support files for your SuperWidget and check it into version control. If someone updates SuperWidget in such a way that it needs to have the code-gen rerun, they would rerun it. Tests would be the gatekeepers to ensure this happens. &gt; I find templates to be a simpler alternative. The nice thing about code-gen is clean code is output that you can just debug, if it has an assert fail, it is in vanilla language constructs. It is just C++ code, and how you generate it is up to you, there are thousands of wonderful template systems, pick your favorite. &gt; I suspect templates also compile faster. What, no, god no, no... what... Templates are a major part of why C++ build times are hell on earth (use STL and Boost, enjoy your wait) -- remember, templates aren't really even C++. Templates are a different language that is building C++ source files, same as using language X. They are just a goddamn slow to build and awful one. Additionally, as I said, we didn't do our code-gen as a part of the build process, so at build time, it is just C++, the generation is part of the dev-cycle. &gt; I'm genuinely curious why else someone would prefer code generation to templates. To summarize, (1) horrible to debug, (2) they are horrifically slow to compile, (3) they are a different language that compiles into C++, and a terrible one at that... never intended for the metaprogramming tasks they are shoehorned into, (4) they are limited or painful to use to do real interesting stuff, give me a real language or one designed to generate code like python cheetah, (5) ... various other things, lack of type constraints, crippled value parameters, precompiled header hell, and I am sure I could think of a bunch more, but I am not using C++ day to day right now, so my rage isn't as high as it would normally be. 
How did you manage only ever having 512 pointers?
Do you have an example of Redis-like usage? (Ie. having having a key-value store accessible via network.)
I don't know much about GC in general, is the GC overhead really only induced by having too many pointers ?
Cheers.. I was about to search myself, but then you saved the day! 
&gt; At this point I'm not sure if I'll continue to use Go when writing these, it was the pragmatic choice at the time Why are you not sure ? Why don't you want to continue ? 
Thanks, that seems be to nice idea to validate and test both. Will try this out. btw what RPC library is being used, any pointers? I heard about gRpc which uses Google's Protobuffer.
Think thrice before going ahead with "microservice" ideology, make sure you read the pros and cons throughly. Go's native rpc implementation is more than adequate for building distributed serviced. You usually do not need to rely on any third party rpc implementations, unless there is an interoperability requirement. 
What's the performance like? Any benchmark results/comparisons? 
I haven't used gRpc, but it seems like a fine choice if you want to be able to communicate with this service from different languages. If all of your services are in go, then the standard library has http://golang.org/pkg/net/rpc/ which is uses a go specific binary message format called gob under the hood. Gob was designed by the go team as a response to some of the issues they had with google's protobuffer when building the go implementation of them. You can read more about it here http://blog.golang.org/gobs-of-data
Not yet. But I added benchmark tests for indexing and searching in both methods. The prefixes indexing method is significantly slower in a 100000 documents index where the ZRANGEBYLEX method remains with the same performance. 
A vtable dispatch is an indirection through a table. Using a jump table is also the preferred way to implement a switch/match statement; if the switch/match statement is compiled down to an if/else chain, is going to be even slower than a vtable dispatch most of the time. What you want is to execute different code depending on the type of the object; the vtable does exactly that, and in the most efficient way. A switch statement can be just as fast, or much slower, depending on how it is implemented.
It's about 500ns per operation. I'll add benchmark code later.
The other factor is creating objects too fast, but short lived object will be garbage collected instantly, the overhead is trivial compares to long lived objects.
Verbatim from the README: Bowtie borrows liberally—both in ideas and in code—from several other Go frameworks. Adopting httprouter as the default seemed like a good idea, given its raw speed. The only changes made were integrating Julien Schmidt's code with Bowtie's context-based execution, and allowing multiple handlers to be attached to a particular route. Bowtie was also inspired by Go-Martini's simplicity and immediateness. Even though Martini's design is not idiomatic to Go, it is perhaps one of the easiest frameworks to pick up and use. In addition to adopting bits of its code, Bowtie strives for the same kind of approachable and immediateness. Finally, the idea of a running context is borrowed from gin-gonic. The main difference between the two is that Bowtie forces the use of Go interface for carrying custom information through the context, whereas Gin allows you to append arbitrary data to it. This seemed like a more sensible approach that allows Go to do its job by providing type security and strictness. Bowtie's error management comes from my personal fixation with safety. I don't want to leak information, and I don't want developers to worry about whether they will.
This is interesting, i've been using boltdb on SSD to cache local things. I'll definitely give this a spin. 
Check out github.com/go-redis/redis. 
Nothing wrong with having a load balancer for RPC, but I can imagine you could get just as much flexibility without the overhead by having the clients "subscribe" to routing info from the "load balance publisher". When any routing needs to change, the publisher will push the new routes to any subscribers that were affected. Then the actual requests need not hop through the load balancer directly, but you have a single microservice managing the routing.
We have apps written in Node.js, Ruby and Go. We'd need a library for each of those, both in the client and the server. Frontends that talk to microservices from the browser would need to be proxied by something which has this client (as opposed to today, where they just talk to HAProxy). The logic isn't the problem, it's just something you'd have to reimplement for each language, and maintain. Every time you update this library, three times, you also have to update every single client and server app. We have 20+ microservices and frontends, and the number is growing fast.
Services and RPC usually don't go together, it's not the best way to make use of HTTP. Do you actually mean RPC when you say RPC?
Actually Consul does handle routing traffic away from unhealthy instances when you use its DNS for discovery. That's kind of one of it's main features.
So I may have gone on a small research spree and I figured I'd share. It turns out that consul has a rich [HTTP api](https://www.consul.io/docs/agent/http.html) that has health info and can support the pub/sub model I mentioned, **plus** it [plays nicely with HAProxy](https://hashicorp.com/blog/haproxy-with-consul.html) so you can leave much of your infrastructure as is and only bypass your load balancer where you really need that extra juice. Did I mention the http API has existing client libraries for all your languages: * [go](https://github.com/hashicorp/consul/tree/master/api) * [ruby](https://github.com/xaviershay/consul-client) * [node.js](https://github.com/silas/node-consul) So the amount of code you'd need to personally maintain would probably be limited to the interface between your infrastructure and these existing APIs. Admittedly, you would still need to maintain the more complex architecture in general. *Disclaimer: I've never used any of this software personally, and you're probably better off sticking with a simple load balancer as long as it works for you. It looks like you have a relatively smooth upgrade path if you ever want to make the switch.*
(shameless plug) Also you can try [gosloppy](https://github.com/elazarl/gosloppy), which can sloppily compile your package, but it still won't be go-gettable until all unused imports/vars are gone. 
Thanks a lot, this is very informative, specially the auth part. Only reason i added to have separate place as every service need to make sure auth is validated so every service will first call auth and then do the task or may be my main server first wait for auth to validate and then call other services to do their task. My main concern is speed as if i add DNS then i need to do one extra step of routing through DNS to go to access service. But surly this will be helpful as load on service increases and i need to add extra layer to do load balancing on different service instances. My main question here is that do people use such thing in real world application, is this fast enough to take the trade of over monolithic design?
Thanks for providing details for it. Will read about these RPC libraries. yes motivation behind using gRPC was to make it flexible for adding different language support so in case we need to use some different language for some specific task, but go should be fine as per current understanding.
I am building a microservice system and for communication I use RPC over RabbitMQ. A simple example can be show here, https://www.rabbitmq.com/tutorials/tutorial-six-ruby.html . What is your thoughts of that? That way I can scale and buffer calls easily. Using for example Go's standard RPC lib I might potentially hit back pressures etc?
I've seen it done where you switch on the type of the `http.HandlerFunc`, and have a few different options. So if the parameters specify a database, it gets one. If they require params, they get it. But there's something very appealing about hiding that implementation detail inside the normal `http.HandlerFunc`, especially as things change.
Really the backend of a web-based game isn't all that performance critical- all the heavy lifting is being done by the client.
Yes, we both are on same page. We can use both approaches, both are fine. I read everywhere people use RPC instead of message queue for response needed tasks, may be it is fast, can not say as never worked on queue system of RabbitMQ (we can ask others in subreddit). But definitely you need to do extra processing to identify what response is one needed by your specific call. Every extra processing takes its own cost and we need to minimize it. Even i am not sure RPC is best way but people recommended it, which is a tradeoff to make system scalable.
For real-time multiplayer games with server-side logic like, say, Destiny or Diablo3, performance will be important and I'd recommend Go (this is usually done with C++ or Java, AirMech for example uses Go). For games with less strict requirements, like most social, turn-based and/or asynchronous mobile games, either is fine (as would also Python, Ruby, etc).
@coocood can u give some source material where its explained why 512 is the number here? this project inspired me to learn about go internals, but its hard to just jump in without any introduction ;)
It use 512 pointers because the data is divided into 256 segments, each segment use two pointers to manage the data, one is lookup index, the other one is the data buffer.
Wrote servers in Node for 3 years. Been in Go now for 1 year. Go is much nicer to work. I bet about 9 times out of 10, your code will be cleaner and more correct in Go. Also agree with @koffiezet, packets traverse networks in milliseconds, where GC happens in microseconds. In most cases, you can forget about GC.
The key difference for a web-based game, is that it is quite nice to be able to share much of the routines/logic between client and server with the same code-base. Depending on the kind of game we're talking about, this can be a significant time savings. But in general I agree that Go is much clearner.
I am starter in Go but working in game development. I would suggest as Go learning curve is not high and it can solve all your problems. Best part is its inherent threading support which helps you set tasks in parallel (depends on cores). It mainly depends on kind of game you are planing to build, for non-real time games your server won't be heavy so it would be ok. To make real time games, RPC will be used for which there are many libraries available, so Go will do all what you need. GC won't be much of a issue which can hamper your performance. I would suggest to do most of heavy lifting on client side and keep sever as simple as possible which will help you on scaling. Security can be handled with both included.
In the past I've used goamz for SQS was decent success, but the amount of forks is dizzying. This is especially frustrating if you are using multiple AWS services and have to pull in services from different goamz forks based on the specific service features. I'm hoping aws-sdk-go will stabilize soon.
That's not actually embedded (it's just a func() with a named field), but embedding a function is still possible: https://play.golang.org/p/iEQFTq565i
This code is certainly valid and resembles idiomatic Go. With such a short example, it's hard to get things wrong. But be assured, this looks very reasonable. That being said, the `defer conn.Close()` could probably just be replaced by `conn.Close()`. You're not using `conn` beyond that point, so you can just close it immediately. 
Great, thanks for the quick reply. And thanks for the advice regarding conn.Close vs defer conn.Close(), I hadn't considered that.
Unless you care about people cheating, in which case you need to have most of the multiplayer game engine logic running on the server.
Microservices are probably a good idea for a large organization with lots of moving parts (think of Amazon for example) but for most projects a well designed monolithic approach will scale just fine. There's no such thing as a free lunch and microservices introduce a ton of complexity (database partitioning, latency etc) you really don't want to deal with at the beginning. 
As well as the answers here, it's probably worth implementing the formatting through using the stringer interface https://golang.org/pkg/fmt/#Stringer (Provided you've learnt about interfaces that is)
Doesn't mean you have to make it easy for them. Or not even put up a barrier.
I've also tried to do something in that way. Although I liked that everything around Websockets and HTTP came out of the box, it did lack of the generics you would want to have. In games you mostly play against other Players (Which is fine to abstract in the code) and NPCs. NPCs are hard in my opinion. NPCs should be able to do what a player can do, but still be distinguishable in the code. There could also be objects in the game players and NPCs can interact with. Again if the objects are somehow placed in the game they should have something in common with others, like their current location, which would have to be implemented for every structure in the game including Player and NPC. NPCs can be quest givers, and objects too (Depends of your game design). You would have to implement their behaviour twice, which would be tedious. So IMHO I think that Go is not the language for game development.
I do that in my test files: https://github.com/pierrre/imageserver/blob/master/server_test.go#L10
Yes many organizations use a service oriented architecture. I've seen both the queueing approach with kafka (where each service has a queue between it and the next service downstream), and the direct call approach. (service A makes an RPC call to service B) You can scale a service the same way you scale a web application. Create more instances and use a load balancer, or round-robin a pool of servers: # config.yaml auth_servers: - 1.2.3.4 - 5.6.7.8 As for DNS, you can use caching to alleviate some of the load (that's probably already going to happen anyway), but ideally you should maintain a pool of connections in your app and re-use them. So the actually # of DNS queries ends up being pretty small. (Service A connects to be service B, makes an RPC request, then puts the connection in an idle pool. When it needs to make another request, it just re-uses the previous connection.) There are two types of scaling at play here: scaling in terms of requests/sec, and scaling in terms of your team. A service oriented architecture can help with both problems, but in my opinion it's the latter that makes it essential. When a whole team ends up working on a single monolothic rails app you end up with lots of headaches.
I thought Node was awesome until I started learning Go. Now I really can't think of a reason to use Node/iojs over Go... 
It's a string because the interpretation of the value is defined by the implementation and not the language. 
It's based on Atom's core so porting the existing plugins and gocode support should be easy for the community to take care of. 
Exactly. The last component of the path name does not actually need to equal the imported package name (though it usually is the same).
I've just been through all of this at work lately. Found that the os library has issues like this but sending signals through the methods in the syscall library worked just fine. On mobile atm so I don't have perfect code examples, but the code I went with was along the lines of syscall.Kill(childpid, syscall.SIGINT)
This allows you test in a local package that you satisfy a type rather than at a global level.
I rarely need this because I usually have a constructor function something like: func NewThing() MyInterface{ return &amp;myImpl{} } That will enforce that `*myImpl` statisfies `MyInterface`. Rarely do I need the odd hack thing to guarantee it, because somewhere in my code something tries to use the concrete type as an instance of the interface.
great writeup, fun to read 
Thanks!
In shorter terms, it avoids ambiguity in the grammar. 
In a library, the library creator writes a context impl. with unexported struct. type secretContext struct { bowtie.Context } func Middleware(yourCtx bowtie.Context) Handler { yourCtx.ServeHTTP(&amp;secretContext{Context: yourCtx}) } Now in your handler, you cannot do `context.(*MyContext)` because that middleware swaps your custom context with a secret context. Even if that secret context is exported, it is still bad to assert context.(*lib.SecretContext). 
Thanks much! I fancy myself an amateur writer/humorist, and it's nice when I can mesh my passions together. :)
Does Go really fit into Visual Studio? I guess for Windows devs it may be nice. But anyone doing server work means VS kinda sucks.. M
Well, I think the best answer (for you) is : Go try both! For me, I use Go for systems stuff, and Node for stateless services and web stuff. But I'm using Go for more and more services and Node just for web stuff. Eventually, I'll probably just be using Go.
You can scale go much better and it is simple. 
I was in a similar position, go go and you won't ever go back!
I was going to say that with Node you don't have to worry about memory synchronization but that's not entirely true all of the time, even though Node is single-threaded.
Yes, if you need to complement your thick glasses, scarf, starbucks coffee and macbook pro while looking like you're doing something useful.
No, there is no reason.
Go will offer you a superior development experience.
This is about [VS Code](https://code.visualstudio.com/), the new cross-platform text editor. My experience with the "real" Visual Studio wasn't good either, but this one looks and feels nice. I'm never abandoning vim though.
I would only chose node/iojs if there were some existing domain specific JS library that I could leverage by putting a thin web shim on top of it and that would be very difficult and time consuming to port to Go. Even then, I'd try to contain that to as small a microservice as possible and build the rest of the system in a better language. Other people seem to choose node because they already know JS, like it, and want to get something running without learning a new language for the server side. Fair enough.
Here is a github repo that gives an example of go server side rendering: https://github.com/olebedev/go-react-example
I agree
It seems most interesting solution so far. I definitely give it a try.
For what purpose? What does VSC bring to the table?
Node developer here. I would use node for web apps. Express is great, the stream pattern is insanely useful, ecosystem is vibrant. Add in promises, generators or use highland.js to avoid callback hell and node may become fun and fast to code in. 
I'm with you there, because even on Windows, I have 5 text editors that all do the same thing, and it depends on my mood of the day which one I use, defaulting to Vim most of the time. I'm sure Mono developers like it though for work on all platforms. Booting up Xamaerian, or Visual Studio could take a while, and is usually resource heavy 
This a [great insight](http://www.reddit.com/r/programming/comments/32jn2a/gotchas_from_two_years_with_node/cqc2hq5) about Nodejs true nature that one should consider commented by u/jerf &gt; Node is fundamentally cooperatively multitasking. We got rid of cooperative multitasking decades ago in our OSes, and apparently we raised a generation of programmers so unaware of the issues that not only did they embrace a cooperatively-multitasking environment on their server, of all places, they actually thought the cooperative multitasking was a feature and some sort of step forward.Further, observe this is not some sort of political statement or something that can be dismissed with more rhetoric. This is simply a truth... Node is cooperatively multitasking. Cooperative multitasking has serious, extremely-well-known problems with tasks causing other tasks to have resource starvation. It turns out these people hit those problems. These problems are really, really hard to solve in a cooperatively-multitasking environment... you can mitigate them but you can not solve them. We know this because trying to mitigate the issues with cooperative multitasking is not some sort of new computer science problem that just emerged in this brave new Node world for the first time ever, but something that entire major programming communities grappled with for decades without ever solving, including but not limited to the entire Apple programming community prior to OS X, which I'll remind you is properly pronounced "OS Ten", as in, 9 entire major versions preceding that with people trying to deal with this problem. The shocking thing is not that there are very solid, time-tested reasons to think carefully about Node... the shocking thing is that these reasons are considered "controversial". &gt; Node is a technology stack based on a language originally designed to animate things when a button was clicked (and I'll remind you, that's also not slander, that really is the origin of Javascript) that developed into a very well-understand dynamic scripting language with well-understood issues, using very old software techniques that have problems that are very, very well understood. The fact that these problems are in fact very well understood means that you may still find use cases where you can use this tech... "well-understood problems" is actually a good thing!... provided you do in fact understand them, which can not be done by trying to go up to the code and argue it out of having these problems, much less trying to argue them out of existence by debating with people.(It is so weird to me watching people trying to defend Node on this point. It's not like when Rust comes out with a new feature and people dismiss it with "Oh, someone wrote a paper on that in the late 1960s and implemented it in some obscure Lisp variant that died, so p'shaw on your claims of newness"... the Node scheduling paradigm was one of the dominant mainstream schedulers for decades at a time. It's not news! It's not something we have to wonder about what could possibly happen... we just open the history book, and there it is.) The OP post on this thread also have some of the gotchas and why the OP change from Node to Go
I've used both a little. I've made a url shortener in iojs, and played some with Go (haven't had much time this semester :/) Anyway, Go has a much better coding experience (code completion is great for shitty programmers like me :p) Sure TypeScript is a thing, but then it's still JS in the end. The thing about Go is it's compiled. ONE binary to deploy. It's also faster, which can make a big difference with large-scale deployments.
Source? That is unfortunate if it's true. But surely it would get better in the future right?
Why not just use something like [React with Go?](https://github.com/olebedev/go-react-example)
If I was at a hackathon or writing a prototype, I'd probably use node.js because it's easy to bang something out quickly and there are tonnes of packages.
Node/iojs definitely has a much larger web-ecosystem. But you can use something like React with Go. Something I don't like about JS is how there is a new framework every other day. Node is great, don't get me wrong. But as someone who is still in the learning phase, Go seems like a better language in general. Hopefully Go will get some good web frameworks though...
From what I can see, you're right. But you could always mix [React with Go](https://github.com/olebedev/go-react-example)
Correct, and that's the way it should work. The struct that encapsulates the custom context is an implementation detail, and *should* remain private. Instead, the middleware ought to expose any functionality it adds by providing its own *public* interface with well-defined methods. That the fact that `sercretContext` is package-private doesn't prevent consumers from attempting to cast it to any interface, so effectively the lib that implements `secretContext` has no effect on the overall functionality of the middleware other than hiding itself from its consumers (which is perhaps kinda pointless). 
Keep calm and leave javascript for the browser.
If you're encoding/decoding known types there are faster ways to use json. Go's code generation tools make it easy to construct packages like https://github.com/pquerna/ffjson which are 2x-3x faster than using reflect. There are other serialization options that are even faster depending on your use case: https://github.com/alecthomas/go_serialization_benchmarks
&gt; PayPal and Netflix are pretty big. I was referring to the isomorphic feature. Yes node.js is large-scale ready itself.
Agreed, sorry, wasn't meaning to imply your choice was simplistic :) Well, performance is super-complex. Personally, I focus on time-to-deliver the project, then I optimize. But it's good to know *you can optimize*, and I'd say Go is better for that.
I think they are joking that Node is vogue, and hipster types are stereotyped to do all those things. *edit* I think I took you way too literally. Just got out of a long meeting about boring things. My apologies.
Promises definitely decrease that feeling, but those can still lead to really hard to read stuff that just have promises for no real reason. It is nice to *at least* have it read better without needing to jump around so much (when done well).
Time-to-deliver is certainly an important factor. But with personal projects you have a lot more flexibility, which is the situation I'm in. I currently have a url shortener in "production" at work which is using iojs. It works and all, but I really want to rewrite it in Go, especially since Go is much faster. That and my callback mess makes me feel disgusted :p Go's easy concurrency and parallelism is really cool to me. Being able to spawn a goroutine for every request and have concurrency without callbacks is awesome. Oh and don't forget.... SINGLE BINARY to deploy! Being able to go back to deploying a binary after messing with scripting languages and things like Java is really refreshing. At first Go seemed really lame to me after getting used to OO in C#. But after learning some node OO doesn't seem quite as important.. 
Your code is fine. As soon as you post code on reddit, people descend on it looking for minor flaws in order to assert themselves. 
I could see where that could be the interpretation, arguably Go could be considered more hipster, but not sure I want to go down that rabbit hole of labeling things just to do it. Go is great, node has uses as well. I personally prefer statically typed back ends, though I do have a Node server up so others in my small organization can contribute.
Just want to mention one of my favorite tools for testing, [go tool cover](https://blog.golang.org/cover). Very easy to use and easy to see understand presentation; it has helped me a lot.
Ahhhh, well yeah, for personal projects, do whatever seems interesting :) As an "old timer" (does 2 decades of programming make you an old timer? I feel like one), I will say that I was gung-ho about OO and used to be a bit of a bigot about objects in general. Age and wisdom have taught me that everything has it's place, and very few things are universal, so I totally agree that OO isn't as important as others may tell you.
I think talking about development is the real enemy of development. This kind of religion wars, like OOP vs functional, are funny, but they are a bit parasitic. When I started with IT we had Fortran77 Cobol and some ansi c. And we had good software, too. I think people should spend more time writing good software and less discussing about the paradigm... 
I think people should spend more time in writing good code, and less to discuss about coding. 
That said, OO can definitely be good for something. But as you say, there is no one size fits all in programming. 
Interpreted languages are usually slower in general. So an optimized Go app will be faster than an optimized Node app. When you have a choice in what language you're going to learn and use, why not go with the one that can go faster when optimized without too much extra dev time? In addition, deployment is easier because you can build a single binary with Go. With iojs you need to also maintain the iojs version. Granted, Docker mitigates this issue. But being able to deploy a single binary is a lot easier and better IMO. I'm not saying "everyone ever should use Go." I just think if you have a choice and no reservations for either language, Go is better. 
My perspective as someone who isn't wild about Go, and writes server-side JavaScript most days: No. Hell no. If you can use Go, you'd be mad to choose JavaScript instead.
Okay that is pretty cool. 
Ahh thanks, I really appreciate the feedback. I'll definitely change that in the gist/post and will endeavor to be careful about it in the future.
You're probably right, Node deffinitly has more traction.... But anyway, I do tend to agree with you on static typing. While working with iojs, I ran into a LOT of undefined vars because of my compile time checks (which I'm sure could be motivated by linters or even TyoeScript) but having real static types is really nice. 
While I'm generally fine with dynamic languages (I like Ruby, for example), JavaScript has enough pitfalls that I fall into them on a regular basis. The server environment I'm working with is slow enough to deploy to, and ugly enough to debug in, that it's a real win to catch as many bugs as possible at compile time. While there are tools like jshint, they aren't as robust as a compiled and statically checked language. So I end up writing as much as I can in a compiled language (in my case, Java, since I'm in a JSF-based world), and then using the bare minimum of server-side JavaScript to glue things together. The thought of having to face debugging race conditions in the middle of a callback in a node.js application makes me realize how good I've got it. Client side it's a different story, as tools like the Chrome developer environment make JavaScript debugging pretty easy, so long as you stick to VanillaJS. I'm not anti-JavaScript, I just find it horrible on the server.
Hopefully something like this exists now. I didn't find one a couple of months ago when I was looking for something to convert SVG to PNG. I'm using phantomjs as my solution. 
I've typically [used Inkscape from the command line for that](https://inkscape.org/en/doc/inkscape-man.html), it has a lot of options for how to export.
Code sharing between UI and backend is a myth that many people fall upon. Another thing many people seem to think is that it's easier to learn/code only one language, but to code in Node you also need to learn all it's specific libraries and conventions, and the same thing for a webbrowser - it might be the same language, but the environment and what you have at your disposal is completely different - which is exactly what takes the longest to learn/master. Both Javascript and Go as a language are pretty simple and easy to learn, it's learning the standard libraries that takes up time. Also - there is a [Go to Javascript](https://github.com/gopherjs/gopherjs) compiler - though I would not recommend it, it generates quite a bit of code ^^
I dont know much about Iojs, but I've used *other* interpreted languages. My point was, almost no one picks languages based on what executes fastest; at least, usually it should be low down on your priorities. Otherwise we'd all write assembly. People pick languages on a variety of factors such as the ones you've mentioned but also others. You aren't considering how interpreted languages *can* be more expressive and easier to write than Go. Don't get me wrong, I love Go. But I wouldn't use Go in favour of say Scala for a lot of problems. Is that because I think higher kinded types are *vital*?. No, it's all about tradeoffs. And If i am hacking together a proof of concept i am tempted to use a lightweight interpreted language to get it done. 
This is untested, but should work. We use this pattern all throughout our codebase. type Entity struct { ID uint64 Age uint64 } type Human struct { Entity Name string } func (e Entity) PrintAge() { fmt.Println(e.Age) } func main() { entity := Entity{0, 20} person := Person{Entity{1, 10}, "ojbway"} entity.PrintAge() person.PrintAge() } PS. I capitalized Id per Go standards
Go is about low complexity in development, windows dev has always been anything but. Apples and oranges.
If we treat methods like fields, then this is just another form of field inheritance. I'm talking about in the cases where I can't program a method and need a function (e.g. my function takes 2 parameters of struct types that are "superclasses" of something else I want to pass). The best solution that I could come up with was to have an interface that returned a pointer to the desired field. That way you could access and set something. For example: type PersonInterface interface { ID() *uint64 Name() *string } type Person struct { id uint64 name string // private fields } func (person *Person) ID() *uint64 { return &amp;person.id } func (person *Person) Name() *string { return &amp;person.name } func main() { person := &amp;Person{0, "bob"} fmt.Println(*person.ID()) // 0 *person.ID() = 20 fmt.Println(*person.ID()) // 20 } I did test this and it does in fact work. This way I only have 1 function for each field. Also I am able to write functions that take an argument of type PersonInterface, and then sub-interfaces of PersonInterface will also work. The problem is that I have to remember that when dealing with these kinds of objects, I am dealing with pointers. I'm the type of person who will forget that and screw everything up. Is there no way for us to do the same thing with structs, and have structs inherit structs and guarantee that a value (even a zero-value) is present for the given field? edit: formatting
I don't think there is any correlation. Mono has existed for a while - it has it's own slew of problems, I know - and anytime I've used it I've not missed any major feature from .NET proper that I couldn't do in Mono (I know there are examples, don't need to show them to me). Right now the "cross platform" .NET things depend on Mono to some extent so it's probably not going to be made irrelevant soon. Basically, the environment has already been on those platforms. I don't see this new push as any thin that would be threatening. It's also important to point out that Go is compiled natively while .NET languages are only IL on top of a runtime. There is a little more overhead there depending on what kinds of applications you plan on writing. 
Dotnet has a nice pattern with async/await that is pleasant. The issue with dotnet lies in nested inheritance that increases complexity. The threading is also not as minimal as go routines. 
Go sits in a different niche in my books, there's space for both to be successful.
Were you trying to quote yourself with that first sentence, then are responding to it? I'll assume that's true. I'm not sure which part you mean with a straight-face, so I'll try and answer the options : * How can I say you have not personally suffered? I was interpreting your wording to mean that you suffer as part of your job, which I am not trying to downplay. I mean Microsoft's larger behavior with bullying, market manipulation, and the whole monopoly thing. * How can I say they're not adoption non-MS platforms? Sorry, that is a wording error. What I meant was, MS will have to behave well for years. Behaving well specifically includes non-MS platforms. They're off to a great start, but it's not enough for me yet. (I do follow their releases and was a huge fan of MS Research for years). I'll specifically say that they need to do pretty much everything close to "right" for years. Probably 5. I'm sorry if that disappoints, but they were pretty shitty to the companies I worked for and it made my life difficult. That's not easy to overcome.
Aside from Mono, .NET on the Linux is not as 'mature'. It has only recently been announced. I am sure it will be a viable solution in a few years, so long as Windows Licensing doesn't weight it down in some way. That said, I view c# as being more of a language you write UI applications in while Golang for servers.
My first thought is to slap a GUI or chrome plugin on that and you'd have a homebrew LastPass clone.
seems overengineered. I use [this](https://github.com/tmc/watcher) small utility plus a few lines of shell to accomplish mostly the same.
The backers of Go, .NET, and Java seem to think so anyway, as is the way with big software corps like Google, Microsoft, and Oracle. Every decision they make wrt the respective languages is to better compete with each other for developer mindshare. 
runtime.GOMAXPROCS(runtime.MaxCPU()) should be enough, no need to input processor count manually :)
Why is it defalt, and not default? I think he's asking that, trying to point out what might be a typo.
https://gist.github.com/kpmy/ba65960a40e41f004fbd no Set/Get
Too much configuration required. Go code does not need this configuration to do effective restart-on-source-mod - clever use of 'go list -f {{.Src}} $(go list -f {{.Deps}} target)' can list all source files that go into the building of target. 
I've been using trends to keep track of the relative growth and regionality of Go interest. The key to using the Google Trends tool is to select the knowledge graph entity for "Go (Programming Language)". Here is an example - [comparing Go, Scala and Rust](http://www.google.com/trends/explore#q=%2Fm%2F09gbxjr%2C%20%2Fm%2F091hdj%2C%20%2Fm%2F0dsbpg6&amp;cmpt=q&amp;tz=). In the second chart, you can see that searches related to the Go programming language appear most popular in China and Hong Kong. 
&gt;no the whole point of unit testing is writing AND testing ONLY the code you really need I *partially* agree with this insofar as 100% test coverage isn't a useful goal. That said, exportation doesn't separate code that needs to be tested from code that doesn't.
I rewrote a production node 0.10.x service in Go and got a 10-30% performance increase. I rewrote a production db migration tool in Go and had approximately the same performance as the node 0.10.x version (probably because core node db stuff was c++) but I had much better type safety guarantees with Go. YMMV. Sadly my company is afraid of Go and used neither. 
Good read. I've shared some of my notes [on /r/programming](https://www.reddit.com/r/programming/comments/34ml5f/evaluation_of_performance_and_productivity/cqw7b8i). Feel free to criticise and correct.
Citation needed.
You need a citation that go is object oriented? You can look at any basic CS textbook and learn enough to make that deduction. Maybe you don't know enough basic CS to deduce this on your own. Just because a language lacks classical inheritance doesn't mean it isn't object oriented. Nobody is daft enough to claim JavaScript isn't object oriented. 
Ironically it seems like, nowadays, Go has begun attracting the vogue hipster types. 
This is a really uninformed and simplistic comment. Scaling projects in either language is equally easy. The general way of scaling is to horizontally spin up new instances which sit behind a load balancer. You can do this with anything that supports HTTP and its 100% transparent to the language itself. Scaling is *cheaper* with Go because generally speaking Go is more performant, sometimes by an order of magnitude. So what might take 3 node machines could be done with a single Go machine. A correct statement is that you scale Go much more cheaply, not easily or "better". 
Unused imports could be fixed using goimports. Unused vars is still annoying though. You're other points are valid as far as I'm aware. What do you like about Go? :) 
One thing you need to keep in mind is that, while Go might be more performant (please stop using the word "faster") under most workloads, if your system ever communicates with an off-machine database then that communication is guaranteed to be the slowest aspect of both a Go and Node system. There are plenty of benchmarks which say "look at this, I wrote a simple HTTP server and Go can serve 10,000 req/s where Node only serves 200", but the moment you have either of those machines talking to Postgres or Mongo I guarantee both of those numbers will drop to 100-300. And this just reinforces the point that most people in these discussions seem to forget: Good programmers use Node for io-heavy workloads. It isn't good for compute workloads and thus really isn't comparable to Go in a lot of domains. That doesn't make it bad or worthless, it just makes it specialized. 
Would be nice if bitbucket/github had statistics on private and public repos without giving data on the exact repo.... This could give a great image of how and where Go is being used. 
https://golang.org/doc/faq#Is_Go_an_object-oriented_language Given the way you've approached this topic, and how certain you are of your opinions in the lack of provable information, I have no desire to continue this discussion with you. Good luck!
Agreed, it'll always happen with something new that is good, the real problem is when people flock away from something good just because it's too "hipster" or for that matter too "mainstream"
Not always true. JVM currently beats Go in performance. No reason why CLR could not.
I appreciate your point, but code sharing is not a myth. Sure there is always code specific to the server vs client, but there is much that can be (and is, in practice) shared.
This. Use the best tool for the job, and Inkscape is one of the best and has been there for ages.
If you can find a package that can read an SVG into an image interface, You should than be able to use standard library functions to export as a PNG.
Thanks for the great feedback. The Rob Pike tidbit is interesting. I'll need to do a bit more research around that topic. 1) As I understand, NSOperationQueue is just a lightweight layer on top of libdispatch (GCD) with the advantage of guaranteeing that each operation is started in the order called. Also I needed a way to register the NSOperationQueue in order to create a global shared map of simulated routines and stacks (called GoRoutine and GoRoutineStack in the swift code). Unfortunately with pure GCD, the ability to call dispatch_get_current_queue() is deprecated so I could not get a context of the current queue. But, fortunately NSOperationQueue.currentQueue() is available. 2) If every goroutine is blocked, thus a total deadlock, then the behavior is left to GCD which may halt or interrupt the process. This does not match the behavior of Go. From my testing NSOperationQueue is limited to 64 worker threads before blocking occurs. Which really suck. But I'm looking into ways of decoupling from GCD. 
You're right! He talks about it at [15:23](https://www.youtube.com/watch?v=VoS7DsT1rdM&amp;t=15m23s). Thanks for the info.
It was interesting but made invalid comparisons in multiple benchmarks. Setting GOMAPROCS is not the same as changing compile time optimization flags. Those things have nothing to do with each other. 
Think about this for a minute: All Microsoft has released so far are some speculatory code dumps and a lot of wishful thinking. Turning that into a robust foundation that you can reliably build your business on is going to take a lot of work. At least two years by my reckoning. How much is going to change in the next two years? How much will Go change? How much will other platforms (Haskell, Scala, Rust, Python, Ruby) change? Another important question: will the community embrace this? Why should we expect that to change now? I mean, sure, this is the *new* Microsoft, and that's great, but that by no means guarantees the community will embrace this platform. There are so many unknowns you should remain skeptical (always a good thing). If Go is working for you, great. The community has embraced it so it so it's going to stay. I see little reason why this new .NET would change Go's velocity. 
The only comment I have at the moment is that your text functions should be using the Unicode package. Right now they're very dependent on ASCII encodings and sing byte characters which will probably work for most practical use cases but I think it wise to make string functions Unicode smart since runes are Unicode code points. 
Damn - that is cool. Going to play around with it tomorrow. Keep up the good work.
Great point. I've added a note on https://medium.com/@matryer/sync-once-with-reset-in-golang-quicktip-6ac44b015256
I'm most interested in rigging multiple gopath folders together, as this would play well with my current dependency management strategy (submodules). I'm a bit confused why gb hardcodes an src &amp; vendor/src, rather than just taking an array. I am tempted to identify how they union the two, and then either use it myself or submit a PR.
https://github.com/sourcegraph/thesrc
In it's simplest form it is just multiple src paths in one $GOPATH variable. Anyone could manage this setup manually and have whichever src &amp; vendor/src directory they want. `gb` hardcodes the src &amp; vendor/src directories for consistency. Imagine how annoying it would be if several projects you relied on used different conventions. To me this is similar to the `gofmt` philosophy. 
As someone still relatively new to Go, it looks like a bunch of these are just rewrites of whats in the standard library? Why, what benefits are gained in some of these libraries. 
I usually use [tomb](http://gopkg.in/tomb.v2) for this purpose.
One thing to consider is various other tooling has to change to work with gb project concept. I mean IDEs (liteide, IntellijIDEA) and editor plugins (for emacs, vim, SublimeText, etc.). Since majority of these tools use gocode/goimports/oracle, that's what needs to be updated mostly. 
Generally speaking the answer is no different in Go than it is in any other language. Getters are a code smell and setters are an _enormous_ code smell. You need to concentrate on what you want the object to _do_, not what the object _is_. Sometimes I end up with something that looks like a "getter" in my interfaces, but really it's just a case where it so happens that what I want to "do" is get something like a name or identifier or something, and there's no further meaning, but it's still conceptually not a "getter", it's a _question_ I'm asking the object that happens to have a simple answer. Inheritance is not a thing in Go. Your example is almost too simple to work with, but what's going on here is that you have: type HasAge interface { Age() uint64 } And that's it. That's the fundamental thing going on here. You have a set of objects that you wish to ask about their age. It is an _implementation detail_ that it so happens that many of the objects can have their "age" code factored out into an "Age" object: type Age uint64 func (a Age) Age() uint64 { return uint64(Age) } type Human struct { .... Age } type NotHuman struct { .... Age } but this is not "inheritance". It's just a convenient refactoring. Basically, that's how you should approach Go OO design. Start with the thing using the objects. Figure out what methods it wants to call; there's always a set of such things. Pull that into an interface. Write a couple of implementations of the interface. If it so happens that some chunk of the interface can be cleanly factored into a subordinate object that can be _composed_ in (key word here, not "inherited"), great, go ahead. If not, no stress, no problem. If you find yourself in a chunk of code that is "getting" and "setting", step up a level (probably literally a block in the code), and see if you can move this logic into the interface itself. Again, your example code is too small here to provide a useful demonstration. In rare cases you may actually want a true "inheritance" hierarchy. In that case you'll have to do it manually, analogously to how languages that prefer to syntactically privilege inheritance require manual work to do what Go does automatically for composition. I haven't hit one of these yet, but I could name some cases where I'd consider it. But in general, you'll find composition takes you quite a bit further than your inheritance-trained mental models are telling you. If you aren't doing "some sort of UI widget hierarchy", you probably don't need inheritance.
That's great but compiling and running a whole suite of tests can take a couple of seconds. This is almost instant because it just runs the test you're currently working on.
So if this becomes the standard are they going to make tools to convert from go to gb structure?
Once developed my loop package as part of the https://github.com/tideland/goas for it. It works similar to tomb but also contains the possibility to start loops with an additional recovery function. In case of a starving goroutine it's called and by the passed arguments it can decide if the loop should restart or fail. See http://godoc.org/github.com/tideland/goas/v2/loop.
That sounds like a reasonable request. I don't see why it couldn't be an option flag in gb.
I wrote this a while back, and would appreciate criticisms: http://play.golang.org/p/JGIWzi5o6g 
I don't see why you chose to build backwards, there is a lot of rebuilding going on with your `append([]rune{'_'}, buf...)`. Provided a sample string of: "SomeClass" You'd end up with a (at least mental, optimizations my change this): append([]rune{'_'}, 'C', 'l', 'a', 's', 's') Which will continue to grow if I `FeedItSomeLongNameThatWillSlowThingsDown`. I, personally, would go with something along the lines of this: func snake(s string) string { rs := []rune(s) lastLower := false buf := new(bytes.Buffer) for _, r := range rs { if unicode.IsLetter(r) { if lastLower &amp;&amp; unicode.IsUpper(r) { buf.WriteRune('_') lastLower = false } else { lastLower = true } } buf.WriteRune(r) } return strings.ToLower(buf.String()) } (further example of unicode support vs. none can be found [here](https://play.golang.org/p/jIInNxgjCC)) The real improvement here is just being more clear about what's going. By not iterating backwards and caching (via the `bool`) whether or not I'd previously encountered a 'lowercase' character I was able to reduce the if/else to a very simple branch test. Also looping forward has prevented the awkward need to append the current buffer to the end of a rune to get the new buffer. Using this method allows for `range` to work which also removes any direct array lookups from happening throughout the body of the loop. **edit:** modify sample and update link
[LiteIDE](https://github.com/visualfc/liteide)
Yes but I don't see any installer for x64 for version X27.2.1.
To me this seems like a worse version of godep, which does the same vendoring and doesn't require import rewriting if you use it to build (in which case it sets the GOPATH). Additionally it doesn't require the src/ directory and it tracks the versions of the vendored packages. Godep has a few warts, but this doesn't seem to improve on anything and seems to have a couple regressions. https://github.com/tools/godep
Ahh, my apologies, I have misunderstood your statement. You want the IDE to be 64-bit? Well, LiteIDE is distributed as a 32-bit executable because that'll run in both 32-bit and 64-bit windows. However, as long as you install the 64-bit version of the go compiler, all programs you compile will be 64-bit. There is really no advantage to having the IDE be 64-bit.
I know, but I hate running 32bit software on my pc. Well, LIteIDE it is then, thanks :).
maybe [Zeus IDE](http://www.zeusedit.com/index.html)??
Do you know why I can't recompile a modified file? Bug is tracked here - https://code.google.com/p/golangide/issues/detail?id=115 - but that's from 2014 and this is still the case :/.
&gt;I know, but I hate running 32bit software on my pc. I can count on one (closed!) hand the number of times I've been bitten by anything negative doing this. The reason it's distributed that way is because there's no reason not to. That said, if you're that close to your metal you should try a text editor with gocode and a terminal for building and running your code. The toolchain is extremely easy to use and you'll become more intimate with the tools you're using. This isn't Java, you don't need an IDE. Edit: For hotkey build/run functionality, try sublime. The go plugin for it does much of this for you. 
I will never ever under no circumstances use everything but an IDE. Tooling around with a text editor and manually start my program over the cmd like it's 1994 - Nope.
how are you running the go code after you are finished developing?
Double click?
I don't see where godep has the option to not import path rewriting? I thought the only way to use godep was to rewrite imports.
If you want to build an api, look into `go-restful`.
I think I'll stick with Godep. I don't like the idea of a Go project not being go-gettable. 
Well, all I can say is the magic words: "Works on my machine"™
I couldn't find a package for this either. One possible workaround is calling the rsvg executable. https://github.com/xyproto/mcbanner/blob/master/convert.go (just an example. Don't use panic and temporary files like this for production).
It's actually pretty easy if the output is similar (or the same) with what the go tools outputs. I think I can very easily modify the existing vim commands to support gb. For example we already can swap gofmt command, either `gofmt` or `goimports` (or even `goreturns`). 
Does not seem to be a specific Go problem ? More like a html5 problem. If you think its a Go problem, then you have to give more Go code.
Running build again seems strange but the overall idea seems very useful! 
I'm not sure why you're avoiding IntelliJ... I've tried them all, and the latest Go plugin makes it leaps and bounds ahead than the rest. If you really want to avoid IntelliJ, then I believe the Go plugin can be installed in their other IDEs - e.g. PhpStorm / WebStorm. However - don't fear the Java in IntelliJ - you really don't have to worry about it at all when developing Go. Although the IDE is written in Java, you don't have to mess around installing JDKs - it all just works.
It's not intend on rewrites, but the convenience. Extract the common, helpful pattern, data structures, functions and components from code, make them a second base library, that's what i do: DRY! Don't repeat yourself! One can imagin how tedious it is to repeat yourself day by day! Anyone can take codes from it and put yours to it, welcome for feedbacks and contributions.
No, it doesn't work without messing around. I installed it, started and and got the nice message "please add the JDK path to Windows".
Yeah, I think it's a design mistake. Eventually you're going to need to decouple one of your endpoints from its location in the code, and the magical router that saves a half a line of typing will be a pain in the ass to work around. 
Awesome ! Thanks a lot !
IANAL, but I believe it's not. Writing code in emacs or compiling it with gcc won't make your program GPL.
Added to “libraries I hope to never need”.
Ah, great point.
It's pretty similar, but I also wanted to support the following use cases: * commands like "go run" should work (which is tricky, since they actually start a separate process for the real binary). I run subcommands in a separate process group to achieve this * customization of what to watch (multiple patterns/directories) * proxy ports that avoid me hitting refresh constantly while the binary restarts.
Note that these handlers won't be broadly compatible with other handlers as they don't satisfy the `http.Handler` method. If `Handler` had a `ServeHTTP(w http.ResponseWriter, r *http.Request)` method it would. e.g. type Handler func (w http.ResponseWriter, r *http.Request) error func (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request) { err := h(w, r) if err != nil { // Do things - inspect the error, raise a 500, render a nice template, etc } } You would then modify your `Handle` func to accept a `http.Handler` instead. I [wrote about](http://elithrar.github.io/article/custom-handlers-avoiding-globals/) a similar thing a little while ago and also [a Gist](https://gist.github.com/elithrar/21cb76b8e29398722532) that works like the method in your post: `http.Handle("/route", use(YourHandler, MiddlewareA, MiddlewareB, MiddlewareC)` Obviously there's not Only One Way to do things, but hitching your wagon to interfaces in the std lib is pretty darned close to it ;)
The first book I tried was &gt; Building Web Apps with Go Free &gt; A good resource for start Building Web Apps with Go. Free to read online, pdf and mobi version. Unfortunately it is only scraps of documentation, not really useful at present. Then I tried &gt; Build Web Application with Golang Again it seems to be not very useful, and a lot of waffle. Opening a page at random I get &gt; The greatest invention in programming is flow control. Because of them, you are able to use simple control statements that can be used to represent complex logic. There are three categories of flow control: conditional, cycle control and unconditional jump. What is offered beyond what is already in the online documentation? Then I tried another one, &gt; http://jan.newmarch.name/go/ Again this seems to offer very little content beyond general waffle and things I can already find in the online docs. Sorry to look these gift horses in the mouth, but a more carefully pruned list would be helpful. 
I like the cleanliness of it
Another two options are https://github.com/zencoder/disque-go and https://github.com/goware/disque.
You already know all facets of the two approaches. Go make your own opinion.
wait so my string vars that im using now -- do they support runes or not? i was hoping to get full unicode support, but i just built everything with string type
Yes, they do. Strings are always UTF-8 encoded.
ty good to know if you know a list of things that break strings but not runes or compaitibility article id love to read it, if not ill google it in a bit :&gt;
Hi, [ptk](https://github.com/cosiner/ptk) now support prefix match, one letter, one command. Also, you can custom colors fully.
What language does it support? I usually just pipe the output to pygments which support pretty much everything I can think of.
Half true: String literals in Go code are always UTF-8 encoded. String values are just a bag of bytes.
Yes, that's correct. I didn't want to type up a long but correct explanation just to let /u/mc_hammerd think he shouldn't use strings (he really should).
ooh, a third one! :) cool. it's nice to see how the different libs create different APIs for the same thing. Personally I tried to keep the low level API as close as possible to the actual API semantics, and abstract higher things on top of it.
interesting, thx for response.. all my data is json so i will have to test how that handles your case
I'd rather use glolcat: https://github.com/cezarsa/glolcat
This is why people pull that sort of code apart into objects/methods though - for clarity. Its much easier to know what `PlayerDidXYZAction()` does just by looking at the method name than it is to mentally pull apart a heap of nested loops. It might seem like boilerplate but you're helping your future self/anyone else who looks at it.
also check out fsnotify.org
Don't worry about picky optimizations over a correct, readable/maintainable design. That's basically one of the things that Rob mentions in the video, he designed the lexer with concurrency in mind not because it made it faster but because it made it easier to reason about. That being said here's a few comments on your question. The "improved backtracking" could be implemented easily by keeping a slice of widths, however for the lexer being written in the video I believe he only required a backup of one anyway, so it wouldn't have been helpful to keep more. Also consider the case where the lexer returns an error after reading only a few characters. Your pre-processing would be wasted effort. I'm not going to outright say that your method is better or worse than then the one in the video, often times what is "more expensive" or "more efficient" is totally dependent on the kinds of inputs you expect.
Bump for atom, rockin it over here.
If you are worried about readability some boiler plate is good. Those additional types will also help with testing. You might consider the work an investment on any work you might have to do in the future. Games generally have substantially more complexity and state than their designs may initially suggest, so an initial focus on readability isn't a bad thing. You can then optimize just the areas that need it after the fact.
Conference? That was at the Go user group Berlin meetup a few weeks ago.
Well, a full answer depends a _lot_ on things you don't discuss, and I do not have The One Answer, but there's definitely some little things we can discuss. First, for an OO design, you are leaving a lot of stuff on the table by using so many primitive types directly. Certainly step one is some more custom types. Board is an obvious one: type Square struct { index [2]int occupied bool owner PlayerID // see below } type Board [][]Square Manipulations of the board should become methods on Board, Square should grow methods too. `index` is actually something you should add only when you need it, in general you're better off not having that sort of reverse link, but it may be unavoidable. You also clearly have a Player object struggling to get out: type PlayerID int type Player struct { id int history []event // a guess, depends on you "events" bonuses []int // probably some other type is called for here, BTW } which has further methods. As I sit here and type this, the next problem I see is a bit more subtle; you've got some concept smearing going on here. You've got a board, which probably has some bits of what players own what (or, if not now, will after a good refactoring), but you've got a separate "thingsplayercontrol" map that has some other elements of what they control, depending on how the "events" are working here they may also have some of that information in them. Probably part of the reason "everything" requires iterating over three arrays is that you've got the relevant concepts smeared across three arrays. On that note, this suggests that you lack some indexing; even with our powerful modern computers you can't afford to iterate several times over even small multidimensional arrays too many times per second before you run out of cycles. Whatever tasks you're trying to do could probably be helped with some sort of pointer or index-based system storing something somewhere. Or, alternatively, if you really are iterating over and changing the entire board, you need to arrange things so you loop through once. "Collect all events" -&gt; "Perform all the events" -&gt; "Present board for next move" is a pretty powerful loop and you may literally be able to write that somewhere. Your types also suggest you have some sort of chat room available; that can be pulled out too: type ChatMessage { speaker PlayerID text string } type PlayerChat struct { roomID int thingssaid []ChatMessage } This is... not 100% accepted, but... I consider seeing an "int" or other primitive type in a struct to be a statement that there is _nothing_ else this element is, that there is no other constraint I can express on this value other than that it is a number (and usually for `int` we don't even assume the user is truly assuming the size limits implied by int). For int, for instance, is it OK if I just stuff the value 2,000,000 into it? If not, it probably isn't an int. The reason why that's valid leads you to what it really is. For instance, if the answer is that 2,000,000 is unlikely to be a valid ID for a player, then you have a PlayerID. While I do end up with primitive values here and there in my structs (`string` is especially frequent as "this is just a string of stuff that came from somewhere and I don't really know anything about it" is fairly common), they are sort of the exception for me rather than the rule. In Go, I find this is particularly so because almost the instant I declare something even so simple as a `type PlayerID int` I find at least three methods that make sense to put on it. Last, but not least, I see: type Roomorlevel { It is not clear to me if the name of the game is "Roomor", or if you mean `RoomOrLevel`. If the latter, well, while it isn't necessarily the end of the world to jam both in the same struct, the inevitable pressures of development will tend to drive the two concepts either ever further apart, in which case they really ought to be different structs, or further together until it is once again just `type Room` or something. As I suspect the former is more likely, you probably want to declare an interface: type Location interface { // all the things a location can do. // This interface may get large. Do not be afraid of that; // "library" interfaces should generally be small but // I think end-user apps often end up needing a few // large interfaces, especially for places where you're // sort-of implementing some "inheritance" } You then declare a `type Room` and `type Level`, which are both free to be themselves and not be carrying around the baggage of the other thing. You will likely find that a lot of the previous little objects I broke the system up into may be reused between the two of them, resulting in less reimplementation than you might think. One last note. If you are not using source control, do it now. Once you start doing this, do one object at a time. There's a temptation to do all of this at once but it's really very dangerous. :) Do one object extraction at a time, and commit after each one. If you are not unit testing, this is a great way to fold it back in; every time you extract one object and give it some methods, that's a great time to put the testing in. It is likely that if you just start doing these two things (extraction &amp; testing) that you'll find a virtuous cycle results, where the act of extracting out the code also reveals places where you can reuse things, the extraction of some concepts out into objects will further reveal where some objects were smeared into too many places, and show further things to extract out, which can then be cleanly tested. Run around this loop a few times and you'll have a completely different program on your hands. (If you're feeling _really_ saucy, here's a [precommit hook](https://github.com/thejerf/suture/blob/master/pre-commit) I use with git to ensure all my test pass before I commit. You may want to whack the golint part. Put this in .git/hooks, or symlink it there if appropriate. Other source control systems have different options for this.)
I'm looking at the code, and I see this "anti-pattern" a lot. Looking at the ccat function(removing all the error handling code for now) func ccat(file string, colorDefs ColorDefs) error { var reader io.Reader if file == "-" { reader = bufio.NewReader(os.Stdin) } else { f, err := os.Open(file) reader = f } input, err := ioutil.ReadAll(reader) content, err := AsCCat(input, colorDefs) This code takes a File (os.Stdin/file), creates a new Reader, reads all the bytes and then sends it to AsCCat. Inside AsCCat, func AsCCat(src []byte, cdefs ColorDefs) ([]byte, error) { var buf bytes.Buffer err := syntaxhighlight.Print(syntaxhighlight.NewScanner(src), &amp;buf, Printer{cdefs}) AsCCat creates a scanner using syntaxhighlight's NewScanner method. If you see inside the NewScanner function, func NewScanner(src []byte) *scanner.Scanner { var s scanner.Scanner s.Init(bytes.NewReader(src)) The NewScanner function creates a new Reader(!!!) from the bytes. So essentially this is what is happening - Open File -&gt; Create Reader -&gt; Read all bytes from the reader -&gt; Create Reader from these bytes! 
Hope no, not dead. Atom is slow and buggy *imo*.
"So Is that more expensive than decoding each rune individually?" So, generic answer so I don't feel bad: "profile". However, specific answer, yes, converting to `[]rune` is more expensive than iteration. I can say this confidently because the work is a strict superset of the iteration, since the conversion to `[]rune` is done via iteration, _plus_ a `rune` is [actually a `int32`](http://golang.org/pkg/builtin/#rune), so you're creating a brand new array that contains 4 bytes per unicode code point. And I don't know exactly how that will be allocated, but be it by scanning the string once to find the necessary size then a second time to copy, or be it by scanning through once and dynamically resizing the `[]rune` when it becomes too small, it's likely to be even more expensive than I'm making it sound. It may be the case that none of this matters, which is why I start with "profile" as the generic answer. If it makes the code flow better, and you do a one-time conversion to `[]rune` then take extensive advantage of a representation more convenient for your code, it may still be a win. (You may also be able to work out how to start with that representation instead, or chunk, or something that amortizes away most of the expense I was talking about.) On the other hand, in the worst case where you casually convert back and forth all over the place, probably without even realizing it, this can easily come to dominate your entire program. It Depends (TM).
The part I hadn't really though through when asking the question was realizing that the `[]rune` wasn't seamlessly pushed back into a `string` (which I mix up most of the time forgetting `string` and `[]byte` are interchangeable). Thanks for the advice though - I do see a reasonable amount of transitioning between `[]rune` to `string` where this would become very problematic.
As has been pointed out, yes, they do support runes, however `string` is a type alias for `[]byte` with some syntatic sugar sprinkled on top of it (i.e. `"Hello, I'm a string"` representation). That means, in a string like: `"Hello, World!"` if you grab (via indexing) `str[0]` you will get `72 (byte)`. Now 72 is the actual rune for "H", but we're looking at two different data types (not just `byte` and `rune` but realistically `int8` and `int32`). The reason this is the case is the way that Unicode encodes text values - they maintained the standard 0-127 encodings and added rules for 128+ values in addition to more things (If you don't know much about Unicode I highly advise you read [this article by Joel Spolsky](http://www.joelonsoftware.com/articles/Unicode.html)). In this case it's what I would call "coincidence" that you can grab the first index from a string and have it map to a character. Because if you alter the string to `"こんいちはせかい"` Then we grab `str[0]` we get 227, and when printed as a character we get `ã` which is obviously wrong. So when working with strings it's important to decode runes from the string - like in this example where I'm using `"unicode/utf8"`: str := "こんにちはえかい" r, size := utf8.DecodeRuneInString(str) if size &gt; 0 { fmt.Printf("Decoded %q with a length of %d byte(s)\n", r, size) fmt.Printf("Rest of the string %q\n", str[size:]) } Output: Decoded 'こ' with a length of 3 byte(s) Rest of the string "んにちはえかい" ([playground](http://play.golang.org/p/qB-6eLQiup)) `DecodeRuneInString` gives us the `rune` and a size (in bytes) of the rune, and to get the "rest" of the string after the rune I have to select from size to the end of the string. **tl;dr** So yes, strings are "unicode" aware, but they aren't "unicode" smart. In other words, you as the developer need to know if the string was encoded with UTF8 or UTF16 or whatever (UTF8 can read ASCII, FYI) and code with that in mind in order to take advantage of the unicode awareness.
I see what you're saying - it seems inefficient. The author doesn't control `NewScanner`. Do you have a suggestion about how to tighten this up?
Can you not just pass the directory location to the package?
That would depend on the package location. It is manual, and not portable.
Presumably there is some reason I'm not aware of which prevents you from just doing this? path.Join(os.Getenv(GOPATH), "src", pkgname)?
flag.Parse() should be called in main(), lest you skip flags defined in the init()s of other files and packages.
It wouldn't really be considered a killer in Go to have to specify the directory. You may also want to look into whether `go generate` can do what you're trying to do. I haven't used it for anything yet but I bet the "current directory" at generate time is the package having generate run on it.
Yeah, you're right. I thought about returning a pointer to a metric struct, but code using the library was far clearer when doing it this way. I will probably make it return an error though if there are troubles when creating the metric.
Is it really? Like you can have multiple directories that will be searched? I was not aware of this and really want to know the answer. 
I have no idea what your problem is. If you just pass the absolute path to the package, you have no problems. 
This doesn't seem to be even remotely a go question...
My question is basically, can you change the url in the address bar of a browser using go.
What you want to search for is somewhat related to DNS You want to go to your hosting provider admin panel and add a CNAME from `notalkingplz.com` to `mydns.com` that's way it'll be effectively "cloaking" not redirecting. As for the port 8080, you have no choice but to listen on port 80 in you Go app to remove the need of having it in the url. (there are other ways, google reverse proxy but I am pretty sure this is too involving for your use case. Please research how HTTP works, understand the protocols and technologies than make the web works you will come out a way better programmer and will be able to ask the right questions in the right forums/communities for them, when in doubt post to StackOverflow. This is obviously not a go related question...
Let's say DNS is out of the picture. Is it possible to change the url in the address bar of a browser, using go?
Not from your server end, and it's barely possible (as in I would have no idea how to do it at all) from the client end. Only Javascript can change the url from the browser and that forces a redirect. So the short answer is no. What you are doing is impossible with go, unless you write a DNA server in go which is a crazy round about approach to "using go". 
Thanks for the answer.
At what scope and time do you need the package path? * Build time? * Run time? * From within the package? * From outside the package? * On your development box? * On a build server? * Where your binary is deployed?
Yes, exactly that.
You should look at using something like go-bindata, in conjunction with //go:generate (sorry, on mobile can'tllink the docs) to generate a virtual filesystem (see go-bindata) asset directory which is compiled into your resulting binary. As others have said, there's nothing to suggest that your binary will have any access to the sources in the GOPATH at run time, be that because its in a /tmp dir because of "go run ...", or because you copied it to a machine without a go toolchain.
I've been using go for about 2 years now and I want to try teaching others. I had the idea to make a series of tutorial videos (similar to railscasts.com), and this is the first one. I want to gauge interest before I commit to making more. Is this a good idea? If it seems like people are interested there will be a lot more videos coming!
Good call. Made some improvement on https://github.com/jingweno/ccat/commit/d42e02246050880ba66a425cabd6c278b10ffe27.
Regarding the first approach: Why return a `*context.Context`? `context.Context` is an interface and safe for use from multiple goroutines according to the docs. It seems like the drawbacks explained for this approach go away when not using pointers. For reference: https://golang.org/doc/faq#pointer_to_interface
If you don't use a pointer, you have to update the map itself. That means you have to lock the mutex any time you derive a new context, which increases the lock contention. It is doable, though.
I used brew to install go. It seemed like a better option because I don't have to do much to upgrade to newer versions.
I have been using runtime.Caller with success on the unix's; not sure about windows though... http://andrewbrookins.com/tech/golang-get-directory-of-the-current-file/
You checked the wrong source. Advantages: Starts about a gazillion times faster, once its open it doesn't lag if you open a file that has more then ~1000 lines while using less RAM.
That is just about the greatest news I've heard all day. Is that stated some place in the docs and I just missed it? 
Meh. All you need is to properly configure Vim or Emacs and that's all you need. Intelligent code completion, code browsing, etc...
I use kdevelop4 with go plugin, if you get it working ti is kinda nice.
Which is way better than any other option proposed in the article. 
There's a [go plugin](https://plugins.jetbrains.com/plugin/5047?pr=idea) for the jetbrains intellij platform, and can be used for free with their [idea community edition](https://www.jetbrains.com/idea/download/). The author has not tagged a 1.0 release yet so I've been downloading the [alpha releases](https://github.com/go-lang-plugin-org/go-lang-idea-plugin/releases) zip file and using them. 
Cool project! I could need such a tool which creates Go code from XSD files: https://github.com/magento/magento2/search?utf8=%E2%9C%93&amp;q=xsd+in%3Apath With Magento1 it is impossible to create Go code from XML files because each module has a total custom XML file. (No XSD definition there)
i'm not sure how vim-go could be any easier.
Yeah, that's like the only IDE worth using at the moment beside Vim (that takes time to learn for beginners) and GoSublime. Everything else it's kind of at the infant stage. (IMHO). If you actually look at the LiteIDE, it has a lot of features.
To be fair, I'm not so sure I'd call it racism. It's more like bad English is a red flag that makes people nervous. It reminds them of the Nigerian prince who wants to take your money. I was following the issues for LiteIDE and I eventually unsubscribed because most of them were in Chinese. We don't really have this issue with open source projects originating in India or the Philippines, both places where English is widely spoken. That being said, I do think more people should use LiteIDE. Maybe we'll get something better someday -- perhaps a solution that's written in Go. 
&gt;All Microsoft has released so far are some speculatory code dumps and a lot of wishful thinking. Turning that into a robust foundation that you can reliably build your business on is going to take a lot of work. At least two years by my reckoning. Well it's not like the Go ecosystem is in much better shape atm. A half-arsed language (Lots of stuff missing from the standard library and third party libs. No good debugger. No Generics in 2015. Slow text-handling. Several arse-backwards design decisions. No versioning for packages. No REPL.). What it has is mostly momentum and some nice tooling, but nothing mind-bogling. Algol offered most of the things Go does back in 1968, and Ada offered even more 20 years ago.
It's mentioned in the article, and like the author said... The plugin kind of hit a dead end for a while there. It's what I use to write Go but I almost never recommend it. The plugin has been full of bugs for a while. I'm glad to see the plugin author has picked up the torch again, and is once again actively developing the plugin.
I hope this was for educational purposes only.
Vim lovers gonna love Vim for the same reason it's nigh onto impossible to get a C++ programmer to switch to something else. The thought of abandoning the countless hours invested in sorting out the arcane and mastering the mysteries it just too much to bear. On the other hand, a Vim master will almost always crank out more code than an IDE user. Likewise A C++ master can create some awesome apps... LiteIDE is a great example. That said, I wouldn't recommend either to someone who's primary interest is becoming productive and getting up to speed quickly. Learn Go instead of C++ and use LiteIDE instead of VIM or Emacs. 
I'm glad [I'm not the only one](http://elithrar.github.io/article/custom-handlers-avoiding-globals/) who likes the particular `func(http.ResponseWriter, *http.Request) (int, error)` pattern! Satisfying `http.Handler` should be a life goal when writing any HTTP libs or packages in Go. 
I was talking with a friend about why I like go web development, and one of my points was that it makes reasonable decisions for me. Here we go, ! Decisions It Made for You * PostgreSQL is chosen for the database. * bcrypt is chosen as the password hasher.
&gt; Now that we have x/net/context, you and the Go Team have an opportunity to unify the handler APIs in the community by declaring func(contex.Context, http.ResponseWriter, *http.Request) as the way forward. They already allow for that—the `http.Handler` interface (as per the post) supports defining your own function types as handlers. There are plenty of cases where that signature may not be suitable—what if you want to pass in app config/env without throwing things into a context `interface{}`?—and by working with the interface you can do that. Part of me feels that the only way (previously) would have been to put an `interface{}` field on the `http.Request` struct for it to be a "general purpose" request context, which leads you to a world of getters and setters for type asserting stuff out of it.
Spacemacs. Adding go support is something like 3 words in a configuration file + installing gocode (or whatever it is called)
Am I the only one that thinks that writing your own implementations of crypto functions in assembly is probably a bad idea? There are just too many edge cases that are easy to get wrong.
&gt; It’s the difficulty to bootstrap a new project within a deadline. &gt; But realistically, a big web project needs a structure. Putting something small together quickly seems like an entirely different need than organizing a large web project. I've worked with large rails projects. As far as I can tell, for all their conventions, they are just as tricky to work with. Finding the right model, the right controller or the right route can take a while. And sometimes small bits of code that folks add accumulate to cause really bizarre behavior. (Like methods that get run on every request, or every time you save a model, but are buried deep within some other file you don't know about) In my opinion you're better off breaking up your large, monolithic app into smaller services which have a much smaller set of requirements. Go already has all the tools you need to organize a large project. Break up your package into sub-packages. Break up big functions into smaller functions. Abstract common patterns into interfaces, etc... Why is making a web application any different than any other kind of application? 
You're describing a good rule of thumb, but at various times qualified security professionals are going to roll up their sleeves and write some crypto software and that's ok. I am not a security professional, but my understanding of the Elliptic Curve and AES-GCM algorithms that they rewrote is that they are basically the straight-up math portion of the cryptography, where there isn't the same capacity for edge cases and you can formally verify that it works. It does not seem like they are re-writing the entire cryptography stack in assembly, which I agree would be crazy.
They explained why they needed to do this: The standard library implementation was too slow for their purposes. They even took care to harden against side channel attacks so their implementation may even be more secure than the current implementation. I hope this improved implementation is security audited and then included in the standard library so everybody can benefit. Go is already amazing to be the only language with batteries-included feature rich cryptography in the standard library, and now with performance on par with openssl there's no good reason to use anything else.
thanks for the gox link. Yes, i mean modern fast embedded devices which can now run full browser such as chrome on android. I'm looking to write small go rountines/functions that can serve some kind of frontend. Do you use anything for frontend on arm? 
What exactly do you mean with 'some kind of frontend'? Some GUI? For anything GUI related in Go I tend to go for a web UI. Only done this a few times, but every time I designed a REST API and a Javascript browser app that consumes it, sometimes backed by websockets if you need to do realtime UI updates.
It's just a matter of familiarity, I saw more bcrypt projects :)
&gt; The concept of text processing in Go is that the first thing you do when you receive textual data from the outside is translating it into Unicode. The only place where a string might not contain UTF-8 encoded data should be the IO-layer of your program. I was referring to the fact that with nothing but a `string` you can't access unicode data directly. The `string` itself might _contain_ unicode but that unicode has to be parsed out of the bytes of the string. I would agree with your statement if `string`s were `[]rune` types but they aren't.
Ehm... You can. If you iterate through a string with a for range loop, you are provided with subsequent UTF-8 encoded characters. 
This isn't bad but you could probably clean up the code a bit. Low-hanging fruit here would be these [goto statements](https://github.com/cosiner/gohper/blob/master/goutil/ast/ast.go#L86) which could just return the error. Then the functions above could worry about if it's a real error or not. Also, why not use a for-range loop [here](https://github.com/cosiner/gohper/blob/master/goutil/ast/ast.go#L83) instead of this very C-esque for-loop? If you return the err, then looping will naturally stop. Otherwise, not bad, but not very Go-like. 
That's assuming the majority of your server cost *is* the crypto. How much crypto are they actually doing ???
They're a CDN. Millions of clients, each making multiple connections gets expensive fast, especially with current TLS technology. CPU time isn't cheap at that scale, since you have to add more servers to handle the load.
It wasn't obvious to me how you were supposed to version control gb projects, so I asked Dave on Twitter. His answer: "once you have all your source and dependencies copied into a gb project, check the whole thing into a new repo." https://twitter.com/davecheney/status/596031147689119745
There is plenty of info on this if you Google it, bcrypt is supposed to be slower (which is good in some aspect), but it's also a bit older too. NIST currently recommend pbkdf2_sha256, but that doesn't mean there is anything wrong with bcrypt at all. I don't think it matters much in the end, either of those two algorithms are fine.
I am using [Hugo](http://gohugo.io) in my [blog](http://gmnt.net) and is very simple to install and use.
"Lean and mean" &gt; Prerequisites &gt; * PostgreSQL ...kinda?
But for each of those millions of clients, how much of the total time is the TLS handshake? Just curious. If the TLS stuff is indeed that heavy, you could put the Go code behind an nginx/apache reverse proxy and let *that* handle the TLS stuff. I don't want to belittle this achievement or anything, it's just....surprising a bit. 
If you use a construct not part of the `string`, yes you certainly can. Just as you can simulate this behavior by manually grabbing unicode code points using one of the various provided unicode packages. The `string` itself has no knowledge of unicode encodings which is exactly what I was saying.
(Hugo)[http://gohugo.io/] looks very cool , But im not going write the site im just looking for the best hosting solution 
I was replying to your point “with nothing but a string you can't access unicode data directly.” `range` loops are built into the language, are they not direct enough for you?
Wrote something very similar. https://github.com/jarosser06/gistcat
If you mean "middleware written by others, everywhere" - then no, you can't. You can of course do it with your own middleware and keep it http.Handler compat. That's unfortunate, but also the same as other programming languages. Their *frameworks* often have a particular request context implementation, and due to their maturity, a lot of libraries leverage that directly (i.e. Django's req context is not Flask's, is not web.py's, etc) The lack of a dedicated request context in Go is only a shortcoming if you compare Go + net/http to the established frameworks of other languages. 
&gt; you could put the Go code behind an nginx/apache reverse proxy and let that handle the TLS stuff. The problem there is that they don't want to be tied to nginx/Apache. For most of us, having nginx handle TLS termination is a Good Thing because it does it well, has wide support for OCSP stapling, session tickets, etc. For CloudFlare, they're pushing the limits and tying themselves to nginx would be hugely frustrating. They'd have to maintain a fork of a large C codebase that they didn't write, and whilst nginx has nice code, it's still a LOT of code. Go's surface area is tiny in comparison.
I know that the team at [MirrorX.com](https://mirrorx.com/) are using Qt along with [qml-go](https://github.com/go-qml/qml) to create GUI apps that they then deploy in RPi devices. Let me see if one of their dev team members would be interested in writing up a blog post on their approach.
Not exactly, unless it is a command line tool. The Go Mobile SDK, which is undergoing very active development for the v1.5 release, will include experimental support for OpenGL. Keep an eye on - https://godoc.org/golang.org/x/mobile/app - for details around Go v1.5 release timeframe.
Perhaps a text generator based on Markov chains would be a better choice for this.
No. It is the [Unicode Replacement Character](http://www.fileformat.info/info/unicode/char/0fffd/index.htm).
It depends on your needs. sqlite is probably the leanest.
I *love* godoc, and I love that it lets you include runnable examples that get tested, so that your examples *can't* go out of date from the code. That's such an innovative feature. I wrote a post similar to this one some time back, except I wrote it using godoc itself (i.e., the docs are the blog post): https://godoc.org/github.com/natefinch/godocgo
not gonna lie, that is awesome. I'm now picturing a static site generator that encodes a full blog and index into a tree of packages.
If it's a static site you won't use `httprouter` or anything. That's not what a static site is. You're just hosting a bunch of flat files, so you can use ANY host. Many people use GitHub Pages + Jekyll, but it would work with any static file site. Amazon also provides for static site serving over S3. You could use GoDaddy if you really wanted to.
&gt; Not the most efficient way to get the forth rune from a string. But you could use it that way. Although if you introduce the loop, again, you have more than just a string. I can't think of any much more efficient way to get the fourth rune of a `string` than something like [this](http://play.golang.org/). The UTF-8 encoding does not allow you to seek. If you need a Unicode string with seekable runes, then you don't want a `string`. &gt; Like I said. The point I was making is that you have to do something with a string to access the Unicode data. The string itself is just bytes. Certainly. But you also need to do *something* with a `[]byte` to get it's fourth entry (namely, employ the index operator).
https://www.reddit.com/r/golang/comments/29ua55/rust_or_go/
Besides all other arguments, it`s probably because Go is a lot more mature than Rust. And by mature I just mean "older".
Hehe - well things have changed quite a bit.... When I started working 15 years ago, having a filesystem on an embedded device was something amazing. Not having to fall back to ASM to achieve some acceptable crypto performance was also a big plus. At that time, the M86k ruled the embedded world I was involved with. These days it's "huh? I can't use `apt-get` on my embedded stripped down linux? How 20th century" :p 
Yes, I faced exactly the same question, and came to the same conclusion as other people have. If your app is compiled it might not have the source files, so won't have the templates. I ended up trying a couple of options, then turning to go-bindata. Here's how I use it with go-generate: https://github.com/kego/process/blob/9aeb13a86629d563906bf6ce4c50daa79b1f6960/process.go#L1 ... and here's how I consume the templates: https://github.com/kego/process/blob/9aeb13a86629d563906bf6ce4c50daa79b1f6960/generate.go#L21-L37 I use IntelliJ as my IDE, and there's an excellent "File Watchers" plugin that you can configure to run "go generate" each time a template is changed.
I always see go apps as an API. Even internally, the way Go is organized, it encourages you to create reusable libraries with only a small front consuming the API. So I would simply create a REST API with maybe a websocket which sends JSON updates from time to time. Then a front-end app can be written in whatever language capable of processing JSON/REST/Websockets. Websockets isn't even necessary, you can also use slow-polling if you don't have too many clients at the same time (which I guess you won't if it's "embedded")
Aside from Rust not really being considered production ready yet, I think there's a lot to be said for Go being simple and "boring" in comparison. I think that most programmers have a limit on how much complexity and innovation they can handle at any given time. If the domain that you're working in is innovative and complex, that consumes a lot of cognitive bandwidth and doesn't leave much for thinking about the language that you're working in and vice versa. Go is great for this. You can basically learn every aspect of the language fairly quickly and then not have to think about it, being free to focus entirely on the problem you are solving. The code might not be as elegant or "clever" and take a few more lines, but the advantage is that it's straightforward to write and for another programmer to read. Meanwhile, when I write Rust (or C++, Haskell, Scala, Perl, or any more "expressive" and complicated language), I have a hard time getting my head out of the language itself and thinking in terms of the application domain. So are you interested in your code innovating in the problem domain, or do you want other programmers to look at your code and marvel at the elegant, clever abstractions and micro-optimizations?
You forget that Go is based on years of compiler development and programming for Plan 9 at Bell Labs, before that. 
Honestly I find it way more flexible than Python doctests, because you don't have to include the code for test in the docstring of the function. Python doctests suck in that regard, because they tend to make the code of the functions unreadable. I think that Go has an awesome approach to documenting, in the sense that it encourages you to produce readable code first, which in turns produces readable documentation. But it is not the other way around, like in python, where you would produce lines and lines of docstrings to make your doc look good, but as a result your code will look like shit.
Go is much closer to its predecessor than C# is to Turbo Pascal.
I spoke to another coworker with some github stuff up, and we've both had the same problem: People often don't realize there's examples in the godoc, because they start out collapsed, and the little "example" can be easy to miss. So on the flip side, I implore you as readers... keep your eyes out for the little "example" links... behind them there may be a wealth of great stuff for you! ... 'course, it may be a useless oneliner too. But hey, at least give it a try! :)
Rust was a research project, and still hasn't hit 1.0. Go is on 1.5, and that 1.5 is meaningful, as each release has been production-quality and backwards compatible. They may both have started at the same time, but Go became usable much earlier (basically due to its lower ambitions), and it's not unfair to say it's significantly older in an important way.
Rust is significantly harder to understand and write, due to its type system being much stronger and making more demands on the nature of your code. Note "demands more from your code" is the key here, not "Rust is hard and I don't understand it", I generally do having written a lot of Haskell which is even more demanding. Rust _demands_ that you constantly be writing your code to be fully ownership correct, all the time, without stopping. I have limited anecdotal evidence this Rust is still slower to write even after one is fluent in Rust and only modestly skilled in Go; the Go still comes out faster. For the extra expense, the Rust code will run a few times faster (not dozens, like Python vs. Go, but probably 2-3x), avoid GC pauses by not using it, and be more correct in general. Sometimes this is a good tradeoff, and sometimes it isn't. I wouldn't dream of building Servo in Go. (I could see building the web browser UI shim, but not Servo itself.) On the other hand, "a quick microservice to give access to a MongoDB database with some basic business rules added" would be significantly slower to write in Rust and not meaningfully faster in execution than Go (both will be waiting on DB IO), even if it had a web handler as nice as Go's which it does not yet. (But that is a temporary situtation, I'm sure.) Rust isn't simply "better" than Go... it's a language that asks for more, and gives more in return. It's awesome that we have this choice, and I wish Rust all the best and will probably learn it someday (personally I'm really a 1.2-sorta guy, that's when I picked up Go too). They compete, but less than you would initially think.
Absolutely! In fact, it was my initial choice, as it's what I'm more familiar with. The major deciding factor was ease of installation (funnily enough). I do development on a mac, and getting Cairo installed there has presented problems in the past (my installation of Mac Ports seems to be busted). So, I went with a library that was easier to install on both my mac and the linux machine I use.
As a fellow Mac user, let me suggest that you use [Homebrew](http://brew.sh/) and not MacPorts! brew install cairo Then I had to do this to install go-cairo... export PKG_CONFIG_PATH=/opt/X11/lib/pkgconfig go get github.com/ungerik/go-cairo 
I'm a big fan of Homebrew :). Unfortunately it suffers the same permission problems as Mac Ports. (As far as I can tell permissions of various directories keep getting changed to ones that it doesn't like.)
Heh crazy how similar the code is.
Thats the best advice: I think its called data driven development. I often had the problem that my bosses wanted to do everything top-down while i was thinking bottom-up. Fixing the database first has been a middle point where management and developers can meet.
&gt; I know Go would always outperform Rails in cases like this but I’m interested in understanding what was wrong with my Rails implementation. Assuming that you didn't see something obvious like the CPU at 100%, which I really doubt, you probably just ran out of workers. You've probably got it configured to have 4 processes ready to serve pages, and you consumed all of them with a "page" that ran indefinitely. Under the load described and for the task described, if you were interested in staying pure Ruby, you probably want to look into EventMachine. But it might require a fully separate process and program anyhow, so if you've got the Go one in hand it may not be any advantage. And Go's "write straightforward code, let the runtime handle the scheduling" will still be cleaner than Ruby's event-based code, even as they've covered it with as much Ruby sugar as they can. Go will, technically, yes, outperform Ruby, but you're a couple of orders of magnitude away from the difference mattering.
Gin should support swagger soon, it's on their roadmap: https://github.com/gin-gonic/gin
I was also going to recommend Gin. Upvotes to you!
This! 
Thanks! :)
I can't easily tell from their website. What is Swagger?
When using Go and Docker, do you have to build a new Docker image every time you change your code? Or do you work on the code on your host machine, then build and run your Docker containers? In both cases, it seems like you'd end up with lots of intermediary Go app images. Is this the wrong way to Docker?
When using Docker, I would normally need to use a "new" container for every build. Using the"-rm"switch when you run the container will remove the container when it finishes running. However, I usually use docker-compose which handles the remove logic for me. When I run a Web application, I'll use something like gin with mounted Dicker volumes to live-reload my code whenever a file changes, bypassing rebuilding my containers.
As someone working at a start-up that decided to standardize on Go, I'll point out a couple of things. First - making a language switch isn't easy. We could incrementally begin using Rust for new projects, (who knows, maybe we will), but a wholesale rewrite of our code-base from Go to Rust would probably put us out of business. We simply don't have time to take on such a project, even if we wanted to. Another thing to note is developer experience. None of us know Rust; a couple of us have played with it a bit but nobody has done a major project with the language. We don't know what the caveats are when you use it for a large project, but we know the things to avoid for Go because we've been writing Go code consistently for the last year or more. The most important reason though - why should we bother switching? Go solves our problems. We're productive with it, we know the language, and we haven't found a real problem with using it for our projects that would compel us to seek an alternative. You can say that Rust is better than Go (although in reality I think it's more correct to say that the two were designed to solve different problems), but from a business perspective if a company like Docker or my own were to switch from Go to Rust, it would most likely be a highly risky move with a dubious return on investment.
Well, 1.4
I've been wanting to do something like this for a little while now, but haven't got around to it. You just found a contributor, my friend. 
I kind of assumed that is how it worked before reading the explanation. Originally I would have said that the compiler didn't check the all function could return two types (like a couple of the answerers suggest).
You should move each tool to separate directory, and then have them installed by go get github.com/polegone/gonix/... Don't use makefiles.
I apply a very light filter to what I submit here, preferring to be an aggregator and allowing the readers to vote up the stories they're interested in. 
Right now I see [an insightful peek into the compiler's special handling of the "comma ok" idiom](http://www.reddit.com/r/golang/comments/35d0b2/about_the_comma_ok_idiom/), [a talk about how the New York Times has been phasing Go into their production systems](http://www.reddit.com/r/golang/comments/35bg0q/using_go_at_the_new_york_times/), [the beginnings of a rewrite of the *nix tools in Go](http://www.reddit.com/r/golang/comments/35bx86/this_is_an_experiment_ive_been_working_on_for_a/), [CloudFlare's own implementation of the standard crypto system which they intend to push upstream](http://www.reddit.com/r/golang/comments/355xs2/go_crypto_bridging_the_performance_gap/), and [a Go implementation of the ssdeep fuzzy matching library](http://www.reddit.com/r/golang/comments/35c5vr/go_implementation_of_ssdeep_fuzzy_matching_library/). But no, /u/car-show sees one "first impressions" post and that's "the best /r/golang can offer". Well, [put up or shut up](http://www.reddit.com/user/car-show/submitted/). Take your concern trolling elsewhere.
Thank you by the way :)
You're kidding me right? Why not take it a step further and use a flat file?
*cgo bindings
I'm developing on a local machine, not using docker images at all (unless I need to run some dep I don't want to build) When I'm done I can either build an image locally, or have the CI server build it for me. We have a base images with the SDK and godep, etc - that's more or less constant; A "build" image that builds the project and runs the test; and a "run" image that just contains the artifact and not the SDK and tools, which is actually what gets deployed. We have a tool that aggregates the entire build steps of the build/run image into one docker commit (from docker's perspective, it runs a single step of a fabric script). So basically a build generates 2 new images per build, but it doesn't happen quite often - only when I'm ready to deploy. I'm not sure how we manage garbage collection for our docker server, as I haven't written this infrastructure. But I can ask if you're interested. Also, we have vague plans to open our docker abstraction tool - which lets the developer specify declarative style manifest file, that manages the whole build and deployment tool. It's really cool. 
Actually, there aren't really any changes coming to the Go language in v1.5. The two main areas of focus for that release are a new garbage collector and new versions of the linker and compiler that are themselves written in Go. The GC updates will have an impact on the runtime performance of Go programs, but won't really affect how you write them. I would suggest the real reason is more like: "Writing really great books is very, very hard."
&gt;Actually, there aren't really any changes coming to the Go language in v1.5. Actually there is one: [elision of explicit type for key in map literal](https://github.com/golang/go/issues/8589). It's minor, but it's still a language change.
&lt;nod&gt; You are correct!
Well sqlite lets you use the sql package so that you can swap out the db driver if you ever need to upgrade, so it's a good balance. If your goal is to build a lean site, requiring a db install is pretty clunky. And if your site is serving enough traffic that you *need* an actual db, you're not going to build it from a service like this.
So it is probably better to write docker rust? 
`` and '' translate to u201c and u201d respectively. They're not ordinary quotes. I can't tell you where it's documented, but it's a feature, not a bug.
I meant should I file a bug to document this feature somewhere?
I really want some thing like preprocessing. We actually need macros some times.
Yeah, lots of minutiae are undocumented. Hope someone, may be /u/natefinch (https://github.com/natefinch/godocgo) can edit the documentation to specify them. 
It's also basically a drop-in replacement right? Nice.
False. It's documented exactly where you linked to: &gt;Each span of unindented non-blank lines is converted into a single paragraph. *There is one exception to the rule: a span that consists of a single line, is followed by another paragraph span, begins with a capital letter, and contains no punctuation is formatted as a heading.* (Emphasis added.)
Nicely written, I too work on something that is not really new but performs better, it's just fun to futz around (didn't know that was a verb) with computers and optimization, even though there is not an immediate need for it. I also find Go very intuitive in what probably performs slow and what not, the pprof tool is invaluable really.
But it's like the top thing on the Star Wars reddit is people's first impressions of Star Wars, over and over and over again. This subreddit is more like Groundhog Day than Star Wars. 
Do you ever run into problems with code written on your local machine vs executing code in a container? For example, if you need to connect to your database, you'll need to check `os.Getenv("DB_PORT_5432_TCP_ADDR")` in a linked Docker container, but on my Mac, I have to hard code the Docker host IP.
didn't like smokeping?
You need to create your own Client and Transport: http://play.golang.org/p/bL1gIUID-p
Using your own write buffer prior to calling Write() does avoid unnecessary system calls, which are expensive if you do a lot of them. However, the buffer size can be kind of arbitrary without affecting the performance much. Appending a byte to a buffer a thousand times and then calling Write() is faster than calling Write() of one byte a thousand times. But whether you use a 1k or 4k or 8k buffer doesn't change the result much. Os.Getpagesize refers to the size of a [virtual memory page](http://en.wikipedia.org/wiki/Page_%28computer_memory%29) not a block of disk. Also, disk writes are generally buffered by the OS unless you use File.Sync(), so you don't really have to align them with disk blocks. It won't hurt, but it's likely not worth much extra effort. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Page (computer memory)**](https://en.wikipedia.org/wiki/Page%20%28computer%20memory%29): [](#sfw) --- &gt; &gt;A __page__, __memory page__, or __virtual page__ is a fixed-length contiguous block of [virtual memory](https://en.wikipedia.org/wiki/Virtual_memory), described by a single entry in the [page table](https://en.wikipedia.org/wiki/Page_table). It is the smallest unit of data for memory management in a virtual memory [operating system](https://en.wikipedia.org/wiki/Operating_system). &gt;Virtual memory allows a page that does not currently reside in main memory to be addressed and used. If a program tries to access a location in such a page, an exception called a [page fault](https://en.wikipedia.org/wiki/Page_fault) is generated. The hardware or operating system is notified and loads the required page from the auxiliary store (hard disk) automatically. A program addressing the memory has no knowledge of a page fault or a process following it. Thus a program can address more (virtual) RAM than physically exists in the computer. Virtual memory is a scheme that gives users the illusion of working with a large block of contiguous memory space (perhaps even larger than real memory), when in actuality most of their work is on auxiliary storage (disk). Fixed-size blocks (pages) or variable-size blocks of the job are read into main memory as needed. &gt;A transfer of pages between main memory and an auxiliary store, such as a hard disk drive, is referred to as [paging](https://en.wikipedia.org/wiki/Paging) or swapping. &gt; --- ^Interesting: [^Random-access ^memory](https://en.wikipedia.org/wiki/Random-access_memory) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cr4bpfb) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cr4bpfb)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I don't like when articles compare languages to web frameworks. Seems to happen all the time with Rails. I understand that the other is new to go, but the go example has compilation errors, is not formatted, re-implements functionality in the stdlib, and the control flow is not go-like at all.
Some code review from just scrolling through the codebase(not super comprehensive) - * Why use custom cli parsing code, instead of flags? * Why not just use a ```break``` instead? done := false for !done { select { case &lt;- sig: done = true case &lt;- timer: showStats(client) } } * In the above snippet, your `for` loop is also blocking on `showStats`, which could be undesirable since `showStats` is doing network requests. * I would use some sort of mature portable library that lets you render color on a terminal rather custom code. * You should gofmt on your codebase. I see un indented code. * I see a lot of magic numbers in the codebase that I have no idea what they represent like if len(parts) == 2 { var upsecs float64 upsecs, err = strconv.ParseFloat(parts[0], 64) * Your `runCommand` returns a string. There's no need to create a Reader and Scanner to iterate over a string - lines, err := runCommand(client, "/bin/cat /proc/net/dev") if err != nil { return } scanner := bufio.NewScanner(strings.NewReader(lines)) for scanner.Scan() { line := scanner.Text() parts := strings.Fields(line) Thanks for working on this. I enjoyed reading it.
&gt; Why not just use a break instead? The break will break out of the select, not the for loop.
Yep. Here's an example I wrote using BigEndian and LittleEndian: http://play.golang.org/p/1pdEjpKo-H OP can tweak it for your 24-bit case -- use Uint32() and then shift right 8 bits.
break label
OP here. Would love to have some feedback on this. It is something I've been using for quite some time and I just wanted to make it available for others.
Honestly, one of my favorite things about go is that I don't need a make file. One or the big underlying concepts of go is that explicit is better than implicit. I like knowing what I'm doing to the code without needing to dig into a make file to find out. If I want to save myself keystrokes, I'd rather make personal aliases. I'm sure some people who are more comfortable with makefiles will like this, but it feels very un-go-like to me.
That's correct -- it's also currently missing Hijack, ReadFrom, and WriteString. I'm working on this right now, but it's a bit complicated because we need type assertions like: hijack, ok := response.(http.Hijackable) to assign `ok` to true for real `*http.response`s and assign `ok` to false for `*httptest.ResponseRecorder`s. Good catch.
It also doesn't rely on global maps / mutexes like Gorilla Context. Hopefully this will make it more performant. I haven't done any rigorous profiling yet, but some local benchmarks look promising. I'll add real benchmarks to the test suite when I get a chance. The tests and README have simple examples of chaining. What kind of example are you looking for?
Gin is the RANT about Martini, I tried to worked with gin in a small project and when I tried to do something a little bit more complex I could not find any documentation about it, instead I migrate to negroni https://github.com/codegangsta/negroni and I got very impressed how easy was to work with, this is because negroni it only uses the standar library, wich is better documented and exploited
Sorry to see that as this guy didn't "prevail" with his arguments he just moved the discussion to another place trying to get more sympathy. He got a pretty clear answer already: language is one thing, tools (including the compiler) another. The directives in the comments are not language, are directives for tools. Comments are not code, thus they are a very good place for directives (unless you enforce all projects to use a Makefile for compiler flags, for example.)
Yeah, I wish the documentation on godoc were better specified. There's a lot of things it does that you can really only figure out by using it and reading a lot of other people's documentation... like which docs get formatting and which don't... there's even plenty of stuff I missed in godocgo... like functions that return a type getting sorted under that type in the docs.
I think the answer to the second question is maturity and the amount of 3rd party libraries + there are more Java devs on the market etc. Golang needs some time to be more robust and stable.
Pony is pretty interesting. Actually they wrote and deployed the runtime before creating the language, and actors were originally written in C. All GC is local to actors, so there is no global GC pause. There is no mutable memory shared between actors, unlike Go where you can share mutable data between goroutines. They have algorithms to handle distributed actor cleanup without necessarily having up-to-date information on global state. The whole thing could potentially run over a cluster (although I don't know if that code is out there yet). Definitely one to watch, although as yet only at 0.1, so way behind Go and Rust in terms of lots of things.
They chose java a long time ago, they can't just switch to another language over night, look for developers skilled with that new language and rewrite everything from scratch.
Author here. I did this for a side project a while ago and had a lot of fun. I'm sure there are lots of areas for improvement in it, but I hope someone finds it useful. Godoc [here](http://godoc.org/github.com/antzucaro/matchr). Cheers!
Depends of what you mean by large projects? If it's lines of code, sure it can be used for large projects. What I mean is that the "large project" has a small and clear logic. In other words, there isn't the need for an abstraction middle layer. This doesn't mean that it's easy or simple, just that is concise and restrict, well defined. When you want more open/abstract logic you will start missing some tooling that other languages give. For example, you will miss things like LINQ or Akka or other general purposes frameworks. This type of frameworks can still exist in Golang, and you can use it for projects. Just that IMHO there are better choices in that department. This doesn't mean that Golang is bad or something like that. It just means that the creators defined different compromises. And as such Golang is very good in some areas and not so good in others. As with every language out there... 
Can you highlight the advantages of this middleware over others, especially interpose (since you are comparing infuse to interpose)?
This. Golang middlewares are kind of like JS frameworks. It's getting crowded in here and the differences don't seem very clear.
Thanks, this is the final code. s.Pos is the reading position and s.Data is the byte slice I'm reading from. func (s *Stream) ReadUIntLE(count int) uint64 { var n uint64 buff := s.Data[s.Pos : s.Pos + count] s.Pos += 3 for i, b := range buff { n += uint64(b) &lt;&lt; uint(8 * i) } return n } func ByteSwap(value uint64) uint32 { buf := make([]byte, 8) binary.LittleEndian.PutUint64(buf, value) return binary.BigEndian.Uint32(buf) &gt;&gt; 8 }
Fair enough. A more complex project needs a more complex build tool and make may the right one. I'd still probably prefer a small script if it's as simple as chaining a few commands. I just would hate to see smaller projects start using a makefile by default. It would raise the barrier to entry for new gophers coming from languages like python. Edit: I'd personally also look into things like https://github.com/dshills/goauto and https://github.com/omeid/slurp for more complex workflows before make, but mostly just because it's one less syntax for my contributors to learn. The same argument works in reverse if your team already knows make syntax.
Of course that works too. Since this video is targeted to beginners (experienced programmers will probably have no problem installing go on their own), I didn't want to use brew since that would just be one more thing to install. I also cover things like setting up your GOPATH, installing an editor, and writing and running your first go program, which are important to understand either way.
Go Programming Blueprints was really good (I think the author posts here). Go in Action is a MEAP, but so far it's also a pretty good book. 
Infuse provides a per-request shared context value. Interpose does not provide this. You can use Gorilla Context with Interpose to get this functionality, but Gorilla Context uses a global map and mutexes, which is less than ideal (and has performance implications). Infuse also conforms to `http.Handler` everywhere, even when middlewares are chained. Interpose requires a special `UseHandler` method (which captures the next middleware in a closure) to do this. Infuse also provides a mock version of itself that's suitable for testing using dependency injection. Finally, infuse `Handler`s are concurrency safe and don't change once they are created. (I'm not sure if this is actually useful in practice though.)
Well, in this case, the slice content length is 202. However, when I use len(data) it returns 4084 which is probably the buffer size, not the size of the buffer content.
I suspect you are talking about the difference between len() and cap(). http://golang.org/doc/effective_go.html#slices
+1 - use this, love it.
Fixed. I didn't use the length from conn.Read and my buffer size was set to 4096. Therefore, len(buf) was returning a big buffer size which was correct but due to me not reslicing the buffer it was wrong.
That was the problem, after reslicing it everything works fine. Thanks!
Unfortunately the frontend stuff often won't play nice with make either. They really want you to use grunt/gulp/brunch/webpack/... (For example how do you generate a source map for merged sass files?) I usually just open two terminals one with the go code and the other with the frontend stuff. Sometimes they are separate projects. I have a project using pnacl which is more like a traditional c project. I used ninja instead of make since it's way simpler and a whole lot faster.
I'm contemplating commercial use and I have no problem complying with the GPL, or even AGPL. I think you meant "no company that wants to benefit from your work without reciprocating or paying it forward".
Don't get me wrong - there's nothing *wrong* with writing GPL'd code. It does make me sad that I'm unable to use such a well-written library for my particular use-case, but that doesn't mean the author is somehow wrong. And, to answer your second question - I'm actually doing that for certain libraries (none of which are written in Go, admittedly) - but it's not worth going through the hassle (and yes, potential expense) for libraries that are 'smaller'. 
Yeah, but the thing I'm doing is actually a 'distributed' binary. Go makes doing that really easy - you can just ship a single binary for the architecture you want.
They're tracking where people clicking in their e-mails? Wow, that's creepy, even for NYT.
What if at some point down the track you want to distribute your product? I have a pipe dream down the line where I actually sell virtual appliances &amp; black boxes of my software. Fairly sure this would count as distribution.
It could also mean "I want to release my software as MIT license, so that people are free to do whatever they like with it." Get off your high horse.
Really nice work.
ninja?
Then I have 500 folders I have to create, rename and every folder has 1 single file. Brilliant idea ...... And I don't work on the console, I use LIteIDE, CTRL+R to run, done. That's the reason I use an IDE. I guess your solution doesn't work in LiteIDE or any other IDE? Without me typing in the console at all of course = shortcuts.
I don't think so, gb and the go tool have roughly the same overhead, all the time is taken by the compiler and the linker. gb does try harder to always cache the results of incremental compilation because we've dispensed with the `go test -i`, `go build` vs `go install` dance -- but it's not a significant saving in the long run.
&gt; And I don't work on the console, http://i.kinja-img.com/gawker-media/image/upload/s--bfm5sLsU--/gaqifx9s5k33teds1xif.jpg
When I have to look at source code from one of the files I have to dig through 500 folders instead of having every file lined up for example. I'm totally fine with a mandatory structure like "src + bin + whatever config makefile or so". But I want to structure my projects in my own way, creating 500 different project folders because the Go toolchain is too dumb to handle when they all belong in the same folder because it's the SAME project but different parts of the project is nothing I will ever do.
Where did I hate Google? You can't distinguish between "criticism/I don't like something because reasons" and hate it seems.
&gt; http://i.kinja-img.com/gawker-media/image/upload/s--bfm5sLsU--/gaqifx9s5k33teds1xif.jpg 
So we have the gb-vendor plugin, this might be useful. It is a separate project to gb (it used to be included, but it became very confusing to say "gb doesn't use the go tool, or GOPATH, oh except for gb-vendor, which does use the go tool, and forges a GOPATH" http://getgb.io/plugins/gb-vendor/ The plan for the gb-vendor plugin is to possibly grow those features, but this is independent of gb, which is only concerned with building and testing code laid out in the project structure.
&gt; I drop Go, no need to stick around with a company that competes with Apple to force people to use their way. Seemed pretty hateful to me.
Thanks for the insights, so there seems no particular technical reason behind this. 
I have hacked up a basic SSH config parser, as that seems the most requested feature is to have SSH config available. Have a look how you want to use it, if that helps: https://github.com/dullgiulio/sshconfig
Pony is super interesting, and I'm excited to try it out, but it will be years before we know if it can deliver on its promises. Remember that Go has traction largely because it's easy to pick up; Pony's capabilities, for example, may prove too onerous.
To me, Go just adheres more fundamental philosophical ideas: KISS, YAGNI, DRY. Few examples: 1. It keeps things simple with orthogonal features. Implicit interfaces, types and method sets, functions and goroutines. 2. You ain't gonna need generics for most of your work, but Go stays practical and provides common generic types (arrays, maps, channels) and functions. Not to mention other popular language features that are absent in Go: inheritance, function overloading, operator overloading, const type modifier, exceptions as part of API, etc. 3. DRY: `func lerp(a, b, v float32) float32` and type inference of course. Go's iota for const definitions. Very lightweight syntax in general. Knowing these principles, you also need to learn to avoid extremes. For example the fact that Go always asks for explicit receiver when defining methods may seem like a violation of DRY. But at the same time it keeps things simple by eliminating ugly nesting (which is a bad idea in textual representation).
thanks
have you tried: https://clipperhouse.github.io/gen/ ?
I'm starting efforts to port our current gumstix based offerings over from badly written C to go. Already done a SettingsManager that controls phonebook/settings etc and generates a RESTful api to consume from my angular based frontend and our Android app. Really good language - wrote my own route handler and authentication stuff and the core libs make the C style stuff really easy to replace. I've seen no memory issues but we only have 512Mb and no crashes/OOM problems.
Predictions are hard, especially predictions concerning the future.
On my own PC at home I feel like I should be able to do so. Also, what's bad about "everyone structures tbeir projects the same way"?
The zen of python is quite similar to what I would write as the zen of go. Go is just much better at following it. 
It seems like Go was designed with at least a lot of the core concepts of the Zen of Python in mind I think python gave birth to a community of thinking that extended beyond the language that shaped Go weather we admit it or not.
I don't see something like that in the xml file, could you give me the name of the "id" field where this option is in the config? Do you know the command options to get "go run currentfile.go" into some valid parameters?
That's a good idea. Can you file an issue at GitHub, please? 
You need to reread the definition of "hate" ....
So you mean a main.go with 500 lines of "switch case" that parses the os.Args() and calls the parametername.exe when it gets a match? Won't do that because of 500 times switch/case, that's just insane.
Boom.
As mentioned here, quite similar to the zen of python. I'd also add: everything is a library. 
I submit: the sarcastic zen if go. 1) There should be only one way of doing anything, unless that thing is a go built-in function. 2) renaming is better than overloading anyways*. 3) Nobody needs a number type that's not already built-in**. 4) Always maintain go's type safety, unless you are a library developer, then just use the unsafe package to hack around it. *caveat for #2, see #1 ** My toilet paper is made of IEEE 854.
You *can* make it go gettable. To experiment, I made this wgo workspace go gettable (and wgo workspaces are by default compatible with gb): https://github.com/skelterjohn/tmplcute Or maybe I should say, I made that 'go get'able project into a wgo workspace, by adding in a symlink under src. You can 'git clone' and then 'wgo restore' to get the deps, or 'go get' in the first place (without pinned deps). Only issue is that that probably won't work with windows.
Here are a few comments: Solution #1: You can always mount the volume and then have a filesystem watcher look for changes in the files. Recompile, kill and re-run the app. This does mean that if the blog app fails your container is left hanging BUT you could always add a little more code to make sure that process stays running. What OS are you using with your docker? Solution #2: Just cleanup the images once in a while. Usually, I do this (it's automated of course, like my suggestion above) and then when I'm ready to deploy it I clean out everything I don't need and push the docker image up. Solution #3: Now imagine all of this, but automated in the container itself. My Experience: When I'm Dev-ing out a project on my machine I usually run a Vagrant (VirtualBox) instance of CoreOS. CoreOS has GREAT support for handling a lot of the things we've discussed with systemd and Unit Files. This also makes it REALLY easy to deploy your blog to a little CoreOS cluster or even a single machine. If you want more help let me know and I can show you exactly what I've done. 
I was doing this too! The only problem, I believe, is that Gin operates as a proxy before the application. And while this is good in development it means setting up a whole different method for production as well as having a few limitations such as ports, ip addresses, etc...
How is this different than a bash function that overrides the GOPATH if it detects a 'src' or a 'vendor/src' directory? To me, that seems much simpler to achieve the same result. Is there something I'm missing? What are the reasons for another tool? something like: go() { if [[ -d './src' ]]; then export GOPATH=$PWD; fi command go "$@" }
Why would you say Go is better at following it?
[Now I'm just a small town ~~pizza~~ **golang** lawyer, but local development is perfectly legal!][pizza_video] I use solution 3. I develop locally but take care to use [environment variables to pass configuration parameters to the executable][envirnoment]. That way I can configure the dev environment to properly point to dependency containers but more importantly, I can use the docker [link environment variables](https://docs.docker.com/userguide/dockerlinks/#environment-variables) to configure the docker instance to point to docker dependencies. You shouldn't have to change your source code in order to change operating parameters. My Dockerfiles use a commit hash or a tag or branch to pull a copy into a sanitized container. Then I use a go get and go test ./... to confirm the build works. I use the Dockerfile to create a tagged version of the project and push it to the docker registry. Like /u/dewey4iv, I use coreos to deploy containers to actual environments and this model of using environment variables helps to orchestrate those deployments as well. In the fleet service files I use tagged versions of the container along with cloud metadata to effectively put the containers where I want them. [pizza_video]: https://youtu.be/5Dg0ckpmpWM?t=10s [envirnoment]: http://play.golang.org/p/DYIih_R5X1
Spot on. Same here. How do you work the go get ./ with subbed projects? I've found this to be a bit annoying and I usually have to include a pre-build script (just downloads the dependencies that I need) before I get and build.
Please have a read of http://getgb.io/faq/why-not-wrap/
In the spirit of Python's Zen... Less is exponentially more Unless you're doing math, then less is less
Short and sweet :)
That's probably the solution a beginner would come up with.
I don't like that you use a global variable to control the behaviour of your package. That makes your package useless for all but the most trivial multi-threaded applications as there is no way to configure behaviour in a thread-safe way.
I understand, but that's how even http://golang.org/pkg/log/#SetOutput works. Your feedback to change it for good is much appreciated.
In the `log` package, that's okay because * it only pertains the standard log * which usually does not change where it outputs to once set up * if you need a logger without global state, you can use `log.New()` to make one Some other things: * You can't change the style back to the traditional style. In fact, calling `bytes.BinaryPrefix(false)` does nothing at all! * It's weird that the output for zero bytes is `--` instead of `0 B`. * You might want to defer conversion to floating point until after you figured out the suffix as to get greater precision; the current, logarithm-based approach is slow and might yield wrong results due to floating-point inaccuracy. If you like, I can show you how I would program a module like this so you can learn from that.
It's easy to be performant when you don't implement any functionality at all.
6) Every problem can (and should) be solved using goroutines.
It's a nice quote :) but could you be more specific? Echo is just a month old and for that age it's doing fine.
&gt; I would accept those as enhancements. What do you mean with that? &gt; Thanks for your suggestions and offer to learn for you! I'm always happy to help.
Correct.
I meant, I would take your suggestions and apply to the project.
Hm. I tried this, but then the Nginx container couldn't forward the connections to the Go container. I'm thinking the IP address for the Go container changed after `docker restart goapp`.
&gt; you should report issues in the repository so everyone can benefit. I just told you about these issues. I'm not really interested in your project (it's functionality is too simple for me to justify adding an external dependency to my project), I just wanted to give you some criticism; that's what you are asking for when you post your project on reddit. If you want, you can fix these issues but I'm not interested in doing any bureaucracy for you.
The benchmark is for HTTP routing only. It doesn't do much for now, but I have it for future.
Dude, I don't have time to argue on each of your message. If you want more information go the projects website and find it out. Thanks much!
Hmm ok, I'll take a look at that, thanks!
I had a few goals in mind for doing this: 1. Use very little vendor packages. 2. Create an application where modules can be plugged/unplugged. 3. Create an application that could have several clients. Ex. http server, cli client. 4. Get more familiar with Go. I think I accomplished those. I *tried* to be as idiomatic as I could but i'm sure I'm not doing some things right. I'd love any feedback you're willing to give. Thanks!
You seem to be complaining to me that your IDE doesn't do everything that the go command line tool does. I don't think that's my fault.
Ooh, wait. If I understand you correctly, are you saying that I could mock the link env variables on my Mac? $ WEBDB_PORT_8080_TCP_ADDR=1.2.3.4 $ WEBDB_PORT_8080_TCP_PORT=1234 $ ./myapp That way I can still use `os.Getenv` in my Go code, like usual. Is that right? Or am I way off?
Nice use of the struct tags. Will look at it further. 
input should be an io.Reader
Hey, thanks for that. I've actually found it useful for a sort of "catch all" helper package that I use from project to project. It's nothing special but it does make it easier to manage it all in ONE package rather than using 10+ repos.
OR if you are using docker just use the ENV in your dockerfile or the -e when using docker run. `export` has seemed to work a little funky for me. Granted I'm thinking that it's more due to Vagrant and how it runs it's provision commands. 
I'll make that next week's entry and share it with you! :) 
Schweet! That'd be freaking awesome! It kind of sucks that I'm still in school because almost none of my friends even know what a Docker is, so I can't sit down with anyone. The few of us that know about Docker are total n00bs. Yay reddit!
Ah, cool. I didn't even know about `os.ExpandEnv`. This is great. Thanks!
[http.HandlerFunc](http://golang.org/pkg/net/http/#HandlerFunc)
Posting here too because Gophers also have to deal with their share of negativity.
I don't get it, Most of the Rust articles out there suggest that people love Rust and are looking forward to it as a true replacement for current systems programming languages. The exception being one article posted today in r/programming where author argues why Rust won't ever replace C++. I highly doubt that Rust will ever get the same amount of criticism that Go gets for its design decisions
It's people we're talking about, and people like to complain. I can tell you for sure, in a few years we're going to see some articles with titles like "A Farewell to Rust" and "Why Rust's Design is a Disservice to Strong Independent Programmers Who Don't Need No Borrow Checker" being upvoted to top in /r/programming. Either way, the article is useful to any community trying to do things its own way. Correct the incorrect stuff, inform the uninformed, ignore the angry stuff, and carry on.
Yes, this is expected. The type assertion is saying that `someFunc` is a `Fn`. But it's not yet, it's just a `func(int) int`. However you can say something like `foo := Fn(someFunc)` to make it into `Fn`: http://play.golang.org/p/DiHSoPtjKa
What I mean is to join some open source project.
I second /u/davecheney: the default should be ignore. Ignore the incorrect, ignore the angry stuff, just answer questions as they are asked. There are other language communities out there (cough D cough) that constantly jump in on a thread anytime their language is mentioned. It's creepy as hell and very annoying, you can never just talk _about_ their stuff without ending up talking _to them_ about their stuff. 
it is not really clear to me what you are looking for. Do you want to contribute to the Go project? If yes, you just have to go download the source code from the website, see on github the issues still opened and follow the mailing list to communicate with other contributors. Do you want to contribute to whatever Go open project? My suggestion is: go to github, find a Go project you may be interested to, start using it, and once you are familiar with it the options are 2: 1) see the open issues and see if you can fix one of them, 2) you will find a bug yourself, you fix it and you create a pull request. How to find a Go project? There are plenty of them available on github. Just filter by programming language and you will find hundreds of them.
Rust and Go are at different phases of their [hype cycle](http://en.wikipedia.org/wiki/Hype_cycle). I'd put Go more or less just past the trough of disillusionment and now heading with steam up the slope of enlightenment. (Good news... that's the hardest part of the cycle, if you can survive that, you're good for quite a while.) Rust is just in front of the peak of inflated expectations. Cycle-reading isn't an exact science, it's all heuristics and stories-we-tell-ourselves-about-history anyhow, but that's my read... they aren't _quite_ there yet. In the next few months, a lot more people are going to go from merely watching Rust to trying it out, and quite a lot of them are in for a bit of a shock because it's going to be the first time they've really used a _strict_ type system like that. They're going to write $SOME\_STUPID\_ALGORITHM that's a one-liner in Python or something, and it'll take them a week to fight with the ownership, which they'll accidentally solve by copying everything everywhere, then post benchmarks in which Rust is ten times slower than Python because of that, and the complain about how the hype of Rust is all lies and whathaveyou. They'll post angry screeds about how they found 5 incomplete, buggy libraries, half of which don't compile, for something, and step up on a soap box to tell the Rust community exactly how they need to conduct their business because you just aren't a real language if you don't have a library for reading my precise crazy-ass CSV file format in exactly the way I meant. Huge discussions will explode on HN as people form opinions based on 13 minutes and 21 seconds of "Rust experience", decide that Rust is stupid because it doesn't implement $X, and the dev team is intrinsically evil because they're working on $Y instead, which is also stupid and probably evil. A lot of defensive screeds from C++ programmers are inevitable. D programmers will be jumping into the middle trying to slag both C++ and Rust at the same time. It'll actually be a bit amusing watching them trying to thread that needle, actually. People will start posting angry screeds from _both_ sides of the ownership issue, with both "I never needed all this in $LANGUAGE, how come Rust needs this, I totally wrote awesome code without it before, real programmers don't need all this it just blocks their awesome" from one side, and the functional programmers complaining about how the type system isn't already dependently typed and where's my higher kinds and basically "Why isn't this basically Haskell, if not Idris?" All of this is tediously predictable. I could dredge up posts from /r/golang for everything I gave above, yes, even that last line, yes, even both sides of it ("Go's interfaces are basically Haskell type classes except Haskell's are better, why didn't Go do that instead, or, basically, why isn't Go Haskell?"). It's not a bad idea to prep the community for it.
I've just got two questions for you, what u do and how you do it ? ; )
Go's about my fifth time around this carousel ride. I'm not a bleeding edge adopter, I'm more a 1.1 kinda guy, which is where I got in Go, but I've still watched this all before. Heck, /r/haskell _still_ gets periodic "I tried to write a CSV parser in Haskell and it's like 40 lines and it's 10 times slower than `[",".split(x) for x in "\n".split(f)]` in Python!" every couple of months or so! Haskell's got a bit of a problem in that all the "basic" libraries do strings via "linked lists of characters", which is pretty slow. You have to use the correct Text types, which will handily beat Python in speed if used correctly, and can be roughly as concise (that list comprehension syntax I used there comes from Haskell in the first place, after all) but, it is admittedly a bit more effort than it could be because the very base libraries are pretty old now.
Ok, I will join your guys and how to do it?
Taking the single example of "generics", most ranters seem to be unaware that the interaction between subtyping and parametric polymorphism is a non-trivial issue. And few (if any) languages with *both* those features, have been used to build current large-scale, decades-lasting, easy-to-maintain infrastructures. In that respect, the conservatism of Go (in approaching the problem) makes all the more sense. Interestingly enough, I came across a blog post from Eric Lippert (C#) a few days ago in which he was pondering on generic constraints with subtyping. Look at what he has to say on his attempt #5 for instance : http://ericlippert.com/2015/04/30/wizards-and-warriors-part-two/ That's perhaps the kind of article *serie* that could help people understand the design tradeoffs of a language, I don't know. Then again, it might be a waste of time for misinformed people who dismiss technical tradeoffs for emotional reasons anyhow: they are unlikely to read or try to understand the articles. 
so you add a rewind buffer. https://github.com/jordanorelli/moon/blob/a100556004be563a43964fb0f8a43c77efba4501/lib/lex.go#L134-L136
Just to add a little. The spec says: &gt; Two named types are identical if their type names originate in the same TypeSpec. A named and an unnamed type are always different. Two unnamed types are identical if the corresponding type literals are identical, that is, if they have the same literal structure and corresponding components have identical types. `Fn` is not a type alias, it's a new type, so it's always going to be considered different by the language. The two are however mutually assignable: &gt; A value x is assignable to a variable of type T ("x is assignable to T") in any of these cases: &gt; x's type is identical to T. &gt; x's type V and T have identical underlying types and at least one of V or T is not a named type. So you could use reflection: type Fn func(int) int id := func(x int) int { return x } var zeroFn Fn log.Println(reflect.TypeOf(id).AssignableTo(reflect.TypeOf(zeroFn))) If that's true then you know you have a `func(int)int` even if it was given a different name.
Go and the Zen of Python https://talks.golang.org/2012/zen.slide#1
&gt;http://ericlippert.com/2015/04/30/wizards-and-warriors-part-two/ That's a very interesting series, thank you for posting! One more programming problem to ponder while procrastinating :)
I'm biased since I wrote it, but for "humanizing" numbers (the term used by FreeBSD's [humanize_number](https://www.freebsd.org/cgi/man.cgi?query=humanize_number&amp;sektion=3) function in libutil) I prefer a more complete package such as [`bitbucket.org/dchapes/humanize`](https://bitbucket.org/dchapes/humanize).
lumost answered most of your questions, but to put it in different contexts, Kafka and Dynamiq don't necessarily attempt to solve the same problems - although with some bending, you could certainly use either of them for a range of situations. We feel Dynamiq excels mainly at it's stated purpose of being a fanout style queueing system, with a simplified consumer model (basically, a drop in replacement for sqs/sns). Kafka is a distributed log that offers some guarantees around ordering, but the consumer model is significantly more complicated, given the need to manually track offsets and "know" where your partitions live.
Don't get me wrong: It would be perfectly fine (that is, not a "beginners solution") to use something like a switch statement if the number of cases is reasonably small. But I agree that this approach does not scale well. To save a bit of typing work, you can replace the switch/case code by a map from string to function. Whenever you write a new Euler task function, add it to this map. The key would be the name you give it on the command line. Then you can lookup the function by its command name and call it. See a working example [in this stackoverflow post](http://stackoverflow.com/a/15507147/2322962). To be honest, for the ultimate reduction of this problem I was thinking of using reflection - I had something like a "CallFunctionByName(name)" call in mind, but it turned out that the reflect package [can do this only with methods](http://golang.org/pkg/reflect/#Value.MethodByName) but not with free functions. 
https://github.com/codegangsta/negroni is a really good middleware library
Thanks for the insight. This post was great. I definitely _knew_ that it wasn't a type alias but for some reason was still trying to _use_ it like one. I try not to use reflection unless I really have too (I'll leave that to `luar`). I just use the actual type for the check. 
Yeah, it's possible. He's using Gopher JS. https://github.com/gopherjs/gopherjs
&gt; https://github.com/codegangsta/negroni This looks way better. Thanks ^^ I think I'll most likely give this a go =)
I know it's possible, I'm trying to think whether it is a good thing or not.
It really depends on what your "real" app is doing. But, it could be as easy as using [net/http](http://golang.org/pkg/net/http). func checkAuth(h http.HandlerFunc) http.HandlerFunc { return func(resp http.ResponseWriter, req *http.Request) { // check if authenticated } } http.HandleFunc("/user-profile", checkAuth(serveUserProfile)) I've been able to use [net/http](http://golang.org/pkg/net/http) for a lot of routing. Though, I would probably use something like [gorilla/mux](https://github.com/gorilla/mux) or [julienschmidt/httprouter](https://github.com/julienschmidt/httprouter) if you had to do any subrouting. For getting data from the URL, you can do this. // note the trailing slash http.HandleFunc("/user-profile/", checkAuth(serveUserProfile)) // URL like /user-profile/12345 func serveUserProfile(w http.ResponseWriter, r *http.Request) { key := r.URL.Path[len("/user-profile/"):] userID, err := strconv.Atoi(key) // etc... }
Ironically, Github has automatically tagged the repository as JavaScript even though it does seem to be all Go. 
+1 for Negroni.
I've settled on systemd. I use debian/ubuntu on most of my systems and the writing is pretty much on the wall. I don't want to add any mental overhead to what I already have to keep track of.
docker :)
So manners again will pass currently open http requests that are still being processed?
supervisor
I've been using `screen`.
Ok cool. My worry was that it closed any pending requests. Since it doesn't, it's a good tool
Good article. It shows why subtyping and parametric polymorphism is a non-trivial issue. When working together. But you can still have both and their utility still be positive, as is the case in C#. Using the problem of Eric Lippert. It's resolution would be easier if C# hadn't have subtyping or generics? No. Personally, I think generics isn't an option and you have to encode the requirement into the Player class. I.e. instead of having the property Weapon, you have the method TryToEquip(Weapon). Back to topic. It's just a guess but I would say that generics would be problematic in Go because of implicit interfaces.
I was not aware of this. I'll have to take a look, thanks :)
I like the idea that both server and client side uses the same language (preferably a language that is more pleasant than JS). But the reality is that front-end developers don't share that enthusiasm. So it's hard to sell a setup/framework that force them to learn another language (and this language have little to do with their day-to-day workflow).
Clearly init.d is the only sensible option for people that like writing hundreds of almost identical bash scripts.
Why not systemd? It is far more easier and elegant solution, then go-daemon.
Well but its not portable. I dont mind of Windows but you cant use it on *BSD or UNIX. With go-daemon it basically schould work. BTW. hundley10 asked for a daemon not a wrapper.
There's dozens of us!
Running under screen is fine for one-time scripts that only have to run a little while. But running your production server under screen is bad: First, if the box reboots, your service will not come back up. (Neither will your screen.) Second, if your service crashes, it won't get restarted. Yes, crashes are rare. But even well-tested software has occasional problems (memory leak, corruption, etc.) Or sometimes some *OTHER* process has a memory leak and the OOM killer kills the wrong process. Third, the process will inherit all your current environment variables. So you edit your .bashrc someday, and months later need to restart the server for the first time. Oops, it won't start because it relied on some value of a variable like $HOST or $HOME. Or someone else tries to start the process, but it doesn't work because some file is owned by the wrong person. You need something like systemd (or Upstart) so that when you start the program, it's started the SAME (from a clean environment) no matter who starts it. No need for ' fork into the background'. That code was annoying and very hard to get right anyway. Use a modern service like systemd/upstart/etc.
Literally!
Things you will need to read: Effective go. https://golang.org/doc/effective_go.html Go database example: http://go-database-sql.org/ Build a binary that connects to the db and does the calculations. Run it on a cron job. You should be set.
I created this Video just now. Looking forward to your feedback!
Don't understand why this is getting all the downvotes. It actually answers the question.
The [CoreOS fleet model][2] has impressed upon me quite a bit. I use docker containers to isolate daemon related processes and Systemd to orchestrate processes in the context of a system as a whole. If there is no run time dependencies I will forego docker. I even use Systemd in the [user context][1] too! [1]: https://wiki.archlinux.org/index.php/Systemd/User [2]: https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/
Sorry but you don't need go for that. I would stick to PHP. Either use something like crontab or gearman to launch workers (PHP scripts) that will perform the calculations and populate your database with the result, as background processes on your server. There is absolutely nothing that would make the use of Go relevant here. 
runit
Its not that hard to create these things anyway. What value does using the library add?
Maybe you could provide an English translation for that is the lingua franca.
Done.
Systemd makes that easy, just make a proper service file. An example of systemd service config and init.d examples for older RHEL/CentOS and Debian systems for a simple server can be found here: https://github.com/zaf/agitator/tree/master/init 
On the other hand, learning new things is good!
That's very interesting. Thanks for sharing, I had no idea it had so many drawbacks.
Anything with more than one network/database/whatever connection.
The Go standard library has everything you need to write a Go web app. Using some vetted libraries like Gorilla's MUX and Context, negroni, logrus, etc. Just helps speed the development process along. I agree that you should stay away from depending on unnecessary libraries... But in some cases I prefer to take that risk. 
Gorilla mux adds a bunch of functionality to the standard server mux. If your intention is just to add logging and sessions then that's easy to do.
Thanks for your suggestion! I was trying to show a bottom-up design (refactoring to patterns) along with the introduction of interfaces.
There are always people carpet bombing positives for this as if they are paid to. There is zero utility in using this as you can replicate it all with a bit of work, using the standard library -- which is the stock framework critique, but it is particularly apt here.
You can do a lot w/out much code, like this example http://laicos.com/writing-handsome-golang-middleware/
Along these lines, I can't think of anything other than a chat application. Can you think of more stuff, buddy?
and it restart deamons unlike systemd ?
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Daemon (computing)**](https://en.wikipedia.org/wiki/Daemon%20%28computing%29): [](#sfw) --- &gt; &gt;In [multitasking](https://en.wikipedia.org/wiki/Computer_multitasking) computer [operating systems](https://en.wikipedia.org/wiki/Operating_system), a __daemon__ (/ˈdiːmən/ or /ˈdeɪmən/) is a [computer program](https://en.wikipedia.org/wiki/Computer_program) that runs as a [background](https://en.wikipedia.org/wiki/Background_(computer_software\)) [process](https://en.wikipedia.org/wiki/Process_(computing\)), rather than being under the direct control of an interactive user. Traditionally daemon names end with the letter *d*: for example, syslogd is the daemon that implements the system logging facility and sshd is a daemon that services incoming [SSH](https://en.wikipedia.org/wiki/Secure_Shell) connections. &gt;In a [Unix](https://en.wikipedia.org/wiki/Unix) environment, the [parent process](https://en.wikipedia.org/wiki/Parent_process) of a daemon is often, but not always, the [init](https://en.wikipedia.org/wiki/Init) process. A daemon is usually either created by a process [forking](https://en.wikipedia.org/wiki/Fork_(operating_system\)) a child process and then immediately exiting, thus causing init to adopt the child process, or by the init process directly launching the daemon. In addition, a daemon launched by forking and exiting typically must perform other operations, such as dissociating the process from any controlling [terminal](https://en.wikipedia.org/wiki/Tty_(Unix\)) (tty). Such procedures are often implemented in various convenience routines such as *daemon(3)* in Unix. &gt;Systems often start daemons at [boot](https://en.wikipedia.org/wiki/Booting) time and serve the function of responding to network requests, hardware activity, or other programs by performing some task. Daemons can also configure hardware (like [udevd](https://en.wikipedia.org/wiki/Udev) on some [GNU/Linux](https://en.wikipedia.org/wiki/GNU/Linux) systems), run scheduled tasks (like [cron](https://en.wikipedia.org/wiki/Cron)), and perform a variety of other tasks. &gt;==== &gt;[**Image**](https://i.imgur.com/aoofm3w.png) [^(i)](https://commons.wikimedia.org/wiki/File:Free_and_open-source-software_display_servers_and_UI_toolkits.svg) - *Components of some Linux desktop environments which are daemons include D-Bus, NetworkManager \(here called unetwork\), PulseAudio \(usound\), and Avahi.* --- ^Interesting: [^Windows ^service](https://en.wikipedia.org/wiki/Windows_service) ^| [^Background ^process](https://en.wikipedia.org/wiki/Background_process) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cr914gh) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cr914gh)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'm not sure I understand, what do you mean?
The OP asked about a library for middleware that's a bit more general purpose than the example he mentioned. Negroni in comparison is light and doesn't get in the way of anything. There are also many third party libraries that plug right into it. Negroni serves a purpose. But I agree that one should be weary of relying on external libraries for tasks they could accomplish themselves. I still think its a cleanly written library so I will use this implementation personally. 
And neither you nor /u/klaaax could reasonably have any idea whether or not this is that time.
I have used the `golang.org/x/net/websocket` package and I haven't had any problems with it. I don't see how the garbage collector could be an issue.
Does this make our point less valid? OP asked: *Thoughts?*, which is a very open question. Based on the rather limited information in the original post both /u/klaaax and me expressed very valid and reasonable thoughts.
Yes, it's suitable.
Seems to use a good bit of client's CPU. Interesting technology though.
I agree, it's better to stick to the language you have and try to have a clean architecture than using and whole other language. If he needs speed or something, go could be a viable option. But so would be C,C++ or whatever. Use the tools you need, for the job you want get done, not the ones who are popular. And if you want to learn something new, make a weekend play project!
There's also *cough* nice libraries (https://github.com/simon-whitehead/relayr) *cough* to make that a bit easier. (I wrote that one - works nicely for me)
Basically, it's when instead of classes (or in addition to classes in most cases), you have more or less blobs of properties. It makes the system more dynamic (while properties by themselves are statically typed in most cases, even in dynamic languages, see Django ORM for example) and flexible, makes it easier for procedural generation and user made content (such as scripting). You can easily encode rules of the system if you don't deal with classes on that level. For example, "only wizards can wield staves" can be encoded as checking for `baseMP` property. Basically it's composition taken to its logical extreme.
The best feature of Go is that is has very few features.
The way I understand it, he still wants the resolution to happen statically. But types are not enough, he claims, indeed. Some kind of Abstract Interpretation to track mutable state is what he is hinting at I think, though.
Well, yeah, types are not enough, unless you have a turing complete type system because rules can be arbitrarily complex, so you have to roll your own custom contract enforcement facility (and failt at it, see hilarious bugs in games like Skyrim).
Websocket or Long polling server. User submits job -&gt; Goes into queue -&gt; N workers take jobs off queue -&gt; User gets results. Doing this for a fairly complicated or long-runing task can be fun. The tricks come into reporting queue position and job status all the way through the pipeline to one or more interested watchers. 
You have to polyfill it for IE which is why SSE is not more popular.
server sent events in golang: http://sse.getgin.io/room/hn
I think you would almost always be better off using a single go process and running multiple goroutines (which the net/http server implementation will do without any extra work from you). Make sure you experiment with either the GOMAXPROCS env variable or using runtime.GOMAXPROCS to change number of real threads allocated. See http://golang.org/pkg/runtime/ for details. If you are just using nginx for load balancing among processes, you could likely also ditch that component for this type of setup. Of course, if you are using other features of nginx, feel free to leave it in place. In experiments last year, I was able to get about 750k requests/sec on a large EC2 instance with a single golang webserver and running wrk against it for simple responses.
Off topic, but I'm curious how you pulled off 3/4 million requests per second.
yes
"Arrays Are Passed By Value" - is there anything NOT passed by value? (hint: https://golang.org/doc/faq#pass_by_value) I know what he meant, but the way it is formulated can be confusing. Other than that, THANK YOU for an awesome article! :)
(self promotion, since I created wgo) I think that godep is the wrong approach. It tries to stick dep management *inside* of 'go get'. Specifically, the fetched package will have a subdirectory for the workspace, and to build that package properly you really have to treat it as primary (eg, run 'godep go install' from inside that package's directory so that it can use the internal workspace). But because of how Go works, you cannot have conflicting versions of a package in the same workspace. They're different packages, their types won't be compatible, and people are likely to get confusing errors. Package versioning really needs to happen on a workspace level. That's the approach that https://github.com/skelterjohn/wgo (and also gb, if you've heard of that). It manages the workspace for you, and has some tools to vendor and to pin versions. So, it's the *workspace* that has the versioning, rather than the package. There is only one king, and it's the workspace :)
I initially started this project to play with `go generate` after reading up on it [on blog.golang.org](https://blog.golang.org/generate). I thought it would be fun to use it to make a curated list of known TLDs and then use that to match urls. Although with the boom of TLDs, literally any word following a period could end up being a valid top-level domain.
I have been checking out go ORMs and found the following promising libs: http://jmoiron.net/blog/golang-orms/ http://www.hydrogen18.com/blog/golang-orms-and-why-im-still-not-using-one.html http://intogooglego.blogspot.co.at/2015/05/day-8-orm-comparison-in-go-today-gorp.html http://present.go-steel-programmers.org/talk-review-orms/gsp-go-orms.slide#1 http://stackoverflow.com/questions/19019117/orm-orm-like-lib-in-go 
Sorry, I just checked my notes and the correct number was about 600k request/second. I just verified again using a simple 'hello world' golang webapp with no custom settings besides changing GOMAXPROCS to 24 and see results from ./wrk -c 1000 -d 10 -t 10 http://localhost:8080/ Running 10s test @ http://localhost:8080/ 10 threads and 1000 connections Thread Stats Avg Stdev Max +/- Stdev Latency 7.71ms 51.31ms 816.88ms 98.07% Req/Sec 60.89k 10.04k 84.01k 70.30% 6089332 requests in 10.07s, 1.40GB read Requests/sec: 604525.60 Transfer/sec: 141.82MB This was on a c4.8xlarge, but I think I could have used smaller and gotten similar results. This is clearly a "benchmark special" result since I am running queries against localhost and doing no significant processing. The response above was primarily to answer the question about whether you need to run multiple golang processes compared to python based servers.
This is a beautiful package, btw. It doesn't seem like much when you create a Linux service and, yeah, there's my init.d file, but then you can install the same code as a *Windows* service... now *that's* cool.
Is it much different from [Go-Package-Store](https://github.com/shurcooL/Go-Package-Store), beyond being console app?
why gb tool is a better tool then godep?
Can you make a "go gettable" project with gb?
Nope, they are similar. The difference is Go-Package-Store shows and updates *all* packages from GOPATH, whether gofresh checks only relevant for the current project. It matters when you have a lot of packages in GOPATH.
I thought that the built-in websocket support was based an older version of the websocket protocol, I forget exactly what the issue was, but it is pretty much why you should use Gorilla websockets... well last time I checked anyway.
Ah, I wasn't aware of this. In my case, I was only sending short messages. That being said, if you're using web sockets to communicate with a web browser, it's inevitable since web browsers only read a single frame at a time.
One star, would not recommend.
This is pretty neat.
1. Choosing a language which doesn't have generics
Why, so you can get more upvotes on hn?
Thanks for sharing :) do you happen to know any go related resources with arduino
Go works at the folder level, not the file level, so why bother?
&gt; The bcrypt API be easier to use because it handles salt for application. Perhaps copy that API? The bcrypt golang API provided inspiration for this API. They are nearly identical, but I left salting up to the user so they could configure the size. That's how it's usually done with PBKDF2. https://godoc.org/golang.org/x/crypto/bcrypt &gt; Why give choice of md5 hash? Pick good hash for app to prevent mistake of md5? A gave the option to provide backwards compatibility with systems that are already using md5. I mention this in the documentation.
This will result in multiple package statements per file, a syntax error. 
I liked this https://github.com/Unknwon/build-web-application-with-golang_EN/tree/master/eBook or this as a really simple examples http://www.alexedwards.net/blog/golang-response-snippets
Quick link to actual 1st book &lt;https://github.com/Unknwon/build-web-application-with-golang_EN/blob/master/eBook/preface.md&gt; 
I've extended the minifiers and tested them thoroughly (also with go-fuzz). I'd love feedback, thanks!
Nope. Seems logical to me. That's the behavior I would expect.
This is my major beef with gb. Being able to install or update a binary with a quick 'go get' is a lifesaver. I work on a variety of platforms and can manage my go based applications in a uniform way. To be fair, I've only once been bitten by a problem using a single shared workspace. If gb can generate a stub main.go in the repository root that I can run I'd consider it, as I can live with running two command to install a binary. 'go get -d ...' Then 'cd ... go run main.go'
Personally, I don't quite understand what's surprising or an edge-case here. IMO, the only issue seems to be a lack of understanding of the language and doesn't really have anything (specifically) to do with append or slices. e.g. given `b := a[:N]; i, err := Read(b)` one would not expect it to be ok to index into, or slice `a` with `i` (I hope), so why is this *edge case* a surprise. 
append makes it clear that it's returning a (possibly) new slice by forcing you to assign it back to `a`. So it shouldn't be surprising when `a` and `b` are no longer the same. It's actually more surprising that sometimes append returns the same slice and so the alias *isn't* broken. It's a totally understandable optimization, but it would be semantically cleaner if it didn't :)
The answer is always complicated and varies depending on your local needs. But one generic answer is that many of the dynamic scripting languages popular today are miserably, miserably slow, and despite the common meme that it won't matter because the languages will always "be stuck in IO" it turns out not to be the case. A language that is faster and better at using multiple CPUs can serve potentially an order of magnitude or sometimes even two orders more than such a language, and even in "the cloud" using 10x or 100x fewer servers is nothing to sneeze at.
If you want to create an interface, then you probably don't know exactly how each concrete implementation of that interface will behave, and so it would be unreasonable to require all implementations to make use of all variables. Since methods are functions, the same rule applies to all functions, even those that aren't methods. That being said, I think it would have made sense to force the following: func boom(_ string) { fmt.Println("Having funnnnn") } I think you're right that it's sort of inconsistent of Go to allow unused parameters.
You mean something like this? func sum(x, y int) int { return x + y } func partialSum(x int) func(int) int { return func(y int) int { return sum(x, y) } } func main() { partial := partialSum(3) fmt.Println(partial(4)) //prints 7 }
Built in concurrency is one huge factor that helps you scale. A low memory footprint is another. Significantly faster than something like python and rails in most cases. Compilable code allows you to easily run it without external dependencies. All of that, and the standard library has everything you need to build a modern scalable web application.
Well keep us posted on how it goes. Go is so new still that seeing how people are using it is helpful and interesting.
IMO you shouldn't panic if given invalid `hpwd` values (e.g. ones with fewer delimiters than expected) but should instead return an error.
The library doesn't panic, it returns an error. Are you referring to the example main function in the README or something? If so, it's just an arbitrary example.
The [unused imports section](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/index.html#unused_imports) could/should link to [`goimports`](https://godoc.org/golang.org/x/tools/cmd/goimports).
Perhaps the [map capacity section](http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/index.html#map_cap) should be renamed and reworded to make it clear that using an extra argument to [`make`](https://golang.org/pkg/builtin/#make) with maps **does not** specify a capacity but instead an **initial allocation** and the map can grow larger.
I just happened to look at your CMS demo a few minutes before stumbling on your post here. It's the first thing that comes up for "Golang CMS" on google. Are you planning on formerly announcing the project soon? Looking at the demo, I see that content is called "nodes". Is Monsti influenced by Drupal by any chance? I keep getting application error when I try to add content on the demo. Is the demo meant as read-only?
When would this type of solution be better than something simpler? Just trying to wrap my head around it...
I'd build it for the Web and then use Selenium, web driver, or similar for your faked UI interactions. 
Functions are first class objects in go and are designed to be used as such. 
Well, you can do func (foo) Bar(_, y string) to satisfy an interface but show that you're not using x.
Yep, I agree.
If you mean further minifying JS, then yes. I want to shorten function parameter variable names and remove more semicolons/line-terminators using ASI, both will significantly reduce JS size. Maybe I'll add a few other techniques, but UglifyJS is quite extensive and I won't (can't) compete it. But you can attach the UglifyJS exec to the text/javascript mime if speed is not an issue.
That doesn't mean all idioms involving first-class functions in other languages are going to be idiomatic Go.
Does go have closures?
 // b "aliases" a b := a No, no it doesn't "alias" anything. b is a copy of the value of a.
&gt; A RESTful microservice to manage asynchronous tasks in the cloud. Wow that sounds webscale, very cool +1
yes
* Your style is not idiomatic. Getters should not start with `Get`, abbreviations should be one case (`PNG` or `png`, never `Png`), doc comments are wrong, and the package name is way too long (seeing how it basically validates magic numbers, it could just be `magic`). Consult: * https://golang.org/doc/effective_go.html * https://github.com/golang/go/wiki/CodeReviewComments * http://blog.golang.org/package-names * Too many packages. `bytescontentvalidator/types` should be merged with `bytescontentvalidator` (see, how long it is?). In Go, if you want to pursue the Java/Ruby-on-Rails style of "One module = one class" you're gonna have a bad time. [In the words](http://dotgo.sourcegraph.com/post/99652344343/go-team-q-a-dependency-management-language) of /u/davecheney, &gt;Packages should be at the granularity of an idea. HTTP is an idea; an HTTP client is not an idea. * Hungarian notation. Just no. * `int` is usually the size type. * Using `reflect.DeepEqual` just to compare two byte slices in an overkill. Use [`bytes.Compare`](http://golang.org/pkg/bytes/#Compare).
I often use this pattern in JavaScript when, for example, I want to construct different functions with the same essential structure, but a couple of different values. Most recently, some button events: button1.onclick = makeEventHandler(1); button2.onclick = makeEventHandler(2); function makeEventHandler(val) { return function(event) { console.log('button', val, 'clicked'); }; } Contrived example for simplification, obviously. In my actual case, the inner function was about 20 lines long. The example /u/dvirsky gave was also contrived - but essentially, this type of solution is useful because it often _is_ simpler. /u/hobbified's example could be implemented by creating a struct with a Writer member and a method that accepted a Gizmo, but sometimes just wrapping a function in a function is the easiest solution.
Why do you need to concatenate Go source files? What problem are you trying to solve?
It certainly would, so don't hold your breath. This feature won't make its way into Go 1.x.
Are they? One obvious advantage of Go is of course that the language was designed with concurrency in mind. But on the other hand Python 3 has now its *asyncio* module. **UPDATE** Uhm, is it too much to ask to explain why you're downvoting?
Another thing: You use the Google logo as an example image. While it is unlikely that they are going to sue you, you should not use images you don't have the permission to use.
You shouldn't write your own hash-map, you should revisit your requirements. In particular, why builtin map is not enough for you? ([edit] it's pretty obvious that there exist no such thing as "custom equality" as equality is only one in Go - byte-wise one, so I smell troll; if yes, please see my counter-troll: https://play.golang.org/p/UM6aJlM28D)
Thank you very much for your list of suggestions, they are really valid. I am a PHP/Java Programmer, so my first instinct was to create a module("Namespace Level") for every new class. However, I have taken your points on board and I have re-jigged the code. As regards the types package, I have still retained that because I think it promotes the separation of code, however since I have changed the package name to magic, it has reduced the overall package import name. I agree, bytes.Compare is better and I have used that. As regards the int/uint -&gt; Infact, I have changed that uint8 "byte", I think this would be more performant ("I may be wrong"), however, in any case , I don't someone adding a signed integer then. Anyway, like i said, thank you very much for your suggestions.
thank you very much. 
Thank you very much, I have changed the image, although I guess I would have loved the press that I would get from the open source community if google were to kill off "a young basic project" over use of logo, maybe that would even make the package a bit popular. Lol Anyway, thanks for your kind suggestion.
Yes, I think so. You can look at what is done in /runtime/alg.go for inspiration. What is your intended use ? Toy project ? edit: if it is for a toy project that will never ever.. ever... ever see production, I can help you as I've done this a while ago as a learning project of my own. I extracted a few files from the standard lib. But it was a toy project and there is some black magic of my own involved. Otherwise, are you sure you really need a custom hashmap ?
You may not need to write your own map implementation. It should be possible to write your own shallow or deep map comparison function for whatever map type you're using. The trick is to iterate the map keys, rather than use the built-in '==' operation, since Go's map implementation randomly hashes things such that two map instances are extremely unlikely to iterate in the same order. The other route is to roll your own implementation. But beware: the only fully generic approach must wrap `map[interface{}]interface{}` since Go lacks compile-time generics. So the best practice here is to either roll a specific map wrapper, or again, just implement the comparison function(s) you need. Edit: it *is* possible to create a type of the map you're interested in using, and write a receiver function for that type. IMO, this is as clean as it gets with Go: https://play.golang.org/p/gvvr6gGZON type FooMap map[string]string func(f FooMap) Equal(other FooMap) bool { // todo: iterate key list and compare maps return false }
Actually, gevent's pretty cool. The reason I've pretty much abandoned Python for this use case isn't that Python can't express concurrent solutions... it's more that it's miserably slow (PyPy merely brings it up to "slow") and that I'm tired of dynamic typing. And I work at a scale and in a place where both of those are fatal killers for me. Oh, and the fact that a lot of the ecosystem is still event-based, which is a really unpleasant way to program once you use something better. Gevent really should have "won". I fail to understand the python community's love of asyncio, it looks like a big hack when you have a nice concurrent runtime like Go.
Great suggestion - this would make for a nice community-edited document.
Sorry, to be clear I meant custom equality for the keys. Like overloading _ _eq_ _ and _ _hash_ _ in Python.
I am aware that Go equality mentioned in the spec is pretty much binary equals. Although from what I can tell for interfaces this isn't quite the case. See my message above for clarification.
It's very easy to code a production-ready hash map but it feels wrong when one is in the language already! It would be possible to extend maps to something like make(map[K]V, capacity, equalityFunc, hashFunc).
The default map/hash implementations are tied to the runtime, partly for additional protection against collisions and also, as far as I can recall, because the map is aware of the garbage collection process. So, I don't think that your idea is possible. 
I hear ya. Go, for better or worse, has *zero* operator overloading. &gt;You can't get there from here.
Maybe you can canonicalize your keys somehow. Say you wanted to use string keys but not be case sensitive, you could convert the key to a lowercase string before inserting it into the map and do the same when querying the map.
Fair enough. I just double checked, and it appears both Python and Ruby are adding cooperative concurrency. Not quite what I thought in Ruby's case. An improvement, but nothing like real green threads.
Curious. What makes it a microservice?
I was amazed the first time I used _ as a parameter and go let me after yelling at me for just about everything else when I was learning it.
Just make your key have what you want in it: type ( User struct { ID int64 Name, Email, Address string } UserKey struct{ ID int64 } ) func (u User) Key() UserKey { return UserKey{u.ID} } func main() { m := map[UserKey]User{} u1 := User{1, "name", "email", "address"} m[u1.Key()] = u1 } The only way I could see this not working is if you want to have a huge amount of data in your key, in which case you can transform that huge data into a single value (maybe sha256 it) and then use that as a key. Given those two options, why would you ever need a custom function?
That would be amazing. I have at least a couple projects percolating in my head that revolve around generating code from scratch.
nice! I've had so much fun abusing struct-tags, I think someone should write a book or a website about all the cool things that can be done with a little struct metadata.
Because it matches the definition of a microservice: http://en.wikipedia.org/wiki/Microservices The service is basically sending and managing "webhooks" from a RESTful API. This simple feature allows to implement differents use cases: - asynchronous tasks if you call your own URLs. - cron tasks if you use the "schedule" feature - webhooks to remote endpoints if you call your customer URLs
here is good web page with good articles . http://microservices.io/
I think it is important that the Go language was probably designed with automatic formatting in mind. For example, almost no code-formatter can handle a long expression of nested or chained ?: expressions in C or Java sensibly (that I know of!). As Go doesn't have that (?:), there is less initial resistance to a common formatter, and once established, there is no going back. Retrofitting a common standard formatter on a language not initially designed for it is going to be more problematic, IMHO.
I hadn't since mine evolved so quickly. It does initially seem quite similar but, personally (of course), i prefer [go-flagged](https://github.com/Urban4M/go-flagged) since it: * automatically creates a hierarchy based on nested structs. * registers the flags such that flag.Usage() works. * the public interface is similar to flag, i.e. `Parse`. * and the tag field names align with the names of flag's parameters. I do like gofigure's configuration through struct-tags. I might incorporate that. Thanks
It can be made significantly easier...it's all about the implementation. In Go all you need to do to use concurrency can be summed up in a few slides on the Go tour. Like ihxtx said, one can just type go func() and you're on your way. Channels might be a bit more complex, but they're straightforward once you learn how they operate.
There are some good replies here, so I'm gonna do a TLDR version. * **Microservices** architecture means that you do not deploy single application (like SOA), but you deploy many standalone "micro" applications. Micro services. * Microservice should be **single responsibility** service. Determine every action in your app. Each of them is a separately deployable service. For example, user logging in is a separate service. User logging out is a separate service. Max 100 lines of code. * How is that better than deploying everything as a single app? * 1. **Scalability**. When your application needs scaling, you scale only services that are critical, and you replicate only services that need to scale, instead of replicating whole app. For example service for serving landing pages needs to scale more than a service for editing users profile. * 2. **Availability**. When you need to redeploy or update some of your code, you only update/redeploy single service, instead of your whole app. You deployed a bug by accident? You don't need to rollback whole application, just the affected service. * How do they **communicate**? This is the biggest bottleneck of microservices. General rule is "clean endpoints, dirty pipes". Meaning that your exposed API is your priority, and how microservices communicate is up to you. Microservices should generally be as decoupled as possible. * 1. In order for your cluster to know the availability of certain service you need a **service discovery** system. This is basically a registry of all deployed services and their availability. There are a lot of premade solutions for this, like Consul, etcd, ZooKeeper, Serf. * 2. In terms of inter-services communication, most popular approach is **central bus microservice**, that serves as pub/sub system, and other microservices use it to publis messages and subscribe to others. A lot of service discovery systems have this built-in as well, through different event systems. * When are microservices useful? When your app requires high scalability and high availability. If SOA approach is good enough for you, its probably a better pick since managing microservices cluster is hard and not worthwhile if you don't require 30 instances of one service and only 2 instance of other. 
It's already announced, but it's not stable. It's mostly influenced by Kotti CMS, which itself is influenced by Plone. Compared to Drupal, nodes in Monsti are hierarchical. Yes, the demo is read-only.
why would Clang Format struggle at all with that? If the format tool, which is using the compiler frontend for Clang, can't handle that, then the compiler can't handle it, which it most certainly can.
This is a cool presentation. It's really easy to underestimate: 1. How difficult it is to write a good code formatter. 2. How useful it is for a language ecosystem to have a single automated style. Doing this is, I think, one of the smartest things the Go team has done. I work on [the formatter for Dart](https://github.com/dart-lang/dart_style). It's different from gofmt in that it doesn't do alignment (because our style guide doesn't encourage that), but it *does* do line breaking. In the presentation, Griesemer says comments are hard. If they did line breaking, they'd say compared to that, comments are easy. (Worse of all is dealing with *both* comments and line breaking.) The whole Dart formatter is just a few thousand lines of code, but I've rewritten it several times and am in the middle of another large scale change. It's probably the most difficult code I've ever written. One interesting decision an AST library has to make is where to put the comments. Most users of the API don't need them so you don't want to clutter the API up with them too much. Also, they don't really respect the tree structure of the program. It looks like Go's parser pulls them out into a separate list. The parser package from the Dart team makes a different choice. It hangs them off the tokens output by the lexer. For each token, you can access the list of comments that appear before. That makes it simpler to output everything in the right order. 
If you're going to commit to having a certain predefined set of stages, then consider one of these two alternatives. In real code the const will have to come first, but the harshest one: type stage byte const ( Preshutdown = stage(0) Stage1 = stage(1) Stage2 = stage(2) Stage3 = stage(3) ) Now the only way to have a legal stage value is to use one of those. The downside is that you can't store a "stage" anywhere, because the type is not exported. You can use `:=` to assign it in a function, but that's it. This is sometimes suitable for flag-like things, and your case is at least borderline. The other option: type Stage struct { stage byte } var Preshutdown = Stage{0} var Stage1 = Stage{1} var Stage2 = Stage{2} var Stage3 = Stage{3} Again, the only way for an external package to obtain a legal Stage value is by using the four values you've provided. This also has the advantage that external consumers can now store things with the exported "Stage" type. But you can't stop anyone from doing "Stage1 = Stage2" in their code. Though the Go solution to that problem is for the consumers not to do that. With either of these choices, it becomes impossible for an external user to call the function with an illegal value. (Internally you can still screw up, but, Don't Do That.) At this point, if you are feeling particularly saucy... func (s Stage) SetTimeout(d time.Duration) { ... } It looks like it would clean up your code to have func (s Stage) Notifier() Notifier { ... } func (s Stage) SetFunc(f ShutdownFn, v interface{}) too... very much a code smell to have First, Second, and Third appearing like that. "There are only three numbers in computer programming... 0, 1, and _n_." It is likely that you'll find a lot of other places where you've got a `[3]` really ought to be properties on the stage, rather than global arrays. type Stage struct { shutdownQueue []Notify shutdownFnQueue []Notify timeout time.Duration // .... } If the Stage type starts storing all those values, you can then start handing out `*Stage`s instead. And then once you do that you may discover that your code _further_ collapses and you can almost more easily offer users arbitrary numbers of "stages" that get tied together via a `next *Stage` or something, rather than a hard-coded 3. Behold OO. (One more thing pre-emptively, not that you've said anything but I've encountered it before and find it a bit aggravating... with all due respect, to a first approximation you currently have zero external users. Wait until you have some to worry about "backwards compatibility".)
And you'll fail miserably. Python has the GIL as well as heavy threading. Not to mention call back hell. Asyncio is *horrible* compared to go routines. 
You're probably being doenvoted because you're displaying ignorance about go versus Python capabilities. 
Ah yeah, when gofmt aligns other stuff like that it's super nice.
Haha, I planned to try something on EVE too. I know ahk but I'm currently trying to do everything I need in Go for learning purpose. But after some research it looks like there's no easy way, only C bindings
As someone who only started using Go a bit more than a year ago, vendoring (or the lack of it) already affected me in a very unpleasant way. One of my first go projects did not compile anymore with the latest package I used somewhere. I had to manually check it out by date to just to let my app compile again - but it crashed afterwards because some other package now responded differently in a certain situation. I ended up having to manually check out 6 packages which was a major pain in the ass. Now everything is vendored, but it is an ugly solution to a problem that should have been addressed in a much cleaner way by go itself. Sorry but if your toolchain pretends to do some form of package management (which Go certainly does) - it should be able to handle versions.
I havne’t had any issues with godep at all. I don’t find it “shackling.” I find it easy to use, simpler to install things and it doesn’t forgo the breakaway from the standard of Go - a single workspace. That being said, I much prefer a tool like [gom](github.com/mattn/gom) coming from a Ruby background, but it’s a lot easier to specify dependencies - however it breaks out of Go norm and modifies the GOPATH to do it’s magic. I switch from gom to godep because of [this resource](https://code.google.com/p/go-wiki/wiki/PackageManagementTools) and the subsequently linked page to Go’s endorsed approach of vendoring which is what Godep does. The tool recommend by the Go team (goven) has been deprecated in favor of Godep. Given that this is the approach they prefer and the potentially for vendoring to be integrated in to the go toolchain I would avoid any such approach that does “workspace management” to keep all of my projects in tune with the Go process for handling it. The desire to constantly break away from this set path is humurous to me because the whole point of Go was to create simplicity (and it’s dependency management does that, in an albeit terribly flawed way) and now there are tools that replace “go” commands, remove the concept of workspaces and calls them “projects” (gb, which doesn’t yet support libraries very well) and so forth. My advice, stick with godep - recommended by the team and potentially similar to somethign will see as a native toolchain utility in the future.
My original comment was at *-3* even before the discussion started. So please quote exactly the part of that comment where I'm "displaying ignorance".
I really want gofmt to honor the whitespace I put between operators, [not by way of precedence rules](http://talks.go-zh.org/2015/gofmt-en.slide#12). This drove me up a wall so I kinda stopped using gofmt.
I find the way it changes spacing around operators to help indicate precedence is a little weird. 
WRT where comments go, I'll highlight that on [slide 31](http://talks.go-zh.org/2015/gofmt-en.slide#31) is says: &gt; * Single biggest mistake: comments not attached to AST nodes. &gt; &gt; =&gt; Current design makes it extremely hard to manipulate AST and maintain comments in right places. &gt; &gt; * Cludge: ast.CommentMap &gt; &gt; Want: &gt; &gt; * Easy to manipulate syntax tree with comments attached.
Tiny nits for your example: you should probably either use your own `const HashSize = sha1.Size` (or just use `sha1.Size` directly) everywhere in place of `20`. There is no reason to use pointer receivers for the `Map` methods.
Generally libraries that detect file types use libmagic, you will get way more detected file types "out of the box" than trying to do this from scratch, though I am not sure if libmagic works on Windows, it works on all major Linux distros and BSD.
It's mostly glaring when the expression terms are doing array or member access, e.g. thing = ary[foo] + ary2[bar].member * whatever is way more readable to me than thing=ary[foo]+ary2[bar].member*whatever where the terms and operators become inseparable 'noise'. I guess I could first assign to well-named variables afoo := ary[foo] memb := ary2[bar].member thing=afoo+memb*whatever which is more readable but...I'd rather not. Whatever. Just wanted to throw in my 2c.
Thanks a lot for taking the time. I think you made a persuasive argument for the var types. I have changed the library to reflect that. It was great getting rid of the panic. The choice to go for a maximum of three stages is long-considered and on limiting on purpose. The aim was to get rid of what I call the "z-order" issue. This refers to CSS, where you can specify a "z-order" property on html element, that is used to determine the layering order of HTML element. The ability to specify any number in time leads to pure chaos on a page. Some people go for 0, 100, 200 so they can insert stuff later, and then use '99999' because "it must *always* be on top". But somehow, there is always a need for a '1000000' because this one element needs to be just one higher.... and so on. By limiting the design to "only" three stages enable you to clearly make design choices, and force you to run as many things as possible in parallel. With this you can write simple design docs (webserver example): * Preshutdown: Finish accepted requests, refuse new ones. * Stage 1: Notify clients, flush data to database, notify upstream servers we are offline. * Stage 2: Flush database bulk writers, messages, close databases. (no database writes) * Stage 3: Flush/close log/metrics writer. (no log writes) With arbitrary stage ordering you will quickly loose the overview of the ordering. If the database package needs the package logger to shut down after itself - how should it indicate that in a simple concise way? Don't think of the 3-stages as something that must do all stages of your shutdown. A single function call can of course (and is intended to) contain several "substages". Shutting down the database can easily be several stages, but you only register a single stage in the shutdown manager. The important part is that nothing else in *the same stage* can use the database. My intention is that this makes the shutdown process easier to manage, and encourage more concurrency, because you don't create a long daisy-chain of events, and doesn't force you to look through all your code to insert a single event correctly. 
&gt; One thing I don’t know (because of lack of research - all I know of wgo is what’s been passed around here recently) is whether wgo projects require wgo or not. They do not. For a wgo workspace /path/to/W, if you set GOPATH=/path/to/W everything will work fine, assuming the deps were copied in (and wgo helps you do that). gb is the same. &gt; Thanks for the reply, by the way. Thanks for being thoughtful with your critical feedback :)
How about using [reflect.DeepEqual](http://golang.org/pkg/reflect/#DeepEqual)?
Sure ...
Can someone explain to me why BSD code cannot be relicensed by third parties as Go licensed? I thought the two were (unidirectionally!) compatible. I mean, redistribution without (modified) source code (edit: even with redistribution limitations) is permitted under BSD as well, right? That is also a more limited form than the original code was released under.
Well, this sucks.
&gt; The choice to go for a maximum of three stages is long-considered and on limiting on purpose. No problem. Go's pretty opinionated about this sort of thing in general so it fits right in. I just wanted to make sure it was on purpose and not due to incidental implementations issues. Happy Gophering!
Incidentally, if you do need mixed structures, `encoding/xml` can actually do it out-of-the-box, though only on XML with tags and such in a certain way. `encoding/json` isn't really the best generic JSON parser (it definitely favors convenience over power, which is fine as long as you get that), and `encoding/xml` is even less so a generic XML parser, but when it works, it works.
It seems like the project shares goals with Camlistore. Might be worth a comparison: https://camlistore.org/ 
It is a flawed idea [to have an assembly implementation of crypto algorithm](https://go-review.googlesource.com/#/c/8968/2/src/crypto/elliptic/p256_asm_amd64.s) in a modern language. Edit: And yes, there is nothing unsurmountable [in Intel's BSD license](https://go-review.googlesource.com/#/c/8968/2/src/crypto/elliptic/p256_asm_amd64.s): &gt; We at CloudFlare can remove anything, but I am afraid that the Intel notice got to stay. It comes with BSD license. The same thing happens in number of files in Go: [1](https://github.com/golang/go/blob/fd392ee52b984e655390ad9147c9fe95e82bc459/src/cmd/5l/l.go) [2](https://github.com/golang/go/blob/8a3132dd5ec1e1ffcad1dfdb33d98ea9b134cd1d/src/cmd/6g/reg.go) [3](https://github.com/golang/go/blob/b986f3e3b54499e63903405c90aa6a0abe93ad7a/src/cmd/internal/obj/ar.go) The only problem Russ Cox has is there is no mention of the type of license: &gt; This is not okay. This is a copyright notice without a license giving the terms of use. I know agl@ is working with you on resolving this, but the final commit absolutely must make the situation in this file clearer than these two lines. He explicitly says that they *try to avoid* additional notices, not that it stops a patch from being merged: &gt; Also, we try to avoid additional notice requirements. The best way to get this code submitted would be to make it covered by the existing CLAs. In particular, if you work for CloudFlare then the right thing to do for your part of this code is to get CloudFlare to do a CLA and then remove the Copyright CloudFlare line below. Edit 2: Reddiquette, anyone? It is not like I don't have a point. Modern crypto algorithms, including ChaCha20-Poly1305 [don't have an assembly implementation](http://bxr.su/OpenBSD/lib/libssl/src/crypto/evp/e_chacha20poly1305.c). Nor does [ChaCha](http://bxr.su/OpenBSD/lib/libssl/src/crypto/chacha/chacha.c) and [Poly1305](http://bxr.su/OpenBSD/lib/libssl/src/crypto/poly1305/poly1305.c) separately. Or, for example, [Libsodium](https://github.com/jedisct1/libsodium) doesn't come with any assembly. [NaCl](http://nacl.cr.yp.to) generates assembly from [their own qhasm](http://cr.yp.to/qhasm.html). Even [PolarSSL](https://github.com/ARMmbed/mbedtls) (which is now mbedTLS) doesn't come with assembly.
Certainly encoding/json could be written in such a way to make this easier. I was thinking of how while writing this post :) but that's a bit too much work.
&gt; flawed idea I don't think assembly implementations of crypto are bad. Processor manufacturers added processor instructions for AESENC and AESDEC for precisely this reason - performance improvements of 10-30x. Since it's such a small portion of the entire go codebase I don't think it's much of an issue.
Fortunately, others have. You'll have to ask other people for reviews of the other JSON decoders for Go, though, as I've never yet quite needed them. (So far my biggest JSON use case I had with Go, it was OK for Go to dictate the terms of the JSON layout and I did something pretty similar to what your blog post suggests.)
Usually, the problems causing the crash are printed at the beginning of the outputs.
Yeah, that's the one thing I noticed about it too but I learned to let it go. I can't exactly do full math expressions anyway so who cares.
Yes, it can, but then we need an easy way to change the algorithms used in the TLS Package.
I put it in the original question.
Also, consistent timing is necessary to prevent timing attacks. There are things that you always want to have the same level of (in)efficiency - classic example is string comparison. If you bail out early as soon as you know the compare failed (usually the correct and fast way), an attacker can statistically determine how close he was to success, and incrementally deduce the secret value. It's one of the rare things in hacking that actually works like JASON stealing the nuclear launch codes. Many of these consistent-time algorithms can't be implemented reliably in C, let alone Go, because optimization is so ingrained in the way compilers work, and it's only a very small area where you want them turned off. Assembly is the perfect choice, or at least as good as it gets. On a modern processor, even machine code is a high-level language subject to god knows what optimization and RISC-ification before it gets executed, although it's mostly crypto engineers that hate this, and everyone else is happy to accept the speed boost. There's actually a source for that last part, but I'm on mobile, so hopefully someone else can find and post it.
The BSD license does *not* contain a grant to relicense the work. Each copy of a BSD licensed work is *directly* licensed from the authors. You cannot amend that license contract as a licensee. What is usually meant with “compatible” is that the restrictions imposed by one work are a subset of the restrictions imposed by the other work.
&gt;It seems like there is an opportunity here for someone to make a patch / repo [...] This is what cloudflare is currently doing at [cloudflare go fork](https://github.com/cloudflare/go). However, having to use an unofficial go build is just a nightmare. 
Seems very nice. I have actually been looking for something like this (and camlistore is just too 'heavy'). A few random notes after 30 minutes of first impressions: * The video doesn't help at all. It shows some random clicking around without any explanation of what I am looking at. I was considering leaving after seeing it. * The "sync" client isn't explained clearly. When looking at the homepage I have no idea why I would need it. It *works* really well, but before downloading it I don't know what I get. * On the download page, you should note that you are downloading the "freehold server". That would also make it more clear that "sync" is a desktop client. * Installation was very easy. * I would propose installing "Admin Console" and "Explorer" by default. * What is 'datastore' in Explorer? * Got [this error](http://i.imgur.com/hNm7M44.png). The text says "The process could not access the file, it is being used by another process." Not really sure what I did. * Owner for a file suddenly changed from 'admin' to a test user after using the Sync client. * Admins doesn't have access to properties of all files. * Upload/Download rate limiter on the sync-client would be nice. * Nitpick: "Admin Console" is perhaps not the best title. I associate the word "console" with a text console. * Sync is easy to set up, although I cannot see any way to set permissions of uploaded files. **Permissions UX** * This is difficult and essential for a good user experience. * Folder permissions are difficult to find (why isn't there a cog wheel as files?). * Maybe color coding permissions would help, so I can see who can access which files/folders? Could also be icons. * I experienced that in the 'Sync client' I could see a folder which the user didn't have access to. When I selected it I got a "permission denied" or similar error. Don't show folders that the user cannot access. * Being able to give "friend" access to a file in a folder they don't have access to is confusing to the user. * Default permissions (maybe for a folder) would be nice. If I share 100 files, as far as I can see I have to edit permissions on all 100 files. Sorry about all the negatives. Let me say that it **looks really good** the Explorer UI **works very well**, and with the exception of permissions is **intuitive to use**. I haven't looked at "Datastore Viewer" (no idea why I would need it) or the "Mindmap" (seems like a rather random addition).
It may take a while but I can't imagine why Intel would not let them relicense the code. It's in their interest to have things run faster on their processors. 
There's a lot of justification for it though. There are lots of boneheaded stubborn decisions made for the standard Go that everyone endures. It's a compiled language, this isn't necessary.
&gt; works like JASON stealing the nuclear launch codes Are you talking about [Joshua searching for the code](https://www.youtube.com/watch?v=tGNBdjVO04Y)?
It looks great! :-)
You can copy &amp; paste the whole library, for better or worse, then `import tls "github.com/cloudflare/fasttls"`. Modules aren't first-class citizens but you can relatively trivially swap them out wholesale at compile time, if you're in the mood. Of course you get transitive closure issues... if you're going to serve net/http over the new TLS you end up copying &amp; pasting that too. It isn't quite as bad as simply "putting out your own custom Go" but you can end up with a lot of libraries. It works, though.
&gt; If you bail out early as soon as you know the compare failed (usually the correct and fast way), an attacker can statistically determine how close he was to success, and incrementally deduce the secret value. Avoid that by turning off compiler optimizations (cc -O0) for source code that contains crypto algorithms. What you're telling is more painful. If there are assembly implementations only for popular architectures (amd64/i386), and the original implementation contains a timing attack vulnerability, then all other architectures (arm, sparc, mips, you name it) fallback to the original implementation and become subject to timing attacks. Even if there is an implementation of every crypto algorithm for every single architecture (which is hardly maintainble), assembly is less readable and more prone to human errors. It is easier to skip a bug in assembly during an audit than in C. And using assembly complicates porting. Edit: wording
Yep, misremembered the name of the sentient computer. Thanks for the correction and link.
You don't need to be a lawyer to understand a license. There is nothing cryptic and inaccessible to an ordinary person in a license. Probably some people want you to think another way by enforcing legalese in their EULAs, but most public licenses are not this way.
Ah, I didn't realize they already had that. I know, it's very suboptimal. Better than nothing I suppose. 
&gt; When you are using "cc -O0", C to assembly translation is straightforward. Only to audit. If you really need to use instructions that the compiler wouldn't normally use, like CMOV, you may have to bend over backwards to get the compiler to comply, and those workarounds may not be portable between compilers or compiler versions.
Not quite sure when you were elected as the decider of who can and can't post here. Just go about your day and leave the community to talk
I believe using CMOV in a crypto algorithm inevitably leads to a timing attack vulnerability.
I think you are correct about running out of memory, similar issue [here](https://github.com/gocql/gocql/issues/330)
 EAGAIN A system-imposed limit on the number of threads was encountered. There are a number of limits that may trigger this error: the RLIMIT_NPROC soft resource limit (set via setrlimit(2)), which limits the number of processes and threads for a real user ID, was reached; the kernel's system- wide limit on the number of processes and threads, /proc/sys/kernel/threads-max, was reached (see proc(5)); or the maximum number of PIDs, /proc/sys/kernel/pid_max, was reached (see proc(5)). http://man7.org/linux/man-pages/man3/pthread_create.3.html
I'm very curious why there's a reference to `runtime/cgo` in your stacktrace. Were you using `cgo` to call C code from your goroutines? What version of Go are you using? What OS? I'm not totally familiar with how the go compiler creates goroutines, but it doesn't make any sense that it would be calling pthread_create for each goroutine, as that's a standard pthread and it very much would run out of file descriptors after a few thousand, if that. Goroutines are supposed to be much lighter. I've tested a simple program ([here](https://play.golang.org/p/LYvvZdyxe3)) up to 10M goroutines and while it takes ~4 minutes to see any output as the main thread is starting up all those goroutines we do eventually start seeing the expected output. Go 1.4.2 on OSX. 
Did you not read the blog by a professional security researcher, who gets paid to make this stuff work reliably? Let me quote it for your convenience: &gt; One solution to these problems is the CMOV, "conditional move", instruction. It's like a normal "MOV" instruction, but succeeds or fails based on condition flags. It can be used in some cases to replace branches, which makes pipelined code more efficient in some cases. Currently, it takes constant time. When moving from memory, it still waits for data to arrive, even when it knows it's going to throw it away. As Linus Torvalds famously pointed out, CMOV doesn't always speed up code. However, that's not the point here -- it does make code execution time more predictable. But, at the same time, Intel can arbitrarily change the behavior on future processors, making it less predictable. You're not only wrong, you're perfectly opposite of correct. Even better, this blunder was completely preventable, if you had read the article I posted, which is fairly short and interesting.
This is cool. The task orchestration in celery is really superb but the problem with celery is that, by default, it uses processes to spawn tasks. I think you can use gevent to use coroutines but I guess that introduces a whole new problem. Lastly, I don't think celery supports asyncio from python 3.4. If we could combine goroutines with the rich task control support that celery provides all within one package, it would make for a really nice way to processes tasks concurrently.
Another advantage is that you can restart the workers without losing state.
Unfortunately for your rant, I have read this article a while ago, way before you have mentioned it, while it still was at HN top. I forgot that the article mentions CMOV being *practically* constant time instruction in this article, though. There is nothing that stops CMOV from being a variable time instruction if one of operands is a memory location. It is not time-proof to use CMOV in a crypto algorithm. You shouldn't rely on this behavior since it is not defined.
Indeed. Thanks :)
It depends on who you are. If you can contribute to the core Go code, yes, it is. If you can not, it turns out you'll find my approach a lot easier than changing the core Go code....
This error is usually associated with either making a lot of outgoing network connections (requiring a dns lookup, which is handled by cgo by default on linux), or by not closing http request bodies.
Crap, I started to drool so hard I'm now about to die of dehydration. Thanks.
If it's a shared, static config, just use a global.
IMO what you're trying to do could easily be considered an anti-pattern. I would personally either: - pass config to some struct and reference it via the field(s) - pass as little as possible to each function, don't assume entire config structs etc Usually going with the least amount of indirection possible leads to nicer implementations, but it sort of depends on the use-case a bit – though I'd certainly stay away from global config. I try to do all "bootstrapping" of config in the 'main' package, everything else simply becomes a package as if it were going to be open-sourced and used as such, rather than strictly designed as an application or CLI. 
I'm the author of Camlistore. What do you mean its security kills it? You don't need to use the signing parts to store files (nor encryption). And even if so, I'm not sure what limits that would impose. Where did you hit problems with the number of files? It has no known scalability problems.
Termbox-go is the base library for ncurses-like applications in Go: https://godoc.org/github.com/nsf/termbox-go
Bump for termbox-go, fantastic library, but takes a bit of learning if you're exploring without any prior terminal pseudo-graphics experience. It may not be perfect, but here's a little termbox-go snake game: https://github.com/pnd-tech-club/Seans-Go-Playground/blob/master/snake.go 
The question is way too general for any answer.
That's not really an accurate summary of the highlighted text.
I suppose *you* never tried to read and understand the GPL. [Go ahead](http://www.gnu.org/copyleft/gpl.html), it will take no more than half an hour to read *and* understand it, at worst. I despise it and prefer [ISC license](http://opensource.org/licenses/ISC) instead, by the way. My point is, there is quite a lot of definitions, and there is a lot of rules that make GPL. It comes from the nature of the license. Each rule, if taken separately, is easily understandable. While it takes some time to read it, there is nothing inaccessible or cryptic to anyone who is able to read in English. Edit: `wc` tells me that there are just 4614 words in GPL. It means it is just 37 times larger than this message.
I really wish I had a use case for this that html/template didn't suit better. :/
I pass around a `x/net/context.Context` everywhere and shove the config inside of that. 
I have used https://github.com/yohcop/openid-go with success.
What does the _ do there?
If you have a hard time understanding a relatively simple license (consider Apple EULAs), drop a line at rms@gnu.org with your question. The old guy is most likely nice enough to answer you within 48 hours. I'm all ears as well. Stop walking around the issue. Cut the crap. What are the details no one can understand? Sources? Law precedents?
There's also gocui https://github.com/jroimartin/gocui which is also based on termbox-go.
appengine https://github.com/akavel/openid-go https://gowalker.org/github.com/akavel/go-openid I tried one more but I can't find it now :/ 
I didn't know anyone took OpenID up as a new method anymore.
What is tip?
He is running it off the tip. As 1.5 gets closer to release status, that gap will close. He also just published the highest score(of 56 seconds), vs what he said was the median(16 seconds). I believe that outlier score was Golang compiler rebuilding files/libraries, before switching to more incremental builds. Still much slower then go1.4.2's 6 seconds.
According to Russ Cox the speed is unlikely to change much. However some of the cases of slowdown, particularly the 10x ones, are nearly worst case scenarios. 
Basically `HEAD` for Subversion and Mercurial.
I use an [environment object](http://www.jerf.org/iri/post/2929), which turns out to work out pretty well because as you refine your system into objects that are having methods run on them, rather than passing them "everywhere" you often end up just passing them to "a few places", then they end up available everywhere via the sort of natural struct embedding you'd be doing anyhow. It's much more convenient than it sounds at first. Still harder than global variables, but much safer and more testable.
To quote Steve Jobs: "People think focus means saying yes to the thing you've got to focus on. But that's not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I'm actually as proud of the things we haven't done as the things I have done. Innovation is saying no to 1,000 things."
Also, unused private functions/methods are OK.
&gt; Now repeat for uint32, uint64, int32, etc. In any other modern programming language, this would get you laughed out of a code review. In Go, no one seems to bat an eye, and the alternatives aren’t much better. The use of numeric types here is kind of funny... although his example (`Contains`) can be implemented for a container in C#, most numeric methods cannot. I can't, for example, write a generic implementation of `Average` for singles and doubles. This is because there's no type hierarchy for numeric types in C#. You eventually run into those limitations in every type system (though Haskell will take a lot further). You just run into it a lot faster in Go. &gt; You start to realize that Go isn’t actually all that great at what it sets out to accomplish in terms of fostering maintainable, large-scale codebases—boilerplate and code duplication abound. I didn't understand his argument here. Go is a very good language for large-scale codebases and I think that's proven by the quality of the standard packages. (ie a large-scale codebase) Well written Go libraries are remarkably easy to use. To give one example, take the yamux library (github.com/hashicorp/yamux). It allows you transform any `net.Conn` into a `net.Listener` by multiplexing streams onto a single connection. And then because so many libraries in Go take `net.Listener`s as arguments, you can now run TLS on top of that: func NewListener(inner net.Listener, config *Config) net.Listener Or HTTP: func Serve(l net.Listener, handler Handler) error Or any number of other things. In a dozen lines of code you can build sophisticated, high-performance, easy to understand applications. &gt; Go needs to let go of this attitude of “you don’t need that” or “it’s too complicated” or “programmers won’t know how to use it.” It’s toxic. I disagree. Simplicity is not an accident. Go's conservative attitude is what prevents it from becoming like Java, C# or C++.
Generics are really useful tho.
Generics are like classes - useful in some very limited circumstances, but very often abused in ways that make your code significantly more complicated. I've been working in Go full time for 2 years and on side projects for 9 months more than that, and haven't really ever needed generics. I *have* enjoyed the simplicity of the language and the simplicity of third party code that not having generics encourages.
ok. I will give Camlistore a try. It may take a few days. 
So, you haven't needed to write libraries that are type-safe containers?
Great! It's in a pretty good state but if you have any issues or complaints please file an issue or let me know.
Classes are just one model. Sometimes they fit the problem space quite well. Most of the time I've found that they overcomplicate the problem, or rather, the solution. As usual, it just depends.
This has been open sourced since day 0, I actually submitted my solution as a public link, so there was never such disclosure. This test was unique, the intention is to share open source code to help people learning Go, or learn myself from feedback of others, not for letting copy my solution, which makes no sense.
I got just the binary and a short specification, as the one written in my README file, and had to do all the implementation from scratch by myself
Indeed. I am enjoying my fair bit of Go, but seriously, generics should be discussed again and again and again....
It's only v1 in title, and was in a lot of flux for years before that. They also didn't say they got everything right, and there's a couple examples of things they rightfully admit to messing up. What they did say though is that v1.x will be stable, and that they won't fix design flaws that break compatibility until v2 in some distant future.
I'm tired of these fence sitting pieces -- just use the language or don't. Go hasn't changed since it hit 1.0 several years ago, and that is a good thing. Rather than repeating the Osbourne Effect, you can use the entire language today without fear your investment will be obsoleted with the next point release. The important part of using Go is not complaining that it doesn't support generics or exceptions or custom iterators or monkey patching, ad nausium. The important part of Go is the simple, understandable, consistent, foundation it provides to build solutions on top of. This isn't complacency, it's pragmatism. 
When you wrap it, you have to restrict it to a single type or use interface{}, which then bypass compilation-time type-safety. 
Damn, won't be fun using compile on save
You do realize that most programmers know more than one language. Especially when go is a very young language in the grand scheme of things. &gt;Golang is neither functional nor object It can be both... Functions are a first-class type and can be closures, and structs in go are more than c-structs, they include visibility, and while they are more prototype-ey they are still classes. Just because it's not JAVA doesn't mean it's not object-oriented, and just because it's not haskell doesn't mean it's not functional.
&gt;python has lambdas and is dynamically typed does that make it lisp? I... what? functional/oop are language descriptors, they aren't a specific language. Python/lisp are languages... Thats like saying that rust isn't dynamically or statically typed even though it can do both... That's just dumb. 
I think the meaning of "blocking" is getting a bit twisted. The call to http.Get() blocks, because it prevents the next line of code from executing until it finishes. This is good because it makes it easier to track event sequences. Go makes it better by making it easy for other code, in the form of goroutines, to run concurrently.
What are saying?
Doesn't scale for the web? What does that even mean? One should not say "web scale" unless one is being ironic. I use Go because I find it pleasurable to code in &amp; after struggling with both Python's &amp; Node's frustratingly bad implementations of concurrency, goroutines was a breath of fresh air.
Yeah, I would not expect generics to be in 2.0 either. I don't see anything outside of go generate as being the go way for generics, although currently it's immature and as I think Dave Cheney pointed out people will create great tooling around it. But many other things, yes, maybe one day. Also, any discussion I've read on generics has not been a backwards compatibility issue - afaik most generics proposals would be backwards compatible.
This is basically the Go culture right here. Either hate it or love. God forbid you try to discuss some of its short comings to help try to improve the language. You can like something and use it every damn day and still be critical of it. Honestly that's the best time to be critical of something, when you have that level of experience. Also these articles can help the other people that are on the fence or researching using Go for their next project. Choosing a language can be a major investment for companies. And understanding it's shortcomings without having to make significant engineering investment and being stuck with tech debt is quite valuable. If I knew what I know now about Go there are projects I would absolutely use it for (web servers, message routers, etc) and others I would avoid (low level systems like databases, caches, etc). The more open discussion the better. Btw Tyler does discuss the nice things about Go as well. It's not always black and white. I just wish the leaders in the Go community would appreciate that. Maybe approach the community more like this: https://graydon2.dreamwidth.org/209581.html
Because you didn't read the article. "it quickly falls apart for even the most trivial situations. Further, you can’t add methods to types from a different (or standard library) package. Instead, you must effectively alias or wrap the type with a new type, resulting in more boilerplate and code that generally takes longer to grok."
Please explain to me what "web scale" means.
Yeah because the changes the Angular team made was universally loved. I want someone with a vision leading Go. Not someone that will bend to please the vocal minorities. 
And people will write and continue to write useful software in Go and enjoy doing so.
Look into the numeric trait (typeclass) Numeric in the standard library. It elegantly solves the problem. EDIT - Forgot to mention the programming language! Scala! This method will compute the square of any number type. It only accepts a specific number type and evaluates to that number type. So square[Int] != square[Double] def square[N : Numeric[N]](n: N) = implicitly[Numeric[N]].times(n, n) 
I believe that's why this article spells out that the author writes Go everyday. The trend has been that the complaints come from people that don't write much Go at all. And they are always quick to dismiss that many seem to be writing successful production code without running into these problems.
What are you going to do on this type within your library that's non-trivial since you can't call any methods or use any fields on it? All you're gaining is input and return type safety on something that you could probably write inline or into a function for that type. If its not a numeric type you're probably just copying of doing some sort of moving.
Not sure what you mean by this comment, but generics have been discussed many times at length by the Go team and the community. There has been plenty of "sane debate". But what's the point of continuing to debate it? Think about this: if generics were added to Go tomorrow, the whole standard library would need to be revised to use them. We would be left with a new language and ecosystem to surround it. In a sense, we'd be starting again. Sure, you might like that, but most of us would like to continue building on what we have. This is why I found this article pretty hollow. It's like "Go has issues, they should do something about them," but what we have _is_ Go. When we released Go 1 we defined it as such. There's no turning back now. If you don't like it, you really should use something else.
&gt; I will know that Go is a mature language on the day when I see a discussion where people actually discuss its shortcomings and disadvantages, But this article _is_ one of those! There have been many other such articles and discussions. It seems all some people ever do is discuss Go's pros and cons (I'm not really complaining; I'm happy people are interested). I have never seen anyone claim Go is perfect. But a lot of people do seem to get upset when their criticism is viewed as a feature. As has been said elsewhere; opinions will differ, and the "pro-generics" (or rather "pro-change") crowd doesn't get to have the only valid opinion.
Rather than a change in leadership I'd rather see folks make use of the language's open source nature and prototype some of these things. Show the community and language devs how its done and how useful the features can be without sacrificing what those that use the language like about it. That includes not adding features just for the sake of it. Then we can see if the community really wants the implementation included or not.
As long as people are happily writing software and don't see a need for these changes I don't see how those that want the debate think their talk is going to outweigh the writing of production code. The name calling/labeling of those that are happy with Go as is tells me that they already see a mass of happy users that the can't move.
trolls
If its political then its for sure not going anywhere. One of the selling points of Go is the careful adding of features because of merit. Nothings going to be added for the sake of adding it. So people can keep bring this discussion up for the next 20 years but it will be a complete waste of time.
&gt; That has 0 thing to do with adding a new features to language. I don't think we can have a sensible conversation if you don't consider the ecosystem when talking about language changes.
It appears, that if you'd been left to your own devices you would've chosen another language over Go, and your article is a drawn-out whine about Go not being like language X. It's highly unlikely that Go's feature set will undergo any significant changes, even in the medium term. So, one way you could end your resentment is by moving to another project that doesn't use Go. Whilst you make that change, I see many reasons why Go will end up dominating its domain.
Generics are missing not because you would use them, because you would consume them. Compare the collections story of Java vs Go. There's a reason for Go lacking so many useful data structures Java had years ago. Not to mention concurrent data structures. Java guy who would need a concurrent map would get an excellent concurrent map implementation by default. Go user would usually use a single mutex.
Generics are not well-understood if by "well-understood" we mean "people agree on how they should be done". There is no consensus on what is the best design for generics. Despite being very similar (when it comes to type system), C++ and Java and C# all implement generics differently. They differ pretty significantly in what trade-offs they make. Java was the last one to get generics partly because a bunch of very smart people who were experts on Java and JVM couldn't agree on the design. You can't have iterators unless you either have dynamically typed language like Python or generics plus some kind of protocol recognized by the compiler. I'm also not sure if you appreciate how invasive adding generics is to a language due to ways it has to interact with everything else in the language. For example, after adding generics you can pretty much assume that all the code that uses reflection (e.g. json, xml, database marshaling) is now broken and has to be updated to take into account generic types. But that's only the beginning of complications. With generics it no longer makes sense to have the built-in "generic" types (array/slice of T, map[T1]T2) so you have to come up with a way to replace them with library code. To make range work, you have to define some sort of protocol or interface that user defined types can implement and have the "user-space" array/slice implement those. The same for range on map. To make map work you need to define some Hasher interface that all types that you can stuff into a map have to implement. Those are just 3 things I can think of off the top of my head because I know they exist in C# but I haven't thought about all the issues caused by generics very hard. I do know there's more because both Java designers struggled with generics and Anders spoke about how hard it was to evolve C# and how easy it is to make a mistake and how they did make mistakes. Go + generics would either be some frankenstein compromise to keep it compatible with existing code or it would break lots of existing code. Neither option seems great. In theory breaking backwards compat is no biggie (and they would get to fix other mistakes in Go as well) but in practice look at Python 3.
&gt; Reverse engineering is taking apart an object to see how it works in order to duplicate or enhance the object. I had the binary myself, I was playing with it, trying around all cases, checking responses and headers, that's it.
thanks, i will go read up on the documentation
/u/hoffentlich pretty much understood as to what i was saying, the use of term RE is incorrect. When you say "trying around all cases" etc etc just wondering if the binary had help section in it ? ./&lt;binary&gt; -help ? which gave u info on the various flags and arguments, files etc the binary makes use of ?
You wrote that Go nailed composability, which I think is not correct. The way the language and standard libs work, it is hard to encapsulate things correctly. Example: embedding types inherit functions defined on the embedded types. If you provide a struct type in your library, and someone else embeds it in their struct downstream, and you implement a new function on your type, all downstream projects could break, even if all you did was add a function, which should be backwards compatible.
How about a Trie? It's a non-trivial implementation. https://github.com/tchap/go-patricia
Take a look at http.Transport
gorm looks like one bloated lib. I will use gorp anytime compared to gorm. Just look at the gorm syntax and i will want to puke!. You dont believe? Check out the gorp examples: https://github.com/go-gorp/gorp/blob/master/README.md or https://github.com/kimxilxyong/gorp/blob/master/README.md
there's no options, the binary just starts the server
In almost all of your cases it doesn't matter. There are some people out there trying to write high-performance code. In response to zero_coding, mutexes are faster for synchronizing access to shared memory. And, as mentioned, they are almost universally chosen over channels in the standard libs. Channels are simply threadsafe queues (with limited functionality). Use them where you might use a threadsafe queue or if you want to use select statements to coordinate multiple slow processes. For almost all other situations there are simply better, cleaner, and safer alternatives. 
Can you expand on your struggle with Python, and how you found Go to be better? I am picking up Go (and I come from a C/C++/C#/Python background) - and finding it hard to see why it is a "good" language. Some of the syntax makes me cringe. Maybe I need to keep at it for a while.
&gt; c got most things right wut
Which syntax makes you cringe?
Yeah, the btree implementation is actually faster in bulk. For instance, the Btree might take the list of items and multithread the lookups across all leaf nodes and then, in parallel, add items to their respective nodes cascading up the tree. That's pretty fast (Intel's PALM tree) but works best when the tree can work on multiple items at once. Or, if the btree is empty and there's a bunch of items in the first add you might do a really fast sort and construct the necessary nodes. etc, etc. None of that works if you call Add one at a time, setting aside the overhead of calling Add hundreds of thousands of times to do something that should be simple. The reality is that the BTree can contain highly specific logic around threadsafety to decide how it can best add items to itself in a threadsafe manner. FWIW, this is one reason I have trouble with Rust. Rust makes it harder to put the threadsafety inside the datastructure itself, which is where I think it should be if I'm shooting for maximum performance. As far as interface, yes, you can do that but interface method calls are not free. It involves an itable lookup (as far as I know). If you play with data structures that do a lot of comparisons of an interface, say Comparator with a single Compare method, you'll see runtime.assertI2T and some itab functions pop up on your CPU profile. As far as accepting interfaces of other types, sure, I could do that. But it's the same issue, any struct that happens to implement that interface could end up in the BTree. I agree that it shouldn't, but it'd be nice if I could verify that at compile time, but I know it's not the Go way.
It is an interface, so all you can do is invoke its single method RoundTrip and I think the documentation is pretty clear.
We're using go to write systems in the telecoms space and we benchmarked our smsc at 150 000 transactions per second. Including decoding, appending and reencoding the pdu's. Unfortunately I can't really share the source but I believe go is the easiest way to write performant transactions systems that I've used.
Oddly enough we actually used nsq for awhile before deciding it wasn't stable enough at the speed we were writing at. For most systems it would work very well I believe.
I totally forgot to mention the PL -- Scala. I've never used C#. This is the scaladoc page: http://www.scala-lang.org/api/2.11.5/scala/math/Numeric.html And a blog post using them: http://www.azavea.com/blogs/labs/2011/06/scalas-numeric-type-class-pt-1/
For http clients, it's behaviour can be configured using different RoundTripper implementations. By default, an http client will use an appropriately configured Transport struct (which satisfies a RoundTripper). By default, the Transport struct is configured to re-use network connections from a pool, timeout after a certain amount of time, use a certain proxy service etc. If you wanted to modify the behavior of your http client you have two options: 1. Use the pre-existing Transport struct and configure appropriately. 2. Write your very own implementation. As long as it satisfies RoupTripper, it can be used. You could do something creative like implement http over SSH, or some other crazy madness. 
Go's easy enough to set up that my advice would be to do a spike prototype to check it out. The reason for that is not just that no matter how you slice it, you're looking at something very hardware dependent, it's also going to be dependent on what exactly it is you are doing with that data. It's not an absurd hope that Go could do it on one well-outfitted machine, but your running close enough to the line that I can't promise that it can. Then again, I can't promise anything can, in the absence of more information. (Which I'm not asking for because this is one of those cases where all the fiddly details matter, and, well, here we roll back around to your need to spike a prototype to really see.)
Yes go is literally the only lang that is both web scale and simple pm if you have any other questions
The basic answer is that you'll need to put it behind a load balancer (i.e. HAProxy) and have it route requests to multiple server instances. You then can do a rolling deploy to take down one instance at a time and swap it with the newer updated code. Ideally this should provide you with 100% uptime throughout the upgrade.
One reason would be that because it does not break backwards compatibility we would not need to wait for 2.0. Since it does not seem like generics will be added anytime soon and because go generate exists I don't think it will be added unless someone comes up with a really good implementation that satisfies the greybeards.
Well x.(T) is a [type assertion](https://golang.org/ref/spec#Type_assertions) and (T)x is a [conversion](https://golang.org/ref/spec#Conversions) I'm not an expert so I can't tell you *why* they did it that way. And if you don't like overloading, there's also channel switches. I feel like there's not a lot of keywords or particular syntax in general, so maybe x.(T) isn't intuitive but it's easy to use and remember so yeah.
How is analysing packets going in/out not RE? RE isn't only about reading ASM.
Mozilla [Heka](https://github.com/mozilla-services/heka) is a log router written in Go. We use it for all our Docker Containers logging at New Relic. I cannot share the numbers but it definitely scales, and much slimmer than logstash. Some benchmarks I found online: http://people.mozilla.org/~mtrinkala/heka-bench.html
It usually won't break anything and breakage I'm aware of is usually trivial to avoid in the first place or fix after the fact (feel free to show/find an example where this is not the case). [The spec](https://golang.org/ref/spec#Selectors) has a few fine points about how the language chooses what to promote and when it turns ambiguous selectors into compiler errors and when they're allowed. If you add something that "conflicts" with a shallower selector in a wrapping type then the other selector takes precedence as before and nothing changes. The only "problem" I'm aware of is if I have say: type MyFoo struct { Field int } type Wrap struct { MyFoo pkg.YourFoo } func (w Wrap) X() { _ = w.MyFoo.Field // Immune to changes to pkg.YourFoo _ = w.Field // If this isn't mentioned anywhere it's // fine if pkg.YourFoo adds it's own Field. // If it is mentioned this becomes a compiler error. :( } Arguably double-embedding external types like this should be avoided for this reason. One fix if `pkg.YourFoo` suddenly gains a `Field` selector is to just use `w.MyFoo.Field` instead of `w Field`. What other "all downstream projects could break" cases are you thinking of? 
What aspect of this is a strength of Go?
Don't use mafsa - that was an experiment that only kind of worked. It's a bit clunky and needs more optimizing. (Anyone can feel free to contribute to it.) All you need for a simple, fast, in-memory autocomplete service is a radix tree. Here's a pretty solid one: https://github.com/armon/go-radix
http://play.golang.org/p/GIHvQm1ZF- Imagine LibFoo lives in a library package. Wrap lives in your project, it embeds LibFoo. The json marhsal output is `{"Field":"test","Foo":"foo"}`. Now imagine I extend the library and provide a default json marshaller for LibFoo: http://play.golang.org/p/hoWKY1ASfn All of a sudden, the downstream project's json output changes to `123`. To fix, you have to go and write a MarshalJSON function on Wrap, that manually marshals all of Wrap's fields. Bye bye helpful reflection. I had to deal with this in my real life projects. Downstream library adds something that shouldn't affect me, but it does. Edit: updated with clearer example.
I also use a radix tree for http://www.alphahat.com but I actually wouldn't recommend it for this use case. Radix tree works fine if you literally just want autocomplete in that you want to take a prefix and find all the strings that have that prefix. From my experience, that's actually not what you want. You want something that not only starts searching prefix but also searches substrings and misspellings then returns the results sorted by popularity. If you're ok paying for a solution, then you can use Algolia https://www.algolia.com/ . It's basically an API that lets you do what I described above. I'd personally prefer a native solution. Maybe we can collaborate on building one in Go! 
I used elasticsearch. (Connected to the REST API with net/http). Took some setup, but works well.
... you will have to define the problem much more concretely. If we assume "millions" is 10M, and you talk to 10 hosts -- you are already at 40Gbit coming off that box. You are going to have to buy some very fancy network cards and switches that will probably become cost-prohibitive fairly quickly. We currently are using an 80 thread (quad deca-core box) and while not getting linear gains, we are getting close with our unique workload. I suspect your experience would be worse unless you do intelligent batching. 
I'd love for more people to put [Caddy](https://github.com/mholt/caddy) through its paces. If you or anyone tries it for load balancing, do let me have your feedback. [Load balancing docs](http://caddyserver.com/docs/proxy)
How many companies? When I last worked with XBRL filings (which was admittedly a long time ago) there were surprisingly few companies doing it. If you're in the 1,000s then I'd just do it in javascript (assuming this is a client-side thing). But even if that doesn't work I don't think you need to do anything really special for this. If you cache some of your most expensive searches (perhaps all the 1 and 2 letter combos) I think it would probably help. In fact you could do a hybrid solution, with your JS preload the most common really short searches, and then only hit the server for everything else. Typing "A", then "AA" would then give the appearance of going really fast, and the data is relatively static. (maybe refresh it once a day)
I'll have to take another look at ES.
This sounds really cool. Where would I go to learn how to do this in Go specifically?
The reason you might use `interface{}` is when you don't *care* what the type is, meaning that you have no contract with that type. The standard library uses it all over because it largely doesn't care what the types are; it's a *standard library* that way. When you're writing code that relies on a contract, you use an interface. The interface specifies what you need from that type in order to use it. If you don't need it to expose any functions, then you *don't need a contract*, and `interface{}` is fine. The largest use-case for generics in other languages seems to be data structures in a Collections-esque framework. But hey, guess what? Go has that built directly into it's array/slices framework, because that's strongly typed - you never need to say `List&lt;Foo&gt;` because that's equivalent to `var something []Foo`. Or if you're afraid of rewriting the same function for slightly different types, *you can inherit functions* in different receivers, meaning you write one "generic" function which takes a supertype that defines the contract you need, and that function is usable from all subtypes. You haven't provided any example for why you actually think you need generics (more accurately, your example didn't make any sense), but perhaps with more experience with development you'll find you don't have one.
Yeah, XBRL is a major pain in the ass to use. I also started with XBRL and eventually just switched to Quandl data
+1 for ES... Fuzzy search is perfect for what you're looking for. https://github.com/mattbaird/elastigo is a decent library, the documentation on github isn't up to date but the godoc is good
That assumes you have your app's dependencies 100% vendored into that directory that you are renaming or relinking. In Ruby or Python, for example, if your dependencies change between versions and you don't have everything vendored, it's often impossible to do what you describe.
Looks great! I will look into including it as an option for my general purpose "make a HTTP handler more realistic" lib :) https://godoc.org/github.com/quii/mockingjay-server/monkey
I learned something more about go from you, THANKS! ++
&gt; for large scale file processing system using Go in AWS and it worked very well for us but that was distributed and de BTW, do you know of any open-source go libraries that can decode and encode SMS PDUs?
Also https://github.com/argusdusty/Ferret
&gt; Avoid that by turning off compiler optimizations (cc -O0) for source code that contains crypto algorithms. Eh... no. You have absolutely no clue. Achieving constant time for cryptographic algorithms is far more than just turning off compiler optimization. In fact, turning off compiler optimizations is likely to have no effect on the constant-time properties of a program.
And you, obviously, don't follow the discussion: &gt; Also, consistent timing is necessary to prevent timing attacks. There are things that you always want to have the same level of (in)efficiency - classic example is string comparison. If you bail out early as soon as you know the compare failed (usually the correct and fast way), an attacker can statistically determine how close he was to success, and incrementally deduce the secret value. It's one of the rare things in hacking that actually works like JASON stealing the nuclear launch codes. &gt; **Many of these consistent-time algorithms can't be implemented reliably in C, let alone Go, because optimization is so ingrained in the way compilers work, and it's only a very small area where you want them turned off.** [...]
Not asking for trade secrets, but which ways did you consider for reducing allocs? The most obvious is to just use sync.Pool, but I'd love to hear about some more subtle approaches than just reusing a pool of data.
You don't need a licence to use software. And we're talking about a "copyright licence" not a "software licence". There is no such concept in law as a "software license". And a copyright licence does not allow an owner/author to control use. They can control copying and distribution. I think most of your comments simply served to add weight to Dave Cheney's argument that only lawyers should comment here. In these types of discussions, the lawyers tend to understand why only lawyers should comment. Non-lawyers don't. I write and modify software as a part of my job, including open source software, and I interact with our legal team on such issues. I've learned enough from those interactions to know that I don't know enough to make comments without the lawyers help. Being able to read and understand the licenses is a small part of the problem. davecheney is right, and judging by most of the comments here, he's probably going to avoid reddit in future for these topics, which would be a loss for all of us.
https://github.com/skelterjohn/go.uik/blob/master/fonts.go#L40 is a function in a now-unsupported library I made that rendered text to an image. You can then overlay that image onto another one, since its background is transparent.
As it's already been pointed out this isn't a language question so much as an ecosystem question. I love working with Go but I don't find the current Go ecosystem as supportive of RAD web development as the other resources you mention. Django or Angular for me are FAR better at just getting something up and running. While I love Go I think there's too much of a sturggle with what should be basic components of rapid web development in it as compared to other ecosystems. For instance just the sturggle with integrating GORM with Revel or the limitations of the ORM in BeeGo that you quickly hit if you try to do any kind of complext querying or structure reveals the general difficulties with it. I do feel like this is a maturity issue and the problems in the ecosystem of Go are age appropriate and it's a fair argument to say that Go is pretty mature given how briefly it's been on the scene. Anyway, that's my personal experience.
You have to build libsass to use an implementation. If you look at the instructions for my wrapper, it tells you to build with brew or use the make file to compile a submodule linked libsass. There are OS X instructions, but you can inspect circle.yml for linux instructions or PR some! https://github.com/wellington/go-libsass#libsass This is just a wrapper, for a CLI tool and more high level library check out https://github.com/wellington/wellington
https://godoc.org/github.com/xlab/at/sms
&gt; Naturally, it's a pattern that's best avoided Why ? It turned out to be a very clean solution.
All that is being copied is the net.Conn and the io.Writer, not the references they point to.
Ahh! I missed it takes a pointer to the buffer. Thanks!
Generic drama due to no generics.
I haven't used it, but there's also https://autocompeter.com/
I made something a while back. github.com/jamra/gocleo It is used on an internal company search. It is a hybrid prefix and partial match alg that uses bloom filters for speed. 
RAD Web apps have an ecosystem that supports the rapid development of common web functions (usually crud). Sure, django and python have more to it but the ecosystem supports working with those very easily. Even .Net MVC has a better rapid development ecosystem. This isn't a discussion about better and liking Go isn't enough. Being able to make an HTTP server in a few lines of code is neat but it has nothing to do with rapid app development for the web. Lack of easy to use, integrated or mature Auth frameworks, ORMs, flexible templating systems are just some of the reasons why Go doesn't fit the mold for RAD Webapps. It's a new language, and the ecosystem in particular is still developing. So if someone wants to rapidly develop webapps along common development paradims there are much better solutions to that in place already than Go. If someone loves go, has the bandwidth to put into figuring these things out and wants to save work down the line in other ways then Go could be a good fit. If you're wanting a simple ecosystem to throw up and develop webapps though, there is no credible argument I can see for recommending Go for that use case.
Yeah. But my point is not how annoying a particular wrapping is, but the fact that you do have to wrap it, for no good reason at all: an upstream project doing what should be a backwards compatible addition. That was my point: Go is bad at encapsulation by default.
https://godoc.org/code.google.com/p/freetype-go/freetype
Thanks! That's just what I need. 
It probably depends on what you're doing. A lot of web development these days has moved off of the server and onto the client. You end up with a static host, maybe some routing and some sort of API. Go does very well with the routing and static bits. Assuming you know a little HTTP, it's just as easy as, say, flask in python. The API bits are a little trickier. If you already know the Rails or Django ORMs then the transition to go will be difficult. But if you're just doing plain SQL calls it will be pretty straightforward. For more traditional web apps you will probably miss a lot of the features Rails provides. Generating models, migrations, controllers, views, etc... Go is much easier to setup and run than Rails or Django. (rvm and virtualenv are not fun) Though node+npm is also pretty easy. Now if you are building something experimental, that doesn't easily fit in the rails bucket, you will have a much easier time of it in Go. For example: an API that supports Web Sockets, or a real TCP service. These are trivial in Go and really hard to do right in ruby or python. Though, once again, node also makes this straightforward. One advantage go has over all of them is that once you actually want to run your application on a server it's a whole lot easier than it would be with a scripting language. (no need for nginx, passenger, capistrano, bundle, rvm, and all their dependencies, you can just scp the binary and run it)
The templating packages are pretty flexable. I'm still not understanding the problems you have with it because the only packages that are really missing are easy to use auth packages but other than that it is dead simple. If your argument is that you have to learn Go,you have to do that with any web framework that you want to eventually use for production. 
How does this compare w/ https://github.com/duckduckgo/cpp-libface? From what I can tell DDG would just be prefix search but probably faster? Yours might work better for us....
Why mention an IDE at all? Just say "your favourite editor" (or perhaps list some fancier *optional* ones). The few times I had to use an IDE I hated it with a passion; I think the whole idea of not using the same single powerful editor for (just about) everything is flawed.
When you try to teach someone how to use Go (or really any language) you immediately run into this massive knowledge barrier. Regular people have never used a terminal or a text editor. You'll be lucky if they even have a firm grasp of files and folders. If a user already knows about vim (for example), then they probably don't need my help in learning how to configure the rest of their machine. The existing go documentation is more than adequate. But if they've never used a text editor, they don't even know that they need one. The entire programming compilation lifecycle is brand new to them. That's why the original book started the way it did: http://www.golang-book.com/books/intro/1. My hope was to alter the text here and link to the setup guide, but maybe I should revisit the installer.
Can you explain how it became unstable? Were all the queues in memory or were they persisting to disk?
Aaaand as Gophers we are lucky enough to be able to use the lib in process so you dont have to create a new process to run the fakes https://github.com/quii/mockingjay-server/wiki/For-Gophers
That would be nice if you could speed it up. Although we can cache most of the queries (e.g. "Apple, Microsoft, etc) we have some high volume users of our API that send high-volume queries that don't hit the cache very often.
Also, I was looking at LinkedIn's autocomplete and they don't seem to be doing any Levenshtein stuff (unless I am misunderstanding how Levenshtein works)....I tried typing in "brent adamsen" with an "e" rather than an "o" and didn't get any results.
Very cool - and it works on bash-via-mingw32 on windows too: http://bit.ly/1FJeFY9 Although I don't recommend typing 'go build [tab]' with a $GOPATH with 500+ packages :-)
&gt;And we're talking about a "copyright licence" not a "software licence". We are talking about a 'software license' because that's the term we use on copyright terms related to software, here read: http://en.wikipedia.org/wiki/Software_license &gt;And a copyright licence does not allow an owner/author to control use. Yes it does, since the terms of the license defines under what conditions the code may be used without being considered a copyright infringement. &gt;I write and modify software as a part of my job, So do I, that don't give you any authority whatsoever, perhaps you should have another talk with your legal team since they seem to have misinformed you.
you should definitely have a look over [awesome-go](https://github.com/avelino/awesome-go)
The latest beta version of the Zeus IDE adds support for Go Build tool. More details found here: http://www.zeusedit.com/phpBB3/viewtopic.php?f=5&amp;t=7495 **NOTE:** Zeus is shareware, runs natively on Windows and runs on Linux and Mac OSX using Wine. *Jussi Jumppanen* *Author: Zeus IDE* 
&gt; It sounds like you got burned by using a bad library. That's unfortunate. But go is a relatively new language, Well, actually not just one. Initially I planned to use several libraries, and on 5, 4 were mostly JBOD. &gt; and NAT uPNP is not exactly an everyday technology to use well, if you want the router you have at home to open a tcp port thru the NAT, what you do? It seems to me most of home routers are using it. Anyway it was good, because it showed me golang doesn't needs so much libraries, often is faster to write them by your own than debug other's ones. &gt; I don't think there's anything wrong with people noodling around with a language to get a feel for it. We've all done it. You did it. I am not going around to say people can use my code as a library for NNTP or whatever. Sure, I am writing beginner's code, but I don't pretend others can reuse it. What had made me astonished was not "a library is bullshit". What mades me astonished is, when I ask for a UPnP library, everybody suggests to me this one. Which is very dangerous, if you think to OpenSSL and heartbleed. &gt; You can't just trust that some repo on github is quality code. You have to dig in and check for yourself. Run go test -race -cover ... are there data races? Is the code coverage better than ~85%? Are there issues filed weeks or months ago with no responses? If there are hundreds of forks, why is that? How do they differ from the original? Read the code. Are there docs for every exported type and function? Is the code easy to read and well organized? Does it clean up after itself (defer f.Close etc)? Read the tests, are they easy to understand? Are they thorough in their attempt to cover all use cases? all that you mention takes more time than writing it from scratch... this is the point. I am astonished by the amount of rest libraries are around, and actually, it is much easier to rewrite them from scratch than to follow all checks you mentioned. So if we proceed that way, given the high productivity golang achieves, we don't even need libraries. The other alternative (to write them from scratch) is a time saver. This is why I say: ok, let's have a formal verification tool. So we can test formally the library, and we don't waste such a time to debug other's code. I think we agree to debug other's code takes a terrible amount of time, right? &gt; You can't formally verify my log rotation package, for example - it's not implementing a spec. That's what tests are for. And how can I know it won't crash my program, or that is not a waste of time to use it? I am just doing it for fun, but if my time was paid, I won't spent it on each log rotation library I find. It is probably faster to write one from scratch. This is the point. &gt; Your post comes off as pretty grumpy, and is not really a very good first impression to give the community. Well, actually I started with the good feeligs, and perhaps, at the end, I just would like to have an automatic formal testing tool. As I said, I am starting to develop **just for fun** thanks to golang, after 10 years. I won't say this is "grumpy", eing honest. But also I see some issues which needs, IMHO, to be addressed. Actually I won't have spent a minute of my time, if I was grumpy: grumpy people just says "that's bullshit, I go home". I never had seen a grumpy employee coming and say "I would like to have a tool for this and that". In my experience, they only mourn in the caffee room.... 
Caleb, go-plus author here. Please let me know if you have ideas about further simplifying a user's first experience with go and Atom. I have specifically tried to make the experience as easy as possible for a newbie gopher, and I want to continue to streamline that experience.
Formal verification is not a cure-all. It's incredibly laborious, and often in conflict with other important properties of software, like ease of modification, speed to produce new features, etc. 
I didn't say it is a cure-all. We are working wiht automotive and railways, so I know how hard it is. But actually once you define a policy, you can reuse it automatically. And often is the customer itself to define it. And also I don't say it is mandatory for who writes all software. But, having defined a policy, I can check against this policy any library, and decide quickly. So this is an acceptance criteria, not a project criteria. I don't see using formal verification as a must for people writing software, I see it as a self defense for people willing to use code written by others.
If you like goconvey you might also like [gunit](https://github.com/smartystreets/gunit) and [scantest](https://github.com/smartystreets/scantest), which I created as my own response to the goconvey project (which I started as well). They accomplish the same things, but in a very different style, and with less code. I haven't got around to adding them to awesome-go yet.
Hi Joe, I think the plugin is fantastic. It's very easy to get installed and almost everything just works out of the box. It even catches common mistakes (like not having a GOPATH set, or not having git installed) and gives you a sensible error message. That's why I thought it would be the best option for a new person. The upside to an IDE like Intellij or Visual Studio is that they do a lot to get a user started. You can develop applications in Visual Studio and never touch the command line, so that would be one less thing to learn. But I think even with an IDE, you would still use the command line a lot with go. It's just how the whole tool ecosystem is designed - so I'd be doing users a disservice by not covering it. I think Atom + your plugin does a nice job of making that as easy as possible without compromising the basic workflow. And unlike sublime it's a free editor that's actively maintained. The only issue I ran into with the plugin was that apparently `autocomplete-plus` comes with the windows version but has to be installed in the mac version. I'm wondering if maybe this is just a version issue - where maybe the windows version was slightly more up to date. Anyway thanks for all the work you put into the plugin.
This must be a version issue. autocomplete-plus was a separate package but now comes bundled (as of 0.200.0) with Atom. You should not have to separately install it on OSX or Linux. Oddly, this is only the case because I wanted atom to have a great gocode integration, and the built in autocomplete couldn't deliver a great integration. So @park9140 and I rewrote autocomplete-plus and managed to get it accepted by the core Atom team to replace the old autocomplete package. See also: http://blog.atom.io/2015/05/15/new-autocomplete.html
Go convey is nice, but super buggy. 
I'm (obviously) not a part of the Go creators, but here are my thoughts: 1. Type conversion cannot fail at runtime, type assertion can. 2. On the lower level, [interfaces are structs](http://research.swtch.com/interfaces), so you can think of them as having two "fields", `(type)` and `(T)`. 3. See point 2. It's not as much "overloading" as just a usual switch on `(type)` "pseudo-field" of an interface. It'd be interesting to hear from the Go creators though.
If you like goconvey, you may also like [ginkgo](http://onsi.github.io/ginkgo/)
&gt; not as much "overloading" dunno ... the two seem orthogonal to me. Look at how the switch value behaves: switch t { case ' ', '?', '&amp;', '=', '#', '+', '%': return true } switch t := t.(type) { case bool: fmt.Printf("boolean %t\n", t) case int: fmt.Printf("integer %d\n", t) } In the first case the case values match the value t. In the second case they match the type of t. But from the syntax, it looks like both are switching on value to t. Just in in type switch there is a magical unseen entity that holds the type, that the cases match.
&gt; My question was why they decided on separate syntax for type assertions. Could they not have used the T(v) syntax and do what they have to do under the hood? Because [this](http://play.golang.org/p/Fd0yAQUX-T) maybe? If you want a direct answer from the Go authors, try the golang-nuts mailing list. &gt; I mean, other languages do this - with no loss of intuitiveness. In fact, you could argue that it is more intuitive. Sure, but other languages are not Go. &gt; Looking at the link, seems like in the expression v.f - they refer to f as the selector - not the "dot". The dot is a dot. It's required in a selector expression. I don't know how else to explain it. What would you use instead? &gt; What is the terminology they use for fields / methods that "belong" to a type then? That's what they use. "Fields" and "methods" describe *values* that belong to a type. (Although, technically, [methods receive function values](http://golang.org/ref/spec#Method_declarations).)
Most definitely coming. There's a lot to write down and we're just getting organized. 
Thanks for responding! 1) We are the people who need it. We organize GopherCon (and maybe a few other surprises too) 2) We are coders, too, we know what we're doing there. But between organizing a huge conference and keeping our day jobs satisfied there isn't a lot of time to go off building the tools we need to do this right 3) there's a huge gap for this sort of tool. Nobody has done it in FOSS, the commercial tools are crazy expensive 4) We aren't asking people to write it for us, we're asking them to write it with us 5) We've done several other successful open source projects (SkyNet, SkyDNS, captainhook, vault, go-mysqlmock, many more) so we know that you can't have a successful project without a good start and community involvement. 6) I see repeated requests from new developers on this subreddit alone asking for projects to contribute to where they can have mentors and learn Go. We're looking to provide one of those. See the issue #9 for our thoughts around that specifically I hope I've corrected my original lack of details well enough. If I missed something, do let me know. Thanks! 
I added quite a bit more background on the wiki. It barely scratches the surface of the required documentation, but should give a better idea of where we're going.
I totally agree with you!
Good luck. I'd help but I'm snowed under at work and writing a book. Take a look at http://www.easychair.org/ for inspiration - I've used it a little and although it was ugly it worked pretty well.
My bad sorry Mr Pike
It's funny that you should say that, I was just working on a setup guide: http://www.golang-book.com/guides/machine_setup, and the book would walk you through the language: http://www.golang-book.com/books/intro. The go docs are very good, but a little more advanced: http://golang.org/doc/install and http://golang.org/doc/code.html.
[getgb.io](http://getgb.io/) - vendoring for Go projects without import rewriting 
Have a read of my talk from GDG Berlin, http://go-talks.appspot.com/github.com/davecheney/presentations/reproducible-builds.slide#1
Thanks. I was just thinking I need to write a scraper today.
Formal verification would be really interesting. What kind of formal verification tools/languages/etc do you use in other languages? How hard would it be to adapt one of these for Go?
How about self-classification, i.e. encouraging people who publish code to rate it as "alpha", "beta" or "stable". Then there can be meaningful discussion about whether the code meets the classification without discouraging people who just want to put stuff out there in the open-source style of sharing/cooperation. It is still valuable that people put out "alpha" code because someone else might build something much better from that starting point.
One of the ideas I had yesterday was to use GopherCon's 3rd day -- the HackDay as an organizational day.
This is very useful, thanks.
&gt; well, if you want the router you have at home to open a tcp port thru the NAT, what you do? It seems to me most of home routers are using it. I think what /u/natefinch was getting at is that most people don't write code where such a library is necessary or even useful. 
I would like to help you out. Feel free to PM me. This might work better if we could communicate more directly, at least in the start. I can help with both the backend and the frontend. Have a nice sunday.
Excellent, thanks
I spent a few years working in ruby, java and js before stumbling into Go. It's changed how I approach every project, regardless of the platform it's intended for. Go is easier to grasp than most people expect. It comes with an excellent standard library and lots of talks (and blog posts) are available on the official site to guide you through unfamiliar territory. For ex, should you break up your code into smaller chunks or let that file grow? It's tempting to rely on experiences from other languages but Go isn't OOP, it's solving problems in a way that will be easy to maintain or improve upon because code complexity is inherently discouraged. 
&gt; each attendee costs $350 to feed for 2 days Were you planning on serving endangered blue gophers?
It shows that people support the idea and are looking forward to it, if not to bookmark it for later.
enlighten me, why is vendoring insufficient?
In addition to Effective Go and the other links already here High level: - [Go at Google: Language Design in the Service of Software Engineering - Rob Pike @ SPLASH 2012](https://talks.golang.org/2012/splash.article) - The Go Programming Language (3 part keynote by Rob Pike @ Go Conference 2014) - [Part 1](http://go.googlecode.com/hg-history/release-branch.r60/doc/GoCourseDay1.pdf) - [Part 2](http://go.googlecode.com/hg-history/release-branch.r60/doc/GoCourseDay2.pdf) - [Part 3](http://go.googlecode.com/hg-history/release-branch.r60/doc/GoCourseDay3.pdf) More technical: - [Go Memory Model](http://golang.org/ref/mem) - [Go Spec](http://golang.org/ref/spec) 
fmt.Sprintf(). I wish I was joking. I've used flags and tags to turn on and off debug statements ala [this post](http://dave.cheney.net/2014/09/28/using-build-to-switch-between-debug-and-release) from Dave Cheney. I've heard that [Delve](https://github.com/derekparker/delve/) is gaining some traction. And [MailGun](https://github.com/mailgun/godebug) put out an interesting approach. I've not played with either much. If you find them useful, let me know!
:) Our food budget per person for GopherCon 2015 takes nearly the entire ticket price. It's expensive to provide food for a lot of people.
The entire discussion of how to handle dependencies in Go.
Hadn't yet seen Papercall. Does it have an external API? Glad to use it as an integration point, but if you look at our planned feature list the CFP is only a small percentage of our requirements. Great looking project - how can we get them together?
I think one of our most important goals in this early phase is to build a base and separate much of the functionality out into well defined modules that can be developed independently.
Of course, for me would be very nice. I mean, my software has "STILL IN PROGRESS" label. But we should understand people is writing code to have another line on their linkedin profile. So they don't like to say "i wrote a beta". They want to write in the Linkedin that "they wrote the new amazing 42". This is the point I am noticing. And this is, IMHO, the point which made other languages a mess to use.
&gt; Meh Indeed
Do you deal with one contractor or do you manage the coordination between several?
Sadly, there is no good debugger after years. It is sort of pathetic.
Well, if you say "golang is a better c" you should consider many and many formal verification tools came with C. Is hard to say "add formal verification to something which was designed with speed in mind", of course.But also, some "light" practices, coming from frama-c , could be integrated. &gt; Side note: your original post sounded demanding and at places demeaning to other people. Not everyone is going to want to discuss with you if that keeps up. well, when you complain because people is , by example, smokin where they should not, of course some people will feel pointed. When you complain against some **convenient** _bad practice_, you always get hate back. On the other side, if you want a bad practice to stop in a human group, you need to raise the problem, and get the hate back. Of course you could prefer to keep the bad practice, and don't wonder when the common environment becames a mess. 
The way you restart haproxy isn't a traditional restart - it's more of a replacement. The new haproxy instance takes over listening for connections while the old one completes requests on open connections. When those connections close the old instance shuts down. This results in no down time for haproxy. I manage multiple containerized haproxy instances to load balance traffic in a production CoreOS cluster. Their configuration is entirely dynamic and they restart using this method. They never lose connections. The infrastructure for doing all of this is written in Go and some of the load balanced applications are as well.
My Surf project (https://github.com/headzoo/surf) has goquery baked into it. Surf is meant to act like a full blown browser, but also works quite well for scraping content. Especially if you want to automate the scraping. It was also born from [a discussion](http://www.reddit.com/r/golang/comments/2efw1q/mechanize_in_go/cjz4lze) here in /r/golang. Full docs can be found at http://www.gosurf.io/.