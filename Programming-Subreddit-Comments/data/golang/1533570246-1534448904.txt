The biggest tragedy of Go is that it has been tied to devops tool like yin and yang We use Go for low latency distributed data pipeline and it shines there. Java takes too much memory, it means we can run 10-20 instances on same machine while we can barely run 2 Java ones. Go code is dependent on the devs who write code, no silver bullet there. Choose wisely. 
Note that the second version doesn't tell the programmer (reader) what the size of the array is. In this case you can solve that by having 4 groups of 4 values, but in general it can be better to add the extra "[16]byte" even if you think it looks uglier.
Should have caught that with the hot swapping bullet
Careful with concurrency and map writes.
This is not a big project or anything that are seriously important per se. But can you explain more about that or any article should I read so I know what I'm dealing with? Thank you in advance. 
&gt; I was looking for a simple session management wrapper for Go and from what I could tell there exists no simple sesssion library. There exists. https://github.com/icza/session.
Why "jeff?" That's a bit of a random identifier to see in the middle of code that seems likely to hurt readability: func (s Server) Login(w http.ResponseWriter, r *http.Request) { user = Authenticate(r) if user != nil { // Key must be unique to one user among all users err := s.jeff.Set(r.Context(), w, user.Email) // handle error } // finish login } Would `s.users.Set` or `s.auth.Set` or `s.session.Set` not be less likely to confuse?
golang maps are not natively ready for concurrency. In order to the same map across multiple goroutines, you need to use something like \`sync.Mutex\` to ensure that a goroutine has exclusive access to the map during the write/read. There are variations like \`sync.RWMutex\` which allows multiple readers but only one writer which may be the most appropriate. Often, people wrap a map they wish to use concurrently in a struct that exposes a sunc.Mutex for these purposes.
No relation.
yep that's the Google result u was talking about :)
You can call it anything you want. Jeff just didn't seem like it was already a Go package in major use.
&gt; I was looking for a simple session management wrapper for Go and from what I could tell there exists no simple sesssion library. &gt; &gt; Nice. I did not see this while looking around. After giving a quick gander I'll say these few things about it: It has session variables, which I intend to add in the near future. It uses `map[string]interface{}` to accomplish this which I intentionally avoided. It has two interfaces: a manager and a store. The store is obvious but I don't understand the purpose of the Manager yet (looks like it's only cookie manager?) Anyway it looks pretty good but it's too late now. :-) I'll add it to the list of alternatives.
In addition, Go is actually making 3x the amount of requests as the original cluster.
Are there actually any plans for genetics in go? I have only seen people joke about it so far.
I wish people would just stop making these already. I'm going to just quote my comment from the last one of these. The code won't be quite right for this, but it has the same problems: --- &gt; There seem to have been so many of these popping up recently, and only Google's "wire" seems to make some sense IMO (but even then, I still wouldn't use it). &gt; &gt; This still has the problem that many of the other libraries like this has, you're sacrificing compile-time type safety, and heading towards runtime panics. There is no way to avoid that with a library like this, you can try guard against some of the ways that you might run into panics, but you can never guard against all of them - like for example, not defining a dependency. You couldn't check that at compile time without code generation. The problem of course being the use of interface{}. &gt; &gt; For example, say you update a type to need a new dependency. You update your constructor, all good, but you forget to Register that new dependency - it happens, but instead of failing to compile, or even failing unit tests potentially, it fails at runtime instead. If you have integration tests that might catch it, but nonetheless - why put yourself in that position? &gt; $ go run foo.go panic: Injection of argument 2 failed since the type 'Bar' has not been registered &gt; &gt; vs. &gt; $ go build foo.go # command-line-arguments ./foo.go:17:14: not enough arguments in call to NewWibble have (Foo) want (Foo, Bar) &gt; &gt; I know which I will always pick.
You mean, as a package name or as a variable name? `s.jeff.Foo()` is very very clear *when used in documentation*, since the package name is `jeff`. Now if you're talking about the package name itself.. I got no comment, haha.
If you're server experienced lots of concurrent requests it would crash with this error: fatal error: concurrent map read and map write I've [updated the example with a concurrent safe map](https://gist.github.com/montanaflynn/020e75c6605dbe2c726e410020a7a974#file-context-go-L12-L44) exposed as a struct embedded with sync.RWMutex. There is a [good section on concurrency from the Go blog](https://blog.golang.org/go-maps-in-action#TOC_6.). One thing to note is deleting from a map is considered a write. 
Side note: If you're using `vgo` primarily to test modules, it might be better to use the latest beta version, as it works a bit differently. You can get it via `go get golang.org/dl/go1.11beta3`.
My post wasn't clear. By free, I meant free to the dev in terms of UX/man-hours. Yes, Google might be paying 50c in server resources to build things faster, but that's preventing maybe 30usd+ in time spent having a Dev wait for a long build. 
Has anyone done a good job of explaining why you can't just use an interface and make fakes and shims? As far as I'm aware, proper use of interfaces gives you dependency inversion. With some interfaces, it should be possible to write an implementation that routes dynamically. What's the point of this?
Thanks for the feedback. I was wondering about writing some type of middleware/wrapper code to make the interface less verbose.
That's just \`$HOME\`. You can't just put random config files under \`$HOME\`, and on windows you can't just use \`$HOME\\.config\`.
If you are already familiar with erlang/elixir, you should use them instead of Golang. There is a ton of stuff available in erlang for distributed computing.
It's for containers, not that hard to make my own
[removed]
How can it be zero allocations when you add items to the set?
Not really an experience report, but at least a quick overview of TUI/CUI packages is [this blog post of mine](https://appliedgo.net/tui). The goals and features are vastly different between the TUI's I inspected. I would thus not say there is a single best TUI package; rather, it depends on your needs (lots of "graphic" widgets versus windows and panes versus gaming capabilities...)
You didn't say what kind of software you write. If you want to write Android or iOS apps or windows desktop apps or JavaScript front-end code, then don't learn Go. If you write backend code or command-line programs Go is an excellent choice. It hits the very sweet spot of performance and speedy development. It's also one of the easiest languages to learn.
Good question, the only allocation you will see is for growing the underlying map. The cost, however, is spread across multiple additions, benchmark reports 0 allocs/op. ``` BenchmarkTypeSafeSetAdd-4 3000000 469 ns/op 58 B/op 0 allocs/op BenchmarkInterfaceSetAdd-4 2000000 909 ns/op 117 B/op 2 allocs/op ```
 After the configuration and the token, you can get a client: config := &amp;clientcredentials.Config{} t, err := config.Token(oauth2.NoContext) client := config.Client(oauth2.NoContext) This client is a `*http.Client` [1] so you can do `client.Do(req)`. Variable `req` is a custom HTTP request built using `http.NewRequest()` [2]. You can overwrite the User-Agent header using `req.Header.Set()` [3]. [1] https://godoc.org/net/http#Client [2] https://godoc.org/net/http#NewRequest [3] https://godoc.org/net/http#Header.Set
Sorry, I meant, I need to overwrite the User-Agent on the Token call, not the call afterwards. 
Because you’re asking this, I suppose that you aren’t experienced developer. So I suggest to stick to more commonly using languages. But if you want to learn something new or your area of interest is highload web servers - it will be useful to learn go.
Well… • `config.Token()` is calling `config.TokenSource()` [1] • `config.TokenSource()` calls `oauth2.ReuseTokenSource()` [2] • and then calls `(config.(*tokenSource)).Token()` [3] • which ultimately calls `internal.RetrieveToken()` [4] Here is where the POST request is being built and executed. I am not sure how much you can configure that, but I hope these hints help you in any way. In your case, I would try to use _context.Context_ which is passed around down to this method, to try to set the header via _ContextClient(cxt)_ called here [5]. Good luck. [1] https://github.com/golang/oauth2/blob/3d292e4/clientcredentials/clientcredentials.go#L47-L52 [2] https://github.com/golang/oauth2/blob/3d292e4/oauth2.go#L335-L362 [3] https://github.com/golang/oauth2/blob/3d292e4/clientcredentials/clientcredentials.go#L80-L109 [4] https://github.com/golang/oauth2/blob/3d292e4/internal/token.go#L179-L261 [5] https://github.com/golang/oauth2/blob/3d292e4/internal/token.go#L189-L197
K, I think I've figured it out. You're right, I have to write a customized TokenSource() but I have to pass a customized Roundtripper to handle setting the User Agent. :( 
Are you trolling? You literally took all of erlang’s pros and attributed them to golang, deservedly or not. I’m surprised you didn’t list “prolog syntax” as a golang negative, or would that have been too obvious?
On `IsSubset` and `IsSuperset` you could add a short-circuit on set size. If `t` has more items than `s`, then clearly `t` cannot be a subset of `s`. 
Now make it use *go generate* to generate the *In* method for more excitement.
Very cool project. Kudos to Fatih for starting it and to you folks for keeping it alive and for improving it.
Why did you replace \`sync.RWMutex\` with \`sync.Mutex\` for reading the map?
[removed]
- lazy initialization - automatic dependency resolution 
nice sharing,thanks man
The remainder of 10 divided by 3 is 1 not 3, 1..
It returns the quotient and remainder.
Oh sorry I got mislead by the name of the function 
Erlang/elixir should be fine if that's what you know. I'd suggest though that you pick an RPC system that's more or less language agnostic. I've used grpca few times and have really liked the results. Type safe and supports streaming which is really nice if the requirements call for it.
Thanks! I've never coded in Erlang so all my knowledge comes from your documentation. Would love an example on how to code with Reign. Thanks!
Are you just ignorant or trolling? Most of those, especially those last few about hot code reloading, ideas came from Erlang/OTP.
What do you like better
&gt; I wrote this because I was tired of creating a []struct{} fixture for most of my tests. I hear your boiler plate pain but... Writing table-driven tests the way we do in Go is the most genius thing ever: they are extremely readable and highly extensible. (Did I mention that they are addictive too and once you start doing them they’ll be everywhere?) There are even plugins to generate some of the boiler plate, integrated in e.g. VSCode. 
I’m not sure, I was really tired. 
Thx, added.
Did you learn to ride a bicycle? Did your learn to play an instrument? Did you learn to write essays? Did you learn to handle logarithms? Did you learn all this because there "really [is] a work area for it" or because it adds common and useful skills to your toolbox? Doing the Tour of Go twice including exercises takes one day. Reading The Go Programming Language is interesting by its own. Doing Advent of Code in Go is a nice pastime. Learning Go is not like learning Java/Spring/Hybernate/whatnot or learning C++17. It takes a few weeks to pick it up. If you are interested in Go: Learn it. If you want to learn stuff because job ads ask for it: Read jobs ads and learn what they require.
[https://godoc.org/github.com/docker/docker/pkg/homedir](https://godoc.org/github.com/docker/docker/pkg/homedir) is a good alternative, too. You need to do os.MkdirAll + ioutil.WriteFile.
I'm not sure what to answer as I honestly have no idea what the code in the two packages is supposed to do (except being dependent on each other).
&gt;package b type p struct{} func (p) Instance(s string) \*i { return &amp;i{s: s} } type i struct { s string } func (i i) F() string { return i.s } what about that?
Let's say the package a have the struct T which use the interface P to produce objects of the interface I which contains some data to use (a transaction for example, but here it's a string).
I think what you are trying to say is, you have an interface in package a that you use in package b as a return type and that creates a dependency you are trying to break?
I'm checking it, just a sec
From a configuration standpoint, I enjoy Zap's opinionated default configurations for development and production setups. I also like that you can setup your configuration once and then replace the global base logger, so you don't have to derive all your loggers from some global variable in your code or by passing a configured logger around (mind you, Zap still uses a global, you just don't have to manage it). Also, Zap's ERROR and WARN logs in development mode include a full stack trace, so you know exactly where in the code the message is coming from. Other than that, logrus is a perfectly capable (if slightly less efficient) logging library with lots of integrations and a myriad configuration options. You can't go wrong with it.
Yes! You are right.
could you please put all your code in a git repo? main was not part of the picture until now...
If a.P's methods do return a.I then nothing in your package b can satisfy a.P's method set without importing package a. So no.
I'm currently thinking about adding live-reload/auto-build for the main application. I'll put it into README in my free time.
Define the Interfaces in package b too.
[https://github.com/krocos/redditquestion](https://github.com/krocos/redditquestion)
Let’s not count that against pseudocode :)
 ./main.go:10:13: cannot use b.NewP() (type *b.p) as type a.P in field value: *b.p does not implement a.P (wrong type for Instance method) have Instance(string) *b.i want Instance(string) a.I
Gocqlx is not everything, we use gocqlx to build tools for our customers. We have Go almost everywhere except for the database core.
I'm not sure what you want to say with this sentence. If package a uses a type T from package b than a depends on b. This is unrelated to whatever "realize" does or could mean in that context. What allows loose coupling and breaking direct dependencies in Go is implicit interface implementation. If `a.T` implements all methods of an interface `b.I` than `a.T` can be assigned to a `b.I`. All without a being dependent (read imports) package b. Your code (which leaves the impression of porting traditional OOP to Go) does not use such loose coupling as the return type of one method of `a.P` is `a.I` and the return type is part of the signature which must match literally. Maybe it helps dropping (borrowed?) terminology like "realize". Your types "implement interfaces" by providing the full set of methods required by the interface. If you talk about "implement an interface" everything might become clearer. E.g. if `b.P.Interface` must return an interface I than this interface I could live in its own package c. Packages b and a would then both depend on c, but not on each other.
&gt;Your code (which leaves the impression of porting traditional OOP to Go) does not use such loose coupling as the return type of one method of a.P is a.I and the return type is part of the signature which must match literally. Yeah, well, you are generally right. Many years I used languages with traditional OOP. It's my problem that I drag traditional OOP into my Go code. And this question are here generally because of that.
So, it's the bad design problem here as I see now. So, how to turn the example code into Go-way code?
&gt;realize Yes, I meant implement there.
Not sure. I would start with less types and more functions. E.g. your `b.p` exists only to attach a method to it. Use a function instead of a method. Do what you need with concrete types and functions and create the interfaces once you have more than one type.
There’s nothing stopping you from using Docker even though you want to use live-reloading. Just mount the local volume to the Docker image, and voila it would reload once you do a change. (Although I’d stay away from live-reloading myself, since I like to trigger builds myself)
Actually it is [true](https://dominik.honnef.co/posts/2015/06/statically_compiled_go_programs__always__even_with_cgo__using_musl/). Just follow up instructions and you well end up with purely static libraries. Also sqlite3 can be statically linked too, check documentation. 
The more you know, the more you're worth.
What's the current status of compression being added ? As I recall it would require a new backup format.
Still not implemented, here's the issue you can subscribe to if you want: https://github.com/restic/restic/issues/21 It requires at least an extension of the repo format, we've got several ideas how to do that without breaking existing repos. It'll just take time :)
just a heads up: b2 upload can be painfully slow from europe.
Indeed, for each API request, the typical latency until the http headers have been received is around 800ms (tested from Germany)...
Indeed, for each API request, the typical latency until the http headers for the response have been received is around 800ms (tested from Germany)...
Time for new ideas or time to do it ?
This is where the "proverb" "return concretions, accept interfaces" really becomes obvious. You don't need to return the interface type in package `b`, just you just need to accept the concretion from package `b` as the interface type (which it will implicitly be able to do) in package `a`.
In package b, return lowercase 'i' in your Instance method. Then should remove the dependency on package 'a'. In Go, you don't have to explicitly return the Interface type as long as the struct has the interface functions. 
Yes, if you are a web dev.
There is no point really. There is some point in Java since you can instanciate types from their names with reflection and a XML/YAML/JSON file, thus not having to re-compile a codebase. You absolutely cannot do that in Go. AT ALL, plugins or not.
Nothing in Go makes distributed system easier to write. Go is not fault tolerant by default, doesn't support hot loading by default, or doesn't magically gives you "high availability", unlike Erlang/OTP that gives you all of the for free. IMHO go and the absence of basic native thread safe data structure is a complete fail. Go doesn't make concurrency easier, at all...
I'm working on it. That said, I would say I'm not necessarily advocating for this to be a good design to start a brand new Go code base. Although I'm not sure there aren't necessarily some applications where it might be a good idea, either. But I certainly want to make it clear I don't consider this an all-purpose solution.
no. interfaces in go should be implicit. return a concrete type ( which may conform to an interface a.I ).
Use type alias. Type I = interface { F() string } Put this into both packages. The downside of type alias is that you cannot define new methods on an alias binding to a type out of scope, but since you can not define methods on interface, this is perfectably fine. I even have a bitbucket snippet on this already: [https://bitbucket.org/snippets/leafbebop/ne64qX/just-some-dohavestringers](https://bitbucket.org/snippets/leafbebop/ne64qX/just-some-dohavestringers)
Because you've stripped the code of all meaning, that's pretty difficult. I realise you're trying to give a simple example, but people can't help with code which is not meaningful. Given the code you have, almost all of it is boilerplate related to relationships which don't have any effect. So for example, the simplest version of the code above is just a function (assuming F actually does something): `func F(s string) string {` `return s` `}` `func main() {` `fmt.Println(F("string to return"))` `}` Start with the data, and the functions that transform it, forget about packages until you definitely need them. If you do need to use multiple packages eventually, always only import one way. 
file structure: /implementations /workers /cmd implementations fulfil certain interfaces, they dont know who uses them. FerImplementation can be extended with any amount of methods. package implementations type FerImplementation struct{ TextToPrint string } func (f FerImplementation) F() string{ return f.TextToPrint } workers need specific interfaces to do some things workers do not know about implementations, they just define what they need to work: package workers import "fmt" //Fer does some func F() type Fer interface{ F() string //F returns a string } type Doer struct{ DoersFer Fer } //DoSomething requires an Fer to work func (d Doer) DoSomething() { fmt.Println(d.DoersFer.F()) } //main wants doer to do something and sets the worker.Doer's fields DoersFer with the implementation of implementations.FerImplementation and then calls doers method. Only main knows about the coupling now. package main import ( "../implementations" //..import should be replaced with your project path "../workers" ) //main calls DoSomething with the Fer implementation stored in package 'a' func main(){ doer := workers.Doer{DoersFer: implementations.FerImplementation{"hello world"}} doer.DoSomething() } thats the way i build most of my code. You only request what you need to do your work, no matter the implementation. Makes it very very easy to mock behavior, test and expand your code because you can break things down to single function interfaces.
As I said, If you're not building Chrome or OS project then it will compile quick enough in any language, considering you have good decomposition so you build it incrementally. 
I'm not sure which is the most elegant or "correct" way, but one possible way is to place the interface in a package and include it when you need to use it. Both of these packages implement interfaces from `pinterface`, and have a test in place that ensures that the continue to implement it: https://github.com/xyproto/permissions2/blob/master/permissions_test.go https://github.com/xyproto/permissionbolt/blob/master/permissionbolt_test.go
Seems to me like go_generics could really use extraction into a standalone package.
[removed]
Oh ok, thanks for taking the time to explain it to me. 
I very much stand corrected. I don't know when that changed, but I definitely remember it being a problem in the past. Just checked some mysql bound projects and they are statically compiled, and what used to be a problem with the musl lib portability (`alpine &lt;-&gt; debian`), also doesn't seem to be an issue anymore. It doesn't hurt to check if the resulting binaries are statically linked, in case some library doesn't have a `.a` file that would allow it to be statically linked. Just linking the [sqlite flags which i found in some dockerfile](https://github.com/creack/go-sqlite-static/blob/master/Dockerfile) for a possible future reference (and to save somebody some googling)
Golang is a tool, one among many others. IMO, learn programming in general, algorithms , etc. Than You can select the tool that most suitable for the task. But Golang is good choice, it’s strong point is concurrent programming.
I'm going to zig a bit to some of the zagging here. Based on my survey of various github projects and such, I tend to be a bit package-happy compared to the average Golanger. The reader may decide whether you consider that a reason to listen extra carefully or run away screaming. So in this case, assuming that this is a blog-post-sized example of a larger problem, in a lot of cases I would make a third package here, containing the I interface. Then each of package a and b would import this "c", and they would have no cross-dependencies. I qualify that with a size thing because if the packages were literally this size I wouldn't worry. It is very often my experience that when I find two packages getting excessively chummy, there's a third package in there trying to get out. That is to say, it's not just that the two packages are too intertwined and shouldn't be separated (though that can happen, too), but that if you study the intersection long enough, you can start to see there's actually a package there in the intersection itself. If you practice this for a while, you'll see it's a skill you can get good at. It gets easier over time.
[https://rclone.org/](https://rclone.org/)
Hi all, author here! I'm not quite finished with this package yet (see issues), but now that I've got both the kernel and userspace APIs working, I figured it was time to share it to a more broad audience. For those who aren't familiar, WireGuard (https://www.wireguard.com/) is a next-generation VPN that's in the process of being upstreamed into the Linux kernel. On top of that, there's a Go userspace implementation which works on other platforms as well. This has been a fun project so far, and I'd appreciate your feedback. Thanks!
What you are referring to is better known as the robustness principle. It states: be conservative in what you do, be liberal in what you accept from others. And it comes from the networking world at least to my knowledge. Btw it is not contained in the official go proverbs https://go-proverbs.github.io/ but I think we all agree that it is beneficial to follow.
I'm curious as to why you think this. I'm in the field
If you look at it from the set of methods of a type, it is exactly the opposite. An interface is always a subset of the set of methods implemented by a type T. If the set of methods of type T, an interface may describe only a part or at most all of the methods of the type, but never more. So in reality, when you accept an interface you're being strictly conservative in what you accept: you're restricting whatever is sent to be only a subset of what it is really sent. If you accept a concrete type, you're being very liberal: all the methods of the concrete type may be used. 
[Pointers for members automatically get dereferences](https://stackoverflow.com/q/30786206/8749212)
The link: [https://madnight.github.io/githut/#/pull\_requests/2018/2](https://madnight.github.io/githut/#/pull_requests/2018/2)
I'd tend to look it from the opposite point of view, and look at it in terms of types. By using an interface you are able to use multiple types, multiple concretions, multiple implementations. This is less restrictive in that sense that allowing the use of a single concretion.
C++ is also growing ?
The 'idiomatic' Go way for types that are shared across multiple packages in an application is to create yet another package that exists to define those types. 
You don't give any information about `s` or `Exec`, so this is not answerable.
blockchains
The best things about it it that JS is losing.
Syntactically, it is pretty straightforward c-style stuff, curly braces, function calls. Good standard library, very tight and consistent. The interesting part, for me anyways, is the concurrency/channels and avoidance of object-style programming. I really like golang, and I enjoy programming in it considerably. It is indeed very very fast, especially compared to, say, Javascript. But on sheer intellectual stimulation, I would take a look at Lisp (or Scheme) or something like that as well. Python, as you mentioned, is also an interesting language. The question I would have is, are you looking for a language that will stretch your programming skills and make you think about programming in very new ways?
Thank you! &gt; The question I would have is, are you looking for a language that will stretch your programming skills and make you think about programming in very new ways? Yes, I think you named it. Something that would make my conceptual understanding of programming better and deeper, and / or extend it to very new ways, which is also, in the end, making it better and deeper. But I think my question about Go was more will it bring me new ways of thinking, yes, compared to, say, JavaScript :)
What you describe has a different name: Interface segregation principle (One of the SOLID principles). I would rephrase it as: Only require functionality you are using. This also by all means desirable. 
Can I translate that into "not so complicate to learn but very intereting"?
Sounds like a spell at Hogwarts
What about using `sync.Map`?
To little information, we need to know something more about Exec()
The concurrency stuff is cool and can be fun to think about but the language's design is very dated. For me at least it can feel like a chore to write Go code a lot of the time. It is very difficult to create meaningful abstractions in your code and it often feels like the language is designed to keep you from trying to be too clever which it seems is the point. 
oh, ok, I see, so this sounds more like something I wouldn't like…
Python, Go, C++, TypeScript, Kotlin.. What a beautiful world this would be
and PHP
Yes they must be, although I'm not sure but, I think there are some JavaScript compilers or something that allow you to use strict typing that then compiles to JavaScript… (maybe Elm?) not sure though, my memories are a bit dated, and anyway yes it's not JS core. 
JS then PHP? If you ever plan on becoming a serious developer, then don't learn these 2 languages. JS one can understand, but PHP.. no
Writing Chaincode 
The keywords and syntax are small enough to keep the entire thing in your head, which is fantastic. Too many other languages end up being "kitchen sink" collections, where 10 people writing the same small program would each use a different subset of the language. There are a few subtleties of course - how channels work and how to structure your use of them, learning how to design composible interfaces if you're used to class-based inheritance, etc. If you're coming from interpreted languages, having a compiler that spits the dummy when you get it wrong - rather than your program crashing at runtime - is a godsend. Although it irritated me at first, things like unused imports, unused variables, etc. being a compile error is great for keeping your code smelling nice.
Cool! What is the current/past way people have been managing these? I would suppose a list of packages in a text and a script that runs go get on each line?
Am I getting you wrong, or does it sound like something "very convenient, but not necessarily so exciting"?
I don't mean to knock it too hard but I think it's a language that works best for team projects. If you're looking to learn something for your own fulfillment I'd recommend Haskell or Nim maybe even Rust. My favorite of the three is Haskell but it has I think the steepest learning curve. I see someone recommended Lisp which is also a very fun language. 
How much of that was to Typescript though?
theres a sorting method. a quick google search will answer that for you. I know this because i needed a sorting method just a few hours ago
~~C++~~ -&gt; D
~1.4%
You just have one big gopath and go get pulls all transitive dependencies automatically. People used a vendor directory to bundle their package with exact versions of other packages. This will become deprecate with the next release expected in a few days.
If you are really looking for a 'stimulating language' I would recommend Haskell. It is just mindblowing how everything works together in it. Go is also great if you especially looking for a non-functional language. It is very clear and has very few irks compared to most other imperative languages.
Not surprised. Really like Go. Would expect with Flutter we will see Dart also now grow popularity.
Typescript is maybe the one you are thinking of 
~~C++~~ ~~D~~ Go, everywhere!
Developing a major project in any language will broaden your conceptual understanding of programming most of all. 
Go is awesome 
rust as well. what a great time to be alive
ok, thanks! no, I'm not looking for a non-functional language, actually I had read a long series of articles about functional paradigms (leading to talking about Elm, functional language compiling to JS), and it sounded really very exciting (I also was very interested in reactive programming). Well maybe I'll give a look to Haskell finally, but it just sort of makes me shy, is it like, does it require a previous deep background?
yes you're probably right, but I think there were other attempts too. But I've not checked these things for a couple of years, so it's not very clear to me
I'm a huge Go fan but based on your post I'd personally recommend you get into Haskell, this is the book everyone uses now a days, it's made for anyone from seasoned programmers to never programmed before http://haskellbook.com
In some ways perhaps - but in others an enjoyable breath of fresh air. I find Go really enjoyable to use... especially after working on a &gt;100k line multithreaded Python codebase. Some main points I like: * Channels, at the language level. How did I live without them? * Goroutines - being able to be liberal with "threads" (in quotes because they're not the same - although act it in many respects). * gofmt - consistent formatting. I have my editor gofmt everything on save. I hated it at first "but I want this aligned differently" then relaxed, accepted the style, and realised "wow now I don't need to waste mental energy on this anymore". * Easy cross-compiling tool chain. I can set GOOS and GOARCH and build binaries for whatever I want from the development environment I'm comfortable with.
You replied to my comment instead of the one from the person who needed it ;)
Thank you very much, yeah other comments also pointed me towards haskell.. But first Haskell sounds very impressive, and also, even though I did say it was for my own pleasure, isn't haskell to much like « out of the real world »? I would still be happy if I can build some little stuffs, and I have the feeling that haskell is almost strictly for the sake of thinking about it (which is sort of what I asked for, I admit ;) Is that a wrong idea? 
I think it sounds exactly what you want :) First Haskell is being used in production system's more and more everyday. For example I believe Facebook has multiple Haskell systems. Also if you're into Blockchain at all one of the biggest projects are completely written in Haskell. So more and more uses everyday. Second IMO it will definitely make you a better programmer, the more functional the better I've found, so many bugs I've encountered at work were from multiple things updating shared state, so the exactly the problem functional helps with. I think you'll really enjoy that Haskell book :)
&gt; What is the current/past way people have been managing these? There's been a [few](https://tip.golang.org/pkg/cmd/go/internal/modconv/?m=all#pkg-variables) unofficial . [dep](https://github.com/golang/dep) is the most popular one. Personally, I'd wait for 1.11 to be released then you can use go modules.
ok, thanks, sounds very exciting indeed :) and yeah, I'm far less experienced than you, but when you say the more functional the better it also meets what I've came to intuit. Oh, by the way, is Haskell compatible with reactive paradigms? My memory is that reactive programming is some sort of extension of functional programming, something like that? I was very fond of these even listeners and everything, my memory isn't clear but I liked what I read about this. And yeah, I'm definitely into blockchain, and you're right that Cardano is made with Haskell, lol I think what made me think about Go again today was to see that Ethereum was programmed in it (although I'm not sure exactly what part of Ethereum, need to check that, I'm not sure if it's the blockchain itself, or if maybe Solidity was made using Go… but I've read Solidity is pretty similiar to JS, so I guess it's the blockchain itself that was programmed in Go…). 
fetch data in the goroutine pool, passing tripValuesChan as a destination.
Personally I have everything in my path and use mostly standard library (or other Google, Microsoft, or Dgraph libraries which almost never make breaking changes) with only very rare exceptions--those usually being the database driver or bleve search. This is true both in hobby and in work applications. It sounds crazy, but it isn't as crazy as it would be in languages without such fantastic standard libraries. It can cause pain on occasion, but it's going to be a settled issue soon, and Go devs really are good at avoiding breaking changes.
I hadn't thought about it before, but I suppose go and npm are the two extremes on either side of python.
Ok, I don't get the full details as I don't know the language, but rereading your above comment I think I know what you mean about the fresh air. I've read many times similar things about Elm, people were so enthusiastic about how you can't go wrong writing Elm, and how many routine things were treated so quick, and how it was a rest. I guess you're saying something not too far. 
\&gt; I am working on a websocket application that grabs data from a WSGI server every 1 second and pushes that data onto queue. There is then another goroutine which reads off that queue to send via websocket every 100msec. The first thing that comes to mind is that those rates are a bit weird. If you're going to queue things up, I'd expect that's because you want to send \_less\_ frequently than you're going to receive. First I'd ask what's wrong with just hooking up the pull straight to the websocket? In a lot of ways, that's usually the right answer. To the extent that a delay in sending might prevent the next poll, that's \_often\_ actually a good thing in practice. If necessary, and if possible, the rest of the system should be written to accommodate that. (e.g., the poller can't really count on getting a response precisely once per second in the real world anyhow, so don't build your system on that.) However, taking the requirement as written, and assuming that if the websocket process encounters multiple messages it wants to try to send them all, the easiest thing to do is to not use channels and just have a shared lock around a slice of the relevant type. The only real decision then is whether the websocket process should hold the lock while it tries to write or not. I'd say again that while it seems to be a common intuition that we want to let the WSGI process run even if the websocket process is blocked, it is quite often better to go ahead and provide backpressure on the entire system. I would consider "hold the lock while the websocket" outputs the \_default\_ option, and make the alternative work to prove itself, rather than the other way around.
Woah TIL
Ah, I'm an idiot. I tried this but I never added the default case... apparently that's the exact mechanism which allows the non blocking. &gt; fetch data in the goroutine pool, passing tripValuesChan as a destination. Sorry, I'm unsure as to what you mean?
 First let me just say, thank you for the advice so far. It gives me lots to think about! &gt; First I'd ask what's wrong with just hooking up the pull straight to the websocket? Do you mean just having one solo goroutine that pulls the data *and* sends in one go? I did it this way because it specifically needs to send websocket data every 100msec (very important), but if I ping the WSGI server that often, it leads to issues. &gt; the easiest thing to do is to not use channels and just have a shared lock around a slice of the relevant type. Hmm, so with this sort of implementation I'd keep the dual goroutines but instead of sharing via channel, I'd use sync.RWMutex around my map (tripValuesChan)? &gt;I'd say again that while it seems to be a common intuition that we want to let the WSGI process run even if the websocket process is blocked, it is quite often better to go ahead and provide backpressure on the entire system. I would consider "hold the lock while the websocket" outputs the default option, and make the alternative work to prove itself, rather than the other way around. I'd agree with this, but it's very important that the websocket send every 100msec.
Nobody hides the fact the JS has extremely humble origins. Nor is it suited to everything as some fans like to pretend, but it is definitely not a joke of a language. It is among the most performant interpreted languages, incredibly quick to use to prototype in, and who's core is reliably going to be worked on and improved due to the existence of the web. Please drop the BS and the prejudice.
I would try learning many languages at your stage. Get programming problems and write them repeatedly in many different languages is a good way to learn.
Dart looks fine, but Flutter suffers from seriously hideous nested code. Even the basic examples have these staircasing ending tags 20 lines deep. It's not very readable at all. I'm sure there's a better way to write code using Flutter, but if the people behind it can't come up with better example, it's not very inspiring to dive into it.
Why are you asking for permission to learn? Just read about Go. If it’s boring stop and read something else. 
``` ch := make(chan [][]wsgi) go func() { for t := range time.Tick(1000 * time.Millisecond) { var v [][]wsgi json.Unmarshal(wsgiFetch(t), &amp;v) ch &lt;- v } }() for { w := &lt;-ch for _, v := range w { &lt;-time.After(100 * time.Millisecond) ws.WriteJSON(v) } } ```
V8 is performant, yes. But V8 != JS. 
I'd say - no, it isn't. It's one of the most boring languages I've learned. The most interesting language I've come across is Haskell. I haven't done anything "real" in it, nor will I ever, but I do enjoy...ummm..."learning" it. I also like various LISPs, and I actually recently wrote some semi-production Clojure. I like the beauty of it, the intellectually stimulating feeling I get when I can just pipe functions into other functions and can just map/reduce my way to victory. It's cool! But, when I have to actually, really, depend on the code I'm producing, when I need to know how it works, and what every bit of it does, and how it performs, and the edge cases, and its limits - I choose Go. Every single time. It's a simple reliable tool that never lets me down, never surprises me, never makes me want to tear my own hair. I have pretty large programs written in Go that have been working reliably for years, serving lots of traffic. I have much smaller Python programs that still surprise me with weird bottlenecks, unexpected errors, "magical" behavior that happens to "work" - let's say, I don't sleep as easy at night when I'm responsible for a production-critical system written in python/ruby/nodejs. 
\[removed\]
I think it should be `t := &amp;a.T{P: *b.NewP()}`
I have updated the code. Passing values instead of pointers also works.
I prefer the type safety and not needing to do type assertions From the docs on [`sync.Map`](https://golang.org/pkg/sync/#Map): &gt; The Map type is specialized. Most code should use a plain Go map instead, with separate locking or coordination, for better type safety and to make it easier to maintain other invariants along with the map content. 
The ZikiChombo project and its purpose became more clear to me after reading the [homepage](http://zikichombo.org/)
https://golang.org/pkg/text/template/ &gt; Templates are executed by applying them to a data structure. Annotations in the template refer to elements of the data structure (typically a field of a struct *or a key in a map*) to control execution and derive values to be displayed. Execution of the template walks the structure and sets the cursor, represented by a period '.' and called "dot", to the value at the current location in the structure as execution proceeds.
I can't imagine doing most of the stuff I do in Python do in Go instead. Single use scripts, say for web parsing, data manipulation, etc...
This is not what I'm looking for. You guessed it wrong
Can relate to the addictive part :p
&gt; When they are passed to Exec() are they automatically de-referenced? yes. Unfortunately I can't find a reference to the documentation right now :/
The speed is irrelevant to me 9 out of 10 times (I either wait for I/O or I don't work with that much data). Most of what would be slow in python is already in C anyway. Write it quick is the only metric really. Python has some advantages, but as you mentioned some disadvantages as well. I've tried to strip down one simple script I recently wrote in python, it's only a few lines - basically summing multiple json files into one: https://gist.github.com/rplnt/e284b03ad95f676106e92cfd8bf86c27 if you'd find a minute or two to rewrite it to Go I'd be interested to see how would one approach these tasks. 99% of the Go code I write is buried deep down in big applications, so maybe that's why I don't think of it as a language I could use for simple stuff like this.
That's the trouble with providing an absolute minimum of information about the problem domain.
Sounds fair:)
I'd say it Haskell looks pretty good on a surface level inspection and you can get pretty far with not so much knowledge in category theory or algebra. However for the higher level constructs you should be at least interested in mathematics. To give you a short overview over basic concepts: One mayor thing to understand is recursion which also comes sometimes in imperative languages. Then there is pattern matching and list comprehension which are also relatively easy to grasp. Finally you have higher-order-functions. The most prominent are filter, map and reduce and they are useful in imperative languages as well. There is a great book out there with a free online read here -&gt; http://learnyouahaskell.com if you are interested. There also is the mysterious *Monad* which you absolutely don't need to understand as a beginner but tremendously helps you the further you go up. And just one last thing to scare you in the Haskell standard library is something called Zygo'histo'morphic'prepo'morphism (the backticks are for readability). Don't ask me what this is means or where the heck it can be useful but it might provide something like long term motivation. "I'm not done with Haskell untill I have applied this this somewhere useful". 
I'm not asking for any permission about anything. Just asking the personal sentiment of people who are into it. Don't worry about me.
Haha the zygohistomorphic prepomorphism stuff is just a meme, it's not really in the standard library and while it technically does mean something real it hasn't (as far as I know) ever been actually used. 
It entirely depends on how you want to implement your queue. To make it concurrency safe you have to use one of the three: 1. Atomic operation 2. Mutex 3. Channel A channel itself is already a queue so you might want to use it straight away. If you really care about performance the first two might be more interesting to you. A mutex is about 15% faster (at least in the benchmarks I read) but are way less flexible. If you have special requirements on your queue (variable sized buffer, priority queue, maybe a deque) you have to do it yourself. For a quick working solution a channel with a reasonably sized buffer is probably best.
You have a db connection. You prepare a query with Prepare and get back a statement that holds the query. Than you execute the query by executing it. The results will be passed into the args to exec. Alternatively you can directly execute a query on the DB without creating a separate statement by directly invoking Exec on the DB and passing the query as first argument. The sql package will reach your query down to the driver you used and it will operate on the db reaching the result up.
if somebody could go through this initial support for ListArray in Go-Arrow... it would be much appreciated :) PS: here are the specs: - https://arrow.apache.org/docs/memory_layout.html
Well some of it depends on size of your program. That part was not in your question. Go is kinda meant to be straight forward and boring but that's because no one will touch a million line code base of this. let f = () =&gt; ({}) They mostly have a million files of scratch. This is where go shines but you have to follow it's rules. You need to setup custom types. This way your program is completely uncoupled. Example being Reader and Writer interfaces. https://medium.com/@snippet22/reader-types-2ba61290a5cf You will begin to appreciate this way of doing data because you'll be able to build your own package. If you want something harder then look at the context package. https://medium.com/@matryer/context-keys-in-go-5312346a868d If you really have to stay with frontend then soon you'll be able to do go on the frontend stable wise. 
He provided enough information. But you don't understand what he has written. I'm not using the standard template but a [github.com/CloudyKit/jet](https://github.com/CloudyKit/jet) I have a middleware that creates a default view data and then other middlewares add to it. Then in handler I get this view data from the context and add additional handler data into it an pass everything to the render method.
Ok but sure. You are splitting hairs. It's like if I would say, no go isn't fast, the compiler just makes really efficient binaries!!! I know there are different runtimes than v8 but for all intent and purposes, considering that nodejs uses v8, and that nodejs is the most commonly used serverside runtime for js, I'll agree with you. JavaScript has some darn fast runtimes out there. Btw I love go as it is my favorite language. But I'm tired of peopling bashing on js. 
No. 01 reason, performance.
&gt; thought Scylla is C++ shop, in which part do you guys use Go? &gt; Edit: Found the answer: gocqlx Here it is for you https://github.com/mmatczuk/go_generics
&gt; On line 13 in go-set/internal/set/set.go, you have type T = Template with a comment saying "T is a Template type". &gt; My question is what is a template type? That's generics, it's a feature that statically-typed languages typically have (because they like to add features for no good reason), but it isn't really useful for anything practical, it's only good for university researchers and other purely academic purposes. In real-world practical applications it mostly just complicates the codebase. 
I still do a majority my programming in Python as a Python and Go developer. Most of our tools are highly analytic in nature and because Go does not have fleshed our support for data analytics and dataframes...yet. However I rewrote a lot of our core web API in Go.
I don't know. I mean, I picked up React Native recently, and it was so straight forward to pickup. I think if Flutter used dot notation or a markup language instead of this it would be more readable: ``` Widget build(BuildContext context) { return new Scaffold( body: new Column( crossAxisAlignment: CrossAxisAlignment.start, children: &lt;Widget&gt;[ new Expanded( child: new Center( child: new Text( 'Platform button tapped $_counter time${ _counter == 1 ? '' : 's' }.', style: const TextStyle(fontSize: 17.0)) ), ), new Container( padding: const EdgeInsets.only(bottom: 15.0, left: 5.0), child: new Row( children: &lt;Widget&gt;[ new Image.asset('assets/flutter-mark-square-64.png', scale: 1.5), const Text('Flutter', style: TextStyle(fontSize: 30.0)), ], ), ), ], ), ``` I realize new platforms always come with a learning curve, but I don't consider this an upgrade over Android's xml for views. findViewById for everything is a pain, but the ConstraintView is really nice.
I agree with your point. I mostly use JavaScript/Node to fulfill the same purpose - quick-and-dirty development scripts. As an added bonus, there's even a user friendly REPL for the language available on practically every modern PC. Some call it "Chrome", or "Firefox", or "Safari" or "Edge". Go is an interesting language to play around with. And heck, it may even be a nice choice for "serverless" environments where you're mostly writing short scripts, thanks to its better performance. But it's a very unusual day indeed when someone can actually write a utility script quicker in Go than they could in Python or JS. Not "quicker" as in performance (of course), but in terms of raw development speed. 
Not the person you're replying to. I'm fairly new to Go, so this is probably far from the best way to do it, but I gave it a shot. package main import ( "encoding/json" "io/ioutil" "log" "os" "path/filepath" ) type JsonResult struct { Users map[string]map[string]int `json:"users"` } func sumScores(sources string) { totals := &amp;JsonResult{Users: make(map[string]map[string]int)} files, err := ioutil.ReadDir(sources) if err != nil { log.Fatal(err) } for _, file := range files { var scores JsonResult if filepath.Ext(file.Name()) != ".json" { continue } bytes, err := ioutil.ReadFile(file.Name()) if err != nil { log.Fatal(err) } err = json.Unmarshal(bytes, &amp;scores) if err != nil { log.Fatal(err) } addTotals(totals, scores) } data, err := json.MarshalIndent(*totals, "", " ") if err != nil { log.Fatal(err) } err = ioutil.WriteFile("totals.json", data, 0644) if err != nil { log.Fatal(err) } } func addTotals(totals *JsonResult, data JsonResult) { for name, user := range data.Users { for key, val := range user { if totals.Users[name] == nil { totals.Users[name] = make(map[string]int) } totals.Users[name][key] += val } } } func main() { sumScores(os.Args[1]) } Lots of (very simplistic) error handling that you could probably ignore for this use-case, which takes up most of the extra LOC. But I agree that for quick, dirty scripts like that, it's hard to substitute Go for Python. Took me at least twice as long to write this as it would in Python, but then again, I've only started learning Go 3 days ago, whereas I've worked with Python for the past couple of years (any improvements are welcome).
That number indicates growth of TypeScript, which includes *new projects*. To imply that it is entirely migrations from JS to TS is pure speculation.
&gt; That number indicates growth of TypeScript, which includes new projects. To imply that it is entirely migrations from JS to TS is pure speculation. The numbers are changes in growth, so new projects in TypeScript and not JavaScript would impact this change in growth, right?
Idk if this means it is the fastest growing language. It has the highest uptick in pull requests and stars, but do they really indicate a language "growing" faster on github? There are other factors that should be taken into account as well imo. Like how many different unique people submitted the pull requests and stars. No doubt that Go is growing though! :)
Please point out to which template you refer. If no context is provided everyone assumes html/template.
Thank you. I removed the logs and error handling for more fair comparison. There was also a bug, missing `filepath.Join(sources, file.Name())`. It's quite concise. Surprisingly, the python version is significantly faster on bigger inputs. I've prepared 200 files with 5000 users in each. Best out of three: python 4.14s user 0.08s system 99% cpu 4.252 total go 6.91s user 0.08s system 109% cpu 6.391 total
&gt; small bug, missing `filepath.Join(sources, file.Name())` Thanks for pointing that out. I assumed the filename would be the entire path, but looking at the docs now it's just the basename. I'm not even sure how you'd _properly_ compare the two (that is, benchmarking and not just `$time`), but given that the parser Python uses is written in C, I'm not necessarily surprised it's faster. Was a fun little exercise to see how a utility script translates into Go, though.
The library uses the [reflect package](https://golang.org/pkg/reflect/) to take in its arguments and examine them for what to do with them. A basic thing almost all such code will do is dereference pointers for you. This means that two such packages, such as encoding/json and the sql package, can have different behaviors if you push them. One easy thing where there could be a difference is if you pass a double-pointer; some code may dereference until it gets to the underlying value, some may only dereference one layer. The key point here is that it's code in the library, not a language feature.
Sorry, I didn't log in to reddit. If it's linux, it's now fixed.
Yep, this package is a library. See GoDoc: https://godoc.org/github.com/mdlayher/wireguardctrl. As of now, WireGuard doesn't provide any kind of notification of when these events occur. I believe there has been talk of exposing these events via a netlink multicast group (for the kernel API), and then an equivalent for the UNIX sockets userspace API would need to be implemented as well. If they exist, I will support them.
Verify your struct before passing it to the temple. This is both faster and safer. You can still do conditional execution in templates with comparison or a function call.
do you mean, what does $GOPATH/github.com/src have to do with docker? I run docker like this docker --volume $PWD:/app -e GOPATH=... where my GOPATH is "/app/GOPATH" Inside there I have a {bin,pkg,src}. Which is great but its owned by root. So, if I ever make changes to /apps/GOPATH/src/goa-project/design/design.go I would need to run the docker shell as root and make my changes. So I would like to avoid that. 
&gt; Which is great but its owned by root Why?
It's impressive that Go is up there right after JS, Python and Java. Imagine when Go surpasses Java.
It's more a matter of where I am iterating over the values that are similar in the template instead of checking if the value is sane. I'm trying to form an HTML `SELECT` list that parses a series of Items with a similar prefix, these are tested in the templates to display `selected` where there is a match. I'd like to be able to perform the same loop on any additional `Var` items added in the future, across multiple templates. I'm populating the struct items with values, but I don't want to manually type out each item in the templates, and would prefer to be able to loop a single `{{range}}` process that encompasses all items that follow a pattern. If that makes sense? I'm thinking that perhaps it is better to move these into a slice in the struct, something like: type Demo struct { Vars []Var } type Item struct { Val int Ident string } And then make the `Ident` field that which I then use for comparison. Thanks. I am starting to see where I was going wrong.
Thanks for replying. I think it's on it's way to getting resolved. Update in the other thread.
Unrelated: I wonder how long JavaScript will stay at first as WebAssembly gets more and more support.
Such a great language with great promises. The only issue I have with it is the most unimportant one: Its syntax makes my eyes bleed sometimes.
&gt; Otherwise, I would have to create an account in the docker container. Yes.. you could do that. Wouldn't all of your problems go away?
It gives it a certain charm I find, but i agree :p
\[removed\]
It is matter of time, I think.
You are offering the same solution I did except with a custom datastructure of some sort, so if I did not understand what he wrote, you did not understand what he wrote and what i wrote.
Oh. I just tried that and it works! Great idea. Let me play around with this trick and see how far I get
Yeah, I think that's basically the right approach. You could even use a method on the template data to help with the filtering: type Demo struct { Vars []Var } type Var struct { Val int Ident string } func (d Demo) VarsWithPrefix(prefix string) []Var { var vars []Var for _, v := range d.Vars { if strings.HasPrefix(v.Ident, prefix) { vars = append(vars, v) } } return vars }
Looking at the above conversation you could also use a map if you really have this Ident Val layout.
Can't we have something like nodejs (or rather the wip deno) with Go and Dart?
TypeScript? PHP??
ok. here is how I am doing it. lets assume my directory structure looks like this src/design/design.go `make deps` (runs the docker command to get my goa and other depedencies). My directory layout looks like this now: src/design/design.go gopath/{bin,pkg,src} #there is goagen and other depedencies there now `(GOPATH=$PWD/gopath; ln -sf $PWD/src $GOPATH/src/goa) #my code should be in $GOPATH/src` `(GOPATH=$PWD/gopath; cd $GOPATH/src; $GOPATH/bin/goagen bootstrap -d goa/design -o src)` This will create my default template. let me know if you see anything wrong with this approach. much appreciate your tips so far!
Go Json is much faster when it decides into an interface{} than anything else. I tend to avoid decoding into structs or maps if I want performance, but of course it does simplify the code so you have to weigh that against each other. 
I come across similar stuff with my sort of one time scripting tasks, however much I love using Go, it is often double the number of lines and not measurably much faster than a Python equivalent, and sometimes I *just* miss having a nice high level container like Python's list when I work in Go, even Rust's vectors fill this gap quite nicely, when I really just wan't to do things like adding or checking if something is inside the container, obviously these aren't hard in Go, but it's still just a little more work that I don't enjoy doing for small one time tasks
This is what I'm looking for. Any example repo?
I start with panics in main, and return error and never panic unless I’m in the setup phase of the command or service.
https://play.golang.org/p/QDKsnufCaLu
Great talk! Too bad the Q&amp;A got hijacked by dependency management questions. A bit off topic for robustness.
I'm not sure exactly what you mean via the "data structure" part. The "classic" implementation is to store the flash message flag and information in a session cookie. The web framework deletes this data after each request, ensuring it is only used or displayed once. The relevant page template(s) have some javascript that checks the session data and injects the flash display, if present. 
I watched this because it was Francesc, but I was a little disappointed that it's not really about Go. Posting a summary so others can make a more informed decision about whether to watch. [My take on the background state of the world] Based on experience with Erlang, [Joe Armstrong suggests](https://www.infoq.com/presentations/self-heal-scalable-system) there are six requirements for building robust long-lived systems: 1. Fault isolation, so that a problem in one part of the program doesn't take down the whole thing. 2. Concurrency, because that provides the unit of isolation. 3. Failure detection, so that you know when a fault has occurred. 4. Fault identification, so that some other part of the program observing the fault can take appropriate action. 5. Live code upgrade, because that's how you deploy fixes to the faults. 6. Stable storage, because you need your data to outlive the faults and the upgraded code. Erlang is almost unique among programming languages in that it has all of these built into the core language / runtime. (Reusing this infrastructure is one reason Elixir is so powerful.) Typically these features are built into an execution system separate from the programming language. For example, PHP scripts running on LAMP stacks are not robust because PHP is doing anything interesting. They are robust because Apache is running each request in its own separate PHP (at least logically), providing isolation and concurrency; because you've got integrated, always-on logging, providing failure detection and fault identification; because Apache takes care of letting you do live PHP code upgrades, without taking down the server; and because MySQL is providing stable storage that outlasts any particular PHP script execution and hopefully is mostly immune to faults in the PHP. Like nearly every non-Erlang, Go leaves these features to the surrounding environment. You could at least imagine running LAMG stacks where Go binaries or perhaps on-demand-compiled Go programs substitute for the PHP scripts, and that would be one way to get the robustness. But Go is not doing any more than PHP in that case, not really. And while LAMG is not an acronym I see often, certainly many people do run Go programs with, say, nginx as a load balancer / fault isolator / concurrency generator and a hosted SQL database as stable storage. [Summary of talk] Francesc spends a bit of time talking about ways Go is more robust than C/C++, like not having dangling pointer errors, and then talks about how Erlang satisfies the Armstrong requirements while Go mostly does not (no fault isolation, little failure detection and fault identification, no live code upgrade, no stable storage although Francesc gives Go credit for SQL bindings). Having demonstrated that Go by itself is not robust at all, then at the very end of the talk he suggests that Kubernetes would be a way for Go programmers to achieve robustness as defined by Joe Armstrong. Absolutely true, although just about any other popular execution environment seems like it would work too.
Thank you for summarizing it. I'm returning from work, this will be a good read .
I haven't tried it, but I would probably just jump in and not let the raw numbers worry you. I would be willing to bet that of those 8700 students, a vast majority are not actively submitting solutions and taking up the mentor's time, and even if they are it might just mean it takes a little longer to get feedback. Worst case the mentor tells you they are too busy and you still had a chance to practice Go with an exercise.
I tried it on the Elixir track, I completed some exercises last Thursday, and I'm still waiting for a mentor comment on my tries, and I can't progress on the track until then (there are some side exercises available, but their difficulty seems a bit random). I'm not fully convinced by their mentor thing, but it is possible to complete the work without a mentor, and still be able to see other people solutions, so I think Exercism is a pretty interesting learn site, it's way better than those lesson-based sites imo. Hope this helps! 
Robotgo is great. I used it to write a Twitch bot to play Into The Breach fairly painlessly and easily (will probably be open sourcing the core framework at some point for desktop driven Twitch bot games). Was a bit fiddly go get set up with Windows though
If you do work in operations, using tools like a Ansible, etc., then it’s a good fit for that use case. I’m replacing shell scripts over a certain complexity with programs written in go.
\[removed\]
\[removed\]
Monorepo. Teams have different subfolders and third party is separated. Look at the blogs from cloudflare as they have been doing this for a while. We copied them and it got rid of internal / external dependency issues overnight. 
Thanks, robotgo is mainly dedicated to automation.
Thank you very much. I totally get what you mean. About haskell, I hope that it's clear that I don't care being admired. I will code in my room and all I care about is learning new things, and new perspectives that sort of make me more open and more intelligent than I was before. Like, « hey, what is a way of thinking that I ignore and could discover, and that would twist my mind in new ways? » It can be reading a Russian novel, or learning haskell, or go, or musical harmony or Chinese. This said I totally understand your point about building nice APIs. But right now, maybe I'm wrong but it's just that I don't consider myself entitled to build any API. 
Yes, you are right: https://github.com/elliotchance/tf/issues/5 Pull requests are always welcome :)
Which is weird because php definitely can and will take down your server. All those interpreters do is extend their dynamic nature and hide issues of memory. I get though how people think it can make it more productive and easier to pick up mistakes but you better have some high end servers to take that load. Yes I have heard of php 7.2 but most companies don't use it because of the nonexistent promise of backwards compatibly. I'm waiting for PHP to get async wait and implicit traits. Also everyone thinks arrays inside arrays is a great thing until they have to separate them through different Server requests. 
This. So very this. No more “Where’s Waldo” with ALL of the company’s code in a single place!
My biggest issue with the monorepo right now is our build system at work (jenkins) is really set up to run on a seperate git repo basis. I am worried about building only the code that changes, and deploying the right things. Right now all of the solutions I have seen in the wild or see myself being able to come up with is shell script duct tape essentially. There must be a better way without overcomplicating it I hope, go is suppose to be dead simple to build.
We have a monorepo: https://github.com/blend/go-sdk
Thank you, this makes sense
I think it might be this: [https://blog.digitalocean.com/cthulhu-organizing-go-code-in-a-scalable-repo/](https://blog.digitalocean.com/cthulhu-organizing-go-code-in-a-scalable-repo/)
On my previous team it was a monorepo, no tags, no vendoring, no CI, and fixing things when they broke. It was early in the team's move from C#, so there wasn't enough code to know if it was the right choice yet, but I think the extremely intense focus on avoiding third party libraries from anyone but Google, Microsoft, and a choice of data store was a big part of it working.
I maintain some Jenkins infrastructure at my place. I dont think Jenkins really handles monorepos well at least in the open source version. You can do it but it involves a lot of work on your part Jenkins isn't going to do it for you. I personally feel like separate repos are better overall unless you intend to build custom tooling around your monorepo or you dont mind everything building on every commit.
Hi, a few remarks about internal/set/set.go contents: * Add() + Remove() methods: not sure you gain something with testing len() here, but you surely loose as most of the time your users will pass at least one item; * Has(): almost the same here. You can avoid testing len() but initializing "has" to false. In your case, initializing it to true is useless, as its value is immediately overwritten in the loop; * IsEqual(): testing for same size is a bit complicated, why not `if len(s.m) != t.Size() {`? * IsSubSet() &amp; IsSuperSet() seem bad named. When I read `a.IsSubSet(b)` I understand I will test whether `a is subset of b` but in fact it is the opposite; * Copy() could be far more efficient as you already know the size of the new set; * Separate() could avoid creating a list of items to remove, by removing them directly without any allocation; * Intersection(): `result := all.Copy()` is more efficient than recomputing the same union; * Difference(): you say "separate is thread safe" in a comment, but it is not true. See [https://golang.org/doc/faq#atomic\_maps](https://golang.org/doc/faq#atomic_maps)
I joined about a week ago and have completed a few exercises in the Go track. The mentors are getting back to me relatively quickly on my solutions (usually by the next day).
We use Buck for all our build systems and in the monorepo it can detect incremental changes and has separate build targets. This makes it easier to use a monorepo, as long as you have persistent caches on your build machines. The clone time still sucks and the git log is kinda useless since the commits could be any project. 
Mono repo here too, with everything. Libraries and utilities use vendor external libraries with dep for now. We will be trying out modules when 1.11 is released. The idea is that you should be able to go get the whole repo or any of it's parts. We modeled it on the way the Go repository is structured. For now, there's no semantic versioning on URLs, but we plan to start using semantic versioning by the time 1.12 is out. All utilities do use semantic versioning.
I've been using dapper, while I was at Google, but wasn't formally trained into, more like learned it out of curiosity, and sometimes asked been asked by SRE's when I was oncall to provide dapper traces. From my experience we had (and had the ability through some built-in internal web page (that almost every app would have) to increase the sampling rate to say 1.0 instead 0.01 or 0.001 for the next 30 seconds (or whatever you like)). This was usually requested by the SRE, and then they would use this data to trace down things. Like is it spending too much time in bigtable, spanner, or something else. In anycase I understood that this way of tracing has many benefits, yet finding the balance, or using the "tool" properly would take me some time to understand fully. In the last OpenTracing conference, the guy from Google, behind OpenCensus - talked about tracing models, to record spans (and I guess keep their parents) only if they happen to take too much time, or some error happens - e.g. in away adapt itself to trace only what seems to be important. For example why even bother recording things that flow normally.
Best summary I've read on the topic of errors and panics in Go!
&gt; Monorepo, everything is in there, including libraries and the projects that use those libraries. This one. Works like a charm if you can invest in infrastructure.
You are not distinguishing fs read errors from nonexisting file errors. Also use inotify to watch filesystems. 
Thank you
I talked about this for our company (DigitalOcean), extensively here: https://speakerdeck.com/farslan/go-at-digitalocean Definitely check it out.
Could you elaborate on what you mean by that? When working with a monorepo, what is it that makes you need to invest more in infrastructure? Is it to do with what I mentioned in my post about detecting what to build, etc.?
Interesting, how did it help with external dependency issues? Maybe I need to read this blog post first! I'll go check it out. Thanks.
Hi , I am A Noob to golang, what is the difference between a package and a library in golang ? Thanks 
We use monorepo with event vendors commited in. It's painful until you include all the vendor stuff and slow to update\*, but works very well most of the time. (\*: Thanks to the kubernetes client...)
This is pretty much exactly what I was thinking when I said "Monorepo, libraries only", and for those exact reasons. The example I had in mind when I was thinking about it was the Symfony components from PHP. They have a symfony/symfony repository that contains pretty much everything to do with Symfony in there. All of the components, the framework bundles that you get out of the box in the standard edition, and some other bits of code. They differ a little after that point a little I believe because they use Git's subtree splitting to also use separate repositories. I was thinking if you treated pretty much everything as a library, then you could make these little "distribution" repositories that you built from. That way you'd never have the headaches about deciding what to build and when, you'd have to go and update the distribution repository and then it would just trigger a build on push. Those distribute repositories could even just be a main.go if you wanted to take it to a bit of an extreme. Going to read that post you linked now, thanks for commenting.
Ah sorry I meant digital ocean, yes this is the one 
That is quite an interesting approach. What stopped you from having vendoring or CI?
Nice, it sounds like you're in a great environment there. I'm looking to implement Go Modules with 1.12 too. That's an interesting point about the versioning though... In a monorepo where you'd be tagging the whole repository, perhaps you'd have to do a sweep through all of the code and update all of your import statements when a major version bump of the monorepo occurred? Or do you think you'll just go with version folders on disk? I suppose version folders on disk would give you more freedom to make breaking changes more gradually.
I suppose you could get around that issue by putting the components that were changed in the commit messages?
Yeah, I made a small flutter app just for the heck of it. Followed some guides/tutorials from Google. Basic examples were hideous to read. 
All non-main packages are libs.
Thanks! That code is the original upstream impl. We definitely should fix that. I created and issue [1] will let you know when it's fixed. [1] https://github.com/scylladb/go-set/issues/7
A nice write-up why Google uses a mono-repo. https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext
Oh boy, can't wait wen that happens.
Define a main package
I have not noticed this at all. I work in Go for an Ireland-based company. I've had various EU companies (non-blockchain based) send me offers to come work for them. Over here in Bristol UK there is an active Go meetup group with people working on all sorts of stuff. 
I do think though that the English speaking countries in Europe do not show the overall "reality" of the European tech mindset. 
&gt; Which is weird because php definitely can and will take down your server. how? you can set up a memory limit, a script execution time limit inside php.ini . I've never heard about PHP "taking down" an apache server.
GROM is a typo for GORM
again, any review much appreciated :)
I work in go here in Denmark and I know there are many gophers here.
Oh there's memory leaks. But I'm not going to start a discussion between interpreter and runtime/compiler. They both can take things down with interpreting syntax in any language. We take down the server almost every day in php so no that argument that the interpretor is some how robust is very false. 
Is there a difference between the 2 if I'm not reading the contents of the files?
We have go developers positions open in Lithuania. DM me if you are interested.
Working for a Swiss company. But I have to admit we use Go very sparingly. IMHO its twofold why adoption is still low: 1. Abundance of (cheap) JS and PHP coders and 2. Vendor lock-in on enterprise software with Java and C#. And: People are afraid that "new technology" will become as complicated as e.g. Java. Complicated as in certifications for developers, expensive special infrastructure, fragmented knowhow, complicated operations, licensing. To enterprise veterans it is almost unbelievable that you can write, test, debug, run and maintain production grade enterprise software with not much more than a bash and emacs and existing infrastructure like git, Cloud Foundry and Graylog.
Thanks sorry I don't know how I made such a big mistake 
`make start` and `make stop` appear to me to be abuses of Makefiles. Use them to compile your code; use something else to run it.
What is your recommendation ? 
Yeah I'd have to agree. It's because ctos care about clients demands, not the latest tech.
the good thing is that go compiler knows how to actually build go packages from source files, unlike gcc or g++ so makefiles are mostly useless to build go. to auto reload an app I use "fresh" utility written in go. I wonder why this idea doesn't exist with c or c++, 0 configuration / 100% convention build system in c or c++, or I don't know that tool...
For CI it was time. Also, our Docker setup made the lack of CI less painful. For vendoring there wasn't an official solution yet, so requiring most things to be from the standard library or one of a couple other reliable places prevented breaking changes without us taking the risk of depending on a vendoring tool which might not have stood the test of time.
In case this post doesn't get much traction, this gets posted every once in a while, and got upvotes [last month](https://www.reddit.com/r/golang/comments/8vhwpu/goto_2018_containers_from_scratch_liz_rice/)
Depends. If it's just running things in dev mode (for example with fresh and rebuilding &amp; restarting on file changes) I find it useful. We've got multiple `run-{service name}` in our Makefile - with a monorepo containing multiple services it saves a lot of hassle.
Why name the folder "api"? If its a subdir of [github.com](https://github.com) it should be your username. If you require a package and its called "api" and hosted on [github.com](https://github.com) then you've got problems.
Done.
don't be sorry. first time i've seen it.
No, you definitely can still post. Plenty of people wouldn't have seen the last one. This was a great presentation. I just wanted to give that note that if you only see 6 upvotes, its not because people didn't like this, but they may have seen it. and this made the rounds a few times.
Does it honor TTL for individual records?
This is live project and hosted on Centos server. That's y I shared all possible screen shots.
Berlin has a lot to offer on that front.
I didn't catch it last time either. No reason to worry
It just saves whole reply, so until the cache is updated you'll get the same TTL value with every query. The cache itself doesn't care about TTL at all and doesn't take it into account when dropping/updating entries.
AKA database.
No I have all three and they don't go past concurrency and starting a server and some conversion. The authors might in the future but I doubt it. I'm afraid you'll have to utilize tutorials for something for deeper dive. That's why I use these. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
I've always found realize to be a great one. https://github.com/oxequa/realize
Hmm, this has made me think. I was just about to make a post saying I think Go 2 should support generics. I’ll just have a quick look through the history to see if anyone else had the same idea....
Seems over engineered. `go build` satisfied my needs.
Or use (Magefile)[https://magefile.org/]
This is just a shell script in make's clothing. It only declares very simple internal dependencies and could as well have been a much tidier and more readable script. Some more concrete notes: * Recursively calling make for a trivial makefile like this is confusing and unnecessary * `restart-server` results in running `stop-server`, `stop-server` and `start-server` * Weird style in `compile` where you first touch the stderr log and then immediately remove it. You probably want `rm -f` * `go-build` and `go-install` depend use `GOFILES` but don't declare that dependency, so they'll be run unnecessarily if there are no changes to the GOFILES * `start-server` depends on a binary having been built, but doesn't declare that dependency * `WATCH_PID` is seemingly unused, but maybe it is used in the `.env` include? * stderr of go-compile is redirected to a file, which is then immediately piped through sed. Why not pass stder directly tp sed? Why do the sed business in the first place?
\[removed\]
I am not sure what you’re referring to. 
I mean what fs read errors should I handle? I create files but the files are empty
Reminds me of [realize](https://github.com/oxequa/realize), which is sort of the go version of what you're trying to do here with the Makefile.
You shouldn't need to call MakeRaw there. That function is mostly for full screen editors and other "visual" programs. ReadPassword will hide the echo for you, accordingly to the documentation. 
I like the concept from https://github.com/ScatterHQ/eliot/ where you can make a relationship between log events to better show the context of a log
anyone out there with micro repos? I am curious about your opinion.
We don't use tags. Utilities define their versions by checking in a version file. During the build process we just inject the contents of the version file into a version variable in package main. For libraries, we will use version folders, so the import path changes. It's simpler and allows us to use the go tools on all versions simultaneously. Building the entire repo still takes only a few seconds, thanks to Go's fast build speed. Which reminds me, I'd be interested if anyone knows of a tool that detects correct naming case via static analysis. I haven't been able to find one so far and Go recommends camel case.
Lol saw this talk just yesterday. It's talk was great even though I am not a huge fan of live coding.
In contrast to Exceptions panics in Go are used exceptionally.
Related issue: [https://github.com/golang/go/issues/26799](https://github.com/golang/go/issues/26799)
[removed]
You want Mage. It's very similar to Make, except you write go, and not shell script. It's portable wherever Go is supported, so you don't have to worry about Windows or what shell works locally. It's very simple to make a magefile that mimics the one posted in that article. Mage does all the heavy lifting for creating the CLI and documentation, so you don't have to do help: Makefile @echo @echo " Choose a command run in "$(PROJECTNAME)":" @echo @sed -n 's/^##//p' $&lt; | column -t -s ':' | sed -e 's/^/ /' @echo You just write normal comments on exported go functions and it just works. // This is a mage target that will appear as a command with this as documentation. func Build() { } 
Yeah, but the default handling seems to be working for me in the following program: package main import ( "fmt" "os" "golang.org/x/crypto/ssh/terminal" ) func main() { fmt.Println("Password?") pw, err := terminal.ReadPassword(int(os.Stdin.Fd())) fmt.Println(string(pw), "|", err) } Hitting ^C while entering the password terminates the program, without resetting the terminal. Golang sets up a default handle that prints out "signal: interrupt" and terminates the program. /u/weberc2, check your program for any calls to [signal.Notify](http://127.0.0.1:9000/pkg/os/signal/#Notify). If something is explicitly catching the interrupt, but not terminating the program, that could be the problem.
I love this talk , but she gave it at least in 20 different places 
Updated [to create new movies](https://play.golang.org/p/p5dveGMTemq)
It executes the anonymous function defined above. Same as `calc := func(url string) { ... }; go calc(word)`
Yes I know it’s OT... 
You should really honor TTL. There are so many messes that are caused by DNS caches not honoring TTL. 
I see that but there are a ton of file system errors while reading a file or directory ("reading a directory" means listing contents of a directory). Imagine a permissions error: When you see this error, you simply ignore it as if the file doesn't exist. Maybe the file does exist (created by the preStop hook), but you are getting an error about "can't read directory because insufficient permissions" and so instead of crashing, you're ignoring the error and keep running. Clear now? os.IsNotExist exists exactly for this reason [https://golang.org/pkg/os/#IsExist](https://golang.org/pkg/os/#IsExist).
Just in case anyone happens to read this, the latest GoLand fixed it. It could have maybe been bug GO-5702, there was a replace command in the go.mod (although it wasn't that dependency specifically that wasn't working).
Do you have any links to where you pulled this screenshot from?
+100
We have been using a monorepo since beginning. Every service / team has it's own folder and common libraries go in a common folder. As for CI automation, you just need to mention the relevant paths the build job needs to checkout. The downside to this is in cases where common libraries get upgraded. Every dependent service has to eventually make changes accordingly, in case a breaking change has been made. We are yet to figure out proper versioning for these libraries that services could specify in their build job.
90s demoscene. yes, I remember that. I assume there isn't many "hacks" needed for writing wasm demos. The only constraint would be a reasonable download size.
Wait. I assumed you named it Jeff after the infamous judge Jeff Sessions?
This is anonymous functions. Useful examples that explain it a lot better: 1. [https://gobyexample.com/closures](https://gobyexample.com/closures) 2. [https://golangcode.com/anonymous-functions/](https://golangcode.com/anonymous-functions/)
[removed]
Rob Pike's quote kind of summarizes it well: ``` Our proposal instead ties the handling to a function - a dying function - and thereby, deliberately, makes it harder to use. We want you think of panics as, well, panics! They are rare events that very few functions should ever need to think about. If you want to protect your code, one or two recover calls should do it for the whole program. If you're already worrying about discriminating different kinds of panics, you've lost sight of the ball. ```
&gt; So, whatever I "should" be adopting ought to be in a style-guide. Sure, there is. https://github.com/golang/go/wiki/CodeReviewComments. Not a comprehensive style guide. But some guidelines to follow. As mentioned in the link, supplement that with [Effective Go](https://golang.org/doc/effective_go.html)
The stdlib is really very readable though. One of the best things about Go is that the readability makes some complicated topics very approachable. The stdlib is more "over there" than "down there"
Haven't looked too much at it, but I found this really quick that is hopefully close to what you're looking for - https://github.com/h2non/filetype/blob/master/README.md If you wanted to google more, it'd be along the lines of MIME type inferences and/or parsers
Neat!
1. Goroutines (aka threads) `go someFunction(anArgument)` This will run the _'someFunction'_ function in a goroutine. 2. Anonymous functions `anonymousFunction := func(name string) { fmt.Println("Hello", name) }` 3. Combining the two, part 1 `anonymousFunction := func(name string) { fmt.Println("Hello", name) }` `go anonymousFunction("John")` 4. Combining the two, part 2 `go func(name string) { fmt.Println("Hello", name) }("John")`
Never saw a GRID before: who uses it and for what purpose?
I've seen the package you referenced, but it has a flaw which results from two conditions: 1) Microsoft office documents are just zip archives 2) filetype stores the list of matching functions in a map and maps do not guarantee the order of iteration Given these two conditions, for same docx file, filetype will sometimes return the zip mimetype and the docx the other times, depending on the order of iteration of the matching functions. mimetype works around this issue by keeping the matching function in a hierarchical structure, thus docx matcher being a child of the zip matcher. If a docx file is inspected, mimetype will first check it for zip and if successful it will also check it for docx and return the latter result.
At a first glance, it seems like this is a worse version of [gimme](https://github.com/travis-ci/gimme/blob/master/gimme). After looking even more, that looks even more true. There's also plenty of other tools that do this like [gvm](https://github.com/moovweb/gvm) and [goenv](https://github.com/syndbg/goenv) which all seem to be more battle-hardened and featureful. &gt; Setups $GOROOT and $GOPATH by entering required path variables into your zsh or bash shell automatically. As an fyi, GOPATH is going to be optional starting in go1.11 for module-enabled packages, and hopefully optional for all in go1.12. On to the code itself: &gt; wget https://storage.googleapis.com/golang/$download_file -O /tmp/go.tar.gz 2&gt;/dev/null || curl https://storage.googleapis.com/golang/$download_file --output /tmp/go.tar.gz Oh, hey, cool, it's that well known security vulnerability where you use a fixed path in `/tmp`. I'm glad in the year 2018 that's still a thing. So, the problem is this: "/tmp" is world writable, so I can create a file there that I own, and then wait for someone else to try and use it. Using inotify, I can see when someone else writes or opens that path, and then swap out the contents with evil code. For a more concrete attack, imagine the following scenario. I have non-root access on a shared machine. I think the "root" user on the machine will run your script at some point in the future. I run `touch /tmp/go.tar.gz` and set up an inotify watch on it. Now, whenever "root" runs your script, `wget -O /tmp/go.tar.gz` will open my file with `O_TRUNC` to truncate it and download the file there, but it won't change the permissions. Now I, the attacker, just have to use inotify to notice that wget has closed the file and quickly swap out the downloaded tarball with a malicious copy of go. Now when root runs "go", I have executed arbitrary code and pwned the server. There have been numerous CVE's for programs doing this over the years. The solution is to use `mktemp -d`. While you're doing that, you should also look into what `trap '...' EXIT` does, since that's a good thing to pair with mktemp. Speaking of, next item in my review: error handling in bash. You really need to have `set -eu` and `set -o pipefail` in any bash script that's more than 5 lines. If you're going to write bash and recommend others use it, please actually write okay bash. Another trick to know about in bash is related to how you append a multi-line string to the profile: https://github.com/solodynamo/go-init/blob/822ef28cf968468d872f81ddc78d7e5525e21731/goinit.sh#L83-L90 A more canonical way to do that is: cat &gt;&gt; "$HOME/.${shell_profile}" &lt;&lt;EOF # GoLangConfig export GOROOT=\$HOME/.go # etc... EOF Sure, you'll have to escape the dollar signs now, but it's a much more expected way to do it. The whole 'sed' thing is kinda messy too, and honestly it would probably be more readable to do that via writing a file like `$HOME/.goinitrc` and then just write the one line `source $HOME/.goinitrc # GoInitConfig` to the shell rc file. After doing that, you could just delete the `.goinitrc` file since your script would control it, and then only have to sed out that one `source` line. It really doesn't look too bad other than the security issue I mention above. I think it's a good learning project to write stuff like this... but I'd recommend against telling other people about it or to use it when you don't know about bash and don't have a reason to recommend it over the many alternatives.
The only good Makefile is a deleted Makefile.
Indeed - there will not be a 64k intro scene with Go webassembly. I will be covering building up an arsenal of effects and getting and understanding of what makes fast graphics, but without resorting to raw assembly.
I think this does Not exist because the c/c++ environment has grown to be able to things against conventions. Since you cant really force All of them to suddenly become compliant this is likely never going to happen. 
Update: We have made generating sets for your own types really easy now: * go_generate tool was forked and you can just go-get it, see https://github.com/mmatczuk/go_generics * all the generation procedure was wrapped in a bash script In addition to that the original set implementation from github.com/fatih/set package was improved, most notably Copy, Union and Intersect are smarter in terms of memory management.
Did you meant this to be an announcement? If so, you forgot the URL to your project.
What is the intention here? I have a small func I use for running things in parallel. It abstracts a lot of noise away. https://github.com/ihsw/sotah-server/blob/master/app/util/util.go#L16 Here is an example of its usage: https://github.com/ihsw/sotah-server/blob/master/app/items.go#L77 Granted it doesn't use `sync.Pool` at all but it looks kind of similar to what you're trying to do.
I'm gonna go out on the limb here and ask if using `map[T]struct{}` is what makes it zero-alloc? If it would use `map[T]bool` it would become allocating, but this way the compiler optimizes empty struct away and just keeps an entry in the hash with a nil value?
Good call. Cheers!
This is about Go's garbage collector. Here's an extract but the document is concise, I recommend reading it: &gt;The current algorithm is racy and, as a result, mark termination must cope with the possibility that there may still be marking work to do. We propose a new algorithm based on distributed termination detection that both eliminates this race and replaces the existing “mark 2” sub-phase, yielding simplifications throughout concurrent mark and mark termination. Want to read more about Go's GC? Here's the transcript of Richard L. Hudson's keynote on ISMM ^((International Symposium on Memory Management)): [https://blog.golang.org/ismmkeynote](https://blog.golang.org/ismmkeynote) He's part of Go's dev team.
Interesting approach, I was thinking about something like that myself. The only problem is that goroutine count growth is unbounded in the provided example, and it can result in very bad things if server become overloaded. 
Just saw this. JWT authentication since I had no clue how all that worked and wanted to learn. I referenced some of this when building it out: https://auth0.com/blog/authentication-in-golang/
The problem, is not when creating short lived workers. It is for when the workers have a high cost for initialisation or take time to initialize, so keeping them between task would improve performance. The use of the sync.Pool is mostly here to keep some of the workers alive while still being able to create new one when there is a peak of task. Also it let the GC choose whether the Pool have grown too much and should be emptied. My example don't show this at all, I should have had context. My main problem is I can't return a `chan something` but have to work with `*chan something`. In the code you posted, there is no caching of the workers.
The posted link goes to the [preprint (non-peer reviewed) technical paper](https://www.biorxiv.org/content/early/2018/08/01/380808) about SciPipe. See also the [main website](http://scipipe.org), and [GitHub repository](https://github.com/scipipe/scipipe). The preprint will be submitted to a journal shortly, so any feedback on it is warmly welcome as early as possible.
This could be handled with the use of a counter, incremented in the New method of Pool and decremented in the finalizer. With this you can have a max number of worker. If it is for worker really in the sync.Pool the increment should be done in `sync.Pool.New` and when calling `Sync.Pool.Put` and the decrement when using `sync.Pool.Get` and in the finalizer.
Try Elixir out, not only functional (and a bit less annoying than dealing with monad hell) but it has some interesting concepts due to actors as a core mechanism. It will make you question whether you understand what the language is doing. Like, why you would start a yaml parser as an application, instead of just import the code. It borrows a lot from Ruby but is built on Erlang so you get this weird mix of both, plus there's Phoenix which is very Rails like.
My advice is that you don't want to put anything that requires life-cycle management in a \`sync.Pool\` because it can be cleared randomly. The pool is great for caching reusable buffers to prevent allocations, but I wouldn't use it for any struct that requires clean up. The use of a finalizer in the example is a code smell of that problem.
This is interesting. Yes there is no caching of long-lived/always-on workers, the intention was to spin up a few go-routines for small-scale parallel workloads (usually for network/disk IO-related tasks).
I didn't know. I'm mostly a Google Cloud and Digital Ocean guy :-) Thanks!
&gt; Goroutines (aka threads) No. 
That's the ideal, but in reality a lot of projects not only have Go code, but also depend on data that needs to be processed, have to create distribution packages, generate man pages etc.
Yes yes I know, a goroutine is not necessarily a thread The runtime decides itself if it should run it in a thread or not But that's not the subject here and the comparison is okay enough for OP's use case 
I like the examples for the custom functions, however, do you have to write to a file for the intermediate steps?
If there is an existing code base in Java, it might be a good idea to stick with Java dev. I abandoned Java for Go for what I did, because I had performance issues that our Java framework made impossible to solve. I easily solved it by abandoning the framework. I could have used a different Java framework, but was able to solve it easily with stdlib Go code. The downside to porting to Go is that our SDK is now forked between Java and Go, with front-end devs wanting a Javascript SDK (for node.js). But Go is almost inevitable if you have problems where you are seriously considering using C.
Source code is very simple now and it's basically ton of Swing code (written breaking every swing rule, barely uses layouts...), it can't be reused. New application will have that exact fronted but as website and in addition handle database connections (it didn't before because we have custom db connections balancer). All real logic still lies in PL/SQL. It's not that that go code will have to do much, it's more about scale of users/requests. 
&gt; Having to look at whether the left or right value was "got" or "want" is an annoyance and likely impediment. Personally, that's not really something I've ever noticed as a problem myself. I think it's probably more advantageous when *writing* tests (since you don't need to look up the argument order) than *reading*. I will think about adding it. I would prefer to keep the article reasonably short and limited to the most important points, instead of boring everyone with a long list. The best style guides are the ones that are actually read and people actually follow, not the ones that annoy people with "pfft, what a long and pedantic list". &gt; I am wondering, however; What does "tt" mean that it makes sense for the name of a tests row/test case? Table test? But it's not a table, it's a row from a table. Maybe it's an alternative form of simply "t" because "t" is used for "testing.T". And maybe I should just accept it as "table test" despite my own perception of some semantic dissonance. I think it's just to avoid conflicts with `t`, and doesn't really mean anything as such. Like `j` instead of `i` in nested `for` loops. I am not wildly in favour of `tt` myself, and previously always used `tc` (for "test case").
Why is the multiplication by 1.25 needed here? func newSet(size int) *Set { var m map[string]struct{} if size &lt; 4 { m = make(map[string]struct{}, 4) } else { m = make(map[string]struct{}, int(float64(size)*1.25)) } return &amp;Set{m} }
I enjoy Go a lot and introduced it to a C#-only team that also found they loved Go. By the time I left that team, almost all applications were Go in Docker running on Ubuntu with a frontend reverse proxy on a Windows machine running IIS (sounds weird, but that gave us a place to run holdout .NET apps). You've mentioned things like LDAP, which one might assume are easier in C#, but over time we began to favor Go even for projects that spoke LDAP or dealt with SOAP. That said, obstacles in the form of executives with very strong opinions might not be something you can control. Half a year after I left the team I mentioned, an executive decided that all Go, all Python (which was where 100% of the predictive analytics projects had been for years), and all TypeScript (shrug) had to be rewritten to C# because the company was a "Microsoft shop". I think the last point (TypeScript) is still being argued since replacing Angular with Blazor frontends would be... a heavy lift... and I think the team has gotten savvy to talking to this exec and have told him that TypeScript is a "Microsoft product" and that Blazor is experimental. It's a weird dance to navigate political demands in development, but to me, the best success comes when you use big company names and talk about things that have been stable for long periods. So... you can mention Google, mention how long Go has been past 1.0 release, and talk about how much of the web goes through Cloudflare (uses Go), Google, etc and point out that Microsoft even has Go repos. Make it sound big, enterprise-accepted, and talk about things that can leave an impression that its strength as a outscaling and performance languiage is well supported (point out SDKs for Azure, AWS, GCP), established, and accepted by the largest players in the industry. You might also get an exec that demands everything get ported to PowerShell! Who knows. Anything can happen really. I've seen execs with no technical background directly order a specific database schema (around the time I resigned). Just remind yourself that you can only do so much and it isn't personal. It's just... people with power having opinions...
1) How is each repository setup? I preassume like this repo1 src/ main.go repo2 src/ main.go 2) How do you pull depedencies? do you use \`go get\`? I agree from a CI/CD perspective it makes its much simiplier and safer. 
If possible, hand them a working prototype of a few API calls, if it's that easy. That carries a lot of weight. Do be sure to include at least one non-trivial call, though. In this case, the odds are extremely, extremely good that it really doesn't even matter what you choose, if all the work really is in the database. That'll be your only scaling and availability concern. For everything else it hardly matters what you choose.
[removed]
Creating your own Pool is pretty tough. Pool hides its content from the GC and involves a lot of unsafe operations to do so.
I am not really sure myself, that's why I ask here. I bet we can make it work flawlessly in java, but I don't like being dependant on one ecosystem, in Go I am going to make fronted as portable as possible to different back-end in the future, because tech changes no matter what and these systems are often in use for over 12 years. While java implementation introduces a lot of abstraction specific to them. Here's my thought now: is there some low-level http framework for java, something as simple in principle as in Go? Just template engine and no other useless abstraction crap. Only requirement is that tool is battle-tested and supported. 
We avoided SOAP whenever there was another option, and for a couple third party services where it was necessary, we didn't really implement SOAP and certainly didn't provide a SOAP API. Instead we simply called a SOAP action and parsed the XML response. There was enough information in there to then cache some bits and provide a REST API. In that way, third parties that only provided SOAP endpoints didn't need to be spoken to directly, and the very simple adapters that proxied the requests between our applications and third party SOAP APIs were very simple microservices that could be understood in only a few minutes of looking at the code. It also meant we had an easy step by step avenue to remove those third party services entirely since we could look at replacing one SOAP endpoint at a time. The team never wound up changing those though. The SOAP endpoints were old APIs that weren't likely to change anytime soon, and the adapter proxy approach worked fine.
[@echo's latest tweet](https://i.imgur.com/9POVNjr.jpg) [@echo on Twitter](https://twitter.com/echo) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
It would allow you insert 25% more entries before Go needs to expand the underlying map size, but I don't know if that's why or how they arrived at that number if it is why.
Loved the game!
Thank you very much! 
i have a template for starting go projects, i use a make file for it to compile and run tests, you can find it here [https://github.com/lacion/cookiecutter-golang/blob/master/%7B%7Bcookiecutter.app\_name%7D%7D/Makefile](https://github.com/lacion/cookiecutter-golang/blob/master/%7B%7Bcookiecutter.app_name%7D%7D/Makefile) i been trying to get some people to use it or maybe contribute a bit on improve it, but so far people seem to use it and, not change it a lot.
Thanks, very good question. I had a look at hash map (hmap) implementation in runtime. It consists of n buckets each holding up to 8 items. In reality when you do make(map[type]type, size) you pass a hint for the number of buckets. The number of buckets is minimal power of 2 greater then the hint. I have fixed that with https://github.com/scylladb/go-set/pull/10 also the hinted constructor is now exported.
Sure check https://github.com/mmatczuk/go_generics and generics_tests dir contains other examples.
Currently, that is the case, yes. I have wanted to lift out the core logic of SciPipe into a more generic framework, and did that of a very early version of SciPipe, into what is now [http://github.com/flowbase/flowbase](http://github.com/flowbase/flowbase). It (flowbase) currently lacks a lot of the goodies that eventually went into SciPipe though, such as a generic navigable network structure, graph visualization etc, so I'll have to take another stab at separating out the generic from the specific in SciPipe again (Go's lack of generics doesn't help to make this easy ...).
I was on irc #go-nuts a few years ago witnessing an infestation of some fanatics keep saying "you do not need package managers", "you do not need context for your http handlers", "you do not need generics", praising the decisions of the Go authors as immutable commandments of the gods. It is now funny to see when Google _itself_ needs any of these highly requested, yet highly dismissed, features from the community, they walk back quietly and make it happen. It's just a matter of time. Hey #go-nuts fanatics, where is your gods now?
I found it very stimulating to learn (still am) but one of the benefits is that it compiles down to an independent executable. No runtime support required. So your Dev environment may be chock full of go source artifacts, but the compiled executable is totally stand alone.
Could this work for an ETL solution ?
Spring Boot + Angular
They definitely don’t have enough mentors. Your better off setting learning in independent mode. I finished an exercise 2 weeks ago and still no mentor. 
Awesome..Starred!
Dude I can't type when even one person watches me. I can't even imagine what it would be like to have an audience. 
You may find this package useful: https://godoc.org/github.com/artyom/httpflags — it contains logic to parse url parameters/form fields into given struct, using stdlib’s flag package under the hood.
From what I read go_generic applies Go-wise transformations on code files. How does it differ from golang.org/x/tools/cmd/eg?
Getting "410 The author deleted this Medium story"
https://github.com/gorilla/schema
Coworker of mine created this synth project in Go. It might provide some inspiration. https://github.com/brettbuddin/shaden
So its a little distracting, but streaming coding keeps me focused more than not streaming it would since it prevents me from hopping over to Reddit or turning on a video game. Development that is slowed to 40% of its normal speed is still faster than 0%.
Are you sure you have a hard real-time requirement? No application under Linux, Windows or OSX can support this requirement as the kernel can interrupt any process at any point. Likely this will not matter for your usecase and a near real-time approach is good enough. For this go can work if you pay close attention to allocations as well as long computational tasks and there is a very good chance that you won't notice or care about the GC pauses. So give it a go, learn a bit more about what you actually require and see if there are any actual limitations or problems. Go have a lot of profiling tools that can help you detect and tune the performance to an acceptable level. In the unlikely event that you decide that go is not fit for this project you may consider looking at rust before heading down the C/C++ route. But I seriously doubt that go will not work for you in this application.
Not just heap allocations, one big cause of really slow GC is CPU intensive tasks with no I/O or other forms of yeilds. Goroutines are not preemptive and the go runtime cannot interrupt calculations so it must wait for all goroutines to yeilds their control before it can actually complete a GC cycle. There are lots of natural ways goroutines do this (any I/O, selects, launching other goroutines, channels, etc) so most of the time you won't notice. But a simple loop can block GC completely.
I’m moving my code base back to Go from Java. Right now everything calls web services directly. Go is made pretty much for microservices and containers. 
I meant a struct where I can store my worker and retrieve them, and given some rules/time remove some workers. Nothing low level like `sync.Pool`.
FWIW I wrote a midi application in go that streams midi events to a web browser via web sockets. It’s simple and only lights up keys on a keyboard in a browser but it works great
&gt; I don't use macOS, but there's got to be an easy way to install it there, too. Yes, via Homebrew. Works for me like a charm since years. Or download the native installer .pkg from golang.org/dl.
Try to split the CSV and do the import in parallel.
Go is a general-purpose programming language. Have a look at [Awesome Go](https://awesome-go.com/) to see the wide range of projects that Go is used for. (Awesome Go is a manually maintained list of Go projects.)
&gt; One way to do this is to loop over read each line of data from csv, then inserting them to database records. Are you doing this as separate insert statements over separate connections all serialised? Or are you batching these up and submitting each batch as a single insert statement? Are you going the uploads serially or in parallel? Have you read the [mysql guide on Bulk Data Loading](https://dev.mysql.com/doc/refman/5.6/en/optimizing-innodb-bulk-data-loading.html)?
Comments for PG, I don't know about MySQL: The `COPY` command allows you to set the delimiter, but if your data has inconsistent delimiters you can also fix the data and stream it to `COPY` as it can read from STDIN (your client app). The biggest time saver for bulk importing is to not create indexes on the table till after you load the data. There are also some smaller tricks using things like the `FREEZE` option to COPY. If you give more details I may have other recommendations, but to give an idea I recently built a system that loads 200M rows into PG in about 4 minutes, including copying data, setting up indexes, doing some warming operations, etc. 
Did you identify what actually takes up most of the time? Did you try a short version of that csv to see if it actually reads the lines as intended?
The application you're suggesting isn't real-time by a long shot. I don't think you're going to have speed issues doing something like this.
Wow man great, but this will break the sequence I believe.
&gt;I recently built a system that loads 200M rows into PG in about 4 minutes, including copying data, setting up indexes, doing some warming operations, etc. Can I have a look at the code (if possible)?
It actually writes 120 data/second into database
but is this limited by writing to the database or by the speed you read and batch the data before writing it to the database?
That's slow
I can't share it, sorry. At a high level: 1) Begin transaction 2) Create table without indexes 3) COPY data with FREEZE option 4) Commit Transaction Create table + COPY...FREEZE allows PG to skip certain checks but breaks MVCC visibility (the data will be visible to other transactions immediately). However this usually doesn't matter for bulk loading. After this you can create the indexes you need on the table. Now, if you have to insert to an existing table with indexes setup because it's in active use, there are other tricks that can be used to make it faster. It's dependent on the use case though, e.g. if these bulks loads are common, use a partitioned table and each bulk upload becomes a partition, this allows using the same process as above with a couple added steps at the end to attach the partition efficiently. 
Cool stuff.
I don't have idea why it's slow
OP probably already knows this, but for anyone else, it might be prudent to check on Oracle's licensing plans for java, where enterprise users will be charged for both JDKs and JRE.
You don't do insert 1 line at at time, You read every 1000 lines (very fast), make a single insert statement, and continue with next batch. It shouldn't take more than a few minutes.
Rewrite it in Go. Use gopkg.in/goracle.v2 as a database/sql driver and github.com/tgulacsi/oracall for gRPC code generation of stored procedures, and github.com/UNO-SOFT/soap-proxy for a SOAP proxy before that gRPC server. (Shameless plug)
This. Look into Bulk Insert. 
Probably yeah, but generally you'll need to do the same thing any other real time code needs. Pool message structures from the websocket/http request so you don't get hit with heap latency, then run the midi output on a separate thread from the networking and it'll probably be good to go. May not even need the message pooling u til you get lots of connections. Even then, 100 people on one synth sounds like chaos.
Try batching the inserts. Something like this: https://play.golang.org/p/SWhaPXIXiFq
It's fine just don't load down the os, you can play with the thread scheduling if need be as well
There is no xmlsec implementation in pure go - you'll have to use cgo to handle SAML
And it's pretty awesome! :-D
Yeah, I have to admit: even with that, I don't really understand how to use it.
I've done it (well, I'm taking midi input and generating sound, but it's similar real time requirements). Perfectly feasible. Whatever latency you get from the GC drowns in the non-realtime behavior of your operating system anyway. Just figure out a good way to measure your latency and keep in mind that 1ms ~= 30cm, so if 1ms of latency bothers you, move your speakers 30cm closer to your face and you've removed that latency.
"The synth was used to create the intro music for the GothamGo 2017 conference videos" That is so cool!
&gt; Here's my thought now: is there some low-level http framework for java, something as simple in principle as in Go? Just template engine and no other useless abstraction crap. Only requirement is that tool is battle-tested and supported. Vert.x
Found it yesterday, will go with it. 
For PG use the COPY command. For MySQL use the LOAD DATA command. Simple.
How do you handle primary keys
Postgres doesn't require primary keys, add one when adding indexes / constraints if needed.
Hello there! This is my first attempt to write some go code. It's a very very, simple utility; just a wrapper around `git status`. Anyway, since sometimes I forgot what I've been working on, this utility helps me find uncompleted tasks. Feedback always appreciated!. :)
if output, err := gitDeleteBranch(selectedBranch.Name); err != nil { return createErrorPanel(g, output) } On mobile but it looks like you don’t use the error at all.. is that by mistake? Seems a bit against the grain. 
could you share what you coded a bit?
what's the difference? there is none. containers will just run your app... in a container... how micro should a microservice be?
There is [a package I've used before](https://godoc.org/github.com/jolestar/go-commons-pool) for pooled objects that I want to have a lifecycle. It's pretty flexible, and will be able to do what I understand you're looking for.
Any language will do want you want. What are your goals? If it's to learn Go then use it. If it's too build a real time midi app then use the language you know. Don't combine both otherwise you risk finishing nothing.
I had poor data hygiene in college and most of what I did back then (15-20 years, pre-github haha) is on a dead drive. :( That was mostly C, Java, and Python -- I did some simple DSP in C and Java and a lot of MIDI / control data in Java &amp; Python. Currently when I tinker I use [Pure Data](https://puredata.info/). I have a collection of patches for an Arturia Minilab which [look like this because I can't be arsed to lay them out better](https://i.imgur.com/1Mx5g7B.png). I haven't done any audio or MIDI in Go, but Go's garbage collector is _wicked_ better than Java's, at least in things I've had to profile for work.
A common way I see this done is in a select statement on a `time.Tick()`. Select on channels for work to be done as normal, but also be sure a GC is done every `d` time interval. 
Hi, this is my first Go package. It wraps the *net.TCPListener with the following features: * IP-Ban * Limiting Maximum Alive Connections * Limiting Maximum Alive Connections with Single IP * Limiting Maximum New Connections with an IP address in a Time Interval
Not super relevant, but I found this article to be very interesting. It's about performance.
The garbage collector is arguably worse than Java's, but the compiler and language work to give the GC less work to do in the first place. Java is extremely heap intensive, while Go manages to allocate on the stack remarkably often, avoiding the GC altogether. Idiomatic Go code (simpler code) and native compilation (no dynamic class loader) also make Go about an order of magnitude less memory intensive overall, which also gives the GC a lot less work to do.
Have you tried Scala? Or go is the only option here? 
Those containers are going to have different IPs on the jottNetwork. You want to connect to db:3306 instead of 127.0.0.1:3306 (I think; refer to the [docs](https://docs.docker.com/compose/networking/) if my memory is faulty and this doesn't work).
This is the right answer. 
Perhaps I should have said "Go's garbage collection behavior under typical usage patterns".
Hi - are you trying to achieve something like this? [https://play.golang.org/p/4cVKV7sApq8](https://play.golang.org/p/4cVKV7sApq8)
This worked! Thank you so much
Sort of but i don't know what the structure will look like before hand to define it. 
Did you use go run to execute your program? If yes, no wonder.
Then use map[string]interface{} rather than a specific type.
Try using a string builder. var a strings.Builder a.WriteString("Hi there ") for i := 0; i &lt; 100000; i++ { a.WriteRune('(') a.WriteString(strconv.Itoa(i)) a.WriteRune(',') a.WriteString(strconv.Itoa(i)) a.WriteString("),") } return a.String() My guess is that python uses a string builder implementation as part of it's basic string functions.
http://herman.asia/efficient-string-concatenation-in-go &gt; The thing to know about this is that strings are immutable in Go - each time a string is assigned to a variable a new address is assigned in memory to represent the new value. This is different from languages like C++ and BASIC [and python], where a string variable can be modified in place. In Go, each time you append to the end of a string, it must create a new string and copy the contents of both the existing string and the appended string into it. As the strings you are manipulating become large this process becomes increasingly slow. In fact, this method of naive appending is O(N2).
https://blog.golang.org/json-and-go - read the part "Decoding arbitrary data"
You're a code magician. Now it takes only 0.02 second. Now it's much faster than python. Thank you
IIRC python strings are immutable too
Replace type 'myData' in the code @devfd1 suggested with a map of string to anything.
They are, a faster method to do the python version would be to use the .join() method
In addition to others said, docker-conpose link is deprecated, you just use a network, all containers on the same network are accessible
CPython does an in-place string replacement when it can: https://stackoverflow.com/questions/3901124/performance-comparison-of-immutable-string-concatenation-between-java-and-python
&gt; I have no experience with go I'm afraid that you should familiarize yourself with Go first. There's not really just a magic way to read in dumped strings and run them, in fact I doubt that the dumped SSA form is written to be machine parseable.
Hey, what's your definition of real-time? Sub ms response time? Or something else?
[removed]
What I was trying to point out is that he checks for an error, then does not actually use it. Error might as well be a bool and not an error type if it's not being used there. I looked through the code and it's technically OK because it boils down to this function: `func sanitisedCommandOutput(output []byte, err error) (string, error) {` `outputString := string(output)` `if outputString == "" &amp;&amp; err != nil { return err.Error(), err }` `return outputString, err` `}` Which is a pretty weird function to have.. the output string can be the error, and also the error can be the error. So that means things like \`gitDeleteBranch\` don't need to return a string and an error.. they can just return one, since they're both going to be the same thing potentially. Typically, when you have a \`func() (T, error)\`, if an error is returned, you don't want to rely on T to be anything worth using. 
[https://play.golang.org/p/FrDJceW-lJA](https://play.golang.org/p/FrDJceW-lJA)
[removed]
This part `"(" + strconv.Itoa(i) + "," + strconv.Itoa(i) + "),"` is in fact very efficient, because the compiler has a special for it, so the string is not copied five times or so. It is the `+=` part in a loop that ruins the performance. 
sed on \*nix should do a fantastic job and it would probably be faster than implementing it in Go.
I don't understand a dropper with a custom language or macro on an existing one. Why would I not statically compile the Go compiler in my "dropper" and receive Go code instead of a custom "gscript"? Or why would I not cross-compile it on a source machine and send the executable over? Afraid of having another visible process running? There are plenty of JITs out there that are probably smaller and less-noticeable than V8 if you have to be fast, or interpreters (e.g. otto) if you don't. As a devops tool PoC, I [built a system](https://github.com/cretz/systrument) that compiles Go for a target machine (e.g. compile for Linux while on Windows), SSH's into the target machine, sends over the executable via SFTP, runs the executable over there, allows the executable to request files from the source machine (also sent over SFTP) and sends stdout/stderr back. Granted that was a while ago and I didn't pursue it. This used open SSH but the idea of shipping executables and data is there.
Definitely.
IIRC the go stdlib json package uses a lot of reflection under the hood and 3rd party libs (at least fastjson) can have 15x faster performance
I'm just guessing here, but is the value being used after the loop? It's possible python 'optimizes' the entire loop away if it sees the result is never used afterwards. Whereas the Go compiler probably doesn't. 
It may be better to get your hands an x86 asm (AT&amp;T or Intel) than Gos SSA-IR. Btw in the past it was Plan-9 asm. For more information please refer to the compiler publicly available on GitHub https://github.com/golang/go/tree/master/src/cmd/compile/internal/ssa.
Yea, that sucks, especially when they want us to list every single host running java and we have hundreds hosts, because it's almost always host per application with dev, preprod and prod environments at least, well played oracle..
You can definitively containerize both. I'd say for a small project Django might be a little easier but if you want to scale consider using Go.
Is there any special reason you are using regex/syntax? This is rather uncommon and most just use regex.
This makes sense since python uses reference counting so it can know if it's safe to mutate a string without anyone noticing.
Instructions unclear - speakers stuck on face.
To be fair the go compiler should be able to see it's only got a single owner and do the right thing in a lot of cases too. I'd be kind of surprised if they didn't implement that soonish.
The big difference has to do with string concatenation caveats in Go. You should never naively concatenate strings in Go because it's very slow and gets slower the more concatenations you run. 
No it shouldn't. There is no way to know how many references are alive at compile time since it can depend on runtime behavior. Maybe it can do some super simple version but it can't do anything like python without adding runtime overhead. 
Sorry for plugging my own blog post, but this recent post is extremely relevant to this question: [http://eli.thegreenplace.net/2018/on-the-uses-and-misuses-of-panics-in-go/](http://eli.thegreenplace.net/2018/on-the-uses-and-misuses-of-panics-in-go/) Beyond other things, it covers why using panics makes sense sometimes.
Yep, the post mentions this exact quote! But it also shows how some places in the Go standard library actually go against this advice.
This takes 0.05s in my PC: var b strings.Builder for i := 0; i &lt; 100000; i++ { b.WriteString(fmt.Sprintf("(%d,%d),", i, i)) }
I actually read this in my research! What still remains somewhat unclear is when I would actually use it though. I understand it's supposed to be sparse, but the inconsistencies within the standard library do make it somewhat confusing.
btw, this would still work with just \[\]chan&lt;- int64 exactly the way you intend for it to work here
Think about the cases where you'd use `json.Unmarshal`. A typical example would be in a server which accepts json input from the public. Clearly in this case, you wouldn't want a malformed json query to kill your server. So it's a good design to have it return errors. Contrast this with `scanner.Split` - the design is such that `Split` must not be called after scanning has started. This is done for good reasons: changing the splitting function makes the scanner's meaning change. 
I’ve found that the best way to learn go is to read open source go code. I learned all of my kernel knowledge by writing and reading various parts of open source projects. Here’s one of my favorite network programming projects. https://github.com/vishvananda/netlink I must warn you, this is not simple socket programming project. This dives deep into the network stack. 
Oh, it seems I understand what you means. And I want to say that I completely agree with you :)
Yeah.I try it a lot in my day to day workflow as i needed.I think one of my weaknesses is that i haven't enough familiarity with Linux and it's network stack!
Nice! I like it. Thanks!
How to estimate the final size of a large string?
1.10
Yeah I prepared it already by string pre-processing
Domain knowledge
To answer the question of "why is it in the language", a key reason is to handle division by zero and slice index bounds. Those operations shouldn't fail, and if you're worried about them failing, you should use if statements to handle it correctly, but the program needs to do something when you ask for an invalid index. I would believe that the standard library isn't perfectly consistent, but the guidance around unrecoverable errors seems like a good place to start. 
Go does not have promises, for concurrency it has goroutines and channels. Here are two great resources for understanding concurreny in Go: https://www.golang-book.com/books/intro/10 http://www.golangbootcamp.com/book/concurrency Here is an example of sending a lot of requests that uses a technique called bounded parallelism, that is to say doing concurrent requests up to a limit, otherwise if you tried to send them all at once it might actually be slower than doing say 10 at a time. https://gist.github.com/montanaflynn/ea4b92ed640f790c4b9cee36046a5383 
Can I suggest https://github.com/mdlayher/netlink instead? * It's idomatic Go * It's a clean, well documented API * It supports *all* the features in netlink (try creating the equivalent of `ip route add default dev eth0`, throws a strange error) I've used the above library for a "smart" router in production, I am currently pulling it out due to the fact it does not support "device routes" (not sure what to call those routes). 
Maybe this would help: https://talks.golang.org/2012/concurrency.slide#50
&gt;Here is an example of sending a lot of requests that uses a technique called bounded parallelism, that is to say doing concurrent requests up to a limit, otherwise if you tried to send them all at once it might actually be slower than doing say 10 at a time. Yea I am thinking of the aspect of python multithreading where you have x threads running at once. Thank you for your help, it is much appreciated!
I will give it a shot thank you
var dict map\[string\]interface{} dict = JSON.Unmarshall(jsonvar) dict\[newkey\] = "asdfasdf" jsonvar = JSON.marshall(dict)
``` ~ $ python2 /tmp/test.py 0.275259971619 0.224035024643 ~ $ python3 /tmp/test.py 0.40205731700007163 0.24330045799979416 ~ $ cat /tmp/test.py repetition = 100000 def test_1(): a = "Hi there " for i in range(repetition): a += "(" + str(i) + "," + str(i) + ")," return a def test_2(): a = ["Hi there "] for i in range(repetition): s = str(i) a.extend(("(", s, ",", s ,"),")) return "".join(a) if __name__ == '__main__': import timeit print(timeit.timeit("test_1()", number=5, setup="from __main__ import test_1")) print(timeit.timeit("test_2()", number=5, setup="from __main__ import test_2")) ```
Is there a reason you need need it to be a Go program? `cat *.graphql &gt; schema.graphql` will work on a mac / linux OS. I googled ["golang gulp alternative"](https://www.google.com/search?q=golang+gulp+alternative) and [found this repo](https://github.com/go-godo/godo) if you really need a task runner instead of a simple concatenation command. Also just for fun here's a Go program that does the same as the `cat` command above, although it only supports a single argument pattern. https://gist.github.com/montanaflynn/4b573f09ce6e4e1989e9d22149cfb43a Use it like this: go run main.go "*.graphql" &gt; schema.graphql or mkdir output go build -o wildcat ./wildcat "*.graphql" &gt; output/schema.graphql
I encourage you to try to design a scanner where your description is a valid operation that returns an error. I put it to you that you may find it a bit more hairy than expected if you want to cover all the edge cases. The solution would also probably involve mutexes. The API would have to change too, I suspect. Now the users would be expected to anticipate bad behaviours occurring from possible changes to `SplitFunc`, and would have to continue. All in all, a lot of changes for not a lot of benefits. It might be better to consider that changing `SplitFunc` midflight is a irrecoverable behaviour. Here's a good guiding principle: design your software according to how most people would use it. Panic when any bad behaviour that is semantically nonsensical occurs. For other behaviours that can be guarded against and recovered from, return an error.
I personally feel like libraries should not panic similar to how I think they should not print or log anything. That should be left up to the main package. When I'm writing a program sometimes I want to panic so I can find the stack trace and other times I might handle the error differently.
Here's an improved python version btw. It's 0.07 second ``` a = "Hi there " for i in range(100000): a += f"({i},{i})," ``` 
It is not idiomatic to benchmark like this in Go. Please use the benchmarking facility provided by the standard library - https://golang.org/pkg/testing/#B. And then use `benchstat` to compare benchmarks. Use atleast count=5 to get consistent results. 
Also a book by jan newmarch http://tumregels.github.io/Network-Programming-with-Go/ Not sure if its up to date any more as hes published a paid book via apress https://www.apress.com/gp/book/9781484226919 used to be free 
individual http requests will be handled in parallel by default by spawning a new goroutine internally. If want to parallelize tasks in a single http request, you can try something like https://github.com/rafaeldias/async , or use the basic go constructs using channels as stated in other answers
Eventually your app should behind a firewall which job is doing this. 
I would say only when something is totally wrong - like a bug in your code, and not actionable by the caller. You may discover some \`switch\` case that just can't happen, etc.
Good point
I highly recommend becoming proficient in Linux commands and basic shell scripts. Many times they are going to be faster with less edge case bugs than writing a program from scratch!
I'm pretty proficient with linux. Just didn't think about it. 
[This article](https://go101.org/article/channel-use-cases.html) explains how to use channels as promises in detail.
I reserve it mainly for startup issues, developer issues, and absolutely catastrophic failures that are unable to be recovered from (though usually this is one of those other two situations). The most catastrophic of errors you can have are things that will panic built into the language (e.g. out of memory, some kind of hardware failure causing an issue in your software, so on). Past that, I try to just use errors as values and handle them appropriately, be it logging them or taking a different course of action because of the error, where possible.
You set a time but the context doesn't know about the time and with timeout you need duration of time. This is with deadline so it is with an exact time but you'll get the idea. https://play.golang.org/p/8Ti7eBAtIOX 
Yes. As others have pointed out, your application is soft-realtime (where the system degrades if you are late), not hard-realtime (where the system is useless if it's late by any amount.) Just saying "real-time" is ambiguous, so it always causes a lot of bickering. Ok, to your question: First, GC in Go gets better every release. We [hit sub-millisecond times](https://news.ycombinator.com/item?id=12821586) way back in 1.8. For audio, this is probably good enough, as long as you use a hardware buffer that is 1-2 milliseconds ahead. Doing the math, at 44KHz, you need a 1K buffer (at 8-bit samples, double that it 16 bit samples, and double again for stereo.) Second, you can influence the GC: You can tell it when to run, and you can write your program to NOT do any dynamic allocations in critical loops (so it won't generate lots of garbage for the GC to collect). For example, instead of using \`append()\` and allowing the language to randomly make copies of the array, you can pre-allocate the array bigger than you will need. Instead of constantly creating/deleting new objects, keep a pool of objects and re-use them yourself. (But only worry about this if your program has noticeable pauses.)
Kthxbye
Use `panic` when you encounter an error for which there is no good recovery strategy. Use `recover` when something panics, but you actually have a good recovery strategy. User `error` when you have a good recovery strategy.
The main goroutine pulls the ball from the table, dumps it out, then immediately puts it back on the channel. That loop is just going to keep running, and the "player" goroutines aren't going to get a chance to run and do something to change the ball. That is, just because the player routines are waiting on the channel, there's no guarantee they'll get a ball. Your tight for-loop in main is starving the player goroutines. If you want to ensure the player routines actually do something with the ball, you'll need a more elaborate mechanism to coordinate their activities.
&gt; No TLS? The H2C (HTTP/2 Cleartext) protocol is HTTP/2 with no TLS. The standard library will support it only from Go 1.12. But currently the external package x/net/http2/h2c can be used. That's not accurate. The standard library will never support h2c by default. 
Got it, thanks.
Btw you should cgeck again after RUnlock and Lock for existence of the key...
I can confirm this. Refactoring the line you could write something like `fmt.Sprintf("(%d,%[1]d)", i)` and the performance of it is identical. 
Gotta love the new f-strings :)
Neat, I also a small one for fun
I did change it to independent. You can still ask a mentor to look at it. I did get a response after a day or so.
[https://golang.org/src/net/http/jar.go](https://golang.org/src/net/http/jar.go) CookieJar interface has only one method for getting a cookies. So you do not have many options.
\`go run\` will include compile costs.
Thanks for the comment. I meant that the H2C handler will be available in the standard library. That's correct, right?
Until that issue gets merged (_if_ it gets merged) your options are: - reflection - `CookieJar.Cookies()` You almost certainly want the latter.
Thanks
I've done something similar: [https://github.com/tehcyx/gomarkov](https://github.com/tehcyx/gomarkov) and I've created a sample application for it as well: [https://github.com/tehcyx/twitter-bot-go-markov-chain](https://github.com/tehcyx/twitter-bot-go-markov-chain) I have to check out yours more in detail.
As I suspected, prepared statement is not improving your queries speeds that much over simple queries. The reason is that reusing statements is already build into the SQL framework when you do queries. Right now you have a 10% performance gain. If you use a realistic query, the performance gain can be even less. It also possible that no cache is just slow because you are calling the database twice instead of once. If I were to reuse statements, instead of locks and maps, I would just put each statement in its own global variable, and initialize them at startup or first use with `sync.Once` or a simple nil check. Also, database queries are already safe to use concurrently. If you are also writing, then you should use transactions, which "locks" the database instead of locking your program.
Great tool, i’m use the automator script for this. 
In short: You do not need new (jet) and make is used to make complex types like slices, maps and channels. (I'd recommend the Tour of Go, all of it). 
do the [tour](https://tour.golang.org), new is used for allocating memory, it has to be there for things like `new(int)` because you cannot use `&amp;int{}` 
You should read go specification, it 100% explained. https://golang.org/ref/spec https://golang.org/ref/spec#Allocation https://golang.org/ref/spec#Making_slices_maps_and_channels go isn't perfect but nobody can say its website isn't full of examples/explanations about everything, it's the only authoritative resource out there and it's well written.
Thanks 🙏
Arguably, `new` may make the intent clearer in some cases. For instance, to use the `sync.Pool` effectively, you need to store pointers in it; and so when you intend to create an instance of some type with the explicit intent to carry around pointer to it, it may be clearer to just use `new` to create such instances, like in the classic b := new(bytes.Buffer) // ... pool.Put(b) Of course, this implies the type has sensible (usable) zero-value, like `bytes.Buffer` does. 
meh, I purely use the composite literal declaration syntax since it lets me specify default values (or not) and I can stay consistent in this regard it bothers me more having to context-switch in my brain between `new(T)` and `&amp;T{}` (admittedly such a small, unimportant little thing, yet it is definitely a wart of the language) 
sorry, I do not understand the question.
Yeah, but automatic reusage of statements is not part of sql or sqlx as far as I can see. Yes, you can prepare a statement, and you should close it, but it is not internally reused if you do not do it yourself. Also I think it is the other way around, this is the most simple query and its parse has performance penalty of 10% per query. Just tried it with another query, stupid-version of an unoptimized join over two other tables, a group by, a join, a date comparison, order by some other column and an aggregation by the group by. Totally messy query, no question. Just to challenge the parser a bit: SELECT AVG(p.age), u.* FROM profiles p INNER JOIN share s ON p.id = s.profile_id INNER JOIN user u ON s.user_id = u.id WHERE u.created_at &lt; '2019-01-01' GROUP BY u.id ORDER BY u.id resulting in $ go test -bench=. -benchtime=10s BenchmarkMutex1-8 200000 106200 ns/op BenchmarkSyncMap1-8 200000 103665 ns/op BenchmarkNoCache1-8 30000 412331 ns/op BenchmarkQuery1-8 50000 287153 ns/op PASS ok 77.955s broken down to the postgres log entries about the different steps, looking at the first time the query hits and the nth time, some samples: mutex/syncmap: database_1 | 2018-08-13 10:51:03.948 UTC [187] LOG: duration: 0.475 ms parse // once database_1 | 2018-08-13 10:51:03.948 UTC [187] LOG: duration: 0.462 ms bind // first bind database_1 | 2018-08-13 10:51:03.949 UTC [187] LOG: duration: 0.056 ms // first fetching database_1 | 2018-08-13 10:51:03.949 UTC [187] LOG: duration: 0.031 ms // nth bind database_1 | 2018-08-13 10:51:03.949 UTC [187] LOG: duration: 0.035 ms // nth fetching nocache (new stmt, parse, bind, execute and close every query): database_1 | 2018-08-13 10:54:48.675 UTC [196] LOG: duration: 0.477 ms parse // first parse database_1 | 2018-08-13 10:54:48.676 UTC [196] LOG: duration: 0.447 ms bind // first bind database_1 | 2018-08-13 10:54:48.676 UTC [196] LOG: duration: 0.066 ms // first fetching database_1 | 2018-08-13 10:54:48.679 UTC [197] LOG: duration: 0.070 ms parse // nth parse database_1 | 2018-08-13 10:54:48.679 UTC [197] LOG: duration: 0.152 ms bind // nth bind database_1 | 2018-08-13 10:54:48.680 UTC [197] LOG: duration: 0.027 ms // nth fetching query (are logged as "statment"): database_1 | 2018-08-13 10:48:55.856 UTC [179] LOG: duration: 1.354 ms // first database_1 | 2018-08-13 10:48:55.860 UTC [179] LOG: duration: 0.274 ms // nth Thats a bit more "realworldy" and it does not any advanced stuff. From my understanding the more complex the query, the more work for the parser. Might be wrong, just tried it and never cared about statments before. But from the looks of it you should either reuse them or just skip them alltogether as the first bind is the most expensive (maybe creating the query plan there). But thats much more into DBA than I wanted to go, so lets skip it here. Nice idea with the sync.Once, totally forgot about that one. Yeah, on first use would be the way, as I do not want all statements prepared on a new connection, freezing it until its done. I agree, locking writes to transactions is important part. Thanks, nice hints!
Citing the author... "I haven’t found face recognition libraries for Go so writing one would be both fun and helpful for community." Definitely there are not too many, and all of them are based on third party dependencies, even the author's framework is heavily cluttered with C and C++ code. But [https://github.com/esimov/pigo](https://github.com/esimov/pigo) is not one of them (I'm the author). It's small, fast and has zero dependency tree.
Hey. That's a nice lib, but as far as I can see it only does face detection. I.e. it can't recognize the actual person on the image.
You can also put all your strings in a slice and use `strings.Join(slice, "")` to achieve the same result, more or less. Knowing the size of the slice, or at least giving it enough room to reduce reallocations, is better, obviously : slice := make([]string, 100000) for i := 0; i &lt; len(slice) { slice[i] = "(" + strconv.Itoa(i) + ")" } return strings.Join(slice, "")
Can you share your solution?
Not to hijack this thread, but Gocv is pretty cool. It's Go OpenCV bindings for most of the stuff you would want to do with it. Theres a couple face recognition examples in the repo. [https://gocv.io/](https://gocv.io/)
Yes, that's true, it cannot recognize the actual person.
Viper is great, but word of warning, the file watcher doesnt work on K8s configmap changes (known issue). You'll need to roll your own solution to watch for configmap changes and dynamically reload.
It is. You can go get it and see the docs on godoc.org/github.com/vdobler/ht/cookiejar
&gt; In this mode, SQLite can be safely used by multiple threads provided that no single database connection is used simultaneously in two or more threads. At least as far as Go is concerned. There is no meaningful concept of a "thread" in Go and goroutines don't map to operating threads meaningfully. So I'm not sure how this is intended to be interpreted. I'm having trouble coming up with a way to use this that isn't "use a single connection and guard its use by a `sync.Mutex`", which makes it effectively not goroutine safe. Maybe an example of how multiple connections can be used from Go would be helpful here.
It says "may" ? It is not guaranteed. 
According to the [spec](https://golang.org/ref/spec#Size_and_alignment_guarantees) (and as flatrecursion points out), this is undefined behavior. In which case it doesn't really matter why printing causes the change, no? It's undefined so really anything could happen. Something is happening in fmt.Println that requires slice a to be given a unique space in memory, whereas up until that point, slices a and b were 'fungible' as the article puts it.
My guess - passing &amp;a as an argument forces it to stop treating A as a vague undefined void and make it something concrete, because for all it knows, fmt.Println might do things to it, so it'd be bad if it passed in a generic pointer that may refer to other empty structs.
I think you're reading right and you need to use a mutex. This uses `-DSQLITE_THREADSAFE=2` whereas https://github.com/mattn/go-sqlite3 uses `-DSQLITE_THREADSAFE=1`, added [here](https://github.com/mattn/go-sqlite3/commit/acfa60124032040b9f5a9406f5a772ee16fe845e) as part of [this issue](https://github.com/mattn/go-sqlite3/issues/274). That issue is referenced in the `go-sqlite3` README when it says you can only use connections concurrently across goroutines for reading. Reading https://www.sqlite.org/threadsafe.html, presumably `-DSQLITE_THREADSAFE=2` is faster on the sqlite side than `-DSQLITE_THREADSAFE=1` with the tradeoff this library chooses that requires synchronizing both reads and writes on the Go side instead of what `go-sqlite` chooses which seems to be asking sqlite to synchronize reads/writes AND ask you to synchronize writes on the Go side.
I tried messing around with `unsafe.Pointer` and got the same results. It looks like attempting to read the value of the pointer alters the equality check. That's weird. https://play.golang.org/p/IUXSvBuIH5P
Try it with a dynamic quarry, where you are varying the where clause. 
Would love to read how this is different to https://github.com/crawshaw/sqlite.
These are the types of problems that `go-sqlite-lite` solves. You don't have tow worry about connection pooling. You have control over your SQLite connections and what state they're in. You don't have to use shared cache mode if you don't want to. All of the normal rules of SQLite database/table locking apply.
It's a funny story. As I was finishing up the `go-sqlite-lite` package, I read about his driver on HackerNews. I commented about how I was just finishing my own. He wanted my opinion on his SQLite driver and suggested that we collaborate. I found a bug in his driver and opened an issue and gave my opinion on other issues. I think his driver is great and I probably would have never started my project if I knew that his existed. The main difference is that his driver seems to be much more direct and a simple one-to-one mapping to sqlite functions. His driver supports the session extension and mine doesn't yet. My project currently has more convenience functions to make it nice to use.
In some ways I consider this to be outside the scope of the `go-sqlite-lite` package, although I understand that it's a common use case. The problem with `database/sql` is that a connection isn't really a connection and each individual SQL statements might be sent to any random connection in the pool. Since each connection has its own state, it can be hard to predict what will happen. I personally think that connection pooling is inappropriate for an embedded database like SQLite and I would recommend that you open a new connection for each request. Connections are light weight and do little more than open a file handle. You wouldn't pool file handles for an HTTP server, right? This ensures that each request is separate and they don't affect each other. If you compare this to the `mattn/go-sqlite` driver, the recommended way to use that driver is to set your maximum connection pool size to 1 and enable shared cache mode. You lose any advantages of connection pooling in that case as well. That being said, if you do want to implement a connection pool and your profiling has determined that there's a performance benefit, feel free to do so.
Where exactly in this spec is this defined as "undefined"? I was running through the examples in the cited website, and determined the behavior changed for an operation that should not affect anything by definition. The website author appears to be a "go expert", so I am doubting he thinks his claims are wrong, so this looks more like a compiler/runtime bug ?
It certainly looks like a bug in the runtime/compiler to me - or the source website should be changed to not makes the claims about "empty structs" since they don't appear to hold. Still, the equality comparison changing by reading a variable seems really broken.
&gt; I personally think that connection pooling is inappropriate for an embedded database like SQLite and I would recommend that you open a new connection for each request. Thanks :) I think it would likely be helpful to make that recommendation explicit (it's exactly what I've been looking for).
Can't you just use maven and the maven repo for the Go packages ?
Then still it uses username in their package.
My opinion... they are different enough that there will always be a place for both Python and Go. Pythonistas really like the syntax and the dynamic-ness of it, from what I understand. For me, I much prefer an executable binary with type-safety, no dependencies, and a no-nonsense feature set.
I'm happy to give a detailed explanation. I think this tool does have a niche' user base so it's hard sometimes to understand why it fills such a void if you aren't a target user. At the airport right now heading back from DEFCON, but will write it up when I get more than a few taps on the phone. In the meantime, you might find the slides from the talk helpful: [https://docs.google.com/presentation/d/1kHdz8DY0Zn44yn\_XrZ2RVqDY1lpADThLPNPwHP-njbc](https://docs.google.com/presentation/d/1kHdz8DY0Zn44yn_XrZ2RVqDY1lpADThLPNPwHP-njbc)
Last paragraph of the page I linked: &gt; Two distinct zero-size variables may have the same address in memory. The keyword here is *may*. They might, or they might not, therefore, undefined. If you look at the article too, right above the section titled "struct{} as a method receiver" the author says that this behavior is not *required* by the spec but is possible. &gt; Two distinct zero-size variables may have the same address in memory. You're right that Println theoretically shouldn't have affected anything, but remember the original behavior is undefined to begin with. At that point - no matter what you do afterwards - all bets are off as to the value of that comparison. 
I believe Project Athens is attempting to address these concerns. I'm sure they'd like your help. [https://medium.com/@arschles/project-athens-c80606497ce1](https://medium.com/@arschles/project-athens-c80606497ce1)
I believe the state is a) you are correct that currently the semantics are not well-defined, b) others have encountered that and it should happen at some point (that's why there's an issue about it) and c) until that point people tend to rely on some reasonable assumptions about the behavior. 
I totally agree 
Yeah, Got your point. Actually I am trying to figure that solution, as a developer doesn't need to rely on any repository hosting service e.g. GitHub as they are not CDN. So, currently I'm working on a project that might solve this whole issue across all gophers. Will release that soon. 😊
Can you clarify that a bit? When I use maven in Java projects (my real experience), I do not provide a username in my projects - the configuration of the maven repo is external to the project I am working on.
No sir, let's clarify we are on the same page. I am talking about the dependency's remote import path of Golang, not java. In Golang normally the package developer uses their vcs path as package import path, like for GitHub, as an example they uses `github.com/rousan/yourpkg` , so the dependant packages uses this vcs identifier and also the username, which could break the dependant codes if the package owner changes his username or tries to move code to another vcs.
OK, but couldn't the package import path always be relative to the local project (rather than a remote reference), and then maven pulls the packages from the remote repo (wherever) into the local ?
No sir, in Golang a package should not be used as relative path according to idiomatic Golang pattern, you should use full import path which might be remote import path or your own local import path.
The bigger issue is that GitHub is not append only. It is possible to delete projects altogether, with similar effects to leftpad.js (this _has_ happened in the Go community), and it is possible to delete tags, or even worse, to alter those tags to point to different revisions. All of this makes reproducibility without vendoring virtually impossible. Google is not some poor, indie company. They can easily afford to host an immutable Go registry, and they should. I've glanced at Project Athens before, and I got the impression that it wasn't going to host any code, it was just going to provide gopkg.in functionality of just redirecting one URL to another.
Don't worry sir, I am working one such solution which is different from project Athens by providing code hosting to separate completely development platform from deployment platform.
Yeah you got valid point, but in Golang package import path can't be relative to the root project.
&gt; All the dependant codes would break if you change your GitHub username. WTF 😑. I don't think this is true. Pretty sure github.com/codegangsta/cli was renamed to github.com/urfave/cli and I think everything was seamless. Maybe /u/codegangsta can weigh in (he hasn't posted in 3 years, so not holding my breath)?
That article was pretty terse; it sounds like Athens isn't worth without first-class support from the Go toolchain?
Also, Python's base string type doesn't handle Unicode, so it's not really a fair comparison to start with. Should be doing `a = u"Hi there "` etc.
I use [Mage](https://magefile.org/) to concatenate, minimize and compress resources.
What about if GitHub server goes down. Can't Golang have a registry like any others languages e.g. npmjs for js, rubygems for ruby?? Why should I use GitHub as CDN?
Bait + switch method, like NPM(a close source registry) and Node? Go toolchain should never be tied to a specific registry.
I've successfully used [github.com/russellhaering/gosaml2](http://github.com/russellhaering/gosaml2) to handle SAML 2 federated login in pure Go.
The JavaScript package count in npm is bigger than any other ones, and it was possible because of support of a commercial hand.
Hi, this looks really nice! is it possible to deploy a single stream on multiple nodes/machines somehow?
More info on Athens here https://talks.bjk.fyi/golanguk18.html#/
Maybe just a matter of running the same stream config on multiple machines? 
&gt; The JavaScript package count in npm is bigger than any other ones, and it was possible because of support of a commercial hand. bigger =/= better. I'll take maven quality packages over all that useless shit on NPM.
Is Java going to wrestle Fortran to the ground? Will Ruby overtake Perl in the last lap? Who will sponsor the C# stock car next year? What's PHP's odds of being in round 1 in the draft this fall? This is apples/oranges. And pointless. This is not a competition.
Hey, it depends on the protocols you are using. If you consume AMQP for example then you could deploy as many instances of Benthos as you want across as many machines as you'd like. Similarly, with Kafka you could use partitions to distribute messages across multiple consumers.
A Go rewrite will likely be the same performance as Java or slightly slower, since that's the state of Go performance right now. However, it will use a lot less RAM. So which direction to go should probably be evaluated based on where your scalability issues are.
I'm curious if it's just optimizing out the arrays altogether since they're only read from and never written to, resulting in default values being supplanted for the accesses, folded together since a write never occurs, and then having the now communal address taken. As you said, using the array itself forces the creation of the array, preventing the specific optimization passes from occurring for one of the items, resulting in two different addresses for the empty structs.
What's happening here is different optimizations. Most of this can be verified by a debugger Without the fmt.Println(&amp;a), the compiler know's that these variables aren't going to be used in function calls, so they can be allocated on the heap. If you stop your debugger you will see that \`&amp;a\[\*\]\` and \`&amp;b\[\*\]\` are some address on the heap of a zero value struct{}. When you add the fmt.Println(&amp;a), now a needs to be on the stack, that's how variables are passed in go, so it's preallocated somewhere near the PC. All of &amp;a\[\*\] address will still point to the same value, just one on the stack, and &amp;b\[\*\] addresses still point to the heap. If you add a fmt.Println(&amp;b) also, everything is true again. Is this a bug? I don't think so, as it tells you right in the spec that zero values of structs can be the same address, and you are prevented (except in unsafe) from accessing them. It does give weird behavior tho.
Not really. The registry is open source, and there will be many of them synced, so no central authority that "owns" the registry. The whole thing is being built on top of the vgo protocol https://medium.com/@arschles/project-athens-the-download-protocol-2b346926a818
&gt; The registry is open source where is the source code?
We are working to provide support sympathetic to the go tool chain. 
https://github.com/gomods/athens
I wish the people writing these kind of threads at least tried to make a substantial point.
I'm not advocating for the github-as-a-CDN model in general, but you'll be dependent on the reliability of whichever CDN you choose, whether it's a registry like NPM or Github. One of the advantages of Github vs NPM is that publishing your packages is much less work. The "working around a CDN outage" case seems slightly harder under the github model because you have to find clones for all of your dependencies and stand up a git server and figure out how to point your Go tooling to it instead of Github (maybe this is as easy as changing your /etc/hosts or something?) while the NPM model is just "point it at a mirror".
Wouldn't that be the other way around, if it not being used it can be on the stack? Why do a dynamic allocation to the heap if it is not used in any methods calls?
I should also add that it's not a registry, technically. An author will not add/remove modules, rather it will act as an immutable cache for module versions. This means after one user requests module@v2.0.12, that module@version will always be the same for subsequent requests.
&gt; e glanced at Project Athens before, and I got the impression that it wasn't going to host any code, it was just going to provide gopkg.in functionality of just redirecting one URL to another That’s wrong, take another look. There are two elements - the distributed caching layer, to hold immutable copies of modules, and a proxy, which can host private modules and white/blacklist package downloads from the main registry. 
the backing arrays should both point to `runtime.zerobase` since `struct{}` is a zero sized type.
The word "caching" implies that it's only intended to improve performance, not something to be relied upon, since caches can be freely cleared at any moment in time. The word "distributed" also doesn't make sense here. There needs to be a single, _central_ registry. If this caching layer is distributed, then it truly only exists to improve performance, not to improve reproducibility. I've looked at it before, and I haven't come away with any satisfactory answers. Project Athens seems like a nice thing to run at the edge of a corporate network to make "go modules" really fast, but it doesn't seem like something that seeks to solve the problem of not having a registry.
While caching may imply mutability, the immutable aspect negates that. Maybe cache is also the wrong word, perhaps module store would be more appropriate. Regardless of the current phrasing, the goal is to provide an immutable, globally distributed (read available, no single authority) module repository. I'm not the best at describing things so please feel free to stop by our channel in gophers slack to discuss further. #athens
Ditto. I just don't like having multiple ways to do exactly same thing. Many times when I come back to some code and can't choose and keep switching between them.
With systemsd, because it's much more powerful. 
I can vouch for that course, I took it as well as the instructors other go course. Check out greatercommons.com which is his platform, some of the courses are updated there. Also he's a great guy, of your having trouble affording the content reach out to him.
&gt;I peeked at the slides. No need to do a detailed write up for little-ole me. Just curious if embedding V8 is more practical than many of the other VM options, that's all. It wasn't easier for us (the developers) but it was the greatest common denominator for our users. Javascript is a language most security professionals have some familiarity with. This is in contrast to our own implementation or something like Lua, where people know what it is generally, they've very rarely ever written any code in it. This lets us keep the logic specific to runtime, flexible and forgiving for our less skilled SWE users, but still extending them the same power.
Another Athens core maintainer here. I'm super happy to see so much discussion about proxies and go modules. This is something that I've wanted for a few years. I'd like to take some time to clear up some points that are in here, and hopefully assuage some concerns that I've seen in here. ...and maybe convince some folks to join us on our journey to make dependencies better for the community :) # Blog Posts &amp; Project Status First, we publish weekly blog posts about Athens with project status and sometimes call out architecture details. Until last week, posts were under my [personal medium account](https://medium.com/@arschles) (and prefixed with `Project Athens:` in their title). Now, they're under [this publication](https://medium.com/project-athens) We're a big tent, so if you have something you'd like to contribute to that publication, message me (`arschles`) on `#athens` in the Gophers slack. # Registry? We've been using the term "registry" so far. It's all over docs, blog posts, and more. I'm super guilty of saying it tons. We're realizing that the term connotates something that we're not going for. ## Architecture We have in mind an architecture that: - Provides a centralized authentication system, code provenance, and discovery system for modules in VCSs - Is run by many companies, likely under a foundation - Allows proxies (i.e. the Athens proxy) to use it, _if they want_, to serve go modules that live on public VCSs We've talked about this architecture a lot in public, but we haven't written it down very well - especially the first part - because we haven't specified it yet. When we do, it will go into a standard Golang proposal. We have specified some the second two points in this unfortunately named article: [http://docs.gomods.io/design/registry/](http://docs.gomods.io/design/registry/). ## The Name _TL;DR We've discovered that "registry" doesn't describe what we're trying to do here. I personally think that "global proxy pool" better describes, but it's still an open question_ So that brings me back to the name. A registry is generally run by one entity, is one logical server that provides authentication (and provenance sometimes), and is pretty much the de-facto only source of dependencies. Sometimes it's run by a for-profit company. That's most definitely not what we in the Athens community are going for, and I personally think that would harm our community if we did. We think that a federated discovery/auth/provenance system is a great resource for folks building proxies, and although it's young, we think that the Athens proxy is growing into a good quality implementation. But it doesn't have to be the only one. We're purposefully building this project - and working with the toolchain folks - in a way that everyone who wants to write a proxy can participate. Even if they don't use the federated bits. So, if you look back to "architecture" above, there are a few discrete "things" involved in this system we're building. The term "proxy" describes what it's trying to do fairly well. But there are other things going on too. I personally think that "global proxy pool" covers everything in the global, federated system. # Go Toolchain Support Athens is currently supported by the Go 1.11beta3 toolchain via the download protocol linked to [here](https://www.reddit.com/r/golang/comments/9704se/the_missing_package_registry_for_golang/e44pgqg/) by /u/fedepaol. For the TL;DR of the protocol, it's a REST API that lets the `go` toolchain (i.e. `go get`) see lists of versions and fetch source code for a specific version. Athens is a server that implements the protocol. Both it, the protocol and the toolchain (as you almost certainly know) is open source. # Immutability &amp; CDNs _TL;DR Athens does store code in CDNs and has the option to store code in other persistent datastores_ The longer version: /u/coder543 is absolutely right that it's virtually impossible to ensure immutable builds when source code comes from Github. I've been annoyed by that problem for a long time, as have a few others that I know of. The Go modules download protocol is a great opportunity to solve it IMO. The Athens proxy works pretty simply at a high level: - `go get github.com/my/module@v1` happens - Athens looks in its datastore, it's missing - Athens downloads `github.com/my/module@v1` from Github (it uses `go get` on the backend too) - Athens stores the module in its datastore - Athens serves `github.com/my/module@v1` from its datastore forever To repeat, "datastore" means a CDN (we currently have support for Google Cloud Storage and Azure Blob Storage and AWS S3) or another datastore (we have support for MongoDB, disk and some others). And, sidenote - we don't have many concrete details on this aforementioned fondation/group, but I personally would like to see them pay for CDN hosting (and other hosting fees). I'm not the only one and we're working to make that happen. _One final note - we use "caching" in lots of our docs, and that's technically wrong because no data is evicted or expires. We'll need to [update that terminology](https://github.com/gomods/athens/issues/469). Thanks to all you fine folks this thread bringing that up, I created that issue, so thank you!_ # Vanity Module Names In our v1, we're not planning to support vanity module names. We are planning on it for sometime after v1, and there's nothing technically preventing vanity names&lt;sup&gt;1&lt;/sup&gt;. There was a gentleman (/u/rousanali ?) who is working on a tool to package up Go code and upload it to a CDN as a vanity module name. I believe this is an extremely elegant solution and when it's up I'd like to see it integrated into the federated auth/provenance system if possible. &lt;small&gt; &lt;sup&gt;1&lt;/sup&gt;If you want to build this, we could use the help. Come [get involved](https://github.com/gomods/athens)! &lt;/small&gt; # In The Open This part is kinda "touchy-feely" but I encourage you to read it, even if you're only interested in technical details and/or future plans for the project. I feel that the open-ness of this community is our most important asset. Our code is [open source](https://github.com/gomods/athens) but we the maintainers are constantly trying to go beyond that. If you come into `#athens` and want to get involved, we'll do everything we can to help you get started (we [cover lots of time zones](https://medium.com/project-athens/project-athens-an-international-community-b62305be5121) by the way, so please don't let that deter you) As with many open source projects, we have a [Code of Conduct](https://github.com/gomods/athens/blob/master/README.md#code-of-conduct) that helps us ensure that everyone is included, and enforce that where we need to. On top of that, we have a [philosophy document](https://github.com/gomods/athens/blob/master/PHILOSOPHY.md) that we use to set the tone for new contributors. _The TL;DR of that document is: make it easy to get started, and fun to participate._ The least open part of our community is that we don't have good docs right now. If you come into our project and want to try it out, it's hard. All the contributors are trying to improve our docs, but we need help. If you can help, please let us know in a [GH issue](https://github.com/gomods/athens/issues) (say something like "what docs can I write?" in the title) or in the `#athens` channel in the Gophers slack. I said this in the TL;DR above, but can't stress it enough. My _number one_ goal in this project is to enable anyone who wants to contribute, to contribute in a nice and supportive environment. Great docs and developer UX are nothing unless anybody can come and work with us in a pleasant environment. # That's It I wrote a wall of text in here for three major reasons: - To help folks understand what's going on with the project - To help assuage concerns that some folks might have that we're out for world domination - To invite folks into the Athens community I want repeat that last point. If you want to join us, here are some ways you can: - Come to the `#athens` channel in the Gophers slack and say hi. New contributors are always welcome, and as I said above we'll do our absolute best to help you get started - Join us for one of our [dev meetings](https://docs.google.com/document/d/1xpvgmR1Fq4iy1j975Tb4H_XjeXUQUOAvn0FximUzvIk/edit#heading=h.j77t62eely05) - File an [issue](https://github.com/gomods/athens/issues) if you see something wrong - [Contribute some code, docs, etc...](https://github.com/gomods/athens/blob/master/CONTRIBUTING.md) 
[removed]
[removed]
[removed]
[removed]
That's seems highly error prone... That was the reason C/C++ were so bad for so long - not a proper defined memory model - which is something that Java fixed. This is very important for highly concurrent systems. Doing some further reading, it seems that many have identified this issue, and the language creators would of rather removed the low level sync primitives and just used 'locks &amp; mutexes', but the cat is out of the bag, and now they are attempting to rectify the problem. So I would expect this to be resolved (rather soon?)
Well done!
I was at the GoSF talk. At some point Sam needs to realize his sad crusade isn't going anywhere and he needs to get on with his life.
Thanks for the great overview. The main comment I have is regarding this: &gt; TL;DR Athens does store code in CDNs and has the option to store code in other persistent datastores &gt; I've been annoyed by that problem for a long time, as have a few others that I know of. The Go modules download protocol is a great opportunity to solve it IMO. I agree that it is a great opportunity to solve it. However, if each organization runs their own Athens server, company A can't necessarily share code with company B, since company B's Athens Athens proxy may not have some of the same exact {package, version, hash} objects. If the plan is to have a few public Athens servers, why not just have a single centralized Athens server and make it a registry? People could still run Athens behind their own firewall to cache private packages and whatnot, but having multiple public servers that a developer has to pick from is just an additional choice that the developer probably doesn't care about. It's like the old Sourceforge days. You could download the software from any of a hundred different mirrors, and most users just didn't care which one as long as it was fast... unfortunately, you often had to try a few mirrors to find one that worked well. Since the word federated has been thrown around, I assume these servers will have some way to share packages with each other, but how would that work? If two different packages with the same import path are pulled through two different Athens proxies at about the same time, how can the federated network decide which one is the _right_ package?
[removed]
https://github.com/golang/go/issues/5045#issuecomment-412714313
Was this handled well by either side? No. Have the go “powers that be” decided on a different direction? Yes. Is this debate helping the community at this point? No. Will I ever hit the edge cases described? No idea. But if I do I suppose I could still use Dep right? I am genuinely not sure. Did go break anything in Dep? 
Immutable append-only stores will cease being such shortly after the DMCA/GDPR requests start rolling in.
But I am probably misreading the “amongst atomics” phrase, and what they mean is sequential consistency when using atomics. Still if the is the current behavior across all implementations I’m not sure why they just don’t update the docs to state it as a requirement. 
I’m quite sure dep still works fine. The workflow of working with other maintainers might be tougher though. 
I don't think so either, but at this point it just looks increasingly like it with each post. I think there may be a time to step back and save an "I told you so" for later rather than pulling a Cassandra. 
I've not noticed anything connecting to localhost _outside_ of Docker, so maybe it's a Docker issue.
I agree wholeheartedly 👍👍👍👍👍👍👍👍👍👍👍👍👍👍👍
To be more specific, python3 strings are Unicode, python2 strings aren't
take a look at nomad
&gt; Does Golang need a consistent package registry by which your package remote import path doesn't depend on GitHub or Bitbucket or your username? No, it doesn't.
Can you explain it please
`("^[A-Za-z_\\-\\$]+$", username)` You need to escape the '-' Check out [https://regex101.com/r/BQe3uQ/1](https://regex101.com/r/BQe3uQ/1)
Thanks /u/englio! I totally missed that. I've been making a mistake with "-" for years. It should have occurred to me since A-Z, a-z, 0-9... etc. Kinda weird that it seemed to work in tests, but I guess there's some interaction with $ being there.
Hint: search [the doc](https://godoc.org/net/http) for the word cookie.
this. i love using python for scripting and system tests (patching stuff together from strings etc. is great to create test data) but for “proper” applications compilation eliminates so many issues
Very nice tool. I tried it today. I used the file as the input, it automatically exit after finishing reading the file. Is there a way to waiting for new messages injected to the file, Just as the log file?
Oh no, again..
Hey, you can read from stdin the same way, so if you do 'tail -f ./file.txt | benthos' that should do what you need.
&gt; That's seems highly error prone... Yes. But also pragmatic. The choices at this point are pretty much "don't use atomics" or "make some reasonable assumptions on how they work and hope". It's not contentious that there *should* be a definition, it's just not clear what that definition should be, so currently there isn't one. It's regrettable, but it's where we're at. :)
Interesting. Gofer is also a Haskell-like programming language :P
The kafka_balanced input automatically balances partitions across a consumer group. The load depends on your set up, a simple bridge could chomp through hundreds of thousands of messages per second, doing CPU heavy stuff like compression or JSON manipulation is probably going to be a few tens of thousands on a dev machine. I go into some more detail about getting max performance from a pipeline in this video: https://youtu.be/QLRywTqrAoU There's also documentation in the repo that outlines best practices, etc: https://github.com/Jeffail/benthos/blob/master/docs/concepts.md
It will be much easier if you use back quote: https://play.golang.org/p/6JTpVq9f-0I
Ask yourself: What fundamental problem does a registry solve. Answer none. A registry by itself does not prevent packages from vanishing and does not prevent packages from changing in unwanted ways. All it does is mapping a "fixed" name to a "volatile" name. No registry alone prevents leftpad style package vanishing. It just allows a simpler, more local fix: Redirecting the fixed name for leftpad to a new, other copy of leftpad. As all this is unacceptable for professional work you vendor all your leftpads. Now "vendoring" sounds bad so you call this a caching proxy and set up your own Archiva or Nexus which you backup. Basically you vendor all your dependencies of ever used inside your organisation. 
* I'm not *entirely* convinced that MVS fundamentally can't avoid picking incompatible combinations (around 12:55). For example, a very easy way to prevent that, is to remove any version of a module that is declared as incompatible with any other involved module from the graph entirely. Then MVS couldn't pick it. What *is* true, is that MVS fundamentally isn't complete in the presence of these constraints - it will have to have false-negatives. i.e. no matter what you do, it will sometimes not find an existing solution. That's fundamental to avoiding the NP-complete problem. While it's a bit of a nit-pick, there is a decently large design space between these two ways of introducing incompatibilities to MVS: a) Do MVS with the complete graph and fail if you pick an incompatible version or b) Remove any potentially incompatible version from the graph and run MVS. Other points in the design space are things like "if you pick an incompatible combination, remove the offending versions from the graph and re-run MVS. After a constant number of tries, give up" (which would still be linear) or "if vY &gt; vX exists, treat an incompatibility on vX as a ≥vY constraint, otherwise remove vX from the graph". These are just simple, linear-time alternatives off the top of my head. Any of these will create different false-negatives for different edge-cases and knowing what kind of problems we actually encounter in practice is paramount in deciding where in the design space you'd want to land. i.e. it can ultimately be decided based on experience. * (Around 14:30): A thing that isn't really clear to me, is how lock-files are working for libraries. I again see a possibility of a false equivalency here. Sam's argument is: "A wrote the following intent of compatibility (`A/Gopkg.toml`). Dep persisted it's version selection into `A/Gopkg.lock`. If we translate `A/Gopkg.lock` into a module intent-file, we get an `A/go.mod` that breaks `D`". But… Why would you translate `A/Gopkg.lock`? ISTM, that in dep-world, you wouldn't use `A/Gopkg.lock` to select versions used to build `D`, so why would you assume you have to use that as a basis in module-world? ISTM that `A/go.mod` should just contain the *intent* of the author of `A` (which is `&gt;= v1.0.0`) and then no information gets lost. You can make the argument that a `go get -u` will update `A/go.mod` to `&gt;= v.1.0.2` anyway and most people will use that (and he does that around 21:30) - but again, the equivalent to that is to update `A/Gopkg.toml`, *not* `A/Gopkg.lock`, so the same information loss happens in dep-world. The example provided at bit.ly/information-loss-strikes is a good example of that. If module B's `Gopkg.toml` file was initialized at the same point as its `go.mod` file (say, by using only the import declarations or some goimports-like tool), it would *also* have been initialized with the newer version of vault and experience the same kind of breakage. * (Around 17:00): "These [replace statements] are actually cheating and don't resolve any structural problem, so we're not gonna talk about these" - I'm sorry, but why? On the surface, this seems to be solving all the problems Sam is bringing up - at the very least in the most common of the already edge-cases that require them in the first place. I'm willing to consider that there are problems with it that are harder to see, but if there are, you definitely have to talk about them. And "as a rule, roll-backs really aren't something we want to do"? We learned very different rules, because "roll-back is the safe default-action" is literally the first rule I learned as an SRE. So much so, that in a lot of cases we just have automation that will roll back without human intervention if there's a problem detected. Rolling back provides exactly what Sam is claiming to want: A quick fix to buy enough time to consider a proper fix to the problem. I'm baffled by this part of the screen cast, as it seems to directly contradict what he's been basing his arguments on [previously](https://sdboyer.io/vgo/failure-modes/); that it's about providing unilateral options to D to stop the bleeding and repair the build, when you don't have time to properly fix the problem right now. He is categorically excluding exactly those actions and I don't understand why. And again, the example he is providing for how bad information loss is, actually got solved by a replace directive, so it seems to illustrate that it's a perfectly fine solution - and I don't understand how he could, knowing about that thread, still just not talk about it. * It might be a nit, but I think his summary of the arguments in favor of Go modules is misrepresenting. So much so, that I (as one of the vocal proponents of modules) first thought "I've never heard anyone ever say anything like that" (except 3). I don't think anyone ever claimed that modules would *solve* dependency hell. It helps, but even there, I don't think the primary mechanism by which it helps is by eliminating SAT (but instead by preventing bitrot). IMO that's important, because of course "it doesn't solve dependency hell because dependency hell isn't caused by SAT" is of course an easy argument to make - I even agree with that. OTOH, if the actual argument splits twofold, that a) it avoids SAT, which provides a better UX and b) it discourages bitrot, it becomes much harder to refute. And actually exposes that this is a difference in opninion about how important those goals are, instead of an absurd assertion by proponents of modules. * Around 30:00 he compares the problem to code formatting, saying gofmt works well because it has well-defined inputs and outputs and making an opinionated choice is correct in that case. I find that ironic, given how many *hard* problems code formatting has that gofmt is currently ignoring or solving poorly (just look at the [open gofmt issues](https://github.com/golang/go/issues?utf8=%E2%9C%93&amp;q=gofmt+is%3Aopen)). I'd argue that gofmt is in exactly the same class of problems, where the input is fuzzy and the intent of the programmer is hard to gauge automatically. But it still is widely accepted, that even an imperfect, simple solution to this problem, like gofmt, is still preferable. * In his "Forward" proposal, he says he wants a go.modlock file, but he still doesn't explain how it is supposed to be taken into account. I'd argue, that it's entirely possible to get what I *assume* is the intended effect, without any changes to the toolchain. Because presumably, lock-files of dependencies will be ignored in the build anyway. So for binaries, you can just run MVS with the existing go.mod file and output the result into a new go.mod file. This is functionally a lock-file as intended; all the dependencies still contain only the expressed intent of compatibility, but the root module declaration provides a specific choice (and MVS guarantees that it is unambiguous, even if it technically provides lower bounds). Library authors can't do this, but their lock files would be ignored anyway. They just stay with an intent-tbased `go.mod`, that contains the actual minimums they want to express. The actual output of MVS only matters for libraries, if they want to run tests against newer modules than they actually require (presumably, that's the only case that go.modlock files would be used in non-binary packages too). --- Overall, this talk helped me understand the argument of information loss Sam is making better than his previous blog post - and I'm thankful that he made the effort to record it. But the only thing that understanding is doing, is convince me even more that it's not as dire of a problem as he claims. On a meta-level… I'm a bit tired of these arguments. Sam is painting a catastrophic picture here, but even with *his worst case projections* and if I am taking his arguments at face-value, I'd still claim that there is no catastrophe here. We are spending unbelievable amounts of time on this argument that is just not commensurate with its importance. But the air of confidence and fatalist tone Sam (and others) are speaking in makes it impossible to ignore this. I feel, to a degree, forced into spending more time on this argument than I would like, to write up all the detailed explanations of why I don't think things are as bad as they are painted, to rein in the rift in the community this argument is creating. TBH, at this point I empathize with the dep team and I understand why they feel ignored and are convinced that dep is a better solution. But I'd still wish the projections of an apocalypse would stop and we could at least agree, that the problems with modules can be fixed *as they arise* and based on actual *experience* with the approach, instead of speculations. There simply is no need to panic here.
Isn't the best time to do this now when modules will become an experimental feature in a released go version very soon? 
Do you plan to add the encryption extension or know how it can be enabled?
go it, thanks!
To be perfectly blunt, the best time to do this was &gt;1½ years ago, when the issues where first brought to the attention of the dep maintainers. It would have saved the community as a whole quite a lot of grief. Another decent time to do this would be in a year or so, when we have got some experience with the approach chosen and the issues predicted have actually manifested (or not). *Now* is IMO literally the worst time to do it.
It's the best time to write simples obvious issues on github to go forward. Like we did when we experimented on Dep, when the Dep and Go team convinced us to focus on one experiment at a time.
Well, it's also the best time now since a bunch of new people will probably be introduced to go modules with the new release. Like me, I have only read about it but haven't tried vgo yet so this is potentially very good timing to get additional updated information about potential issues,.
If I could, I'd recommend Sam to just back off and sit on his hands for a while: - If the modules and MVS will turn to be a brain-dead idea, people will naturally use _the other solution,_ which is `dep`. - If the future will prove otherwise, then it will merely mean Sam was wrong and Russ was correct in their prediction of what will work and what won't. 
Anyone have a changes list from beta3? I know GoLand broke affter beta2
If I (as root) create a file in /tmp, it (by default) has the permissions rw/r/r. Then I change to an unprivileged user, and I can read the file without any issue. I can also overwrite the file without issue from the unprivileged user and make it contain anything I want.
Nice, this seems to have fixed the issue I was having with downloading dependencies with vanity URLs. I still feel like `go mod graph` is not all that useful in a non-Go-modules-world. I expected it to work with dep for while...
If you are interested in resources that are suitable to consumers of the Go tooling, I suggest [the wiki](https://github.com/golang/go/wiki/Modules). It will give you information about common pitfalls and issues you might encounter, with a specific focus on helping you solve them. The issues mentioned in this talk in particular, are addressed in [this section](https://github.com/golang/go/wiki/Modules#how-to-upgrade-and-downgrade-dependencies) (including solutions). The talk is IMO a very bad resource to learn about pitfalls, as it's intention is to sway public opinion about the viability of modules, not to teach people how to use them. It's not a resource to warn beta-users about issues they might face, but a resource for arguments not to move forward with modules (for people who, like me, are participating in the discussion from the sidelines). So while, yes, now is a perfect time to provide learning material about how to learn about Go modules and potential pitfalls with them (even from a perspective of hating them), this is not that. This is a discussion piece about whether to use them at all, for which it's a very bad time.
Then something may be wrong with your system... $ cd /tmp $ sudo touch hello $ ll hello -rw-r--r-- 1 root root 0 Aug 14 12:55 hello $ echo "world" &gt; hello An error occurred while redirecting file 'hello' open: Permission denied That's with fish, with bash it outputs something like this for me: $ echo "world" &gt; hello bash: hello: Permission denied 
All releases are tagged in github. You just have to go to github and compare the tags.
Alright I found it https://github.com/golang/go/compare/go1.11beta3...go1.11rc1 couldn't see this on the github tags list though
you can set the umask, that can be used to limit access to `-rw------` for all files that are created by a process. (look at syscall.Umask) Also, these processes are designed to be run in a secure environment. If anyone has access to your `/tmp` then you have bigger problems than that. 
There is a [bug](https://github.com/golang/go/issues/20253) open for this. Files are cleaned up in finishRequest by the server, but I think if you use a context on the request the request is copied, and the original request form is cleaned up, not the one which parses the form and owns the tmp files, so you end up with resources on disk which are never cleaned up. At present as a workaround call r.Form.RemoveAll() after parsing, but the bug will probably be fixed eventually so that you don't have to do this. 
Bigger problems yes, but you're still breaking best practice of minimum access. You can't assume all hostile actors come from outside the company without permissions.
The hashicorp product?
Whatever happens, I do hope Ruby dies.
Not really related, but the older I get, the more I believe that there is no need for anything between Bash for scripting and compiled languages for systems. We use Ruby for a lot of system tests and any gains made in development speed by a scripting language are quickly lost in the huge maintenance burden that comes with dynamic typing and non-standard development practices (that seem especially popular in Ruby). At the end of the day with rubocop, gems, gemfiles, gemspecs, and all that, you are compiling your code without the benefit of using a compiled language. But this is a Go board, not sure why in ranting about Ruby
I watched the last section again and thought about it some more. And I understand the purpose of the proposed `go.modlock` file even less. What is preventing a community tool to just put its choices into a `replace` directive into the main `go.mod`? AIUI that is functionally equivalent to `go.modlock` and works without any changes to the go toolchain. I see literally no difference, except that in one case the list is kept in a dedicated file, while in the other case it's a dedicated section in an existing file. 
I feel dumb. I thought I tested this, but apparently I was still root when I overwrote the file.
Neat utility for converting structs. Reading the documentation, it seems unclear to me though, if repacked supports the use-case where you don't control either source or destination. Forinstance, if you are using a third-party library and want to convert that into your own datatype (or the other way). Can the repack tag help you there?
The purpose of the lockfile is to enable using different algorithms to solve to the constants. SAT based solvers need them because SAT solutions are unstable and time consuming (because the consider more options). If a lock file was introduced he could modify dep to output to that format.
You did in no way address the actual questions: Why does this need a separate file, instead of just using `replace` directives?
Well, if you are compromised from the inside you're fucked. It all boils down to some level of trust, usually in your administrator of that given service.
&gt; [syscall/js: extend ValueOf to support arrays and objects](https://github.com/golang/go/commit/a9dcbab0fd4b5adfb40cb924f14ee2af9c8938eb) Oh nice. I guess that means that I can remove [the little function I'm using to do that with `map[string]interface{}`s manually right now](https://github.com/DeedleFake/wdte/blob/697fa587649f01420993e550a6845352474fb572/go/wdte.go#L36). Ironic tonight, perhaps, though; I just wrote all of that WASM code yesterday.
Very interesting, I have built r/https://newreleases.io, first for my own needs, as other similar services was not so reliable for me. But it is nice to see that regex filtering is a feature needed for others, too. 
I agree, he spits out some concerns, which I admit, could be a problem, but only time will tell how catastrophic. Then just casually says the solution (err, compromise) is "us go.modlock" and possibly add the SAT solver, but make it optional. Essentially "merge in dep" with minor modifications. I think we should try the module system as a community for a while, rather than deciding it's no good right from the start.
He’s admitted communications with Russ Cox have broken down, and that even his “compromise” proposal still involves a NP-complete SAT-solver. His idea of launching a petition is quixotic at best, he is clearly extremely emotional about the topic, and he has a second child on the way. He seems like a nice guy, passionate too, but I worry he is headed for a nervous breakdown at this rate.
Previously submitted: https://www.reddit.com/r/golang/comments/972p5d/sam_boyer_we_need_to_talk_about_go_modules/
a. It would legitimize the approach. b. This is about politics, this is not a technical issue. You are technically correct (the best kind of correct). Using the replace directive can fully specify versions for the current package. I'm not suggesting using replace directives in this way nor am I advocating for a modlock file. 
Let's imagine I am a sysadmin, and you are Cowboy Jack, running a program you wrote, on my machine. Turns out your program is written as if a cowboy did it, though. It leaks resources such as files and memory, and eventually requires manual intervention. Should I, as a sysadmin, have to add "delete Cowboy Jack's old files from `/tmp`" to my list of things to do? Or should you clean up after yourself?
I agree with you, but I also don't `chmod 0777` every file I come across. There's nothing wrong with being sensible with file permissions.
The package image has a method SubImage for the various image types: https://golang.org/pkg/image/#RGBA.SubImage This would give you the part of the frame you want to blur. The package draw has a method Draw: https://golang.org/pkg/image/draw/#Draw This allow you to copy the "blurred" image back on top of the original. 
Hey, I'm sharing with you something that I created a few weeks ago. It's actually a pretty simple package but it saves me some copy-paste code. The main reason for open sourcing this package, is to share with those who are unfamiliar with this error-handling pattern. I would recommend reading the [motivation](https://github.com/a8m/errors#motivation) section to get some context about it. 
&gt; All the dependant codes would break if you change your GitHub username. There is an already existing solution for this which is admittedly not very well documented: [https://texlution.com/post/golang-canonical-import-paths/](https://texlution.com/post/golang-canonical-import-paths/)
The idea is interesting, one immediate gripe though is that the `errors` package name conflicts with both stdlib's `errors` as well as `github.com/pkg/errors`. Personally, I think this could make for some awkward code, where people will have to import alias either your package or one of the other ones.
Wow, this is timely, you just caught a bug in one of my microservices.
 I think [https://github.com/xormplus/xorm](https://github.com/xormplus/xorm) gives the perfect balance between being simple and being convenient 
Hi, There is a SliceStable in the sort-package then for loops are a pretty easy way to sum it all up by category and write a neat csv file for it.
 I think [https://github.com/xormplus/xorm](https://github.com/xormplus/xorm) gives the perfect balance between being simple and being convenient 
I second this!
- DynamodDB usage examples (especially with complex conditions) and dynamodb streams - Event-sourcing with sqs and dynamodb (or anything else) - Neptune
I really like your suggestion. Thanks for the post. :)
I haven't seen this before. It looks like that it requires code changes to sqlite that you have to pay for. Since the sqlite C code is compiled by my package with CGo, I'm not sure how I would support this. It does however look like the encryption extension can be used with only PRAGMA statements. So if someone had a sqlite.c amalgamation with the encryption extension, they could just fork my code, drop in their new sqlite.c that includes the encryption extension, and then just use the PRAGMA statements to interact with the encryption extension.
Yeah, and thats fine and definitely understandable. I'm sure it'll all be fine once Go modules are the norm. This transition period might just be a little odd.
Some pain points we've encountered that I'm sure other people would find useful: * Authentication/[CredChain](https://docs.aws.amazon.com/sdk-for-go/api/aws/defaults/#CredChain) * Pagination * Good testing practices * How/when to use custom [RequestHandlers](https://github.com/aws/aws-sdk-go/blob/master/aws/request/handlers.go) * Dealing with aws types and their conversions, e.g. using `strptr := aws.String("foo")` and `aws.StringValue(strptr)`
&gt;if each organization runs their own Athens server, company A can't necessarily share code with company B, since company B's Athens proxy may not have some of the same exact {package, version, hash} objects. good point. at the moment, we're thinking that the group of folks hosting CDNs will all collaborate on a stable endpoint that will likely load balance to the specific hosts (i.e. with round-robin DNS). So there will be organizational federation (i.e. not owned by anyone) but we want to abstract it away from developers. Of course, folks can still point to a specific organization's proxy server if they want, or host their own public instance. I expect that many will. There's some technical details on how the synchronization between instances will coordinate [here](http://docs.gomods.io/design/registry/), but there are some kinks to work out. Personally I actually would like to see a lot of mirrors like the old sourceforge days because that would indicate a healthy ecosystem to me. It's just that I would prefer to have a stable endpoint that I can fall back on if a mirror goes down, a provenance check fails, or some other unforeseen reason. And finally, I'm glad you're hopeful! Would you want to start testing the proxy out? I'm happy to get you started.
Too bad about needing to drop full color - I thought that was super cool. Would gladly pay extra for it. Will probably pick up this book anyway though.
Thanks for the tip. Hopefully this gets a better fix, or the documentation if more explicit about the need to run `form.RemoveAll()`
I would recommend taking a look at this presentation: https://talks.godoc.org/github.com/sbinet/talks/2018/2018-04-03-go-hep-jlab/talk.slide#1
Dynamo conditions were annoying when I first started using them, so I can definitely see how walking through some examples would be helpful. I only started playing around with Neptune and more comfortable with RDS/Dynamo, so I will hold off on that service for now. Thanks for the suggestions!
well, thanks for the mention :) but I am not sure Go-HEP libraries are really targeted at HPC workload... if by HPC we mean workloads that run high end HPC machines like, say, NERSC's Cori. I would probably look at what Brendan's been doing with, e.g., a pure-Go implementation of MPI: - https://github.com/btracey/mpi that said, Go's compilation model is a great fit (IMHO) for HPC deployment model (static binaries) but I would also say it's lacking a bit of mindshare...
Nice, Thanks for the article. I am trying to learn golang using these applied approach on k8s. 
I've said it before and I'll say it again: this is one of the best programming books in general I've ever read, and it belongs on every developer's bookshelf. 
I'm glad you found it useful!
If you want to live in relative poverty in Mountain View, CA
Op, is the job in Mountain View? 
For some software engineering roles yes. For others, provided there is a strong match, I can be flexible on location. 😀 But all involve go. 
The price difference for simply getting a little more syntax highlighting is huge. I wouldn't be surprised if he barely made any money on the previous book. I'm certainly excited for this one. The previous book was my favorite computer science book I ever read.
Thax Douglas ? Is that you? https://youtu.be/JyHh35y4WDQ 
This, I've come to terms with the fact that these jobs just aren't practical (in comparison) when they are tied to anywhere around SV. I'm sure it's worth it to some, and if I wasnt tied down I'd be more inclined myself but certainly isn't feasible for even a couple.
Lmfao; love it, but sadly no :-(
Thanks for sharing repo. I'm also new to Golang. Wondering how did you create makefile and vendor.json Since I'm coming from nodejs world. Where package.json gets created by node and used by npm. 
The makefile borrows from other go projects (see the ones I listed in the README). The vendor.json comes from [govendor](https://github.com/kardianos/govendor) but there are other [options](https://github.com/golang/go/wiki/PackageManagementTools). Good luck! 
Which book are you referring to? The interpreters book?
Yah. He just re-released the interpreter book in B&amp;W as well. 
[removed]
Thanks for the response!
Thank you!
that's interesting, thanks for sharing.
\&gt; And as my Computer Science professor said, if you're repeating code, you're doing it wrong! This advice should never be taken to an absolute extreme. Little copying is ok, where it makes sense (but "makes sense" should be trained through year of practice, I agree). Anyway, JS Leftpad case is a good example of the perils of "extreme DRY" approach.
I personally don't like the look of that `collect` statement at all. I can't see why people have such a big issue with `err != nil` tbh. 
Fully agreed, the explicit error checking is a feature in my opinion. Not bothered at all by "too much" \`if err != nil\`, if anything it makes me think about error code flow better.
Personally, I like the error handling pattern. I have stared into the gaping maw of nested catch (any) and I never want to go back there. Things I want to see in Go to make it a top contender: - Deprecate GOPATH - Generics - True inheritance (we can deal with a few deadly diamonds) - All the features of logrus in the base logging package - Test output to xunit format from the native go binary (no go2xunit piping madness) I know some of these are harder said than done, and the generics/inheritance ones change some fundamental assumptions of the language. But I think if these things were done, then it really would be a java/c++/ruby killer.
Make the pool size configurable from outside the application (env var maybe) and benchmark different sizes under load in the container.
Well, no, the issue there wasn't that DRY was taken to an extreme. In Go, we have fmt and we can easily do leftpad. This is a shortcoming of the standard library.
Isn’t there already a pattern for catching (collecting) panics? I don’t like the collect proposal at all. Fan of the literal interface proposal. The choice of sort.Interface is a bad example because it’s terribly named and i was a little confused at first. Proposal: rename sort.Interface to sort.Sorterer Also fine with renaming other things or aliasing them no big deal. 
I'd like to add enum types to your list
Base classes are very useful for sharing common patterns throughout a codebase. Not having this tool is the single biggest stumbling block I had when coming from traditional OO languages, and others have told me the same thing. The go version of inheritance is more like embedding a class inside another class as a property. But it still maintains its own namespace, etc. I guess it's nice when combined with interfaces, but I ultimately haven't found much use for it beyond being able to jam things through an interface by matching the signature. Which is only necessary because there are no real generics. I'll be the first to admit that I haven't mastered Go yet. But if I'm having these issues, then others are as well.
I would like to see some more examples of webassembly and maybe a go-vue library. 
&gt; I can't see why people have such a big issue with err != nil tbh. It's a pain to type (or copy paste) all over the place. 
Thanks for looking into that one. Yeah, I just noticed that it’s a paid option. I generally wanted to ask if you plan to add any full database encryption option as that’s usually the missing feature of every Go SQLite wrapper.
Is remote an option :)
If like to see some sugar added but at api boundaries I'm mostly using github.com/pkg/errors to add a stack trace, and a description of what caused the error for better diagnostics. The example the author gave strips all of that away, not a fan.
Found the official comment confirming your experience: https://golang.org/doc/faq#inheritance “It takes some getting used to but this implicit style of type dependency is one of the most productive things about Go.”
For, it will be great to improve `range` in order to avoid race. 
err.nn
Two questions for you here.. 1) Is writing p.Assert..(...) such an improvement over if &lt;statement&gt; { .. }? Either your p.Assert..(..) is going to be bloated with a large statement or error message, making it hard to read, or it's going to contain a very short statement that can easily be replaced by an if-statement without making things hard to read. I'm not convinced that it will provide such a dramatic improvement in readability. My main concern is that an if-statement has clear purpose, while a "hidden" statement like your parser does not. 2) Having your default handler panic and making that available through "easy to use" Must-statements seems like bad practice to begin with. I'm referring to your main() example. Errors should be properly handled, and if necessary tear down should occur rather than panicking and shutting everything down abruptly? 
Thanks. The purpose of the go.sum file is clear. It however has some redundancy, and since it is easy to be regenerated, I thought maybe, it'll add too much noise for not much profit. But thinking again, you might be right: the benefit of having exact replication in not insignificant.
What's obviously going to happen is the same as DEP vs go mod. None of these community proposals will be taken into consideration whatsoever and RC will just pop up say "here is go 2" and a simulacra of a debate will happen in order to make things look like it was somehow community driven. I'd prefer there is no go 2 at all.
&gt; JS Leftpad case is a good example of the perils of "extreme DRY" approach. Stop spreading lies and bullshit. "js leftpad" has nothing to do with "extreme DRY", JS std lib is just piss poor. Imagine go had no std lib safe from core types, well that's what the JS spec is basically. So of course people will be tempted to rely on external dependencies. A padding function was added to the string prototype by the way. So much for your bullshit.
The fact that you are getting downvoted for stating facts while your parent is upvoted for spreading a blatant lie says a lot about the kind of idiotic echo chamber this sub is.
Rewrite libxml2 in Go so people can do XSL,Xpath,Xquery and SOAP in Go.
If you remove whitespace the StringSorter example becomes more compact. I don't see any use for interface literals. Also you don't need the temporary variable in Swap. func (s StringSorter) Len() int { return len(s) } func (s StringSorter) Less(i, j int) bool { return s[i] &lt; s[j] } func (s StringSorter) Swap(i, j int) { s[i], s[j] = s[j], s[i] } 
I don't like any error-handling proposal at the moment, but for me, there are two kinds of things that \`err!=nil\` makes me feel bad. One is that \`err!=nil\` or other error handling tends to get in the way of the normal (i.e. no error) code flow. This usually is not a problem of Go but a problem of design, and can be fixed by using patterns (like the \`bufio.Scanner\` uses) once understanding the saying "errors are just values". I call this kind of problem a "horrizontal" problem. The other one is that sometimes the code does not really wants to bother error-handling, and is just using \`err!=nil\` and returns the error to its caller. Moreover, on the calling stack there is quite a few (&gt;=3) calls with the problem. To make it even worse, it is not a design problem: error-handling are beyond the scope of those usually tiny functions - it is the caller's responsibility to decide how to format, wrap or ignore the errors and differenct callers treat errors differently. I call this kind of problem a "vertical" problem. I believe a "vertical" problem is much more valid. I recently realize the problem might not be error-handling but to have a flow-control syntax that allows to "return" across several calls. I didn't have time to give it a thorough thought so I can't answer that if such needs of having a new flow control is general (not just for error handling) and if the builtin \`panic\` (in the way \`fmt\` widely uses) can suffice. I really want to talk about this.
I use Go every day now and the thing I personally don't like about Go is that lack of almost any feature like generics or overloading is explained like "It would complicate the compiler". 
Hi, author here. This is commonly accepted that naming convention and style convention have no place in code reviews so we invented style linters (eslint, prettier, golint...). But what about filenames and directory names ? Here is the reason of flint: have a consistent naming convention among your files and directories in your projects. 
Hi, sure I will soon :) I didn't until now because it's in our disadvantage ;)
Go has composition, in my opinion it is better.
Thanks for the kind words! And yes, the price difference is \_huge\_. I made money on the paperback of Writing An Interpreter In Go, but with the printing costs so high, the profits were consequently pretty low, which made it hard for me to justify pouring time and effort into another paperback edition. So I switched to b&amp;w and I still think it looks good and am pretty happy with the results :)
Is there any real difference between collect and try catch?
This is just a try catch attempt and that to reinvent it is a bad idea in itself. either go full force or not at all. Having to handle every error on its own draws the attention back to where it should be: correct error handling.
With the interface literal you don't need to declare another type. But I see your point, it might be more readable without interface literals. At least in some cases.
&gt; The go version of inheritance is more like embedding a class inside another class as a property. But it still maintains its own namespace, etc. I don't think that is true. You can embed a 'superclass' without using a property in te subclass. ``` go package main import ( "fmt" ) type Super struct { } func (s Super) Foo() string { return "super:foo" } func (s Super) Bar() string { return "super:bar" } type Sub struct { Super } func (s Sub) Bar() string { return "sub:bar" } func main() { sub := Sub{} fmt.Println(sub.Foo()) fmt.Println(sub.Bar()) } ```
I think some are even just hung up on the err != nil part itself, because they see that as a duplication in itself. Checking a variable is just not as ingrained as try/catching or just letting the caller handle any panics/escalations. But in the end you are not repeating yourself with err != nil, you can what you do right after that and that can be abstracted. Nothing wrong with 5 err != nil parts in a simple REST api GET call, one will throw a 404, one will throw a 400, two might throw 500 with different components failing and logging more. Nothing bad there. You might get a large function but its crystal clear where it fails and why a specific code triggers.
[removed]
&gt; And as my Computer Science professor said, if you're repeating code, you're doing it wrong! Not really. This applies to a different kind of code. Mostly it covers code that implements some business logic. You don't want to duplicate business logic rules in multiple places obviously but error handling? I don't think this statement covers that. Think of replacing error handling with exceptions. Most statement might be covered in a try..except block. Would this statement hold on repetetive try...except/catch code? Certainly not, because with error handling, you don't really need to update all error handling cases if you update 1 unlike with business logic. I think more valid excuse would be that error handling gets repetitive and cumbersome in Go but code duplication as emphasized by the quote is not a valid reason IM.
Why not just do something like [this](https://play.golang.org/p/oe7UCna4UOe)?
You mean like Rust's \[question mark operator\]([https://doc.rust-lang.org/std/result/#the-question-mark-operator-](https://doc.rust-lang.org/std/result/#the-question-mark-operator-))? Yea, I like that.
`github.com/lib/pq` is just a driver for https://golang.org/pkg/database/sql/ So you'd mostly be interacting with `database/sql`. What do you mean when you say you want to experiment with Go, not SQL? Do you mean you just don't want to fire up the postgres CLI and perform your insert, or are you trying to avoid having to hand-write SQL in your go program? If the former then use `database/sql` with the `github.com/lib/pq` driver and use the `COPY FROM` SQL statement (https://www.postgresql.org/docs/9.1/static/sql-copy.html) If the latter you are looking for an _orm_ which is going to be a layer of abstraction on top of `database/sql` and `github.com/lib/pq`. I've been out of the game for a bit but the only one I remember was `github.com/jinzhu/gorm` that you could check out.
I personally don't like the collect but could live with it with some changes. 1. There should be no `_ :=` or `_! :=` on the left hand side of the statement. 2. It shouldn't allow the flexibility of specifying which statement to cover with `_!`. Instead it should always catch the very first non-nil error. 3. As mentioned in the doc, `err!` would perhaps be better but could we may be have just `err`? I know `err` would just be a variable name but in that case the compiler could match `collect &lt;var&gt; { i, &lt;var&gt; := func_call() }` So the example would become: ``` collect err { err := SomeErrorProneFunction() _, err = AnotherFunc() // ... i, err = LastFunc() } ``` and collect would exit on he very first non-nil err var. The reason I don't like allowing users to specify which statements to cover is that I fear people will enclose entire functions inside collect like: ``` func Do() error { collect err { // 100 line function here } if err != nil {return err} } ``` I think this can be avoided if the collect statement always catching the very first non-nil err. 
errn (vim-go)
Hey, thanks for your feedback. Did you have a chance to read the "Motivation" part in the README? I tried to give there a few examples to explain that more deeply. Anyway, following your first question - I think the best example to show the difference between an if statement and using this pattern, is to go to the `go/parser` package and try to replace every call to `expect` with `if err != nil`, and then you also need to change the function's signature to return an error (and its callers) - you will see that the code gets much more complicated and unreadable. About your 2nd question - The default handler calls log.Fatal on error or when an assertion failure occurred. Like I wrote in the README - &gt; "You talked about parsers, but you showed above a main example?" - Yes, I treat the main function the same. In the sense that if I expect something to pass in order to start the application, I don't see any point in handling the error if all I want is to crash. In these cases, I use that too. 
Well, leftpad was a bunch of different issues, and culture of creating new packages for the sake of one tiny function (that would be easier to just copy-paste to your project) was just one of them.
One thing is to introduce a `go for` loop that in every iteration spawns a new goroutine.
In practice I haven't stumbled into any issues with named constants. If you want to avoid misuse at all cost you could create a distinct struct type so it becomes almost impossible to misuse them.
S/o to [remove bare return](https://github.com/golang/go/issues/21291).
Isn't that the whole point about interfaces. That you want a new type that is able to do a certain thing.
I have no immediate inspiration unfortunately. Naming things is hard :-(
`err` being whatever you are collecting, not necessarily named err.
I think there is a great deal of sarcasm in that sentence.
So GoLand 2018.2.1 and rc1 properly resolves dependencies and autocomplete. 
Yeah. Go's error handling while simple has it's downside. I've already advocated for using concrete error types (that implement the error interface) instead of the error interface but go's lack of variant subtyping makes this impractical.
&gt;With the interface literal you don't need to declare another type. If you need custom sorting you probably want custom type.
This is great idea, I love having all of these kinds of things taken care of for me in code reviews. Nice work! I might take this for a spin soon.
Go 1.11 can be used without GOPATH with the new modules feature: [https://tip.golang.org/doc/go1.11#modules](https://tip.golang.org/doc/go1.11#modules)
If you have a large number of items to process, I'd tend to create a smaller goroutine pool that you re-use. You could create the same number of workers as you have cores (if you've not updated the value, by default this will be returned by `runtime.GOMAXPROCS(0)`. From there, fill a channel with all of the items you want to process, and then just start consuming from that channel, something like: concurrency := runtime.GOMAXPROCS(0) workCh := make(chan Foo, concurrency) wg := &amp;sync.WaitGroup{} for i := 0; i &lt; concurrency; i++ { wg.Add(1) go func() { for w := range workCh { // do something with the item from the channel... } wg.Done() }() } fnThatFillsWorkChAndThenClosesIt(workCh) wg.Wait() That's a pretty basic example. In some cases you might be doing something in that goroutine that involves IO, in which case you can make that concurrency value a multiple of your CPU cores and it'll potentially make it faster. It might take some tuning. Generally though you want to start a limited number of goroutines to do batch work. Depending on the task at hand you might even find that using concurrency makes it slower. It really depends on what you're doing, and how much stuff you've got to process, etc.
Something you're actually interested in for a start, but also something that's looking for contributors. I'm sure there are a lot of very popular projects that always want contributors. Moby, Kubernetes, all that kind of stuff.
There's many strategies you can use. The simplest one is that your \`request\` function returns a \`chan result\` instead of \`result\`. [https://play.golang.org/p/hkHAgBhMwjn](https://play.golang.org/p/hkHAgBhMwjn) for example. This really depends on your exact use case and needs. The example above for example would have an implicit barrier at N requests. You do N requests, then wait for all the results. This isn't ideal if you want to keep doing more and more requests in which case a worker pool approach is better because then you don't have this implicit barrier and keep queueing requests. [https://play.golang.org/p/NLENd6lY6IK](https://play.golang.org/p/NLENd6lY6IK) for example. 
As others have already said, do not like the proposal for collect _at all_. It seems clunky and unclear - when I read that, I feel like I make a mental context switch every time I see a !. The explicitness of ‘if err != nil’ is fine with me. Of all things, I would like to see context become a first class “thing” in the language, rather than a convention. Right now, most of my code is instrumented to pass and accept ctx (in most cases for recording metrics) and it looks and feels just .. bleh. I imagine “treating it as first class” involves ctx being implicitly created and made available between all func/method calls. ... but I might be oversimplifying something and someone much smarter than me may be able to explain why this is not easy and/or possible. In the realm of much simpler things - can we please get an interface for logging? :(
`(word)` passes `word` as an argument. See for example: [https://play.golang.org/p/VP7PFbrHBXo](https://play.golang.org/p/VP7PFbrHBXo): `func(i int){fmt.Println(i)}(9)` calls the anonymous function `func(i int){fmt.Println(i)}` with argument `9`.
Yup. The way it is proposed, yes
The difference is that I won't have to make an extra directory with one file that has 5-20 lines in it.
I mean, error collect would be fine if Go naturally gave errors context, like stack trace information for each "bubble". Unfortunately Go doesn't help us at all, so we're stuck building the worst stack traces I've ever seen, and risk destroying values by making these crappy stack traces. What I don't understand is why so many error related proposals are focusing on the syntax of throwing away errors instead of simply giving errors more context with less developer assistance being needed. What we have now is just gross. What `collect` and many others propose completely misses the point. My 2c.
&gt; Then C updates a small bug fix C 5.0.7, will B stick to C 5.0.6 or would the 5.0.7 dependency download to fix a non critical bug? B will continue to use C 5.0.6, until it cuts a new release and explicitly upgrades. This is a feature, not a bug, because it's the only way to get what Russ Cox calls [high-fidelity buidls](https://research.swtch.com/vgo-mvs). &gt; If the answer is no, is there a way to force bug fixes to go through? Either B cuts a release with an upgraded C and A cuts one with the new B, or A cuts a release with an explicit `replace C v5.0.7` directive. Go will always install exactly the versions used by the author in the release (to guarantee reproducibility/high fidelity), so someone needs to do a release.
thank for the support! I'm currently (like right now) implementing more formatters (for nicer output format) which will make it more user firendly. Then I'll add some liniting rules. Then I'll see how to handle hierarchical configuration files and overrides (like eslint). And finally I will add the `fix` command which will **automagically** fix all the encountered errors. 
The exact behavior of `append` (as in, how much extra space it allocates when the slice gets overfull) is undefined. That is the difference you are seeing. You are using a different Go version than the playground :)
Why would you Introduce a new package?
You could encode/encrypt the image to effective obfuscate the file contents. Then theoretically no matter what input the user gave, it would not be executable to the system the file is hosted on. I bet this is a fairly standard problem, so perhaps some google searching could recommend goo ways to do this. An encoding that keeps bytes fairly 1:1 as to not increase storage size would likely be best? No experience in this, just offering ideas.
So that I can do something like this cleanly: type user struct { UserLevel userlevels.Admin `json:"user_level"` }
Trying to understand - are you suggesting something like structured exceptions where you have to list every exception type a function and all of its transitive dependencies can raise?
Wow, that's rough. If you're using a lib that's fairly stable and a lib they use pushes a bug fix you're kind of fucked if that library you're using isn't maintained often. Might be the worst part about vgo imo.
That is almost certainly not the reason. If it complicates the compiler to the point that we risk adding new bugs, then it is a plausible reason, but I doubt that is the only reason. I am curious to see if you have any references where a Go team member has mentioned that.
We had a similar issue with the grpc package. Basically, we were relying on a specific error value to do some specific error handling in a specific case. grpc updated and deprecated the functions we were using to connect, instead, hiding that functionality behind another interface. it was an architectural improvement, i think but it also left us scrambling to figure out how to tease out the same behavior from a new set of errors. i think we ended up abandoning the special case error handling altogether because it wasn't that important. when i went to write my own first Big Package (a subcomponent of our system) one of my biggest concerns was making sure error handling was sane. the whole package shares one coherent set of error types.
Well, look at the `net` package for example. Some functions return an `OpError` but the function signature always specifies `error`. The documentation doesn't even say which function return which kind of error. This results in people writing unsafe code like `err.(*ConcreteError)` which will crash if the devs decide to return a different kind of error sometime in the future - which they can because the function returns `error` and not `*ConcreteError`. Then you have high-level APIs that might do all kinds of IO operations and return `error` as well. There's no way of knowing why exactly something failed - which results in people doing regular expresions or `HasPrefix/HasSuffix` stuff on `err.Error()`. In case of errors you need to look at it from a programmer's perspective and a user perspective. If you have for example func LoadConfiguration() error if err := LoadConfiguration(); err != nil { // I have no clue why LoadConfiguration failed. It might be a syntax error in it, // it might be that the configuration file does not exist... it might be that the // configuration file is locked by somebody else. } If you're lucky LoadConfiguration returns something that's useful to the end user. That's great. But as a programmer... there's not really much you can do to figure out what the problem exactly was. This makes it impossible for example to present \_better\_ error messages in a user interface or suggest solutions to the problem etc. because all you have is an error message that is useless for you as a programmer. With concrete errors you can differentiate this much better and you have compile time guarantees that you're dealing with the right types. This essentially would require union types such as func LoadConfiguration() {*SyntaxError, *IOError} which allows you to have that compile time guarantee. At runtime there's not too much of a difference there because it'd still require a type switch but you have compile time guarantees you don't currently have and it means that the kind of error returned is actually documented in the function signature as well so you don't have to dig through source code looking for what kind of error this function returns hoping they'll never change that but of course - at the very least you should use \`ce, ok := err.(\*ConcreteError)\` anyway to prevent crashing. 
Use a CSV reader to read from a CSV file: https://golang.org/pkg/encoding/csv/#Reader Then construct a query for each row of the data to be inserted (or batch it if you prefer). I'd personally just stick to using `database/sql`, which would mean using https://github.com/lib/pq with it. Keep it simple.
[removed]
&gt;or A cuts a release with an explicit `replace C v5.0.7` directive I don't believe A needs to use `replace`. A can use `go get C@5.0.7` to upgrade to later indirect versions as well.
Why would you want a stacktrace?
interesting.
This is classic concurrency vs parallelism. Design your matching algorithm to use goroutines where it makes sense to do calculations concurrently, and then adjust GOMAXPROCS at runtime in accordance with the hardware/cloud resources available to maximize performance. \&gt; Is it even necessary / recommended to limit the pool? For a production service, most definitely. You basically never want to have unbounded creation of anything, and this goes for goroutines as well.
Say I have some kind of central error management (i.e: if I hit an **unexpected** error that's behind 4 function calls, that error should be returned all the way back up the chain to somewhere that it can be handled). The error management will most likely at least log the error out someplace so I can deal with it later. One day, I actually hit an error. I excitedly go to check my logs. "Your SQL is bad, and you should feel bad". Well crap. Where the heck did that error come from? There are hundreds of places in the application that could be calling an SQL query, and finding which one it is ASAP would be really helpful. While I could certainly wrap every error I receive from an external library so I can tell exactly which part of my application produced it is *not impossible*, it is very tedious, and very (ironically) error prone. 
Yeah, if you just pass errors up the chain without wrapping them then you might end up with not knowing where it originated. There are two ways of tackling this: **Log errors at the source** If you log erros at the source.. then you know where they came from. Of course, this means you have to log more than just the error messag, but also the code location. **Wrap the error** You can wrap the error and there are I think good libraries to do that where you have something along the lines of type Error struct { File string Line int Cause error } which also contains information about the exact code location. 
At the very least one of the numerous "go error packages" but inside the std lib. This is such a fundamental thing to at least be able to track errors when required, i'm sick of all these libraries that use 20 different libraries with 20 different incompatible ways to trace errors. To me it's a no brainer. If the go team doesn't want it to be part of the std lib at least but one version in /x/ namespace. 
yeah I just tried this method and it works without issue. `go get bitbucket.org/user/module@v0.0.2` when the module i depend on requires 0.0.1 I guess the only missing feature is go not supplying dependency change info from the cli directly. Maybe someone will create a tool to check dependencies for all libraries and ask you if you want to install any of them using go get. 
At the very least one of the numerous "go error packages" but inside the std lib. This is such a fundamental thing to at least be able to track errors when needed, i'm sick of all these libraries that use 20 different libraries with 20 different incompatible ways to trace errors. To me it's a no brainer. If the go team doesn't want it to be part of the std lib at least but one version in /x/ namespace. 
Those are clever solutions to work around the issue, indeed. But we wouldn't even have the issue in the first place if stack traces were built in. The solutions are also a little prone to human-error. Logging errors at the source throws away the benefit of central error management - I now have no way to centrally define what all errors should do when they occur, and must instead duplicate "logging code" (even if it's just a one liner) around the application, and ensure that it's called *every* time we encounter an error. And if we swap the "logging implementation" or need to provide it more information? Oh boy ... This is opposed to a simple, idiomatic "if error, return to whoever called me", where the functions are completely unaware that error logging even exists. As for the second suggestion ... I *could* wrap any encountered error with a filename and line number, but then I've just manually reinvented stack tracing. Worse, if I rename the file or move some code around and miss out on updating the error, it's going to give me completely false information. In either case, we're just working around a deficit of the language and/or it's standard library. Even grabbing a "batteries included" error package feels a bit dirty sometimes.
wow thats pretty useful. Is there a list of these things somewhere?
I'm curious - what are the proposals that "change nothing but add sugar"? And what is being suggested with "making the compiler be aware of the interface"? 
&gt;Proposal: rename sort.Interface to sort.Sorterer or just `sort.Er`? ;-)
&gt; Worse, if I rename the file or move some code around and miss out on updating the error, it's going to give me completely false information. You can access the file name and line number at runtime so you don't have to do that manually. &gt; Logging errors at the source throws away the benefit of central error management Not sure what exactly "central" here means but yes, if you use a Logger then you might run into packages that don't let you set a logger, yes but you still can log the error when you encounter it in \_your\_ code but yeah... it might be hard to localize where exactly it came from from within the other package. &gt; And if we swap the "logging implementation" or need to provide it more information? Should be somewhat mitigated by using a proper Logging interface I guess. By "central" do you mean you have some outer level function that calls a function that calls a function that calls a function... and you pass the error all the way back to the top and log it there?
Performance. Creating a backtrace touches a lot of cachelines. (and is unbounded)
I'm not familiar with that javascript now. Must have a look at it. Any opinions/pitfalls with it? Bad error handling is a little pet-peeve of mine :P
Yes I know, check my other post in this thread. Also I'm unsure what you are referring to regarding "this is a feature, not a bug" I don't think I implied anything was a bug outside of my example of a inner lib patching a bug? 
I'm not sure of supporting that at a language level is a good idea. In most cases, just returning the error isn't a good idea and means that the error loses intermediate context. Having that mechanism in built in to Go would only encourage the use. We ought to optimize for the majority of cases, which should be adding intermediate context.
Couldnt agree more. Would love to see more stuff in the `errors` package.
Code is read much more than it is written. `err != nil` is much more explicit and makes code much more readable imo
Totally agree. For something with minimal batteries, check out r/https://github.com/zeebo/errs &lt;/shameless plug&gt;
&gt; You can access the file name and line number at runtime so you don't have to do that manually. I genuinely didn't know that. In hindsight, it should have been obvious - the "batteries included" errors would need this functionality to exist too. How do you do this? &gt; you still can log the error when you encounter it in _your_ code I could. But I'd still be having to write the "logging code" everywhere where an error occurs in my code. As opposed to doing it from a single central location. &gt; By "central" do you mean you have some outer level function that calls a function that calls a function that calls a function... and you pass the error all the way back to the top and log it there? Bingo. A very common scenario in a web application, because the error will have to bubble up to the request handler anyway (if only so that we can see that err != nil and tell the user "Uh-oh, looks like some bad mojo happened, we're looking into it").
&gt; Might be the worst part about vgo imo. This is not Go module specific. Dep is doing the same thing. As is any other package manager that supports reproducible builds. You simply can't have both silent upgrades *and* reproducible builds, that's the very definition of reproducible. And in general, reproducible builds are considered really important (among other things for operational security).
I assume you mean generic map functions, which opens up the generics can-o-worms 🤣
You could do the same with an in-package declaration. Could you?
&gt; I don't know how you get to that conclusion got that conclusion by not having [all the information](https://www.reddit.com/r/golang/comments/97hx1b/i_have_a_two_questions_regarding_vgo_and_semver/e48k14s/) - I'm sure others would be just as confused with this feature not being that well documented yet.
That is not correct. You are thinking of named return values, which is a different feature.
I don't understand why that comment would change anything. You still have to cut a release in A with the updated version.
Where is the Go github issue, so this can be potentially fixed?
`go list -m -u all` works. thanks. 
Hmm, well my original comment said I didn't have control over my dependencies and that comment pretty much explained why I was wrong since I can use go get to update without going to the middle man if I want that update pushed. So yeah that comment changes everything in my original post because of that fact?
First an error value can carry any form of information you wish including a full stacktrace. And you don't know how many levels an error might have been propagated. The collect statement shares all the negatives of try-catch while not bringing any of the benefits. Introduction of a new superscope is akward. Either you put logic in there and then have the downside of implicit breakout (this is the single reason Google banned exceptions in C++) or you need to extract the assigned values out of the block which increases their lifetime and you have to deal with shadowing issues. And while catch allows you to directly handle special error cases collect does not.
Errors are for expected errors in your program so having to make a stacktrace every time is expensive. Panics are for unexpected errors and they do print a stacktrace. Perfectly fine IMO.
Nice idea. I'll try it on my projects in new t couple days.
&gt; I could. But I'd still be having to write the "logging code" everywhere where an error occurs in my code (mocking it out of my tests would be a pain ...) I don't see a problem there though. You have to do something like if err != nil { return nil, err } anyway so what's the big fuzz of doing if err != nil { logger.Error(err) return nil, err } ? &gt; How do you do this? [https://golang.org/pkg/runtime/#Caller](https://golang.org/pkg/runtime/#Caller)
Ever looked at Dave Cheneys [pkg/errors](github.com/pkg/errors)?
&gt; There is basicly no difference between struct embedding and (multiple-)inheritance. Struct embedding breaks the single most defining feature of inheritance: relationships. If Foo extends Bar, Foo "is a" Bar. But if Foo *embeds* Bar, Foo isn't a Bar.
Promise.all just takes an array of promises and then executes them. It allows you to then group promises together and also group error handling together. The idea is if one promise in the array fails they all fail. 
I like Rust's solution here: - enum for error/success - enum for error types, which all implement an Error trait Go could change syntax to something like this: res := net.Dial(...) if res.IsError() { switch res.ErrorKind() { case net.SomeError: } } else { conn := res.Ok() // could panic n, err := conn.Read(&amp;buf).Ok() } Or a switch, or whatever. The point is, you cannot access the success case without checking or ignoring the error case, and error types can be handled directly. Rust's approach is also pretty nice in that "switch" conditionals *must* be exhaustive, so you have to explicitly support or ignore all variants. However, this is probably "too complex" for the core team...
That's absolutely not what you want to do. How can the super-type know in the first place that it is embedded/extended? And it also violates the open-closed-principal: Open for extension; closed for modification. Changing something in a superclass when its even present violates this as it modifies existing behaviour.
Now I wish the Go runtime would randomly permute strings returned from \`error.Error\` into visually similar but non-equivalent values to subvert inspecting the message.
At one point I made my logger return the error value so you could just `return log.Error(err)` to both log and return the error. However, I was eventually persuaded that both logging and returning an error was an antipattern.
And why is it an anti-pattern? I don't see a problem there unless you also want to handle error during logging itself. 
What you are referring to is called polymorphism. Go does not have polymorphism but instead uses duck-typing which is similar but not the same. Polymorphism is about type hierarchies and any subtypes can be put in for a super-type. Duck-typing is different however. You just look can this type do this, that, something else. Go uses interfaces for that. Duck-typing combined with embedding is a strict super-set of polymorphism as any type that embeds a different type can do everything the super-type does and therefor can be used in its place. Ducktyping allows even some type not related to the two former two if it offers all required behaviour. The reason it only works with interfaces is that they are the only construct in Go that uses dynamic-dispatch for method calling. I hope this made clear that everything that relies on polymorphism can be implemented in Go. 
You end up double-logging errors, because the caller typically logs the error too.
This isn't a perfectly worked out example, but... sort-of sum type error: [https://play.golang.org/p/oNgKBdcS-4y](https://play.golang.org/p/oNgKBdcS-4y) The handlePickError function could require a last function arg for non-PickError handling. Similarly, the PickError.Handle method could require an "unknown error" function arg. Also, I've not worked out other "fallback" behavior which is noted in comments. /u/rosacanina_, /u/DongerDave, /u/one_is_the_loneliest
That would be vary nasty. Sentinel error values are an ok error-strategy it just does not fit all problem domains. People just need to read documentation. io.EOF does fit its problem perfectly for example.
The currently accepted way (as somebody might have told you already), is to use https://github.com/pkg/errors package. It provides `.Wrap()` (to add additional error context) and `.WithTrace()` to add just the backtrace to the existing error. Retrieving the backtrace is possible over a `causer` interface (part of readme), or just by printing it with `%+v` over `log/fmt.Printf...` and others. I know you said you can take any batteries included package, I'm just adding it for posterity, in case people haven't heard of the package yet. The main reason as to why it's not auto-on by default has been added by /u/nsd433 (performance), and unfortunately as to why it's not included in the standard library (or something like x/errors package), the best insight is available from this GH issue: https://github.com/golang/go/issues/25675 - TL:DR: mainly, the Go team doesn't subscribe to the mantra "go fast, break things"
The error resolution is just wrong here. It relies on sentinel-error-values and error-types while ignoring the right one -&gt; error behaviour. The OpError provides `Temporary() bool` and `Timeout() bool` as access to behaviour. Here is a talk by Dave Cheney that explains error-handling in greater detail: https://www.youtube.com/watch?v=lsBF58Q-DnY
github.com/pkg/errors mostly fits this role as it's blessed by Dave Cheney.
&gt; github.com/pkg/errors mostly fits this role as it's blessed by Dave Cheney. And? that's not the issue, the issue is that if library A use another package with a different API, I'll have to unwide error stacks multiple ways depending on what library was used. And Dave Cheney isn't part of the go team at google he makes no decision regarding the language and its ecosystem.
thanks for the extra insight. It actually is like an email where you can upload different file types including, images, text files, videos. Is there anyway to block a directory from executing stuff and just enable it to read but then again if someone does sh images/malware.sh then I'm exposed again :/
As you probably discovered later on, such a simple wrap isn't enough when it comes to proliferation of some functions usage across your apps. I can easily pin point the errors origin with a file/line wrap to the causing function, but I have no context of how this function was invoked. It's easy to have some function used 20+ or even 200+ times in your app. Especially some parameter dependant functions (like SQL queries) would hurt app development quite a bit, if you would wrap the error of each query return. As such, it's better to add the full stack trace at the place where the error occurs, or as close to it as possible. If you're doing something 20+ times in your app, there should be a handling structure available for that API, so finding a few places where to add error context shouldn't be difficult.
The problem is that `Temporary()` and `Timeout()` are not the full spectrum of differences in (net) error behaviours that are interesting to people in the real world. For instance, in our case there is a significant difference between 'host not there' (which is more or less an expected outcome of a connection attempt some of the time) and things like 'host refused connection' (and neither are temporary except by stretching the definition very far). The reality of life is that you probably never can capture all of the differences of interest to people in error behaviours. (I'm the author of the linked-to article.)
So you essentially want the equivalent of Java's try{ } catch(Exception ex){ ex.printStackTrace() } ?
The Go team doesn't want it to be part of the stdlib. There are proposals to use github.com/pkg/errors in Go 2.0 and not something else. In the meantime, your best bet is to advocate for the use of this library, either directly or as a base.
Why can’t Go just implement exceptions using the current Java implementation??? It is essentially zero cost when no exception is thrown, and if exceptions are continually thrown then they are being improperly used for flow control. The Java exception methods always works fine with the functional implementations. The defer can remain, as I think that is cleaner, but no reason finally couldn’t be implanted, to try with resources. The throws declaration also removes tons of boilerplate, and allows the higher level methods to handle the error as appropriate. I think the lack of exceptions is one of Go’s biggest weaknesses, the other being lack of generics. 
I'm aware of everything you just said and please, easy on the patronizing tone. You reciting CS101 to me does not serve as proof that Go's embedding + interfaces is a superset of polymorphism. 
I skipped most of the introductory stuff and went back to the more 'advanced' topics since I had already pretty good knowledge on 'general' programming concepts. It really shed some light on me and I really liked them, would adivse to take them as a beginner golan programmer.
Ah right cool. Sounds very similar to `errgroup` in Go.
Also: The work you do on open source forms a portfolio you can show potential employers. Also, the way you interact with people in Open Source (i.e. in issue comments, code reviews, etc) will demonstrate that you are a nice guy that would make their team work better. OTOH, if you are a not a nice guy, you'll have to be careful about not making an ass of yourself and having it go down on your permanent record. :)
Cool .. i'm currently on the beginner topics only and i'm finding the course pretty decent. However, one thing that worries me is that there is a lack of practical approach (at least upto what i've covered) and he's just showing the code and not letting the students take any exercises. Are the exercises in the subsequent modules well structured?
That wouldn't work for functions that return more than one thing.
I think beginners mind is a plus. Todd McLeod is a great instructor and his course is very thoroughness about learn to program. The best course for me! You should take course 1 first IMO. Check out greatercommons.com also :)
Try catch (and especially finally) really messes up code flow. You go from clear paths to any number of possible paths depending on the number of potentially throwing statements. if else are totally explicit, and there's no ways out of a function without a return.
There are a load of techniques available to share code that don't use inheritance, and of the techniques available, inheritance is probably the worst and unfortunately the most used.
Hey, author here! Thanks for sharing my post! I think my view has definitely shifted a bit on the whole idea of `collect`, I liked it when it first came about, then I didn't like it, then I liked it again, and now I'm back to not liking it. I've been looking through even more of the proposals, and I've found quite a few that seem really intriguing. If I decide to make another post, I'll probably show off [#26070](https://github.com/golang/go/issues/26070) (no unsafe.Pointer properties if unsafe is not imported), [#26842](https://github.com/golang/go/issues/26842) (allow all values to be compared to their zero values), generics, and one or two more. It was fun to write, and it's fun to hear what people think about the future of Go.
Ehh, seems like syntactic sugar, WaitGroups make it easy enough
commonmark implementation (you can port one from C# or C)
Yeah, there's all kinds of ways you can kinda-sorta get something to work, but the point is that it's not standard. Some places use error instances so you can directly compare them, but most don't. The nice thing about Rust is that you *cannot* discard errors and get wrong behavior, and it's *very easy* to make an enumeration that contains all error types. If Go had enums, we could mostly get the second part (and `var (Err1 = iota ...)` isn't an enum), and potentially work out the first part (Rust enums are just tagged unions, which is *really* handy for forcing error handling). Honestly, a Go 2 with enums would solve quite a few of the problems I have with Go today. Enums give you: - generics (sort of) - enforced error handling - space efficiency (I use pointers and check for `nil`) - a state for "unset" without having to use a separate variable (reduces errors) If I can be greedy, then I'd tack on destructors and be quite happy with Go (though I'd *really* like proper generics, as well as a whole host of other features).
Definitely not true. Overloading is for clarity, not the compiler. Go is an opinionated language, and the creators believe that overloading makes code less readable. If you want more arguments, briefly explain what they are in the function name. (ie `strings.Split` vs `strings.SplitN`) Generics they haven't gotten around to quite yet. They definitely can't put it into Go 1, as all Go 1 code should be mostly similar. They are thinking about including generics for Go 2, although they want a plan for the syntax and how they would work behind the scenes. Go is a spec-first language. If it complicates the spec too much, sure they won't add it. That's because then the language gets confusing. But the compiler comes after the spec.
Good suggestion for sure 
This is the mantra but something interesting I noticed is that the go subcommand makes extensive use of globals. Its just very ergonomic I guess.
The line:file wrap is just not sufficient to track down the path from main() to the triggered error. It’s why stacktraces specifically are a useful construct, because if you’re adding context why add just file:line if it “costs” you the same developer time to add a stack trace instead?
Potentially!
Pm'd you
Any chance there will be a bundle comprising both hard-copy books and their ebook versions? I'd buy that. 
Check out the new version of the Go course here - This is from me, Todd McLeod :) discounted access code: coverBandwidth
[https://greatercommons.com/](https://greatercommons.com/)
Hold on a sec. Polymorphism is the ability for code to work on multiple types, and subtyping is a particular way of doing that. Polymorphism is _not_ about type hierarchies, or generics in various functional languages would not be considered polymorphic. Go Interfaces provide dynamic dispatch, and that's enough to provide polymorphism. sort.Sort can work on any number of types, so long as they satisfy the interface, and is polymorphic code. Struct embedding is also not a superset of inheritance. A method on an embedded struct cannot use a method on the containing object because it has no concept that it is part of one. Effectively I think there's no equivalent of the virtual keyword, where the behaviour and calls of a base class are intercepted or altered by the one that uses it, which is good, because that's a horrible pattern.
He's in my top 5 favorite Udemy/YouTube instructors 
Yeah it's just syntactic sugar. People in Go often just fall for the race condition a range loop can introduce if you don't copy the value for every iteration.
Python uses a dictionaries for objects. You can do the same in Go. Just have a map at the root of the object where all attributes live.
It really depends on how much information you (want) need to make an informed decision on how to proceed. If you really want to know everything sure you have to go the ugly road but I'd say after testing for Temporary() you can decide in most cases.
Patterns like this spread all the way up the callstack, much like trying to make something const requires you to go fix everything it touches. Adding a call to the network might require you to run all over your codebase fixing things, and writing a function that executes a callback and doesn't know what errors it could raise would be a nightmare.
How do you typically handle if a function might pass it further up the stack and add its own errors?
Not disagreeing, but some packages just use error.New() and the only way to distinguish is the string. It forces bad patterns on others.
Maybe this suits your use case? A Go engine that can target browsers with GopherJS: [https://hajimehoshi.github.io/ebiten/](https://hajimehoshi.github.io/ebiten/) 
At least to my definition in polymorphism being ad-hoc or parametric you are still interested in the actual value while duck-typing just relies on behaviour. Regarding the access to values to make them work in a duck-typed fashion the access to them must be included in the interface (setters, getters) to make them work with dynamic dispatch. You of course have to override the methods. As we all know this is 'unidiomatic', so while you are not gonna use it every day it is still possible if pragmatism dictates it.
To gain access to attributes use setters/getters in your interfaces. Yeah this is unidiomatic but if you go for an OOP-style it is feasible I guess. I am just concerned if a language can fit both polymorpism via subtyping *and* duck-typing. Is there any language that uses both?
I took your course on greater commons and really liked it. I felt like it did a really good job of introducing the material. I'll get around to the web one here sometime soon. Anyways, just wanted to say to anyone thinking of getting it that it's worth it.
I'm taking the go web dev course after doing grider's go course. I enjoy it so far, I like that many different technologies are taught. 
The only way to change what an embedded object calls is for it to take an interface or function pointer that you would have to set from the parent object. You can wrap them for people calling into the containing object, but even if you provide a container.A(), if embedded.B() calls embedded.A() it will not call container.A().
Kinda-sorta in the "not actually a mathematical proof" sort of way, but otherwise accomplishes the goal in a conventional and safe manner. What is desirable/satisfied in this case is the enforcement of pre-specified condition checking. That's pattern matching and not the same as the union types that are commonly used as the tested condition+data structure. Regardless, I would like both union types and pattern matching in Go, but only if adding those things does not send the language down the path of gross complexity. For Go, usable simplicity is far more important than fancy features. Hopefully a worthwhile and pragmatic solution can be found.
That wouldn't work at all with error collect would it? Theoretically it would only know the location of the new instance, and it still destroys instance values on wrap/etc. You can potentially check for the original value but you have to use a made up interface/func to assert the origin error.
I would just like to point out that [https://godoc.org/golang.org/x/sync/errgroup#example-Group--Parallel](https://godoc.org/golang.org/x/sync/errgroup#example-Group--Parallel) also exists.
That's not too different from the `io` package, which has pre-defined errors, like `EOF` and `ErrClosedPipe`. However, what's *not* ideal is that there's no indication of *what* errors a given can throw, and you have to rely on documentation that often doesn't enumerate the types of errors that can be returned (basically anything in the package or its dependencies is fair game). I've read threw parts of the standard library to find out just that. The benefit of using an enum to handle errors is that you get a specific list of errors that a given function can return, and you can optionally make your error handling exhaustive. Or, if you don't want that complexity, you can handle one or two cases specifically and have a default handler for the rest. Also, using enums means you can force the user to check errors by having error and success variants, which means they *have* to check whether there was a success instead of ignoring errors, which can introduce subtle bugs into code (especially if a bugfix returns errors in previously unerroring cases). There are a ton of benefits with fairly little complexity. Go is supposed to be a "better" C, and enums are "better" unions, so it fits right in with the goals of the language. Also, it would require fairly limited syntactic changes. I think the best approach is to introduce a new `enum` type and tuples, like so (we'll pick on `net.SplitHostPort` here since it returns multiple non-error values): // defined somewhere in core type Result enum { Ok(...) Err(error) } func SplitHostPort(hostport string) Result{Ok (string, string); Err error} match SplitHostPort("host:1234") { case Ok(host, port string): println(host, port) case Err(err error): println(err.Error()) } I added tuples (`(a A, b B, ...)`) and an enum type, everything else is recognizable Go syntax. I think it would look *way* better with generic syntax though, like so (this is essentially Rust's syntax): func SplitHostPort(hostport string) Result&lt;(string, string), error&gt; The `Err` part of the enum could be any type that implements `error`, so you could have another enum of possible errors. In fact, the `Err` part of the `Result` would only need to be populated if it's different than `error`, which can save on syntax. Bikeshedding aside, adding enums shouldn't overly complicate the language, but it opens a *ton* of opportunities for safely expressing behavior.
[removed]
[removed]
It would if you enforced named return parameters
You don't need to escape $ inside of a character class. https://play.golang.org/p/bZUOpyrKsHz A good rule of thumb here is that unless it's defined to have a specific meaning within [], a character just means itself. That includes dot '.' and ^ when it's not the first character (for negation) and - when it's not between two characters.
&gt; However, what's not ideal is that there's no indication of what errors a given can throw, ... Did you read the snippet I posted? It takes care of exactly that. I used typed functions and a function signature to communicate the same things as pattern matching on variants. It's slightly roundabout, but not really much more than a case expression within a more functional language would be otherwise. Discarding "patterns" would be harder in my example if handled as I proposed in the code comments, but could be eased by handling nil args gently. Please take another look at what I shared.
https://devcenter.heroku.com/articles/s3-upload-python Do that and you’ll be safe. 
The crucial difference with gradually passing an error all the way up the call chain and throwing an exception 6 levels deep and catching it "at the top" (which is deemed haram in the Go community) is that every function along the way has a chance to deal with the error before passing it on. If the error occured because "updateUserRoleAPI" called "updateUserAccessToResources" which called an SQL library ... Then "updateUserAccessToResources" has a chance to deal with the error (e.g: rollback the DB) before handing it back to whoever called it. It's more similar to how the Node community handled error handling before Promises than it is to Java exceptions. But while every error might need to be dealt with in a different manner, pretty much all of them should be logged. And if you're logging an error, knowing the exact context of how it arose is very helpful.
I know it's not the most elegant solution, but could they not have made the stack trace behaviour toggleable if performance was a concern? Like, add a ".Stacktrace()" method to the error interface, but it only produces a stack trace if you set a certain flag on during runtime, and just silently returns nothing otherwise. Compare/contrast this with the type-unsafe way that was used to work around the exclusion of generics (liberal use of the dangerous "interface{}" everywhere, including the standard lib).
There's a bit more indirection than necessary there, but yeah, it kinda-sorta does variants. And you can kinda-sort get enums by doing something like this: var ( Err1 = someErrorConstructor() Err2 = someOtherErrorConstructor() ... ) func do(cond bool) error { if cond { return Err1 } return Err2 } switch do() { case Err1: case Err2: } Which is essentially what your example is doing. However, since the function just returns an `error`, there's no guarantee that the errors are limited to that set of errors. To get around that, you can return something that *implements* `error` *and* has a concrete type, such as: type MyError error var ( Err1 = MyError(someConstructor()) Err2 = MyError(someOtherConstructor()) ) This gives you *more* confidence that the errors you'll receive are bounded by the ones provided by the package. However, there's really no guarantee since users can add their own implementations of `MyError` wherever they want, so you don't know if a `MyError` in some other package is actually bounded by the set of errors in the original. And that's where enums shine. You can set the complete set of values for a type, so your users know that your error *must* be one of them, and if they see that error type in the wild, that still holds. Yes, you can approximate an enum of error types, but all you'll get is a little more ergonomic use of errors without most of the benefits. Having something like Rust's `Result&lt;T, E&gt;` be ubiquitous in the standard library makes it ubiquitous in the community. An `error` interface is nice sometimes when you don't care about the error type, but when you do, you have to rely on conventions, and Go's standard library doesn't hold too well to those conventions (most errors are just `error` and not a type/var defined in a package).
Buffalo is pretty nice. Good docs and great community with very active development.
You can get really everything you need from multiplexers to routes to redirect with just the base net/http package. I would say base HTTP/HTTPS networking from net/http + maybe [https://github.com/go-chi/chi](https://github.com/go-chi/chi) if you want a little extra ease handling routes
The pros and cons of those solutions will depend almost entirely on the context in which they are applied. Do you need a solution that is like rails that is going to do everything for you? Do you want something more like express? Would you rather just implement it all from scratch?
Come on man, if you're going to go to all the trouble of making a video, could you take two seconds to look up what the name of the language is? It's two letters, and uses normal English capitalization for proper nouns. It's written all over the homepage.
Standard library + Gorilla mux gets you everything you need. I'd argue most that come after that is personal (or collective team) choice, and, well - what good is someone else's opinion on a personal choice. That's because most frameworks are built on top of net/http anyways - providing syntactic sugar (and the ones that aren't often do goofy shit for "performance reasons").
Especially if you're coming from express, chi will be very familiar while still sticking as closely as possible to net/http
Hey redditors!! I see that nobody has mentioned Gin. Is Gin not that good?
I would suggest looking in to https://julialang.org. They seem to be moving in to the HPC scene from what I've been reading. There are three things I'd consider when choosing your language: 1. How fast does the code run? 2. How fast can you read/write code? 3. What packages/libraries are provided to me?
Well, exceptions are a nice thing and worked really well making code easier and more correct and programs better and less error prone in the 80s. And the early 90s. Let's skip back to 1988. The user clicked/pressed "Save" and your code starts doing its magic writing 5 files to your 3.5 inch floppy disk. Somewhere during writing the 3rd file in some obscure serialization function your floppy drive reports an error. That was common. Now such an error has two major qualities: 1. It is a hardware thing like "floppy defect" or "floppy full" or "floppy write protected" 2. To solve the error a human user has to do something: Replace the floppy, delete some old files, get some tape to cover the write protection hole. Exceptions are the perfect solution to this kind of error: Your code just throws whenever a problem occurs, the exception bubbles up the whole call stack to your main event loop which triggered the action and now catches the error, displays it to the user with the options "Okay" and "Abort Program". Contrast this with most errors in 2018. Some backend service is not reachable (short network glitch) does not answer at all, not fast enough, has problems, returns 503 because of maintenance, whatever. None of the two qualities of 1988 apply to these kind of errors: Most are not (or at least not permanent) hardware errors and none can be fixed by the "user" of the software (which often is not a human!). There is no top level event loop which can magically fix the error, there is no human. Such errors are handled by carefully retrying, switching to fallbacks, graceful degrading and polite excuses. What makes handling errors with exceptions attractive even in 2018 is the possibility to _not_ handle the error by retrying, fallbacks, degrading, etc. but to simply _ignore_ the error. Bubble it up as far as possible and just log the error. A human can than inspect the logs, and might improve the system. Unfortunately this log-and-forget style is still an accepted way to "handle" errors of 2018. I think it is unacceptable for a large class of software. So unless your software works like 1988s software (i.e. single machine, single user, single task) exceptions are no longer suitable to actually handle errors of 2018. P.S. A lot of software still is 1988 style: Any script, or small task a human operator runs directly from the command line is often such a program and you do have panic and recover at your hands here. 
Would you mind to share some cases where so much efforts are being spent to work around the current limitations? Or even better, you can write an experience report to Go team. I think many progranmers including Go team and me are trying to figure out what the real underlying problem of "generic" is. Use cases will help a lot, thanks.
I am going with Chi. Very basic and strong though. Gin could be also be an alternative.
&gt; Adding a call to the network might require you to run all over your codebase fixing things Yes, but bear in mind that you've changed the behaviour of your function. If you add a new kind of error, then there's a new kind of error to be dealt with and that's a significant change in behaviour of the function and people switching to your new version of your thing should then also update their error handling to reflect that change. &gt; how do I write an interface for that if I have to pre-enumerate every internal error return? How do I do error handling if I don't know what kind of error you return and what types you return? How do I know whether an error is transient or permanent? How do I know if an error is a soft error (like file does not exist or permission denied or busy try again later) or whether it's a hard error? If you design an interface, you also need to design proper error handling. And you of course can use wrapping as well. Such as maybe use type BackendError { Cause error ... } in case it's a (hard) error in the backend and then use other errors for other error conditions.
Use an interface. https://gobyexample.com/interfaces
I am a node developer at work but write go at home. I've found [echo](https://echo.labstack.com/) to be a good mix of new, exciting, familiar, and productive. I think it gets some hate because not everything about it is idiomatic go, but I've enjoyed building a few projects with it.
Could you share full chart please?
I went with a non-traditional stack: - Backend server is gRPC - Frontend is a big single-page vue.js app - We use [grpc-web](https://github.com/grpc/grpc-web) to communicate between backend and frontend Why should you consider this? - It sounds like you want to learn something different, rather than immediately apply it - gRPC is very different than REST - Many major Go projects rely on gRPC: etcd, heka, cockroachdb, kubernetes, etc 
Stephen Grider course is better 
&gt; Each has `info` method but I would like it to be private and have a public `Info` function which accepts each shape and calls the private method behind the scenes. So, instead of `myTriangle.Info()`, I would like to type `Info(myTriangle)`. Why? This seems like an unnecessary indirection to me. &gt; The closest thing I could find is to have an empty interface and then using reflection switch-case to each particular kind but I would like to not loose compile-time type checks. type Shape interface { info() Info } Though you probably want other common behavior in the interface too, so that it's clear what type actually implements it. See, for example, [go/ast#Expr](https://godoc.org/go/ast#Expr). In general, though, without information about the actual, non-contrived problem you're trying to solve, it is very hard to give good guidance on how to solve it. 9 times out of 10 I'd advise *against* this pattern and advise to instead make an interface describing the common behavior you're interested in and use that. *Because* it allows other people to also provide implementations of that behavior and doesn't unnecessarily close you off. But there is that 1 in 10 case and it's hard to say if this is one of them. &gt; PS: The shapes examples is intentionally contrived to illustrate the problem I have. Contrived examples are hilariously bad at illustrating problems :) As shown clearly by my question above :)
As someone who already had a lot of programming experience, some sections were a bit too longwinded for me. But otherwise, excellent courses! And, following these was my main introduction to Go and now I have a job programming in it. So there's that.
+1 for echo, very good documentation and handful of middlewares for you
i would say mux/go-chi are some of the best choices around for a very lean external package dependency list
is gin still actively maintained?
buffalo is great if you want more than just a backend service, as it is more like ruby on rails for go
…or you have to be Linus Torvalds or Ulrich Drepper or Eric Raymond etc :-)
…I'd say it would be better to augment (or fork) https://github.com/russross/blackfriday
fair point
&gt; Support for build systems like Bazel But go doesn't support any build system, why start with Bazel and not something more popular?
As much as I love golang, .. For code reusability's sake you ought to stick with node all the way if you insist on building the backend with node?
Woah! Thanks Todd. Bought your greater commons course. However, I have already completed upto control flow in your Udemy course. Would you suggest to start from the beginning in new course or start from somewhere in the middle?
I think that in the old situation the new slice was created (for which memory is cleared). If it turned out here wasn't enough capacity in s a new backing array is created for which also memory must be cleared. Now the first allocation is skipped when s cannot hold enough items and a new backing array is created which can hold s + the appened slice.
`go/packages` will support Go's native build system (modules) and Bazel, which is the open source version of the build system used internally at Google. Keeping in mind that Google has a huge amount of Go code using that build system, I'd say that Bazel is the second most popular build system for Go. Do you know of any other? Even if people use makefiles or tools like `gb`, those still rely on Go's native build system - they're not completely separate like Bazel.
I think what /u/bastiaanvv said is correct. If the new zero elements don't fit in the original capacity, before you had to make a larger slice (zeroing the memory), make the n-sized slice (zeroing the memory), and then append the second to the first. Those N elements in memory were zeroed twice. With the optimization, the compiler sees what you're trying to do, and realises that the second zeroing is not necessary.
&gt; error collect would be fine if Go naturally gave errors context, like stack trace information for each "bubble". This passage makes me think that you did not grasp the idea of how Go approaches error handling. By advocating for adding more context to errors, you look like treating Go errors merely as _exceptions which need manual propagation._ But Go errors are not exceptions, and Go `panics`—which _are_ the closest thing to exceptions—do have the necessary context. The difference between errors and panics in Go is that errors are _no different from the other values a function may return._ The philosophy behind this approach is dead simple: in the real-world, most of the time the program interacts with the outside world which is constantly in flux, and hence failures to perform some action there must be expected and dealt with—not much different compared to success cases. The simplest example is a server which _stores_ something into a filesystem. It may be an SMTP/LMTP/IMAP server, a FTP server, whatever. When it receives something from a client to store (an e-mail message blob, a file etc), and discovers there is a problem with storing that content—such as no space left on the underlying storage device, there is _absolutely no point in attaching the stack trace to the error generated._ I mean, really. The stack trace is only useful to dump to `stderr` just before terminating the process—because the only sensible way to _process_ it is by eyes of a programmer. You wouldn't want to look at the stack trace somewhere at a point where you would have caught such an error, if you would. So, the only meaningful context to add is something about _what_ was done, and/or what _for._ A very good example of this is the `os.PathError` type used for most FS-related errors by the `os` package. Having said that, I admit that in boring production code it is sometimes useful to have stack trace attached to an error value. That happens in a place where you do not want to `panic` for whatever reason but reaching there definitely means a _logic bug_ in the code. When you need that (very rarely, in my experience), you may use the `github.com/pkg/errors` package or some custom error type which does just that. 
These slides are near unusable on mobile, is this a general bug? It's impossible to scroll them and zooming is messed up too.
&gt;gRPC Wow this is super interesting, thanks for the advice :)
&gt;is gin still actively maintained? Seems like that is maintained, see it for yourself: [https://github.com/gin-gonic/gin](https://github.com/gin-gonic/gin)
That's absolutely correct. You have to override all methods of the embedded object to modify it's functionality.
Yeah, the present tool isn't great on mobile. Maybe I should just be using google slides.
[removed]
Wow I struggled through that presentation on a mobile device and it was pretty frustrating. Ug
The present tool is unusable on mobile. I'm sad no one has fixed it.
Filed https://github.com/golang/go/issues/27026.
Prior to my Gophercon lightning talk, create starter kit and blog post on Twirp - Simple RPC framework in Go. Article [available on my blog](https://www.ribice.ba/twisk/).
echo 
thx to all the responders. it was very helpful for the langage, i decided to go with c langage 
I don’t think there is a whole lot of difference between testing an error and entering a retry loop (if network door) and catching an exception at the higher level and initiating a retry, possibly changing the destination. I would be the exception code is far cleaner and it is type safe. In this scenario you are making a temporary network error an exceptional condition - thus exceptions - so it is guaranteed that it will be handled. Versus the error condition that is probably ignored as most naive developers would think “I’ve never seen this error during testing I don’t need to handle it as it won’t occur” 
My article on [sum types in Go](http://www.jerf.org/iri/post/2917). I however agree with everything TheMerovius said. I've had almost every imaginable combination of things being exported and not exported (technically Go does not have "public" and "private"), so I'm not saying what you're asking for is impossible or wrong, but without knowing the real problem it's hard to help much more.
[removed]
Just found this explanation: [https://github.com/golang/go/commit/6269dcdc24d74379d8a609ce886149811020b2cc](https://github.com/golang/go/commit/6269dcdc24d74379d8a609ce886149811020b2cc)
Thank you.
Stephen Griders course is aimed at people who are adept at another programming language already. Todd McCleod's "Learn How To Code: Google's Go (golang) Programming Language" is exactly what it sounds like, you are learning how to program ALONG with the go language. So it is more a question as to which category you fall into. Do you feel strong enough with JS that you can just have the Go language features discussed and be ready to go? or do you need to review basic programming concepts?
In the time it took for you to create this question, you could have searched reddit (not to mention google) and found the answer to your question 100 times over.
What's this `l=4` business? Where is this documented? I found `go tool compile -help`, which indicates that the `-l` flag *disables* inlining... is this the same flag? If so, what's the difference between 1, 2, 3 and 4?
Why is godoc's command line interface being removed?
&gt; This passage makes me think that you did not grasp the idea of how Go approaches error handling. By advocating for adding more context to errors, you look like treating Go errors merely as exceptions which need manual propagation. Not at all. I'm treating Go errors as things that are utterly useless without manual intervention. 40 bubbles up, someone has a failure of `end of file`, great! What do I do now? Who the hell threw that error, it has no context, there is no information attached, it's useless. &gt; The difference between errors and panics in Go is that errors are no different from the other values a function may return. That's entirely false, imo. They are **very different**. Conceptually yes, they are a value - but calling it a value all day long doesn't help you understand *what* the value is. As in my example above, a plain `end of file` error after many many "bubbles" without more context means nothing. It's akin to hiding all of your return values behind a single, monolithic `interface{}`. See, if I write a func like this: `func() (foo, bar, baz int, err error)`, it is *very* clear what foo, bar and baz values are. The 2nd int is bar, there is no question. People rarely make return values dynamic, where the 2nd int might be bar, it might be baz, or it might be the page number. A dynamic meaning for a return value like that would be a gross interface by most. Yet, that's what the return "value" of `error` is exactly doing. Sometimes it has meaning, and it's great. Other times it has no meaning, and people have to destroy/wrap the original value to actually make the error useful. Honestly your argument baffles me. If what you said was true, then we wouldn't see bare error returns being completely and unidiomatic. Ie, ``` err := foo() if err != nil { return err } err = bar() if err != nil { return err } ``` This is considered *very bad practice*, because it gives no context. The only time this is acceptable is when the error *value* is considered meaningful and important. Such as cases of `io.EOF`. Yet, even in those cases - great, we have an error value, but if it bubbles too far it loses context, and you have no clue who was upset or wasn't expecting an EOF. **NOTE**: EOF was a bad example, since that's not really an "error" usually, but the value in question is pretty meaningless to my point.
Yes. This way I am hardcoding the dependencies I need. What about a way to create a variable that will hold these in build-time? So I will scan directories create the kind of map you emphasized only in build time. Is it possible ever?
I could not find an explanation for this but Go 1.11 release notes say that godoc in further versions will only have web interface. One should use `go doc` for command-line help that time. https://tip.golang.org/doc/go1.11#godoc
One suggestion: Avoid any framework which doesn't use the standard HTTP handler interfaces. The problem with nonstandard APIs is that it can be hard to find someone who knows them in enough detail to answer questions. I've seen people turn up on Slack with a simple question like how to get a custom value from the HTTP request, and because they're using some fancy framework that hides all of that nobody has any idea.
They are not removing godoc. But I do not know what lynx is.
[Lynx](https://en.wikipedia.org/wiki/Lynx_(web_browser\))
echo
As I see, Lynx is a web browser and you can still request `godoc` web pages.
Beego is very popular in Asia. Check it out. It provides a lot of basics for building websites...
This is one of the worst ads I have seen here LOL • What industry is your client working on? • What's the salary range that your client is offering? • Are you offering a relocation package to New Jersey? • What's the name of the "wonderful fortune 500 company"? • What's the percentage of Go that the candidate will work on? • What's the percentage of Java that the candidate will work on? • What's the percentage of JavaScript that the candidate will work on? • And by the way… Insight Global is not the 3rd largest staffing agency 😑
I think it's only documented in the source code. These flags are mostly for developing and debugging the compiler, not for Go users.
Hmm ok. Regardless, I'm quite curious as to what they do.
If I remember correctly, 0 is no inlining, 1 is the default conservative inlining of leaf func calls, and 2/3/4 simply make the inlining heuristic more agressive. I believe mid-stack inlining is now part of the heuristic too. So `-l=4` is often used as a compiler test case, as it might uncover bugs in the toolchain. But otherwise it's not really useful at the moment.
Just wanted to say that both of your Go tutorials / courses were incredible. I really enjoyed them. So, so much material. I watched many parts of it multiple times. Loved the parts you filmed in your pantry and on holiday. Will recommend to anyone new to programming.
[removed]
I'll check out Jon Calhouns after this one for sure. Thanks for the tip. 
Does that apply to httprouter? It's got that Param on the handlers. I've looked at the benchmarks. It seems to meet my needs (lot of small rest APIs on 2 GB of RAM with Docker).
How much code reuse does one really get? I'm honestly asking. I had a coworker that tried this. He hated it (JS all the way to Mongo). I've moved to the Clean Architecture. As a result I don't even validate the inbound JSON. There is a mapper from JSON to Use Case DTOs. The Use Case validates the DTO and says which, if any of the input is bad and how. This presenter maps failure back to the REST API. I don't think I'd want to duplicate (even by copying) the domain logic to the client and on the server.
Would be happy to discuss all of those details in a private message :) 
The post said to message if you were interested. Those are all questions that would probably be answered in a conversation with the recruiter, and I bet they can’t reveal who the client is online due to non-disclosures. Don’t hate on someone for just doing their job dude. 
Yes. I also think `httprouter` is a bad choice because of the lack of HTTP/2 support. It's not like the regular Go routers are heavy on RAM or CPU; you can run entire Go web apps in 10-20MiB, so 2GiB is a huge amount for Go.
dot
Do other routing services (or go) automatically switch from JSON to binary protocol?
&gt; Coming mostly from a Java background [Quasar](http://docs.paralleluniverse.co/quasar/#channels) and [Kotlin](https://github.com/Kotlin/kotlinx.coroutines/blob/master/coroutines-guide.md#channels) impls might interest you.
Whether your JSON is binary or not is an independent issue, you can use any router you like and still send binary JSON. (Or any other data format, like XML or protocol buffers.) However, HTTP/2 is a binary protocol with compression support, which might be what you're thinking of? Go supports that.
I'm new to Go (and HTTP/2). I'm presently writing JSON pushing APIs. Does HTTP automatically create a binary payload?
Python has [multiprocessing Queues](https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes) that are *sort of* like channels.
Erlang doesn't have channels exactly, but it has first class communication primitives much like channels. Plus they work across local and remote processes. Like Go, its concurrency is based on Tony Hoare's [Communicating sequential processes](https://en.wikipedia.org/wiki/Communicating_sequential_processes).
Scala has also messaging between actors.
I think it's more accurate to say that an embedded object behaves in the same way as an unembedded object. It can be wrapped, but not modified.
With HTTP/2, data will be sent across the wire as a compressed stream using [a binary protocol and compressed headers](https://medium.com/@jacobtan/understanding-http-2-and-its-caveats-1e8200519c4c), but you don't have to care about any of that as it's all transparent. If you stick UTF-8 JSON in at one end using JavaScript, you get the same UTF-8 JSON out at the other end in your Go HTTP handler -- but it goes across the Internet in a compressed binary connection.
On my phone, I can't align the slid to the viewport, and if I go to far, I need to go back to the previous slide to try to read the beginning column again.