I saw a select with a channel receive and a default clause. Empty channel == spin loop
That‚Äôs what the integration tests are for.
What exactly are you asking for? What constitutes "proper" organization is subjective. Go has no particular restrictions on where things go, except that all files inside the same folder share the same package and don't need to import each other (symbols defined in `p1/a.go` are accessible directly in `p1/b.go`) 
While I think you‚Äôre exaggerating quite a lot, there is a kernel of truth‚Äîthe Go community in general and this sub in particular have an opportunity to be the most helpful and welcoming of language communities.
I think you are just bring over baggage from the JS world into Go. &gt; Auto-updating of dependencies Are you sure you want that? It always causes headaches. I'd rather updating dependencies be an explicit step that I take consciously rather than something that "just happens". &gt; Statically linked binary compilation That's built-in to the go compiler and one of its best features. What exactly are you adding here? go build main.go &gt; Packaging into a scratch Docker image What is the use of a docker image exactly in this context? You need it with npm/python/ruby because you have to depend on specific versions of the interpreter and libraries to be present on the target deployment system. Go's output is a statically linked binary. What does Docker solve for you?
Since the beginning of Go there have been a bunch of posts, tweets, etc by people trying Go for the first time and then bashing everything about it. It's not just one person that has stated these problems, yet everyone seems to repeat them ad nauseum. This fatigue has made people very terse in their responses while it's not intentional. And yes if someone complains about generics on a post that has NOTHING to do with generics I will downvote it. 
Aaaand like always .. a post about modules gets hijacked into why the language doesn't have ternary operators/generics.
[removed]
Start with the standard library net/http. It goes much further than you think, there‚Äôs less to learn, and you‚Äôll have a better understanding of frameworks afterwards. Also, most Go frameworks are over-engineered IMHO. 
I agree, but my integration tests include testing the my queries against an actual database. Sounded like you were never testing yours
try [https://github.com/gobuffalo/pop](https://github.com/gobuffalo/pop), it uses sqlx and was heavily influenced by ActiveRecord. And it works absolutely fine independently from the buffalo framework. 
It isn't an ORM right? &amp;#x200B;
Recently, I tried \`text/template\` to build queries. Check it out in a series of tutorials I'm recording [https://www.youtube.com/watch?v=ddKB1MQs34Q](https://www.youtube.com/watch?v=ddKB1MQs34Q)
[removed]
&gt;text/template How vulnerable is it to SQL Injections?
First, congrats for (a) finishing a project and (b) exposing it to the public. Especially with "first projects" this sometimes is not easy. * Confusing function: I see deep nesting here but nothing confusing. To reduce the nesting, either try removing else branches by using early returns (not possible here), or refactor the deeper levels into their own functions. * 99% identical files: I ran a quick diff between (1,2), (1,3), and (2,3), and they contain more differences than similarities. So maybe there is not so much to refactor here. In general, if code needs to call different functions with the same signature, consider passing the functions themselves as a parameter. LIke so: func do(data int, doit func(int)) { // note the func parameter // do common preprocessing if needed // call the doit function doit(data) // do common postprocessing here } // define different functions on the same data type func doThis(d int) {...} func doThat(d int) {...} ... func main() { // com do(42, doThis) do(23, doThat) } Just an idea though. Not sure if this fits into your scenario. * Testing CLI commands: No need for frameworks. Test the functions like any other function. If a function `f` reads or writes files, do not pass path strings or file handles to the function but instead just pass an `io.Reader` or `io.Writer`. Write a wrapper function that does the file handling (open the file, create reader or writer, close the file, handle errors) and calls `f`, passing the reader or writer. Then test only `f`. Pass a string reader or writer, or a bytes.Buffer reader/writer , or whatever quick'n'easy reader/writer fits your testing needs. 
[removed]
No. I actually keep using the `$1` placeholders. I do it to add some logic. Check the video.
/u/cengelbracht stole the top comment from the Hacker News post... of course I downvoted it. The fact that I also don't agree with the sentiment of the comment is secondary to that.
Oh is this being worked on again? I tried this a while back but it had issues with complex types, and also couldn't work with go &gt; 1.6 due to not conforming to the newer cgo rules. I haven't tried it since and instead have been manually exporting functions with github.com/sbinet/go-python
I don't either way, but maybe they are the same people? &gt; The fact that I also don't agree with the sentiment of the comment is secondary to that. Downvotes aren't supposed to be for disagreement, they are meant for comments that don't contribute to discussion. The parent comment doesn't contain anything downvote worthy IMHO.
Sweet! I submitted a talk!
Background: I did serious work (like in payed, research or actually used open source) with BASIC, C, C++, Python, Java, .Net and Go. I did work (education, tooling, for fun) in FORTRAN77, REXX, bash, R, TeX. I have used Ant, Maven and Gradle to build Java projects. My opinion on GOPATH is: It's the simplest and most smooth and easiest way to develop. Of course this based on my limited view, resulting from my limited experience with other languages. Limited but not narrow. And of course I recommended to get used to it and "deal with it". Why? Not because I'm an ignorant asshole (at least I hope I'm not) but because there was no (real) alternative. If someone is unhappy with her Maven bases build I could recommend Ant or Gradle (or whatnot monstrosities exist in Javaland :-) but with Go there was no alternative, so the only advice was "deal with it". Like in: Todays supper is bread, cheese, butter and pickles; no alternatives. Deal with it (or stay hungry). To a certain degree you are right that such responses do contain that I do "not want[...] to see something (in this case GOPATH) changed", well simply because I think it is a very good way because if something goes wrong it takes one engineer 20 minutes to find the problem and 10 more minutes to fix it instead of a team of three discussing and fiddling 2 hours to get the build back running. Such a factor of 10 in problem solution time is a game changer (for me). Of course there are problems with GOPATH and these are nicely addressed (if not solved) with modules. The pushback you experienced is real. I push back (downvote, etc) on such arguments/questions because they are frequent and too often are based on an argument like "I use X and this works perfectly fine. Go should do the same." with a subtext of "I never used anything else, my team is 3 developers and all our projects are greenfield developments". So please do not take this personal. It is just that these issues have been discussed a lot, by people with more experience in more technologies and more tools and a quick question does not contribute much to the technical discussion.
Try squirrel https://github.com/Masterminds/squirrel
Doesn‚Äôt have good documentation 
While I agree that you don't need some of what Docker provides for something like Python, personally I still like using it to easily leverage deployment options. Context: I'm talking about building personal projects. Generally if I'm building something I don't really know how I want to host it until after it's already in an MVP state and I'd like to start figuring out how it will actually be running. I don't have a dedicated server to just stick it on, so commonly what I do is wrap it up in a Docker container as I'm building. That way I can throw it up on Heroku, or Azure, or AWS, or gcloud, etc, depending on what I'm doing without worrying about it much. I also do a fair amount in other languages where you do get those additional benefits, and just wrapping everything I do in containers lets me handle everything I build in the same way, which is very convenient.
At that point, why not just use a string builder? Declare the constant portions, and everywhere you do a template if, instead do a real if and concatenate whatever SQL snippet you were going to add. I still think both are significantly less legible than squirrel's query building pattern, though.
is Google really a argument to use golang?
arf feels like a fanboy article, I was hoping some tech-talk :(
thx 
It‚Äôs kind of interesting how almost everyone with a background in web or mobile development straight up ask for a framework to develop projects using Go, as if the language couldn‚Äôt do more than to print a ‚ÄúHello World‚Äù using the standard library ü§î
on and off... For Go &gt;= 1.6, there is still the `GODEBUG=cgocheck=0` trick. by complex types, do you mean `complex{64,128}` or "sophisticated" user defined types?
grpc
You are not going to find something as magical as the ORM behavior of auto-handling json types. 
It's best to use `iota` only when the value never leaves the program. If the numerical value goes elsewhere (including a database) it's best to use explicit values so that removing one (and thus changing all subsequent values) doesn't break your code. For example, const ( HideFromTopUser Scope = 0 HideFromSearching Scope = 1 )
I meant user types, although it's been a while so I don't have an example handy. I vaguely remember problems with slices of user types 
So, OP, it looks like you have to... [starts putting on sunglasses] delve it while delving [the guy from The Who starts screaming]
Problem is not in iota and values never will change. Problem is that Go's enum HideFromTopUser is 1 and in Postgresql it 'HIDE\_FROM\_TOP\_USER' and I want to leave it that way with saving context of value in both ways: in go code and in databases tables.
You don't really need to understand all of the technologies used in a project to start contributing to it. It's better to start installing the project on your computer and use it. You may be able to find some bugs, or some usability issues that you can fix. Knowledge will come later, by usage.
Make a table of strings, indexed with values from enum. 
Yeah, I thought about that. After some research I found this the only way to do it. Thanks!
that looks indeed handy! nice!
&gt; with a minimum code overhead [...] Try focusing on creating the least surprising solution rather than the solution with the least number of lines. Why use integers at all for the constants? Why not just use strings? ``` const( HideFromTopUser = "HIDE_FROM_TOP_USER" HideFromSearching = "HIDE_FROM_SEARCHING" ) ```
I‚Äôve enjoyed using https://upper.io/db.v3/
Yeah, this will be great solution. But I forgot to mention, that's this enum/constants uses in external code like grpc and others, where I can easily convert one enum to another by wrapping them, because it's all the same ints. &amp;#x200B; For now I looking for another converts to externals, it will be easier then dealing with databases.
[RTFM](https://golang.org/cmd/go/#hdr-Download_and_install_packages_and_dependencies)
It's not the same thing as NPM. You can't do `go get install tor `
That's because there's no centralized repository.
I'm actually wondering why npm would not use github as its code repository.
Either: [https://github.com/golang/dep](https://github.com/golang/dep) &amp;#x200B; Or (the more recent way of doing it, but not rly stable yet): [https://github.com/golang/go/wiki/Modules](https://github.com/golang/go/wiki/Modules)
In Go, the idiom is to use domain names to namespace different packages to avoid collisions. In python you can import "foo" but which foo do you get? Whichever one is in your PYTHONPATH. Hopefully it came from a virtualenv which was populated by a requirements file, but who knows. Pypi (pip) may enforce unique library names to at least ensure there is only one "foo" you could get from their package manager. Go tends to not care so much about the specific package name, and just let the entire import path prevent the collision. 
Read newest blog entry: [https://blog.golang.org/modules2019](https://blog.golang.org/modules2019)
Except that you can, you just need to know the fully qualified package name, ie: ``` go install github.com/user/project ```
That's not the way we use npm, cargo or pip It's just now same!
Go doesn't have that concept of a central repository. Not yet, anyway. The idea is a less centralized approach based on the URL (github.com/foo/bar, or bitbucket.org/foo/bar, etc.) Incidentally, there was a weblog post about this today, which will probably help clear up confusion about the current state and future plans: https://blog.golang.org/modules2019
dep isn't really stable either. It has a bunch of issues and work on it has stopped.
"We are working on a new service, the Go Module Index, that will provide a public log of packages entering the Go ecosystem. " From the above blog post. It seems it's coming soon!
You maybe want to implement the Scanner and Valuer interfaces on the `Scope` type so marshaling to/from the db can be controlled by you.
Technically there are differences, but how is the CLI functionally different, and if you can point to a significant difference, why is it a problem for you?
[https://gobuffalo.io/en](https://gobuffalo.io/en) looks promising. &amp;#x200B; Here comes the downvotes, but I honestly don't understand why the go community is so against web frameworks. It makes no sense. People recommend using the standard library, but you will need a better router, you will need sessions management, database migrations, maybe an orm, api generation, templating, assets embedding, hot code reload, etc. All these make up for a framework. So why using bits and pieces from dozen places when you can use a framework that offer you all of these, with documentation in one single place, etc, beats me. It makes me wonder if people who recommend against using a web framework actually ever built something large enough to hit the issues a framework solves. &amp;#x200B; So let me say it, for web development, you will need a framework!
If I missed the mark, I would like to know why. I think the OP should take a bit more time to explain what qualities they are missing in Go package installation. Is it in fact the centralised vs decentralised package repository? Is it the short package name install vs the domain namespace idiom? Is it extra installation version tracking by the project after download? 
Yes, but I need to have converter from string representation to int and copy constant names all over. Or make some magic with stringer generated string and slices. It can be done, but overhead is big.
But with "soon" I would expect at least 6 months, if not more. And I would expect it won't be quite the same as pip/npm either (which wouldn't be a bad thing).
[removed]
there has been some improvements in the slice department: - https://github.com/go-python/gopy/pull/165/files - https://github.com/go-python/gopy/pull/168/files thanks to [ondra](https://github.com/ondra)
For many languages that is the truth though. There aren't many languages I'd like to build a web service with only using the stdlib.
I was frustrated in a similar way and put this together: https://github.com/ae0000/sqlhelper It might be useful. 
One significant difference is the lack of sane versioning and ridiculous global $GOPATH thing.
it might be easy to deal with in postgres, but enums are dealt with differently in different databases and they're not standard across databases, so you might find that they're more trouble in the long-term than using an integer or string. There might be a good way to manage them in pqx since it supports Postgres specific types. I'd look there.
Yawn, why are you beating this horse? Have you seen modules? You might also check out the roadmap for them recently published. Also, I guarantee this was not the source of OP's reaction.
The last couple projects I've started have been outside my go path using the new modules and I've enjoyed them.
A lot more stable than dep! Simple hello world app could hang for minutes while trying to do something in dep. Modules are efficient and seemed to make simpler good choices.
I do get annoyed from time to time realizing that the GitHub repo and npm source with the same name are not the same project because they name is already taken and I didn't notice. There are some important advantages to using a dedicated package manager over source control. Npm doesn't need to worry that the version tag will be in an incorrect format, for instance.
https://github.com/go-chi/chi
I've never had any issues with dep. Use it in a couple of projects.
Read How to Write Go Code and take a look at the stdlib on how to split a large package into files.
Have you considered not having the validation code live in the handler, and where you would put it if not?
It doesn‚Äôt matter where validation code live. It looks bad in any place. I‚Äôd put validation code in the middleware. 
I‚Äôm not sure i agree. Try pulling out the request contracts to structs and define it as a Validate method there. 
I only used it twice, and both times it was unusable / slow. Then I placed an issue and nobody ever replied to it, so I decided to wait for a different solution. The people that worked on it did work really hard, and I appreciate the work deeply even if I think there were some fatal mistakes. I also appreciate the community working hard to help consolidate things on dep. Even Glide was helpful in getting people onto dep. It was a great example of solidarity and collaboration. The issues I saw were: huge non-standard-lib dependencies (thus I wasn't sure it could become the official tool--that was the issue I raised that nobody else joined to discuss), performance (made npm look fast), and it didn't change how GOPATH worked as well as mod (not their fault; mod has the benefit of the devs knowing they could change more about Go itself), and they wouldn't consider additional commands (even one as simple as version to show the version of dep in use, which really annoys me when a project is vital to a toolchain).
This is a good option, I also did it, but sometimes there are cases when one parameter can have different validation conditions in different methods. For example, in one method, parameter is required, but not in the other. In this case, the structures are powerless.
Do you really prefer a smaller namespace which may (or may not!) indicate the repository it comes from? Functionally, I find it to be better. It's slightly more work, and none of us like to type more, so I understand the perspective, but we aren't typing this command again and again, so I'd prefer to have the specificity.
&gt; What does Docker solve for you? a chroot environment, keep-alive and "cloud ready". you're running go binaries in small ["FROM scratch"](https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/) containers anyway.
I've used [https://github.com/doug-martin/goqu](https://github.com/doug-martin/goqu) a few times. It seems heavy, but also very flexible.
If you are using grpc it generates a mane and value map for enums (the map is indexed with int32 though)
The point is F off youre a racist A hole
I just found that and was suprised, pretty handy! Thanks.
[removed]
Those benchmarks are pretty impressive and the rationale is pretty clear. This is exciting.
I was just about to dive into a project that involves a lot of concurrent redis queries, talk about perfect timing!
Pardon my ignorance, but when would this type of parser be used?
That's right. Now -- f–∏—Å–∫ 0ff
String builder or simple string concatenation was what I was doing before. I think templates are more legible than that.
Welcome. I'm always eager to ask this around: Coming from a sophisticated language such as Erlang, what's your first impression on Go's conservative approach with language features?
Awe, little boy
When you want the parser to be easy to understand. https://github.com/protocolbuffers/protobuf/blob/46a48e49aa8357bbeee8040819a35e59880e329a/src/google/protobuf/compiler/parser.cc
Please excuse me, but as I think there is no other ways to source golang web apps rather than [https://github.com/gin-gonic/gin](https://github.com/gin-gonic/gin) &amp;#x200B;
That seems like an issue with how goimports is integrated with the editor, not with the tool itself. Also, this might be possible to speed up with indexing, and the module cache is better suited to that than GOPATH/src.
&gt; not with the tool itself. The two are not mutually exclusive. Either way, a slow tool is a problem. &gt; Also, this might be possible to speed up with indexing, and the module cache seems better suited to that than GOPATH/src. Why? AFAIK currently it's an explicit design goal of goimports not to do indexing. If it *would* index, that would be trivially to solve in either system (you could start by simply storing a list of package-names to import paths).
Why not? It *could* even update the existing tag, though AIUI the Athens-developers are against that (it wouldn't change the security properties though). But it definitely can provide an updated hash for a new release.
The Go parser in is a recursive descent parser.
If it could, then that would probably work out. I just would have assumed that it wouldn't happen in favor of a strict automated only method in an attempt to avoid "moderating", if that's the right term for it.
Take a look at how they solved a similar issue in the stdlib: [https://golang.org/pkg/time/#Month](https://golang.org/pkg/time/#Month) &amp;#x200B; [https://golang.org/src/time/time.go?s=10596:10626#L287](https://golang.org/src/time/time.go?s=10596:10626#L287)
Cool. I may give this another whirl. Thanks! 
I don't think that's really what you mean (or that it'd change anything, at least not dramatically). Import paths will still always be rooted in a fully qualified domain name and there will still be no centralized hosting of Go repositories. The index will provide a list of Go modules, but you can already get a pretty comprehensive list of packages from godoc.org (e.g. using [jq](https://stedolan.github.io/jq/), you can do `curl https://api.godoc.org/packages | jq '.results[].path'`). The Go team made the conscious (and IMO good) decision to not have a central packaging authority. It does make package-names slightly longer, but it also has a lot of advantages - not least of which, that the Go team can't be compelled to take down or change a package. They simply don't have the means to do that. Either way, as the blog post mentions, that decision isn't changing.
For any context free grammar
Go jer–∫ off over your reddit votes. 
Sooo, in summary (a "tl;dr", if you will): - They've been working on the current tools and fixing bugs based on feedback with `GO111MODULE=on`. - Go modules leaving "experimental" status and becoming the default workflow for Go tooling has been pushed to Go version 1.13, from the original plan of 1.12. This gives them more time to work on the next bits that I'll mention, and further iron out the kinks. - They've designed and released a new package to abstract the fetching of meta about a piece of Go code that's compatible with both workflows (GOPATH and Modules): [golang.org/x/tools/go/packages](https://golang.org/x/tools/go/packages) - They're working on a new command line tool to use the aforementioned package to do code querying and inspection, that will also use the Language Server Protocol for more consistent integration with editors/IDEs. - They're improving the breadth and depth of static code analysis available to tools like `go vet`. - They're working on a new **Go Module Index** service to aid in the discoverability of available Go packages, and to help other services (like godoc.org) with listing available packages. - They're working on a new "Notary" service that uses the aforementioned "Go Module Index" to build a tamper-proof signature log of available, public Go packages/modules. - Google is building a module proxy server, not unlike those already available such as The Athens project, that builds upon the existing module proxy design and features introduced in Go 1.11 but with the "Index" and "Notary" features seemingly included. - They're going to improve godoc.org to include features made available by the aforementioned projects. Personally, I'm super excited about this update. I'm happy to hear that they're spending more time to "get it right" and working on tooling (like, a lot of it) to make so many of these higher-level services and features available right out of the box. Fantastic news. üòÉ
I'd use Vue for the frontend as a SPA, or Nuxt (based on Vue) if you need SSR. Then develop an API with Go. If you want to do everything in Go then I don't have a good answer since it's never interested me.
My unit tests test my units. My integration tests tests my assumptions about how my units integrate with each other.
You‚Äôre correct! It‚Äôs not the same, it‚Äôs better in every way. üëçüèª
Those dont matter to me. Doing the right thing is what matters.
Woohoo! The first Go conference in Canada!
It's certainly under-documented. If you feel up for it, you should totally start writing something as you explore and figure things out! There's a lot of content in the go-ethereum wiki: https://github.com/ethereum/go-ethereum/wiki For example, [Native DApps: Go bindings to Ethereum contracts](https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts) is fairly old but still relevant. 
Is this your library? Just curious if you‚Äôve looked at gonum? I know they have a plotting functionality so maybe you could contribute some to there. Looks like a cool library in any case. 
[removed]
The first thing I noticed was that the code had not been formatted. `go fmt` is basically mandatory in the Go ecosystem. Consistency is nice; when I read formatted Go code, I can just parse the logic without paying any attention to the style. In general, the structure seems too "heavy" in proportion to the actual complexity of the program. You could probably write the same program in five files (main+common, plus one file per action), and it would be much easier to navigate than a big nested hierarchy. The massive Makefile is another red flag. I'm guessing that you are aware of this, and that you are using this project primarily as a learning exercise for how to structure much more complex programs. That's reasonable, but my advice is that you're better off trying to match the complexity of your structure to the complexity of your program. Trying to fill a large structure with a small program just increases the amount of incidental complexity, unnecessary abstraction, etc. Your `emojis` package is a good example -- a whole package just to define an array. (With a getter function, for some reason? Why not just export the array?) Better to grow your program's structure organically, refactoring as needed when your files get too large. For CLI flags, I again prefer to keep it simple; most CLI frameworks are overkill. The standard `flag` package is adequate for most programs. If you need subcommands, I wrote [a tiny package for that](https://github.com/lukechampine/flagg). For error handling, `github.com/pkg/errors` is my preferred choice, but honestly anything is fine if your errors are intended for humans rather than code. Even `fmt.Errorf` would do the job. Lastly -- TESTS! One of the primary reasons to introduces abstractions everywhere is to make testing easier. But I don't see any tests here at all! Complex programs need loads of tests because you have lots of moving parts that need to be correct both individually and in concert with the other parts, which of course grows as O(n^2). So if you are indeed using this as a learning exercise, I strongly recommend trying out some aggressive testing to get a feel for how to properly use mockable interfaces, prefer pure functions, etc. (But stick with the standard library, no testing frameworks.) This is way too slanted towards the negative, so here are some other good aspects I noticed. First, lots of error handling with human-readable contexts, which is great; I didn't see any lazy `panic` calls or bare `return err` statements. Good package names: no `util` and no stuttering. Also, I noticed that pretty much every exported identifier had a docstring -- nice! These little details really add up, so I'm happy to see that you addressed them thoroughly.
Thank you for giving feedback! I'm pretty sure that the code... is formatted? There's a pre-commit git-hook that formats, lints, and `go vet`s all the source code. Where does it not seem to be formatted? The `emojis` package uses a getter because I wanted to be able to change the implementation to get emojis from an external API without changing the way it is used‚Äîthe package acts as an abstraction so that the underlying implementation can be modified (I'm not 100% sure I liked the idea of hardcoding all of those emojis in the source code). But all in all, thank you for taking the time to review my code! I will define some tests soon, and consider reducing the Makefile complexity for future projects (I pretty much share the same Makefile for all my Go projects, which is why it's so thorough and large).
That's really interesting. Thanks.
Hi, What I like the most in Go, until now, is the simplicity of the language and the tooling. Erlang is also a simple language but all the power comes from the Runtime System. Go every tool is really handy and easy to use, the concurrency concepts is some what similar with Erlang, goroutines &lt;-&gt; processes, channels &lt;-&gt; mailboxes, but Erlang has several extra-powers "immutable state": we stop thinking about shared memory and focus in the problem solving, pattern matching: easy to understand kind of declarative, in production systems you have supervisions trees to ensure your processes are always running (it seems k8s LOL ) , a shell to inspect running systems and the hot code swap that make hot fixes so easy to deploy. My background is C++ and Java and the use of concurrent primitives as mutex, locks, etc is a way to give a shoot on your foot, and that is present in the Go language (some argue that we should avoid and use channels but for me, a noob, it seems that it can make Go programs more difficult to understand and maintain) So, I still prefer most of the things of the BEAM languages, but Go is really fun to use for tooling and I am still experimenting and getting my foot wet in the language. Next step it will be writing some backend service in Go (small to start) and learn more from the community. 
I appreciate your input. I'm tempted to play with Erlang now :)
For go-ethereum, basically everything starts from the ethclient package in the main repo. Googling golang and what specifically you want to do usually gets you what you need. I‚Äôve been thinking about writing up some tutorials but just don‚Äôt have much time just yet. Using abigen to interact with contracts is usually pretty straight forward. Getting keys to sign transactions is usually a bit more complicated but it‚Äôs doable.
Ha, you're right about the formatting, sorry. GitHub just changed their default tab size or something, so I was seeing 2-space indents instead of the 8-space indents that used to be the GitHub default. Carry on!
Also, I was part of the CPAcademy for a while, which has since gone quiet (though it might come back at some point). I did a guest stream going over how to use Go to access the Ethereum blockchain and basically went over all this info. It's not exactly a tutorial, but it does go over most of the things you mentioned. https://www.youtube.com/watch?v=S2dWr9woSR8
It can be generated automatically: https://blog.golang.org/generate
Ok I don't come from a computer science background and I'm new to Go. Under what circumstances do you write numbers in hexadecimal and binary?
Author of one of the projects RedisPipe is being compared against (radix.v2, though v3 is out now; the benchmarks wouldn't have been significantly different I don't think). As it says in the docs, it seems like most of the benefit is coming from batching in the parallel case rather than the pipelining aspect. It's an interesting idea, and I hope the author doesn't mind if I try to come up with some way of incorporating it into radix. The new API in v3 makes doing something like this in a transparent much more plausible.
I have to wonder why people feel they need to use Redis with go? Redis is a hack needed for python/ruby because they are slow and bloated. If you're using Go, you can just use a global map. Plus with things like gob encoding, you can easily sync your hashmap across your instances (if you have several instances running).
You can accomplish a lot with just the standard library and some libraries. Combine `net/http` with [chi](https://github.com/go-chi/chi) and you get a minimalist framework(like express or sinatra). If you need sessions you can use [gorilla session](https://github.com/gorilla/sessions) etc. Also have a look at: https://gowebexamples.com/
ahhhh, arguiving with others, giving them unwanted advice and calling them bad names are the right things for you. get out of here, I won't ready what you'll reply
The easiest option is to forego the int type and use \`type Scope string\` and set you constants to the postgres values. This is obviously tightly coupled but not hard to change later. Failing that, you need to explicitly map from the Go value to the Postgres value when you insert. I'd do it in Go and not in SQL: func (s Scope) postgresValue() string { switch s { case HideFromTopUser: return "HIDE_FROM_TOP_USER" case HideFromSearching: return "HIDE_FROM_SEARCHING" default: panic(fmt.Sprintf("Illegal Scope value: %d", s)) } } type Foo struct { ID string Scope Scope } func (f Foo) insert(db *sql.DB) error { _, err := db.Exec( "INSERT INTO foos (id, scope) VALUES($1, $2)", f.ID, f.Scope.postgresValue(), ) return err } &amp;#x200B;
Because people have existing Redis installation used from python, ruby, ... and want to access it from go as well?
Lol for calling redis a "hack"
Instead of a direct hashmap access you delegate the hashmap to another process and make a tcp request to it. If that's not a hack, what is?
If it was just a hashmap that would be correct but it is much more than that.
Redis is a network-accessible, persistent, shared datastore for one thing, and it offers way, *way* more than a simple key-value store. It has ordered sets, HyperLogLog, automatic expiration, and even kafka-style streams. I bet you think Postgres is just a hack too, don't you?
Generally not unless you need it. I turn it off in Django. 
This solution a big hack, especially when you know the bad performance of the default Go map. Calling redis a hack lol ... I hope you're not in charge of tech decision where you work.
YES. For the love of god. Use transactions if you like data integrity. A transaction should start when you start processing a request and commit at the end if there are no errors or roll back otherwise. 
&gt;YES. For the love of god. Use transactions if you like data integrity. A transaction should start when you start processing a request and commit at the end if there are no errors or roll back otherwise. How experienced are you in this with sqlx? 
Huh? So you think making a tcp request to another process (potentially on another machine) and waiting for it to do it's own look up, copying the result and sending it back over the tcp socket is FASTER than just accessing your own memory directly? You want to call the shots on technical decisions?
I'm a little confused by your situation... I think you're trying to reinvent the wheel, as all of the concurrency stuff is already addressed in the http package. You just take requests and process them, let the package handle all this complex stuff. Anyway it sounds like a thread pool would normally be used in this situation. There's a set amount of threads (goroutines) that are constantly running and just grabbing off a channel that you feed into. You generally "monitor" a channel by using `range`. When something is added to the channel it pulls it automatically.
If you have Postgres, what does Redis provide you? People use Redis as an intermediate cache to lower the pressure on the database.
Redis offers substantially lower latency than Postgres, even when Postgres isn't under heavy load, so for performance sensitive stuff, it can be a win. (examples include updating/retrieving numeric counters and session authorization tokens) Postgres also still doesn't offer streams, automatically expiring data, etc. Postgres chokes when you get more than a few hundred connections, where a single Redis instance can handle well over 10,000 active connections in my experience.
&gt; The thing I am not clear on is how do monitor this channel that has collected the jobs? Should I spawn n go routines (at startup) all with 'infinite loops' looking for data in the channel? Will this crash the server in anyway? This is sensible, lets you control the number of concurrent operations: ``` const numReaders = 8 ch := make(chan struct{}) for i := 0; i &lt; numReaders; i++ { go func() { for val := range ch { doSomethingWithVal(val) } }() } ``` Alternatively, depending on what sort of resources are required to complete each request, you could look at using a `sync.Pool` to retain the ability to limit concurrency, but avoid expensive overhead in setting up handlers on each request - this entirely depends on what your handlers will be doing. &gt; Elsewhere I read, long running go routines are not recommended That advice is scenario-specific and not well thought out - if you cannot control the number of requests you receive, you have unbounded goroutine creation, which is likely to bring your process to its knees.
You can build a semaphore with a channel: http://www.golangpatterns.info/concurrency/semaphores, use that to limit concurrency. Basically try to acquire the 'semaphore', when you can spin off a go routine to do whatever your doing and have it release the semaphore when it's done. You can use a `select` statement with a default to handle the 'buffer is full' case.
Couldn't you do something like this: ``` for message := range c { processMessage(message) } ``` That for loop will run until you `close(c)`. Have another goroutine feed messages into the channel as they become available. The goroutine will block (sleep) until you can read from the channel. Whoever said "long running goroutines are bad" is not very smart. Your Go application will have at least one goroutine no matter what, and GO apps are perfectly capable of running for extended periods. *Maybe* they meant "Be careful about memory leaks" or something but that has no intrinsic connection to goroutines, that's just standard optimization concerns.
Thanks. The challenge for me is that I am kicking off an external api request which rate limits the consumer (my go app) and I want to be able to queue those requests and call the api within the bounds it set. This is not handled by the http package. Your suggestion of 'constantly running' is what I was thinking (my attempt was just run the an infinite loop inside the go routine and keep looking for data.. I just was not sure if I had 5-10 such infinite loops running, would it cause any big performance issues. Per /u/pdffs comment above, it looks like that is not an issue or not something i should optimize before it becomes an issue.
Just to complement the answer. This only answers the 'spawn n goroutines at startup'. The part where you write to a DB and retry later makes the whole problem a lot different: now instead of just the channels you also want to look at the DB. Anyway, I would suggest pushing this to the client side by returning an error and keeping your design simple (you may also implement retrial on the client side). Anyway, if you want to check whether the buffer is full or not you need to do a nonblocking write to it. Something like val := "hi" select { case ch &lt;- val: fmt.Println("some goroutine picked this val") default: fmt.Println("no goroutine ready to pick it") } 
It sounds like you are overthinking it. Make your requests, and if you get back a rate limit error, just try again before you pick up a new job. Don't worry about trying to rate limit your outgoing requests. 
Have you looked at this article? Just glancing it over looks like it might put you on the right track. https://www.opsdash.com/blog/job-queues-in-go.html
I use transactions pretty liberally. I try to only keep them open as long as they need to be, but see no reason to avoid them. Pretty much every personal project of mine has a function that looks sorta like this (with some variation): func Transact(fn func(*sqlx.Tx) error) error { tx, err := PSQL().Beginx() if err != nil { return err } err = fn(tx) if err != nil { tx.Rollback() return err } return tx.Commit() } That ends up handling the usual rollback/retry code and I can handle the error like I want outside of it at the callsite. So using it is as easy as. err := db.Transact(func(tx *sqlx.Tx) error { res, err := tx.Exec(`....`) if err != nil { return err } // moar execs or w/e return nil // no errors! :D }) if err != nil { // handle the error from a full failed transaction here } 
If you need to reliably action all requests, but have an upstream rate-limit to deal with, I'd suggest you queue all requests and use a shared rate-limiter on your consumer routines so that you can stay within the specified rate limits. If you receive a failure (assuming the backend is idempotent and/or you can discern which error types are transient), and strict ordering is not required, you may choose to simply push the request back onto the queue in case of a rate limit exceeded response. This is much nicer than hammering the remote end, and more performant for bucket-style rate limiters or similar than some other options.
This package may make your life a little easier: [https://github.com/elgs/gosqljson](https://github.com/elgs/gosqljson). Use transactions when you need it. If there's anything you cannot afford to lose integrity, use it, otherwise, no. My guideline is don't use it unless you really need to.
Agreed.
Comparing Go modules to dep, the speed really is a killer feature. 
&gt;Disclaimer: By reading you may have the delution that I know a lot. No, I am a lazy software construction worker, who is trying to get things right the first time, so that he is not condemned to redo it. Good on you for taking time to explore some new styles. &gt;The thing that caught my eye is we do not need to spin up our web server to work on the business model. You can do that without strictly following clean architecture. &gt;I also agree with him on the point that MVC was originally created for small GUI elements. MVC doesn't fit the web 100%, but there are lots of engineers who know the pattern -- which is important. Knowledge has to reach a critical mass before it can be adopted. Too much new stuff is scary -- not because it doesn't work, but because it might mean less agility for your team. &gt;And it also seems to be true that software architecture should not be centered around web and database. Database and web should be add-on to our business process. I disagree, at least for websites. Most websites are fundamentally a wrapper around one or more database engines. Most business logic can be done faster and better with well-written queries and a powerful database. It's slightly less flexible but far more efficient. Developing search functionality with Elastic is way easier and usually way more efficient than a custom implementation. Using an off the shelf notification queue is usually easier and more effective than writing your own. What I'm saying is that the implementation of an application should take as much advantage of its environment and dependencies as it can. If you find something so much better than MySQL, Postgres, or Elastic that its worth switching out your existing engine -- than its worth doing a heavy lift on your application. Otherwise you are only using a tenth of your power, and writing extra code to fill in the gap. Anyways, thanks for the reply and I'm glad to see people experimenting. That's just my $0.02. Take it with a grain of salt and trust your gut.
For sure - I'm finding it's much easier to define now that I'm graphql'ing everything. With RESTful updates, I'd frequently call several POSTs, PUTs, and DELETEs to really do "one thing" from my client POV. Each is a separate request so not practical to use one transaction before, and frequently there's only a single SQL statement involved so a transaction is irrelevant. Linking the transaction to one gql mutator call is a lot easier to manage and more convenient to write, since I'll issue a bunch of UPDATE, INSERT, and/or DELETEs and can commit them all once the mutator's finished.
&gt;For sure - I'm finding it's much easier to define now that I'm graphql'ing everything. With RESTful updates, I'd frequently call several POSTs, PUTs, and DELETEs to really do "one thing" from my client POV. Each is a separate request so not practical to use one transaction before, and frequently there's only a single SQL statement involved so a transaction is irrelevant. Linking the transaction to one gql mutator call is a lot easier to manage and more convenient to write, since I'll issue a bunch of UPDATE, INSERT, and/or DELETEs and can commit them all once the mutator's finished. I'm actually planning on using graphql for my application, so your post really helps me! Thanks! &amp;#x200B;
Thanks, /u/pdffs and /u/redimkira. This makes sense. I will start with this as the initial design and see if I run into any issues with testing before I add any libraries or patterns that I don't understand. 
Redis only works reliably etc if you have one instance of it that all your application instances connect to. My original question still stands. Why not instead design your application so you only have one instance of your application running in Go? Instead of dedicating super hardware to your redis instance and cheap hardware to your many application instances, just allocate the super hardware to your application instance.
A single instance application can never achieve high availability, for starters. Secondly, even an efficient language like Go does not guarantee you can fit on one server. StackOverflow (et. al.) is written in C#, which is similar in performance to Go, and they famously use very few servers, but it's still a handful of servers, not one single server. Maybe if you're just a startup or a hobbyist you can get away with it, but larger companies can't just run their application on a single server. I work for such a company, although we primarily use Rust, which is even faster than Go. Redis Cluster may not be worth much, but a single instance can handle a positively ridiculous amount of load, and you can have read replicas that are ready to be promoted to the new master at a moment's notice. The nature of Redis also makes it really simple to shard your application across multiple unconnected Redis instances as needed at the application layer.
Stackoverflow serves the entire web so it's a very different story. &gt; But larger companies can't just run their application on a single server. Depends on how you do it. Unless you're running at the scale of Google/Youtube/Facebook/Twitter/Stackoverflow, then one server should be enough for you. 
You were wondering why people used Redis. StackOverflow also uses Redis, by the way. Large, real world applications are an answer. The nice data structures and persistence it offers are others. If someone prefers NoSQL, Redis is like the ultimate NoSQL database. Super simple, super fast. Until FoundationDB was open sourced, that is... so it'll be interesting to see what, if anything, happens with FDB. Go maps don't offer persistence, which immediately makes them irrelevant, let alone the other features of Redis. They're great for things that they're applicable to, of course, and I'm a strong believer in keeping your application as simple as possible. If you can get away with a single server and only using native Go maps, then go for it!
I'm actually handling mine like this: &amp;#x200B; `func InsertProfile(firstName string, lastName string, handle string, phoneNumber string, dateOfBirth time.Time, currentAge int, gender string, profileBio string, profilePictureURL string) uuid.UUID {` `tx := db.MustBegin()` `bldr := lk.Insert("profiles").` `Set(` `lk.Pair("first_name", firstName),` `lk.Pair("last_name", lastName),` `lk.Pair("handle", handle),` `lk.Pair("phone_number", phoneNumber),` `lk.Pair("date_of_birth", dateOfBirth),` `lk.Pair("current_age", currentAge),` `lk.Pair("gender", gender),` `lk.Pair("profile_bio", profileBio),` `lk.Pair("profile_picture_url", profilePictureURL),` `lk.Pair("c_score_record_id", InsertCashScoreRecord(tx)),` `lk.Pair("w_score_record_id", InsertWeeklyScoreRecord(tx)),` `lk.Pair("at_score_record_id", InsertAllTimeScoreRecord(tx)),` `).` `Returning("profile_id")` `qry, args := bldr.NamedQuery()` `stmt, err := tx.PrepareNamed(qry)` `if err != nil {` `panic(err)` `}` `defer stmt.Close()` `profile := Profile{}` `err = stmt.Get(&amp;profile, args)` `if err != nil {` `panic(err)` `}` `tx.Commit()` `return profile.ProfileID` `}` &amp;#x200B; Would something like this work in contrast to yours?
This is the approach I would take. Additionally the client request handler can just block until an API connection comes off the channel unless something fancy is needed. You wouldn't even need the select.
Long running goroutines are perfectly fine. The Go scheduler can handle millions of concurrent goroutines... it's *really* not even a performance consideration if you have a hundred.
I believe the enterprise version supports geo-replication with row-based granularity - does the community version supports geo-replication too (just less granular) ? I'm considering using CRDB as well for a service that must keep absolute correctness (it would be better for us to become unavailable than be wrong). Performance would be nice but not a deal-breaker. How has been your experience running and maintaining CRDB? Was it stable? Fast enough? Any recommendations?
We use couple of dozens servers just for front API, and there are a lot of others. And we have Redis Cluster on other couple of dozens smaller servers. 
&gt; I hope the author doesn't mind if I try to come up with some way of incorporating it into radix I doesn't mind. I there were such library year ago I wouldn't write this one. More good libraries is better for everyone. &gt; it seems like most of the benefit is coming from batching in the parallel case rather than the pipelining aspect. It came from both. The way writer doesn't wait for answers to arrive helps significantly reduces latency compared to naive batching. Or you mean batching could help even if many connections used instead of one? I think, yes, except extremely high request rate (but such request rate is not practically possible). &gt; radix.v2, though v3 is out now; the benchmarks wouldn't have been significantly different I don't think I need your help. I saw v3 is out, but when I tried to replace v2 with v3 in the benchmark it performed awful in parallel benchmark. I really think it was my fail and I missed some important config option. Could you sent pull request with correct benchmark against v3 (replaced v2) ?
The documentation you're looking for is here [https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts](https://github.com/ethereum/go-ethereum/wiki/Native-DApps:-Go-bindings-to-Ethereum-contracts) I've been able to generate bindings, deploy contracts, and test my contracts with the SimulatedBackend following this guide. They are really a great way to test a contract, you can even choose when to mine a block in the middle of a test, for integration testing.
Our setup has more than dozen of api servers. We use two-layer cache: small in-memory cache + redis. Redis Cluster is deployed on other dozen of smaller servers, and it is used not only as a cache but as volatile storage as well (ie data that could be lost in case of disaster, but should not be lost with every deployment of API). Therefore our cache have to be out of process: first, it simply doesn't fit one server memory, second, it should not be emptied on every deployment. Yes, you could reimplement redis (and I dream to) . But what's the pount? 
When you work with binary data (like images) or bitmasks, obviously.
Generally use a transaction around every set of database modifying operations. That'll make it easier to keep your data consistent in case of errors, and (on decent databases) be significantly faster. If you're just reading then there are some advantages to wrapping all your selects in a transaction, but they're pretty minor for a typical webapp. It doesn't hurt - at all - to do all your database work inside transactions, so if you're not sure, use one. Just don't keep a transaction open for any longer than you have to. All the SQL access libraries support transactions well, so there's no need to use any specific one. (sqlx just adds some helpers to the stdlib db/sql - but they're very handy helpers).
&gt; I can create the directory fine, but I am stuck on the creating and writing the files. Stuck in what way? I am going to give you some feedback, but it is mostly my opinion. ``` func createModuleDirectory() { var _, err = os.Stat(moduleFullPath) if os.IsNotExist(err) { os.Mkdir(moduleFullPath, 0755) if isError(err) { return } } fmt.Println("===&gt; done creating module directory") } ``` You can replace all that with `os.MkdirAll(moduleFullPath, 0755)`. It does not error if the path already exists. ``` g.Go(func() error { err := os.Stat(moduleFullString) if !os.IsNotExist(err) { return err } file, err := os.Create(moduleFullString) if err != nil { return err } defer file.Close() _, err = file.WriteString("#" + moduleFile) return err }) ``` You can also return early, and prevent nesting a bunch. I feel like this is generally easier to read/reason about. I also like to defer my Closes, this way if you want to add anything else to the file in that same function you can just add it at the end without worrying about where the close is, and opening/closing the file is close together, so it is easy to check that you dont have a file leak. I would also recommend that your top level functions (createModuleDirectory, createFiles, createVariablesFile etc) return errors. If createModuleDirectory fails, then it is unlikely that you want to continue with createFiles, but there is no way for your main function to currently exit processing with a warning/error message. Then, assuming you are looking at high performance (based on you wanting to do concurrent writes), also look at the `bufio` package. Go's files are not buffered by default, so you can get a big speed increase on small writes by wrapping it in a buffer (`bufio.NewWriter`). Just remember to close the buffer before the file so that everything gets flushed. 
I forgot one Erlang super power: Erlang Distribution, that consists in a having a cluster of nodes interconnect enabling you to send messages between processes in a transparent way (local or remote does not matter), more you can even monitor nodes that are removed from de cluster and act on that to adapt. It's a Super Power: This video in Elixir shows the power: [https://www.youtube.com/watch?v=lxYFOM3UJzo](https://www.youtube.com/watch?v=lxYFOM3UJzo) 
Just a comment on your code; you seem to be using panics when you should be returning errors. Is it really reasonable for the program to crash when a database insert fails?
Nah I‚Äôm aware, but this is just for testing purposes. Im definitely going to be returning errors
Okay, great.
Do I seem to be using transactions properly though?
I am not the author of glot. I also tried to leverage gnuplot: - https://github.com/sbinet/go-gnuplot But gnuplot can only be invoked, not linked against, there's no API, no FFI. It's not a pure-Go solution. That's why I prefer [Gonum/plot](https://godoc.org/gonum.org/v1/plot). It's pure-Go, go-get-able. Bonus point: it's all BSD. Also, one could imagine having a gnuplot-like REPL on top of gonum/plot thanks to https://godoc.org/modernc.org/plot#hdr-Parsing_scripts (that can build an AST from a gnuplot script)
I haven't worked too much with databases so I'm not the one who should comment on correctness. At a quick glance comparing your code with others' in the thread, however, you seem to not do any rollbacks on error.i imagine that could be an issue.
What is the point of using an HTML template language that doesn't have automatic context specific escaping? (Especially if there is a safe and easy to use one in the stdlib)
Having multiple servers in multiple datacenters helps avoid issues that affect a datacenter, leading to higher availability. Taking that a step further, if you put your servers in different geographical locations then you'll be even less likely to have an issue with availability. It's just good practice these days for production applications.
Super clean! Thanks. &amp;#x200B; Tip: to build go-bindata with Go 1.11, remember to prefix GO111MODULE=off like &amp;#x200B; GO111MODULE=off go get -u github.com/jteeuwen/go-bindata/...
Generics don't slow down your code. They're just hard to implement when it comes to golang. These are two totally different things/aspects.
Check my edited question.
I'm not familiar with C#. What is faster in C#? Any programs or benchmarks you can point to?
&gt; What makes it lose to C# in terms of speed? Because benchmarks bench the performance of spherical horses in ideal vacuum. 
Change Java for Go: https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/csharp.html
When removing the panic() calls, don‚Äôt forget to add a rollback() call.
It‚Äôs awesome thing, but I guess it‚Äôs very risky to use in production such project, built for learning purposes 
&gt;language with less features and complexity That is exactly the reason why. Go is easier than C#. You can do less low-level optimizations with it then with C# or other languages. Take Rust for example: It obliterates C# in terms of speed, but it is even more complicated.
[removed]
There's absolutely no relationship between supporting generics and runtime speed. Where did you get this impression?
Check out [sqlboiler](https://github.com/volatiletech/sqlboiler/).
Gitignore pls /vendor/ .idea/ .vscode/ **.log Etc No one wants to clone your whole vendor folder
Actually section ‚ÄúWhy‚Äù in the readme 
I actually need to fix it, something changed with go 1.11.3 where the ... Doesn't work anymore. 
As we all know there are just two relevant metrics in programming languages: 1. Does it have generics? And 2. How fast is it? You _can_ _not_ use a language without generics and if your language is not the fastest or at least the second fastest in some random benchmark you _should_ _not_ use it. 
Server side: std lib + gorilla Client: Vue + vuex + Vuetify
Yep, I'm already using it in production, and I created it not just for learning purposes but also for production usage, each day I'm developing it.
Simplicity doesn‚Äôt indicate performance. Unfortunately that website is a trash fire and there is no way to navigate to C# vs Go (only C# vs Java, F#, or C++) so I can‚Äôt say more.
No thanks, I‚Äôm not really interested in ORMS
In this case, how do you plan to handle hitting that rate limit? What if you hit it consistently for a short amount of time even?
I see! Okay thanks so much!
Wow nice! Then I think better to mention it somewhere in readme
One example of a long running goroutine is the `main` goroutine. That is to say, `main` itself is "just" another goroutine. Long running goroutine so are totally fine...that said I could see an argument made that they shouldn't be long running and instead just be spun up as needed to save memory and make things less complicated. But that would be a general consideration instead of a rule.
According to the website you provided, Go actually doesn't lose to C# in terms of speed/mem usage. Were you looking at the C comparison? Here are some of the numbers for benchmarks that have both C# and Go entries: *Mandelbrot: Go-5.47 s, C#-5.54s (and go uses half the mem 31k to 67k) *Pidigits: Go-2.04s, C#-3.07s (8k mem for go, vs 37k for c#) *Reverse-Complement: Go-4s, C#-3s (800k mem for go, 1,035 mem for c#) C# beats go in Reverse-complement execution time (not memory) and if you look at the CPU profiles it looks like the Go version is single threaded and the C# version is parrallelized. Which metrics were you seeing that said C# was better across the board? Note: It's good to keep in mind that that site is just toy programs that random people have uploaded, check this disclaimer of theirs on the front page: &gt;We are profoundly uninterested in claims that these measurements, of a few tiny programs, somehow define the relative performance of programming languages.
What does this have to do with go? The benchmarks on the page you've posted are for C#, C++, F#, and Java.
You are right. Do you know why C# beats Go in reverse compliment?
I suspect it's because the C# version makes better use of all 4 CPU cores on the benchmark machine. (All 4 in the CPU profile have higher usage for C# than for Go) 
&gt; Could you sent pull request with correct benchmark against v3 (replaced v2) ? Sure! I'll try to do that in the next couple of days.
It's mostly just code generation, but suit yourself.
I'm struggling to find a pure stdlib go Rest server, and I would like to find out an answer to this question too
Is there any benefit if you are only updating a single record? My understanding has always been that they should be when you need to update records across multiple tables, but I‚Äôve been in mongo land for a while.
What's the motivation to use a pure single-language solution? Is it only to avoid writing javascript?
Browsers don't yet have a way to modify the DOM without JavaScript. This is true for all browsers and all languages. The closest you get is using WASM, but that cannot edit the DOM yet, so you still need to talk to a bit of JavaScript. In a couple years you'll probably see this become possible in Go and the other languages that support WASM (C#, Rust, C, etc). You can get close with WASM, and you might find that to be fine, but it's early days for that and I wouldn't recommend it for important production work touched by a lot of people due to changes being likely. I tend to use standard library Go for the backend and Angular for the front.
https://github.com/bnkamalesh/webgo ?? ü§î
I mean more an "implementation", which was meant to mean "framework-less", but thanks :)
If you are looking to write an elaborate http router/server using only the stdlib, this might be the perfect article for you: https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html
Wow, thanks! 
To avoid context switching when doing both frontend and backend. To share code between frontend and backend easily. To develop frontend in well designed statically typed programming language 
I've been using Go (labstack/echo router) and Go templates for my web app I'm making. I loathe JavaScript, so I'm using it only when I really have to avoid hitting the server and refreshing a page. I use Bootstrap modals and some jQuery when needed.
Use the right tool for the job. As much as I like Go, Javascript is the language for web development. You're only going to get frustrated unless you're building year 2000 web sites complete with 3d rotating buttons.
Gopherjs has vecty which is kind if like react. One caveat is that gopherjs code is super bloated. Even with tree shaking and compression, my JS files are still huge. I'm actually in the process of rewriting a system from gopherjs to vanilla js due to the file overhead.
You only need transactions for multiple SQL statements. A single SQL update will be atomic, assuming you're using a real ACID database like PostgreSQL.
You could look at the Golang to JavaScript transpilers. I'm new to Go when it comes to actually building something real (not play projects), but personally I wouldn't do that for now unless it's just for fun. If you're considering doing something professional... If you really want that full non context switching experience, just do full stack JS (it's more than good enough for most web applications). If there are aspects of your application which node cannot fullfil on the backend. Use a pattern like CQRS which will allow you to use Golang (or any language) for specific services / endpoints) which require it's individual language benefits and JS for the rest where you don't. Or just deal with two languages. Or you can do as much as is possible with go templates and rely on JS as little as possible. You'll likely still want it for asynchronous browser stuff though... 
If you want to learn authentication /authorization I sudgest you look into auth0 ghithub repo, they have good examples. Never heard of squares but if it respects the standard it is easy to adapt the code. https://tools.ietf.org/html/rfc6749
When I was super new to web development this was my thought too, I tried to learn JavaScript and Node because I thought it would be best to do everything in the same language. But I have to say, there's a good reason there are server languages and browser languages, and Go being a server language, I really don't think I'd want to use it in the browser. I'm not in love with JavaScript's ever bloating ecosystem but it does what it's supposed to do quite well.
I wouldn't use any framework for the backend in go. Http is very well supported by go and you have an interface equivalent to what a microframework would give you (like flask in python) If you are looking for a big framework with a lot of magic I would use Ruby on Rails or Django. If I want to design my software the way I want, I wouldn't use any framework. Then, on the frontend I would use ReactJS and send json over the wire to my go service.
I understand your desire not to context switch often, but the additional clumsy transpiring of Go to JS is not worth it. I forced myself to learn enough front end stuff to get by and build side projects myself. Just pick React or Vue and find a scaffolder which generates most of the CRUD for you and you can just edit/add stuff to it. There are thousands of templates for homepage, dashboard, custom forms etc, use them
WASM is 100% capable of manipulating the DOM. \[There's a library and everything.\]([https://github.com/dennwc/dom](https://github.com/dennwc/dom))
Sounds like you should try it out. You'd be a good fit with those requirements. It's stable and fast enough. We are still using it, but in a smaller project right now. Check out "follow the workload" crdb functionality.
The C# version does use threads. Each sequence is performed by a worker thread. I¬¥m sure you could give the C# version a better run for its money with some judicious optimizations and goroutines.
Thanks, I‚Äôll check it out!
Not sure what you mean... There is a pure stdlib HTTP server and pure stdlib JSON and XML encoders. Use those and you can create a REST server. Not sure what you're really "struggling to find" here.
Overrated. Using the best tool for the job will save you more trouble (even when the best tool for front end is still JavaScript). I really wish I could use a statically types language across the board though...
My [scripting language's playground](https://deedlefake.github.io/wdte) uses WebAssembly to run the interpreter entirely on the client's end. It used to use GopherJS, but I ran into [some problems](https://github.com/gopherjs/gopherjs/issues/705). That being said, it uses React for the actual interface. Like other people have said, I don't know if doing top-to-bottom pure Go is worth it right now. Maybe one day, but not yet.
Ok, will do, Thank You
It seems one would need to rewrite the entire [Square Connect SDK](https://docs.connect.squareup.com/sdks) in Go (with permission of course). It, therefore, goes beyond just *translating* the guide to achieve what you want. 
TypeScript is pretty nice, and basically a zero cost layer on top of JavaScript that can be incrementally adoptedz
Use typescript if you want static typing. The work you do at frontend and backend is usually quite different so you won't really find a lot of code you can reuse.
Server/browser semantics and architecture are different enough that, even in the same language, you can't avoid context switching. Using a transpiler with js libraries (let's be real; you're probably going to want/need js libraries) forces you to convert js docs into Go docs in your head, moving the context switch from a high level to an inner loop.
I don't really like JS development ecosystem. It is so bloated with different stuff, Elm ecosystem looks nice on the other hand, but comming from OOP background is kinda hard to work with a pure functional language.
I mean more about best practices, architectural patterns, how to use the standard library without having to rely on frameworks at all. So far I haven't found anyone talking about how would be a proper architecture to build a REST server using only the stdlib, since it is my understanding that go aims to provide a "batteries included" standard library, and the net/* packages are tailored to web server/client developments.
It's fairly possible as I've been researching using it for a project in which browser support isn't an issue. There are a few poorly-documented (because they're very immature) DOM manipulation libraries out there as well some stdlib support: https://github.com/golang/go/wiki/WebAssembly#interacting-with-the-dom You can also write [entire Qt-based desktop applications and deploy them to the web](https://therecipe.github.io/widgets_playground/) but that's stretching the definition of web development.
It's perfectly possible to use wasm and avoid js, though. The latest versions of Go support wasm. On .NET, Blazor can be used to achieve just what is asked.
We currently utilize a Go backend. Using Go templates (https://golang.org/pkg/text/template/) to generate HTML is a good option for simple web pages and forms. However, you are limited to static, server rendered data. If you are build a complex frontend though, I would recommend decoupling the Go backend service and a JavaScript solution.
The same can be argued about the go ecosystem: dependency management can be difficult, it's difficult to search for packages because there's no one location to search for them. But that isn't a good enough excuse not to use Go. Just as your argument is not a good enough one not to use javascript.
Who said they are working on it? I believe that was just a maybe. I don't think anyone from go officially said they are building anything for right now.
I found that claim deep in another thread here on reddit on the subject that popped up via Google while doing some research so it would be difficult to dig back up. There were some links to issues with some talk on the subject. I'm not going to be able to sit down and look for it today but if I remember when I'm done feeding roosters to bald eagles I'll see what I can dig back up.
They ask specifically about square oauth though. for that you could just use a oauth go library and it'll work fine. then you could just call all the rest endpoints directly without having to rewrite the entire SDK. You'd only have to rewrite the SDK if you wanted to be able to call the endpoints as objects/function calls rather than through rest calls directly.
Yeah, that works. I reasoned the OP wanted something very similar to what is available in the documentation. Thanks though. 
You may just be overthinking it. You can just write a ServeHTTP and run with it. Lately I don't even use the standard mux except for prototypes, it's just unnecessary. It only saves you like two lines of code per route anyway.
Yeah totally. just figured i'd give my 2-cents since they said they were new to go. Didn't want to overwhelm them all at once!
&gt; To share code between frontend and backend easily. This is a bad anti-pattern and will end up with a tightly coupled front/back ends making the program hard to maintain. If you do go with using something like gopher you should keep it in a separate repository and treat it as a separate project. 
There‚Äôs a lot of potential for reuse of validation code in my experience doing this with a node backend, since you prefer to catch errors in the frontend but can‚Äôt trust the client and just also check for them on the backend, but beyond that not much was shared. I suppose it would be cool to work with shared classes and such but something like protobufs might fit the bill better than choosing the entire language for that benefit.
Because performance is an ultra-complex multi-variat issue that cant be explained by a single issue such as genetics. At the end of the day there are three groups of languages: 1) Those fast enough for 100% of all code. C, C++ and assembly come to mind. 2) Those fast enough for mid-volume applications and lower, perhaps 99.99% of all code. Go and everything on the JVM. 3) Those fast enough for everything else, perhaps 99.9% of all code.
I would encourage you to accept that Javascript isn't going anywhere and just embrace it for better or worse. You're kind of limiting yourself unnecessarily by applying these constraints.
I'd say your requirement is a little ahead of it's time. I could imagine that in time, there will be WASM based Go libraries that let you do everything that the likes of React and Angular would. For now though, AFAIK there aren't libraries like that. WASM efficiency also isn't where at where it is for other platforms Go supports. But that will come too, in time. So if you really want a solution that allows you to use Go for web development, you'll need to wait, or write one .
No, it really can't. Read [this article.](https://blog.scottlogic.com/2018/07/20/wasm-future.html) You're looking for the Host Bindings extension to the WASM spec, which is still under development. By necessity, the library you linked must use JavaScript under the hood. It could be relying on the JavaScript that Go gives you for WASM applications to make them work at all, but I assure you there is JavaScript in there somewhere.
Awesome work! Would it be possible to skip shipping a full Node (ie. 2nd JS implementation) and drive the Chromium instance directly from Go?
This library is trying to be simple as possible: https://godoc.org/github.com/shuLhan/share/lib/http
The language isn't as much the context you're switching is it is browser and sever.
Thank!, I'll check it out
After some more thorough investigation of the GraphQL documentation, this should probably be solved using graphql directives that are used for code generation.
Force push will have a different commit sha1, so the "version" (as in "module M at version V has file tree hash H") would be different. Now it might be that someone made a mistake, tagged it, then realized the mistake, removed the tag and *reuse* the tag for the corrected version. In that case the "version" is the tag and the hash will change and breaks everyone. But the simple solution here is that you should use a different tag on the corrected version, instead of reusing the old one.
Use Angular 2+ for your front end. TypeScript is not that far a cry from Go in terms of a context shift. It's still there to an extent, but you'll find a number of similarities, such as passively satisfied interfaces. The Angular framework has its own learning curve, but so does any framework and once you figure it out, you may - like me - decide that it's rather brilliant (as opposed to AngularJS, which was rather not).
Yeah, that make sense, and handles my last example.
&gt; Either way, a slow tool is a problem. I don't disagree, I just didn't think of it as a big one. &gt; [...] AFAIK currently it's an explicit design goal of goimports not to do indexing. I wasn't aware of that.
I've never understood the 'context switching' position. I'm not sure if I'm just such a polyglot that the impedance is low or what. I also haven't ever found myself wanting to share code between the frontend and the backend, but that might have more to do with how I tend to structure my code or my relative inexperience writing complex frontend web applications. However, \*I do understand not wanting to write JavaScript\*, but I've been poking around TypeScript lately and it seems really nice; install VSCode and you'll be productive in an afternoon.
even when you don't explicitly start a transaction, every single query you run in a database like mysql runs as a transaction (it's just a one-statement transaction, instead of several statements). [https://dev.mysql.com/doc/refman/5.6/en/innodb-autocommit-commit-rollback.html](https://dev.mysql.com/doc/refman/5.6/en/innodb-autocommit-commit-rollback.html)
I'm curious to see how things shake out in the wasm era. In particular, is it worthwhile sending a 3MB runtime down the wire just to write code in Go? Further, what kind of DOM manipulation ergonomics will Go be able to achieve? The examples I've seen so far don't inspire.
IIRC there's a syscall/js package that it uses for this.
Thanks!
yep, which means that every DOM manipulation is running a small chunk of JavaScript code... it's not pure WASM. Which is fine. Host Bindings will remove the middle man eventually, but let's not overstate what WASM can or cannot do.
I defer rollbacks as soon as I start transactions. If the transaction is already committed by the time the function exits, the rollback is a nop. Otherwise, it allows me to be sure that I have rolled back on any error.
Agreed; I'm inquiring about the impact is of crossing that language barrier. :)
Ah... yeah, I don't have much of an answer there. Definitely more than zero? I'm sure there is inefficiency in Go's WASM implementation itself, just because of its immaturity, and then since Host Bindings hasn't been implemented yet, I'm not sure anyone truly knows exactly how much impact it's going to have. I think this is something we'll understand much better in hindsight than trying to predict it. Regardless, I think you might find this article really relevant/interesting: https://hacks.mozilla.org/2018/10/calls-between-javascript-and-webassembly-are-finally-fast/
Thanks for the advice &amp;#x200B; Addressing the first few concerns, dep is still my preference. The vendor folder only contains one small code. I highly doubt that will grow so I'd rather keep it as it is. I will post a quick patch to the error structure. I will be adding session expansion options and then work in persistent storage. It should be out within the next month so that's fine. I have an example code, I will add it in for sure. Sorry!
That‚Äôs what I meant to communicate. Thanks for helping clear that up :) 
Thank you so much, I really appreciate the feedback! &amp;#x200B; I'll look into all of these suggestions, definitely seems like what I've been looking for.
Yeah, had the same experience. My JS File was like 10MB (minimized, but uncompressed). The frontend didn't even do that much. It was very interesting to code everything in Go, but for my current (and following) project I'm back to JS.
I'm working on this.
I will write all jobs to DB and the go routines will mark the jobs as completed or failed, etc. When then channel is full (blocks), I will store the job to the DB like normal but mark it for consumption at a later time. This way the client request still completes quickly. I will then have a cron or a ticker to scan the DB every so often to pickup such blocked jobs. I initially thought, maybe I should just make the ticker run every second and always do it from the DB. It seems like an overkill and with the current approach recommended so far, 95% of the time, the app would have processed everything in memory and a small number of requests will have a slightly slower pick up time.
Thanks for sharing this link. This was the best job queue article I have read. When I read it initially, I did not get that `range ch` is technically an infinite loop (until you `close ch`) and that's normal to do.. That's what triggered my question because I was worried I may crash the server if I poll continuously.
Thank you. It certainly feels like a much better approach. I am going to start with the other simpler recommendations only because I intuitively get it.. Since, I am new at this, I don't want to try something that is technically better but I have no ability to debug! But it seems like a natural progression and I should refactor to use semaphores as I gain more experience. 
Yes, that's just my lack of knowledge... I did not see a `for { }` in other idiomatic code and was worried I am doing something wrong. Had I know `range ch` is the same thing, I may have not done this post.. That said, there are some other good ideas in this thread so I am glad I asked :)
You are right. I thought about and I just wanted to be a good citizen and not abuse this API. This is an internal legacy API which is used by lots of other critical services. I don't want to try something and only to cause issues for others. Also helps me learn how to do channels properly.
Always
&gt; what if the REST API I programmed get used a ton? You can answer your own questions with testing... but in most cases the answer is YAGNI.
Alternatively, you could use microservices approach to split apart different functions. As for a static type, I can suggest Crystal programming language which as simple API similar to Python and Ruby and less code to maintan like what you describe. A comparison on speed and memory https://github.com/kostya/benchmarks/blob/master/README.md
my advice on this (that I struggle to follow myself) is to not deal with a problem until you have it. At this point you're close to completing the project in Python. You could decide to start again in Go, or you could decide to launch it as it is. This feels more like fear of failure or procrastination than a sound technical discussion. If you launch it, and it succeeds, then you will have a lot of good problems. The answer to some of those may or may not be to rewrite in Go. But at that point you'll have more information to base the decision on. At the moment you're just guessing. So... finish it in Python, launch it, and then work out if it needs a rewrite based on actual traffic.
I‚Äôm surprised you‚Äôre getting so much hate for this comment. I know many times I‚Äôve had projects that required similar front end and back end code so I ended up going with node even though I don‚Äôt really like JS. I was doing some cryptography poc and I didn‚Äôt want to double the amount of security critical code.
I honestly have had little exposure with Typescript since it‚Äôs never been in a stack I‚Äôm working on. I‚Äôll give it a good look in my next greenfield project. 
&gt; I felt annoyed how it would be little harder to read without the static types Sounds like it might not just be a problem with a lack of static types but more to do with general programming style. You can make python very readable and you can make go very unreadable - static typing is not the main factor in a programs readability. What it does do is make refactoring easier, you can more freely chop and chain bits of code with less fear as the compiler will catch more problems due to its stricter nature. But stricter languages come with their own set of problems. &gt; What if this gets bigger than imagined with traffic? Worry about that when it might become a problem. Design your system to handle 10-100x traffic increase and don't worry about anything more then that - more then likely your service will not grow that much nor that fast and you don't want to spend ages making the most scalable system when it may never need to scale. Solve the problems you have now first before worrying about scalability too much, especially for your first few applications. &gt; I got reminded again when I saw posts on how it would've be 20x as slow That is a random figure for some specific use case that may or may not reflect your use case. You need to do your own benchmarking with actual use cases that you have to know how much of a difference things will make. But unless you have a performance problem I would not worry about it, there is a lot you can do in Python to keep things within an reasonable performance range. &gt; I also read up on a story on how well programmed Golang can bring the amount of needed servers from 30 to 2. Are you running 30 servers? Or even more than 1? If not then it will not matter. You are no where near this scale and should first worry about your applications functionality before its possible future performance or running costs that you may never get to. These types of posts are written by high scale businesses that have been running for years and years and have huge user bases. The reality is most personal projects will never hit this scale and so do not need the same type of treatment or solve the same type of problems as faced by the companies doing these optimizations. &gt; I am not saying I am expecting billions of requests, but what if the REST API I programmed get used a ton? Most applications grow with usage slowly and as they do you can find and fix the bottlenecks that you find slowly increasing your scalability as and when required. You can then look at scaling horizontally for a while to meet larger loads. I would not worry too much about massive increases now as in reality it may never happen and if it does you can solve those problems when you encounter them - switching language is not the only way to scale. &gt; Also wouldn't it be a pain in the butt for maintenance since I would have to adapt the API to new releases? Not sure what you mean by this. The difference between go and python have no effect on your API and that is just a application design problem that neither language will really help you solve any better than the other. &gt; Would it also save a lot of time in the long run due to the readability (I read Staticly typed language better since it helps me see stuff broken down and less unwanted surprises)? Perhaps, you would also lose a bunch of time now learning a new language and porting your application across. You may also find other problems that may or may not slow you down or speed you up. &gt; I just want to make sure if these are good reasons to change to Golang on this project I would say not really. Both languages will be good enough at what you want to do and I would make the decision based on which one you like to work with the most and not worry about things like language performance at this point in time. You are really unlikely to make the wrong choice in this regard for this project, except maybe if you decide you really don't like that language you chose for any particular reason. --- Quite often the best course is to write the application in which ever language you enjoy the most and is at least partly subtile for the task at hand. Once you hit performance problems or scalability issues you can solve them when they arise by either refactoring your existing solution or by rewriting the slow parts in different ways or even different languages. One of the things about writing an application to scale is that it can be quite hard to know which bits will preform well and which bits won't. It is quite common to need to refactor or rewrite large bits of it as your user base grows to improve performance and it is very hard to identify in advance what might make a difference or not in performance. The best thing you can do is make your application easier to rewrite or split apart should the need arise to do so. But this comes second to making your application actually function as it is intended as it does not matter how fast your application is if it does not actually do the right thing.
Great answer.
Ok. Thanks, I just wanted to ask before I rushed in and make a stupid decision that can't be reversed. 
Whew thank you. I felt like I was getting carried away for wrong reasons and glad to know that was the case. 
The difference in these are quite huge though. binary-trees source secs Go 28.82 C# .NET Core 7.73 regex-redux source secs Go 28.99 C# .NET Core 14.85 k-nucleotide source secs Go 12.09 C# .NET Core 5.48
It's funny, if it's for a thesis the documentation is amazing.
Oh. So it's not that there is a "rate limit" on the endpoint, but that it is a shared resource you want to use responsibly. Now your problem makes much more sense. One way to do this is use timers, which send "ticks" to a channel on an interval. Then you can blocking read from the channel and make a request every interval. But then you need to monitor request backup to make sure you are making requests as fast as you need, which is a whole different problem. 
If you need resources. It's really beneficial long term. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
[Great talk regarding this](https://www.youtube.com/watch?v=X45YY97FmL4) 
This is pretty incredible, great work!
If it's for a fun project, use Go. Not for the reasons you described per se, but because it's fun. Writing Go is more fun than Python IMO and because it's easier to read you'll have a better time maintaining it down the line.
Maybe it's just me, but this seems above Bachelor's level. Great job!
This was exactly what I encountered. I was able to minify and compress to 5mb. In copar, my vanilla JS version is under six KB!
Would be interesting if we could get the go runtime as a sharable library. That way all go-wasm projects could share the runtime overhead
Very nice!
Very. Don‚Äôt force the handler to deal with transactions, move it to middleware for a very nice, clean approach. The middleware can auto start the transaction and auto rollback on error. 
I'm actually really new to this, can you give me an example of what you're describing? 
Yep, I posted that because everything is handled using the stdlibs. It's more like a multiplexer with extra capabilities rather than a framework. i.e. it doesn't ask you to setup things in a specific way, the handlers are also stdlib compliant. And it gets out of the way the moment you're inside the HTTP handler.
Agreed
Thanks a lot for your contribution. I'll study webgo in detail during the following days. Right now I have some sort of Frankenstein implementation of a pure stdlib web server + mgo, for a REST API. my implementation follows a line like the blog post suggested few comments above. That's why I wondered why is not clear which is the proper style for writing pure framework-less go implementations, but I think I'm asking too much. Thanks again
[removed]
I don't think there is a book to become an "expert" in anything. Can you become a carpenter by reading books about carpentry? No. The books can be helpful, but only experience and working with it will actually make you an expert. So, if you want a "step by step roadmap", then it's probably something like: 1. Learn the Go basics. 2. Program in Go. 3. Read more about Go. 4. Keep programming in Go. 5. GOTO 3 There is actually much more you need to do to become an expert; such as be familiar with context of design decisions, community participation (so that you get feedback, can discus ideas, etc.), and probably some other things.
For context, I've been using Go for new frontend code in all my personal projects since around [2014](https://twitter.com/dmitshur/status/550373382693199873), and [ported](https://github.com/shurcooL/Go-Package-Store/pull/18) previous projects to use it by 2015. I do it because my personal projects are for my fun and to develop things I want to move forward, and I enjoy working on Go in frontend much more than other languages. Here's my perspective. When you say "pure Go web framework", the closest thing that comes to my mind is [Vecty](https://github.com/gopherjs/vecty#readme), a React-like rendering library for Go. It's quite good and usable, but it's developed by a handful of people in their spare time and can't compete with React, a Facebook-backed project with many full-time developers. It's certainly worth a look and try if you're interested in using Go to build a frontend. I'm using Vecty right now in [Go Package Store](https://github.com/shurcooL/Go-Package-Store#readme) (since [2017](https://github.com/shurcooL/Go-Package-Store/pull/77)), which would be the best (and only) example of me using it to create the frontend of a local web app (i.e., it runs on your computer, not on the internet). My experience with it has been quite good, and it does what I would expect. However, writing the code to create new components with it is quite verbose and makes me want something like JSX but for Go. It's being discussed in https://github.com/gopherjs/vecty/issues/207, and I've seen some compelling attempts like https://github.com/8byt/gox and another that I was shown in confidence. To me, that's the current bottleneck. In general, IMO, Go on frontend has many nice properties, but it has a hard time being competitive with more frontend-focused alternatives like JavaScript and TypeScript because there are a lot more people (and companies) putting in a lot of hard work and hours into improving and maintaining those ecosystems. You have to be pretty determined to use Go on frontend, but if you're so inclined, it has many open many opportunities for improvement.
Where did you go to school and how long have you been programming??
Seconded. Adding: 1. Solve really interesting problems with Go. 2. Actively participate in open source development, including becoming a maintainer. 3. Write your own useful tooling in Go, where such tooling does not yet exist.
This is awesome! Would love to combine this with https://github.com/capsule8/capsule8 to do some distributed network and kernel anomaly detection. Nice work, will try it out!
I'm not an expert but... \`\`\` c.App.CreateUser(user) if user.UserID == 0 { a.Log.Warn("User object creation failed as id is 0.") w.WriteHeader(http.StatusInternalServerError) return } \`\`\` &amp;#x200B; CreateUser can't return error but you guess what happened based on UserID ? &amp;#x200B; How would you handle DB ? Would be a case of global "db" that is kinda often met. Or it is a matter of extending Api or some other struct that you already have with the DB pointer and initialization method. &amp;#x200B; What i usually do is \`\`\` type App struct { // all the things App can be using db, logger etc } func (app \*App) Init() {} func (app \*App) Routes() or SetupRoutes() {} func (app \*App) Run() {} \`\`\`\` I'm still looking for something better in terms of structure because i wanna use as little as possible globals. Ofc for me mostly using redis this isn't a big deal as i don't make big apps usually max redis,postgres and rabbitmq. My stack is Gin, Redis, Postgres/Mysql and Rabbitmq. 
I'd made that program few months ago, but only on windows. Just file changes watcher in one goroutine and gui in another. Without services and so on.
The regexp implementation in Go is slower because it parses regexps in a way that is guaranteed not to hang. Comparing the same type of regexp engines would privacy favor Go.
I know you are sarcastic, but C++ is popular for, at least in part, having the combination of performance and generics.
This is excellent, I'm really enjoying reading the README file on GitHub. Very well written.
Go is "closer to the metal" than C#. It comes with its own dialect of Assembly (plan9 style), an easy way to combine Go with C (cgo), build modes for creating shared libraries and a standard library with syscalls and ways to deal with ELF files.
[removed]
Wow! Embedded demo is awesome!
That‚Äôs very simple, you‚Äôll be able to write that app with this: ‚Ä¢ File Watcher ‚Äî https://github.com/radovskyb/watcher ‚Ä¢ Cross-Platform UI ‚Äî https://github.com/andlabs/ui More file watcher control: https://github.com/fsnotify/fsnotify
Thanks a lot for your answer. I already once created the application using Python. The app itself worked. But the problem was the installation on Windows. Users should be able to install the app without having Go installed. It should be installable like every other program, maybe using an installation wizard. Is that possible using Go?
A dream comes true! Thanks man for this great work.
QAw
Maybe you could have the GUI as a web app, i.e. use the builtin http package to create a web server and let the user connect to localhost, serving all the config there.
This guy is a natural
Definitely yes Keyword: go cross compile
&gt; CreateUser can't return error That is definitely a place where we can return an error, will modify this. Although user.UserID is also a check we can make. &gt;How would you handle DB? DB is handled in the repository, While starting the server, we create a DB object and store it with the repository. Pass this repository instance to our app, so they can be called using our business logic. There is no global parameter here, everything is injected during the start of the server. Global is a bad thing to use. Create required instances during the start of the server, inject them to required objects so nothing is global or static. Most things are called using interfaces so we can change implementations. 
Fixed the error handling.
Yeah... If you are interested in benchmarks then run go's testing tools. You can determine allocations, heap stack, and so on for any given code. You have to remember there is a lot going on here. Go never claimed to be the fastest but when it comes to trying to make it faster, it is the simplest. But you have to remember when benchmarking/testing you have to take into account lots of things. How did they setup the structs? The list of datatypes matter and their spacing/order. Are you using slices that are basically equivalent throughout so that your hardware keeps this memory foot print and skips extra memory layout? Are you even running on native hardware or a virtual container? Did you even use pointers? Are you optimizing for correctness or pure speed? Are you gunning for stack heap? Or speed? How many cores are you using? 2 depending on your code can be faster then 4. Are their optimizations in the language where you don't have to worry about casting types and are you utilizing pointers right before mutation? Or are you just using them? Are you building memory maps for the hardware to take advantage of? What scale are you going to go to for your code? A million isn't rare but when coding for correctness, you want to keep your responsibilities inline for the next guy. I could so go on but you get the idea.....
Nice! Currently I am also implementing the work of my master thesis in go.
v1.5 released, and it has new commands just for real-time purposes, it now supports Webhook and WebSockets natively &amp;#x200B; [https://github.com/alash3al/redix/releases/tag/v1.5](https://github.com/alash3al/redix/releases/tag/v1.5)
You mean in big company?
too bad it doesn't compile on linux go 1.11.4 $ go build -o $(go env GOPATH)/bin/netcap -i [github.com/dreadl0ck/netcap/cmd](https://github.com/dreadl0ck/netcap/cmd) \# [github.com/dreadl0ck/netcap/collector](https://github.com/dreadl0ck/netcap/collector) collector/live\_linux.go:30:16: handle.SetBPFFilter undefined (type \*pcapgo.EthernetHandle has no field or method SetBPFFilter) collector/live\_linux.go:46:26: handle.ZeroCopyReadPacketData undefined (type \*pcapgo.EthernetHandle has no field or method ZeroCopyReadPacketData) collector/live\_linux.go:66:23: undefined: pack collector/live\_linux.go:70:18: undefined: pack &amp;#x200B;
On naming, some of your stricts/interface names are redundant with their parents (like setting.Setting or metric.Metric). Why not put them in the app package ? They both are tools for the application itself, so my point of view is that they don‚Äôt need a package but belong to the app itself. 
Yes, e.g. when using chromium embedded framework (cef) or chromium directly instead of electron. Though, this is likely to be a lot of work to do, especially when you have an eye of packaging. Electron tooling is pretty mature already. Also keep in mind that the electron team uses a patched chromium version for their specific needs inside electron, which might also be necessary when going this route. Making chromium ready to work with go might be less work than the electron devs had to do for nodejs cause it wouldn't be necessary to fiddle around with nodejs integration.
Thanks for the heads up! Working on a fix. 
&gt;On naming, some of your structs/interfaces names are redundant with their parents Agreed, They are to clearly specify what they do. Metrics is an interface with the same name as the package which is redundant but then it gives a clear idea of what it has. I can even move interfaces in the root directory but thought to keep them in clear separation. &gt;&gt;Why not put them in the app package ? Agreed this can be done as it belongs to app, but just wanted to have separate packages so there are not too many files in app package. Also if the interface will be in the same package anyone can see it there only and write its implementation or else they need to look for it in app package (which is fine just another way of seeing the same thing). 
Really not. It is by far a better choice to adopt a language-agnostic paradigm. Thing for thing.
I mean a every company (small,middle,big) in any coubtry who are using golang in production 
8 packages? for what? I'd put them all into one. 
Why having more packages a problem? I created a separate package for clarity and abstracting out code related to its responsibility. As code size increases, it's easy to find code related to a specific module. For example, we have implemented Prometheus for metrics handling. We don't want app logic to know how metrics collection is handled so having it in the separate package makes a lot of sense. We can surely put everything in one package but as the app grows it becomes tedious to handle.
I guess you want people to reply to this post with that information, though the original post kinda reads like you want to add something to your project that phones home and reports what people are doing. You might want to clarify :)
There's also this option for GUI in Go without cgo: https://github.com/zserge/lorca
nice :) compiles fine now, will give it a whirl. thanks for the quick fix and response
No offense, but you might want to lay back on posting every single minor update to your repo here. The last post was just a day ago and if everyone did that then this subreddit would be spammed to death with updates. I'm sure the project is awesome, but maybe you can do weekly/monthly updates with a summary instead if you feel like it's something that *every* Go developer must know about?
Did you check out this example? https://github.com/appleboy/gin-jwt/blob/master/example/basic/server.go
&gt; Are you running 30 servers? Or even more than 1? If not then it will not matter. If you're running 30 servers it means you have some money that you can choose to put on server or on dev. You probably can add o remove some servers if needed. When you're running only one server it means you are very dependent of it, your services should not eat the food of the others and if it does you have no money or time to take an action just now. Same with traffic, if you've a small server you don't need very high traffic to be cramped. Scaling is relative... The same about readability and refactoring. When you're alone and don't have the help of a team of talented engineers you appreciate to have a very readable code and help of the compiler. Think of you in few years reading your own code and deploy on a new server... Do you want to move a binary or trust the last pip alternative ? It's the magic of Go, with it's simplicity it resolve at the same time the problems of freelance and of a big company ! Less is more. I suggest you to start immediately with Go, why not ?
Thanks to @negbie for his pull request on dealing with setting the BPF on Linux :) Tried to install from scratch in a Linux VM - seems to work fine now. However cross compiling to Linux on my MacBook gives me an error that pcap.OpenLive is undefined. Still investigating this... 
Yes I did. But could not make sense of it. &amp;#x200B;
&gt; I suggest you to start immediately with Go, why not ? It takes some time to learn and to learn to write programs well in it - not as much as other languages but still adds overhead to switch. When you already know a language and have not yet hit the problems of it I would not recommend switching it out for a new language on a production project as you will encounter new problems and difficulties. Use a side project to learn a new language and don't just switch your production application because of some untested benefits that you may or may not benefit from in your situation. This is how projects fail. &gt; If you're running 30 servers it means you have some money that you can choose to put on server or on dev. You probably can add o remove some servers if needed. Until you start to reach limits of the server you should not need to worry too much and you would be surprised how far you can push interpreted languages. Just look at Facebook, they are mostly running on PHP still. Yes there are benefits to go (and I highly recommend learning it, with a side project, and these days it is one of my main languages) but it does come with its own downsides and will take time to switch to and learn how to do things effectively with it as you need to learn what gotchas it introduces (such as remembering to close request bodies or not spawning loads of go routines unnecessarily or one of many other issues you need to learn how to avoid).
&gt; Until you start to reach limits of the server you should not need to worry too much and you would be surprised how far you can push interpreted languages. Just look at Facebook, they are mostly running on PHP still. It's exactly what i wanted to say : we are not Facebook to can keep running on PHP (running how much server as we want, rewrite a new PHP engine for your need...) If i suggest to start with Go it's because the OP ask. When he ask, it means it's possible. Like you said also, specially with Go. Then sooner is better than latter.
How does it compare to https://github.com/asticode/go-astilectron ? Seems like you are trying to build the same thing
Idk, I think this kind of thinking gets a lot of people in trouble. It's naive to think that later on when some known issue becomes a real problem, you'll be sitting around waiting for some work to do. So then something else gets pushed to the back burner. You'll end up with enough problems that you *didn't* foresee. If you can predict a problem up front, might as well try and solve it. Not to say that writing something in Python is a problem, but if you can come up with justification to use a different language now (and maybe performance is a good one in this case), you're much better off evaluating your options and rewriting it while it's small, if that's what you decide to do. If you're building something with the idea of, "eh, if it gets a lot of traffic then I'll deal with that later." That almost sounds like you don't fully believe in your idea.
It's pretty similar, sure.
I'd add: also become an expert programmer in general. Expert programmers (or "software engineers" or whatever other title applies) don't need to work in particular languages to be effective. If a particular person isn't fluent in a few different languages, preferably across a few different paradigms, I wouldn't call them an expert yet.
\+1 on [https://github.com/andlabs/ui](https://github.com/andlabs/ui) I'd put my money on that becoming the standard.
Check this code: [https://github.com/devopsfaith/krakend-jose](https://github.com/devopsfaith/krakend-jose) it may help you (notice that this is a middleware for the KrakenD Api Gateway) In [https://github.com/devopsfaith/krakend-playground](https://github.com/devopsfaith/krakend-playground) you have a working example.
I am reading it right now and I find it rather relevant. \+ good exercises
Participate in existing open source projects. You'll get to read and understand lots of code which will help you get better faster
&gt; Comparing the same type of regexp engines would probably favor Go The faster Go regex-redux programs [use PCRE](https://benchmarksgame-team.pages.debian.net/benchmarksgame/measurements/go.html).
[Could you?](https://salsa.debian.org/benchmarksgame-team/benchmarksgame/blob/master/CONTRIBUTING.md)
&gt; a trash fire Just name calling?
I am a backend developer but I find reactjs a lot of fun. Being compostable and tons of options like bootstrap material ui etc make it mostly easy to build front ends with. 
Exactly this. Using go for front end is like trying to keep applets and even asp and jsp alive. It may work but at beat you will be relegated to early 2000s era sites. If you want any of the modern SPA and PWA stuff you have to embrace JS and something like vue or react or angular. 
[Go versus C# .NET Core](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/go-csharpcore.html)
[Go versus C# .NET Core](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/go-csharpcore.html)
https://www.ardanlabs.com/blog/2014/01/concurrency-goroutines-and-gomaxprocs.html &gt;Concurrency is not Parallelism. Parallelism is when two or more threads are executing code simultaneously against different processors. It sounds like you want to run in parallel, on multiple cores.
This blog post mention a lot of time Athens but it never says what it is. So, what is Athens?
Parallelism is a method to achieve concurrency. The other method being asynchronous calls.
https://docs.gomods.io/
You're right that you should focus your effort on step 2. However, it entirely depends on the problem that you are trying to solve and not just the problem but also the algorithm that you use to do it. Some problems can't be done concurrently.
So I actually did come across this blog post while researching my problem. I tried running his 3rd example, but it resulted in a different output: Starting Go Routines Waiting To Finish a b c d e f g h i j k l m n o p q r s t u v w x y z 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Terminating Program So for some reason, it seems that runtime.GOMAXPROCS is not doing what I think it should be doing. I'm running go1.11.2 windows/amd64, and my machine has 8 logical processors, so I'm not sure why his example isn't working for me.
Cheers.
Took a bit longer, but here you go. Here is a very basic, trimmed down example how I need to find a tag cloud for a given set of uuids and have a set of count/label returned as table (and back into a struct): function is: ``` CREATE FUNCTION public.tagcloud(involved uuid[]) RETURNS TABLE(count integer, label text) LANGUAGE plpgsql AS $$ BEGIN RETURN QUERY SELECT COUNT(*)::int AS count, UNNEST(tags) AS label FROM reviews WHERE is_visible AND avatar = ANY(involved) GROUP BY label ORDER BY count DESC LIMIT 200; END; $$; ``` gin route code is: import ( "github.com/gofrs/uuid" "github.com/lib/pq" ) type TagCloud struct { Count int64 `db:"count" json:"count"` Label string `db:"label" json:"label"` } func GetTagForUuids(c *gin.Context) { // get db (sqlx) from somewhere in := pq.Array([]uuid.UUID{ uuid.FromStringOrNil("51024ad0-d92c-4897-8b83-c27f37534ac6"), uuid.FromStringOrNil("ffabec23-49c7-4926-a39b-c4e975746b93"), }) cloud := make([]TagCloud, 0) stmt, _ := db.Preparex("SELECT * FROM tagcloud($1)") _ = stmt.Select(&amp;cloud, in) c.JSON(200, cloud) } ``` As long as the type implements Valuer it should not be a problem passing arguments and types in and out. Otherwise just build a valuer, I use a very bad one for conversion of int64 to postgres DURATION type: ``` type Duration time.Duration // Value converts Duration to a primitive value ready to written to a database. func (d Duration) Value() (driver.Value, error) { return driver.Value(int64(d)), nil } // Scan reads a Duration value from database driver type. func (d *Duration) Scan(raw interface{}) error { switch v := raw.(type) { case int64: *d = Duration(v) //case []byte: // *d = Duration(strconv.Atoi(string(raw)) case nil: *d = Duration(0) default: return fmt.Errorf("cannot sql.Scan() strfmt.Duration from: %s", v) } return nil } ``` hope that helps!
It would take me 2-6 months to catch up to the skill level in Python I have in Golang. Also by the time if it gets to that amount of traffic, then there would be plenty of enough clasped time to learn Golang. I already learned how to do a REST Api in Golang, but I am not good enough yet to utilize the features of the language. Bad Golang will always lose to Good Python. However Good Golang will almost always win to Good Python unless if it's a C library for Python. &amp;#x200B;
This doesn't mean I would stop learning Go. I still am going to learn Golang, it's just I am not going to make a switch just yet
It's relatively straitforward. On your /register route you get the username and password from the user and generate a jwt containing their profile information,insert their profile into the DB, and send that jwt back to the user. For /login the front end sends the username and password which you then generate a jwt for and then send back. To authenticate routes you have the front end send their jwt with their page request and decrypt it to make sure it is valid then check the users permissions against a database (uid should be in the jwt for this purpose). If the permissions are invalid redirect them or send an error. The JWT can be verified to be legitimate because the backend has a secret key that it uses to decrypt and encrypt the jet.
I was also very surprised to see it called ‚ÄúMicrosoft‚Äôs Athens‚Äù. It seemed very out of place. Especially coming from the Go team, who is trying to discourage Go from being referred to as ‚ÄúGoogle Go‚Äù. 
I was going to comment exactly this, so seconded. Also, the gonum project provides some really good numerical tools. 
Don't fool with GOMAXPROCS.
&gt; I don't see how concurrency can help me unless if I am using multiple cores. In fact, I suspect that the overhead of the goroutines would slow me down if I am limited to a single core. It wouldn't. What are you after? Why are you limited to a single core? Usually the problem in 2018 is having *more* cores than you know what to do with.
You've got that backwards. Concurrency is a way of structuring your program to tell the compiler what can be run in parallel and what can't; Parallelism is actually executing that program on multiple cores. If you execute a program with GOMAXPROCS=1, then your program is not parallel, even if it is structured concurrently.
What I meant is that the Go runtime appears to limit itself to 1 core, even on multi-core machines. I'm having difficulty figuring out how to override this (see my response to /u/zootam)
Yeah, I've written quite a bit of React and enjoy it most, but loathed the fact that I'm writing a lot of logic twice, a lot of models twice, etc. Hence why I've avoiding the SPA route and just minimizing page reloads üòä
&gt; it isn't obvious to me how to encourage a Go program to "run in parallel" You use the [`go`](https://golang.org/ref/spec#Go_statements) keyword. Go tries to avoid magic; your algorithm will not be parallelized unless you make it so. If `GOMAXPROCS &gt;= NumCPU` and `NumCPU &gt; 1`, you're likely to see a performance improvement when using the `go` keyword. Last I heard, current Go versions will set `GOMAXPROCS = NumCPU` so you generally won't need to adjust it. &gt; I don't see how concurrency can help me unless if I am using multiple cores. Correct. &gt; In fact, I suspect that the overhead of the goroutines would slow me down if I am limited to a single core. Correct. &gt; Am I making sense at all? Your head appears to be screwed on straight.
I've seen waaay more people endlessly refactoring, never launching, because they're trying to solve problems they don't have. 99% of stuff that launches never gets enough traffic to worry about. 99% of those that do get enough traffic have some fairly simple scaling problems to fix, and usually enough time and resources (thanks to the revenue that traffic brings) to fix them. The 0.01% of times that the traffic is excessive, and the problems severe enough to cause real problems, are still good problems to have. The poster child for this is Twitter's Fail Whale. It's actually incredibly rare for a scaling startup/project to outright fail because of technical problems. It's way more common, massively more common, for them to never launch, or launch too late, or to spend their entire runway messing about with choosing a language.
What version of go are you using? The default `GOMAXPROCS` used to be 1 (changed in 1.5: https://golang.org/doc/go1.5).
No, not at all.
Based on you're question I will assume you're not even a beginner. First you need to become a good beginner before you can become an expert. I recently started learning Go. I am FAR from even a good beginner, but I got the following. &amp;#x200B; **Videos:** * Learn How To Code: Google's Go (golang) Programming Language - [https://www.udemy.com/learn-how-to-code](https://www.udemy.com/learn-how-to-code) ($11.99 as of this post) * Getting Started with Go - [https://www.coursera.org/learn/golang-getting-started](https://www.coursera.org/learn/golang-getting-started) (free if you audit-only the course) * Functions, Methods, and Interfaces in Go - [https://www.coursera.org/learn/golang-functions-methods](https://www.coursera.org/learn/golang-functions-methods) (free if you audit-only the course) * Web Development w/ Google‚Äôs Go (golang) Programming Language - [https://www.udemy.com/go-programming-language](https://www.udemy.com/go-programming-language) ($11.99 as of this post) &amp;#x200B; Learn How To Code: Google's Go (golang) Programming Language is amazing. If you want just one of these, that would be the single best one. &amp;#x200B; **Books:** I honestly don't think the books are necessary even though I purchased them myself. I haven't got through, The Go Programming Language yet so I am speaking more towards, Introducing Go: Build Reliable, Scalable Programs. I would skip this and just work your way through the videos I listed above. &amp;#x200B; * Introducing Go: Build Reliable, Scalable Programs - [https://www.amazon.com/gp/product/B01AB3G496](https://www.amazon.com/gp/product/B01AB3G496) * The Go Programming Language - [https://www.amazon.com/gp/product/B0184N7WWS](https://www.amazon.com/gp/product/B0184N7WWS) **Time:** In the first video above the professor hits on a saying, "Drop by drop, the bucket is filled." Or something to that affect. This is important. You need to make time. If you're not going to commit time you will never be an expert in anything. Time is most critical. &amp;#x200B; Good luck. &amp;#x200B;
Concurrency is helpful when you have tasks, or parts of a task, that can be done independent of each other. Consider a restaurant. You've got a front end taking orders and a back end making those orders. Person working on the front end get an order and hand it to the backend to prepare it. The front end person can take another order while the previous order is being prepared. That order could be given to another backend worker to prepare. Now, you've got three threads working. If you have a large chunk of data where each piece can be processed independently of each other. You process this by breaking it up into smaller chunks and each chunk can be done in parallel by another thread.
I'm a little late to the party regarding this, I feel. But after reading up on the proposals for parametric polymorphism, the idea of a contract always stood out to me like a sore thumb. The fact that you'd need the compiler to analyse the structure of your code to see if contract Less(t T) { t &lt; t } holds seemed kinda strange to me. Coming from both Haskell and Rust, the problem of polymorphic constraints has been solved long ago: via Type Classes. Suppose we want a function that filters all elements from a list less than some x Haskell: filterX :: Ord a =&gt; a -&gt; [a] -&gt; [a] filterX x lst = filter (&gt;= x) lst Rust: fn filter_x&lt;A: Ord&gt;(x: A, lst: Vec&lt;A&gt;) -&gt; Vec&lt;A&gt; { lst.into_iter().filter(|a| a &gt;= &amp;x).collect::&lt;Vec&lt;_&gt;&gt;() } In both of these cases, `Ord` is a type class/trait/interface which specifies the methods/functions that define what "ordering" means. Every type in each respective language that implements `Ord` can use the ordering operators. No need for any of that syntax-level hocus-pocus that contracts provide. I see the benefits of the syntax level jazz, but I feel that it gets a bit too strange and un-golike while potentially confusing the reader of the code more than needed. Additionally, if one were to want to add multiple type constraints to the generic, that would also be relatively straightforward, or at least it is in Haskell and Rust: foo :: (Ord a, Show a) =&gt; a -&gt; [a] fn foo&lt;A: Ord + Display&gt;(a: A) -&gt; Vec&lt;A&gt; Here defining a function `foo` that needs to be both orderable and to-string-able. The interface-based way of constraining the type comes very natural and is relatively easy to reason about.
Athens is indeed a Microsoft (sponsored) project so they can do that as they want (and my understanding is Microsoft want to establish themselves in the open source world so it makes sense to them). In Go's case it's mostly that most of Google's open source projects aren't called that way (see chromium, bazel, etc.) because they are already a big name in the open source world and this works better for them. 
Well the problem might be that you are looking to run processes in parallel. Which is fine if you don't mind locks. If you can't have locks then you shouldn't be using goroutines if you need to use that data at the same time. If you don't need to use it at the same time then locks don't matter as much. So if you need a well structured parallel computing data processing that utilizes data at the same time, then... I'd say don't use go. 
Thanks, haven't seen that one yet. I guess it's pretty new. The new result is super-fast too! That is fun to see.
This is how I had interpreted the phrasing; acknowledging Microsoft's contribution to the open source community. 
The tool you want to reach for if you are IO bound is concurrency and parallel programming when you are CPU bound. The beauty of Go is that both approaches are united and it works very well. Unless you run an ancient version of Go don't mess with GOMAXPROCS unless you have a very good reason to do so. To know if you are able to use concurrency for you algorithm you need to find the parts of that are independent. If you do a map- or reduce-like operation it is a good hint that you can make this part concurrent and Go will make it parallel for you.
You should split jobs into workers only if it is relevant to effort. If jobs are super small sometimes there is simply no point in adding complexity because gain is zero or less.
I'm using version 1.11.2. Although when I try the "parallel example" [here](https://www.ardanlabs.com/blog/2014/01/concurrency-goroutines-and-gomaxprocs.html), I get an output that more closely resembles the concurrent-only example. Now I'm starting to question whether my console's buffer rate could be interfering with the example. I need to find a more direct way to test how many threads are actually spawned.
Reposting from Medium: My apologies for accidentally slandering Athens by associating it with Microsoft. The phrasing in the post about ‚ÄúJFrog‚Äôs GoCenter and Microsoft‚Äôs Athens‚Äù was meant to give credit to the companies who seem to have plans to fund and run production-quality public mirrors. Per your objection I‚Äôve removed that mention of Microsoft (and JFrog, for consistency). Sorry for not addressing the filed GitHub issue immediately, but most of us, myself included, are on vacation now through the end of 2018. Happy Holidays to all, and a Happy New Year!
I don't think I got it backward, I think my second language failed me. I meant that Parallelism is a method **that** achieve concurrency. Like you said, you need the concurrent structure to have that parallelism.
...But with Chrome as an external dependency.
Some hands-on experience with Vecty framework: [https://blog.gopheracademy.com/advent-2018/go-webgl/](https://blog.gopheracademy.com/advent-2018/go-webgl/)
Your analogy is flawed. We object to "Google Go" because the full name of the language is plain "Go", just like "Android" is not "Google Android". We do not object to "Google's Go", where "Google's" is an adjective, because that is simply acknowledging that Google created and continues to pay for engineers coordinating development of the project. In much the same way "Microsoft's Athens" (NOT "Microsoft Athens") was meant to acknowledge that Microsoft created and continues to fund much development of Athens.
https://www.google.com/search?q=microsoft+athens+project
 "The Road to Wisdom - well it's plain and simple to express: Err and err and err again, but less and less and less." - Piet Hein
So your base question is "When is concurrency useful to me?" First, you have to understand what concurrency means, and secondarily to separate it from *parallelism*. [This](https://www.reddit.com/r/golang/comments/a8msnr/when_is_concurrency_helpful_to_me/ecc1zyw/) is an excellent response. To put it differently, "concurrent" code is structured in such a way that it uses isolated "units of work"; a function designed with concurrency in mind takes input values and operates on them in isolation. It doesn't care what's happening in the outside world. You hand it a box full of stuff, it does things, and creates another box full of stuff to be used elsewhere. Parallelism is orthogonal to concurrency. Concurrent code might run in parallel, or it might not. Non-concurrent code can be run in parallel by spawning multiple processes/threads/workers communicating with each other. Next to consider is the "problem space". Is your problem well suited to being broken into independent, isolated units of work? Calculating the digits of pi is not such a problem. To calculate the nth digit of pi, you need to know the n-1th digit, and so on. A problem that is well suited would be something like "take a sequence of numbers and multiply them by 5". Each individual action can be done completely in isolation; the value of `5*5` can be calculated without knowing or caring about the value of `100*5`. Finally, it's important to note that "concurrent" code isn't all or nothing. Some pieces of your codebase might be designed to be concurrent, and others strictly serial. So, you look at the problem you're solving, identify the nature of the relationships between your data at different stages of processing, and figure out when you can apply different techniques.
I don‚Äôt like gokit, it goes against my philosophy of ‚Äúkeep things simple‚Äù. Other people agree with me, and there‚Äôs even posts online with their thoughts [1]. That said, the official documentation says that you can use `transport/http` [2] like this [3]. [1] https://gist.github.com/posener/330c2b08aaefdea6f900ff0543773b2e [2] https://godoc.org/github.com/go-kit/kit/transport/http#NewClient [3] https://github.com/go-kit/kit/blob/d8776e0/examples/apigateway/main.go#L195-L227
Normally I would expect another chip before the GPIO display to handle this cycling of digits to keep the display coherent. This shouldn't be something userspace is maintaining.
You can potentially take nonparallel problems and just do more of them at once. Sometimes that‚Äôs an easy cheat
sure, but it's a good example.
Thanks, I was able to come across the same client you linked and that seems to be it. It was really unclear because the examples talk about a client being created for mirroring another instance of the same service and not for making outbound http calls in general. &amp;#x200B; Do you use any frameworks like gokit? Or just individual libraries for http and metrics and so on
how about you use the filepath instead, which is probably more akin to what you want anyway [https://play.golang.org/p/am1OEut8Yf9](https://play.golang.org/p/am1OEut8Yf9) ``` package main import ( "fmt" "path/filepath" ) func main() { base := "/admin/delete/" path := "/admin/delete/abc" newPath, _ := filepath.Rel(base, path) fmt.Println(newPath) } ```
This is the best answer. Concurrency is about how your organize your code. It is not the same as parallelism. 
Awesome, thanks so much
Shameless plug for my own article series with auth0 [https://auth0.com/blog/developing-golang-and-angular-apps-part-1-backend-api/](https://auth0.com/blog/developing-golang-and-angular-apps-part-1-backend-api/) 
I think I have a pretty good grasp on concurrency already. Maybe I need to clarify my question. I have a task that is similar to your second example: "take a sequence of numbers and multiply them by 5." I already know that this is well suited to being broken down into independent pieces of work. I know how to do this concurrently (wrap it in a loop with "go func() {...}()" statements, etc..). But how to I take a concurrent process and make it execute in parallel too? So far the goroutines I've written do not appear to be utilizing my multi-core processor. As far as I can tell they are executing sequentially in the same order that I call "go func() {...}()".
Wow, a classic XY problem in action. Next time you should ask about what problem your trying to solve rather than how you think you should solve it.
Concurrent design requires a lot of thought when talking about data processing pipelines. There is probably a lot that can be done, but it will require careful analysis of your code. If it's not closed source I'd be happy to take a look and discuss it further.
Other suggestion is better, but for a drop in fix see this function - https://golang.org/pkg/strings/#TrimPrefix 
For the minimum integer case, you can split into say N sublists and for each sublist, have a separate worker goroutine calculating the minimum for each sublist. Then take all those minimum values and in a single goroutine calculate the global minimum. However how much it generally scales up in performance depends on number of cores you have and how much IO and memory latency there is in the computation. 
There is no "best" language, only trade-offs: Scripting languages are generally faster to learn, and faster to "get something working quickly". Go has many features that slow you down during initial development. But those do eventually pay off down the road. For example: \- requires extra compilation step (not required for scripting languages) \- unused var/import is an error (not even possible to detect in most scripting languages) \- strict type checking (only possible with add-ons that your libraries may not be using) \- requires explicitly declaring your dependencies (almost impossible to determine your dependencies in some scripting languages like Ruby) An illustrative question is "Are you writing tests?" You can code faster in a scripting language. But if you are writing tests ("What happens if the client passes a string instead of an integer?"), the gap is smaller because Go generally requires fewer tests. (Many tests in scripting languages are obsoleted by compiler type-checking. You don't have to ask "what if this integer is null" or "what if the number is massively large?" because the compiler guaranteed it's a 32 bit integer. On the other hand, Go encourages you to always do error handling. That slows you down (and requires more tests), but it generally makes the code higher quality because errors are detected sooner and handled better.
Profound talk that helped me think through this question in the past: https://m.youtube.com/watch?v=cN_DpYBzKso
Not sure why you‚Äôre getting downvotes. This would be my recommendation as well. Not because a good framework isn‚Äôt helpful, but because I am not a huge fan of any of the Go frameworks out there right now. 
I think it‚Äôs a bit more complicated than a comment could cover, but start by looking at Go middleware in any framework (or no framework), and get a sense for how that works. 
Honestly I‚Äôd argue those should be separate structs. You‚Äôre describing separate request contracts. 
Perhaps you could past some pseudocode to demonstrate? How are you receiving the results of the operations? GOMAXPROCS is the maximum number of cores that Go should use, is it possible that Go is running in a context with it set to 1?
I think you're supposed to use the Volume Shadow Copy service, it supposedly lets you create a snapshot of the file system so that you can create crash consistent backups and read locked files. How to actually do this, though, I have no idea.
Go programs that use PCRE have been shown since [before 03 June 2013](https://web.archive.org/web/20130603214428/http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=regexdna) ‚Äî so no, really not new.
Monzo use it for everything they do. They're a bank.
Of course you are free to write the way you deem fit. But to me this seems like tediously elaborate Java style framework with dozens of packages and wrapper code. In Go I'd write 1-2 package and concrete code within them.
When I read this question, this was my same exact thought as well. I imagine it'd be pretty easy to look up the winapi for VSC and implement in Go.
Idk. I think there's a balance. I'm not saying it needs to be perfect. But this "it's not a problem yet, so leave it alone" thing gets way overplayed. In any other field, when you have an engineer title, cutting corners like this could get people killed. In software, for some reason it's just okay. I'd much rather live in a world where half my problems were solved extremely well, than one where all of them were solved with some half working buggy piece of shit software. Unfortunately, the latter is pretty much the world we live in. There are tons of open source projects out there with very sound software architecture, built to scale to millions of users, and extensible, etc. If someone can do that for free, then why can't someone hoping to sell a product do the same? And why is the concept of taking pride in your work and doing something right the first time just not a thing anymore?
...And when the time comes, you will want to know about TrimSpace, instead of using Trim, for the exact same reason.
I am having a hell of a time serving my own designed 404 page for my site, It just does not want to do it i always get the normal 404 error...
It's precisely the issue in https://stackoverflow.com/a/26573513
I think he explained the problem he was trying to solve very well, and provided a good example.
Ok. That‚Äôs fair... but would you call Kubernetes ‚ÄúGoogle‚Äôs Kubernetes‚Äù? Or LLVM ‚ÄúApple‚Äôs LLVM‚Äù? It just seemed odd, that‚Äôs all I‚Äôm saying. I wasn‚Äôt so turned off I didn‚Äôt finish reading Russ‚Äô blog post, or felt that it distracted from the content that much. Just felt odd. 
Fair. I don‚Äôt think it detracted from the message of your blog post. I just found it a bit odd and surprising. 
Thank you i moved the files into a sub folder and did like the post, its working now.
I'm in a devops role at a hybrid SaaS company currently and use it semi-frequently. I prefer using it when I need to deploy on a server that doesn't have docker/etc. set up (try explaining these things to government CMBs...). It's a lot more robust than crazy shell scripts wired up with cron tabs that were used in the past to e.g. meet highly specific compliance requirements. For anything I don't have to deploy, I tend to stick to python though. This is mostly because other teams in the company are more familiar with it. I've also found it indispensable in devops just because you can read source code of various tools common nowadays (kubernetes, prometheus, etc) which has saved so much troubleshooting time. 
&gt; ‚Ä¶ It's good to keep in mind that that site is just toy programs that random people have uploaded‚Ä¶ It's good to know [why toy programs are measured](https://benchmarksgame-team.pages.debian.net/benchmarksgame/why-measure-toy-benchmark-programs.html). It's good to keep in mind that [*you* can contribute programs](https://salsa.debian.org/benchmarksgame-team/benchmarksgame/blob/master/CONTRIBUTING.md) which you think are better!
Yep, I was going to suggest something like this. OP if you do go this route check out sync.WaitGroup concepts. You call wg.Add() for each new goroutine and then wg.Done() when it‚Äôs done. In main you just wait for them to all return with a wg.Wait() - this is all to synchronize all the workers effectively and prevent go routine leaks and race conditions 
So, Imagine I have a 2 core computer, parallelism means I'm dividing up my task into two pieces and *executing* them on each core through threads. Concurrency on the other hand means I'm dividing up my task into a 100 pieces (for example, assuming it can be divided) and the go runtime is executing these tasks on my 2 cores based on their availability. So one core might execute more pieces than the other one if the first core has more resources available. Is my understanding correct?
OPdid just that in the first sentence
I use it for simple scraping
Concurrency most likely can't help you if you have a single series of steps or instructions that must be run sequentially, with each step or instruction needing the results of the previous one. If your step two is something like "perform one monster of a calculation" then concurrency might night be of help to you. I do a lot of web development and for me the concurrency benefits come up when i can perform multiple HTTP requests at once, combine all the responses in whatever why i need, then generate my desired output. You can replace "HTTP requests" with "database queries" or "file downloads" or other kinds of tasks of the "I need to do this very similar task 20 times and none of them are interdependent. As others have pointed out, you have to explicitly make your program concurrent. If you post a portion of code, perhaps a dumbed down version of what you're working on, some of us might be able to help you out.
This answer is like the exact opposite of the answer he was looking for. I just want to point this out. 
Thank you
I don't really see how that's true. I stated how I use Go at work in a commercial product and listed the library I use. What's your beef?
Because you might have used a function argument once upon a time, but you can't just alter the arguments to a function. That's a breaking change to your public API. It would be unreasonable for the compiler to require you to break your API unnecessarily.
&gt; "take a sequence of numbers and multiply them by 5." If this is _literally_ your task, concurrency can't help you much. A single thread will still chew through everything RAM can give the CPU. That's probably not literally your task. But one explanation for why you can't get concurrency to seem to help you much is that your concurrent task is starved on some other resource, likely either RAM or disk. The other major explanation is that while channel operations and spawing goroutines are _cheap_, they are not _free_. To get benefit from concurrency in any language (this is not specific to Go), the tasks you are handing out to be run concurrency need to be significantly more expensive to compute than the cost of the concurrency primitives themeselves. You don't give enough info to know for sure what the problem is, but you'd be far from the first to post something like "I spun up a goroutine to add together two numbers, which I sent via a channel, for every number in my array; why is it so much slower than just doing it in a loop?" Goroutines can be a couple hundred cycles to spin up and channel operations can be a few dozen, and it's really easy while playing with concurrency primitives to accidentally try to benchmark it with a task that is much smaller than those and are dominated by sheer overhead. The ever-popular "add all the ints in the array" test can actually end up being less than one cycle per int!
The function signature may be representative of an interface, or it may be needed by a struct field which is of a particular function signature. Some examples are in the stdlib `net/http`, where any use of `HandlerFunc` must match that particular function signature, regardless of whether your function uses such arguments or not. If it helps, it is good practice to nullify unused arguments from the function declaration itself, like so: ``` func MyFunc(_ ctx.Context, _ int) error { ... } ```
In addition to coder543's point, you may be implementing an interface or a pre-existing type that provides values you don't need, so there's not much you can do about it. Also, if you consider that methods are very nearly just functions where the first parameter is slightly magical, you can get "class methods" by simply not using that parameter, and that's a perfectly valid OO thing to do, so you have to not use the class argument.
Thanks, I didn't know about the underscore being allowed!
Good point - thanks for explaining
Pure computational problems are suited to parallelism, not concurrency. Google writes network server software, which *is* suited to concurrency. 
Real estate. I important all is listing from 1000s of mlses every few minutes. Power a national website with this data.
Use it for systems programming making infrastructure for a large company. Provisioning new machines, among other things. net/http, grpc (more recently), sarama, pflag, cobra, and a bunch of others. Has been very effective for us in decreasing dev work as build time is low, learning curve is nice, and statically typed prevents simple bugs that may have been present in Python.
Hand in hand with running concurrent `go` procedures are [channels](https://tour.golang.org/concurrency/2). These let you safely communicate results between concurrent functions. A must for concurrent `go` code. 
My team is building system tools for orchestrating virtual networks and IPSec tunnels to extend them between datacenter locations. Right now, I‚Äôm working on throughput measurement tooling to catch performance regressions. Coming from python and perl before that, Go took a *lot* of getting used to, but I‚Äôm really enjoying it now.
Mostly network and systems stuff. 
webservices, cli utilities, kubernetes controllers...
Sure, some of my best work involved contributing something of questionable practical value.
I'm an engineer on [OpenShift](https://www.openshift.com/), an Enterprise Kubernetes distribution. We run and schedule containers across cloud providers as well as bare metal. Everything on the back end is in Go.
Web server and CLI programs
But does concurrency increases system load and cpu utilisation? If yes, then how can I spawn controlled number of go workers?
I‚Äôm not a fan of go, but the sweet spot for me, at work, is concurrent networking apps.
Not exactly what you're looking for, but I've written some custom Terraform providers at my job.
I tried to follow Domain driven design and kept separate code in separate packages, so anyone can change them just by seeing their interfaces. Developers clone code, and see package name metrics, so they know where to look for if they want to work with metrics. Same with API, repository etc. Can you plz share your thoughts on how to structure code in 1 package? Do i put all api, business logic and DB logic together? My only concern with that is if i want to give support to multiple DBs so it will be hard if everything together. 
I am at one of the largest tech startup in Indonesia, we are currently uses Go at the infra division. This will change soon as we move into Kubernetes and hopefully fully converted our Java and PHP into Go.
The compiler could force you to name them `_` in that case.
the compiler *could* do many things in that case, but it doesn't.
Authentication systems and signing blockchain transactions
I work for the enterprise monitoring team of a fortune 50 company. We are developing a cloud data pipeline in 100% golang, including collectors, stream processing, and various utility services. Additionally, we write services for alert routing, snmp processing, and data analysis, all using golang. In the last 6 months, we have hired 4 contractors (golang devs) to assist with this workload. 
High performance micro services architecture powering many properties on the internet, plus tooling. I use gorilla (handlers), viper (configuration), some proprietary utility stuff, xmux (routing), hystrix (stability, controlled failures). Primarily these services deal with JSON data and act as intermediaries to other services/databases. Almost everything I deal with is high read, high availability. 
What are the advantages of using Go instead of Python?
I use go at work for native ethereum blockchain dapps. I also use it for devops related apps, as all the cloud providers have a go SDK. At home however I use it for OpenGL and emulation.
We use it for our backend services that support our online games. Login servers, item servers and the like.
started playing around with it to write some scripts but am still on the fence as to if I like go. 
The goroutine you spawn at line 60 writes to the stop channel (technically it blocks on that write because that channel is unbuffered and has no reader). When you start a new worker, the select immediately detects that value on the stop channel.
As for your 2nd question, closing a channel causes any readers of that channel to receive a a zero value from the read (this makes sense because you woud not want readers blocking forever on a closed channel). You might find this helpful: [https://gobyexample.com/closing-channels](https://gobyexample.com/closing-channels) &amp;#x200B; Closing a signaling channel like your "exit" channel in this example is a common Go idiom.
I see, so what can I do if the programs accidentally send two or more `&lt;-stop`? How can I make it so the second/third/fourth `&lt;-stop` doesn't block the write channel? The `func main()` is actually a simulation of serial of events i made up if this whole program is a webserver. 
Our entire codebase is Go, and we're scraping, analyzing &amp; classifying millions of websites and emails a day.
Hardware/software compatibility - typically wrapping lower level C hardware libraries and exposing higher level functionality. Also, some automated update utilities for hardware. Some small CLI utilities. I have very predominantly just used the standard library. However, I love cobra for CLIs and have used gorilla/websocket. 
ok i'm a bit confused. `exit` is a chan bool. What does a `zero` value mean? a `false`? Why changing line 60 from `close(exit)` to `exit &lt;-false/true` yield a different behavior? (it's difficult to explain but the print statements will be different if i do that)
FTR, you are mentioning handlerfunc, so I assume you want to work on HTTP Paths - in that case, don't use `path/filepath`, but use `path`. The former is for filesystem-paths, the latter for `/`-seperated paths like HTTP.
Server side background services, API's, webservers, etc. Wherever we can.
FWIW, I'm pretty sure the answer is "because no one thought to do it at the time and now it would break code". The compiler *could* force you to use `_` for unused parameters (or receivers). But as others have pointed out, it's more often not-a-bug than unused variables, which is I guess why it didn't seem important pre-Go1. After Go1, of course, it became impossible. There are people occasionally suggesting to do that in Go2, though (there probably is/was an issue for that, I didn't look).
I would be curious to know if Go was the better choice for this than say Java, C#, Python, etc and why? Was it that you (and team) just liked the language, or is it that much faster/easier to write such complex code with.. and is it more performant at runtime, scales better, etc?
Curious why grpc over rest? I dont know grpc (or go that much for that matter), but am working towards putting together a micro services architecture that is using Rest API for front end consumers, and doing inter service communications with MQTT over a highly fast/scalable message bus (Solace). Some people have said to use grpc. I like the idea of messaging in general for large scale communication between services anyway, but also like that I can build services in any language.. though I susepct grpc works in other languages too. I am curious though if it is chosen due to being faster, easier, better to scale, etc than using a messaging system? 
Why Golang over languages like Java 9 (or 11 now), C#, python, etc? What did you do to determine this was the way to go... like comparisons of other languages/libs, performance, scalability, etc?
Why not?
So why convert Java to go? PHP is not really the same thing.. or maybe the way it was implemented it sort of acted like that? Anyway, curious why with Java moving fast and now supporting small/fast runtime startups, custom runtime builds that are a few MBs in size now, you have decided to move to Go?
Are you scraping 1000s of MLS's or just hitting their APIs?
Would love to understand more what you are doing with this.. I am learning and building out my own micro services architecture.. by my own I mean as I learn how to use Kubernetes, docker and golang, I am assembling a template project that has the basics set up that I can then just copy/paste and get in to specific code and everything else just works. Curious what viper is for (havent looked into this much)? I am working towards using MQTT over messaging to support inter service communications. Coming from a Java background where one service just uses other services in the code itself, as they all run in the same JVM, I am trying to grasp how to change to this new paradigm of a service sending an async message, and then waits for a response, before itself sending back a response (e.g. API service sends request to CRUD service to do some DB work, then waits for CRUD response message (that it listens for.. ) and then using that responds to the API request.
Enterprise ticketing system. Assorted small web apps. In-house forensics and data analysis tools.
I‚Äôm a release engineer and I use go for internal CLI tools, api clients, background scheduling services, web applications backends, heavy scraping of data from legacy systems etc. 
Im not familiar with MQTT. We actually do RPC even with standard HTTP using json. The whole (large) company is built on RPC. A lot of our service calls are not simple operations on data but instead somewhat complex checks or modifications. A part of our system could definitely be rest based but lots of it is hard to sum up in the confines of rest. Also we have so many services that routing would be odd. We mainly use grpc for its bidirectional messaging capabilities as we needed long lived connections for a particular problem. So far it‚Äôs been quite easy to work with. It also has some pretty sweet cooked in features around messaging. It does have libraries for many languages but I think the best support is in go.
I strongly believe it's because the whole ecosystem around kubernetes and kubernetes itself is written in Go.
We want more streamlined build process without cutting performance. It also cuts development time as it doesn't have to compile for minutes. The PHP was a legacy monolith and will be broken up into microservices.
e-commerce apps (Shopify API), Chat Bots (telegram), Reports (data extration to X, send via Y). About frameworks - we don‚Äôt do this stuff here. Only small libraries. Standard library provides enough stuff that we need and its very easy to use/extend. 
So? AFAIK they expose rest apis to control them 
If you send a value on the channel, *one* reader receives it. If you close the channel, *all* readers are woken up. Creating a channel just to close it is a quick way to do a simple sort of "broadcast".
Yeah it's not really about being written in Go as well. What makes Go so kick-ass for Kubernetes is static compilation. No dlls or static libraries or runtime. Just an executable. 
Unused &amp; non-underscored `error` arguments __absolutely__ should be a compiler error; Go has seen a lot of criticism about this. Unfortunately the Go 2 Error Handling Draft Design does nothing about it :-( However there are suggestions about how to fix it on the feedback wiki: https://github.com/golang/go/wiki/Go2ErrorHandlingFeedback Specifically the Go 2 scheme would need separate built-in handlers to: a) panic, b) explicitly ignore any result, and c) return the result (the "default handler" in current the draft doc).
Unlike any other "construction" industry, in software you can change something easily once it's deployed. Also, knowing what the best solution is *before* deployment is pretty much impossible - we don't know how the users are actually going to use the thing we built until we see them using it. Half the problems you're putting down to buggy implementation are actually due to mistaken assumptions during the design phase. So the best plan is to build the thing quickly, get some users using it, and then change it to match what they actually want. I think this is more the key element to the "don't deal with problems until you have them" part. It's not necessarily about not improving things before they become a problem, it's more the realisation that you don't have enough information about the problem until it's a problem. "getting it right first time" isn't a thing, because it's a pointless goal... we simply don't have enough information the first time, so what's the point of beating ourselves up trying to guess what we don't know? I fight this constantly with my database access. I'm forever worrying about optimising the SQL and making it fast. But at this point of the project, I need to get the core features up and running, even if they're slow, and every moment I spend worrying about the SQL is a moment wasted. Some of the SQL I've tried optimising already I've had to rewrite because the schema changed. At some point in the future, yes, I will need to optimise the SQL, but until the schema has settled down and we know the metrics of actual use (how often will the average user log in? Do they all log in around the same time? How many documents do they upload? What's the ratio of uploads to downloads?) it's kinda pointless... do I optimise for writing or reading? Is it a problem if an upload takes an extra second to write to the database? Or is it a problem if the download takes 500ms before starting? I don't know the answer to either of these "problems" until they become a problem, and then I have enough information to solve them properly. 
Real time recommendation service for Ad platform, user data scrapper from storage, pixel server as event ingestion service. All this works with couple of C and Java services. We use stdlib, pebbe/zmq4 , sarama, redigo and zap for logging. We use custom stats implementation instead of a third party stats package because of performance. We faced issues with code early on especially when it came to balancing throughput and latency. We had to work around and do some clever optimizations to get tight latencies.
We wrote the election system, for the supreme election committee of TRNC. They have used it in 2018 General Elections and were happy with it. All the backend and the APIs were written in Go. 
Use elm!
We use #beego framework for building API layer. Unix services , watchers, workers are command line based on viper package.
I like Elm architecture, but firstly it is a bit hard to use Elm after huge OOP background, and secondly I dislike the Elm tend to break a lot of stuff when updating the version.
We are using Go for writing our custom k8s operators. Honestly, I am a fan of Java and don't like Go so much. However, the core part of this ecosystem (e.g. docker, k8s,) is written in Go and the libraries, tools, frameworks written in Go are more supported. That makes the usage of Go mandatory. &amp;#x200B; I am so new in Go and doesn't feel comfortable with it. This may be why I don't like it so much. I wish the ecosystem supported Java as much as Go and I was able to select it by accepting some performance loss. 
&gt; Fun facts: &gt; Removed over 1 thousand Go files &gt; Build time sped up ~2x Interesting example of switching from a framework to standard lib.
Lots of things under the general umbrellas of Kubernetes and Prometheus. Go is also my go-to now for the intersection of "portable" and "fast" -- thin agents/clients and the like.
At Monax we use Go for our open source DLT framework Hyperledger Burrow (https://github.com/hyperledger/burrow) which implements an Ethereum VM. 
That's a very nice article. I enjoyed reading it. I've used scc a few times, and I appreciate the work you've put in to this tool.
I was using Go for specific need, websocket and speed for a scrabble game. But doing this i found that i can write almost as fast as with Python (that I use since decades). Without temptation of magic my apps are immediately more readable and easier to maintain and upgrade. And the last bonus, it's easier to deploy and consume less resources. Now I use Go for everything, CMS, CRM, small specific billing management, specif reporting, and even little one shot apps for transferring data. I've a lot of legacy app in Python2, i rewrite them slowly in Go instead of Python3... I didn't use any framework in Python (sometimes Pyramid), so it's very easy to rewrite them in Go+standard lib, as is. The first app that i put in production in Go was a little web app for temporary worker for one agency. I thought it will have very little traffic, was good to test Go. Few months after my customer asked if we can have more agency with the same app. Why not. Today it run for 40 agencies with exactly the same app, still on a t2.micro ! I use as few dependency as possible, gorilla/mux, jmoiron/sqlx, lib/pq and jung-kurt/gofpdf. The more i use Go the more i found it suited for very wide usage. I regret to don't have more usage of goroutine and channel which is fun.
I use it to control a cluster of automated warehouses
Developing authorisation protocol and an SDK to manage programmable file permission access to protected content in the peer to peer blockchain ecosystem. I really like the way Go helps me achieve this goal instead of staying in my way thanks to all the goroutines and native binaries.
A go binary is per default no statically linked executable. It‚Äôs possible to link statically but this can be problematic with some dependencies. The go binary is also really fat, which can be a downside too. 
How many people work on a project like OpenShift?
"sped up ~2x" is not very meaningful without some absolute numbers. If it was 60 seconds before, a speedup of 2x is great. If it was 1 second before then it's not all that meaningful.
I work for Canonical on the Juju project (http://github.com/juju/juju). Juju models complicated deployments and provides a cloud abstraction for deployment and operations. The CLI, agents and API servers are all written in Go. Juju makes extensive use of the parallelism of Go with goroutines and channels. Juju started with Go pre 1.0, so we ended up writing a lot of libraries ourselves. But we still use many external libs. Gorilla websockets for example. The LXD project is also written in Go, as is snapd, the engine behind snap packages. 
Some dependencies require dynamic linking in go, where completely static linking and cross compilation can be problematic. Also the size of a go binary can be a downside.
[This video](https://www.youtube.com/watch?v=jJS6G7irZSc) helped me a lot when trying to understand go routines and channels. When a channel is created, it can be `n` buffered (which means it can hold `n` values before blocking the channel), or unbuffered (which means it cannot hold any values and behaves like a "pipe"). When a channel is blocked, it mean that the channel is waiting for the sender function to be at line `c &lt;- value` and the receiver function at `value &lt;- c` to "open" the connection and transmit the information. When a channel is closed, the variable that referenced that channel no longer blocks the function at their `c &lt;- value` or `value &lt;- c` instruction lines (because the program would freeze). When a channel is asked for information (`value &lt;- c`), it actually [returns two values](https://golang.org/ref/spec#Receive_operator) `value, ok &lt;- c`. `value` returns either the value sent to the channel or the `zero` value (which can be `false`, `0`, etc. depending on the type of the variable). `ok` returns `true` if the channel is opened, or `false` if the channel is closed.
Faster/less memory required. Go also compiles to a single binary so you don't have to worry about making sure there is an installed python environment where you're deploying code. 
[removed]
I don't use Buffalo or advocate its use, but acknowledge that it has its place for certain situations. IMO the post is in a bad taste unless the poster has an alternative developed/planned/proposed. I did not study it thoroughly, but dont think the author of Buffalo has made any claims around any thing except productivity.
&gt; I use as few dependency as possible Does it mean that you also implement some of the things that are already implemented in third party libs or it is just because you don't need much functions? 
All good points especially the single binary part. Thanks. 
Time on my machine (*after* buffalo was removed) is ~7.7s wallclock/60s CPU time. IMO that makes the 2x speedup very significant. For comparison, building Go itself takes ~34s wallclock/170s CPU time - keeping in mind that it's built three times. Honestly, looking at the list of dependencies and knowing what Athens is actually doing, I don't really understand why it's so heavy.
Yeah it's mostly the packaging part as it's painful dealing with dependencies on customers' servers. 
The language isn‚Äôt as expressive as I‚Äôd like. If I approach it as an improvement on C, sure, it‚Äôs great. But after doing some functional programming, I chaff at not being able to implement some abstractions that would simplify my code.
When OpenShift was known as Makara, the codebase was primarily in Java with a smattering of shell scripts worked on by maybe 5 total engineers including the founders. I don‚Äôt know when the transition happened but definitely after RedHat acquired it.
üíØ% agree. I‚Äôm also not a fan of putting reasons/motivation for a pull-request under ‚Äûfun facts‚Äú.
I don't use Buffalo directly either but I use it often as a source of inspiration. The biggest problem with frameworks is to depend on it. It's fine to see that it's possible to remove such big dependency. For me it show that Buffalo is a very safe framework that doesn't tie you. Some discussions before this PR https://github.com/gomods/athens/issues/870
I was going to say *I* don‚Äôt work on Go at work but my company does. OpenShift is by far my favorite product in the portfolio and y‚Äôall should be proud of your work. I consult on OpenShift (among other products) and in practice it works really well. I‚Äôve been involved with OpenShift consulting since 2.0 Beta. (Yikes.) One of the reasons I started working with Go was to eventually be able to contribute to OpenShift and related projects. (I‚Äôm really interested in Istio right now.) 
I'm lucky, i work alone on small projects. I can choose what i use (database...) Often i implement things that already exists but only very small things (for example middlewares for session, logging...). I spent a lot of time doing this slowly but i can reuse it for years, again because i'm very lucky and i already did it in Python (at the time when web frameworks didn't exists).
Over 100 engineers at Red Hat alone. There were 8,000 attendees at KubeCon 2 weeks ago - a lot of them contributors to all of the various CNCF/Kubernetes projects. Most are written in go.
Parts of SaaS products. Some bigger (complex APIs hitting databases), some smaller (just shoveling stuff from one queue to another). G While I prefer python fork es for good code reviews.
Plain old http. Handles everything we need. Most of our services do http, so it's just wiring up an http client to do the requests according to their RESTful api. Set up some connection pooling and sane default timeouts. Use go funcs and channels to make requests and wait. Use hystrix to keep track of errors/timings and guard your upstreams. Our services are on multiple boxes in multiple data centers rather than all on a single box. they're designed to be Independently scalable. Viper is configuration through many means. It can be used to do 12factor if you've heard of that. Basically take configs from environment variables, set sane defaults. It can do file config too, in toml/yaml/json. It also can do file watching and config reload.
To be fair, most of the removed files were from `vendor`
To be fair, almost all of the LOC removed was from `vendor`
Wow - that goes back! The idea of cloud runtimes lives on with our quick start s2i images and templates for NodeJS, Ruby, and Java. Everything else is unrecognizable. IIRC OpenShift 1.x was Rails based, and used a tech called gears to orchestrate containers. Google then approached us in 2014(ish) when they were looking for a partner to open source Borg - which became Kubernetes. We made the strategic decision to rebuild OpenShift on top of Kubernetes, and the rest is history!
RETS and their new web API. Some custom formats, but all with agreements.
We found Go to inhabit the sweet spot of readability, simplicity and performance. Also, the fact Go code compiles to a single static binary makes it ideal for a container-driven, microservice architecture. 
Another fun fact: Buffalo author used to rant angrily about go module system. Nowadays I think go mod is good enough.
A high turnover eCommerce site
A "zero value" is the value that a variable of that type is initialized with. `var ok bool //ok==false` Other zero values are 0 for int/floats, the empty string, and nil for slices/maps.
Yup - Google made that decision for us a long time ago. OpenShift had to use go because at the start we forked the Kube API server to introduce new features like routes, `DeploymentConfig` (the predecessor to `Deployment`), and builds. Unfortunately that means we had to later de-tangle our code so that we could separate core Kube APIs from OpenShift APIs. These days you can extend Kubernetes with custom resource definitions (CRDs).
We run a lot of scripts performing a lot of shell commands, those we replace by go programs which make everything way more stable.
Thanks! We hope folks will really like 4.0, now in Dev preview. Install experience is much easier than our previous Ansible playbooks. I too am interested in Istio, as well as Knative.
Personally, I don't like Buffalo, because from my limited experience it makes *less* productive, not more. It requires more upfront investment to learn how everything works and fit together when making changes. So, from my perspective, if Athens is slated to be a mainstream core tool for Go (and it seems to be), removing Buffalo is IMO a good thing. Because it makes it easier to contribute (or just assimilate to their own needs) for people who don't have prior experience with that framework. Of course, the equation changes if this is intended to be only run by Microsoft (AFAIK the only company that has so far committed to running an instance?) or other public proxies. For those cases, the overhead makes sense. But if the intended end goal is to use this as a company-internal package proxy, not even mentioning a machine-local proxy to enable offline-work, then I'd argue the job is better done without almost any of the dependencies it carries.
I‚Äôm actually really worried about 4.0. I need to try installing it but I‚Äôm not that worried about it. Is it still Ansible at all? I‚Äôve got a lot of time invested in that. If they are similar I‚Äôm golden. (The playbooks do have a bunch of cruft built up over the years.) The real thing I‚Äôm worried about is disconnected installs. Most of my clients need some form of offline/disconnected/remote installation capability. They aren‚Äôt going to see the benefit of anything that needs that and it doesn‚Äôt look like that will change before 4.1. 
We‚Äôve got a spam bot ppl! 
For all the reasons you claim it is easier, I find it is more difficult. It adds complexity. &gt; it's easy to find code related to a specific module I have to think about that specific module. If it is all in one package, I don't even have to think about this. &gt;We don't want app logic to know how metrics collection is handled why not? collecting metrics is part of the responsibility of your application. This is an artificial constraint that serves no purpose to the underlying problems in anything problem I've solved on the job in my work history. &gt;We can surely put everything in one package but as the app grows it becomes tedious to handle This has not been my experience. I do not value solving problems that do not exist. I'll solve them when they do exist, but not before hand. 
Why so much hate?
Some good point there. It's just that I saw code moving from one package to multiple ones, so I feel it the way to go. There is definitely some extra complexity here which has its own benefits and drawbacks. Do you have any open source example which I can look to understand how others put the code in a single package which you like to share?
I mostly use it for low-level, early userspace code on Linux - kinda like u-root, only without the on-demand compilation. The code handles imaging (and re-imaging, aka factory restore) of a network appliance, as well as derivation of encryption keys. There are also a few services for health monitoring and hardware config (RSS/RFS/XPS and the like). For embedded stuff and early userspace, having a static binary is even more beneficial than in general - no need to worry about compiling/linking against the right libs. Getting a debugger working in early userspace would be a pain, so go's stack traces are a lifesaver. Fast, robust compilation is also nice, same as in any other application.
Looks really nice!
Go checks your local changes even if you reference the github 
That's kind of my point. As an "engineer", part of your responsibility is to figure out how to measure these things and solve real problems that you know exist. If you don't have a pretty good understanding how something will be used, then whatever you're building probably isn't in response to a real problem or need. If you listen to your target audience, you know exactly how they will use the feature they're asking for. There will always be some unknowns, but the reason we are paid six figure salaries is because we're supposed to be able to figure out how to minimize those and build a solid solution. There are too many people using the unknowns as an excuse to cut corners instead, but still showing up to claim their high salaries.
Yup. This and it's supposed simplicity and build speed has me interested 
[removed]
I'm glad to see GUI applications written in Go. Will you merge your fork of gotk3 with the upstream project?
Please make a tutorial with code. Lectures are not very helpful. 
Interesting thing is the use of a GOPROXY is supposed to eliminate the need of vendor (among other things), but Athens being one of the first major proxy project doesn't eat their own dogfood. (maybe they can't bootstrap yet? that still sounds lame to me)
 // file debug.go // +build DEBGUG package foo const DEBUG=true ---- // file nodebug.go // +build !DEBGUG package foo const DEBUG=false ---- // file foo.go package foo import ( "fmt" "os" ) func bar() { ... if DEBUG { fmt.Fprintf(os.Stderr, "This is a debug message") } } ---- $ go build -tags DEBUG # to build a debug build that prints the debug message $ go build # to build a normal build 
 // file debug.go // +build DEBUG package foo const DEBUG=true ---- // file nodebug.go // +build !DEBUG package foo const DEBUG=false ---- // file foo.go package foo import ( "fmt" "os" ) func bar() { ... if DEBUG { fmt.Fprintf(os.Stderr, "This is a debug message") } } ---- $ go build -tags DEBUG # to build a debug build that prints the debug message $ go build # to build a normal build 
This kind of #ifdef/build tag chicanery seems like a terrible idea to me. Why not just use a decent logging package (logrus is safe choice) and rely on runtime debugging levels? 
All the examples and tools mentioned in this article are in Go. However, prior knowledge of Go is not required, only advantageous.
I don't think the points made in the post are little known, novel or even controversial. Language designers make decisions that have benefits and costs. The languages that on average make better decisions tend to see a lot of use. There will always be people who want to see a language take a different direction. If every such person got their way it would be madness. Consensus driven design is often a bad idea, for this reason. It is often better to just invent, or use, a different language. No language is perfect. It is OK to not like Go.
The title of this post says it all: [GoTTY](https://github.com/yudai/gotty) is a program that lets you share Linux terminal applications into a web browser.
I don't want the debug strings in the release binary. This method will leave them there, even if it doesn't print them.
I don't want the debug strings in the release binary. Logrus etc will leave them there, even if it doesn't print them.
I don't, and honestly, the "single package" is hyperbole, and yet, I do feel it is the goal, because simplicity is the goal.
modules are in. generics are coming. am I to believe the OP will now like Go?
Have you actually tried it? ;-)
Some valid points in the discussion over there, but overall it feels like you could sum it up as: * No generics * No exceptions * We hate _if err != nil_ * Module handling, which I understand pre 1.11 it was stupid, but anyone who says python, JavaScript, or any language with external dependencies which are not vendored will run into the cave of pain at some point. I still like go but am hesitant to use it in large scale projects due to it not being stable enough and not seeing a clear path. But at the same time I can't say this about any language. Please point me to one... Rust, Clojure... Please don't say JavaScript dear God.
If that's the case. Then `close(exit)` and `exit &lt;- false`(as you explain a zero value for a `bool`) should yield the same result. But in reality it does not. 
They may return the same value but close and send have different semantics. The behavior of a send (&lt;-) is one receiver gets he value. The behavior of close is that all receivers get the zero value for the type, and if you use the ‚Äúcomma ok‚Äù idiom: _, ok := &lt;- exit, then the 2nd value is a bool indicating the channel is closed, and will no longer receive any more values. 
I work at a large financial firm. Go is used extensively for a bunch of stuff that needs to be performant/scalable and can be audited easily by third parties (PWC). Something I recently did was produce account feeds for 30k servers (both windows and Linux) that has to cache LDAP queries for nested groups. My team also recently created a SSH key management system with Go Buffalo, which I really like. Even though that is heresy apparently. My biggest gripe is that NVIDIA hasn‚Äôt produced a Go compiler yet for Cuda stuff. And, Oracle driver libs that balloon a Docker image from 18 to 350+ MB. 
I evaluated buffalo for a Golang service, my issue with buffalo is that it adds significant amount of complexity for what it does. It makes development more complex just for the sake of *trying* being ruby like. Honestly, I am surprised development of it is still being done, I would have thought it died due to the amount of knowledge of Golang has increased since its conception. To be blunt, if I were to use any framework, I would use Beego. I love Chinese software engineers, they are super awesome to deal with, and super helpful. Ok ok.. and SUPER smart. God bless there Chinese souls.
Why would you wanna do that? There will come a point in production where you would love to enable debug logging. I have seen many situations where there was to few logging and putting a new release took a week to get the logging in to figure out the problem. Now I am not a fan of those log enterpricy release processes, but I do like it when I can just flip a switch in case of emergency to troubleshoot my application without having the need to recompile etc.
This is untrue. Dead code elimination when debug==false will clean it up as you imagine.
Why not just have a 'var timeNow := time.Now' Then change timeNow in the tests' init() function to return a static time value?
¬Ø\\\_(„ÉÑ)\_/¬Ø I don't understand why you want to make life harder for yourself, but whatever
Thank you and you are welcome. Always happy to hear someone using it. If you do write anything about it let me know and I will ensure its linked from the README.
Seems overly complicated. I just pass time.Time as a parameter. So in mock it's just Function(timrVariable) and prod is Function(time.Now()).
The problem with that approach is that you need to make this \`timeNow\` variable global inside the package and that any code inside that package could influence the output of the function using the \`timeNow\` variable. Personally I'm against globals, and with the approach in the blog post the function is more "pure" which is always a good thing.
In case of this example that would've worked aswell, but when you have more complex routines calling functions on the time package can become messy to pass the time as a parameter to every method. ```go type Application struct { c clock.Clock } func (a *Application) DoSomething() { a.c.Now() // do more } ``` vs ```go type Application struct { } func (a *Application) DoSomething(t time.Time) { // use t } ``` This essentially comes to down using instance variables or parameters.
nope.
This was discussed 10 months ago: https://old.reddit.com/r/golang/comments/7zmt8u/i_do_not_like_go/
Elm is my first functional language, so I definitely understand that. Honestly my go code has improved drastically after learning some FP. And the update break isn‚Äôt the largest deal, refactoring in elm takes like 10% of the time a normal app takes, happens maybe once a year and is optional until you want to add more dependencies :) 
When I need to deal with the clock like this, I've been using this library: https://github.com/jonboulle/clockwork . There are some known issues with the library regarding some recently added functionality, but the core design works well.
&gt;[edit] It contains, apparently, 390K SLOC Go - of which ~7K are Athens, the rest is dependencies That sounds horrific but I guess a large chunk of that will be the AWS, Azure, and GCP SDKs. Let's hope they keep removing unnecessary dependencies!
&gt; Then, how to distinguish between missing attributes and attributes with default values? You could unmarshal to a map[string]interface{} and check manually that no key is missing, but it would be so WTF?! &gt; &gt; If someone knows a better solution, don't hesitate! You can use a pointer. If it‚Äôs nil after unmarshalling, that field wasn‚Äôt set in the JSON. If not nil, it can be dereferenced to access the original JSON value.
Thanks
I think a lot of people may be meaning that its not like traditional languages eg java where theres inheritance. Also people by convention wont put methods in different files, your complaint is largely a non-issue
How does this compare to the other redis compatible databases like Titan and tidis?
Similar the grandparent post, I typically pass around a `func() time.Time` (which `time.Now` satisfies); if I need the value inside of some nested function, I'll add the `func() time.Time` as a member of the function's receiving struct as you suggest. I would not recommend introducing your own custom time interface, though. One of the key benefits of using a anonymous function rather than an interface is that you don't need types just to implement the interface, reducing the amount of boiler plate code: package clock import ( "time" ) type Clock interface { Now() time.Time } type Mock time.Time func (m Mock) Now() time.Time { return time.Time(m) } type Real struct{} func (Real) Now() time.Time { return time.Now() } becomes func (up UserProfile) Age(nowF func() time.Time) uint { now := nowF() // ... } // at usage site (real) up.Age(time.Now) // in tests (mock) up.Age(func() time.Time { return myTestTimeValue}) At a minimum if you're going to introduce a single function interface, go ahead and implement the interface for anonymous functions: package clock import ( "time" ) type Clock interface { Now() time.Time } type TimeFunc func() time.Time func (f TimeFunc) Now() time.time { return f() } type Mock time.Time func (m Mock) Now() time.Time { return time.Time(m) } type Real struct{} func (Real) Now() time.Time { return time.Now() } This (anonymous functions to abstract single method calls) is an incredibly valuable technique in testing. For example, I use this exact same idea when setting up network connections (e.g. to swap use an in-memory implementation of `net.Listener` for tests).
Australia? 
I would recommend github.com/cep21/circuit as a better alternative to hystrix-go. I wrote it to be more compatible with go code styles and efficiency. 
But `Latest commit by yudai about 1 year ago` I'm not saying it can't already be perfect though
Server side bins can have the strings no problem. But bins distributed to users on desktops for example better be completely stripped IMO
[removed]
I wonder how significant it is in day-to-day development though? Most builds aren't from scratch due to the compiler cache, so you'll rarely have to wait for the full ~15s build.
[removed]
Us. 
The only meaningful difference between a class and a structure is that the later doesnt have inheritance. OOP doesnt depend on inheritance. Moreover, it should be avoided to begin with. Composition over inheritance. So yeah in principal you can do OOP in Go.
Classes imply a hierarchical class system that is designed/built from the top down with sub-classes inheriting methods and attributes from a super-class. Go doesn't provide any of that. Though not all OO programming languages include inheritance, I think inheritance is strongly associated with OO languages so the term comes with a lot of baggage. While Go and classical object oriented languages may have methods associated with a type with method call syntax that look similar, I think there is a deep and fundamental difference between the way object oriented languages approach design and abstraction. As you're probably aware, Go uses a notion of "composition" for combining types (and thus their method sets) and a sort of implicit interface conformity -- in both cases you don't have to explicitly declare that something implements an interface or builds on a type. I think it is important to abandon any ideas you have about object oriented programming. It is probably best to avoid mapping anything you know about object oriented programming to Go because, IMHO, it'll only cause confusion. 
That's a very wise word. I completely agree with you. Again I see it as small packages who do one and only one task (Unix philosophy) are simple to understand which also align with thinking that "simplicity is the goal". 
Right. Originally it was some history originating in beginning of 2018. But I made a mistake - commit few unnecessary big blob files during previous couple of releases. Thus finally I made a decision to keep my GIT history clean, so I recreate GIT repository to the new release.
Thanks! I'm doing my best to create superior application from all sides :)
It's funny for me to hear time to time that Go language is not for frontend programming :) So I'm glad too, to demonstrate what things could be written in Go. Honestly, it's not possible right now to merge back my gotk3 fork in one commit, because my changes drift away from original gotk3 code base. But I hope I will try in next few months to merge some important parts which still not present either not fixed in original gotk3.
gotk3 maintainer here. Please, open a PR and we can talk through it. Not lots of people give gotk3 some love.
Looks pretty good! There's a few nice packages that can help with configuration (https://github.com/spf13/viper) and command line parsing (https://github.com/spf13/cobra)
I would just recommend dependency inversion. It can come in a few flavors - higher order functions, struct props (similar to constructor DI with classes), or a simple wrapper over an existing dependency that you import. Regardless of the approach, the goal is ownership. If you didn‚Äôt write it, then you don‚Äôt own it, and it will force you into many difficult situations- well beyond mocking. Even if it‚Äôs a part of the standard library, I recommend wrapping it. Let the application define its own requirements. Don‚Äôt let a dependency control how you write code. Own your code. 
Maybe target WASM and provide a Nuxi-Wasm shim environment.
You can run the C preprocessor to handle the #ifdef lines and then pass that to the go compiler.
Because it is good for unix as do one task does not make it good for Go and for packages. Also, read the find manpage and plz tell me what one task it does? It does ALL tasks related to finding files, not one task. When in doubt, use the stdlib as a guide. How large are the packages in it? Where are the seams? How many responsibilities do packages in stdlib have? Are things like logging, data access, metrics, put into separate packages or kept in the one responsible package?
&gt;You don't give enough info to know for sure what the problem is, but you'd be far from the first to post something like "I spun up a goroutine to add together two numbers, which I sent via a channel, for every number in my array; why is it so much slower than just doing it in a loop?" Goroutines can be a couple hundred cycles to spin up and channel operations can be a few dozen, and it's really easy while playing with concurrency primitives to accidentally try to benchmark it with a task that is much smaller than those and are dominated by sheer overhead. The ever-popular "add all the ints in the array" test can actually end up being less than one cycle per int! D'oh! I think you've correctly diagnosed my problem. I've only been running small "dummy" test cases rather than using my actual larger data. I suppose I just need to trust the Go runtime. I have an awful habit of approaching everything skeptically, mainly because I come from a background where you can't always trust an abstraction without completely understanding the low-level implementation details (I support a massive toolkit of legacy C/C++/VB applications from the 90's, which was written using 80's programming conventions)
[removed]
Aside from the already mentioned lack of inheretence, structs in Go also don't offer any first class constructors or destructors. I am not claiming that feature is inherent to all classes, but it has been a feature in a number of languages that I have seen with classes. 
The difference comes when you realize two things. 1. Interfaces allow for types to carry over methods (not just require them) as they also are implicitly extended. Meaning once a type has those methods already, then it automatically gets that interface. Great for when you want to call up certain types or create a custom one. https://medium.com/golangspec/interfaces-in-go-part-iii-61f5e7c52fb5 https://research.swtch.com/interfaces https://www.golang-book.com/books/intro/9 https://www.youtube.com/watch?v=83J256zByHA https://github.com/golang/go/wiki/CodeReviewComments#interfaces https://play.golang.org/p/pv7o3G32I1 https://itnext.io/interfaces-in-golang-f1aea1ba31cb 2. The standard library makes great use of this. So the copy method in the io package https://golang.org/pkg/io/#Copy This is a wonderful example because the params have to be a reader and then a writer type. This means one has to have the read() method and the other param has to have a write() method. What does this allow??? Well in go a lot. Basically if you use the strings.Newreader() method your string automatically gets the read() method and io methods. https://play.golang.org/p/icxGp_EVWRV "A Reader implements the io.Reader, io.ReaderAt, io.Seeker, io.WriterTo, io.ByteScanner, and io.RuneScanner interfaces by reading from a string." The same sorta goes for the param for the writer type. So now what you have returned from copy is a type that gets all these methods (that you may or don't have to use) the only concrete data is the string and from the ground up you can do one of many things. 1. Reuse or change your string. 2. Reuse or change your reader type 3. Reuse or change your writer type. 4. Reuse or change your new return from copy. 5. Use the methods from all three. All this without carrying too much data around and still have full control over everything and plug and play with everything. 
Thanks for the great discussion. Will keep these points in mind going forward.
This is the approach I use as well. For each test I mock the time, then have a defer func which restores what was there previously when the test is done.
a better question would be "why not use a service mesh to solve these problems?"
there is a boilerplate gin-jwt-project code [https://github.com/dejavuzhou/ginbro/blob/master/boilerplate/models/jwt.go](https://github.com/dejavuzhou/ginbro/blob/master/boilerplate/models/jwt.go)
Running Kubernetes on a cloud provider
I wrote to make additional Lock calls without blocking execution in same goroutine or section.
I don't think it's more "pure" to add parameters that are only used for internal package testing. Although I wouldn't package global the variable I'd package global a function you call to get the time then only change it in the tests. Or, at worst, have the package external functions as before but have them just call an internal function which is passed a time.Now() and then you can test that function from tests with different times. Sticking interfaces/etc. in your exported API just to allow mocking for tests is the opposite of "pure" IMO.
This is nice, but has one major downside: you need to manually configure each http endpoint to monitor. You can't practically use this solution in a microservice solution as there's simply too many services, which is quite frequent in Go. I'd suggest exploring service discovery, and letting your monitor API discover all services that are in your system/cluster! This way everything is automated.
Finance. Ads before that, and hosting provider before that. Always backend and ops. Implemented VPS infrastructure entirely in Go when I was in hosting. Implemented high availability services when I worked for ads. Currently developing infrastructure services for finance analytics platform. For me killer features are: 1. Static compilation with no external dependencies. Including crypto (no more *ssl.so hell). Deploying is super easy even without docker. 2. Concurrency - for IO first and foremost. That and parallelism is awesome. 3. Memory usage and GC. Having low latency and predictable GC is super nice when you work with network. Currently planning transition to new module system which should make our experience with 3rd party packages finally enjoyable. 
Some suggestions: * The lack of license won't allow anyone to use it * Dockefile makes a big and fat image, with go inside for no good reason. The [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) build should make it much smaller. * Naming is a little bit unusual. Multiple `main.go` files in different places and most of those not in the main package. Probably instead of `listener/main.go` you better name it `listener/listener.go`. * Tests for some packages lacking, for instance, no tests for `listener` package at all. * Currently there is no way to terminate checker.Run() gorutine. Generally, it is not a bad idea to control the life cycle of goroutines. Practically if someday you will try to write a test for main, this will be a problem. * interface used in java-style. Consider declaring interfaces on a consume‚Äãr level, i.e. in the place, you actually use those listeners and providers * I don't like yaml but configurations in json I like even less. Not an actual issue, just my opinion. 
Check out a monitoring system called Prometheus. They‚Äôre extremely platform agnostic, so they try to keep things simple. In particular, look at how they do service discovery and configuration management. 
Ooh, seems like more than a weekend‚Äôs project then. üò≤ Thanks for the answer &amp; happy holidays!
I do agree that having the parameters as part of the exported API may not be a very nice API. I like the approach of having an internal function using the passing the correct time implementation. Thanks for your feedback!
ye clockwork is my goto as well
*I admit I don't quite understand what problem this is trying to solve (or how it works).* But it looks suspiciously like a [semaphore](https://en.wikipedia.org/wiki/Semaphore_(programming\)). https://golang.org/doc/effective_go.html#channels (specifically the paragraph starting `A buffered channel can be used like a semaphore`)
Hi Reinaldo. I would love to contribute to original gotk3, the project from which I had started my long journey with go-rsync app. But again I need to understand how to do it easier, since just single PR is not the way, in the situation when direct merge is not possible. I'm ready to talk here or elsewhere and spend extra time to make gotk3 better. Thanks for encouragement.
Think about an API with a dozen methods where you‚Äôve got a bunch of functions that need time several levels deep in the call stack. The time function basically becomes another context.Context parameter that you have to pass around to half your functions. I‚Äôm almost always against globals too, but this is one rare case where they can make code easier to read and maintain. Sure, someone could do something hacky like set the time in the global to influence behavior of some other part of the code, but if you found something like that in code review you‚Äôd flag it and deliver a scolding.
One of the major complaints is about the playground not having syntax highlighting. If this is one of the biggest problems with Go than all problems are small. The rest is just the usual rant about error handling, missing generics, how bad GOPATH is and that you cannot show off how clever you are as Go code is just too simple.
It's not a semaphore. From the docs it looks like recursive mutex. In Go mutex in standard library is non-recursive, meaning calling Lock() twice in the same goroutine will hang forever. Recursive mutex doesn't have this restriction and you can call Lock() multiple times in the same goroutine.
So "recursive" == "reentrant" ?
I'd bet that some service meshes have the same load balance problem he mentions in the later part of the article. You could swap the bad instances I suppose? How does that work in k8s?
Thank you so much, this is the kind of feedback i was hoping to get, i will open issues to address every point. Thanks again!!
Not sure about the interfaces issue, but will look it up. I could create almost every issue you mentioned: [https://gitlab.com/skyvet/health-check-monitor/issues](https://gitlab.com/skyvet/health-check-monitor/issues) Please feel free to add or comment anything that'd be missing or wrong Thanks again!
i agree with cittatva, this is meant to monitor only critical parts of your system and immediately notify you via a reliable communication channel (sms), and this monitor should be outside your cluster, because if your monitor is within your cluster, if your whole cluster goes down, you'll not get any notification i personally use this health check in a small gc vm instance and also use prometheus inside my gke cluster to monitor all of my services. It is usually used with grafana, that allows you to send alerts on user-defined thresholds on metrics, so let's say you can tell grafana to warn you on high cpu usage of your nodes, or low memory on your redis instances. it's really cool
thanks! i was trying not to use a lot of dependencies, although the filewatch feature of viper could be really useful for example when you have this mounted in k8s with a configmap mounted as volume and update it. Otherwise you need to recreate the pod
https://groups.google.com/forum/#!msg/golang-nuts/XqW1qcuZgKg/Ui3nQkeLV80J
Yes.
[removed]
Interesting, but what I'm looking for is a straightforward API sample with JWT , not a full-featured code like this which has its own corks and features to entangle. 
I like the idea! Will have a closer look later. I guess Caddy would also be a nice base for something like this.
I was going with the idea of explaining further how Monte Carlo is leveraged in physics simulations. Would that be something interesting for this audience?
Am I missing something here or can that just be modelled as a struct? You can [sort of](https://blog.learngoprogramming.com/golang-const-type-enums-iota-bc4befd096d3) do enums in Go but it's a bit messy
See also: https://groups.google.com/d/topic/golang-nuts/RoB2TP4YLRE/discussion
&gt; Yet, at the same time, you can create your own new type, on the basis of a struct, which can have receiver functions appended to them. s/on the basis of a struct//
thank you :)
A type switch is quite similar to `match` in this case, isn't it?
Silly question, but if that is really your use case, why not just use net.IP and rely on .String() to get text when you need it, or .To4() (and check for nil) to distinguish between v4 and v6?
Nice one :) Although I think the better option would be to have multiple versions in prod though, and have the api-gateway direct endpoints to the correct version of the backend. It's a lot more complicated though, and much harder to write an article about :)
The ad-hoc enums in Go are more akin to a list of constants (like C enums), different from Rust enums which are like tagged unions (a label with some data). The given example can be mimicked somewhat using an interface and several types adhering to it‚Äî type IpAddr interface { ip() } type IpV4 struct { a, b, c, d uint8 } func (i *IpV4) ip() {} type IpV6 string func (i *IpV6) ip () {} The un-exported function `ip` is needed to prevent implementation outside the module.
[removed]
I don't understand the context part. What's the use of passing it down the stack if it is never actually used? 
I found writing a simple "alert manager" was a useful thing to do - remote systems send heartbeats as a dead-mans-switch: * https://github.com/skx/purppura/ Because it centralise all "alerts" you can route them as you wish, for example Monday-Friday 9-5 send an email, out of hours send an SMS, if still pending send to more and more recipients. That "escalation" system is __very__ useful for many people. Because the submission of events comes over HTTP you can hook almost any system up to it. For example my own monitor uses it easily: * https://github.com/skx/overseer/ You'd probably want to update your HTTP-monitor with some of the idea of mine: * Alerting if content doesn't match a pattern. * Alerting if status-code changes. * Do you follow redirects? Or not? * Alerting on __all__ targets. * e.g. https://google.com resolves to IPv4 and IPv6. Test both. Explicitly. * Then you can say "IPv4 down, IPv6 up" * Alerting when an SSL-certificate is near expiration time. You can read (just) the HTTP-probe code here : * [http_probe.go](https://github.com/skx/overseer/blob/master/protocols/http_probe.go) Hope that was slightly useful, and not too much self-promotion!
&gt; Everyone has been (proudly?) stressing that Go is not an object-oriented programming language. That's not really true. The [official answer](https://golang.org/doc/faq#Is_Go_an_object-oriented_language) is a lot more nuanced. To answer how Go differs from "traditional OOP-languages": * The unit of encapsulation is the package, not the type. There is no way to hide members or methods from other types. I'd argue that's the most important difference - yes, types are kind of like classes, but your programming model isn't objects talking to each other via well-defined and encapsulated APIs * No inheritance. You have composition (via struct embedding) or you have subtyping (via interfaces). That's again an importance theoretical difference: You don't have overloading and the subtyping is purely structural. As a result, you don't have any issues with multiple inheritance and [method resolution order](https://www.programiz.com/python-programming/multiple-inheritance#resolution). If code calls a method, it is always unambiguous and easy which is called (though [except when it's not](https://play.golang.org/p/Cc4s3lxADlm), to be fair)
&gt; One of the major complaints is about the playground not having syntax highlighting. Notably, Go was one of the first languages that even *had* a playground.
I came up with this abomination. I post this just to get more straightforward solution. package main import ( "encoding/json" "fmt" "os" "reflect" ) type User struct { Name *string Age *int } func (user User) isValid() bool { v := reflect.ValueOf(user) for i := 0; i &lt; v.NumField(); i++ { if reflect.ValueOf(v.Field(i).Interface()).IsNil() { return false } } return true } var jsonBob = []byte("{\"name\":\"Bob\",\"age\":25}") var jsonAlice = []byte("{\"name\":\"Alice\"}") func main() { var structBob, structAlice User if err := json.Unmarshal(jsonBob, &amp;structBob); err != nil { fmt.Println(err) os.Exit(1) } if err := json.Unmarshal(jsonAlice, &amp;structAlice); err != nil { fmt.Println(err) os.Exit(1) } if structBob.isValid() { fmt.Printf("Bob: %v %v\n", *(structBob.Name), *(structBob.Age)) } else { fmt.Println("Bob is not valid!") } if structAlice.isValid() { fmt.Printf("Alice: %v %v\n", *(structAlice.Name), *(structAlice.Age)) } else { fmt.Println("Alice is not valid!") } } &amp;#x200B;
This is the closest. Thank you
Thank you. not really a use case of mine. It was just of theoretical interest as mentioned in the question.
yeah, i will definitely take a look at that, pattern matching alert is a really good idea it does not check for redirections, it just checks http response code is 2XX also would be really nice to have ssl cert check &amp;#x200B; i will open issues for this &amp;#x200B; thank you!!
&gt;\-tags DEBUG By Merlin's beard, you are right! It gets cleaned up. Thank you :-)
Agreed, should be multiple versions in prod unless you have absolute control over the clients. I also tend to lean towards each container/exe only supporting one version too, with multiple running until traffic for a deprecated api is drained. It's also good practice to be able to mark an api version deprecated and signalled to the client so you can get rid of the stragglers.
I was trying to do this with [https://rtyley.github.io/bfg-repo-cleaner/](https://rtyley.github.io/bfg-repo-cleaner/), but as I remember final commit made the situation worse :( So, finally I decide that project history is not so long to spend a time.
Even though this is possible, I urge you to use more idiomatic code. Closing the interface to outside implementations and substituting `match` cases for type switches are a big code smell, and lose much of the power of interfaces and their use in Go. Go is not Rust, you should embrace that :)
Every time I attempt service architecture or DDD in Go, I always give up because it feels so unnecessary and bloat-y. It‚Äôs quite confusing and does not feel idiomatic at all imo. Maybe that‚Äôs because my projects are not massive scale, I‚Äôm not sure. Does anyone else feel this way or am I just being difficult? 
Mindset. 
People here might not know what symfony is, i assume you mean the PHP Framework, right? So in that case, the title should be \`**Moving from php's symfony framework to go - opinions wanted**\`. &amp;#x200B; Related web development, go ecosystem is pretty mature right now, so i personally don't think you'll hit any brick wall while porting, except the fact you'll have to put some effort in and understand that go is different than php which means you will do things different in go. Which is fine. You'll also see now how much php brings on the table by default, things you got for granted where in go you'll have to work for them(i.e sorting and merging arrays). &amp;#x200B; Good luck.
You can see how the standard library implements this particular example: https://golang.org/pkg/net/ `IP` is the underlying representation which is just some `[]byte`. There are helpers for parsing IPv4 and IPv6 and other formats. On top of that, there are different kinds of address representations: `TCPAddr`, `UDPAddr`, etc. All of these implement the `Addr` interface. It's not the same approach as having enums and matching against them, in fact it's kind of reverse: You have some concrete implementations, and you have a general interface that you pass around when it's abstracted away. You can type-switch on that interface if needed. Overall, it's possible to emulate Rust'e nums to a large extent, but that's not necessarily the best way to tackle the problem here.
Trying to click link, but no link. Trying to copy URL, but not working. I guess I will have to go old school and type in this URL directly...
This is very true. I've been 'playing' with go writing some scrapers and I've dived into concurrency, waitgroups, types, packages and so on. I really like how simple but powerful go is. It's kinda like the vim of the coding world... but makes sense!
well, in a nutshell, symfony components (and the framework) bring a lot of things to the table, such as csrf handling automatically, forms, templates, validation etc. I've been looking at Iris vs Revel and although Iris looks more feature-packed it seems the cool-kids are using Revel. While the really cool kids are using net/http. I don't really want to re-invent the wheel with net/http as this will be a full-blown form-driven application so I'm torn
Quite often the implementation of v2 might have required internal changes to v1, databases etc. Managing both of those within the same application makes sense. Bug fixes, enhancements to logging and other shared infrastructure. For these reasons I would use a gateway to push to a service and manage versions within it.
Agree and Understand :-)
Core platform services &amp; dev management tools for games. Our container orchestrator is also written in Go. 
Here's a little something I wrote up after doing some benchmarking with Go and Java. Thoughts and comments are welcome.
your website looks cool, but i demand to see some frame / table borders and construction site gifs!
I tried to apply it for a project of mine(a reddit/hn clone). It was good "technically" ie. nicely decoupled and I could add tracing/metrics easily but it was very verbose. I probably wouldn't apply it for CRUDish projects again. I followed [this](https://github.com/katzien/go-structure-examples/tree/master/domain-hex/) structure which felt pretty idiomatic. That was my experience. 
It becomes useful further down the line when you want to add tracing.
i cant tell if youre mean or not ;(
Other commenters are hitting on this, but I think it should be reiterated that, for anything more than simple projects and small startup type stuff, you probably should manage your Go project versions as git tags, and do proxy routing to servers set up to run whatever x versions back you support for your API. Why? * Having multiple versions of the same code in a codebase makes reasoning about the codebase harder, as you need to write custom routing logic such as from this post * Understanding the change control on fixes/updates for each version is much more difficult when they are all submitted as a single PR * Deprecation of versions is much less clean, as it's a manual process to go through and rip out old code while ensuring its not still used by new code However, I think the biggest reason of all is, when you have multiple versions of the same application sharing memory at runtime, you get into a scenario where bugs from v1 can affect v2 and vice-versa. This can cause some major confusion, and if things like permissions change between versions, can have a major adverse impact.
I don't see why it couldn't just be two different images though. Represented in two different branches in a repo or something similar. Doesn't make a lot of sense to me to handle multiple major versions within the same application, it can get rather messy really quick in my experience..
It totally could be two different branches, if you want to manage that. Long lived branches should be feared. I can talk to this in detail if you are interested. I understand the desire for a mental model that only considers there is one version of any api. If you don‚Äôt own the clients you can be supporting the apis for a long time. I would preserve the ability to change the implementation while keeping the api stable. By pushing that complexity across branched versions and separate builds means in a way that you have separate apps. That in the situation where a DB is used, you are integrating at the DB which is commonly experienced anti pattern, this makes evolving your schema difficult, you need to test new db changes against old versions of your app. I would assume that you will introduce a breaking api change at some point and structure your app accordingly.
[removed]
That makes sense, I understand the feeling of verbosity. Maybe that‚Äôs my issue, I‚Äôm mostly developing APIs and CRUD apps, so maybe it doesn‚Äôt make the most sense for those types of projects. I‚Äôm gonna give that link a look, thank you for sharing. 
[removed]
You have a few options. 1. Write a custom IsValid() error method, similar to what you've done, but make it more specific to the User struct. E.g.: ``` func (u User) IsValid() error { if u.Name == nil { return fmt.Errorf("required Name field is missing") } if u.Age == nil { return fmt.Errorf("required Age field is missing") } return nil } ``` 2. Find or create a generic library that helps validate that a struct with pointer fields doesn't have any of them equal to nil. Use that library. E.g.: ``` if isIncomplete(structBob) { return fmt.Errorf("Bob is not valid!") } fmt.Printf("Bob: %v %v\n", *(structBob.Name), *(structBob.Age)) ```
If it helps, I found it useful when combined with dependency injection . [Here's an example project I did for college](https://git.packetlostandfound.us/chiefnoah/baka-moe-ws) that uses that architecture. There's some areas that I've since improved on, but it works decently well.
It works through command line and web interfaces, as well as APIs in the C, Go, and Python programming languages.
In this paper the performance and productivity of DASH is evaluated, by comparing an implementation of a set of benchmark programs with those developed by expert programmers in Intel Cilk, Intel TBB (Threading Building Blocks), Go and Chapel.
Mock the database connection and have it return an error when you call update. Use something like go-mock if you prefer or just impl an interface for mocking purposes
Change the content of the database such as renaming a table or a collection externally. Then the queries would fail. Or if you want the database to fail to respond, just stop it. If you have to try every type of fault returned then you will have to create a mock back end that responds with errors 
So far this is the only thing I have found helpful. Learning how to use a language without any practical use of the language is worthless.
Import the data into a real database or search engine?
I want to scan the data with Go and save relevant results to a text file.
The main search engine is in C with any an API wrapper for Go.
I disagree. The thinking that you have deprecated versions and good versions is what the new versioning proposals are discouraging. All of your versions should be supported and first class because backyard compatibility is so important. This implies that 1. all versions need to be maintained as if they are the latest stable release. 2. you shouldn't be deleting "deprecated code". 3. you can and should share code between all versions. That means that if you're using tags rather than a coexisting repo you'll have to cherry pick common code changes across multiple branches which is annoying and prone to mistakes especially as the code diverges. 4. If your package has internal state like package wise locks then your multiple versions MUST share memory. Imagine two versions of SQLite that ignore each other's locks. 
I'm actually a soon-to-be ops guy, and currently learning Go on my own. I simply adore Go so far. Hope to use it in devopsy tasks as well!
If i recall correctly, the problem with setuid system call on linux is that it changes uid only for the current thread. Glibc employs signal hacks in order to propagate this change to all threads in the process. I would guess, that part is broker, since go runtime does not rely on libc. Have you tried using runtime.LockOSThread() and performing the following steps: 1. Lock current goroutine to a single thread. 2. Change uid. 3. Perform fs operations. 4. Restore uid. 5. Unlock thread.
For the love of whoever you pray to. Dont use v1. V2. Etc in url. Use what rest and http provide. Media type. Just as easy to code your apis with the media type and version. More so you should pretty much avoid versions. They should be very rare. If you screw up an api endpoint just add another with a new name and leave the old one for backwards compatibility and document its depredation. Best to use Raml 1.0 to describe, annotate and document your apis. Api first source of truth. You can generate server code. Test code. Clients or sdks and more. Makes it super fast. Easy. Consistent. And repeatable. 
Just to warn you, some people get agitated if you mention the iris framework because the developer pulled some fishy moves. Other than that i am with you, frameworks can make sense and make your work easier than working with pure net/http
Correct me if im wrong here, but working with JSON in Go is a complete nightmare. Compared to python or the like for scripting?
A couple of quick suggestions: 1. Increase the io-buffer size (default is 4Kb), or even better read the entire file in one go. 2. Use strings.Builder instead of concatentating with + [https://tip.golang.org/pkg/strings/#Builder](https://tip.golang.org/pkg/strings/#Builder) . (or simply eliminate the tbody building step. 3. Use more cores processing each file in their own go routine. 4. Use pprof on the the code ([https://medium.com/@felipedutratine/profile-your-benchmark-with-pprof-fb7070ee1a94](https://medium.com/@felipedutratine/profile-your-benchmark-with-pprof-fb7070ee1a94)) to see where it hurts. &amp;#x200B; You might find that a huge chunk of processing is handling UTF-8 correctly, you could potentially eliminate that overhead by searching and comparing bytes treating it as ASCII instead (but it would make the code less correct and less clear). &amp;#x200B; &amp;#x200B;
Assuming from your description that you can set your permissions once and forget it, write the code to check your permissions, and if they are wrong, re-exec a new process with the right ones, setting the permissions on the child with the parameters in *exec.Command. Pass your stdin, out, and err down directly. There may be a couple of other book-keeping things to do. Pro-tip: When re-executing the child, pass it a command-line or environment parameter or something telling it it is the re-executing child. That way, if the permissions are still wrong, you can error out instead of looping endlessly. If you have to _change_ permissions, you pretty much have to exec children. I wouldn't try to fiddle with getting it to work in the core process... too fiddly, too prone to working here but not there.
You can use `os/exec` to run `/proc/self/exe` with a given uid/gid and some magic environment-variable set. You then check for that env-variable in `main()`. You can also pass a file-descriptor to the child process for additional communication. BTW: You can still dispatch a setuid/setgid syscall by using [unix.Syscall](https://godoc.org/golang.org/x/sys/unix#Syscall) and pass [unix.SYS_SETUID](https://godoc.org/golang.org/x/sys/unix#SYS_SETUID). Don't know what that would do, though‚Ä¶
Depends on the error you want, but you can add a trigger to your table that raises an error every time, or randomly
Why is the order of body and header such a surprising behaviour? "headers" imply something that must be written first before a "body". It wouldn't make sense if you could write out the body to the client and then send it headers about how to handle the body. Is the misconception that a user might expect some kind of magic flush operation at some later point in time where it then writes out the accumulated header and body content? 
fork() and exec are completely different things unfortunately. After many hours of reading, from what I've found out has led me to understand that syscall.Setuid() returns an error in linux not because it didn't work, but because the Go developers got reports that it didn't act as expected. Setting UID only happens per thread, so I can actually work with unix.Syscall, considering that :)
fork() in C and exec are definitely very different beasts that do very different things. I'm going to have to set UIDs and just do everything in a single thread running in the direction /u/darthslon mentioned. 
Yeah, I saw this. My conclusion is that I'll need to do LockOSThread and also just use a mutex. I was curious if filesystems are even multithreaded or not, I couldn't figure out concisely in a quick search so I'll have to deep dive into it a bit. If they aren't multithreaded, then I need not worry about designing my fusefs tool this way. If they are multithreaded, then I'll need to figure something out later.
Its different. Python it feels natural since its a key:value and python has as dictionary. In go you need to serialize/deserialize through a library into a struct. This is similar to other languages like java/c/c++ when you deal with json. So yeah its different and a little "harder" but really I think its just different since it forces you to think about types of the values you are receiving.
if this were postgres, i would just make a shadow schema which has error producing functikns
but if that json is huge, you'd have to make a massive struct correct? and know all the keys it needs?
You only need to create fields for what you're interested in.
Let's be honest with ourselves; GoLang is the C language rewritten with garbage collection, concurrency, and a nicer syntax. Should everything in the world be rewritten in C? for performance reasons yes of course, however... I do think we will see python/go become a more common stack since the languages complement each other (go for economy band, python for power band) and both prioritize rapid development 
Using pprof (#5) was my first thought to figure out what is going on currently, but wouldn‚Äôt give you much help on coming up with other ideas for optimization 1-4 look like great places to start.
Ok thanks. It still seems like a lot but I'll look into it more. 
This. Externalise your db dependency behind an interface and make a mock implementation for testing. 
Go is my favorite language to deal with JSON. http://eagain.net/articles/go-dynamic-json/
Either you‚Äôre dealing with something with an expected structure that you‚Äôre going to transform in known ways or you‚Äôre just shoveling opaque data from point A to point B. In the first case, use a struct. I the second case, use a map from string to interface{}. Both work well for their niche. 
how is it possible in mysql
This is the correct answer.
If you don't want to specify the keys (or don't know them ahead of time) I believe you can use map[string]interface{}
No other method will give you the transparency or flexibility of mocking. It is also the easiest especially if you design around mocking early.
How do you enjoy emacs as an IDE? I live on the command line but never learned emacs or vim. I've often thought it would be nice to set up a central dev server that I SSH into and code directly on using emacs. Looked up some plugins, did a couple tutorials on the keymap but I never followed through with the plan.
From time to time I keep coming back turning a text editor (vim in my case) into an IDE through plugins, but so far the ease of use of an IDE keeps pulling me back. It doesn't help that I like my text editors to be very fast, and plugins like YouCompleteMe don't help that, especially when tools like VScode exist.
I'd avoid mocking the DB, but would def have interfaces like GetUser(userID int64) (User, error). You pass in a fakeUserGetter that returns your desired error and you verify the error handling. In the prod code, you pass UserGetter that is initialized with an sql.DB property. You can verify real behavior with integration tests that actually run against a test DB
&gt; fork() and exec are completely different things unfortunately. I am fully aware. `os/exec` does fork+exec and by running `/proc/self/exe` you get a child-process executing the same code. It's not the same as fork (you aren't sharing an address space and are starting from `main` again) but it still lets you have a separate process to do things in.
I'm not 100% this will be of use to you, but, in the gpu realm, we use this little code pattern of having a os thread we can call back to anytime we need to call thread-unsafe operations to opengl or something. github.com/faiface/mainthread see for example.
My thought was that he expected the writer to handle it internally until it gets called for output. Or like some language it being chainable towards the writer. People always seem to find something to picker about every porgraminglanguage.
Biggest tragedy of Go is that, it is considered a Devops language and thus inferior for regular business needs. It actually is pretty nice despite having an inferior compiler to languages like Java or C++. People I forced to work on Go, complain about lack of paramteric polymorphism and error handling the most.
wtf is with all the downvotes in here?!
My emacs init-file is written in markdown at [~/.emacs/init.md](https://github.com/skx/dotfiles/blob/master/.emacs.d/init.md) - there's a smaller [~/.emacs/init.el](https://github.com/skx/dotfiles/blob/master/.emacs.d/init.el) which parses that and executes the embedded lisp. I think it is quite readable doing it this way, and allows people to steal bits more easily. That said [my golang-specific parts](https://github.com/skx/dotfiles/blob/master/.emacs.d/init.md#language-modes---golang) are very minimal: 
It's actually quite common, since there are times you know header values only after you have the body. Still - this can be solved by wrapping request/response object with your own implementation. 
Many bad advices I'd say
You actually don't need 4 and 5 IIRC. It was a huge problem for docker before but it seems they fixed it as for Go 1.10 https://github.com/golang/go/issues/20676 https://github.com/golang/go/issues/20395 
Exactly this. Until the moment VSCode exists and is so damn easy-to-use, it's hard to use a pimped text editor as in IDE.
Clean, simple and elegant. Good job ! 
Hmm - not sure I agree with those comparisons. JMH is awesome in its own way - it does a lot under the hood (warming up JVM to actually compile your code, stabilizing memory throughput) and I can't say that options for configuration is a minus. At the end it comes down to the fact that Go and Java have similar but sufficiently different execution/memory models. There are a lot of pitfalls when benchmarking Go (cloudflare wrote about them) and things you have to do to actually get correct results. For example if you expect your application to fully load all cpu cores, but your benchmark is not parallel - you have to limit the number of GOMAXPROCS to get actually reliable results where and how CPU spends time. Including GC cycles. Another thing is setting proper value for GOGC since application deployed to production is going to use different amount of memory, and hence the GC cycles will be different. 
If each file is ~1GB and can spare the RAM you can try memory mapping the file, this should help with the OS communication speed. If not try using `bufio.Scanner` instead of `bufio.Reader`. If you can memory map the file, then start walking the content with something like: func processFile(fileContent []byte) { const header = `\n\n\nWARC/1.0` // i think there always are three newlines before it lastHeader := 0 for { offset := bytes.Index(fileContent[lastHeader:], []byte(header)) if offset &lt; 0 { handleBlock(fileContent[lastHeader:]) return } handleBlock(fileContent[lastHeader:lastHeader+offset]) lastHeader += offset + len(header) } } func handleBlock(content []byte) { if p := bytes.Index(content, []byte("\nWARC-Target-URI:")); p &gt;= 0 { } // other detection using bytes.Contains ... } This is assuming you are fine with misparsing some of the content. I.e. the content is using multipart. So the body of the multipart could contain the same tokens.
10/10 excellent beaver
The combination of tmux, vim and all the plugins was too tempting to make an entire IDE, one that could be hosted online and logged in from Blink / Mosh through an iPad Pro. But after having gone that path, I can safely say - the productivity of working on an actual computer (MacBook) is unmatched. Key aspects: - Learning and getting used to all the keyboard shortcuts for simple things like skip by word, which is natural in VS Code - Folder operations - Need to work in parallel on the browser to view output and/or documentation, reference, code samples - Working offline (which hugely reduces distractions or while traveling) 
What DB you are talking about? There're lots of them, including non-relational ones. We are using RethinkDB at my job and our approach is a custom "scriptable" driver, which either calls actual driver or return a error based on script. This script here is just a sequence of directives like: []Directive{ On("rename-tags-0", Pass), On("rename-tags-1", Error("failed to rename")), } `rename-tags-0` here is a "label", which is taken from `context.Context` and we have dedicated functions to deal with labels: package label import ( "context" ) func ToContext(ctx context.Context, label string) context.Context {} func FromContext(ctx context.Context) (context.Context, bool) {} Thus, you see, we needed to modify code a bit to add "labels" before DB requests. 
what a sweet little cat
this cracked me up :)
One of the best swag I've seen so far
Love it!
That's funny, because I have completely opposite experience. Trying to force myself to use something like vscode repeatedly over the years and find it very difficult to use. It has a lot of shinny features, but few of what is really needed. And it is way to disruptive for me with all its blinking and colorful bells and whistles. Thus, at the end I keep coming back to just a decent text editor (vi in my case).
Instead of doing the search sequentially in range loop it should be faster to do it in goroutines. Depending on what OP's goal is (learning Go or doing code search), maybe use ripgrep or ag.
Thanks for clearing that up! I've found a great article on this topic: https://blog.gopheracademy.com/advent-2016/context-logging/
I need to know how to make this! 
Both makes sense. I agree about branches, tags would be better imo. I would still prefer to have it in two separate apps, because that's essentially what they are whenever there is a major change. The DB part can be a bit tricky to solve, but there should be integration tests for that. Nothing should just roll out in prod without testing. But I see your point :)
Using a template language that is agnostic from the Go language is a convenient way to simplify the work of the frontend guys. The product is no a template engine, but a generator of minimum valuable products taking data from existing API.
Please open source the knitpatterns!
https://dev.mysql.com/doc/refman/5.5/en/trigger-syntax.html
I am 100% aware of the difference between fork and exec. In this case I meant exec as in os/exec the package, though. I will reiterate that I highly recommend against trying to do anything with the lock thread call. Afterwards, you will still have OS threads in effectively random states in your code. The thread locking functionality is not for this purpose. You need to create new OS processes with the correct permissions. Study all the parameters on *exec.Command. It has most of what you could need, though there are still some advanced cases where you may need a C-based wrapper. I have production code where I've had to go down this route already, both "spamming myself again with the right parameters" and "using a C wrapper".
&gt; and also just use a mutex Wrong. Nothing in the documentation on `sync.Mutex` tells about how mutexes behave with regard to the OS thread underlying a goroutine which called `Lock` on a particular mutex. Hence you must not make any assumption about this. Conversely, calling `LockOSThread` guarantees that the goroutine which called it will always be scheduled to run on the OS thread which was running it at the time of the call. IOW, the mutex is not needed.
No, cool kids use https://gobuffalo.io/
Some testing I did, I found that even with LockOSThread, things can happen out of order if go routines are spawned. The problem is that setfsuid() affects the entire process, which is why forking is ideal, but it can't be done on multithreaded processes. This is a test I've been toying around with for the UID/GID stuff: [https://gist.github.com/protosam/6222bd2a7bb5b42567615a2015aee73d](https://gist.github.com/protosam/6222bd2a7bb5b42567615a2015aee73d) &amp;#x200B; This isn't really a scheduling problem I'm trying to solve. LockOSThread is a good suggestion for what I'm working on because it's a FuseFS application, however I think it's ultimately irrelevant to the overarching problem I face. 
I wouldn't want to run UnlockOSThread() anyway I think. Considering this is going to be a mounted fusefs solution, I'll want it to be always scheduled by the kernel as priority.
The main issue with exec here is that this is supposed to be a mounted solution (the fusefs part of the problem). Spawning completely new processes doesn't really work here, I think. Unless there's something I'm not considering?
That's really dope! One of the things I find most sad is that you can only get those gophers at conferences. I wish they sold them or made them more available.
Does you PHP script also prints something to stdout on every line? https://gist.github.com/shoutweb/5241a25e59db028b95cf709074b44250#file-go-commoncrawl-search-L80
I've used Sublime, Atom, VSCode, Qt Creator, JetBrains, and heavily modified version of Kate and Notepad++. One of the reasons I wanted to try the emacs route is because the only one of those I've *really* liked were JetBrains' offerings and I don't want to pay a monthly fee for a code editor. All the rest of those take an excessive amount of time and work to set up the way I want and they seem to get bloated with plugins and shit starts going wrong as things need to be updated.
Thanks for the feedback! You are absolutely right that benchmarking is difficult to do right. &amp;#x200B; The intent wasn't to say whether JMH is better or worse than Go's built-in benchmarking, it was to look at how the two languages implement benchmarking as a window into the development cultures of the languages. Java development style tends to favor tools that are very configurable, but which manage your lifecycle for you. Go style favors an approach of small, simple tools strung together. We sometimes talk about this as frameworks vs. libraries. Which you prefer is more a matter of how your brain works than an absolute good or bad.
Fantastic, I appreciate the working example. Your project seems much more clear than some of the tutorial articles, so thank you for sharing! Merry Christmas!
https://www.reddit.com/r/golang/comments/57tmp1/why_you_should_not_use_iris_for_your_go_projects/
it comes down to... does it work and does it work well. steve jobs was a dick but look how many people bought his products.
According these benchmark sets for general computation, Go consistently does things quicker and with drastically lower memory footprint than JS. There's no reason to expect it would be any different when you're shaping up database results for consumption. https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/javascript.html https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/go.html
Using gopath is outdated now that modules are a thing right? 
I think that there's good value in ensuring that your business logic is well separated from your persistence, external dependencies and API layers in order to try and make sure it's testable. That applies over time and not just scale. However, I also think that people are too hung up on "patterns", which seem to shift around where you put code weekly as a flavour of the month for various communities to continuously bikeshed. I'm sure I'm in the "get off my lawn" section here, but MVC, MVVM, Service objects are all just fluff around separating responsibilities in a manner that's logical for your project and introduces seams for testability, abstration and separation of concerns in a way that allows you to reason about your code in smaller blocks, which was the original point of OO.
Software engineering is so much more than `does it work and does it work well`. Even if requirement were limited to that, there are other frameworks that work just as well without the drawbacks of being owned by a mentally unstable individual. Here's my experience with iris. When I was new to Go, iris' bold claims caught my attention and I started using for a new project. One day I submitted a kind-worded, purely technical GitHub issue asking for some guidance with a difficulty I was having. Few hours later, without any warning or reply to the issue, my account was simply banned from accessing the repo and I had no clue why. After searching around for answers I finally found the [link](https://www.reddit.com/r/golang/comments/57tmp1/why_you_should_not_use_iris_for_your_go_projects/) I previously wrote above and it was eye opening to read the shady practices of iris author of flattening the repository to remove contributors and removing Issues that could made iris look bad somehow. I consider myself lucky to find out early and first-hand, how bad of a choice iris was. Since then I've deployed projects using varied stacks including gin, beego, buffalo, gorilla/mux and standard library. No serious company would touch iris.
i'm not talking about "software engineering", i'm referring to the end product. the only question is "does the end product work, and does it work well?" not, "how nice is a developer on the project, do i like them, and do i want other people to like them?"
Dismissing what iris author have done as just `not being nice` requires some special effort. 
I'm afraid that your question is too vague. You probably know, but in case you don't, there is an excellent [chat example](https://github.com/gorilla/websocket/tree/master/examples/chat).
you could say that about any billion dollar company, yet they make... billions from people who invest in them and their products.
This example is great, but how would I go about creating 1-1 chat. May I upload the code that I have roght now here?
I really don't care about the framework you use. The link was posted so newcomers reading this post can educate themselves when making their own choice. If you read the linked post, then you've been educated. Feel free to move on instead of using laughable arguments like semantics, steve jobs, multi-billion companies to defend your choice of a framework.
stop trying to hide the fact you have a hidden agenda. dear "future readers", iris isn't liked by bubux and they want you to not use it because some github stars may not be by real people or something and not because it's a rubbish project. kinda makes you want to use it, doesn't it future readers!
As if anyone needs a hidden agenda to dismiss iris after knowing what the author has done: https://www.reddit.com/r/golang/comments/57tmp1/why_you_should_not_use_iris_for_your_go_projects/
oh look, you're spamming your hidden agenda again. you can't even explain your point as your only argument is "don't use iris because of a fictional "star" system on a website"? that's pathetic. offer some knowledgeable advice or move over.
I think I've found out who that "some people" is :)
I never said it was because of stars. You're just making yourself look like a fool since the link says so much more just GitHub stars.
Why wouldn't it? I don't understand what the supposed problem with that is. Fork also spawns a completely new process. What exec changes is mainly that you stop sharing memory, but I don't think that's really relevant here. Any file-descriptors you'd need for fuse or whatever can be shared. But also, I don't really understand why fuse has any relevance at all. FWIW, at that point it becomes a question of what you're actually trying to do. i.e. why do you need to do file-operations as another user at all? In general, fuse filesystems are user-specific and not visible to other users. I guess you could be trying to have it run as root (would need to, to set a uid/gid anyway) and set `allow_other`, but that still doesn't explain why exec would be a problem with fuse - the original process is still the fs-process handling the fuse-protocol with the kernel and the child processes do the filesystem operations as other users.
Please take a look at updated code. https://gist.github.com/slon/b7fc6bb3822844fa58007f54023b0da9 I was talking specifically about setuid() system call and not about setfsuid(). Raw setuid() system call applies only to the current thread. Normally that is not what application expects, and hence that system call is disabled in the standard library. https://github.com/golang/sys/blob/master/unix/syscall_linux.go#L1460 But in your case that behaviour is ideal and allows concurrent access to filesystem from multiple threads with different UIDs.
Either the author has never heard about Blockchains, or they are just plain wrong. (yeah, it's obvious that the post is rage bait)
ok, i'm going to go ahead and block you as you've made no point whatsoever and can clearly bring nothing to the table
Thank you!
Why do people keep writing articles about this? It‚Äôs basically the simplest thing you can do with Docker, so if you‚Äôre aware of Docker at all, you should know how to build a Go binary. 
IBM ported Go to the Z machine so they could do blockchain on mainframes, so there maybe some synergy here. :-)
google tells me surrounding text with backticks renders it a \`code block\`
I think 'find ASCII values' is a bit of a reductive way to describe their usefulness - they are useful for all kinds of character processing, and particularly they work for all UTF-8 text characters, not just single byte ASCII characters.
No https://www.reddit.com/r/golang/comments/84o986/why_is_gos_regex_so_slow/
Poorly written. I usually upvote these types of articles for the sake of diversity, but not something that's so low quality. 
Since they can represent a UTF-8 code-point, use `rune` as a replacement for `char`
In order to simulate db behavior without changing code, you can use https://github.com/DATA-DOG/go-sqlmock it helps to maintain correct TDD practices. Though, a good option is also to pass in interfaces instead of actual sql.DB instances, so you could reduce the unit test code, for methods like findUser or similar when already tested using mocked database.
Removing that would certainly speed things up :-) &amp;#x200B; The OP might find this progressbar usefull: [https://github.com/schollz/progressbar](https://github.com/schollz/progressbar) . (I¬¥ve been using it a few times myself for lengthy batch jobs) &amp;#x200B;
On reddit you get the nice code formatting by preceding the code block with four spaces.
Bonus points if you post crochet program in Go!
pretty boring. i was hoping for something that triggers a good old fashioned flamewar. but this isn't even worth a fartwar
I'm not sure if you don't know or choose not to mention it but if you don't force the GC then the biggest part of it is threaded and won't affect your program (unless tied for CPU). forcing the GC is a bit misleading as it makes it look / sound like every time the GC runs your whole program would block for that long. a better way to look at GC is using GODEBUG=gctrace=1 and you can see most of it is simply in the fan out phase and not that harmful. 
hmm, that didn't work for me, but the reason why backticks wasn't doing it was because i was in the fancy pants editor which escapes the ticks (thought it has a UI element to do the formatting) when i switched the markdown mode, backticks did the trick. 
Printing is the most common use case - a user can provide any number of arguments to be printed, possibly of different types, and variadic arguments support that. Take for example the signature of fmt.println: func Println(a ...interface{}) (n int, err error) It's very similar to T.Error, because the arguments to T.Error are basically the error message to print.
There are many good use cases that you'll run into. For example, in the standard library, strings.Join() expects the first argument to be a list and the second to be a delimiter for joining the strings. This could also be implemented as a variadic, like so: func vJoin(delim string, strs ...string) (r string) { for idx, str := range strs { if idx &gt; 0 { r += delim } r += str } return r } The variadic argument is accessible as a slice inside the function. This can be useful for something like a reusable function for running shell commands, or for doing a poor man's form of overloading where you have a single interface to several similar functions.
ok, glad to hear that, but now my question is what is it about the language that allows a function like, say, Println to assume that no matter what I feed it will be printable. Some languages have every language object or whatever inheriting from something or delegating to something that provides a default toString (or the like) implementation. Golang must have some sort of mechanism to ensure that printing works, what would it be.. 
unicode.IsLetter(rune(√§))
Every time you need to parse a string char by char (e.g. reverse string) or get the length of a string, you need to think about runes. See Playground https://play.golang.org/p/2QQZCHJ7rJq
&gt; EDIT: after your update I realize you're talking more about the interface{} part than the variadic part. Yeah pretty much, and not just that, I get why when writing my only function I might want that, because unless it's a library I know the range of values I'm passing in and I can use a reflection mechanism (I know they exist in Go but haven't got there yet) to find out what I'm dealing with in the function body and work with that. &amp;#x200B; What puzzles me is library functions that are that open ended, they have to be able to makes some assumptions and I'm trying to get at what and why they are. &amp;#x200B; Moreover, even library functions like, say, `func Printf(format` [`string`](https://golang.org/pkg/builtin/#string)`, a ...interface{}) (n` [`int`](https://golang.org/pkg/builtin/#int)`, err` [`error`](https://golang.org/pkg/builtin/#error)`)` I can relate to, because the format string implies the contents of the blank interface slice, so what really bothers me is just the arbitrary amount of arbitrary arguments to a library function. 
Per [the documentation for fmt](https://golang.org/pkg/fmt/), each type has a default format (ctrl-f for "the default format for %v" on that page). This can be overridden by implementing the Stringer interface's String() method. I'm not sure what the particular implementation is - Go doesn't support inheritance, so it's probably not quite the same as delegating to a superclass.
Because configurable selection of cyphers has been a source of many security holes in the past.
Yeah I see your point. It's not intuitive, very open ended. But as someone else mentioned, I think it's just for printing. Maybe just because it makes some cases easier, like passing a function directly as an argument and having its return values printed.
hmm, makes sense, interestingly [https://tour.golang.org/methods/17](https://tour.golang.org/methods/17) see there where the tour teaches about the Stringer interface, if you remove the String method definition, fmt.Println still prints out the the contents of the struct by a different implementation. so there's certainly some usable defined behavior on G types. I'm going to look at the spec.
So cute
Ok, taking a look at the source-[https://golang.org/src/fmt/print.go](https://golang.org/src/fmt/print.go)\- it appears the fmt.Println indeed makes use of reflection when necessary. (look a the switch and comment starting on line 636, which is couple of stops down the Println rabbit hole) &amp;#x200B; accordingly, its just seems like code accepting arbitrary arguments, just handles whatever it handles via reflection, and probably only handles relatively simple things, like printing as you've said above. &amp;#x200B;
Reminds me of my office gopher: https://imgur.com/a/YcleDiT
They lost my interest from the first gripe that chooses to pick on the naming of package vs module. Why make that an argument even? Why attribute it to being special? For the record, Python has a package terminology. It just happens to be the opposite of Go where a package is a collection of modules. 
Please tell me you have an etsy
Is the trouble involve handling the inner maps? You need to type cast the inner empty interfaces back to maps to access them. What exactly you need to cast them to depends on what data type they are in the first place. It isn't clear from your text. You can always use `fmt.Printf("%T\n", x)` to print out `x`'s type.
I did a similar library last year: https://godoc.org/github.com/fishy/rowlock. Some key differences are: - `rowlock` uses `sync.Map` and `sync.Pool`, instead of `map` and a lock. - `rowlock` only provides an interface similar to `Locker`, not `RWMutex`. But it allows its user to provide a different `Locker` implementation. - `rowlock` doesn't remove locks after unlocked. The main reason is that it's not possible to guarantee atomicity without adding an extra lock (make sure that when you are removing the lock another goroutine didn't get the lock at the same time. your current implementation also can't guarantee atomicity in such case) and I don't think the saved memory is worth the extra speed overhead of the extra lock (also in your case, the builtin map has a bug that [it doesn't really free the memory of deleted map entries](https://github.com/golang/go/issues/20135).)
They represent unicode codepoints. Utf8 is an encoding of unicode.
It's still an experimental feature... It will also take a while for the tooling ecosystem to catch up, so it's ok to wait if you can.
I'd go to www.golang.org and take the go tour, it will show you the basics. Another starting point is gobyexample.com, you can use the playground at play.golang.org to get a hang of go before actually installing it on your computer. Go and python are quite different, the former being a compiled and typed language (the use of variable types is mandatory) while the later is an interpreted scripting language. Jumping from Bash to Go will require you to think a little bit different, but totally worth it.
Can I get one?
Searching around a bit looks like an awesome person already wrote a library to do this, check out [https://github.com/go-vgo/robotgo](https://github.com/go-vgo/robotgo). If you are unfamiliar with using code from Github, this is a great opportunity to get started. The actual code to control the mouse and click looks very easy from the examples. If you need any help with it let me know. In both Python and Go, you need to use the operating system API's, which are generally a huge pain in the butt with terrible documentation. For Go, it looks like the person writing the library had to write a lot of C code for it to work in Go. So, don't feel bad if this feels really difficult, it's not something that people normally in a general purpose language like Go or Python
Nice. Unrelated, but a little trick with variadic arguments, if you don't know already, is that if you have a slice, you can pass it as a variadic argument by appending `...` to the variable name in the function call.
thank you
I don't think that is what OP meant by "click"
Haha, yeah I must be tired
BTW, though Go's type system is missing some capabilities that are common in modern programming languages, it's still a better tool of choice for real world's serious software system.
Thanks. I did the most of the tour already. I‚Äôll give gobyexample.com a try. It‚Äôs a massive shift, and most of the Go I see looks like hieroglyphics, but I‚Äôm sure Bash was similar when I started, although this involves both new syntax and new paradigms.
So the main thing you need to get used to is using libraries and using syntax, searching up examples etc. So for each common bash oneliner try recreate it in go: &amp;#x200B; e.g. cat file1.txt (look into ioutil - [https://gobyexample.com/reading-files](https://gobyexample.com/reading-files)) &amp;#x200B; Conditionals, maps, lists, loops, structs, parsing data (look into using strings.Split, yaml, json unmarshalling into a struct [https://gobyexample.com/json](https://gobyexample.com/json)). &amp;#x200B; Essentially, BASH is quick and dirty. Go is a bit of a jump up. Personally, if you want a quick language to learn that has plenty of examples, I'd start with Python - Go as a first language can be daunting. &amp;#x200B;
Get used to typing a lot more code to do the same sorts of things. 
I am using mysql with beego ORM 
Surely Go implies switching the first a little, but within a few days you will see how elegant and intuitive it becomes. A good way of learning is to solve problems, you can head to https://exercism.io/tracks/go and get a hang of it. But, if you want to start with simpler task, as I did, look for projecteuler.net, they are fun to solve and will help you with basic coding: conditionals, for loops, functions, and such. Hang around if you need any help :)
Soo cute. I love it üòòüòò
Not generally classed as reflection, the construct used is called a 'type switch'. Commonly used to figure out the type of a variable, also useful when given one of a set of error types: &amp;#x200B; [https://tour.golang.org/methods/16](https://tour.golang.org/methods/16) [https://yourbasic.org/golang/type-assertion-switch/](https://yourbasic.org/golang/type-assertion-switch/) &amp;#x200B;
Can this be used for json data, and would it be of any use in a micro service architecture where you could deal with 1000s of messages per second between services? Not sure if the actual time to compress and decompress is worth it especially for potentially smaller chunks of data (say a few dozen bytes up to a few hundred bytes per json message data). Asking to determine if it would allow more message handling due to less data being sent...
Low low
do you use jwt? gorrila cookies? sessions? got any examples online of implementations?
Nice) I have some like that: [https://rasarts.github.io/Crochet-maze/](https://rasarts.github.io/Crochet-maze/)
For the uninformed, what makes Go special for blockchains? Is there something in the blockchain domain that Go can achieve and other languages cannot?
Auth0 uses JWTs. They have fantastic documentation on their website.
Ah, missing security is a feature, cool
I ain't gonna click on that
Without having done any benchmarks, my gut would say no. it would probably take more time to compress and decompress at this size of messages than to just send them over the network uncompressed. If you get to way bigger messages this might be a very valid technique to Look at. 
Pipes are equivalent to Goroutines + Channels Input, process, output. Rinse, repeat... üòé
Quick? Maybe! Dirty? It‚Äôs equally easy to write bad code in all languages.
Aren‚Äôt char typically one byte values?
Thanks. My initial thought as well. Good thing is it should t be difficult to throw it in the mix once I have the ability to gauge performance and see how will it works. Good to see an improvement in speed none the less. 
That wasn't what I said. I was just pointing out that the spot of "biggest CS scam of the 21st century" is already taken.
No, bash is dirty. All variables are text, there are no data structures. It relies on calling binaries written in other languages to do anything difficult
Dont know why He did the - a but the CGOENABLED=0 is necessary if you use the alpine image because alpine uses the musl c library. it is absolutely not needed to even use alpine at that point though because the App does not rely on any features the image provides (besides the certs but im fairly certain there are images that just provide those without a full distro in the image). He should really have explained why he uses these flags. Other than this: Yeah they could really stop writing beginners guides and start writing some advanced guides. 
Thank you a lot for the comment. I altered my code to use sync.Map. Can you please explain why do you use free list (sync.Pool) with sync.Map? About `I don't think the saved memory is worth the extra speed overhead of the extra lock` - in my case there will be over tens thousands of locks (mutexes) so length of the map will be increased to huge spaces over time. So I think it would be miserably to not remove unused locks from map
Not very clear for now, but works well - [https://github.com/s-kostyaev/.emacs.d/blob/db8d31d99ee60fffa77724ad7d845e3aad8d1cbc/init.el#L390-L532](https://github.com/s-kostyaev/.emacs.d/blob/db8d31d99ee60fffa77724ad7d845e3aad8d1cbc/init.el#L390-L532)
Oh, the horrors!
Why not use docker compose?
Still GC eats CPU, and some times a lot of. Certainly, if you use Go for writting in-memory storages, it is better to keep data out of GC heap.
thank you for the links the switch checks for what can be handled without reflection as the introduction comment says but the default on the switch uses reflect
A good place to start (with any programming language) is to check out the config that Prelude includes: [https://github.com/bbatsov/prelude/blob/master/modules/prelude-go.el](https://github.com/bbatsov/prelude/blob/master/modules/prelude-go.el). You can also check out the config Spacemacs includes, but I find Spacemacs a bit harder to understand: [https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/go](https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/go) &amp;#x200B; Personally, I use Prelude, which provides good configuration out of the box. I also have some extra customization for Go in addition to Prelude's defaults: [https://github.com/cfclrk/dotfiles/blob/6033b82dcdedc104955dfd4e73a7b857be6e92f6/emacs/init.el#L233](https://github.com/cfclrk/dotfiles/blob/6033b82dcdedc104955dfd4e73a7b857be6e92f6/emacs/init.el#L233). I think my favorite feature that I don't see in your config is hitting "C-c ." in a test to run the test.
Only for na√Øve systems that think there is only ASCII
The Go Programming Language by Donovan and Kernighan - also know as The Book.
When scanning quickly, my main concern is that you're very bound to your CLI cobra implementation. If it's a one-off and you don't want to re-use much, it's fine. But currently it feels like if you ever want to turn this into something else, say an API, you'll need to do some refactoring and copy-pasting. Some minor stuff regarding your ES client: - Don't use log.Fatal(..). Return errors instead. - The BulkProcessor can have a before and an after function to execute. The After-function can be useful to view the result of each request that was executed. This way you can spot if e.g. 1 of your index requests failed for some reason.
Start simple and play around. Implement `echo` in Go. Then `cat`. Try making a simple version of `grep`. Once you feel adventurous, try implementing a minimal shell (just the pipeline part). It will teach you goroutines, which is a core component of Go. Start from what you know and extend into the new realm. Play around with *problems* you understand well (e.g. the ones that are solved with `echo`, `cat` and `grep`) and try finding solutions to them in the new environment.
Nice list! You have a pull request.
yes, we can use docker compose. Using code in the app will help us remove the dependency on docker compose the file. 1. Everything becomes code by adding it in go application 2. No external dependency on docker-compose file and no need to wait for docker compose file to start running Docker container. 3. We can take action inside our application in case of failure to start docker container.
I don't like Go much, but this is just terrible.
Somewhat off-topic from this compression post: If you're looking for performance with sending lots of messages between services, it can be much better to look at e.g. protobuf or flatbuffer. JSON marshal/unmarshal is incredibly slow, which is an easy win if you switch to better formats. You can of course move to better versions of JSON en/decoders, but it's going to be a pain regardless. If you're sending a lot of numerical data, JSON is also not very size-optimal as it's basically strings you're sending, i.e. a byte per digit. Protobuf and flatbuffer both allow for better representations of these values. There's other formats as well of course aside from protobuf and flatbuffer, but those are the ones I have experience with :)
That‚Äôs correct about disabling Cgo on Alpine, but this code is literally copypasta: https://medium.com/@chemidy/create-the-smallest-and-secured-golang-docker-image-based-on-scratch-4752223b7324 https://medium.com/@pczarkowski/using-docker-multi-stage-builds-for-go-apps-f4ed578b99d8 https://flaviocopes.com/golang-docker/ https://blog.codeship.com/building-minimal-docker-containers-for-go-applications/ I‚Äôm sure there are more. None of them point out that -a means ‚Äúrebuild all, ignoring cache‚Äù which is pointless on Docker. The cgo suffix is also pointless AFAICT. 
https://gopher.golangmarket.com 
Sorry, I misunderstood.
I literally look like surprised Pikachu rn
There are some data structures in bash. Associative arrays (maps) for example.
Not really. Closer equivalent would be a chained method call or something, e.g. thing.First().Second()
[removed]
Aside from what's mentioned here already.. I think a major difference between Go (or any programming language) vs. scripting, is that in scripting you're looking at: &gt; Program A outputs X, so I can process this with program B to have it output Y With everything being text output as you've said yourself. In programming languages you do it more efficiently basically. You don't use program A, B, C, etc., you just write 1 program that does it all. You also don't use text, you use "objects" that holds all the required information much more conveniently. Essentially it's still all there though. For example piping in scripts translates to using functions in a row on each other's output: cmd1 | cmd2 | cmd2 vs. output1 := func1(args) output2 := func2(output1) output3 := func3(output2) It's a bit of a turn-around in your mind though. I was more familiar with programming and started scripting only afterwards. I had similar issues as you, but then the other way around :) 
I kinda kept a list of resources as I went along. https://docs.google.com/document/d/1Zb9GCWPKeEJ4Dyn2TkT-O3wJ8AFc-IMxZzTugNCjr-8/edit?usp=drivesdk
Thanks, MrPhatBob. Nice addition, and already merged!
i agree with you. Working with JSON/XML/YAML I almost always use Python. It feels more natural. Go and JSON is a real pain to work with. Especially nested JSON data.
&gt;http://eagain.net/articles/go-dynamic-json/ Its a good page but a more complex example is warranted with the page -- [http://opensource.adobe.com/Spry/samples/data\_region/JSONDataSetSample.html#Example4](http://opensource.adobe.com/Spry/samples/data_region/JSONDataSetSample.html#Example4) &amp;#x200B; &amp;#x200B;
&gt; then in app-&gt;config module we are putting the dependency for app-&gt;utils using the external github link. If you refer to the `import` directive, no external links are used here, only local paths that often tend to look like URL's to online repository hosts. `go get` is the only tool in the Go toolchain that actually has a concept of external code repositories. When you go-get a package, `go get` creates a local path resembling the URL path. This avoids name clashes between different packages of the same name.
You're going to get a pretty biased answer in this subreddit
Haha, posted on both Kotlin and golang subs. Just want to learn the pros and cons, if there was more time, I'm sure learning both languages is the best way. 
there is no right and wrong awnser here. GO will be better in some edge cases and same goes for kotlin. Both are greate modern languages with similar use cases.
They are both fine probably till you hit a massive scale then issues start coming out. I think try both and see which language you like the best and go with that one. 
As someone who uses both languages professionally, I'd personally steer towards Go for backend services that rely on widely used other technologies. Kotlin has the advantage of being able to use java libraries, which is quite mature. Go however, has the guarantee of ultimate stability of you do error handling right. Kotlin however doesn't enforce any strict error handling. And on the backend, I feel like that extra little verbosity for error handling in Go is worth the added stability. 
it simply does not matter
Nice.
For microservices(that exclude mongodb) and CLI apps I find Go to be a good choice. I'd use kotlin for a full stack app which requires authentication, payments etc.
Yeah makes sense, thanks.
[removed]
Read [the source code](https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/regexredux-go-2.html) !! m := pcre.MustCompile(pat, 0).Matcher(bytes, 0) The fastest of those Go regex-redux programs [use PCRE]().
`sync.Pool` is to be used with [`LoadOrStore`](https://godoc.org/sync#Map.LoadOrStore), which is the only way to guarantee atomicity on `sync.Map` without using an extra lock (you used an extra lock instead of `LoadOrStore` in your implementation). With `LoadOrStore` you need to prepare a new, unused lock in case that the key doesn't exist in the map, but if the key already exist in the map, the new lock is unused. So using a `sync.Pool` will limit how many unused new locks we creates (just leave them to be collected by GC also works, but `sync.Pool` will hugely reduce GC load in this use case). The problem of trying to remove locks after unlocking is that it's very hard to guarantee atomicity. In you [current implementation](https://github.com/enfipy/locker/blob/1187c420c4d2c50644b4da0961d18f3fcafc8d2d/locker.go), it's possible that one goroutine trying to lock already got the lock and just about to add the pending number ([L41](https://github.com/enfipy/locker/blob/1187c420c4d2c50644b4da0961d18f3fcafc8d2d/locker.go#L41)), while another goroutine is removing the lock after unlock ([L79](https://github.com/enfipy/locker/blob/1187c420c4d2c50644b4da0961d18f3fcafc8d2d/locker.go#L79)).
I love Go but my fulltime work is in Kotlin In truth, both choices are fine. Go with whatever you'll find most fun or the one you're most comfortable with. You dont _have_ to learn Spring, there are much simpler options if you're keen. I use this, its very simple and easy https://github.com/http4k/http4k 
it really doesn't
I've been mostly playing with kotlin to see how it compares to node/go, never done production apps with it, but really enjoyed using [ktor](https://github.com/ktorio/ktor). You can look through the samples [https://github.com/Kotlin/kotlin-fullstack-sample](https://github.com/Kotlin/kotlin-fullstack-sample) to get an idea.
I am not sarcastic, your comment really reduces my OCD.
Thanks a lot. I was thinking of moving "selflock" directly to functions Lock/Unlock and RLock/RUnlock, so that goroutines would wait for other ones to complete. `it's still trivial in modern servers` - yes, it would be several megabytes of data (if more than 1kk mutexes) and [Loads, stores, and deletes run in amortized constant time](https://golang.org/pkg/sync/#Map). I cannot refute your arguments. So removing mutexes would be the best solution? Or am I missing something?
devops engineer here. You see most people use python but I love go because its a single binary that just works
IMO, you should spend some time writing C. &amp;#x200B; To make the shift from "scripting" to "programming", it will be useful to understand (at least conceptually) machine architecture, memory management, and data structures. C is a relatively simple language, that doesn't do much for you. After you've had to think about exactly what goes into storing and processing a string "under the hood" you'll be in a much better position to understand what higher level languages like Python and Go are doing for you, and how to write code in ways that work with the machine and compiler as opposed to against it. &amp;#x200B; If you understand why 4096 is theoretically a better choice for a buffer size than say, 5000, and how pointers and structures work, you'll have a much easier time learning lower level (relatively speaking) programming languages like Go. You're also likely to be a much better programmer in any language you try your hand at going forward. &amp;#x200B;
&gt; https://github.com/tinylib/msgp I am going to assume at this point, early on, that *most* of the messages will be very small.. like short bits of json. I absolutely go against the norm and try to optimize early on, but time is also a concern and learning new formats/libs may not be in the cards. My thought with the compression lib, Kanzi, was that it would fit in like a chain.. Rest API request comes in with some json, determine what service to send json to, run it through the compressor and send it. If it made sense, basically my "send to service" would just build in automatically every json string being compressed, and the "receiver" would always uncompress. But if the majority of json is a few dozen bytes to a few hundred bytes in size, and the added resources to compress and decompress are not beneficial in the majority if situations, then its probably better to just send the json as is for now. MQTT which is what I am using for now, uses JSON anyway, so it may fast enough. Also, I could very well do a simple request body length check and if its larger than a few K or something, compress, then on receiving, via a message header check possibly, determine that it was compressed and decompress automatically. Protobuf didnt look that worthwhile to me, but maybe it is. Again, try to optimize where it makes sense out of the gate, but in this case it may not be as important to do right now. 
&gt; I was thinking of moving "selflock" directly to functions Lock/Unlock and RLock/RUnlock, so that goroutines would wait for other ones to complete. I'm not sure what you mean here exactly. But if you mean lock the whole `Lock` function with a global lock, don't do that, it won't work because the inner `Lock` would block which means you are gonna holding the global lock for a looooong time.
/u/jerf knows his shit and is worth listening to.
Would you mind sharing how do you use go for devops?
Random http apis into things. Scripts that need to be done. One example of it is a script to import data into HDFS and it pulls from olfactory. 
If you use curl a lot, this tool will help a lot: https://mholt.github.io/curl-to-go/
They both have their use cases and likely both worth learning to some degree. Python is on almost all systems, easy to read and write and does not require a compiler on the target system nor a separate build environment. But extra dependencies can be a pain if they are not packaged by your distribution. Go on the other hand is easier to distribute than multi file python applications and I find it just as easy to read and write but can be a bit more verbose. But far more important than any of that is what other tools use. Saltstack, ansible and quite a lot of other DevOps tools use python and benefit from knowing a bit of python as it tends to leak into how you configure them. It also helps if you want to extend these tools to do things they where not written to do and are quite pluggable, but require knowing python to do so. But go is used but a large amount of other DevOps tools like terraform, consul, docker etc. But it does not tend to leak as much into the configuration of these tools so you can happily use and benefit from them with out knowing any go. But they can also be extended, which is generally best done in go so if you want to extend these then just like the python tools it helps a lot to know the language they are written in, ie, go. So, a lot of it depends on the tools you want to use and more so which language you prefer to use. But it will not hurt to know a bit of both languages and focus more on the one that benefits you most at any given time.
&gt; Why people claim that Go is not object oriented Some people think that inheritance is required aspect of object orientation. 
[The same question was asked a couple of days ago](https://www.reddit.com/r/golang/comments/a8zgvm/class_vs_new_type_receiver/) with a bunch of answers :) (I'm honestly confused about the coincidence. I've never seen anyone claim that Go is not object-oriented, at least not from the Go side of things. So having two people being confused by everyone claiming that seems weird to me :) )
[removed]
Looks promising.
OOP takes on different meanings depending on who you ask. Some people equate OOP to classes and inheritance and since go does not support these they do not think go can do OOP. But OOP concepts can be, and arguably better expressed by, composition and interfaces. Which are core parts of go and thus go can be considered an OOP language. In truth no language is singularly OOP, precdual, functional or anything else but instead borrow from all the various concepts to some degree which gives you some flexibility in which style you can write in each language. Though some make it easier to favour one style or another.
Not a dev ops myself. But in our company we use Go for automation tasks. If I recall correctly that's due to Kubernetes and conteinarization stack. It seems that conteinarization / cloud stuff is mainly managed with Go. While previous solutions were managed with Ruby / Python. Don't quote me on this. Point being, it depends on tech stack. Although having in mind that Kubernetes is becoming the enterprise standard, I would expect to see a lot more Go.
Object Oriented normally implies structures with special behavior and classification. Go has structures without special behavior or classification. These things are demonstrated most apparently by the lack of magical struct methods like constructors and by the expression of polymorphism being restricted to descriptions of behavior rather than groupings of concrete implementations. The behavior of the "new" keyword versus other OO languages is worth noting. Also, polymorphism via closures, in my opinion, is similar enough in nature to an interface with a single method to qualify as a "description of behavior".
I prefer go because I don‚Äôt have to install python on the target machines. With go I can just run the compiler executable and it‚Äôs good. 
These two Go wiki pages are good starting points: [Learn ¬∑ golang/go Wiki](https://github.com/golang/go/wiki/Learn) and [Training ¬∑ golang/go Wiki](https://github.com/golang/go/wiki/Training) 
[removed]
What matters more here is your deployment and maintenance strategy. Keep in mind that you'll have to deploy `Java` runtime for your `Kotlin` back-end and that both `Java` and `Kotlin` are getting rather big changes lately (I am talking feature updates, not just security updates). `Go` has been stable for a long time and maintains compatibility guarantee. Also easy to deploy (only `libc` dependency and libraries for modules compiled with `cgo`). In the end it may not matter to you. Use whatever you feel more proficient with.
Yeah. Sure. Imagine you have some identification request processor service which consists on 4 subproccesses which some of those consist of 4-8 subprocesses and those have even more? First of all, why do you want to read everything to begin with? You want to read just enough as it is required according the the level of abstraction you're currently operating in. For example, when I'm thinking of how to sent an email to employees who check certain type of document, I don't want to be concerned about how image of indentification request is being processed. Now ofc image processor will be separate service which is being reused not just in indentification request, but anything else concerning uploaded images. So it has to be kept separate. So does emailing of responsible employees service which will probably be invoked in some listener / middleware. You might have quite complex dependency trees. And you really not only want to see all of the verbosity associated with initiation of high-level abstraction, you don't really even want to care about it.
Just for fun. package main import "fmt" type Cat struct{} func (c Cat) Meow() Cat { fmt.Println("Meow") return c } func (c Cat) Sleep() Cat { fmt.Println("Zzzz...") return c } func main() { felix := new(Cat) felix.Meow().Sleep().Sleep().Meow() } &amp;#x200B;
https://hackernoon.com/aws-lambda-go-vs-node-js-performance-benchmark-1c8898341982 Go outdoes node.js as far as technical spec is concerned in all aspects by quite a huge margin. It's also productive to work with. Generally, I have difficulty to find justification why even bother with node other than some open-source libraries. But that's my personal take :)
Printing to stdout for each line could be slowing it down a bunch. You use a modulo operator to log every 1000th operation and speed things up a bit. \`if lineNumber % 1000 == 0 { fmt.Println("some stuff") }\`
apples and oranges
Curious gopher. Do you mostly use kotlin with already existing java frameworks or people prefer pure kotlin libs ?
I end up using Go for most of our [Prometheus](http://prometheus.io) related operations. I've done exposition in Java and Python as well, but Go is almost always more light-weight for that particular use case.
I doubt you will receive much help from community by trying to gloss over something what that community regards as gross offence against it. I work with Symfony on daily basis. I also do things in Go. However, I'll take my liberty to refrain from further comments due to recently manifested behavior on your part.
I'm uncomfortable with anyone using extremely rigid terms to define a language in purely binary terms of whether or not it's a [paradigm] language. Even assembly can be written following OOP principles, so long as you are managing some kind of in memory "object". Being too strict otherwise leads to a lot of pedantic silliness, where people care too much about specific syntax. Eg in JavaScript, you heard a lot of people who thought the `class` keyword suddenly "made the language OO", even though it was really some thin (perhaps unnecessary) sugar around its existing `prototype` system. You get further muddied by frequent misunderstandings of what oo is. It's too frequently considered a procedural paradigm, or worse as somehow the "opposite of functional programming", which it is not. The question really isn't whether or not it can be oo, but if it's easy/expressive/comfortable for writing oo code in. It doesn't have a built in system for polymorphism, but personally I'm not a fan of that even in heavily oo-favoured languages like Java or PHP. Simply lacking features isn't enough to say it's "not suited" for a paradigm either -- nobody asserts that go is a bad language for looping or conditionals simply because there's no `while` or ternary. A lot of languages kind of force your hand into oop, but using `class` because you're forced to (eg to trigger the autoloader in PHP) isn't the same as the language being **good** at oop. 
What you said sounds reasonable. I'd still love to have a GitHub PR/commit link of a real life project to see for myself.
Generally the latter. I dont write kotlin so i can use java frameworks, most of which i find horrible. Java _libraries_ on the other hand are often handy. 
so... your point was... nothing?
My point was to be humble towards people you are asking for help. Might actually serve you better on the long run.
Why aren't things like Vue.js and vuejs grouped? Same thing for react. 
[removed]
First off, composition over inheritance does NOT mean we never use inheritance. We use inheritance when it makes sense. The reason Go is a functional language is because while you can follow some OOP principles, Go does not allow for using all OOP principles so it can‚Äôt really be considered on OOP language. Having said that, what does it really matter? If you enjoy writing in Go, then just do it and if you utilize some OOP principles in the process because they help produce cleaner, more readable code, great. Don‚Äôt worry about the labels. 
Free and quite comprehensive book: https://www.programming-books.io/essential/go/
The only missing thing is sessions which is important . Granted you can write your own session management library but the same can be argued for any component. Of course no other language I know comes with a server in the standard package so that is definitely cool 
Chained method calls don‚Äôt pass the results (particularly so in your case) and are synchronous. Pipes and goroutines + channels share the pass the result and asynchronous operation.
k8s, docker, terraform, and etc are written in GO.. Definitely worth picking up
Why the hell is .net still a thing? Are there still ColdFusion devs lingering around too?
&gt; Granted you can write your own session management library but the same can be argued for any component. Or you can use Gorilla's [sessions](http://www.gorillatoolkit.org/pkg/sessions) package, since Gorilla's already in the mix for routing purposes.
Python does, but i wouldn‚Äôt use it for production. 
[removed]
Windows, and therefore .Net are firmly entrenched in healthcare. Personally, C# is a joy to program, especially when filling the wide niche Java does. I'd really like it if we could use something different for our remote services but hospitals want to own all the hardware and that means windows licenses. Even if we could convince them to use cloud linux platforms, .net core would be our first choice so the front end and back end aren't out of sync.
The regex used to determine Go related jobs skips many valid jobs. Someone submitted an issue to fix this: https://github.com/venkateshthallam/hn-whoishiring-analysis/issues/1
Gorilla and regex sucks in performance, ppl just don‚Äôt care about perf these days?
&gt; The reason Go is a functional language You mean procedural?
It all depends on where the performance issues are. If my app is getting 100 requests per second, i probably wouldn't care and would just choose whatever library was the easiest to use. Keep adding zeroes to that rate, and re-evaluate and look at profiling data.
I think that your question is spot on, in that what mainly makes Go "non-OOP-like" is that classical OOP (as the name implies) focuses on classes and objects as the unit of encapsulation, whereas Go focuses on the package as the unit of encapsulation. There is no "private" (only visible to the class), but only "unexported" (visible to everything in the same package). And that shows in the way you program too - you don't have a type per concern, but a package per concern. And a package might have zero, one or more types :)
&gt;Of course no other language I know comes with a server in the standard package so that is definitely cool NodeJS also has it built in for production use. I'm sure there are many others too.
The preference should be ‚Äúwhich do you know and which does your team know‚Äù. There are pros and cons to each, but for ops tasks it‚Äôs a coin flip since raw performance isn‚Äôt usually a concern. Go is great for command line tools you need to distribute since it is a single binary, but... you can package up any old Python app in a docker container with a shell alias and it‚Äôs as easy to use. Many ops related tools are written in Go now (k8s, vault, consul, Prometheus, etc) so being familiar with it can be a plus. 
‚ÄúDo you need X?‚Äù is a different question from ‚Äúdo you want X?‚Äù. My most substantial project in Go implements some 15 HTTP endpoints. I spent a good amount of time abstracting commonalities between them in the beginning, only to realize I was reinventing the wheel about one third of the time, and then having to test it remained round for every use case I had, which was a complete waste of time. I moved everything to Gin in a single afternoon and haven‚Äôt looked back. My guess is the average Go developer writing code REST endpoints for a living is better served by using a simple framework. For the speed freaks out there, there‚Äôs always the standard library.
Go is great for working in environments where you can‚Äôt or don‚Äôt want to install dependencies, since it compiles into a stand-alone binary. Great for one off tasks where you just want to pop in and get something done without having to get the whole environment set up.
Go fits better with specific utility libraries that implement the functionality you need, rather than frameworks that try to make those decisions for you. A good library will play equally well with the stdlib and any other helper library. A good exampe of this is the gorilla suite which has a mux that's useful for REST and a session library, both work well with the stdlib and other such libraries and don't enforce that you stay in the gorilla "ecosystem"
A framework is nothing but a half built solution which gives you an ability to write best practice code, not to start application from scratch and built in good strategies noting but Design patterns. They differ language to language because a particular framework addresses a particular domain (requirement concern), where actually it gets fit to remove the repetitive concerns. My daily job is just to implement rest service with JAX-RS (easyrest implementation) I don't use any framework to do this,
.net core comes with kestrel built-in. 
Yeah I have some similar thoughts, one of my concerns for Go is that it has very few libraries, also what do you think a startup should go with, keeping in mind to minimise server costs, connect to databases like Elastic search and MySQL. Also do you think any framework like gin and echo should be used to be safe and future proof
Yeah I have some similar thoughts, one of my concerns for Go is that it has very few libraries, also what do you think a startup should go with, keeping in mind to minimise server costs, connect to databases like Elastic search and MySQL, integrate authentication and payment. Also do you think any framework like gin and echo should be used to be safe and future proof
Yeah I have some similar thoughts, one of my concerns for Go is that it has very few libraries, also what do you think a startup should go with, keeping in mind to minimise server costs, connect to databases like Elastic search and MySQL, integrate authentication and payment. Also do you think any framework like gin and echo should be used to be safe and future proof
Yeah I have some similar thoughts, one of my concerns for Go is that it has very few libraries, also what do you think a startup should go with, keeping in mind to minimise server costs, connect to databases like Elastic search and MySQL, integrate authentication and payment. Also do you think any framework like gin and echo should be used to be safe and future proof
It is not suitable for production the way Go is, you would still need express or something similar for any serious work 
The point of the article is that you can just use the standard library without any additions. My point was that a session management package is still needed if you don‚Äôt want to waste time writing your own session management. 
Lol I actually did mean procedural. Too much Christmas cheer I suppose. 
The overall solution for my problem is to just give up on trying to make the filesystem wrapper passthrough for perms. I'll just have to create a local database file for tracking file permissions and determine if permission to a file is allowed per user in code. I prototyped a loopback file system with fuse in C just to test out fork and even that had some problems. =/
Did you benchmark your app and find that routing with gorilla was your bottleneck? Or are you referring to router micro benchmarks? 
Revisiting this thread. Thanks for the detailed reply! How does the performance compare between TF and gorgonia? 
Globals is bad idea in general. It is not read only hash map but stuff like dB connections. I personally think that biggest problem for this type of development in go is lack of unified structure. I personally use ‚Äúrails‚Äù like structure with app,Config,public,tmp but views I put into views rather than app/views. For me this makes a bit of a sense rather than flat 0 structure. Also in go you need to build stuff like from LEGO a lot of small blocks. So imho second biggest problem is lack of generalized dB approach. Global dB object works just because power of the dB package. But dB package is missing one key thing. Database migration handling so some people will use different packages to handle this. But not many people talk about this while it is more than important while building web apps unless you are using nosql or building something ultra simple with barely any scheme around. Last but not the least is handling of views and sub views things other people call layouts and views. This is also not really tackled around. My point is that everyone seems to be showing in their example single page rendering json which is fine if you are creating micro services but not so fine if you wanna build a web app. Web app requires nested views, database and Config handling and professional approach to database. I‚Äôm not even mentioning stuff like rabbit mq or different env for production, test and dev. Just basic things.
Well, inheritance does not define OOP. Is one of the ways helping to do OOP. Which frankly is regarded as a bad practice generally for doing OOP. Although people insist on different levels of rigidity when defining concepts I suppose. The reason I'm asking is that I'm quite used to composition. And all of a sudden I start organizing my code with Structs, defining received methods of the structs, interfaces and even using Dependency Injection as per official Google lib Wire supports it. And I like it. I never enjoyed classes in OOP. I always regarded those as bloatware for complicating something which could be a lot more simpler. And given that inheritance should be avoided why to even have it. :) Barely any general-purpose languages are 100% something. And employ multiple paradigms. It was just confusing for me that some people insist that Go doesn't do OO. But at this point it's a lot cleared due to people like yourself explaining how you see it! :) 
People still use templating with advent of SPAs &amp; SSR &amp; service workers? Seems like superflous feature. 
The biggest problem I see all these articles missing is this: Do you need a framework for Go when writing a single microservice? Maybe not. Do you need a framework for Go when writing 50 microservices? Yes. Definitely Yes. Why? Because abstractions are useful. You do not want 5 separate teams to waste time doing redundant stuff like setting up things like Logging, Distributed Tracing, Metrics, Kubernetes integration, Service mesh, etc. Basically all the grunt stuff should be abstracted behind a framework, so your teams can focus on delivering business logic and not worry about upgrading client libraries and setting up liviness probe, etc. Also frameworks help in uniformity, go fmt will not help you standardized your logging or tracing or database access layers, a framework will. Sometimes I enjoy just starting a new microservice by writing the business logic and letting the framework handle everything else automatically. 
Why add tones of js bloat to your app if you don‚Äôt need to? Making everything a single page app with react might be ‚Äûcool‚Äù bit sure isnt practical. If you use go for speed why you force someone to download 6mb of js crap just to check a graph and status page :)????
[https://blog.gopheracademy.com/advent-2018/go-devops/](https://blog.gopheracademy.com/advent-2018/go-devops/)
How different is this from goreportcard.com other than private repo access. 
FYI, your link is broken
I was wrong, you were right. Thanks for pointing to the source. I will read up on this.
Performance of what kind? Latency or Concurrency? Gorilla barely adds much latency. If QPS is your concern just horizontally scale your service.
I've written a bit about OOP: 1. https://medium.com/@egonelbre/paradigm-is-not-the-implementation-af4c1489c073 2. https://medium.com/@egonelbre/relearning-oop-89f10e0e2f68 tl;dr; paradigms are less about the language and more about the mental model you use to construct your code.
Go is a language. NodeJS is not.
That‚Äôs not a great name choice for something this general-purpose. Reads like thumb.ai