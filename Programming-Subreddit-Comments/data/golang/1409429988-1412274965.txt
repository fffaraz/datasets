This is good for very basic design patterns, but not so much for larger concepts. It's a good idea to read the source-code of the standard library, which has a lot of good patterns. The official golang blog has a lot of good stuff too. 
All good points. The doc I linked to is just a guide to idiomatic Go. As you said there are some lovely first party things on the blog. Due to the fact that Go is actually a pretty "regular" language (ignoring the semantic differences like using structs for OOP instead of classes) pretty much most normal *design patterns* will still apply. Design patterns are generic and broad things, the language used to implement them doesn't really make a huge heap of difference. *Although I don't use any functional languages (yet), I guess design patterns wouldn't apply there but I dunno...*
I would love to see: * [Torrent-Stream](https://github.com/mafintosh/torrent-stream) * A Node-Webkit alternative (I know of only one - [cef2go](https://github.com/CzarekTomczak/cef2go) ) * FFMpeg * Closure Compiler (yeah, long shot) 
There was another [similar package](https://gowalker.org/github.com/dustin/go-humanize) here not long ago. My only criticism is that functions index() and countSize() aren't needed because they're very simple and used only once, so they could've just been inlined in Size(), but it can be argued that it makes the code clear, etc, so it's more a matter of personal taste.
Reddit *has* a search engine.
`rune` is just an alias for `int32`.
This was proposed by the Go team at one point, but some people can't conceptualize the equivalence of allocating a `T` and returning a pointer to it with initializing a `*T` and returning it. They see an allocation function as a primitive, and a factory function as necessarily doing something extra.
A few questions: 1. Who is the book targeted at? Developers coming from web dev in other languages (i.e. PHP, Python, Ruby)? 2. Why teach a framework—and a very heavy, poor one at that? I have a ton of reservations about Beego's code quality and security. You would be doing readers a *much* bigger favor by teaching them net/http and the power of the http.Handler interface. 3. What kind of "asymmetric" encryption are you prescribing for the storage side?
You want to send the buffer you just read into, to multiple writers which will write the buffer to sockets. This means you absolutely cannot reuse the buffer until *all* writers are either done writing it to the socket, or timed out. This is going to be the case whether your code does this in C or in Go. So here is what I would do. In the read goroutine, which I assume already has a reference to the writer goroutines, I would allocate a largish (16? 64?) ring buffer for the read buffers, then allocate a counter C to zero. I then read() the first incoming datagram into the ringbuffer[C] position, and bump C, in a loop, until C reaches length of ringbuffer - 1, where I would set C back to 0. Within this loop, I would send(C) to all writer goroutines. The writer goroutine would recv(C) on its channel, then use it to access the ring buffer element that just got filled by the read goroutine, then perform the send(), and signal back to the reader goroutine that they are done sending that particular index. The reader goroutine can use this returned progress information to know which writer goroutine is the most "behind" sending data, and when that lag reaches the number of buffers in your pool minus 1, you can take action from the reader goroutine such as (a) removing the lagged goroutine from the list of writer goroutines, (b) increasing the size of the ring buffer adaptively (kinda tricky, but doable), or (c) throttling reads so you don't start overwriting unsent buffers on your ring. This provides a simple, lockless one-copy mechanism with minimal inter-thread data exchange and no extra copies.
- The book is targeted at developers who have gone through the Go tutorial and can write simple programs on their own. - Web dev knowledge is preferable but not required - Why do you say Beego is heavy and poor? I'd love to know the reasons ( I've used it on my machine and it seems to do it's job just fine ) - http.Handler interface will be covered in the introduction chapter itself. - There will be no asymmetric encryption on the storage side. That's a typo on my part. Thanks again for the feedback, I really appreciate it! 
The specific problem of using a single buffer with multiple goroutines can be solved [quite simply](http://play.golang.org/p/2y40Rr1DzZ). Not sure I understand the routing you're trying to achieve. Might multicast TCP be what you're looking for?
&gt; Why do you say Beego is heavy and poor? I'd love to know the reasons ( I've used it on my machine and it seems to do it's job just fine ) I've trawled through some of the code base after someone pointed out potential security concerns with Beego. I raised [this issue](https://github.com/astaxie/beego/issues/620) which showed some 'ideological differences' with how I believe a web application should handle critical/core errors. The secondary issue is that for something as "monolithic" as Beego, any readers are going be tied to how Beego does things and not how Go itself does things (through net/http + http.Handler). I think this does newbies a disservice, because their skills aren't transferable when they outgrow Beego (or &lt;insert large framework here&gt;. My (personal) preference is for smaller 'frameworks' that stick to net/http conventions and/or happily interact with other packages (the Gorilla stuff). Something no longer working for you? Swap it out! Thanks for the other clarifications too—appreciated.
I think the idea is great. Sticking to a framework is a two-sided matter. It can be great to teach someone the ins and outs of a specific framework and teach them to create great content. On the other side, they just learn to use this framework and not the internals of the language itself. But as you tell those things to the reader from the beginning on, it should not count for or against a book. But I would maybe think about changing the title to something that contains Beego ? But bookmarked the whole thing, kinda excited about how this will turn out. Even downloaded your book, but that is kind of empty right now. Good luck on your endeavour and I'm looking forward to it!
I think this is a great idea! As a nodejs developer, I'm looking to learn golang in the context of web development, and I think this book will appeal to many. As others have pointed out, however, I think including a framework is pretty nice, but I would personally like to see the core of the book to be focused on golang itself and perhaps even building a light webapp framework from scratch. In any case, I'm looking forward to reading it!
I get your point and I thank you for a detailed reply ( again ). I will refactor the book to use net/http and I will add beego and revel as appendices, so that users may get a taste of it. I think most, if not all people here want me to cover the core net/http stuff rather than a framework. I have thus decided to refactor the book. The twitter-like microblog example application will be built using net/http, Gorilla mux with Gorm. I will use Go's template package with Twitter bootstrap and Angular.js ( not too much of angular, the focus will be on sending data from the server and doing the bindings in the UI. I think this should create a well-rounded book, useful to developers. 
Thank you for the feedback. I will base it on net/http and move beego out to an appendix. I have edited my original comment (see above ) and added the details. I will keep updating and refactoring the book as I go along and I hope to produce a useful book for Go developers. 
Thanks for the feedback. I have updated the TOC ( please see my edit on my comment above ) and i hope once it's done you will find it a good read. You can 'buy' the book from the site for $0 - and it will update you whenever I publish an addition/change to the book. Your feedback / criticism is very valuable to me as the aim of this book is to be a good book for teaching web application development with golang.
I don't think your code sample does what OP wants.
What's wrong with using the same rules for non-pointers. That is, a pointer to type T would have a zero value of new(T). Of course that wouldn't work for pointers to interfaces. They'd probably need to be optional if they weren't assigned during declaration. Wouldn't that work or am I missing something?
Every hilly billy has search engine these days, doesnt mean it is usable! 
Sounds like a good solution. Ill measure performance on this with iperf and compare the single goroutine version throughput and latency to the reader + channels + writer one. Each payload is actually only sent to one destonation and not to all though so only one write is needed per read, just not necessarily to the same socket. 
an ORM purely so that the readers don't have to write SQL or is there any specific reason for it? (asking mostly because I personally do not see a point to most of the features apart from "hydrating" a struct from SQL data)
This book is highly welcome! I've downloaded it for free now, but once it's done I will certainly pay for it.
packet routing is done by the kernel, so would it be safe to assume that what you want is to accept connections in one port and then connect to one of many endpoints and then bridge those two together like a load balancer? Something like http://www.inlab.de/balance.html ?
More important that your $$ would be your feedback. I want this to really help the Go developers. Thanks a lot again for interest in this book. I will keep providing updates and requesting for feedback as chapters get done on /r/golang And since you have bought it, you will get emails when updates are pushed out. Thanks again! 
1 let's meet up. Always happy to meet a fellow gopher. I haven't met any in real life yet :) 2 yes I think a simple railstutorial.org - style book is what seems to be what people wanting. I am so glad I asked for feedback before going off on the wrong track. Please see the long comment I wrote above ( the one with multiple edits ) - your suggestion is greatly appreciated and incorporated! If you are interested in providing feedback, just 'buy' the book for $0 Thanks!! 
already using it :) , also works great with [testify](https://github.com/stretchr/testify)
I wasn't aware of GoOse! thanks for the link! I've used ruby readability before and was fairly familiar with its heuristics approach, but it looks like GoOse has some of the same features as readability. I'll make sure to use and maybe I can join the devs
Awesome, I've been looking for a book like this!
I like that idea because then you can add multiple framework alternatives later and show people what's really different between them as they would all be implementing the same functionality. I feel like when looking at frameworks now you just see a bunch of examples showing off what the framework makes easy.
My opinion is that Java 8 will shine for this types of applications on the serverside. 
Ah, then my solution may be overkill.
I think "traditional" was meant to describe a setup similar to a RoR application, where the server side handles everything. As opposed to the method of using Go for an API then JS/mobile/whatever as the view. I've not got any experience with using a Go-only stack, so cannot comment on whether I agree or not. But I am very happy with the Go-based API and a JS frontend.
Could someone put up the version that was discussed here somewhere? I too only got an empty document. (One can not help but wonder why the author is working on a version that is "live" somewhere? That is pretty bad form, even more so from a web development standpoint)
Can you qualify that opinion and point out in what ways you deem Java 8 to be superior to go in this context?
Emscripten (mobile so no link) is really quite promising in this field. No idea if it works for Java or Go (I'm really not very knowledgeable in that regard) and I highly doubt it could work with .NET but it's pretty cool being able to do C++ -&gt; JS. 
Love it and use it. However I'd like to see the runner as a generalized tool that I can wire up to other frameworks/languages.
Does io.MultiWriter solve your issues?
Related: Check out [my response on this thread](http://www.reddit.com/r/golang/comments/25290y/dream_course_on_golang/chdnj7d) from ~3 months ago: "Dream course on GoLang??" Given the content that you have already planned in your updated table of contents, my feedback: - It is great that you are writing about pushing messages to authenticated and logged in users. This is something that many golang tutorials do not do at all, or gloss over. - It is great that you are writing about background processing tasks. Again, this is something that I find quite often glossed over in many golang tutorials. - Deployment. I request deployment using Docker. Given Docker is written in golang, that will likely be a popular choice among golang developers. - I concur with the other comments - Eschew all-in-one frameworks like beego, and go for libraries such as gorilla instead. - Testing. Please include a section describing how to write unit tests for the web app as you develop. If this is done as a separate chapter, that would be good. If this is done in line with the rest of the content, alongside development, that would be even better. You have not mentioned what database technology you are planning to use yet. If you have not made up your mind, I would vote for Postgres. Reasons: - Most golang tutorials out there are based on either mysql or mongodb - Postgres is capable of storing both traditional relational data and document data - including [JSON](http://www.postgresql.org/docs/9.4/static/functions-json.html) - which means you can explore both types without the overhead of installing two different databases. Lastly, thank you for taking the time to develop a resource like this. I have signed up for updates, and will purchase the book when it comes to fruition. Also, if you are writing this book and decide to post your repo on github/ bitbucket, point us in its direction! 
You don't actually have to use done at your topmost promise. No "Bad Things" will happen. Easiest solution to .then() scoping (which is really just basic function scoping) is to nest the promise chain by that layer - otherwise, as you said, declare a variable in the outermost scope and assign to that.
Promises give you a pretty elegant way to set a top-level error handler: doStuff() .then(function (results) { // do more stuff }) // ... .fail(function (err) { // handle your error })
The article was really short and light on details, but the TL;DR of the team's reasoning for switching away from Node.js were: 1. Multiple application layers could not be brought up in tandem. 2. The infrastructure had a single point of failure if the instances went down. 3. All functions of the service ran on a single process. 4. Latency became an issue due to high CPU and network load during peak usage. 5. There was an inability to scale horizontally. The TL;DR for why they shouldn't have used Node.js (IMO, not from the article): lack of experience. Node.js (or even Javascript) is not for beginners. It takes time to write good, solid, maintainable Node apps. Time that a startup doesn't have. It sounds like they just made a poor technology choice for their team. According to the article: &gt; Falter said she knew how to write JavaScript and thought she could use that background to learn Node. I couldn't help but laugh at this part. There's a lot more to being effective with Node.js than knowing Javascript, just like there's a lot more to being effective with Rails than knowing Ruby. One thing (or rather, 5 things) that bothered me about this article were the team's cited reasons for leaving Node. I'd like to address those, in order: 1. I'm not even entirely sure what they mean by this, but if they're talking about operating a service-oriented/microservice architecture, then they're flat-out wrong. There's nothing inherent to Node that keeps you from deploying multiple instances doing different things. I've done this several times, in fact, with little hassle. 2. This sounds reasonable (ish), but is also problematic with any Go architecture I've seen. Hell, most modern server-side tech has this issue, unless you architect around it specifically. Go doesn't appear to have any better answer for this than [Node|Ruby|Python|your_favorite_stack]. Perhaps they should consider Erlang? 3. See 2 4. Yes, Node is somewhat memory-hungry. However, unless you have a single, monolithic server (as opposed to a horizontally scalable app, which is standard practice these days), this is really a non-issue. 5. This cannot be attributed to anything but the team's effectiveness (or in this case, the lack thereof). Node scales as horizontally as any other technology. You can deploy it to Heroku, AWS, etc all day long. Run as many instances as you want: if they all have the same config, they're all the same app. &gt; Text processing increased 64 percent just by moving from Node to Go. They could have easily gone with a hybrid structure here. Nothing was stopping them from hosting the text processing part in Go (as a microservice) and then using Node for the rest. Or, better yet, have a C module that handles the text processing, and call out to that with Node. &gt; As the company scaled, the task of administration became increasingly complex, due to “call-back soup”, a common complaint with Node.js. I've said it a million times: "Promises, 'nuff said". That being said, promises can be difficult to grok on your own, and because they had 0 experience to draw from, this probably wasn't an option for them. No fault on that point, but there are libraries that make managing callbacks fairly easy (not promise easy, but easy). Overall, sounds like the founder made a poor technical choice, and the company suffered. Still, I really hope they have as much fun and success writing Go as I have over the past few weeks (that is to say, quite a bit).
It really is. Great work man!
No, why would it? Go code can do everything C can (using unsafe), and the Go compiler generates *much* better code than the Plan 9 C compiler. 
Thank you for your feedback! I will be using GORM as the ORM and that supports PostgreSQL, MySQL and SQLite. As pointed out in a different comment, I plan to have 0 SQL statements in the book. 
You could try your chances in reviving this [1] old issue, someone else has even better argument than yours for renaming the language. [1] https://code.google.com/p/go/issues/detail?id=9
No. 
Interesting. May I ask, why did you decide to create a new package instead of adding stuff you miss to [gonum's matrix package](https://godoc.org/github.com/gonum/matrix/mat64)?
haha, so cool!
The job of the compiler is to generate an [ELF](http://en.wikipedia.org/wiki/Executable_and_Linkable_Format). If they emit the same file, there's no difference.
Client certificates is easiest/most secure IMHO. Implementing your own is usually a bad idea.
pretty infofmative, thanks.
I'm with /u/thockin. Either you care or don't care. If you don't care, you can sort or shuffle the enum and the program should run just the same. If you can't shuffle it then the value is important. Perhaps this is because it's sent over a network or otherwise persisted. Either way, you will want it to be a greppable value in the source rather than an implied value. I think it spends mental overhead on something which isn't actualy solving anything. Just my opinion as well.
&gt; No, why would it? Because the library code is now GC, which comes at a price. Also, Go code usually is slower than equivalent C code (at least in most benchmarks). Not saying it is slower, but the question is legit.
But it will be very important to know how fast the new compiler can create that ELF !! Go is known for fast compilation !!
I doubt it will be significantly slower. Go compiles fast because it's designed to compile fast, not because the current compiler (the one written in C) has something special.
&gt; Because the library code is now GC, which comes at a price. This statement makes no sense. The GC is implemented by the runtime, and both the old and the new runtime used it. &gt; Go code usually is slower than equivalent C code (at least in most benchmarks). This statement makes no sense. You can only compare implementations, not languages. Perhaps you are comparing gcc with the gc Go compiler. This makes no sense because the runtime C code was not compiled by gcc. It was compiled by a modified Plan 9 C compiler which generated poorer code than the Go compiler. 
Actually, it's the lob of the linker to emit ELF, or PE, or a.out, or whatever files, not compiler's (though many compilers do use ELF object files too, not Go though). This is a very confusing statement as the choice of the binary format doesn't have anything to do with, well, anything. Also, the new binaries are different from the old binaries because the runtime is, well, different. Perhaps you are thinking about the automatic translation of the compiler from C to Go. That will not affect the execution speed of the binaries and will generate the same code, but that is not what is being discussed here. 
Quite the contrary. See: &gt; Currently if C code in the runtime is found on a Goroutine’s call stack the runtime will fall back to the old split stacks method if it needs to grow the stack. When all the parts of the runtime called from Go code are written in Go, the copying stack method can be used more effectively.
This is beautiful
Thanks for the input, Simonz05, also for referencing your library. I'm going to attempt my own very soon.
&gt;Perhaps you are thinking about the automatic translation of the compiler from C to Go. You're correct. My mistake. &gt;Actually, it's the lob of the linker to emit ELF, or PE, or a.out, or whatever files, not compiler's (though many compilers do use ELF object files too, not Go though). Correct again. I was oversimplifying in an attempt to make it clear that two build tools producing the same output won't have an effect on the resulting executable. Obviously, because I was talking about the wrong thing, it made no sense anyway.
No problem, it's very easy to make this confusion; the automatic translation of the compilers has been widely publicised while the manual rewrite of the runtime has been a relatively silent endeavour for people not following -dev. If you're just hearing about the latter you could well think it's about the former. 
Mmm... I'm not sure the Go community is quite aware of why Numpy is interesting. So this comment isn't specifically about this library _per se_, but a general comment on why people (like me) say Go is weak for matrix math. The point of NumPy is that you use Python to construct the matrices (load from a file, whatever), and use Python to say what to do to the matrices, but that the actual code for the matrix manipulation is highly-optimized to go fast, using SSE and such on the processors. The end result is significantly faster than you can get with pure Go right now, because you can not get to the SSE intrinsics, let alone anything else. This isn't my field, so I don't know if there's a package you can easily bind to or something. (I know there are such packages, but a quick google search for "bindings" to these packages doesn't turn up much. I don't know if that's because nobody has bothered to make them or if there is some reason they are extra hard to "bind" to.) But if you want to make Go a viable choice for matrix or scientific computing for whatever reason, that's the approach to take for now, creating a Go binding to some library that does this stuff already. At the moment, there is simply no way to beat those packages at their own game in Go. (By the time you did with "unsafe" invocations to custom ASM you'd have been far better off just binding to something that already existed.) The general problem with Go and matrix math isn't that Go "can't do it", it is that just as Go is dozens of times faster than normal Python at "conventional" stuff (like HTML rendering or being an HTTP server or doing normal arithmetic), NumPy will be dozens of times faster than Go on matrix-manipulation code.
&gt;&gt; Why do you think that I don't think it's a fair question? &gt; Because you said: &gt;&gt; No, why would it? The posters expressed a perfectly sensible, but wrong, hypothesis. It's obvious he had something in mind when he posted that; I asked for his justification. At no point I have said it's not a fair question. Asking someone for justification and arguments is one of the things that make a quality discussion. It doesn't mean it's dismissing either the question or the poster.
Tldr please! Lol
Go is dog shit slow when processing text. It's something that seriously needs to be looked at before you consider doing any text processing. It runs at about half the speed as Python3 (which is also handling Unicode natively) and 1/3rd the speed of Python2 (which doesn't do Unicode natively so it can cut corners). For an example to convince yourself of this, consider the following programs: #!/usr/bin/env python3 ''' Read CSV file and print the number of fields. ''' import csv import sys print(sum(map(len, csv.reader(sys.stdin)))) vs: package main import ( "encoding/csv" "flag" "fmt" "io" "log" "os" "runtime/pprof" "time" ) var cpuprofile = flag.String("cpuprofile", "", "write cpu profile to file") var memprofile = flag.String("memprofile", "", "write mem profile to file") func schedule(work func(), interval time.Duration) chan struct{} { ticker := time.NewTicker(interval) quit := make(chan struct{}) go func() { for { select { case &lt;-ticker.C: work() case &lt;-quit: ticker.Stop() return } } }() return quit } func main() { flag.Parse() if *cpuprofile != "" { f, err := os.Create(*cpuprofile) if err != nil { log.Fatal(err) } pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() } if *memprofile != "" { f, err := os.Create(*memprofile) if err != nil { log.Fatal(err) } quit := schedule(func() { pprof.WriteHeapProfile(f) }, 1*time.Second) defer close(quit) defer f.Close() } reader := csv.NewReader(os.Stdin) sum := 0 for { rows, err := reader.Read() if err == io.EOF { break } sum += len(rows) } fmt.Println(sum) } On a pokey slow laptop I get the following: for x in $(seq 1 1000000); do echo "hello",,",",world; done &gt; test.csv time ./csvreader.py &lt; test.csv real 0m2.202s user 0m1.930s sys 0m0.048s time ./go &lt; test.csv real 0m2.743s user 0m2.411s sys 0m0.068s I've seen bigger differences too on other machines.
In some ways yes, but overall performance should increase slightly and this will allow more people to hack on and optimize the language which will be where the largest improvements come from.
* [Tiedot](https://github.com/HouzuoGuo/tiedot) * [BoltDB](https://github.com/boltdb/bolt) * [LedisDB](https://github.com/siddontang/ledisdb) * [GOD](https://github.com/zond/god) * [GoLevelDB](https://github.com/syndtr/goleveldb) * [Diskv](https://github.com/peterbourgon/diskv)
A few copy pasta errors in the godoc // FloatFromPtr creates a new String that be null if f is nil. func FloatFromPtr(f *float64) Float 
Thanks Dave! I think I got all of them. P.S. We were at the same table at the Tokyo GoCon party, much respect! :)
Sqlite for relalional db. Bdb for k/v.
Try [ql](http://godoc.org/github.com/cznic/ql), a pure Go embedded relational database.
Agree on LDAP. I ended up using cgo + Open LDAP on my last project. There were some interesting options on Github, but they all seemed fairly new. 
I came across this paper a while ago: http://ecs.victoria.ac.nz/foswiki/pub/Main/TechnicalReportSeries/ECSTR11-01.pdf It might not be what you are looking for but it could be interesting if you come from an object oriented background. Basically they take all the standard GoF design patterns and implement them with Go. I though it was just interesting to see how they accomplished some of these patterns by leveraging the features of the language. 
Kyoto Cabinet is kv db with a lot of options
PHP extensions are shared libraries with C ABI. Go has neither shared libraries (yet) nor C ABI (never will).
I came to recommend it as well, though one downside is that it is not pure go.
Why posting a link to Hacker News and not directly to the slides?
Excellent tutorial gradually introducing some of the powers of Go. Already recommended it to a friend who was interested in learning more about Go.
[SQLite](https://www.google.com/search?q=sqlite+golang&amp;pws=0) maybe? or flat file db like [DBGo](https://github.com/HouzuoGuo/DBGo "dbgo"), which is actually quite outdated.
My first Go (and open source) project. Comments are welcome!
At Bitly we had similar needs for handling json with an unknown structure. We ended up with [go-simplejson](http://godoc.org/github.com/bitly/go-simplejson) which is fairly similar.
I'm just being a nay-sayer, so feel free to ignore me... Your example doesn't seem very convincing to me http://play.golang.org/p/SOLmaYqLUm
I feel his introduction of the concepts and idioms of concurrency are a bit rushed. Other than that, great work. (I happen to know the guy personally. A former colleague of mine who now manages various Go projects at Soundcloud. He even [held a talk](https://www.youtube.com/watch?v=Y1-RLAl7iOI) at GopherCon. Interesting stuff.)
I did the same project a few years ago. It wasn't in Go though. In my opinion there is nothing terribly un-Go like about your code, although there are some stylistic changes I would make. The biggest one would be to separate out the larger methods into smaller constituent methods. For instance the inner loop in hasMoreCommands() could easily be it's own method that gets called there. By choosing good names for these methods it will help the reader understand what you're trying to do. Also I would replace the two big switches with two maps. Jump() essentially doesn't do more than j, err := jump[s] does, and replacing the switch in comp() reduces the size of the function while making it clear that every branch of the switch adds some number to b, without the reader having to scan his eyes down the page. Go code can be really clear and nice to read. For a good example I recommend checking out the source code of the Go standard library. 
Yeah, using switch statements instead of maps was some /r/shittyprogramming/ \^\^. I fixed it. Now the code is shorter, clearer and faster. Thank you. But I don't get why I should change the inner loop of `hasMoreCommands()` to a function. Imho there are two reasons why some code should be a function: 1. Avoiding duplicate code 2. Being part of an API
[Ditto.](http://github.com/jmoiron/jsonq)
3: Clarity. Functions have a name and a signature describing their inputs and outputs. This is huge for comprehension, especially as a single function gets longer or deeper. Breaking it into several different functions can improve both the readability and testability of that same code. Consider the [Linux kernel coding style](https://www.kernel.org/doc/Documentation/CodingStyle): Chapter 6: Functions Functions should be short and sweet, and do just one thing. They should fit on one or two screenfuls of text (the ISO/ANSI screen size is 80x24, as we all know), and do one thing and do that well. The maximum length of a function is inversely proportional to the complexity and indentation level of that function. So, if you have a conceptually simple function that is just one long (but simple) case-statement, where you have to do lots of small things for a lot of different cases, it's OK to have a longer function. However, if you have a complex function, and you suspect that a less-than-gifted first-year high-school student might not even understand what the function is all about, you should adhere to the maximum limits all the more closely. Use helper functions with descriptive names (you can ask the compiler to in-line them if you think it's performance-critical, and it will probably do a better job of it than you would have done). Another measure of the function is the number of local variables. They shouldn't exceed 5-10, or you're doing something wrong. Re-think the function, and split it into smaller pieces. A human brain can generally easily keep track of about 7 different things, anything more and it gets confused. You know you're brilliant, but maybe you'd like to understand what you did 2 weeks from now. I don't have an opinion on breaking out the inner loop of `hasMoreCommands()` but clarity should be a significant factor in the decision on how to structure code.
With this library you no longer have to explicitly create structure and then decode/unmarshal !
Interesting read! It's unfortunate that unsafe uses of structs require ordering to be as defined in the struct declaration, otherwise the compiler would be able to simply re-order the items into the internally optimal positions.
I got a great deal of learning and inspiration from go-simplejson, thanks for the contribution! This is an introduction to Go kind of project for me. I just wanted to see how difficult it would be to replicate a similar Python library that I really liked in Go.
Oops, guess I didn't Google hard enough. But as mentioned, this is a learning project for me, so I'm glad I did it anyway. Thanks for sharing!
This is a bit of a WIP, but I have used this (with slight modifications) in a few projects pretty heavily. For my needs, it gives me a really quick and easy way of creating workers that I can light up in my apps with minimal effort -- usually just defining a tube and function. Itd be nice to get some feedback on areas that might need improvements or suggestions for additional features (its pretty basic as is). There are a few examples in the repo to get a feel for how this can be used.
This looks great. I just had random structs laying around. This will be very helpful for using something like Elasticsearch. Great job.
I quite like that I need to use a struct for JSON, you can use it as a model layer and assign methods to the struct so it becomes useful instead of just a place to hold the data. As soon as I need to type assert I feel dirty :-/
You're right; I thought it was rune's an underlying type.
&gt; With this library you no longer have to explicitly create structure and then decode/unmarshal ! I'm not sure I agree with that. IMO all that changed was instead of a static, compile-checked definition you now have a runtime one in `d.g.h[1]`. It doesn't tell you anything about what data is to be expected, so if you're receiving garbage data e.g. because the API changed, you likely won't know. It's not clear to me why writing a struct is such a bad thing. I don't think it's any harder to write because in order to deal with `a.b` you must already expect `a` to be an object. I wrote that definition faster, and with more confidence than I could read and understand the source format. The final code isn't much longer as-is and in reality it's actually shorter because you (hopefully) aren't ignoring all the decoding errors on each access.
For one, it would break compositionality, since you'd need special rules for how you compose types. For another, it would require a lot of recursive allocation that isn't needed today and may be redundant. Perhaps it could be done lazily though. It would also mean that two zero values for a type would not be equal.
My understanding is that pretty much all linear algebra solvers in any language are wrappers around certain libraries, BLAS, LAPACK, PETSC, etc, so as long as they link these libs (in Fortran 77 and C), no language has any real advantage or disadvantage (**except** that nvidia or somebody's working on making python a native language for CUDA) -------- the 13 Dwarves: http://www.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-183.pdf http://people.inf.ethz.ch/arbenz/ewp/Lnotes/lsevp2010.pdf page 354 (i think their server's having issues, not that it's been DMCA'd or anything so here's a cache: https://web.archive.org/web/20120718090042/http://tacc-web.austin.utexas.edu/staff/home/veijkhout/public_html/Articles/EijkhoutIntroToHPC.pdf -------- occasionally there's a brain fart http://xcorr.net/2013/04/12/numpy-uses-the-wrong-blas-libraries-solution/ 
We've been using this in production for a while, it has job dependencies with beanstalk tubes etc. https://github.com/nutrun/glow 
For the level 1 blas functions, at most 4 times faster. https://groups.google.com/forum/#!msg/gonum-dev/Cqa41tbUUCw/EuTBQFBhod0J. The algorithms get much more complicated for matrix-matrix math, of course. BLAS function bindings: https://github.com/gonum/blas (see cblas bindings) LAPACK function bindings: https://github.com/gonum/lapack We're working on integrating the bindings with Matrix, but it's a lot of effort and we're all volunteers.
How will the mobile port be achieved?
How does this compare to SDL (aside from the pathfinding algorithms)?
 result := Memoize("calc_sub", func() interface{} { res, err := calc_sub(1000, "string to process") if err != nil { return nil // not memoized } return res }, 60) // cache for 1 minutes if there is err, you can return nil to prevent caching. 
This was a very interesting and informative read. Thanks!
SDL probably won't provide very many 3D-related things: 3D model loader, skeletal animation, morph target animation, etc. Other things is that we may have a full blown UI package in the future, resolution independent text rendering, SSAO, etc. Right now I'd say they are about on par with each-other (with Azul3D being just a tad bit more powerful and SDL being a bit more documented online via tutorials and such). In the long run I think they are very different projects.
I’m experiencing instant crashes when running the examples under OS X. I wonder if it might be related to using a MacBook Air with a HD5000 graphics card? Most of the go-gl/examples (for glow et al) seems to work just fine though. The azul3d examples just hang there, no windows are created and I have to force kill them/send SIGINT.
Can you elaborate on how it would break composability? I don't see what special rules would be required for composability after this change. Optional pointer would work basically the same as existing pointers under the hood. It's just that some new syntax would be introduced in place of your standard if(foo == nil) and the compiler would require it before dereferencing a nullable pointer. It's true. Non-optional pointers would need to be recursively allocated up front (or lazily allocated behind the scenes), but honestly, most programmers expect their whole object to be recursively initialized up front in some sort of constructor anyway. Making it part of the way non-optional pointers work just makes zero values more useful and would eliminate lots of boilerplate constructor functions that simply initialize pointer values. If you didn't want up front allocation for your struct, you could always use Optional pointers instead. Anything you can do with today's pointers, you'd still be able to do with optional pointers. It'd just give the compiler enough info to catch null pointer errors at compile time instead of runtime.
Very sorry about this. Please see https://github.com/azul3d/issues/issues/5#issuecomment-54257595
Yes, this is exactly what I was trying to get at with my comment. Thanks for the great reference. The reason I gave hasMoreCommands() as a possible example is that the inner loop essentially seems to be trying to grab a new token from the current line if it can and failing otherwise. So it made sense to me to factor it out to a getToken() method so that it both clear what that loop is doing and what hasMoreCommands is trying to do. If that is really the best choice in this case it's up to the programmer and the project style. But it is something to keep in mind.
 file := Memoize("opened_datafile", func() interface{} { file, err := os.Open("datafile") if err != nil { // handle err return nil // not cache } return file // or // data = new(buffer...); file.read(data) // return data }, 60) 
Thanks.... That fixed it!
You can see the example form _test.go.
Why everyone is ignoring Beego? Honestly, Martini is joke against Beego. And yes, I worked in both.
Stuff like the comments in [this issue](https://github.com/astaxie/beego/issues/620) make me a little scared to touch beego.
This started out as a project I created in order to learn Go. I've been updating it here and there as I progress with the language, and it's something I've enjoyed working on. There's now a client-side library (that takes heavy inspiration from Pusher) that you can use along-side the Go server. Feedback welcome!
I agree 100%. There's a nifty tool here to save you a few minutes of typing: http://mholt.github.io/json-to-go/
While all the pieces were mentioned, the combination of verbose, timeout, and running a specific test is really useful when you have a specific test that is taking longer than it should, allowing you to see any output being generated as it comes out and get a stack trace of what is hopefully your system in its "hung" state. Just a mental thing more than anything else, but remember that a `_test.go` file doesn't _have_ to have a test. You can also create something that just provides testing support code, isolated off from your actual testing code. `go help testflag` for all the special docs. Most of what's left uncovered here is specialized details for the profiling.
Looks promising. 
Sure, nothing is 100% perfect, nor the safest system in the world. Are you aware of the fact how many things like this are in Martini / Gorilla? Btw, those discussed issues aren't such a risk tho.
&gt; A Go program that uses a plugin interface, either C style or Go style, where plugins are implemented as shared libraries now all it's missing is timeline :)
Looks like the file is getting slammed - not sure if you're reading this thread, Ian, but you might want to publish and use that link sintead.
Thanks, was waiting for it.
I'm not sure how to feel about this. On one hand, having a plugin interface is great, and the possibility to link Go code to legacy C code is neat. But on the other hand this may lead to a C-level linking hell. One of the things I love about Go is that I can just `go build` and get an executable that contains all it needs to do the job. 99% of the time no `-I /that/other/direcotry/over/there -L /and/another/path/to/some/libs -lfoo -lbar -ldont_forget_me_or_this_thing_wont_compile -l $(pkg-config some_more_stuff)` required. I don't want that to go away.
I've used `go test` to run systems tests that make sure services are up and running normally -- had nothing to do with actual Go code. Go test is awesome.
Here's the full article: http://mwholt.blogspot.com/2014/08/maximizing-use-of-interfaces-in-go.html
kind of wish it were simpler somehow, like resque, but we do what we can...
It is a security problem. The discussion left me with the impression that beego emphasizes doing *something* over doing *the right thing*. I don't want my framework making that decision for me, especially when *something* is silently compromising my application. Even if this particular case is not all that practical to exploit, that mindset is applicable for other internal design decisions.
Also Beego is Chinese I think so it could contain backdoors
Yep, check it out: ffprobe -show_streams -show_format -print_format json=c=1 &lt;INPUT_FILE&gt; | json-to-struct Result instant struct ready to auto-parse the data straight out of ffprobe :-) https://github.com/tmc/json-to-struct
&gt; Consider also -buildmode=guiexe for a Windows GUI program. ] I would prefer if we could set this in the source code with some sort of build-tag.
What is going to happen if you close a plugin and try to use symbols from the plugin you looked up earlier? It might be tricky to make this panic correctly.
I've been using and enjoying https://github.com/codegangsta/cli.
Docopt is probably one of the best - full POSIX compatible way of creating a command line app. Libraries are around for a bunch of languages.
All nice but for command line parsing you use https://github.com/docopt/docopt.go nowadays...
Might also be worth looking at [docopt.go](https://github.com/docopt/docopt.go). Basically you write the help usage text a specific way and it is parsed into arguments. Does have some corner cases that are a pain and uses the POSIX argument format. But much less programming. Also implementations exist for other languages.
I’ve been very happy with the Go version of termbox.
Do you mean _libraries_, right? I thought we left behind the "all is a framework" madness back in 2012.
I thought you just wanted to be able to find out if a file is a directory or not? What's the other situation?
use a switch: // use a switch to make it a bit cleaner fi, err := file.Stat(); switch { case err != nil: // handle the error and return case fi.IsDir(): // it's a directory default: // it's not a directory } check both in one if: if fi, err := file.Stat(); err != nil || fi.IsDir() { // error or is directory } EDIT: I don't see anything complex with your original code. It's simple and explicit. 
That doesn't make sense. os.Stat() *does* handle both situations. An example of something which only handles situation 1 is: func IsDir(filename string) bool { return true; } It will correctly report all directories as directories but incorrectly report all "not directories" as directories. Such behaviour is useless though(!) [BTW: using os.Stat() is race-y if you use the IsDir() call to determine whether you then os.Open() the file.]
your code seems correct, and not overly complex given what you're wanting to do.
I don't think you clarified your point at all. That being said, the first example you have is race-y in exactly the way I warned against in my original reply and the second does os.Stat for no reason at all, just use Stat on fi. To determine in a race free way that a path points to a directory and then retain an open file descriptor you need to use Stat on fi in your example. I don't see why having to Open the pathname in all cases is a disadvantage. It's required to check for directories in a race free way.
I think you got my point but I'm as wrong as a non-swimmer in the middle of the Pacific Ocean. :) Btw: Why is os.Stat racey, but file.Stat isn't? And how did you find that out? I want to learn identifying such stuff. Is that documented anywhere?
I'm so glad I'm not the only one thinking this way. You stole the words from my mouth!
It isn't clear what you actually need to do with the file descriptor, but POSIX specifies that open can return EISDIR if you open for writing. So the only race-free way is to call open and check for EISDIR. Any solution that makes more than one system call is inherently racey.
Whatever happened to good ole int or int64 representations? I'm actually not trying to be snippy, I've stored Unix timestamps as plain ints in Go and within Mongo without any issue, although I've long since abandoned Mongo, so there may well be some date functionality I don't know about.
What DB have you since switched to?
Sure, but you have to do it yourself, you can implement the json.(Unm|M)arshaler interfaces
I've done something similar to this by using [mapstructure](http://godoc.org/github.com/mitchellh/mapstructure). I unmarshall the JSON into a map, check the type/kind field in the map then decode the map into the appropriate struct. mapstructure works mostly like JSON unmarshalling: type Params struct { Name string `mapstructure:"name"` Domain string `mapstructure:"domain"` Version string `mapstructure:"version"` Deployer string `mapstructure:"deployer"` Replace bool `mapstructure:"replace"` } // Unmarshall to map mapConfig := make(map[string]interface{}) json.Unmarshal(rawData, &amp;mapConfig) // Check the 'Kind' field to see what type of data it is. Let's pretend it's type 'Params' // Marshall into Params type var p Params mapstructure.Decode(mapArg, &amp;p) 
Use json.RawMessage fields so they can be decoded at a later time (and perhaps to different types): package main import ( "encoding/json" "fmt" "os" ) var jsonBytes = []byte(`{ "kind": "frobber", "frob_strength": 100, "manufacturer": "IBM" }`) type UnknownFooError string func (e UnknownFooError) Error() string { return "unknown foo kind: " + string(e) } type UnknownFoo struct { Kind string `json:"kind"` FrobStrength json.RawMessage `json:"frob_strength"` Manufacturer json.RawMessage `json:"manufacturer"` } func (f *UnknownFoo) Parse() (interface{}, error) { switch f.Kind { case "frobber": return f.FrobberFoo() default: return nil, UnknownFooError(f.Kind) } } func (f *UnknownFoo) FrobberFoo() (*FrobberFoo, error) { var frobStrength int err := json.Unmarshal(f.FrobStrength, &amp;frobStrength) if err != nil { return nil, err } var manufacturer string err = json.Unmarshal(f.Manufacturer, &amp;manufacturer) if err != nil { return nil, err } return &amp;FrobberFoo{ Kind: f.Kind, FrobStrength: frobStrength, Manufacturer: manufacturer, }, nil } type FrobberFoo struct { Kind string `json:"kind"` FrobStrength int `json:"frob_strength"` Manufacturer string `json:"manufacturer"` } func main() { var unknown UnknownFoo err := json.Unmarshal(jsonBytes, &amp;unknown) if err != nil { fmt.Println(err) os.Exit(1) } fmt.Printf("%#v\n", unknown) foo, err := unknown.Parse() if err != nil { fmt.Println(err) os.Exit(1) } fmt.Printf("%#v\n", foo) } [Playground link](http://play.golang.org/p/HT9HowyP_u)
Thank you, I agree with you regarding wrapper. btw having this features might be useful in some cases.
I see weird things in there :) https://github.com/docopt/docopt.go/blob/master/examples/git/git.go#L74 Looks like a quick and dirty rewrite of the python script :(
Well, this package attempts to solve this problem: https://github.com/voxelbrain/jsonext
Why don't you use SOAP?
Postgres I believe. Every one uses Mongo until it locks. Mongo is the biggest troll system ever. So many companies lost money and time with it
Awesome, thanks for posting! I doubt I'll ever have a Nest product so I don't see me ever using the library, but it's nice to see unique projects posted here. Stuff like this is so fun.
For coloring my CL output I enjoyed it using https://github.com/wsxiaoys/terminal/tree/master/color
The typical use case is that the structure of the data depends on the value of the 'Kind' field. So you don't know what class to marshal the data into until you've read the Kind field. Therefore you need to parse the data just to read Kind. json.RawMessage is just an alias for bytes and doesn't really help you in this case. If your data is deeply nested and you don't need to parse all of it then RawMessage can possibly be useful for lazy parsing of part of the data. You are usually better off just parsing the whole message into a map, reading the Kind field, then turning the map into the concrete class. 
My original example, while not perfect, was able to delay the unmarshaling of data until after the Kind field was read. I generally prefer well structured input and this would not have worked for unknown fields, but if all of the possible fields for any valid Foo are known at compile time, the additional fields could be added to the UnknownFoo struct, and ignored if they aren't used by the specific Foo being parsed. There are two main stages (I'm generalizing here) that are performed when the bytes of a JSON type are unmarshaled into Go types. First it must scan (parse) the JSON to find the beginning and end of every JSON type. These types can be complex JSON objects (which map to Go maps or structs), but the next item in the stream can not be scanned until the end of the previous is found. Even if these objects are not being unmarshaled into types, the scanner must parse JSON types out of the entire byte slice, possibly terminating early if all required fields have been parsed. When unmarshaling, not only must the data be scanned, but you must also convert the JSON representation into an equivalent Go type. The idea you had suggested (unmarshaling the original bytes into a map[string]interface{} and then type asserting each map value into something more appropiate after a kind was read) is possibly the worst way to solve this problem. Not only does that parse every JSON type, but it also allocates memory for and unmarshals each JSON type into a Go type. Converting the map back to a well structured type is not only tedious and error prone (consider input with JSON objects inside other objects, resulting in maps of maps, when you actually wanted structs), but also horribly inefficient since you're converting types not just once, but possibly twice. There were two problems with my original example. The first was that the parsing stage would need to be done multiple times (once over each JSON type to find the kind field, and a second time to validate each saved RawMessage as valid JSON). The second was that unmarshaling into a RawMessage makes a copy of the scanned JSON, which could hurt performance unnecessarily if you know your buffer won't be modified underneath you before the final parse. I have reworked my example to fix both of these issues: [Playground link](http://play.golang.org/p/PBBx_09-ph)
Someone should do tutorial on this amazing project !
Personally I'm big fan of LiteIDE
github.com/spf13/cobra is good for bigger projects :)
Why not move this gforms.Validators{ gforms.Required(), gforms.MaxLengthValidator(32), }, into this Name string `gforms:"name"` Weight float32 `gforms:"weight"` like type User struct { Name string `gforms:"name,required,max=32"` Weight float32 `gforms:"weight,required,max=32"` } PS Non related observation: the effect of Not-Invented-Here syndrome in Go community is enormous - why not use already existing validation library (first pop from google search stack: https://github.com/go-validator/validator) or join the efforts to make a single, ultimate framework for a given purpose?
Wow. I think I love you. (In a non-creepy/stalkery way.)
&gt; but i'm totally new to web development Honestly, creating something in the scale of Trulia/Zillo would be impossible to someone "totally new to web development". It's like saying you're totally new to mechanic engineering but you'd like to build a car. You might end up with a car, but it won't be a BMW (or even a Geo Metro). There's a lot of large and small details that you need to consider when creating a scalable and performant system - it's more than just creating a web app and spawning more web workers when traffic is heavy. You need to take into consideration your database architecture, caching locality/eviction/distribution, the networking between your services, work queues, redundancy, etc. Of course you can always start basic and grow as your experience grows too. With that said, to answer your question, it depends on a lot of variables, but I'd say that going with Go would be the optimal choice as far as resources go, but not by much.
I don't always find these kinds of questions easy to answer and as jeft says, "It depends" is the only honest answer you can get without more information. It's worth it list out what is important to you about the language choice here. Obviously you mention performance but everyone cares about that these days. What kind of maintainability do you need, does it just need to run without many updates to the codebase in the future? What other things are important about it?
Thanks @avrtno for the tip ! I'm a newbie in GO and is what I was looking, examples implementing the package.
That's what I want to motivate. If you update your dependencies quite regularly, it's a lot easier to spot problems (and offer fixes) or update to API changes compared to updating everything at once every 18 months.
I'm really glad if you find it useful. I want to help make updating Go packages as easy and enjoyable as possible, so that people don't have to deal with problems that have already been fixed upstream. :D
&gt; If you update your dependencies quite regularly, Ah, this reminds me of a discussion I've had a work with some frequency. Among the many ways to consider a development process, consider it like exercising muscles. You get good at what you do a lot. Things you do infrequently atrophy. There are some teams where I work that can't turn around releases very quickly, but the reason is, when you really get down to it, circular... they can't make frequent releases because they _don't_ make frequent releases. In a lot of ways, the solution is to simply start trying, fixing the problems you find as you go, and not to be paralyzed with fear at the prospect of having to make a fast release. So this goes with a lot of things... writing unit tests on your un-unit-tested code is hard, precisely because you've never done it. Do it, and it will become easier. Continuous integration is hard, precisely because you've never done it. Do it, and it will become easier. And indeed we have this exact dependency problem too... we're on an _ancient_ version of our primary language, because we fear upgrading, because it's hard... because we haven't upgraded. So I would agree; get good at updating your dependencies frequently, and it won't be hard. Sticking to the old dependencies and never updating is a great deal of what makes updating hard in the first place. I mean, yes, updating a dependency has a certain irreducible amount of work associated with it, but you don't avoid that by letting many updates go by and having that work accrue interest. (And you should also consider this a lesson in the virtues of not letting your dependency list explode if you can help it....)
&gt; i having a hard time deciding if i should learn Erlang or Go to achieve the fastest loading speed of the pages in all devices (Smartphones, tablets, Desktop PC's etc), this include images, Youtube Videos, google maps with the location of the properties etc, and responsiveness navigating the website. The loading speed of the page on various devices is not very strongly related to the server-side programming language, so the question is rather ridiculous in my opinion. 
A nice clean Web UI is nice, but is there a CLI version built-in? If not, I think that would be useful.
Hm, getting an error on `go get`: # github.com/shurcooL/Go-Package-Store dev/go/src/github.com/shurcooL/Go-Package-Store/main.go:62: cannot use exp14.GoPackages literal (type *exp14.GoPackages) as type exp14.GoPackageList in assignment: *exp14.GoPackages does not implement exp14.GoPackageList (missing exp14.addSink method) have gist7802150.addSink(*gist7802150.DepNode2) want exp14.addSink(*gist7802150.DepNode2) dev/go/src/github.com/shurcooL/Go-Package-Store/main.go:82: cannot use goPackages (type exp14.GoPackageList) as type gist7802150.DepNode2I in function argument: exp14.GoPackageList does not implement gist7802150.DepNode2I (missing gist7802150.addSink method) dev/go/src/github.com/shurcooL/Go-Package-Store/main.go:160: cannot use goPackages (type exp14.GoPackageList) as type gist7802150.DepNode2I in function argument: exp14.GoPackageList does not implement gist7802150.DepNode2I (missing gist7802150.addSink method) dev/go/src/github.com/shurcooL/Go-Package-Store/main.go:265: cannot use NewGoPackagesFromGodeps(*godepsFlag) (type *GoPackagesFromGodeps) as type exp14.GoPackageList in assignment: *GoPackagesFromGodeps does not implement exp14.GoPackageList (missing exp14.addSink method) have gist7802150.addSink(*gist7802150.DepNode2) want exp14.addSink(*gist7802150.DepNode2) Does this have something to do with the fast that the package imports gists (a pretty unorthodox way to do imports)?
&gt; Is there any way to simply decode a json blob into a map[string][]byte - the key and the bytes of value, for later decode? Use map[string]json.RawMessage: http://play.golang.org/p/V4SlfUYCMf &gt; There's still a problem: any other fields in a struct with an embedded Plugin are lost. It sounds like you want to make Plugin an interface and then plugins, not widgets, get registered into the package during init. Then so long as you can unmarshal them, and the external packages can provide the implemenation, you don't actually need to keep around the raw JSON. http://play.golang.org/p/Uhq2CzhCiL 
Take a look at my previous project called gostatus [1]. It's a CLI version that tells you the status of your Go packages. It includes things like "do I have any uncommited changes?", "are there any updates?", "do I have a stash". https://github.com/shurcooL/gostatus#examples Go Package Store is a GUI version that elaborates on "are there any updates, and what are they?" part. But you can use gostatus if you just want a CLI tool to tell you which packages _have_ updates.
To add on a bit here, people who are new to programming or architecting environments for a web application make the mistake of thinking the application layer is the bottleneck. In 2014, this is almost never the case. How that pertains to the primary question is this: it changes the scope of the question. You can create a Zillow/Trulia in any modern language. It's entirely possible that the library tie-ins for your external dependencies might be faster on Python than on Go or Erlang. Go and Erlang excel at concurrency, which has more value at the server level than the application level, at least for the Web. Long story short: it doesn't matter and you're so far away from that point that you're years from worrying about a language decision. Assuming you were able to build something of that scope, your real question would be "which language gives me a better pool of developers?"
awesome!
Edit: recreated in playground. Kind of. I want a way to decode known fields in a struct AND to catch all the extra fields. http://play.golang.org/p/74_hSIUboo Basically it reflects on a type which has an embedded Extension (which istype map[string]json.RawMessage). It sets any struct fields that have json data, and leave any unknowns. The problem is that each type that wants to embed Extensions has to declare an UnmarshalJSON() function that forwards itself to the core code. This is fugly. There has to be a better way.
One thing that some companies at large scale is update dependencies automatically on every build, trusting their automated test and deploy (and rollback) systems to keep things stable. Its the continuous delivery of dependency management. Amazon.com is one that does this.
That said, it is possible to add a text mode if you prefer to avoid opening a browser. It would use text/template and write output to stdout (similar to how go doc has both http and plain text modes). It's something I'll consider adding if it can be done cleanly without too much weight.
The README.md says to import *"../."*. I assume that's an error?
feel free to post a new working example sometime if you'd like :)
&gt; Maybe because you might need different validators for different contexts? Basically what you're saying is user may want to use own validator strategy. Typically he/she will code it, then why using this library in the first place for such use-case?
Erlang is not designed to be on pair with the fastest languages when it comes to speed. It's designed to create programs that are easy to reason about and run forever (it makes it possible to change code while the program is running.) In short, its meant to create very stable programs, not very fast ones. I'm also about to learn something Erlang like, but I'll probably put my effort into learning Elixir instead. You might also want to check that project out before learning Erlang. It seems much easier to get used to.
~~Honest question here:~~ ~~&gt; import "github.com/shurcooL/go/gists/gist7802150"~~ ~~Is this a good idea even if you control both the project repo and the gists linked? I've seen this pattern around here and there, and I'm not sold on the idea just yet.~~ ~~A quick bit of googling around suggests that gists also don't scale very well: http://stackoverflow.com/questions/2082723/how-do-you-manage-your-gists-on-github~~ Nevermind. I see that you have these in a repo instead. Nice idea. FWIW, I *have* seen people do crazy stuff like reference a gist URL from within a .travis.yml file before.
I'm just going to assume it only works with git repositories. Does anyone know otherwise? 
This is the final version that I am using: https://github.com/mozilla/masche/tree/master/listlibs (the interesting files end with _windows.(go|c|h)
It supports finding updates for both git and Mercurial repos, since that's what the underlying vcs package supports: https://github.com/shurcooL/go/blob/b403b5c49f5bd8e403c29a7f0250becd59b86395/vcs/vcs.go#L64-86 It supports getting list of changes for repos listed on github right now, because that's what the presenter package supports: https://github.com/shurcooL/Go-Package-Store/blob/e37c37cd337f98780b8354a632c6965bf607804b/presenter/presenter.go#L46-77 Both are made to be easily extendable, and PRs are welcome. But open an issue before doing work so I'm aware.
If you need to validate what users put into your forms, maybe you should get more trustworthy users?
Does the description for "inline" on the [mgo/bson package](http://godoc.org/labix.org/v2/mgo/bson#Unmarshal) sound like what you're looking for: &gt; Inline the field, which must be a struct or a map. &gt; Inlined structs are handled as if its fields were part &gt; of the outer struct. An inlined map causes keys that do &gt; not match any other struct field to be inserted in the &gt; map rather than being discarded as usual.
If those fields are actually unknown (not known and optional), it's probably best to unmarshal to a map[string]json.RawMessage and convert each known field, removing them from the map. Whatever is left are the unknowns. Otherwise, if the fields are known but optional, what you want to use is the 'omitempty' struct tag. That will let you check for the (non)existance of a field by letting the json package fill in a zero value for your struct field. This works well with pointers, since if there is a nil pointer, then you know the field was unset in the json blob.
Well, maybe not good form. It will actually run in that directory using the library, so you may just do 'go run'. But it might be better just to show an example as if you had done a 'go get'?
&gt; it might be better just to show an example as if you had done a 'go get'? Yes. It's unclear what "../." is importing; however, it's clear what "github.com/jsgoecke/nest" is importing.
&gt; github.com/jsgoecke/nest Noted, changed and committed to Github.
TLDR "My encoded stream was wrapped in a bufio.Reader, which I wrongly expected to Read() fully. This wrong expectation was correct 99% of the time, except sometimes where it would read less than all the bytes."
even the most trustworthy user is able to mistype their address or postal code...
Not is recommended put the logic of the validator in tags of structs.
Not mentioned in the article, but when you're doing this sort of thing, be sure to paw over the io and ioutil packages. For instance, [io.ReadFull](http://golang.org/pkg/io/#ReadFull) will collapse the cases your code has to worry about down to A: I got all the bytes or B: I didn't, and you don't have to worry about the inbetween cases... well, as long as you've got timeouts handled somewhere else ([probably something like this](http://golang.org/pkg/net/#IPConn.SetDeadline)). If you're slurping in _huge chunks_ of the string that might not work but in many cases that's a lifesaver. See also io.ReadAtLeast, io.Copy, io.CopyN, and ioutil.ReadAll. Oh, and while I'm here, if you're writing _serious_ network apps, you should pretty much always be using SetDeadline in some way. Otherwise network timeouts, a very common problem, start causing goroutine leaks as the readers or writers get locked and never come back. (Or only come back literally hours later. Note that TCP keepalives sound exciting at first, but the ones implemented by the TCP standard are much slower than you'd expect.)
Looks interesting. I am curious as to what systems still use that CPU?
Only expensive IBM mainframes as far as I know.
Looks like great user experience. It didn't tell us where/how they actually implemented the final solution though. I know it involves a /k flag on cmd.exe, but how it the app itself influencing that?
That's a good point, I should probably explain that. The basic gist of it is that you just re-exec with cmd.exe /K: if mousetrap.StartedByExplorer() { exec.Command("cmd.exe", append([]string{"/K"}, os.Args)...).Run() os.Exit(0) }
Hah! I love when someone points out what is probably the most obvious idea that I completely overlooked. You're absolutely right that I could just include another .bat file to launch with. Without feeling too much like I'm justifying my past decisions, I'll mention that it's another thing to include in the download bundle. This adds user confusion about how to run the program. Right now there is a single binary executable and nothing else. I really value that simplicity. Why wouldn't you suggest I include that functionality in the app itself?
Well in my mind you are trying to account for cmd "flaw" and I don't see that solution as clean. The truly simplest way to have it work like you want it to ask for input. In winc++ I would just use a system("PAUSE") which asks for input to continue. Here you are asking "where am I launching from" and I don't think that is the best way to handle it. I quoted flaw above because I also feel this isn't a flaw. There are a lot of batch files out there that will run commands that need to spawn instances of cmd and it would suck if they are left on the screen. The "proper" way of handling it is to redirect stderr to a file and log the error there. But thats a lot of garbage to deal with, so I just use the input option :) 
This is my second post on JSON usage in Go. Opinions are welcome as always.
&gt; I can call conn.WriteTo(slice, clientAddr) and it works. &gt; How do I get a Conn that I can use Write() on back to my client? I want to use io.Copy, for example. There is your answer. Here is an example, https://github.com/davecheney/partyline/blob/master/cmd/partylined/main.go#L29 edit: using io.Copy sounds like the wrong tool for the job, it is for stream oriented Readers/Writer, UDP is packet (datagram oriented), so you need to give more care to reading and writing packets individually to respect the implicit message boundaries.
I don't believe that you can. Fundamentally, Go's net package leaves listening UDP sockets unconnected. An unconnected UDP socket has no destination address associated with it, which means that you always need to provide the destination address when you send something to the socket. The best solution that I can think of is to create something that satisfies the io.Writer interface by, for example, having a struct that has the client address as well as the net.Conn and having a Write() implementation that calls conn.WriteTo() for you. But I echo davecheney's cautions here; UDP write semantics may well not match what callers expect. (Plain Write() works on client UDP sockets because they have been explicitly connected to a remote address.)
I would love to see more examples of people consuming other peoples data. My current project involves parsing JSON from a NoSQL database, containing product information, and the data structures are very dynamic, meaning defining structures to unmarshal the data into won't work. 
You should make your mysql connection outside of the handler. the db/sql lib is goroutine safe, and each connection to your web server will create a new goroutine, so you're connecting to the database on every request. Instead let db/sql manage your connections. Connect in an init() function and make the connection a package level variable.
You should run go fmt on your code.
I'm dealing with this right now on a project and our solutions are similar (I have several Struct/PublicStruct pairs for public consumption). So for me personally, this blog post was really useful and timely, because I'd been thinking about different approaches and trade-offs. This struck me as particularly "un-go-like": json.Unmarshal([]byte(`{ "url": "attila@attilaolah.eu", "title": "Attila's Blog", "visitors": 6, "page_views": 14 }`), &amp;struct { *BlogPost *Analytics }{&amp;post, &amp;analytics}) I'm not married to this opinion, but I was wondering if anyone else felt the same. Great post, thanks again!
On KDE ever since the whole gnome3/unity fiasco. XFCE just didn't work well enough for me.
I'm using the default on Ubuntu 14.04. Looks decent and provides easy application startup with Meta -&gt; Type -&gt; Enter. Although I could work in any environment as I just need a browser and terminal. I've used them all over the years, and they all bugged me so I just stick with the defaults and focus on important stuff.
Ubuntu/Gnome, but I miss running Gentoo (making my own source based distro, with a package manager in go just to get some code under my skin) and E17. I like a minimalist setup, but I use GoSublime and a terminal, so any desktop will work. I am setting up Ubuntu in VirtualBox on my my new MacBook Pro, but it is quite slow. I might look into cartograms tip :)
GNOME 3 / Unity. I could use another DE as well and wouldn't really care. OS X would be a good choice as well. I don't think there is any relationship between language choice and DE choice.
I use i3 or Xfce
Same here. I used to be die-hard Ubuntu/Gnome, but now I've gone through half a dozen distros trying to find something I like. I'm on Kubuntu for now, but not particularly thrilled about it.
Unity was the last straw for me running Ubuntu. Way too many discomforts to put up with. Gnome 3 is to Gnome 2 as Amarok 2.0 is to Amarok 1.4. Amarok (1.4) was so good I was happy to load the KDE libs on my Gnome 2 desktop just for that purpose. Shame about all that.
I use CrunchBang, a Debian based distro, as I can use Debian package manager, yum, brew, and apt right out of the box. It's also VERY lightweight and doesn't use a boatload of system resources with unnecessary graphic displays as I'm in my terminal most of the time. This allows me to use it on my 2008 Toshiba Satellite which could barely handle Windows 7 (the OS it was running before I fully wiped it and installed CrunchBang). My main desktop uses Windows 7, CrunchBang (which I'm likely to replace with another Debian-based distro sometime soon), and Mac OS X Mavericks. Using my home server and git, my projects are synced throughout all my computers and I'll hopefully be able to configure my Chromebook to do the same when I end up buying it.
+1 for Crunchbang 
Just clean and simple i3 here. Vim to code in of course.
Could you be specific about what you find "un-Go like?" I know I personally have a dislike of inline struct declarations, but that's personal. It's in Go because it's supported by the authors.
encoding/json's ability to go straight to and from structs is, ultimately, a convenient shortcut, and not a complete ability to handle arbitrary JSON. This is a frequent occurrence in many languages/JSON libraries. There is often a "default" serialization to whatever the local equivalent of structs are with varying levels of convenience, but that default serialization simply can't be used by everything, and in the end, you may need to use the parser in its most generic mode. There may simply not be a better choice for you than `map[string]interface{}`, unfortunately. There are some projects that can help you convert from an inner `map[string]interface{}` to a struct in the some way that encoding/json does, if that helps.
OS X here.
xmonad
Let's make a WM in Go? Or better yet a Wayland compositor?
I am still in the Ubuntu/Gnome realm. I don't like or hate it really and it doesn't make much difference to me one way or another.
That sounds like alot of fun. If you start this up, tell me and I'll contribute. Tbh I'll probably only use it if it's tiling though. I'll contribute either way, but I can't go back now that I've used a tiling wm for my day to day.
thanks for your feedback. Those are helpful observations. I don't know that your examples you give are a fair comparison though. You're using simple python shortcuts without using equivalent simple shortcuts in go. The longer process you're seeing could be from the memprofiiler and scheduler and not the text processing in Go. That said, it doesn't surprise me that Go may not as performant with text as python. Regardless, I'd like to see a good option for NLP library for Go just to have the option. This isn't the topic for it but I'd MUCH rather see a python3 port of NLTK but that doesn't look likely.
At the very least I wish we had a better word tokenizer in Go.
Not yet, but it's at the top of my list to try next!
pretty much this for me as well
[Wingo](https://github.com/BurntSushi/wingo) exists. It's pretty nice.
Stock Ubuntu + GoDeb + Vim. GoDeb to be replaced very soon with Ubuntu Develper Tools Center (https://github.com/didrocks/ubuntu-developer-tools-center). It is supposed to receive Golang support soon.
The simplicity of cross compilation in Go amazes me
I think a combination of the inline struct declaration mixed with doing a lot on one line. Noted re: inline struct declarations, I feel the same way about them and that played a part. But to you, when you look at the excerpt, you see clean, idiomatic, effective go? 
The prepared statements work with MySQL and you can handle them the same way you would with any *DB.prepare() call.
Wayland is quite a beast to deal with (both, cgo and pure go). As a starter you might want to look [here](http://www.reddit.com/r/golang/comments/2c28hd/go_and_libwayland/).
[dwm](http://dwm.suckless.org/) on debian. Plain and simple. 
How well does this play with godep?
On my gimpy 2006-era Core Solo laptop (single core! maxes out at 2GB RAM!), I'm still very productive with [Emacs 24](http://www.gnu.org/software/emacs/) + [flycheck](http://flycheck.readthedocs.org/en/latest/) + [auto-complete-mode](http://www.emacswiki.org/emacs/AutoComplete) + [gocode](https://github.com/nsf/gocode). `go build` runs in under a second most of the time. For the "other desktop" stuff, I use [stumpwm](https://github.com/stumpwm/stumpwm) with gnome-panel (I followed [these instructions](https://github.com/stumpwm/stumpwm/wiki/Ubuntu-12.04-and-Gnome-and-StumpWM)).
Icholy is correct. And structs are just more elegant. Believe me, I came from python and wanted to use something similar to python's dictionaries but the struct is the best way in golang. 
Let's. But then let's make a tiling window manager. Why would anyone want windows hiding other windows?
Tiling is the way to go. I need a replacement for xmonad.
xmonad as well, but I use Synapse as a launcher (it's not great) and I use the gnome panel.
I'm using KDE on Debian or Ubuntu, I got off the GNOME train with the already unusable 2.x releases and never looked back. On older hardware, I used a mixture of Fluxbox and various KDE parts, but as my machines got faster and KWin got more feature complete, it stopped being useful. Mostly this is all just eye candy wrapped around my emacs-x11 instance, though :)
arch, gnome, emacs
openbox
I wouldn't consider myself a Go dev precisely, but I'm using Gnome with the Phosphene theme and Emacs right now. Light themes are out of my comfort zone, though, so I'll end up switching to StumpWM for Lisp hacking when I wipe my laptop in preparation for school next week.
Hey people thanks for all the suggestions. I can google too so I had already seen most. What I am really interested in is opinions from people who have actual experience with a pure go embeddable database.
I use XFCE.
Arch Linux, Gnome Shell, [Vim](https://github.com/beefsack/.vim). I'm one of the very few who's used Shell since beta and have actually really liked right from the beginning. It fits my workflow really well for some reason.
LXDE has been great, but I've never really given a tiled manager a chance for too long. I'll install i3 tomorrow and see how it goes :)
Good luck! I installed awesome and xmonad 2 or 3 times out of curiosity and switched back after a day or so...I installed i3 and stuck with it for about 3 days when all of a sudden everything just clicked. I could never imagine going back. Not that i3 is necessarily better than other tiling wms, since it's mostly opinion. Just sticking with it for long enough to let it become second nature instead of reaching for the mouse has been one of the best decisions I've made when it comes to tooling.
Yes.. Good idea. Not code connects and disconnects with db on every call. Will impliment that in init() Thanks 
1) true, will add the db dump of database with code. 2) replied in 1. 3) we can 4) yes we can, and must do 5) same as 4. 6) bad, I should commit that. 7) yes 8) Sure. fork the code and add. Thanks for asking. Thanks for good ideas, Surely it will improve the code.
Great post! Where were you half a year ago?!
How so? You can add some login etc or server-side sanitization before running the command 
Thanks for gofmt advice. Do you have any source where I can see whats wrong with go.net/websocket ? 
&gt; this is my first go app Where? I don't see any links.
Not sure what happened to the link... https://github.com/nateri/netget 
.exe files in the repo. OMG.
i3 here.
I've used nearly everything over the years. Settled on ubuntu+Gnome2 for the desktop a long time; run Mint+Mate now, mostly because I'd built up a ton of muscle memory with compiz shortcuts and a lot of helpful custom configurations with it. Unfortunately, compiz is barely installable anymore and is totally abandoned, I feel like Mate is also an evolutionary dead end. Looking forward to trying out Elementary OS.
Should I remove it? Didn't realize it was taboo..
Stock Fedora 20 &amp; icewm.
Windows desktop running any torrent app (uTorrent etc) Cell phone (browser) Can you give me 1 solution where my cell phone can queue a magnet link or .torrent URL onto the desktop? I'm guessing uTorrent may have some remote login web interface now but it didn't back when I first wrote this as a non-go app a few years ago. Assuming the torrent client doesn't have some remote API, what solutions would you suggest?
I must be missing something. What do you mean by vol up/down? What's the mechanism for queueing into a torrent client that you didn't write? Are you using one with some external API? Also, that sounds exactly how I'm submitting requests via a form GET. How is your description different than the webclient in the git repo? 
It's portable in that it will run on any windows machine. Usually "portable" has a wider definition (different operating systems or architectures). The most annoying part for you will probably be that every time you commit, a new 8+MB blob will be added to you git repo, and it probably won't delta compress well. After 100 commits, suddenly the repo is enormous.
Ahhhhh!! I didn't even think about repo size! I'm used to work servers where storage has never been a concern for devs. That is an excellent point!!! Thanks!
Oh sure. I used it for a long while but switched to Audacious not long ago. At this point it's about dodging annoying features in audio players. ;^) Thanks for the tip!
Gentoo, i3, vim
http://syncthing.net/
If you're using the (deprecated) Godeps file, there's actually a hidden flag to read the Godeps file and use that as the starting package version source. It doesn't supporting actually updating the versions, but it shows the updates with changes. Run it with `--help` to see the flag.
So, a few more things that nobody caught yet: * You're allocating a crazy huge buffer at the beginning of your handler, and mostly only using one element. Not only could you be using append() instead, you're actually setting LIMIT in the only query which uses more than one element to a length that's literally 100 times smaller. * While it's good that you're no longer blindly continuing after errors, simply calling return will result in a HTTP status 200 being used for error responses. * If URL parsing fails, you'll render a text/plain response body after writing an application/json content type. 
Off the top of my head: https://camlistore.org/ https://aptly.info/ https://github.com/BurntSushi/wingo
Soundcloud Parts of Youtube Backend (the ones delivering video streams afaik)
http://hekad.readthedocs.org/en/v0.7.1/
Dwm on debian. 
Java is popular because Sun (Java's developer) made a successful effort to push it into the enterprise software market from the start. Now that it's established, we won't get rid of it quickly. If we look at [the long-time Tiobe Index](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html#container) we can see that *Java* is on the retreat. Most of its share is probably taken by the highly successful *Objective-C*. *Go* is not a big player yet. Also important: Google has tied Java to the Android OS. That's a huge advantage for Java. C is tied to Linux and Objective-C is tied to iOS. That's where those languages get their power. Go is not tied to anything. I personally dislike Java, but also believe that things could be worse. 
Could golang be more worse then java, for example in webapplication? Coding in golang is more productive, that is experience.
This is a really loaded question and the reality is there is no "one" perfect language. Each one has its strengths and weakness and part of being a good programmer is picking the right tool for the job. Do you need high concurrency, C code integration, and fast start up times? You should probably consider Go. Do you need to write once and deploy without worrying about cross compiling incompatibility or do you need to integrate/leverage to an existing Java framework? Java is probably your best bet.
In my opinion Golang is much better than Java, but such a thing nearly impossible to argue objectively. 
What is deprecated about it? What should I be using?
https://github.com/youtube/vitess
Just take a look at [awesome-go](https://github.com/avelino/awesome-go).
https://code.google.com/p/go-wiki/wiki/GoUsers Old list; unmaintained but some are still relavant: http://go-lang.cat-v.org/organizations-using-go
I think this is too big of a topic to really address properly and there are a couple of typical traps people fall into when they do. The first is treating all languages as directly comparable when you likely need to talk about what problem space you're working in, what environment you have and so forth. So for instance if you have a whole team of Java Spring developers maybe Go is great but it's not a great fit or if you have a strong need for concurrency and been using PHP then maybe Go would be worth looking at and so forth. The second is starting from the paradigm of a particular language is the one true way to think about engineering or language theory and tearing down one language because it isn't the other. This is the origin of the "Go stinks because it doesn't have Generics" argument in my opinion. My best advice it to invest a bit of time writing idiomatically correct Go and putting some open minded though into the principles in Effective Go and that will likely highlight most of what you want to know.
Is this available as an unhosted solution? I need to generate rpm, but we wont be trusting third parties with our deployments anytime soon. 
The name of the language is not Golang, it's Go. Please get this right. 
Stock Ubuntu 14.04. It just works and I have more important and interesting things to do than muck around with my OS.
Take a look at [FPM](https://github.com/jordansissel/fpm), a ruby tools to generate these kinds of deb/rpm/chef.
okay fair enough. Generally if you want to write comparable tests you should use similar artifacts. So if you're looping in one you should probably do it in the other. You want to compare performance on text processing speed not performance of for loop. I rewrote these to be more similar. **NOTE this still proves your point and I get an almost 2x time under Go than I do Python so this highlights it even more. This isn't to refute your point, it's to say that comparisons should like this are more effective when they are functionally equivalent. **Python code #!/usr/bin/env python3 ''' Read CSV file and print the number of fields. ''' import csv import sys reader = csv.reader(open("test.csv")) sum = 0 for line in reader: sum += 1 print("Read a total of %d lines" % sum) **Go Code package main import ( "encoding/csv" "fmt" "io" "os" ) func main() { // Tested using ftp://ftp.census.gov/econ2012/CBP_CSV/zbp12totals.zip // 3.2 mb csv file uncompressed csvfile, err := os.Open("test.csv") if err != nil { fmt.Println(err) return } defer csvfile.Close() lines := 0 reader := csv.NewReader(csvfile) for { record, err := reader.Read() if err == io.EOF { break } else if err != nil { fmt.Println(err) return } lines += 1 // out the csv content } fmt.Println("Read a total of", lines, "lines") } **Results &gt;time python3 csvtest.py Read a total of 38819 lines real 0m0.131s user 0m0.121s sys 0m0.007s &gt; time go run csvtest.go Read a total of 38819 lines real 0m0.264s user 0m0.224s sys 0m0.045s 
Try searching Go on Google...
&gt; io.ReadFull didn't want to read fully, only N bytes &gt; io.ReadAtLeast I didn't remember about that one, ended up using `io.CopyN`. &gt; serious network apps, you should pretty much always be using SetDeadline I agree with this, however the format is oblivious to networks or files or wtv, it's exposing `io.Writer` and `io.Reader` and it's up to the user to wrap their `net.Conn` or `*os.File` with proper timeouts/rate limiters/etc.
Right now the examples have bad artwork. I am working on it and you will hear from me again very soon! =)
Google's smarter than you might think. I can't recall having any problems.
&gt;&gt; io.ReadFull &gt; didn't want to read fully, only N bytes io.ReadFull reads until the provided buffer is full. If you want to read `n` bytes, pass it in a byte slice of length `n`. You're confusing it with ioutil.ReadAll, which reads until EOF, and should be used only with care on server-type applications due to the unbounded nature of the reading.
It depends on what you're trying to do and even then depends entirely on what you personally find annoying. I have no experience with developing java webapps, but I will say that installing something written in Go tends to be a lot less demanding than Java. It feels like every Java-based webapp I've tried to deploy has needed its own high spec server just to launch even with nobody using it, whereas I could easily squeeze a bunch of go-webapps on the same server and not worry about it as much. With all of that said.. I don't even know if Go is that ideal for webapps unless the webapps you make need to be highly reliable or scalable. If you're trying to make some simple inhouse webapp used by 20-30 people, you may find something like Python or Ruby to be a lot quicker to get things up and running in, then you can just make all the 'heavy lifting' be done by API calls to a golang based backend server. But again, it really depends on what you're doing and what is important to you. 
Debian / awesomewm / sublime text 3
Asking here if Go is better than [put whatever language here] will probably be equivalent to ask a blind man if he wants to see...
Yeah, I can't stand Unity. I'm a huge fan of Gnome 3 though.
arch w/ cinnamon. sublime is my editor of choice (GoSublime is cool).
I went to google in an incognito window and searched for "go". The very first result is the programming language's website. I was actually surprised it beat out the board game.
Yeah, python3 is natively treating it as Unicode which is good but brings with it a cost in this usage.
Awesome, but it's looking in my $gopaths bin folder, rather than in ~/.vim-go/ what gives? I'll report that.
Hey, could you do a ":GoInstallBinaries" ? This was changed with this PR lately: https://github.com/fatih/vim-go/pull/166
:|, doh.
Yep, that's a good suggestion. I'll do it.
Nice!
I think you're probably right.
Next time you feel the urge to hijack browser scrolling behavior, take a moment, beat yourself in the head with a shovel, and say the word NO in a very loud and stern voice. That said, the actual content is really interesting and insightful. Particularly about Dockerfile caching and the --link parameter, both of which were (good) news to me. It was really interesting to see how this compares to the homegrown solution we use at my work.
You're not the first to mention the scrollbar. I'll bring it up with the person in charge of the site tomorrow morning. Thanks for the feedback!
And thanks for the surprisingly prompt and positive response!
In lieu of digging for a nicer post which explains the same concepts, please read the canonical guide to [asking good questions and getting great answers](http://www.catb.org/esr/faqs/smart-questions.html) in a technical setting. - What exactly are you looking for? - What functionality does 'serverspec' provide. - What *is* serverspec? - What about the stdlib or other packages available is lacking? - What have you tried so far?
If you can provide the schema, I can help a bit more. I have created a pull request for you. Oh, and don't call me Shirley.
I've done that and created a pull request.
Some great comments on starting out with and learning Go here.
Thanks Added database https://github.com/motyar/restgomysql/commit/4f8fe6d5cf43e18f0864cc40fb4449d27c7f4547 
Ubuntu/debian + fluxbox
I don't have the link/name, but Paypal made a point-of-sale blue tooth device leveraging Go
OP here, you can try the open-source tool behind Packager.io: https://github.com/crohr/pkgr, which is itself based upon FPM. Otherwise, Packager.io is also available as an on-premise edition.
Thanks, but quickcast doesn't allow me to change it :(
Why? encoding/xml and friends do it. (disclaimer: I mean *only* regular validation like non-empty, required, max, min string length etc., basically the schema of the struct; I do agree that business logic should be separate from the model)
http://www.techtalkshub.com/embedded-go-bluetooth-low-energy-hardware/ 
This is a cool thing. The ressl API looks nice, too.
Are you a programmer who searches programming terms all the time? If so Google knows this and adjusts results.
Results (Spreadsheet): https://docs.google.com/spreadsheets/d/18P3X5JJ2QhaM_VdxNtPXFNwaKN7cO8YS5ybI880P1PQ Results (Summary/Charts): https://docs.google.com/forms/d/1FLPeANe5Dwqz473lgdxxdc6xumDKTQ7KEqmRvazm2a4/viewanalytics Official golang-nuts thread: https://groups.google.com/forum/#!topic/golang-nuts/dxzoE_pI5Fg
Arch + KDE here.
Your `UnMemoize` / `UnMemoizeAll` need to use a mutex otherwise it's a race.
Will be interesting to see the results. The last question is a bit tongue in cheek but the It's Complicated was the only answer I could really give (rather than one of the 3 Yes options). I'll always do python, javascript will get me the things I need and want at time. I really enjoy Go. I prefer it to any other server side language and love that it's given me a great alternative to having to use where that had been the best choice.
This survey fails to consider students and hobbyists.
So you gave them their own packages anyway? Perhaps you meant repositories?
err yes, I was half asleep doing that. good catch.
Also, why do the you need the doc.go in the root that declares pkg utils?
Last question has three "Yes" responses. For fun?
Unfortunately, while in general you've got the idea, you picked a bad specific module. The JSON module uses reflection to examine what is passed to it, and can easily encode and decode structs that have no specific method for doing so. Many of the serialization modules work like this. It's generally a bad idea to require `json.Marshaler` when encoding json... `SaveData` should just be taking `interface{}`. And yes, I saw your text about needing custom code... it's still not a very good idea. I am a bit annoyed by this, frankly, because not all `interface{}` can be serialized. There is no type safe way to take "things that can be serialized in some manner". But only a bit.
I see your point. SaveData can only be used with types that have MarshalJSON method. Not sure how it would work using interface{}. Have to think about that a while. 
If you're looking for an example of how to use interface in general, look at how `io.Writer` and `io.Reader` are used... everywhere. They really showcase how useful the interface idea is.
64-bit OS are supported... I'm not sure what you are meaning. =) sorry
yes!
A more textbook example would be something like getting a tracking information for a package using a tracking number. The interface would be interface TrackingInterface { TrackingInfo getTrackingInfo(String trackingNumber); } It doesn't matter what carrier your package is being shipped by, the interface simply defines a method called getTrackingInfo that takes a tracking number and returns some tracking information. Now you can have a UPSTracking class, FedExTracking class, etc for each carrier you want to support, and a simple factory that can be used like so ... TrackingInterface tracker = TrackerRegistry.GetTracker("UPS"); TrackingInfo whereIsMyStuff = tracker.getTrackingInfo(number); ... Does this help?
http://godoc.org wouldn't parse the repo without a .go file in the root, not sure why.
I did not realize that at all, good catch. Most of this code I had lying around for a while and I did it for learning.
It is inflexible to validate some complex forms.
These results are pretty cool! In case the author is reading, I have some feedback on the testing question. There are a bunch of other valid opinions on the subject that should be captured, like "Yes, but I'd like to do it less," and "I mostly write throwaway code" Also, 0-6 is a strange usage range, since I imagine someone with 3000 hours of experience would have a much better basis for answering questions than someone who has never used it.
Yes
the begin at https://github.com/jnwhiteh/golang/commit/eefc165c0b299d4c8206809f0c771eaccef8dc50#diff-891dacf80a6391353748b5521e8e2f69R843
This seems like a really bad idea. I can see people trying to name vars these and getting really hard-to-debug errors if they don't know they are easter eggs already.
Don't want to play devils advocate but this is just a shittier version of your previous blog post from 4/20. And this form of "multiple versions" is kind of a no brainer. 
It is indeed, I discovered that when I went to publish it and WP was determined to put a -2 on the end of it. In any case, I don't think it hurts to toot the simplicity of Go's install story - it confuses me greatly why people need to write tools to automate a 2 line process. 
notwithstanding &amp;&amp; despiteallthat } else { isstillasyntaxerror :(
In lex.c, defining the basic types and "lexical thingies": "notwithstanding", LIGNORE, Txxx, OXXX, "thetruthofthematter", LIGNORE, Txxx, OXXX, "despiteallobjections", LIGNORE, Txxx, OXXX, "whereas", LIGNORE, Txxx, OXXX, "insofaras", LIGNORE, Txxx, OXXX, I'm also slightly puzzled (headache+Saturday morning?) about the type "any" Can't remember seeing it in "use," maybe internal? "any", LNAME, TANY, OXXX, Also, print and println are names in some lower level: "print", LNAME, Txxx, OPRINT, "println", LNAME, Txxx, OPRINTN, (other LNAME type entities are len, append, cap and panic)
Except that notwithstanding is [a single word.](https://www.google.com/url?q=http://www.merriam-webster.com/dictionary/notwithstanding&amp;sa=U&amp;ei=zhkUVPjEM_DlsATZ8IFw&amp;ved=0CA0QFjAB&amp;usg=AFQjCNH2IbmVNPTkHRuPghxMiCjirkG9ig). Points for excellent use of the keywords, though.
Yet another opinion.
"[OCaml] has many of the same features as Go but, with the exception of concurrency stuff" I hate this stuff. That's my opinion.
&gt; It has many of the same features as Go but, with the exception of concurrency stuff, Yeah, that little exception. Just Go's main feature. 
The great thing about opinions is that there are so many to choose from!
Right, I just checked and byte (and rune) are aliases. TANY only appears twice in the lexer code, seems to be some debugging/helper type
Thanks!
Perhaps today it has to do with the few ad-hoc polymorphic builtins, like make, append, etc.
&gt; When I get on someone else's computer I'm paralyzed for a second trying to remember how the rest of the world works. Sound like you've successfully managed to make you computing experience very custom-Emacsish even though you're a vim user. ;-D
Well, a new douche company is in control of it, not much better than the old one.
It's actually trivial; it all boils down to the fact that one and the same program written in a portable language has to generate the same result no matter where it runs, and that compilers are ordinary programs. You should rather ask why is cross-compilation so *difficult* in other environments.
Who cares whether OCaml is 13 years older? Go predates OCaml in having a native TLS implementation by several years. Nobody cares about conceptual elegance if nobody gets stuff done in that language. Nobody cares about ugliness when it helps get out projects in time while leaving behind maintainable code.
Hey Luke! Great article. I'm going to get back into helping with this project after we get a couple of major projects done at wrote. Great job on 2FA as well.
&gt; Its not a door, its an opencloser
Always a bit of a nice surprise to bump into /r/darknetplan folks in non-/r/darknetplan contexts. Nice article, will have to keep 2FA in mind as auth plugin for ContentGremlin.
Also, http://blog.gopheracademy.com/day-21-two-factor-auth
My jaw dropped when I read this line.
Hi there, &gt; When a user goes to login, they start off normally with their username &gt; and password. After they click login--assuming the details are correct-- &gt; we create a session. You should prompt for 2FA even if primary credentials are not correct, otherwise this mean you allow bruteforcing the first password before xposing the fact that accont has a 2FA security on the top of that primary pasword. Hope it makes sense, -RB
&gt; The problem is that there is no single natural default value for things like integers, so Go's choice of 0 is relatively arbitrary—why not 1? This is such a load of bull looking for problems where there are none.
That isn't the usual way two factor auth is implemented (google, facebook, twitter etc. don't do that) Brute force protection is usually done by rate limiting.
Not mention, if we are just talking pure ugly--OCaml is pretty freaking ugly. At least Go is readable.
&gt; But if having nil everywhere is bad, having nil almost everywhere is even worse. It makes the language inconsistent. You have to remember that a handful of built-in "primitive" types behaves differently from everything else. More special cases! It also means that any types theprogrammer creates are going to be second-class citizens compared to these built-in types. This theme actually gets repeated a few times in Go's design. This is incorrect. There are no special cases for nil. nil is the zero value for pointers and interfaces. error can be nil not because it's a special case, but because it's an interface. Note that string, map, and chan cannot be nil because they are not interfaces. &gt; Zero values are another example of Go forcing any type you define to be a second-class citizen: only built-in types can have them. Also completely incorrect. *Everything* has a zero value. All newly allocated memory is set to appropriate zero values. The zero value of a struct is the struct with all members recursively zeroed. The zero value of all pointers and interfaces is nil.
That is very true too. Then there is always the case of a program is only as "pretty" as the programmer makes it. Like in python you can create a lot of one liners that can help eliminate some unnecessary code blocks but to a non-python person it just looks like sorcery. 
&gt; And, instead of returning both as a tuple, it does it in a magical, built-in way that cannot be reused for anything else. I don't follow.
&gt; Note that string, map, and chan cannot be nil because they are not interfaces. Map and chan can be nil. That's their zero value also. That's for all reference types. 
I guess he means that this n-valued thing is only valid for function returns (he misses type assertions and channel receives, but that's not the point). You can't have arbitrary things with more than one value, like, say, variables that you could perhaps compose and destructure at will. Not that I endorse the argument, by the way.
People keep saying that Go doesn't have "generics" and that's just not true. We don't get the usual kind, parametric polymorphism (the &lt;T&gt; thing in Java and C++), which yeah, would be handy and which I hope we get at some point, but we have alternatives, all of them able to do some kind of ad hoc polymorphism: 1. Interface values is the most obvious one. You operate on arbitrary types, provided that they can do what you need them to. You can give [any kind of handler to net/http](http://godoc.org/net/http#Handler), and [sort any kind of sortable thing](http://godoc.org/sort#Interface), and return a [connection wrapped in a generic type](http://godoc.org/net#Listen) that abstracts the underlying concrete type. This is typechecked at compile time. 2. You can also give arbitrary values boxed in an `interface{}` and have your users type-assert the return value. The bad things are that it's kind of at times, and that this can crash at runtime. For example, [sync.Pool](http://godoc.org/sync#Pool). 3. Reflection allows you to mutate an arbitrarily typed 'out' argument, so you don't need to return your result as `interface{}` and force your user to type-assert it. This can also crash at runtime. This is what [encoding/json](http://godoc.org/encoding/json#Unmarshal) does. So you need to either bloat your types with interfaces or perform ugly magic with reflection at runtime. But the functionality is there, and for many cases the first option is enough and the second is not that bad.
yep.
Hello everyone! This is something I've wanted to do for a while, and I finally took the time to make it happen. If you have any questions or comments, please feel free to let me know or submit a PR/issue on GitHub! Hope you find this package useful!
&gt;My main overall impression of Go is that its design feels arbitrary: its features are just whatever the designers felt like adding, however they felt like making them. That's true of just about every language. How could it be otherwise? 
On the other hand, that means that the idioms don't look like idioms; they look like several lines of repeated code. Error handling in Go is explicit for (arguably) good software-engineering reasons, but to me it sticks out like a sore thumb compared to Python exceptions or a Haskell Either type. For me, until I learned to skip past it when reading code for comprehension (as opposed to for review), all the `if err != nil` is an impediment to reading. Go does have special punctuation for some of the operations that make it unusual, notably channel send and receive. Would Go be substantially less readable if instead of `foo(&lt;-c)` and `c &lt;- bar()` you wrote `foo(pull(c))` and `push(c, bar())`? Probably not, overall. But in some cases, Go has special syntax that masquerades as a function call. New users can reasonably ask, "What does the function signature for `make` really look like? The documentation says it accepts a type as an argument, so can I write my own function that accepts or returns types?"
I might be wrong here but I think Go zeros memory when you get allocate it so 0 is the natural value of an `int`. A lot of things in the standard library work with that assumption and don't need to explicitly initialize values.
I will upvote if you add support for sonographs. 
They drive a hard bargain, op... 
Seems like you're right, the only one that use this schema I used lately is Apple 2FA. Anyway until he uses rate limiting it could be an easy move for security. Rgds, -RB
So basically you have nothing, just a concept and some screenshots, and you want us to donate and build it for you so you can get rich.
I would say it makes constructors explicit instead of implicit. If you want a 'constructor', you make a method which returns a properly initialized version of the type you want. But now, everybody who reads the code knows _exactly_ which method is called, and doesn't have to wonder if there is a constructor at work that magically does things.
Looking into this 'Human' thing and the 'max' person posting, this entire thing seems to be just a massive scam. Maybe it's even just a joke at the expense of the startup bullshit sphere, but I fear not. Could the mods consider this spam?
Except you can't force users to use your constructor, so they can still screw it up. It *could* even have been a twist on 'make' or 'new' which would have eliminated one of the special cases. But it's not. Builtins are special. User types are handicapped.
Please don't turn this subreddit into a job posting forum. There are specific subreddits for this, like /r/hiring
Bravo Sir Dave !! Thank you very much !
That's why there is gofmt. So no excuses.
No, I have something that I've been working on for over 3 years and could have accepted investments for at a over billion dollar valuation (I have this in writing), and instead have decided to give it all away to the public for free. I've worked on this without pay for years and am donating all the money I have to it. If nobody wants to build it I'll just take 1 thousand out of the 50 I'm initially donating and have somebody build the beta. This was an opportunity for you guys to get involved from the start. You don't have to accept it.
This is not a joke or a scam. If you guys don't wanna help we will build it ourselves. Totally up to you.
Typically in your ~/.bashrc file. However you may want to make it more usable: deps() { go list -f '{{join .Deps "\n"}}' ${1:-.} } So you could pass an import path as an argument, e.g.: ~ $ deps code.google.com/p/go.tools/cmd/godoc
I'll upvote op twice, if he makes it as a service. ;)
You can configure your editor to do that very easily! 
But I use notepad!
&gt;If I were you I would go get that billion dollars somebody offered you ... No, I would never sell this company. I could have built it to 100 billion dollars on NASDAQ and kept 3/4 of the shares and didn't. And for the sake of clarity, the people offered a few hundred grand each at a billion dollar valuation, not a billion dollars. Nobody in their right mind would risk that much money on a brand new company, but they WOULD be willing to risk a few hundred grand if the payoffs and fame are potentially huge. &gt;But really? All I can tell is this is a site entirely for collecting donations "for a good cause". No, you are thinking of the empower crowdfunding service - it's just one of like 2 dozen revenue streams. Wow, we really suck at explaining things don't we? Sorry, after THREE YEARS, there is just SO MUCH that it's hard to shrink it down to something very small. But there will be 20+ online services and 5 hardware lines to start, the 6th (contacts) will be added closer to the end of this decade. &gt;And that some how I will have some super small say in what happens with that money. No, you control the entire company. Everything. You get one vote, I get one vote, everybody gets one vote. We run the company TOGETHER. We own it TOGETHER. &gt;At first I thought you were going to describe something cool like, a strong AI or something. But then .... dat gap ... transition. Look at /pics/old - see discover? That is the landing page of the network, once it is finished. What you see there will be controlled by AI - she will learn what you like and don't like and will act as your personal friend and assistant throughout our entire software and hardware ecosystem. In the future we will also make robots, so you'll be able to give her a BODY. In the far future we will build a Strong AI and use her insight to help us run the company better.. Google, Apple, IBM and so forth will do the same thing - in the future, it won't be about who has a better CEO but who has a better AI. We plan to be on the forefront of that.
I always google using "golang"
Is it related to the old netchan?
Please expand he readme. Navigating GitHub from mobile is tedious :(
I'm working on it slowly atm, documention isn't one of my strong points. You can check http://godoc.org/github.com/OneOfOne/netchan for now, also check my reply to davecheney for a better code example.
In my original design I had a `SendAll` function, but after rewriting the code for 10th time I forgot to implement it. Gonna push an update in a few that includes Select on multiple channels and SendAll.
http://godoc.org/github.com/OneOfOne/netchan#SelectRecv 
`SelectRecv` spins, wasting CPU. Calling `runtime.Gosched()` is a crutch and is _not_ guaranteed to yield to another goroutine; all it do is make the current code path call the scheduler. Is it possible to implement `SelectRecv` without spinning ?
Problem is that the lack of generics force any library solution to be wrapped with ugly typecasting. Not the end of the world, but it does highlight the limitations of the language.
You're right. I always assumed "generics" means "ways for a function to take arguments of several concrete types", since for example no one complains about Python or Ruby not having generics, but seems like it's the same as parametric polymorphism. Anyway, the important point is that you can still make generic code in the generic sense of "generic".
I stand corrected, I ran a longer test with gosched and you were correct.
&gt; is quiet specialised A typo?
For performance-sensitive code, it is definitely the lesser evil. I wonder if the golang community will start looking more to code gen in place of generics.
The original netchan was discontinued because it was not possible to send channels and functions over netchan. Unless this is solved I don't see any benefit over the old netchan.
I guess my point is you really don't seem to have anything to give away but an "idea". Ideas are free. Once you have something actually worth something then give it away it makes a world of difference. For example. Had you some how stumbled upon a real strong AI and then given it away to start something it would have made more since. I feel like you are coming here and saying you are giving away something on the level of IBM's Watson to everybody to build a company with but when you really just came with the idea of building something like IBM's Watson. Correct me if I am wrong ... I did not see any source code or hint that any real backend has been made. What I did see was the idea of making one ... 
happy i3 user here. but yeah, wingo. a full window manager in golang. https://github.com/BurntSushi/wingo (there's some X window bindings at the bottom of course, but you're not gonna escape that, and it's nicely tucked away in the corner.) i don't currently use wingo, but I plan to next time I install a machine, and I have a coworker who's been a happy user for several months now, so i'll confirm that it's definitely not vaporware (it looks pretty much indistinguishable from i3 on the cover). and BurntSushi is a top notch dev all around, from his other code that i've used.
Templates?
There is one already!
Ow.
Right. I don't think the goal is to be pretty or to be utterly DRY, it's to make reasoning about code easy. 
Right.
whoops, fixed. Thanks.
You getting confused is the point he was making here. It's easy to get confused about some of this stuff because a lot of the design decisions were ad-hoc and determined by implementation simplicity rather than a uniform set of abstractions which led to a lot of special cases.
I love `go list`. I'm using it extensively in vim-go and let go do the heavy work done: https://github.com/fatih/vim-go/blob/master/autoload/go/tool.vim 
The C++ approach? If you are not familiar with all the generics-debates this article is worth checking as it explains the problem nicely. [research!rsc: The Generic Dilemma](http://research.swtch.com/generic) While the answer may seem obvious to someone, each of the options is obvious to someone and it's far from trivial to decide which one is the optimal one. It's not a decision that you really can change later on either. For what it's worth I personally really like the C++ approach although it might be fairly horrendous for compile times.
From what I understand, compile times in C++ are not inherently slowed down by templates. It's the header stuff.
$0.02: I love templates. But I would hardly call C++'s implementation ideal. It's very flexible - perhaps too much - which causes issues with communication and education in groups with mixed skill levels (i.e. the typical workplace). At the same time, it lacks some very basic type-safety things that people are *still* trying to get into the language proper (read up on 'concepts'). The result is an implementation that is both a language unto itself, yet refuses to allow the author to easily provide strong controls on how templates get used. A better candidate for how Go should approach templates would be how Java is pulling it off right now (and maybe that's not a good answer either). I'm not a fan of type erasure, but it may address concerns in terms of the cost of implementation for the feature, and how people reason about what the compiler does with such code. The C++ route, while insanely efficient at run-time, can be a bit much for some people to wrap their heads around (IMO).
You are right. They are pretty far from ideal for Go.
In addition to YEPHENAS' point, the other major problem with "netchans" is that the semantics of a channel are _impossible_ over a network. Inside a singular Go process, a (non-buffered) channel sends and it is guaranteed that some other channel consumer has received it XOR the channel is notified to you as closed. This is impossible to provide over a network, and the channel concept doesn't have a way to deal with that. Nor should it. Things that may go over the network need to deal with the possibility of failure, and there also needs to be APIs that are simplified by not having the possibility of failure to worry about because there is no network. We don't need "net channels", we need "channels" and "things that use the net", and we need them to not mix.
I hadn't seen that panel. That was a lot of fun :)
I moved to using reflect.Select however it will still (randomly) burn cpu cycles as bad if not worse than using spinlock if there's nothing to select right away. Not sure if that's the intended behavior or it's a bug in tip, hard to test when I keep losing electricity.
The notification part can be done, not easily but it can be. Also, Erlang would highly disagree with your last statement ;)
Actually I half way have sending channels over net channels working in my local repo, it's very ugly though and I don't feel comfortable enough to push it. functions, well that's not gonna happen without native changes in the runtime.
From the title I thought he wrote his own CSV parser and I almost had a heart attack. Then I read the article. Phew.
&gt; the standard library is responsible for allocating a block of memory to be used as that thread's stack. I'm no expert but this doesn't seem true to me
If truly restful apis and security is your concern a framework is best because it has many eyes on the code unless your are a vetted api and security professional with peer reviewed implementations of your own under your belt. Tyk is a golang api gateway that lets your build your api and handles all the authentication and authorization. Its a young project and does not make any claims to rock solid security but it is a solid start. Beego has an api skeleton in its toolbox and can handle authorization Revel can handle authorization gogi is a nimble framework to create apis with and so is jas, gorilla, and the go stdlib gives everything you need to roll your own... Use which ever makes you most productive... 
Don't forget to check this https://github.com/rcrowley/go-tigertonic 
Or maybe "we" as in we, the community that uses and supports Go, as we'll all be using that new method. (Edit: And if you read any of the author's previous articles, you'd know that he liked to use "we" even before he became a part of CloudFlare)
Same old sap story.
It seems like he's referencing C's stdlib (ie malloc) Usually the thread API has an optional stack size which would invoke some low level allocation
Is there a difference between this and goose? So far it looks this same, but I didn't look that closely.
Does it work the same on heroku? Thanks
There's no need for that workaround: just use it as a library inside your application. I haven't tested it though: give it a go and open an issue on Github if things don't work, happy to help.
Wonder how many migration tools are still in-progress :0 https://www.reddit.com/r/golang/comments/2dlbz5/database_migration_handling_in_go/
Nice to see how they can all get along when they're within punching distance, isn't it? ;) But seriously, I would like to see more panels like this. It's nice to see them realise how much they *agree* on things and accept they have different priorities within systems programming, instead of the focus being on how they disagree about the details.
I usually make a point on migration threads that writing your own migrations system is much simpler than you could imagine and quite rewarding. If you go for schema versioning, it is a few steps: 1. Create a versions table, usually a single column containing some sort of version time stamp. 1. Create some custom functions to actually migrate the database, identified by a version time stamp. 1. Create a migration function to collate migrations, check which ones are missing from the versions table, and run those. I've recently written a declarative database migration system for a few of my most recent projects in which the database and indexes are all defined centrally, and the migration logic compares that with what is actually in the database and modifies accordingly. I've found that a really cool design though you get a bit less flexibility over defined migrations.
&gt; If new features are added to a package, say foo.v1, if the API is the same it keeps the same version number (v1) -- so, yes, you have to update your v1 package multiple times to get new features which looks silly. That's not silly, that's basically how semver works.
Enthusiastic. (shameless plug: https://github.com/eanderton/grapnel) At the end of the day, we need a LOT more semver tags on repos. Version pinning, and due diligence on the part of library maintainers, is only part of the problem. There's another area that has been left largely untouched by the Go community: enterprise development. The enterprise needs to shield itself from all the volatility out there, so supporting local repositories and archives of stuff helps tremendously. Not to mention that a lot of places have web proxies in place, which only makes the whole matter more complex. In short: not all environments are always 100% internet connected, and once you're in such an environment, you begin to see how the current status-quo throws up roadblocks for that use case.
http://golang.org/pkg/math/big/#Int.Int64
I'd argue you're better off going about it a different way. Using `big.Int` is pretty unnecessary and probably inefficient in this situation. I'd recommend importing `"encoding/binary"` and doing something like: b := make([]byte, 8) n, err := rand.Read(b) if n != 8 { panic(n) } else if err != nil { panic(err) } i := binary.BigEndian.Uint64(b) % n It's not too neat, but it works.
looks awesome, I think I'll use it in my site I am rewriting in go this week :)
maybe we could start the bidding at spectrographs?
How do you handle dropping or altering columns with SQLite?
I think i misunderstood the survey on this. I don't expect changes in "v1", i expect "v1" to become "v1.1" or "v1.0.1" and etc. To me, a version identifier should never change, and should basically just point to a single commit/build.
You didn't specify if `n` can be larger than `1 &lt;&lt; 64 -1` or not.
&gt; line 31: reader.Comma = ';' //field delimiter What the...?
Hi jerf, Thanks for your comment. I'm an author of yosssi/gcss. &gt; You shouldn't be writing straight out to the disk in the API; let the user decide with an io.Writer. I provide [CompileBytes](http://godoc.org/github.com/yosssi/gcss#CompileBytes) for users so that they can read/write any resources. This function gets GCSS byte arrays, converts them into CSS byte arrays and returns them. &gt; Just as a style note, in that file, it's weird that cssFilePath is a var, but is private. Yes, it looks weird but it's needed for 100% test coverage. This var is overwritten by [the test code](https://github.com/yosssi/gcss/blob/6a1a76677380fbcee921005558bff04b662fed4d/compile_test.go#L34). Race conditions are automatically checked by [CI tests](https://github.com/yosssi/gcss/blob/6a1a76677380fbcee921005558bff04b662fed4d/wercker.yml#L28).
&gt;Yes, it looks weird but it's needed for 100% test coverage. This var is overwritten by [the test code](https://github.com/yosssi/gcss/blob/6a1a76677380fbcee921005558bff04b662fed4d/compile_test.go#L34). Ah, well, this all sort of ties together... If you offer a Writer, you won't need to test path handling in an integrated manner and could then easily just test the default file name code as a simple unit test. Thank you for replying, too. I always find it frustrating when somebody post something and then fails to interact. 
The way you suggested to take an `io.Reader` &amp; `io.Writer` is useful for developers, so I'll try to fix the current `gcss.Compile` function. Thank you very much for your valuable feedback! Your advise was very helpful and I studied a lot.
The sample data he provides in the article is comma-delimited. He's not parsing anything. He reads in a record, doesn't parse it, and prints it out. 
I disagree this is an "enterprise" problem. In fact I reject the idea that there is a certain set of development teams who need to have absolute control over the code they depend on and a set that can reliably outsource this problem. In both cases, if you depend on some code that some group outside your control manages, then you need to make a copy in a location you control. That could be vendoring it into your source code, or forking it into a DVCS that your company controls. I strongly recommend following the advice of Peter Bourgon from slide 34 of his Gophercon 2014 presentation, https://github.com/gophercon/2014-talks/blob/master/best-practices-for-production-environments.pdf Nobody wants to be the person that has to explain to the CEO why they couldn't deploy a fix to production because github/maven central/npm.js/CPAN/PyPi/bitbucket/something was down.
An import cycle is where two packages depend on each other. What does package bar depend on?
it depends on 2 other packages, but neither one is used in main.go.
ok, thanks for explanation on what import cycle means. Looks like 2 packages (not main.go) depend on each other.
http://play.golang.org/p/uedKm93AEX
As much as it pains me to say this we are really in need of a SOAP client. 
Are we sure that pants are inappropriate headwear under all circumstances though? I'd want to see some data before I accept such a quick dismissal.
Different strokes :)
Just FYI, this works because 2 is a constant. If you just had an int you wouldn't be able to multiply them. You'd have to do `time.Duration(i) * time.Hour`
All those points were brought up in the post, and he gave some additional justification in the appendix. Can you talk about why it would be a net loss to use suture instead of either a) rolling your own solution or b) having no solution? Or, how the author is underestimating the shortcomings of Go with regard to implementing this pattern? 
Supervisors are an all-or-nothing solution. Having a half-baked solution is just needless indirection over the top of idioms that people are already using.
Also works inside. http://play.golang.org/p/OBxAelnW0P
That cast is pointless.
I feel bad doing things like that. I feel like I should get square nanoseconds. `time.Duration(i)` doesn't make any sense by itself. Where does `i` come from? What type does it have? `time.Duration(time.Hour.Nanoseconds() * i)` feels better.
It's not hard to live without async kills. The supervision aspect of supervision trees is the important part.
This is to me from a code reviewer when I did this once (I wanted a time delta of the smallest possible unit): &gt; You're making the assumption that time.Nanosecond will always be 1, which might be true, but you're breaking the abstraction if you just blindly cast from int to time.Duration instead of using the constants to do the conversion. So if you want i+1 nanoseconds, you should just say &gt; time.Duration(i+1) * time.Nanosecond
I mean like http://play.golang.org/p/gw-41g0xZy If he's getting the value from like a flag or whatever he'll have to cast it. (vs. http://play.golang.org/p/5CoS1EcVoz)
And supervision implies monitors, which Go cannot do.
That doesn't match my experience. In my experience, this gives me the same results in Go as I get in Erlang, to the extent that it matters. As far as I'm concerned, that's the only argument that matters. Results trump theorizing. 
Not quite. Erlang _uses_ monitors to _implement_ supervisor trees, but that doesn't mean that the only way to do supervisor trees is via monitors/linking. Existence proof: Suture works. As for "Go can't do monitoring", well, [that's perhaps a bit strong](https://github.com/thejerf/reign), though that's a work in progress. Just as with suture, the semantics _are_ a bit different, yes, but that doesn't make them wrong. In general, `defer` is just as much a guarantee of certain functionality as anything Erlang provides. Just because Erlang does it a certain way does not mean it is the only way, or the best way, or a necessary way. It certainly doesn't mean that any other language environment that wants something like what Erlang has must just throw its metaphorical hands up in the air and give up if it can't _exactly match_ Erlang's every last fiddly detail. (And as I believe I noted in my post, it does mean that if you want to port something out of Erlang it is important to do an _idiomatic_ conversion, and not a "literal" one.) Erlang's way may have certain advantages over a Go-native approach, but Go-native approaches can have advantages over Erlang approaches, too. You can get any answer you want if you only consider the advantages on one side and the disadvantages of the other, but that's not a useful way to reason. It's probably also important to realize that Erlang isn't some sort of magic, perfect solution. If you wedge a Go process, Suture won't restart it, but Erlang won't necessarily do anything useful, either. I've run out of memory in a running, production Erlang process because a particular process wedged, and its mailbox grew to consume all RAM. I've had my production infrastructure unexpectedly brought down by one monitored process that crashed just _barely_ over the thresholds, which crashed its supervisor, which crashed the application, which took down the entire process in a massive flurry of nearly-impenetrable log statements. It's absolutely true that Go has some pathological situations, but it's not that Go has them and Erlang does not... it's that Go has some and Erlang has _different_ ones. Yes, it was advantageous that on Erlang I could log in to the server, witness this, and manually kill the target process. But that's neither here nor there when it comes to my library... that's just Erlang. It's not something very many other languages can do at all.
&gt; Suture works Only in the sense that if you manage to send the exit message then the monitor works. In Erlang the thing crashing isn't sending the monitor its death throes message. Suture therefore fails in cases where Erlang does not. Not to mention implementing this cross-node. As to the rest of your post. The reason Erlang does it the way it does is not because it's *a* way or that it's *the* way, it's just a way that *works*. There are aspects of the way Go does things that mean that making supervisors and links much harder to get correct. You do need linked processes to make supervisors work properly, it really does not give me any faith in this library when you assert that you don't, here's why: Drawing on conclusions from work done on detecting network splits, we can apply the same reasoning to actors within a single process, such that detecting remote node state is next-to-impossible to do accurately without a third party. Without some agent external to both actors in a system, you cannot detect a remote actor's death. Imagine a situation where a Goroutine gets blocked a socket read, or something of that nature. Is it crashed? Is it just blocked? Paused for GC? Who knows? You absolutely cannot tell. With Erlang processes you can tell. To be perfectly clear -- I am not asserting that Erlang provides any better guarantees with remote notes in that case Erlang is still at the whim of network weather and suffers most of the same problems that other languages do. More succinctly, Erlang doesn't really offer anything better over most languages in clustered environments. &gt; It's probably also important to realize that Erlang isn't some sort of magic, perfect solution. If you wedge a Go process, Suture won't restart it, but Erlang won't necessarily do anything useful, either. This is not *entirely* true. You can query a process' state remotely and act upon the state *remotely*. In Go, without some incredibly convoluted and most likely fragile code you cannot do this. Having the ability to query this means that even *if* a process is entirely fubar then you can kill it and have the supervision tree's child specification pick this up and restart that child, without the child itself taking part in it. In short, if the only tools to ascertain an agent's state (crashed, paused etc) is the agent itself, you will not be able to properly create a supervision tree without making huge sacrifices of correctness. &gt; I've had my production infrastructure unexpectedly brought down by one monitored process that crashed just barely over the thresholds, which crashed its supervisor, which crashed the application, which took down the entire process in a massive flurry of nearly-impenetrable log statements. This is not a problem unique to Erlang, queues (and your problem is a queue consumer problem, masked in Erlang process) that get written to faster than they are consumed from are bound to grow in memory size. This is extremely uninteresting and totally pedestrian information. To solve this problem a lot of solutions are available as a whole and for Erlang specifically. There's a new book [you should look at.](http://www.erlang-in-anger.com/) Finally, I'm not saying that this is entirely impossible task to implement in Go but I firmly believe that you cannot implement this with purely Goroutines and channels if you expect any where near the same semantics as what you get with Erlang supervision trees. You may be able to provide *some* level of similarity but it will not be as robust as the behaviours as what OTP provides. 
&gt; Without some agent external to both actors in a system, you cannot detect a remote actor's death. Imagine a situation where a Goroutine gets blocked a socket read, or something of that nature. Is it crashed? Is it just blocked? Paused for GC? Who knows? You absolutely cannot tell. With Erlang processes you can tell. With Erlang processes _you_ can tell... the supervisor can not. Mind you, that first bit _is_ nice, but it is mostly irrelevant to the discussion at hand. When Go is chosen, you've given up on remote kills. Actually, per my discussion, the moment you chose an imperative language you gave up on it. That's really just ground state for imperative languages. Further, there _is_ an external agent here, which I hinted at in a previous message: `defer`. It's really easy to miss what defer is, and how important it is to Go in general, not just suture. What it is is the _Go runtime_ __guaranteeing__ that some bit of code will be run when the stack unwinds past the point where the defer was created. This is different in character, but ultimately of the same type of thing as the Erlang runtime guaranteeing that one process will hear of another's death. Yes, a suture supervisor can be _guaranteed_ to hear about the child process' termination. That is all an Erlang supervisor gets, too, FWIW. It is true that _you_ can do more, but in comparing Erlang supervisors to Go supervisors you can't call this something the Go supervisors have a disadvantage in. This is part of what I was trying to say when I said that it's important not to accidentally raise the way Erlang happens to do things too high in your head. Yes, the runtime needs to provide some guarantees, but they don't have to be the _same_ guarantees. There are many different paths. There are some ways in which defer is more powerful than the raw "process death" notices that Erlang guarantees... it's certainly obviously more flexible. &gt; You may be able to provide _some_ level of similarity but it will not be as robust as the behaviours as what OTP provides. Hmmm... you mean, like &gt;In the end, is it _quite_ as slick as Erlang is? Frankly, no. Erlang was in some sense built around supervisor trees, or at least the set of features that provides the ability to build them, and it's hard to compete with that. &gt; However, even in my limited experience, adapting this style into Go still carries enough benefits to be worthwhile. I feel I've had a net benefit from this library just writing and using it myself. Everything I do that can possibly be a Suture service is, and I've already witnessed it taking some 99% functional code, and making it something I can deploy for a while without it completely failing. This is good stuff. I did not edit the point before quoting that. I gotta say, I'm really tired of people dismissively explaining _my own points_ back at me, without acknowledgment that I had the courtesy to _spell them out_ for you. Now, next question: _Even if_ Go can't provide something _quite_ as robust in every last detail as Erlang, might it just possibly still be worth implementing? Because Go does, after all, also have some reliability tools that Erlang doesn't, like static type system. (Yes, I'm aware of Dialyzer and friends. It's a bolt-on, and it shows.) To say nothing of how performance itself can be a reliability tool, if Erlang would be choking under a load that Go will handle on the same hardware. Also, suture doesn't make anything _worse_. Suture does not create the problem of a wedged goroutine not being able to be killed. It's a problem in Go to write that code. It's still a problem in Erlang to write that code. Whether or not a full Go system or a full Erlang system will be more reliable in the end is a _complicated question_. It isn't obviously the case that Erlang is just automatically better. I've had real problems with its performance, real problems with its GC (despite the apparent benefits it ought to have over Go), real problems with its weak typing, and _real_ problems with having a hard time getting people to work in it due to it being a fairly non-standard language. I still say you're starting from a ground point in which Erlang is simply Correct, all deviations are automatically Wrong, and there can never be anything that Go might do better which might make up for the Deviations (or, even, perhaps surpass).
&gt; What it is is the Go runtime guaranteeing that some bit of code will be run when the stack unwinds past the point where the defer was created. And if the stack never unwinds? (Blocked socket read, etc) &gt; Also (and this is key), suture doesn't make anything worse. Are you sure? I mean, you're providing the exact same guarantees that people can get right now but behind an API which claims it's as good as Erlang does it (obviously still debatable with according to you, clearly). Arguably one could say that hiding this kind of complexity behind an API whilst providing no more guarantees that you get out of the box is a bit misleading. &gt; I still say you're starting from a ground in which Erlang is simply Correct, all deviations are automatically Wrong, and there can never be anything that Go might do better which might make up for the Deviations (or, even, perhaps surpass). This is not my stance, my stance is that Erlang works and that there are certain primitives that you need in order to implement similar things.
&gt; And if the stack never unwinds? (Blocked socket read, etc) Are you actually reading what I'm writing? Erlang supervisors can't handle that case either. (Incidentally, not the best example. Blocked socket reads are sort of your own fault. All serious socket code should be using SetDeadline, or arrange for time outs in another way. I say "sort of" because the current Go API could be improved; it puts more burden on the API user than there should be. But in general the problem exists of course.) &gt; which claims it's as good as Erlang does it Are you reading what I am writing? Are you aware I'm the author? Are you clear on the fact that I quoted from my own blog post about how it's not quite the same as Erlang's implementation, _at length_? Which is directly referenced in the godoc and thus I'd consider it part of the core documentation? I'm not responsible for claims you make up. (Normally I wouldn't snark like that, but you started this with "pants on head retarded", so, you know, I hope the great Reddit vote brigade would kindly cut me a bit of snarky slack.) &gt; you're providing the exact same guarantees that people can get right now but behind an API which claims it's as good as Erlang does it While providing a structure with sensible restarting code, logging, a general structure for using the available guarantees without having to manually implement them over and over, and a single place where improvements can be updated in a library without having to propagate the fixes everywhere. That's more than enough to be worth putting up on GitHub. Sure, you could write that all in, but you'll find that you just reimplemented suture. And, you know, while I don't guarantee suture is perfect as-is, it also took me several days to write, cover with tests, gain the experience using it that I have to make sure that it does provide value, and finally, take the time to trim down to its essence with no extraneous features. _You_ may not agree, but I'm a decent programmer and that's a lot of programmer-time that you can save by using this code, instead of developing your own solution. (And there's a lot of ways to get tripped up and spend more time than I did writing a clone...)
&gt; Are you actually reading what I'm writing? Erlang supervisors can't handle that case either. Uhm, yes they can. https://gist.github.com/AeroNotix/3fb9f52ab6fc697b17eb suture (and Go in general) cannot do this. &gt; Are you reading what I am writing? Are you aware I'm the author? Are you clear on the fact that I quoted from my own blog post about how it's not quite the same as Erlang's implementation, at length? Which is directly referenced in the godoc and thus I'd consider it part of the core documentation? You're the one that's likening it to Erlang *everywhere* in your code, posts and here on Reddit. It's clear that you think that it could be even a small replacement for it. I'm disagreeing with you here on that point. &gt; While providing a structure with sensible restarting code, logging, a general structure for using the available guarantees without having to manually implement them over and over, and a single place where improvements can be updated in a library without having to propagate the fixes everywhere. That's more than enough to be worth putting up on GitHub. Sure, you could write that all in, but you'll find that you just reimplemented suture. My point was that it provides no better safety guarantees than a simple goroutine listening on kill channels with a defer/recover watching for errors. Wrapping it all up with some logging and restarts, whilst nice is not anything which I have the issue with. &gt; And, you know, while I don't guarantee suture is perfect as-is, it also took me several days to write, cover with tests, gain the experience using it that I have to make sure that it does provide value, and finally, take the time to trim down to its essence with no extraneous features. You may not agree, but I'm a decent programmer and that's a lot of programmer-time that you can save by using this code, instead of developing your own solution. (And there's a lot of ways to get tripped up and spend more time than I did writing a clone...) A whole *several days* eh? I'm not entirely sure if you're aware of the history of Erlang but it certainly took a little while longer than several days. I'm not really wanting to get into a back and forth argument about some pseudo-Erlang library but seriously I really don't think you're getting that something like a proper robust supervision tree is just not something you throw together on top of the primitives that Go gives you.
Not to be a downer but I feel I've seen this blog post a dozen times already from other sources.
I was never, *ever* talking about *automatic* detection of a hung process. I'm saying that a hung process cannot be killed and therefore it breaks the contract of having a supervision tree. If you cannot kill children, you cannot reset the state of an application. Without being able to reset the state of an application then you're missing the whole reason you'd want to be able to supervise a child process, to be able to capture crashes and bring yourself back to a known-good state. Your supervision trees lack this feature for edge-cases purely because of Go, not because of your implementation. This is why I believe on-the-whole that pursuing supervision trees should be done in the runtime, not in user-land code. Guessing would be risky at best and leave random goroutines around doing lord knows what at worst. &gt; You keep asserting the impossibility of things I have in my hand. Not really -- I'm asserting that you don't have an implementation of supervision trees in a form that realistically should be called supervision trees. You're conflating the idea of starting and stopping an application with monitoring and linking to the application, these are separate things and I'm saying that you are not properly implementing the linking and monitoring because Go cannot do this. Sure it can have a tiny interface that describes start/stop, but supervision trees in the form that they are useful is something you cannot attain properly. 
I'm not unclear on it at all. I just think you don't understand the importance of being able to kill arbitrary processes when you want to provide a supervision tree.
I'm digging the concept quite a bit. And even in the limited sense that the concept can be implemented in Go, I've certainly written code which uses similar concepts. The thing that bugs me about this is the implied use of panic() everywhere, at least at the top level of a server. Go doctrine is that use for normal control flow is to be avoided, and I can't see how code using this framework wouldn't routinely violate this rule. Anyone care to ease my mind on this point?
Wow gibbon.co is horrible.
Terrible bookmark site Near-useless and unguided list of things you've read. Ooh boy, how is your site better than Google? If you want attention, pick a topic and write something meaningful about it. 
Great article. I just cringe at his thoughts at the very end. &gt; Or I could write it in Go in about 2 minutes and move onto fixing the next bug in the backlog. Don't blame swift for being a fun language. If you need to be productive don't play with it, just do the work and move along.
I couldn't find a way to do geospatial queries on Google's App Engine datastore, so I made this simple package that is inspired by a similar package in Python. However this package isn't a straight port of the Python package, and uses different methods to accomplish the same goal. As a result, its definitely not as well-used and robust. In other words, feel free to use it as the basis for your own projects, but don't expect it to be production ready.
I think part of the point there though is that you may write it in two minutes in Swift, but now the next guy to come along has to understand whatever dialect you wrote there, and so on, and so on. Goodness help you if one of the "and so ons" decides to mix in another dialect there, because it's easy, and before you know it it's just a snarl of every style of Swift ever written. I'm in much the same position. Is Go my favorite _personal_ language? No, probably not. But I've really been coming around to the position that Go is the language I want to work in. Because not everyone I work with is a language dilettante who knows ten languages already and doesn't mind picking up Scala or Haskell or whatever just to work on this project. They want to sit down and be up and running ASAP. And Go offers a really fantastic compromise, where I get enough power to be effective, and they can just sit down and read it with about 30 minutes tutorial and be submitting patches in a couple of hours.
Not that this is a good solution but there is a package similar to the Llama stuff. https://github.com/go-on/queue
Nitpick: frobulate doesn't need to define err there. You can just do: if err := whatever(); err != nil { return nil } and err will be scoped to the if statement.
This is a new feature we're working on at Sourcegraph, and it's available/free for all open-source projects on GitHub, Bitbucket, Google Code, etc. I thought some folks here would find it useful and have some good feedback/ideas. We want these smart diffs to help you perform code reviews more quickly and effectively: * see a quick high-level overview of what a commit or PR changed (at the function/type/etc. level, not files/lines) * click on anything in the code diff to jump to definitions More examples: * Docker: https://sourcegraph.com/github.com/docker/docker/.commits/3a90004f3c2d86ec849f4674c8046693ea061ed1 * go-github: https://sourcegraph.com/github.com/google/go-github/.commits/d8cbc48267a4b92eb7072a61f0193a811a0129e3 What sucks about it right now (it's not ready for broad release yet): * it takes a while to analyze commits/PRs to produce these results * the interface looks awful * it's not integrated with your GitHub workflow, so you have to remember to go to it Feedback and ideas would be greatly appreciated. Thanks!
It doesn't give you the source file, but the list of imports.
This is kind of robbing Peter to pay Paul. You're not even really saving a line of code since you're cramming two statements into the if. You also can't use this if the whatever() returns multiple objects. It's pretty idiomatic to just result, err := whatever() if err != nil { Handle Error } Since error handling is (very) nearly always done right after an err is declared, it's perfectly fine to just reuse the same err throughout a function. 
Hey, I'm also one of the founders of Gibbon, please let me know what you find horrible and I will see what we can do about it :)
Yeah, sorry about that. We just released the website yesterday and didn't test it enough on iOS. Will do some fixing today. There is also an iPad app. available btw: https://gibbon.co/ios
I think the point is to limit the scope of err as much as possible. As always it depends on the application.
I've frequently felt the same way, but the more I've used it the more I've felt that templating/code generation is the way forward with this. This was further reinforced for me when I read the panel discussion the article linked to (http://gophercon.sourcegraph.com/post/83845316771/panel-discussion-with-go-team-members) &gt; Q: What’s the best way to work around the lack of generics and polymetric polymorphism? &gt; A from Rob: If it’s not performance critical, just use reflection. Otherwise, use Robert Griesemer’s fantastic libraries for source code rewriting, and write a tool to automate the writing of source code. The whole computing community underappreciates the value of programs that write programs. This is a perfect use for them. While I don't know exactly which libraries Rob is referring to there, there are several technologies that are great starting points: * [The AST package](http://golang.org/pkg/go/ast/) Write your algorithms to take interface{} and use the AST tools to rewrite that for your specific type * [Gen](http://clipperhouse.github.io/gen/) A generics code generator for your types. A quick annotation on your types and it generates your favorite underscore/LINQ type functions (Where, Each, Select/Map) * [go generate](https://docs.google.com/document/d/1V03LUfjSADDooDMhe-_K59EgpTEm3V8uvQRuNMAEnjg/edit) Coming up in Go 1.4, generation from code annotations will be built into the Go tool set. A few of the first things they discuss as possible uses are method generation and macros, so I expect to see some great tools coming out to this effect.
Are there enough tools like this that someone could customize bootstrap, add angularjs UI and not use node.js at all?
Yep, [it's even in the official docs](http://golang.org/doc/articles/wiki/#tmp_3). I think this is yet another one of these *"Whoo, I discovered a new language!"* posts.
Make the channel buffered, then the gorutines would not block and finish. The channel will be GCed when no gorutines use it.
That seems to do it. Thanks!
"Go feels under-engineered because it only solves real problems." I love this!
Good point. But I didn't interpreted his message in that way. I agree completely with you, high flexible languages can incur a penalty to the readers since more styles and more higher abstractions being used. But he isn't complaining as a reader but as a writer. &gt; This was my first time using Result&lt;Void&gt;, and I started asking myself if I should create a typealias for that and maybe a helper function for the slightly strange looking success(()). The var bothered me. It always feels like a hack in FP, like you’re not smart enough to do it right. I wrote a different version that didn’t have a var. That duplicated self.cleanup in two places. So I started working on a new function that would let me include the conditional in the functional composition. I made and re-made a lot of choices. In my opinion, this isn't about the code being more readable, just being more beautiful in his eyes. It gave zero value to the future readers.
I feel like I understand what you mean and it's a valid point, but I think the complaint he's levelling is more like this: He's a perfectionist and wants to write correct code in the most beautiful and expressive way available to him. In more "engineered" languages, he has many elegant ways to express his solution, and he ends up spending a lot of time contemplating, 'what is the absolute best way of doing this?' In Go, there's often only one clear and correct way to accomplish the task, so he doesn't end up wasting that time tweaking an already-functioning solution. I agree that it's wrong to blame the language for giving you so many ways to express yourself -- it's more of a personal flaw really, if someone is unable to *not* constantly play and tweak in the language and it harms their productivity, but I can understand how, as a perfectionist, it can be kind of liberating to work in a language where those kind of decisions are mostly made for you by design.
For all newcomers: NO, this is not good structure. For school project maybe, not real world application.
Thanks for the heads-up. What's wrong with it? What's a good structure for a real world application? 
Can you explain more?
The spacing in the title is quite hard on the eyes. I can't be the only one who finds it hard to read that, right?
What I like about go is that it makes you rethink the paradigms learned and see if they really worth for the problem that needs to be solved.
This got me off-side the second it mentioned "utilizing goroutines for increased performance" as a selling point on successful deliveries of projects.
There's no simple answer to that question. The structure of your code should reflect the structure of your application. I'm not ready to say the structure shown is not good for them, but I am ready to say it's unlikely to be good for _you_, and it's certainly not good for me and I wouldn't dream of adopting it. That's writing... I'm not exactly sure what, maybe Ruby on Rails? A particular Java dialect?... in Go, not writing Go. (It's certainly not merely "Ruby", which doesn't require such a strict layout just from the language.)
Yeah, sorry about that. We will make the sidebar smaller or invisible on mobile (or figure out something better to do). Most code reviews don't occur on mobile, but still.
Roslyn should make this much easier. Check out https://github.com/sourcegraph/sourcegraph.com/issues/157 for progress and some more info. We would love to get C# on, but none of us have used C# in a while, and we need someone with recent experience with it. Open source contributions are welcome. For an overview of what adding language support entails, and how you can help contribute, check out https://github.com/sourcegraph/sourcegraph.com/issues/216 (that's for Dart, but same idea). BTW, all of our code analysis toolchains are open source at https://srclib.org.
It's good. Go is object oriented.
Haha, same!
Always look at real world projects for example on github. This structure has in mind only basic stuff, when complexity comes you're done.
That's pretty cool. I'm lazy, though. I've gotten into the habit of using JSON as it's reasonably human readable and it can easily parsed again. See my [jlog package](https://github.com/jackmanlabs/bucket/blob/master/jlog/jsonlogger.go).
It just feels slow. Viewing the network tab while loading, you can even see the slowness. Also, the 2nd article I tried reading: "Currently we are unable to show you this article, but you can view it on the original page." On another article I tried closing out of this popup/overlay, but it's not working: http://i.imgur.com/1i3Dbeo.png I read that you just releases this a few days ago, so congrats on releasing. :)
Here is an example that shows querying an arbitrary number of servers in parallel, accepting the first (fastest) result, canceling all other requests, and returning the first result returned to the caller: http://play.golang.org/p/nXSZ5nuRlq
That's pretty neat and I could find myself using it. Is there a reason why you didn't use text/tabwriter?
Anyone have a handle on the alternatives to gpm? I'm starting to hit a point in my projects where I need something like this. Is godeps something that solves this problem too?
That website has horrible navigation.
yours is a common complaint: https://news.ycombinator.com/item?id=8337115 but there is a tremendous amount of valuable info in those 15 slide decks: http://talks.golang.org/2014/ you can navigate using Left/Right arrow keys, space bar, or click on preceding/following slide. But yeah, you can't tell how many slides are in the deck
I use mattn's gom, because both godep and gpm don't support Windows.
This. It BTFO's all of the academic bloat many other languages suffer from.
gocd! Nice, I'm glad that's mentioned.
"go get always fetches the latest code, even if your build breaks" Also false. "go get" only fetches missing code (including the dependencies), but it never updates the code. "go get -u" does so.
I also made a program inspired by identicons: https://github.com/cupcake/sigil
We use godep at Sourcegraph, and it works well. Haven't tried the alternatives on our own projects (only in open-source projects we work with, like etcd and docker).
/insert jarring chord Homebrew strikes again!
I think many people did :) https://github.com/dgryski/go-identicon 
Yes, less of a method and more of a shorthand for calling a function without needing the first argument (like in C).
Could you please explain "block and finish" ? I am new to Go. What I understand here is that after the select block exits, sometime later the other goroutine will complete, but there is no receiving end of the channel. What happens exactly here ? And buffering the channel just puts the message in the channel without waiting for the message to be received. How does this alleviate the problem ?
You're too kind. :-) I definitely haven't been actively developing Wingo lately, but I've been *using* the shit out of it since it first became a usable WM a couple years ago. So at the very least, Wingo will remain in a working state lest I go back to the dark ages. &gt; (there's some X window bindings at the bottom of course, but you're not gonna escape that, and it's nicely tucked away in the corner.) Wingo is pure Go. I wrote the entire X client stack from the bottom up.
indeed, I think that's the underlying idea.
It's because you're using html/template to produce XML, which are different things. As long as you can trust the data you're giving to the template, text/template should work fine here.
I don't see why it generates these problems though, unless the homebrew formula has just ironed out the bugs over time, but from my experience I've been pretty successful using these commands when installing/uninstalling go brew install go brew remove go EDIT: the only time I can think it might screw up is if you install the brew version, THEN try and install the installer from golang.org or something else. 
For 'html/template' - it's untrust data. [Look at this](http://play.golang.org/p/oUSZ7GfGX2).
thank you!!
That is precisely what happened to the OP. It's not an isolated story, and again makes me wonder what is wrong with the binary installer provided by golang.org that people don't trust it.
You could use encoding/xml instead.
I don't think it's necessarily a matter of not trusting the installer, it works fine and does the job. I think it's more just people, including myself, like brew because it *should*, in theory, give a management mechanism over packages you install on OSX and allow you to roll them back accordingly. This is great for maintenance as you can at least reason (somewhat) about what you've installed on your machine. My OSX installation has been running since 2011 and gone through the upgrade path to Mavericks, but it still carries the scars of kludges and hacks that I've put in over the years and largely forgotten about. For example, installing Java 8 or different versions of Ruby or python on OSX is a pain in the backside and it still is in Java's case (brew can't solve that one!) I'm not saying homebrew is the panacea to all ills, it still suffers from the package management problem that I don't think anyone has fully solved yet, but I do think it's a step in the right direction - you just have monitor and use it appropriately. 
However, you ought to be sure you know what "trusting" the data means. Using text/template to just plop in data to what is XML will break when you should have encoded it properly, at which point the "trust" required goes down significantly (now you just need to trust the content, instead of "trust" that it doesn't contain certain characters). You'd need to use encoding/xml's [EscapeText](http://golang.org/pkg/encoding/xml/#EscapeText) on _all_ textual values you use in the XML. Do not try to guess whether or not it "might" need escaping... it all does. It's best to even send things you think you know will be just numbers through, to get in the right habit. Alternatively, since you're outputting XML, use [encoding/xml](http://golang.org/pkg/encoding/xml/) in general, since it's the right tool for the job. Creating the right types for that wouldn't be hard. (Ironically, a quick Google for whether somebody already had produced as its first result somebody else who also wrote sitemap code that will break by virtue of not properly encoding the output....)
&gt; Alternatively, since you're outputting XML, use encoding/xml in general, since it's the right tool for the job. Creating the right types for that wouldn't be hard. I think that seems to be the most elegant solution, will rewrite my code to do that. 
Even GitHub's identicons are (now) generated in Go!
These are hard to answer really. But a starting place is this list: https://code.google.com/p/go-wiki/wiki/GoUsers It provides a relatively maintained overview of companies who have publicly disclosed their use of Go. I suggest you go through it and draw your own conclusions about future marketability :) 
1. Many big companies are currently using Go to solve scaling issues (Medium, Dropbox, GitHub, Disqus, Tumblr, etc. https://code.google.com/p/go-wiki/wiki/GoUsers). 2. Hard to say. Right now Go is trendy but who knows if it's going to be a Ruby and last or a Node.js and fall out of favor quickly. I'm sure there are people in both camps.
Marketability aside, learning many languages is something every engineer should do IMO. I write high throughput, low-latency backends Java for a living, but I've made time to learn clojure, scala, and most recently go. If you don't end up using the language in anger (read: production) it will at the very least inform how you design and approach problems in your 'main' language. For me personally, go is replacing Java as my language of choice for command-line utilities as sort of a trial run. If I like what I see, I may push for more production-critical services written in go. Hope that helps.
We just started using Go at Fog Creek on Kiln. It never occurred to me that I'm affecting my career path. I guess I'm probably not interested in working somewhere that would count this against me.
What @avrtno says. :) Looks like there are also DO-specific notes here: [https://www.digitalocean.com/company/blog/get-your-development-team-started-with-go/](https://www.digitalocean.com/company/blog/get-your-development-team-started-with-go/) 
Just wanted to add if you want this application to be available on port 80 you can: - reverse proxy to it with something like nginx - use iptables to redirect port 80 to 3000
Simpler solution than avrtno: hop on your server, clone the repo, and type "go run main.go &amp;". (to later kill it, do a ps aux | grep main and kill the pid of everything you see) But...simpler is not always better. /shrug Your call.
For pedantry's sake, this isn't true if you depend on the net package, unless you built the standard library in a certain way. But the C library dependency in this case is generally reliably present.
Why is that?
"Go run" is great when debugging code, but it's a lot slower than compiling. I wouldn't recommend this option. 
Do you have a source for that? Just curios how you know.
You are doing it wrong. One does not learn a language to speculate of future dmenad, but rather because that language solves your current problems well. So if you currently work on a problem that Go solves better than Java, you may want to use it. Otherwise you're probably just wasting time. On the current projects that I'm involved in, Go is only about 5% of the codebase. Best tool for the job &gt; hipsterisms/personal preferences.
IIRC net uses libc functions like gethostbyaddr to use the native DNS cache and libc provides access to the system's SSL trust stores. Cross compiling will use pure-Go/syscalls and avoid the libc dependency: https://inconshreveable.com/04-30-2014/cross-compiling-golang-programs-with-native-libraries/
It's for DNS lookups. I think it had something to do with matching the C resolver, and a comment in dnsclient_unix.go corroborates my memory.
Then you're also leading to a potentially bad situation with dependencies. your app depends on usefulpkgv1, A, and B. A depends on usefulpkgv1.0 B depends on usefulpkgv1.0.0 You go get all of your dependencies.. what versions of usefulpkg are going to be downloaded and included in your binaries?
Post it like you would any other job offers on the related websites then link to it?
No, because "best tool for the job" depends on popularity. People would consider Java to be a much worse tool if it was a fringe language with a tiny ecosystem, for example.
Divide code in to layers - web frontend - http api - data store. Check out the source code here: https://github.com/sourcegraph/thesrc/ You can enable closed captions on youtube.
God save the internet!
thank you! already did. 
Is it ok to post it here?
i don't see why not, as long as people aren't spamming stuff everywhere (imo)
I would honestly prefer not. I don't know if there are rules or not.
No, this will lead to spam.
this breaks my condition for it being okay then and won't be allowed
Are you using a compatible GDB version?
I invoke Poe's law.
Thanks! 10/10 above expectations. 
Why not post them here. It would be relevant. 
"GDB does not understand Go programs well." Check this [link] (https://golang.org/doc/gdb). Essentially, native debugging should still be possible. For anything specific to Go, you're SOL.
No it isn't
try comp.lang.go.jobs
I think it is fine as long as you give details about the company, the role, and the remuneration. "Work for super l33t stealth web 3.0 startup, ninja bros only" is not appropriate. 
I was just saying that in the sense because those official websites reach a much larger audience. 
Thanks for the support! Will do :)
Thanks! got it :)
There is also go-debug for basic debugging (shameless plug).
Did you read the post? It has several features that gpm doesn't (afaik).
Honestly, it's such a simple language that any decent developer can be a decent Go developer in a couple weeks. Hire wherever you can get good developers.
For one, GPM doesn't manage workspaces.
I love Go and have since 2011, but it needs an official package manager BADLY. There are **so many** different tools to manage packages, with every project using a different tool, it is one of Go's biggest problems and the Go devs don't seem to care.
From the readme on github: "Through some trickery, the GOPATH is set to..." Isn't using multiple GOPATHs something that is frowned upon by many in the Go commnunity? (Even when putting aside for the moment that some kind of trickery appears to be involved that the readme does not describe closer.) 
TL;DR for OP: b 'main.main' r &gt; "GDB does not understand Go programs well." What is your own experience debugging Go programs with gdb? And what do you mean with "native"? I'm sorry, but I see words and they carry no meaning. Example of GDB session on an HTTP HandlerFunc (in $GOPATH/src/reddit-example): $ cat re.go package main import ( "log" "net/http" ) func PongWriter(w http.ResponseWriter, r *http.Request) { w.Write([]byte("pong\n")) } func main() { http.HandleFunc("/", PongWriter) log.Fatal(http.ListenAndServe(":8080", nil)) } $ go build $ gdb -q ./reddit-example (gdb) b main.main Breakpoint 1 at 0x400c70: file $GOPATH/src/reddit-example/re.go, line 13. (gdb) r Starting program: $GOPATH/src/reddit-example/reddit-example [New LWP 100604] [New Thread 801406400 (LWP 100604/reddit-example)] [Switching to Thread 801406400 (LWP 100604/reddit-example)] Breakpoint 1, main.main () at $GOPATH/src/reddit-example/re.go:13 13 func main() { (gdb) n main.main () at $GOPATH/src/reddit-example/re.go:14 14 http.HandleFunc("/", PongWriter) (gdb) n 15 log.Fatal(http.ListenAndServe(":8080", nil)) (gdb) b main.PongWriter Breakpoint 2 at 0x400c00: file $GOPATH/src/reddit-example/re.go, line 8. (gdb) c Continuing. And here I visit http://[::1]:8080/ with my browser: Breakpoint 2, main.PongWriter (w=Unhandled dwarf expression opcode 0x9c) at $GOPATH/src/reddit-example/re.go:8 8 func PongWriter(w http.ResponseWriter, r *http.Request) { (gdb) n main.PongWriter (w=Unhandled dwarf expression opcode 0x9c) at $GOPATH/src/reddit-example/re.go:9 9 w.Write([]byte("pong\n")) (gdb) n 11 } (gdb) c Continuing. My gdb -v is: GNU gdb 6.1.1 [FreeBSD] (which should explain the "Unhandled dwarf expression" I'm getting) Now there are problems with using gdb, but anyone who have ever debugged a Go program can see that the OP simply does not put a breakpoint on 'main.main' (with namespace) and ends up in the runtime instead. It's a common mistake and the docs are not very clear about how to use gdb, but it's not difficult to find out how to do it. It's really easy. So next time you want to give advice, make sure you know what you're talking about so you don't spread this "GDB doesn't work well with Go"-stuff around. There are problems, yes, but that quote was out of context and most of the time using gdb with Go applications is no problem at all.
Looks like you're dereferencing twice. s := &amp;Estados{}... fmt.Scan(&amp;s...) ...creates a pointer to an Estados with "&amp;", and then takes the address of *that* in the Scan statement. Lose one of the '&amp;'s and you'll be fine. As Dave says, you'll probably find that Scan was complaining about "s" being a pointer to a pointer.
Until Generics is implemented, Go will remain a minor player, whether that's a bad thing or not is arguable.
I think the bottom line is that if your tool-of-choice writes stuff to ./src, you can wind up in a situation where your project is more or less blended with its dependencies. Granted, tools like git can usually sort this out. By dumping things in ./_vendor, there's less room for confusion, only now you need to add to GOPATH appropriately. Honestly, I've never run into such an issue, but I can see how some folks might not like putting everything in ./src.
Even if it's frowned upon it doesn't mean that it's wrong, GOPATH is an env variable which means it was meant to be something people could change. I haven't seen how glide does it so can't comment on the "trickery", however I do use this approach (with gvp, which inspires parts of glide so maybe they do it similarly) and find it to be by far better than sharing a single GOPATH for different projects.
So is it entirely end-to-end tests then? Is there a good story for unit testing individual components, or is mocking/etc. just not worth it? I have found I can do a tolerable job starting up my server as a test init step and launching it all together, but it is not as instant as I would like it to be. Still pretty fast though.
One of Go's big problems is that unless Google takes any official stance on this it is very difficult any of these tools will ever be the de facto one. The problem is not only package management for Go, what worries me is that this is just one of the places where it becomes evident that having all decisions about Go's future centralised in Google is hurtful to the language and the community. Can't think of a way around it so far. EDIT: Go devs apathy bothers me a lot too, I had a chance to talk to one of them at a conference last year and when asked "what *don't* you like about Go?" he proceeded to point out things that other people didn't like and how they were wrong. Not being able to have criticism over your own language is a bad thing, there are always things to improve. 
That looks like an issue, but it wasn't stopping the program from running, my problem is to make a code that will scan several Estado struct (like in C), is that possible in Go?
How can I check the error value? I can't seem to find in the documentation how to see it
Try it on iPhone. Calling it an awful experience would be a compliment. It is beyond frustrating.
I would recommend opening a support ticket on the gopy github page. https://github.com/qur/gopy/issues
&gt; The glide in command will configure the environment variables like GOPATH and PATH Nooope. Any tool I use better not screw with my GOPATH or PATH. If that's a requirement, it's a non-starter. GOPATH=$HOME or GTFO
Interesting **Ruby/Sinatra** project. Not sure what this has to do with Go other than it has to do with code.
Go is supported, i believe, but that's probably about it. Quite the general project it appears
Go is one of the supported languages. I found it helpful to practice and refine my Go code with this site and thought I'd post it here for people to try out.
the CLI client used is built using Go: http://cli.exercism.io/
Been trying to set it up for a while now. You have to download so many 3rd party tools...
This is the process I use: * Pull from version control * Build and copy to directories where application is ran * Setup binary to be controlled with supervisor * Set up vhost with nginx to listen to the fastcgi process I've used this method, and it works pretty well. One thing I do use that is great is [toml](https://github.com/BurntSushi/toml) for my config files
Really? All I had to do was get the cli which you can get multiple ways. I think I used curl to download the install script, but that wasn't really necessary since you can just clone it off github. What tools did you need to download?
The cli, go, brew, cmake, and like one other thing. And I still can't get it working.
My web framework of choice is still mostly Djano right now. I've liked BeeGo best of the various stuff I've tried so far.
It really depends on your requirements and what you're comfortable with. Even with my .NET background I've stayed away from Martini after using it a little bit and now prefer to write web apps with just the standard library. I use Gorilla for sessions and cookies.. but other than that, StdLib. Its your call ultimately though. Weigh up features vs your competency vs how "idiomatic" you want to be.. and go from there.
net/http is enough, along with the multiplexer of your choice if you want!
After spending a lot of time reviewing the options, I've settled on Beego. I suspect that there more functioning Golang websites based on Beego than any of the alternatives.** Another 'full service" framework I looked at was Revel which has it's own ideas about how to do things. The main complaint is that it is not very "Go like"... i.e. strays a lot from idiomatic Go. Martini has a good following, but its creator has moved into the minimalist camp as explained here. http://blog.codegangsta.io/blog/2014/05/19/my-thoughts-on-martini/ If you are first rate Go hacker, you too will likely be happier as a minimalist. The "tool set" Gorilla tools seems to be favored by the minimalist crowd. For someone who is fairly new to Go and is primarily interested in building web sites, Beego has a lot to offer. On the downside, "how to" documentation is scattered. IMO, the best source for English speakers is here... https://github.com/Unknwon/build-web-application-with-golang_EN/blob/master/eBook/preface.md ... Translation quality varies, but is generally good. Tip: affair = transaction. :) Because Beego IS a full service framework, there is a lot to learn. Don't even start until you have a good working knowledge of Go itself. My reference example of Go as it was intended to be used is ... https://github.com/golang/groupcache/blob/master/groupcache.go Beego occasionally strays in this regard. For example it insists on using "this" to represent receiver functions, which can be confusing if you come from a world where "this" has a specific meaning. The "Go way" is to use a short identifier based on the name of the receiver. ** The vast majority of functioning sites based on Beego are in China. 
I've heard some good things about revel/gorm.
or change the port to 80 and run it as sudo... Anyway, what I do is just nohup my go server and run an nginx proxy to it, so I can direct a particular "named" domain to it [it listens on a different port, like 3000 like yours does]. FWIW mine is just a toy project.
I can share my experience cause i was searching with same question not so long ago. First of all i decided not to use revel and beego, just because i don't like big frameworks with batteries (i'm python developer and i hate django, yes) and prefer to choose all required tools by myself. Martini is very popular nowadays, but it has sort of slow router and i don't like its approach with context handling. So, after surfing a net for a while i decided to stick with Goji - one of the fastest routers on the block and pretty neat way to handle context. But, after i started actually developing my service and going deep in golang internals i understood that i just don't need it. Really, golang is so sophisticated and elegant that You can develop almost everything just using standard libraries.
totally agree.
yeah, I have just done a simple site, where I only used https://github.com/ant0ine/go-urlrouter for making easy routes. I tried to play with the idea of making a MVC layout, but I didn't bother since it was mainly a site for tinkering with the frontend (Angular.JS).
Beego is only reliable option.
Not sure if serious
 b 'main.main' actually helped.. I guess I should have read more documentation. I will test the rest of these suggestions later, as well as the GDB version (actually using cgdb - less painful) Thanks all!
I use Negroni (https://github.com/codegangsta/negroni) from the creator of Martini. The description from the author is: "Negroni is an idiomatic approach to web middleware in Go. It is tiny, non-intrusive, and encourages use of net/http Handlers. If you like the idea of Martini, but you think it contains too much magic, then Negroni is a great fit."
It depends what you want to do with it. If it's simple CRUD, then Beego and Revel get you up and running quickly. Of course the more complicated the project the more friction from a large pre-built framework.
So, the whole point of vendoring only makes sense if .. what exactly?
Thank you for your helpful replies, @ericanderton and @poteland. I start to understand why people would want to use multiple GOPATHs. 
I think both libraries serve a different demand. The libclamav version is ideal for embedding clamav within your own product (cannot be closed source though). The clamd library is perfect if you just want to communicate with running Clamd software. The pyclamav guys are recommending pyclamd though. * http://xael.org/norman/python/pyclamav/CHANGELOG * http://stackoverflow.com/questions/4481289/clamav-and-python
Exactly. net/http is enough. If you want a great multiplexer, you should see https://github.com/julienschmidt/httprouter. It has the best performance in this moment for this purpose.
Huge achievement by Go Team!
wow, thanks :)
that doesn't seem very apropos.
For those of us coming from a higher level language and don't know much about CS or GC...what does this mean for the language? I assume when they say "conservative" the GC has been leaving garbage around just incase something really is relying on it. So it'll have a lower memory footprint but longer stop-the-world time?
Loosely, conservative GCs look at the bytes contained within something to see if it's a pointer. Precise GCs only scan the things which are actually pointers. Conservative GCs are simpler to code, which is why Go started with one. I would imagine the relative stop-the-world time depends on the actual implementations, but in Go's case the stop the world time has been getting lower with each release.
Awesome, thanks! I was thinking "conservative" as an adjective, not a particular type of GC so I was way off base with what I thought this was saying...glad I asked, and thanks for taking the time to answer :)
I'd recommend [flotilla](https://github.com/thrisp/flotilla), but I'm a bit biased for it being one of my current projects.
Pretty fairly researched writeup. If you're the author, thx for skipping the usual #include generics and exceptions diatribe ----------- The upcoming Manning and Oreilly books "in action" and "up/running" should address his/her doc complaints to a large extent http://shop.oreilly.com/product/0636920030638.do http://manning.com/ketelsen ---------
Interesting, do you have an example app?
https://github.com/thrisp/flotilla_skeleton will be an example for extending, and there will be more at https://thrisp.github.io/flotilla/ eventually, but I haven't gotten to the point of being able to use it yet, so there isn't much. Everything is sort of in a basic, barely useable if at all, state.
You may find [this useful.](https://www.youtube.com/watch?v=7IE0fzbuEdQ) I've also found the process frustrating. The program and all the third party tools the website points to seem designed for people who already know programming, not for people who don't even know what a repository is. I get that a lot of programming is having to figure out how to make your tools do what you want, but I don't see the point in doing nothing to streamline the process...with a program that is *supposedly* designed to help you learn programming.
"640k ought to be enough for anyone." (c)
A nice alternative to Martini is [gocraft/web](https://github.com/gocraft/web): - Your own contexts. Easily pass information between your middleware and handler with strong static typing. - type Context struct { HelloCount int } func (c *Context) SetHelloCount(rw web.ResponseWriter, req *web.Request, next web.NextMiddlewareFunc) { c.HelloCount = 3 next(rw, req) } func (c *Context) SayHello(rw web.ResponseWriter, req *web.Request) { fmt.Fprint(rw, strings.Repeat("Hello ", c.HelloCount), "World!") } func main() { router := web.New(Context{}). // Create your router Middleware(web.LoggerMiddleware). // Use some included middleware Middleware(web.ShowErrorsMiddleware). // ... Middleware((*Context).SetHelloCount). // Your own middleware! Get("/", (*Context).SayHello) // Add a route http.ListenAndServe("localhost:3000", router) // Start the server! } 
I've made, and continue to make, many complex Rails apps. That just isn't what fits Go.
&gt; Another interesting lesson emerging from our performance measurements is how Go achieves respectable running times as well as excellent results in memory usage, thereby distinguishing itself from the pack just as C does. It is no coincidence that Go’s developers include prominent figures—Ken Thompson, most notably—who were also primarily involved in the development of C. The good performance of Go is a result of a careful selection of features that differentiates it from most other language designs (which tend to be more feature-prodigal): while it offers automatic memory management and some dynamic typing, it deliberately omits genericity and inheritance, and offers only a limited support for exceptions. In our study, we have seen that this trade-off achieves not only good performance but also a compiler that is quite effective at finding errors at compile time rather than leaving them to leak into runtime failures. Besides being appealing for certain kinds of software development (Go’s concurrency mechanisms, which we didn’t consider in this study, may be another feature to consider), Go also shows to language designers that there still is uncharted territory in the programming language landscape, and innovative solutions could be discovered that are germane to requirements in certain special domains.
Which is really no different from go.net/context or gorilla/context - unless you create structs per-request you can't avoid some level of type assertion if you want flexibility (read: the ability to use third-party middleware and not re-invent the wheel).
Hi guys, Had fun hacking with you at GopherCon. Glad to see that you're still building cool stuff. So, my question: how does the Edison compare to the BeagleBone Black? 
We use Ember + Yeoman
We recently moved our whole dev team from PHP to Go and are finding Martini to be the most comfortable to our developers having had worked primarily in Laravel. 
I use bower. Whatever project I'm working in, be it java, ruby, python, golang, node, .. etc. I heard [component](https://github.com/componentjs/component) is gaining popularity tho, not sure if I can benefit if I switch
rsc wrote on the issue: &gt; There is one other piece that I am not counting: if you use SWIG to allocate Go memory from C++, that Go memory is scanned conservatively. That's a different problem ([issue 6461](https://code.google.com/p/go/issues/detail?id=6461)) and not a concern for most Go programmers (since most don't use SWIG).
I use bower for for the actual libraries and gulp to build them into one file. See my revel experiment how I did it: https://github.com/tamasd/gowalkhub
I don't feel reflection is any better than type assertions here. Martini and its DI are the cause of a lot of confusion, and also what (I believe) make Martini so obtuse at times.
Bower/gulp. For production, nginx to serve the static content (or proxy for S3) and reverse proxy to the Go app.
Inside the loop, a new struct is created, scanned into, and then added to the array each time. So, to print them all out again after you're done... for _, e := range EstadoCollection { fmt.Println(e) } Simple as that. Edit: Here you go - http://play.golang.org/p/qTFkLgUAsG
As everyone has made clear, you might not need a framework. That being said, I use Goji in production for a very popular iPhone app, handling a huge amount of requests per day. I like how it adds a bit of structure and Einhorn support is very nice. It never feels invasive or "too magical". There isn't much Goji does that you can't do yourself with the standard library and a bit of elbow grease, but I'd rather just use what works instead of reinventing everything myself. I don't remember why I picked Goji over Gin, maybe it was Einhorn support, or how middleware works. I would like to check out Gin again sometime though, it looks very nice. Huge monolithic frameworks like Beego and Revel aren't my style, but I see no problem in using a compact micro-framework like Goji or Gin. See what works for you.
Yes, go is ahead of c and java here. Additionally go doesn't force every object to be heap allocated, so there's generally fewer pointers. Personally I just pretend null doesn't exist - if you find a null where one wasn't expected all you can do is throw/panic anyway - so might as well NPE... With the exception of ensuring nulls aren't left lurking in data structures to be found much later when it would be harder to track down the cause. 
I've played around with the lightweight frameworks, and found gorilla/mux to be the best in terms of flexibility. Some others e.g. goji may be faster but not to the point where it would make much of a difference (bottleneck usually is in the application code, data store etc). I've not really done much with beego or revel, but I think if I need a traditional "big" CRUD app I wouldn't use Go anyway at this point, python/django or ruby/rails (or one of the Java or PHP frameworks) having more out of the box functionality for that sort of thing. In that case I'd use Go for some backend stuff or websockets for example.
Agreed. See github.com/jadekler/git-go-websiteskeleton for a small net/http + mux example
net/http. See github.com/jadekler/git-go-websiteskeleton for a small net/http + mux example
We use interfaces to mock our code too. It works well. We have much simpler mocks, though - our db would only have things like QueryWasCalled on it, and RespondToQueryWith(), a la rspec. Also, check out github.com/onsi/ginkgo for bdd goodness. :)
When would you cast from `interface{}`? Honest question, because I've never found a use-case.
When handling json input that has inconsistent structure, you're pretty much stuck with using `map[string]interface{}`.
Hey everyone, first time posting here. I put together a quick post on using net/rpc - looking forward to the feedback. 
That's a terrible way to show the graph. Go's in there somewhere, I think.
I migrated from net/http to Gorilla toolkit, to Goji, to Gin in the search of a well-rounded, fast framework that allows me to stay DRY. What did you miss in Gin that prompted you to create your own framework? Have you considered replacing httprouter with something else (like Denco, for instance)? I am personally missing named, reversible routes and, to a certain degree, multiple ordered matching routes (primarily to cover for legacy URLs declaratively). The latter is optional and can be achieved with middleware or a proxy layer.
[golang intensifies]
I've been working on a [language ranking site](http://langtrend.com/l/Go?period=quarter) for a while now (that example is using a percentage of all repos created for Go). Data goes back to 2008 which is when GitHub was publicly launched. [Compared to a few other niche compiled languages](http://langtrend.com/l/Go,Swift,Rust,Haskell?period=quarter) [Go is currently ranked 13th, top rank was 12th](http://langtrend.com/l/Go?period=quarter&amp;metric=rank) App (web and workers) running Go (with some Gorilla) and RethinkDB (dancannon's awesome [gorethink](https://github.com/dancannon/gorethink))
MOO see also: http://www.milk.com/faq/
Go seems to be popular here on reddit as well based upon this summary: https://github.com/steaz/reddilytics
I looked over Gin and I'd reached a point of understanding Go where I understood what needed to be done to do some things I've wanted to do, so started with it as a base. Yeah, I think about replacing httprouter, but I've gotten to know it and how it functions. What will be done is making the router in [Engine](https://github.com/thrisp/engine) swappable so so that you can choose a router implementation for the engine, so long as it satisfies a suitable interface. I'm unsure about how flexible that needs to be now and what exactly needs done, but it is planned. 
Very good point. At the time I didn't see the githut link and thought one would have to download and build the app. My bad. I'll updated the link.
Jcdyer3, my fault. I linked to a static image rather than the interactive site. The link has been updated.
Decoding XML documents conforming to an XML Schema with a [choice element](http://www.w3schools.com/schema/el_choice.asp) to a struct.
Question 2: You could define this method on the Position struct: const invalid Position = ^uint32(0) func (p Position) IsInBounds() bool { return p != invalid } So when GetAdjacent returns, it sometimes returns invalid positions as the left or right parameter. It's up to the caller to make sure the returned positions are valid.
Wow, I so don't agree with that. If what you were saying were true, APL would be the worlds most popular language. 
nice.
Don't do that. There's no reason to make a magic invalid value. Go has nullable integers, too. They're called pointers. *int can be a valid integer, or nil. 
Just... no. Is the extra $ cost for heroku entirely the overhead of having a real hypervisor and VM you say? No?! Well that's odd. Is Heroku expensive for the raw computing power? Yes. That's because they manage installation of the stack, and such a tight knit deployment process, and database management for you. If you have the skills, and time to build a shittier PaaS or other such deployment stack yourself - or self-host an open source one, then yes. you can pay less for hardware and more for time spent maintaining it, being responsible for uptime, and upgrades yourself. This is the value trade-off.
I don't follow how that's true unless I assume readability is the major factor for popularity. How would you define readability then?
Yeah. OP, what is a Move? How are these types actually being used by your library? These are important details when designing interfaces.
Yeah exactly. Readability also can't be fully demonstrated with such a simple example (although it can be illustrative.) I care more about how readable code is when the code is more complicated - I have a feeling that Go's readability scales more flatly than Ruby's as inherent complexity increases.
At what memory cost?
Honestly, I think you're trying to make it too generic. Do you really need generic states and moves and all that? Making things overly generic is a problem many people have when coming from java or C# and similar languages. The only thing that chess and checkers really share is the notion of an 8x8 board with pieces on it that can't move off the board and the fact that they're 2 person games where people take turns. So really, the only thing you might need to share is a function to validate that a piece is not being moved off the board.... and that's so simple (valid := x &gt;= 0 &amp;&amp; x &lt; 8 &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; 8) it's probably not even worth sharing that.
I'm torn, I want to downvote because of the obvious clickbait, but docker itself seems cool. Ahh, the reddit conundrum. 
There's always a tradeoff. I first learned C in '79, and C++ around '88. Like everybody else, I wrote *crap* C++ until the early 2000s; it took that long for the language and our collective understanding of how to use it to get to the point where reasonably performant code was reasonably maintainable. When I look at Go, all my memories of C++ (and Java, and PL/I) come rushing back with a great thunderous *"Why TF would you __do__ that to yourself?!?"* C++ took 20+ years for the industry to learn well. Java is taking *much* longer. Ruby took a bit less than C++, with Rails as the moral equivalent of MFC. If we're writing Go code in 2024 that's as good as the C++ code we wrote 10 years ago or the Ruby code people are writing now, then IMO the Go community will have a *ginormous* achievement and bragging rights therefor. By then, we'll know the tradeoffs well enough to make reasonable decisions around them, as we do for C++ today and are coming to grips with in Ruby. (Java? That'd be for our grandkids to figure out in the [Computer History Museum](http://www.computerhistory.org/).) **tl;dr** Premature optimisation is the root of all software evil. Replacing a language wholesale based on edge-case performance issues *will* bite your most sensitive nether regions when it is most technically and politically inconvenient. History speaks loudly, eloquently and consistently to that. Beware.
We are! (two of us from Idaho)
newbie at it, but i'm gulp-ing like a boss. use gulp pipelines to crunch app js files to a.js, vendor stuff to v.js (mainly angular, but other bobs and bits), sass to s.css. some people use bower to grab dependencies, but i prefer to hand curate dependency versioning, at least for now. currently have an injector set up in the gulp pipeline and will at some point use fingerprinting - ie generating names like a-a4e561.js and tossing them into the html at injection points. done so updates aren't inadvertently obscured by caching. aka "cache-busting". may drop it if it's not really useful. everything gets copied over to an interstitial output directory and from there bundled for deploy. this is roughly similar to how most people do it, afaik, and it's going to be loosely similar regardless of your backend choice.
I'd disagree - given a real-world piece of code, someone unfamiliar with coding probably wouldn't be able to figure it out easily just by reading even in highly readable languages. For example, [this](http://sandbox.mc.edu/~bennet/ruby/code/box_rb.html). To someone familiar with Ruby it's probably stupid obvious, and someone familiar with coding it should be pretty easy, but to my mom... never.
Two of us from Prevoty will be there. Looking forward to meeting other Gophers.
i just mean that the things that make some code "kinda sorta understandable" to an interested layperson, are generally also in the set of things that make code understandable to developers. for one example, relaying the intent of code through identifier naming conventions and preferring expressiveness over concision. for example, if you see a sequence of words like 'get' 'website' 'scrape' 'content' 'save' 'database' amidst language noise, it's plausible that one could at least guess what's going on, even if the underlying machinations are otherwise inscrutable.
You're right: Go's precise GC is very tightly tied to the runtime so re-using it as-is in another project is not feasible. It's going to be true for any precise GC - they all require support from compiler and runtime to provide information about each type so that GC knows if a given value is a pointer (which needs to be followed by GC) or a value. Conservative GCs have the advantage of not needing this information, which is why it's somewhat easy to re-use them in different apps. You might also take a look at http://piumarta.com/software/gsgc/index.shtml for an alternative to Boehm GC (it's also conservative). 
Taking an, admittedly small, look at the gsgc landing page I am wondering what advantages it would have over the boehm gc.
Does this make sense if its not required to export the mutex?
I just want to say thanks for doing a tutorial on something that isn't "make-a-webserver-101." Not bashing on those posts at all of course, they are great right at the beginning, but there's a real dip in resources between pure beginner and super advanced. So thanks for doing a beginner accessible article that isn't crazy reductive or redundant.
Guessing what's going on is fine if you don't have modify it, find a bug in it or use it to make other guesses about a larger system. Buggy code that is supposed to fetch a website is very likely to look a lot like code that is supposed to fetch a website.
Great news. I love InfluxDB. It has great promise and immense necessity in a market which has saturated with the overuse of Graphite. We need something fresh and future ready.
Use [godep](http://godoc.org/github.com/tools/godep) to vendor a copy of the packages you depend on. 
If anyone is wondering what the answer is, he chose Go because it was made by Google, beyond that he seems to have little of any novelty to say. Further it seems to be wrong on the issue of the development, implying that Google organized the team of people and requested them to make the language. That conclusion isn't even supported by the Wikipedia article he links to. 
Is there a way to vendor dependencies with godep, without making my package incompatible with go tool?
Doesn't appear to be. 
There no great solutions out there, unfortunately. Check out [godep](https://github.com/tools/godep) and [gpm](https://github.com/pote/gpm) for two (imperfect) solutions.
I know this is terrible, but I'm just renaming the .git and .hg directories to .git.disabled and .hg.disabled and committing them to git. I don't want to deal with subrepositories. When I'm ready to update the dependencies, I rename them back first. This is just how I'm punting until I figure out a better way. 
https://www.ravenbrook.com/project/mps/ is another alternative that might work.
What would you recommend instead?
Would depman help out? We use that with some success. Or Glide looks promising but I haven't tried it yet. 
No, json document is loosely typed by design.
- gofmt -- it is plain rude to have stuff NOT run through gofmt -- it is a huge Go community value. (goimports will make your editing experience better). - make -- nothing is wrong with make, but a lot of people love Go because it avoids makefile hell, all you need is go get foo/... and good to go. If you have more complex shipping needs (which you do) considering building a docker. Setup can be baked into your app -- or done with go run setup.go or some other way that doesn't depend on a non-go 3rd party tool. - don't ever use relative paths (./) for imports (it might be removed in a future Go version) -- use full paths. This makes code more portable, and able to be automatically refactored. https://code.google.com/p/go/issues/detail?id=6147 - consider if you actually want globals, it makes injecting test mocking MUCH harder. - don't hardcode the config location, remember Go compiles to static (easily movable) binaries, assuming it will be run from your project directory is silly -- configs should be passed in with flags. Additionally, don't try to use your binaries location to find the config either, that is just another anti-pattern. - understand the go get process (and go install) and leverage them. - not sure you want to blindly restart the process via that runner. - you probably actually DO care when the ListenAndServe fails (check all errors is a good policy, check out errcheck) I am sure there are more, but trying to read code not run through gofmt hurts my head. 
I like to encourage things I depend on to use http://gopkg.in and support backward compatible major versions. When that fails, godep (or home rolled).
For a simple, maintainable wiki the file system makes a great document store. Just look into access patterns and do as much as possible asyncronously. You should be able to write a special-case store that outperforms mongo by far.
Java programmer meets Go.
Now if only I could get the v1 package to build correctly. 
&gt; I can't possibly image cloning a repository for every single dependency in every single project. Unfortunately, that is the **only** way to ensure that the build doesn't break. As others have mentioned, there are tools that help you do this.
This is a big problem and makes debugging with gdb almost unusable with go 1.3. Please click on the link and add star. Maybe that will help to push for a fix.
Anything in particular wrong with graphite? 
Different method, same conclusion. That's a good thing. :)
&gt;configs should be passed in with flags or environment variables.
 I don't understand all the hate on vendoring dependencies. People try to use it as a reason why golang was developed by a bunch of degenerate hill-billies in a back alley somewhere. Everybody else does it. Why does it confuse so many go noobies. It isn't a foreign concept. Disk space is cheap. Plus, having a copy locally gives you an opportunity to look at the code and poach ideas or make improvements. Color me confused Some examples: PHP: composer, PEAR Python: pip, virtualenv javascript: just copy it into filesystem, bower c/c++ shared libs, dll, etc Ruby: gems or bundle* /rant * I've never actually done ruby, this is just a cursory internet search. http://errtheblog.com/posts/50-vendor-everything http://ryan.mcgeary.org/2011/02/09/vendor-everything-still-applies/
Not really. But it really doesn't scale very well. When you have a lot of metrics that you have to move to 2 graphite servers, its a pain to set up carbon relay to 2 servers. Also, the python implementation is a bit slower. There is an alternate c implementation which is a lot faster. That is why I was saying, graphite is good but only to a certain limit.
I tried this shortly after it was first released and although I felt it had a lot of potential, it left much to be desired in its then-current state. You've reminded me about it and it looks like it's had a steady stream of commits to it since I last played with it, so I think I'm going to toy around with it again and see if it's to a point where it can be used for more than just an experiment.
I'm using it for UAC elevation (with `ShellExecute()`). It works flawless and way easier than Go's own `syscall` functions.
Yeah, I don't like the challenge of finding out the running environmental variables, but it is a very common alternative. 
A few issues, the first conceptual, and the rest annoyingly practical: 1. In general, the way public-key crypto algorithms work is not to generate public keys from private keys. Instead, they generate a pair of (public key, private key) from random data. To make a program that can both decrypt and encrypt with a keypair, you give it both keys; to make a program that can only encrypt, you give it only the public key. (s/decrypt/sign and s/encrypt/verify when using keys for signatures). 2. The crypto/elliptic package doesn't implement a complete elliptic-curve, but rather the basic primitives required to implement elliptic-curve encryption using a specific interface to curves. 3. Go's builtin crypto libraries do not implement encryption based on elliptic curves, just signature algorithms (ecdsa, as you pointed out). 4. I can't find a standardized cryptoscheme using elliptic-curve cryptography that implements only encryption. The two I'm seeing that do encryption both also include signatures, and are built for key exchange between two parties with different keypairs. (ECIES, which AFAICT has no golang implementation, and [go.crypto/nacl/box](https://godoc.org/code.google.com/p/go.crypto/nacl/box)). This leads to a further conceptual issue - why are you using asymmetric cryptography for file encryption? Are there two parties involved who need to share a key material?
This is the first I've seen of 'go generate', and I'm already intrigued by the possibilities. This could be a really big deal for the third-party tools that simulate having generics, making them much closer in ergonomics to first-class support. In fact, that may have been a big part of the motivation for 'go generate' in the first place. It feels a bit whiny to pine for go1.4 so soon after the go1.3 release, but darn it, there's some exciting stuff down the pipeline.
Nope, I didn't intend for it to be a joke. The article is about the factory design pattern in Go, the reason why I use the term "Class factory" is to show that the way Go does the factory pattern isn't very much different than how a Java or a C# programmer would think about it. I explain the concepts of interfaces and structs in Go in order to cover the difference in implementation between Go and Java or C#
Been looking for a simple graph database with a permissive license. Everything else seems like its some java behemoth that costs thousands of dollars to use commercially, is mind numbingly difficult to deploy, or has no language agnostic interface. Cayley looks pretty promising.
Your understanding of what you're doing is insufficient to do it in a secure manner. The system you describe is insecure where it even makes sense. If you're just trying to do this as a learning exercise, you need to find some better source material because you're trying to learn to drive by crashing into a concrete wall. If you're intending to actually use it for security, know that you're very likely to end up with something trivial to break.
We use graphite very heavily at Booking.com . We have ~90 machines storing whisper files on SSD (~55TB, IIRC), and a number of the front-ends. We've re-implemented much of the stack, much of it in Go. We wrote https://github.com/grobian/carbon-c-relay to to help route ~30 million metrics per minute into our cluster, which are served from the storage by https://github.com/grobian/carbonserver . We use https://github.com/dgryski/carbonzipper which acts as a proxy for graphite-web, handling all the concurrents requests, and have just deployed a re-implementation of the JSON API layer ( https://github.com/dgryski/carbonapi ) that is now handling many of our internal requests that don't need rendered graphs, but only the data. We've probably pushed graphite well beyond its limit :)
I actually strongly disagree with your first issue: Virtually all algorithms, generating a public/private keypair work by generating the private key and deriving the public key from it. As a matter of fact, if you know the private key, it is assumed that you know the public key, since it is computationally cheap to generate public key from private key. And to top that off, in many cases the public key is not even generated, unless explicitly specified, e.g. OpenSSL's treatment of RSA - it generates a private key from which you then generate the public key. Finally, in many cases there is no way to only create just the public key, since its construction depends on the private (and the very idea of Public-key crypto is that private-&gt;public key algorithms exist, while the inverse is computationally unfeasible). Again, in RSA you generate two big primes, which you then multiply for the public key (the public exponent is pretty much fixed, being 65537 or 3 in rare cases), so there is no public/private keypair generation, just private key generation. EDIT: I see someone downvoted my (I dare say rational) explanation. Could this person be so kind as to also contribute as to why s/he finds my comment unhelpful? I would say debunking mistakes in cryptography-related posts is public service, so if you think I made one, you might as well correct me, too.
If I understand build tags correctly, there's a typo: extra +'s at the beginning of the lines with build tags.
Yes I am still learning about this. But could you care to explain what parts are insecure ? I would love to understand the flaws in the design.
Aah so you guys wrote the c implementation ! That makes my point perfectly. If you need to re-implement nearly all parts of the stack, you are not using graphite anymore. You are using graphite v2. And so my point is I would rather try with InfluxDB and keep on optimizing graphite.
This is incomplete and in no particular order. 1. You're encrypting data with the same key multiple, possibly many times. 1. You say nothing about what encryption mode you're using. 1. The IV is not secret, keeping it secret only "protects" the first block anyways(assuming CBC mode) 1. You're using a predictable, often reused IV. 1. Your description of why you need public key encryption makes no sense. 1. You shouldn't have to store the master key anywhere regardless of what you're doing, the fact that you even mention not having to store it as an advantage is worrying. 1. Extracting filenames from what? 1. Your description of the overall system is so vague as to be utterly useless.
Since no one's said it yet, this was a great post for new entrants; from the subtleties of dereferencing a receiver, to a simple channel example.
Does the noop inline out of existence entirely? (I can't check right now myself, so I have to ask.)
1. There is a random salt given to PBKDF2, which will generate a different master key everytime. 2. Yes its CBC. 3. With only IV, and no master key, is it possible to break AES ? 4. Same as above. 5. Well, maybe. That's why I want to learn more. :) 6. I see. Alright good to know. Just a beginner here. 7. Extracting file names from wherever it is stored. For the user to know what all file he/she has uploaded. 8. Same as 5. Sorry if I sound incorrect. I am still learning the nitty-gritties of cryptography. Would love some constructive criticism. 
No it wont. I have high hopes for Go but it will follow the same Hype, decline, disillusionment and adoption curve as everything else. 
It does inline, but doesn't get eliminated completely. I think I raised a bug about that a while back, it'll get done once the compiler is in Go.
Thanks.
Don't vendor dependencies. You should make sure your dependencies follow semver and if they do not you should fork and file an issue as well as a pull request fixing it.
I originally had this issue when learning Go. I consider myself fairly polyglot .. with 7 years commercial exp. My main issue is the fact that all of the languages I use in my job are C-syntax derived/loosely derived. However, all of them have semicolon statement termination, parenthesis, etc. When I really committed to learning Go, I found myself writing some C# without parenthesis or C++ with no semicolons. It didn't take long for my brain to learn how to context switch .. but I definitely had an issue to begin with. I should point out that this wasn't much different to learning any other non-C-syntax-derived language as well. I had the same issues learning Ruby and switching back to C-style.
In the RSA system it happens to be algorithmically easy to generate the public key from the private key, but I'm not sure that's true for all public-key cryptosystems. In any case, that is not the standard workflow, and I suspect if you tried to do such a thing you'd end up having to (horror of horrors!) rolling your own implementation.
6,7 - Yes and Yes ! That's what I have come to decide. Thanks for the explanation. Anything is a bit difficult to get at first, but hey that's what reddit is for ;) And yes its a learning project. But I am hopeful that it will turn out to be a good open source tool. :) Thanks a ton for being patient with a n00b on cryptography.
Actually - no. Using python and go in production (for last three months mainly go) but still feeling comfortable to switch back to python or my old friend java. Go is beautiful and powerful, bu its just a tool with own pros and cons. It still lacks of normal OOP, functional style and tons of useful functions and external libs. On the other hand go - is very young and i have big hopes for his future. But as wisdom says - there is no silver bullet. So, anyway, we need to choose our arms depending on the problem.
:D I'm just a newbie at APL (it spurred me to write some Javascript on the side to better use it, codename althingijs, still working on it on my rare free time.. backend is go, for sure :D), but there are surprisingly "a lot" of APL programmers out there. Just last week there was a conference by Dyalog (one of the APL vendors) somewhere in England (IIRC) and it was relatively packed!
Thanks a lot for this comment. I am going to update my post accordingly. I was not aware of these functions. As a beginner in Go, I share my first step experience to get these valuable feedbacks! :) And indeed, last sentence was for a former version. I'll also update it.
I longed for a language like Go for years. By day I am a C# developer but preferred to use Linux at home for personal projects. I like the efficiency of Linux and used to use C/Python to code. C had the simplicity I desired in a language but was missing some things a modern language could provide. Python is packed full of everything but for larger projects the scripty feel annoyed me. Go is the answer and I have picked it up really quickly. I use Sublime 3 with the SublimeGo plugin and a drop down shell and it is superb.
`fmt.Println(fmt.Scan(&amp;s.i))`
The point is you don't need to bring over OO Java style design patterns and shoehorn them into Go
Because windows sucks :D
I still use Erlang more than Go, and the various Erlang flavors (LFE and Elixir). I just find error handling and recovery nicer in the OTP model for services that need to run. I tried coding something with panic/recover for restarting goroutines that bomb out but could probably keep a service running through a re-tried connection. That didn't appear to be the best way to get it done in Go. I will try again someday, but I've not had the time to dig in and had to get real work done. Also Erlang processes may be "linked", in that you can easily set up something that watches for something else to die. I'm not sure, but I think you can do that kind of thing in Go by looking for close on a channel in some receiver. However you have to explicitly close it don't you (honestly not sure), which means a recover function on a panic or something... Anyway, if I can figure out how to reliably link goroutines this will help my situation greatly! Erlang will still have a one-up on Go in the distributed programming sense, that the code I've writtent to run locally needs minor changes to run and function well in an actual distributed environment, but this will close a major gap for me. Also not sure if it's the right problem to solve with Go, and therefore, polyglot continues to do well :-). Trying to be good at too many things is why C++ is so big, and I think I like Go staying fairly small.
It doesn't even matter, because it is an advertised platform and apparently they didn't even run the unit tests on it before releasing.
Yes they did, in Australia. The bug has something to do with timezones and it does not show in Australia, as far as I understand.
Looks neat. I'm going to take this opportunity to toot my own horn here: https://github.com/cryptoballot/entropychecker If you're generating UUIDs on boot-up it's important to make sure your system has enough entropy before doing so.
The Sydney bug has nothing to do with the fact that 1.3.2 is broken on windows (I know because I was the one that patched it on tip, weeks ago). The Sydney test fails on 1.3.2 because the patch is not merged yet (it's going to be in 1.3.3, I think) but it's not serious. The windows problem is in the runtime: [Issue 8826](https://code.google.com/p/go/issues/detail?id=8826)
Did anyone audit that code ? Remember what happened to OpenSSL? Google knew about the loophole for one year !
Thanks its great!
Weird. I can't seem to compile 1.3.2 on Arch Linux. I keep getting: FAIL: TestParseInSydney (0.00 seconds) format_test.go:201: ParseInLocation(Feb 01 2013 EST, Sydney) = 2013-02-01 00:00:00 +0000 EST, want 2013-02-01 00:00:00 +1100 AEDT Using the latest tzdata.
sssh, the microsoft satanists will get you
Yep, that's what I wrote &gt;The Sydney test fails on 1.3.2 because the patch is not merged yet (it's going to be in 1.3.3, I think) It's not windows related and fails on every system with an up-to-date tz database. You can wait for 1.3.3 or manually apply the patch, but it's nothing serious (it's a bug in the tests, not in the code).
Still using multiple languages - XML manipulation I can still write faster with python. I don't write anything bigger then small projects with python. GO when building API's and need performance. Able to develop and scale faster and better then any other language. Still lean on meanjs.org to quickly put together a website. If it was for RDMS I would probably just use Beego. 
Fixed, thanks for the feedback.
I agree. This is much nicer than my attempts at an extendable CLI lib.
&gt; cli.NewCLI This repeating is against the guidelines. It should be cli.New().
Thanks for the feedback. I agree that is repetitive. I have changed the method to New(), updated the documentation and aliased the old method for backwards compatibility. Odin is now 1.1.0.
This is just a personal preference/nitpick, but I don't like that uppercase CLI variable. I think it would be more idiomatic to name the package odin. http://play.golang.org/p/XUjj0Ej7M1
In your example you're doing New(...) instead of cli.New(...)
corrected
You can have a subdir called odin which would be the main package. That's how docker does it https://github.com/docker/docker/tree/master/docker
This looks alright, but has anyone tried Docopt for Go? It was ported over from Python and creates a CLI based on POSIX-style usage documents. You can check it out here: https://github.com/docopt/docopt 
I don't know of the exact post you're talking about.. but its pretty simple to implement `ServeHTTP`. Is that what you're talking about?
There was a very specific post I had in mind regarding a specific way of managing routes. The part I found most notable to distinguish that post was how they were one of the few bloggers who implemented the Handler interface instead of leaning on a web framework. The reason I wanted to find it was because they had an interesting approach to routing. 
Thanks for being so open about this. It really means a lot.
Maybe this? http://justinas.org/writing-http-middleware-in-go/
No that's not the one I had in mind, though it's a good one too. In the one I had in mind, there was something mentioned regarding how they use a muxer in a unique way that I have not seen elsewhere 
[httprouter](https://github.com/julienschmidt/httprouter/blob/master/README.md) does a pretty cool way for routing with radix trees. if nothing else, it's some nice code to read. Edit: not a reddit post, but may be along the lines of what you were thinking.
I use it, works very well.
Possibly related to these? http://rcrowley.org/articles/tiger-tonic.html http://www.hakkalabs.co/articles/building-web-services-go
The simple answer is the second one. The slightly more complicated answer is to rewrite the whole parsing function in terms of `io.Reader`, and pass that around instead. It's what I suggest for "industrial strength" code... what you do for now to learn is up to you. I don't want to push too hard while you're learning. But it's something to keep in mind.
If I understood you correctly, you could use `continue`. Something like for i, r := range str { if r == ';' { // Do stuff with substring. continue } // Collect substring. }
That won't advance the range, and will cause you to need to write complicated code related to skipping over things that have already been processed. One's intuition might suggest this is a performance problem, in practice it probably wouldn't be, or at least not much of one, but the code complexity is a sufficient reason on its own not to do this... precisely matching how much was consumed with how far to advance will take a lot of work. It's part of why I suggest `io.Reader` in my other comment, it automatically holds those together for you.
&gt; r := str[index] Thank you for your answer. :) I was considering the Reader approach (and even tried it out), but 1) I know in advance, that the file will not get larger then ~5 MB and 2) I wanted to do the basic parsing and afterwards extract some of the code into goroutins, which, I think, will not be possible if I work with streams..
&gt;That won't advance the range, and will cause you to need to write complicated code related to skipping over things that have already been processed. Care to explain what you mean by "advance the range"? Because [this](http://play.golang.org/p/C9JCm_h24_) shows that `continue` in range does skip the iteration as it should. My version doesn't fit if you need to skip more than one iteration though.
Nice post. It seems to be missing quite a lot about switch statements though. They certainly aren't C switches. 
What's wrong with the standard lib's log? It occurs to me that having two different formats for output is a recipe for misunderstanding. 
 // Encode it in base 64, URL-safe base 64, ASCII 85, base 32 fmt.Println(idA.B64()) fmt.Println(idA.URL64()) fmt.Println(idA.A85()) fmt.Println(idA.B32()) Why not just fully write out the encoding names in the method?
I see your point and will indeed retry the implementation with io.Reader. The parallel implementation (idea) was intended to get me into goroutines and never to improve the performance of the parser. Thanks again for your example and comments.
Cool. This is exactly what I wanted to do next with my gengen tool that the author mentions in the post. The ability to simply `go get` a generic implementation is a great usability improvement. There are still lots of issues in trying to build a generic implementation (for example, equality is not possible across all types) but this is handy for many simple use cases, like wanting strongly-typed collections and data structures.
I'm sorry if my intention wasn't clear. English is not my native language. What I need is to delegate parsing of the string between two semicolons (e.g. FF[3]) to another function, and after returning from that function I need to "advance the index" to start from the second semicolon. In other words - yes, I need to skip more than one iteration.
Could this be more generic?
This actually put a smile on my face. I really interesting solution!
This is fantastic and I can see myself using the heck out of it. ~~How do you plan on handling nested types like struct{foo, bar}, or a pointer to such a struct? Can go get automatically escape the characters?~~ edit: nevermind, I was confused. To answer my question... Duh, mostlywaiting, you can just name that type and then everything will be fine.
What if I want a single package to use both an int set and a string set? Won't I get a name collision on `set`?
I think for the most part Go code is focus on being short and concise with the intent of keeping functions small and lean. It's a good rule of thumb in Go that if you start to get confused in a function, that you're probably doing too much in it and not encapsulating things properly. It seems a bit of a throwback to naming conventions in C as well and I wonder if it's a bit of a reaction to the VariableNamesAsLongAsTweets in Java. That being said, I still stumble a bit myself as I'm more wetted to the naming conventions in python. It's a habit thing though and not a problem I see in Go and pushing myself to write idiomatically correct go has always paid off for me, sometimes for reasons I don't grok until later on. 
Unsigned integers are something every developer is aware of, but not every developer is aware of every domain specific acronym.
http://research.swtch.com/names
It depends on a context a lot. I mean there can't be possibly anything surprising in the File structure. But data structures which describe more abstract and less known and new things should have better field names. As of variable names, if it's a local one to a function, you can call it practically anything. It's not their names which cause problems, but their amount per function. Short variables are easier to read. When you read a function, you build a mental model of it. It's much easier to quickly spot different variables at different places if they are single letter ones and the code is short. Sometimes it's much better to have "a, b, c, d, e" instead of the crap people invent trying to explain stuff using a single or multiple words.
This probably isn't why everyone else does (or even a big deal for that matter), but the longer the variable name, the more likely I am to misspell it later on. So something like `req` is fine for a request, but I won't use something like `initialBackgroundRequest`.
That's just my opinion, but code should be written in a way, that it doesn't need to be commented in most cases. All those short acronyms remind me of slang, that teenagers use when texting. It's just that it takes a lot of time to understand big code bases, if i need to remember all the acronyms and constantly check up what a variable represents instead of just reading the code.
I guess it's a matter of style and preference. I don't think there's a general principle but, if I can help it, I try to keep my comments in the comments. It's not that I'm too lazy to write it CorporateJavaAbstractSingletonProxyFactoryStyle; I just don't want to come back and have to decipher these mile-long camel cased monstrosities. Essays written with a broken space bar don't help readability for me and being forced into concision, compartmentalization and readable code structure does.
See also "The Practice of Programming" by Kernighan and Pike http://books.google.com/books?id=to6M9_dbjosC&amp;lpg=PA3&amp;ots=3_H-Fmy327&amp;pg=PA3#v=onepage&amp;q&amp;f=false
&gt; equality is not possible across all types But many socialist developers don't think it is true. They believe in equality and saying that it's not possible across all types makes you sound a bit racist
To the extent that generics can be adapted to Go 1, this makes it less likely that the 2.0 release will be motivated by them. Also, there is nothing about this that would prevent the go team from turning it into a part of the language in Go 1: &gt; The interpretation of the ImportPath is implementation-dependent but it is typically a substring of the full file name of the compiled package and may be relative to a repository of installed packages. &gt;-- Go Spec Therefore there could be some currently illegal import statements that would result in the same thing as gonerics. For example, import ( "templates.Map{int, string}" ) Which could then either be generated by one of the go tools or whatever.
Something like: cur := 0 for { next := strings.IndexByte(input[cur:], ';') if next &lt; 0 { process(input[cur:]) break } process(input[cur:next]) cur = next + 1 }
Most of the short variable names are conventional. r, w, f, rc, buf, err, i, n -- they're all well established variable names throughout Go code. The method receiver's name can be short, because you (should) know what type the method is defined on when you read it, so why have a `file *File` when it can just be a `f *File`. Other, non-standard short variable names require you to acquire the domain knowledge first, which in my opinion isn't a bad thing. How can you be expected to fully understand the code if you don't know in what domain it is actually operating? I have to admit, I have absolutely no clue what `a` and `z` stand for, but I bet that if I spent a minute looking at the containing data structures, I'd know, never forget, and actually have learned more about the domain I am working in than if the names were longer and gave me the illusion of complete understanding. And if I work on code in the same domain again, I'll already know their meanings, and now benefit from all the benefits of short variable names (which are explained in documents already linked in other comments.) And, just as a personal opinion, I find short variable names a lot more readable than long ones.
Despite the fact that Go is hardly the first C-style imperative language to have interfaces, it does seem like the fact they are very easy to use in Go causes more code to actually use them than in things like Java. Consequently it is far more common in Go and especially in libraries to see very generic code, in the sense that it accepts some interface rather than a concrete thing. If you have an `io.Reader` coming in to your function, well, what _are_ you going to call it? It's not a file. It's not a socket. It's not a byte buffer. It's any of those things and any of a long list of other things. It's hard to be any more specific than `reader`, and from there it's a short trip to `r` as a conventional variable name. You get the same thing in Haskell quite a bit. Combine that with the fact you basically made up `f.a.z.Fopen` and that doesn't actually happen, and I think you get your answer. (By contrast, dealing with interfaces is more painful in Java, and in the scripting languages, because interfaces don't formally exist there's no way to confine the usage of a variable to be guaranteed just using the interface, so you end up in a place where it becomes very tempting to end up using something specific about the incoming object and the interfaceness is lost, and on the topic of this post, you end up giving it a very specific name. This is part of why I consider go a decent scripting language once you pass ~50-100 lines, the conventional scripting languages really tempt you away from this style of programming and that starts to hurt very quickly, despite the fact Go appears to be more strict on the surface.)
http://commandcenter.blogspot.com/2012/06/less-is-exponentially-more.html In particular: "Early in the rollout of Go I was told by someone that he could not imagine working in a language without generic types. As I have reported elsewhere, I found that an odd remark...What it says is that he finds writing containers like lists of ints and maps of strings an unbearable burden. I find that an odd claim. I spend very little of my programming time struggling with those issues, even in languages without generic types...But more important, what it says is that types are the way to lift that burden. Types. Not polymorphic functions or language primitives or helpers of other kinds, but types." I find type problems (of the sort that require generics) to be "CS-ey" or language-level problems, not application-level problems. If I'm finding myself constructing Type-Hierarchy Towers of Babel, my design is probably too esoteric and complex.
1. Remembering that f is a File and rc a ReadCloser and err an error in a 7-line function is not that hard. You might wanna try it sometimes. 2. This "code shouldn't need comments" is plain nonsense. Code and comments transport different ideas. 3. All this "speaking variables names" resulting in theCurrentlyOpenFileWhichWeAreProcessingRightNow or readFileUntilEndOfFileWhileCountingLinesAndThrowOnAnyError are not helpful. 
That jumped out at me, too. Also, saying that parentheses _aren't allowed_ in conditionals is misleading. You can certainly use them for grouping.
What does this give me that glog does not?
Every time I see this quote I rage. In C++ I have often made use of (sometimes-complex) templates to make the rest of my application code vastly simpler. Aside from that GO DOES NOT HAVE A SET TYPE. So we all end up reinventing it. That is just flipping idiotic. 
Isn't using map keys to emulate set already a well known practice? 
One of the better workarounds - looks like it would be usable for containers. But I'm not convinced by the functional programming examples. Each time I want to Map a different type I need to import the package under a new alias? 
Can we agree that there will be no generics in go? I think it's obvious right now and everyone who can't program without generics should go find some other language.
That's what I thought as well. Maps *are* sets, essentially.
Right up until you need actual set semantics. It WORKS its just a fugly hack.
stdlib log doesn't have any log levelling facilities, so you can't control what gets logged.
&gt; This "code shouldn't need comments" is plain nonsense. * Code that explains itself properly greatly *reduces the need* for comments. * Code *can* explain itself even with short names for variables, if the author thinks carefully about the right name to use. * The shorter a function body is, the shorter the variable names can be. * There is always a point beyond which the code alone cannot easily reveal the idea behind it, and then comments are simply a must. This is the point where... &gt; Code and comments transport different ideas. And that's the whole point about good commenting. Thank you drvd.
I finally settled on [glide](https://github.com/Masterminds/glide) and I'm pretty happy with it.
&gt; I find type problems (of the sort that require generics) to be "CS-ey" or language-level problems, not application-level problems. I don't even know how to properly parse what you're saying to make any sense of it. Where exactly do you delineate the application-level concerns from the CS concerns. The entire discipline of programming and software engineering is nothing more than the application of CS theory to practical day-to-day concerns.
The idea would be to get the syntax popular enough that it is blessed by the core developers and added to the compiler. It's clear the Go team doesn't see generics as a burning issue, but they've taken the line of maybe, someday, if someone can suggest something good enough. As to why the developer of the web service didn't write it into the compiler, presumably they found the implementation easier.
No, we don't agree. The maintainers have always said that if they do get generics they want to do it right, and right now they consider other things more important.
I think I'm guilty of not expressing it very eloquently, but my argument boils down to the observation that heavy use of generics tends to indicate a design with (what I consider to be) excessive layers of abstraction. Or at least abstraction without justifiable benefits. I believe that abstraction is a tool (albeit often useful tool) that can be abused.
Or maybe people simply religiously love features which are not critical because they can't think of original solutions to their problems... which is funny because generics are a more recent thing out of academia. Go is used in enterprise, people there are not whining as much about it's minimalism as life in professional programming is complicated enough.
Good point. I can see where I would miss the equivalent of the Python: set([0,1,2]).intersection(set([1,2,3])) Google finds this: https://github.com/deckarep/golang-set
Hey jerf, thanks for the feedback Re: Simplicity: True. Like the repo, it was supposed to say "small" instead of "simple", was a typo, though unfortunately I can't edit post titles. Re: Reusability and io.Reader/Writer: I originally was using io.Copy, though couldn't get access to the data, I chose the naive approach because I thought implementing my own `net.Conn` would be more complex. However, now I look back I only need `io.ReadWriter` and the refactor will indeed make it much nicer. Re: Regex: Packet boundaries are indeed a problem, though not a common one. This was intended as a debugging tool for text-based protocols, so I'm often only searching for small peice of a large chunk of text. Down the track, I plan on using this as a client-server validator for binary protocols. I've already got stream parsers for a few protocols I wish to verify. I've updated the repo README :) 
I agree that abstraction can be abused, but I don't think that abstract type-safe data structures constitute abuse. Put another way: I'm not content with how Go forces me to choose a) using type-safe maps/slices/channels because that's all the language gods saw fit to provide, b) sacrificing type safety via `interface{}`, or c) copy/pasting and find/replacing boilerplate. `go generate` might help, but I agree with /u/07a: this post is both an elegant service and a terrible hack, and it should be interpreted as evidence that we're missing a feature.
Bad week to announce something that operates via CGI and shell :) But despite this being an insane hack, it's pretty creative and ergonomic. Would like to see something like this interoperating with 'go generate' in a fully local environment.
Sort of begging the question to answer a gripe about a Pike idiom by citing Pike, in it?
Great question... without a very good answer despite all the attempts so far. Oh so many years ago I rejected C in favor of Turbo Pascal. I much preferred the Pascal culture which encouraged writing readable code. Comments were encouraged to explain algorithms and such, but not to explain things that should be made obvious by the code itself. Back then obfuscation contests using C were all the rage. All I could say was WTF??? You would think that every extra keystroke caused a unicorn to lose a rainbow. The biggest thing I don't like about Go is that it promotes hard to decipher code. Again, I can only say WTF??? The next biggest is OffTopic... giving us the kluge of map[string]interface{} instead of providing a legitimate implementation of generics. Generally accepted values like i, j and k for loop variables are fine by me. I can even accept shortcut names for function parameters in a function definition where it's easy to see that r is reader and w is writer. Beyond that I reject the idea, promoted in the documentation, that "Variable names in Go should be short rather than long. This is especially true for local variables with limited scope. Prefer c to lineCount. Prefer i to sliceIndex." My personal preference would be lineCnt and sliceNdx. Using i for something other than a loop counter is, IMO, especially egregious in terms of degrading ease of maintenance. &lt;Scope of rant widens&gt; Then there is this... in the Go Tour of all places. The first example for the if statement is excellent. No problem understanding the logic: func sqrt(x float64) string { if x &lt; 0 { return sqrt(-x) + "i" } return fmt.Sprint(math.Sqrt(x)) } In the next example I guess we're supposed to be impressed by the cleverness of this... func pow(x, n, lim float64) float64 { if v := math.Pow(x, n); v &lt; lim { return v } return lim } as opposed to this... func powLimit(x, n, lim float64) float64 { v := math.Pow(x, n) if v &lt; lim { return v } return lim } which does exactly the same thing without making new Go programmers face a pointless gauntlet of cleverness. Does the compiler really generate less efficient code for the latter? If so, spend less time being clever and more time on the compiler. Jeez Louise! My theory is that there is some sort of ego thing going on here. Perhaps the genius required to create a language as dominant as C and as awesome as Go makes that inevitable. 
Completely agree. The reason I phrased this the way I did in my blog post is because the bulk of my professional experience has been with PHP, Ruby, and Python. I reckon that I am not alone in this. In each of these languages, these issues are a very real struggle on a daily basis. However, you're correct that binary distributions are by no means a new idea. Thanks for your input.
Two thoughts: A) Generics are metaprogramming and metaprogramming is code generation. B) The type system isn't broken just because people have to write more code sometimes.
Ruby is a quirky language. It's supposed to follow the Principle of Least Astonishment, but the author claimed that wasn't the general case, but least astonishment for himself. A lot of people found Ruby's quirks fit them well, too, and embraced it. I preferred python's quirkiness and stayed away. I find Go to be a very quirky and opinionated language. Your point about terse variables exemplifies this. At least for me, it's quirky and opinionated in ways I like. If you want a conspiracy theory, here is one: short variables are preferred by programmers who cannot [touch type](http://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html). Ymmv.
http://doc.cat-v.org/bell_labs/pikestyle
Unfortunately, in this case at least, the effect is to encourage new Go programmers to write pointlessly clever code rather than easy to read code. IMO they'd be better off NOT paying attention to this particular example.
I have 0 interest in this 1 sided view.
Haven't seen anything happening :(
nope. nope. nope. You import _packages_ not _types_, this would be a massive step backwards.
They need to go fmt their code and `ToString()` should really be `String()`. Other than that and what /u/davecheney said, the article is fine.
To the naysayers here: here's one guy not whining about but rolling up the sleeves and experimenting. He doesn't deserve to be looked down just for showing a way around from Official Way. Really, that attitude is just as bad as the typical "let me write Javaskell in Go or GTFO" zealotry. To the author: truly clever. Congrats for that.
Or, using set literals and operator overloading: {1, 2, 3} &amp; {3, 4, 5}
IMO: the Go itself is kind of "framework" and except maybe routers, there is no need in the next level of complexity. i.e. that "frameworks" is waste of resources. 
This is one of those arguments that works in isolation, but in real source code has a disproportionate impact on real code. It's * easy enough for me to screw up a little something when I write it * _distressingly_ easy for someone more junior than me who hasn't written some form a union dozens of times to screw it up * and probably worst of all, by making this hard it strongly encourages people to do something else that may be superficially easier but less correct. (If you haven't seen junior programmers dodging around what seems to be something simple to just write and produce something that is by comparison bizarre and way more complicated, you must not be maintaining a very old or well-used code base.) That last one is really the worst one... it is not good to encourage people to write basic algorithms out over and over again, because making something that should be easy hard encourages programmers to do something superficially easier instead, which will probably turn out worse in the long run. I'm not a "hater" who is going to pretend that Go lacking generics is the WORSTEST THING EVAR, because in practice that's not true. But neither am I going to pretend that it's all hunky dory that Go makes me repeatedly type out set operations, or repeat error-prone casting operations, or just in general type out what is often very fidgety and precise code over and over again. It isn't a problem big enough to outweigh the advantages of the language, but it _is_ a problem. In fact this really strikes right at the heart of one of Go's usage propositions, which is making Google-scale programming easy. We really shouldn't have to be reviewing and testing this code over and over again.
Please calm down. 1. Not every function is 7 lines long. 2. Never said that, read my post again. The fact that you write a comment for something that could be expressed in the name of the variable is code smell. 3. That is not a realistic example. The idea is to explain, what the variable holds. f := readFile() is just noise because i know that it's a file. It would be better to describe what does the file hold eq. is it a configuration for something or just a plain text. Proper naming becomes even more important due to type inference.
From a randomly selected library: https://github.com/hailiang/go-zip/blob/master/file.go
I come from a Python/web2py background. I absolutely **love** web2py. In switching to Go, I've chosen Beego as the closest thing to web2py (I didn't like Revel). I've even written an [advanced tutorial](https://medium.com/@richardeng/a-word-from-the-beegoist-d562ff8589d7) for it! Give Go a chance.
I'm certainly not a biographer of any of the Go team, but I think I can support Dave's comment by saying that even a brief look at the Go team members will illustrate very clearly that these people are _authorities_ on programming language design and theory.
&lt;nevermind...&gt;
Where does it say that a windows build is fixed?
I had a conversation once here with one of, I believe at least, beego developers, that defended some poorly (my opinion) implemented map. From now on I don't believe the whole framework can be any good quality (again, my opinion).
TL;DR: Not that George Clooney.
sure, brilliant.
Thanks, that's indeed everything to retain from this post :) (seriously)
".. The test failures on Windows are real: Windows users should avoid 1.3.2 and continue to use Go 1.3.1. The test failures on other systems are benign and may be ignored. To resolve these issues, we will issue the 1.3.3 release in the next couple of days. .." https://groups.google.com/forum/#!msg/golang-announce/eeOHNw_shwU/gjUZswx4OqAJ so, here it is I think.
If I may join the fray... I too am using Beego on my latest project and have been working on one project or another since buying TRS-80 Model I, s/n 00000158. Buying an already built "home computer" was not considered cool until Jobs and friends made it cool a year or so later. That attitude is not unlike the framework vs roll you own debate seen in the Go community. The first thing to understand is that Beego is not Rails or Django in two important ways. 1) It is MUCH lighter... mainly because Go does most of the heavy lifting. 2) It is MUCH newer... hence it is being improved as its authors learn where the gotchas are. Assuming you have a solid working knowledge of Go, the effort required to learn Beego is minimal. It has an active and growing community of supporters. Beego is written in Go (with a bit of JS) and you have access to ALL of the source. Instead of worrying about being abandoned, make changes as needed to suit your needs. If you find and fix a bug, pass that information back to the authors. A recent rework of the beego.me site provides access to much improved, much more complete documentation and examples. The functionality of Beego is testified to by the number of functioning websites based on it. I would venture to say that more commercial quality websites based on Go use Beego than any other framework, including no framework at all. Most happen to be China... but websites work exactly the same way anywhere on the big network of pipes we call the Internet. I have no connection to the Beego authors. I'm just a satisfied customer with a desire to show my appreciation for the time and effort saved as a result of having Beego available. 
Others have already posted why Go prefers shorter names. I have nothing to add - other than to each their own, and you should stick with the style common for a language if there is one. I think the example you posted is an example of short names gone overboard. though. Go uses short names for a couple of things: function arguments, variables with a local, short scope. a, and z are private variables on a type. These should be longer (but not excessively so) So this should probably be f.archive.zip.Fopen(), or something like that. Other than that, there's nothing un-readable about the function. 
Most of the time when I use sets I construct them from lists, so set literals aren't very useful. I'm generally against operator overloading, I find method calls more obvious. For some reason my brain always wants to read '&amp;' as "bitwise AND".
From 40 to 2 ( well 1 plus a backup) if insanely impressive. I was thinking that maybe they just didn't know Ruby that well, but then again they presumable just picked up Go and got these speed/load improvements. My employer aren't going stop all new development to allow me to rewrite our current Python platform in Go. To bad, perhaps that would bring me closer to my goal of replacing four servers with a RasberryPi :-)
It is experiences like the one described by "!George Clooney" that give web frameworks a bad name. Django is another culprit. 
It'd be nice to know what kind of application they had built in Rails. $10 says it was something that should have never been built in Rails in the first place. Most of the slowness in a typical web app comes from the database. Switching to Go isn't going to make that bottleneck go away. Go is great and all, but it isn't a magic performance solution for most typical, database-backed web applications. 
&gt; Go provides performance comparable to C and C++ Is this really true? I'm asking because I don't know. When I looked at Go a while back, I saw a number of benchmarks that showed it to be considerably slower than C and C++. From memory, it was also slower than both Java and C#. Obviously, things change, so I'd be interested to know how well it performs now.
You make a valid point. To some degree it applies to any method used to build an enterprise quality website based on Go. Chances are good that in three years Gorilla, Goji, Martini, Beego ... will all look a lot different than they do today. By then Go 2.x.x may even be a reality. :) Those who choose to be pioneers will no doubt have arrow wounds to prove that they led the charge. 
We got a wiki prof here. Ya, ML was so generic it generally only used ONE data type, int, which was expanded to a bigger int in case of overflow. Languages like Haskell have a completely insignificant userbase because they're hard to read, making them impractical for multiple developer projects.
Hi soybean - I built 1.3.2 from source a few days ago and saw the errors. I did build 1.3.3 from source and confirmed the build passed before posting the link.
&gt; Combine that with the fact you basically made up f.a.z.Fopen and that doesn't actually happen Technically it did [here](https://github.com/hailiang/go-zip/blob/master/file.go#L21)... :O
Well, alrighty then. That is bad.
&gt; It's unsafe because it doesn't enforce any kind of type checking. You are misinformed: Python is dynamically, but strongly typed.
It will always depend on what you're doing. Having said that, I have profiled go in text processing and found it to be surprisingly slow. From my terrible investigation, the bottlenecks appear to come from three areas: GC, Unicode handling, and the instruction generation. WRT the GC, I'm really interested to run my tests against 1.3 with its precise GC. I don't expect a huge speedup, but I'm still eager. I don't really understand why Unicode processing is so slow in Go since it's fine in Java and Python3. Finally, the instructions generated are more basic x86\_64 instructions. Go doesn't generate AVX2 or anything fancy (which would probably require some build flags like `--march=native`). Using these could speed up some maths operations and also string parsing. Edit: by slower than I expected, I thought it would be on par with Java, but it was about the speed of Lua (not luajit) at processing text.
Yeah, that's crappy (and not just because of the names, but staying on topic…). Still, those are fields of a struct, which I feel is a whole different beast than local variables and have been covered by jerf and dominikh.
 &gt;&gt;&gt; 1 + 'a' Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unsupported operand type(s) for +: 'int' and 'str' &gt;&gt;&gt; int('a') Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; ValueError: invalid literal for int() with base 10: 'a' From [wikipedia](http://en.wikipedia.org/wiki/Strong_and_weak_typing) &gt; The object-oriented programming languages Smalltalk, Ruby, Python, and Self are all "strongly typed" in the sense that typing errors are prevented at runtime and they do little implicit type conversion, but these languages make no use of static type checking: the compiler does not check or enforce type constraint rules. The term duck typing is now used to describe the dynamic typing paradigm used by the languages in this group.
If you still want to limit the scope, then you use an else. If you don't want to limit the scope and you think it's a legit use, then you don't limit the scope. However, I don't want to take this down a different path. You asserted the code was just being clever. I'm asserting it has a purpose. Once you know Go, that code is not unreadable. It reads just fine. It's not done to be clever, it's done to make the scope of v only as big as it needs to be.
A good rule of thumb is that for CPU intensive tasks, the less mature Go compiler will produce code that is 2x-3x slower than what GCC would produce. This puts it about the same speed as Java, probably a bit slower for some cases (but not by mutch). However, once you move to the dynamic languages (javascript, perl, python, ruby), you're looking at easily 10x+ speedups. The other thing to consider is that if you're *not* doing CPU intensive workloads because you're actually a network server which blocks on I/O for most of the time with a little bit of CPU work, then you won't really notice the difference to C (other than how easy it is to write network servers), and you'll get nice cheap concurrency primitives that are expensive in Perl/Python/Ruby/etc.
I agree, very clever.... I never would have thought to use the server end of go get to generate code. 
I think we should agree that it's very unlikely that we'll get traditional generics in Go. Maybe at some point we'll get a little something extra that helps with things like type safe generic containers (trees, for example).
You could write another program that would execute the binary with various inputs and check the results. Shouldn't be hard to do in Go in a format similar to idiomatic go tests minus using the actual testing package. It's not a terrible idea, but would be a waste of time to try and check every endpoint condition IMO. Figure out where the logical segmentation in the wrappers and just test that each of those work out. If you really want to test every endpoint, I would look into sharing the endpoint testing data between the unit tests and the binary tester so you stay DRY.
This is exactly how I feel. To me, Go isn't a faster Python, a more circumspect C++, or a native Java, it's an improved C.
Begging the question does not mean do not go to the source of your question. Pike also gives really insight to his thought process.
...because whatever they built apparently isn't a "typical, database-backed web application", and clearly had no business being built in Rails in the first place.
Now I wanna know what f.a.z is short for :/
This is beautiful and amazing. Perfect balance of features and minimalism for composing gist-size code.
I agree. I have an experience in porting C code to Go, and it is quite straightforward and easy and enjoyable. Go is a better C.
Why not just use go test? Else you are just going to have to use bash to create a testing environment which is very verbose. 
Keeping a thin main.go aids in unit and integration testing. Our build systems test the binary and those tests are able to be built and maintained by our QA/QE peeps. Our current flow for one of our latest projects is our CI runs the Go tests, compiles, and ships the binary to the next bout of tests. This next bout is a suite of Ruby specs built and maintained by the QA/QE team (and by devs if needed) to test the functionality of the binary. If that sails through, then the binary finds itself installed to our staging server(s) where any additional verification that is needed can happen (such as product owner sign off or whatnot). If all is good, the binary is made available to our prod system and deployed. I'm not a huge fan of the Ruby spec tests, but they are easy to read and are a tool that the QA/QE team is comfortable working quickly in.
And by only being statically linked it encourages actually free open source licenses like BSD or Apache. (I'm less and less a fan of the GPL and LGPL nowadays; *BSDs have done just fine... Edit: why the down vote? Some of us think BSD licenses are free and GPL licenses are not. 
I'm just trying to figure out if there are any frameworks already in development that I could leverage instead of just rolling my own `exec.Command("compiled-go-cli")` based tests.
Fair enough. I'm sure there are cases where limiting scope in this way is of value. 
If go is a replacement of C to you, you most likely did not need C for what you were doing. The absolutely biggest strength of C and the reason why nothing really replaced it since the 70s is its good balance between high and low level language (pretty much every statement in it you can easily guess what the machine code equivalent would be), it doesn't stand in your way (no GC, and runtime checks and other magic), these things are to prevent from shooting yourself in the foot, but only get in the way on lower level. These things are important in system level programming. That's why Go did not have much impact on C. Based on my limited knowledge Rust actually has significant chance to take C's spot, because of ability to write safe code and enforce it at compile time.
But if you want to, you can write highly efficient, low-level Go code that can do (almost) anything C code can. * You can turn the garbage collector off and only trigger it manually (or not at all if you're really careful) * Use arrays instead of slices to avoid most bounds checks (although you should be doing those checks anyway) * Using goroutines is vastly more efficient than native threads, since the scheduler is in userland and thus doesn't need a context switch In any case, normal Go is probably giving you the same order of magnitude performance as C, but without lots of headaches. I'd take much safer software over slightly quicker software any day.
Plenty of projects were only written in C because the alternatives were PHPython or Java#. Go is a better choice for those use cases.
&gt;Type Inference &gt;Go doesn't have type inference. And why? I really don't know. It has `:=` which is better than nothing, but I don't see why it couldn't have full type inference. OCaml has similar type system features—and more—and has no problems at all with full inference. Go raises compilation errors if you import a type not being \[explicitly\] used. However, imported modules affect the pool of inferred types available. So if we wanted type inference the nice import cleaning feature of Go would have to be removed so magic imports could be brought in.
Language designers are very clear on this one http://weekly.golang.org/doc/faq#unused_variables_and_imports Your best bet is to compose your program in such a way to always use debugging until you are completely sure that your finished product is ready. Then you remove all debugging calls. Start from scratch with logging calls on each critical point of your application. Don't try to write entire application in one go (no pun intended) but move on to next part once the previous one is proved to be correct by logging. You can also make your own "debug" function which could be something simple like this http://play.golang.org/p/vQOdVthOSl That way you have a way to switch debugging on or off when script is ready.
Potentially consider using http://golang.org/pkg/strings/#Split for this step in your parsing given that your delimiter is well defined.
Most gophers use good logging as the primary means of debugging. Go is a very simple language, so this generally does the trick. As for imports, "goimport" will automatically add / remove them for you as needed. As for unused variables, that will remain a problem. Also, it isn't a script, even with go run, it is compiling a binary and running it. 
Sorry for the late reply. The original demo does use a file system, but I wanted to tie it to a DB more just to explore the use of an ORM in Go. Plus it's been a minute since I used mongo, and while I don't necessarily need the schemaless state of a NoSQL db, I wanted to get some face-to-face time with using it again. I think for a true, non-dev wiki, I'd research other options. Thanks for the thoughts!
Thanks for this! this helps me out a bunch, and I didn't even know gofmt existed.
Thanks for pointing to explanation of the language designers.
This post explains how to do this http://dave.cheney.net/2014/09/28/using-build-to-switch-between-debug-and-release
I believe GDB works under Linux, but does not work under OSX.
Linux is all I care about :-) Thanks for the update, we are looking at potentially evaluating Go for some internal projects, so lack of debugger would have been a very unwelcome surprise.
There aren't enough of these posts from the C or C++ world. Thanks for posting this; I shared with my colleagues at work (C programmers).
How do you turn the GC off?
Call [`debug.SetGCPercent()`](http://golang.org/pkg/runtime/debug/#SetGCPercent) with a negative value. You can then do a manual GC with [`runtime.GC()`](http://golang.org/pkg/runtime/#GC).
Nice, clean code, Mike! As always. Glad to have another Ruby convert in the gopher camp 😄
+1 for goimports, I have it run in SublimeText when I save with GoSublime [1]. Great tool. [1] https://github.com/DisposaBoy/GoSublime [2] https://github.com/bradfitz/goimports
Thanks! I'm mostly brand new to Golang so the first two months of the project were lost to: 1. Write feature 2. Refactor 3. Refactor 4. Refactor until I got code that looked mostly idiomatic. I'd be very happy to see issues and PRs polishing the code further though, I've still got lots to learn I'm sure.
It's a pain. In my experience though the best thing you can do is write your code in a way that's easy to test and write as many tests as you can, luckily enough tests in Go are really damned fast so the feedback loop is quick. The work involved in writing tests is pretty much the same as manually printing log lines to the console - but the tests will still be there tomorrow, making sure your stuff works.
If you haven't debugged with gdb before, it's harder to pick up and use than in IDE debuggers you might be used to. Check out http://thornydev.blogspot.com/2014/01/debugging-go-golang-programs-with-gdb.html?m=1
There's nothing wrong with C. It's an amazing and excellent language. Use the right tool for the job.
&gt; ... acceptance tested AFTER compilation. Is that a strange idea? Not everybody uses the same definitions for these terms, but so far in my experience, I would expect that acceptance tests MUST use the compiled binaries - unless you are delivering the source tree. The "acceptance" test is to gauge whether the delivery is acceptable to the stakeholder who is receiving it, and so the test must use what is delivered.
Job description link: http://www.golangprojects.com/golang-go-job-lr-Senior-Go-Engineer-Burlingame-Crowd-Interactive.html
Just a thought: you may be back to bash or some other scripting language if the acceptance of these binary tests are contingent on others being able to read/grok the tests being conducted. A compiled Go testing framework may not be transparent enough.