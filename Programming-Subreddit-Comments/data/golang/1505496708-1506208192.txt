Great, I might use it in the next few months. It's been a year after someone created the issue for "Add web browser support" for gRPC, and yet they haven't implement it which makes me headache for my Vue.js clinet.
From that PR it sounds like he never got explicit approval from the sponsors, and just assumed that their lack of response was an approval? Yuck.
Despite the sad downvotes, actually a compelling reason to remove the header was posted on github... The header is a bit unclear and suggests that the site running through Caddy itself may be sponsored by the people on the list. That's compelling. Your "109 bytes" argument is not compelling. Have a nice day.
Yeah when checking with people on something important, it is better to get an affirmative answer rather than lack of a negative one.
Awesome. This is really good info. Thanks!
I'm using chi at this project https://github.com/diegobernardes/flare, isn't ready yet, but if you want to look at the structure it's done.
There is a mismatch between the package in the README 'pubSubApi' and the package declaration in the files 'mcpubsub' For constant names, stick with camelCase instead of all caps, see https://github.com/golang/go/wiki/CodeReviewComments#mixed-caps How about letting the client specify the server address? This way a server could be shared by multiple client machines. 
update your go, it seems like you're using an old version of Go.
Thanks! Appreciate the info. So the reason I don't know about my COLs is because MySQL has this frustrating habit of creating tables and columns on the fly when looking at system info, and these tables and columns change all the time. For example...in MySQL, there is a tool called "EXPLAIN." You can add the phrase "EXPLAIN" to the start of every query and MySQL will "explain" what the query is doing at the index and table level. Typically , "EXPLAIN'ing" a query yields 10 rows...but sometimes it's 9 and sometimes it's 11, depending on the query. And that's just EXPLAIN. The same issue arises when we execute "SHOW SLAVE STATUS" or "SHOW ENGINE INNODB STATUS." I love Golang's concurrency features, and for administrating 100s of servers running many different instances of MySQL, the ability to talk to many servers at once, without losing track of who's responding, is really appealing to me. I'd like to see if there is a way I can write dynamic Golang code to handle variable numbers of columns and rows so I can effortlessly gather system feedback, from many systems, without having to create a struct to receive data for every single administrative command MySQL has. I figure...if I can figure out how to dynamically handle columns and rows from a small test table (like the test table I have in my original post), then I can do so for tables that are generated on the fly, like the "EXPLAIN" table in MySQL. It's challenging because it doesn't seem like there is a single way to handle variable rows and columns. It seems like the SQL package with Golang was written with the expectation to handle explicit numbers of columns and rows.
At least for EXPLAIN you can create a struct with all the possible fields (sometimes 11 ;)), and whenever it will return less than that, the unused fields will be left at their default empty value. Checking if you have that value is usually as simple as `if struct.Val != "" { ...`. The struct doesn't have to match exactly to what is returned, it can be a superset of that. Edit: again, this might be sqlx specific. I haven't used the default sql/database with the mysql driver, as sqlx felt more natural in features from the beginning. Definitely give sqlx a try.
[removed]
good idea. Thanks
Yes, saying "keys that are stable over time" is an ambiguous English statement, that's what I'm getting at. I wasn't saying it's likely that they're referring to the map size, in fact they most assuredly aren't; I'm simply saying that it's an unnecessarily difficult to parse statement that could be construed as such. For example, if a city were to open a zoo and require it be "with rabbits that are stable over time", I could almost certainly make a case for that to be interpreted as the rabbit population must stay stable over time, i.e., the ratio of births:deaths is 1.
This is also a full fledged project implemented with chi, but the it still uses the old github repo in imports: https://github.com/anthonynsimon/parrot
I appreciate the sentiment, however, that's such a thought-terminating cliche. Just because something is open-source doesn't mean PR or DIE. Relevant feedback can be given. Time required to give relevant feedback &lt;&lt; time required to fix. That's a fundamental law of open-source. So whether they want to address it or not, doesn't really matter to me. I'm simply saying "hey this could possibly be improved if you want to maintain your high-quality docs."
Ahh, soo close. So that's working, but it's printing memory addresses instead of string values. Seems I need to have a conversion somewhere. Here's the code that is working so far....Where do I need to make a conversion at? At the interface level? Is there a to-a-string function I can run inside of the fmt.Println() command? [This is my current ALMOST working code](https://gist.github.com/akalaj/a8087ef8a23f21de3240717862624f58)
Email is the only acceptable form for critical communications like this. 
waiting on clarification for that situation at https://caddy.community/t/caddy-commercial-sponsor-header-clarification/2716/15
Yes, it's unfortunate. Perhaps bulk.Run() should have declared to return an `*mgo.BulkError` instead.
i would LOVE this.
This isn't so bad, you can do a type switch on your errors to get a catch type syntax. 
don't do this: bulkErrs = err.(*mgo.BulkError).Cases() The type cast can fail, in which case, this panics What you want to do is this: bulkErr, ok = err.(*mgo.BulkError) if !ok { // not a bulk error } for _, case := range bulkErr.Cases() { // } 
FYI, the Equifax breach was due to far more than just a vulnerability: http://spuz.me/blog/zine/3Qu1F4x.html /r/AskNetsec might be a better place to ask this question however as some general guidance: * Make fuzzing a regular part of your testing. * Never _ever_ trust user input. * Use gometalinter to spot problems like variable shadowing, unused variables, general bad practices, etc. By far most vulnerabilities are the result of bugs rather than a true application vulnerability. * Never assume your code is secure so do the right things at the system level: use strict selinux policies, run as a user with no privileges, isolate resources from each other, etc. * Always run the latest version of Go to get the latest security updates. * Don't store secrets in your application. You'll probably find a lot more answers if you look for an "application security scanner". There are a lot of language specific scanners but I'll be honest and say that because of the way Go is designed and the lack of popularity compared to something like Python, C or Java you're unlikely to find a wide set of tools specific to the language.
SourceClear recently announced Go support. Said support amounts to flagging outdated dependencies that have known vulnerabilities. https://www.sourceclear.com/blog/Announcing-Go-Language-Support/
[removed]
Not trying to be flamey and I'm coming from a sincere place here. I'm kinda frustrated after figuring out what's up (way too much wasted time). I'm not frustrated at you /u/GentooMonk, nor anyone else really. I'm just frustrated in the current state of the go-libp2p repo and wont be using it. So I actually figured out the problem. I'm on the latest and greatest, 1.9, that has nothing to do with the compile issues. The problem with libp2p is actually multiple issues that just build into a fluster cluck of `bad management`. After careful review and scrutiny, they are heavily relying on `gx`, which is a heaping pile of hot garbage and the guys managing the go-libp2p repo (+related repos) are currently managing this wrong with no consideration to how developers are actually using Go. `gx` - This is a package manager or dependency handler if you will. It's nothing new in the Go world. We already have `glide` and various other solutions to handle version management. However the guys that made it literally made it to avoid conventions that are in place to standardize the language. 2. Lack of knowing how to `git` - If you check out how the repos for libp2p are being managed, there are no tags. The only indication of versioning is in the commit messages. This is a poor convention that is being completely overlooked, probably because of the reliance of `gx`. For a library using `semver`, it is failing to follow that standard that they are using in their internal systems. I can't even take this project seriously. I burst out laughing when I saw this heaping pile of a bad joke. 3. The potential of `go-libp2p` is being hindered from being a usable solution in many existing projects. It's faster to write a new implementation for some projects than the time it would take to redo the dependency management systems a developer may already be using. I'm not a fan of `glide` either, but `glide` doesn't sit there dumping things into an arbitrary directory in your GOPATH's source directory and it doesn't edit your code. It is much easier to implement that `gx` is in an existing monolithic project. It also can handle versioning of various different types. 4. Converting go-libp2p into a thing that actually does follow conventions would be an effort of epic proportions. I seriously sat there reviewing the amount of work it would take. `gx` is not what I would call production ready. It also wont easily tell you where it is getting packages from. I did end up getting go-libp2p completely through manual tasking. To automate it is just too much of a hassle. Anyway, that's just a brief breakdown of actual problems I see with go-libp2p. It seems that I'm actually making headway on what I'm building and I guess it's good-enough. I can't find any p2p libraries in go that just make gossip protocol implementation easy. With some TLC I can probably make it a good solution, despite it being horrid to look at right now.
Thank you for the response! Yes, I am aware of the many, MANY issues with Equifax. The Struts vulnerability was but a small part of what seemed to be a culture of lax security (the Argentina web portal, etc). But, with the breach being so massive, it has spurred, at least in my neck of the woods, increased emphasis on security built into our Sprints. We use a wide variety of tools to test security implications, such as user input in our integration tests, but I was mostly interested in something that could find vulnerabilities we may not be aware of in our repositories. I had used things like FindBugs and PMD for Java apps, and the built in linter and compiler is great, but I was curious if there were other tools. Thanks for the feedback though!
Thanks! This is right along what I was looking for. I will check it out!
this is excellent. i'll definitely be trying this out on my next batch of UTs. thanks for not trying to replace the testing package and actually augmenting it in a way that adds value.
Like /u/joncalhoun, we often wrap other packages to make our specific use cases simpler, but for this specific case, we have helper functions to help build requests, rather than a wrapper object. Here's one example: // NewJSONRequest marshals the payload to JSON, adds default JSON headers, allows KeepAlive func NewJSONRequest(c *ctx.Context, method, url string, payload interface{}) (*http.Request, error) { var data []byte var err error if payload != nil { data, err = json.Marshal(payload) if err != nil { return nil, logger.Error(c, err, "NewJSONRequest - json.Marshal Failed") } } req, err := http.NewRequest(method, url, bytes.NewReader(data)) if err != nil { return nil, logger.Error(c, err, "http.NewRequest failed") } req.Close = false req.Header.Set("Accept", contentTypeJSON) req.Header.Set("Content-Type", contentTypeJSON) return req, nil }
You're not obligated to provide support, we'll act as liaison if needed. Thank you so much for maintaining the jwt plugin that helps a lot of people. I hope you'll keep it up!
[removed]
I don't get it. It looks like I could strip out all the it("should do another thing", func() { and just leave the contents of the functions, and still have a test that runs, without the clutter of the BDD stuff. 
"keys that are stable" != "map is stable"
That's a great article, thanks a lot for the effort. I'd like to go through all the code though whenever I have the time
Yes, that's one interpretation of the statement. There are many interpretations. I'm not sure what you're hung up on. The statement is ambiguous as-is.
My use case is HPC, so I generally have a whole system to run my scientific code on. Specifically, I have 200TB of data to process so I want to use as much ram as possible to speed it up - but I don't want to start thrashing!
Matt has reponded https://caddy.community/t/the-realities-of-being-a-foss-maintainer/2728/
And I'm not sure why you claim it's ambiguous.
Absolutely not! This is one of Go's big gotchas; returning a struct when a caller might expect an interface makes nil comparisons iffy. Always return interfaces when your caller might ever interpret it as such. Here's an example of how this can shoot you in the foot: https://play.golang.org/p/RBkfTmRQST Note how 'case 2' can be turned into 'case 3' by some simple refactoring, so even if you start with correct code, it's basically a timebomb to define functions that return like that.
I completely understand this criticism if you aren't familiar with other BDD testing libraries in Go and other languages. The structure is used by practitioners of TDD and BDD to make tests expressive and to serve as a form of living documentation. Similar frameworks include: - Go: Ginkgo, Goconvey - Javascript: Jasmine, Mocha - Ruby: RSpec - Objective-C: Cedar More concretely: The `it.Before` blocks run before each `it` block, with a fresh closure to prevent test pollution. The `describe` blocks allow you to scope an `it.Before` block to a subset of the `it` blocks. The `it.After` blocks run after each `it` block instead of before. This results in less repetition from repeated calls to setup/teardown code. It also helps you write tests that are organized around the behavior of the code you're testing. I empathize with your skepticism of this as something that seems unnecessary. I've seen the combination of BDD process and Go work to keep impressively large code bases (like Cloud Foundry) maintainable, so I personally find value in it. I wrote this as a more idiomatic replacement for Ginkgo.
How's reading in a spiral cleaner than reading from left to right?
The features listed in the readme are not features of `flag`. (I have been using `pflag` so far to get POSIX-style flags - I never got really used to `flag`'s unusual single-dash-long-name style.)
I also did a pubsub implementation, as well as a gRPC and JWT implementation. Maybe it's a bit messy, but you can maybe look at it and see if you or I missed something :) https://github.com/johan-lejdung/golang-prototype
I've been using ST3, with GoSublime and haven't had any issue at all. I tried VSCode for about a week, though one of the most annoying things for me was Go To Definition. If a project has multiple things named the same, Go To Definition will just take you to a random one. Vs showing you the files containing the definition and letting you select which one to jump to, as ST3 does. Oh and also, when opening a file using the navigator panel, it won't search by the path. So if you have multiple files named the same thing, you have to look down the list to find the one you want. Where as ST3 will match the full path. I know they're only minor gripes, but I found them both pretty frustrating. Maybe I just need to change my workflow....
Use [context](https://golang.org/pkg/context/) although this sounds like a really strange edge case bug :s
What does https://play.golang.org/p/razCG09UpL give you when you run it on Windows and press \^C ? It may be you were watching for the wrong signal. I don't have a Windows box to test currently.
I didn't look to closely at the other replies, you might have your answer already. If not the mssql go driver got a good example: https://github.com/denisenkom/go-mssqldb/blob/master/examples/tsql/tsql.go The printValues function is probably what you want.
Hey, there's a lot which can be improved; of course take everything with a grain of salt, maybe you had a specific reason to do it this way; I'll just leave some open questions upon seeing your code: * Why JSON and not something like Protobuf? * Code mapping a struct to/from JSON: You could use json.Marshal and json.Unmarshal if you insist on using JSON. Additionally, if you need to do some specific mapping then take a look at the example [https://golang.org/pkg/encoding/json/#Marshal](https://golang.org/pkg/encoding/json/#Marshal) * The used singleton patterns are probably not what you want. You make it impossible to change any Repository/Storage implementation like that. * e.g. in storage.go you access a map (concurrently). Is it thread-safe. This smells like a data-race you should check. * the code uses log.Print.. pretty much everywhere. What if I want to use a different logger or not log at all? * 0 tests * frame.go looks "complicated", i.e., is there a reason you chose these specific constants? Did you port the code and kept that for compatibility to a different library? Additionally, in this file variable naming does not follow the go specification, i.e., get rid of all the underscores. * Any reason for defining the type EventType? Why not use a string instead?
Hey, I've found two problems. The first is related to security: The chosen encryption/decryption method (XOR with OTP) is of course the best you can do as it is unbreakable. (Side note for none security experts: The keyfile in this crypto system must be transmitted via a secure channel - thus one could send the plaintext via this secure channel instead.) There's one point which your code is not doing: Error checking! This could lead to a problem. You're calling rand.Read which can return an error, but you're not checking for that. Or you're writing a file which might fail (e.g. disk quota exceeded/no permissions/...) and again you ignore the potential errors. You should fix that! Code style: You reference global variables like the flags from within the functions instead of passing them as a parameter. This makes future changes harder to do and especially testing could get more complicated. Finally, make sure to add tests. Should be pretty doable for such a small project :)
`flag` supports both - and -- out of the box. plus if you want short hands you can just define multiple on the same var?
True, but this does not follow the [POSIX/GNU conventions](https://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html). For example, with POSIX style, `-abc` is a shorthand for `-a -b -c` whereas with `flag` it stands for the single option "abc". This is why packages like [pflag](https://github.com/spf13/pflag) or [args](https://github.com/dmulholland/args) (the one announced here) exist.
ah gotcha! cool. perhaps a matter of taste I've always thought of that style being pretty ugly, think I like the pure additive way better instead of "abc" since they are not immediately distinguishible nor easily composable 
A very minor thing. In Go, we try to write less indented code as much as possible. So, we try to avoid the 'else' clause in an 'if-else' if possible. And if there's a lot of cascading else's, we replace that with a switch statement. That makes the code more readable. In your case, it seems you can avoid the else clause in the writeKey and writeEncryptedData function. 
i know academic papers are not usually posted here so thanks for posting this! very informative.
See https://www.reddit.com/r/golang/comments/6x0y5e/announcing_go_language_support_scan_your_go/
Previous discussion: https://www.reddit.com/r/golang/comments/5rj9j5/justforfunc_6_building_a_flappy_bird_clone_with/
Looks like the sponsor header got removed: https://github.com/mholt/caddy/pull/1866
Thanks! 
Tl;Dr Considering Energy AND Time AND Memory these three languages are the most optimal: C • Pascal • Go Page 10 of the paper: https://www.google.com/url?q=http%3A%2F%2Fgreenlab.di.uminho.pt%2Fwp-content%2Fuploads%2F2017%2F09%2FpaperSLE.pdf&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGebt7yzCxeElQH2GzL0DiRWXP63Q 
I would take this with a grain of salt. The toolchains used to compile the examples vary wildly, from 2 years old to current bleeding edge. Quite a few of these compilers and languages have undergone significant enhancements since the versions used in this paper. For Go 1.6 is used which is two years old but in 1.7 a lot of things changed for the compiler. For Swift 4.0-dev is used, the bleeding edge (though I can't find at which commit). The C examples are compiled with a year and a half old GCC with `-O3 -fomit-frame-pointer`. The dotnet release used is similarly a year old and one whole major version behind. Though the results are interesting I'd expect for all these the latest stable release of each compiler to be used at the point this comparison was made. This does not appear the case since dotnet 1.0.1 became available after the release of Go 1.7 and at that point in time GCC 6.2 was availabe too. PHP 7.1.4 was release in April of this year (which would put Go at 1.8 and GCC at 6.3) . A year is a long time in the evolution of certain programming languages and many are constantly refining their compilers with new optimisations and adding usage of newer instructions, which affect exectuion speed and energy consumption (though not always in a positive way). It would also be really interesting to see the C example results with both GCC and LLVM/clang. Something else, the paper claims to use Python 3.5.2 but the benchmarks have it using 3.6.1.
Did you find Goblin in your research of similar libraries? What are the main differences between Goblin and spec?
&gt; * Why JSON and not something like Protobuf? &gt; * Code mapping a struct to/from JSON: You could use json.Marshal and json.Unmarshal if you insist on using JSON. Additionally, if you need to do some specific mapping then take a look at the example https://golang.org/pkg/encoding/json/#Marshal *Add as new feature: protobuf (as optional)* &gt; * The used singleton patterns are probably not what you want. You make it impossible to change any Repository/Storage implementation like that. &gt; * e.g. in storage.go you access a map (concurrently). Is it thread-safe. This smells like a data-race you should check. &gt; * Any reason for defining the type EventType? Why not use a string instead? &gt; * Additionally, in this file variable naming does not follow the go specification, i.e., get rid of all the underscores. *These was decisions in java-thinking style (thanks! this require more experience in go. putting in the next review)* &gt; 0 tests &gt; frame.go looks "complicated", i.e., is there a reason you chose these specific constants? Did you port the code and kept that for compatibility to a different library? *The docs and tests was removed* &gt; * the code uses log.Print.. pretty much everywhere. What if I want to use a different logger or not log at all? **Please, explain more!**
Thanks for the suggestions, but I have tested this. ctrl-c from a command prompt does send sigint, but I tend to use mingw64 git bash because I like access to so many utilities in 1 terminal :) Any serious dev would be done on linux so its a non issue, but I am also concerned about the program crashing at some point and leaving behind a million goroutines in the background - because my project is a pointless simulation to strengthen my concurrency knowledge. 
Thanks, that looks useful! However, some testing shows that sigkill doesn't exactly terminate the main thread, so the code I'm using as a sort of keepalive with that timeout context would still be there. If a golang process **crashes**, is there a panic that will kill the child processes? What even causes a kill signal? Maybe I shouldn't worry about this since I will be able to catch ctrl-c if I get over my preferences and run a regular windows terminal :P = And yea I have a crappy little $300 machine dedicated to stuff like this. I'm going to use all available resources on it to create as many routines as possible and each one will be a primitive ai and they will use mutex synced objects to interact with common resource and substract/add to those resources. It'll be like a colony of primitive organisms :D I don't know if anything useful will come out of this, but it's amusing. ctrl-c will be sufficient, 1 goroutine can watch that and set a flag / panic to shut off the rest of them. --edit: Oh and just to make sure I understand - is context a light weight alternative to passing a channel to a goroutine for signaling? For example, I've seen lots of examples for control signals where you pass 1 channel along for receiving data and 1 struct{} channel for control signals. I think that "withvalue" context might serve the purpose people usually use a struct{} channel for to tell the main thread that a goroutine did a thing. 
There's a lot of things to unpack here and it's not clear to me everything that's going on. First, go has "goroutines". If you happen to call them "threads" every so often it isn't that big a deal, plus I still see the phrase "thread-safe" used sometimes, possibly because "goroutine-safe" is just a kinda klunky phrase. But it's important to be clear that they all live in on OS process, so there's no way for goroutines to be living on past the termination of their host process. Second, there is no way to "kill" a goroutine. You can only write code that will cause them to eventually kill themselves. So for instance if you have goroutines doing some calculation in a tight loop without ever "looking up", the only way to control them is to modify them to "look up" for the sign they need to kill themselves every so often. If they need to be able to checkpoint their calculations or something, you have to write that in yourself. The most popular mechanism is to have a channel that gets closed, then using the checks on channels being closed to see if the process terminates. However, there's nothing necessarily special about that; channels are used in the default context package (referenced by TheBeasSneeze) because they work well in a context where the core thing being done is a `for { select { ... } }` loop, but anything that allows a goroutine to "look up" and see they need to stop works. Just be aware that if you're trying to get a whole bunch of goroutines to use the same signal you need to start worrying about the contention on the signal itself. (One of the things about using Go that took me a while to accept is that it's fine to take a channel, which has a whole bunch of behaviors, and use them for just a part of that behavior, like whether they are closed, or sending down `struct{}`s to just use them for their syncing, or whatever. The existence of a channel does not obligate you to use all of its functionality.) The other problem here I _think_ is that you either have a bookkeeping issue, or a major runtime flaw in your environment that is the real problem. The duration of a Go program's OS process is [specified to be the duration of the initial goroutine that executions the program's `main` function](https://golang.org/ref/spec#Program_execution). Once that terminates, the OS process terminates. There is no way that goroutines can continue running in the background for very long past that, and even if you are able to witness some side effect that says they are continuing to run, the process is still on its way down and nothing can be relied on after that. I would carefully check your bookkeeping in the main routine, and whatever else it uses, and ensure that you do not accidentally end up running some `go` somewhere that accidentally moves the logic of what you thought was the "main" program into a new goroutine, while the original goroutine gets frozen into waiting on something. (This is pretty easy to do with closures.) Alternatively, if you can create a reduced test case that _proves_ that under your environment program execution and other goroutines can substantially outlive the original goroutine, the only logical and correct move is to submit that as a bug to the Go bug tracker. This is the kind of bug you do _not_ want to try to just bash around in your client code. Trust me. This is one of those cases that once you're sitting on top of a substrate acting incorrectly, the stuff sitting on top of it simply can not properly "fix up" the underlying layer. I can assure you that the bug will be taken seriously. (I can't promise it will be immediately fixed or whatever, because there's other concerns and issues that arise there. But I am confident it will be taken quite seriously.) I kinda doubt this is it, but if it _is_ the problem it's a huge one.
Alright will do! The global variables we're just from when I was learning how to use that package! But it's just pointers so it shouldn't be that hard! Error checking should have been something I've done on the fist place , thank you for catching that! When you say write tests do you mean like a bash script or something else, sorry I'm new to this ...
I'll refactor my code and try to keep this in mind thank you!
Main differences are: 1. Spec is a wrapper for Go 1.7+ subtests. 2. Spec provides completely fresh closures for each subtest run. 3. Spec doesn't encourage the use of dot-imports. 4. Spec doesn't provide assertions, or do anything that `testing` already provides. 5. Spec has cleaner and more flexible syntax (ex. you can call a group whatever you'd like). I am not aware of any other testing libraries for Go that are similar to spec.
I was talking about unit tests with *go test* command. https://golang.org/pkg/testing/ With that you can check if for example the encrypted plaintext will decrypt correctly, etc.
Glad you like it! Don't hesitate to open issues if you have feedback :)
I hope you only refer to the last part where you want more explanation. Consider three example situations that might come up if someone is using your library: * You don't want to have any log output written by your library. To achieve this right now, the developer has to step through all lines of code and remove any call to log.Print/log.Printf and so on. There's no way for the developer to disable logging entirely. * A developer wants to have log output but the format used by the standard go log package is different from the one used in the remaining application. Again, to fix this behavior the developer needs to check all lines and replace each with his own logger implementation. * A third developer wants to leave everything as is, but instead of logging to stdout he wants to log to a specific file. Again, this could involve changing the code. There's a simple fix to this problem. Instead of depending on a concrete logger, you use an interface. Read this and have a look at the third code example. https://dave.cheney.net/2017/01/23/the-package-level-logger-anti-pattern By using an interface, the developer can achieve any of the 3 scenarios without any changes to your library.
&gt; Second, there is no way to "kill" a goroutine. You can only write code that will cause them to eventually kill themselves. I did this with a panic, I think. I set a handful of goroutines to print to the console on a loop forever with no termination, and then I had another goroutine wait 5 seconds and then panic for no reason. This killed every goroutine started by the main process. My issue is I have no idea how to determine if the main / parent process is still running or not since we can't observe sigkill. &gt; The most popular mechanism is to have a channel that gets closed, then using the checks on channels being closed to see if the process terminates. However, there's nothing necessarily special about that; channels are used in the default context package (referenced by TheBeasSneeze) because they work well in a context where the core thing being done is a for { select { ... } } loop, but anything that allows a goroutine to "look up" and see they need to stop works. Just be aware that if you're trying to get a whole bunch of goroutines to use the same signal you need to start worrying about the contention on the signal itself. The issue for me is that the goroutines are watching a value that is being decremented. They all break when it is 0, and they take turns decrementing it, but in the next phase of the pointless project some goroutines will be adding to it. I'd like some way to kill the processes for that reason because the point of the pointless venture is the thing they're watching to know when to die will be ever changing. &gt; Once that terminates, the OS process terminates. There is no way that goroutines can continue running in the background for very long past that, and even if you are able to witness some side effect that says they are continuing to run, the process is still on its way down and nothing can be relied on after that. I'll get a code sample to demonstrate the issue. Maybe that'll properly emphasize the terrible design is the purpose of the project ;) Thanks for taking a look! Took a few minutes to recreate it from memory, but here you go! https://play.golang.org/p/60ucZvDhEA I'll add this to the main post as well so some people can give me some help after telling me how pointless my idea is.
My perspective: you say a lot of things, but don't really address the criticism at all.
There's a tool called gocyclo that can help you keep track of that. It scores each function and method for cyclomatic complexity. The generally accepted target seems to be a cyclomatic complexity score of 15 or less. 
Here is an [example](https://gist.github.com/cstockton/77e38b16999f382fa0ef3060d785413a) I made some time ago with a signal handler added. Though in general you should avoid trapping signals, if you do and the intent is using it as a synchronization mechanism it's a strong indicator of a design issue with the program. As for everything else a few general concurrency rules that I follow which can apply to most programs to help ensure they are correct: - You should always have a top level context in main, even if it's context.Background() - This context should be given to all function calls that perform long-running tasks, they should always have at least this signature: func(Context) error, so they can cancel work when context is done and report a error to distinguish task failure from cancellation. - All functions that create other goroutines should always follow the rule above, but never exit until all goroutines they have created have exited. There are exceptions to these rule at times, such as creating a service that can start/stop that runs workers and in those cases I ensure that Stop() does not return unless the goroutine started by Start returns. The general theme here though is you always "close the loop" so to speak, any call site that starts a goroutine is responsible for ensuring it exits. Golden rule: work is done when the call returns. If you start goroutines and try to join on a condition that is _not_ them returning to their callers programs get very difficult to debug. Without seeing code it's hard to know what you're running into, but maybe these rules may help.
Okay- so the main issue here is you do not have clear program flow, you are using conditions and synchronizations to "signal" exiting rather than the natural way you do when writing software: returning to your caller. This problem could be solved following the general rules I posted in my other reply, key take away being context.Context, [errgroup.Group](https://godoc.org/golang.org/x/sync/errgroup) and indicate task completion by returning to caller.
Maybe a less pedagogical example would better demonstrate the value. [Here's an example of Ginkgo used to test Guardian (a containerization daemon used by Cloud Foundry)](https://github.com/cloudfoundry/guardian/blob/master/gardener/gardener_test.go). The criticism (that stripping out the structure would result in working tests anyways) reflects a lack of understanding of how these tools work. In general, if you remove the structure from real tests written in a BDD framework, you would end up with broken tests. As I mentioned, each `it.Before` is run before each `it` (not before all of the `it`s). 
I've started using chi in my project: https://github.com/urandom/readeef/blob/2.0/api/api.go#L260 The chi usage is pretty much done now
I appreciate the repost, first time I've seen this!
yup it did :)
If you decide to give it a try, it would be nice if you would implement the terminal with complex text formatting in mind (ligatures, arabic script). This is not handled correctly by gnome-terminal or all the other vte-based terminals (see [vte bugzilla](https://bugzilla.gnome.org/show_bug.cgi?id=584160)).
Took your advice and added it to the repo!! (: Thank you!
I see, I eliminated the redundant else staments and updated the repo, thanks alot!(:
Always annoys me when people don't add units to a table or graph; it just shows "energy". Is Watts? Jouls? Sugar cubes? Elephants? crushed dreams?
I just made a post a little bit ago that may [help](https://www.reddit.com/r/golang/comments/70fjlm/kill_child_goroutines_on_sigkill_detect_main/dn37mc2/), here's the [example](https://gist.github.com/cstockton/77e38b16999f382fa0ef3060d785413a). You could start by editing he Worker func to "fetch" and change the channel to be a structure that contains a []byte field of image data as well as a field the result collector can use to correlate the byte to relevant metadata or embed the metadata directly if it's just a x, y coord. Then instead of appending to alphabet you would just applyOnCanvas.
It makes sense to wrap ALL non-application packages in your own, IMHO.
Ncurses maybe? 
oh wow i didn't realize that, that's horrible.
To be fair, new people come in to the sub all the time looking to learn through examples and tutorials, and others still to learn about new projects or ideas they haven't heard about before. Maybe OP got in to Go more recently or the sub, found this video, and wanted to share it for others who may be interested. 
I'm not entirely sure what you are looking for, but have you had a look at [go-prompt](https://github.com/c-bata/go-prompt)? It is serously cool!
When the main program (thread) exits, all goroutines immediately go away. You don't need to detect anything and don't need to notify any goroutines. This is how go works. (And Linux does so that on SIGKILL the process goes away without any opportunity to do anything.) I don't see how your playground link demonstrates that goroutines continue running. Take a simpler example: https://play.golang.org/p/D1k-k0Vox7 When the main process exits, the goroutine stops printing. 
I take it back. Maybe I don't want a rich interface after all. I'd be happy with just menus with number/letter selections. go-prompt looks great but overkill for my case.
Agreed. Go has many annoyances but the fact that's a simple language that does most things reasonably well is THE appeal of it. 
Go natively crosscompiles. Zero bullshit language. Get your rocks off with Go, and let future generations bleed performance margins when they eventually replace those sexy goroutines with Rust smartpointers.
&gt; The chosen encryption/decryption method (XOR with OTP) is of course the best you can do as it is unbreakable. (Side note for none security experts: The keyfile in this crypto system must be transmitted via a secure channel - thus one could send the plaintext via this secure channel instead) Hi, security expert here. This is inaccurate, while xor is one of the primitive building blocks for secure block ciphers by itself it is absolutely insecure. I can go into the details if you would like, but the key can be revealed fairly trivially. It lacks the most basic properties of a secure cipher, confusion and diffusion. So patterns emerge in the cipher text for some inputs that expose the private key. So really no one should use this for anything beyond a thought exercise.
What a stupid question to ask. Go and rust are two fine languages with different strengths and weaknesses. Which one you should use depends entirely on what you plan on using it for.
This is a go article go to a python one if you want bells and whistles :)
I would choose Go if I'm going to do with something that relates web. But I'll choose Rust if I'm going to write some system-based(like a file system) stuff. I think both are not comparable, they are doing the different things.
What I see is just setup and teardown functions around an unintuitive, frustratingly mock-oriented, and extremely un-Go-like, way of triggering actions and checking the results. I'm sure you cannot be seriously claiming that only BDD allows setup &amp; teardown. I'd write an example of how to implement your example without BDD, *but its use of BDD is obscuring what's happening* so I can't be bothered. And that is my real criticism of BDD.
&gt; But I'll choose Rust if I'm going to write some system-based(like a file system) stuff. &gt; Why? What does Rust offer for interacting with the filesystem?
I believe the intent was that Rust would be better to _implement_ a filesystem. Which I would strongly agree with.
&gt; Though, Matt has decided to remove the header in Caddy itself. Is there a source for this? I'd be very interested to hear why.
Have you even opened the academic paper? It fully details everything in the online appendix 
A few thoughts I'd like to mention. Before that however let me say I agree with a lot that he has said in the article. Things I don't agree with as arguments (these are just my opinions): &gt; these guarantees come with a cost: ramp-up time. You'll need to unlearn bad habits and learn new concepts. It takes maybe a day to get through the rust book and you get used to the patterns involved with the memory model after a week. After that all the hard work is done and development is pretty smooth minus some common mistakes. Remember that compile time errors are pretty quick to fix usually. One can say that the concepts in golang are extra cost from the other side so keep it in mind. This works both ways. I had to teach a python developer golang for a set of projects and it took him 2 weeks to ramp up. Is he dumb since golang is so easy? No it's just that it's different. You won't be a rust expert in a week but you will be productive. You should be doing this for ALL technologies. Always be learning imo. Don't use ramp up time as an excuse to be a one-trick pony. &gt; Go is one of the most productive languages I've ever worked with An opinion is fine, but just remember that it is an opinion. It's more productive for him at his current level of experience this depends on what you do for work, and the previous language experience you've had. A front end developer might just as well say upon learning backend programming that node.js is the most productive. And as for solving problems today? We are programmers. We all solve problems today. Unless you are only writing simple tools or apps (would be nice were it so easy), even golang projects take multi-day development with testing and proper documentation). I just get a bit tired of authors artificially creating ultimatums in language choice. Sure he says at the end that both work great together, but tell us more about that instead, please. There are already tons of these golang vs rust posts. Golang is cool. Rust is cool. C is cool. Python is cool. Assembly can sometimes be cool. They all have different perks and when you break away from just sticking to one you get the benefits of all.
I'm definitely not claiming that only BDD-style libraries allow for setup and teardown code. That's obviously not the case. I'm just explaining how BDD-style testing libraries work -- you can't just remove the structure and expect the rest of the test code to work the same way. I'm proposing spec as a cleaner, more idiomatic alternative to other BDD libraries for Go. If you don't like or use this type of library, then spec is not for you. Feel free to disregard this post. For what it's worth, I don't believe that BDD and idiomatic Go are incompatible. It's a valuable process that many large, real-world Go projects use.
&gt;Both languages seem to be competing for the same user base and they both seem to be "systems programming" languages ...uhh not really. &gt;Go is not a systems programming language. Lol
Other than "What a stupid question to ask," you paraphrased the article.
I would move the encrypt/decrypt functions into their own package.
&gt; This is not at all a comprehensive list of reasons to choose Rust. He didn't claim to be. &gt; "Choose Go" because it lets you maintain your bad habits and avoid learning things. That doesn't seem like a good reason. It might not be a *good* reason, but it is *a* reason. All easy-to-learn languages (including Go) have the unintended side effect of making it easier to write bad code. &gt; I feel like a lot of people on this subreddit would disagree with that statement strongly. Only those who don't know [what systems programming is](https://softwareengineering.stackexchange.com/questions/151610/what-exactly-is-system-programming). Rust is a language *designed for* systems programming. Go is a language where you could do *some* systems programming tasks, poorly (compared to Rust).
Ok, that makes more sense ... but I'm still somewhat skeptical. I can see how Rust code might be much more likely to get into the kernel than Go, but that also feels more like the difference between 0% and 1%. As for "userspace filesystems", it's not even obvious where to draw the line anymore. Does syncthing count? keybase? upspin? Looking at https://github.com/trending/rust and https://github.com/rust-unofficial/awesome-rust#applications-written-in-rust doesn't show anything of that nature (indeed most of them I'd assume would be better written in Go, but I have little Go experience and much less Rust ... hence the questions).
I expect it wouldn't surprise too many programmers that filesystems are non-trivial bits of code. But I think many programmers who haven't dug into it will be shocked at just _how pissy_ filesystems are. It's one of those bits of code where it basically has to be _better_ than perfect. It's going to be run quintillions of times and every possible failure case that could ever be dreamed up is going to happen to it. It has to be able to recover from hardware failures as gracefully as possible. Oh, and people like them to be blazingly fast, too. Every constraint in that case that you can offload on to a compiler at that point is a win, and Rust will let you offload a ton more than Go can. Yes, most or all filesystems right now are written in C or C++. Most or all filesystems also spend an embarrassing amount of time working through issues that Rust would have caught at compile time in their early development, before they even have time to start working through the fact that the hardware basically hates them and want their data to die. Yes, I'm an unapologetic member of the "Rewrite It In Rust" squad. C should be considered a dead language and _at best_ a last resort for any serious code base, and every major C code base with _any_ exposure to correctness or security issues should be looking at how to get off of C. (Rewriting [C programs] In Go is still definitely a nice improvement, though, as long as you can afford the additional execution time and memory pressure. Also I consider "C + a suite of the best static analysis tools money can buy" to be a distinct sublanguage of its own.)
Go *has* tried to market itself as a Systems Programming Language, and in some cases still does. The problem is the ambiguity in what "Systems Programming" means for Go, and what it means for Rust/everyone else.
Lol, why? Each has its strengths. Use the right language for the right task. And do not try to solve every problem with a single language, even though it might be possible.
Very cool, thanks for sharing
How dreadful, being allergic to the most popular language on the planet :-)
I hate its API, even find it harder than C, but when it comes to Go, assuming that I know rust, I'll think twice before making a choice
I'm sorry but practically nothing that I've seen in that source is idiomatic. I would further propose that you are not a good judge of what's idiomatic Go ;) If you want to do further advocacy, please show concrete short examples comparing your style and stdlib Go style ("idiomatic Go") side by side, and *show* what you think is so hard to do without your framework. Everything else just comes across as you repeating your opinion (Sorry!).
Go is not simple. It's simpler than rust sure but not as simple as Kotlin, Crystal, Swift or a dozen other languages.
Where did you get the auth?
&gt; the problem is the ambiguity in what "Systems Programming" means Exactly. Go can be low level enough to write a programming language, a memory allocate, etc. I wouldn't write anything that has to be "fast" (ie, a kernel), or real time. But, it can do lots of low level stuff, while still being productive.
The Go documentation explicitly calls Go a systems language in its FAQ, but I think at Google, "systems" has a different scope. They should probably have called it a "web systems" language or perhaps a "distributed systems" language.
How is this even a question? Rust is a mess.
What do you mean? Authentication is your email and password
Here is the original source: https://github.com/mholt/caddy/pull/1866#pullrequestreview-62939772 Matt also published a blog post with more explanations about the story.
Read the article people.
You mean JS? https://stackify.com/trendiest-programming-languages-hottest-sought-programming-languages-2017/
If one is passing around pointers than one should be checking for null pointers. Manual work and more LOC (just like Go error handling) but pretty simple to deal with. Go race detection seems to be pretty strong, so it's not without virtue there. I don't use Rust and I'm sure it's a fine language but I think the contest there isn't that much of a big deal.
What is a mess specifically? 
Thanks! Amazing observations!
Well said. We use rust and go at work. Go for our web infrastructure bits and Rust for domain specific code. Our choice to use Rust is for its type system.
[The 2017 Top Programming Languages](https://spectrum.ieee.org/computing/software/the-2017-top-programming-languages). How many of the current new kids on the block will still be going strongly after 25 years?
Go needs a garbage collector and isn't compatible with the c calling convention. This makes it highly unlikely to wind up in the kernel. Fine for user space daemons tho
&gt; I'm sorry but practically nothing that I've seen in that source is idiomatic. That Guardian test file I linked uses Ginkgo, not spec. I provided it as an example of BDD-style testing to help you understand how this type of tool works. That test file doesn't reflect my own opinions of "idiomatic Go" -- that's my whole point here: I wrote spec as a more idiomatic alternative to Ginkgo. &gt; I would further propose that you are not a good judge of what's idiomatic Go ;) Check out the source for spec itself. My own style is somewhat similar to the standard library. &gt; show concrete short examples comparing your style and stdlib Go style ("idiomatic Go") side by side, and show what you think is so hard to do without your framework. As I've stated repeatedly, I am proposing spec as an **alternative to existing BDD-style testing libraries for Go,** not as an alternative to the standard library testing package. The standard library testing package is great by itself, and I use it that way for many of my own hobby projects. However, BDD and other agile programming methodologies are widely used by many tech companies that have standards for developing business-critical software products. I didn't post here to debate the value of BDD. If you have any meaningful, constructive criticism of my library, I'm happy to hear it. If you just want to argue against BDD in general, I suggest you pick up a book first (I recommend *Extreme Programming Explained* by Kent Beck) and then head over to /r/agile. 
The clickbait misleading title doesn't help.
Indeed, Go was assumed to be 0% to make it in the kernel ... Rust I optimistically put at 1%.
Thanks.
When people say that Go is complex, I always point them out to the short and readable [language spec](https://golang.org/ref/spec) and I tell them that there's no sugar syntax and how simple it is to get a development environment up and running across different platforms. What do you find more simple in those languages?
I find it a bit interesting that the Fuschia team is writing their network stack in go: https://fuchsia.googlesource.com/garnet/+/master/go/src/netstack/
I don't really feel like reading through 12 pages of text just to find out what scale the tables are in; not that curious. Sorry :-( There is a link to "[2] Complete Set of Results" which has the tables without units for energy and time. If you're to publish tables like that without context then you should also add basic info like that. Otherwise it's kind of pointless to publish the tables, or can even be harmful in some cases as the results may get misinterpreted.
This is a library I wrote for my last job. It does exactly what you're asking for below: https://godoc.org/github.com/juju/juju/cmd/juju/interact Especially check out the Pollster type. It's for asking a user for information, you can give it a list of options to choose from, etc I don't recommend importing that library directly, instead fork it into your own repo, since I wouldn't trust it to stay stable (you may also want to remove the jsonschema query... it brings in a ton of code that you likely don't need).
I know this a Go subreddit and it's super positive towards Go, but couldn't the same things that were said in this article be said about Python? &gt;With Python, you get things done fast. Python is one of the most productive languages I've ever worked with. The mantra is: solve real problems today. &gt; I don't think Python is an elegant language. Its biggest feature is simplicity. Python is not even a systems programming language. While it's great for writing microservices and tooling around backend infrastructure, I would not want to write a kernel or a memory allocator with it. Okay that part is pretty specific to Go because of the standard lib. ... &gt;99% of the time, Python is "good enough" and that 1% where it isn't, you'll know. And then take a look at Rust, because the two languages complement each other pretty well. This all sounds pretty accurate to me. It actually applies even better to JS.
I choose PHP! ... I'll get my coat.
Thank you very much. I'll have to evaluate the license as I think it's a viral one and I might not be able to bring the code under my project but in either case I want to thank you.
Go is great for network stack stuff. Very solid choice IMHO
First of all it's not simple to get going because of the silly GOPATH thing. Also the language spec has nothing to do with developer experience. From a developer's perspective go is more complex to learn and use than python, ruby, kotlin, java or C#. All of languages have a sane package management system for one. Go is a "meh" language. A weird little language full of idiotic quirks and silly demands on the developer. It's overly verbose and all go codebases quickly devolve into being 70% boilerplate and error handling. As a language I would certainly put it on the lower end of the scale. What Go does have going for it is a great compiler and a huge corporation behind it. 
&gt; Go race detection seems to be pretty strong, so it's not without virtue there. Have you heard about race ~~detection~~ prevention in rust? It is done *at compile time* and does not even need tests to (potentially) catch the races. Seriously, have a look at this beautiful article: [Fearless concurrency with Rust](https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html)
Hahaha, well, I disagree with all that you said except the silly GOPATH but I feel like objectively explaining it to you would likely be lost since it seems you already made up your mind.
I just want to comment on this one point you make: &gt; It takes maybe a day to get through the rust book and you get used to the patterns involved with the memory model after a week. For me the memory model was fine and easy to grasp. However getting to understand the syntax, the middle system, the generics and the way around docs took at least a week. You might say it's fine, but it is not. Rust is my ~8th language I've tried learning seriously, and I've been doing professional programming for quite a while now. The language should not take that long given the strong foundation that I [supposedly] have. I have friends, who are just trying to get into programming. They are overwhelmed by the rust book, and cannot navigate in their own at all. Languages like python, go, or even Java come to them much easier. This is bad for rust. Being this noob-unfriendly means there language is at the risk of dying. Look at how Erlang it Scala are doing - rust might find itself in the same spot several years from now. &gt; I had to teach a python developer golang for a set of projects and it took him 2 weeks to ramp up. Try teaching Rust to a (non-genious) non-C/C++ dev to see what I mean. It's nigh impossible.
Thanks for writing, I especially like the section on adding timeouts and shutting down cleanly. In the Plumbing section, I think you want 'continue' in the Accept error handling In Handler, I typically see the for loop of using a scanner written as: for scanr.Scan() { which makes the internal logic cleaner 
ThinFS is an implementation of a FAT filesystem in Go:https://github.com/fuchsia-mirror/thinfs
There's already a rust os kernel. So technically, rust in the kernel, 100%. It's just not the Linux kernel.
Looks nice. You shouldn't use GOPATH directly though, for example in `find $GOPATH/src/$cur*` and a few other commands. The problem is that GOPATH works like PATH: it's a colon-separated *list* of pathnames. I have mine set to `$HOME/go:$HOME/work`, as I would like to keep the various `go get ...` packages and actual work-related code separate. It's also a good idea to add quotes around pathnames (`find "$GOPATH/src/$cur"*`), otherwise stuff will break with spaces and such ;-)
Also discussed here: https://www.reddit.com/r/golang/comments/707iy0/merged_revert_implement_caddysponsors_http/
exercism.io
Thank you for reading :) You're absolutely right about the missing `continue`. I've added that in. I'll leave the scanner loop as-is since I prefer it that way.
I guess that the Caddy authors did not expect this to be such a controversial change. Personally, I'm not a fan of such a header, but I don't see the problem it either. In the world of pervasive ad tracking without informed consent and companies that literally sue nations' regulators for the "right" to track people (like Facebook did in Belgium), I consider this to be one of the least invasive forms of advertising.
"article".
&gt; After that all the hard work is done and development is pretty smooth minus some common mistakes. Only if you stick to straight forward data structures. Anything complex, and you'll spend another week before introducing "unsafe"...
I wrote it elsewhere, but if you compare JavaScript and TypeScript and one scores 6.5x and the other 46.2x, there's something terribly wrong in your benchmark.
CHAOSFISCH specified OTP. A one time pad cannot have patterns because it is only used once. If you do have ideas how to break a (proper) one time pad, I'd love to hear it.
Oh is that how they tie down the API? You never registered and got a API key or Token it is just using any N26 username/password?
"Basic YW5kcm9pZDpzZWNyZXQ=" I googled that and it shows up in your project and https://github.com/njuettner/n26/ which is what you copied right?
I don't think you could have misunderstood my point more. For starters rust definitely isn't a good first language. We are talking about seasoned programmers. Second my point isn't that rust is simpler. My point as I thought I clearly summarized at the end if the paragraph is that one should not use ramp up time as an excuse to disregard a language's benefits or uses. If you don't need those benefits then sure, ignore it and move on. However for those with systems programming familiarity, one week was a fair estimate imo. Btw the rust community is very helpful and the people are awesome. If you are struggling send a message their way and they will help you out with anything you have questions on.
It is a bit strange you need "Project Euler" alternative without much math. Euler. Without much math.
Didn't notice the OTP when I replied, it's well understood OTP has proof of perfect secrecy so I won't challenge that. But I would certainly challenge using OTP as a anything beyond a learning exercise as I stated in original post still because the proof requires cumbersome constraints. So why use it when it's long been superseded with superior schemes free of these constraints is my point here.
Might be a stupid question, but I do hear it being asked a bit at work. However I don't think both languages are aimed at the same userbase at all and I don't really see both as systems programming languages, Rust is more a systems programming language, Go is more suited for writing network services and webapps.
Yeah, thats it! At least for now
Hmm i got it from here actually: https://pypkg.com/pypi/n26/f/n26/api.py (not exactly this website but from this python api)
I think that is supposed to be unique and links it back to each dev that calls into the API.
There's also bootgo and gopher-os. So technically, Go in the kernel, 100%.
Probably yes, but it doesnt seem to matter at this point. It can be anything https://github.com/timoschlueter/number26-unofficial-api
I think OP means like programming challenges without the mathematical side of Project Euler, which has some challenges that without the mathematical knowledge of the subject can only be brute forced
The shutdown code seems racy because there's no synchronization between the goroutines running `(*Server).Shutdown()` and `(*Server).ListenAndServe()`, but the former writes to the `inShutdown` field and the latter reads it. The usual way to handle this is with a `chan struct{}` that `Shutdown()` closes and `ListenAndServe` checks with select { case &lt;-srv.inShutdown: return nil default: } but in this case you don't have anywhere to initialize the channel that wouldn't create a race condition by later trying to close it, so using the existing mutex might be easier. Running the server in the race detector (`go run -race main.go`) to verify, it found two more. The first is on accesses to `srv.listener`, between the same two goroutines but with read and write reversed. The last is between the `net.Listen()` in `ListenAndServe()` and the `srv.listener.Close()` in `Shutdown()`. The first would be easiest to fix by using the mutex you already have: srv.mu.Lock() srv.listener = listener srv.mu.Unlock() and srv.mu.Lock() srv.listener.Close() srv.mu.Unlock() which also fixes the last one because `srv.listener` is initialized after `net.Listen()`. (Though you probably also need to handle the case where the `Shutdown()` is called before `srv.listener` has been initialized, so add an `if` in there) --- In addition, your timeout code seems vulnerable to a [Slowloris](https://en.wikipedia.org/wiki/Slowloris_(computer_security\))-style attack where the client sends a byte at a time on each of many connections to keep them from timing out. To mitigate that, it might be better to have the timeouts be per-request/response instead of per-read/write by setting the deadlines in `handle()` before the first read operation (`Scan` in this case) and the first write operation (`WriteString` in this case).
**Slowloris (computer security)** Slowloris is a type of denial of service attack tool invented by Robert "RSnake" Hansen which allows a single machine to take down another machine's web server with minimal bandwidth and side effects on unrelated services and ports. Slowloris tries to keep many connections to the target web server open and hold them open as long as possible. It accomplishes this by opening connections to the target web server and sending a partial request. Periodically, it will send subsequent HTTP headers, adding to—but never completing—the request. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Ah nice. Cheers. 
It doesn't look like the homepage is loading the correct CSS if you visit via https (which is the link that was posted on Reddit), the rest of the site looks fine but that is because it is switching back to http when you navigate the site, what is up with that?? You should probably just redirect all http to https and setup HSTS, because serving up two versions as you have now is a bit weird and is going to confuse people. https://www.gonum.org/ vs http://www.gonum.org/ 
I think that has more to do with what you're doing. If I look at unsafe, according to godoc about 11.400 packages import it. That seems like a lot, but then consider fmt is imported by 282.000 packages. So roughly 4% of GoDoc indexed code uses unsafe, by this relatively unscientific metric. Once we start looking at the unsafe usage, a lot of it is in things that provide C bindings or call out to C, FFI like support or interact with OS primitives (such as storage drivers or the graphics layer), which makes a lot of sense. Not a lot of that usage seems to stem from "complex" data structures.
I was referring to Rust: complex data structures first make you break your mind and then force you to use "unsafe".
Do the math. Your future self will be thankful.
'Some' might be a little lenient, I believe it's more like at least half
Ah sorry, I understood it the other way around.
Ah sorry, I understood it the other way around.
Ah I apologise. I understood it the other way around. It seems strange to me though that so much in Rust would rely on unsafe, considering all the work they've done to build a much safer, verified at compile time, language.
Ah I apologise. I understood it the other way around. It seems strange to me though that so much in Rust would rely on unsafe, considering all the work they've done to build a much safer, verified at compile time, language.
You don't have to explain it to me. I have typed in enough lines of go to be intimately familiar with it. Try some different languages and then go back to go to see what I am talking about. I suggest you start with Crystal.
Hi! I'm an author of go-prompt. Thank you for your consideration. How about [survey](https://github.com/AlecAivazis/survey)? I've never used this, but looks interesting.
Direct Github link - [https://github.com/olliecoleman/alloy](https://github.com/olliecoleman/alloy). I've been working on my first non-trivial project using Golang. I've extracted this starter template from that project. This does not aim to be a web framework but is instead a collection of useful libraries and packages that you can use as a base to build on top of. A quick rundown of the major packages used - * go-chi/chi (routing) * lib/pq, jmoiron/sqlx, markbates/pop/nulls, pressly/goose (database) * gorilla/sessions, gorilla/csrf, gorilla/securecookies (login/signup) * markbates/refresh (recompile app on file change) * microcosm-cc/bluemonday (display HTML) * pressly/douceur, gomail (sending emails) * pkg/errors, satori/go.uuid, spf13/cobra Let me know what you guys think.
Thanks for reporting the issue. Working on it.
Awesome analysis :) The racy code was intentionally left racy. The example will work fine despite the race due to the polling/loops. Also, twas' supposed to be an exercise for the reader. The Slowloris stuff was amazing. It's so simple once you're told about it. The approach I would take is slightly different. I see the `net.Conn` timeouts as protocol level timeouts that should remain as-is. We should add the Slowloris protection in `handle` as you rightly called out. Here's my implementation of Slowloris protection: sc := make(chan bool) deadline := time.After(conn.IdleTimeout) for { go func(s chan bool) { s &lt;- scanr.Scan() }(sc) select { case &lt;-deadline: return nil case scanned := &lt;-sc: if !scanned { if err := scanr.Err(); err != nil { return err } return nil } w.WriteString(strings.ToUpper(scanr.Text()) + "\n") w.Flush() deadline = time.After(conn.IdleTimeout) } } I would love a review from you :)
nice catch! turns out OP didnt even bother to test his code against the race detector. ironic for a server thats advertised as running like "clockwork".
there no such thing as benign data races.
My issue when testing this is that it could not capture sigkill. If something terminates the program that way, those child processes keep going.. --edit: this appears to be a bug with mingw64 on windows 7. Will update tomorrow afternoon with proofs. Looks like a non-issue since sigint stops child threads on a proper OS. --edit2: that's worded poorly. Sigint always (usually?) stops the child processes, just need an environment that sends sigint when you ctrl-c. 
&gt; Okay- so the main issue here is you do not have clear program flow I wanted to do a little primitive organism simulation with each having its own *thread* to act on instead of iterating over them like most games would. It's designed strangely but intentionally. = &gt; indicate task completion by returning to caller. The program terminates when the counter is zero. Or in the eventual end goal of this project, when there is no food left for the little sims to consume. If the program receives a SIGKILL I seem to have no way tell the goroutines to stop. Is this just a flaw I have to live with? In the code example I provided - that continues even if that "main thread" gets killed. 
Ah yes, sorry I forgot it's AGPLv3. That's unfortunate. 
I just ran this myself on linux and it looks like interrupt does kill the threads. I guess this is a bug specific to windows &amp; mingw? Well, since it works on my target platform, I guess I don't care anymore :P I'll get a screenshot of the issue though for the doubters. Expect an update to the original post in ~10 minutes. --edit: oh my, it looks like this has been fixed on windows 10 and is only an issue for the out of date version on my other win7 machine! I guess if SIGKILL is not something we should expect to happen, then I'll stop worrying about it?
Ok.
https://github.com/sclevine/spec/blob/master/spec_test.go Nope, doesn't look like stdlib, not at all.
&gt; I wanted to do a little primitive organism simulation with each having its own thread to act on instead of iterating over them like most games would. It's designed strangely but intentionally. Intentionally incorrect is still incorrect. You can achieve your desired behavioral properties and still maintain a correct program. Do you think your game is the first one that had a group of objects which wanted to act independently...? Then do you think that the best design pattern in game engines with complex rendering pipelines and game events based on various goals being reached really would approach this by just starting a ton of threads and atomicly incrementing a counter? No. They don't. That is poorly designed software in any langue in any problem domain. That is why you are replying to posts on Reddit, because your software design is causing you issues. Interface type Ticker has method Tick(time.Duration), Struct World (Worker) has slice of Struct GameObject (organisms) and both implement Ticker. While context is not done call method Tick on world with time.Duration being the time since the laser cal to Tick. Worlds Tick method calls each child Tick method. When organism ticks simulate organism behavior by updating fields performing linear interpolation against the Tick time. Now you have a truly independent organism and you can use fields to increase or grow it's attributes artificially or randomly to get the desired game behavior. You could also interact with a World game object in each organism because it's a thread safe call. You could implement a behavior tree for complex interactions between organisms. There now your using proper software design and can actually simulate arbitrary conditions with your organisms rather than have their behavior based on the language runtimes schedulers underlying implementation of atomic primitives, which is hardly like indecently operating organisms. &gt; If the program receives a SIGKILL I seem to have no way tell the goroutines to stop. Yes, you are creating your own problems here. Again, you do not have clear program Flow like the example I gave you. 
I'm sure rust is superior in many regards but Go is good enough for me. There's room for multiple players in this game :-)
I expect a framework to build 'web applications' (assuming as in 'online applications to access and modify information') is to have a good system for: 1) User registration. With option to enter email plus password, send link to confirm, resend option, password forgotten option, etc. Plus optional social logins. 2) Manage users plus manage content related to specific users or groups of users. Without an solution for user and content management there is not much added value to me in using any of these frameworks. Those are all about serving the pages, which is not really a problem in Go anyway. 
&gt; 1) User registration. With option to enter email plus password, send link to confirm, resend option, password forgotten option, etc. Plus optional social logins. This is already built into the boilerplate. There is an 'admin' panel that requires you to login. There's no social login as of now but I'll add it to the TODO list. &gt; 2) Manage users plus manage content related to specific users or groups of users. From the admin panel, you can perform CRUD operations for managing a resource called 'pages' (i.e. add a new page, edit a page etc). I've also added some screenshots for that. This can be used as a base for building other models/resources like users, groups etc. 
I would suggest against this method since it causes allocations without any benefit. The best way I think is still [this](https://github.com/cstockton/pkg/blob/master/ctxkey/ctxkey.go) or any empty struct as conv2E no longer allocates for that as well.
# Golang ## Good * Easy parallel processing * Easy to use peripheral tools * many libraries. * Easy cross compilation * It's fast as it is native compilation ## Bad * All others
Everything below [this line](https://github.com/sclevine/spec/blob/master/spec_test.go#L238) is an example (which I can't use an `Example` for, because `testing` doesn't support `Example`s that are provided with a `*testing.T`). The rest is largely just assertions on call order. If I introduce more options, I may break some of the call order tests out into matrix tests. If you have substantive suggestions, I would happily review a PR. Aside from that, I'm not terribly interested in arguing with you about testing Go code. We obviously have differences of opinion in this space. 
I appreciate what you've tried to do here, and do think you some people will reflexively downvote - but let's be real, it is a framework, you're just having to avoid calling it a framework. It seems like a good selection of libraries, but it's not something I'll use personally because I'll just pick specifically the libraries I need when working on something. Anyway, good luck!
Hey /u/serverangels, I've half completed the youtube playlist to rss converter. It has some bugs like 2 people downloading same feed at the same may cause a connection time out error on one connection if the audio file isn't stored on the server. I have some exams from tomorrow, So, I'll fix those bugs after 3 days. You likely won't have to change anything once I fix these bugs so you can start using it right away. Feed url: https://justforfunc.herokuapp.com Github: https://github.com/ishanjain28/youtube-playlist-rss Try it out and let me know if you find anymore bugs, have suggestions, Criticisms or anything else... A screenshot of how it looks in a podcast app on android: https://i.imgur.com/Iv75XYX.jpg Cc /u/campoy
&gt; including staying up late, to work on and push a patch for a critical security vulnerability in Caddy. Is that security issue documented somewhere public?
[removed]
Additionally, I don't like shutting down by calling `listener.Close()` anymore, as there's no good way to determine from `listener.Accept()` if you got an error because of a graceful shutdown request, or because of a real error. Instead, I now like `listener.SetDealine(time.Now())`, so that you can reliably check `nerr.Timeout()` to see if it is a graceful shutdown request or a real error.
&gt;Try some different languages From your list I got Java, Python, and C# covered. To give you more perspective, I have over 6 years experience with C# but only 1 in Go. So it's not a case of Go being my first ever language and not being able to do comparison and talks about pros and cons between different languages.
There's one for bioinformatics algorithms: http://rosalind.info/ Less math, but kinda assumes you know most data structures and concepts.
Gotcha. In that case I agree. Thanks for clarification!
Not exactly an alternative because it does not provide exercises, but [rosettacode.org](http://rosettacode.org) is stuffed with sample code for any kind of algorithm, in about all programming languages (ok, maybe not all, but 668 is more than enough), including Go.
Not sure how Matt handles it. I think it should be. It was a bug in how Caddy handles malformed URLs that could defeat basic auth, the JWT plugin, and another multi-auth plugin. It has been patched in the latest version. 
Try this book, [Exercises for Programmers: 57 Challenges to Develop Your Coding Skills](https://pragprog.com/book/bhwb/exercises-for-programmers) — exactly what you are looking for, and language-agnostic. Nonfree.
TL;DR: "If you have no idea whether to choose Rust or Go, you obviously are better off with the simpler one. (Even though Rust provides some strong guarantees that Go cannot provide.) If you know exactly what you need, you probably do not need to ask that question."
Well, it's system as in "non user-facing program" (as opposed to "applicative program"), not as in "kernel/embedded program". FYI, most of the go programs I write are neither web nor distributed programs. But they are "non-user-facing programs" for sure.
Those are great points. Thanks!
What is the use-case that made you choose this architecture vs building an API with Go and consume it by a mobile or JS front-end?
All I want is that you don't call any of that idiomatic..
Global ID uniqueness sans coordination is an illusion.
seconded, this.
https://www.growthmetrics.io/open-source/alloy &gt; JS: (in admin panel) Bootstrap (v4.0), jQuery, Froala Editor https://github.com/froala/wysiwyg-editor/blob/master/License.txt#L4 &gt; In order to use Froala Editor you have to purchase a license from: https://www.froala.com/wysiwyg-editor/pricing. 
Generate text, not AST. Only after finished, parse it to get an AST, but only if you need the AST. To format the result, use gofmt or the go/format package - you don't need to produce the AST at all for that,
I think this is probably the best characterization for the Go vs Rust debate. Although I will say I would seriously consider Rust over Go if I'm doing anything remotely abstract. At the moment, I'm writing a parser in Go, and generics/macros/sum types would be a godsend here. If I was particularly familiar with parser concepts before I started this, I probably would have used Rust and one of its parser combinator libraries (which can't be built in Go without `interface{}`), but playing in a new domain begets iteration, and iterating in Rust is a pain.
The AST is only in service of generating text. Generating text directly from my language's AST is fine for cases where my language's concepts map neatly with Go's concepts, but for more complex cases, it seems helpful to target Go's AST and then render that.
Test as specified in https://github.com/cstockton/pkg/tree/master/ctxkey#allocations using Go 1.9 shows there is no difference - https://paste.ofcode.org/KmfGn86QpMHaFQHvJDyqiM. Taking the address of empty struct isn't good idea (https://golang.org/ref/spec#Size_and_alignment_guarantees): """ A struct or array type has size zero if it contains no fields (or elements, respectively) that have a size greater than zero. Two distinct zero-size variables may have the same address in memory. """
OK so look at the amount of boilerplate code in one of your python apps and one of your go apps. Look at how much of your codebase in go is dedicated to error handling alone. How many times did you type if err != nil blah in your app. You'd think at a minimum somebody would have made that a little more convenient right? How about your classes? Why is it preferable to write your functions outside of your struct (class) definition? What possible benefit does it give you to keep typing func (s SomeStruct) blah blah for every method you want to define? Isn't it easier and more understandable to put the methods inside of the class definition? Is it because you want to be able to define methods elsewhere in another file? If so then make your classes open like in Ruby or C#. It's a braindead decision made for no real reason than maybe because it was on the compiler. Optimising compiler times instead of developer productivity. Like I said. Go is a "meh" language. It's not even fun to program in but in my case I had to. I certainly would not choose it for my own projects. There are dozens of languages which are much better. On a final note. The go community is quite cult like. Not a very pleasant experience asking for help. As a hint to others don't ever say "how do I do this in go, here is how I did it in language X". They can't stand comparing their language to anything else.
I don't know exactly what you are writing but this [talk](https://www.youtube.com/watch?v=HxaD_trXwRE) &amp; [slides](https://talks.golang.org/2011/lex.slide#1) and [this article](https://medium.com/@farslan/a-look-at-go-scanner-packages-11710c2655fc) might be able to help you.
Generating AST nodes is way more work compared to directly generating Go source code. The later is rather trivial, here's an [example](https://github.com/cznic/irgo/blob/ccd5eb988d5b96df3a1b515d81f8d74b69e62175/irgo.go). 
I've only skimmed, but I think these are the opposite problem--they're starting from strings and parsing an AST. I want to build a Go AST and render it as text (pretty print). Like I said, I can roll my own pretty printer, but I wanted to see if one already existed.
I took a look at your example, and it doesn't look trivial. How is that much less work than generating AST nodes? Perhaps you mean `go/ast`'s implementation of AST nodes specifically, and not AST nodes generally? Or maybe you mean it's less work than writing an AST/pretty-printer library *and* compiling to it?
Every single g.w(...) statement in the example equals a couple of lines when generating an AST directly That's what I mean by saying 'rather trivial'.
Not true, you have to `g.w()` every little syntax thing, including commas, parens, braces, etc and then you get no guarantees that the stuff you're outputting is syntactically valid Go. If you have a sane AST/pretty-print library, you can get stronger correctness guarantees and simpler code (*maybe* more lines, due to multi-line structs and the like, but far fewer statements/expressions/conditionals/etc).
Do you have some sample code that almost works or shows what you want to do? There's at least a chance you're only off by a bit, because I do think this should generally work.
Please be kind with the code, i'm going to refactor it a lot (but still keeping the algorithm) :)
&gt; Taking the address of empty struct isn't good idea If you use a empty struct than you don't take the address.. that is the entire point of using an empty struct. You rely on the type for the equality checks. type ( keyOne struct{} keyTwo struct{} ) // zero allocs because empty structs do not allocate when // stored in a eface. lookupKey := keyOne{}{} As for the test I am not at a computer to look up the commit but if it doesn't allocate anymore that is nice to know. With that new information I'm not opposed to integer keys, though I do think it would be cleaner to assign them as const. Like the [blog/context](https://blog.golang.org/context) post from 3 years ago showing the exact same pattern except using "const" with a more in depth explanation.
I don't have any sample code yet, but the general concept is that I have an AST for one language and I want to compile it into Go (I think we may have talked about this in the Gallium thread?) ideally by compiling first to a Go AST and then pretty printing the result. But `go/ast` assumes that you have some existing Go string that it points into (instead of an ident being a string, it's a start/end indices pair into the Go string). Make sense?
To reinforce this point: `go/ast` in its current form is absolutely meant for parsing and reading; not for generating or manipulating. Trying to generate ASTs, or even just modify them in non-trivial ways, is an extreme pain.
for users who use NoJS addon.
id personally never sacrifice the benefit's that come with writing react js code. It just does not seem reasonable to do. I can understand for anyone who still has not been initiated with the bullshit of learning javascript and webpack for them it might be worth it. But for those who already had to learn them it is just not worth it still imho to go to gopherjs. once someone learns how to get webpack to just auto recompile output on file change, and setup golang to serve from the output directory it is totally unneeded. hot reloading among other features like devtools are just too handy to give up.
&gt;from your list I have three languages which are all really similar ftfw Also lol no generics
For what it's worth, I think that "template-based" web apps are considerably better from almost every angle: easier to develop, easier to maintain, typically faster, and typically better user UX. Maybe it'll be better in the future, when and if the browser environment sucks less. I'm not really holding my breath.
I think it's fine.
I was definitely talking about "on the metal" filesystems. Userspace file systems are another kettle of fish, and those can be implemented in Python if you so choose, because all the heavy lifting is done elsewhere. &gt; I can see how Rust code might be much more likely to get into the kernel than Go, but that also feels more like the difference between 0% and 1%. If you mean literally the Linux kernel, I agree, if only because I doubt that project will ever accept anything other than C in a "proper" component of the kernel, if only because at this point adding another language would just be asking too much. However, Rust would be a much better choice for a kernel on its own, if only because you actually can implement a kernel in it. You could modify Go to run on bare metal, but rather than "using Go to implement a kernel" you'd be "implementing the Go runtime on bare metal", which isn't quite the same thing even if there is some overlap. Rust can have all its runtime stripped away and still be Rust, Go can not. (To be clear, "implementing the Go runtime on bare metal" is not necessarily a bad idea. It's been done for Haskell and I believe Erlang can be convinced to do it too. You can also find some projects that implement a language's runtime directly on top of the Xen hypervisor. It's definitely a niche product, though. I believe that as others have linked, people have played with doing it with Go but I don't know if any are production-quality.)
I never quite finished my work with it, but my understanding is that you can just leave those parameters off and the output will be correct. One of the things I don't love about Go's standard library (or its authors) is that they do sometimes overload types in a way that is unnecessary in Go, because Go has all the tools to make the correct types easy. Another example of this is in http.Cookie; you really want separate types for incoming cookies (which are really just key/value pairs sent by the browser) and outgoing cookies (which have a lot more attributes to them). The outgoing cookies could easily embed the key/value part of the incoming cookie, but they don't. As a consequence there's some validation opportunities that get passed up. Similarly, while the AST nodes are all greased up to be used as if they come from a real file, I _think_ you can just ignore those fields and use the output portions and it'll all work for you. I was fishing for details/examples because if I could run my claims past a compiler before I said this, I would prevent myself from sticking my foot in my mouth. :)
I am not sure about the state of Gtk bindings, but I think some pretty decent Qt ones exist now.
The golang plugin in oh-my-zsh works very well https://github.com/robbyrussell/oh-my-zsh
The regular installer couldn't be simpler. Installing new versions is handled fine with the latest download. No need to remove first. I wouldn't fret it.
thanks!
yeah they looked pretty old from the commit log. thanks for Qt tip. 
Neither. &gt; brew install wget &gt; wget https://storage.googleapis.com/golang/go1.9.darwin-amd64.tar.gz &gt; tar zxvf go1.9.darwin-amd64.tar.gz &gt; sudo mv go /usr/local/ Set up your `GOPATH` (and possibly `GOROOT`) in your shell's env settings file, and you're done. There is nothing inherently wrong with doing it through homebrew or the package installer, but the simplicity of "just drop it somewhere in your filesystem" should not be overlooked. The only time this gets hairy is when you need to work in multiple versions of go, in which case I would let a tool like [gvm](https://github.com/moovweb/gvm) handle it.
How does this compare to [Buffalo](https://gobuffalo.io/)?
&gt; for users who use NoJS addon. Yeah... No doubt tailored for his exact use case! &gt; import "jquery-ujs"; &gt; import "bootstrap/js/dist/util.js"; &gt; import "bootstrap/js/dist/collapse.js"; &gt; import "bootstrap/js/dist/alert.js"; &gt; import "bootstrap/js/dist/dropdown.js"; &gt; import "bootstrap/js/dist/tab.js"; &gt; import "bootstrap/js/dist/tooltip.js"; &gt; import froalaEditor from "froala-editor/js/froala_editor.min.js"; &gt; import "froala-editor/js/plugins/align.min.js"; import "froala-editor/js/plugins/code_beautifier.min.js"; import "froala-editor/js/plugins/code_view.min.js"; import "froala-editor/js/plugins/colors.min.js"; import "froala-editor/js/plugins/emoticons.min.js"; import "froala-editor/js/plugins/entities.min.js"; import "froala-editor/js/plugins/table.min.js"; import "froala-editor/js/plugins/lists.min.js"; import "froala-editor/js/plugins/font_size.min.js"; import "froala-editor/js/plugins/url.min.js"; import "froala-editor/js/plugins/link.min.js"; import "froala-editor/js/plugins/quote.min.js"; import "froala-editor/js/plugins/image.min.js"; import "froala-editor/js/plugins/image_manager.min.js"; import "froala-editor/js/plugins/paragraph_style.min.js"; import "froala-editor/js/plugins/paragraph_format.min.js"; import "froala-editor/js/plugins/line_breaker.min.js"; 
My buddy /u/OneOfOne has a great [webkit2gtk library](https://github.com/OneOfOne/webview) for go. It might be a good reference point for you.
Whoa, this is news to me. So when the time comes for me to update, I just need to run this same command(s) again? Will it overwrite the preexisting version when I have to update?
Do you have anything more specific in mind? While much of the Linux user space is implemented in c / cpp / (shell, python and others though not relevant to your post), those are mostly just the primary clients of the associated user space functionality. Many of those systems such as dbus, X and common distro services like kde* have API's to consume that define a language agnostic protocol, or at the very least a local unix socket in var run that you can easily determine the structures needed to interact with. In cases that they don't you will find the CLI util symmetric with the user space library may have mutual inclusion with the system you want to interact with, meaning you can always just exec out to it. When neither of those options are feasible you then have the various Linux kernel subsystems, devices, drivers, and many other things exposed in the virtual file systems such as sysfs mounted at /sys. You can use procfs mounted in every distro at /proc to correlate most these systems with the current kernel state and /dev for current device driver information. With all of this I haven't needed to type import C for any of my local system utils I've made over the years. The only area you may struggle with is pure GUI applications, but much of the functionality around the GUI you can get by just exec out to CLI tools like the xdg-tools for basic X11 stuff. You can create simple notifications, do actions on clipboard changes, all kinds of stuff without a single C import. There are binding for Go for many things (xdg has some for example) when you can't get what you want from a shell. Point is Go is great for this kind of thing. It's more secure in the sense that most every CLI tool is thousands of lines of string parsing with subtle annoying input / output differences and potential overflows laying dormant in them as well. Most everything (99.9999%) done in userspace doesn't need to be in c and the more tools written in Go the better the desktop experience will be. The world doesn't need 20k lines more of while(char) to shit out information already in a file in /proc/ in a more annoying but "readable" format using whatever flags tickled that developers fancy. cmdname -h did you mean --help? $ shutdown -h now &gt;realize I forgot to unmount my nfs that isn't in fstab and is offline now anyways but systemd is the most important diva in the world and will make me watch with no ability to get a tty despite having zero technical reasons why it can't be accessed at this point in the shutdown process. Leaving it "waiting for a stop job to finish", go to bed. Wake up. Same screen as my mind explodes I turn off my pc and realize when I reboot that system didn't close device mapper for the luks part on my raid array. Deal with latency for 3 days while my raid array recovers. So solutions like [this](https://github.com/systemd/systemd/pull/5688#issuecomment-291092505) end up being implemented, a ton of setup / tear down for pthreads just to do: go func(ctx) { select &lt;-Done() or &lt;-umount() } Which much of systemd [code](https://github.com/systemd/systemd/search?utf8=%E2%9C%93&amp;q=%2Fproc&amp;type=) revolves around parsing the procfs in all the various places i.e. [core/umount.c](https://github.com/systemd/systemd/blob/d74edffa8b9c82a4de30eb2e513cb0411bdec4d3/src/core/umount.c), supported by [fifty-thousand](https://github.com/systemd/systemd/tree/dd8352659c9428b196706d04399eec106a8917ed/src/basic) lines of various string parsing / handling. Lol. A last note is that any system utilities I write, instead of: lsblk --format UUID,NAME ps -o pid,user top -o %CPU w --no-header -s kill -me I just stream json arrays of whatever struct the cmd is for and filter / format using a few helper commands in Go or when I want to get a bit more precise I'll use [jq](https://stedolan.github.io/jq/) and call it a day. I type: $ ls $(awk -F&lt;DELIM&gt; '{print $N}' | a | few | more | awks | toss in a | grep) &gt; ls: cannot access 'yourfilename': No such file or directory &gt; ls: cannot access 'had-a-space-lmao': No such file or directory $ shutdown -h now Much less these days. 
&gt; For what it's worth, I think that "template-based" web apps are considerably better from almost every angle: easier to develop, easier to maintain, typically faster, and typically better user UX. Care to elaborate on why you think that? To my experience, "template-based" web apps are considerably harder to maintain and they become gradually more difficult to iterate as the complexity of the app grows. The main reason is all the logic you keep in the template language which is strongly coupled with your "models". Add to that the dynamic UI changes that the JS will make on the client and you end up with something which is quite hard to test. The user UX is usually pretty bad, unless you throw in tons of extra JS and CSS to make sure the UI is responsive and works (and looks) appropriately on each screen size. On the other hand, a Go API that will be consumed by a client front-end, makes your app more flexible and scale-able. It's also closer to "using the right tool for each job".
The API of the `go/ast` package in standard library is very poorly fit for the task of generating an AST. It's only suitable for parsing Go source code into it, and generating Go source code out of it. I think the most common approach at this time is to generate Go source code via `text/template` or so. There may have been an attempt at making another AST package that would be friendly for generation, see https://github.com/dave/jennifer. I have not used it so can't say how well it works.
When it comes time to update, remove the old directory, then move/extract the new version into same place. If you don't remove old version, you might inherit files from old version that weren't kept in new. This is what I do to install Go on new computers (usually VMs): # Install Go on Linux. sudo rm -rf /usr/local/go &amp;&amp; curl -L https://golang.org/dl/go1.9.linux-amd64.tar.gz | sudo tar zx -C /usr/local/ # Add to ~/.bash_profile. export PATH="$PATH:/usr/local/go/bin:$HOME/go/bin"
when a new version is released, you need to first delete the old /usr/loca/go folder, as there are times when having files from an older version cause issues, but other than that, yes, just those few commands and you are ready to go :)
You would just remove the existing directory (`/usr/local/go`), but yeah that's how you would do it. Again, if you need to work with multiple versions, a version-switching tool might be more what you'll need. But if you only care about one single Go version, then you can't get much simpler. 
As soon as you introduce C into your Go project, you can say goodbye to many nice Go features like memory safety, good tooling, easy cross compilation, testing, maintenance etc. Of course if you are only interested in Linux, the lack of easy cross compilation might not be such a big deal but you really lose so many other nice things. Personally I'd advise you to stick with writing simple command line tools and APIs in Go which combined together provide the end result. If you really want a GUI, you can create a new project that acts as a frontend of your Go tools. That project can use any combination of languages. The difference is that in this case, the main bulk of the work will be done by pure Go code and the main logic will not be strongly coupled with the GUI. Another benefit is that in case the GUI becomes too hard to maintain in the long run, the Go tools will still survive and remain usable on their own.
Use homebrew, you don’t have time to waste dicking around keeping this stuff up to date. Let homebrew handle it.
[removed]
Go from homebrew is not from the official package. You don't need to compile it though (as Homebrew uses precompiled one) Go was in homebrew cask but has been removed. Homewbrew cask does not accept go since other homebrew packages (not cask packages) may depend on go and there is no way in homebrew to use go from cask to build homebrew package. See https://github.com/caskroom/homebrew-cask/pull/31728 for details. I wanted to use the official package and manage it with homebrew cask, I just created my own tap. I don't install any homebrew package which needs homebrew go so jt just works. 
Thanks for bringing this to my notice. I'll be replacing it shortly.
Thanks!
Thanks!
Thanks!
I'll take another look, but I'm pretty sure they're necessary to represent any sort of information. Iirc, an Ident isn't a string and a token pos, it's just a token pos. So you have no way of specifying the identifier apart from the pos. It might be possible to just keep a string that is just the concatenation of all of the things that are represented by Poses; I doubt the pretty printer cares?
I've accomplished this in that past with a struct with an internal channel handing out tokens when ```Add``` is called. An alternative and honestly cleaner pattern most times is a Worker Pool. 
Thanks! Please create issues if you have any problems, I'm very happy to help.
[removed]
If something ever screamed pics in the readme, this was it! See UI within https://www.makeareadme.com/ :) 
I've had good luck just using `text/template`, then passing the result through `go/format`. It's very effective and easy to write, particularly for smaller or embedded tools.
What are some good ways to have the GUI interact with a go program assuming they are written in 2 entirely different languages?
Depending on the application, a JSON API over a socket could work. Isn't that how gocode does it? It's totally likely I'm remembering wrong.
That's also my reason for using Homebrew. And so far the `go` formula has always been kept up to date--I usually get new Go releases within a day or so.
It desperately needs various examples. After all this time, I still have no idea how to use gonum (not that I've looked very hard)
SIGKILL is intentionally uncatchable. It's the OS forcibly shutting down the program, usually because it's misbehaving by not responding to SIGTERM. SIGINT and/or SIGTERM are the "soft" kill signals that can be trapped by the program being interrupted.
This sounds like a job for sync.Cond, [gist](https://gist.github.com/cstockton/d611ced26bb6b4d3f7d4237abb8613c4) and [play](https://play.golang.org/p/haEHcprSwM).
&gt; Taking the address of empty struct isn't good idea It's a great idea, but your keys then need to have different types. E.g. https://play.golang.org/p/Qcm6eIk6Ox -- the values share the same address, but have different types, so comparison still works as needed. I think the approach in that link you posted is fine, though.
May be you could spend your time contributing to [`golang.org/exp/shiny`](https://godoc.org/golang.org/x/exp/shiny) — this *is* a "blessed" attempt at creating a cross-platform solution offering GUI experience. What's exceptionally good about it is that it's Go-style right from the start. That is, you write Go code when working with it, not a set of plugs for an event loop provided by the whatever GUI toolkit.
[Works just fine](https://play.golang.org/p/zejMG9K7mK). Just leave out all the position information. The pretty-printer will deal with it.
[NewIdent](https://godoc.org/go/ast#NewIdent) is for the specific purpose of doing what you want. Really, I don't think you need to *at all* deal with `Pos`es or `FileSet`s, if you just generate code. [edit] To illustrate: https://play.golang.org/p/kmAcSg4Kaw
One more point: while I'm a Go aficionado, I'd recommend looking at [Vala](https://wiki.gnome.org/Projects/Vala) for your Linux GUI gigs: while not being nearly as much pleasant to program as Go, it's still pretty much higher-level than C and C++ — on par with C# (from which it draws much of ideas). Vala compiles down to C which uses Gtk and Glib (and other G-stuff), so you get pretty much "native" (in the sense of GTK-native) programs which fit nicely into the ecosystem. There's even a [whole stab at creating a DE in it](https://elementary.io/).
I agree - most operations that can benefit from concurrency also have a practical limit; CPU-bound operations are limited by the number of CPUs, file-bound operations need to be limited by a OS limit on the number of open file descriptors, etc. After running into this problem a few times and doing some reading-up about it I came up with this, which has a similar API to sync.WaitGroup. It would be nice to have something in the sync package instead, but it doesn't exist there (yet!). Hope it's helpful! https://github.com/jamesrr39/semaphore
[removed]
Nope, i didn't put a screenshot :) EDIT: i added one. I'm going to add also some pics about the algorithm.
Seems much more cumbersome than a `brew install go`. What would you consider the advantage of manually installing it over using a proper packagae manager?
But then it wouldn't really be a waitgroup. You can make it yourself easily enough with a type that contains a waitgroup and a buffered channel of `struct {}` (used as a semaphore). It could implement the same interface as sync.WaitGroup except for the fact that its zero value wouldn't be useful so you would want to give it a constructor. I think this is about right: https://play.golang.org/p/ChjP2wpvyt but I'm only convinced of its correctness and usefulness when `Add` is called with values of 1 and -1 (apart from an initial `Add` of any size &lt;= `cap`). The case where there are multiple blocked `Add`ers with `delta &gt; 1`, and the channel reads get divvied up between them, seems fraught with peril of random deadlocks.
Are you trying to hammer a WaitGroup into a Semaphore hole? If yes: Why?
I have experienced this first hand and fully agree. SPA's take so much more effort to develop it really blew our budget of the last project I was on. Developing API's takes a lot of time and effort, especially if you have lots of nested objects that all need complex validation done on the server side. Basically you need lots of layers, model layer, API validation layer, API resource layer, frontend model layer, frontend code. Sure we used Python for this, but I don't think it will make a lot of difference whether Python or Go was used. We made the mistake of having most of our validation code in the API resources, having the chance to do it again I would make it a layer of it's own because it ended up getting really gnarly.
&gt; The user UX is usually pretty bad, unless you throw in tons of extra JS and CSS to make sure the UI is responsive and works (and looks) appropriately on each screen size. It depends on what you're creating, but I think most web apps work pretty good with just minimal JS. Reddit or Stack Overflow are good examples; sure, there's some JS-y stuff, but most of it is old-fashioned HTML documents, and it works pretty well. The problem with Single Page Apps is that unless you're careful you will break the back button; or middle click (favourite: middle click will reload the current page); or it will break in some browser. Not to mention that for many applications a single failure or error will usually break the application, and the user will have to do a "hard refresh" (which will make many apps lose state, such as page number, filter, etc). Then there's the issue of performance. Most of the time that my laptop's fans start buzzing it's because of some JS-heavy SPA app. I've seen SPA apps use over a gigabyte of memory, etc. APIs are often also inefficient; many pages need information from three, four, or more API endpoints, so that's a whole bunch of HTTP requests there which all add to both performance (network/latancy) and developer time. Often people say that SPAs are faster, but in practice they usually seem to be slower in terms of "time user spends waiting in front of screen". These are all solvable issues, but as a user, I see that many sites don't solve them, solve just a few or them. Some of the most frustrating sites to use are these poorly designed SPA apps. &gt; The main reason is all the logic you keep in the template language which is strongly coupled with your "models". Not necessarily. Personally I always try to maintain a clear separation between views and actual code. I do appreciate that many frameworks and applications don't do this, and that it's can be easy to come up with a spaghetti mess here (never said it was a *perfect* approach :-)). &gt; Add to that the dynamic UI changes that the JS will make on the client and you end up with something which is quite hard to test. I've found that testing SPA web apps is considerably harder. Maybe some of the newer SPA frameworks make this easier, but for a lot of what I've seen/used it's not so easy (or even nigh-impossible) to test. With templates, it's basically "call controller with data, string comes out". Pretty easy to test. --- Perhaps there is a good way to do SPA, but if there is then I haven't found it. Thus far, my experiences has been roughly similar to the ol' "microkernel vs. monolithic kernel" debate. Sure, a microkernel is better from many angles, but it also turns out to be really hard to implement correctly, which is why most kernels take a more monolithic approach, adding micro-kernel-y parts only where the advantages are really clear. I should probably write a more complete "SPA vs. templates" weblog post or some such one day, but this is the gist of it...
You might be interested in Dave Cheney's article about this topic: https://dave.cheney.net/2016/01/18/cgo-is-not-go
[shiny](https://github.com/golang/exp/tree/master/shiny) was unfortunately ditched ~4 months ago afair, I believe there was a post about it on reddit previously.
Thanks for making this. I think lots of developers will find it easier to start with "something" rather than a blank page. I'd suggest you consider using [dep](https://github.com/golang/dep) instead of glide.
&gt; Not true, you have to g.w() every little syntax thing, ... AST approach e := &amp;ast.BinaryExpr{ X: &amp;ast.BasicLit{ Kind: token.INT, Value: "23", }, Op: token.ADD, Y: &amp;ast.BasicLit{ Kind: token.INT, Value: "42", }, } vs text approach g.w("%v + %v", op1, op2) 
What's not official about it? The [formula](https://github.com/Homebrew/homebrew-core/blob/master/Formula/go.rb) uses https://storage.googleapis.com/golang/ to fetch the binaries from or uses https://go.googlesource.com/go.git when a head/source build is triggered. It's all fetched from the authoritative sources.
What is a "program for the linux ecosystem" and how does it differ from every other program?
[removed]
I fail to find it using the `https://www.google.com/search?q=shiny+site:https://www.reddit.com/r/golang/`query. May be you have confused it with GXUI?
I have started looking at dep. I'll try and switch to it in the next couple of days.
Linux community more critical of bloat / implementation details and different libraries to potentially work with I'd say is the only real unique things. But I mostly listed it like that incase people would bring up unique problems for Linux or best practices since I am very new to developing for Linux within its ecosystem of libraries etc, and for all I know it might be completely over complicated to run a go backend service doing all the logic with something else running the GUI. 
Quite a few tools work that way nowadays, it's actually pretty neat. You can also use net/rpc for this I suppose or gRPC+protobuf etc. Just ensure you use a socket or always bind to localhost.
When I read this yesterday I thought it was some jibe at Greymarch being ignorant about Rust or something; I thought it was a bit abrasive but okay. This morning I was playing with Wayland and was compiling some Wayland window manager written in Rust. I now understand it was a jibe at Rust, bot Greymarch :-) I have literally compiled entire operating systems faster than this single WM... :-/
Excellent! It would be even better if you could show the Go code that made that inline too! Your user community should be bigger if they can see how easy it is to make great Mondrian PNG :)
what you probably want is something more like a separate struct that composes a sync.WaitGroup and a sync.Cond (so you can control the number of routines that wake) bound to a sync.Mutex while using sync/atomic to increment/decrement your current active count. using a channel for the semaphore is sufficient for values of n that are small, but allocating n sentinel values into a channel when n is a large number would not be an efficient use of space. The one major benefit you get with channels is that you can reason about time easier than you might using the other sync types.
Nope, I used to use GXUI as well (good times), you can check the repo I linked to see it hasn't been updated in ~4 months as well, I must have been wrong about where I found out from though...
Found a recent message, I'm sure there's older ones, too lazy to check https://groups.google.com/d/msg/golang-nuts/Gazd5rzJM_s/1AneN5OkCAAJ
Ah, thanks. I've read that thread but did not actually got the impression the project is dead. But it's underpowered, yes. And actually this means that having more fresh blood in its veins would be a very cool thing to have ;-)
It's dead as far as using it in production is concerned =c The author mentions another post for a new UI, you should check that one out, I'm sure the fresh blood would be appreciated there =)
It does not use the official *installer package* file - `.pkg`. It does not use the official binaries neither. It only downloads the 1.7 binaries to bootstrap the go build env. That's what I'm saying it is not using the official package. I was not saying it isn't using the authoritative sources. 
Missed that from the description then, sorry. Will have another look !
I thought it was necessary to do additional cleanup, but yesterday when I tested go on galliumOS and win10, the goroutines died when the program received SIGINT. In about 2 hours I'll be updating the main post with a screenshot of the bug with mingw on wind7. Though I did initially explain I tried signal trapping and acknowledge sigkill cannot be caught (bullet points in OP if anyone missed it), and that was still half of the responses, and I got downvotes for asking questions / clarifying I've tried that to those responses. Gives a pretty bad impression of the community and probably won't post here again for issues :/ Going to post that screenshot and abandon ship. --edit: Updated the main post with [the image ](https://imgur.com/a/K1XRY)
I was recently looking for a book on this topic, but this might be even better.
This is taken from the 'admin' JS file. It is not loaded on the front-end site. Almost all these files are needed for loading the rich text editor. I am currently exploring [Trix editor](https://github.com/basecamp/trix) (jQuery free). If anyone would like to suggest an alternative, I'm all ears.
In a development environment I use the [asdf](https://github.com/asdf-vm/asdf). But it would be overkill if you are going to work with go only.
[removed]
I've written quite a few linux apps in Go and had no problems. 
Homebrew puts go into some path that I always tend to forget, like /usr/local/Cellar/go/... For me, the advantage is that I can run brew update &amp;&amp; brew upgrade without breaking anything.
2 cents here. I avoid Homebrew like the plague. I use to use it until it messed up installs on me several times. Since then I have been grabbing official installers and never looking back.
Cellar is the path where brew installs everything, so I'm not sure how one can forget that. I've been using `brew update/upgrade` with go installed just fine and nothing breaks.
Avoid homebrew like the plague. 
But then it wouldn't really be a waitgroup? How so?
I'm not sure what you mean :)
I'm happy someone agrees! Seems like something harmless that could just be there in case it's needed! Also, implementing it would break no existing code at all.
It may sounds like a troll, but I'm totally serious : have you thought about Rust for this purpose ? People often see Go and Rust as competitors, but they aren't, they're just different tools for different jobs. And for what you want to do Rust is probably the best tool out there : you don't have to go back to C/C++, and it's been designed to interop gracefully with existing C code. If you want to use GTK, you should have a look at [GTKrs](https://github.com/gtk-rs/gtk) or [Relm](http://relm.ml/relm-intro) Qt, and if you prefer Qt you have [this](https://www.vandenoever.info/blog/2017/09/04/rust_qt_binding_generator.html). I don't want to look like a Rust Zealot here, because I'm not (I would never advise anyone to do back-end stuff in Rust instead of Go) but this is such a canonical example of “picking the right tool for the job” I couldn't help myself. I hope I don't offend any of you and don't start a language flamewar.
I haven't looked into rust at all besides what I've read on this sub, and if golang looked futile to use I definetly was going to investigate what rust is like. 
Awesome! Thanks very much!
A semaphore is what you actually want for your scenario. You can read up wikipedia for better explanations than if I attempt at it :) A waitgroup is only useful when you want to wait unless a certain no. of goroutines have completed execution. Using a buffered channel with blocking semantics is the standard way to implement semaphores in Go. As answered by /u/hobbified here - https://www.reddit.com/r/golang/comments/70sfmk/syncwaitgroup_limit/dn5rmmz/
Doesn't have deque, which is the only commonly needed algorithm not in Go's stdlib. Linked list based stacks and queues are not as good. Gotta keep those elements continuous. 
You can make a .so library written in go and call its functions from a C/C++ frontend, too. Depends on what you are trying to make, actually.
I wrote a taskpool to solve that problem: https://godoc.org/github.com/carlmjohnson/monterey-jack/taskpool
why aren't element types interfaces?
Using chan struct{} solves the space problem.
On my TODO. Thanks :D
Like this one ([urfave/cli](https://github.com/urfave/cli))?
Ah I see, well actually when I thought that it'd be good if there was an in-built limit to wait groups, I wasn't trying anything specific; I just know in the past I've had to (sometimes) setup my own limit counter, and it just seems like it could be a few extra lines of code in the sync package which would help a lot of people if they need it.
I found these articles about the subject: https://www.slideshare.net/RobSkillington/go-at-uber https://eng.uber.com/go-geofence/
This is our package that limits concurrency and helps you manage return errors, with similar semantics to a wait group. We've easily pushed trillions of goroutines through it, so it should be stable. [https://github.com/nozzle/throttler](https://github.com/nozzle/throttler)
Now that's something I could possibly scratch from my TODO list.
Fantastic! Can't wait to replace hugo's dependency on Pygments!
Can you please post the source code as well? I have been running Go on Win7 and msysgit mingw bash without problems.
OMG, this is amazing. I'm SO psyched about this! Thanks for all your hard work, I can't imagine how much time work must have been. 
Ditto.
&gt; I mostly only converted languages I had heard of My favorite line from the README ^ :)
&gt; "If it doesn't load through curl, it's broken." &gt; &gt; Some very wise person. Can you show us the output of `curl -v http://localhost:8081/idontexist`?
IMO Go hits a sweet spot between productivity, speed, and safety. It performs significantly faster than Ruby and Python (8x would not be surprising), with significantly lower memory overhead (~1/4 the memory for similar programs). Static typing makes it a little less quick to produce code, but you need significantly fewer tests, since a lot of common mistakes are caught by the compiler, so you save some productivity there. Go also has real multithreading, so your deployment is significantly simplified - you don't need multiple processes to use multiple cores. (Addendum about Python - many of python's libraries are actually written in C, which makes them pretty damn fast, but that doesn't hold for application code that you or I write). It performs slightly slower than Java (somewhere between being almost on par down to maybe 50% the speed depending on the specific code), however, memory-wise, go uses about 1/4 the memory of Java, which can make a huge difference for the size of machines you need... it also means that java's improved garbage collector loses a lot of its benefits because it has to collect so much more memory. Go also has multi-threaded support built into the core of the language, which means it can be easier to use Go in a multithreaded way in some circumstances. Javascript (Node) is basically in the same boat as python and ruby. Slower, more memory. Node still doesn't have multithreaded support, and their blocking I/O magic requires callback hell. C/C++ are 2-3 times as fast as Go, but require manual memory management, are significantly less productive, and you have to worry about critical security issues due to buffer overflows etc. Basically no one should be writing code in these languages anymore for any application exposed to the internet. Rust is similar to C/C++ in speed. It has a lot more cognitive overhead than Go due to its built-in safety vs. race conditions and its non-gc automatic memory management. That being said, when you need the ultimate in safety and speed, and are willing to spend some more time getting there, Rust is what you should choose. I won't go into functional languages or older ML-style languages such as Haskel or Elixir since I'm not that familiar with them. But that's honestly the biggest knock against them - they just don't get developer mindshare and thus choosing them means that you'll always be limited in who you can hire / who can contribute.
I was just wondering how uber-like app would benefit from Go lang, and wasn't expecting a full comparison of Go with other languages lol but thanks for the comment!
 * Trying ::1... * TCP_NODELAY set * Connection failed * connect to ::1 port 8081 failed: Connection refused * Trying 127.0.0.1... * TCP_NODELAY set * Connection failed * connect to 127.0.0.1 port 8081 failed: Connection refused * Failed to connect to localhost port 8081: Connection refused * Closing connection 0 curl: (7) Failed to connect to localhost port 8081: Connection refused` That's output. I can see that something is redirecting, because If I test with `localhost:8080` it redirects to `https://127.0.0.1`...
If you could write on the gonum-dev mailing list which examples you would find most useful it would be very helpful.
this!
Try this: func redirectHTTP(w http.ResponseWriter, r *http.Request) { w.Header().Set("Connection", "close") u := r.URL u.Host = r.Host u.Scheme = "https" http.Redirect(w, r, u.String(), http.StatusMovedPermanently) }
&gt; C/C++ are 2-3 times as fast as Go Citation needed.
Re. the latter link, https://eng.uber.com/tag/go/ is even more interesting ;-)
Thanks for the heads-up!
There's nothing inherent about an uber-esque app that implies a requirement or a benefit for or from any particular language. Rather the type of application should be broken down into component parts and those parts' requirements or preferences. 
A rough comparison: http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=gcc. The relative performance seems to depend heavily on the program.
Seems pretty good but the example code could do with some comments.
this, this, so much this.
[Benchmarks](https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=gpp), [more benchmarks](https://github.com/kostya/benchmarks), [Google paper](https://days2011.scala-lang.org/sites/days2011/files/ws3-1-Hundt.pdf) (in which it did significantly worse than that), [another microbenchmark](https://lionet.livejournal.com/137511.html), [web framework benchmarks](https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=db), etc.
For simple usage I use something like this: https://play.golang.org/p/ziuuy02u18
Short version: Go is targeted squarely at networked services. That's most of what Uber is (and a nice mobile app). Go is better than basically everything else at creating networked services, except under niche conditions*. *added because I know programmers and they'll always find some exception to any rule.
Well, StackOverflow is harsh. Don't be discouraged by downvotes. Nobody dislikes a honest, well-structured question. Just make sure to research a little bit before asking something.
Have you tried gophers.slack.com ? It's always been very friendly for a newbie to Go like myself.
Try [Go Forum](https://forum.golangbridge.org/) very nice people there if you have something specific you can also contact with the moderators of this reddit directly
&gt; Javascript (Node)... their blocking I/O magic requires callback hell Callback hell comes more from cargo cult programming in lieu of thinking through a problem. There's definitely no "requirement" for that style of coding. It can even be avoided without using Promises or the new `async/await` feature.
The two really bad benchmarks in there are effectively degenerate cases for go vs. C. Binary trees is all about how fast the language can allocate and free memory. IIRC, the C implementation of the binary trees uses a special memory allocator that basically lets it cheat the benchmark. And the regex test I think is due to go using RE2 rather than PCRE... the latter is faster but has fairly common degenerate cases that make it take exponential time.
I think you'll find a lot of excited developers starring this today.
Following up on this. I have a guess, it might be that there were additions to the blog. The blog is included in the binary distribution of Go (also see https://github.com/golang/go/issues/21917).
the go community, at least on Stackoverflow is more neutral/negative than other communities. I even know this "for a fact" a few weeks ago I carried out a toy analysis where I scraped q/a for c, c++, python, java and go off Stackoverflow for the last couple of months and even after controlling for things like views, reputation, answers, the negative effect for go was there why then? my hypothesis is that it might be because it's a more unambigious language than many others — there typically is a well documented (often in the language spec) canonical way of doing things. don't feel discouraged by that! as others have said the slack channel is a great place to ask questions to get you started. plus gradually reading the spec + stdlib docs will grow on you, they are not as messy as other languages
Please take the following as neutrally as I intend to write it: The question is ill-posed. From my perspective, it's unclear what your question is. Are you dealing with infinities or NaNs? In what context do you need to handle them, to what goal? Is there a reason why NaNs and infinities might have a connection in this case? [Here's how to ask a good question](https://stackoverflow.com/help/how-to-ask). Feel free to write longer texts and include code samples. Preferrably on the Go playground (play.golang.org).
I'm not a node dev. But regardless, it still doesn't give you multithreaded support, just less-bad single threads :)
I think you replied to the wrong post?
yeah, you're right but... whatevs :p they'll probably see it here too.
As others have said, stack overflow is harsh even to veterans. I just don't go there anymore because I hate how they handle basically everything. I'm sorry you feel like the Go community is harsh in general. Reddit can be hard, as there are a lot of trolls on reddit, and even one or two people who are grumpy can make you feel like crap. But that's not go-specific. It's everywhere online, which sucks but is not something we can change. Now, keep in mind that downvotes on reddit don't mean your post is bad. It means it may be less interesting to the general public reading your post. That being said, there are grumpy gus people in every community that think that newbies asking questions is bad. There's not really anything we as mods can do about people downvoting whatever they want. If anyone is verbally abusive or just plain rude, that should be reported, and the mods are trying to keep that kind of response out of here. We can't be everywhere at all times, so using the report button is very important so we can catch things quickly. The gopher slack and gobridge forums as stated elsewhere here are both more friendly, I think because they have a higher barrier of entry than being public on Reddit, so there's a lot fewer trolls and just plain old grumpy people on there.
i just read the cheney article about the empty struct, i wasn't aware struct{} consumed zero space. thanks.
Ok I will lay things out more fully. I was doing exercise 3.1 from "The Go Programming Language" which references this [program](https://github.com/adonovan/gopl.io/blob/master/ch3/surface/main.go). The exercise it asks &gt;If the function f returns a non-finite float64 value, the SVG file will contain invalid &lt;polygon&gt; elements (although many SVG renderers handle this gracefully). Modify the program to skip invalid polygons. I was planing to solve it by adding the following to the corner func if math.IsInf(z, 0) { return math.NaN(), math.NaN() } and changing the contents of the second for loop in main to ax, ay := corner(i+1, j) if math.IsNaN(ax) { continue } bx, by := corner(i, j) if math.IsNaN(bx) { continue } cx, cy := corner(i, j+1) if math.IsNaN(cx) { continue } dx, dy := corner(i+1, j+1) if math.IsNaN(dx) { continue } fmt.Printf("&lt;polygon points='%g,%g %g,%g %g,%g %g,%g'/&gt;\n", ax, ay, bx, by, cx, cy, dx, dy) I wanted to check my work so I decided to look up any answers other ppl had posted online to this problem. No one else that I found had used math.IsInf() in there solutions but most had used math.IsNaN(). This made me wonder if I was missing some something and if math.IsNaN() was better for this purpose for some reason. So I looked through the Go Docs for both functions. I looked up NaN on wikipedia and the IEEE 754. I did general web searches for why everyone else was using math.IsNaN() even though it seemed less intuitive to me. Then I did searches on here and on stackoverflow for answers after all of that I didn't really have an answer so I decided to post a question. For which I have lost almost all my reputation on stackoverflow. Which is really frustrating.
I looked at your last go question here on reddit. It wasn't a good question. A good question asks something specific and shows what you have done. You mention os.OpenFile then complain that os.Create and os.Open don't work but never explain the errors you are getting or showing any of the code. You need to ask clear questions and provide the code if you want good answers. Also, when you show the code, you need to make sure it's readable. People will either ignore your question or down vote if you just paste the code in and it isn't readable because you didn't format it properly. I think if you ask questions that show the code that has the problem, explain the problem you are having and ask a specific question, you'll get much better results. 
Thanks for your reply. I look into it :)
&gt; Don't be discouraged by downvotes. Nobody dislikes a honest, well-structured question. Just make sure to research a little bit before asking something. This. Learning how to ask good questions is a great life skill: http://www.catb.org/esr/faqs/smart-questions.html
Rating questions (and answers) is about: Is this question relevant for other users? Just because a question might be important for you does not mean that the question is that much useful for your fellow programmers. If you just want answers to whatever comes up your mind: Don't go to SO. golang-nuts might be a much better place.
I always do my own research before asking a question. Most of the time I think my questions are complete and well structured but I admit sometimes its not as good as it could be usually because I am felling rushed, frustrated, or distracted by something. But when someone points that out to me I am always willing to go back and fix them and I do make an honest effort to do it right the first time. You said &gt;Nobody dislikes a honest, well-structured question. in the past I would have agreed with you but since starting to learn Go it doesn't fell true anymore. Now that I have calmed down I am somewhat embarrassed to have been on here complaining but I am just so tired and frustrated with everything right now. Not sure what I am going to do. And now I think I am rambling so I am going to stop now.
&gt; my http requests to 8081 are successfully redirected - BUT only to https://localhost , without port 8080. vs. &gt; localhost port 8081: Connection refused Sounds like some things changed between your initial code sample and your curl test. If I compile your sample (without the TLS listener, because I had no cert at hand), I get $ curl -v http://localhost:8081/foo * timeout on name lookup is not supported * Hostname was NOT found in DNS cache * Trying 127.0.0.1... * Connected to localhost (127.0.0.1) port 8081 (#0) &gt; GET /foo HTTP/1.1 &gt; User-Agent: curl/7.39.0 &gt; Host: localhost:8081 &gt; Accept: */* &gt; &lt; HTTP/1.1 301 Moved Permanently &lt; Location: https://127.0.0.1:8080/foo &lt; Date: Mon, 18 Sep 2017 19:46:36 GMT &lt; Content-Length: 61 &lt; Content-Type: text/html; charset=utf-8 &lt; &lt;a href="https://127.0.0.1:8080/foo"&gt;Moved Permanently&lt;/a&gt;.
I don't know the answer 100%, since it depends a bit on how the parsing works, but it seems like someone here ought to at least take a stab, so: I would suggest it is definitely a possibility that either the other solutions you may have found, or the person who wrote the question, may have some misunderstanding of how IEEE floats work. [NaNs aren't infinities and vice versa](https://play.golang.org/p/hz4GjV_Jo2), and the way the question is written in your quote does suggest that you're going to get _infinities_ and not _NaNs_. Like I said, it depends on the parser, but parser that works the way I would expect may generate a NaN for input that is totally non-numeric, and may generate Inf for input that is completely out of range, so both possibilities are something you _may_ have to contend with, depending on the parser's output domain, and it would be plausible to me that either the problem or the other people would use test data that results in NaNs rather than Infs. You'd probably want to synthesize a `IsNum` that is !IsNan &amp;&amp; !IsInf that you could use as a filter.
If you're testing for NaN then use math.IsNaN, if you're testing for Inf then use math.IsInf. There is no overlap.
Two I can come up with right off the bat... but I'm sure there are more: 1. Everybody is a professional who thinks they know best (but according to recent go-related blogs, suggestions, etc. it should be obvious there's a lot of people who claim to be but are no where close). It's kind of like being the 'n00b' in a MMORPG. Software developers have always been notorious for letting their projected 'smarts' get to them. It's probably from the constant 'you're so smart... all that looks like Chinese to me' they get from non-technical or people who don't understand what we do (a good example is their parent inflating just how intelligent they are just because they can code). They let this go to their heads... 2. In no other languages I've ever used, have I seen so many people lately come into a community and completely trash the language and complain "Why can't Go be more like {insert other language}...". That's been happening A LOT lately. I think long-timers and people who think Go is fine right now (a lot of us) are getting sick of the influx of this. Everybody has advice and their opinion on this. If you're making any comments related to this when asking for help, this could be part of the issue.
Its not about the 2 comments on that post. Its about the 4 immediate down votes it got when I have never gotten a single down vote on stackoverflow before. But more than that its about a constant trend of down votes and responses in go communities across several platforms that have left me feeling stressed and frustrated. Which feels even worse compared to the actively inviting and helpful communities I have encountered in every other programming language and community I have participated in. The linked stackoverflow post was just the straw that broke the camels back.
That paper is from six years ago.
Several things I have found seem to say that inf is a form of NaN or that it is sometimes.
Thanks the IsNum idea is a good one.
Internally changing wait groups to support that would probably result in worse performance for the standard use case, however, and there are already tools for your use case (or you can construct your use case with a wrapper struct). 
This is almost certainly not true. See this for a spec for NaN: https://en.wikipedia.org/wiki/IEEE_754-1985#NaN That spec is old, but the updated spec has the same rules in less-explicitly clear terms: (4th paragraph) https://en.wikipedia.org/wiki/IEEE_754#Interchange_formats
First let me point out that as I said above it is not just about the down votes or that single post. It is also about responses I have received in the past on other posts in multiple places. Secondly I have been part of both large and small communities in the past and have never experienced anything like this. Finally as to "fake internet points" they can have some value in places like stackoverflow where they can effect your ability to fully utilize the site and its features. Besides the fact that the points are used at least to some extent to voice an opinion. Now if this was just one or 2 posts or 1 forum or over just a week or maybe a month you might have a point but it over months, multiple posts, on multiple platforms.
...so hopefully these days we're closer to C/C++ being 2-3x as fast, rather than 5x, yes.
There is the possibility that I misunderstood or misread the sources that I looked at but if so it would seem to be a common misunderstanding given that all but one answer I have found that ppl have posted to the question have used math.IsNaN() to find both the non finite floats.
Exactly what I was thinking!
They probably checked the outputs the problem gave them and recognized they only needed IsNaN. There should be zero confusion between a floating point infinite and a floating point NaN.
No worries, man. We all get frustrated. It's a hazard of the job.
I've updated post with your suggestions. Thank you.
I actually thought his os.Open question was perfectly clear. If you haven't used linux much, 0666 doesn't mean anything to you, and there's no explanation of it. This is actually a problem with much of the OS package, it's written from the standpoint of "if you already know linux/C then you know this package" which doesn't mean it's actually a *good* API. 
Dude, I get downvoted on Stack Overflow all the damn time. Worse than that, I get my questions closed as off topic when they're clearly not. It's why I just don't go there anymore. Don't assume the people on stack overflow are representative of any particular group other than stack overflow itself.
no, I was wrong. You were looking at his stack overflow post... I totally missed the link when I was reading the post.
also https://github.com/willf/bitset
For those of you who are hesitating, there are both simple and more complex challenges. It only takes as little as 4 completed simple challenges to win a T-shirt as well!
You have to draw the line somewhere ;)
Mine too! Calling out to Pygments was not ideal :(
Hey, appreciate the follow-up and shoutout. I'm going to be a bit pedantic because there's still an issue here. While `wheels []wheel` and `wheel struct{}` are private, the member variables of `wheel` (`Diameter` and `Color`) are public. Furthermore, since we're returning a reference to `c.wheels` from the `Wheels()` getter, then client code is able to modify the internals of the aggregate, and once again violate invariants. I'm almost positive a wheel with negative diameter is senseless, and yet: ``` c.Wheels()[0].Diameter = -1 ``` is perfectly valid with this domain model.
You're right. I'll correct it. Good catch!
&gt; There's not really anything we as mods can do about people downvoting whatever they want. This probably doesn't help that much but I've seen in other subreddits that the vote count is hidden. I don't know how this works, and from my limited research it seems that it's hidden only for 24h hour, but even that would be a start, maybe?
Yo! I see no major issues with your tool, so in the spirit of constructive criticism: * Your smiley face is the wrong way. :) You must be from the southern hemisphere. * You've got a ton of extra whitespace. This, while not incorrect, is not recommended in the style guide. * Lots of spelling errors. * You could write [documentation](https://blog.golang.org/godoc-documenting-go-code) * You could write the actual logic as a library, and then structure your program with the [cmd as a sub-package](https://dave.cheney.net/2014/12/01/five-suggestions-for-setting-up-a-go-project). [A live example can be seen here](https://github.com/monochromegane/the_platinum_searcher). This has the added benefit of allowing others to import your library and use it in their code, as well as a standalone tool. * It would be cool to pass the key as a string to the cli, so that it's possible the key is never saved to disk. This library will probably never be used by anyone in the real world, but it's another layer of complexity to your logic that would be a good exercise. * If you refactored using the above strategy, you should remove the fatal logs. If someone were to use your library, it should only ever call fatal/panic in the absolute *oh shit stuff is really broken* situation. If I imported your library, and tried to encrypt a file, but instead it halted my entire program b/c you called `log.Fatal` due to a file perm issue or something, i'd immediately remove your library. Ideally, you should bubble up errors until higher level logic can deal with them. In your case you'd fatal in the main func, since that's the calling code. * If this were a real tool and I used it, i'd be pissed that you're deleting the keys after usage. There's nothing that explains that to the end user, and no way to disable it. That's not bad programming, but it's not a great experience. * You could try to abstract away the idea of a "key" into an interface with the required methods, just for fun and to learn how interfaces work. They are really integral to writing code in bigger projects, and very useful for unit testing. * As others have stated, there's no tests. [Start here.](https://golang.org/pkg/testing/) * Furthermore, it would be cool if the library introduced a simple interface that a calling application could mock. This requires a bunch of changes and understanding of Go, so let's call this a bonus objective. Note that I don't necessarily recommend creating interfaces for all your libraries (let the consumers do that), this is just an exercise so you can do it.
I was expecting to see the number like "-1200" on that SO post, but c'mon, "-2"? What do you care of - your carma on SO or your knowledge? Hint: ask something like this for Java or C# :)
The source code is the same as what I posted in the OP but different print statements. It's the same thing - reading from a channel that 1 routine will send to after decrementing the counter to 0. The difference in the source program is that the threads print "ded" when they read 0 from the counter :D I do find it interesting that you are not seeing this issue on win7 and the same git bash. Maybe my git bash is out of date? It's an old bug where it sends sigkill instead of sigint when you ctrl-c. If your terminal sends sigint then you're fine. I have the screenshot now and a code snippet so... I don't know what else to say other than I'm not surprised if it's an issue with the win7 machine because it's a work computer for AT&amp;T and who knows what is running on it lol. 
&gt; That is poorly designed software in any langue in any problem domain. However I did explicitly state that was the purpose and you can see it yourself in the code snippet posted in the updated original post. = &gt; Intentionally incorrect is still incorrect. for the purposes of this project I disagree = &gt; Then do you think that the best design pattern in game engines with complex rendering pipelines and game events based on various goals being reached really would approach this by just starting a ton of threads and atomicly incrementing a counter? No. They don't. If it's representing a line of people waiting to access a water fountain then I'd say it's a pretty darn accurate simulation ;) If I wanted multiple threads to access a variable at once I'd make an array they could take turns simultaneously accessing. = &gt; You could implement a behavior tree for complex interactions between organisms. Part of this experiment is also to learn about mutexs. I am certain I will eventually come across ticker and the like as you have suggested and I thank you for that suggestion to resolve problems I will undoubtedly eventually have. I have no problem like that to solve at this point, so pardon my responses. I'm new to go, I thought I was doing something wrong (as far as controlling the life of goroutines), and it turns out it was an environment issue. I cannot reproduce the bug on galliumOS, windows 10, or redhat 5.7. And another user stated they don't have the issue on windows 7 so it's even more of an edge case I don't have to worry about! = &gt; Yes, you are creating your own problems here. Again, you do not have clear program Flow like the example I gave you. The next phase of the program is, let's say, a pile of bananas. Some goroutines bring more to the pile and some only take. The program ends if there is a prolonged state of 0 bananas in the pile. I understand the design of the program is totally and completely wrong for any other purpose. The counter isn't for their communication, the atomic counter is so that they access resources in a queue just like any group of individuals would. = I don't think this will surprise anyone, but I am horrible with design. I am a pretty good code monkey and have no problem following the architects' instructions, but this is what happens when I mess around on my own, hah. My job just set me loose on a 7 day task without any direction so they're about to learn that as well :/
Been waiting for something like this for a long time. Was going to build something like this at one point, but did not have time. Mad awesome props, thanks alecthomas!
Hugo has a dependency on Pygment. I would like it if that were dropped for Chroma. 
They're [looking into it](https://twitter.com/gohugoio/status/909884463202566144), I think.
There's a Gopher Discord server too that I've found to be a delight to participate in.
C++ SO is toxic beyond reasoning. Most of the questions is either discussing Qt or some quirks in the standard. Everything else is mostly left unnoticed at best.
I disagree with your general opening sentiment here, you didn't post asking to help reproduce a signal handling bug. You posted about work on a potential game, the basic concept of it and how you achieved it. You then went on to explain behavior that was presented as an obstacle to progress. I saw the obstacle was the design of your concept, and presented a solution to allow progression to continue. You then justified the existing design and continued to chase the signaling red herring, which was just a consequence of the design I was giving you a solution to. I even wrote you an example to start with that could have used an atomic counter just the same, and exited just the same, with the benefit of the concurrency best practices I mentioned in other replies. &gt; I'm new to go, I thought I was doing something wrong (as far as controlling the life of goroutines), and it turns out it was an environment issue. After seeing the rambling on into your last couple paragraphs it seems you mean well and are a nice guy, so I'll just come out and say it. Are you sure you're not taking a [soldier stance](http://ideas.ted.com/why-you-think-youre-right-even-when-youre-wrong/amp/) here? That is focusing on something to "blame" I.e. Environment issue with signals to divert your attention away from a root cause that could have came from within? It's pretty natural to do sometimes, I do it on occasion myself with topics I'm very experienced in. Anyways hope you stick with Go and came out with some new knowledge regardless. Take it easy. 
&gt; u := r.URL Shouldn't that be u := *r.URL
" If the value is already a string or []byte, it's unchanged. " Have you tried assuming it is []byte?
worse performance? Only performance decrease would come an if statement such as: if wg.count &gt;= wg.limit { Each time `wg.Add(1)` is called.
I've found r/rust to be of particularly good quality. I don't know how r/Golang stacks up against other subs (certainly no worse than r/programming), but when I ask questions here, I usually have to sift through a bunch of arrogance from people who know very little about the question before someone intelligent comes in, and it's pretty dicey as to whether that person will be terse or friendly (fortunately the blatantly-rude/knowledgeable personality is rare here). I've eventually learned to just time out the rudeness and ask anyway, but the level of foolishness here is way too high for a community of alleged professionals.
[Related post (same paper, different link)](https://www.reddit.com/r/golang/comments/70by56/energy_efficiency_and_go/)
I'm sorry, and I empathize. I often get the feeling that many folks in these communities (including this sub) want to stroke their own egos by making others feel like their questions are bad. None of these programmers have the technical chops to justify their rudeness, and you'll quickly surpass them. For me, I've learned to ask questions and ignore the stupid responses. If I can get my answer and annoy some snobs, all the better.
There is no need to dereference `r` first. The dot notation [works transparently with pointers, too](https://golang.org/ref/spec#Selectors). That is, `r.URL` is a shorthand for `(*r).URL`.
fmt.Sprintf("%s", sv") ended up doing it... :| Thanks for the insight!
I wonder what property makes Go comparable to C and Pascal in terms of energy efficiency. It's interesting that Go and the other two are actually genetically related.
You should be able to type assert it to []byte and then string() cast it, it will be faster than fmt.Sprintf. https://play.golang.org/p/zFEUxwmvW4
`fetchImg()` can be implemented using a goroutine. Rather than return a `[]byte`, it should accept a channel to which it will send its output to. func fetchImg(out chan&lt;- []byte) { .. } out := make(chan []byte, 4) go fetchImg(out) // do this 4 times, per your requirements `fetchImg()` fetches an image, then sends the result to the `out` channel. Then, you can have another goroutine that is actively listening to the `out` channel. For every `[]byte` that it receives from the channel, it invokes `applyOnCanvas()` for o := range out { applyOnCanvas(readCanvas(), o, opts) } Bonus points: find out how and where to close the `out` channel so the loop can exit out gracefully.
OK, cool. I've used the combination in question (win7, bash from msysgit, go) for years, and never seen any goroutines continuing after program exit. I think Go the language promises that doesn't happen, but if it can't do that on Windows then that's a bit worrying.
I don't see those answers on SO as harsh. They were just trying to help. That said, programmers in general can be an ill-tempered bunch, try not to take it personally when you encounter it.
For what it's worth the user with the unhelpful comment implying 'go learn more stuff and come back' looks to mostly be active in the Python community on stackoverflow. :-) [ reading later comments .. ] Oh, ... well, don't be concerned about a few downvotes here and there. People might just have thought the question wasn't interesting. Or they don't know what they're doing.
While I agree on the absurd error handling boilerplate, I completely disagree on your premise that the method syntax is bad. It does seem like you are stuck in the mindset that classes are all the way down, until you get to the turtles. I personally prefer declaring methods 'outside' of the type, because that's just more screen real estate. In class-based languages you always lose a bit of space due to the extra indent. Also, this just looks weird: type Foo int { func bar() int { return this } } Also, how am I going to tell the language that 'this' is a pointer in certain methods?
I haven't read the paper yet however you can start by assuming they use SI units
Is the wind blowing where you live? Go fly a kite, it always works for me.
I'm getting the same output as you now. What's very strange is that my curl request gets picked up from the redirect function and prints the host connecting (just a test), if I do the same and type `http://localhost:8081` in the address bar, the request doesn't even respond! Any ideas why? 
Is your code good2go now?
I posted a grumpy thing here before saying that because the test code couldn't be shared, the problems need to be correctly specified and I didn't think the first one was. That's still true, but I found a single word in the first problem that made the difference between under specified and correctly specified. So if you take on this challenge, you need to consider the problem specifications very very carefully or else you will not be able to solve them. -jeff
are mingw64 and msysgit the same thing? Here's something I found while researching before https://stackoverflow.com/questions/38824561/catch-ctrl-c-on-windows-using-git-bash-mingw64-with-go There are a few links about the issue being fixed in mingw32 but not 64. 
I’m a Go newbie so I may be missing many things, but this seems strange. alpha_reader.go replaces characters with NUL bytes — is that what you mean by “filter out”? (To me, “filter out” means exclude bytes from output altogether.) And why does it make an intermediate buffer instead of writing directly to the provided p? I mean, that’s one way to implement the NUL behavior, but it’s kind of round-about, and costs an extra allocation. Does simple_reader.go rely on implementation details of strings.Reader? That doesn’t make for a good general io.Reader illustration. For one, if an error other than io.EOF occurs, it goes into an infinite loop. For another, it doesn’t handle data returned together with EOF (which is permitted by [io.Reader docs](https://golang.org/pkg/io/#Reader)). Again, alpha_reader2.go doesn’t correctly handle the case where the underlying reader returns data together with an error: in that case the data is not processed to filter out characters.
What is your PATH variable? Does it include the binaries in the GOPATH?
I'm not dereferencing the r, I'm dereferencing r.URL. See https://play.golang.org/p/POTLkz0Afk 
Thanks! That's what I was looking for!
[Godoc `time` constants](https://golang.org/pkg/time/#pkg-constants) lists the possibilities
Nice! Definitely will come in handy. I think it would be relatively easy to link up with something like [Black Friday](https://github.com/russross/blackfriday) by defining a custom renderer with a `BlockCode` callback that hands the code block to Chroma. This way you could do markdown with syntax highlighting of code blocks, which might come in handy for blog-style articles or documentation.
I don't like that you pass strings in as the validation rules. It makes it weakly typed and you won't know about typos until runtime. Check out something like goconvey that uses interface{} to allow static rules passed in. 
This is also why I don't like stuff that relies on struct tags. It's kind of difficult to 100% avoid passing any strings though; or if there is a way, I haven't found it :-) In [the package I wrote](https://github.com/teamwork/validate) a while ago you need to use e.g. `v.Required("firstName", customer.FirstName)`; the `firstName` is used for the error output only. It's hard to avoid this; reflection is a possibility but first of all reflection, and secondly it would limit the input to structs. `v.Required("firstName", firstName)` would not be possible. It's a bit redundant, but not too much, and at least the string value is close to the actually typed value (usually on the same line), so typos should be easier to avoid. Also, typos don't prevent anything from working, it would just make the errors look wrong (or in our case, not correctly highlight the form input in the frontend JS code). This can still be very confusing, but I don't know if any good way to avoid it... Also, the code in my package is ridiculously simple and avoids a lot of the complexity I've seen in some other packages (like the OP's package).
In a typical web application, reflection won't add enough performance overhead to matter
content-editable works fine for me. 
There's already a [pull request](https://github.com/gohugoio/hugo/pull/3891) to integrate it into Hugo. Stay tuned!
I'm not concerned about performance per se, it's more that reflection can make code hard to understand. Point in case: this morning I actually updated some code which used a lot of reflection, and even though it turned out to be a simple 2-line change it took me 30 minutes.
I find the Go community to swing in the other direction, in almost an extreme way. You can always try our Slack. There are a ton of people on there that are always willing to help, and they have a lot of patience. Also the golang-nuts Google group is pretty good IMO.
You should have added the problem you're trying to solve as well as the code you have to your Stack Overflow question.
Awesome, thanks!
Yep!
why not use goplayground/validator
&gt; so I may be missing many things You are not. The code in that article is at best a very poor example (for all the things you mention and more). The author would do well to have their code reviewed by someone more experienced and competent with the language before publishing an article that inexperienced beginners may otherwise follow without knowing better.
Why not use something like JSON Schema? Honest question as I haven't gotten much into the spec or implementations in go.
Use the FromBytes function Edit: gocql.FromBytes won't work if you're storing the uuid as its string representation. But you could store it as binary to save some storage space
Didn't look at the code but did you try to profile it to see where is the bottleneck? https://golang.org/pkg/net/http/pprof/
~~What `FromBytes` function are you referring to? I find no such function anywhere in Go 1.9's std packages.~~ [Thanks for the clarification, I had missed the `gocql` reference and even I had seen it wasn't aware of if it having that function.]
[List of Go wiki software](https://golanglibs.com/top?q=wiki)
I just re-read the question and the person edited it after the fact. The original question was very unclear. This one is less unclear. 
Informally, the overwhelming majority of users are professional software developers. I agree the core team left, but that's irrelevant to whether or not the community is composed of professionals. It seems like you're trying to pick some strange and incorrect nit by distinguishing between a community of people who may or may not be professionals and a community of professionals--if the community is 90% professionals (and I believe it is), then by any reasonable definition, it is a community of professionals (whether or not those professionals behave as such is a different matter!).
[It's Go time](http://gotime.agardner.me/)
vfaronov, thanks for reaching out. Re alpha_reader.go: https://github.com/vladimirvivien/learning-go/blob/master/tutorial/io/alpha_reader.go#L26 You mentioned that the code replaces chars with NUL bytes. Please specify a line number where you think it's doing that and we can discuss. But the code is not replacing any char with NUL byte. The loop uses function alpha() to return chars in set [a-zA-Z] only. With each iteration, char is placed in buf, then buf is copied to the p. Admittedly, buf maybe overkill but it ensures no garbage chars lingers in p (from index 0 - n) and makes the slice bookkeeping simpler. Re simple_reader.go: https://github.com/vladimirvivien/learning-go/blob/master/tutorial/io/simple_reader.go#L9 No, this example has no dependency on strings.Reader. The code is way too simple and would be buggy if used as is. As you pointed out EOF would work in most impl of io.Reader but breaks the general rule as outlined in the docs. Thank you for pointing this out. Re simple_reader2.go I will review the code there as well to add the case where data may have been returned along with error. In general: Most reader implementations returns n=0 at EOF. But, that's not a reason not to properly handle bytes read at EOF as you pointed out. Also, if a Read() returns a n &gt;0 and non-nil error, you may not trust those bytes an simply re-request. If you are writing code at that level, then you know what you are doing none of what I am saying matters. Thanks again for the constructive feedback and will update the write up. 
Definitely the Go to for all the details. Think when you first read it, you miss the point of how easy it is to work with date formats.
Read up on [struct embedding](https://golang.org/doc/effective_go.html#embedding).
Cool
I'm not sure what you're asking, are you talking about embedding a sync.RWMutex in a struct granting acesss to its method set? Or the fact sync.RWMutex implements sync.Locker interface?
dchapes, I appreciate your honest feedback. What is the "and more.." in your comment, do you care to share what else you think is bad with the writeup? Judging by the definitive tone of your feedback, it sounds like you are a Go god and most likely more competent then someone like me. Any additional feedback is welcome.
&gt; Now that I have calmed down I am somewhat embarrassed to have been on here complaining but I am just so tired and frustrated with everything right now This is a sure sign that you need a break. Take a walk. Get away from the screen for a bit. Happens to the best of us :)
Sounds like requests are queueing but not being read somewhere. I would write tests for your parser funcs to assert they are correct with local buffers. Static valid known data, then try having them write And drain the same buffers and see if you can find any issues. I wouldn't introduce tcp until you can see exactly where your issues are in tests. Main point here is to be sure your protocol has correct semantics that are comparable with your transport. That is the current flow of information is always clear, client requests the mode to change from sending msgs to receiving them. Obviously you can't just write from the server to the client while your client is expecting some kind of ack from their previous message, it's essentially a deadlock and sounds similar to what you describe here.
SLE is a conference, not a peer-reviewed journal. More to the point: academic papers require units to be listed on graph axes, precisely because it hinders comprehension if you have to go to the appendix to understand the main point of the paper.
I find creating a struct of an intended api is better, then creating functions on that struct for the individual api routes. Helps keep things clean and easy on naming.
Try remove default in select from `respondToServer`
I was searching around for the exact same thing! Every wiki I find is either crazy complicated to setup, part of a much larger CMS/Knowledge Management System or isn't maintained anymore. We are using Dokuwiki right now and it is OK but has some rough edges around the WYSIWYG plugin and theming. If I had ANY skills in front end development I'd start working on one or modifying those out there already.
Summary: faster languages use less energy when executing the programs. Doesn't talk that much about individual languages like Go. 
Edited for clarity and it sounds like FromBytes wouldn't work with how the uuids are being stored
Ahh, my apologies, then. I didn't realize it had been edited.
And my apologies for prematurely judging both of you as jerks through the process of reading that then being wrong on both counts 
sounds reasonable. fwiw i have unit test for all the parsing functions. requests from the server is async and client doesnt have to change the mode. its expected behaviour is to handle incoming requests in a concurrent manner.
We're building something that "docs + wiki": https://github.com/documize/community Go + EmberJS front-end code, all packed and served up from single executable -- makes deployment and upgrades super easy (compared to the status quo). 
this is the answer. Thanks
&gt; IIRC, the C implementation of the binary trees uses... Why are you guessing? Why haven't you looked at [the source code](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=binarytrees&amp;lang=gcc&amp;id=3) for that C program? &gt; And the regex test *I think* is due to go using RE2 rather than PCRE... No. Why are you guessing? Why haven't you looked at [the source code](http://benchmarksgame.alioth.debian.org/u64q/program.php?test=regexredux&amp;lang=go&amp;id=2) for that Go program?
you can't really confirm the validity of the validators at compile time anyway, because any validation system would itself require some form of validation. E.g. this constraint: `"email": []string{"required", "min:4", "max:20", "email"},` We could model it in a typesafe fashion. Let's say we have some interface `valid.Validator` that validates a value, `valid.All` is a `[]valid.Validator` that satisfies `valid.Validator` and requires every contained validator to validate a value, `valid.MinLength(n)` is a function that, given an int, returns a string validator requiring that the provided value is a string over length `n`, we could write the above constraint in a type safe fashion as follows: `"email": valid.All{valid.Required, valid.MinLength(4), valid.MaxLength(20)}` That's all well and good, but the safety here is purely imagined, since even if you have types, you could have invalid constraints. For example, `valid.MaxLength(-20)}` makes no sense because you can't have a max length of a string be -20. It gets worse when you are composing the validators, since you could potentially create an entirely disjoint union of validators. For example, `valid.All{valid.MinLength(10), valid.MaxLength(9)}` would yield a validator that has no passing values. No matter how you cut it, you need to perform some type of evaluation to determine the legitimacy of your validators anyway.
Please don't discourage people from writing blog posts about Go (or anything else). I really don't want people to wait until they're experts to post, or we'd have no content about Go at all, and then we'd have nothing to learn from. Also, Vladimir *is* experienced in Go, and has written a book about it. The people in this thread seem to be nitpicking details that would complicate the topic for newbies. Yes, the error-plus-data return of readers is an annoying edge case that we all need to be aware of, but it's an easy thing to forget even for extremely experienced devs, and due to that, almost all implementations wait until all bytes are read to return EOF (and for other errors you almost always want to just toss the data anyway). 
Conferences (and SLE in specific) are also peer-reviewed
Just make sure you don't embed anything you don't want a potential user to use. If this is a mutex you intend to use within your implementation, just make it a normal struct field. Otherwise, you're saying that a user is free to call Lock and Unlock as a part of your exported API.
[removed]
Re: alpha_reader.go: to observe the problem, replace line 59 with: fmt.Printf("%q ", string(p[:n])) The output becomes: "Hell" "o\x00\x00I" "t\x00s\x00" "\x00am\x00" "\x00whe" "re\x00i" "s\x00th" "e\x00su" "n\x00" This happens because, on line 44, you advance position in buf regardless of whether you have written to the current position. If you haven’t written, the current position keeps its zero value. &gt; Admittedly, buf maybe overkill but it ensures no garbage chars lingers in p (from index 0 - n) I’m not sure what you mean. p[:n] can be filled in directly by the loop, p[n:] is not touched by the copy. &gt; and makes the slice bookkeeping simpler. How?
Ok, but whichever pointer gets dereferenced in this context, the result is the same as using `r.URL`: https://play.golang.org/p/hXDD4Dj5CN
These are great case studies for data structures. Thanks.
&gt; Please don't discourage people from writing blog posts about Go How does giving a concrete suggestion discourage anyone? &gt; Also, Vladimir *is* experienced in Go, I base my comments on the *content*, not on an authors *name*. The code in the linked article shows basic mistakes that I would not expect of a competent and experienced Go coder. I wouldn't let code that pass the most basic of code reviews. As you say, even extremely experienced devs can make errors, but catching those is one of the purposes of code review, and experienced devs know (almost) all code should be reviewed. 
Same reason mobile processors keep pushing the performance envelope, the sooner they finish doing work, the sooner they can get back to those power saving modes. 
But at least if I spelled 'valid.MinLength' as 'valid.MinLen' it wouldn't compile. 
EDIT: Thanks for putting your talk in blog format. Great content.
The network model your attempting is very error prone if you never have explicit synchronization for your requests and responses. It's sometimes reasonable to setup a second connection for a protocol that needs to send bulk data, like ftp. But I would probably re-evaluate hand rolling your own protocol and look at grpc or other protocols with clear semantics covering all the edge cases if this isn't just for learning. If for learning, debug away friend, you are likely having your internal state become out of sync under high throughput, waiting for an ACK on both sides somewhere.
But why does that matter at all? What's the benefit you get from use the `.pkg`?
Is the `Send()` function ever being called? I couldn't see where it's being called, if it is. Messages being added to `client.bCh` are blocking until they are picked up in the send() function, which might not be happening.
I like sketching out all sorts of linters in Go, even for non-Go syntaxes. Go's so fucking productive that it's replaced Ruby in my toolbelt!
I love build constraints. I have a very weird use case. 98% of my code is in a public repo, but there is a private repo containing the final 2%. The public repo has stubs which the private repo overwrites. Simple solution? Import the private repo as a package. However, that means the public package is not build-able, because it's missing an import. Build constraints saved me, by hiding the import in a build-constrained file, I have to pass in a specific tag to have the import be included. Others can "go get" with no weird trickery but I can pass in a build tag and have my private overrides applied. 
&gt; While wheels []wheel and wheel struct{} are private, the member variables of wheel (Diameter and Color) are public. Well, while we're being pedantic: Go parlance is "exported" and "unexported". Note, in particular, that the notion of un-/exported is package-level, which differs from private/public as usually understood in object oriented languages (where it's type-level). Wouldn't have said anything if you didn't claim being pedantic ;)
While that's true, see https://golang.org/pkg/net/http/#Handler &gt; Except for reading the body, handlers should not modify the provided Request.
There are some nice concepts in there. Keep a focus on making maintenance of a in knowledge base easier. Keeping its content up-to-date and relevant is the hardest part.
Do you have an example code how that is done?
Ugh, the documentation here for this sucks. I had to dig through at least two github issues about it before figuring out how you do this. So, I suspect: // +build !private something here... and then run `go build -tags private` that would "include" your 2% package. How do you modify public repo stubs? Globals? init()? A more concrete example would be interesting.
First off - my apologies for the miscommunications. I came into this sub with the wrong idea in my head. Although I guess technically if something did SIGKILL my program I would still have this issue, but that's not a normal occurrence, so I'm done with that concern. &gt; Are you sure you're not taking a soldier stance here? That is focusing on something to "blame" I.e. Environment issue with signals to divert your attention away from a root cause that could have came from within? Look at the [screenshot](https://imgur.com/a/K1XRY) - that is the issue I was trying to address. I assume it's an environment issue because the same code does not cause the issue on other environments, including... - mingw64 git bash on windows 10 - a normal terminal window on galliumOS - a windows 7 command line I'm familiar with the soldier stance, I literally only encountered this bug on whatever distribution of mingw64 git bash I have on windows 7 on my work laptop. You could probably replicate this behavior yourself if there is a way to send a kill signal to the code snippet I posted. = &gt; I saw the obstacle was the design of your concept, and presented a solution to allow progression to continue. Does the pile of bananas rambling clear that up at all? I do appreciate your example because it's most likely what I would need in a serious project. But until a game engine supports go, I trust Unity's magical Update loops to handle the "tick" behavior. For now I wanted to build a program where a bunch of goroutines just do a thing and take turns operating on some resources. = To clarify my decision to continue in this direction of poor design - I've used a lot of programming languages. Go's easy to use (and abuse) concurrency is a fun new thing I want to play with, that's all :) I will eventually have a project where I circle back to this in my post history for your example of having a tick interface. If that's what I think it is, it would be similar to unity's under the hood script execution and some implementations of async code where a scheduler iterates over a list of subscribed THINGS that do STUFF. 
You're correct, but getting rid of some forms of error through static typing is always an improvement for catching errors ahead of time. 
[removed]
[removed]
obviously this code is written as a library. 
Nothing special. I just want to use the official binaries. I’m not saying I don’t trust precompiled bottle from Homebrew :) 
I'd look into the [filepath](https://golang.org/pkg/path/filepath/) package. [Clean](https://golang.org/pkg/path/filepath/#Clean) will do this: [example](https://play.golang.org/p/PsXNHAJYWF) edit: if what you're working with isn't a filepath and you don't want as many changes as `filepath.Clean` imposes, `path.Clean` also does this, according to its documentation.
Probably separate files that import that 2nd private repo. In addition to the `go build -tags private` flag that /u/titpetric mentioned. It can work like this: https://gist.github.com/protosam/a8900dde24c6fe3ecc1056749131471a
Important to note, `-tags private` must be before any file names. Go is kinda specific when doing this.
I am always delighted to see Go projects that deal with graphics or GUI. It's one of the areas that Go lacks the most at the moment.
This is super cool, but I'm a little confused about how to use it.
Awesome. Looks like it was a lot of work, any memorable moments of frustration or joy while porting to Go to share? Maybe some areas of code that were very difficult to follow or replicate the design from c but came out nicer in Go?
Strictly speaking, all parameters are passed by value. When you're passing a reference (e.g. a slice), it makes a copy of that reference. 
I think ` a := b` is not pass by value but by reference?
[removed]
There's no "passing" at all there, since you're not calling a function. `a := b` does make a copy of `b`, but if `b` is an interface, pointer, or reference type (`map`, `chan`, slice), then (1) the copy is cheap, and (2) modifying one of `a` or `b` will modify the other.
I have to agree with this a little bit. The first code I saw was a function that took a `Space`, so I looked at `NewSpace`, but that has no reference documentation, and `Space` itself doesn't either. I'd love if this package got significant reference documentation to go along with the large number of examples, though, and I'm sure googling "Chipmunk tutorials" would get a number of rundowns of how to start using it. 
Regardless of this being a library, won’t the channel still block that goroutine until send() is called by the user? I’m relatively new to concurrency in go, so this might be a naive thought, but it’s one of the first rules I learned when working with channels. 
I have to do web projects from time to time and every time, I reinvented this wheel. Finally got the time to put it together. Might come in handy for somebody else too.
This contest is frustrating due to lack of specification on some of the problems. I really don't understand how first place (currently) was able to solve every problem flawlessly in a day or so. C'est la vie, some of the problems were fun.
Same here. But I came for Go and some certain individuals that gracefully granted their time to review my code and blog posts, which was incredibly encouraging. I respect those people. I've never seen such an atmosphere in any other communities. I ignore the irrelevant and the negative. Just a handful of good people, helped me to get start with Go relatively fast and they still help me out from time to time. That alone worth a whole community. Yet again Go community (outside the crowded places) are normal, non-trolly people. It's some certain individuals that constructed bands and took over places. I do not see a solution for this.
most instances of pointers in parameters are practically unavoidable (maps, slices, strings, functions)...so this boils down to struct instance parameters...and frankly the advice I have seen on this over the years is all over the place and boils down to "it depends", with most people erring on using pointers still, good points about the cost of interfaces
First bug from about 10 seconds of reading: only hashes first Write content.
Very nice. Interesting find on the `AppendFormat` function. 
@tv64738 This is meant to serve assets (js, css), not streaming big files and I think that's fine. Assign from that, any practical suggestions? I thought of getting (for example) only first 1 KB of data, since we do not know when the last write happens (only if that's a multi write, which doesn't happen for small files) and hash it together with the url path.
&gt; if b is an interface, pointer, or reference type (map, chan, slice), then (1) the copy is cheap ...because only the pointer itself is copied, or the "header" struct in case of a map, chan or slice. This is a typical pitfall if you are used to languages that do a deep copy of all parameters when calling a function. &gt; and (2) modifying one of a or b will modify the other. Almost, but there is a subtle distinction to consider. After passing a map, slice, channel, or pointer to a function, modifying the *contents* of a map, slice, or channel, as well as modifying the data that a copied pointer *points to*, also modifies the original data (because no deep copy happens when passing parameters to a function). However, if the called function modifies anything in the header struct itself, like for example, assigning a new slice to a copied slice variable, changing the length or capacity of a slice, or if it assigns a new value to a pointer, then this does not affect the values of the caller. These changes are lost when the function returns. (This is the reason why `append()` *returns* the slice that it modified, otherwise the original slice would not be able to receive any change made to the header (that is, the length, capacity, or the actual slice data pointed to).)
Oh, ok, now I know what you were after in your original comment! Sorry, I was on the wrong track all the time. You are right, the request header should remain unchanged.
awesome. Thank you
woah, so `a := b` will create a new copy of `b`? like say that you have type struct_one struct { nested1 struct_two } type struct_two struct { nested2 struct_three } type struct_three struct { some_int int } if nested_level2 = struct_three{} nested_level1 = struct_two{nested_level2} nested_level0 = struct_one{nested_level1} a := nested_level0 Does this mean `a` will have a different address than `nested_level0` `a.nested1` will have a different address than `nested_level0.nested1` `a.nested1.nested2` will have a different address than `nested_level0.nested1.nested2` ? 
Maybe it shouldn't be middleware but a few methods on a struct. Then the user can call it explicitly when and how they want and you can have a less restrictive interface, that accepts a r or file path so you can tee to your hash and response writer and can get an eof.
All is pass by value unless you pass a pointer. But passing by value for a **map** or **slice** means copying the reference. So passing map or slice by value is same as passing their pointers, when you modify them inside a function the original ones are modified as well. While passing **int**, **string**, **array**, **struct** copies all content. So modifying them inside a function will not modify the original (unless you pass a pointer) interesting cases: func main() { a := []int{1,2,3} change(a) fmt.Println(a) } func change(a []int) { a[0] = 4 // this will modify original a = append(a, 5) // this won't modify the original } will print [4 2 3] func main() { a := []int{1,2,3} change(&amp;a) fmt.Println(a) } func change(a *[]int) { (*a)[0] = 4 // this will modify original *a = append(*a, 5) // this will modify the original as well } will print: [4 2 3 5] I think passing the map as a pointer or value doesn't make a difference. Can someone confirm this?
I think that's the same reason that the zero value of a map or slice is nil while all other types are usable directly even without initialization (their zero values are not nil)
It rebuilds the related binary every time. You can make subsequent test runs faster by first running `go test -i ./pkg/blah/...` before running `go test ./pkg/blah/...`
Funny, I think the Go community is one of the most fluffy, welcoming and sometimes downright "Teletubbies" communities I have ever seen. Try asking on the #general channel at the [official Go slack](https://gophers.slack.com/) next time. What exactly about your experience at [your post](https://stackoverflow.com/questions/46284285/which-is-better-for-testing-for-non-finite-floats-isnan-or-isinf) did you feel as "harsh" ?
Also reading those two posts gives a much better idea: https://blog.golang.org/go-slices-usage-and-internals https://blog.golang.org/go-maps-in-action
Yep: https://play.golang.org/p/VygP7SR9or
I had to add an int for every struct as when I didn't, all the nesting is useless. All nested structs have the same address in memory like the parent one as no need for more space in memory to add the nested struct. (you can remove the ints inside the structs from the link I posted and you'll see what I mean)
&gt;I personally prefer declaring methods 'outside' of the type, because that's just more screen real estate. In class-based languages you always lose a bit of space due to the extra indent. Also, this just looks weird: You'd have the exact same problem with go and in fact even worse because you have to close the struct before you can define funcs on it. Furthermore it's more typing since you have to declare the struct with every function definition. &gt;Also, how am I going to tell the language that 'this' is a pointer in certain methods? I have no idea what you are asking. Ruby doesn't have pointers. You can always return self if you want.
Thanks, I get the idea now :) 
No, because that isn't a safe atomic operation, *and* it doesn't come with a way to (correctly, fairly) block the add until the condition becomes false in the case where it *is* true.
These "build an API" blog posts are wholly inadequate. Where is the logging? Where is the authentication? Where is the permissions system? 
Previously I've used a http.FileSystem (which I think is very close to your suggestion) and it was a middleware that would explicitly handle files - it sits before a http.FileServer. But reading files twice (once by this and once by http.FileServer) and calculated hash felt cumbersome. But I'll look into those codes again. Thanks!
Yup, indeed.
Actually I was trying to add what I posted in my original question into the internal sync waitgroup.go file, and using the wait function already made, along with writing the `if wg.count &gt;= wg.limit {` inside the `wg.Add(1)` function itself made it safe.
I'm very interested in this aswell. The only example i've come across is this https://github.com/go-chi/httpcoala
For what it's worth, I've found that maintaining strict ownership of stack objects (and always verifying with -m) by allocating them as values and passing their pointers down the stack is the biggest winner in the escape mitigation game. We use this liberally so that goroutines own things like underlying buffers that can be used safely by a single thread and which never escape. Interesting that you guys had to dodge the pointer in time.Time! One of our biggest offenders is a monitoring library that has a super common interface function that takes in variadic arguments. The number of allocations caused by that one call alone are crazy. Concrete types for the provider, let the caller apply the interfaces &gt;&lt;
there is a lot wrong with this code, but as to your specific question: looks like you are not sharing "as" between calls... that is, your assetSync sets/gets are not done under mutual exclusion. example: https://play.golang.com/p/Ua7gjQnbAf note I've moved "var as ...." to line 8. by the looks of the code, you haven't done a lot of concurrent programming, so I would encourage you to experiment with it. Its one of those skills that are invaluable. edit: here is an example of some better code. not perfect, but focuses on the locking for you. there is also sync.Map. https://play.golang.com/p/SrHbuCTJtr
Not really. There's an abstract committee, but definitely nothing resembling the degree of peer-review in academic journals.
I would like to add that the second one on that list (go-wiki) is just a toy project I created as a process to learn Go. But I posted it to HN (and Reddit I think?) and now it has a bunch of stars...
[removed]
thanks. fwiw the protocol im trying to implement is an industry standard in telco. im aware of mainstream protocols but unfortunately the server that i'm trying to connect to only speaks this protocol. 
To elaborate a bit more, it's having to build the binary and all dependences. Pure Go packages are pretty quick to compile, but lots of dependencies can take a bit of time to find on disk and compile. If any of the code has any C or C++ to compile, the compile time goes up significantly (sqlite for example.) e: If the packages are installed, as mentioned with go test -i, it doesn't have to recompile the dependencies (unless their source has changed.)
Is that really a problem, though? Go is quite happy server-side and client side thick client stuff space is mostly mobile - Swift and Java's territory. I don't see anyone abandoning C++/C# for thick Win32 apps, and Linux people seem to have settled on Python with its Qt/GTK bindings when performance isn't critical. Obviously Swift is where its at in Apple's eco-system. The only other modern cross-platform toolkit I can think of that's not Qt is Electron and that's JS. Go chasing thick GUI client apps reminds me of the lost "Linux on the desktop" wars from 20 years ago - so much reinventing the wheel for almost no tangible result. 
&gt; Assign from that, any practical suggestions? With apologies because I don't mean this personally, I think this is just a fundamentally flawed approach and there aren't any practical suggestions. This isn't a general ETag middleware, this is an ETag middleware for static files where the first bits of content are guaranteed to differ from both all other files and from the user's cache (i.e., if you change the end of the file this may tell the user their copy is still valid) and a few other assumptions that must be true for this to work, and those assumptions aren't going to be something you can remove without fundamental work. Broadly speaking, trying to generate the entire content of a web request and use ETag to abort it at the last minute is a web antipattern. ETags only really come into their own if you've got some way to figure out from the web request that you can abort the request without actually doing all the hard work of putting the page together. There really isn't an easy way to use them, unfortunately. I'm actually disappointed in 2017 that this isn't considered a common feature of a web framework, where it does some dependency tracking of incoming data and the requests used to render them and does something to make ETags relatively easier to use than they are today. (But it is a case of something that is legitimately difficult to provide in an imperative context and most web frameworks are still imperative, of course.) (For all the massive profusion of web frameworks there are in the world, there's actually some simple stuff like that that I continue to be disappointed is missing.)
I sometimes wonder if I'm just odd in hating multi-line if conditionals. Since the if conditional, [seen here](https://github.com/dc0d/cache-control/blob/master/cache-control.go#L43-L46), is gating literally all of the code except the return, why not flip the logic around. Have a few distinct condition checks that bail early. Then the body of the original if condition becomes the body of the method instead. Edit: Thinking about it a little more, that entire conditional statement should be moved to a method. You can then unit test the cache/no-cache logic on it's own and clean up the conditional considerably.
Very nice write-up, but I think the interfaces cost are a bit exaggerated, and you can lower the difference using sync.Pool and hash.Hash*.Reset().
My only pain points in the conversion were self-inflicted. I should have done an exact conversion of the functions instead of trying to make idiomatic Go, then I could have copy/pasted more and avoided typos and make the code idiomatic later when everything was working. There wasn't anything surprising as Go is really close to C. I converted some pointer arithmetic for array traversal to slices, and I chose to use channels as a memory pool. I have to give praise to the chipmunk authors who made a really solid codebase! 
&gt; With apologies because I don't mean this personally, I think this is just a fundamentally flawed approach and there aren't any practical suggestions. This isn't a general ETag middleware, this is an ETag middleware for static files True, &gt; where the first bits of content are guaranteed to differ from both all other files and from the user's cache (i.e., if you change the end of the file this may tell the user their copy is still valid) and a few other assumptions that must be true for this to work, and those assumptions aren't going to be something you can remove without fundamental work. As far as I could understand from Go internal file server, it call Write once, but I am curious to find out the exact behavior, &gt; Broadly speaking, trying to generate the entire content of a web request and use ETag to abort it at the last minute is a web antipattern That's not the case. Query path is used as a key in a map, it won't get recalculated unless it's the first time or max-age has passed. &gt; ETags only really come into their own if you've got some way to figure out from the web request that you can abort the request without actually doing all the hard work of putting the page together. There really isn't an easy way to use them, unfortunately. I have another package that takes a http.FileSystem and the request and loads the file itself, as a middleware. So it's possible. I wrote this one to take advantage of the Write method of the ResponseWriter. &gt; I'm actually disappointed in 2017 that this isn't considered a common feature of a web framework, where it does some dependency tracking of incoming data and the requests used to render them and does something to make ETags relatively easier to use than they are today. (But it is a case of something that is legitimately difficult to provide in an imperative context and most web frameworks are still imperative, of course.) Indeed; the frustration is exactly why I wrote this. &gt; (For all the massive profusion of web frameworks there are in the world, there's actually some simple stuff like that that I continue to be disappointed is missing.) Sure things are not perfect and that's good! It means we can improve things! Thanks! 
Thank you, I appreciate the feedback. I will test the second example you sent and see if that works. I agree the code is a mess, it’s based off code that’s a few years old and it’ll eventually be rewritten but as you can imagine a lot of the other code looks similar in style and also needs to be rewritten, so it’s a slow process. I initially did what you suggested in your first example, but when you run parallel requests to that the app essentially locks up because now all requests are waiting for the slowest request, even if another asset is a lot quicker to access than another.
@metamatic thanks you for the list, I've glanced through it and unfortunately everything looks years away from what we are currently using (https://wiki.js.org/).
Yes same boat here, we are currently using https://wiki.js.org/ and it looks great but has some rough edges, just to give an example, we have to wait for v2 to be able to delete a wiki page without going directly through the git repository (?).
@HarveyKandola this looks interesting, I will play with it in the next days. I will have married VueJS instead of Ember though.
Somewhat strange to use methods that aren't going to be visible outside a package on an exported interface.
Agreed, me too. I liked the practice by Martin Fowler that says when you feel your code needs comment, write a function/method instead. I've even developed a tool that checks methods/functions with a name convention (_func) are called exactly once (like this case to prevent these if clauses). But I've got discouraged to do so. So I just let them be for sometime and then as you said I'll refactor them into small methods.
Just a heads up, the word you're after instead of "encouraged" is "inspired". You might normally say something like "heavily inspired by". It looks pretty comprehensive though, so nice job with that - there's some good validations in there. Could you make it more generally re-usable though? i.e. maybe make it support validating things other than HTTP requests?
+1 to make it a method with a nice name so that it's a lot more obvious what it's doing. ANd also +1 to performing the shortest path first, even if that means a tiny bit of repeated code. It's just way easier to read.
Electron was only released 4 years ago. I think discounting efforts in Go to provide a multiplatform GUI toolkit disregards that tech like electron has gained a huge amount of momentum in such a small time frame-- if a sufficiently beneficial Go framework came out it could gain traction just as quickly. There's seemingly always a desire for more tools that can improve on existing tools in the GUI / graphics space. 
Martin Fowler's advice can easily be taken too far. In this case, I think it makes perfect sense to turn this mess of conditionals into an isFooBar() method. However, saying that you should write a function instead of a comment means you're writing the wrong comments. Function names should talk about *what* they're doing. Comments should talk about *why* you're doing something. So they should generally have little overlap. Like this: func url2filename(s string) string { // ugly string munging here } s := foobar() // foobar returns a url, but we need a filepath, so // we convert it to a valid format path := url2filename(s)
Regardless of what it's meant to serve, it's broken. An `io.Copy` or such is free to make e.g. multiple 4096-byte writes, if it wants to. The obvious correct answer is to hash all of the response body. Since you're trying to construct an Etag that needs to be in a header, you'd need to buffer the body.. which can be a bit silly and counterproductive. That, to me, says that you're trying to solve this at the wrong level.
Go is always pass by value. Always. Sometimes that value is a pointer, but it's still a copy. maps, functions, channels, slices, and interfaces are all pointers underneath the hood. (and obviously anything that is explicitly a *foo type)
Most "web frameworks" basically give up on the idea of Etags for dynamic content, and the common scenario for Etags to work is static files (or nearly-static files; e.g. updated once an hour).
please don't use the word reference. There are no references in go. There are pointers, which are just a value that you can use to access a location in memory. I know it seems silly, but the word reference confuses people. Go has pointers, that is all.
One option here would be to cache the file's checksum in memory and only re-hash it if the `ModTime()` you get from `f.Stat()` is different that the previous one.
I was looking for the series of tutorials and then I noticed it's an ongoing blog post which will eventually be a series of tutorials.
I refactored the code. Check it out! :)
Easy peasy: the "success" of electron is only because if JS. I don't see (yet) the needs for gui stuff in Go, i'd like to put more efforts on improving compile times and performance (this more than everything) for the niche that Go fits in right now. (microservices)
Please add a custom rule to check username [see here](https://pastebin.com/yGhJu8JP)
&gt; I'm implementing a custom protocol over TCP. A industry standard in telco.. might of been good to include the standard instead of saying it was "custom". Heh.
Thank you, I have updated the word. It's a request validator so it's main focus is to validate the HTTP requests. If you need struct/map validator then you should use go-playground/validator
&gt; You can use a bash script to do the work for you. Or better, at least for me, you can write a makefile. See, my problem with makefiles is almost entirely the fact that they *are* bash scripts. Not only do they not work on Windows, but bash is just a terrible programming language. No one would use it if it weren't the lingua franca of the command line.
this is just the same slow if not slower. How about -c?
With little effort the make will work also on Wi dows with cygwin or gitbash. But you are right it is little painful on Windows. 
Really? golang.org uses the word reference. Besides, what do you call following a pointer?
slngleflight https://github.com/golang/groupcache/blob/master/singleflight/singleflight.go
It's not necessarily that it's a little work for you, if you want to do it, it's that it imposes that work on anyone else you want to use your library. You're already writing in Go, so all of your library's users have Go, and using Go for scripting isn't very hard. Why not write your makefile as a Go file?
`-c` would skip the step where it runs the test and you'd have to run it yourself. While this might, ironically, make it feel faster, it would not actually be faster. If it isn't being fixed by `go test -i`, which was my first thought as well, the next thing to try is running `go test -v` and just watching the output. If the first output `=== RUN (your test name)` comes out quickly, then the compile is happening quickly enough; you may have a slow test. If that still isn't fast, and if you are not compiling an excessive amount of code in your package or linking to an excessive number of packages (lots and lots of "import" packages, like, many dozens), the next thing I would be looking at is the system itself; are you in swap? Is something eating 100% of your CPU that you didn't know about? Have a look at your hard drive's SMART statistics, too. I have had hard drives that "work" but are actually throwing errors every which way, in which case you need to stop working on your Go program and start getting everything off the drive. (Long shot in terms of fixing this problem, but worth mentioning due to the high potential impact.) Failing all that, I think we'd need to see the test code in question, if at all possible. Right now, with all due respect, your report is basically "It's slow. Why?" There's not a lot to grab on to, there; we barely even have a hint what "it" is. [You may find this helpful](http://www.catb.org/esr/faqs/smart-questions.html).
Use maymay (https://github.com/mcandre/meme) to help write cross-platform Makefiles As much as I enjoy make, this bullshit is one reason why plugin based DSL like Gradle and Gulp are more reliable for cross-platform development. Shells are flakey.
Interesting point, never thought about that this way.
I use "makefiles" written in go. It works pretty well. Obviously more verbose than bash, but it doesn't have to be horrible with some helper functions, and the error handling is so much nicer in go.
Yes, it is valid JSON: http://json.org/. Arrays can have any value and the values do not need to be the same type.
wow, will the go json package do this? I guess an array of interfaces...?
its a protocol by nokia, cimd. the protocol parsing is straight forward since its just key value pairs. the tricky part is the request coming from the server that needs to be acked.
&gt; so much reinventing the wheel for almost no tangible result. Assuming the GUI is written in pure Go then easy cross compilation will be possible.
The Go community has grown a lot. There's no reason those can't be done in parallel.
&gt; processes hundreds of thousands of events per second "It depends". On my desktop, I'm showing 2.27 nanoseconds to make a do-nothing call through an interface, in a tight loop where I'm pretty much guaranteed everything is always in L1, so best possible case. Let's make it a round million events per second I want to handle, so that makes it 2 milliseconds out of my 1 second budget, or .2%, _just_ to make that one interface call. By contrast, a concrete call could well be inlined so that it costs no overhead, or could be something like 4 times faster for an actual call. That's not enough to instantly disqualify that as a solution, especially because we can also get some overhead back as we start using multiple cores, which they almost certainly are, but we're definitely up into the range where we need to be paying attention to the costs. And remember, that's the cost for _one_ call, just to give you a ballpark feeling for what they're looking at there. If you need to make a few hundred interface calls in order to handle your event (and for loops can make this sort of thing add up quickly), you can definitely be looking at a problem. Of course, I don't worry about it until it becomes a real problem. An interface call in Go is still an order of magnitude (or more!) faster than any function call in Perl or Python or similar language.
Take a look at https://github.com/faiface/pixel Pretty active, and GUI using it is also on the table.
This is a great answer. Thanks
Yay! I found some other physics libraries in Go that for one reason or another I thought were lacking or nothing I liked being non-pure Go. Maybe this could be like an addon to https://github.com/faiface/pixel ? That is what I will use it with at least. :)
Yeah I know about it but thanks. The GUI/graphics libraries in Go are very few so it's not hard to keep track of all of them and pixel is one of the best.
...then you'd have two problems.
The problem is - because Go doesn't have an instrument to guarantee inlining you are basically stuck with "handcrafted method body that will LIKELY be inlined". Likely - because rules change from version to version, and while they are getting better, there is no promise about methods being inlined in any version of Go. Another problem is that inlining itself can become an issue - the big functions are bad for cpu - a lot of state to be stored, not a lot of registers to manipulate. The instruction cache is also not that big (that's why C and C++ community had numerous debates on where it's actually worth it to inline). And when we are talking about 3-10 lines of code - I'm not convinced we shouldn't manually inline it anyway. The interface is also about abstraction - usually it shows that there is more than one implementation of data processing. And while there will be always cost for this abstraction - the cost of processing itself is likely to be much bigger. That or there is wrong abstraction. There is also thing about tracing and the fact that profiling can be unrepresentative. That and OS and CPU specific things. My point is - the likelihood of interface being a problem is extremely small. And if it is - you're likely having a wrong abstraction. 
It makes sense to me to use Makefiles for doing things that cannot be done (easily, conveniently, or at all) without Makefiles. In the case of Go, I just don't see what can't be done without Makefiles for vast majority of simple projects (things that aren't as huge and complicated as Kuberentes, etc.). The best part of _not_ using Makefiles is there isn't a project-specific Makefile. Instead, it's the same set of Go commands that work on any Go package in your GOPATH. Nothing to maintain and keep in sync or learn and tell others to learn. The best kind of Go package in my mind is one that contains just 2 files, foo.go and foo_test.go. Just by knowing its import path, and nothing more, you already know how to build it, how to test it, how to read its documentation, etc., etc. Imagine 1000 packages like this, they're still easy to work with, and you can use [import path patterns](https://golang.org/cmd/go/#hdr-Description_of_package_lists) to work with them in bulk. Imagine 1000 packages, each with a custom Makefile. What would you rather deal with? In the end, I'm not afraid to use Makefiles when they're helpful. In C++ projects, they were unavoidable and helpful. However, I feel very fortunate that with Go, I can get away without needing them.
&gt; In the case of Go, I just don't see what can't be done without Makefiles. A good example is building your application. You usually need a bunch of extra ldflags and a way to grab the version of the binary from git tags or whatever.
If you need to pass particular command line flags, such as linker-set symbol values or test parameters, you force your users to do that. If you need to do any sort of non-trivial code-generation, you force users to do that. If you want to actually optimize repeated test runs, you need to run `go test` with different parameters to install deps and then run tests. All of these are shortcomings in the ethos of "the go tools are all you need". CF the kubernetes Makefiles. Kubernetes takes many minutes to compile from scratch, and something like a half hour to run all tests. Go misses EASY optimizations on this, that we wrap up in scripts. Go's pathetic code-gen support means I have to basically use `go list` to emit the DAG that Go already follows internally, in order to trigger external commands only-when-needed. blech
Yep, that would be a valid use in my mind. The article (and most Makefiles in Go packages I've seen) also try to create replacements for `go build`, `go test`, `go generate`, etc., which are not neccessary.
 go func() { for { var wsDialer websocket.Dialer wsConn, _, err := wsDialer.Dial(structs.GDAXExchange.Socket, nil) if err != nil { println(err.Error()) continue } if err := wsConn.WriteJSON(map[string]string{"type": "subscribe", "product_id": "BTC-USD"}); err != nil { println(err.Error()) wsConn.Close() continue } if err = wsConn.WriteJSON(map[string]string{"type": "subscribe", "product_id": "ETH-USD"}); err != nil { println(err.Error()) wsConn.Close() continue } if err = wsConn.WriteJSON(map[string]string{"type": "subscribe", "product_id": "LTC-USD"}); err != nil { println(err.Error()) wsConn.Close() continue } message := Message{} for { if err := wsConn.ReadJSON(&amp;message); err != nil { println(err.Error()) break } if message.Type == "match" { switch message.ProductId { case "BTC-USD": structs.GDAXExchange.Coins["BTC"].Price = message.Price structs.GDAXExchange.Coins["BTC"].Buy = structs.GDAXExchange.Coins["BTC"].Price structs.GDAXExchange.Coins["BTC"].Sell = structs.GDAXExchange.Coins["BTC"].Price case "ETH-USD": structs.GDAXExchange.Coins["ETH"].Price = message.Price structs.GDAXExchange.Coins["ETH"].Buy = structs.GDAXExchange.Coins["ETH"].Price structs.GDAXExchange.Coins["ETH"].Sell = structs.GDAXExchange.Coins["ETH"].Price case "LTC-USD": structs.GDAXExchange.Coins["LTC"].Price = message.Price structs.GDAXExchange.Coins["LTC"].Buy = structs.GDAXExchange.Coins["LTC"].Price structs.GDAXExchange.Coins["LTC"].Sell = structs.GDAXExchange.Coins["LTC"].Price } } } wsConn.Close() } }()
 * I'm not a fan of the "pkg" package. Not sure where this came from but it's so ambiguous. I'd just move everything up a level and remove the pkg subpackage. Completely subjective. * TBH I don't understand why you created all the subpackages. In this case the code is so simple and straightforward the subpackages make it harder to navigate. In this case I see no reason to have client, parser, etc in their own packages. * Test? How are you sure that the information it's giving me is correct? Nothing else really sticks out, the rest looks reasonable.
Does it? Rob Pike has even expressed remorse that he ever used 'reference' when referring to slices, maps, channels, etc. because they have concrete types and semantics that differ from true references. &gt; Besides, what do you call following a pointer? I don't know how this makes your point. You de-reference a _pointer_ not a reference. In other languages with true references you can't de-ref a reference—it just _is_.
Alternatively, maybe la light weight one `strings.TrimRight(path, "/")`
Makefile is a terrible format. Don’t perpetuate it if you have a choice. Just write a Go program to do your builds for you. It’s easy and it uses a format you know your users will know. 
You can, but for instances like this I typically end up using something like https://github.com/buger/jsonparser
I think that if your application is hinging on 10uS of validation turning into 100uS of latency, then you are probably not the target audience. On the other side of the coin, 10x degradation in performance is frequently more desirable than a panic at runtime crashing the whole goroutine (or more) due to mis-spelling a validation rule before build time that went unnoticed. 
That is why I like things like that Pixel library. One day a nice GUI might come for it, that will be much more light weight.
It does. From the FAQ: &gt; Slices and maps act as references I'm not going to get into the definition of reference debate. Go absolutely has references simply because it can have things that refer to something else. That's what a reference is. Some CS people want it to mean something else, something more specific. That's fine for them -- for them, Go may not have references. For myself -- I'm not going to break a common English word.
Everytime I think "modern C++ might be a good fit for this project" I start to think about headers, installing libraries, makefiles, autoconf/automake, cmake, CXXFLAGS, gdb... Then I go "Nah. Go will be fine."
Steve Francia and Nicholas Jackson's talks are particularly good.
There's also a more simple Ragel/Go example at https://github.com/baliance/gooxml/tree/master/spreadsheet/format There I use Ragel to create a lexer for Excel's number format strings (e.g. "0","$#,##0", "dd-mm-yy", etc.) to allow retrieving a value from a spreadsheet as Excel would display it. 
I use makefiles. I use them for compiling, for installing, for deploying to remote systems, building container images, and more. I tend not to do things that aren't pretty readily handled by a makefile. 
Indeed. The primary difference in meaning is that a pointer must be explicitly dereferenced; whereas a reference, once created, is implicitly dereferenced whenever its symbol is used. In that sense, slices are references (plus some data size information), not pointers, because the internal pointer in the slice data structure is dereferenced automatically and invisibly when the slice is used.
How is make a terrible format?
PHONY
&gt; For myself -- I'm not going to break a common English word. I think most of the pushback comes from a situation like this: var a []int func foo(a []int) { a = append(a, 1, 2, 3) } func main() { foo(a) } Obviously it's a dumb little example, but it's not unusual to see newcomers to Go assume slices, maps, etc. function identically to "true" references (a la C++) because people call them references.
And what's so bad about `PHONY`? All it denotes a target that doesn't correspond to a file output. .PHONY: clean clean: $(RM) -r build
Does this mean their go language server is going to be developed into a full language server for editing? Right now it just does goto definition and basic linting iirc.
Why do I need to do that, when the common case is to have a target without an output? Why is that of all things the way to denote no output? It's a goofy format. 
Well, the idea is you can create a set of rules (using a pattern, for example) that correspond, one each, to a .a or .o file, then those rules are skipped if the file exists. This doesn't really make sense with Go, but for something like C or C++, it's a simple way to speed up building. Think something like (please forgive my terrible handle on Makefile syntax and clang): compiled_sources := $(subst $(wildcard ./src/**/*.c),.c,.out) $(compiled_sources): cc -c $(subst $@,.out,.c) -o $@ .PHONY: build build: $(compiled_sources) dothelinketc Now `make build` will create all those .out files, and you just need to remove the one you want to re-compile. But yeah, it's an old tool for an arguably by-gone era. But it works, and it works well. I'm not sure its necessary for most Go projects, however.
I think the last time I used a makefile with Go was so I could run everything through a C preprocessor ([GPP](https://logological.org/gpp)). There were downsides though. Line numbers are thrown off. And conditional compilation sometimes meant having conditional imports as well, since unused imports are forbidden.
Thanks a lot, this a part of Go that's rather obscure to most people and it's great to see it used outside the Go repo itself.
EDIT: never mind, not getting into this argument :-)
I tend to use a `Makefile` as "executable documentation", and also for cross platform builds. It shows how to perform all the steps for setup, linting, build, test and deploy. My `deps` target usually looks like this though, as I prefer to let the Go tooling (`go get`, or these days `dep`) to handle dependency installation. deps: # or "go get -t ./..." dep ensure I usually have a `tools` target as well for installing tools used in my build process and development (linting etc) tools: go get github.com/golang/lint/golint go get github.com/golang/dep/cmd/dep I see less CI "debugging" issues as well because you run the same build process locally, rather than lots of steps in a `.yml` file (or whatever) on a build server that you can't really debug quickly locally. I also always have a `make deploy` which fires of the preparation, tests, compile for target, builds the container, uploads app and service config and restarts the service.
This is actually not a valid json. I have highlighted the error: { "type": "subscribe", "product_ids": [ "ETH-USD", "ETH-EUR" ], "channels": [ "level2", "heartbeat", { "name": "ticker", "product_ids": [ "ETH-BTC", "ETH-GBP" ] },&lt;-- Error ] } *edit*: Enhanced highlight
If you think that is the common case then it explains why you don't like makefiles. They are literally for making things, which depend on other things, that are files within the unix world.
I've found a number of those in other languages. The author gets bored after the second or third one and the 'series' ends with that....
Nothing in the article that is new. In fact author does not use the power of makefile. For example, * dependencies should be run only if Gopkg.lock is newer than vendor directory. * build or test should only run if source or test files changed. If you know about `go list`, you can combine it with makefile to run test only if one of the source or test files is changed. And so on. *Oh is it September now?*
That's how they always go, then the post chain dies after its a popular result in Google :(
The common case is to have a target with output. The most common case by *far* in typical projects. Make has it's flaws, but this one isn't an unreasonable way to say "Hey, tool that is based entirely on making file X from files Y &amp; Z if X is older than Y and Z ... when I ask you to make file X I don't actually want you to create file X, nor do any dependency checking."
another approach (using the std json library) would be to make a type that contains pointers to possible type of entry in the array, and has a custom UnmarshalJSON method. the UnmarshalJSON method would do just enough custom introspection to figure out what kind of element it was looking at, and then unmarshall into the appropriate entry. 
That's a pretty simple example thanks for that
I like the look of this library I'll try it out
I love BoltDB. Will take a lot for me to switch to anything else. With that, I'm glad to see more database work done in Go. 
I know the title's clickbait but I couldn't resist. Having worked on this project for months, I'm pretty proud of it and would love review, criticism, etc. Documentation is sparse but the tests should be enlightening. It's not a simple system, and more than what is typically offered by an ORM is possible with it (due to it's ETL-like mapping features, etc.).
Omg, I was looking into this!
Have made one contribution to Badger so far. Works perfectly for me on my chat server (shameless plug http://www.raspchat.com), have been planning to pull off a distributed key value store using raft and Badger but so far it’s far from reality 😝 hopefully someone else does it before I do 😁
Setting $GOPATH to a consistent value for repeatable builds. One of my devs was just bitten by this last week, when his GOPATH was pointing to a different location than where he was building, and he incorporated an old version of github.com/lib/pq without .pgpass handling. I asked him to write a makefile for a consistent build, and all is now well. To be fair, you can actually automate a lot in the Go standard tooling using go generate: https://blog.golang.org/generate
Yes, I basically agree. If you need to use Make or inherit a Make project, it’s fine, but it’s not a good fit with Go, and if you have a choice, there are better options. For example, Make doesn’t have a “watch” option, unlike many newer build tools, which do. 
In typical C projects. In a Go project, it’s not the common case. Cf, this article. 
Etcd is a distributed KV store based on Raft (though, not Badger).
It's a good proposal with good points, but looking at [#18517](https://github.com/golang/go/issues/18517) I think there's a small chance it will happen any time soon. I hope I'm wrong.
:-)
...With a bunch assumptions around how you interact with it and the scope of what it might do. 
bravo! I wanted to help add support for negative numbers in text/scanner and see the collaboration guide does not invite me to do it registering a google account on a mandatory way, or accepting a contract to cede code to a project that is already OSI, sucks.
The trivial example posts are a bit repetitive, but they often use somewhat different approaches to how they handle routing and handlers, framework vs. no framework, gorilla/mux or not, etc. It's nice to see different approaches to solving the same problem. But, yes, most seem to just stop at getting the basic CRUD setup and then go no further. Ultimately I just went and bought some e-books for more a more in-depth look at API creation.
&gt; registering a google account on a mandatory way, or accepting a contract to cede code to a project that is already OSI, sucks. The CLA won't go away, no matter what happens with this proposal.
Even the simplest app needs logins, permissions, some way to manage configurations and environments, database migrations, etc. I don't see how writing the ten thousandth blog post on how to do a simple CRUD example helps anybody. Why isn't there a "base" setup which everybody can build on top of and write blog posts about?
Or... you know; don't mess with $GOPATH.
I wonder if their reasons for doing things the way they are are at all similar to the reasons Linux won't move to GitHub: http://blog.ffwll.ch/2017/08/github-why-cant-host-the-kernel.html
I see thanks for the playground, I didn't know that golang does this by default.
Thanks for linking this, I am reading them right now, and they are super helpful.
This benchmark looks like a bunch of lies. Where does it enable actually storing things on disc? Badger defaults to losing your data: https://github.com/dgraph-io/badger/blob/77f23f68f199940a71fcb00606087cbec8fc7f5d/options.go#L96 and the benchmarks don't seem to be enabling that either: https://github.com/dgraph-io/badger-bench/search?utf8=%E2%9C%93&amp;q=SyncWrites&amp;type=
It seems the benchmark disables data safety for others, too: https://github.com/dgraph-io/badger-bench/blob/4d34f91e70bd1eaf82cfe5228b5d32ce468257e8/populate/main.go#L197 Don't do that.
"Bash is why people leave IT." ([Kesley Hightower](https://youtu.be/XPC-hFL-4lU?t=4m25s))
Ah.. you're back to troll a bit more? We disabled sync writes for all, so they get the best shot at high write throughput. Otherwise, their write throughput would be a fragment of their potential.
Right, and as I said, most blogs seem to stop after CRUD and do not add in any of the middleware or other features necessary for a production application. I think a lot of these posts are written by people who are still relatively new to Go and are writing the posts to help clarify their own understanding more than trying to teach Go API design to others. And there's nothing wrong with that. 
You're describing a program.
Github's tooling is unsuitable for the code review workflow the Go project uses.
Was, now it's a lot better than it used to be.
So, is there a gerrit-like tool for github? Is there a way to take contributions without causing a merge (which should be avoided to have an easily understandable linear history of commits)?
&gt; or accepting a contract to cede code to a project that is already OSI, sucks. That is how things work, and it's unavoidable. By signing the CLA for contributing to Go they can ensure they are not going to be sued later or someone will just pull their code back saying it's now copyrighted. It helps everyone, and it's in everyone's best interest that users of Go can still use it, regardless who contributes to it, or from which company. What you don't seem to understand is that reading the CLA takes very little time or effort and that software that's free doesn't need those kind of provisions in order to defend itself from patent trolls and whole category of legal trouble which simply go away. So yeah, it sucks, but it's the only way to protect us from undesired effects. Read it, understand it, ask a lawyer if needed but stop complaining about things you clearly don't understand or pretend to do so.
Yes, github has that feature for a while now.
Oh cool! What is it called? I want to look this up.
It's in the merge options of a PR, have a look
"squash" and "rebase" style, documented here https://help.github.com/articles/about-pull-request-merges/
"a lot better than it used to be." - completely agree. Several times over the past ~2y I was really impressed by announcements of new review-features. "good." - No. It still doesn't even come close to feature-parity with good code review systems (and Gerrit isn't even really *good*).
Can anyone please explain this? I disagree with the proposal, having done the contributors workshop, but I don't get the why is Gerrit so much better. And since I spend 0 time in it I can't measure it
It's sad this doesn't compare https://github.com/syndtr/goleveldb
Gerrit is using feature patchset by default, which means each patchset is 1 commit. Github also added the feature to squash commit. Change in Gerris requires a certain point to be able to merge, you need a 2 and a verified point, without any blocking point (-2). Github kind of has the feature, but not as complete. You don't have to fork a repo to create a pull request, having to fork to make a PR is really unnecessary, defeated the ability to find a good fork. Force push a PR changes the history, make them hard to track in a PR. A Change in Gerrit has several patch set, you can compare them, you won't lose history with Gerrit The review process and UX is nicer in Gerrit, it's hard to keep track of small inline code review in Github Gerrit has all of those features for a long time, since the first version of Android, Github only recently added some. 
I think the complaints are hard to put into specifics. Last time I used the github review feature, things that where either missing or worked awkwardly at best, where viewing only the diff since the last round of review, drafting comments, the interplay between line-comments and PR-comments, tracking the progress on individual comments… On paper, Github has most of the features I'd want from a codereview system. But in actual UX, when you try to actually use them, they turn out to be riddled with small frustrations and bad UX. But the problem with bad UX is, that it's hard to generally talk about specifics. There really is no great way to explain the issues without recording the review lifecycle of a typical change and pointing out all the things while they are happening. And/or comparing it to the experience in a better tool. As a reviewer, I basically want to be able to fire-and-forget a review and then, when coming back, be presented with exactly the context I need to see whether my comments from the last review have been addressed. Similarly, as a reviewee, I want to get a list of things I need to change to move through and address one-by-one. I just found Githubs UI not good for that. It would randomly hide my comments from me as a reviewer, show disconnected diffs, display/hide different sets of comments on different tabs…
I wonder if the advantage of having more contributors onboard would be worth the pain for all the existing contributors having to change workflow and tooling? Or maybe it'd be better to spend some effort to make getting setup with the existing process as painless as possible? I don't know. It does seem that it's easy to underestimate the impact and work involved in a tooling change though, especially when those who will be most effected are also the people who are contributing most to the project.
Can you enforce a certain style on a repository?
Please no!
We didn't expect goleveldb to outperform rocksdb or Badger. At this point, I doubt we'll run more benchmarks, but the benchmarking code is available (linked off the blog post), if you're curious and would like to integrate goleveldb.
Totally agree. Stale content causes more issues than we think.
We started with Angular but switched to Ember, and VueJS was still new kid on the block at the time.
Rigorous code review with GitHub is like trying build a load bearing structure with Duplo blocks. That comment threads are wiped out between new revision snapshots and not easily transposed onto the new one is the real killer. Yes, I acknowledge that GitHub has gotten better, but it's still inadequate. Gerrit may not be easy to use, but it is effective. I realize this may be unpopular, but perhaps Gerrit's implicit barrier-to-entry is a feature in disguise: it requires a modicum of brainpower to offer a contribution and saves the project maintainers from extra junk reviews.
&gt; (and Gerrit isn't even really good). Kinda OT, but is there a system you'd consider *good*? 'Cause Gerrit is the best I've seen so far.
In our old benchmarks goleveldb blew bolt out of the water I think.
[removed]
I don't know most of the code review systems. My point of reference is Critique, the internal code review system at Google. It's not beautiful, but works beautifully.
Please do not obsess over routers. Their difference in speed, if any, is negligible compared to the network and disk IO of a standard web app. Just pick one and move on.
Its about how the router stores the patterns on startup and, when running, does the pattern matching needed to dispatch an incoming request. "The router is optimized for high performance and a small memory footprint. It scales well even with very long paths and a large number of routes. A compressing dynamic trie *(radix tree)* structure is used for efficient matching." (https://github.com/julienschmidt/httprouter) "chi's router is based on a kind of *Patricia Radix trie*. The router is fully compatible with net/http." (https://github.com/go-chi/chi/ 
You say there is nothing wrong with that but maybe there is something wrong with that. First of all it's of dubious value because it's one of ten thousand posts that are almost exactly the same. Secondly when you look at tutorials from other languages they are much more sophisticated because the basics are covered by the language or the framework. So instead of talking about CRUD they are talking about cache management, or clustering or invalidating JWT tokens or encrypting user passwords properly and securing your apps. That might give people the impression that those languages are more suitable for real world apps. 
I just remembered this other library [Oak](https://github.com/oakmound/oak). I am not sure how it compares with pixel but the author seems very passionate about eliminating dependencies: &gt; Because Oak wants to have as few dependencies as possible, Oak does not use OpenGL or GLFW. We're open to adding support for these in the future for performance gains, but we always want an alternative that requires zero or near-zero dependencies. (We are very sad about the linux audio dependency and are considering writing an audio driver just to get rid of it.) This is the attitude we need if we want to someday get rid of C and cross compile the world.
This is slightly OT, but... Does anyone else here feel that the Go project is a cathedral trying to be more like a bazaar, but just not quite able to do it? &gt;I've looked at the source and there are pieces that are good and pieces that are not. A whole bunch of random people have contributed to this source, and the quality varies drastically. --Ken Thompson about Linux &gt;He wrote a polite but firm response back explaining his position. He had worked with a graphic designer to choose a visually pleasing color palette. He said he believed strongly that it was important for the author of a system to get details like this right instead of defaulting on that responsibility by making every user make the choice instead. He said that if the users revolted he'd find a new set of colors, but that options wouldn't happen. -rsc on Rob Pike re: acme color schemes I think Go has been a labour of love. They don't want it ruined, but they're conflicted because they don't want it being passed-by either.
Thank you for benchmarking! Is it safe to use Badger with Sync disabled? Does it have value log to safely restore?
When SyncWrites are disabled, we still sync the value log when either itself, or memtable fills up. So, worst case, you'll lose the recent writes. If that's a no-go, then just set SyncWrites to true. Every write which is done with this flag on, will be recovered in a crash.* * Unless there's a file system corruption.
I wouldn't worry about "unpopular" so much as "simplistic and incomplete". The score Gerrit would be filtering on is more of a composite of brainpower and dedication. Plenty of very intelligent people with good contributions would just not care enough to figure it out. Resources like * https://golang.org/doc/contribute.html and * https://blog.gopheracademy.com/advent-2016/contributing-to-the-go-project/ and others lower the bar from "intelligent enough to figure out Gerrit unaided" to "willing to find, read, and able to comprehend a guide". Invoking "brainpower" as a filter here is not really helpful.
The the company that develops the Badger finds out its the fastest database... 
Reading comments on github thread I agree with Robert Griesemer and @cznic that issue is strange complain with mix of activism. The assumption is somehow open source itself is an end and contributor experience trumps reviewer experience. I'd rather have core Go hackers have access to top quality tools they prefer than me complaining 'Oh, I can't contribute spelling fixes because contribution process is not to my liking'
Rejecting our analysis solely because we wrote Badger would be [genetic fallacy](https://en.wikipedia.org/wiki/Genetic_fallacy). If you find specific issues with our methodology, do bring them up. The benchmarking code along with observation log is open source (link is in the post).
**Genetic fallacy** The genetic fallacy (also known as the fallacy of origins or fallacy of virtue) is a fallacy of irrelevance where a conclusion is suggested based solely on someone's or something's history, origin, or source rather than its current meaning or context. This overlooks any difference to be found in the present situation, typically transferring the positive or negative esteem from the earlier context. The fallacy therefore fails to assess the claim on its merit. The first criterion of a good argument is that the premises must have bearing on the truth or falsity of the claim in question. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
I have not read anywhere but I think Linus might secretly think not getting drive by contributions by huge 'open source community' by placing kernel github is itself a great value of not using it.
It's still not nearly as good as Gerrit. 
As a side note - do you have good code review systems in mind? 
for clarity nothing better than the GPL or any of its variants, but by using a BSD license we have stupid CLAs that calm the lawyers down
Unikernel seems to be a hot topic recently. Related projects: - https://github.com/achilleasa/bare-metal-gophers - https://github.com/achilleasa/gopher-os
I didn't reject any of the results. Yet I never really have seen a company making a blog post, where their database / product wasn't the fastest / best one. If one of the other databases would have been twice as fast as Badger you most likely wouldn't have published the results in a similar manner. This is why these kind of blog post always smell a little bit like "just marketing".
I can understand. That's why we open source our benchmarking code and running log, so anyone can follow the steps we took to reproduce these results.
And that makes the benchmark pretty much meaningless.
Ah, thanks, so I guess I'll stay with Gerrit for now :-). In the company, we were recently on a hunt and settled with Upsource, mostly because it seems the best one that works with svn (yeah, will still have some svn repos to handle...). It is inferior to Gerrit as well, though. Same with all BB, GH, etc.
As much as I like and use Go and participate here, I do have to agree that while I don't know of any language I'd be willing to hold up as "the only language you need to know", Go strikes me as a particularly dangerous "only language you know". It is important to understand other ways of doing things because sometimes approximating those is the best choice. That said, I still doubt there's all that many people who only know Go, since it's not something I think is being used as a teaching language very often. One element of the interminable "Go generics" debate that I often find myself bringing up is that there probably aren't all that many people using Go who have never used a language with some form of generics in it; the people ranting about how awful it is that Go doesn't have generics often seem to be operating on an assumption that the only possible explanation for anyone disagreeing is that they just must never have used a language that has them to understand how unambiguously awesome they are. But I think this is an absurd "just so" story; there's hardly any Go users who only know Go. At the moment I suspect the vast bulk of Go users are already polyglots, or at least bi-glots at the very least.
Ohh, _that_ sort of clustering. This could come in handy; good job
"Clustering" as in k-means, not as in distributed programming.
I was thinking this was related to networking due to the work "clustering". Might want to clarify the math nature to draw in the audience you're looking for.
Yes, you can select what you want in the repo settings.
I like reviewable.io - it is familiar to critique.
Very nice! I need to test this some time.
Note that these optimizations only applied to a fraction of the codebase where it was needed. The rest of the program still benefits from the high level constructs that Go provides.
You're right, I should have referred to it as "cluster analysis" tool (though I can't change the post title after submission).
I hope so too, but I agree.
On my work projects, I disable the merge button and only allow squash and rebase or plain rebase. It's nice. It makes history much easier to follow. You can also require that PRs pass tests and have a positive review before merging too. Github basically copied the features of Gerrit in the last year or two.
CLAs are necessary because lawyers who know a lot more about code licensing than you or I have said they're necessary. If google's army of lawyers says it's necessary, it probably is, at least for them.
I'm not a lawyer, so instead of collaborating with the standard library I'll take the code that suits me, and make my own versions with casinos and without CLA
The issue is full of comments saying "Yeah, if only it was easier for me to submit PRs I would contribute to make Go a better language", but I fear that a lot of it is empty promises. Anyone who's done open source for a long time knows there's always a lot of people with a lot of good intent talking a lot, but true contribution boils down to a much smaller number of committed (committing? heh) people. And I think those people have taken the time to just get started with the existing contribution flow and contributed already. Basically, what I'm saying is that I don't think making this change will raise the quality of contributions much if at all. And if it slows down the pace of true contributions going into the project (e.g. by having a worse review flow), that's a very bad thing. If there were a lot of existing contributors saying "this is too hard, please change it" it'd be a whole different thing. But as [a contributor myself](https://go-review.googlesource.com/c/go/+/28514), I just don't feel that way.
&gt; at least for them. I generally don't take part in these licensing discussions, but I have a feeling that this quote is the culprit to most of 'em...
Use `Request.Context` not `CloseNotifier`, these days.
right? that's just non-sense complain.
&gt; 'Oh, I can't contribute spelling fixes because contribution process is not to my liking' Exactly. The only people complaining are those who's "contributions" took less effort than the contribution process itself.
1. on GitHub it's impossible to draft a response to a review. Actually, according to this github thread, it's possible but it's so hard to find that most don't realize it's there and I have never seen anyone use it. 2. on Gerrit you can see the diff between any two revisions of the same changeset as well as the diff between any revision of the changeset and the branch base. On Github there is no concept of changeset revision and you can't see anything except the diff between the current state of the changeset and the branch base. 3. On github every time you change a line in a PR all the discussion that was attached to that line will get hidden. Reading the entire history of a changeset is much harder than in gerrit, which has implication both if you are coming into a review that's already in progress and if you are conducting a review.
You don't want to create a Google account but have no problem giving it to Github? 
To add further, what about people who don't /can't access github? Then again someone will claim it is not 'truly open source'. I personally find github as metric of 'true open source' a rather arrogant statement.
Unfortunately with it on you're just measuring sync performance on writes (like my boltdb write performance on a desktop/laptop is always exactly half of my hard disk rpm, though servers tend to be much better with non-volatile write caches and ssds), and it's already an apples-oranges comparison between ACID and non-ACID databases.
I'd also throw in `-x` to see what it's doing before it runs
I got a good laugh regardless. :) I've been pretty obsessed about finding a simplified API for some p2p stuff so I don't have to write my own. Side not, I looked over your godoc. I like how simplified you're keeping it. 
Are these DBs meant to be used with sync off? cos if not, then it seems to me that these benchmarks are pretty much useless. It's like proving how fast sqlite is (I've tested myself and it's really fast) by using a memory table.
So that's a *no* to whether it's safe to use Badger with sync writes disabled? 
I was getting 20k requests/second to a small vps with just the builtin ServeMux, while updating a database with each request. That was enough for the few urls that I had to handle. I've never come close to needing something faster. The problem might come if I had lots and lots of url patterns, or other special needs. If you've got 1000 patterns in ServeMux, that's has the potential to be 1000x slower, if it has to check requests against all of them. You'd want something more specialized that can handle them in o(1) or o(log n) time instead of o(n).
&gt; "took less effort than the contribution process itself" QFT. The current process weeds out a lot of low effort, and bad "contributions". If someone gets through the current process, there is a much higher chance they actually read the guidelines for contributing.
- Got it from here: https://peter.bourgon.org/go-best-practices-2016/#repository-structure - Wanted to keep it structured for future enhancements - That's right, need to write them
Damn, this was a really cool talk. Low level programming is mostly like black magic to me, so this was really interesting to watch. By the way, if someone goes looking for his vim setup, I'll spare you a few clicks ;) https://github.com/achilleasa/vimrc
Most of the times you don't even need a router.. Just use a switch case on the req.Path and you're all set up.
Really cool demo included inside as well!
Everyone who wants to be a good programmer should learn a half dozen radically different programming languages, at least well enough to write some personal utility programs in them.
Internals changed, now calculating md5 from the file itself, instead of using a http.ResponseWriter. For sure there are rooms for improvement. 
Your `Awesome` function would create an instance of MyClass per call anyhow. I've settled on a top-level "var" declaration with documentation that says "Don't change this". There's only so much you can do.
I expect a "DNS client" to be a library or program that can make DNS queries, like `dig`. This is a unified DNS _API_ client, which is actually somewhat cooler and deserves to be clearly identified as such in the docs, I would suggest.
You should start with a few of your own projects, otherwise you might not be able to contribute much. It's much easier to start from scratch than to try to understand someone else's code. 
Awesome! I was just going to need something like this and bang! :D
I agree with the distinction.
Yeah, I did some Googling around after I posted this and exactly what you said was the closest I saw.
That's why you run such benchmarks on realistic hardware, not an old laptop with spinning rust. The whole question is how well does a database manage its operations in realistic use. Measuring something else is pointless and misleading. Hell, since BoltDB is not optimized to coalesce writes (it does the simplest thing, two syncs for every Update), Badger would probably win even more. It's in your best interests!
I did, you called me a troll. Have a nice day.
I've failed to mention this. I've already written some Go tidbits for work. I am not completely new to the language or programming, but I would like to get a better command of it.
Thanks for the idea. I am going to update the repo description.
You must avenge my death, Kimba... I mean, Pimba.
If you have written code for a while, you would have used some 3rd party libraries. You might have noticed some perf issue with a function call, or maybe an extra functionality can be added somewhere. So, I would recommend just finding such a suitable library and contributing to that. You are already familiar with their API, and as a bonus, your code will be benefited from it :)
If you just port a library from Java to Go and keep the API the same, it won't be Go. You can do a one-to-one as a first step, but really, you should rethink the API as part of the complete move.
All three points have been addressed by recent changes to Github. It's still not perfect, but it's probably good enough.
Spoiler alert: They aren't. All of them are, for all intents and purposes, infinitely fast. (routing cost, while not being zero, ends up being completely negligible, no matter what scale you are running at and basically no matter how naively you are doing it. Don't worry about it)
If it's just work in golang that you're looking for, a github search like `is:issue is:open label:"help wanted" language:go` might get you results, but if you'd like to contribute to something that a lot of people use or that has been checked (at least a little) to have some quality you might want to check [awesome-go](https://github.com/avelino/awesome-go).
Cheers. I'll check the list out :)
Bolt did add a Batch() function since I first played with it, which they used in this benchmark. I didn't notice they chose that before. BoltDB's Batch() is scary counter-intuitive though IMO, queueing up callbacks to run later (up to 10ms delay or 1000 callbacks), rather than running them immediately. If you don't expect it, you may end up writing values that are no longer valid, or querying a result before it's written, or have data race problems because it runs from a goroutine. If if one update fails it'll [rollback and rerun](https://github.com/boltdb/bolt/blob/master/db.go#L714) the batch entire minus the one that failed.
We're keeping the Java library along side the new Go one. I've already redesigned some stuff maybe this requires a closer look.
There's nothing specific to Linux or C here. If you pick up any operating systems text book and lookup the chapter on file services, this is the API you're going to see. Including a CS101 mini-class into the docs of every single package just doesn't scale. Thankfully, we nowadays have a wealth of free learning material available that you can get to just by switching to a different browser tab.
This guy is trying to "sell" his web framework. What do you expect him to say?
&gt; What do you expect him to say? Just use the standard library.
https://github.com/corylanou/oss-helpwanted
Agreed; with this concern, in general. Re-inventing the wheel for well established, well known aspects of web development, by per-project, error-prone (and usually badly designed) packages, is super counter productive. Might get a deeper look at this tool-set.
Pure madness. Awesome.
I'm in the same position. I'm trying to break into the go professional world but don't feel confident enough to start applying. I wanted to know what are must knows for building APIs in Go ( something I'm very interested in). I have basic hands on experience with packages like negroni, gorrila mux, gorp, and so on and so forth. 
When I saw the generated boilerplate it was pretty clear this is totally different from what the rest of the community treats programming like. I guess this is the webdev take on Go? At no point was it clear to me why this was done in Go but not PHP or whatever established webdev language.
I wrote Batch. All the mechanisms for coalescing multiple sync writes work by delaying the synchronizing part of the disk write a little; all of them. What do you mean "writing values that are no longer valid"? The rest of your paragraph doesn't seem to align in any way with Bolt's Update/View transactional semantics.
I prefaced it with "if you don't expect it". If someone expects it to work like Update(), running the callback immediately but delaying the tx commit, they can run into those problems. 
What the callback does can depend on the state of the database, which depends on the other callbacks before it. The callback and its persistence cannot be separated from each other, because Bolt transactions are just Go code.
Don't use an exported type. The compiler won't allow users to change it without hacking the library.
[removed]
The public/private casing rule in Go can be leveraged to construct factory patterns: Mark the struct as private, and offer a public method that generates instances
I think the “Marlow column=columnname” is a little verbose; personally I’d just use “Marlow columnname”. Other than that looks nice!
That's mostly orthogonal to this question. If you do package sample var SupposedToBeConst = factoryFunction() then other code can still do `sample.SupposedToBeConst = SomethingElse` if the type is public, which is a reasonable possibility. Making that type private has its own problems, because while Go does permit you to expose values that have unexported types, they are difficult to use. And the decision about whether to export the type or not is not one that you want to be making based on whether or not you've got an exported "constant" you want to stay constant. So, in conclusion, I've settled on a top-level "var" declaration with documentation that says "Don't change this". I actually fiddled with quite a lot of possibilities before that, but they all come with pretty nasty side effects vs. just trusting people not to touch the variables. Also, people are generally _really_ incentivized to not touch those variables because if you don't provide a sync.Mutex or something to synchronize those changes, they're unsafe to change anyhow because it's automatically a race condition once the the program gets past initialization. Granted, that's not the strongest protection in the world, but it's definitely a good reason to leave those variables alone unless something is explicitly documented about why it's OK to change them.
I think the community's advice is a little more nuanced than what was presented in the talk (and I'm sure the presenter understands this). I would summarize the general advice as follows: - If you are authoring a library, try to stick to only the standard lib as much as possible so that users of your library don't have to pull in extra dependencies. - If you are writing an application, start with the standard library so that you understand what it's capabilities are instead of assuming you need a third-party library. Most libraries try to maintain compatibility with the standard lib anyway, so switching to something more feature rich later isn't usually an issue. - Frameworks in general are discouraged as they tend to go for a kitchen sink approach. Just like Go itself and its use of small, well-defined interfaces, the community encourages the use of small libraries that play nicely together. This approach gives the developer more choice and flexibility. Gathering together a list of vetted libraries that work well together and providing them to users in a way that is easy to learn should help ease the pain for those coming from languages with a popular web framework. But I do think there is value in the sometimes unexplained reasons why people just say "use the standard library".
Plenty of examples in the stdlib. For example, the DefaultClient and DefaultServeMux in net/http: https://golang.org/pkg/net/http/#pkg-variables Generally, if it's an interface and the implementation details should stay hidden, leave the type unexported, otherwise a default+accessible export type are better.
FWIW, we didn't notice any performance benefits of using Batch() call in BoltDB, during data loading.
&gt; cc-runtime is now compatible with the OCI runtime specification and works seamlessly with the Docker* Engine pluggable runtime architecture. Clear Containers 3.0 can now also be run using Kubernetes* through CRI-O*, which is a Kubernetes* Container Runtime Interface (CRI) implementation. This puts your containers in lightweight VMs.
Seriously, the examples were bad, misleading, and not pretty Go. I'm sorry to hear the author has written a book about Go, and still puts out something this bad.
The image of gophers stacked up to fix/tune/build "the cloud" is brilliant.
&gt; Also, if a Read() returns a n &gt;0 and non-nil error, you may not trust those bytes an simply re-request. That's not how it works.
This [comment](https://www.reddit.com/r/golang/comments/71lvb1/to_everyone_here_who_keeps_saying_just_use_the/dnc2hm1/) by /u/frebb explained very well the context in which this phrase is used by the community. But I can agree that when the phrase is used out of context, like in the talk, it doesn't make much sense. 
Go is not radically different than most mainstream languages.
Thanks for linking me to that Bourgon article on the package structure. I'll have to investigate further, I can see it being useful for large projects with Dockerfiles and a chained build process. In a small app, looks like it's overkill. Same with the subpackages format. However if you see this getting big or just as an exercise, awesome. Cheers!
I like how one of the gophers is upside down. But because he's on the bottom stack, it doesn't matter, he's still doing his job successfully. That's gophers for you.
Yes! It's precisely these kind of things that I really like to see Go being used for. If I ever need this, it's just go get and import away. Easy to read docs, convenient way to make changes and run tests if needed, etc.
Really happy to see Go used for projects like this!
Australian Gopher
Yeah, this is awesome.
&gt; That's gophers for you. That means disapproving, doesn't it? https://dictionary.cambridge.org/dictionary/english/that-there-s-for-you
Nice! I implemented some Hierarchical Clustering algorithms a couple years ago too: https://github.com/pbnjay/clustering Mine aren't very fast or resiliant, it was mainly for some small problems I needed a quick analysis on. Great to see some more interesting/better implementations now available!
Thank you thank you!! My intent was to support the same field related goodies developers get from other ORM layers like validation, update hooks, or whatever. The m.o is to be as flexible as possible while maintaining compile time type safety assurance. This is very much so an experimental project in the space of application-data-layer interfacing. The more and more i play around with this though, the more and more i see myself being a consumer of if it. I haven't really come across a "oh sh*t this wont work" moment yet. I absolutely love the go language and with the phenomenal standard libraries they offer for parsing golang code, I've yet to come across a (data layer) problem that cannot be solved with generated code; especially when our structs resemble exactly the underlying data source architecture. I love the golang community. ❤️
Thanks, I really appreciate it! It's one of my first Go projects, and I had a great time writing it. I doubt it's something people will need in their daily life, but I love Diablo II and I wanted the private server community to have an Armory where they could view all characters on the server.
I didn't know that, thanks for pointing it out. I meant it in a positive sense, like "that's [the eccentric and awesome] gophers for you."
https://github.com/google/go-github is quite friendly to beginner contributions. There's a lot of precedent for how to do things and previous examples to look at, but also a chance to investigate issues and find solutions.
These have been the 8 best years of my programming life. Thank you Go.
Also, i mean if they change it and it breaks its kinda their own fault. You warned them not to do it. 
Can't help if you say you want a static final java object. Instead describe the object itself, what a user can do to it. Then you can get the most idiomatic suggestion. What others posted here is reasonable, but you can in fact get the identical behavior as this. Just because you return a value doesn't mean you can't grant access to mutate or read the state that you want. Go strings and slices are a good example that I imagine will click right away what I'm heading towards. type state struct { privateFields string; ... } type MyClass struct { s *state } // now my class has methods to mutate / read state but // pass by Value only so no one can change what Awesome // returns. It's cheap as passing a pointer around so no real // penalties. var awesome = &amp;state{} func Awesome() { return MyClass{awesome} } // If you wanted to really go full anti pattern and // write something I could only describe as Gova // you could... type MyClass string const ( Awesome MyClass = "Awesome" ) func (s MyClass) SuchFinal(muchPrivate string) { govaMap[s].privateStuff = muchPrivate } var govaMap = map[MyClass]*state{ Awesome: &amp;state{...}, } The reflect pkg Value T is a good example too, it always returns a value with three words that point to internal types. It still has a full (one of the largest in the std library in fact) API that mutates internal state. Still though, in the spirit of Go try to justify complexity, ask yourself: would i assign to a global variable "by mistake". Other developers will have the same answer.
&gt; list of vetted libraries that work well together and providing them to users Is there such a list? One problem in this community is that every sort of wheel gets reinvented from time to time and there is no will to provide stable tools, tiny or big, which accumulates community efforts in form of a reliable, well maintained package. And this reinventing the wheel is about well known aspects of web/app development - logging, cors, authentication/authorization, etc, etc - not rocket science, not corner cases, but public scenarios that has a dependable solution in all other PLs (Python, Ruby, PHP, C#, etc). That's why they get footage better: accumulating efforts.
[Here](https://groups.google.com/d/msg/golang-nuts/DN2-F7wrDqs/Q_RM31GFAAAJ) is one good example (by Sam Whited). Reposting it here: - https://godoc.org/golang.org/x/net/xsrftoken - https://godoc.org/golang.org/x/oauth2 - https://godoc.org/golang.org/x/oauth2/jwt - https://godoc.org/golang.org/x/oauth2/jws - https://godoc.org/golang.org/x/net/netutil (contains a method for limiting simultaneous connections) - https://godoc.org/golang.org/x/net/websocket (though I've heard that some people prefer https://godoc.org/github.com/gorilla/websocket) - https://godoc.org/golang.org/x/time/rate (rate limiter) - https://godoc.org/golang.org/x/net/trace (request tracing) - https://godoc.org/golang.org/x/text/secure/precis (Unicode safety) 
I really appreciate how you abstracted the actual cluster set, stopping condition and the linkage type. As you pointed out I focused on performance rather than extensibility, yet it would be instructive (and empowering for the users) to define generic clusterers and their components the way you did. Thanks for sharing!
Awesome. 5 years since I began my go journey. Easily the best 5 for me too
Oak is cool. What I'm mostly worried about is how active Shiny development is. Also, using GLFW, I recall that running on mobile isn't all that hard to do either.
Rob 'Commander' Pike ^^
&gt; What I'm mostly worried about is how active Shiny development is. Yeah same here. But after the first disappointment of [gxui](https://github.com/google/gxui) I wouldn't be surprised if it happened again.
To prevent someone from creating multiple instances I recently started using this pattern import ( "sync" ) var once sync.Once var awesome *MyClass type MyClass struct { string } func Awesome() *MyClass { once.Do(func() { awesome = &amp;MyClass{"Awesome"} }) return awesome } https://play.golang.org/p/yNoKLjoUXv
I've recently been using that pattern also for Singletons in Go. I could use that but feels like it would be a lot of boilerplate to get what I'm after, but that doesn't mean it's wrong. A lot of good ideas on this thread trying to figure out which one works best for our situation.
The web dev world is a giant ghetto of snake oil salesmen selling their "framework du jour" of "amazing library" all designed to fuel traffic to their shitty blogs. It's all it is. The Node eco-system is a case study in this - it's the worst I've ever seen. It's a horrible idea to bet your product or company on "some guy" and pray he doesn't get bored and abandon it, or get bored and rewrite without preserving compatibility for "v2". And guess what - they always do. Their ego requires it. Just use the std. lib. 
I remember some time ago replying to a question from a talk Rob Pike gave on NewSqueak. I think it was a tech talk. Anyway I think Rob was looking for some CSP-like way to write concurrent applications in C++. I eventually found one that looked good and he said something back to me like “we are working on another solution”. A few months later Go was announced and available. Russ Cox has his video showing how fast it was to build the toolchain all the tests and run them and I was basically blown away that things could be this simplified. (I had considered Rob and Russ to be friendly acquaintances from my Plan 9 days. I still use Rob’s Acme system to this day!) Since then I’ve modeled PoC software in Go that I could not get myself to commit to companies I worked for supporting and wrote some hobby software with it that powers some of an internet radio station’s twitter/irc presence (a hybrid bot). I have been amazed at how few iterations it took to make such software stable and it runs reliably for months on end until our server needs a reboot! Thanks for Go!
I love listening to Rob Pike talk. His talks are succinct and without any useless fluff or air - it's just knowledge getting hammered into your brain. There's an "old school" feel to Go and its documentation - everything feels "brief", and business-like. This is a tool. This is how you use it. We won't waste your time. Go. 
I was mainly referring to the Buffalo project from the talk which uses existing Go libraries to provided the needed bits of functionality for a web app. If you're looking for an all-in-one web framework for Go, those do exist: https://github.com/astaxie/beego Too much fragmentation is indeed a problem, but I'm still extremely impressed with the quality of the libraries written in Go. Even still, it does create a lot more work for the newcomer who is presented with many options and doesn't necessarily have the experience to judge which are best.
Given that both JavaScript and C++ are mainstream, I don't feel like "mainstream" contradicts "radically different".
Can someone eli5? Is it just another OS to base docker images on? Lighter then alpine? I'm confused...
You're reading the entire file into memory before performing the decoding; that's a bad idea in a number of ways. I suggest that you want to: 1. Open the source as an io.Reader. 2. Open the destination as an io.Writer. 3. If enconding, Stick an encoder around the io.Writer, [like this one in base64](https://golang.org/pkg/encoding/base64/#NewEncoder). If decoding, wrap the decoder around the reader. 4. `io.Copy(dst, src)`. Along with being more functional, you should find this shrinks your code quite a bit too.
Wow, this is actually pretty cool looking. Good job.
Since all the talk of makefiles recently, and since I already use go code to build some of my projects, I figured I could probably make something along the lines of rake, to make my go makefiles better. It's still a little feature-light at the moment... I need to implement dependencies, for example. And probably file targets as well. I have a start on dependencies... constructing the tree of deps and walking it is a little tricky in a statically compiled language, but it seems doable so far.
Real life example magefile here: https://github.com/gnormal/gnorm/blob/master/mage.go . (note that I called it mage.go, but mage doesn't care what the filename is)
There are loads. Here's the offical tutorial on how to make a wiki. https://golang.org/doc/articles/wiki/ Once you understand that, you may want to look at a framework, such as labstack echo: https://echo.labstack.com/guide These are quite simple guides, but they will get you started on routing, etc.
Thanks, i appreciate.
Neat. I bet you could reuse a lot of the ideas in [Godo](https://godoc.org/gopkg.in/godo.v2) for this.
I don't quite get the negativity around Makefiles, for most small stuff they are absolutely fine, sure they have their ups and downs but it isn't that big of a deal for small Makefiles for a Go project. * Most of us are creating webapps that only target Linux so don't give a crap about Windows support and make is "always there" on a Linux machine, you don't have to install anything is important to me * Makefiles are great for only running a rule if necessary, only run this if this file or directory doesn't exist, that sort of stuff * Having done some loops/if statements in Makefiles, sure then it can sometimes get a bit ugly, but if you stick to the basics it's not that bad and most of my Go projects Makefiles are hardly 20 lines long.
A E S T H E T I C
nice find! id really like to get a code review from you
linux kernel + security tightened + OCI (docker compatible) probably to be used in Kubernetes, but I really hope it is not 1 vm per 1 container
Maybe, but I tend to run Make just from my workstation for building, not so much on the target server the app is going to be running on. At work we all run either Ubuntu, Debian, or some sort of derivative which all have Make by default I think, so this is not so much a problem for me.
Nice. I also did something similar for fun, but using python.. Take a look at Poisson Disk Sampling, it would be nice to have points not only on the edges, to make it more pleasant. You can take a look at what I did [here](https://github.com/8carlosf/img2poly), I never made anything out of it, but it may have some interesting ideas that you could implement. Also, I have a macaca_nigra_selfie.jpg there, I'm pretty sure that it is a CC0 image, add it to your examples :) It is a cool image.
My problem with makefiles are two things: significant white space and bash. Both are terrible. Oh yeah and PHONY. 
I do recall there is one situation where Makefiles can get a little annoying and that is when you also do Debian packaging from that same repository. Debian packaging will detect a Makefile and will start calling all the rules in it "make", "make clean", "make build" etc. Some solutions we have taken at the time is either use a fabfile instead, or use that feature to your advantage if you figure out exactly which Make targets the Debian packaging process is calling then you can shape your Makefile around that.
I hadn't heard of that one. Thanks, I'll take a look. 
I heard that gophers can't triforce...
In the article the example targets are all, build, test, clean, run, and deps; none of which is a file. Yes, for C, Make made sense, but it doesn't fit with Go, and its only advantage over other systems is ubiquity. 
Along a similar idea is [primitive](https://github.com/fogleman/primitive), also written in go. It allows many shapes as well as mixing shapes. As a comparison, triangle looks like it has extremely clean results versus primitive for triangles. It also looks like triangle seems to be faster for the results it creates as primitive is based off stochastic shape placement with a heuristic.
Thanks! This doc is really useful for anyone out there doing anything with d2s files :) 
Neat!
Ok. Good it's only for a week. I don't want to lose all the free advertising. ;D
This shit is awesome. Please make more. 
Awesome! Computer generated art is one of my favorite programming activities.
still don't super get it lol I'd have to see like a block diagram to understand where it fits in, ohwell :P
Awesome approach. Definitely looking forward to build tools for Go that don't encourage writing shell commands, for better cross platform support!
I have to confess my ignorance here. I develop almost entirely in Go but none of my projects seem large enough to require something like a well considered build system. I mostly write small internal sites (Go http server serving an API, possibly proxied through nginx, with a Vuejs frontend) and CLI server admin tools, for work. What are the advantages, if any, for a makefile system for someone like me?
`exec.Command` probably isn't a problem, as it's just a constructor. If you meant `cmd.Run`, then you make that into an asynchronous call by wrapping it in a goroutine: go func() { err := cmd.Run() if err != nil { log.Fatal(err) } }() You could do something like this to monitor it: https://play.golang.org/p/KOu4qB6jEv (I haven't run this myself, there's potential errors) Alternatively, from the [docs](https://golang.org/pkg/os/exec/#Cmd.Start), use `cmd.Start`
As much as bash may suck, isn't it still easier to call external programs (eg. `go build`, `go install`) from it, than trying to do so from go code itself? Wouldn't you ultimately do `exec.Command("go", "build")` ?
It's useful for any language that has files which depend on other files and can be brough up to date with shell commands. Go is one of them, protobufs are an example as well. The main issue is people don't leverage them right, they use them to alias commands. 
it's pretty easy to make a wrapper so it's just run("go", "install", "etc", "etc") 
Yeah but that's still just running external programs, something bash is actually good at I'm just trying to figure where this tool would be useful. Perhaps something related to encryption and cryptography, to calculate target values (like number of encryption rounds) on compile time, on target system, using the same language project is in? 
It's useful if you need to do more than just `go build`. For example, I like having a foo -version that will return the commit hash and branch name that the code was built from. That's what I'm doing here: https://github.com/gnormal/gnorm/blob/master/mage_helpers.go#L18 It's also useful if you want to embed files in the binary, for example, in gorm I embed the HTML docs so they can be run locally. At work we embed sql files for database migrations.
I find go to be infinitely more readable than bash, and easier to debug. There's nothing you can do with this that you can't do with bash and/or makefiles. They're all turing complete. :)
Sort of counterpoint, I really want to see `go build` librarified and the same actions doable without spawning a subprocess. It's just Go.
Don't forget the perly feel: %oo: $$&lt; $$^ $$+ $$* (from https://www.gnu.org/software/make/manual/make.html)
I just tend to have a `task` directory with go files that implement what's needed. `go run task/build.go` builds a version with a version string set from git describe, ensures it's statically linked, and so on.
Well, your code here is pretty short; that pretty much is the code review. This is not a bad thing. It's a useful little utility. But there's not much more to say. :)
&gt; It's useful if you need to do more than just go build I suspect I don't really fall into that category. As I mentioned, I mostly write small internal sites and CLI tools. Even my for my SQL work, I write statements using [sqgenlite](https://github.com/nboughton/go-sqgenlite) which is very basic. From my point of view it doesn't try to model or make any assumptions about my data. I had a play with GORM a while back and I found it relied a bit too much on magic for my tastes as a Go dev. I can totally appreciate how these tools would be great for other Go devs but I suspect in my limited use cases they wouldn't be a game changer. Thank you, though, for providing this! I can very much see how it would be a very useful tool on projects bigger than those that I currently work on.
So all your base are being to go?
Yup, me too. I just like that this removes the need for worrying the CLI code. When I add the dependency tree code it'll be fancier, but since most of my build times are like one second, it's not a huge deal. For bigger or longer builds it could make a difference though 
That's a lot of code for what amounts to var Awesome = &amp;MyClass{"Awesome"}
None of the ones listed are required, and listing those as your "skills" would be negative if I was reading the resume. IMHO you're better off learning actual Go better. Let me put it this way: if you know http://gopl.io/ front to back, are a decent programmer regardless of language, and have never ever touched gorp/gorilla/negroni/whatever, and you don't get hired, it's their problem not yours, and you're better off working somewhere else.
Not an OS, a runner for what's inside the container. Instead of running the container using linux kernel cgroups and namespaces, it runs it using a virtual machine.
I think you overestimate the overhead of a VM built to be small.
I find the difference between your mage and these tiny command-line tools is 1) I have just one main() per file, filename not function name is the unique bit 2) to make it prettier, my main starts with extra two lines: log.SetFlags(0) log.SetPrefix("# ") And, well, mine don't need a tool installed ;) 
Have you looked at task: https://github.com/go-task/task What did you think? What about redo? http://sogilis.com/blog/building-files-redo-simple-branch/ Why did you decide to go the route of making it Go code by default? Without having used it doing it this way seems like a cute idea, but the normal case looks too complex and if I ever need to run a bunch of Go code I'd much rather do "go run blah;" as a callout.
Demo video now up: https://youtu.be/GOqbD0lF-iA
Task: it's yaml, so that's already a mark against it in my book. It's declarative, so I don't know how I'd do loops or branching. It uses a shell, so we're back to bash-isms which are terrible IMO. Redo looks like a whole new thing to learn.... and it's still bash. I made it Go code because I like go, because I use go 40 hours a week at work and 10 hours a week at home. Go run is good, but it has some handicaps: it only ever exits 1 or 0. If your script has os.Exit(99), go run exits with exit code 1. Go run munges the output of your script if it exits with a non-zero exit code by printing "exit code #". I can't easily share functions between different scripts, else I have to remember to `go run build.go helpers.go`. Mage fixes all of this. Mage exits what your script exits, unless there was a problem processing the script. Mage only prints out what your script prints out. Mage sets up verbose/quiet logging for you. Mage sets up help output for you. And Mage will glob all files in the directory with `// +build mage` so that you can have a helpers file and not need to remember to include it in the build. I also intend to keep adding features to Mage to make building scripts easier and faster and more reliable.
Mage sets up verbose/quiet logging automatically, and lets you use shared helper functions in a separate file in the same directory that all the targets can use, without having to remember to `go run foo.go helpers.go`. And more features are forthcoming. This is something I whipped up in the last two days. It'll get better :) 
Yeah, it seems like this should be a no brainer, just invoke the compiler (or test, or generate, etc) directly from within go code. For all that go encourages the community to create new tools, it doesn't make it easy to expand on the core tool chain.
Really nice job!
Absolutely true. As Ludwig Wittgenstein said, "The limits of my language mean the limits/borders of my world." ("Grenze" in German can mean both "limit" or "border".) But one also should pick *one* of these languages to gain deep experience with. Go seems an excellent choice if you ask me! :)
If you're going to go down that route then `go` isn't likely to be installed by default!
*If you're going to go* *down that route then `go` isn't likely* *to be installed by default!* ______________________________________________________________________________ ^^^-english_haiku_bot
This is really nice. I have seen some osx only paid for software that does similar but allows for use of other primitive shapes and beizers - on their own or in groups. Once again, really nifty :)
Just installed golang-1.9 on ubuntu 16.04 using [gvm](https://github.com/moovweb/gvm): # install to bash, replace bash with your shell if not using bash bash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) &amp;&amp; source ~/.bashrc # binary install, none binary install requires first a working golang install to compile gvm install go1.9 -B gvm use go1.9 --default
I played a bit with it this morning and did [a video](https://my.mixtape.moe/httjlx.mp4) using it. It's a video of "[the block](https://en.wikipedia.org/wiki/The_Block_\(basketball\))".
**The Block (basketball)** In basketball, The Block refers to a defensive play in Game 7 of the 2016 NBA Finals. With less than two minutes remaining in the deciding game of the championship series, Cleveland Cavaliers forward LeBron James chased down Golden State Warriors forward Andre Iguodala and blocked Iguodala's layup attempt, ensuring the game remained tied. The name echoes a series of bitter moments during Cleveland's 52-year championship drought, including The Drive, The Fumble, The Shot, and James' own 2010 televised special The Decision. Unlike these other events, however, "The Block" was in Cleveland's favor, and helped the Cavaliers win the city's first major sports title since 1964. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/golang/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
this is like beating a dead horse.
Please don't do verification using regex. It's hard to read and often subtly wrong.
Oh, this is awesome. Can you detail the process how you did it?
Thanks. Yes, i know some other cool projects using this technique, but almost none of them sharing the source code. I wanted to open it and give it for free. We are learning from open source, so we are responsible to give something back. 
Sure. The original video is https://www.youtube.com/watch?v=-zd62MxKXp8. I've downloaded it with youtube-dl, extracted the frames for the first 7.5 seconds, also the audio. Then I processed the frames with triangle, using a [small go script](https://gist.github.com/dplesca/bf6542923ecf6a9620688700800b4f90). Then packed the frames back into a video file, added the audio that was previously extracted and the result is what you saw. Most of it is ffmpeg work and can probably be automated, but I was just curios how will it end up and did it by hand. #extract the frames into png files ffmpeg -ss 00:00:00.200 -i block.mp4 -t 7.5 in/%03d.png #extract the audio ffmpeg -ss 00:00:00.200 -i block.mp4 -c:a aac -b:a 192k -t 7.5 test.aac #repack the resulted frames after triangle ffmpeg -framerate 30 -i out/%03d.png -pix_fmt yuv420p -y block-triangle.mp4 #repack everything ffmpeg-i block-triangle.mp4 -i test.aac -y block-draw.mp4 
Pretty cool!
That doesn't make much sense in the context of Go. "A makefile replacement for Go" is pretty much geared at people that do Go development, which will have `go` installed. It's "for Go", not "in Go", though it happens to be both. And if you're going to be compiling Go software, you'll have `go` installed too, but in this case wouldn't also need `make`.
What if we made a file that was random data, and a program that stopped reading after a specified human readable number of bytes. Oh wait.
The original parent comment said "Make isn't available without installation". I think its fair to say that go isn't installed either, and that a developer should expect to install "some stuff" before they can develop. *shrugs*
I am guessing you probably don't know OP. You don't know his programming background, how much of Go has he written. He has gone to the effort of writing something and share it with the community. Yes, the topic is goroutines which everyone here is already well familiar with. But from the point of view to someone who is learning Go for the first time, the content may be helpful. You may not have posted the comment in a flippant way, but as members of the community, I think we should not discourage people from writing posts. Be it of any technical depth.
you're right. my bad. i just want to see more of the advance stuff that other people are doing with go.
could you please give an example of feeding an alive horse?? for concurrency? 
&gt; Thank you for the suggestion, I'll try to remove regex in future as possible.
Imho mage should if possible rely on just importing mage as a package instead of requiring yet another external tool so that the build process dependencies can be safely managed in vendor/ for each individual project. I think that a pure Go API would be generally preferable and much of it could probably be implemented using reflection without adding too much noise to the usage. For a couple of projects I've used a make.go which also contains a Makefile-generator which generates a file looking like this which also (in a rudimentary way) uses make to do the actual binary cache: GOMAINS = make.go %.bin %.go: $(GOMAINS) go build -o $@ $&lt; default: all .PHONY: all all: make.bin ./make.bin all ... 
not much, but it defeats the whole purpose of containerization, there are useless layers, even though virtio-net and disk drivers are fast, they are never as good as raw access
Creating safe shell scripts is most certainly something which is a black art. I use to say that among the 20+ programming languages I've learned sh/bash/... are one of the hardest ones to learn properly. It's a bit related to the fact that writing a working, fail safe shell program what works on a bunch of unix/bsd/gnu os'es is complicated because the various differences between the OSes but it's also the sh language itself. Having said this, properly written shell scripts are very expressive and very good at running commands so something which might take 10-40 lines of go code can sometimes be expressed in a single line of bash which often actually is more readable. If you need things like maps sh script very fast starts to get very complicated and you should move to something more powerful. 
If you're ever used Rake or Pyinvoke or similar tools. . . you might see how Makefiles (or Ant files!) are less attractive. . . especially if your team uses languages like Ruby or Python heavily. Gradle's not that bad either. Of course, if you want to stick to Makefiles and shell scripts, you have that freedom. Seriously, try Rake. . . it's nice. I use PyInvoke and Gradle now because I work at a Python/Java shop. I do not miss make at all.
I tried Buffalo out the other day. The boilerplate application it created immediately died in flames due to some error in all of the Node crap it installs. I guess a full-featured library is nice enough in theory, but the Buffalo docs don't do a very good job of explaining how all the parts fit together. So I deleted the lot and now I'm going to just use the standard library instead. With a bit of Gorilla, natch. 
And as the trade-off, one gains actual isolation. It's all trade-offs, and lightweight VMs can make a lot of sense.
You have to remember that the compiler started life as a C project, and was largely machine-translated to Go. I think it'll slowly get librarified.
&gt; I can't easily share functions between different scripts, You know, we have an import mechanism in Go ;)
Yes, it is a tradeoff, and it might be useful in a multi-tenant environment. My hadoop containers can behave sometimes weird and block IO
I was just looking around libraries that do validation. Your library has a lot of stuff I like, it uses struct tags just like JSON and SQL, so all my model data is in one struct, and it has good error response from which I can display field-specific errors in my forms. However, I really don't like the way you need to use `New` and then validate. Passing in the `http.Request` seems like a restriction if your want to use it for other inputs as well, why not make it a helper function that parses from a request but make the core functions accept a reader? Ideally I'd like to create one instance of validator and use it for every request. Then per request I call `Validate` with a reader and a destination struct. Also why is `messages` not a `map[string]string` instead of a `[]string`? And I feel like `required` should be the default, but okay.
it would be nice if you exported helper functions like https://github.com/gnormal/gnorm/blob/master/mage_helpers.go plus some others inside mage itself. Then out of the box, magefiles could do something like import ( // "m" would be a good name for a generic helper lib for this very specific context // analogous to testing/t "github.com/magefile/mage/m" ) func Build() error { m.Must(m.GoGet("github.com/foo/bar")) m.Must(m.GoGenerate(".")) m.Must(m.Run("some", "arbitrary", "cmd")) return m.GoBuild(".") } 
Thank you for such a great suggestion. I will keep in mind for next update. 
Can you move the waitgroup creation into the main function and then pass it to foo and bar? Bad practise making it global.
Yes, it's bad using it globally. but for this simple example it's probably okay.
I rather doubt it. Write some good tests (make sure to exercise delta values other than 1 and -1), run them with concurrency. You'll see deadlocks, violations of your limit, or both.
Yes, but that doesn't help on Windows where bash only runs extremely poorly. 
bad bot
Thank you ar1819 for voting on I\_am\_a\_haiku\_bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
It's actually kinda sad. The pcj became an echo chamber, where it used to be sarcastic and precise. Now is just repeating the same memes and buzzwords again and again thinking it's funny. Oh well - back to the n-gate.com then (:
Ruby has Rake, Python has PyInvoke (and others), the JVM has Gradle. . . there's no reason why there shouldn't be a Go analog. Although, you can use one of the above if you don't mind the additional runtime dependency - most Linux systems have Python installed right out of the box for example. Shell scripts (and Makefiles) are all you have sometimes but I generally avoid them when possible.
Would author enjoy having generics?
Yes, i know Primitive, which is a cool project by the way, however as far as i studied the code and the description it's using a totally different approach in terms that it is based on annealing process, meaning that it's trying to find the best score from a series of mutations. This is the reason why it's slower than my approach, but as i mentioned it's a totally different kind of generative process, with a totally different aesthetic output.
If you need a CI/CD system, then something more than shell commands is extremely useful. Mind you, I'm saying you will want something like Jenkins, GitLabCI, CodePipeline and that a tool like Rake would be an excellent addition to a full CI/CD system. IMO a much more flexible and powerful replacement for make. tl;dr a lot of folks are doing more than just compiling binary and running unit tests.
It's not really possible. Most of the magic in mage comes from the binary - parsing the files to make it easy to run. There definitely will be a library for reusable helper functions, though. I guess in theory you could make a file you could 'go run' instead of running mage itself. I'm not sure that's all that much better.
Well, people can continue to bash Go all they want. I've been developing in .NET, PHP, Javascript, etc. for many years. Found Go... and landed a go-specific $140K a year job w/ only 6 months of using and studying it. I'd like to see any other language provide such opportunities career-wise. I'm also able to use it to deploy back-end web services at about 1/4 the time it took me to construct with anything else, and a lot less boilerplate. Haters gonna hate... while I'm sitting actually enjoying going to work for the first time in my life (because I actually love developing in Go), and the salary isn't too shabby either.
Appreciate that. - Timing can be monitored with *cmd.Start* and *cmd.Wait* - Memory usage can be monitored with *cmd.Start* or *cmd.Run*
[removed]
&gt; Ultimately I'm trying to just expose an API in JavaScript that includes some CGO imports. Why do you need llgo and not use the Go toolchain for that? Also afaik llgo is not yet a blessed implementation and by the work it goes into it it looks like it still has a few legs to go before that (I might be wrong).
Nah, typing that boilerplate code over and over is too fun.
exactly :)
Well, thanks for the review, i'll try to improve it
I want to evaluate the feasibility of using a webassembly port that I compile with llgo -&gt; emscripten. While it may not be blessed, I don't really think many people are even bothering with it. Personally reading over it, I believe the llgo impementation may be enough to bridge cryptography API implementations and am just aiming to test it out before making a decision to write multiple code bases. I'm working on an open source project that I am aiming to provide wide support for, but I'm only one guy. Being able to manage 1 code base and maintain high portability is pretty important to me. 
 func (h *Horses) Feed(f FoodProvider) { for _, horse := h.Horses() { food := f.GetFood() go func() { horse.Feed(food) } } } Although I must warn you that I have not tested this code, and it is distinctly possible it may contain serious bugs that, say, may force feed the last horse in the herd with all the food while starving all the other ones. As a random example that I picked out of nowhere.
It's not like there is a huge difference between `go run mage.go something` or `mage something`. I'd even go so far to say that for a Go developer `go run` is easier because it's already a known thing while it's almost always tiresome when projects use a bunch of obscure small tools which might or might not have been maintained at all for the last five years.. If it's all plain Go it's at least directly understandable what it is rather than having to find out what `mage`is first. Maybe it could be good if both invocation methods worked where the `mage`command can do additional stuff like possibly cache binaries.. Something similar to this would probably be easy to understand and use as an API: var MyTask = mage.Task("mytask", // reserve a task name for command line usage mage.Depends(SomeOtherTask, YetAnoterTask), // depend on some other task var mage.Func(func(m *mage.M) error{return nil}, // supply a function to execute ...mage.Opt) // using variadic opts so that the creation of the variable can be validated at initialization. func main(){mage.Run()} And nobody will probably ever save more than a few minutes in total in comparison to: func MyTask() error {return nil} 
It's just programming forums in general. When a language is new, there is philosophies floating around. Go being a language created in spite of c++ philosophies, people still find a certain way of doing things. Plus, programming seems to draw those autistic people. Where you get into it about generics and this language does that, and c# is written in c# but not totally....ect And then you just stay away from that nonsense because it doesn't really matter... Unless you have prestige. So moral of the story is, help others, even if something is glaringly wrong, don't think you'll change their minds.
The usual way to add a mutex to a struct is type T struct { mu sync.Mutex ... } 
Haha, there's no need to do that. Regular expressions are ubiquitous for a reason. The Go team included support for regexs in the standard library for a reason. Because they're really useful! And I think your use of them is proper. Regexs for validation should be write-once read-many (or read-little really) meaning that you'll *rarely* if ever update a regex that verifies a CSS color, and other developers should *rarely* if ever have to read such a regex. Now, if one is worried about regexs being subtly wrong, then you can provide a test harness -- maybe include a fuzzer -- that demonstrates their efficacy. If one finds a bug, then a regression test is provided and the regex is fixed. Simple enough. Thanks for sharing your library with us!
These slides should belong in /r/restofthefuckingowl/. Starts nice and easy, then "let's bootstrap the allocator" then "boom, SSE enabled motherfuckers". (the [video](https://www.youtube.com/watch?v=8T3VxGrrJwc) has a livecoding session which makes the progression make more sense fwiw)
Maybe "DNS management client" or "DNS admin client"?
Oh, I see, that wasn't clear from the initial text. Maybe you can post the instructions / a Dockerfile which is useful to compile llgo and al that's needed for it? 
This is what I was working from: http://llvm.org/svn/llvm-project/llgo/trunk/README.TXT When I went to build it I ended up being ultimately stuck on the last cmake. I'm not really familiar with cmake. I'm more of a `./configure &amp;&amp; make build` kinda guy. 
That's definitely on the list to do. :)
Well, RegEx is extremely powerful for validation; however, I agree that it's actually VERY often implemented wrong. Properly implemented (and thoroughly tested), it's actually perfect for such a use. Most of the time when I'm searching for regex (for phone number validation, for example)... almost all the ones I find online are incorrect in one way or another. I usually have to make major adjustments, even to the most commonly accepted ones, to make it work properly against all the tests I throw against it. Like anything else... test... test... test... and then test again.
I can but this gopher isn't doing it for free!
Definitely use cmd.Start() otherwise there is a race because you won't know when the command has started in another goroutine. Waiting for a second does not solve that race, just makes it much less likely.
&gt; with a focus on producing as little garbage for the garbage collector to manage as possible. As you've discovered, garbage collectors don't manage garbage, they manage reachable memory.