If you use symlinks often (and you should! symlinks are great for organizing things), then when you backup you'll be more careful to follow symlinks. I keep gocode in ~/.go/src/, and when I create a new go project I create a symlink to ~/Projects/$name. Backups with tar -h
RethinkDB is not Go but C/C++
See also [this earlier post &amp; discussion](https://www.reddit.com/r/golang/comments/82aplu/gloo_function_gateway_built_on_top_of_the_envoy/).
So it seems you want to develop everything from scratch. I also wanted to port Discourse to Go. I really like Discourse UI but it is really heavy on resource usage due to being written in Ruby. I had an idea it could be done by re-using half of Discourse code (i.e. all front-end and database code) and only re-writing the backend from Ruby to Go. It could be done incrementally by starting with a server in Go that merely proxies all requests to Ruby and then implementing more and more APIs in in Go until all Ruby is ported. 
&gt; How? They are different packages. Yes and no. They are considered different packages, for good reason. Something *can* be backwards incompatible, doesn't mean everything **has** to be backwards incompatible. &gt; Do we get confused I'm not talking about human confusion, though that will be a part of it, I am talking about needing to wrap everything between versions of the same package in the middle of an incremental upgrade. &gt; gorilla.Mux and http.Mux There is a clear distinction between changing from stdlib `http` package to `gorilla` and going from `v1` to `v2` of a package. A *lot* of types remain the same in a major version upgrade In cases where definitions are the same, having some way for a simpler upgrade would be nice. Unless the package maintainer does something like [this](/r/golang/comments/85vnyf/proposal_versioned_go_modules/dw13j2y/?context=3), I have to jump through hoops to make sure I can upgrade from an older major version to a newer one.
&gt; There is a clear distinction between changing from stdlib http package to gorilla and going from v1 to v2 of a package. A lot of types remain the same in a major version upgrade Sure but still I don't think there will be any confusion. import ( foov1 "my/pkg/v1/foo" foov2 "my/pkg/v2/foo" )
&gt; Sure but still I don't think there will be any confusion. As I have tried to clarify before, I am not talking about the human confusion here. In most cases, as part of an **incremental upgrade** you would most likely do: ``` bar := foov2.NewBar() return foov1.Bar(bar) ``` At the end of your method to maintain compatibility with the rest of your code. But it breaks as soon as you have something like this. ``` type Bar struct { Baz *Baz } ``` Now you have to essentially serialize and deserialize between old and new types to make it work. Unless the package maintainer goes meta and imports their own older version and type aliases everything before making breaking changes.
Most exported stuff would most likely remain constant though, public and private. People change a few big things, not necessarily everything And if we can have a way to upgrade those painlessly, it would promote upgrading to latest version (with sweet security fixes) easier. During an upgrade, is there no alternative to: 1. Expect package maintainer to type alias things. 2. Have serialise/deserialise methods for every type we use.
&gt; Unless the package maintainer goes meta and imports their own older version and type aliases everything before making breaking changes. The other way around is possibly even better: if you import the new version from the old one and keep it as a compatibility shim, you can get some bugfixes backported practically for free. (That's what [golang.org/x/net/context](https://golang.org/x/net/context) does for newer Go versions that have a builtin "context" package, for example)
What is the benefit of using OpenCensus instead of just exporting the metrics to the Stackdriver or Prometheus?
I considered this. I also like the Discourse UI, and I also felt Discourse was a bit too resource hungry. the problem is that discourse is GPL (and, as a developer, I really prefer BSD/MIT/Apache) also, at the time, I couldn't find an API documentation that could help me interoperate with Discourse w/o looking at the code (and thus preserve my favorite license.) In the end, `saloon` took me about a month of on-and-off on-the-side hacking, thanks to buffalo. Saloon isn't as featureful as Discourse is, but it's already rather serviceable. The non-profit organization for which I wrote `saloon` is using it. The number of users of the saloon is about ~20, so I can't say it's under heavy usage, but, so far, no complaints :)
What are the intended use cases?
&gt; How is a concurrent map a very specialized collection? In Go, it's a very specialized collection because most of the time the solution you end up with writing idiomatic Go code has some resource manager/arbiter (such as a goroutine) which keeps the collection as its non-shared state and mediates accesses to it made by other goroutines. The documentation is pretty clear on this: &gt; The Map type is specialized. Most code should use a plain Go map instead, with separate locking or coordination, for better type safety and to make it easier to maintain other invariants along with the map content. &gt; &gt; The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, or (2) when multiple goroutines read, write, and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex. Still, that is not to say that *if* generics were part of Go 1, they would not be used for implementing `sync.Map` — I'm pretty sure they would have been.
OC gives you a clear separation between metric collection inside your app and reporting it to different backends
Why is it metrics _and_ tracing? We already have opentracing for tracing?
I've been using this for now: https://github.com/cortesi/modd It works really nicely for simple stuff, but it'd be nice if it supported starting multiple separate watchers.
If you do say so yourself? ;) * Recovering from a panic in main probably means something has already died, maybe just let it happen at that point so you can have the stack trace? * Your deferred call to GracefulStop might not actually happen if you don't catch signals. * You accept context in GetCCurrencies, but don't actually use it (!) * You have a typo in the godoc for NewCTicker. * What on Earth is trash? Honestly, I think it'd be much more useful for you to make an example gRPC service, rather than a ~~micro~~ nano-service like this. This service really is tiny, and is barely doing anything past the basic tutorials you can walk through for gRPC. I don't see how you could show that something is well structured when there's barely anything in there to maintain to showcase that it is actually well structured.
There's nothing inherently wrong with the first code example, as long as you're not opening a thousands of files. Knowing that defer is function scoped is pretty basic. Not sure where the OP is coming from that they thought it was block scoped. 
It's coming, and I do agree; it's the lack of isolation that I don't particularly like about the `$GOPATH`. The current dependency management tooling doesn't make it easy to get away from it though, with dep and glide both not allowing you to checkout code that has refactored package paths for example. One way I've tackled upgrading code before is by wiping out my vendor folder and defaulting to the `$GOPATH`. Hopefully `vgo` will sort all of this mess out...
I'm excited for this because it helps enable an offline module repository for Enterprise use cases. Golang can be frustrating without internet access.
Whoops I stand corrected - thanks buddy. 
the simplest use case is you dont have to think about low level database things. for example while testing just use map driver then without changing anything start using mongo driver your code will be untouched 
https://github.com/jpillora/cloud-torrent
I've used [reflex](https://github.com/cespare/reflex) for this.
Yep Russ took his time, but came up with a pretty good one :)
&gt;Active Record is a hard dependency for many of the RubyGems. The drawback to this is that the domain becomes tightly coupled to persistence mechanism. This leads to some bad architecture decisions. AR is one of the best libraries that Ruby has going for it, and Golang doesn't have anything that comes close. Also, AR being a dependency of many rubygems (is it really? Activesupport, yes, but not AR in my experience) is not a problem wit h the language, it's a problem with developer culture. All in all I love go, and it's performance smokes Ruby, but... This article seems to be thin SEO bait, IMO.
Replying to the full chain here, it seems people may not be entirely aware that this is _already how it works_. Even today it is possible for you to end up with the exact same package in two places, either via two vendor dirs or a vendor and direct usage, and the compiler already will consider the types to not be the same. I got in trouble with an LDAP package this way once. Different versions will be different modules and modulo type aliasing, that's already the case now and will remain the case in the future.
&gt; Not sure where the OP is coming from that they thought it was block scoped, If you've used a lot of languages, it's how most languages work. Generally you'd expect defer to be part of a scope, not part of a "function", to minimize the differences between functions and scopes. It is, of course, totally false, documented in the specification, covered in tutorials, etc., but it's still really easy to bring in ideas from other languages accidentally when learning a new one. The other reason is that there doesn't seem to be much reason for it to be function scoped rather than block scoped. After programming in Go for several years now, it so happens that this week, for the _first time ever_, I actually used the pattern func Whatever() { if someclause { // some stuff here defer something() } // rest of function } It's literally the first time I've written a defer statement where I _deliberately_ wanted it to be function scoped. By contrast, I've had to extract probably a couple dozen functions over the years because I wanted a defer statement scoped to a block, but I can't have that. I've even got a couple of very Javascript-esque var this int var that int func() { obj := whatever() defer obj.Close() // stuff this, that = obj.Result() }() places where I have a function scope inconveniently smashed inline and immediately called, just because I _need_ the defer to run before the end of the function. It's not a major annoyance, but I'd definitely prefer a block-scoped defer over all, even after years in Go. It's easier to occasionally (as in "once in the ~5 years I've been doing this") pull one up to function level than to very frequently have to scope one back down.
1) Do not agree, see no reason to let it die, if it can be recovered. And we can already see stack trace in log output (in case of panic) 2) Good catch, will fix it 3) Take a look on api.pb.go: ``` type ApiServer interface { GetCCurrencies(context.Context, *GetCCurrenciesRequest) (*GetCCurrenciesResponse, error) } ``` 4) Fixed 5) I explained it already, but I agree, no reason to use such "good enough" tools.
But I want my tests to test against Mongo if I’m using Mongo in prod. And if I need to mock Mongo, I’d rather do that than pretend it’s a map. You’re rarely gonna use a data store of type X but not somehow exploit features unique to it. I’ve never ever seen the “deploy with Postgres then a year later just drop in Mongo” step happen. :)
&gt; Full control over the sql, and no fighting with the abstraction. I prefer this actually unless I'm doing a crud app. Abstractions are nice when you're repeating the same thing over and over again or having to compose similar things (like scopes in activerecord, for instance).
Thanks for the information and the profiling info link. This really helps a lot.
The only thing I'm disappointed in this the statement "Disallow Vendor Folder" except at the top level. To me the most elegant and full proof way of doing dependency management is recursive vendoring. When I want to use Library1 from the Author @awesomedude, put it into my vendor directory in it's canonical path (github.com/awesomedude/lib1). I probably used dep to do this. I check it in and forget about it. Library1 dependencies are within the vendor folder for it (not flattened) because @awesomedude was smart enough to check in his vendor folder. @awesomedude was also smart enough to not rely expose anything from his dependencies as part of his public interface for me to consume/create/rely on. Now, I want Library2 from @equallyasawesome. I do the same thing. He does the same thing. It so happens that Library1 and Library2 both rely on the same dependency (Library3) but I don't really care because Library1 and Library2 provide complete isolation and my code doesn't have a direct dependency. After successfully using Library1 and Library2, I try Library4 and it's dependencies are bleeding up through it's public interface. I decide Library4 isn't good at all, because the library author was @notawesome. All is not lost however, I take inspiration from what it does. A little copy is better than a little dependency. 
This says AR is bad and then brings up error types as a comparison, huh? And what’s this nonsense about deployments requiring stack swapping or rolling upgrades and how apparently go doesn’t need this because it builds a binary? You’re still going to need to put up a load balancer to handle switching over smoothly. Agree with other commenter this is click-baity and doesn’t really say much other than go has better performance and concurrency 
are you okay
this news has me giddy!
It may be my naivety / general oversimplification over everything but why cant the version just be some form of URI, so 2.4.5 maven like ones or git-url:&lt;commit hash&gt; or tag or whatever / pluggable. Have something like a package.json that is a simple list so go can resolve / download dependencies, which have their own package json -&gt; circular / transitive and bark / warn on a version conflict -&gt; and its up to the developer to resolve (e.g. pick the greater version) and test their stuff.
as the article states &gt; be conservative with what you do. be liberal with what you accept.
exactly. I did ruby for some time, and AR was quite nice, until you had to do something off the beaten path. Then you had to make your queries in a way that it works with the abstraction. Pain. Switched to python/sqlalchemy afterwards for another job, same deal there. Once you needed a custom query you are in trouble. Abstractions over abstractions. What I was talking about: https://github.com/femaref/dbx. `dbx.Create` or `dbx.CreateWithDB` is basically 95% of what I use it for, because inserts are painful with bigger tables. 
would you tell us that you’re okay 
&gt; Storing the data statically vs. a database is really the same to me but it’s not the same - if your usecase allows for it you should almost never externalize data.
I think I heard this the first time with some package related to mongodb. All package managers kind of fixed by deleting a package's vendor directory/moving it's content to top level and trying to solve for a version that satisfied everyone. No such fix is possible/available so far with `v1` vs `v2` imports in this proposal and probably should be discussed at the proposal phase and not after a release (the case you mentioned was discovered much later), so I brought this up now :)
*There's a sign at the window That he struck you A crescendo, Annie*
&gt; A little copy is better than a little dependency. In my opinion, this is not an appropriate usage of the proverb since you actually end up using the dependency.
Hmm, I think I disagree...if I'm using lib1 and lib2 which both depend on lib3, I'd like to just have one copy of lib3. Basically, it seems reasonable to me that a final executable says, "here's all my dependencies, vendored up, you can build me without problems". But a library, which is never something you directly use, says, "hey, when you want to use me, you've also got to get deps A, B, C". You only have to do that when you're actually incorporating the library for the first time, so it's a reasonable cost to pay, for the benefit of not having dep-of-dep libraries duplicated out a million times. To me, it seems a sweet spot between various more extreme positions.
This proposal removes the ability of libraries to vendor. Only the final module being built gets to vendor.
He came into your apartment
awesome :) 
I didn't end up with a dependency on Library4, which is the one that didn't hide it's internal dependencies correctly. 
Why have one copy of the lib3? Are you concerned about binary size? Lib3's types shouldn't matter to your code at all.
Go vs Ruby is like bacteria vs antibacterial, depending on which way you look at it.
&gt; Basically, it seems reasonable to me that a final executable says, "here's all my dependencies, vendored up, you can build me without problems". How is the "final executable" different from a library? If it is good for this use case, why is it not good for a library? 
I like your idea of inserting into a database from a generic buffer. Kinda like a bulk load interface may have. Also, this may be of interest for database/sql users.
Having worked Rails and Go contracts in the past, I personally prefer Go because: 1) it's not extreme convention over customization 2) it's syntax is prettier compared to Ruby
I reread again your comment and now I see it. By taking inspiration, you implied that you didn't actually end up using Library4. Sorry it was hard to spot it with all those dependencies.
Because a library on its own is not useful. So the use-case is different.
He puts forth a reasonable argument, I like the quantitative analysis behind it. I think Sum types would be a great addition to Go. My only reservation is around claims like "removes all runtime errors" :) I've used languages like Scala, Elm et al and whilst they _do_ remove a large number of errors at compile time, there's still chances of problems Let's hope any discussions dont degenerate into "if you add feature x to Go then it will become just like C++" 
The post claims to be a Go experience report, but it does not report his actual experience in the original sense that the Go authors described. I really laughed at the "Everyone else has it" section, since that is exactly what drives gophers crazy. That being said, the quantitative analysis of return parameters in the std lib is interesting.
Unfortunately for this proposal, for it to lead us to the promised good stuff requires Go to add both sum types _and_ generics. We clearly don't want to declare a sum type for every function that either returns a value or an error, which means we want a general `Either` type. However, Go can not express a general `Either a b` type today, because it can not do any type parameterization. Note I'm not saying this makes the idea bad; I'm saying that the language is very far away from this and would require not one, but two major features. Given the rate at which Go adds major features, even if these are the _next_ two major features, we'll have them in... umm... it's actually pretty hard to estimate the rate right now since it's very nearly zero over the entire lifespan of the language.
The best tool is a platform that scales with your needs. I've used Jenkins and Concourse in the past, each has their pros and cons. &gt; Tool to build and restart webserver on changes Not testing before deploying? That's not kosher. Rabbi will never approve.
I'm curious, what kind of work is required to enable Google App Engine to support newer versions of Go? Does it vary from version to version? Now that 1.9 is in beta, are you starting on support for 1.10? Is it a goal to eventually have parity of schedule between Go releases and GAE support for them? It's fine if you can't provide answer; I figured I'd ask just in case, since I am curious.
Thank you. 
[removed]
&gt; In this Go Experience Report Once again, I feel compelled to point out that the idea isn't to attach the term "experience report" to every blog post about your pet Go feature request, but to provide a good, common framework to talk about problems you are encountering using Go. &gt; I believe that most of the time we return: &gt; &gt; * a value and a nil error, or &gt; * a nil or zero value and a non nil error Every implementation of `io.Reader` and `io.Writer` violates this assumption. And those are only the first and canonical examples I can think of. &gt; Sum types is how Elm can eliminate all possible runtime errors: This is literally impossible (in a Turing complete language). &gt; In my opinion this makes Go a strong dynamically typed language, rather a strong statically typed language, which I would prefer to use. Potayto Potahto. You can always check more invariants via types. The question is, whether doing that is worth the tradeoff - i.e. how severe the problems this would solve are and what the right way to solve them is. Notably, the blog post contains no examples of actual *problems* this lack of strong types is causing, it only expresses preferences of the author. Which is fine, but see above; there is a *reason* the structure of an experience report was created and it would really help if people would use the "manual of how to be most helpful to address your wishes" they were given, if their goal was to actually have their wishes addressed… &gt; The use of an interface as a way to simulate a sum type can also be found in a Protocol buffers library for Go where they have to implement oneof I don't believe that, even if Go would grow sum types, they should be used in protobuf generated code. Protocol buffers are created to be backwards- and forward compatible and breaking the build of every project using your .proto-file when you change it isn't really something that I think is likely to be tolerated. FWIW, I actually think oneofs in protobuf provide a great example of why sum types *aren't* great for many usages they are proposed for. There is a reason the protobuf language guide contains an explicit [section](https://developers.google.com/protocol-buffers/docs/proto3#backwards-compatibility-issues) on their caveats. It's a lesson learned the hard way (via multiple outages and data corruption incidents) that at least for everything on the wire, sum types are *very hard* to get right.
Right, as I said, you could use sql.OpenDB to make sure to get the one you want. Most drivers also have a helper function that will create and return a sql.DB for that driver. And actually, yeah, I would expect a driver to change it's id for the sql.Open function if it made breaking changes. It is annoying, but breaking changes are annoying, and drivers don't have to use the Open API if they are making lots of breaking changes and confusing people.
You'd have issues with global state, singleton instances, and also types wouldn't match up (e.g. you want to pass some type library a to library b, but library b also has library a vendored, it's library a would technically be different to your library a, and your code wouldn't compile).
Yes, I agree. That just goes to show why dependencies are hard :) 
Not sure I agree but I'm willing to accept that as solid reasoning. 
How does annie compare to youtube-dl?
Why shouldn't you be able to though? There are many times when it makes a lot of sense to. For example, we have a lot of internal libraries where I work, one example of this is a logging package. We produce a logging interface, and some other libraries use that logger where it's appropriate. With the recursive vendoring approach I wouldn't be able to pass a logger from my application to a library because of the aforementioned issue.
Here is the discussion about it https://github.com/census-instrumentation/opencensus-go/issues/502
He left the bloodstains on the carpet
That's actually a great point. I wouldn't run into that because I believe in the mono-repo approach, my logging library is just a package in my single repository as is all my other code. I guess if I was vendoring in my own code I'd probably share your opinion. 
[removed]
This. I love VIM, but i'm too old to tinker with tools. I want tools to be tools, not things to care by itself.
Table of Contents: # GothamGo (New York, NY) The Legacy of Go, Part 2 From Frontend Engineer to Go Core team member Implicitly Impacting the Cloud with Go A Go implementation of the Skylark Configuration Language Closures are the Generics of Go A Python and a Gopher Walk into a Bar - Embedding Python in Go The State of the Go Nation Calling Rust from Go, without cgo Performance Optimisation: How Do I Go About It? Making Code Write Itself Building a Distributed Serverless Platform from Scratch I Will Debate Mark Bates Building a Multiplayer New York Times Crossword # Silicon Valley Code Camp 2017 (San Jose, CA) Getting Started with The Go Programming Language # Chester Devs (Chester, UK) Going Golang 1 Going Golang 2 # London Node.js User Group (London, UK) Scalable Scraping in Node and a bit of GO # Google Dev Fest 2017 (Colombo, Sri Lanka) Introduction to Golang # Vilnius Golang (Vilnius, Lithuania) JSON+Go in practice # dotGo (Paris, France) Managing Package licenses in Go Go's work stealing scheduler Unmasking netpoll.go Simulating a real-world system in Go Machine Learning and Go Go, C++ or Java for DNA sequencing? The Art of Testing Reducing Go programs Exposing Go code to Android and Python The Functional Design of Dep Go for Real Time Streaming Architectures Handling slow requests in your Go web server Rethinking Errors in Go Debuggers from scratch Behavior Of Channels Go Lift # Open Source Summit Europe 2017 (Prague, Czehia) Develop Your Embedded Applications Faster: Comparing C and Golang # Go Sydney Meetup (Sydney, Australia) Upspin 
They remove 100% of _certain_ types of runtime errors (experience with Scala here). In the Scala case, if you interact with some Java library or have something specially "leaky" sum is not going to help. But it can help make your code more concise and clear by taking advantage of some structure that is not present otherwise, and this is a big win (although I'm not saying Go should or should not get sum types here)
We patch the go toolchain to work inside a security sandbox and disable some features. We also update our compiler service and the SDK. The 1.9 upgrade took more work than I expected due to the filesystem polling changes introduced in the release. I had to make it work with our virtual filesystem. 1.10 is in progress, including fixes to how we handle vendoring and standard go package layouts. Hopefully we'll have time to remove some of the old limitations (sockets, filesystem, etc), too, but I can't promise that. The eventual goal is parity, yes, with same-day releases as the ultimate goal. We're working on getting there!
You need to think about the implementation before you consider the feature. New features _must_ be worth the cost in complexity of both their implementation and their implications to the added complexity of the language as a whole. The current multi-return is implemented in quite a simple, straightforward and performant way by the Go compiler. Return values are allocated on the stack; while it's always harder to go from 1-&gt;n, I think the flexibility here in vastly reduced typedefs for every multi-return is well worth it; conceptually, multiple return values are fairly straight forward. For free, you get a vastly superior error handling mechanism/convention (superior over C's that is) that works for non-nullable types and types where `nil` is valid. Sum types would not be restricted to return values, so they'd likely add a lot more complexity for something that most Gophers think is already implemented well enough with simpler semantics. IMHO, Sum types are _clearly_ at best a small incremental improvement over multiple return types that come at a _great_ cost of complexity; a classic case where "No thanks" is the prevailing answer. I struggle to understand why a programmer who wants sum types and [monads](https://awalterschulze.github.io/blog/post/monads-for-goprogrammers/) is using Go, as clearly their preferred paradigm is very poorly supported by it. Those of us who like Go do not want to see it turn into "everything else", because there are plenty of kitchen sink languages already available but not a great deal of them like Go. If you do like what's there, invest more thought in how what's there is good as much for what it has as for what it lacks. --- I want to also echo the sentiment of others ITT that the original research into multi-return usage is valuable and a great contribution. Related to something else I liked in the article, I have always been a bit perplexed by the non-support of `f(g(), foo)`. This gets good treatment in the spec: &gt; As a special case, if the return values of a function or method g are equal in number and individually assignable to the parameters of another function or method f, then the call f(g(parameters_of_g)) will invoke f after binding the return values of g to the parameters of f in order. The call of f must contain no parameters other than the call of g, and g must have at least one return value. If f has a final ... parameter, it is assigned the return values of g that remain after assignment of regular parameters. So, clearly, `f(g(), foo)` is not supported by this special casing, but I can't come up with a reason offhand why it _can't_ be supported. There's probably something in there with variadics that make it difficult or error prone in the general case, even though it is unlikely to be a real issue in practice.
I appreciate someone working on this, but I think this proposal is missing a few things. For example, doesn't the data show that only a small number of functions (3.5%) use multiple return values? Doesn't that seem like a pretty minor impact? Especially considering the magnitude of the change. Also, how would sum types make code safer? I think it's important to include some examples of real bugs that were caused by the lack of sum types. Also, how would you deal with `nil` - you mention that Java has `Optional`. Should we remove `nil` from the language? Or if we're keeping it, why? I know it seems like this is just "adding" a new feature, it's actually a pretty huge change to every part of the language, and would require a tremendous amount of work to implement. That's not necessarily a dealbreaker, but we need a lot more information first.
&gt; That's a terrible restriction to put on experience reports. Of course you can workaround a lack of any particular feature by doing something else. If Go didn't have, say, functions and you were collecting experience reports about it, would you reply with "just use goto"? So? I don't really see a problem with anything you are saying. You'd say "we used goto, that introduced $bug1, $bug2 and $bug3 because the spaghetti-code was hard to follow and those bugs brought down our production service". And then you'd pretty likely get functions added to the language (or something else that would solve that problem). The point of experience reports is not "if there's a workaround we don't have to care about it", but to focus discussions on problems, not solutions. Go is a language from and for engineers. And in the essence of engineering, every change is weighed and costs are, as much as possible, avoided if they don't have clear and demonstrable benefits. Experience reports attempt to give a framework to make that tradeoff: They encourage you to a) give context around the business-domain problem you are working on, b) demonstrate that it is important enough to actually require a solution (important problems tend to be solved with the tools available, one way or another) and c) demonstrate that the currently possible workarounds are lacking. They also enable the Go designers to estimate the severity of the problem people are facing and a benchmark to measure proposed solutions against - only if a solution actually solves the problems from a given set of experience reports, it should actually be considered successful. It is fully in *your* interest, if you want your problem solved, to provide the necessary tradeoff to build a solution that fits into Go. Because adding anything just because someone thinks it's a good idea is not good engineering practice.
&gt; The point [is] to focus discussions on problems, not solutions. Yes and what you seem to refuse to accept is that sometimes, for some people, a lack of a feature - even when there are alternatives - *is* a problem. &gt; because the spaghetti-code was hard to follow I think the author did pretty good job showing that. There are functions with 4+ return values in the standard library. That's just spaghetti code. &gt; every change is weighed and costs are, as much as possible, avoided Yes, and that's on Go devs. It's neither required nor expected of blog post authors to consider their post's implications on the compiler or stdlib. &gt; Because adding anything just because someone thinks it's a good idea is not good engineering practice. Of course not. But if enough (for some definiton of "enough") people are asking for something, it's probably worth asking why, instead of having a knee-jerk reaction like you do on every single experience report that doesn't fit into your expectations.
Also caught my eye. Not sure if it’s relevant, because having a value and error currently forces you to use both (even if to throw away the error with _, there’s just no omission unless you throw away everything like fmt.Println). The interesting pathway would be how to handle these sum types according to their parts, which I didn’t see here. That’s where this thing falls apart because you don’t want necessarily just to merge a value and error.
&gt; Also, how would sum types make code safer? I think it's important to include some examples of real bugs that were caused by the lack of sum types. In context of returning a value *or* and error (with a sum type) then the compiler can make sure that you actually handle he case when it is an error. Go right now does not do this. Perhaps the biggest potential bug is deferencing a nil pointer (which is a pretty common bug across all programing languages).
&gt; FWIW, I actually think oneofs in protobuf provide a great example of why sum types aren't great for many usages they are proposed for. There is a reason the protobuf language guide contains an explicit section on their caveats. It's a lesson learned the hard way (via multiple outages and data corruption incidents) that at least for everything on the wire, sum types are very hard to get right. I want to note that caveats with protobuf oneofs are how they are represented in the wire format, which is orthogonal to this discussion.
You have some interesting points, but I do not find them persuasive. Analysis of multiple return parameters: it does not support your argument at all. Firstly, you did the analysis on the source code, which was written with a much higher standard of discipline than application code. The value of returning multiple values is not decided by how many functions return multiple values, but how much utility it brings to the application development. In the applications that I worked with, returning two values is very common practice to avoid throwing exceptions like other languages do. Returning multiple values actually saves a lot of time for debugging and facilitates logging. The bottom line is: the number of those functions does not say anything about the utility that returning multiple values. The utility cannot be measured quantitively and you can only get a feel for it when you actually write large and complex applications in Go. Tuples are not first-class citizens: I don't see your point. If the language prohibits such use, why would you even try it? You can use either a function pointer/wrapper or declare two variables and pass them to the next function. Neither of them is too difficult to do. Does writing one additional line of cold really bother you that much? What are sum types and we need sum types: cool idea, but horrible for Go. The main advantage of Go is that it is strongly statically typed that you basically cannot mess with type of variables or functions (unless you use reflect, which still add restrictions to the type that you want to mess with). It's a big restriction on how programs can be written, but it also enforces the design philosophy of Go in application code. Go does not try to be fancy like JavaScript (imo, JS is horrendous in terms of language design). As for your argument "everyone else has it", it's logical fallacy. Everyone else has it does not justify that Go should have it. Go will have it if it does not violate the design philosophy, which inherits the Unix philosophy. In addition, looking at those languages that were listed, none of them is actually stable enough for system program. C++ is used for Windows and Windows still bluescreen you even today. I think the work you put on this article is noble, but I sincerely believe that you did not have a good understanding of the design philosophies of Go and why it was created on the first place.
Not really, though. Even if you'd represent them differently, you'd still need to handle "a value I didn't know" explicitly. Otherwise, no matter what, if you add a new field to a oneof, then software without the change won't be able to decode values written by software with the change (and, of course, the other way around if you remove a field). The basic argument is, that on the wire, all bets are off. And if you see something you don't know, you have only two ways to handle it 1. Fail the decoding, which contradicts protobufs design goals of being forward- and backwards compatible. 2. Explicitly handle the "I don't know" case, which makes closed sums a poor choice for representation. There's also the kinda sorta not special to protobuf point that if you add something to a oneof and do exhaustiveness checking of switches, you need to fix all consumers of that proto-file at the same time, else they break. But that's just a general property of exhaustively checked closed sums, it applies just as much to any other use-case for them.
Perhaps, because in the special case you already have parameters for f() on the stack in proper order from g() - minimal stack manipulations.
They remove 100% of certain types of runtime errors only if you happen to match them (or your language requires you to match). If they go unmatched, it's no different to a null pointer exception. Remember, nullable types ARE optional types (for further proof, see Types and Programming Languages by Ben Pierce). 
I had an idea to use grumpy to convert relevant files from youtube-dl, i.e. regexes, url requests etc. to Go and to write something to connect that, so that some Go lib can benefit from all youtube-dl updates. But, grumpy was missing a lot of things, and I didn't found out if it is possible. Still, I think it is a nice idea.
It is theoretically possible to have one member of a closed sum type to be a byte slice - binary representation of the "I do not know" value.
While standard library is a good source of initial statistics, I would be interested in a similar stats from a wide variety of Go projects on GitHub. Perhaps, from a selection of 3rd-party packages hosted on godoc.org Most functions returning 2 values are probably constructors. In many cases it is easier to organize multiple values into struct and return that instead of multiple values of primitive types. Reading and writing operations and crypto are candidates for 3 or more return values.
Yes, that's 2. It defeats the whole point of closed sums, which is exactly why I think protobuf (or any other usage for encoders/decoders, including communicating with the kernel and other programs via RPC) is an unconvincing example to demonstrate their usefulness.
"Yes and what you seem to refuse to accept is that sometimes, for some people, a lack of a feature - even when there are alternatives - is a problem." The lack of a feature is never "a problem". Being unable to implement something you want to implement, or finding the existing ways of doing so to be excessively bug-prone, verbose, developer-hostile or just generally groady ... that's a problem. A possible, even obvious, solution to that problem may be the aforementioned feature, and that's fine. But you start with the _actual problem_, not with _but I waaaant this feature and it not being there is a prooooblem_. That's one difference between an experience report and a feature request. And they're both perfectly valid things, just don't label one as the other.
Regarding the abstract syntax tree, I think [this](https://github.com/golang/go/blob/master/src/cmd/compile/internal/syntax/nodes.go) is a better approach. Not sure if that is compatible with Protobuf though. 
So a valid solution would be to enforce `nil` checks in Go. Inevitably, someone will complain about being too verbose (alá `if err !=nil`). So we'd need to come up with syntax that performs syntactic abstraction. Eventually someone will invent semantics for that, then now we run into an issue of a syntactic abstraction becoming a semantic abstraction - you'd need a good type system to be able to handle the newfound semantic abstraction (we'll assume that Go won't go down the Java/Scala path of terrible ad-hoc type systems). Now we've complicated the issue a LOT more. What do?
Don't rewrite imports, use git remotes to store your fork in the original repo's path on disk. cd src/github.com/original/project git remote add mrfrobozz git@github.com:mrfrobozz/project git fetch mrfrobozz git checkout mrfrobozz master 
This was already possible with vendoring and/or with dep.
There is also https://github.com/rylio/ytdl
Follow the instructions at https://splice.com/blog/contributing-open-source-git-repositories-go/ or http://blog.campoy.cat/2014/03/github-and-go-forking-pull-requests-and.html
Excellent! Thank you. That cleared it all up for me.
To be honest, I don't have enough experience with Go to say anything useful, but some kind of compiler flag for unchecked nils could be an interesting solution for those who want it, without forcing it on everyone else. I guess something similar could be achieved with a linter though.
I don't think "everybody else has it" and "multiple returns aren't used enough" are strong enough arguments.
That’s a very specific set of requirements. Can you elaborate on the problem you’re trying to solve?
[GopherCI](https://gopherci.io) comes to mind. Though it focuses on running linters and other static code analysis tools. Running package tests is a future enhancement as far as I know.
A quick search on GitHub ([`ci/cd language:go sort:stars`](https://github.com/search?o=desc&amp;q=ci%2Fcd+language%3Ago&amp;s=stars&amp;type=Repositories&amp;utf8=%E2%9C%93) reveals that most CI/CD projects seem to either be focused on containers or on some cloud service. One exception I found in the first page of results is [harrow](https://github.com/harrowio/harrow) (but I know nothing about it). Or have a look at GopherCI as /u/sh41 [suggests](https://www.reddit.com/r/golang/comments/8693du/are_there_any_cicd_servers_projects_in_go/dw3cdw6/).
https://concourse-ci.org/
Good to know, I also tried a couple but fresh works as expected. Thanks!
Thanks for the tip, I am going to get started with fresh!
I think you misunderstood, I was not talking about deploying just how to iterate faster in local development without having to switch to the terminal and rerun `go build`. I am curious what you think about Concourse tho, I haven't used it but a couple of coworkers are using it.
&gt; using docker images for every build task is a wasting precious build time/performance/builds count You sure you using docker correctly? The amount of time it takes stepping in / out of the container should be minimal in comparison to the time spent to complete the build itself. The benefits of building in a container are great enough that you shouldn't be so quick to abandon the approach.
Concourse is not straightforward to use, but it is very powerful once you get it kicking. Can build entire build -&gt; test -&gt; stage -&gt; canary -&gt; deploy workflows. Seems to do well scaling up and down, since everything's just containers...
Do you have some better method than using containers, to produce repeatable environment(s) for isolated builds?
I'm sorry u/chewxy I've edited the post and the DB. I'm trying to reach out to everyone involved before publishing these posts but I missed yours. Thanks for recording your events!
have you read the question? he mentions drone
just added a search-button feature. (it was really easy, thanks to bleve)
&gt; I'm saying that the language is very far away from this and would require not one, but two major features. I don't think sum types are anywhere near as major a feature as generics. In fact, if you got generics, you could probably emulate an `Either`-like type with a structure. It would be somewhat less space-efficient compared to sum types, but then again multiple return values aren't very space-efficient either... 
Sqlx is nice because it uses the same SQL interfaces that a default mysql connection would use. It just adds a bunch of extra nice he's on top of it including easy inserts and turning queries into usable objects. I've used go orm little bit and it's ok to but I prefer SQL x for it's simplicity and not being too over the top. I haven't written a 50 table database driven application with golang yet though. Mostly services with small functions and needs.
&gt; Sum types would not be restricted to return values, so they'd likely add a lot more complexity for something that most Gophers think is already implemented well enough with simpler semantics. You could restrict them to return values. If you're so worried about stuff being generally applicable and the associated complexity (whether real or perceived), you could easily have Go feature exactly one `Either` / `Result` type. In fact, Go already does this kind of special-casing with slices, maps, channels, etc. If you wish to avoid generality, just carry on with the trend. (I personally don't think it's a good idea, just like with special magical types like slices, maps, etc., but the call isn't mine.) &gt; I struggle to understand why a programmer who wants sum types and monads is using Go, as clearly their preferred paradigm is very poorly supported by it. It's pretty simple: Other people may see other benefits in using Go than you. I personally also see the value of golang elsewhere than the majority of Go community. As I've written previously I personally mostly don't see the simplicity argument, to me it either isn't true in some cases or in other cases it's simply a trade of lower complexity in one aspect for a greater complexity in another. To me, the value of Go is in the thin runtime, the goroutines and that it compiles to native code. A more complex type system would be in no conflict with any of that. 
[removed]
You can lock to cores, take a look at https://golang.org/pkg/runtime/#LockOSThread
Thanks, this one looks very interesting. Do you know if it has GitHub Pull Request integration?
Ok, fair enough. To me it looked like you replied based on the title alone. But if "Have you tried drone?" means "have you actually tried drone to see how slow it is?" then I get you.
How do you get build isolation on Jenkins if not through VMs, Docker or actual slave servers? Because from those choices I don't see why Docker wouldn't be the fastest for spawning and killing builds. Or don't you need isolation for your builds for some reason? 
I find this kind of question slightly peculiar: Why do you want you CI/CD server to be in Go, specifically? I suspect what you really want is just a build orchestrator that is better than Jenkins, and in this case, doesn't use docker images. The Go part seems irrelevant. I am also personally quite annoyed with the obsession with containers, but that is primarily because I *cannot* use containers even if I wanted to. I'm building and testing cross-platform (windows, freebsd, linux) kernel drivers. I'm stuck with Jenkins for now, but that's such a steaming pile of horse dung.
Fast http? https://github.com/valyala/fasthttp
The OP may have been referring to the standard practice to install dependencies and such as part of the build process. These are things that can be easily resolved by either providing a docker image that has these included and then using that. The build performance isn't impacted significantly, if you decide that these are steps that you can prepare beforehand. The only penalty in using docker I can think of is the startup and the shutdown/cleanup time. These can be measured in seconds, but when you're doing something like 50-100 builds per day, you might have wasted only something like 2-5 minutes of server time, and I would consider this heavy load for a CI/CD server.
&gt; &gt; Sum types is how Elm can eliminate all possible runtime errors: &gt; &gt; This is literally impossible (in a Turing complete language). Well, obviously, Elm neither prevents _all_ possible errors nor does it prevent errors with sum types specifically (they're just a small-ish part of it). OTOH languages with strong static analysis are pretty much able to prevent the vast majority of "non-catastrophic" runtime errors. It is an experience of many people that these kinds of languages produce much lower numbers of runtime errors / crashes while requiring fewer tests. Of course, that doesn't mean everyone needs to use strong static checks. &gt; FWIW, I actually think oneofs in protobuf provide a great example of why sum types aren't great for many usages they are proposed for. There is a reason the protobuf language guide contains an explicit section on their caveats. That's not a section on caveats of sum types. That's a section on backcompat caveats of Protobuf's `oneof` feature and the problem seems to be stemming from its implementation detail. I don't really see anything that would be applicable to sum types generally. 
https://concourse-ci.org/concourse-vs.html &gt; It [Travis CI] also has great support for building your GitHub pull requests. This is something that Concourse cannot yet do but we have plans to allow the same workflow in the future.
Particularly, I'd want a CI/CD server to be in Go because I can just copy over one binary to almost any machine and run it with minimal setup. In fact, even better if it's in a Docker image. Considering system requirements for Travis, etc., I'd rather have something that has better memory management, and doesn't require a &gt;1GB pull of dependencies like Java to run it, vs. up to about 20MB for a Go app. Also, we are doing some cross platform builds but not in the elaborate way as you are. It's completely feasible to *build* stuff and have your cross-compile environment inside Docker. We're building multi-arch stuff for windows, linux and arm/amd64/i586 targets. We're also targeting specific hardware devices that require kernel drivers, but the actual destination platform isn't available at build time. Having things packaged in docker is just a convenience, albeit rarely used one. It's just about as convenient as having a backup of a dedicated VM.
I think that if err != nil is the best way of doing things still. It's makes explicit what you're doing, and you can reason about it like "I am checking if there is no error". It's 100% the same as C++ exceptions and is beautiful.
&gt; It defeats the whole point of closed sums How so? A sum that has an `Opaque` or `Future` or whatever variant is still a closed sum that can still be matched on exhaustively. Thinking of such a sum a non-closed is, I suppose, possible, but don't see how it is useful, it seems to me to be more useful to think of it as a nested sum, for example. &gt; which is exactly why I think protobuf (or any other usage for encoders/decoders, including communicating with the kernel and other programs via RPC) is an unconvincing example to demonstrate their usefulness. What's the alternative though? Typically in the absence of sum types in these situations people implement an ad-hoc pretty-much-a-sum type sort of thing, which often ends up being worse than a proper sum type. And so a sum type is still an improvement. 
For every single function that returns a different "real" type or an error? That's a lot of types... Also many of them would have to be public, so they'd cruft up the godocs, too. That is a lot of hassle cost for not much benefit over what we already have. (Not zero benefit, because if I meant that I'd have said that. But I'd consider that to firmly be in cost-exceeds-benefits territory. YMMV.)
Code generation is better and always will be better.
Ah, but what you want is then not Go, but static linking. Or, rather, easy installation. You can get that from almost any language. I think even Java can be packaged into a self-containing executable. You also want low resource consumption, which is a quality of the project rather than the language. Go isn't going to help here. You can write memory efficient applications in Java. I find this "I want X, but implemented in Y" to be an emerging trend that is quite peculiar. Instead, state the real requirements. You want easy installation and good perf/low resource consumption. The language holds no importance at all.
Concourse is written in Golang. It relies on Docker containers for isolated build environment but that is an advantage in nearly every way. The cost of image build is neglible over time / many builds as it doesnt happen every time. Concourse is hands-down the best CI/CD tool I've used and I've used a ton of them including Jenkins and Drone. 
I'm pretty sure that the Docker's [build cache](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#build-cache) solves this, at least if used correctly. Docker caches the image after each step in the Dockerfile, so if you use a Dockerfile like the below, it's only if something changes in `requirements.txt` that it would cause the dependencies to be reinstalled (normally it'll just use the cached image). Taken from [this SO answer ](https://stackoverflow.com/a/34399661/68707): COPY requirements.txt /opt/app/requirements.txt WORKDIR /opt/app RUN pip install -r requirements.txt COPY . /opt/app ...
&gt; Being unable to implement something you want to implement, or finding the existing ways of doing so to be excessively bug-prone, verbose, developer-hostile or just generally groady ... that's a problem. Okay, let me try. In my experience, error handling in Go - is excessively verbose, the consequence of which is reading and writing code is annoying - lacks an easy-to-use support for adding context information and/or chaining, the consequence of which is unhelpful errors Is that experience report-y enough or still personal preference? 
You are partially correct, especially given the example of COPYing stuff into the container. Since these commands are usually at the beginning of the Dockerfile, and you constantly change your code, it will invalidate all further layers that come after `COPY . /opt/app`. &gt; For the ADD and COPY instructions, the contents of the file(s) in the image are examined and a checksum is calculated for each file. The last-modified and last-accessed times of the file(s) are not considered in these checksums. During the cache lookup, the checksum is compared against the checksum in the existing images. If anything has changed in the file(s), such as the contents and metadata, **then the cache is invalidated**. Also, it's common to add ENV/ARG to the beginning of the Dockerfiles, passing build arguments like git commit ID, again invalidating caches. Most of the times caches are either discouraged or (possibly non-intentionally) disabled, and the most "reliable" way to ensure a "reproducible" dev/build environment is by using a FROM image which contains your dependencies, before you possibly do any COPYing and such. Effectively part of the OPs issue could just be assigned to incorrectly setting up their builds and thus incurring the penalty of rebuilding everything each time. This behaviour might be exactly what is wanted in some cases, so it's more the case of knowing and working with your specific requirements, and not some underlying bad practice. 
https://github.com/jtarchie/github-pullrequest-resource
You could fork https://miniflux.net
Concourse is a great rethinking of basic ci/cd concepts that has honestly made it hard to go back to other ci/cd solutions. I’d highly recommend it, but the lack of a simple hosted offering is kind of a drag. Sounds like you’d be looking to host it yourself, which is totally doable. Nice thing is you can it working locally first the apply that exact same configuration to a remote server and have it just work.
I don't see how it's an open sum situation. Unless I missed something, you're enumerating a finite set of options, one of which is "Reserved for future use", in which case you pretty much either ignore it / default to something, if possible, or report an error. That's semantically the same as the treatment of any of those other options. It's distinct from an open sum - interface - where you call a method that may lead to arbitrarily numer locations, which is not the case with a 'future-proofed' sum type. 
&gt; you're enumerating a finite set of options, one of which is "Reserved for future use", in which case you pretty much either ignore it / default to something, if possible, or report an error. Whereas when using open sums, you are enumerating a finite set of known options and add a "Unknown type added in the future" case, in which you pretty much either ignore it / default to something, if possible, or report an error. Which is, of course, completely different. Pardon my sarcasm. Of course it's different if you describe it by different words, but the actual *arguments* in favor of sums simply stop applying. A type-switch with a default-case is exactly as type-safe in every regard and exactly as concise (it's pretty much exactly the same syntax) as a closed sum with a "unknown" case added in.
&gt; Yeah, I know. The article is wrong in this regard. Then why argue, if we agree? &gt; Strict types my behind. Go doesn't even support constness. Well, that's a reasonable response that certainly proves you are interested in getting your viewpoint taken seriously 🙄
&gt; Then why argue, if we agree? I didn't argue this point specifically... &gt; Well, that's a reasonable response that certainly proves you are interested in getting your viewpoint taken seriously 🙄 What wording would you prefer? Maybe "Go's types aren't very strict, it doesn't even support constness"? 
&gt; Of course it's different if you describe it by different words, but the actual arguments in favor of sums simply stop applying. A type-switch with a default-case is exactly as type-safe in every regard and exactly as concise (it's pretty much exactly the same syntax) as a closed sum with a "unknown" case added in. What??? No. A sum type with cases `A`, `B`, `C`, and `Future` is still a sum type with all the goodines, its states are finite and explicitly listed. You can still have exhaustive matches and you can still have IDE hints as to what the possibilities are. To make a match fall into the "unknown" (ie. `Future`) arm, you have to explicitly create a value as such, which would only meaningfully happen when decoding forward-compatible data. With `interface` on the other hand, none of that applies. The list of possible values is neither constrained nor defined anywhere. Unlike with the sum type, the type switch will not guarantee you matched against all the possible values defined in your current version. Additionally, when reading part of code where a value is created, there's no way to tell whether it is a "known" variant or not in the current version. Apples and oranges. 
the word getty(short for go netty) means that the session interface name is the same as netty.
Nice article and videos. Really like how you inject personality into the bytes.
Desktop applications written for .NET usually depend on Windows-specific function calls and works shit on Linux. In theory, they work fine on all platforms, but that's in theory, and they don't.
Perhaps this is ignorance but I'm curious about what prevents you from doing container based builds and then testing on dedicated machines? Is there a quick reason you can state or a reasonable resource you can point me to that covers the restrictions you face?
Like I said in another post, I run my .NET Core code exclusively on Linux. No issues so far and our performance benchmarks match Go. Do you have links to these issues you speak of on .NET Core's GitHub?
(I work at influxdata). We're really excited about this. Thank you to the Apache team and to the Arrow folks for being so welcoming of this work. I'm eager to see arrow as an interchange between more and more databases and data processors going forward.
Examples on mobile do not look right. Might want to use screenshots. 
The Go command is not Go!
lol no generics
Yeah, I have no intuition about cost/benefit of doing this; for me it's a curiosity. If anyone has more concrete information or experience, I'd love to hear it!
What is missing is some real world examples on why verbosity is a problem or with context chaining. That is an experience report.
It sounds like you are describing the current system, in which packages have *no* version number. This is in contrast to the proposed system, in which the version number can be used to specify which one you want. I haven't ever worked on a go project that was large enough to care, but "being able to specify the version I want" sounds like a definite improvement to sanity. Having a defined method (semver) of specifying compatibility sounds very much like "the go way" of doing things, rather than letting each module come up with its own compatibility rules - that said, I expect that "intended compatibility" and "actual compatibility" will clash in a place or to. Having a way of specifying alternative sources for specific modules is the one thing I have definitely wanted out of this, and it sounds like it would solve such "intended, but not" compatibility issues, as well.
&gt; I don't need isolation for most of the build tasks Translated: I've yet to find the bugs caused by lack of isolation. (Wanna find them? Easy! Test your build node failover...)
&gt; I can just copy over one binary to almost any machine and run it with minimal setup. You're talking about the artifact(s) of the build process. That's orthogonal to the CI/CD server. &gt; I'd rather have something that has better memory management You're not saying what sort of "better" you're looking for. Despite the apparently larger footprint, Java memory management is quite efficient. Google is doing 1,000s of daily builds on Travis, and it doesn't require an entire data center. &gt; Also, we are doing some cross platform builds Again, totally orthogonal to your choice of CI/CD. Cross compilation can be done natively and/or in a container, with any tool you choose. &gt; Having things packaged in docker is just a convenience No, it's a necessity, to ensure repeatable builds. When you build outside a container, and you're not super careful, you're going to start carrying artifacts from one build to the next...
I think the honest answer to OP's question is no. Seastar's main claims to fame not replicated by Go: - network stack optionally in user space w/ dpdk ([go bindings](https://github.com/millken/dpdk-go)) - [direct io](http://docs.seastar-project.org/master/group__fileio-module.html) for files - core pinning + lockfree msg passing I think it is misunderstanding seastar to say it is mostly provided by Go, although I think that _stylistically_ seastar C++ programs will probably feel more like Go programs than non-seastar C++ programs. Generally, I think people use seastar because of these low level implementation details, not just as a way to do concurrency via actors in C++.
Yep. Or push to another branch if you want to send multiple PRs.
Glad to hear that. Enjoy, Go is indeed very pleasant for many tasks.
Interesting, how does direct io performed compared to https://golang.org/pkg/net/http/#ServeFile 
&gt; I had heard a lot of the FUD about Golang and hadn't given it a fair shake. [FUD](https://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt)? Please elaborate. Criticism is not the same as disinformation.
I'd say that they are for the most part not related. IIRC, ServeFile uses [sendfile](http://man7.org/linux/man-pages/man2/sendfile.2.html) behind the scenes, which is meant to cut down on context switches (ie, you do not need to `read` and then `write`, which are syscalls; the kernel just pipes the whole thing) Direct IO (and `O_DIRECT` upon which most impls are based) is a way to avoid the fs cache so you can control read and write caches in-app instead of letting the OS manage it. This can be important for databases which may have more information about write patterns than the kernel would. 
I don't know in what sense 'strict' is used in this subthread (perhaps as in 'strong typing'?), but it's beside the point in either case, as it was a reaction to this: &gt; It is an experience of many people that these kinds of languages produce much lower numbers of runtime errors / crashes while requiring fewer tests. and I certainly didn't mean Go by this. 
Whoops! Thanks, will add some screenshots.
Oh, thanks a lot! &lt;3
This is similar to what Whisper(Python) storage in Graphite ecosystem. The problem with using direct filesystem is that, at tremendously high volume: 1. you will run out of inodes. 2. your disk read and write will be too hot, harming your SSD, because you are missing out on modern database's in-memory buffer. 3. You still have to solve ReplicationFactor and multi nodes memberships. Just my 2 cents.
Out of curiosity, how does using something like Arrow compare to using an in-memory sqlite instance?
agree completely, I primarily implemented it because it was easy theory to test out raw performance I'm working on getting better logic in 'splitter' and something that could mimick WAL. Having multiple low-res backend 'servers' with a better 'splitter' might be able to address that.
Just adding my 2 cents: &gt; It's not a waste. It's the cost of using a container. And the benefits outweigh that small cost. I will not state whether 2-5 minutes is a realistic claim of penalty here, but 2-5 minutes extra on my pipeline would be absolutely unacceptable. It would be adding 50% to the entire integration pipeline, and it would *triple* the time it takes to get a branch merged to master. The *load* of installing the environment build environment is insignificant (it's all I/O), but if we have programmers waiting for things to complete, we are indeed wasting time. (And no, the short build-times here are not due to light load, but because each build is parallelized over ~10 VM's out of a rack full of beefy VM hosts—hardware is cheaper than (wo)man-hours)
Why did this get removed? 
&gt; but 2-5 minutes extra on my pipeline You didn't read the thread very carefully. /u/titpetric is talking about 2-5 minutes over one day of builds.
While I agree with you somewhat on the second bullet point it's still vague personal preference, neither a concrete feature request nor a concrete example of a real problem found in real-world code. As is it's just unfocused criticism of the language, which is a great basis for a blog post but not a lot else.
MGO Driver var result Property // a struct type collection.FindId(propertyId).One(&amp;result) MongoDB Driver result := bson.NewDocument() filter := bson.NewDocument(bson.EC.String("hello", "world")) err := collection.FindOne(context.Background(), filter).Decode(result) At first glance, the new driver looks much more verbose. 
I like seeing different approaches to testing in Go. Unfortunately, I think this might not be a good approach. By moving the core analysis code out, you have made it so that's the only thing you're testing, but you are no longer testing the actual API that other people will use. You've actually reduced test coverage instead of increasing it. In general, I prefer to not accept a file name in an API. A file name doesn't give users enough control. It doesn't let you use an unusual encoding, special file permissions, or a bytes.Buffer instead of an actual file, for example. Accepting a file name adds a huge dependency to the code: the file system, along with all of its associated OS specific stuff. So I probably would have eliminated the file name based API and only exposed one based on io.Reader. That way, you have complete code coverage, fast tests, and far fewer edge cases to worry about.
[removed]
It's not difficult to implement sum types. It's difficult to implement sum types with enforced checking. See my reply here for a general case https://www.reddit.com/r/golang/comments/863r1c/for_sum_types_golangs_multiple_return_parameters/dw3326f/
Yes, but decoupling the file i/o based part from the datasource-agnostic part is the first step towards that - and that's what the article talks about. Often times you can't simply change the user-facing API easily, because the API might be public and might have users. So small, incremental steps are better than nothing. I wanted to show a practical, hands-on way to change the code for the better in situations like this. That got me thinking, maybe I should clarify that point in the post.
Not a big fan of the new file type. It would be nice to reuse an existing file structure like toml or yaml
What does your project structure look like? 
I believe the idea is that getters and setters do not add to what you can do with exported struct properties. Methods should provide additional functionally based on what you are actually doing with the data structure. However it`s just a suggestion, not a requirement. Is your code just sharing a data structure or do they really need an interface, which you have multiple implementations for?
Ah, over one day, 5 minutes is certainly entirely irrelevant. We agree on that. &gt; You didn't read the thread very carefully. The writing is ambiguous, so it's not really about careful reading. I chose the interpretation that seemed realistic (complaining about 5 mins per build rather than 5 mins total a day).
Thanks, that’s true now I think about it
/u/XVilka this is no longer true as of a few hours ago! https://about.gitlab.com/2018/03/22/gitlab-10-6-released/
I'm writing unit tests for another team member's code. He decided to separate some of the core low-level components into a separate repository and I'm now trying to break this dependency so that i can isolate and test each component. Some of the methods which I was able to abstract away will return structs, the high level components will read property values (usually more objects) from said struct. I would like to decouple these two repositories completely by first defining a set of abstractions which will reside alongside the high level codebase but I'm not sure how to handle the return types without doing some major refactoring or introducing Getters (which can be abstracted away via interface). 
Ah, yes, the billion-dollar mistake...
I haven't done a threat model on this or a code review, but I'm trying to understand the risk that you're trying to solve for. A vendor makes a plug-in, and as a consumer of that plug-in, I want to trust all plugins by that vendor. Since, presumably, the plug-in would be put on the filesystem before execution time, wouldn't it make sense to use existing controls such as PGP signature verification at install time, and then os controls such as ACL's to prevent the file from being replaced after installation? I'm not saying there's not a case for this, just tying to figure out where it is that I'm running my code in a non-hostile environment, but I expect plugins to be from a hostile environment, and I know in advance who the plug-in providers that I trust are. 
Just wanted to say thanks for the tick stack it doesn't get enough praise. 
It's a directory with a single go source file, and a static and templates directory. I've managed to keep the whole thing in a single source file so far.
Have you tried just using an infinite for loop and a buffered channel as a queue? Send the root node on the channel and then: for { select { case node := &lt;- ch: // Send all children on channel // Do work on node default: // nothing left in queue break } } BFS in ~10 lines The major down side that I can see is that you need a channel buffered to len(graph) but can always use pointers if need be. If you know the structure of the graph (eg binary tree) then you can exploit that to reduce the size of the buffer. Makes everything much cleaner to read at the very least, and I'd be interested to see the benchmarks.
I'll cover parallel approaches in the second part. And I'll add that to the potential basic implementations. As a good approximate for calculation, each send on a channel has ~50ns overhead and a write to an array has ~1-2ns. Also, when you put things in a channel you cannot sort them afterwards.
I wonder if you can load it to a read-only virtual filesystem of some kind and load it from there? Or copy it to a random tmp directory to make the attack harder to time. But the attack is already pretty hard to time properly. 
I was thinking of it to allow whitelisting of plugin developers for updates. I'm toying with automatic updates for plugins.
I doubt it's anything "profound", it's probably just that they decided to A: represent EOF as a token, which is good for the parsing phase B: require that all tokens have a position and C: require that no two tokens overlap. If you take those three properties of tokens, none of which are all that shocking on their own, then you end up implying that the EOF token must be one past the end of the file.
Useful
Can I quote you in the README?
I like this idea. Any plans to add Wiktionary? Right now I am using the Wiktionary dump files but would like to give people who are running their own version more options (including the Wiktionary API). Here's what I am doing for Wiktionary if it helps: https://github.com/jivesearch/jivesearch/tree/master/instant/wikipedia.
My favorite resource is awesome go: https://awesome-go.com 
Few hours ago I was watching "just for func" refactoring episode and it tackles the exact same problem, I think in a more elegant way, I highly recommend you watch it: https://youtu.be/ifBUfIb7kdo
That's a great idea! I'd happily accept a contribution. Otherwise, I'll add it to my list of potential sources to add! Thanks!
You can do that
 cheers!
I want to write a cli tool that can adjust the order of structure fields. You inspire me👏👍
you should think of this more as a dependency on the io.ReadCloser factory. You have a factory method that accepts a string and returns a (ReadCloser, error) you defer the ReadCloser.Close() and consume the ReadCloser with a Scanner. Rather than isolating the scanner, control the factory (os.Open) and the rest is trivial.
My TMFRAME is similar but further along, with mergesort, grep, dedup, and indexing tools already implemented. https://github.com/glycerine/tmframe/tree/master/cmd
Awesome man! Good luck🙂
Shoot! I was just searching for a fun, small but useful CLI project idea and I'm jealous I didn't think of this idea- will totally use this. Oh well, back to brainstorming...
&gt; Often times you can't simply change the user-facing API easily, because the API might be public and might have users. Definitely you are sometimes restricted in your choices by business realities, but the standard advice here would be to create a v2.0 of your API with the better designed interface. Existing users are undisturbed, but are encouraged to upgrade on their own time frame if they want new features.
File locks on Linux only work if all programs use the file lock. 
3pm is 15, not 12. So the correct string for 24 hour format is "15:04:05".
Linux does not have (reliable) general-purpose mandatory file locking. Not only does it not help someone from scribbling on the file while you're verifying it, it also doesn't guard against the file being completely replaced by a `rename` system call. What you really need is a way to pause the plugin load process after the file has been mapped into memory (and actually locked in the same way that running executables are locked) but before any on-load code has been run.
Buildkite could be another alternative. It's a hosted service, but the builds run on your own infrastructure using a small Go binary - here's a link on how it works: https://buildkite.com/docs/agent/v3 The hosted BK stuff handles all GitHub integration, and all the hard/annoying parts of CI. We leave the actual running of builds up to you (a $5 Digital Ocean box is a great fit for something like this) (Full disclosure, I'm the creator so 100% bias). It's a SaaS, but if you shoot me an email at keith@buildkite.com - I can comp you a free personal account if you wanna have a play with it.
(This offer is open to anyone that sees this btw!)
Nice article. It's like they say, "accept interfaces, return structs".
Can somebody practically explain when you'd use Apache Arrow? 
C isn't an assembly language
The last code sample has a bug, missing a j = 0 at the end of the loop
Because a N runes file has N + 1 scanner positions. Imagine a single letter file. In the beginning the scanner position is before the letter, after the file is scanned completely, the scanner is after the single letter (and at EOF). Those two positions are clearly distinct, aren't they?
As fond as I am of ElasticSearch (we use it in production at work), this blog post doesn't really offer much? It basically wraps the elastic client in an API. It would be better to explain ElasticSearch more in-depth, because it is so elaborate and offers so much. This post doesn't even scratch the surface of it. Minor remark: you don't need a "type" anymore for ElasticSearch 6 and up, as multi-type indices are no longer supported.
Great and concise article. In general, file I/O is full of edge cases. The majority of the bugs in the CLI tool I'm working on is due to file system issue, most often platform discrepancies: * Permission errors * Slashes and backslashes. Drive letters. * Relative paths * Multiple representations of the same file path makes it hard to determine equality. * Symlinks. Concrete example: I point you to a file, (say a package.json file), and then you should package up the app for me. If the file is a symlink, do you resolve it in order to determine the directory? * Temporary files is its own can of worms: * Creating a file within a directory without race conditions * Life time/cleaning up. * File modes, seeking, truncating.
That's not helpful at all. Of course I read that answer but it doesn't practically say when I as a dev would use Arrow and for what cause. 
How does it compare to [Clickhouse](https://clickhouse.yandex/)?
Sure, a common mistake then, you're correct :). Mostly it's just because of tutorials which start with this stuff and then move on to various ADD/RUNs and so on, and people that learn by copy pasting first, until they actually get to the docs.
Well, I did take Etsy statistics as an estimate, since they did so many builds some years ago, and even at 10x the penalty may be negligible. I have about 600 git repositories under my wing, work with groups up to 10 developers, and at a maximum there would be about 10-20 builds per day per developer, and obviously not all of the same time would touch so many projects, so our statistics are on par with etsy, at least as far as back of the envelope calculations go. Let's consider that you're an enterprise player (if you're working with 1000s of builds per *day*, you'd have to be, and have to have a significant developer team size/distribution), there will be still negligible impact in regards to using docker because of one or two facts: 1. you *will* optimize docker images for size, 2. you *will* run everything off very fast storage, 3. you *will* be running many instances (agents, etc.) With both of these properties taken into consideration, the overhead even with the unrealistic 2 seconds per build will still cost you just an hour of server time for all of the builds, total.
I've had a similar experience discovering Go. I've been coding in C++, C, Java, Javascript, VB, Haskell, Rust and found the best productivity in Go. It is simple and gets things done. Now I'm doing all my projects in Go and have full web apps running happily, powered by go.
PS: can you share some of the FUD with us? Inquiring minds want to know.
Thanks a lot!
What kind of FUD? Just curious. 
What’s with the thumbnail?
peaker here, if you have any questions about the talk ask away :)
thajunk is right. The inner loop is only run for the first function in your example because j is not set back to 0.
A good way is to define your HTTP handlers as methods to a type. You can then inject dependencies, like your logger, when initializing the type. type app struct{ log Logger } func (app *app) handler(w http.ResponseWriter, r *http.Request) { app.log.Printf(...) } You could also centralize your logging by using helper methods or closures to chain handlers together. If it fits your use case you could potentially use a global logger like [Upspin](https://github.com/upspin/upspin/blob/master/log/log.go) does. Some good reads: * [Go best practices, six years in](https://peter.bourgon.org/go-best-practices-2016/#logging-and-instrumentation) * https://blog.golang.org/context * [How to correctly use context.Context in Go 1.7](https://medium.com/@cep21/how-to-correctly-use-context-context-in-go-1-7-8f2c0fafdf39)
In case you're not joking, the text of example commands and outputs under the usage info are the "screenshots", since it's a CLI tool.
fair enough
The common ones: Go is useless because it has no generics, and you need generics to write anything more complicated than "Hello world". Go makes you copy and paste tons of code all the time and there's no way to refactor it. Go claims to be strongly typed but you really end up using interface{} everywhere. Less common, but one of my personal favorites: Go is not suitable for concurrency because it's a blocking-based language, so it'll never be as good at concurrency as Node. (I will never forgive the Node community for breaking people's understanding of what "blocking" means, because that community conflates the difference between blocking a _thread_ and blocking the entire _process_, because of accidents of Node design.) Slightly less FUD-y: Despite Go's claims to be good at concurrency it's still a shared-state threading language. (This one is less FUD-y because it is actually true, and is something you do need to stay aware of. Go _affords_ good multithreaded programming with channels and a good philosophy, but technically you can still get yourself stuck in multithreading hell if you do the wrong things.)
You are commenting in a subreddit called /r/golang...
After learning that SOCKS5 isn't enough, (easily detected and blocked), I'm hoping projects like shadowsocks continue to gain research and support.
All the traffic between local host and remote gsocks5 server is encrypted by TLS. I just wonder that how it detected by a firewall? 
He gave a similar talk at GopherCon Denver 2017. It was eye opening. 
Just because something is encrypted doesn't mean you can't figure out the type of transport. Shadow socks was built by someone in China where their firewalls (like other countries) can spot protocol patterns. Read the guides, it's really interesting.
Thanks!
Be careful with your purism. I remember former coworkers of my former colleague who were proud of their 100% coverage but it turned out they were testing their mocks. File system is right on your machine and in the huge majority of real use cases it is easier to play with real files (temporary directories, etc).
I recognize that this is /r/golang, but this article provides no numbers or actual proof one way or the other. It presents itself as an A/B comparison, but by the end you realize its outcome was predetermined.
Along with what others already said, I can't speak for the Go scanner in particular but in my own adventures in scanning/parsing I always give EOF a position because then you have something to report in error messages that are triggered by an unexpected EOF, without having to special-case EOF with its own error message. That is, you can report e.g. "unterminated string literal" with the source position pointed at either a real token or EOF, rather than having to have a special "unexpected EOF during string literal" error case to pass this context on to the user. Additionally, if there are text editor build/verify steps integrated with your language then it gives the editor a specific location to show the squiggly red underline when an error occurs at EOF. 
Node.JS isnt a language either. Those two names were chose to make clear what the article will be comparing. 'Go vs Javascript' would leave many people confused. 
I assumed this was the mitchellh talk, wasn't disappointed.
You should prefer the external libraries when possible. The internal ones (via import appengine) don't receive much love 
But "Go vs Node.JS" wouldn't. Actually that's the only sensible way to spell that. The situation about JavaScript vs Node.JS is special in that JavaScript was born as a "hosted" language with very limited scope. Node.JS is a *platform* which is basically a networking engine with direct support for executing JavaScript code on itself while providing that code with certain capabilities. Contrary to this, Go does not have such "platform": it has netpoller in its runtime and the standard library to wield sockets and HTTP, so programs written in it require nothing but an OS kernel to run. Hence it's "Go vs Node.JS". If the article was to compare, say, raw network performance, that'd be "Go runtime vs Node.JS".
That wasnt quite my point. The name 'go' is just not good for a title. Say you are not really aware of the existence of go, and read 'Go vs Node.JS' that can be confusing. Also, we should really not care if people call this language go or golang or gohmygosh. Names are just identifiers without much value (at least for languages). 
&gt; SOCKS5 isn't enough Your requirements != requirements SOCKS was intended to fulfill. SOCKS5 is still fine for the things SOCKS was meant for.
I forgot there’s an EOF token. You’re probably right. Thanks!
In that case, wouldn’t there need to be a position before the first letter too? Is that how the Go scanner actually works? I can imagine it instead working by starting at the letter, processing the first token, then advancing past the end of the file and stopping, no extra valid position required, it’s just past the end.
You're treating the subject very well, thanks for laying it out as you are. I think many of us who bring our org into the modern age of distributed build systems go through these same struggles with containerization: one has to learn how to use containers optimally, tuning the container host as well as the build process itself. The former (tuning the host) is well documented, but the latter can be a bit of dark art, especially when one tries to optimize individual build steps. Builds work fast when intermediate build artifacts are cached, but we use containers because we don't want to keep build artifacts around, it's a catch-22! I suspect here is where OP has tied his dick in a knot...
https://github.com/golang/go/wiki/SuccessStories
it's just format, why do I need to match the meaning? 
What’s bad about simulating getting an unexpected EOF token by detecting there are no more tokens? You can still report the same error message if you want. Wouldn’t reporting an unexpected EOF token at a file offset outside the file be invalid for an editor?
Thank you for posting the project, new projects are always welcome here. One small suggestion: a few words in the readme about what the tool does and how to use it would not go astray.
Fortis Hospital is urgently in need of kidney donors with awarded amount of (1 Crore 45 Lacs). Interested person should kindly contact us and you will be highly rewarded with this amount. For more information WhatsApp OR call: +918792491580
I’m new to Go but the Go ecosystem doesn’t encourage a huge file,... does it? That screams unreadable to me.
It's currently less than 200 lines, I wouldn't consider it huge at all. If I needed to break it up I could but it's far from unmanageable so far.
&gt; In that case, wouldn’t there need to be a position before the first letter too? That's exactly how it is. In the one-letter example, two positions are needed as discussed before: &gt; In the beginning the scanner position is before the letter, after the file is scanned completely, the scanner is after the single letter (and at EOF). ``` | A | ----- ^ ^ | |__ after A, at EOF | |_ before A ```
I see, I thought you had a large web app running from one file. I suppose a lot depends on if other developers will look at it? My understanding was Go encourages you to extract your functions into mini packages and import and call them but again, new, so wanted to check.
It's not large by any means, it's a simple web application for a class project.
You're using the filesystem, hence its trivial to saturate your IO channels by batching writes. Performance is entirely dependent on your hardware and your fsync patterns.
Presumably when you make that SELECT statement, you're doing it to satisfy (i.e. fill up) some domain type in your program. You can SELECT into it directly, i.e. type MySQLStore struct { db *sql.DB } func (s *MySQLStore) GetRecipe(recipeID int) (r Recipe, err error) { row := s.db.QueryRow( "SELECT i.ingredient_name, r.recipe_name FROM ... WHERE i.recipe_id = ?", recipeID, ) if row == nil { return r, ErrNoSuchRecipe } return r, row.Scan(&amp;r.IngredientName, &amp;r.RecipeName) }
And of course, there's nothing stopping you from scanning into separate Ingredient and Recipe structs, with a different selection of columns going into each.
cheers. So I was right when thinking that domain types must be prepared to receive JOIN queries, as opposed to composing the "tables's structs" together somehow.. ?
A function is more than a name, it's the whole signature. type hash string type password string func (h hash) Matches(p password) { ... } This is an extreme example, but don't feel afraid to lean on your arguments for descriptive power. By the way, I hope your passwords are not just converted into base 64. That's not a hash, or even encryption, just another way of storing plain text.
In most Go code I see the context describes the object as well, such as the package name and type. Such a name would be redundant in a well formed and designed package. This is why package names like “utils” are discouraged and using the Type system properly is important to prevent programmer error. Here for example you are having to describe input invariants by naming due to ambiguity between string and a base64 encoded hash string and a Password string. So a type safe interface may instead look like: package authorize // enforce type safety type Equaler interface { Equal(Equaler) bool } type Password string // impl Equaler type Hash string; // impl Equaler Then anything that returned a Base64Hash would return a Hash, I.e. maybe you would have a Hash() function on your Password type to derive a Hash type. Then comparing looks like Hash(hashFromDB).Equal(Password(requestPassword).Hash()) Obviously this abstraction is going wayyyy to far. Strings are comparable so you should just have a Hash type and compare them. But point was to illustrate how naming and sharing interfaces qualifies objects to prevent obnoxious naming. 
Just make your struct match what your data looks like if that's what you are going for. You'll still have to determine when it's better to do a JOIN in a single query, meaning that you'll be duplicating scanning and using more bandwidth for the parent table, vs doing two separate queries, but that's the same for any language. type Recipe struct { Name string Ingredients []Ingredient } type Ingredient struct { Name string } rows, err := db.Query("SELECT i.ingredient_name, r.recipe_name FROM ... WHERE r.recipe_id = ?", recipeID) if err != nil { log.Fatal(err) } defer rows.Close() r := Recipe{} for rows.Next() { i := Ingredient{} err := rows.Scan(&amp;i.Name, &amp;r.Name) if err != nil { log.Fatal(err) } r.Ingredients = append(r.Ingredients, i) }
Go's time parsing uses the numbers to determine what the appropriate part of the text is interpreted as.
The medium-term plan is that the library at `cloud.google.com/go/datastore` should be the one to use *everywhere*. But, until we have better support on GAE standard for that one, the `google.golang.org/appengine/datastore` is the correct one to use. As /u/sbuss says above, avoid the `appengine/datastore` package in favor of `google.golang.org/appengine/datastore`.
Let me know how your progress goes. I use Golang day to day for my civilian employee but don't dare bring any of my automation type skillsets to the military reserve side since I'd get more hassle than it's worth to try and improve efficiency.
One letter, two positions. One before the letter, one after the letter. Are we looking at the same picture (above)?
[removed]
Will do. I didn't find anything directly Gov related on SuccessStories or GoUsers. But Paul Tagliamonte (@paultag) reminded me that Docker is written in Go (see tweet linked below). And Docker is used all over the place in the government, so there's hope. https://twitter.com/paultag/status/977282164319547395 (thanks @dgryski)
Anything non-obvious people new to the elastic client should know?
My company roll our own database code and generate the boilerplate stuff. Currently it’s just MySQL but I’m working on CockroachDB-flavoured Postgres support at the moment :)
Out of curiosity, what is this method being used for?
https://github.com/golang/go/wiki/CodeReviewComments#variable-names discusses this a bit: &gt; The basic rule: the further from its declaration that a name is used, the more descriptive the name must be. For a method receiver, one or two letters is sufficient. Common variables such as loop indices and readers can be a single letter (i, r). More unusual things and global variables need more descriptive names.
[removed]
My example is a little contrived as I was especially interested in choosing the right approach for mapping results of JOIN queries and at the same time re-using "model" structs (if ever that was a good idea...). From what I can see here, it looks like ad-hoc structs will be used wherever there is the need, which is what I wanted to know. Thank you for the example, it helps :)
I like K&amp;R Go quite a lot.
https://www.goodreads.com/book/show/25080953-the-go-programming-language is the best Go book.
My sister and I created that collection and we would be glad to extend that collection. We would highly appreciate ideas and topics to consider.
Basically, you want this : https://secure.php.net/manual/en/function.password-verify.php
Like others' said, you need a designated struct to do so, and you will need to write the SQL code in Go. I use a SQL builder, squirrel, for simple select and join statements like the one in your example. For complex join statements, I usually write a draft against the database to make sure it produces the result that I wanted, then I format it to fit Go's need. Personally, I am not a fan of ORM as I usually don't trust the performance and/or the correctness when it comes to very complex query statements. I prefer to write my own DAL code and take the responsibility. I hope it helps.
[Essential Go](https://www.programming-books.io/essential/go/)
Thanks!
Thanks! 
Thanks!
Thanks!
I grabbed this one, looking forward to digging into this one.
&gt; You'll still have to determine when it's better to do a JOIN in a single query, meaning that you'll be duplicating scanning and using more bandwidth for the parent table, vs doing two separate queries, but that's the same for any language. You could also returned the joined values as an array column in RDBMSes with necessary support. You still have to consider the tradeoffs with each approach, but I think it makes reasoning about the data more clear when the array tradeoffs are acceptable.
This is a good book 
Thank you, justinlindh, for voting on im\_bot-hi\_bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
I was just giving you a hard time since a screenshot implies an image and the section was actual text in a code block lol.
I really liked Todd McLeod's course, you can get it for free here https://greatercommons.com/cwg 
bad bot
Is there anything public?
holy shit nice!
The picture consists of a single letter `A` and _two_ position markers `|`. The first position marker is labeled `before A`, the second position marker is labeled `after A, at EOF`. There's no third position nor third position marker in the picture.
I don't have a book recommendation, but i often use http://exercism.io when i need to pick up a new language. I feel like it's a better training tool than my previous approach of just reading and messing around with the language, since the practice is more focused and you get to compare your solution to others, so it gives instant feedback.
So neither of the two positions are inside the file?
I wrote [API Foundations](https://leanpub.com/api-foundations) with this exact transition in mind, albeit PHP/Node -&gt; Go. As long as you have some knowledge building APIs in other languages, it should be easy enough to follow.
That is excellent, thanks!
Excellent, thanks!
Great stuff, thanks!
That is great! Thanks!
I have created one for CockroachDB and Firebird for my own use. The ORMs I've toyed around with seem very slow by comparison. I've done the same for C# for the sheer amounts of data I work with. EntityFramework has too much overhead it seems. My generator also use text templates (recursively) allowing you to generate models, APIs, etc. If anyone is interested, I'll put it up on GitHub.
Yeah, that’d be great, cheers!
I'll clean up my code, document it a bit and I'll get it posted.
In go, you can return two values: func myFunc() (int, bool) { return 0, true vs return 0, false } Then you call your function like this: if val, ok := myFunc(); val { fmt.Printf("Returned value is valid: %d", val) } 
Our main real time stack is go servers that basically generate the data (as in, serve stuff, generate log we can postprocess), they generate data that is then processed by Scala (personal recommendation), Python or some Pig Latin (a map reduce thingy)
Could you elaborate a bit more for me? Where do I put the function that I want to execute at intervals?
To add to this, the "comma ok" idiom is also used in checking if a value exists in maps. Very nice when an operation can only succeed or fail and you don't need failure infom
Interesting! Thanks for answering. If I understood well, you get data and preprocess it using Go, what do u use to store it or do u do everything on the flow ?
My fault, now I've included all the details in the article: "A number literal in Go (as well as in C and Java) is in base 16 if it starts with 0x or 0X, in base 8 if it starts with 0, otherwise it's a decimal number."
Yes, I have. Feel free to raise any issue. 
It's definitely trivia. I intended the "besserwisser alert" as a warning that you may come off as a little arrogant if you insist on keeping up these distinctions. The guy in the picture is the philosopher Jürgen Habermas and he may well be one of the top smart alecs of our time.
Thanks to both of you.
How do you build your image? Try running `docker inspect &lt;containerID&gt;` to see if the variables are set and have the correct values. It sounds like you're hardcoding the variables in the Dockerfile, don't do that. It's very insecure. You could just as well make the bucket public. Passing the keys as command line parameters is slightly better and should be preferred over putting them in the Dockerfile.
Contributions are welcomed!
You can find a Cockroach DB generator I have made here (https://github.com/siginterrupt/cockroachdbgen). There models generated contain both the model and functions to update the database. I'm sure there is room for improvement. Enjoy! Don't rip on my code too much! 😀
`t2, _ := time.Parse("03:04:05", "12:03:30")` why does this work? if YEPHENAS is correct, this should fail as well.
I think The reason is your environment variables are missing underscores after AWS.
Would you mind sharing the definition of your handler func that can decode 2 different events? In my case I need to make it work with events.APIGatewayProxyRequest and events.CloudWatchEvent. But any example will work. 
Would you mind sharing the definition of your handler func that can decode 2 different events? In my case I need to make it work with events.APIGatewayProxyRequest and events.CloudWatchEvent. But any example will work.
Whoa, that’s very useful. 
My entire pipeline is Go, except exploration. That's done in Jupyter. AMA
[removed]
How does it compare with https://github.com/mattn/go-oci8 and https://github.com/rana/ora?
I can't remember _exactly_ where it is (could probably look it up), but that's not relevant honestly. It's just JSON, you need to handle `event` and `context`. It's not Go either, it's Python. The concepts are still the same.
Mainly, since its based on ODPI-C instead of OCI, it does not require oracle client to be present during compile time. So no need to fiddle with things like oci8.pc making it way easier to use. It is smilar to Python's cx_Oracle and nodejs oracledb driver
Go uses the literal portions of the reference date for date and time formatting. The reference date is 01/02 03:04:05PM '06 -0700 The values here are special because they also correspond to meaning, instead of thinking about DD/mm/YY or anything like that. So you can see writing "12" never makes sense for format string.
/u/grannyno [if you look at the docs](https://github.com/aws/aws-lambda-go/blob/master/lambda/entry.go#L25) you'll notice it does not declare an explicit type and the private signature [is just \[\]byte](https://github.com/aws/aws-lambda-go/blob/master/lambda/handler.go#L13). You should be able to make a function signature like this: func(context.Context, interface{}) error You'll just have to handle the encoding/decoding yourself.
You might want to look at contributing to: https://github.com/cavaliercoder/grab
If it could download a file through multiple gateways that'd be awesome. I have eth1 and eth0...
I know a little bit of Java, OOP, but never actually developed any programs, just the basics.
Thanks, will check it out!
Also a lot more info [here](https://golang.org/doc/) once you're done with that, the FAQ is good. The sidebar has a link too, https://dave.cheney.net/resources-for-new-go-programmers
Thanks man, will definitely check your live streams!
actually, if your function takes an "events.S3Event" struct (github.com/aws/aws-lambda-go/events), you don't have to take care of any parsing.
Do you have the correct region of the bucket set? Sometimes I have seen that explicitly passing/setting the S3 bucket's region in your S3 calls help.
Yes, I have se the correct region. I think the problem is with setting the env variables which I need to look into.
I do have underscores, I have also pasted the entire ENV variable command in the description. At the moment I have resolved the issue by passing the env as a command line argument.
Thanks for your suggestion. At the moment, I have resolved the issue by passing the env variables in the command line.
In that case are you wrapping the env car in quotes? Perhaps you’re not trimming the quotes which would cause this error as the access key is a part of the s3 signed header. 
Thanks, this is really great.
$GOPATH
We don’t preprocess with go, the servers are the source of the data. They generate it. We have a real time pipeline involving Kafka and the data is persisted to S3
so hacking. so wow.
My readeef aggregator supports sqlite3
So you moved the core logic out, but you are no longer testing analyze. Testing analyze still requires file I/O, right? How would you test this with full coverage? I agree with the other commenter that the API for this example makes it difficult to test, but at some point someone needs to consume it. I suppose the API consumer mocks out the interface that provides doSomething?
Any suggestions for rendering js?
Have a look at Caleb Doxsey's book available online for free http://www.golang-book.com/books/intro I believe O'reilly publish a physical copy of the book as well. It is very concise and covers all the key concepts of the language. Also checkout golang's documentation on golang.org. Golang has got to be one of the best documented programming languages out there
May be later, thanks for your suggestion or you may just contribute.
In my experience, it is more stable. Everyone seems to be recommending rana/ora.v4 but I was unable to solve my production crashes with it. goracle has been a walk in the park, although Oracle has some black magic with it's SQL*Net break/context functionality. For examples of it's usage, I'm having to offer advice to others. If you're interested in a dynamic Golang ORM that supports Oracle *and other databases*, with some constraints, maybe take a look at my package that standardizes on goracle: github.com/rbastic/dyndao
Thanks!
Thanks man will read it.
If it's actually backed by a single binary file, how are you dealing with appends to / deletions from a file in the middle of your blob?
Selenium and PhantomJS are the only options I can think of.
&gt; However, we decided to take the plunge and do a bit of research on it. To come up with a more accurate verdict on Nodejs vs Golang , we read up a bit on it. If the goal was to compare performance, why wouldn't you set up a benchmarking test, instead of deciding to 'read about it'. &gt; Concurrent and Scalable - This is an another aspect in go vs node where Golang beats most of the modern computing languages Seriously? Threading and concurrency has been in languages for decades. Go makes it slightly more convenient but hardly making it some new breakthrough in performance. This was the most shallow comparison I'd ever seen. It was literally a couple sentences written up after reading a Quora post without any actual information that is useful.
It's not, it's basically what google does.
Or maybe Chrome Headless with something like this: https://github.com/chromedp/chromedp
Didn't use a html phaser, use substring matching instead; and when you find valuable information to be keeped in ram, copy it, don't index it from the original string, this allows the page to be garbage collected. 
I don't think you need to, wouldn't extracting the identifiers and request the json directly be better?
heh heh heh! Here's some fun reading material I found on github: https://github.com/ksimka/go-is-not-good It's a curated list of articles that find fault with Golang. (just for science. I like Golang)
Selenium with the Chrome webdriver in headless mode. Works like magic. PhantomJS maintainer announced already it will no longer be supported since Chrome headless is a way more robust solution. 
&gt; Currently we have two projects which are related to crypto currencies, where we need some support. So you need help setting piles of real money on fire? I'm good at lighting things on fire. DM me for my rates.
Thanks for the insight /u/funny_falcon, will add the details to the blog and update what's missing. Thanks for the read
&gt;&gt;&gt;Imagine a single letter file. In the beginning the scanner position is before the letter &gt;&gt;In that case, wouldn’t there need to be a position before the first letter too? &gt;That's exactly how it is.
Autocert is nice for simple use cases, but doesn't handle advanced use very well. For more advanced ACME use cases like yours, use lego: https://github.com/xenolf/lego - it allows you to wrap the ACME layer with your own challenge providers. But if you can just put a single service in front, and reverse proxy, that would be simpler. For that, you can use [Caddy](https://caddyserver.com) (which uses lego), which can even coordinate ACME certificates in a fleet configuration very easily, so if you do need more than one instance or machine or container or whatever, they can all share the same certificates, and Caddy can reverse-proxy to your backend services. (I'm biased of course, but this is still good advice.)
Businesswise, they have to do this stuff to succeed. If they didn't, I'm sure things would just be terrible for the company. 
RSpec is more than an assertion library. 
In Dockerfile syntax its like this: ENV AWS_ACCESS_KEY_ID &lt;MYKEY&gt; ^ There is no "=" supposed to be there 
`0.0`?
This is actually pretty neat! I'm going to download it this week and play around with it a bit. I just so happen to have a fresh Raspberry pi to test with!
[removed]
Another option that may be applicable where several services have the same machine names is to issue certificates for the names once, but use the same cert (and associated private key) in all these services. This will not be appropriate for situations which prioritise security, as compromise of one service would get the private key that could be leveraged against the other services, but it may be simpler in some scenarios and often if everything shares a machine any security partitioning is pretty flimsy anyway.
I haven't even read it yet but I was interested due to the title. Is it that bad? No experience on that to be able to judge it.
It sounds to me like you shouldn't use a function, but instead define an interface needed to satisfy the behavior of a MessageHandler. This way you can carry whatever state a MessageHandler may need in it's implementation- instead of binding it to a Typed function. I.E. type Handler interface { Handle(Client, Message) } type dbHandler struct { db *sql.DB } func (h *dbHandler) Handle(c Client, m Message) { h.db.Insert(...) } Which you will probably notice is exactly like the http package in the std library, since it's a single method interface you can leverage the same basic Func implementation for simpler adhoc msg handlers. i.e.: type HandlerFunc func(Client, Message) // Same as your MessageHandler func (fn HandlerFunc) Handle(c Client, m Message) { fn(c, m) } While you're still learning what works best for you with Go it's always good to start with structs and a concrete implementation first, then when you need to accept another type find the common behavior and add an interface for it.
Article does use a central server and it seems to be an oversimplification of the entire system though so it might be a bit misleading. I would suggest looking it over if you are interested in learning about PoS and research some points that are not fully fleshed in the tutorial.
Nice! Did you made some tests ? like comparation of resource usage of jackal with jabberd etc. ? :)
Thanks for the great tutorial! Reading through the POW one now :)
This is great. I've been looking for a good PoS tutorial!
When I last tried WSL in VS Code, the arrow keys didn't work yet due to an issue with the CLI API in Windows. Is that fixed?
You committed your cert and key. You probably don't want to publish those.
The documentation and readme don't explain what the benefits of this package would be. From a cursory examination, it doesn't appear to provide much utility beyond what the standard library provides, and would cause applications that use it to look different enough from a "standard" Go app to be harder for a future maintainer than simply using the standard library.
It sure is. I've changed the text to "there is no decimal zero integer literal in Go." Thanks!
Not sure if it was edited later on, but at least now the article very clearly says that it doesn't use a peer to peer networking approach for simplicity. Besides - leaving PoS aside - you are clearly dismissing the fact, that not all blockchains are distributed, or need to be.
blockchain and center server are not conflict at all.
The fact is that jackal enfoces the use of a TLS/SSL connection, and that cert and key is nothing more than a `localhost` domain self signed certificate with no expiration date. The idea is to allow anyone to try the server without having to deal with any cert issues. 
Cool! No I haven't yet! Currenly I'm mainly focused on adding as many capabilities as possible, though I'll consider to do it. ;)
In order to avoid confusions, I've removed the `cert` folder and updated the README.md file explaining how to generate a default self-signed certificate. Also updated the Dockerfile. I hope it's clearer now ;)
In order to avoid confusions, I've removed the cert folder and updated the README.md file explaining how to generate a default self-signed certificate. Also updated the Dockerfile. I hope it's clearer now ;)
Make the message handler a method on a struct containing the handles you need as noted elsewhere, or simply close around it, since Go also supports closures. For example: func CreateStoreCallback(conn *db.Conn) func (Client, Message) { return func(c Client, m Message) { conn.DoSomething(m) } } [...] conn := BlaBla() cb := CreateStoreCallback(conn)
Last month or two I worked on a Golang Restful Starter Kit. Ideas and motivation behind this project are available as a blog-post on my website: [LINK](https://www.ribice.ba/go-restful-starter-kit/). All feedback is welcome. 
Ah this is great. I've been trying to wrap my head around creating one-off, unofficial .debs for a couple of days.
No Postgres support?
If you poke crypto/tls the right way, [you can generate self-signed certs in Go code](https://golang.org/src/crypto/tls/generate_cert.go). I'd wrap it behind something that makes it _very clear_ we're in a non-production mode, but you can get the best of both worlds that way; no dealing with having to create a cert, but also not committing the same one everywhere.
I've been using [goreleaser+nfpm](https://goreleaser.com/#linux_packages) It's not the "right" way to do packages, but a few lines in the yaml file and I can easily generate .debs and .rpms along with plain binary tarballs with one command.
I think it’s safe to say this hot take came about without having taken a moment to read the linked article. I’m a skeptic too. Trust no one, form your own opinions, yadda yadda yadda. However this is a well articulated article presenting opinions about why the author prefers one language over others. The author also takes care to call out that this is just their opinion and include caveats of where Go struggles and has issues compared to other languages. Tough break about the downvotes, I do believe there’s value in being a skeptic and avoiding hype-driven development. Next time be a little more thoughtful in presenting criticism and I’m sure the community will be more open to discussion.
Okay, Ima try shutting up
Bad bot
that sounds great! falling back to self signed cert this way would be much more elegant. Thanks for the notice!
Most (all?) arguments in favor as well as against Go have been presented many times before. To me there is nothing new in the article. This would be fine when the language was young to lure developers into trying it out. These days, if you want to praise Go, start a project and show how it's done. I prefer posts that point to nice examples on GitHub or elsewhere. The author does have a small IRC bot example. But it is not representative of the language strengths. I think, his NAS tools and scan2drive are better for that purpose. 
It looks like you just need to change your expected value to `"websocket mock implementation"`. Here: assert.EqualValues(t, "websocket mock implementation", string(received)) The second argument to assert.EqualValues appears to be the expected value, so you should put what you expect back in there. 
I think the connection that is being made is that you can use t.Run to create a similar structure you might find in rspec with describe, context, etc. Also, the comments mention using t.Run to provide a pre/post. Onpar (https://github.com/apoydence/onpar) is a more full featured implementation using this idea. 
Ok, I can see that. Thanks for sharing that. I think the examples on the readme page of onpar are more like RSpec than what the OP linked to.
an example of this in actual use would be helpful, it sounds like a lot of 3rd-party libraries, some that I would use and a lot I would never use, all lumped together, I'm sure it's better than that but I have to see "it" in action
Looks high-quality and has sane default dependencies.
[0.1.7](https://github.com/ortuman/jackal/releases/tag/0.1.17) release already supports automatic self signed certificate generation. Thanks for the point!
/r/drgryski thank you for posting this. :) If anyone has any questions / feedback, please feel free to put a issue up on my repo. 
Sqlite may be a good option for this since it's very small. BoltDB/bbolt may be good options as well if the data fits.
What advantages are there to your approach vs using https://github.com/ory/dockertest and/or https://github.com/DATA-DOG/go-sqlmock?
Programming languages are created by humans. Therefore, programming languages are all terrible. Which one sucks least at any given moment is *very* situational, depending on the application, the ecosystem, the phase of the moon, and most importantly, who's paying you for the work. Making a statement like "X is my favorite programming language", *in public* and outside of the confines of a bar, displays a lack of good judgment. Besides which, a generalization like that isn't nearly as useful to the readers as "language X worked really well *for this specific project* because blah blah blah". The latter is much less likely to get bogged down in matters of opinion. Opinions, like programming languages, are created by humans and are therefore all terrible.
Who hurt you?
Same, I've been working on this for about 2 weeks. Let me know if you have any questions!
For quick dirty scripting, id prefer BASH or python - but thats why I love Go; its not designed for quick and dirty, but rather pushed productive, clean and elegant code out.
I understand the current state of it. I was just adding other solutions that may be worth considering. For me, I often stray away from solutions that require a full RDBMS especially if it's just for a single access application. It's too much of a strain on system resources and takes my time in hardening, patching, etc... so I prefer solutions with embedded options (i.e. Sqlite). Of course, my situation may be unique to me, but having options certainly doesn't hurt so long as they are abstracted away enough for the maintainer to not put too big of a burden on them.
Without any discouragement intended; The code organization goes against recommended practices. It is suggested that grouping is based upon purpose/types rather than location in the control flow. For example, instead of having a "mw" package with all of the middleware, it would be more appropriate to have a "jwt" package that contains the relevant middleware, endpoints, helper functions, etc. Similarly, for a starter kit, it would be more enlightening for newcomers to avoid the use of a framework and stick to the stdlib.
One thing I was trying to do was have the `rules` file download `dep` and run `dep ensure` prior to the build. I've kinda sorta got it working but it'd be great to see if you have a better way of doing this. I'd also like to download the latest Go and build from that, rather than using the outdated Debian package :-)
Hey thanks for this. I really like the structure and I have been doing something like this for the last couple of projects I have worked on. Only thing I would recommend is using Chi as the mux. It's a simple router and has stdlib compat. I really like the store / service decoupling and I am going to study this more since some of the projects at work are really starting to struggle in this area.
Thanks! Is this only related to splitting mw package or? For the second point, I know that most Gophers prefer using stdlib if possible. However Go's 'frameworks' are not real frameworks (RoR, Spring, Django..), I rather see them as small wrappers around net/http. At work we use net/http with a small wrapper around it (for validation, marshalling and finer handler structure). So I do agree with you, and I get your point, but I don't see Go's frameworks as bloated. 
Shameless plug. I am writing tutorials at golangbot.com please check it out 
Here is a fantastic post that will likely help: https://rakyll.org/style-packages Needs such as marshaling and and validation are certainly important and can easily be met by using appropriate libraries, but, in my opinion, are poor reasons for wrapping net/http. I'd guess that a project which does wrap net/http for such needs is overly object-oriented and likely to go the way of ["lasagna code"](http://wiki.c2.com/?LasagnaCode).
Ah. That's great! I'm unfamiliar with BadgeDB and a quick web search didn't bubble up anything for me, so I wasn't sure what exactly it was.
thanks. nice-comprehensive list to immerse myself in the ecosystem, but to be clear: I'm trying to avoid frameworks and ORMS (for learning). Most (maybe all?) comprehensive projects that I've seen use a framework and/or ORM.
I had my first interaction with semantic import versioning's ability to implement gradual code repair (importing two or more versions of the same package within a single project) this weekend and was pleasantly surprised at how simple - and semantic - it was. At first when the initial `vgo` blog posts came out I was skeptical about having to "hardcode" version numbers into my projects, it felt a bit redundant and messy, having your import paths muddied with both raw import URLs and versioned URLs alike, and then the `go.mod` and `go.modverify` files as well. But when you think about Go's import compatibility rule, it makes sense that different versions of packages would effectively have different import paths. Furthermore, when you're working on a project that imports two versions of the same package, being able to easily see what version(s) are being imported directly within the package you are editing makes your code so much easier to read - you don't need to tab back and forth with a json / yaml / toml configuration file, you simply look at the import path to know exactly what version of the package you are working with. When gradually migrating a codebase from one version to the next, it's not an "all or nothing" endeavor, you can make incremental changes to each piece of your project, all the while importing both versions of the package until your full migration is complete. I'm still running into a few edge cases with larger and more complex projects, and the requirement for a GitHub `~/.netrc` isn't ideal, but it's clear that there was a good about of forethought that went into `vgo` and I'm glad to see the versioning question will finally be addressed by Go core. 
&gt; But when you think about Go's import compatibility rule, it makes sense that different versions of packages would effectively have different import paths. It's frustrating that we're bandying around this thing called "The import compatibility [b]rule[/b]" because it's not a rule. It's not even strong enough to be called a convention, because almost no package abides it. At best, it's a wish, or a hope. And something that no other language ecosystem wishes, hopes for, requires, or enforces. &gt; Furthermore, when you're working on a project that imports two versions of the same package It [i]still[/i] hasn't been demonstrated to me that this is something that actually needs to or should be allowed. Other language ecosystems (notably Node) have even gone the other direction, from allowing it to disallowing it in the general case / by convention.
[removed]
All that's described here is the encapsulation of the database, and the encapsulation of the data model... and there isn't much detail beyond that. It's not said what goes into a mock that sits behind the same interface, nor is it said how these mocks are used. Don't know what we're supposed to get out of this post. Encapsulating one's DB in such a fashion has been standard practice for a long time.
I haven't ran into any issues. I installed it a couple few ago. The only thing that I did run into some issues with was getting debugging working, but that wasn't too difficult to resolve.
I'm under the impression you're talking about moving the bash session's cursor left/right and also navigating the history with up/down. That definitely works for me.
Unfortunately this would need to be mostly a sacred rule for it's benefits to become reapable. It is a direct containment of entropy. However, if the cost is bore, my bet would be that it will set a new bar for how software is managed.
&gt; Allowing multiple versions of a library in a single binary is likely to bite you. FTR, the proposal is to allow exactly that and the justification is gradual code repair. If you want that, it is unavoidable to have two different major versions of the same package in one binary. If the dependency graph is * A -&gt; B, C * B, C -&gt; D and B and C are maintained by different teams in different repositories, then you can't atomically update both B and C to use a new major version of D. And yes, there are cases where this will require great care to prevent hurt. I'm not sure they are avoidable in either case, though.
Yep, as a Linux SysAd, I couldn't do it. lol
Might be a bit biased as I’m the author, but https://github.com/getfider/fider is a web project that doesn’t use any web framework or ORM, it’s mostly built from scratch (except the router) 
thanks! This is an excellent reference. 
[removed]
I also have never heard of it. Perhaps they mean BadgerDB? That is similar to bbolt.
That method was purely made up for the example. But oftentimes I'll have the same conundrum. I'll fight with myself between naming something with brevity or clarity. For me, at least, it's difficult to find a middleground. I typically err on the side of having long, descriptive names, simply because I feel clear intent is more important than readability.
&gt; In other words, it is being suggested that we stop breaking shit, and you're asking for proof that doing so has value. No, please, you prove why we should continue in chaotic practices. Dependencies exist in two axes, space (the dependency identifier) and time (the version of the dependency). These are independent axes. In approximately every other source code management ecosystem, breaking changes are signaled by convention (i.e. semantic version) in the time axis. That is, we do not expect Foo v1.0.0 to be equivalent to Foo v2.0.0. You claim this is "chaotic practice" but that's certainly not true. Software engineers have a native intuition that Foo is a label that transcends specific implementation, and that versions exist to categorize changes. This intuition flows into the tools that we've built (npm, cargo, etc.) to manage motion through these vectorspaces. vgo claims these tools are too complex, and collapses the two-dimensional vectorspace to one: you get only package identifier. But in so doing it creates its own set of complexities, not least of which is the baby-in-the-bathwater of this natural intuition. Large disruptions from the intuitive status quo require correspondingly large and convincing justification: No, please, _you_ prove why this new scheme represents an improvement. The work just hasn't been done. IMO.
I think you're correct.
I understand the rationale. I believe it is a problem. But I believe it's a problem with software development methodology (i.e. unnecessary complexity) and should be fixed at the process layer, rather than conceding that it's intractable (i.e. necessary complexity) and needs to be accommodated with tooling. The latter case has been repeatedly asserted by the core team, but (IMO) never convincingly argued.
Do you know of any writings on exactly that topic by Ken? I'm desperate to hear more wisdom from him :-P. (Well I guess I can dig in the papers archive, but I'd love for more recent reminiscing.)
Grouping graduations at obvious stages dramatically expands the efficacy of communication and is far more intuitive than always requiring the inspection of fine details. "Collapsing dimensions" is commonly practiced in casual communication to great effect. For example, referring to young children as "toddlers" and over 18s as "adults" enables most affected conversations to continue without requiring additional investigation. Hosting a party for toddlers would naturally evoke different planning than one for adults. Likewise, once visitors for either party arrive, closer inspection would serve to provide more careful accommodations to fit existing moods/needs. It does not seem like an improvement to have required the exact ages of each guest at the beginning of planning. What could be contained by a simple reference, is not better served by a complex tool. Though, this is not a question of whether there should be a tool which can navigate metadata, it's a question of whether there should be a mechanism which facilitates progress without that dependency. This proposal is quite defensive of keeping the go toolchain focused, and it's easy to see why. Whether something is a million years away, or a million years ago, the net result is initially the same. Closer inspection should be left for when proximity narrows.
Maybe his interview in "Coders At Work"? He didn't write as much as Pike and the others.
Second example is getting close to the functionality of https://godoc.org/golang.org/x/sync/errgroup
I don't expect that there are advantages (and those two libraries you mentioned are likely more thorough options) - it's just a non-third-party library solution.
&gt; Other language ecosystems (notably Node) have even gone the other direction, from allowing it to disallowing it in the general case / by convention. Can you clarify the meaning of this comment? npm allows the same package but different versions to be installed and used at the same time. 
I've read about this design methodology, basically Domain Driven Design (DDD), however I think a mix of this idea with Service Oriented Architecture (SOA) could possibly be a better approach. Here's a [GitHub repo](https://github.com/marcusolsson/goddd) showing a pretty in depth example of DDD in Go. This seems to me that it can get confusing rather quickly. For instance, using the `user` package example within DDD, this package would contain sub packages to handle routes for a member dashboard, API endpoints, middleware, error handling, so on and so forth. Where this becomes confusing to me is determining the full responsibility of a 'domain' and its relationship to other packages within the project. For example, instead of having a single `dash` package, which handles all aspects of the member dashboard such as the routes, middleware, etc, you would instead have a sub package of `dash` (or `handlers` with `dash` and `api` sub packages) within a `user` package. What if there's other routes or API endpoints or services that merge together a 'user' and some other packages? To me it would be simpler using the ideas from DDD and SOA together. The [link](https://rakyll.org/style-packages/) you posted to below even points out: &gt; Rather than creating a models package and declare all entity types there, a User type should live in a service-layer package. From the example above, if there's a member dashboard, have a `dash` package that handles all aspects of the dashboard. API? Have an `api` package. User data and services are used by both? That can go in the top level `services\user` package. Error handling from the `user` package? It's separated out and specific to both the member dashboard (return HTML output with error status header) and the API (return specific JSON error format with error status header) who each have their sub `error` packages. Where would this central error logic be otherwise? Thinking of solutions just seems to further complicate what is imported and used by everything else, which is the opposite of the end goal imho. This is a good subject though, and the reason I'm so interested in it is because I'm actually writing an article on web application structure atm. Would love to hear your thoughts.
Check back here in a few weeks or visit my blog. I'm currently writing an article on web application structure that goes over these concerns, and it will include an example repo on GitHub.
You're describing vgo's design decisions in the context of, like, aphorisms — "grouping graduations . . . is far more intuitive than always requiring the inspection of fine details" — "keep the go toolchain simple/focused" — but you're not really saying anything. Until now, we had the dimension of Identity (space) to establish a collection of versions; and the dimension of Version (time) to establish specific compatibility. Your "grouped graduations" were implemented by semantic versioning along the time axis: collapse all the versions with the same major version number, and you have a casual way to describe compatibility. vgo lifts this casual compatibility descriptor out of the Version (time) dimension and into the Identity (space) dimension. This action reduces the utility of the former, without apparently reducing its complexity; and increases the complexity of the latter, without apparently increasing its utility. It makes the work of the tooling easier, at the expense of disrupting the intuitive — and, I'm claiming, _correct_ — mental model of what package names and versions ought to mean.
&gt; I think it’s safe to say this hot take came about without having taken a moment to read the linked article. Not at all, I read it. There wasn't much there. &gt; Tough break about the downvotes Fake internet points. I have more than sufficient. &gt; I’m sure the community will be more open to discussion. You're either new to reddit or fantastically stupid.
mining.luxor.tech All Golang from the ground up :)
Linking and storing all of our data into a warehouse. 
About to start month 6 at my "new" job, helping build a CDN / edge compute platform at https://www.walmartlabs.com . Projects include: custom reverse proxies, TLS/HTTP2/WebSockets, load balancing (layer 4 and layer 7), embedded edge plugins (Lua and Go), advanced DNS systems, and security/PCI frameworks... All written in Go and operating at industrial scale. I started right before the holiday rush so things were a bit hectic. Now our division is shifting gears on how / where we run our "mega clouds", which will keep things busy for the next few months as we shuffle things around. Then ramp up load testing for holiday this year and see if we can squeeze in a few more big projects, like replacing a really large, really expensive asset store. Oh, and if these things sound interesting we have a few developer, operations, and internal services/consulting positions opening in the next few weeks. Remote friendly (but usually requires the right to work in USA) and an awesome team. Hit me up for details!
A dot to channels converter. You describe the structure as a dot file. The names of the nodes correspond to types that process compatible channels. It's an experiment in reusing existing code by just rearranging it.
Yup, it is pretty rude of you. Here's a guide for your next "help" thread: http://www.catb.org/esr/faqs/smart-questions.html &gt; i ended up having to sift through the source code of testify to figure out what the problem is. I "end up" doing that as my first line of research. Before I even think to engage another, let alone an entire community.
I'm one of the authors behind [Nakama](https://heroiclabs.com) - It's an open-source server for realtime and social games. It has built-in support for realtime multiplayer, rule-based matchmaking, and a lot more (user auth, social login, leaderboards etc). I think it's a great start point to develop your multiplayer game with :)
If you are looking for complex go networking projects that you can learn from, checkout [Nakama](HTTPS://GitHub.com/heroiclabs/Nakama). It has a web server, a websocket upgrade process, an embedded dashboard, authentication, database interactions, session management and a hell of a lot more. 
Recently mostly on https://github.com/cznic/sqlite2go.
Textual data analysis for a research project.
I think that concept backing vgo is that space and time are not continuous but segmented. After some time a v2.0.0 comes along and it creates a new identity, a new space. The two packages (v1 and v2) are now incompatible, why would they share the same space have the same identity? The fact that they share most of the code is not an excuse, so do forks with entirely different names/import paths.
Adding features, reducing code in the [gorgonia](https://github.com/gorgonia/gorgonia) family of packages. The key things I'm working on are performance and accessibility - the packages needs to improve in terms of user friendliness, so a few APIs will be broken
Ooh, sounds fun. If you need NLP stuff, I wrote a [NLP library](https://github.com/chewxy/lingo). AMA if you need help
Just started working on https://github.com/radicalrafi/lori I was inspired by Lodash and Ramda although the lack of generics makes it a bit hard to work on it, I'm thinking providing type consistent functions is suitable for Golang style would love your feedback people. 
I think this talk from Rich Hickey is relevant https://www.youtube.com/watch?v=oyLBGkS5ICk Side-note: It's also interesting to note that Clojure core.async library is heavily inspired by Go's concurrency model.
That's how ssh works :) You execute a command remotely and can write to its stdin and read from its stdout/stderr. You can reuse a channel by making the one command act as an agent to do things for you. Three simple ways to achieve that: * Execute a shell and pipe in commands into stdin * Copy over a binary and execute that. After that, you can communicate with it over the ssh channel and use RPCs to execute things * Also, you can pass state to programs executing remotely on stdin, so you don't have to write things into remote files, even if you use multiple sessions.
I thought I read somewhere that Walmart uses Openstack for a lot of their internal infrastructure, is this true? If so, it would be massively vindicating. I've had to defend Openstack from a lot of VMware-inclined colleagues who think it sucks and should never be used at the enterprise level. 
Really like the design of the website .
As /u/TheMerovious says, SSH spawns a single command per session. When you use SSH from the CLI, this is usually a shell, with a pty that accepts input over stdin, and outputs to stdout/stderr. You can produce the same behaviour using `x/crypto/ssh` by using `ssh.Session.Start()` to spawn your process, then sending/receiving data via `ssh.Session.Stdinpipe()`/`ssh.Session.Stdoutpipe()`/`ssh.Session.Stderrpipe()`, the same as you would for a local process via `exec.Cmd`.
Looking forward to it!
I'm attempting to write a Web-based Postgres client in Go and React: https://github.com/velvetreactor/postapocalypse
I thought their external facing mobile-store ran on Triton, with internal customers on OpenStack. 
Just found this project which seems pretty cool: https://github.com/Zeta36/chess-alpha-zero
I'm not a huge fan of the example in the documentation, it looks for most intents and purposes to always return nil, but doesn't: https://grace.oxequa.com/1.0/overview/getting-started While it's entirely personal, I'd want to return e to make it clearer that it's not necessarily returning a nil.
This isn't directly related to what you're asking, but have you looked into Ansible at all? It's typically used for configuration management. It may be overkill for what you need, and it does require Python on the guest machine, but I figured I'd throw it out there. It might save you some time.
Yeah I'm familiar with ansible and Python and can do this same thing with them but was hoping to learn Go and thought this would be a bit more straight forward. Thanks for the response! 
Thanks for the responses. I think I understand the concept better now however the implementation seems more complicated than I'm currently able to pull off. It looks like I'd need to write to the stdin then wait for a response (handle any unexpected responses) and then send in more commands. For now I'll just stick to writing things to files that I'll need for the following sessions as that seems like a far simpler solution. The fact that I can't really find a good example online for doing this makes me wonder if Python might have been a better choice. 
Yeah, I think it should be a bare return. That would make the intent more clear.
I'm working on an Alexa skill for interacting with Destiny character/game data via the bungie.net API. https://github.com/rking788/warmind-network
Full time on microservice related tools https://github.com/micro
Thanks! I will try this.
Hi, you can use my package https://github.com/talut/ppk also if you send me an message from iletisim@taluttasgiran.com.tr I can send you an email of my posts (because a time ago I closed my blog)
Awesome work man! I read the whole readme and your library is really impressive :)
Noob here but what is ./...? Is this specific to golang?
Thanks for the link! I'll have a look at it.
I have an educational stream teaching Golang and programming via small game based projects. We have covered topics from the basics, like linked lists and control flow, all the way to faily advanced - like binary heaps and creating an interpreter. Currently we are working on a 2d RPG: https://gameswithgo.org/
Working on adding more units to my modular synth project: https://github.com/brettbuddin/shaden
Thanks that means a lot! Yeah I did it as a side project because I was tired of writing rushed code at work and wanted to have some code I wouldn't be embarrassed of lol. 
Have any examples of how this works? Sounds interesting.
This is our biggest release ever. We finally have **debugger** support! Checkotu the demo here for an example: https://twitter.com/fatih/status/978652722835656704 Thanks for Martin and Billie working on vim-go, Mattn for the debugger support and all other contributors. Much appreciated! Checkout the changelog for all changes and improvements: https://github.com/fatih/vim-go/blob/master/CHANGELOG.md#117---march-27-2018 As always thanks for using Vim and let us know if there any issues or you want to give a feedback :)
What does it actually _do_? The docs are pretty sparse, yet somehow already have ads on them.
[removed]
I like to manually include scanned classes: &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jetty.version}&lt;/version&gt; &lt;configuration&gt; &lt;webAppConfig&gt; &lt;webInfIncludeJarPattern&gt; .*/javax\.[^/]*.jar$|.*/jsf-[^/]*.jar$|.*/primefaces[^/]*\.jar$|.*/atlas-theme-[^/]*\.jar$|.*/rewrite[^/]*.jar$|.*/classes/.* &lt;/webInfIncludeJarPattern&gt; &lt;/webAppConfig&gt; &lt;/configuration&gt; &lt;/plugin&gt;
I think that choosing a language where you have to discover better solutions yourself was an excellent way to go. You're going to be better off for it. You'll remember your solution better as it's your own.
Wow this is awesome! Thanks for the work on this. Keep it up :)
Options for how to communicate depend entirely on what sort of process you plan to run on the other side. If you're running a Go application, you can use something like `net/rpc` to make RPC calls over stdin/stdout, and receive responses as native objects. If you're using a shell script, you can pass data in as env vars via `session.SetEnv()`, however reading data from a shell script will certainly require you to parse the output - same as you would any other script, from the CLI, on your local machine, or whatever. This is just how these things work. Your difficult does not appear to be with Go, so choosing a different language would make absolutely no difference - rather it appears you're having trouble grokking SSH/shell semantics.
Thanks again for the work :) Amazing stuff as always
Gotcha! I saw "base64" and "password" and my security senses were tingling.
Great example. Just another example, which is likely to be recognized, is the **AWS SDK for Go**, [which was actually adopted from Stripe originally](https://aws.amazon.com/blogs/aws/coming-soon-aws-sdk-for-go/). Its v1 has been API "stable" for a while now ([Nov 2015](https://aws.amazon.com/blogs/aws/now-available-version-1-0-of-the-aws-sdk-for-go/)): https://github.com/aws/aws-sdk-go ... buttttt they wanted to change the API and couldn't just kill support or API stability for v1 without doing a lot of damage to apps that use the SDK, sooooo they made a whole new repo just for the new version: https://github.com/aws/aws-sdk-go-v2 In fact, in their blog post they mentioned the necessity to support both and how it was useful to be **able to use both version in parallel**: &gt; You can safely use the AWS SDK for Go 2.0 in parallel with the 1.x SDK, with both SDKs coexisting in the same Go application. We won’t drop support for the 1.0 SDK any time soon. We know there are a lot of customers depending on the 1.x SDK, and we will continue to support them. As we get closer to general availability for 2.0, we’ll share a more detailed plan about how we’ll support the 1.x SDK. (https://aws.amazon.com/blogs/developer/aws-sdk-for-go-2-0-developer-preview/)
So from what I can tell from the rules file, you would need to play around with the override_dh_auto_build target. So I would inject commands before dh_auto_build (Line 50) first. dh_auto_build is where all the magic happens. Hope that helps!
A program to replace a locksmith services windows xp or older client. Looking at redoing a lock data base our company uses internally I wrote about 6 years back in PHP Also an inventory tracker my co-workers can't mess up . Maybe later something video game related. I've only taken up programming again recently and having forgot most of what I knew from 5 years ago (which wasn't much, I'll be honest) decided go would be an interesting foray back in.
This came out of the realisation that almost all data processing pipelines are directed acyclic graphs. The only things that change are the nodes and the types of data that flow on the edges. The nodes usually represent data transformation of some sort, which would end up being a Go type. So if the source nodes are readers, the sink nodes are writers and the the ones in between are both, it should be possible to create different data processing pipelines just by changing the structure, provided there is a good collection of readers and writers to choose from. Since the only real variable is the structure of the pipeline, I describe the structure with a dot file. I've limited this to directed acylic graphs for now to keep things simple. From my brief experimentation, it should be possible to include cycles, but that implies buffered channels.
Saved for a later maybe
Didn't know about this project until I saw this post. Really cool to see a web server written entirely in Go.
I once made a toy Go package that defined the game of tic-tac-toe (https://github.com/shurcooL/tictactoe). This is reminds me of that, except a whole lot more sophisticated!
I'm constantly trying to improve my twitch IRC library https://github.com/gempir/go-twitch-irc I'm very interested in writing the highest quality code possible and testing all of the functionality extensively 
Worked on a tutorial for packaging Go apps using Debian packages (https://github.com/junland/hello-deb) so that I can package my apps such as a Auto Proxy Config Server (https://github.com/junland/pak-mule) for integrating with Squid. I also have some other smaller apps that I want to make down the line written in Go so being able to package these apps is great so I can test them on my Raspberry Pi's that I have deployed on my home network. Also thinking about doing a packaging tutorial for RPM's too.
Thanks. This is the first step in a larger experiment, which is nothing but a dream right now. The idea is then to take something like what I'm working on and design a protocol on top of it where readers and writers are only connected if they both pass certain tests. So think of a situation where more than one readwriter could do the job. You would use the protocol to select the best candidate. I'm calling it test driven graphs right now, but it needs step one to work.
At work i do lots of interesting projects involving multi petabyte storage clusters. As a side project i just started a terminal stock tracking app [screenshot](http://s.chiparus.org/2/2fd0c73576151348.png)
There is also [Traefik](https://github.com/containous/traefik/), which is more focused on micro-services.
Yes, I agree that this is the idea. It's even reasonably coherent. It's just not how most software builders build software. Should our tools adapt to how we work, or should we adapt how we work to our tools? Obviously the answer is "somewhere in the middle" but vgo falls clearly to the wrong side of that subjective line, on this issue, for me.
These types of packages are exceptions, not rules. It seems to me that what AWS did is entirely correct: if you want to make substantial breaking changes to a large package used by many importers, and you can't provide adapters for a gradual upgrade for whatever reason, then go ahead and create a new identifier — in this case, a new repo. It works well for both producers and consumers. It doesn't seem correct to lift this exceptional case into the tooling as the standard workflow.
nice thank you
Is it just me, or are the docs still empty?
Running apk update with installing and removing cached packages as separate **RUN** instructions makes no sense and that last instruction, "**RUN** rm-rf /var/cache/apk/*", actually won't make the image smaller, because once the data is in the image you can't remove it, since you only add layers. You have to do it in the single RUN instruction. Read more here: https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#run
What is the purpose of this line? tt := tt
Awesome sauce! Thanks kindly for all your work.
https://github.com/flowup/owl I am using this tool with a combination of docker is great option
my side-project is building a meetup.com clone from scratch in an all go backend (polymer front-end)
I have my own chess library, too: https://bitbucket.org/zurichess/zurichess The library powers zurichess engine which is ~2890 on CCRL 404.
Thanks!
The tests are run in parallel in their own goroutines. This prevents the data race where the value of `tt` is different by the time the test runs (since `tt` changes on every iteration of the loop). Same thing as https://play.golang.org/p/6mY3k_jhLe3 
There’s a nice collection of exercises for a lot of languages on Exercism. http://exercism.io/languages/go/about For more pure math there’s Project Euler. https://projecteuler.net I like to try to do at least Set #1 of the Cryptopals challenge when I learn a new language. https://cryptopals.com 
I've been doing the exercism ones (about 80 so far). There is no hand holding but I do like the way they've set up their system. Very convenient if you're used to working in the terminal.
[removed]
AUR package is updated to 1.17
Awesome work !👏👏👏
An language-agnostic advice: I feel like I never truly learn anything code-wise until I get my hands dirty on some project. So my advice is just build a project that you always wanted to do but you never quite put the time on it. It doesn't need to even be remotely "novel", *just do it*! Maybe check a repo or project that you enjoyed it and try to reimplement it your own way. Google your way through problems and internals whilst building your app and you will find yourself reading blog posts / articles regarding a problem, and then a framework or an architectural style; etc. A nice exercise specifically for Go is to implement something-you-want-as-a-REST-API! You will learn a lot about Go, web services, APIs and other cool stuff along the way.
Yeah, but the difference is that tt isn't being mutated, it's being rebound every iteration already in the same scope by the range operator.
 wg.Add(5) for j := 0; j &lt; 5; j++ { go func(j int) { log.Print("j: ", j) wg.Done() }(j) } wg.Wait() j is being mutated. It doesn't matter, though - I was wrong. Range is weird and the `tt := tt` line is very necessary.
This is really good advice. The one and only thing I've written in Go is an IRC bot server REST API. Every time I had a new challenge, I had a REASON to learn a new technique. It's probably garbage, but it was an excellent start for me.
Oh I see what you mean. `range` reassigns to the same variable exactly like how `j++` is really just syntactic sugar for temp := j + 1 j = temp 
12pm PDT happens when this comment is 13 hours and 42 minutes old. You can find the live countdown here: https://countle.com/u166493jqy --- I'm a bot, if you want to send feedback, please comment below or send a PM.
That's looking really cool! Have you gotten any use for it yet? And how is that ui created?
High dope factor on this! Will give this a try :) 
Thanks for this! I used it for the client side match play feature for evaluation matches for http://www.lczero.org, which funnily enough is an alpha zero like experiment using go and c++ :).
Coincedentally I am writing something about this right now (WIP) https://github.com/quii/learn-go-with-tests/blob/master/pointers/readme.md#write-enough-code-to-make-it-pass-2 &gt; Other times, I've seen people create their own custom types for errors with methods on them, the Error() method making it fit the interface -- but then reflecting to figure out what type the error is is still a clunky, messy-feeling multi-step operation. AFAIK, if you want a way of attaching your own info you'll have to make your own type (that implements `error`). There's literally no other way to pass information around. re the type assertion. It looks like you have multiple ways that it can fail and you want the caller of your code to have to handle it. That's great! Sounds like robust software. But there's very little syntactic sugar in Go, the language values explicitness in these scenarios. I can imagine a `switch` on people calling your function, checking the type of the error and then acting accordingly. It isn't clever or elegant, but it is very clear. But that removes some convienience for developers who aren't going to handle your error other than log it. 
is there video up for this?
I didn't know anyone used it super cool! Interesting project I will definitely check it out.
Thank you and all the contributors!
Haven’t tried this, but something like type RecoverableError interface{ Error() sting Recover() } type Error1 struct{ error X context.Context // just some attached data } type Error2 struct{ error Y context.Context // just some attached data } func (err1 Error1) Recover() { // use data in err1 to handle itself } func (err2 Error2) Recover() { // } You get .Error() for free Easy to wrap errors and attach some context to it When handling you’ll have to type switch or reflect 
Generally, reflecting on types in Go is not scorned upon so much as in some other languages. In fact, there are cases when it is seen as *idiomatic code!* In particular, in this case, I'd totally go with creating a custom type — probably something like: type ErrNeedMoreSpace struct { Bytes int64 } func (e ErrNeedMoreSpace) Error() string { return fmt.Sprintf("not enough space (need %vb more)", e.Bytes) } See also: - [os.IsNotExist()](https://golang.org/pkg/os/#IsNotExist) - [os/error.go](https://golang.org/src/os/error.go) - [os/error_unix.go](https://golang.org/src/os/error_unix.go)
Thank you. I just use it to get a quick market overview and to track my own stocks. It was inspired a bit by [mop](https://github.com/Dirionz/mop) for the UI i use [termui](https://github.com/gizak/termui).
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/Dirionz/mop) - Previous text "mop" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
Thanks man for your advice, actually I’ll need to implement a rest api at work ^^
Is it a crime hahhhh ?
Frankly, it would be better if these functions paniced instead of returning errors. The errors that it returns are mostly things that are under control of the programmer, and they'd be compile errors in another language. Returning errors prevents you from writing more fluent code in certain ways, like the ability to use them in ranged-for loops. Additionally, passing nil data to the array and collection functions should return a sensible defualt value (e.g. gubrak.Filter should return nil) instead of returning an error.
Copy what you want out of the build image into production image, even better
I think these videos explain a lot. https://youtu.be/hDC7IF3OQLM https://youtu.be/1B71SL6Y0kA
Got it, thanks Gooopher ;)
He is already copying only executable from the build image.
http://exercism.io/
&gt; Other times, I've seen people create their own custom types for errors with methods on them, the Error() method making it fit the interface -- but then reflecting to figure out what type the error is is still a clunky, messy-feeling multi-step operation. Not sure, why you would call it a messy-feeling operation. It is perfectly fine to do in Go. And exactly what is recommended- https://golang.org/doc/effective_go.html#errors. We call it a [type switch](https://golang.org/doc/effective_go.html#type_switch). So, in your case, it will be - err := writeFileToDisk(webcam.imageCapture) if err != nil { switch err := err.(type) { case *ErrNeededMoreSpace: // take action case *ErrDiskWriteLocked: // take action default: // generic error } } See here for something similar - https://golang.org/src/os/error.go?s=2154:2185#L94
Thanks for all your hard work! Any idea if/when neovim support is coming for debugging?
I might be wrong on this, but maybe the other tools are following a workflow from before semantic versioning gave a clear meaning to a major version bump. In this world the difference from V3 to v4 is just added functionality not a braking change, and the tools reflect this by keeping the packages in the same space/identity. And when a breaking change happens it might not even be in a major version bump. This blurred the lines. With vgo we can experiment a different approach with more stark lines, it took a while but I for one would like to see how it pans out.
I might be wrong on this, but maybe the other tools are following a workflow from before semantic versioning gave a clear meaning to a major version bump. In this world the difference from V3 to v4 is just added functionality not a braking change, and the tools reflect this by keeping the packages in the same space/identity. And when a breaking change happens it might not even be in a major version bump. This blurred the lines. With vgo we can experiment a different approach with more stark lines, it took a while but I for one would like to see how it pans out.
Not specific to Go, but https://adventofcode.com
thanks !!!!
Why not though? Genuinely curious for the opposing side. I find Russ' arguments persuasive but "not seeming correct" doesn't really do a ton to explain what would be so bad about his proposed path forward.
[removed]
Looks great so far. Any plans on supporting UCI? Also a benchmark doing [perft](https://chessprogramming.wikispaces.com/Perft?responseToken=0f31e88faaaee46c422360b6ea2775147) would be really nice. Shameless plug but I'm also writing a chess engine in go: [chesskimo](https://github.com/dbriemann/chesskimo). The current state is: working move generator, UCI in early state and a simple monte carlo search. It can play almost random games via UCI these days. No readme so far :) Good luck with the alpha zero approach.. however I believe you will need a supercomputer to have fun with it =)
Try gin-gonic for that.
Probably not any time soon (think months, not weeks). A good first step would be to use/make a unified jobs interface, instead of `if has('neovim') [..]` switches. I know there are some libraries out there, but never really looked in to any of them. There is actually an issue for that: https://github.com/fatih/vim-go/issues/1704
MessagePack is just the communication protocol for the job interface. I assume the actual data you pass to the jobs you start can be anything, otherwise it would be pretty useless as an interface.
I'm just practicing with building a link saving site. Of course go restful crud app and jQuery consuming. Only problem is I have js and it takes up all my time because of the million of these }); } } }); }); And database relationships are getting complicated. Cause you have meta tag, link, and user. Searching link by meta tag is easy but then per userid is harder and then sharing and global and optimizing so you don't have to dig the whole database ect. But it's a great learning project that isn't too complicated. 
&gt; gin-gonic it's a framework ? 
Try the vim-delve plugin - works with both Vim and Neovim https://github.com/sebdah/vim-delve
Impressive!
Have your upvote and GTFO. Was an emacs user for years and then switched to Vim because I have no need for butterfly-Mode
Nice! Should've called it "goup" tho haha eww 
Good read, but the font size is too big and the actual font is not pleasant.
Once you get into board eval, the supporting API (board, notation) changes quite a lot. It's really really difficult to maintain a small API surface when you need the last bit of performance.
Goulash
how about "goop" (as in 'a viscous liquid')? =p
The design doc was interesting. I had no idea wasm doesn't have jumps
“Graper”
Nice. I was wondering why no one used net/html to create something like this before.
Better than Todd's course? (Other redditors talking about it above)
[removed]
eh, close enough
`gunit`'s [example code](https://github.com/smartystreets/gunit) using `this` as a receiver name is a smell that the author or authors of GoConvey continue to swim upstream against the most basic stylistic conventions of Go laid out in "effective go" and in the standard library.
Despite the disadvantages the article mentions about the standard library testing example, I find it much more readable than the 2 versions that were written with goconvey and gunit.
oh baby
Agree with this completely. If there is an easier at this level you have other serious issues.
I know people you are going to make happy, I considered writing one at my previous job but ended-up just extending harlow's to support the shard iterators I needed.
cute docker wrapper! i made one for virtual machines for cross-kernel work, though of course it’s much slower github.com/mcandre/tonixxx
So needy https://play.golang.org/p/IIC7MtAJOGk
I'm going to take a wild guess and say that has something to do with their suggestion to use a GoLand template to build a fixture, so just making every snippet use `this` as the receiver is easier than coming up with a descriptive name...
Clicked the post just to see. I agree. They should just use [Overpass](http://overpassfont.org/) if they can't bother to use comic sans!
It would be so great if llvm ir was a Go compiler target. The approach used by https://github.com/llvm-mirror/llgo was pretty good also (SSA to LLVM IR).
What’s wrong with comic sans?
Not to nitpick, but if you're using Apache 2.0, your stuff is also Free (as in speech). That's a bigger deal than just "open-source". Good on you and your org!
pretty awesome project. I've built a web scraper system just using goquery and that's super efficient but can be kinda difficult to use if you're not sure how to follow all the reclusiveness. nice work. 
Source code which is not free as in speech is called [shared source](https://en.wikipedia.org/wiki/Shared_source).
There is colly. But colly relies on goQuery as well and is a bit higher level.
Meh, I like convey because it allowed me to nest tests and fixtures. Absolutely do not see the point of gunit over the regular test framework here. I can write these helper functions myself, there is no added value. I know the Go community hates anything that doesn't "stick with the std lib", but it takes 1 minutes to learn Goconvey API, so it's more of a case of intellectual lazyness for whoever who complains about it. Sometimes i feel like a bunch of gatekeeper developers are actively making sure go ecosystem stays barebone and hostile to new ideas. This is definitely something that sucks with the Go community.
The std lib example seldom use pre conditions for tests. Leaving out an easy way to do easily set before/after preconditions FOR EACH fixture in isolation was a pretty big oversight from whoever wrote go test runner. I'm really curious to read the source code of a large web you wrote by yourself,including the tests, and judge he quality of your code.
Holy hell, yes.
I'd really like to see a solid Beautiful Soup port into Go. I've been porting python code over to go and for the most part it has been smooth. The tricky spots have been with parsing markup in Go. Here's the library we're working with now for parsing: https://github.com/anaskhan96/soup I should probably contribute to it, now that I think about it ... Anywho, I think another good question would be: "What are some open source projects in the Go community that need some TLC?"
I did not. As it turns out, my time as a Go developer was short-lived :) 
Thanks /u/icholy this example was really helpful in understanding this. I tried this following /u/pdffs suggestion and I was missing hooking the stdout in so I couldn't see the results of the commands and I was doing the writing of the commands wrong. 
[removed]
I would love to have a good layout engine. Kind of like html or Like the flexbox model in css. I would love to edit a yaml file that would generate the model. Then based on the content of the cells it would calculate the size of everything. I often play with little screens on raspberry pis and it would save me a ton of time when outputting layouts.
Like this one on top of the subreddit right now: https://github.com/anaskhan96/soup
One alternative is solving the problem on the infrastructure. Using tunnels, VPNs or encrypted file systems.
Looks pretty cool. I've never ran into a case where logging was a performance bottleneck though. I don't usually include a lot of trace logging though.
Like this one https://godoc.org/golang.org/x/exp/shiny/widget/flex ?
Is there a good library for working with unstructured xml?
I've seen that before but hadn't used it. Any idea how it compares to Beautiful Soup?
Yeah
Well. Long time since I used Python, but as I remember it, easier. It is just like working with JQuery, just in go. A ton of selectors, you can give it a response directly. It seems to do everything related to scraping HTML pages. You need to implement paging yourself, and since many pages renders through JSON responses from some API, you often might as well hook into that directly, but for scraping markup, go-query does what it needs to very well.
I do a lot of work with XML, NITF and other weird-ass news wire formats. We've been able to get most stuff with [Soup](https://github.com/anaskhan96/soup) but it is still awkward to do a lot of things. I feel your pain. I'll be taking a look at [goquery](https://github.com/PuerkitoBio/goquery) which /u/Phr0ztByte suggested and see how that works out.
&gt; weird ass-news wire formats *** ^(Bleep-bloop, I'm a bot. This comment was inspired by )^[xkcd#37](https://xkcd.com/37)
That sounds pretty reasonable. Thanks for the info. I'll give that a try and see how it works out.
&gt; Sometimes i feel like a bunch of gatekeeper developers are actively making sure go ecosystem stays barebone and hostile to new ideas. This is definitely something that sucks with the Go community. What is the other end of the extreme though? Probably something similar to the Java ecosystem, full of different solutions but also bureaucratic and full of bloat. We've seen that and we've been there already. I think that's a good reason the Go community is skeptical when encounters such solutions. No end of the extreme is good. Ideally we should strive to be somewhere in the middle. But we naturally gravitate towards one end because of convenience and companies wanting to attract. Thus, I think our natural stance should be caution.
Job scheduler. I use node-cron for the node projects but can’t find anything for go. 
A Go version of JDBC. One big problem I had with it is getting it to connect seamlessly to multiple databases, especially commercial ones.
https://godoc.org/github.com/robfig/cron this is not enough?
I have had issues with teradata and oracle. Commercial databases don't have that level of support in Go yet.
Alright but then it sounds to me like the problem lies with the specific driver you are using and not `database/sql` because the latter allows to seamlessly connect to different relational databases. I believe what you are essentially asking for is for the Go database drivers to reach the level of maturity of the Java database drivers.
Exactly. The drivers just arent there yet. Of course writing a small jig in Java to take command line arguments for a db, and then call it from Go isn't too hard. 
On top of that, I wrote a wrapper on goquery so you can just write struct tags with goquery selectors and have it unmarshal into your struct. It makes turning the markup into structured data a little more declarative, which is nice. https://github.com/andrewstuart/goq
Not a good library by far, but I tried creating a package once: https://github.com/krpors/dom. It's basically an attempt to a DOM level 3 implementation. There are plenty of other (attempts) packages to be found for Go which implements DOM lvl 3 although I haven tried them exhaustively. I ran into 'problems' regarding `null`: DOM3 specifies that certain things can return `null` to indicate nothing is present (for example, a returned `Node` could be `null`). However, Go does not support nulls like that.
As a potential user of this for script-like purposes, I appreciate having the retrieving parts be built-in.
Yes. * [Gin-Gonic project page.](https://gin-gonic.github.io/gin/) * [Build RESTful API service in golang using gin-gonic framework.](https://medium.com/@thedevsaddam/build-restful-api-service-in-golang-using-gin-gonic-framework-85b1a6e176f3)
Thanks !!!! I visited the page yesterday but when I saw Gin Martini I close it hahhh
A good twitter API client - I've used 3 or 4 and they all had missing features, not the best code, lacking tests, etc.
a decent and easy GUI. go is perfect to in-house small programs that are easy to distribute. I wish I could bundle a small program with a simple gui in one exe
Org here. We will post it here when it is ready.
Nice. I think this is the first open implementation I've seen that does the full algorithm, including rebalancing on removal.
C compiler so that packages using cgo would be easier to install
wxGo is pretty good for this I’d argue. I’ve looked around a lot for GUI’s and it’s what I settled on.
Gorm is great, but it oversimplifies database access. It works well, but only in simple scenarios.
A pure go implementation of python plumbum. https://plumbum.readthedocs.io/en/latest/ I'm migrating all my shellscripts to python, and I wish I could go directly to golang.
Does exist any package that compare images and tells that are the same, similar or different? 
Torrent files manipulation like lib torrent in python
Lots of people have used https://github.com/clbanning/mxj
Gonna take a look at that!
I hope once WASM comes we can get something similar to [Yew](https://github.com/DenisKolodin/yew).
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/DenisKolodin/yew) - Previous text "Yew" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
A pyspark(Apache Spark) equivalent in go would be pretty great
I've been struggling with this one for a while too. I don't want DB-first, which I think there are a few good packages for. I want model-first, and I want good relationship handling without dumb query mechanics behind it. Django's .select_related() with proper model filling, and metaclass-like model definitions made prototyping work so much more pleasant.
and prefetch, and subqueries, and default ordering, and passing queries around not knowing if/where they will be used, and a lot of maturity (just seconds ago I needed to order query results randomly), so I think we are still waiting
Another useful consistent hashing implementation in Golang: https://github.com/buraksezer/consistent It also achieves both uniformity and consistency.
Checkout ponzu. Only issue is the api is not rest
We are sorry, there was an error in the docs, now it is online.
Something like this? https://github.com/corona10/goimagehash
That license would be quite the deterrent
I use ```github.com/bamzi/jobrunner``` for this. It's not exactly a robust cron table, but it fit my needs.
What's wrong with golang.org/x/image/font?
It is abandoned no? I tried it but it is really a tedious task.
Nothing a side project could provide.
When it's ok for the UI to be bland, andlabs/ui is small, easy, and performant. I've used it with success and the executable only ends up being 9mb or so.
A file-backed key/value store that supported encryption (including metadata)
- spacy.io NLP in go - tensorflow in go - electron in go - react-native + expo mobile wrapper in go
I'd really like to see something like Dart's Flutter on top of `golang.org/x/exp/shiny`
PREACH!
Check out the gollvm project: https://go.googlesource.com/gollvm/
Same with Xorm. It has a set of relational operations that turn into rather lame batch-of-N queries. The design choices around it are all awkward for anything but single table fetch/save scenarios.
I like minimal. Like the language.
A Go based UI toolkit which could also run on iOS and Android. . . imagine that.
[removed]
Lack of documentation and the fact that x/image/font includes the &gt;type Drawer struct { &gt; // Dst is the destination image. &gt; Dst draw.Image &gt;... &gt;} which has dependency on draw.Image which depends on image.Image which are useless in the context of PDF report generation.. But it's mostly the "undocumentedness" of the package x/image/font and x/image/font/sfnt and x/image/font/opentype that gave me hard time..
Why should the standard library provide this feature?
A proper XML package with all DOM levels that supports Xquery, XSLT and all that shit in pure Go.
Something as featureful as Eloquent. I’m meh on the rest of Laravel but IMO Eloquent is amazing. 
There is a native .net Oracle driver someone could use as a reference for a version.
Man, I haven’t seen a mention of NITF in a while. I left the news industry in ‘10.
Oh god yes please Flutter for Go
A well-maintained ICMP ping package. tatsushid/go-fastping is most recommended, but seems abandoned.
I personally use https://github.com/zserge/webview
My attempt at a simplified summary of this (as I needed to write one for the Go newsletter :-D).. Go's runtime allows co-operative context switches to occur (e.g. execution switching between goroutines) during the initial stages of running a function, but there are edge cases where this can cause latency issues. This proposal suggests an approach that would allow non-cooperative context switches to safely occur at any point. Corrections welcomed!
interesting, is the current situation one of the reason Go debugging experience is so poor? Delve debugger is constantly crashing for me, making step debugging extremely hard, especially when debugging tests. If there is one thing that is inferior to Java and C# with Go it's definitely the debugging experience. 
I'm a big fan of the mono repo. You can separate things with folder structures, and by sprinkling in some internal folders, even enforce better separation of concerns than a repo would provide. Here's a good discussion of the topic from Digital Ocean: https://blog.digitalocean.com/cthulhu-organizing-go-code-in-a-scalable-repo/
Another pub-sub platform. Could someone please tldr why this would make a difference in a world with 50 others 
https://github.com/anacrolix/torrent/blob/master/cmd/torrent-create/main.go
If you find one I would be interested, otherwise this is a library that I plan on writing. 
It's the agpl
* [lingo](https://github.com/chewxy/lingo) - has SOTA (circa 2015/6) transition based dependency parser, spacy style PoS tagger, NER (almost SOTA I think), and a bunch of utility libraries * [gorgonia](https://github.com/gorgonia/gorgonia) is really like TensorFlow + PyTorch. It created long before tensorflow but lack Google's ability to pump resources into it * No solution * No solution * No solution nb: I'm the author for both
It's down to muscle memory at this point :)
It’s not, unless it solves a problem you have in a way that’s better than the others. There a tens of thousands of extinct programs and solutions that did what we take for granted from our systems today. I argue that they were not only necessary, but shaped the competitive field and helped shape the superior tools that won out. Supporting an open ecosystem where the best ideas win out and the best tools for the job rise to the top regardless of where it came from is extremely powerful. Don’t knock things because you don’t need them; it’s not about you.
Hey hey, calm down. I asked, or rather nicely requested for a tldr about why this was different. I need these tools and have recently spent a while analyzing multiple competitive tools. Hence asked for a summary. 
Thanks!
We can probably make the theme more similar to godoc (https://golang.org/pkg/). But I wouldn't want any more gopher mascots cluttering the header. 
What was the example before? I don't like the bare return in the current example.
I actually think, in general, _small_ teams use multiple repos, and as you get bigger you start preferring the monorepo style. Google, Microsoft, Facebook, they're all on monorepos. The main reason I would argue against a monorepo is ease of setting up a deployment pipeline. With a "one deployment &lt;- one artifact &lt;- one CI trigger &lt;- one repo" structure, it all just works. Once you turn "one repo" into "multiple artifacts", you need to answer questions like "how can the CI know when to just build artifact X versus all of the artifacts in the repo". Which means more tooling to detect where the file changes happened. Its not impossible, but its harder, and small teams don't need "harder". Another one is that, especially with Go, its _too_ easy to not follow best practices when importing code from elsewhere in the monorepo. Large teams often have a bunch of testing and great human reviewers. Small teams don't. So there's less stopping someone from throwing a new module in `repo/internal/left-pad`, importing that from somewhere random, not following good versioning rules, essentially just not following the process. Nothing replaces enforced processes, but separate repos add natural barriers. Its easier to catch a new `left-pad` repo on Github than to follow every PR when teams start scaling up. But do what works for your team. As I said, I prefer monorepos at any scale. Being able to pull all your changes across your entire product in one `git pull` is huge. Being able to track PRs across your product in one interface on Github is huge. If you have the tooling capability to execute on a monorepo, I believe its the best choice for any organization, not just Go.
I think the default theme suits Go really well. It's got a similar colour scheme, and the Gopher still makes an unobtrusive appearance.
https://github.com/m0rcq/go-exif https://github.com/rwcarlsen/goexif https://github.com/xiam/exif For example 😉
A built in GUI a la Python and tkinter, that is cross platform. 
Thanks for your contribution. I did note in the original post that I was looking for a library to write as well as read. And in pure go. Unfortunately none of the libraries you linked fit into this category. It seems we might need to write one.
I just tried debugging. You are awesome!
Besides, there's now a pure Go library to read LLVM IR: https://github.com/llir/llvm 
I could be wrong by my understanding is that many big name monorepo users actually started from different systems. Google used to use perforce at one point and Microsoft used its own VCS. Facebook also started with SVN (I think!) and later migrated to mercurial. The point being is that these companies already had an investment in a monorepo and VCS that likely made breaking this up more trouble than it was worth. That is especially true when they didn't start with repository management tools like Github that provide an API across a variety of repos. Also, we use a monorepo, but it has its downsides. Daily development is slower, CI is slower and we're starting to hit performance limits on our Github instance because the unit of operation is a repo. Therefore, with most systems supporting the single repo == single artifact model, there is a lot to gain by keeping thing separate and capitalizing on the repo management tooling, like Github, to enforce consistency. All that said, I'd let deployments and project automation guide decisions of when you should break up a repository. If it seems like you're writing a ton of code to manage your build and project tasks, then break things up and use your current project automation as a standard. 
tunnels, vpn, sure, but filesystem encryption doesn't help in many cases, if an attacker gets ssh access to your system, you are done, because the file just looks like plain text, on an encrypted fs that is mounted and being used. You probably already knew that, but a lot of people think encrypted fs is the magic solution and then they find out how it really works. 
There's a new layout for Reddit coming "soon", and any theming would need to be redone. Once the new Reddit style is live, we can have a group bikeshed about how it should look.
A package which can parse time and repetition from natural language. ``` inputs := []string{ "today at 9 pm", "every day at noon", "next tuesday", "in 2 hours", "on the last day of every month", } for _, input := range inputs { thing, err := timeParser.Parse(input) if err != nil { return err } // can use 'thing' to know when to trigger next, etc. } ```
I am not quite sure, what you are asking. If you want to know how to get the positional information of where a function was called to output them (like e.g. `(*testing.T).Logf` does), the answer is [runtime.Caller](https://godoc.org/runtime#Caller). Example: https://play.golang.org/p/ae5lIK7DguU If you want to read a file and record positional informations of tokens and the like, you may be able to reuse [token.FileSet](https://godoc.org/go/token#FileSet), which is used by the `go/` packages. It essentially implements a mapping `int-&gt;(filename, line, column)`. Example: https://play.golang.org/p/TkVL_mt1Xz- Note, however, that the last examples cheats, as it uses bufio.Scanner to split into words, but then *assumes* that there is a single space between each word to keep track of the position the word is at. You likely have to write your own bufio.SplitFunc to keep track of the position consistently. The [go/parser](https://godoc.org/go/parser) might also provide inspiration of how to use the `go/token` package correctly. Hope this helps?
This looks cool, but why invent your own configuration file syntax?
[removed]
Thanks guys! this definitely gives me some good options! Will post back when I have something to show!
Polishing my spartan PDF writer (github.com/balacode/one-file-pdf) and just planning to write an embeddable SQL database with built-in DB file encryption and simple replication. Both things I need to write business apps. I wonder if a basic SQL DB can be written in 10K LOC? SQLite is a light embeddable DB but needs cgo, doesn't encrypt its files or have network features, and is about 100K LOC. Not a small codebase at all, unless compared to 1.4M LOC of Postgres for example.
s := "A^w^e s^o^m e" fmt.Println(s)
wonderful! The former look like internal and debugging tools, but the latter are similar to what I want. although it looks like I'll have to implement a custom library I've been looking around a bit and it looks like they're implementing something in the code for future versions, for example the [fmt.ScanState](https://godoc.org/fmt#ScanState) interface that covers the previously available [text/scanner](https://godoc.org/text/scanner), only lacks one method to record the position (and the origin) really thanks for the guide!
I find it a little confusing how the Scanner relates with Fileset there is a dance between the text of the `Scanner.Scan.Text()`, the `Position` of token and the `word` structure
&gt; I find it a little confusing how the Scanner relates with Fileset Yes. That's what I mean when I say I'm cheating here. You probably want to write your own `ScanFunc` that tokenizes as you want and keeps track of the position in the file you're in (and then adds that to the `(*FileSet).Base()` to get the final `token.Pos` of the token). As we say in mathematics "that is left as an exercise for the reader" :)
ha, ha, ha, home work
It feels somewhat generic though, there should be a way to differentiate this subreddit from others using the default theming
Honestly, being able to "script" in Go would be awesome! What I mean is something like putting "#!/usr/bin/go" at the top of your file to make the code executable, without needing to compile it, or having to use "go run {file}". Furthermore, being able to do "one-liners", like "perl -e" would get me to stop using bash, perl, awk entirely. I realize that this is a huge technical challenge, but it would be awesome!!
Thats what she said.
Looks like a fun project especially the lexer stuff. I haven't touched much parsing myself. I hope you are okay with some feedback. A few suggestions: * consider using the built in [log.Fatal](https://golang.org/pkg/log/#Fatal) for fatal errors. * Avoid panics when possible, mostly in your checkError function. *Try to avoid stuff like your doNothing function, the compiler is intentionally complaining for a reason.
BINFMT_MISC [.](https://blog.jessfraz.com/post/nerd-sniped-by-binfmt_misc/)
Does GoLand have the ability to suppress GoLint (or its version) warnings/errors? I’ve seen that the Go team doesn’t want to support that, and I’m curious if I can suppress dumb errors like errors not starting with a capital letter
Thanks but this doesn't work on macOS and I've not tested yet.
I meant the same author's 99c didn't work on macOS.
Yea you don't need Node.js nor Express. Those are used on the server side where you're going to use Go for it. I would suggest you to use a framework that is doing a lot of work for you and will provide you with some examples: \(IMO\), here is an easy one to start with: [https://echo.labstack.com](https://echo.labstack.com/middleware/static)
I think you are struggling with the WEB programming with Go, that's ture, you do need some background knowledge about js(or relevent library such jQuery), css(Bootstrap), html regarding of web programming, even there are many tutorials online but it still need a right sequence and consume a lot of time to learn one by one. Go has been applied in many areas, WEB is the most popular one. I'm working in telecommunication industry, I used go to implement RTP, SIP, you may not familiar with those keywords. I mean if you don't work in a specific areas, you just want learn some Go, maybe you should start it from a small project. You don't need start learning Golang from WEB programming(server side), you may start from network programming(client side). Let's say, if you are a student, you can write crawler to grab information from your school website or you can start from writing a timetable. Anyway, start from a small project that you familar with the whole process and it can be implement by computer language, or reimplment an existed one that you were working on.
`tmp = tmp[1:]` is definitely O(1) its just changing a pointer. append though, might be log(n) amortized? 
Super cool, thanks for posting this. I had some serious questions about Go on super memory constrained hardware. 
It's been like 20 years since I wrote Pascal and this makes me want to tinker with it again. I don't know why, but I have fond memories of it.
Agreed. +100 ... I have installed unixodbc and used an ODBC package I found for go with great success (other than the unixodbc setup party which is annoying but not terrible). But JDBC would be awesome, I know the bridging required and such to use any old JAR file is likely a nightmare. I'd much rather use Go for my ETL stuff over Scala to be frank.
This wouldn't work because the sql is a string (I updated my original post for clarity).
Zmq native go package without Cgo dependency on zmq C library. Life would be so much better.
That's all true. We haven't hit any performance bottlenecks with our monorepo, so I don't know where those would start. And if you're on Github, good luck engineering around them like Google and Facebook can because they have a billion engineers. I do wish there were a way on Github or a competing product to tie multiple independent repos together into a single file hierarchy, with combined human tooling like PRs, Issues, Project Boards, Wikis, etc. Submodules don't really solve the problem well enough. I think it comes down to: My complaint with monorepos is the technical tooling. My complaint with single-artifact repos is the human tooling. I'd love to see some innovation in this space.
If you're already familiar with any programming language or you feel like getting dazed by reading the doc, what's usually works is to learn these news basics by actually writing code. Setup your environment and write down the examples you find interesting, don't copy paste them, try to understand how it works and how to tweak it towards your goal. Good luck :\)
 tmp = append(tmp, tmp[0:i, i+1:]) That's a syntax error. You can't have a comma in an array access.
Appending single elements is amortized constant time. This is because you're adding something of a constant size. Appending an entire new slice takes at least O(n) for appending a slice of length n because it needs to be copied.
You'll have to build up the query yourself. It's not the most efficient, but something like this would work: func UpdateUser(db *sql.DB, u models.User) error { cols := []string{} args := []interface{}{} if u.City!="" { args = append(args, u.City) cols = append(cols, fmt.Sprintf("city=$%d", len(args))) } if u.Interests!="" { args = append(args, u.Interests) cols = append(cols, fmt.Sprintf("interests=$%d", len(args))) } args = append(args, u.ID) query := "UPDATE users SET " query = strings.Join(cols, ", ") query += fmt.Sprintf(" WHERE id=$%d", len(args))) _, err := db.Exec(query, args...) return err }
[removed]
Just completed LGbWT, and really enjoyed it. Great Work!
I would highly encurage you to read through the postgresql SQL docs: https://www.postgresql.org/docs/current/static/functions-conditional.html The answer to your question is to use a CASE statement as follows: update u set city = $1, interests = case when $2 = '' then u.interests else $2 from users u where u.id = $3; 
thanks! this looks promising. I'll try this and read up on the postgresql docs.
Use gometalinter for that
You are not kidding about "very small hardware"! 4 KB RAM and 12KB Flash is absolutely miniscule.
While all the inspections are optional, you probably still want to consider that your code doesn't live in a vaccum and others may use it at some point.
Well, it's a start :)
neugram.io
See this WIP: - https://github.com/zeromq/gomq
Sorry, there is no GC in Emgo.
If only you didn't have a subscription based sales model...
&gt; Appending single elements is amortized constant time. This is because you're adding something of a constant size. No, it's because `append` grows the underlying array by 2x when needed. A naive append, like func append(s []int, v int) []int { s2 := make([]int, len(s)+1) s2[len(s)] = v return s2 } would be `O(n)`, even though "you're adding something of constant size".
It's not subscription based if you don't want it to be. You can just buy 2018.1 and have it for life. And when 2018.2 comes up, you can pay the difference in months then have that for life. The idea is that 12 months of continuous subscription will get you that license. Furthermore, if you buy it the second year, the price drops from $89/year to $71/year and from the third year onward you pay just $59/year for a license. Hope it helps.
Looks like it's dead though...
Thank you, this was an interesting discussion. I think I will stick with a single repo for now. I am a single developer and this is just a large hobby project, so if I'm careful with managing my dependencies etc splitting it out into smaller repositories down the line should be simple enough.
Thank you; I've decided to stick with a single repo for the time being. I have a feeling eventually I may separate some of these things out, but now doesn't seem to be the time. 
Ah, wasn't aware of that. Thanks for clarifying.
It was 'return nil' before, 'return' now. I still prefer 'return e', but at least it's not totally misleading.
Its been a very long time for me using pascal as well, but writing a parser for it was thoroughly enjoyable.
Its been a very long time for me using pascal as well, but writing a parser for it was thoroughly enjoyable.
Your naive append doesn't copy the existing elements from s to s2.
I realized I wrote it out wrong last night. It's O(1) even with the spread operator? `tmp = append(tmp[0:i], tmp[i+1:]...)`
updated.
true, brain fart :) Edited, thanks.
What's the added benefit over VS Code or Atom with additional plugins?
A social network.
Can't recommend goquery enough.
Great libray /u/ziutekgo . I will be receiving one or two [nRF52832](https://www.nordicsemi.com/eng/Products/Bluetooth-low-energy/nRF52832) SoCs (those test dev kits from Nordic) in a few weeks that allegedly have BLE 5.0 support. Do you happen to know if your library works with those or you haven't had a chance to test them yet ?
Every variable you allocate, is stored at a particular memory address. When you must pass around variables in your program, sometimes you want to be able to manipulate the contents directly. And sometimes the memory allocated is too big to pass around between functions. So what a pointer allows you to do is, instead of pass around a literal value, you pass around it’s reference, which is always the same 32- or 64-bit size depending on the system’s architecture. Likewise, when you need to pass a pointer to a function, you know the original address in memory of the variable inside the function, which enables you to overwrite its contents. Passing by literal value doesn’t let you do that. A pointer is always “the address of _______”, eg if you make a pointer to a UInt32, it is always “the address of a UInt32”. If you make a pointer to a Byte[13], it is always “the address of a Byte[13]”. Does that help?
Spectacular stuff. The API for configuring the peripherals along looks very nice. Any reading to find out how this works in more detailed?
https://invite.slack.golangbridge.org
Slack sucks balls. And that community is lame. Real hackers use IRC.
&gt; since the language I'm dealing with doesn't have pointer (Javascript, Python, PHP....) I really don't know the point of pointer. The thing is, those languages *do* have pointers. They mostly don't have non-pointers, though, which is why they don't expose it to you. But whenever you have an object that modifies itself, you are using a pointer. If you pass a python-list to a function, which appends things to it, then that works, because you are actually passing a pointer. So, the real question is: What use are *non-pointer*? And the answer to that is, that pointers are more expensive: If you need to follow a pointer, you might have to load new data into the cache, they need a bit more total space and you might need more instructions. Often, you don't need that cost, so it is advantageous to be able to decide yourself what data has the extra indirection and what data hasn't (this is called "controlling the memory layout"). Go allows you to do that, by distinguishing pointers from non-pointers.
IRC lacks history and I am 12 hours away from nyc
[removed]
I don't think many people will spend much time checking this out without at least *some* documentation. Even one or two usage examples would go a long way. As it is, I don't really have any sense of what it is, why I might be interested in it over other tools, etc.
I've been using IntelliJ for a long time, for multiple languages. I'm actually not at all happy that Goland has forked off and that the IntelliJ plugin will not match it in feature parity. I.e. I use Java, Python, Ruby and other languages on a regular basis, I'd love to have one IDE for Go as well. I get it, JetBrains wants to make more money, but this kind of sucks. Also, the initial bootstrapping stage with JetBrains IDEs is still way more painful that it should be. I downloaded a trial version of Goland but could not get it to debug a basic Hello World app. After an hour or two, I gave up. This has been my experience with IntelliJ (with language plugins and re-skinned as PyCharm and RubyMine. Setting up a new project is always an enormous pain in the ass resulting in unhelpful, and sometimes nonexistent error messages and tons of googling. Always always always, I can build and test everything just fine from the command line but the IDE just beats me into submission. And then, worst of all, I end up with a snowflake configuration which I'm terrified to touch because I don't want to blow away hours and hours reconfiguring everything again.
I have one for about a month, but I didn't have much time for it: https://github.com/ziutek/emgo/blob/master/egpath/src/nrf5/examples/ebyte/board.jpg nrf5/hal is designed for both nRF51 and nRF52. You can find example code there: https://github.com/ziutek/emgo/tree/master/egpath/src/nrf5/examples/ebyte
I should definitely write something about...
&gt; Profiling, debugging, build and automation tools, rich VCS support Sounds like Atom IDE
Who would have thought that IDE may sound like IDE, wow. Also sounds like Netbeans, Eclipse and a bunch of others.
thanks !
I always find it confusing when someone begins a post with "no" and then proceeds to not disagree with me. Both what I said and what you said are why appending single elements can happen in constant time. My intent was to draw the important line between the single-element and arbitrary slice append. I believe it was the source of the OP's confusion. I agree that I could have been cleared and more complete.
GetInfo() map[string]interface{} Cringe. There are very few reasons to do this in Go. If you are going to use the "info" to build JSON, just use the struct. If you are going to print it just use "%v" or if special formating is needed, implement your own stringer. This was a missed opertunity to show how idiomatic Go differs from idiomatic PHP. P.S. Its also fun to end these example with a unit bench of each for shock and awe :D
Yeah, to sum up pointer is just like a reference? 
&gt; So unlike modern PHP, Go does not have the same Object Oriented constructs we’re used to, such as Classes, Inheritance and Polymorphism. Go doesn't have polymorphism? &gt; the provision of a single interface to entities of different types
Ahh, It's just a reference which can be apply to almost any thing even function?
By what you say can I assume that Go is a flexible language hence allow developer to have more control over what they doing that can result in performance boost? 
Kind of. My best attempt at an ELI5 explanation would be to say you could think of pointers sort of like associative array keys in php, dictionary keys in python, or object keys in javascript. Pointers let you access information in memory like keys let you access information in arrays and/or objects. Key's and pointers are different but the concept is the same.
hmm, I see the point but why are programming start to not expose the pointer to developer (C#) and then Golang come up with pointer. I know different language different purpose but why can't they keep thing the same? is there a reason behind that?
I think having access to pointers depends on your needs. The concept behind pointers is indirection which is the ability to reference something. I've very rarely seen scenarios where pointer access was needed in interpreted languages like php and python. As far as C# is concerned it seems to be a design decision made by Microsoft. According to their [docs](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/unsafe-code-pointers/) "To maintain type safety and security, C# does not support pointer arithmetic, by default." Most of the time it comes down to what the language was intended for and what the problem authors of a language were trying to solve.
A map and a mutex is a perfectly reasonable way to implement some caching. Yes, you need to lock read and well as write. You might fall under the preconditions for which [sync.Map](https://golang.org/pkg/sync/#Map) is optimized. Assuming you know you're going to use all those SQL statements repeatedly for every new publisher, it probably makes sense to prepare and cache the statements. However, I'm thinking you'd get a much bigger boost in performance from buffering and inserting data in batches rather than paying the overhead of journal and index updates for every individual insert. That's harder work from a programming point of view, of course.
Try reading this https://golangbot.com/pointers/
&gt;C# does not support pointer arithmetic Neither does Go
If you use IntelliJ IDEA 2018.1 Ultimate and you'll have the same features from the Go plugin there as you would have from GoLand 2018.1 &gt; I downloaded a trial version of Goland but could not get it to debug a basic Hello World app. After an hour or two, I gave up. I'm happy to help you with this, as it should work put of the box with no configuration needed. Feel free to ping me here, on Slack, Twitter, or open an issue on the tracker, https://youtrack.jetbrains.com/issues/Go &gt; Always always always, I can build and test everything just fine from the command line but the IDE just beats me into submission. And then, worst of all, I end up with a snowflake configuration which I'm terrified to touch because I don't want to blow away hours and hours reconfiguring everything again. Again, this sounds terrible as an experience and I apologize for that. Please reach out to any of the above channels and I'll be happy to help out (and avoid building snowflakes but give you a reliable build as the IDE should match what you use from the command line).
This is interesting! "this time for SQL", are there other non-sql QLs for Go?
Levels of abstaction. Some languages try to make you life easier by doing the same thing under the hood. Having pointers gives you more flexability, but also implies greater responsibility.
I get it. I just wanted to point out that Go and C# are the same in this regard.
I am a total beginner in Go, so take this with a grain of salt, but I prefer VS Code with the Go plugin over GoLand. I personally found that VS Code (and Vim with the Go plug) had more descriptive errors and function/struct/interface helper popups, and better auto complete. VS Code uses Delve for debugging, and it has been a pretty great experience on that side. Both do auto formatting and auto import (if you want). The one minor thing that GoLand has going for it, is that when creating a new struct without using field names, it will auto visualize them for you, which I found to be a super helpful feature. I am very interested in what I am missing because people on Reddit are religious about IntelliJ, but I haven’t found a JetBrains product that I personally love (although I don’t work with Java)
Why is an append in O(N) amortized if an insertion in table doubling is O(1) amortized? It should be O(N) in the worst case, as in this case: https://www.cs.cornell.edu/courses/cs3110/2009sp/lectures/lec21.html
Why does the author bother writing tests if the don’t give a shit? Why do they bother writing any code at all if they don’t give a shit? 
Thanks for the tip on `sync.Map`, I didn't know about that type. Regarding batching, that's a good idea, but as you pointed out, it's extra work to buffer for each table. I'll look into it when I feel it could become a bottleneck.
how's it amortized?
I can't remember where I got this Mutex protected Map code from but if you combine the Mutex with the Map in a struct: var index = struct { sync.RWMutex m map[string]string } {m: make(map[string]string)} Then you can protect writes with: index.Lock() index.m[idx] = thing you're writing index.Unlock() And reading with index.RLock() thing = index.m[idx] index.RUnlock()
The article is about his testing methodology. He's a non-native English speaker.
I've done something similar (cdb integration), but the concurrency and timeouts while managing a process can be challenging. There are some libraries that might help, although I haven't tried them: https://github.com/shavac/gexpect/blob/master/examples/ssh.go So there's no reason you can't, but YMMV.
A very minor cosmetic issue: In a small browser window, the text has no left or right borders anymore. This makes it a bit difficult to read. 
[Release note to save you 2-3 clicks](https://golang.org/doc/go1.10).
Any contribution is welcome!
I had several try before, not exactly in NoSQL , for example this one : https://github.com/fzerorubigd/humanize
I'm not generally a fan of "fluent interfaces" but this is one place where you'd be better off with that instead of copying SQL too closely. Having the query as a big string is much more difficult for me as a user, because if I can write Query().Select("name", "source").From("Funcs").Where( Clause("receiver", IsNotNull).And("name", Like, "%print") ).OrderBy("name") then that means I can also write code like func IsPrintlike(c *Clause) *Clause { c.And("receiver", IsNotNull).And("name", Like, "%print") return c } // later Query().Select("name", "source").From("Funcs").Where( IsPrintlike(EmptyClause()) ).OrderBy("name") or something like that. It may look trivial in a comment, but as the work scales up, this becomes very powerful and useful. It's basically an extensible query language, for free. And on your side, the parsing is _way_ easier, too, because there isn't any. Just your Go objects and some methods to construct them, which probably already exist. (And for the love of goodness, don't consider what I bashed out up there to be a good example. It's just an example to be concrete. There's at least two significant problems I noticed just as I was typing it out, but it's here to be an example, not a design document.)
Pass by value creates a local copy of the argument, whereas pass by reference creates an alias of the actual argument. Pointers are no different, they are just variables whose value is the address of some other value. I.e., in go passing down a pointer is essentially just passing down a copy of that address.
That’s exactly right. To use a real word analogy, imagine a trailer, a detached house and a condo building side-by-side on Main St. The “pointers” are 1 Main St, 2 Main St and 3 Main St, but what’s actually referenced at those addresses can differ wildly. 
From a modern programming language perspective, it can be difficult to understand what "pass-by-reference" or "pass-by-name" truly means, because every modern language is pass-by-value. That is, there is some sort of distinct "function call", which receives copies of arguments from the caller, proceeds to do its business on its copies, and then returns, destroying its copies in the process. It's easy to get confused by the fact that one of the things that can be passed are references/pointers, so if a function gets passed an \*int and uses it to modify something, it may look like there was something "passed by reference". But in fact under the hood, while the function is running, there is two places in memory that have a pointer to the int in question, and no matter what the called function does, it can't change the original pointer. There's a few languages that still simulate this at the language level, where there's a hidden pointer not exposed to you, the programmer, that is passed in, but there's still a copy made of the pointer. Then it looks as if you can have: func Caller() { i := 1 Incr(i) fmt.Println(i) } func Incr(i int) { i += 1 } and have Caller end up printing 2, but there's still a pointer copy. The _real_ "pass-by-name" or "pass-by-value" languages, though, had very different mechanisms for calling a function that didn't involve making copies of anything. Forth, for instance, had a stack that all functions pulled from, so if you had a stack with `[1, 2, 3, 4]` on it, and called the `+` function/operator/word, the result is a stack with `[1, 2, 7]` in it. No copy of the 3 or 4 was made; the + operator directly operates on the values in the stack, and directly wrote the value back on to the stack, popping the bottom one off (that is, after the 7 is probably still a 4 in memory, to be overwritten the next time the stack grows again). Back in the days of constrained resources, this could be a major advantage for Forth vs. trying to port a language that does copying on every function call when every byte is precious. That's the real alternative to the modern world of "pass-by-value`, but it's almost impossible to point at a modern language currently in use that works that way. Other languages existed that had things that looked like a conventional function call, but hooked up the called function to operate directly on the original input unconditionally, again with no copy made. Nowadays, everything under the hood is pass-by-value.
How does this compare/contrast with gobot?
whoah, thanks. I had to read this a few times but it makes more sense to me now. Quick question: when you say 'The real "pass-by-name" or "pass-by-value" languages, though..' did you actually mean to say 'The real "pass-by-name" or "pass-by-reference"? 
It is sad that screen scraping ssh/telnet output is still a think in 2018. Try to find alternative, more automation friendly, interfaces like NETCONF, RESTCONF, Arista EAPI, etc and push on your vendors to support them. For RESTCONF and Arista EAPI just a small wrapper around net/http.Client. For NETCONF I have wrote a (basic) library https://github.com/Juniper/go-netconf. You can still fall back to screen scraping, but try alternatives first. Go and Networks are perfect together. The concurrency makes automating a network of 100, 1,000, 10,000 or 100,000 devices very easy. 
In my experience, people who use Jetbrains IDEs for one language tend to use them for other languages as well. I've first started using IDEA for Java many years ago and I've never looked back. It really is a powerful IDE and there isn't anything quite like it. Pretty much everything you can think of can be customized to match your (or your company's) exact workflow, including UI, keyboard shortcuts, macros, run configurations, dependency management and third party library integrations ^1. ^1: For example if you are using [sqlx](https://github.com/jmoiron/sqlx) or [pop](https://github.com/gobuffalo/pop), Goland can autocomplete your queries inside strings.
Great advice; thanks so much for reading the code through.
The GoQL is a standard sql driver for go, so in paper , it should work with Gorm/Gorp and whatever orm available in the market, never tried myself, but its on my list to try :) this could be an orm idea, in a higher level. 
Oh wow, that is very fancy, hmm, maybe I will give it another try.
Dave Cheney wrote a good [post](https://dave.cheney.net/2017/04/26/understand-go-pointers-in-less-than-800-words-or-your-money-back) on this. I think you will find it helpful. 
Expect (the library that inspired pexpect) has been around for decades. There are quite a number of Expect implementations in Go to choose from, Google's implementation is one example: https://github.com/google/goexpect You can find alternatives by searching for 'golang expect'.
Yes I know but this doesn't sound amortized, since it sounds like it'll always be O(n). O(n) amortized would mean sometimes it runs at a higher complexity like O(n^2) but so rare that we don't count it.
Yes, thank you.
Check out Micro https://github.com/zyedidia/micro
&gt; It is sad that screen scraping ssh/telnet output is still a think in 2018 You're telling me! 
Wow, this is really neat!!! I might give this a go as my daily driver! 
You can write extensions for [Neovim in Go](https://github.com/neovim/go-client).
[removed]
[removed]
I see what you did there
Mapstructure is good for working with any type where you don’t know it’s shape, just declde into a map and you can then use mapstructure to access things. 
fresh doesn't look maintained. Lots of great open PRs
This actually runs on the target platform for constrained ARM devices. GoBot requires you to install firmata on the device, and the PC will send commands to that. If the link it stopped or removed the program will stop working (effectively). 
This is kind of a tangent, but it reminded me of the [LimeText](https://github.com/limetext/lime) project, where they were separating the backend from the front end. The goal was to have multiple interfaces, including terminal, all talking to the text editor engine. 
I do not against the idea. Actually I like it this way you describe. but In my plans, there is lot of feature in the way. for example, without definition of types/vars/function args and returns/const this library has no much use. A cool ORMish interface is fun too, but I need time to handle all of this stuff :) 
Nice one! thank you. 
VIM is single-threaded, but it would certainly be interesting to make a clone that isn't, as Go provides you the concurrency primitives to make that work nicely. The major pieces / fun problems to work out would be the display engine (probably using curses or some similar library), input processing, file management, syntax highlighting, plugins, and (if you're really crazy) multi-party editing ala Google docs.
Not sure what you mean with "keep the protobufs in sync" but I'll assume you mean the generated client/server code with the original PB? Well, at least you should have a Makefile to automate builds and/or ideally a full-blown CI/CD pipeline. But who hasn't these days? ;) I'd store it close to the rest of the code, so not a central lib of PB (unless you have a really good reason to, but never seen in practice). Reason: it's a build artefact that you will want to have strongly coupled with the actual consumers (client/server).
BoltDB is very nice. But as you said, it's neither of those.
not mine, it's the Ops
Javascript uses pointer implicitly
Interesting.. never knew though
Not exactly what you want, but it works on *nix OS family: ///path-to/bin/go run $0 $@; exit $? package main func main() { println("Hello World!") } Then run `chmod +x file.go` and then you can execute it as `./file.go p1 p2`.
Very interesting and I like it mostly (maybe watching the actual talk can help with clearing things up). I wonder how this could be applied when using [Standard Go Project Layout](https://github.com/golang-standards/project-layout).
Working on a golang backend for my mobile game https://cheapshot.co/ (sorry if not avail in your country, but scaling that thing is hard)
[removed]
ye this is just auto build and restart
proper text editing is actually quite complex. Look at the xi editor project. They have some write ups on the architecture.
While slices are not references, they have reference semantics, since assigning a value of a slice type to another variable creates another place referencing the same backing storage array.
Do you mean Nvidia CUDA? They only provide the nvcc (nvidia compiler) for fortran, c and c++. So anything you find will just be a wrapper around C/C++ 
so your saying that i have to use unsafe standard package of go and cuda lib for c++ than i can use that
I wrote a tool that is more towards searching Go code rather than querying it: go get mvdan.cc/gogrep Very different approaches, but in the end they are both tools with their own languages to express what you want out of some Go code.
OP means to say you have to use CGo. Whether that library internally uses unsafe or not depends on the API.
Hmmm you weren't asking nicely in my book and the reply you received was justified.
looks very cool, any source available?
[removed]
Er, Go's Mkdir fails if the path already exists. We want `mkdir -p` behavior (`mkdir` in Windows).
No problem. If you ever try it with Postgres, let me know of any issue. I agree, and have thought of giving it a shot at writing a broker, specially because the ones I've seen in Go aren't quite complete. But it is of course a lot harder and bigger than a simple plugin, which in turn means it is very time consuming. Maybe some day.
&gt; Er, Go's Mkdir fails if the path already exists. [No, it doesn't.](https://golang.org/src/os/path.go#L24)
Confirmed. Deprecating my mkdir.go with maximum force!
[removed]
Awesome to see people experimenting with things like this. Could you talk at all about why you chose to modify the gccgo compiler instead of the `gc` one? Just curious what the motivation was, or if it was easier in some way etc.
[removed]
&gt; {Foobar foo@ex*ma*ple.com} &gt; &gt; {Foobar foo@ex*am*ple.com}
LAWDD HAVE MERCY
&gt; I think the least convoluted code uses both exception and return code based error handling . . . If an error is typically propagated at most one stack frame (i.e., to the immediate caller of a function), return code error handling should be used; If an error is typically propagated more than one stack frame (i.e., up through several callers of a function), exception based error handling should be used. This rationale is unconvincing. The "destination" of an error cannot be known _a priori_ when it's generated, especially in the context of programs that accrue responsibilities and abstraction over time.
Factory libs? Not sure what you mean by that. Use a straightforward routing library such as goji.io or gorilla/mux and it should be pretty simple. Add a framework only if you need one.
[cu](https://gorgonia.org/cu)
I don't get the point of the local go server to host the HTML pages (it's just putting the repeated header/footer, which I guess makes sense, still seems like a bit of overkill here). Also, looking through the go101.go, it will issue "git pull" every 5 minutes for 24-hours (if you keep the app running) for the current directory.
The first run of "git pull" happens at 5 minutes after the server starts. The later runs happen once every 24 hours. This is to keep the local content always updated. The local server is mainly for Chinese gophers, for https://go101.org, which is hosted on Google AppEngine, is blocked from time to time in China. Whereas if you want a better experience (fast loading), you can also run the local server.
Just wanted to say “thanks” for gorgonia! Maybe one day Nvidia will promote Go to a first class language for Cuda. 
Finally! The white paper is a great read for anyone who isn't excited already.
Gorilla/mux seems to be the standard now. There are others, but there is an ORM library that includes gorilla/mux, and other nice capabilities (management of db, etc) that can easily handle this for you.
Logo: https://twitter.com/egonelbre/status/980345054035312640
Fun fact: Go 1.12 will utilize all available CPU cycles that have been freed up due to optimizations over 1.10, to mine Bitcoin. 
Excellent response. I really detest exceptions because they mean i can no longer _trust_ function signatures. Does this function actually work? In order to know if it throws i have to inspect the function body. In Go if a function has a chance of failure I can see this very clearly and the compiler somewhat forces me to deal with it. 
Next time, I will ask you some naming ideas. And can we change the name of it into fuego. It released just a few hours ago :)
http://memes.ucoz.com/_nw/55/78915193.jpg
maybe just check it out: https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html and go vanilla :)
yall should read the White paper https://go4.org/golang/go-blockchain-support-whitepaper.pdf
There will be an ICO at the time of G0 1.12 release. There will be 0xFFFFFFFF coins issued at that time. Every gopher will get some. The more lines of Go code a gopher has written, the more coins she/he will get. "if err != nil {...}" doesn't count for the code lines.
thanks! (it's not my project per se, I am just a happy user, sometimes contributor) AFAIK, `gomq` is missing: - multipart messages - req/rep - pub/sub - zmtp-plain - zmtp-curve so there's plenty of issues to tackle :)
The whitepaper link seems to be broken: "The uploader has not made this video available in your country."
yes, gccgo is pretty approachable. It's written in c++. It took a certain time till I figured out how some things work, thankfully the c++ used is a basic one, no boost and similar things. Now I'm confident to deliver features unless gccgo is decided to rewritten from scratch, that would break our ability to maintain this thing and will have to re-learn how the new frontend works. We had long ago a hack built on top of gc. But it broke when gc removed yacc parser. Since then nobody really looked at it in depth. Also gc is a full compiler so the learning curve is kind of steep. I for example still don't know in what files some of the necessary pieces we need to modify are. The advantage is this proposal is limited generics and therefore not too complex to implement (unlike others more complex proposals out there). We would of course want a more complex proposal implemented in go. But given the choice of no generics and limited ones, I prefer to have something.
[removed]
Great read. I have wanted a much larger standard library for years, looks like they are getting around to it.
I solved the same problem a couple of days ago. I have a straight forward nodejs backend that I was able to deploy to Google App Engine, by just adding 4-5 lines of app.yaml. I need to serve the API via https which comes out of the box with https://&lt;my-project&gt;.appspot.com. Unfortunately there is no way to use shared CPUs in flex environment so it's a lot more expensive than just deploying it in a container on a GCE micro instance. So I moved the backend to GCE micro instance and reserved a static IP and wrote a simple REST Server in Go that simply forwards the request to the GCE instance and sends the response. I used nothing fancy, basically just that: https://thenewstack.io/make-a-restful-json-api-go/ Hint: You can't use the standard way to make HTTP requests you have to use urlfetch in GAE. https://cloud.google.com/appengine/docs/standard/go/issue-requests Somehow this feels like a hack but it does what I need and saves money.
I don't see how using GCE as a backend would be worth it. The whole point of moving to App Engine Standard would be to get rid of virtual machines entirely, while maintaining scalability.
Hey, I really like this. ;)
I meant standard libs.
I just spiked on this for work I plan on using https://github.com/lestrrat-go/libxml2 
Ahh I see the thing in my case was that my backend uses PhantomJS, which I use with node-horseman so I needed to call native code on some kind of compute instance anyway.
True, lol. And none of that is a unit or integration test!
Are you planning on using this for that etherium stuff?
I have solved the problem. GOPATH must be set to an absolute path, not relative. While all of my settings follows it, my workspace settings on vscode was set to relative. The solution is to change the workspace setting from: { "go.gopath": "$GOPATH" } to: { "go.gopath": "/home/aerhv/go" }
Sorry but I just love these blogs! https://blog.golang.org/slices https://blog.golang.org/go-slices-usage-and-internals They make me want to drop everything and study code. And the one that really explains it! https://research.swtch.com/godata And of course bill's easier explanation. https://www.ardanlabs.com/blog/2013/08/understanding-slices-in-go-programming.html And just cause https://nanxiao.gitbooks.io/golang-101-hacks/content/posts/the-internals-of-slice.html 
Thanks
Another cool reference, built using only the standard library and extended standard library, inspired by Acme: https://github.com/as/a
One of the easiest things you can do is to test with the testing package instead of testing in a main function with println.
Some webrtc to rtmp convertor.
Personally, I don't contribute to, recommend, or use AGPL software because it feels very restrictive to me. I prefer to provide software as MIT or BSD (I like Apache more in theory but prefer simplicity) and happily use / support LGPL and GPL plus a linking exception, but something like this would prevent me from integrating its UI with other projects.
A lot of the routing libraries work pretty much the same as the stdlib router, so there isn't much to learn (in addition to the fact that a router is only a really small piece of API anyway). Personally I use [Chi](https://github.com/go-chi/chi) because it's convenient and because the routing is more sensible than the one from the stdlib router (e.g. routes not automatically matching all sub-routes without explicitly adding path variables).
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://github.com/go-chi/chi) - Previous text "Chi" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
I feel bad that the link gave you up, and let you down.
Thanks for sharing your thought about AGPL! I understand the AGPL-3.0 license will not be attractive for certain contributors. Despite these negatives, I think I have made up my mind. Those who are not familiar with AGPL-3.0 license, I would suggest to read this article: https://www.gnu.org/licenses/why-affero-gpl.en.html A quote from the above article: &gt; The GNU Affero General Public License is a modified version of the &gt; ordinary GNU GPL version 3. It has one added requirement: if you &gt; run a modified program on a server and let other users communicate &gt; with it there, your server must also allow them to download the &gt; source code corresponding to the modified version running there.
The Google must be compensated. It's totally moral
Here is one case study about AGPL-3.0: https://www.youtube.com/watch?v=116nfodTVOY
Thank you for your attention. I will take note of the remark. The thing is that I tried to visualize algorithms through standard I / O
I would suggest using testify to make more readable unit tests. It basically just means you have to use less boilerplate. Also, you can use loops to test a bunch of conditions quickly. An example: import "github.com/stretchr/testify/assert" func TestAThing(t *testing.T) { tests := []struct { input string expect string }{ { input: "oo", expect: "foo", }, } for _, test := range tests { result := "f" + test.input assert.Equal(t, test.expect, result) } } 
Funny how Google jokes around on Go's repository but when I commented that Go can finally run Chrome after they removed the 512GB memory limit my comment got deleted and comments were disabled for everyone. They can dish it but they can't take it.
Not impressed by @param
[removed]
github.com/skelterjohn/rerun
Beautiful.
Is this an april fools post.... trails off in thought.
Offer your first born to The Google and you will get generics. Is that a deal you are ready to make?
A lot of this seems dubious at best, and very much specific to the company investigated.
I will applaud the study authors for including a robust section on threats to validity, something I've seen peer-reviewed software engineering papers leave out. However that section correctly points out that this was done for a few weeks with 20 participants that were not selected at random. This means it is not generalizable and should not be used for decision making of any kind. If you're interested in evaluating claims from SE papers, I find "The Leprechauns of Software Engineering" to be an excellent read. 
I see that too. Maybe an old cached page or something haha.
https://godoc.org/mcquay.me/trash I made that as an exercise. Each of those are io.Reader implementations. 
If it's generated dynamically using a map or some concurrent tree walking, order won't be consistent. It could certainly be sorted in this case, at the cost of performance.
Placing the error handling in a deferred function is the real "magic" here. `defer` is quite transparent otherwise. Similarly, naked returns can be wonderful in short functions. Though, they can appear to be magical due to complexity (especially unnecessary complexity) or function length disconnecting naked returns from their declaration. I believe that this would simplify the example code (Apologies if I've misunderstood the intention of the original source.): https://play.golang.org/p/nHkZ02gGbHW
This was a bug that has been recently resolved. See issue [#24601](https://golang.org/issue/24601).
I did it! WOOOOOOOOO! &lt;!document html&gt; &lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; var hostName = "untamed.co.uk"; var userName = "Public"; var password = "A35C475F10B3E90C293E30353F2932283D313938723F3372293728332E2E3932282F21D8D6E263A8AC1B5A8E6097BA847D7E"; var PW_MAGIC = 163; //0xA3 var PW_FLAG = 255; //0xFF console.log("Password : " + decrypt(hostName, userName, password)); function decrypt(host, username, password) { var key = username + host; passBytes = password.match(/[A-Za-z0-9]/gi).map(t =&gt; parseInt(t, 16)); var length = 0; var d = dec_next_char(passBytes); var flag = d.a; passBytes = d.b; if(flag == PW_FLAG) { d = dec_next_char(passBytes); passBytes = d.b; d = dec_next_char(passBytes); length = d.a; passBytes = d.b; }else{ length = flag; } d = dec_next_char(passBytes); passBytes = d.b; passBytes = passBytes.slice(d.a * 2); var clearPass = ""; for(var i = 0; i &lt; length; i++) { d = dec_next_char(passBytes) var val = d.a; passBytes = d.b; clearPass += String.fromCharCode(val); } if(flag == PW_FLAG) { clearPass = clearPass.slice(key.length); } return clearPass; } function dec_next_char(passBytes) { if(passBytes.length &lt;= 0) return {a: 0, b: passBytes}; var a = passBytes[0]; var b = passBytes[1]; passBytes = passBytes.slice(2); //return {a: ^(((a &lt;&lt; 4) + b) ^ PW_MAGIC) &amp; 0xff, b: passBytes}; var aa = a &lt;&lt; 4; var bb = aa + b; var cc = bb ^ 163; var dd = ~cc; var ee = dd &amp; 255; return {a: ee, b: passBytes}; } &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;
Yep, I just fixed it yesterday. We will be re-deploying godoc soon (I am not sure of the actual policy of whether we need to bump Go version or not for a tools package change). In the meanwhile, you can use tip.golang.org.
Damn and I've been using htop for years...
Hah I've been trying to get their attention for sometime...
what tool do you use to make the graph? they look neat
You end up needing to learn it's equivalency rules instead of Go's. Along with that, I've never found it carrying the weight of adding a dependency.
We're actually not that far off, native Web Assembly support is likely be included in Go 1.11. I suspect we'll see front end frameworks soon after
Very interesting! So one can get away with just GO + HTML and completely ditch JS? I like the sound of that. Really don't want to learn React / Vue.
Sort of, the underlying framework will still need to interopt with JavaScript, at least until Web Assembly can interact with the Dom. But hopefully this would be abstracted away. An example of what I'm talking about, but in Rust: [Yew](https://goo.gl/vvvX4P) 
[removed]
MollyDB a databse engine based in configuration documents that provides a GraphQL API, You could find more info on https://github.com/wesovilabs/mollydb and please any feedback will be very appreciate!!
I use Hype 3 from Tumult Software. It is Mac only but AFAIK, Adobe Animate is a similar app that also runs on Windows. 
[removed]
Know the concepts, just don’t wanna learn them. Use cases that do warrant their use are quite rare. Let’s see how web assembly unfolds. I didn’t even know it existed. Hah.
When view https://go4.org/golang/go-blockchain-support-whitepaper.pdf it redirect to https://www.youtube.com/watch?v=dQw4w9WgXcQ
I wrote this post a while ago, I'll have a look into this!
This is neat as a starter crawler. I recommend a couple of things to add or improve upon. First, storage. Right now this is in memory so if the application faults for any reason youd have to start over. An easy solution is to store the last page crawled for each collector in a text file and have the collectors update it. Second, header requests. Http response codes can be very important for determining the site structure. I'm thinking mainly of redirects. Why bother attempting to download the entire page when you can first get the header which might contain redirects or meta info you can use for your crawler. In example if you're tracking changes to a website you might just grab the eTag and compare it to the last time you retrieved the page. No point in crawling over a oage twice if it hasn't changed at all. The last thing I'd add is some kind of notification system for when the crawl ends. Either by fault or by success. That way you can know if your application actually crawled the entire site. I thought this was great for what it was though. Very simple and refined at the same time. I liked the approach.
&gt; Most software developers at our company, Jexia, say that a maximum time spend of two minutes per activity doesn’t account for them. Their statement: it looks like the researchers monitored the time between switching from one application to another, while these apps are used for the same coding activity, rather than really switching between two different activities. I'd believe that in general we have a hard time getting to 10 minutes on a single task without too much difficulty, but, yeah, two minutes is a bit much. Editing some stuff and then switching to a shell to see if it worked is not a task switch. On the other hand, one of my favorite things about programming is that you rarely have to do the same thing over and over. There's a persistence to our work that is unlike physically building things; as long as you use source control sensibly, it is very rare for a code base to just straight-up regress. I may go down a false path and throw a branch away, and I may wreck up the code in the middle of a refactoring, but I haven't straight-up just wrecked my program in a long time. If there is any high-powered intellectual discipline that could string together a series of two-minute productivity sessions into something huge and useful, it is ours. Still... two minutes? Pretty short.
There's also a tool called "realize" in Go. On mobile sorry for not providing the link.
This is because Google Cloud feature velocity is 1/10th that of Amazon Web Services... And what is interesting is that Google originally had only AppEngine which was actually like Lambda functions before they were cool. And now when they are cool, Google again missed the boat. 
Speaking to the task as given, you want to wrap an [io.LimitedReader](https://golang.org/pkg/io/#LimitedReader) around your random source, then you can [io.Copy](https://golang.org/pkg/io/#Copy) into an arbitrary Writer, and it will generate from the Reader into the Writer without using too much buffer space. If you are trying to provide a tool that writes random files as you specify, this is the way to go. If you are trying to provide things that will be used in Go specifically, you do want something more like what /u/smcquay gave you. As a random "design good APIs" sort of note, since LimitedReader is part of the standard library it is perfectly reasonable to give out io.Readers that are infinite in size for testing purposes and expect consumers to limit the scope to what they need with a LimitedReader, rather than trying to guess all the possible permutations of limits or combinations in your test data generators.
Looks like it depends on using [lapstack](https://github.com/labstack/tunnel/blob/master/tunnel.go#L45) in place of ngrok.
Love it! Please update how it will be going in the blog!
OP take a bow. 🙇 you’re a crazy man — of course in a good way! 👍👍
Gophers are getting perilously close to inventing monads.
Not that I like Javascript in any way, but when you go with a totally non-standard solution you make it more difficult to hire people who have frontend skillsets, and more difficult to keep up with things that happen outside of your fishbowl.
[removed]
Will do, got most of the hardware configured today so will put an update on there soon :)
Unconstructive remark: I would probably go home even if I could not buy eggs.
Great updates. I love me some Hugo.
No, on the client side only JS is supported. Just pretend you are writing Go with semicolons 😉. Anyways, learning JS is not a bad skill to have, since so many things for the web are done in it. If you wants to experiment, you can try https://github.com/gopherjs/gopherjs , which compiles Go to JS. Or look for other compile to JS languages, which have the advantage of been designed for that purpose. Personally, I just use vanilla JS without any frameworks. It gets the job done and will never go out of date. 
And the layout framework will be?
Everything. People run even Qt with web assembly.
So you are suggesting Qt bindings and downloading an entire ui framework for the client?
We should wait for the winner. Client devices will have that library cached, so not really a burden. 
I don't think html and css as ugly, it's just primarily designed for page layout, not application layout. I also don't think anything will win, people will complain about whatever they are currently using as they push the envelope. There will always be the next shiny thing. You are also assuming that everyone will use the same version of the library. 
&gt;package from fasthttp author :) Does this mean it also only implements a subset of zstd?
Zstd has been heavily fuzzed.
I've added this to an "experience report" section on the Go 2 database/sql issue: https://github.com/golang/go/issues/22697#issuecomment-344095510 Reply here or let me know if there are other experience reports.
The go binary is uploaded to lambda, so lambda is not compiling anything, just runs your binary.
As you've noted, it is possible to do streaming AES encryption in Go with the standard library. The issue is that AES alone doesn't provide any integrity guarantees. If you don't trust the location where you are storing the data (most likely the reason you're encrypting it to begin with), then you may not want to decrypt and store data when you are unsure if it has been tampered with. There are a couple of ways to solve this. The first is to use a MAC on the data to ensure that it hasn't been altered. This is typically calculated on the encrypted payload. The limitation is that you have to stream/download all of the encrypted data before you can calculate the MAC and confirm the data hasn't been altered. This may be an option if you don't need to use the bits of data as they are streamed and only care to confirm the data hasn't been altered once its optionally been decrypted and the MAC confirmed. This method does not require storing the whole file in memory. A similar but more modern solution is to use an AEAD cipher like AES-GCM. As far as I understand it, this cipher waits until the end of decryption to perform the integrity check, just like in the manual MAC method above. The benefit is that it does the encryption and integrity calculation for you and acts as a single cryptographic primitive that is harder to screw up. Unfortunately, the AEAD interface in Go does not provide a streaming interface, but this seems to be a limitation of the Go implementation and not of the encryption algorithm (see: https://github.com/minio/sio/issues/26#issuecomment-378012290). The alternative to these methods is to use a chunking protocol, like the DARE protocol you reference in minio/sio. The benefit here is that the integrity can be checked on each block instead of waiting for the end of the stream. It still uses an AEAD cipher, but because each block is encrypted independently, you get the integrity check with each block decryption. The main reason to use the block/chuncking method is if you want to use the data as it comes over the wire, which would require doing the integrity checks as each bit of data is decrypted. If you don't need to use the data as it is decrypted, but just want to avoid storing it in memory, AES encryption with manual MAC (like HMAC), would be the way to go. You mention that you could only find one implementation, but the minio/sio library seems to be complete. What if you aren't concerned with integrity? Then you can just use plain AES without an integrity check, using the streaming interface in the standard library. In this case, no one would be able to decrypt your data, but it does open you up to other attack vectors (see: https://security.stackexchange.com/a/33576/1158).
Why would you want to log to a db?
I came across this as I was setting up a Pi cluster using Kubernetes, and waiting for `kubeadm init`to complete on the master. :-) If it helps, check [this](https://kubecloud.io/setup-a-kubernetes-1-9-0-raspberry-pi-cluster-on-raspbian-using-kubeadm-f8b3b85bc2d1) out. It's helped immensely, especially with the [cgroup snafu](https://github.com/raspberrypi/linux/commit/ba742b52e5099b3ed964e78f227dc96460b5cdc0). Make sure to use cgroup_enable=memory until the kernel gets past 4.14
More details [here](https://developers.cloudflare.com/1.1.1.1/dns-over-https/cloudflared-proxy/).
Site down?
Getting a 522 on my end, looks like
Nice! I bookmarked it 👍
Centralized logging across a large number of servers and applications makes it easier to to do analytics and alerting on your logs. What we use: https://www.elastic.co/solutions/logging
Cached: https://webcache.googleusercontent.com/search?q=cache:LLSGIRkBul4J:https://crawshaw.io/blog/go-and-sqlite+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us&amp;client=firefox-b-1-ab
Based on some benchmarks from openfaas, go has some of the quickest cold starts out of any language. Google doesn't really develop their cloud for external customers, they just have the essentials and whatever they end up spinning off from internal use (spanner Borg/kubernetes, grpc, pretrained models for image, audio and textual analysis, etc). My guess is that Google doesn't have a big use case for FaaS internally
I don't understand why Google is so shit at this.
Must be written in Go using SQLite. /s
basically you put logs for errors and stuff that shouldn't happen, leave the application running, and go back to and query based on things like timestamp, or level as a way to monitor or debug production applications.
 &gt; fmt.Println( len( b1.Hash )) Please use `go fmt`!
So.. I am trying to grasp the use of block chain when sending data over say, REST apis, or a message bus. I dont fully grep how this would work..or be of use. I am told, however, that it is the next frontier in sharing data with 3rd parties.. e.g. up coming integration work where data is shared across different applications would want to or prefer to use block chain. Yet, I know I am missing something, because I thought block chain meant anyone can view the data. How then, would this be used in lieu of say SSL or other forms of encryption to send data if anyone can view it? 
[removed]
[removed]
The data itself can still be encrypted or even permissioned on a channel for those interested parties only. The idea is that nobody owns the data (and the platform it's on) which makes sharing easy between companies or governments. There is no (supposed) hierarchy between national governments so if they want to share data whose database do they use? A private or permissioned or data encrypted blockchain is an easy answer
Is it though? I was wondering just that.. seems like its the new catch phrase of the year or so.. and because bitcoin is so secure using it, it will revolutionize how we send/store data in a distributed manner... or something like that. I look at a library (like this one) and am like.. do I just take whatever data I get out of DB.. or from some GUI user form sent to my API.. and apply some special block chain thingy to it, and store it or send it and thats it? It cant be that easy.. 
Don't get me wrong, I'm all for centralized log aggregation, my point was rather: why not just log to stdout and have it shipped to something like elastic or whatever done by standard components specialized at just shipping (fluentd/logspout/...). To have logging be a blocking operation into a relational db sounds like a operational nightmare.
Does it use transfer encryption? Because in today's world it absolutely should even in local area networks
Rocksdb is from Facebook. Never had any issues with that
You may be interested in this library (by the creator of hugo): https://github.com/spf13/jWalterWeatherman It doesn't do the mutex locking like yours, but it's leveled and prioritizes extreme ease of use. Even if you don't use it directly, I think it's a good, short read.
Wrote a minimal fluentd/logstash replacement in Go - https://github.com/agnivade/funnel. Feel free to check it out.
A blockchain is a chain of blocks. An if you look a the golang example the most important part is the crypto hash (using sha256 - secure hash algorithm 256-bit). The crypo hash / digest / checksum makes sure that the data (and block) is tamper-proof / immutable and the blockchain gets more secure by "linking" the blocks together (that's why the previous block's hash id/checksum is included) and so on an so forth. The point is ... to understand the blockchain "hype" the best way is to build your own blockchains from scratch (zero). See examples above :-). 
[removed]
Good point. I like my own formatting "style". Live and let live. Sorry, please run go fmt on your own local copy.
Greeting from Vienna, Austria. Cheers. Prost.
But what is the benefit of using this for say an api that you provide for 3rd party use that returns data in block chain? Or sends data to 3rd party in block chain? How does 3rd party unravel it all to get the actual data? Do they need some crypto key that I the api owner send them that they can apply to the block chain data they get to unenceypt it? What is different using this vs a normal encryption of data? Is it that the block chain data is sent to dozens of servers so that it is not stuck on my server in a database and the 3rd party can then get it somehow??
Fair enough. Nothing wrong with that at all. I didn't see the bit that restarted the process but I was looking at it pretty late. Might be worth just going through what system[d|v] does to see if there's anything to glean from it with what you've got. Good luck!
Sorry for that, i will attach copyrights
It worked juat fine yesterday
It works just fine right now.
Sure, but as has been pointed out elsewhere, this approach is riskier because logging like this means making blocking calls to an external service every time you want to log something. Not only that, but it's not like relational databases are best suited for logging either. A more conventional approach like logging to stdout/stderr, then collecting logs with something like fluentd and pushing them to something like Elasticsearch makes a lot more sense. Granted, that might be too expensive to run the Elasticsearch part, but you could still move to logging to stdout/stderr and then pushing from there from a separate, buffered collector into your relational database. Just gotta be careful with locking, etc.
Since you're interested in Tensorflow + Go you might be interested in this blog post: https://pgaleone.eu/tensorflow/go/2017/05/29/understanding-tensorflow-using-go/ and this project: https://github.com/galeone/tfgo The project, in particular, can simplify the trained model import workflow a lot and more than that, can help you define a preprocessing graph for your input in a go-like style.
Gin is indeed a well established framework which does a lot. Compared to Gin, WebGo does not even provide a lot of features. WebGo is a micro-framework, which helps developers handle APIs by getting out of their way as much as possible.
nice
I just hope I can get to a point where I'm using React *with* Go. I know, a pure Go framework would likely be better.. but I mainly use React for React-Native. 