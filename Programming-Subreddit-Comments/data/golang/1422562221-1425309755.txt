This is fantastic! If only Kibana was going this route instead of node.js.
I've had persistant go processes running on a number of centos5/CloudLinux servers for a couple of years now with zero problems. Ymmv etc.
Added a Dockerfile. docker run --name gofana -d -v /mnt/my/dashboards:/app/dashboards -p 8080:8080 jwilder/gofana -graphite-url http://host:port
Reimplementing something that already exists in the standard library. When you say to yourself "That really ought to be common", double-check. It probably is there, it just may not be quite where you expected at first. This is especially true of concurrency constructs. Slightly more controversially, failing to specify interfaces in your functions and using them to [essentially drop privileges](http://www.jerf.org/iri/post/2923), which is perhaps not an antipattern per se, but is passing up a chance to make your code more easily testable and understandable with either a slight signature change or just a small rewrite. Thinking goroutines are free, instead of merely cheap. They are cheap, but they are still way more expensive than, say, a single integer addition. Similarly channels; they are cheap for all the things they do, but if you don't need all the things they do they are expensive relative to a simple mutex. 
My current learning project uses boltdb with encoding/gob for serialization, running on the built-in http.ListenAndServe() server. It's fast and a fun experience, but not as flexible as a normal db, being a simple embedded key-value store. Not really a recommendation, just throwing it out there.
boltdb looks great, I only know redis. Any idea if there's a way to compare two boltdb database and get the difference in a nice format?
Cool
Over use of modules. Its a pain. Suddenly you need to specify them everywhere, you have to import your own project all over the place. You end up with 'stuttering'. Ie buffer.Buffer. Your test code becomes harder to write especially if you need some shared helper functions since they then need to be put into another module that will pollute your project (since you can access other modules _test content). And the biggest issue. Import cycle errors. The only way to resolve is to totally separate implementation from interface with yet more modules (or drop the modules). Basically for most cases if you need a module, you would probably do better with a separate repo.
It seems like you are talking about 4x7x6 values and that you'll only ever have the last one and the current one. If the values are less than 1000 bytes in size, you are talking about a completely insignificant amount of space, and should store it in RAM.
Yep the space used is almost nothing, but if it's in RAM or in a file doesn't matter since speed nor space are important here. I'm just trying to see if there's that already exist for checking differences. (If not I'll probably end up with some structs)
Structs and JSON sounds good in this case. I was imagining the value count as being per-record, rather than overall.
Define your errors as part of the module: http://talks.golang.org/2014/readability.slide#13 
Thanks! I'm going to watch this. 
We've also used Go 1.2/1.3 in production with RHEL 5.3 and 5.11 for a year, without any problems.
Good call. Our eng.uservoice.com site just got a make over so I'm sure there are still some tweaks to make. We've made this change and it looks much nicer now.
I really dislike the aws.*Value (aws.StringValue, etc) implementation. It makes for messy implementation code and is used on fields regardless if they are nullable or not. Otherwise, this is a great move forward.
I like the spinner thing! How do people make these gifs of their console?
Yes! This has been my mantra all day long. aws.String this and aws.StringValue that. Besides that this library is phenomenal and incredibly well self documented. 
+1 Channel VS Mutex.
why is the build time being benched? `time (go build...)`
It's a pity it delivers only to US or Canada.
Yes he did.
https://golang.org/doc/effective_go.html#channels has the canonical example of channel-based semaphores, but /u/demitriousk got it about right.
I used Quicktime to do a screen recording, then imported it to Photoshop.
That solves an entirely different problem.
If you are not too attached to the format of the scraper configuration files themselves, the easiest thing to do is to simply write your configuration objects and then use the default JSON or XML serializations. One big difference between the two, incidentally, is that while everybody may love JSON, if you want heterogeneous lists of some interface, the XML encoding can do that. You may encounter that use case here. If you're still new, the easiest way to "discover" what the format looks like is to just bash together some configuration in source code, then emit it via JSON or XML and see how you like the looks. Get this all set up and it'll essentially be "deserialize &amp; call '.DoIt()'."
Have you looked at gopacket? In particular, look at the source for gopacket/layers for info on decoding packets (creating is similar but in reverse).
Before you start part II please spend 5 extra minutes for ensuring the code you post is somewhat quality. In particular: - please handle errors! - don't copy and paste - name things properly (if necessary run go lint &amp; go vet on your code) - compile regex once (make regexp.MustCompile global) After you applied all or part of the above your code could look like: http://play.golang.org/p/_5mzXw89Fb
With Google I always use "golang &lt;this&gt;" and that worked good so far. Maybe Google has special routines to better index its 'own projects' ;-) 
NO TIME. MUST BLOG. RE-READING BEFORE PUBLISHING IS FOR THE WEAK.
You missed the whole inner collection handling... u is undefined
To clarify, simply returning the result of an `errors.New`/`fmt.Errorf` call is fine if you don't expect the caller to *handle* the error, but just, say, log it (if they can't do anything about it anyway, the program doesn't need to understand the error). But if you want the caller to be able to understand the error and attempt to handle it, then you should provide a way to understand the error. This is commonly done with exported error variables like var ErrBadThingsHappened = errors.New("bad things happend") or custom types that implement the `error` interface (it has an `Error() string` method). type BadThingsError struct { message string Errorcode int } func (e BadThingsError) Error() string { return e.message } This is just one example of a custom error type, there are lots of ways to do it. The point is that [errors are values](https://blog.golang.org/errors-are-values); “you have the whole language at your disposal” as Rob Pike says. Dave Cheney has a bit of a different take on how to do errors, which is interesting (although I prefer using error types/variables): http://dave.cheney.net/2014/12/24/inspecting-errors. He also has a few other posts about error handling that are worth reading too.
whoops, thanks, it's hard to keep track of things when everything is made up. 
There is an awesome toy from ukrainian company ITStuff.com.ua: http://itstuff.com.ua/shop/gopher/ I've made some photos of this toy: http://habrastorage.org/files/58d/7bd/fd8/58d7bdfd86a7437bb9871645e56e7a62 http://hsto.org/files/424/dd5/fa0/424dd5fa03204d61af9dc18b9161a33f.jpg http://habrastorage.org/files/16c/021/f13/16c021f13b6143f4ad47e677abac6074 BTW, I find it much better then original Google's toy: http://imgur.com/4PVAUJD They do worldwide shipping, but looks like there is no enlgish version of their site yet. If anyone interested, I can assist to get this toy.
Thanks for the feedback! The reason clientPool maps to poolClient array is so that multiple clients can listen for same token.
I looked ahead to part 2. Having New(opts ...*Options) for the primary new func for the package will obviate having to pass in a nil, so var Exit, Enter = tracey.New() can be done. A bit more will need to be done to unpack the opts but whatever works for you.
you might find the benchmarking instructive as well. http://dave.cheney.net/2013/06/30/how-to-write-benchmarks-in-go
Cool pattern, though. :)
&gt; even though it would be really really nice in many specific situations. Like what? Genuinely curious.
gorp doesn't support foreign keys and relations, you should use GORM: https://github.com/jinzhu/gorm
I know, but I have a full time job and other open source projects I maintain that requires my thoughts and time. A person can only do so much. Maybe you can pick up the cause for all of us? :) 
Thanks for cleaning that up. Part I was sort of intended to be rough around the edges (cop out, I know haha). I had posted this link after Part II was up :) Anyhow, I probably should be checking the error out of runtime.Callers(). And the reg-ex has been made global (thanks for that). As for the copy paste thing, I even had a little quip in the post about it. I appreciate your time in writing this, thank you muchly, you are awesome!
Documentation? What do i use it for and how do i use it!?!?
I just finished the first version of the tool yesterday, so at the moment the tool just generates the simplest form of the table driven test which tests that all the results of the function or method match expectations. &gt; how would one even want to do that? Right now the generated test functions are pretty simple and could easily be written by hand, but the generated functions can be improved overtime to provide better error messages based on output types. Some examples would be if an output of the function or method was : - A **struct** it could test that each field of the struct matches expectations and output errors for individual fields. - A **function** as the expected value you could provide it a table test and it would run those tests on the produced function and output proper test results. Again you can code all this each time, but it begins to become cumbersome at some point. The idea here is simple you define a test table and it generates the tests for you.
1. Tooling 2. Excellent standard library 3. Statically linked binaries 4. Friendly community 5. Easy to write robust code - a piece of code I wrote as a Go newbie about 2 years ago is still working without maintenance today and being used by a largish team of users. Very satisfying.
Most of the time I've seen constants written in UpperCamelCase. So https://github.com/vhakulinen/push-server/blob/master/main.go#L15-16 would be PushReadTimeout and BufSize
I suggest running the race detector with GOMAXPROCS set to &gt;1. If it complains (I suspect it will), looks like it'd be easiest to create a new goroutine to serialize accesses to that map in an endless loop
Yes, I will make sure to do that as the package matures, but if someone wants to use it now here is an example of what it does at the moment. You define a table test, like this for example : package main //go:generate tab func DummyFunction(a, b int) (c, d, e int, f float64, err error) { // dummy function to test return } var ttDummyFunction = []struct { // inputs a, b int // ouputs c, d, e int f float64 err error }{ {1, 2, 5, 6, 7, 5.4, nil}, {1, 2, 5, 6, 7, 5.4, nil}, {1, 2, 5, 6, 7, 5.4, nil}, // and and on ... } And then you run go generate and it adds the table test underneath : package main //go:generate tab func DummyFunction(a, b int) (c, d, e int, f float64, err error) { // dummy function to test return } var ttDummyFunction = []struct { // inputs a, b int // ouputs c, d, e int f float64 err error }{ {1, 2, 5, 6, 7, 5.4, nil}, {1, 2, 5, 6, 7, 5.4, nil}, {1, 2, 5, 6, 7, 5.4, nil}, // and and on ... } // TestTTDummyFunction is an automatically generate table driven test for the // function DummyFunction using the tests defined in ttDummyFunction. func TestTTDummyFunction(t *testing.T) { for _, tt := range ttDummyFunction { c, d, e, f, err := DummyFunction(tt.a, tt.b) if tt.c != c { t.Errorf("expected %v, got %v\n", tt.c, c) } if tt.d != d { t.Errorf("expected %v, got %v\n", tt.d, d) } if tt.e != e { t.Errorf("expected %v, got %v\n", tt.e, e) } if tt.f != f { t.Errorf("expected %v, got %v\n", tt.f, f) } if tt.err != err { t.Errorf("expected %v, got %v\n", tt.err, err) } } }
With this version, you're accepting multiple Options despite only using one. You would have to pick one right? Like just use the first and throw any others away? Not having to pass nil is nice, but I'm not sure I like the trade off the misleading signature. Do you have opinions on that, or is there something I'm missing?
While it may be a nitpick to some, the implications are quite considerable. Go follows C++'s type deduction (using the C++ term) with it's `auto` implementation. This is quite different from true type inference where many people associate it with the Hindley–Milner type inference algorithm (or something similar) that Haskell is based on and Rust used to be somewhat based on, for example. While technically, the two terms are synonymous in definition, they lead to drastically different results. In Go and C++, it's pretty dumb (not to be taken negatively) type deduction. It's a simple lhs=typeof expr() type of thing. Whereas with something like Hindley-Milner, you can declare an empty hashtable (for example) and many lines down you can insert a string as a key and integer as a value, without specifying those types directly. The algorithm infers based on the *usage* of the types. Maybe there are more accurate terms to separate the two systems (weak inference vs strong inference?) instead of conflating the two.
* Writing tests way after the code is written. Writing tests after the fact is quite painful, especially when goroutine is involved. * Not thinking in multiplatform (darwin/linux) from the get go. Go environment inside Vagrant is dead simple, you should just do it. * Distrusting standard library and use 3rd party library instead. Regrets usually ensued not long after.
great point. I think Go wouldn't be able to do Hindley-Milner inference right now given the way you declare a map. I'd just call it simple or naive type inference.
When I get home I'll update the README. The gist of it is that you use it to query SemaphoreApp about your current projects, branches and builds. api := semaphore.NewSemaphore("auth token here") status, err := api.GetBranchStatus("project_hash", build_id) status will contain all the information that Semaphore returns about that [branch](https://godoc.org/github.com/jbydeley/go-semaphore#BranchStatus). When I get a bit more time, I'll be adding the ability to kick off new builds, stop builds, etc. 
Ah, the Go tour. Yes, I've done it and I loved it! I tried to write this code as go idiomatic as I could, so that was the main reason for the feedback call. And thanks again for pointing out those naming things :)
Sweet, thanks! Gonna try this when I find the time to do so :)
What's wrong with using your own functions? Perhaps it seems slightly less expressive than operator overloading, but I would argue that it's *more* expressive because it's explicitly clear what operation is taking place. When you use C++ libraries, you never know what an operator is doing, and it is a real issue in practice--people regularly make crazy uses of operators.
http://play.golang.org/p/UMKgI_NLwO Would do it, could also just write the file directly to the rw without http.ServeContent, there is also http.ServeFile
TL;DR I built a calendar client for Go that could use some contributor love. Should you be interested or are simply curious, click the link! I am building an app that relies heavily on the ability for users to schedule events. The only existing Go tools that allow one to build such an application are a combination of Google's OAuth API library and the Google's Calendar API. I found the library unnecessarily bloated and their API unbearably slow. Google clumps all of their API wrappers into one client, forcing a complete download when running go get for their client; this isn't ideal. In addition, Google has no incentive to improve the speed of their API, at least with regards to software as old as their calendar service. As a result, I went down the route of trying to create my own calendar solution. After a few days of research, I found a combination of CalDAV and iCalendar to be the most widely-adopted standard for communicating scheduling information with a server. To illustrate this point, Yahoo, Google and a few other services offer a CalDAV interface to store user scheduling data. So, I started building a client. The client I started is actually a combination of several modules that work together to send scheduling information to a remote CalDAV host. These modules include: - An HTTP Client (just a wrapper over Go's) - A WebDAV Client (lightweight, just enough to implement CalDAV on top) - A CalDAV Client (to manage iCalendar documents on the server) - An iCalendar (Un)Marshaler (to allow native manipulation of iCalendar components) Combined, these tools allow for a native interface to scheduling. Eventually, I plan to break these modules into individual projects. Granted, one will still require a server that actually manages the scheduling data but, given the prevalence of options, I opted to forego building such a server. The only features I plan to build are those that I need for my particular use-case. However, I understand this to project to currently be the only option for CalDAV and the most complete option for iCalendar native to Go. Hence, I've open-sourced it and seek assistance to ensure the codebase evolves in a way that helps the most people. So, should you be so compelled, I would greatly appreciate any bug reports or pull requests you would offer. Thanks in advance and hope you enjoy this Go library.
Thank you, this solution worked perfectly!
Oh wow, I am an idiot! The entire reason this wasn't working for me is because I didn't put the file extension in the url... Thank you so much for the answer! I really appreciate it and hope I didn't waste your time with my previous comment.
If somebody felt their time was being wasted, they won't waste it commenting. (Unless they just want a reason to complain, but that's not the case with sh41.) For future reference, here is a simple middleware that lets you serve clean (extensionless) URLs: https://github.com/mholt/caddy/blob/master/middleware/extensionless/extensionless.go Here's how you might use it: http://play.golang.org/p/75XpNP4pUs
I actually quite prefer the general idea behind centralized package managers like PyPi and npm, though these have some implementation-specific problems of their own. The source location becomes totally irrelevant. It doesn't matter whether a library's source is hosted on GitHub or Bitbucket or whatever. You are always going to be able to `pip install` it from the central repository. Go's model locks you in completely. Imagine you have a library with thousands of users and want to migrate it from GitHub to Bitbucket. You are going to send your users through a world of hurt to do that. I think requiring the version to be explicit is a good thing, and that semantic versioning goes a long way towards making this non-painful. Versions exist whether your package manager acknowledges them or not, so making them explicit does not add incidental complexity. Downsides of central repositories: availability, mutability (this exists through Go's model, too). These can be solved through mirrors and by implementing immutable central repositories. Clojars, for example, does not let you change a version once you've uploaded it (unless you append SNAPSHOT to the end of the version name).
I was thinking Options a bit differently from how I'd do this after a and a second look its not exact as I intended: Define a type Option. type Option func(*Options) error Then you have, New(opts ...*Option) Then you have a configuration step that generates the Options based on whatever number of Option funcs are provided e.g. YourOptions := &amp;Options{} // or whatever you would want to generate a default Options struct for _, opt := range opts { opt(YourOptions) } and you'd have you options for whatever you want to put into For example, DisableNesting create a func: func DisableNesting(disable bool) Option { return func(o *Options) error { o.DisableNesting = disable return nil // or do whatever error checking you please } } [turns out to be an incredibly useful(to me at least) pattern for configuration](https://github.com/thrisp/flotilla/blob/master/configuration.go) I went searching for the links I learned this pattern from and they're both dead...hmm, its not an original solution to configuration in Go. Some may want users to create and pass in options structs, or random strings, or whatever, but configuration by function is useful linking default &amp; user specified options in a composable way. 
See my answer to blaze816.
That's really cool. I'm going to have to experiment with this pattern, I could see a lot of cool possibilities. I did some googling and came across this article which discusses the pattern: http://commandcenter.blogspot.com.au/2014/01/self-referential-functions-and-design.html
Updated README with installation and usage documentation. 
I agree. I really like the Cargo package manager that was based on good parts of both bundler and npm. Even when they released the alpha version, it just worked. Having reproducible builds is extremely important. It also has an immutable registry. You cannot overwrite or delete a previous version. In the future, it'll bare you from introducing a breaking change without bumping the major version, adhering to semver. I hope Go acknowledges that its package and dependency story isn't what it should be. I don't believe vendoring is the solution.
So many things! But the tooling and standard library are really top notch. "Language Design in the Service of Software Engineering"
Are you looking for a static processor of some kind or do you have all of the epub internals and you just need to package them up? If it's the latter, you probably just need [archive/zip](http://golang.org/pkg/archive/zip/).
No worries, I'm glad to be helpful! :)
It definitely was and its a much cleaner way than I was looking at previously :)
agree with both you guys actually, but Go is the "least bad" for me because package managers end up being a SPOF, and something gets compromised. I have a bunch of experience in n the JVM world, for example. There, the Maven central repository is probably the most widely used, but there's still fragmentation (Bintray for example) and some staging services (Sonatype, one of the biggest ones, included) have caved on immutable releases. They let you manually delete a release version and replace with a new one, effectively mutating an immutable release. Go is the least bad because it doesn't try to guarantee anything - everything in that library is off of HEAD on that repo. Agree that it'd be great for someone to build a better solution for packaging and dependency mgmt in Go, and I think the "Go Way" can guide the community to the right thing, but for now at least vendoring follows the principle of least surprise.
Thanks for your work on the library. I think that was reasonable criticism by the other guy and your response was pretty illuminating. You got a little aggressive at the end though, like criticism of something a guy gets for free shouldn't be allowed.
Great thanks. Good to see this is part of golangs tools.
Interesting pattern actually, I think I like this usage in the caller the most: foo.Option(pkg.X(3), pkg.Y("HELLO")) I might have to steal this for my trace code as well. Thanks for all the pointers! 
Any particular reason why under 18s are not allowed?
I dealt with a similar problem for page handlers and came up with a working solution. Define a global scraper factory map[string]ScraperFactory in func init() on each go file that you define a scrapeTask in, add the appropriate factory method to the global list with the key used in the config file when you start your program, the list of factories will be populated immediately in the init calls, and you can just rip through your config and hand the factories the section they need to build the scraper example: scrape.go: func init(){ globalList["reddit"]=redditFactory globalList["facebook"]=facebookFactory } func redditFactory(configStuff string) ScrapeTask{ //eat the config and make the scraper } func facebookFactory(configStuff string) ScrapeTask{ //eat the config and make the scraper } main.go: type ScraperFactory func(string)ScrapeTask globalList := make(map[string]ScraperFactory) func main(){ //load the config //iterate the sections and grab the name factory = globalList[sectionName] scraper = factory(sectionConfig) go scraper.Scrape() } hope this makes sense.
If I try img.Pix[0] I get img.Pix undefined (type image.Image has no field or method Pix)
You'll need to assert the return value of `png.Decode` into the `Paletted` type, e.g `pi, ok := img.(Paletted)` (or maybe `PalettedImage`?) As `png.Decode` can return a variety of types, a type switch might be more suitable if you also care about other image formats.
Aaaah, thank you! This worked img, _ := png.Decode(file) pic, _ := img.(image.PalettedImage) fmt.Println(pic.ColorIndexAt(x, y))
Take a look at the structure generated by pandoc, then re-create in Go (or simply call from Go if you can live with less purist setup). Also, in my experience, take time to get to know pandoc, the parameters are less than clear at times so took a couple of hours fiddling before I got correct output
I had been looking for a similar post for sometime now, would like to hear from Sysadmins, DevOps, NetworkOps who are actively using Go to solve their day to day problems and any road blocks they might be facing, if any ?
I really hate writing so many for loops, my god. Also passing around `interface{}` everywhere just throws away virtually all type safety. I've been doing "DevOps" for years now with Ruby and it's so awesome that it has list comprehensions, which go lacks. It's so much better to write `.inject(&amp;:+)`, than expand into a for loop like you have to with go, or extract a single field out of an array of objects with `.map`. Go just doesn't have this stuff. It's really nice to be able to use things like `.select`, `.reject`, `.any?`, `.all?`, `.detect`, etc. Also, I really like pattern matching &amp; destructuring (from Scala, Rust, other languages), Option types, Result types. None of which go has. I hate that most stuff in go is a statement, not an expression, which means you can't write `x = case y; something; else something_else; end` Importing modules using github or google code URLs is extremely idiotic. I think about the only things I personally like about go are channels, goroutines, and static compilation. Almost everything else in go is extremely tedious and extremely verbose. The more I use it the more I am annoyed by it. I'm not a language designer, nor am I a a theorist, i just want to make things go. So this is all very experiential and opinion :) 
Has now been changed.
I don't know of any projects like what you describe in Go, however they definitely exist in other languages. Any particular reason you want to do this in Go?
also that adding $GOPATH/bin to the system $PATH allows you to run stuff that you go-getted (like goconvey)
&gt;Imagine you have a library with thousands of users and want to migrate it from GitHub to Bitbucket. You are going to send your users through a world of hurt to do that. It wouldn't be *that* bad, although it would be a bit annoying. However, if you want to avoid this type of problem, simply set up a vanity import path on your own domain—then you can always point it at whatever repo you want to.
&gt; _Rich Go_ is a library to enrich the Go (golang) standard library. &gt; For now it contains only [about 50 lines of code that provide] a more comfortable to use version of regexp. I added the bracketed text, but it's accurate. I'd really suggest that you first write the code, maybe release it as several little libraries, and only worry about publicly proclaiming a unifying project that will "enrich the standard library" when you've got the ability to back that statement with something more than 50 lines of code. I say this not because anybody else is going to be disappointed by the description, but because _you_ are headed for disappointment from the looks of it.
So is it a case that once i run "go install" and it out the exe in bin, I can just move it back to my project folder or am I doing it wrong if I do that.
If you run go build, it will create the exe in the project folder. If you run go install, it will create the exe in the \workspace\bin folder.
There was a thread yesterday on this exact topic on the Go Nuts mailing list: https://groups.google.com/forum/#!topic/golang-nuts/o4R2HyXopZA A guy that was taking up a sysadmin type job and wondering how well Go will work in that environment, lots of great responses.
Good info, thanks for the link
Looks like it works now! Thanks!
I think it's important to look at readability as something that first helps you process the coding blocks that make up the loops and functions and variable definitions and so on, but the second phase of the term is all about the ease with which one can read code and understand the logic flow. Go is boring and that's why it's solid. I'm not saying I love the syntax, but I do love how quickly I can read and understand code I knew nothing about just a moment ago. There's a lot of value in knowing that most applications will never surpass a certain level of complexity because the language encourages simpler solutions. 
Nicely put, thanks for your input
Code readability is highly subjective. Regardless of the language you are working in, readability is highly dependent on whether your project has conventions and uses them strictly. Nothing is hard to read than code where conventions aren't followed. Picking the right language only helps you to a small extent.
Readability *is* very important and actually Go's "boringness" works in it's favour sometimes, and sometimes not. I am going to compare it with Scala, as they're interesting to compare. Boilerplate is noise. With time programmers grow to ignore it but it's still something to overcome. I would argue Go has a lot more boilerplate and "noise" than good scala. With scala you have a lot of helpful abstractions over common computations such as concurrency, "nullness", errors, etc. The collections library is far more expressive than Go. However, it's not all good. With Scala there are many, many ways to solve problems. This is often Scala's downfall on large teams because you will find a myriad of styles that are very different. "Boring" OO? FP? Typeclasses? Actor systems? You can find so much variety. This *hurts* readability so much. With Go, there isn't much room for creativity because it simply lacks the features of Scala. Most Go code looks the same, which is really good for readability
I'm sure it does, but for me the magic bit made the learning curve much steeper than necessary. I must not have been the only one since the author reneged.
I'm a big fan of the code generation work being done right now. I don't know if I've seen an optimal solution yet, but the beauty of go generate is that these projects don't need to be widely used to be useful.
Author here. Thanks @cryp7ix for posting this. Some of you may remember I shared this repo here not too long ago but had to pull it suddenly due to some internal reasons. I am able to release it again (albeit with some functionality removed, just for now I hope). The good thing is during this time we improved the performance of the parser by almost 50%, from averaging 85K MPS to over 125K MPS on a single i7 2.8Ghz core. Using two cores we achieved over 175K MPS for mixed size messages. Pretty certain this is going to stay now. Apologies for pulling the earlier version without notice. [edit] oh Go Patriots!
I have no perspective of a decent test results. So would you say the following are good results. I do not want to use Reactjs, if it means that all the website's operations will be slower due to the use of the of a Javascript interpreter for Go. BenchmarkRender1 100 17128739 ns/op BenchmarkRender5 50 47324904 ns/op BenchmarkRender10 20 79839996 ns/op BenchmarkRender20 10 164226676 ns/op BenchmarkRender50 2 612836671 ns/op BenchmarkRender100 1 1777275883 ns/op BenchmarkRender200 1 4190131936 ns/op BenchmarkRender500 1 20789000942 ns/op ok github.com/101loops/go-reactjs 39.314s
&gt; your project has conventions It's better if the language (as opposed to the project) has strong conventions/enforced, then anyone can pick up the code much faster, subjectivity is reduced. 
I may be looking into this more soon so I will update you with anything I find. 
We do it at Codecademy to render our learning interface (http://codecademy.com/learn/make-a-rails-app/resume). We don't actually use Go, but you could because it's just an HTTP interface to a node server that runs locally on the box. We pass a payload (component name, props) which returns the rendered HTML. Then we just hit that with Ruby's HTTP stdlib to get it into Rails views. Since it's just hitting 127.0.0.1 it's pretty fast.
A [trivial test](http://pastebin.com/BHFUmZBs) using your example input isn't exhibiting that behavior at all...
The Go Challenge site is now up - http://golang-challenge.com/
I'm not using the "html/template" package. I was using golang's "golang.org/x/net/html" package to parse the html. Link: https://www.godoc.org/golang.org/x/net/html
I can reproduce this behavior with your sample code. It appears it's due to the way x/net/html tokenizes the html and attempts to return a "well-formed" tree. The documentation notes that Render (and parse) will return something similar to the original tree but not necessarily an exact clone. Is there an issue with the html coming back like that with what you are working on? 
It's ok. I figured that's what happened. Easy to do
I'm just using YCM +vim-go. 
`export CDPATH=.:$GOPATH/src/code.google.com/p:$GOPATH/src/github.com:$GOPATH/src/golang.org/x`
This is true, but even if the language enforces some conventions (like Go does), other conventions (like those of naming) can only be enforced by languages in a very limited way and require discipline by the programmers.
Go is opinionated. If you look at languages like Swift, C#/F#, Scala or C++: Their creators throw more and more stuff into the languages, since they seem to have no idea at all what their languages should be. So they all develop into that huge bloatware that is hard to understand, hard to learn, hard to remember, hard to maintain, hard to read. For that reason i like SML or Haskell too.
I have a few on bitbucket. It's not bad.
If you aren't on Mac OSX there is a pretty good Dash clone out there: [Zeal](http://zealdocs.org/) (Linux / Windows). It is good, but I use just on very rare occasions, like when I'm on a train.
I tried building from master the other day on a new machine and it wasn't very user friendly. I know it's not released yet, but I hope they come up with better ux than "install go 1.4 first dummy. " Can they bundle a bootstrapping go binary for each platform or something like that?
I do have some. They go into `~/src/bitbucket.org/…`, etc.
go is awesome, it makes me cry when ever I need to write java...
I found this boilerplate which solved my problem: https://github.com/horrido/acme3
Thanks !
Great ! But links doesn't work.
Original author of the post here - I hadn't spotted devdocs before. Looks nice!
You're right! Apparently I've got cached old version and have no offline tab visible: https://i.imgur.com/WJ0FjF0.png.
Thanks for the information. The fact it cached old version was confusing for me. Still working fuzzy search is what I miss there the most.
Thanks, an other version with a Map and runes.
Thanks for your answer &gt; Appending to the output on every loop through the string is slow. A map is better? &gt; Searching a string to compute letterToCrypt - 'a' is slow. Use math. ok 
I was looking forward to checking this out. Unfortunately there are a number of barriers that make anything beyond perusing the source code difficult. * It is not "go gettable" which means no executable in the GOPATH/bin directory. * Installation requires downloading the ZIPed version, then moving the acme3-master directory GOPATH/src and renaming it to acme3. * To build with Go 1.4 a source code change (an import that still used code.google.com...) is required. * The SQLite3 driver import requires a gcc compiler. * To install a gcc compiler requires (at least on my Windows desktop dev system) installing MingGW. * After all that is done I get "cc1.exe: sorry, unimplemented: 64-bit mode not compiled in. I'm sure that means that I didn't select the correct options among the dozens of options available when installing MingGW. There probably isn't a simple solution for users without gcc already properly installed for their dev system. All that said, your "acme2" project was helpful when I was getting started with Beego. I thank you for that. 
I've looked at a few of these and have mixed opinions. I generally prefer the vending route as it leads to the repository being buildable from any checkout without internet access. I do like the declaration of what the dependencies are to be up front though.
Try Gradle sometime.
Had a brief look. A readme would be nice. Will look at the code properly later.
Built in race condition testing is awesome. Does anyone have any experience with how well it works?
Why not both? Android needs more go code, and it's not bad since 1.4
Try doing calculations with quaternions in connection with 3D graphics. The lack of operator overloading makes this extremely cumbersome.
Also, no integration with an editor. With Dash, for example, there is a Sublime Text plugin where pressing ctrl+h will search Dash for the word currently under the cursor. You can also have it pull docs from godoc.org.
I use it a lot. It works well if your test exercises some racy code. I don't believe it can detect code paths that could be racy but aren't exercised.
Use [the goapp tool](http://blog.golang.org/appengine-dec2013). The "go serve" command automatically reloads source files when you make changes.
acme project is not mine, I just linked it. the author is Richard Eng: https://medium.com/@richardeng
I was just taking a closer look at the net/html source and felt that I should note that the block I linked before doesn't affect the output you got. Those newlines are included because they are TextNodes preserved from the original parsing. The newlines that are stripped before the head element are removed during the [parsing](https://github.com/golang/net/blob/master/html/parse.go#L523)
Dealing with pip and virtualenv is even worse. I like Python but damn is dealing with this is hard.
Your generated code creates a new map of the static data for every Marshal/Unmarshal, you should look into stringer's source code.
That *would* be nice, or embeddable go.
For building small apps, I think the app engine is still easier and lower mental model.
Scaling via a compiled language is nothing new. It's case specific so pick the right tool for the job.
I was just about to post the same thing. I saw this post over at the register. http://www.theregister.co.uk/2015/02/02/aws_going_googles_way/
this is my simple project (https://github.com/pyk/automata/blob/dev/main.go) it implement basic `GET` and `POST` request on `postgres` maybe you can learn from it . if you have any question let me know! :)
I dunno. Pip is a pretty good package manager. I still haven't figured out how to do this in Go besides just checking all my dependencies in. Fortunately, I haven't had to use different versions of the same package between projects yet. 
or you know `godoc -http :8080`
Thanks. I'll send my feedback directly to him. 
To be fair I didnt see the features it offers out of the box. Fair point.
To be fair: A phrase that often precedes a statement that is intended to offer a piece of information which the speaker feels is important to the conversation. This phrase often sounds pretentious when used, and will often be followed by a piece of obvious information that nobody wants to hear.
Thanks I'll fix it!
Missed opportunity to rename `WriteJson` to `JSON`.
Take a look at [clipperhouse/gen](http://clipperhouse.github.io/gen/). It's pretty complete and easy to extend.
Right, I think this is the only golint rule that I'm fighting a little bit. When the package is about things like JSON, URL, HTTP, API, ... You can very quickly feel like you're writing your code with caps lock. I don't want my code to yell at me :-) 
The HashTable is implemented with a HashTable: type HashTable struct { Table map[int]*list.List Size int Capacity int }
Let me throw my hat into the ring with [https://github.com/asim/go-micro](https://github.com/asim/go-micro)
&gt; The total savings was a few hundred dollars a month in server costs. This is ultimately what it comes down to. What is the programmer cost vs the server hire cost? How frequently does the code need to be updated/maintained? If never across hundreds of servers then real savings can be made by using a compiled language over a scripted language. But the issue isn't one of Go vs PHP. It is compiled vs scripted. And in most situations the programmer cost is the highest economic risk - which is why scripted languages are common among start-ups before their solution scales significantly-enough to justify higher-performance requirements.
Awesome thanks a lot. Will test it and also add some benchmarks test.
that explains why im always getting them ordered from small to big. but is there something like an reverse option? 
net/http
I don't think there is, sorry. At least, none I know of. You can either reverse-sort your keys on server and iterate through them, or use a [dirty CSS trick](http://jsfiddle.net/dufwuy71/) to make it look like the list is reversed.
Yeah. I thought the article it self covered things pretty accurately, as i listen to marco's podcast, but just the title was a bit misleading more than anything. 
unbounded chan;
Can you just change your data structure to better suit your needs? type Seasons []Season type Season struct { Show string Number int Episodes []Episode } type Episode struct { Name string Number int Season int } Then you can store your list of seasons as an ordered list, instead of an un-ordered one.
Revel makes me so sad inside, especially because people just FLOCK to it. edit this random text file to declare your routes - full stop.
I ought to disagree. The packages tailored to the specific needs have the right to life. Let me use httprouter as an example (although it does provide the http.Handler interface, it's just a useless appendage).
This is awesome! Your code is very easy to follow for someone who has never looked at path tracer source code before. I'm so disappointed that your HN story didn't make front page--it totally should have. 
That's good to hear - this is my first foray into the world of Go. I like it a lot! HN is a weird place.
Yup, this is it. This is the final push I needed to finally start writing Go. 
Very well done! Looking forward to spending time with the code so I can learn path tracing.
I feel that once the APIs are public, they should never be renamed ever :)
I can understand. But people have different preferences/requirements, sometimes you want more control and deeper understanding of things, at other times, you just want to do things faster and learn as you go forward. I do not see any issues with any of these approaches.
A mix between x/net/context, net/http, and NSQ for distributed stuff 
httprouter is probably a terrible example to your point, because httprouter.Router implements http.Handler and thus can be plugged into anything that accepts a http.Handler. ;-) I'm not saying that every package needs to accept http.Handlers to be plugged into them, but they at least must act as http.Handler so that they can be plugged into other objects and functions implementing http.Handler, such as http.ListenAndServe or http.ServeMux.
I really appreciate the help!
You lost me at "It is a bash script"
Tagged as "Go purist"
Tagged as "not cross platform compatible" unlike Go.
I know, bash isn't everybody's favourite shell, but it is likely the most widespread one. The reason why I have built nitrogen is that currently there are a lot of dependency managers for Go and you will likely end up installing most of them, while you could simply put a dependency manager script in your package and ship it with the required dependencies. However, nitrogen doesn't use any bash specific black magic (check the code), so you could happily use it with ksh by changing the first line with #!/usr/bin/env ksh
I think the objection is that the tool you created doesn't support Go everywhere (like Windows) easily. A tool created in Go matches it's target platform precisely. I don't think anyone is saying you're wrong or this is a bad idea, just that your implementation misses the mark by not including the same platforms that Go itself supports. Unless you're suggesting that Windows users install BASH/KSH (not impossible, but definitely unlikely).
There's already a program called [nitrogen](http://projects.l3ib.org/nitrogen/). It's fairly popular, too. 
Thank you for your feedback! I've built it mainly for my personal use, then I've thought that it could be useful to someone else, but I didn't considered the cross platform issue. I think that I could rewrite it in Go for cross platform compatibility. An user could then run it with 'go run'.
Awesome. Lead with that and you'll probably get less criticism. Awesome work!
Salt in the wound... *ouch*
I made a writeup of the Go runtime 1.3 memory allocator and garbage collector but held off on distributing it due to the rewrite of most of the components from .goc and .c to .go. I will revisit the document once the dust settles and distribute it then. The runtime code is relatively readable. Memory manager parallels TCMalloc in some respects.
Looks similar to glock (https://github.com/robfig/glock), which is written in Go.
I didn't know glock. However, I think that the projects are very different. Glock is a command line tool that you have to install, nitrogen is a script that you distribute with your package. For the portability issue, as I have already said, I'll try to rewrite nitrogen in Go.
&gt; This is the problem with trying to encode too much into the type system. It's more of a problem of trying to encode a problem in a way that the type system isn't at all equipped for. For instance in Haskell you could do: data NonEmptyList a = NonEmptyList a [a] data Tree = Branch String (NonEmptyList Tree) | Leaf String Can't do that in Go though.
Wait... It's a library? Sweet!
Oh, somehow I missed it in the Google Search result page. I was finding a different GoNative that was indicating that you or I misunderstood something pretty fundamental. sorry for the noise. You already hit all the highlights and then some. Didn't know about the TLS on OS X restriction.
:( Who spends time writing these kinds of tools without spending a tiny fraction of the time to explain what it provides over the half dozen tools that do the same thing?
I could have used this when I was making this little [command line util](https://github.com/ProfOak/cmdji). There was something that really troubled me regarding heterogeneous arrays in json. I found out that you need to use [interfaces](https://github.com/ProfOak/cmdji/blob/master/go-bindings/bindings.go#L27) and [how to parse them](https://github.com/ProfOak/cmdji/blob/master/go-bindings/bindings.go#L132). In my solution the parsing only works when you know things about your data. 
What advantages does this framework have over others that are currently available? Also the events section really doesn't make it clear what they'd be useful for.
Yes, disabling cgo will disable these features. 
How was the experience of developing it in Go?
Looks right. Keep in mind that if you want to build binaries without cgo, you need to disable CGO when building the standard library. Setting CGO_ENABLED=0 when building your application will do you no good if you built the standard library with cgo enabled.
to op: It is conceited to make statements that something is "blazing fast" without publicized measurements demonstrating that argument.
Not necessarily. There is a cgo version in all these cases but there is normally a pure go version as well as a backup. The cgo version might just be more efficient. If memory serves, package "net" used to need cgo but now works fine with the backups. I've got a feeling "os/user" still needs cgo. Basically, check for the things you need and use -a to make sure you're compiling everything without cgo.
half dozen is a very low estimate. There were a half dozen when I first started looking for them a year and a half ago. I have seen one or two posts like this a week since then it feels like.
I really like this, followed the docs but could not find the "tabular" view anywhere, any help / screenshot?
It was very easy, the implementation is very simple. I wrote everything in about two hours. I kept the logical part separated from the UI, so it was trivial to connect the UI part using gopherjs.
You can play it online here: http://dimiro1.github.io/gopong/
Even thou you could do that in Haskell. Personally I would think that is a terrible idea. It would be simpler to work as /u/natefinch mentioned. data Tree = Tree String [Tree]
And, by the way (related to what /u/IstNotMineISwear answers to, that's why I'm answering now), there is no problem with a branch having no subtrees; that doesn't make it equal to a leaf just because they have the same data. When you do, say, `type HTML string` in Go, you're encoding with the type system different stuff that have the same data. Perfectly fine. (It's probably not clear in the example case. Sorry for that.) Think leaf=file and branch=folder in a filesystem, or leaf=atom and branch=S-expression in a Lisp parser, or about more complex trees with more than two options for a node like Go's AST.
Ah, it's called "Console" now under /graph. We'll need to fix that.
If you have: * already read the README in the repository. * already read the answers that I gave to other users. And you are still asking yourself "Why should I use nitrogen instead of X?", the most simple and light-heartedly answer that I can give to you is: "You shouldn't". Go on with your tool of choice and happy hacking with Go. I don't mind, I promise you!
The example about Django (and probably Rails) is not a good example. Building anything nontrivial with Django's auth system either requires you to extend the User model and write your custom things on top, or install python-social-auth, djangorestframework-jwt or the myriad of other libraries. Auth is often very specific to your app or use case and needs tweaking. 
You think too much in the buzzwords that are spun off from "best practices" Just because you shouldn't rig your own crypto if you aren't trained in that field doesn't mean you can't touch anything crypto related. 
Taking users security seriously is no buzzword.
That's a good description of my work office.
I guess, it does not matter, whether authentication is in the core of go or not, what matters is whether community can decide a de facto solution. Lets say you develop a solution for authentication in go (not complete, but good enough), it gets wide community acceptance, it will be one de facto solution. For example [spring security](http://projects.spring.io/spring-security/) is a de facto standard for spring based apps, **but not the only solution**
Sorry, but the project you linked to falls into the second category I explained above. It looks like yet another half baked framework for go, with a homepage that returns 404. How can I take this seriously for a reliable authentication system?
I never wrote the authentication system must be in the std lib. All I said was that a proper authentication system in go seems to be missing, and there seem to be no urge in go community to build one, as they tend to follow golang minimalism of 'you do not need it'.
It seems that all that you'll need can be easily found here https://github.com/golang/crypto/blob/master/bcrypt/bcrypt.go#L84-L115 There is nothing wrong with implementing your own auth system, it's implementing your own crypto that's stupid.
I do agree with him that people shouldn't be doing either, though.
Go is a programming language. Django/Rails are web frameworks. I feel like you're comparing apples and oranges here. The Go language does not need a package for web-based authentication in its standard library, nor does the ecosystem need a mature third-party package to handle it. This is really an argument of convention versus configuration. The reason Django/Rails have authentication systems is because they are fully-featured web frameworks with predefined *conventions* as to what a user is and how to work with them. For instance, in Django, they rolled entire aspects of the framework for this purpose (Users, groups, permissions, sessions, etc.). However, outside of the context of a Django application their implementation is useless. As far as I know, Go does not have (or need) a flagship web framework like other languages. That alone makes writing a generic web authentication system a pointless endeavor. Roll it yourself for your specific needs because no two people are probably going to write their app the same way. I don't see this as bad practice, but rather just an inevitable consequence of the language choice. In short, Go is much more in the *configuration* territory than technologies you may be used to. Lastly, I don't know where you got your information about rolling your own authentication systems as being bad practice, but it's just not true. Just do a little research! While I do know other authentication methods exist, here's a nice [guide](https://crackstation.net/hashing-security.htm) on how to properly implement the popular password-based authentication.
To be fair, if you can't read up on the knowledge needed to write something to handle authentication in your application or website, how do you manage to code anything at all? It's not rocket science.
Yeah I agree that structure is probably easier to work with. 
Not even a MEAN dev, but I really enjoyed this and part 1. Easy to follow, and who doesn't like sloths?
Did someone mention sloths? Here's a random fact! The algae in a three-toed sloths fur supplements the diet of the sloth. This algae growth would not be possible without the help of a species of moth which lays eggs in the sloths fur! Woah!
Yes go is a very opinionated language. I can survive with it.
Django and Rails are fairly comprehensive frameworks which include everything under the sun so plugins know the ORM, the routing system, etc. Go's standard library offers functionality more similar to Sinatra and Flask. Basically, BYOS(tuff). If you want Django/Rails then the closest solution is probably Beego.
It would be nice if this could keep a metadata file to record all the dependencies and versions. I'm unsure if it would also be helpful to have this metadata file also be used by vend (if you want).
does anyone have a good naming convention for multiple-word package name? For example, priorityqueue seems to be a really long package name.
&gt; Though, what about if I have multiple packages that all rely on an import? Would I have a "lib" subfolder in each of those packages? If the packages are all part of the same project, they could share one `lib` folder, if you run the `vend init -r` ( recurse flag ) that is exactly what it will do.
I don't like the metadata approach, because metadata needs to be maintained and it can become out of sync. Also it is quite unnecessary, the version of the package is fully defined by the files you have in the directory and you can update packages individually as necessary as long you don't forget where you got them, and if you did I'm sure it would be easy to Google. 
Even better: export GOPATH=$HOME
This blog post is mandatory reading for every gopher. 
Well that's the thing. You could have used a fork and completely forgot which one. That's why I suggested having it create a metadata file so you have a history of this. Not necessarily that it uses the metadata file. Though, I can understand how it could get out of sync.
Ugh... I just realized that if you're keeping the original go-get sources around, then you gotta be careful not to mix imports.
[For the convenience of others, the valiant, if flawed, efforts of Google Translate](https://translate.google.com/translate?hl=en&amp;sl=ja&amp;tl=en&amp;u=http%3A%2F%2Fportal.nifty.com%2Fkiji%2F150203192687_1.htm). The language descriptions are pretty fun... &gt; It was developed by Google Inc., the new language that appeared in 2009. Parallel processing language ... alter ego killing method of a new generation with the inter-thread communication function by channel, Go! Everyone, I welcome you with open arms and open channels to /r/alter_ego_killing_method_of_a_new_generation !
I can see many of their points. 
This obsession with routing speed is silly, verging on stupid. It just needs to not be "too slow". (And to be fair, there were a few cases of that in the past.) If you aren't servicing 10,000 req/s on a single node, you don't need to worry about this stuff; if you are, I damned well hope you don't need a benchmark page on the internet to tell you how to solve your performance problems.
Yes, a nice integer math library in the standard lib would be nice. Otherwise...
i do this everywhere. It has the added benefit of putting your go binaries in ~/bin which is also in my $PATH. Win all around.
I will definitely consider this, I could at some point add an option for placing a simple, readable metadata file for each copied package that lists the remotes.
Uh. So it's *literally* a tug of war. 
&gt;Lastly, I don't know where you got your information about rolling your own authentication systems as being bad practice, but it's just not true. Just do a little research! While I do know other authentication methods exist, here's a nice [guide](https://crackstation.net/hashing-security.htm) on how to properly implement the popular password-based authentication. It's generally accepted that you shouldn't be writing your own cryptographic code, because there's a ton of work being put into hardening existing crypto libs that your own implementation almost certainly missed. Authentication is so heavily dependent on cryptography that it's usually a bad idea to roll your own authentication methods too. 
I never said that rails and django are secure, they are not. Yet, there is a huge man hour behind both of them. If they cannot make it secure, neither can a single developer, or a small team. &gt; keep your login system as simple as you can possibly get away with Go through this list again: http://stackoverflow.com/questions/549/the-definitive-guide-to-form-based-website-authentication Which items can you drop to reduce complexity? Can you drop forgot password or login throttling? These are not fancy features, if you do not have them in your authentication system, it is not complete, or secure. Remember, just because your authentication system has never been under attack, it does not mean that it is secure. 
For what it's worth, I just switched to disabling cgo for a service i launched a couple months ago per the recommendations of Go-Nuts folks. The system's DNS resolving library was getting stuck, with all DNS lookups for that domain piling up behind it. It's too early to tell if this fixed the issue. It seemed like the Go libc wrapper should have handled whatever was happening.
&gt; There are tons of tiny projects with exponentially better security that either of the ones you listed. Could you list some of them? My point of this post was to learn from projects like the ones you mentioned, which implement secure simple authentication systems in go.
&gt; As far as I know, Go does not have (or need) a flagship web framework like other languages. Why shouldn't Go have a flagship (well executed, well received) web framework? Would not having such a framework result in even wider acceptance of the language as a compiled, statically-typed alternative to Python or Ruby? If so, who in the Go community would see that as a bad thing? Just all me Mr. Curious Go Advocate. 
"pew" lol.
It is definitely an alter ego killing method. Of a new generation.
Given that Beego was my choice for a full stack web framework several months ago, the results are encouraging. It consistently ranks ahead of the very popular Gorilla routing-only solution and well ahead of Revel, the only other full stack solution included in the test... and perhaps the only other full stack solution period. That said, I agree that the obsession with routing speed seems misplaced. 
Too funny! As already mentioned, the Google Translate effort only adds to the fun. I know Go is very popular in China. I've never read anything as to why? Anyone know? 
Go seems to be doing fairly darn well -- and I think a non-trivial part of that is the opposition to magic (explicit costs, explicit code). When people flee Python and Ruby -- it is often because they hit some problem with Rails or another framework that was buried under 10 layers of magic. As Rob Pike said. "Less is exponentially more". For an example, you could have a fancy filter library for Go rather easily, Rob Pike wrote one just to prove it: https://github.com/robpike/filter **"[On filter] Having written it a couple of years ago, I haven't had occasion to use it once. Instead, I just use 'for' loops. You shouldn't use it either."**
Someone tried to explain it here: http://herman.asia/why-is-go-popular-in-china Not sure how accurate it all is but it's an interesting read.
Take a look at what I did [with this project](https://github.com/emadera52/sixty) under Database Setup. Your project will use a different configuration procedure, but the concept should be similar. This may not be the best solution, but it works. I've deployed to a Webfaction shared server and to a Digital Ocean droplet. For the latter I had to include and configure nginx since I wanted to use a CentOS server and as best I can tell Docker only supports Ubuntu. If you want your database populated with initial data of some sort, a simple export on your dev machine and an import on the target server should do the trick. 
Thanks for the link! An interesting read for sure. 
I have placed my bet on the ancient technology of "libraries" (in Golang terms, packages). Before frameworks were the norm, we used to use "libraries", they are simply bundles of functionality (and sometimes state) that do a job. You use the ones you want, you ignore the ones you don't -- you swap out the ones that don't work well. Frameworks are mostly just libraries (written by one group) + lots and lots of magic. This magic make the frameworks feel easier at the start, and makes them a nightmare once you get going. I've placed my bet on libraries. With implicit interfaces, I see a bright future for libraries in Go -- that will get better as people standardize on stuff like https://blog.golang.org/context
For more complex emails (attachments, several body versions) I would use their API instead ? http://www.socketlabs.com/api-reference/injection-api/#email_req Otherwise you have to construct the raw body yourself. 
Heh,I sure hope that a Web framework routing mechanism does not slow down every api call due to its "performance characteristics". 
It was me! I'm that someone :D Someone else also recently posted on the history of Go in China, which I think provides clearer answers than I did in my post: http://www.reddit.com/r/programming/comments/2s5c5n/why_is_golang_popular_in_china/co3oohy
Wow, It's like the new Pepsi! I hope, when we have ubiquitous AI, Google Translate still offers a "legacy" mode that falls back to today's tech. I get huge enjoyment from it's various efforts. EDIT: I also like Javascript's description: &gt;Only God of browser, battery included language that more than enough module is attached in the standard. Actually, no massage related to Java. Hachimenroppi, 
&gt; The only magic I've seen is the use of empty interfaces and reflection. Which breaks type safety, one of the MAJOR reasons you use a language like Go. Why do you considering using 12-15-20 independently written libraries more scary than using 12-15-20 libraries written by one group (probably composed of many individuals)? If you argue implicit quality, I bet that can be debunked. If you argue coordination, I would argue components that need to implicitly coordinate are "magical" and terrible. I think small independent pieces are higher quality because they are small and independent, they tackle one problem and focus on solving it well and not bleeding into other places, because they don't know what they will be put inside. The fact the components of frameworks tend to assume where they live, they create undocumented, unspecified expectations on the world... which leads to all sorts of confusing and interesting bugs. Additionally, if one of the components I use ends up being bad, I swap it out -- create an interface or re-code as applicable and continue on my merry way -- what happens if a framework takes a turn for the worse? Massive rewrite time! 
No its not. Its the exact same reasoning behind the 'bufio' package. If they have a rule for that one, they should've bloody well followed it for the net/url package as well.
&gt; Ordered maps? Nope Ordered map is a stupid idea.
priorityqueue seems like a fine name to me.
 * For the code part : you don't need to copy the code anymore, you need to build a binary on your machine, and copy only the binary to the remote server. Depending on how you wrote your program, you may need to shut down the running instance on the server, and execute your new version of the program. * For the configuration part : you will most probably have one (or more) config file next to your binary, to hold parameters like the IP of the MySQL server, the name of the database to use, etc ... You will need to copy these configuration files as well. * Extra assets : you may need some extra files, which are not go code, like for example html templates for your views, js/css files, etc ... You will also need to copy these files along with your binary. * The database : the database (be it MySQL, Redis, PgSQL, or whatever) is not part of the binary, so you will need to take action to set it up correctly. You may do this by hand (e.g : load a mysql dump to get you started, then run mysql scripts to apply updates ...), or look for a tool to help you organize this aspect (see for example goose : https://bitbucket.org/liamstask/goose) Depending on the libraries and framework you use to build your go application, some of these steps may be taken care of by the framework itself. For example, if you use revel, "revel package myapp" will build an archive, which will contain the binary, the conf file, and the templates (see https://revel.github.io/manual/deployment.html). If you find out you have many assets to handle, docker may be the right way : you can build and test a docker container with your go binary + assets + mysql ... on your machine, and then use docker to deploy this container on your remote server.
What else would you call it? Maybe uri.URL?
+1 for goose 
Or you could just do export GOBIN=$GOPATH/bin export PATH=$PATH:$GOBIN
openid is on it's way out,as less and less providers support it in favor of oauth.
&gt;&gt; Why shouldn't Go have a flagship (well executed, well received) web framework? Because it would be difficult.Go isn't as meta as python or ruby.It's difficult to write generic code with some magic. Furthermore,I don't think Go is made for classic websites,like rails or django.It's more for server infrastructure components or apis,in replacement for nodejs(or to write performant desktop programs, to manage deployement like Docker). I think people writing "blogs" or ecommerce frontends in go are making a mistake. The language is verbose and you have to be quite explicit each time you write something,no generic coding here.
I suspect packages such as util will find their place once the internal imports has been implemented. So utils has functions that pertain to the package and subpackages as a whole but without the publicly available api. 
Are you saying that go is not suitable for a large web app, because it has no generics? If this is about verbosity, java is more verbose.
I still do not get it. Why is that go is good for a web api that spits json, but not a web app that renders html?
I have another stupid idea. Ordered Arrays..... I hope you can detect sarcastic comments. 
Thanks for the info. As it worked out, having to learn a bit about ngnix was well worth the time spent. That said, learning a bit about docker deployment is high on my list of priorities. 
Good info. That api uses http I believe.
Site is down? 
In my specific experience, Beego has one primary author who has written most of the code. It has reached a level of stability that has allowed me to vendor his code. I've already made a couple of changes to modify the way certain HTTP errors are handled. His code is somewhat modular and I've learned a lot by simply looking at how http/net and other standard libraries have been integrated into the framework. Bottom line is that I'm comfortable with my decision to adopt the framework. YMMV. As I understand it, any package that provides the flexibility to process caller defined data type uses the magic of interface{}. I agree that the solution is terrible, bad and undesirable. Good luck interfacing with the libraries you'll need to implement a commercial web site without passing the dreaded empty interface as a parameter. A real world e-commerce web site has dozens of moving parts that MUST be coordinated. You can do it yourself by coordinating multiple libraries or you can find a framework that you trust. You prefer plan A, I prefer plan B. Not a problem. 
It may be difficult but it is being done. Go is promoted as a general purpose programming language. Based on questions on this forum, a lot of website developers are interested in the performance and scalability Go offers. A lot of high traffic websites (mostly in China) have been developed using Beego. I understand that Revel has also had some success with real world web sites. I'm working on [this low traffic website](http://60plusadventures.com/)** developed using Go and Beego. By using Go's template language I've avoided using JavaScript with one exception. Developer demand virtually assures that before long Go will have an accepted alternative to Rails/Django/whatever. ** I'm not a website developer. I realize that anyone who is could create a much more attractive site. 
[Original post](http://www.reddit.com/r/golang/comments/2updsa/path_tracing_in_go/)
Over on Hacker News someone just rendered a Gopher in Go... (https://news.ycombinator.com/item?id=9009554). But this one wins :)
Go has crypto in the stdlib. Password hashing is not rolling your own crypto.
Dependencies are hard. I don't agree that this “dead simple” approach is the best way to handle vendoring: * By just `go get`ting your dependencies, you're unable to exactly specify what version of the dependency you want to import. The Go authors are probably able to live with this restriction because they only ever import in-house dependencies. :) * You loose the revision history of your dependency … and even worse, you mix it with your own project's once you start updating the dependency. [Glide](http://technosophos.com/2014/09/22/how-glide-solves-go-vendoring.html) allows pinning specific revisions, checking out the sources using Git or Mercurial, and best of all: it allows forking (say, you want to fix a bug in one of the libraries you use, without waiting for upstream to accept it) external dependencies _without_ renaming the package imports. All of these features are crucial if you want to keep your sanity as your project grows, IMHO. Not exactly “dead simple”, I know.
You can continue working on the original or fork of the package in its designated location in the `GOPATH`. The revision history would remain there. When you want to update the package, simply copy it to your project's vend directory ( with the `-f` flag to overwrite ), for example would update your `uuid` package with the version you have in the `GOPATH`: vend cp -f code.google.com/p/go-uuid/uuid ./lib/uuid Regarding mixing revision history : &gt; ... and even worse, you mix it (revision history) with your own project's once you start updating the dependency. IMO changes in a project's dependency are pertinent to the project, so it is fine to store them along with the project.
https://gitorious.org/dongml
great trick.
The same concept can be applied to GOROOT for multiple versions, which I like much more than GVM. 
[Are you at my desk?!](http://imgur.com/dGKJ9h5)
I say we both win.
Currently a work in progress: https://github.com/rakyll/gometry
OpenID Connect leverages oauth2
i dont like this, why dont they make a cool logo and website like [Dart](https://www.dartlang.org/)
Is that just using the standard lib?
I'm the author of the benchmark suite and HttpRouter, and I agree. The original idea for the benchmark suite was to show how wasteful some of the frameworks were (many of them actually improved a lot!). HttpRouter was born since I needed something very lightweight for a project. I optimized it further since it was fun to do so and because I like high performance software. I sleep better when I know that I run efficient software ;-) I am glad if other people like it too and can make use of it. But there are very few cases where the router is actually the bottleneck in your application.
And how does that interact with the transitive dependencies? And what if some other package I import but don't want to vendor shares a dependency with one I'd like to? After a little thought I'm thinking that for anything that I have to either * vendor only dependencies such that I don't use parts of their API in my exported API * vendor everything. Am I missing something here?
Changed. Just for you. :)
And let me be clear I found your effort interesting and useful, and it had a great effect on the community, and I think you did a great thing. But we can collectively declare victory and move on. :)
FYI, there is also gopkg.in/godo.v1 (orchestration) and mgutz/goa (pipe and filters)
Depends on the use case, of course, but for engineering-type simulations just set the seed at the beginning / when you create the random number stream. Don't reseed it after that.
If this is your blog, what technology do you use for it?
`math/rand` is actually a very good random number generator. The problem is that it's very slow. You can write pure-Go RNGs that are a factor of two or three faster. You never reseed the RNG for Monte Carlo integration. It serves no purpose, since the bulk statistics at any point in the sequence are the same.
Not poster but that's definitely a [Ghost](https://ghost.org/) based blog.
I recently tried running a Go app with Docker on Beanstalk and I ran into a couple "gotchas": 1. You can only expose a single port per beanstalk deployment. 2. The port can only be a HTTP port. I was trying to build a streaming log parser, but the nginx implementation that Beanstalk uses only supports HTTP reverse proxy, not persistent TCP/IP connections. I'm hoping the EC2 Container Service removes these restrictions. 
Or at least something with fewer allocations. Awhile back, I did a text diff implementation for fun, and optimized it as heavily as I could without dipping into other languages or breaking the public API. It was astounding how much of the profile time was in allocation and garbage collection.
Using `crypto/rand` for something like this (other than perhaps as an initial PRNG seeding value) is bad. It's not needed, it's slower, and most importantly, depending on the system's implementation you'll drain/starve the systems entropy pool.
Examples?
Not sure what this means. Sorry, I can't speak to that.
Adding and multiplying integers, vectors, complex numbers and quaternions.
I was there when it happened during FOSDEM :P.
Actually the use of `sync` is unnecessary, since the channel is synchronised. A simpler, more idiomatic implementation is: func Pi(samples int) (pi float64) { goroutines := runtime.NumCPU() runtime.GOMAXPROCS(goroutines) results := make(chan float64) // no need to buffer the channel for i := 0; i &lt; goroutines; i++ { go func() { count := 0 n := samples / goroutines r := rand.New(rand.NewSource(time.Now().UnixNano())) // only seed it once for i := 0; i &lt; n; i++ { x := r.Float64() y := r.Float64() if (x*x + y*y) &lt; 1 { count++ } } results &lt;- float64(count) / float64(n) * 4 }() } for i := 0; i &lt; goroutines; i++ { pi += &lt;-results } return pi / float64(goroutines) }
Move `wg.Add(1)` outside the goroutine. If it's inside there's a race condition where you could reach `wg.Wait()` before any other goroutines are scheduled.
The `sort.Sort()` function is smarter than that. It switches to heap sort (in-place guaranteed O(n log n) with constant memory) if the recursion depth gets too large (2*ceil(lg(n+1))) and uses insertion sort for small subarrays. If you're interested in sorting, it's worth reading the paper ( http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.8162&amp;rep=rep1&amp;type=pdf ) and watching Bentley's talk at Google: https://www.youtube.com/watch?v=aMnn0Jq0J-E
i built a palette generation webapp in go + React.js: http://colores.manugarri.com Got to the top on Hacker news, and my tiny server handled the traffic for hours.
You don't. Just type "go build" inside the goblog directory and you'll have an goblog inside your goblog directory instead of your bin directory. Otherwise, you'll want to add your $GOPATH/bin to your $PATH if you haven't already and cd to your goblog directory and execute it as if it were a global binary.
Is there no relationship between predictability and distribution?
Yes, isn't that what he said? When you don't need to eliminate predictability, you don't have to use RNG, a good PRNG is enough. 
I'm not sure I agree that there is no relationship between predictability and distribution, at all. You are basically viewing statistically equal distribution of points as axiomatic with both sources for identical set sizes, and I'm not sure that's true due to the above. I do think math/random is acceptable for this application, but I think distribution is better with crypto random.
Awesome, thanks. That made it clear.
I think the technical term is Not Invented Here syndrome :) Give me a widely used package on GitHub over something cobbled together in-house on a deadline any day!
You're right and I removed the sync package from the post, thanks.
[x-post](https://www.reddit.com/r/NixOS/comments/2v6qgy/developing_in_golang_with_nix_package_manager/) from /r/NixOS
Adding a comment here as well, as I don't speak German and don't know if my comment was added correctly in his site. Overall this was an interesting article. I'm not sure I buy the authors premise that Go is an OO language, but he does show how it fulfills some of the necessary attributes. However the author left out half of the requirements for a call to be polymorphic. Go does allow the receiver of a message to invoke the correct behavior based on the receiver's type. He says nothing, however, about the ability of the sender to treat all "subclasses" as equivalent for the purposes of sending s message to an instance. Perhaps interfaces in Go allow this, but I don't know the language. At the very least, the article doesn't explain this point. Bab 
I say it's not, and that this is the best thing about it and the reason it's fast. But I'm just an idiot on reddit, what do I know?
I can confirm this. I was chief architect on a 30m line C++ system for many years. It was (and still is) a mission-critical system for many Fortune 500 companies. You have to be very careful about introducing dependencies into a codebase like that. My project was nearly sunk twice because the company owner (who had once been a programmer himself) insisted that we use two libraries we had no business using, but that he had become enamored with. The irony is that one of the projects he had worked on had died because of dependency on a UI library that had broken backward compatibility at some point leaving his system stranded on a decade-old unsupported version of that library. If you use a third party library you have to be prepared to completely take over development of that library if necessary, which means it had better be small and a very close match to what you really need. For the most part, Go's philosophies match up very well with the lessons I took away from that large project.
C++ yes, but I'm not so sure about Java. For example, http://benchmarksgame.alioth.debian.org/u64q/go.html (I agree that OO is unrelated)
The link within the post for ["Inner Pattern to mimic Method Overwriting in Go"](http://objectscape.blogspot.de/2013/09/inner-pattern-to-mimic-method.html) is a bit odd. The Mamal struct contains an Animal interface but it is never assigned to or used, instead he's passing around an Animal interface explicitly and having to redeclare the Act func for both Dog and Cat. [This is a bit cleaner](http://play.golang.org/p/Sv8znEvdjI), it uses the previously unused member interface Animal, and only has one Act func at the Mamal level which can dispatch generically to either Dog or Cat.
The more appropriate comparison is between Go and C. Wait, did you seriously just compare Java to C++ and Go? Java's on the same level as Python and C#. It doesn't go this deep, except possibly- perhaps- in a few special cases. At this depth, the fishes have headlights. It's hardly enough to have gills.
Great article. I don't know why people say Go isn't OO. I write object oriented Go programs all the time (and the OO features are language-supported; not just pattern or convention supported like trying to implement OO in C). In my opinion, inheritance was a mistake from the start and delegation and interface polymorphism are the most useful features of OOP. Automatic delegation as provided by Go is neat, but well written Java, C++, etc programs manually delegate all the time, so it's no big deal. I can't think of a time when I actually wanted inheritance and not just delegation. EDIT: it's worth noting that Go's automatic delegation and implicit interfaces make it the most convenient language for OO that I know of.
This is awesome. I have been meaning to look into docker but never really known why exactly i would want to use it. This is a very strong case for taking the extra time. 
certain parts of go standard library are total and utter crap.
I built a dynamic blog engine in Go. https://github.com/9uuso/vertigo It was a Go trending on a Github for a day.
I've previously said roughly the same thing about database/sql. But it's slowly getting better, and in 1.5 it might be a lot closer to the bare minimum a database layer should have.
haven't done extensive search for packages, but settled for https://github.com/Sirupsen/logrus and can't be happier 
It's not my project. You can contact Burcu, the author, and ask her. Her twitter account is twitter.com/rakyll .
Eh? I have seen exactly zero substantial go projects that weren't depending on a half dozen random github libraries.
Another way you can do this today ("manually") is to set up an AMI that has Docker installed. Then use a private Docker repo to host your built containers. Use a load balancer with an auto-scaling group to run your instances. The trick is to define a Launch Configuration that pulls the latest Docker image from your private repo via CloudInit (user data).
I don't see the point really. What you want is a good library for dealing with .xls and .xlsx files, that's the bit for office toolkit'ting you need in the majority of cases. Maybe a nice way of extracting text from Word documents would be good. 
I think the only issue I found with logrus was that you can't specify that you want the timezone to always be UTC. 
Events appear to be very actor model esque. Fire to kick off something and forget. Not really something one would need default in a web framework imo. 
OK, but what are you basing that assertion on? Edit: you said specific cases. OK, agreed.
I wrote this to support an app we're developing with multiple dependent services (identity, tokens, various db i/o components). Assuming your app &amp; services exploit env vars to determine run-state (production, testing), `gobox` let's you spin up and shutdown everything in a single terminal. I still want to improve logging of managed processes (right now, I'm just routing to os.Stdout/err), but it has proven really effective for helping us run integration tests and build out API workflows. Comments welcome!
A thousand times, yes. That was my favorite dotGo talk.
I am currently torn between thinking you have a point in there somewhere that I'd probably disagree with, or thinking that you used a Markov chain generator to generate that reply.
also, and this is purely opinion... I'm working on mac these days (was nix from 1999 to 2013) and I just find boot2docker annoying to work with. of course, i also dislike virtualenv, so i'm probably in the minority.
Huh? What shootout are you looking at? After you discard regex-dna, Go is generally faster. Go wins 7 of the 11 benchmarks; regex is it's only major loss.
The one where my eyes are in upside down. I was reading it backwards. I stand corrected. In which case I'll repeat the relevant bit of my comment here since I whacked my comment up above, regex is the least useful test since it test the regex implementation, which is often just FFI'd to one in C. Or, in this case, Go is losing because IIRC it uses the NDFA implementation, which has better O() performance but worse startup and simply performance. For the same code tests could easily be produced that would show Go winning by an arbitrary margin. (The regex test would be a lot more useful if it mandated a particular algorithm and that it had to be done in the language natively.)
Now, this may be an old java worry rising from my past to gnaw at me, but I wonder if there's a non-negligible performance impact to using this method. That said, I liberally use this approach myself. It's simple, succinct, and when I'm only doing a couple of endpoints or I'm prototyping, it's perfect. Edit: looking it over (had to get on my phone, Google docs blocked at work) I completely agree with the layout and function. You don't save any lines over your method, but you do gain proper response compression handling if you don't have that already handled. 
The code snippets in this are horrible.
Why not just use alice?
Compile on your own machine
The code in that article is ActionScript 3.0 which appears to support it, but Go does not. That's just the way the Go authors decided to implement things.
If you want to save a condition in `x` so that you can do `if x` then do so with something like: `x := (y &amp; 1) != 0`. Of course in this case just put the condition in the `if` statement.
OK, I think I was confused by reading about other programming languages which either didn't have a 'bool' type, or had a 'bool' type that was a subtype of int.
Since you need to call `gzip.Writer.Close` for the compression to work properly, I generally only do this when `w` is an `io.WriteCloser`; unfortunately, `http.ResponseWriter` isn't, and unlike `io.Reader`, there's no convenient way to turn an `io.Writer` into a `io.WriteCloser` with a noop Close method. I think you're suggesting something like this: var writer io.Writer = w if gzipOk { gzipper, err := gzip.NewWriter(...) if err != nil { return err } // we'd like to check the error from Close(), but it has to run // after the encode/write pipeline outside this; we either need // a closure with a named return var or we check gzipOk twice defer gzipper.Close() writer = gzipper } return json.NewEncoder(writer).Encode(i) So we either ignore the error from Close (bad), we make a NopCloser for `http.ReadWriter` (overkill), or we just repeat the encoding step with the different writers.
Thank you for the amazing work!
But, do your speakers work? ;)
It does have quite the performance impact when you create one gzip.Writer per request. This allocates (IIRC) about 1 MB of memory. With a steady amount of incoming requests (in my case, ~2000 per second), this can put quite a lot pressure on the GC. BTDT.
Yeah, I feel nowadays a lot of people think that everything out there on GitHub or posted here is like "production ready"(tm) I love this talk touching on the two subject here, not nessesarly needing to import a whole library but just copy needed parts, and all out there is not necessarly production grade so maybee read it and learn/use only the important stuff https://www.youtube.com/watch?v=yi5A3cK1LNA
wait what!?
Good point. Modified function to use global gzip writer that is reset, not created on each request.
Thank you for all the hard work!
You don't need to cast to bool there.
Int isn't bool. And what your trying to do can simplified as: if SomeVar % 2 == 0 { //even } else { // odd }
Why not?
A lot of things lack docs. 
Couple of things you can do: 1. Manually kill off old instances and let the auto-scaling group spin up new ones for you. 2. Use https://github.com/awslabs/aws-sdk-go to query instances and kill off the old ones. Just means your front-end &amp; back-end code must be able to handle version mismatches (e.g. old front-end instance can still talk to a new back-end instance).
+1 Using logrus with Papertrail works very well.
&gt; global gzip writer that is reset on each request This is asking for trouble. Two or more competing requests and your handler is fucked up. A pool of `gzip.Writer`s is a more suitable solution.
I have no idea what to do on Time to Jump.
You just need to find out when to deploy your chute, at what elevation. When you reverse engineer algorithm in simDrop it turns out the deploy_chute_at_evelation is given by: (400 - 0.1*x) * 4 + 0.1*x = 1000
Very interesting and cool! Great work!
Looks quite good. A little worried about the use of non idiomatic variable names (location_west -&gt; locationWest)
Knee jerk fix was dumb ass. Will look into the pool solution.
thanks - nice solution. Did you consider using the official docker golang images btw?
I think gdork1 is being facetious.
The idea is to improve the hackability of Office files and workflow. And to be able to come up with cool projects like Documize easier and faster ;).
I put this up a while back and had to pull it for some other reasons. Now I am able to post it again with a new and improved version. Completely written in Go, the Sequence Analyzer is all about helping system and network admins reduce the effort to parse log messages.
Cool idea, but the layout could benefit from being a bit more responsive. With a viewport size of 1213 x 700 the text on the right gets cut off, this is what I see http://i.imgur.com/1tJlaHQ.png I also want to echo the previous remark that it should probably use more idiomatic variable names.
In my eyes that bit of code does not make it any clearer to see what happens compared to 'normal' Go.
Nope it's not idiomatic. Idiomatic way would be: http://talks.golang.org/2012/concurrency.slide#35 Although, I haven't throughly reviewed the library, so there might be some underlying reasons they did it that way.
Those aren't arguments for an IDE, those are arguments for good refactoring, debugging, and build tooling. An IDE just bundles mediocre implementations of each tool together--a minor convenience at the cost of awesome discrete tools (which can usually be integrated with some configuration). Besides that fundamental misunderstanding, you're also placing *way* too much emphasis on debugging, particularly in so simple a language as Go. &gt; Though we pretend it to be true, code that compiles isn't guaranteed to work. No type system nor any compiler in the world will make that a reality. &gt; You will need debugging. fmt.Printlnis not debugging. Comments like these indicate that you're using a debugger to validate your code--this is what tests are for, and Go has awesome support for testing. If you wrote (good) unit tests, you wouldn't be debugging as much as you are. If you're following good testing practices, `println()` *is* more than adequate. &gt; I've worked with Go a couple of years now, I like it, but there are aspects I miss from before when I worked with C#, and they aren't languages features. Mostly in the tooling. Having worked in both languages, I'm guessing most of your sadness comes from trying to apply a Windows GUI workflow. Developing for Go on *nix is smooth and easy. If you're developing Go on Windows, I would recommend you try to apply a Unix workflow in the PowerShell environment (adapting as needed). To address your refactoring concerns, I find `sed -i "s/find/replace/g" *.go` to be adequate. Go is sufficiently simple that I would be a little surprised if dedicated refactoring tools didn't exist, though I've never felt a strong need. Unix and (vim + go plugins) have left me little to desire.
Can I use this to analyze any kind of log data? I have a relatively large system where I collect 2k to 8k log messages per second, all very application-specific. I even have them in a structured format (protobuf-encoded, so I can read them into structs). How much work do you think it would be to integrate this?
good call, I fixed the variable names
Good catch! Thanks for the screenshot. It works down to 1200px wide now: http://gocode.io/ Also, fixed the variable names.
Personally, I would prefer to just see a circuit breaking package in Go as unopinionated as possible. I don't like how opinionated the Java version of Hystrix is and would prefer that not to happen to Go too.
I admit, this one isn't a hard programming problem, but a hard math problem to reverse engineer the formula like hipone mentioned. If you get stuck, you can always copy the code to local and run it with outputting the actual landing spot, rather than just the success/fail message.
I wrote [one](https://github.com/rubyist/circuitbreaker) that tries to be as unopinionated and flexible as possible. It's been performing pretty well in production for a while now. 
A simple SMS gateway that uses GSM Modems to send SMS, can be deployed locally, supports multiple devices and provides API over HTTP just like internet based messaging gateways. // we both are full stack developers looking for full time jobs : [Omie](https://github.com/omie), [Madhur](https://github.com/madhurjain)
It kind of helps to actually have a field E:\Go\go32\src\github.com\haxpax\gosms\gsm.go:17: undefined: serial.ReadWriteFlushCloser 
You assume so much it's rather patronizing, but more importantly, you're *wrong*. What is an IDE if not a collection of tools? Its very name means that. And that is *exactly* my point. I do agree that good unit test coverage may reduce the need for debugging, but you're missing the point. Unit tests and debugging complement each other. They do not eliminate each other. If one counters debugging with unit testing, one demonstrates a significant (though common) misunderstanding. The name *debugging* does little to help eliminate this misunderstanding. Unit tests are there to show that code works as expected. Debugging is there to help you determine why it doesn't work as expected. You cannot assume that if you have good tests and sufficient test coverage you will never need debugging. In a perfect world where all code works, maybe, but we know that is not a reality. A lot of the time, code does *not* work, and when it doesn't, you want breakpoints you can toggle with a click, you want navigable stack tracers, movable instruction pointers, local variables you can explore like a tree, a REPL for evaluating expressions. Not `Println` or any of its ilk. Debugging may not be as essential as unit tests, but they do make development a lot more agreeable. In fact, if you have good tests, most of your debugging will be debugging your unit tests! For that matter, your guess was incorrect. I've been a Linux user since 1999, though for what that's worth there aren't any differences in workflows on any of the platforms Go supports, provided one installs the proper tools. `sed` for rename refactoring? *Really?* What about name collisions or type safety? There's `gofmt -r` and `gorename` and an Emacs plugin for both, but they aren't always that reliable. Close, but not quite there yet.
Level 11, Phone Home? Definitely a tricky one. Take a look at the difference between the send/receive/sendSignal functions. After you get it, you're on to the final level. Good luck!
From the readme I can't tell what this is for. Any hint?
This really gives me a great idea to build my my own SMS-sending app like Twilio. However, I need some help finding out what hardware I need. Do I need a GSM Modem? An SMS Gateway? I could find a way to have something sent from Amazon to where I live (Asia). Could you refer to me a link where I could purchase such a device? Thanks!
I guessed it right the first time :P
Author here. `encoding/binary` for structs gets nasty quickly in the real world, especially once a protocol includes one or more "length" fields for variable-width data: https://bochs.info/p/cxvm9 TLS is a good example, where a ClientHello message uses something like six length fields. This will require three simple nested structs in struc, and no extra code to pack/unpack: https://bochs.info/p/z2k3e I have a couple of nice features planned around embedding structs, like helper methods on structs that get called for pack/unpack (this opens the door to insanity like transparent JSON encoding without an extra manual step). Usability over performance does not require bad performance. I'm just trying to be transparent about my goals: 1. Usability 2. Performance Edit: Benchmark results against encoding/binary are in a couple of replies down. It's going to be very hard to get much faster without dropping to `unsafe` or code generation.
For people who just want a simple, recursive-by-default, cross-platform `ionotifywait`, I've added `github.com/cespare/reflex` to the basic tools I install for myself in my homedir on all my unix &amp; osx boxes. It's great.
 jsonStr, _ := json.Marshal(JiraSearchRequest{query, 0, fields}) Never throw away that last return value!
Transparency about your goals is great. Don't be afraid to put a nice link to that in the README.md, if not directly embed it; it immediately shows the idea more so than any text you currently have in your README. There's a fine line, but you're free to advocate for your library without necessarily slagging encoding/binary. I'd also suggest some benchmarking might be a good idea... not necessarily to brag about but just to make sure you're not going badly astray accidentally. (I don't have any specific concerns, this is just a general comment.) Finally, for this sort of a library, I'd expect 100% coverage. You might want to run (bash) t=$(tempfile); go test -coverprofile="$t" &amp;&amp; go tool cover -html="$t" &amp;&amp; unlink $t and have a looksee. Again, I have no _specific_ concerns from my casual glance, just a lot of years of experience telling me that you're virtually guaranteed to find some bugs in the red stuff no matter how careful you are.
Yeah, you are right, I will try to write my own packages instead of just refactoring old ones.
use vim-go in linux, way better.
This is superb quality stuff. Thanks for that, really addicting. Scored #4 so far :) Some fixes: - in level with lasers, lasers' ids are equal (1). probably should be [1,2,3,4,5,6,7] or so. - also in one of the latest levels, there is a typo in initial comment, something like 'Lucikly' or like that.
Awesome work! Mission 4: "** Well, good news and bad news. The bad news is it looks like ** you've already been spotted. The good news is you should ** be able to shut turns these cameras back to idle. **" I think the last sentence needs re-writing: "shut turns..." 
Good catch on both! I just updated both levels. Thanks for paying closer attention than I did :)
Thanks for catching that :) Just pushed the typo fix.
It would be good if you could implement receiving messages. Most Most services for receiving SMS messages cost a bit so using my own modem would be good.
So this is for low-volume (or whatever your carrier enforces) use, requires a GSM modem? Any other restrictions? This is pretty slick ; I've been looking for something like this for a while, thanks!
Looks nice. Two bits of feedback: 1) Use the standard struct-tag namespacing otherwise go vet will complain, and people will not be able to marshall to json and use your library with the same struct defn. See StructTag.Get in reflect. 2) I strongly encourage you to get rid of 'native' byte order. This is going to make all users of the package accidentally introduce an invisible platform-dependence. At the very least, don't make it default. Better yet, remove it, and let users choose to set it themselves if they want. Bonus, this will remove unsafe, and therefore will run on appengine and other restricted environments.
vim-go is *excellent*; don't know why you were downvoted. 
when you use an efficient editor, then all others become counter productive.There is a hierarchy to editors as there is a hierarchy to languages, some are just better than others.
Let me know if there is a better way to mock flags and stdin. I'm new to Go.
I'm not entirely convinced that it's that much of a cop out. I think there's certainly a lot to be learned from big IDEs, but that applies conversely, a lot of the big IDEs are big lumbering monstrosities, and would benefit from the agility of the editor-as-IDE style of thinking. I do think if someone has never used the debugging or other convenience facilities, ReSharper comes to mind, of these big IDEs, one has missed a lot on developer experience, and I don't think it condescending to assume so. As before, though, editors have features IDEs lack, so this statement applies conversely. That wasn't what I meant, though. Go doesn't attract Java/C#/C++ (or "IDE people" if you will) because the language isn't that attractive to them. The lack of familiar development environments only exacerbates this unattractiveness. The majority of new Go programmers come from dynamic languages. That said, I don't think the IDE users' voices are so silent. I have some anecdotes of people who snubbed Go because they needed "that solution explorer window and projects" and found Go wanting in that regard. It may have been unclear on what I meant, your assumption that I was talking about using debugging for code validation was rather odd. My comment was about the often false assumption in that imperative languages with strong static typing just work if they compile, though it is closer to actual reality in strongly typed functional languages due to the way their type systems are built, but languages like Go which allow nil values and mutable state cannot be validated via compilation, this assumption is wont, and incorrect. Everybody knows code must be validated through some method of testing. I have seen a lot of cases and arguments (in the mailing list, IRC, and blogs) where people quip about being so "safe" when they see their code compiling, and *this* is the assumption I attacked in my initial statement you quoted. It is not *completely* incorrect to assume some safety when a good compiler or linter is there to call you out on mistakes, but it is naïve, because no matter the quality of the compiler or the strictness of its type system, code will never work 100% properly. Unit tests will expose bugs, and when you do encounter them, they're much easier to diagnose with a graphical debugger than GDB, and this is where I find Go lacking.
&gt; github.com/cespare/reflex Thanks for the heads up, regarding cross-platform - this should also work where fsnotify works. I think I'll make it recursive-by-default as that's probably the typical option (and removes a config line).
I didn't have a .vim/bundle, I created it, then followed the instructions, but it never loads, `:h vim-go` always replies 'no help for vim-go'. Any idea? \*: I'm now using Vundle
You can just assign to os.Args in your test. See https://github.com/golang/go/blob/master/src/flag/flag_test.go#L320
Tested again with the newer version and now it works: Gathering server list and testing... 5 Closest responding servers: ------- ------------- --------------- ------------------ ----------------- ID Name Sponsor Distance (km) Latency (ms) ------- ------------- --------------- ------------------ ----------------- 0 Helsinki DNA Oy 15.81 2.02113ms 1 Helsinki Elisa Oyj 15.81 1.894296ms 2 Tallinn Starman AS 86.79 8.226132ms 3 Tallinn Telset AS 86.79 16.015774ms 4 Tallinn AS EMT 87.18 17.427155ms ------- ------------- --------------- ------------------ ----------------- Enter server ID for bandwidth test, or "quit" to exit ID&gt; 1 Latency: ▃▃█▁▃▁▁▁▃▃▁▁▁▁▃▁▁▁▁▃ 2ms avg 2ms median 5ms max 2ms min Download: 183.27 Mb/s Upload: 213.48 Mb/s
select works well for the timeout pattern, but in hystrix's case the fallback could be triggered for more failure conditions like the primary function returning an error or the circuit being in an unhealthy state. providing functions as parameters allows the library to execute the fallback for all these cases without needing additional code from the developer 
An editor that requires me to remove my hand from the keyboard every other time I type something is not fit for purpose.
the initial version of hystrix-go represented commands as structs which implemented an interface declaring Run and Fallback methods. it worked, and could be argued as "idiomatic", but usability sucked. since the methods needed to match the interface regardless of purpose, they returned an empty interface and required casting back to the type (you hoped) they actually returned. by switching to functions as parameters, it allows the devs to create closures around channels to maintain type safety. 
Did you follow the instructions for Pathogen? If that's the case, then you'll need to install the Pathogen plugin first.
I would expect both... select { case result := &lt;-request(): if result.Error { // handle error circuit.Fail("blah") } // success case &lt;-time.After(1 * time.Second): // timeout circuit.Timeout("blah") case &lt;-circuit.Closed("blah"): // broken } and... select { case result := &lt;-request(): if result.Error { // handle error circuit.Fail("blah") } // success case &lt;-circuit.Broken("blah", 1 * time.Second): // timeout } be doable. (Although, I haven't actually tried it... so it might be bad for GC or perf.)
Also, in the final tweet, the link is "http://operationgo.io", which seems to be incorrect.
What isn't? And why not? 
The reason I would do it that way is that I would probably give different error messages to the user. When I get a timeout, I will give a message -&gt; "things aren't accessible", on error -&gt; "something went wrong", circuit broken -&gt; "server is having trouble, please check after 30min". That's of course not always the case. What if the Error is simply "file not found"; i.e. should the circuit be broken for all errors? What if I have 3 concurrent requests and I need only one of them to succeed, discarding the rest? How would the call through the hystrix type look then? Basically, it depends... I'm definitely not saying that your approach is wrong. As usual, it depends what the purpose of the code is, what does it need to cover... etc. What I'm basically saying is that, this is probably how the "idiomatic" solution would look like... not that it's best for every situation.
When I started writing Go a few years back the first thing that really got me puzzled was the way encoding/binary worked. Coming from a C background I'd expect to binary.Read and binary.Write from and to structs and it should work just fine. In fact it does, but turns out to use reflection and is slow. I see most of you are still with this C/Python (pack/unpack) mindset for Go, which seems wrong. The way to pack/unpack structs in Go is in fact slightly different, and the encoding/binary package is not only great for that but also as fast as things can be. It's just different than what you're used. See for example how gopacket decodes a TCP packet from bytes (https://code.google.com/p/gopacket/source/browse/layers/tcp.go#148) and how it serializes a struct to bytes (https://code.google.com/p/gopacket/source/browse/layers/tcp.go#61). By no means I want to discourage your work but it's definitely unnecessary to have yet another binary encoder and decoder when the stdlib has a better one.
Hadn't realise I had to install pathogen. I just did, now it's all working. Thanks!!
A web tutorial, seriously?!
IMO, Qt is used for GUI not Go. Plus s lot of ugly python stuff. In short, its a mess.
Good call. Fixed it. And congrats on beating the game :)
&gt; By no means I want to discourage your work but it's definitely unnecessary to have yet another binary encoder and decoder when the stdlib has a better one. I couldn't disagree more. You linked to a method of decoding that requires a few things: 1. Define a struct. 2. Read the entire packet into a []byte, when you're already going to allocate a struct for it (note: struc does not currently allocate buffers on the heap while encoding or decoding, except for slice fields that would be unallocated). 3. Manually invoke `binary.BigEndian.PutUint*(bytes[offset:], struct.Field)` with hardcoded fields and byte offsets, for every entry you want to decode. (Can anyone say "off by one error"?) When I look at that code, all I can think is "I hope this is generated". I would not want to write that for every possible message. I'm implementing the X11 protocol, and writing manual decoders made me hate myself enough to start working on struc. My method of decoding: 1. Define a struct. I'd focus on code generation, but I don't need the extra performance in my current use-cases. I'm blocked on network / other things, not CPU/reflection. The best solution I've identified for my use case is a library that looks at my structs and figures out how to encode/decode them without any boilerplate code, so I made it. It's also worth noting I should be able to make things quite fast with `unsafe`. I can precompute memory offsets into a struct using reflect *once*, then the decode is just a switch statement casting offsets to pointers. I haven't tested the performance of this yet, but I think it might be competitive with a manual decode. I added a benchmark for manual decoding: BenchmarkEncode 1000000 1982 ns/op BenchmarkStdlibEncode 1000000 1857 ns/op BenchmarkManualEncode 5000000 301 ns/op BenchmarkDecode 1000000 1519 ns/op BenchmarkStdlibDecode 1000000 1788 ns/op BenchmarkManualDecode 20000000 92.6 ns/op From [the implementations](https://github.com/lunixbochs/struc/blob/1954a70bc20fbac64137edc842a834290b119da9/bench_test.go#L42), notice the code lengths from struc -&gt; binary/encoding -&gt; manual encoding. For what it's worth, if I wanted manual field encoding I'd probably rather see this: b := NewBinBuffer(29, binary.BigEndian) b.PutBytes(s.Test[:]) b.PutInt32(s.A) b.PutInt16(s.B) b.PutInt16(s.C) b.PutInt16(s.D) b.PutBytes(s.Test2[:]) b.PutInt32(s.Length) b.PutBytes(s.Data) Than this: tmp := make([]byte, 29) copy(tmp[0:5], s.Test[:]) order.PutUint32(tmp[5:9], uint32(s.A)) order.PutUint16(tmp[9:11], uint16(s.B)) order.PutUint16(tmp[11:13], uint16(s.C)) order.PutUint16(tmp[13:15], uint16(s.D)) copy(tmp[15:19], s.Test2[:]) order.PutUint32(tmp[19:23], uint32(s.Length)) copy(tmp[23:], s.Data) &gt; as fast as things can be I doubt it beats a pointer cast to decode the whole struct in place, or inlined generated code, or C/asm hand-creating Go structures, or some variants of unsafe trickery. The endianness indirection might also make it harder for the compiler to reason about inlining things.
Most of the time in graphical applications is spent waiting for user input anyway.
&gt; It's just not how others do pack/unpack in Go Cool! Let them suffer. The code you've linked is painful to read. If I can do it better for a low performance workload, great! That's what I'm aiming for! Once it's fleshed out a bit, if I can close the performance gap, even better. I don't disagree that other people are doing it differently from me, but I feel you're absolutely wrong about the status quo being better in *any way* than struc besides performance. &gt; and you're coming from a C mindset You don't need to tell me about me. I think the current way of doing things is outright wrong from a personal sanity perspective, regardless of my background. I've also shipped Go code in the past with your recommended way of encoding, for what it's worth.
It's not the same. In the example you just gave, you have an error object to inspect. With this framework, the error will most often be a nil pointer panic with a line number. You won't know if it's from "too many open files" or bad input from a user. I get the allure of this approach, but those error objects have important info in them. The verbosity of Go was off-putting to me at first, as I was coming from Java and Python, but after writing and shipping a complicated service in Go, and "accidentally" handling and reporting every possible error condition, I gotta say, the idiomatic approach is very useful. 
from your comment it appears you haven't read the README. the relevant error object is passed into the fallback function, and hystrix.Go returns a channel of errors to allow devs to inspect what went wrong. also, one of the primary purposes of this library is to react to all errors in the same way: providing a fallback which allows the application to remain available. 
Yes, even in text editor.
yes, the design is for all errors to trigger the fallback. an external service outage is one failure scenario, but deploying an upgrade to a 3rd party library which then starts returning errors is equivalent. the idea is to protect your application against any and all unexpected failures. the goal is not to provide an error message to the consumer, but a useful return value. in a netflix example, if there is a failure loading your personalized recommendations, they will return a static list of popular movies. your point about 3 requests racing is interesting. i imagine you could define the set of them as a single hystrix command and use a standard "3 goroutines sending to a shared channel" approach. hystrix could provide you with a timeout and health metrics for the grouped logical operation. func Get1From3() int { output := make(chan int) go func() { output &lt;- 1 }() go func() { output &lt;- 2 }() go func() { output &lt;- 3 }() return &lt;-output } result := make(chan int) errChan := hystrix.Go("3-race", func() error { result &lt;- Get1From3() return nil }, func(error) error { result &lt;- 0 return nil }) select { case r := &lt;-result: // :) case err := &lt;-errChan: // :( }
Okay, I got code completion working with Sublime Text 3 and GoSublime. It was a long walk, but these are the steps I had to follow: * Install [App Engine SDK for Go](https://cloud.google.com/appengine/downloads#Google_App_Engine_SDK_for_Go) * Install [Go](https://golang.org/doc/install) * Install [Sublime Text 3](http://www.sublimetext.com/3), [Package Control](https://packagecontrol.io/installation) and [GoSublime via Package Control](https://github.com/DisposaBoy/GoSublime) In GoSublime settings, I set "use_legacy_imports": true, "installsuffix": "appengine", "env": { "GOROOT": "C:\\ wherever you placed the SDK \\go_appengine\\goroot", "GOPATH": "C:\\Go" }, This did it for me. Hope this will be helpful to someone. 
Another point worth making about your approach - it's totally possible for you, or someone else, to write a code generation program (to be used with go generate) to write manual pack/unpack code for these structs, based on the same tag data. In effect, you're defining a standard that could be implemented with not just runtime reflection but prebuild-time code generation! It's potentially a more complex solution, and it's not worth the work for your current use cases (yet). But I bet you, dollars to donuts, people are going to fall in love with your library, and then feel a need for speed months after adopting it. Piloting the standard with a reflection-based implementation, and then someone creating a compatible follow-up based on code generation, seems like a beautiful path to me.
I don't want to give away too many hints :) Does this help with the `int` question though? http://stackoverflow.com/questions/6878590/the-maximum-value-for-an-int-type-in-go
A way that you could have changeable defaults, without global state interacting badly between packages, might be something like how XML structs can declare their tag name ([example](http://play.golang.org/p/HTzIluWMMS)). You wouldn't need for the solution to be quite so overwrought. struc.Endianness could be a struct{}, so that the value is always and *only* dependent on the field tag. You could also encourage people to use it as an "anonymous field": type Foo struct { struc.Endianness `struc:"big"` Thing string `struc:"..."` ... }
I hadn't read the README that closely. I did notice the examples throwing away and ignoring JSON unmarshaling, though. It looked like the goal was to use panics like exceptions. I also didn't look at the framework code, but imagine in the case of your examples, it would catch the panic, and return the underlying error to the error channel. In those examples, they'd be nil pointer errors, and you'd be throwing away the reasons that the values are nil. This framwork looks like it could be used with idiomatic Go error handling, where you're checking and returning every returned error object. I wouldn't be at all opposed to that. Edit: s/line/like/
I think it's super useful for interop. Good stuff.
Yep, it's incredibly easy to generate the "manual" pack/unpack code from my struct tags. This is something I've considered for the future. It would end up being like the raw -&gt; minified javascript pipeline, where it works with or without the compile step.
I actually really like and tried that concept already, but I ran into a problem (which I don't remember). I'll definitely look into it again. It's a great place to set any struct-wide config, like overflow behavior. I also have a hard requirement to be able to swap the endianness of an already-defined struct, as this is part of the X11 protocol (you specify on connect, eww).
Emacs can reach vim parity. But neither can be overshadowed by anything else. 
I am working on a terminal-based text editor like vim in go with rpc-based plugin system. PM if you want to work on it together.
I see it as an opportunity to get a collection of best practices and libs that can play well together. An opinionated, well thought out solution and structure that can be used for multiple projects could make it even easier to dig into new codebases that share the archetype. I'm interested in what comes of it. 
If you check the error from Scan, my guess is that it will tell you that you're trying to store `null` in an `int` or something along those lines. You can either use `*int` as the type of those `*_id` variables, use http://golang.org/pkg/database/sql/#NullInt64 or simply return an int in the query e.g. `0 as k_ele_id` instead of `NULL as k_ele_id`
Thing called "debouncer" is not a Go pattern, it came from NodeJS community. It was born from the failure of adapting to Go idiomatic solutions (context.Context from go.net repo) and migrating their solutions instead.
Nitpick, but kind of an important one: &gt; No callbacks. Will you lose performance? No. You can start parallel threads via goroutines – a concept explained here. You can even communicate between to independent threads via channels. Equating goroutines with threads is incorrect. Goroutines do not necessarily run in parallel and are not threads. They run on a thread, but the number of threads a Go process uses isn't the same as the number of goroutines. By default, where goroutines are concerned, Go processes are single-threaded (this can be adjusted, but whether you should will depend on the program -- [the FAQ](http://golang.org/doc/faq#Why_no_multi_CPU) has a couple entries on this). So, it's entirely possible that you could have a million goroutines and the runtime will multiplex them onto one thread as needed. Besides that, the author and others unfamiliar with this may want to check out Rob Pike's talk, [Concurrency is not parallelism](http://blog.golang.org/concurrency-is-not-parallelism). The distinction is fairly important, especially in how you view and use goroutines, I think. Edit: Also, because we ended up in a sort of interesting discussion on go-nuts on what a thread is, a side-note: when I say threads, I mean OS threads.
I spoke to Peter at the Go Gathering in London recently about this topic. At the risk of getting down-voted, I'll be candid... Every time you go to a regular Go meet-up we see the same thing (YMMV): - talks about the basics of Go - how easy it is to get into Go - Channels, Slices, Interfaces, Maps, Mux, Web frameworks That's all great if your intended audience is those that are new to or considering Go. How about a forum for the harder stuff around large codebases or service oriented architecture? Some of us would love to know the things that keep the likes of SoundCloud, Hailo and friends ticking over. They must have a tonne of learning and insight specific to Go application architectures, libraries and more. 
What about cgo?
I'm really glad to see this being discussed. I recently spent a long amount of time tracking down a performance deficit that turned out to be caused by the ... arguments of a never-used log.Fatalf() allocating some variables on the heap inside of a tight inner loop.
Well, the problem is that when you pass a pointer to cgo function, it's assumed to be an escaping pointer (I think). But it would be nice to see some kind of a way to specify whether it escapes or not. Because C functions use pointers much more often due to the lack of multiple return values. And therefore if you pass a pointer to a temporary object on the stack to a cgo function, it ends up on a heap, which is bad.
I would argue that introducing a semantic version system is better way to encourage your users to use the latest gorm than having no version. I would say it's a way to encourage new users to try it as well. When you use something like semantic versions, you are giving your users a strong promise about how they can expect updating to your latest code will go. This is an important thing to consider if you want to encourage rapid adoption. If a developer is worried that upgrading might break his project (which is already working), they have two options. 1) They can look through all the code changes that have happened in your project since they last updated, which can be a long process and requires familiarity with your code base. Most people that want to use a library, don't really want to have to do this every time they upgrade. 2)They can trust your version numbers to mean something and for you to take the time to understand what kind of change you are making to your code and how it will affect users. This is easy and works well because calculating the difference in version numbers is easy. This is why semantic versioning is so popular. Choosing to take and patch-level (0.0.x) change is an easy choice and most people will do it without needing to give it too much thought. The same is mostly true of minor-level (0.x.0) changes as well, but it is more of a prompt for a developer to be on the look out for new features. Most important obviously is the major-level (x.0.0) level version changes. This is a way to let your users know that you are making a change that could potentially break existing code. No one likes it when upgrading a library breaks code, but if that fact is well communicated it's not such a problem. By committing to a strong version system you are telling your users that you are taking their concerns seriously and that they can trust you. If your users trust you, they'll keep using your latest and greatest. 
No, that would break moving stacks and moving GC. It *has* to *always* escape when using cgo. PS: there are ways to mark a function as not escaping, and there are ways to hide pointers from escape analysis. They are used in the runtime, but you must not use them. 
Probably because they're starting a flamewar over a text editor. If vim works for somebody that's fine, but there's no need for a dismissive comment every time there's a thread about another text editor or IDE.
But it's not dismissive; it's the truth. 
Last time I tried it I got really confused by them wanting me to create a project structure that seemed to fight my gopath. This was probably 1.5 years ago. What does that story look like now?
Okay then. Thanks for clarification.
Is debugging supported yet? I could only get debugging working in the 0.9.16 alphas, but those don't properly see libs in my $GOPATH for things like code completion and go-to-declaration. So far I've had to hold off on using IntelliJ even though I love JetBrains IDEs. I have no doubt it will get there and it's great news they have assigned their own devs to the project. For now I've had to stick to Atom with Go-Plus and vim with vim-go to be productive.
making assumptions that panics are used like exceptions without reading the code in question hurts your ability to have a reasoned conversation about the library's approach to error handling. as you can see with a quick github search, hystrix-go does not use recover() and panics kill the process.
I'm not certain. I never got debugging working properly before. I just gave it a shot though and GDB launches... but doesn't hit my breakpoint and I get no application output, so not sure what happens. I'm really hoping that someone's able to add in support for [Delve](https://github.com/derekparker/delve/issues/3) in the future though.
People need to give more love to LiteIDE. It's pretty great, lean and fast. 
Indeed. And as the FAQ points out, the problem isn't with the commented out line as the playground links seem to indicate but with fail defined as `func fail() ([]byte, *customError)` instead of `func fail() ([]byte, error)` as it should be (the latter can still return `*customError` if it likes of course).
Wow, that's a big improvement over the previous alphas I've tried. It now properly detects go 1.4 paths and libraries, has snappy auto-completion. Well done JetBrains and community!
These slides are a bit glib about what is using CSP and what is using some other concurrency model. Whether messages are sent to a process or to a channel is quite relevant.
Thanks!
I don't know where that impression came from, Go is as suitable for creating applications that speak HTTP as any other main stream language. Depending in your style and your requirements people have written projects from the full service frameworks like beego and revel to smaller less frameworkie packages like martini, negroni and gin. Don't mistake the cultural aversion to the word 'framework' in the Go community for an indication that web applications can not or should not be written in Go.
np. I used pathogen for an hour or two, and somebody at work told me about vundle, using that now. Thanks for vim-go btw.
Not having an example to copy-paste != is unsuitable for.
I didn't mean it as pointing out a mistake, just that there is a distinction to be made that some people will care about. It's certainly a bit fuzzy. Hoare's first paper (the one cited in this talk, and [here](http://talks.golang.org/2012/waza.slide#10)) explicitly has a `&lt;process name&gt;` to which messages are sent (synchronously!). This is unlike subsequent CSP work, and of goroutines. I only point it out because some people will bristle rather more than I have if you [say that Erlang is based on CSP](http://golang.org/doc/faq#csp) and not the Actor model.
I've been following this plugin very closely and recently I've finally been able to switch out of Sublime Text for Go development. It's pretty buggy still but I can usually trick it into re-scanning the file and cleaning up most garbage. Even in the current somewhat sorry state it's in it's a lot better than it was previously and if this pace keeps up I will be excited.
How do you trick it into re-scanning a file?
I'd guess that people whose programming experience begins and ends with "web" may be prone to overestimating the amount of difference between an "API" website and a normal one. 
Thanks for the response, the error is now printed a picture of the schema was added, and I am using mattn's sqlite package. The problem now is that tho the select statement is getting a INTEGER column, it seems to be seen as a string (I think). Now it is trying to convert a string "&lt;nil&gt;" to an int. (when I think the value should be an int in the first place.
Ah I see so instead of var k_ele_id int I would have var k_ele_id NullInt64 I will try this thanks!
Weird. Didn't see any downtime and it just worked for me. Hopefully it's working now for you.
That didn't stop me. I use LiteIDE and agree that it is pretty great, lean and fast. The fact that the developer(s) aren't native English speakers is not really an issue. The same applies to Beego as a full stack web framework that has a Chinese dev team. There's still a fair amount of translate.google English in some of the docs. That doesn't keep it from being a useful (and widely used) project. 
I think as far as building the actual http client code goes, you cant beat a compiled static site with all the nodejs tooling. 
This will be the biggest contribution to Golang, you should open source it /s
After answering the captcha and entering a comment the site won't go beyond the front page. * After my 5th try it let me in. --- Although there aren't many grammatical errors on the site, before taking the site live, I'd suggest getting someone to proof-read the text. Also, if it were my site I wouldn't simply open source it. These opportunities don't come around very often, so I'd only open source it if other avenues were exhausted. And remember that money would ultimately need to be made some way to keep the servers and support running. 
Certainly not Docker :P
Trying to process Unicode characters as if they were single bytes fails in *any* language.
The biggest open source contribution to Golang is Golang itself!
Still an alpha. File an issue or pull request if none currently exists. The previous alphas before the JetBrains guys got on included auto-gofmt/goimports invocation upon saving -- I'm guessing they haven't gotten around to adding that in particular.
Rails and django are for anything but classic websites. They eat, sleep, shit, and breath complex design by default. 
I would develop my frontend with go, if there was a complete compatible interpreter. During development, recompiling the app everytime is long and tedious. I don't care if the app is slow when developing. I've checked some of the go-eval code, it's a good piece of engineering but very incomplete and could probably be way much simpler than it is.
Also the code is still wrong. Characters can span multiple runes (code points), there are also [composed characters](http://en.wikipedia.org/wiki/Unicode#Ready-made_versus_composite_characters). Also see [Normalization in Go](http://blog.golang.org/normalization) and [Strings, bytes, runes and characters in Go](http://blog.golang.org/strings) for a better overview of things. And a nice quote by Rob Pike from "Strings ..." - &gt; In fact, the definition of "character" is ambiguous and it would be a mistake to try to resolve the ambiguity by defining that strings are made of characters.
The english is not a reason to not get the IDE. I just noticed it. I stepped back from Beego, because it was too large for. I d rather use a more modular approach and use existing components and stick them together for projects. Maybe I ll switch to Beego some time. But having done a lot of work with PHP I am very sick of big Frameworks and their philosophies.
Cool, guess I can delete my open-source project then, was working on something similar to this! Thanks.
&gt; Some Google employees focus exclusively on Google-internal Go stuff though (e.g. MapReduce, Bigtable, Spanner, etc). Although not exactly surprising it's cool to hear Go being used with such notable projects at Google.
Can't reproduce it. Works fine for me and other users. Just uploaded a screencast on my Mac OSX + Google Chrome here: https://vimeo.com/119535865
Nobody mentioning the windows port? come on, it's THE most downloaded file on the website by far Probably this thread prompted http://dave.cheney.net/2015/02/13/thanks-brainman 
If I get enough time, delve will get some IDE support, which I'll definitely port into IDEA. Meanwhile, stay tuned: https://github.com/derekparker/delve/pull/57
What do you mean by rescanning the file and clean up the garbage? What problems do you have and you need to do that? If you want the plugin not to be in a sorry state, please help us identify the issues by submitting bug reports to our issue tracker. Thank you.
Please open up a ticket following the instructions here: https://github.com/go-lang-plugin-org/go-lang-idea-plugin/blob/v1.0.0-alpha0/CONTRIBUTING.md#reporting-errors and we should be able to help you out. Saying that you have a problem without specifying the details of the problem is not helpful. Thanks.
Going to give this a try. This is a first framework that kind of 'resonates' with what I am looking for. Will send some feedback soon.
[#1305](https://github.com/go-lang-plugin-org/go-lang-idea-plugin/issues/1305)
Hey hey I wasn't trying to be insulting. I have reported a few bugs and I follow the development quite closely as I've mentioned. Most of the things I run into are in the github tracker. I've tried to use the 1.0.0.alpha#58 and it's amazeballs better in a lot of ways but it's a regression in a lot of other ways. Color scheme notwithstanding.
That's a legitimate concern. The same applies to Rails and Django. Deciding to use a full stack web framework is much like deciding to learn a new language. As noted earlier Go also has good support for taking a more modular approach. That road has its own bumps and everyone has to make a decision which route works best for them. 
I personally use sublime so I'd appreciate that more than IDEA ;) But awesome work on Websockets though.
Can't argue with that, however the LiteIDE downloads are safe. Wish they'd move them elsewhere though. 
Thanks
Not... exactly. Many languages tried to go a route where they make it possible to do that, and while yes at some point the abstraction breaks if you try to stuff a char into a byte, they can get a long way: Python 3.4.0 ... on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; x = "Hello, 世界" &gt;&gt;&gt; len(x) 9 &gt;&gt;&gt; x[7] '世' &gt;&gt;&gt; x[8] '界' Python supports Unicode in this manner, and tries to allow you to treat Unicode as "characters", as long as it knows you have a Unicode string. But this support is complicated to implement, and still often leads to surprises with combining characters and such. In a way, Go goes another direction... to a great degree the `string` and `[]byte` simply don't support Unicode at all. This avoids the problems that arise with support that can be sort of deceptive when the abstraction inevitably fails. Then, if you're dealing with Unicode, Go provides a lot of useful primitives that understand it. But it doesn't try to force you into correct Unicode support. It isn't that hard to write, but it is something you do need to watch for. In the end, it's probably easier to verify that Go code really is correct by reading it, but it does mean that it is possible to get it wrong. Whether you prefer for the language to try to sweep it under the rug and make your code "just work" or to make it explicit is a taste issue, though I support the explicit side myself.
Author of Article Here: What I was interested in showing is not only how the implementation of the specification works but how to grok the runtime figure it our for oneself. It is a simple exercise. What's the value in citing the specification, which is done at the article's head, without understanding how it works and the tradeoffs (e.g. explicitly calling out lack of fairness)? Maybe we could try a similar exercise with the CRuby, CPython, or HotSpot runtimes and see how much of a slog it would be.
I'm able to set breakpoints and debug using the Golang 0.9.16 plugin along with gdb. Can you be more specific?
The initial design focus was have a language that can replace large c++ codebases so I don't think it's that surprising.
I don't know Python, but from your example it looks like if someone wants that in Go they just need to do `y := []rune(x)` and then `len(y)`, `y[7]`, etc give the same results. If `x` is long (or an `io.Reader` or something) and you wish to process it piecemeal/efficiently it's a bit more effort to use things like [`utf8.DecodeRune`](https://golang.org/pkg/unicode/utf8/#DecodeRune) and avoid reading and converting the whole contents ahead of time.
They should do that...
The the pow() calls have to be evaluated before the return values can be passed as arguments to fmt.Println in main.
&gt; If Go is normally a walk in the park, working with Unicode in Go can be described as unexpectedly strolling through a minefield. This should be reworded as: "working with Unicode ~~in Go~~ can be described as unexpectedly strolling through a minefield." It doesn't affect just Go!
Nice. I have a pretty small notification library I threw together that's designed to support any platform. Currently Ubuntu and OSX. It's not much, but a good starting point if anyone wants to fork or just copy bits. https://github.com/ViViDboarder/gotifier
No matter what you choose for your next blog post if you're going to keep the current form. You pasted 700 lines of output and you picked one line from it for the summary without analysing what's going on in there. You need to fix this first.
Funnily, people at the VP level at Google thinks they have stopped using MapReduce years ago.
Don't hesitate to contribute :) Still lot of work to do.
For reference: http://www.reddit.com/r/IAmA/comments/1jg781/i_am_matt_mullenweg_cofounder_of_wordpress_18_of/cbed1jk 
What are these pain points in database and template layers?
Still have to wait for the compilation, doesn't solve the problem.
Too many to list here. In the context of MVC Web Fameworks anyway... No real database layers in most Go web frameworks, when they do it's vastly more complex than most other language web frameworks. It it often necessary for your to even code transactions or sessions for the web user on top of it to integrate it all. Templates are also more difficult than working with something like Jinja or even the rails template engine. Nested templates are hard to achieve. Also the native go template notation starts to get confusing fast ('. isn't particularly useful for context in a large template. I generally support Go concisenes but that goes into confusing). I found ways to get past most of these problems but it isn't apparent, the work to get there seemed much greater than compared to other frameworks and even if you adopt a way to do it, most of the examples are in that confusing format. 
Fantastic news. Now I need to update my upcoming presentation, there are going to be _seven_ Go conferences this year.
Yes, and I was most impressed with the thoroughness of the investigation. Dumping raw asm may not make for the most scintillating reading, but you can't fault the author for initiative.
Yeah their Sawzall tool is basically a more flexible MapReduce. 
I'm not sure about that. There tends to be a fair bit of discussion about nearly every single change that goes in to the repo. I think it comes down more to them just being good engineers rather than trying things in an adhoc fashion. 
MVC is just one way to keep your web app coherent. I don't see any problem there.
Not to disagree with you. I meant talking as wishful thinking (it aloud) rather than code review discussions which are thorough and enlightening to passer by like me.
I guess my point was that I think one of the reasons the pace of development appears so productive is that a lot of thought and discussion goes in to each contribution before the code is written and again before it's submitted. You don't see a lot of code being pushed that is of low quality or later reverted because it doesn't work (it does happen, but not often), or a lot of rewrites. I usually associate the "less talking more doing" attitude with developers who just prefer to bang out code, damn the consequences.
I went ahead and logged in with Github. It feels like a spy game using Go to drive the game -- kind of like a souped-up Go tour. Each level has different objectives that happen to expose you to different Go concepts or standard libraries. It's fun. 
In the Epoch's trap level there is a c.gallonsPerMin = 700 but the output Waterline: 800 Waterline: 1600 Waterline: 2400 Waterline: 3200 Waterline: 4000 Waterline: 4800 Waterline: 5600 Waterline: 6400 Waterline: 7200 Waterline: 8000 Waterline: 8800 Waterline: 9600 Waterline: 10400 Waterline: 11200 Waterline: 12000 is looking as the galons per min is 800
I had a look into this and it turns out it is quite easy to get the App Engine autocomplete working with Zeus. I described the steps needed in the link below: http://www.zeusedit.com/phpBB3/viewtopic.php?f=5&amp;t=7458
has anyone of you checked the GPS coordinates ??? it's no fake guys ;-)
Hey, that's some pretty good code for learning the net/http library. It's good that it implements Put and Delete methods, which is conspicuously absent from the standard library. I would recommend you trim the returns down to as few values as possible. It's pretty rare in Go to see a method with more than two return values, and even then the second one is typically only the error. What I would do in your case is rather than break out all the parts of the Response, return the actual http.Response value given by the net/http library. This will keep it composable with other http-related libraries, and simplify your code a bit.
im interested but sucks you have to login with github
Well, I guess we all would develop a REST based api driven app, with a separate front end, when we need one.
Wow, I am really excited about this. I'm already thinking of a few problems in new ways. This is the best README.md I've read in ages.
:)
Also http://blog.gopheracademy.com/advent-2014/go-probably/
Hi guys, I built this game and originally posted it here: http://www.reddit.com/r/golang/comments/2veiht/operation_go_a_routine_mission/ It is a programming game for Golang. The game tracks progress and high scores, hence the user accounts. More info at: gocode.io/about So far, over 3,000 developers have played it but less than 50 have beaten it.
And odd the author didn't mention his own blog post in the readme : http://www.bravenewgeek.com/stream-processing-and-probabilistic-methods/
Nice! I added support for go-nyet to [gometalinter](https://github.com/alecthomas/gometalinter/commit/b8d5edae4ac8f7fc5f68bde635105c88b9915790).
/u/CodeAddict It's my pleasure! Thanks so much for the feedback!!
[See this detailed explanation for one time token generation]( http://stackoverflow.com/questions/10466241/new-csrf-token-per-request-or-not). I am not near my machine, so whenever I get chance, I will do the benchmark.
the confusion is fmt.Println( pow(3, 2, 10), pow(3, 3, 20), ) which is actually fmt.Println(pow(3, 2, 10), pow(3, 3, 20)) your calling fmt.Println with an array of arguments, which it needs to evaluate before it can print them, so it executes both pow functions before calling Println
Is the library called Bloom or Boom? The author switches back and forth.
Wow! Totally missed that link, sorry for the repost. I beat it last night :) (Stantheman)
I think everybody should give more credit to programmers who make packages like this. It's follows the the UNIX philosophy perfectly, it does one thing well. Reading packages as simple as this are a breath of fresh air.
What I would do is release it as open source *but* license it so that only you can make money using it.
I loved the TRS-80 Model I hidden in there. I had a couple of those back in the day, too!
I hate to sound like promoter but give Beego's MVC full stack framework a look. I'm really just a satisfied user. Beego's database layer should prove more than adequate for most website needs. Beego also has solid support for nested templates using a simple system based on native Go templates. In my admittedly limited experience, between templates, HTML5 and CSS3 and Boostrap not much else is needed (apart from design sense, which I lack) to develop a dynamic, adaptive, attractive front end for a Go/Beego powered site. YMMV. I use a database and nested templates in this basic, and [ongoing project](https://github.com/emadera52/sixty). You can see [the app running](http://60plusadventures.com/) here. One final note. In the past I've tried to get a handle on Django (a few years back) and Rails (more recently). I agree with comments regarding excess complexity. Any full stack web framework will be complex by definition... as will any fully functional DIY system. But IMO Beego does a pretty good job of avoiding the excessive complexity that led me to abandon Django and Rails. I really believe a lot of the credit goes to Go (clever eh?). ;) 
That execution tracing view looks pretty awesome. Looking forward to the GC changes too (though the game I'm working on doesn't seem to have any framerate problems due to GC that I notice yet...)
Excited for the mobile work! Don't let the HN folks get to you Andrew. Admirable for sticking in there for so long. The Go team's work is appreciated!
Hah, they didn't cheat :). A valid solution can generate a very high score.
Yea. It's nice to have a library like that for Mac specific stuff. Maybe I'll use Mack for the OSX notifications in mine so I can drop the gem prerequisite and still support multi platform. Great work. 
[Go Tour](http://tour.golang.org/) is a nice introduction to golang. &gt; ass to build on Ubuntu is an Ubuntu problem not golang... I can build under Windows and Archlinux just fine.
And if you are familiar with programming in other languages, [Effective Go](https://golang.org/doc/effective_go.html) can get you moving pretty quick after you finish the Tour.
I'd claim that not only does Go have very good genes, but the breadth of bundled tools, for such a recent language, is unparalleled. 
what do you mean "it's a pain to build in ubuntu"? First of all you don't have to build it at all, just download the binary distribution and you're good to go. But I've built it a few times in the past and it was pretty easy. What problems did you encounter?
I love this, I built gomeboycolor a few years ago but life got in the way a bit, I love that someone has forked it and made it even more awesome! 
What version of Go? Also keep in mind you still won't be able to read variables or debug goroutines.
Why the downvotes?
Yeah, Effective Go and [The Go Programming Language Specification](https://golang.org/ref/spec) are resources I use on a daily basis when working with Go.
I don't agree with this point for a few reasons. The first is the package management lag -- a lot of Linux distros are eternally behind at least a minor point version. Additionally, Go is trivial to setup without package management assistance, the binaries 'just work' and the source build is rather straightforward. I can't see why you would need (or want) to use the distro specific managed files except to keep your filesystem tidy. My final point is simply popularity... Windows is on a lot of developers desktops by choice, and a lot of developers desktops because it has to be, there are literally over a **b**illion windows installations around the world, and to trivialize that is nonsense... both in terms of a target market and a developer base.
Pain to build on Ubuntu? You just sudo apt-get install build essentials then grab the code and run the bash file. It's a piece of cake. 
As a newcomer to Go with a background in Delphi and Windows development, Thanks Alex Brainman. Due to your efforts Go has one more proponent. 
&gt; 6. Avoid Interfaces If Possible &gt; &gt; This is probably not a great advice to give to Go developers. Interface is probably one of the best Go features and everyone should learn to use it. However, if you want high performane, avoid interfaces as it provides additional layers of indirection. I don’t have performance numbers for the sequence project since I tried to avoid interfaces in high performance areas from the start. However, previous in the ring buffer project, the version that uses interface is 140% slower than the version that didn’t. &gt; &gt; I don’t have the direct link but someone on the go-nuts mailing list also said: &gt; &gt; If you really want high performance, I would suggest avoiding interfaces and, in general, function calls like the plague, since they are quite expensive in Go (compared to C). We have implemented basically the same for our internal web framework (to be released some day) and we’re almost 4x faster than encoding/json without doing too much optimization. I’m sure we could make this even faster. Are there any hard numbers for this? 
thank you Alex. I develop Go on Windows.
No it doesn't, I change the code then I have to test it immediately, not wait 5 seconds. Don't really care if then it takes 1 second or 1 hour to deploy in production, or whether it's a single binary or not.
Ubuntu 14.10 (the latest release) is still on 1.2.1. I always install from source, never from the repos.
I ended up writing a networking library in Go that uses UDP and then has the concept of reliable packets through ack masks embedded in the packet structure. So I've gone through some of the pain and can answer questions. I have the following questions: * what operating systems are you going to deploy to? Here are some random tips that may help you: * On Linux (**not** Windows) I've had to set the read timeout to a value other than 1, like time.Millisecond. This can be done by calling Udp.SetReadDeadline(time.Now().Add(time.Millisecond)) In the end since I moved reading to a goroutine, it really doesn't matter (next item). * To decrease my drop rate, I had to move the Udp.ReadFromUDP() listening action into its own goroutine. I pass it a (buffered) channel of packets and after I ReadFromUDP() a packet, I &lt;- send it on the channel. If you want to know if any packets are able to be read, do a *select{}* on the channel. Sadly, WriteToUDP is a method of UDPConn ... but for your case that's not as big of a deal. Either way, I don't deal with the *msg* versions of the UDP functions and DialUDP is unnecessary. The psuedocode for what I do looks a bit like this: conn = net.ListenUDP("udp", "127.0.0.1:0") conn.SetReadBuffer(1024) conn.SetWriteBuffer(1024) // handle 100 buffered packets of bytes or custom struct ch = make(chan []byte, 100) go func(ch chan []byte, conn *UDPConn) { buff = make([]byte, 1024) conn.SetReadDeadline(time.Now().Add(time.Millisecond)) num, addr, err = conn.ReadFromUDP(buff) ch &lt;- buff }(ch, conn) // listen loop for { select { case b := &lt;- ch: // incoming bytes default: runtime.Gosched() } } // if you wanted to send something: remoteAddr = net.ResovleUDPAddr("udp", serverAddress) conn.WriteToUDP(bytes, remoteAddr) This code listens on a random port, but you send from that port, so the server should reply to that port to allow UDP hole punching to work. Make sure you set buffers to a size big enough for max packet. It's obviously not useful (or compilable) as is, but that's the basic work flow I use for UDP networking. Since you're not just blasting UDP packets into the wind, might as well create a listen loop and use that UDPConn for sending using WriteToUDP which allows you to specify a destination address. edits: * Be aware that things that work on one OS might not work on another. I've ran into multiple things that worked on Windows but not Linux, for example. --- Let me know if you have more questions!
&gt; Even if your entire business doesn’t use Windows, consider the moment when your product manager comes to you and asks “so, we’ve got a request from a big customer to port our product to Windows, that’s not going to be hard, right ?”. Your answer is directly attributable to Alex’s contributions. And it is exactly how it was for me a couple of times. Thanks, Alex.
&gt; I doubt that, atleast on point of Go. You are wrong. Double check, most (with exception of source distros) are lagging because of the rapid release cycle on Go. I don't blame them, just hard to keep up with a fast moving target. &gt; What I've seen, developers using Windwos are coding .Net languages or PHP or C/C++ or Java. But what I've seen is really limited so I'm probably wrong... I can tell you Go is being researched at shops with over 30,000 windows machines for dev-ops and other work. Managing that number of machines is hard work, and mostly going over to powershell, but some places have had bad experiences with powershell and are looking for simple deploy-able alternatives. 
I also removed the pointers after I posted, they were there because I was replicating my prog. I solved the problem here : http://play.golang.org/p/zj8sAladqP Now I'm trying to solve it on my real prog, which is way more complicated (edit : finally solved for good)
I assume you just used a for range loop to copy the map elements. 
&gt; gob.Encode your struct and gob.Decode into a copy That's a good idea, you should add that answer to the [stack overflow question](http://stackoverflow.com/questions/23033143/is-there-a-built-in-function-in-go-for-making-copies-of-arbitrary-maps?lq=1) I'll use it next time!
That was fast one, you managed to hit 4-minute window between me posting a comment and me deciding to rework it and repost it again. Feel free to help out those folks on stackoverflow, I may sound weird but I have no account there.
I was wondering what happened to the comment haha. I'll write one when I'll have time.
http://play.golang.org/p/pq-yTDYGd- is a slightly nicer version of what you did (IMO). I agree that it is likely that the way you're laying out your data isn't great.
[Bae16 Ocean](http://www.ideacolorthemes.org/themes/96/). Not sure why it's not on GitHub. The theme exists for lots of other editors as well: [link to the project page](https://chriskempson.github.io/base16/). I use base16 chalk in my terminal and it looks pretty nice
did I say "next time"? The way I did it doesn't work, for some reason. Aaand I found why, forgot to put a new slice in b.data... Depressing, I think I've lost 1h30 because at first I thought it was working, so I debugged my whole comparaison thing haha.. It takes time to write shitty code! 
How would you scale something like this? I feel it would run into the same problems as CGI from the 1990s but the concept is very simple and cool!
Nothing really representative of real-world apps, other than the micro-benchmarks...which probably don't mean a whole lot...my own test results were linked in the article...
This is even better! Thanks for your great work, Fatih!
Well said. I used Go on Windows for a long time. It's an excellently maintained port and Alex deserves a lot of recognition for making it happen. I couldn't imagine the Go ecosystem growing nearly as quickly without it!
Yep. Well, in most cases. If you have some syscall stuff going on you may have to double check that. But most things, the Go std lib will take away the pain for you.
Awesome, does a great job. Looking to use this in our project.
&gt; Did you just pull these numbers out of your ass? Or do you think majority must be using because you and your fancy friends are addicted to Job's iToys? I was talking about my personal experience, not generalities. But, jerks will be jerks -- so I guess -- enjoy being you! 
This is cool but I can't really think of a reason to use CGI. The only thing I might use it for is some dynamic view for an application that takes a web file as definitions for something internal. Definitely wouldn't want to use it for external resources. Is awesome though :)
Yes, in my cases it was cross-compile from darwin to windows &amp; to linux. Cross-compile experience is awesome in Go.
This might be a simple project, but its utility is through the roof. I am very grateful someone took the time to do this. 
My own tests (which can be imperfect) showed that xxHash have no worse quality than MurmurHashes and substantially faster. Just my two cents!
Outstanding tool, thank you! ftr, I got a couple of errors when installing the lint tools, it might be something wrong with my env (?): Installing deadcode -&gt; go get github.com/remyoudompheng/go-misc/deadcode Installing gocyclo -&gt; go get github.com/alecthomas/gocyclo Installing errcheck -&gt; go get github.com/alecthomas/errcheck Installing varcheck -&gt; go get github.com/opennota/check/cmd/varcheck Installing vet -&gt; go get golang.org/x/tools/cmd/vet go install golang.org/x/tools/cmd/vet: open /usr/local/go/pkg/tool/linux_amd64/vet: permission denied gometalinter: error: failed to install vet: exit status 1 Installing structcheck -&gt; go get github.com/opennota/check/cmd/structcheck Installing go-nyet -&gt; go get github.com/barakmich/go-nyet Installing golint -&gt; go get github.com/golang/lint/golint # github.com/golang/lint ../../golang/lint/lint.go:1432: assignment count mismatch: 2 = 3 gometalinter: error: failed to install golint: exit status 2 Installing gotype -&gt; go get golang.org/x/tools/cmd/gotype Installing defercheck -&gt; go get github.com/opennota/check/cmd/defercheck
The first error means you don't have permission on the Go install directory. Run as root or change permissions on the directory. The second one I'm not so sure about but it may be that you have an older version of Go?
Author here. Scaling is easier than expected. A lot of users have concerns about the overhead of launching a new process for each connection. Traditional HTTP web-apps are optimized for high throughput of short requests, but a typical WebSocket based app has a very different profile. It typically handles much fewer, but longer lived connections. If a process takes a few extra millis to startup, it's not a huge problem for a WebSocket handle. The one thing to watch out for though is memory. In reality, I've not found this to be a problem. To scale beyond one machine, it's easy to sit it behind a load balancer that can cope with WebSockets such as Nginx, HAProxy or a home grown Go implementation.
If you're already proficient in Go, the need for something like websocketd is diminished as it's so easy to create WebSocket backends in Go. websocketd is written in Go, but it's not necessarily for Go developers. It's sweet spot is to simplify building backends in languages that are not as easy to build server apps in.
I agree. We use CGI as the backend for displaying the contents of our artifact repository. But I think it mostly depends on what you're writing the CGI script in I still wouldn't really want to do anything internet facing with it. If it takes input it can be pretty easy to fuzz it which was one of the reasons shellshock was pretty horrible. Doing something like CGI if it takes user input can be horrifyingly hard to secure
No that I know of. But I am very interested, and have been keeping an eye out. I would love to help out in project towards it, but I don't have the knowledge to port go to something like Xen. I would not mind learning how to, but have been having trouble finding resources toward this goal. There are a couple of projects that work toward using a minimal linux as a base for running your go app: https://github.com/tv42/alone http://minimal.linux-bg.org/ https://github.com/daaku/goruntime 
Oh god, of course... thank you.
What a marvellous job you've done. Just one thing, I think you be clear that that is for Linux terminal, other *nix terminals are off the table ;)
Joe, Great job with websocketd! Out of curiosity, if I wanted to implement a version of websocketd and use it to pipe output from one program running on one sever to another program running on another server. How would I go about doing it? Thanks!
In fact I don't use compiled languages for web development. I've tried several times to use one, including go, and I feel I'm losing more time waiting for the page to reload with the new code than writing code. It doesn't suit my workflow, so it is a big deal for me. Whether it's not for you doesn't mean it's not a big deal in absolute words for anyone.
we believe that the unikernel is the future - having one in go would be so awesome
?DOES NOT COMPUTE
Nice Work! I want to integrate this with SublimeText ! 
I believe OSv supports a Go stack...
I'm not. I'm telling the truth. Find me a serious Go unikernel in development and I'll bet $30 they're abandoning it for Rust. /me alt-tabs back to writing Golang...
I suspect it's because Go's escape analysis is seeing that `arr` never leaves `main`'s scope so it's probably put on the stack, whereas C++ probably puts it on the heap, which will be more expensive to create, use, and free.
&gt; In reality, I've not found this to be a problem. At what scale?
 if r, err := http.NewRequest("GET", "", nil); err != nil { t.Errorf("%v", err) } else { I usually just ignore the error from NewRequest in tests: r, _ := http.NewRequest("GET", "", nil) 
Wow, a Bachelors in Fine Arts/Photography? Does Andrew still do photography on the side? Up until a couple years ago, I dabbled in photography and found it to be a really therapeutic activity before/after being on the computer all day. I suppose this goes to show the value of hobbyist coding/hacking. Who knows when it'll lead you to something more influential. Sometimes I wish I went into something more artsy or literary and brandished my programming skills on the side instead, so I could explore it with a little more freedom and creativity.
&gt; No way to "star" or +1 issues. One apparently can "Subscribe" to an issue.
[Boom!](https://github.com/alecthomas/SublimeLinter-contrib-gometalinter) (I haven't gotten it into Package Control yet, but I will have to get onto it sooner or later).
 /(| ( : __\ \ _____ (____) `| (____)| | (____).__| (___)__.|_____
Any chance for compressing the images (like TinyPNG/TinyJPG do)? I need to figure out the lowest-maintenance way possible of doing image resizing and compression for a Google Apps Script that I'm writing... (of all things)
Hopefully someday `gc` will produce similarly tight output. That being said, 15% seems like only a few years out.
All of the above (especially `net.HardwareAddr` and `net.ParseMAC`) plus run [`golint`](https://github.com/golang/lint/).
Hey, something for the next check on my list! I like it. I also want one that, in a similar fashion, looks if I declare a nil var (eg, `var x *Foo`) and find if there's any path to its being used without being assigned; for starters, even just calling a method on a nil.
I built websocketd before gorilla/websocket was available (websocketd has actually been used in production for a long time). Had gorilla/websocket been available back then I probably would have used it instead. I've not run into any problems with x/net/websocket yet, but if I do I'll reevaluate.
10K+ concurrent connections. The server has 256GB RAM (quite a beast), but it was still about 70% free. Of course this all depends on how memory hungry your processes are - don't try this with a JVM! The theoretical limit of Linux is 4,194,303 concurrent processes - though I wouldn't want to come anywhere near this. If it's getting really high scale across multiple machines.
&gt; With its focus on simplicity, Go is pretty uninspiring for people who judge technology by feature lists alone. Well at least they're not alone in making simplistic judgements... Just because someone doesn't like a programming language because it lacks some features, doesn't mean that that reasoning is as simple as tacking some feature boxes. For some, perhaps, but most knowledgeable people can give sound, holistic arguments for why they think "features" are important or very useful, and not simply base it on something like "well this language only has 4 out of 12 essential features - pass!".
Follow-up: I just added support for this. Give it a shot.
Wow! Thank you very much!
That was solid, a lot of good information in a nice chunk of time. Content was well delivered and very clear without any distractions. Thanks for sharing!
Good but he went really fast so some of the stuff at the end was tough to follow. I'm not a hardcore programmer so that could be part of the reason. Also, how common/popular are go channels?
&gt; When will Go be ready for full mobile development? It'll be ready faster if you'd help making it happen. A few links to help you get started: https://github.com/golang/mobile https://github.com/golang/go/issues?q=is%3Aissue+is%3Aopen+mobile https://golang.org/doc/contribute.html 
Channels are used to pass information between two separate processes. For example, I have a process that watches some data store for a change, and then on a change I pass the change information to another process to act on that change and go back to watching. 
I have incorporated most of these suggestions, thanks for taking the time to list these out! The usage strings in version.go were just me being lazy at first then forgetting to separate them. There are very few places (now) which check for a null error and nest code (these are diagnostic messages usually). I didn't even realize that the net package had a ParseMAC function. I should RTFM :) However, I am still confined to using / allowing only 48bit MAC addresses since the way I convert the MagicPacket structure to bytes so it can be thrown on the UDP bcast requires the MagicPacket struct to be static in size. If I had used the HardwareAddr directly in the definition of the MagicPacket, then when I do a binary.Write(...) it will write nothing since the size of the MagicPacket can vary. As far as #6, LOL, I guess I like colorful stuff. Always a kid at heart I suppose. Thanks for all the feedback and the comments on github (@dchapes). I really appreciate the help :)
ah, you can see the implementation in the [sql package](http://golang.org/src/database/sql/sql.go?s=2802:2960#L115).
I had a big thing written up, but Wikipedia puts it more eloquently than I managed to: &gt;#[Concurrency: goroutines, channels, and select](http://en.wikipedia.org/wiki/Go_%28programming_language%29#Concurrency:_goroutines.2C_channels.2C_and_select) &gt;Go provides facilities for writing concurrent programs that share state by communicating. Concurrency refers not only to multithreading and CPU parallelism, which Go supports, but also to asynchrony: letting slow operations like a database or network-read run while the program does other work, as is common in event-based servers. &gt;Go's concurrency-related syntax and types include: &gt;* The `go` statement, `go func()`, starts a function in a new light-weight process, or *goroutine* &gt;* *Channel* types, `chan type`, provide type-safe, synchronized, optionally buffered channels between goroutines, and are useful mostly with two other facilities: &gt; + The *send statement*, `ch &lt;- x` sends `x` over `ch` &gt; + The *receive operator,* `&lt;- ch` receives a value from `ch` &gt; + Both operations block until the channel is ready for communication &gt;* The `select` statement uses a `switch`-like syntax to wait for communication on any one out of a set of possible channels &gt;From these tools one can build concurrent constructs like worker pools, pipelines (in which, say, a file is decompressed and parsed as it downloads), background calls with timeout, "fan-out" parallel calls to a set of services, and others. Channels have also found uses further from the usual notion of interprocess communication, like serving as a concurrency-safe list of recycled buffers, implementing coroutines (which helped inspire the name goroutine), and implementing iterators. &gt;While the communicating-processes model is favored in Go, it isn't the only one: memory can be shared across goroutines (see below), and the standard sync module provides locks and other primitives. As for other languages, I think Go got its concurrency model from Erlang, at least partly. As far as I know, the model isn't that common.
tyty!!
His tutorials are great. His series on Android are what taught me when I first started.
You can just split by semi-colons. 
Thanks that was extremely helpful!
Channels are "from" CSP. Also, Rob Pike had implemented them before in his toy language, newsqueak.
This is actually a misfeature. Use strings.Split.
That doesn't work in all MySql dumps. What about delimiter expressions like this: DELIMITER ;; CREATE TRIGGER test AFTER INSERT ON user FOR EACH ROW BEGIN INSERT INTO user (dataSourceId, name, added, statusId) VALUES (1, "trigger", NOW(), 2); END;; DELIMITER ;
Know it's probably not your intent -- but just glancing over your submission it reads to me as a kind of "*just do it yourself!*" attitude. Ideally we can put off a friendly vibe to newcomers. =) Contributing is certainly a great idea, but I think it doesn't really answer the question. I personally imagine that Go will be *capable* (an example, etc) of writing a mobile app in ~1 year or so. You basically can right now, but you have to do a lot of JNI etc. It will probably be a few more years after that until we have a *nice, clean, or otherwise idiomatic* way to write mobile apps in Go though.
Out of curiosity, can you link to or name off some existing plotting-libraries for other languages that have the functionality you require / would like to see in Go?
Is anyone benchmarking these releases in a systematic fashion? Would be cool if that was the case &amp; possibly help catch regressions..etc.
There used to be [performance builders and graphs](http://build.golang.org/hg/perfgraph?builder=linux-amd64-perf&amp;benchmark=json&amp;procs=1&amp;metric=time&amp;commit-from=go1.3&amp;commit-to=tip&amp;refresh=Refresh), but they're dead ever since the project moved to git. I wonder, if they're gonna fix them and when.
I have come to not mind *some* duplication for the explicitness it typically offers. The less I need to consult a generic type definition, the happier I am.
The go/ast package is terrible, however, it was one of the first Go packages ever written; nobody knew how to write idiomatic Go yet, so it's not surprising it's not great by today's standards. 
Have you tried https://github.com/siddontang/go-mysql?
Since we're discussing httprouter modifications, [Engine for Flotilla builds on httprouter](https://github.com/thrisp/flotilla/tree/develop/engine). It goes a different way, but still uses a lot of the same code methods httprouter created. 
Awesome. I should get back to my home automation project. Thanks for making a great library!
Is it possible to test: goosversion.IsOlderOrEqual("Windows 9*") ? ^^btw ^^you ^^should ^^not ^^prefix ^^your ^^package ^^with ^^"go"
[Effective Go](https://golang.org/doc/effective_go.html#package-names) says: &gt; Another convention is that the package name is the base name of its source directory; the package in src/encoding/base64 is imported as "encoding/base64" but has name base64, not encoding_base64 and not encodingBase64. 
If you can follow the examples, you can do something right now. You can call go functions like java functions. See a an example here: https://github.com/MarinX/godroid I had "fun" setting up all the android stuff, so I made my own repo with all the steps I had to do. I'd never done android anything before, so I was amazed at all the steps necessary before a "hello world" was possible. https://github.com/howeyc/godroid I also wrote an app (but I'm probably the one and only user). It's basically a go web server with a webview application connecting to the web server. I went this way because I was more familiar with html than all the java layout stuff. https://github.com/howeyc/spipedmobile As far as I know, the only thing missing is creating x86/android libraries. When I did my thing it looked like only arm/android was supported.
Go has embedded a yacc. That should cover your needs to make a Compiler. Using parser actions, you will be able to build the AST in the way you feel better later to traverse it. Keep in mind, that the use of Visitor pattern might not be the most adequate way to traverse the AST. (Refer to golang-nuts a thread in which Rob Pike comments that the Visitor pattern exposes the flaw of Java type system and not it's strength.) 
There's no regex support, or Windows 9 versioning yet, since things come from ver. But yes, prefix changes make sense.
I'm thinking it's not matter of type system. To make type system in minimum, it's good way I guess. If solve this issue without idiomatic way, I will use embed struct like below: https://github.com/mattn/anko/blob/master/ast/expr.go#L4-L21
Thanks a lot. Made further fixes.
I somehow fail to see the "unmaintainable" redundancy.
Welcome to Go, dude.
Shortener is spelled shortener, not "shortner".
Don't tell me you need a guide on how to use strings.Split.
Anyone have the link to the article they are talking about? Edit: found it here http://tmikov.blogspot.se/2015/02/you-dont-like-googles-go-because-you.html
Probably this [splendid troll](http://redd.it/2w9mg5): http://tmikov.blogspot.com/2015/02/you-dont-like-googles-go-because-you.html Retweeted right before the twit in subject.
How exactly is strings.Split supposed to help me perform multi statement queries?
100% agree
This is a great article. I find it interesting that the fastest, most efficient Go code is basically C: avoid the GC where possible, manage buffers directly, and use for-loops.
&gt; o recommend t I mean for when developing, maybe those should be written from a user standpoint
Do you *not* develop in an edit-run loop?
Well ... *silently backs aways and disappears*
Click the "colourise" button and you should get some idea
I think a lot of people using Go might prefer to use `go build` and then run the resulting binary. The behaviour in this case and with `go run` can be different.
Thank you, your article helped me to understand allocations in go better. As stated already it might depend on the actual source if it's worth it but it's definitively good to know.
Something I whipped up to fix my previous hack of a ruby script. Input welcome.
That's cool!
agree, I came here to find out wtf he was doing with regards to his approach
yup I think it that simple $ go run /Users/kiasaki/code/go/src/github.com/kiasaki/marks/*.go -h Usage of /var/folders/ws/czrxm7496glbs0q5g8c9tvkr0000gn/T/go-build467976175/command-line-arguments/_obj/exe/config: -basic-auth-pass="": Basic auth pass -basic-auth-user="": Basic auth user, also specify password for it to be enabled -create-db=false: If Marks is to create db table instead of starting an http server -port=8080: Port for the HTTP server to listen on -postgres-url="postgres://localhost/marks": PostgreSQL url or connection string
&gt; Writing benchmark program in Go is easy: Write function like BenchmarkXxxx(b *testing.B) in xxx_test.go. To see allocations, call b.ReportAllocs() in it. To see allocations, just use the `-benchmem` flag. 
Huh. TIL. Thanks for the tip.
Hi, Thanks for the information, I used it https://github.com/josephspurrier/goversioninfo 
Yes. As someone who has played with gamedev in go this is a MASSIVE win. Thank you!
&gt; This seems odd. I use git with CombinedOutput() all the time. Can you point to the code where this isn't working? I get rid of it before my first commit. But I simply use the function CombinedOutput() after Run() and a `[]` was returned. Going to try again later, though.
In perl/python/ruby using regexps is fast because they call into the regexp engine which is in C and therefore much faster than having the equivalent non-regexp code in perl or whatever. 
 func NewErrorer() *errorer Shouldn't these functions be returning an exported type? You know, so that once the documentation gets written people know what to do with it once they get it?
[Also posted in /r/rust](http://www.reddit.com/r/rust/comments/2wj6fh/thoughts_of_a_rustacean_learning_go/) I'm not sure how useful this post will be to this subreddit, but I'd be happy to get some criticism on my coding style and tips on getting better at Go. Please don't take this as an attack on the language :)
Ah, I am not familiar with strings.Map. More opportunity for all to learn.
If I understand hugo then, $currentNode variable is either holding a [Page](https://github.com/spf13/hugo/blob/22d85c2a182642da010e3963d5ed5c64325aebb7/hugolib/page.go#L44) or a [Node](https://github.com/spf13/hugo/blob/f264076f669ccb696e052d1707e87ea7917017ca/hugolib/node.go#L22) (is this why its called $currentNode? Not sure). [Site.Menus.main is actually holding []*MenuEntry](https://github.com/spf13/hugo/blob/f264076f669ccb696e052d1707e87ea7917017ca/hugolib/menu.go#L37). So that "dot" becomes the singular context in this code. &lt;li class="sub-menu{{if $currentNode.HasMenuCurrent "main" . }} active{{end}}"&gt; Each one being *MenuEntry, sent as second arg. **EDIT:** Oh I figured out. That "dot" is contextual even inside the template operations. "dot" inside {{ $currentNode := . }} is not the same as "dot" inside{{ range .Site.Menus.main }} as seen in this code &lt;li class="sub-menu{{if $currentNode.HasMenuCurrent "main" . }} active{{end}}"&gt;. I didnt know this before.
Care to quickly explain why?
&gt; making something simple is much harder than just making something that works Isn't that the truth
We've slowly been amalgamating in that direction... Juggling many repos, even with godep, is a time sink :( At the moment we have two repos: one with our server and cli tools the other our package repo. It's likely they will merge into one.
This definitely isn't true. Obvious non-thinking proof: http://www.chromium.org/ and https://source.android.com/ While they have a lot of code in one repo, they have several more than that. 
The big companies have to look at external server costs and electricity savings for self hosted servers. Go may be more efficient to operate for many of their services by lowering resource demands on hardware near and far.
It might be helpful if you were to give examples of where readability and maintenance have been issues. Preferably real examples and snippets.
So, this might be five months too late, but I wrote this article (just found it on reddit today---neat!) and that's absolutely correct. It's kinda a nightmare. Given the nightmarishness, it does make me wonder if Google is working on a different container format for images with depth maps...or whether something like .webp could include this more easily? Hopefully they're cooking something interesting up with Project Tango...
Thank you for catching such a glaring typo! Fixed.
&gt; can't handle that traffic? 5.000.000.000 (requests) They said how many sessions, not how many requests (# of requests &gt;= # of sessions).
Compare the installation steps of GLFW bindings before and after (I'm using the soon-to-be-released new GLFW 3.1 bindings ahead of time in my fork). Before: git clone https://github.com/glfw/glfw.git cd ./glfw git checkout latest # (More steps if you don't have cmake or make installed.) cmake . make # Alternatively, just `sudo make install` mkdir -p /usr/local/include/GLFW/ cp ./include/GLFW/glfw3.h /usr/local/include/GLFW/ cp ./include/GLFW/glfw3native.h /usr/local/include/GLFW/ cp ./src/libglfw3.a /usr/local/lib/ go get -u "github.com/go-gl/glfw3" After: go get -u "github.com/shurcooL/glfw3"
As a simple starter on this the whole team should be using go fmt at the very least. Beyond that golint and go vet are extremely useful. These 3 tools will naturally lead to more idiomatic, standardised, and readable code. I also recommend reading the blog on effective go programming as it clearly outlines what idiomatic go code looks like. I also work in both python and go, using the above steps really helps and they get everyone on the same page. If you have specific examples we can help further, but try those tools first.
I'm confused by this comment. My understanding was that golang only provides stack allocated value types through escape analysis. A feature that Java also has.
Note: some of the code may be quite sloppy. But it still works fairly well. Edit: Also the second branch(V1) is the same thing but all one .go script. May be easier to follow.
thank you. 
I was thinking the same thing. The complexity is overwhelming. But then again Twitter probably process more data every hour than anything I write would handle in it's lifetime. So I can't comment on whether it's to much, to little or just the right amount of complexity. 
Sounds like a camlistore (@bradfitz) over peer to peer ?
yes, games without screenshots are not likely to get played!
Likely not what you were hoping for, but this would work: https://play.golang.org/p/C5XtcMdlsY edit: Adding the code here just so this is self contained. package main import ( "fmt" ) type Person struct { name string } type FmtPerson struct { *Person } type SqlPerson struct { *Person } func (p *Person) UpdateName(name string) { p.name = name } func (p *Person) PrintName() { fmt.Println(p.name) } func (p *FmtPerson) Scan(src interface{}) error { p.UpdateName("Mr. Fmt") return nil } // using string as state so i dont have to implement another interface to test func (p *SqlPerson) Scan(state string, verb rune) error { p.UpdateName("Mr. Sql") return nil } func main() { p := Person{"Jon"} p.PrintName() sqlP := SqlPerson{&amp;p} sqlP.Scan("", '⌘') p.PrintName() fmtP := FmtPerson{&amp;p} fmtP.Scan("") p.PrintName() } 
I wanted to port my mgutz/mapper project from node to Go. Since gocraft/dbr had the same ideas (interpolation, looks like SQL) I started with that and ended up heavily refactoring and introducing a runner using jmoiron/sqlx.
What is cpackages? I had to create cpackages/Pong/src/fonts/bitmap_font.png cpackages/Pong/src/fonts/bitmap-font.js relative to where I was running from to get it to run. 
I think this sounds like an encapsulation problem. You could probably mitigate this issue with two types that implement one interface each, and then have them communicate with eachother. 
You could designate one of the methods to a different type with the same underlying type and decide which `Scan` method you want by converting the receiver before calling the method. http://play.golang.org/p/hAyAfOxZHr 
Since phash is an LSH, you can use the algorithm from the simhash paper to find duplicate images that aren't exact matches for the hash functions. I've implemented this algorithm in https://github.com/dgryski/go-simstore . The simd binary can be used as a simple REST api endpoint exposing this functionality. 
&gt; you can use the algorithm from the simhash paper to find duplicate images that aren't exact matches for the hash functions Interesting. Currently you can specify a threshold for the Hamming distance: findimagedupes -t 8 dir/ 
[Effective Go!](http://golang.org/doc/effective_go.html) is the best I know.
To do it gracefully, i've started to use a library which has a different interface to that of the standard library and i abstract it away from the application's code. http://stackoverflow.com/a/28648274/13227
Nifty. I'll have to look into that.
Good concerns. I've tried building complex builders in the past and the result was introducing another language. My experience is complex queries are better done with a string builder or sproc than a complicated API. I did benchmarks when I created the node.js version of this library and local interpolation is faster. I'll add benchmarks. Also see gocraft/dbr; they confirmed it too. As for safety, there are well known characters which need to be escaped. I agree declaring something safe screams at me too. I'll add a EnableInterpolation flag with the interpolation disabled by default. I wrote the README fairly quickly and have refactored several times. I actually had a node utility that would execute javascript code in markdown to validate the code. Unfortunately, I don't have that in Go yet.
Unfortunately it's for a library and I can't declare a new type because it wouldn't be transparent to the user.
Here is another example: http://wiki.sabnzbd.org 
&gt; I've tried building complex builders in the past and the result was introducing another language. My experience is complex queries are better done with a string builder or sproc than a complicated API. Well, that puts it in a weird spot, however: Simple queries can usually be written as plain strings with placeholders. The first time I looked into a query builder was when I had such a complex query with some conditional logic, because string building made it too hard to read. The expressiveness of a query builder would've had great benefits here, but the API simply didn't allow it. 
Is the main goal a reimplementation of Lua or simple FFI between Lua and Go?
It looks like any other pong, but will do. Edit: Done
gopkg.in only works with git repositories on github. That's a total deal-breaker.
not quite. camlistore is a personal store for your photos and other data stuff. ipfs aims to be a new kind of distributed network where you can host and share data. but maybe i'm missing a point of camlistore.
I think this would be really beneficial as an article. Do you have one covering the topic of reading emails in Gmail using Go?
Any particular reason you read in the source file twice and then manually muck around with a `[]string` of lines rather than just adjusting the `*ast.File` and then using [`go/format.Node`](https://golang.org/pkg/go/format/#Node) to write it out formatted?
I actually did this a couple weeks ago. Check out the package below. It let's you open the systems default browser to any web page (in this case local host). Then you just run the server as if it was running normally. I can post a code sample a little later, as I am on mobile right now. https://github.com/toqueteos/webbrowser 
Yup, the binary is fixed, so $ ./Pong works, but the library is not updated? I still get $ go run pong.go Find font image file: The file cpackages/Pong/src/fonts/bitmap_font.png wasn't foundFind font config file: The file cpackages/Pong/src/fonts/bitmap-font.js wasn't foundopen : no such file or directory Find font image file: The file cpackages/Pong/src/fonts/bitmap_font.png wasn't foundFind font config file: The file cpackages/Pong/src/fonts/bitmap-font.js wasn't foundopen : no such file or directory panic: runtime error: invalid memory address or nil pointer dereference panic: runtime error: invalid memory address or nil pointer dereference panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x8 pc=0x499bbf] 
Oh you're right. Yeah I just updated the lib repo. That file path needs to be properly fixed at some point, but it should work now.
Wow, this is awesome. I will use this a lot, I think!
I've no idea, that's why I'm asking.
That's pretty awesome!! One suggestion is the use of the title attribute in HTML to display the thresholds for the progress bar on the right.
I'm actually not very familiar with parser package and ast in go. I wrote this last afternoon during GopherConIndia. I wasn't aware of format.Node. Thanks for pointing it out, I will restructure the code with it now.
Is there a benchmark suite to run against this and the regular lua vm and luajit? 
Done. Converted the code from string manipulation to format.Node with AST manipulation. 
I've seen Lua incorporated into some Go projects like heka from Mozilla, but could someone comment on a few situations where you'd want to use Lua with Go? I would love to get a better sense of when something like this would be useful. 
I only have a little bit of HTML being returned from my Go services. I wanted to keep everything as a single binary to simplify deployments, so I've been using this: https://github.com/jteeuwen/go-bindata I keep all of my templates in a directory web-templates, then run something like this when I change them: go-bindata -prefix "$GOPATH/src/mydomain.com/site/web-templates/" -pkg "site" -nocompress -o "$GOPATH/src/mydomain.com/site/web.go" "$GOPATH/src/mydomain.com/site/web-templates" This creates a Go function for each asset. The function just returns a byte array, like this: func info_html() ([]byte, error) { return []byte{ 0x3c, 0x68, 0x74, 0x6d, 0x6c, 0x3e }, nil } ... along with some helper functions to map these functions to asset names. This worked well for me, since I only had a few assets, so it wasn't that big of a deal for me to specify these endpoints manually when I wire up my HTTP server. I'm sure this could be made dynamic by asking the generated code for the asset names. While you're still messing around with the files, you can leave them in their place, edit them on the fly, and refresh the browser to see them, if you add the "-debug" flag, which grabs the file contents on the fly. Remove that flag when you're ready to bundle everything up. There's nothing like shipping a website as a single Go binary, in my opinion :)
Wow, that is really cool! It won't work in my case without completely rewriting how my app handles assets, which is never a good idea when porting - I'm trying to keep it a line by line rewrite as much as technically possible. I'll definitely keep this in mind for any smaller projects I start.
Yes, for keeping the connection up. But if you have the need to have really dynamic webpages, say created by the users of the site, using Lua could make sense. No need to pick out the one little thing you disagree on when I'm trying to help out by coming up with several examples. 
Gulp or Grunt. No need to reinvent the wheel, especially since this isn't Go's domain. Also, easier for frontend devs and many other reasons.
Okok. The other two examples, then. 
Is it more stable now?
I think automatically would be best based on parameters in the URL. That way when you call the API, the caller doesn't have to have any foreknowledge of what the acceptable range is for that value. A simple way to do this would be to pass two parameters in the URL to specify the warning level and the danger level in median absolute deviation terms http://en.m.wikipedia.org/wiki/Median_absolute_deviation I had a look through your code. It looks trivially simple to add a numerical value to the struct and accept it in the API. The only issue I see is you would have to make changes to be able to compare to recent history. 
yep, but I left that as an exercise for the reader...
It is aimed specifically at creating Go Code - like go generate, but without all the hassle of having to write a custom generator. Think C++ Style Templates (but less powerful).
If you were implementing something that should have a plugin system. Go doesn't really do any kind of dynamic linking as far as I know, so if you did it all with just Go you'd require people re-build your entire client any time they wanted to add a plugin. With this, you could just let people implement plugins in LUA and load them as needed. A good use of this would be an IRC client or some other kind of chat client like that.
[rice box](https://github.com/GeertJohan/go.rice)
My vote is gulp + bower + browserify which is what we use for a fairly large single page application. For production releases, we use `tar` to archive and compress a dist folder built by Gulp and upload to an `nginx` server for serving. As good as Go is, we still trust nginx for assets with the added benefit of a being a great load balancer and SSL terminaton point. In development, we use Go's file server handler.
You usually do [*not* want to set GOROOT at all](http://dave.cheney.net/2013/06/14/you-dont-need-to-set-goroot-really). Usually, just set `GOPATH` (and possibly adjust `PATH`) and you're done.
Yeah I learnt that the hard way! Was banging my head against he keyboard trying to figure out why packer wouldn't build from source etc... The docs aren't that great for someone just jumping into it either. Thanks for your advice though :)
What was unstable about hugo before? I never noticed any bugs. Admittingly, I have only used hugo for two really tiny sites (no more than a 5 pages). 
Think they left Rails a long time ago, its what they used in the early days and Rails really doesn't scale well. They tried various things reportedly over time, e.g. Python Flask, Node. Go is probably the obvious language for their infrastructure, given its significantly less resource intensive so its no wonder they are looking at it, also doesn't have the issues that Scala has (one of the few modern languages I hate).
Does it support serializing continuations? I see mention of coroutines, but can't see if they can be persisted to a db to be "thawed" later. The Rhino JS environment is the only one I've found that supports this super-powerful concept so far. I'd much prefer to use Lua if I could. 
You misread the parent, he was saying that Scala is all about scalability. It was worded poorly, as it seems op is not a native English speaker.
Any size int big enough to represent the amount of money in cents is good enough. Do a search for floating point arithmetic to see why floats are bad for currency or other numbers where you need true precision.
We use hugo for gophercon.com and blog.gopheracademy.com which have done hundreds of authomated deployments, each using a docker + hugo automated build process. Never a burp from Hugo. Love it.
If you're going to "outsource" it anyhow, why change anything? Will switching buy you anything? Maybe so. I'm just checking on the grounds that you'd be far from the first person to get a bit too stuck on the decision to "change" without giving fair shakes to the current solution.
First, can you cross compile C apps? What environment do you set up for that? You need to set it up for this too. I don't have time right now to dig for you, but you could start looking at http://blog.surgut.co.uk/2014/06/cross-compile-go-code-including-cgo.html
eh, ok -- I see, I was thinking narrowly, I didn't process 'code generation' at first.
We've been doing this at Fog Creek with our few Go projects, right down to renaming .git directories. Though, we did that as a way to punt this decision down the road. I wish there was a better way than this. I don't want to have to upgrade all projects that use a dependency when I update that dependency. Yes, I could just make sure to *really* trust my tests... but ugh, I dunno. However, if different projects used different versions of a dependency, then I'm worried about one of my projects using one version, and one of my own reusable packages using another... that seems like asking for a different kind of trouble. 
well look at his github acccount: https://github.com/tj?tab=activity most of the contributions is to nodejs and golang projects.
I'm curious if someone following developments in Go would have heard of him. Is he becoming as well known in Go as he is in Node, in other words. Haven't heard of segment.io. 
Heh it won't let me comment on your answer in there. But I wanted to note the call statement, err := db.Prepare(sql) Pretty sure you have to Delete() the statement or it keeps the prepared statement in mysql until the connection closes. Probably not much of an issue on something quick but I found it having issues in long running connections.
I suspect the Go community is simply a little less prone to hero worship than node community. There are good engineers all over the place doing amazing stuff. That isn't a cut on TJ -- his work is amazing, but I suspect the Go community is... more subdued. 
This is like many other features in Go: The programmer needs to know (and remember) that this feature is there, and he/she must decide to use it when required.
Yes and no. If you want to check for errors, then you need to check for errors. You can certainly ignore them (by assigning to _ ), but that doesn't help with program reliability since your calls *will* fail. The Go team has a interesting blog post on this point: http://blog.golang.org/errors-are-values
Shameless plug, you can have a http.Dir interface to go-bindata with [go-bindata-assetfs](https://github.com/elazarl/go-bindata-assetfs)
How much code have you written? I write quite a lot of Go code, and error checking is a smaller proportion than you may think. There's plenty of ways to either defer or delay error handling if it's truly cluttering up things. /u/dgryski's post has a link to a good blog post that demonstrates one such technique. But ultimately, if you're writing code where a lot can go wrong then you should expect to have a lot of code to handle those things going wrong.
This seems strange — `go generate`'s output is meant to be committed to source control. Or, put another way, `go generate` is meant to be a tool for package _authors_, never _users_. By giving it runtime responsibility you kinda subvert its design goals.
It's an interesting technique but for most cases I think it's just easier to put your secrets in their own file(s) as constants and then list those files in your `.gitignore`. How does safekeeper differ from this technique, other than having to run `go generate`?
Have you seen https://github.com/omeid/slurp?
If you love Gulp, check out https://github.com/omeid/slurp
Is it on github by any chance? I'd love to check it out.
And now GOROOT_BOOTSTRAP...
If I'm not mistaken, that's only for tip (eventually 1.5) and only needed when building Go from source… not needed at all once built (or for binary Go installations).
Right, thanks. I already had/have this system setup, I was just trying to see if I could "streamline" the process a bit more and not have to native-compile and just have both build toolchains on os x
there have been many bugs fixed. i've been using development snapshots for a few months. haven't had any panics or corrupted output. there have been a couple of changes with default settings but no major changes. layouts and themes are pretty solid, and there are now a couple of dozen to chose from.
Come on. You're seriously going to pretend that "not prone to hero worship" wasn't meant to appeal to a sense of superiority in one community while denigrating another? Whether node devs are prone to hero worship is up to the social scientists to decide, but the reason TJ is well known in the node community is not that. You simply notice who wrote the package you are using and you see that one person wrote an outsized portion of them. My curiosity is simply, can a prolific dev switch to a new community and quickly reach the same level of notoriety? It's not "do you worship him as much as us plebs do".
Hahahaha wow. Good catch. Lesson learned - don't code while sleep deprived.
[JustinCampbell](http://www.reddit.com/user/JustinCampbell) is correct, this is not meant to be used by package authors. Application secrets would normally not live in packages. 
I think I sort of agree with the sentiment but it means you have a contract with every project contributor regarding the constant names. It's not necessarily a big deal but I was trying to make this a bit more formal. Using safekeeper, you're workflow has a standard go tool (go generate) and you get a descriptive error message when you're missing environment variables to generate the appsecrets code. You might be convincing me that this was overkill but I'll try to see where this goes with my usage in my personal [Google App Engine app](https://github.com/alexandre-normand/glukit). 
I [added a section to the README](https://github.com/alexandre-normand/safekeeper/blob/master/README.md#why-you-might-use-safekeeper) regarding when safekeeper can be useful. I think the audience is pretty limited (I'd say: GAE users that want to have a little more formal workflow for contributors) but I had a use for it myself so I thought maybe others could benefit from it. 
This seems pretty bizarre. If something is too sensitive to be committed to source control, surely we shouldn't be in the habit of putting it in our redistributables? The fact that GAE doesn't allow basic [12-factor](http://12factor.net/) best practices says to me that that GAE is moribund and you should be using something more modern and sane, like Heroku, Docker, or EC2. Sure hope this doesn't catch on.
I once scanned over everything I'd written in a non-trivial program intended to be right in Go's wheelhouse (highly concurrent network server), and what I found was that about 1/3rd of the time I handled errors, it was _not_ just "return err". At that point I found it hard to complain much. The other issue is that other languages focus on making error handling "easy", and they can end up focusing on making it _so_ easy it just disappears. The problem with that is that once it disappears, on average so does the programmer's concern for it. Having learned from both my time with Haskell and Go just how _sloppy_ I was being in Python and Perl, I gotta tell you my Python and Perl is looking a lot more like my Go code now! Per my previous comment about how about 1/3rd of my errors can't just be "throw it up to the next level", it is also the case that often in my Perl and Python code the right answer was not "just let the exception propagate"... it's just what I did because I was, well, like I said, frankly being sloppy, because the language made it easy to be sloppy. I'll concede that some syntactic sugar can be useful, but for philosophical reasons Go prefers to spell it out. I will not, however, apologize for Go's apparent mania for handling errors, because the sad truth is that if you're doing anything related to a network, that's simply the ground truth. That's how much stuff can go wrong. If your code is not dealing with it because you're using a language that makes it easy to sweep under the carpet, your code is simply wrong, and to a surprising degree "let the exception propagate" isn't really dealing with it. Your mileage may vary if you're working in a different domain. Networks have really terrible failure cases associated with them. But, well, so do a lot of other things.
You seem determined to take things in a negative way, but please don't tell me what I "meant". Communities are different. You can put your head in the sand and pretend they aren't, but you are lying to yourself. As far back as 2010 there were discussions about hero worship and elevation in the nodejs community being a problem. Node wasn't even a year old and people where talking about how Node is world-changing and XYZ module is the best thing ever and ABC author is a god (and the inverse 'all other languages are shit'). This seems to have gotten baked into the ethos of the community to some degree, and while the targets of it switched over the years the behavior didn't. The reasons are of course up for debate, younger less experienced developers are prone to excessive over the top statements, freshness of the language (obviously, since it is a peer in age to Go, not relevant, but in 2010 it was being compared to Python, Ruby, Lua, C++, etc). Interesting that even back then, the lions-share of focus went on module developers instead of say -- Lars Bak. Now, this tendency in the node community led to a lot of great modules (and a lot of reinventing the wheel), because people did aspire to be talked about in such vaulted prose, to emulate those they held in high esteem, they wanted to be the god-king of templates or &lt;X&gt;. This was probably a positive development for the community as a whole and pushed it forward -- ego isn't inherently bad. A good example of this is treatment of Dhal -- from untouchable god, to mere respect, to annoyance -- to even hate. Read some of the followup on TJ leaving node, most gave him begrudging respect but disagreement, but there was outright vitriol as well. 
I agree except that this won't work on Google App Engine (and that's the motivation behind the tool).
The title is misleading. The project does not belong to the Go team, is not used by the Go team nor is it the only static site generator written in Go.
Xgo only really works it seems for the most basic compilations. For instance, I need to have libvips installed on the host container, but as far as I can tell there is no mechanism to allow for adding custom steps to the build process without forking the whole project repo
"A little less prone" obviously don't mean immune to... what I was talking about was more a type of groupthink. 
Well let's hope that compilation speed is not compromised. This is one of the things what Go stands for. 
&gt; this is not meant to be used by package authors. ...and that's why I'm arguing that `go generate` is the wrong tool, because that _is_ meant to be used by package authors exclusively.
Two big advantages are that now the compiler is easier to profile and refactor, and second the ability to easily parallelise the different stages (e.g. compiling 4 files at once on a 4 core box ). The compiler will get faster, although perhaps not immediately. 
&gt; Nobody wants a slow compiler. Those were my exact thoughts. BTW, when this new compiler is finally out, it would be one big static binary correct? I can only imagine good life after that. 
Congrats! Here's to hoping this makes improving Go code generation easier.
Congrats! To put this huge achievement in perspective Java is trying to write compiler / runtime in Java for at least for 3 years or more and they are nowhere near close to done.
I think it's a good question. Thanks to @davecheney for answering.
While it seems to be against the philosophy of the Go author's somewhat (or maybe that's just my impression), I personally wouldn't mind a flag for aggressive but slow optimization which you would typically use for release builds, this is of course assuming the Go developers would forego certain optimizations due to finding them too costly in compile time, that may not be the case.
javac is not comparable to Go compiler. I believe JIT compilers / interpreters (C1 /C2) which are written in C++ are comparable. I am talking about Graal / Maxine. http://www.oracle.com/technetwork/oracle-labs/program-languages/overview/index-2301583.html Also Go runtime is now written Go. https://github.com/golang/go/tree/master/src/runtime edit: This link shows that Maxine is in development since 2009 or before so much older than I initially thought. http://blog.gmane.org/gmane.comp.java.jikes.rvm.devel/month=20091101
Looks interesting.
&gt; There is another symbol "$" which is the original value of Dot TIL
I use https://github.com/pkg/browser
I doubt the Go developers would ever go for this, it really is against the core principles of Go. However, I am also pretty sure that the reason compilation is so fast is not because they leave out costly optimizations at compile time, but because they very very specifically designed the language to not allow for stupid time wastey stuff at compile time - [here's](https://talks.golang.org/2012/splash.article#TOC_5.) an example from Google.
I made a tool to do it. Maintain a set of table structure files like: https://github.com/chrhlnd/streplace/blob/master/example.tab Maintain a set of config 'data' files for tables like: https://github.com/chrhlnd/streplace/blob/master/test.data Run everything through the binary with the grammar file which generates a giant upgrade script, con-cat everything into one file then just run it against the db. I also version stored proces and concat them all into the file as well, they are in the form of: DROP IF EXIST &lt;db&gt;.&lt;proc&gt;; CREATE &lt;db&gt;.proc&gt; ... The final spit out file looks kinda like this: https://github.com/chrhlnd/streplace/blob/master/example.tab.sql the data file is: https://github.com/chrhlnd/streplace/blob/master/test.data.sql The tool was written in go. I prefer to treat it as a tool instead of something embeded into any particular language, you tend to lose those as you move around languages. https://github.com/chrhlnd/streplace Suppose you could do it all with xml or something too with a crafty xslt. Atm I have it setup for MySQL you'd need to make another grammar file for whatever target db.
OP here. Last weekend, I almost decided to use Jade templates to output my theme layout files because I find the default template syntax horrendous. It is good that they added support for Ace templating which is inspired by Jade.
Go's runtime is now written in Go 1.4. Yes, you need a go compiler written in C for Go 1.3 in order to compile (bootstrap) Go 1.4; but, from now on, we'll be compiling with Go! So, thanks C for the help and the inspiration, but sayonara! -edit: Why the downvote?
The script I have it generating would never delete anything. You could just run the last version's script if you wanted the last version. The columns from any version would remain. Usually on a column rename or drop, I handle it manually with a custom script as the action tends to be pretty destructive and can take a long time. Generally I don't rename columns in production. During development this happens a lot but I don't care about the data so I just blow everything away anyway and reload. Its possible code tries move data on demand in which case you need both columns anyway (this can get messy). There is no real scaffold scripts because its not managing delta state. It just creates any columns indexes that are missing by inspecting the meta data schema. My .tab files and stored proc .sql are all versioned right along with code so if I wanted an old version, I'd just roll back to that and run the tool to generate the script, then just apply it. You could also version the scripts you submit for release, probably not a bad idea to just version all release files anyway. Stored procs as described are just scripted to drop and create then I concat all of them in the sql for a full reload, they are also versioned in version control along with code and the table files. Views are exactly the same. Foreign keys could be as well, its also possible to augment the grammar to take in foreign keys and check them like it does indexes to add if needed or do nothing if not. It would be very similar to how it is doing indexes at the moment. The benefit there would be to reduce db time on building the fk index. I just didn't need it at this time. 
This was run across the converted compiler to clean up the generated code. Mostly things like eliminating dead code and moving variable declarations closer to first use. 
Did you read the documentation? http://golang.org/pkg/net/http/
Why read the documentation when I could ask inane questions to busy people on reddit? [This answers my question](http://golang.org/pkg/net/http/#ListenAndServeTLS). As always, I should have just RTFM. Thanks!
Now someone port CoffeeScript and I will forget about Node.js lolz
Huh, I'll have to look into running that as a pre-save hook in my editor, like gofmt. (Call me weird, but I like my code being messed with by those kinds of tools)
Due to the nature of my asset building (fairly dynamic, changes based on what content blocks are included in the website - which is multitenant) - I wrote some controls for Gulp in Golang. I'm just using my own form of library management / dependences for the moment (ported line by line from my Python app). I'll probably look at including Browserify/Bower et. al. in the mix at some point. But porting this app over is a gargantuan task as it is. It's not as neatly integrated, and I'll probably end up writing a library around it. But it'll do for now. Gulp had a nice short learning curve. I can't say the same for Bower &amp; Browserify. But then I didn't spend a lot of time on them. I'll definitely look at Slurp later down the line, before I spend anymore time in NodeJS land.
Gorm was interesting. The only problem I had with it is I don't want automatic migrations on the production server. I really did appreciate Alembic's staged migrations. It produced a lot less headaches &amp; made rollbacks quite easy. I also really want to avoid ORMs now. Getting back into writing SQL has been... tedious, but strangely enjoyable. It's nice to know exactly what queries are happening. I just want a tool that can handle automatic migrations, so that I don't have to write tedious upgrade/downgrade scripts. Ah well.
Fair point. Still, having an accessible editor command to run it on demand would still be sweet I think.
I think this would be more of a precommit hook if it's set to write changes, although currently I am writing a tool that watches a folder and lints, vets, race test, test, and checks coverage every time a files change and the output would fit in well.
I am just a little worry that the compiling is slow now. Hopefully, this will be rectified soon. [In the justification](https://docs.google.com/document/d/1P3BLR31VA8cvLJLfMibSuTdwTuF7WWLux71CYD0eeD8/edit), plenty of pros, but there seemed to be none of the cons. Clearly, one possible disadvantage is that the Go-based compiler will be slower than the C-based compiler. 
&gt; designed the language to not allow for stupid time wastey stuff at compile time As someone who can meta-program with the best of them, I *adore* writing time-wastey stuff at compile time! But seriously, it's probably for the best. It's difficult to conceive a compile-time mechanism that doesn't allow for deep obfuscation of code and/or create a maintenance time sink. There's a point where it's breathless and easy to understand (Java generics for example), and then there's where it starts to converge on raw code generation; and go-generate has solved that problem handily.
Of course!
Yes, Hotspot does things at runtime.But a language and it's runtime are not the same. My only point is that both Go and javac are compilers for their respective languages, regardless of whether or not there's an optimization pass before,during or after code generation. Case in point, there were backends for Java (the language) that would generate native code, way back in the 1.1 days. I think https://gcc.gnu.org/java/ will still do this (not sure, it's been a very very long time since I did anything with Java and I only had a glancing interest in gcj). 
I guess I am trying to point out Java depends on ~600K lines of C++ code in hotspot and another 500K of (C/C++) code in assorted tools / libraries that comes with JDK for its real world performance. Go only (almost?) depends on Go for its real world performance. To me it is impressive and considering Oracle working on Graal / Maxine they also consider this as worthwhile goal.
I started using [liquibase](http://www.liquibase.org/) regardless of language and haven't looked back.
Isn't this what the `{{range pipeline}} T1 {{else}} T0 {{end}}` syntax is for? It looks to me like this could be replaced with something like {{range $index, $post := .posts}} ... some HTML stuff ... {{else}} ... some HTML stuff that says "No objects found" ... {{end}} and be much clearer. The syntax can be seen in the [text/template docs](http://golang.org/pkg/text/template/#hdr-Actions) (You should use [html/template](http://golang.org/pkg/html/template/) for this, but the syntax is the same)
github.com/lib/pq driver does not do any statement caching for the .Exec() interface. Even worse, the one shot query interface uses the exact same prepare code introducing an extra round trip to the server. To be more exact, [*conn.Exec()](https://github.com/lib/pq/blob/master/conn.go#L650) calls prepareTo() to create an unnamed prepared statement. [*conn.prepareTo()](https://github.com/lib/pq/blob/master/conn.go#L556) allocates a new `stmt`, then sends to the server a packet containing messages Parse, Describe, Sync and waits for the result. Exec() then immediately calls [*stmt.exec()](https://github.com/lib/pq/blob/master/conn.go#L1128) that sends to the server Bind, Execute and Sync messages. If things were rejiggled a bit it would be possible for Exec() to send Parse, Describe, Bind, Execute, Sync in a single packet resulting in a single round trip to the server. Extended query protocol is still a bit slower than the simple protocol, due to some unnecessary copying inside PostgreSQL. My testing shows a slowdown from 16k queries/s to 13k queries/s per core using select only pgbench. However, using prepared queries, the performance is 31k queries/s. So if you care about performance, use bind params and prepare your queries ahead of time.
This looks like a kind of low level API (without offset storage). A few questions: * Which protocol versions does it support? * And if you dont configure the partition, does that mean you read from all? * What is the difference to Sarama? * Do you support meta data requests like Kafka 0.8.2? * And why do you started a new kafka lib?
And if you are not looping, you can {{if .posts}} there is at least one post {{else}} there are no posts {{end}} 
Interesting observation. When we released gocraft/dbr I wrote some [similar benchmarks](https://github.com/tyler-smith/golang-sql-benchmark) (note the BenchmarkPreparedStatements benchmarks), which has similar results in most places, but it doesn't test transactions. I will try to add transaction benchmarks and see if we get similar results :)
It's [available here](https://github.com/dmikalova/go-watch). It basically works as it is, supposing you have all the dependencies installed (lint and grind and maybe others). I actually already use it while working on it. I'm currently working on adding increasing test coverage, refactoring, and documentation - hopefully I'll have the majority of that done by the end of next week. You're more than welcome to try it out, open issues, and submit pull requests. Feel free to message me if anything's not clear - this is one of the first Go projects that I've completed to a working state. For refactoring I'm planning on reducing the code spaghetti, making it more idiomatic, making it flexible for choosing commands by moving everything that's in run() to go-watch-term, adding in more CLI features, and making it more responsive/concurrent because as it is there's a 1 second lag between saving and output. Output looks like [this](http://i.imgur.com/A0wTdbl.png).
Did you look into slurp-todo example? it shows how you manage dependencies with slurp, just downloaded the archives directly and write them to disk. As simple as few lines.
That's really very cool. Looks like I'll be moving everything to Slurp.
Thanks for the updates. 
As I wrote above - for the user the biggest difference is the API. Sarama provides channels while my library is giving you blocking functions. I find the second one way easier to reason about. I found channels approach really strange, because once you will get familiar with the protocol, you will notice that there is no concurrency at all. I also believe testing is something sarama makes way too hard - you can either mock the broker on wire level or you have to write your own abstraction around the library to mock it in tests. None of those worked well for us.
damn son, you got burned with that reply
Playing with this, found that I had to add my user to the `fuse` group to successfully launch it without root (which would have been a BAD idea). I also found I had to manually use `fusermount -u &lt;mountpoint of ipns&gt;` to reset the mountpoint to a regular folder for deletion after shutting down the node. Other than that, it looks interesting. I read through the paper and the design seems really thoughtful, I'm excited to see where this goes. Critical feature right now: we need a directory of "pioneer" stuff hosted, because the design of IPFS appears to make things obfuscated unless you know their hash or have an IPNS entry for them. So, I can look at the example stuff and add my own content, but how do I discover new content and publicise mine? Also, webapps based entirely in JS are well-and-good, but how would I use IPFS to manage a "real" webapp that requires user input to generate content? For example, an aggregator for IPFS where people could submit their stuff for indexing! If I use a JS app in IPFS it can't contact a remote endpoint because of cross-boundary issues, so do users have to go to a regular site for interaction with a server? Maybe I'm not grokking this yet.
Good article. &gt; The disillusionment of the Trough of Disillusionment comes from the fact that you are still thinking in the patterns of other languages and you haven’t yet fully explored much of what Go offers. I can't stress enough how important this is. Not only to Go but to any language. Still remember, during University, how painful was learning Java and programming in it a la C and how refreshing it was after some time when adopting the OO paradigm. Or how infuriating was Haskell at the beginning and later was like in heaven.
Very interesting. I seem to be a mixture of newcomer, explorer and builder.. that's probably not a good thing ;)
[speaker deck for the talk](https://speakerdeck.com/campoy/gophercon-india-evolution-of-a-gopher) GopherConIndia was awesome
Nice
recommend to compile the binary offline and then run the binary app using some init system like upstart
I can see I'm in explorer stage. But I am using Go only as a web and api server for my small side projects, so I'm not sure that I will ever go to higher stages. Am I using the wrong tool for the job?
The most important part for me in this article was the q and a at the end. So they're working on debugging tools that will allow you to see the state of all go routines. Very nice 
There is no link in the blog! Actually I have submitted it for review with Facebook. Since it requires some permissions, which need a [review](https://developers.facebook.com/docs/apps/review) Once that happens, I will put a link about it! 
Thanks for the tip! I guess I can compile the binary on the server and run it using upstart. 
No. I have got it running on EC2.
wow, even the memory manager. im impressed
Awesome post
Personal portable computation device :-D
&gt; 3 To do this you'll need to capture the stderr and stdout of the cmd struct. Set cmd.Stdout and cmd.Stderr to any writer of your choice. You would then run the command in a goroutine and have another goroutine consuming Stdout and Stderr and sending it to your server. Well, I must be doing something wrong. I created a [simple struct that implements `Write`](https://bitbucket.org/shackra/st.-vincent-ferrer/src/e2f9056160c4483a99ed037db75b4e971c1d9d55/slave/utils/utils.go?at=master) for now it just prints to the terminal. I also [did the respective changes to test my custom Writer](https://bitbucket.org/shackra/st.-vincent-ferrer/commits/e2f9056160c4483a99ed037db75b4e971c1d9d55?at=master#chg-slave/slave.go). Did the test run. But the entire output is written at once, I though it would be written line per line as the command output message to `Stdout`. What am I doing wrong here?
I think you meant HTTP/2 client. &lt;/pairredditing&gt;
Maybe go 1.6, maybe. 
How the hell do I edit the title? Anyone?
Submission titles are not editable. Only solution is to delete and resubmit (which I never do -- correction in the comments is usually enough). 
pairredditing... About as good as rubber duck redditing.
Thanks for doing the Hacking with Andrew and Brad videos - it's really awesome to get some insight into the minds of skilled developers while they're developing.
Let me know how it goes. I would be happy to help, specially if you're working on an opensource project. 
Thanks for doing these, I really enjoy watching them
Better now?
It would be a shame to have a book that doesn't cover go generate, though.
This is really cool. Can I ask what the requirements are that makes a Pi too expensive? That $30 difference doesn't seem like much to me. Especially considering the cost of your time getting Go to work on that device.
It sounds like it should get easier to port to new archs. Russ Cox says: &gt; In the 1.5 cycle I intend to pull as much code out of the back ends as possible, mainly to make the non-amd64 systems (especially ARM) as good as the current amd64, but also to support other back ends easily. https://docs.google.com/document/d/1szwabPJJc4J-igUZU4ZKprOrNRNJug2JPD8OYi3i1K0/edit
Also For the record. I came across this. http://blog.gopheracademy.com/auto-deply-revel-site/ Will try to follow this.
I hope you document everything! I've been spending the afternoon thinking about cool implementations that one could use this for.
Why https only? Doesn't the draft says it accepts both http and https?
The spec says so for political reasons, but nobody is actually implementing it for http. In practice, "helpful" proxies and filters would interfere with HTTP/2 if they saw it in the clear and break it, so browsers &amp; servers are only doing HTTP/2 if it's encrypted and know it won't be messed with. This is being done both/either for reliability reasons (so users don't complain that HTTP/2 sometimes breaks) and for political reasons as well (Snowden, etc).
I'm confused, are they interviewing themselves?
Webscale HTTP routers.
TBH, I've never used them. I think ken has.
What ended up being the bug making it unable to send a valid request to Google, but not to their own HTTP2 server? (I presume they've found it by now, since it was recorded almost a month ago)
Gah, I wish Google would put a bit more effort into the quality of their python protobuf API (that this is built ontop of). No support for python 3 yet, and still python 2.5 cruft :( Hopefully otherwise the people releasing this @ Google will stay interested over time and make it something worth relying on. /offtopic 
Python 3 is like Perl 6, never happened.
Thanks. Glad everything worked smoothly for you! You can create messages by clicking on Add Post, just that when you check the Facebook checkbox, we won't be able to post anything to Facebook yet.
https://github.com/stevenleeg/gobb but cannot tell if it's good
What features specifically do you want to get out of having a forum in Go? (I'm building a licensable forum in Go, but probably won't be done for another month or two). 
Alright. So is the server side behavior in this situation ambiguous? As in - who's right? Google who rejected it, or your Go server implementation which accepted it? :-)
The Google server is correct; the spec says you should only send only one of the headers, not both. (The Go HTTP/2 server is now correct too.)
wire efficiency? about the same. power, flexibility, ability to handle strange edge cases... way way better.
Is it safe to use a single mongo session like that? I'd expect one session per request.
Yea, I don't get this at all.
Thanks. Hope it will be of help to you.
I built a content promotion site http://www.socialpaster.com/ 
it's purely nonsense
Cool. As a next step on deployment, beyond 'nohup', I'd recommend a quick upstart or systemd config. Eg, `/etc/init/yourapp.cfg` would be: description "start/stop yourapp" start on filesystem or runlevel [2345] stop on runlevel [!2345] respawn script exec su youruser -c '/path/to/yourapp' end script Then "sudo start yourapp", "sudo stop yourapp", "sudo restart yourapp", etc. This has the advantage that if something crashes your app, (in the case) upstart would notice and automatically restart it. Once it's in place, it also makes sure that the app is started/stopped as appropriate when the machine is booted or shutdown.
Thanks. I got a lot of suggestions here and sure upstart was one of them https://www.reddit.com/r/golang/comments/2x43la/deploying_my_first_app_on_production/
By choice Go has no irony exceptions.
really love to see this kind of work; great post.
Obviously not. But I found it entertaining: while learning Go you first find out that there's no exceptions and you're supposed to handle errors explicitly (point taken), but then you notice that, just in case, there's a secondary mechanism for error handling that's called something different but works equivalently (stack unwinding, complemented with defer, analogous to D's `scope` block). It's like plenty of social engineering went into the language design: "Okay, it's better if people avoid exceptions in Go programs, but we cannot drop them altogether from the language, so how about we leave them but rename to something else so that people don't gravitate towards them so much?"
You could use [bufio](http://golang.org/pkg/bufio/). Its `Reader` has a [`Peek`](http://golang.org/pkg/bufio/#Reader.Peek) method that lets you examine without consuming. (Make sure you configure it with a large enough buffer size.)
I wrote this because I don't need any crazy ORM features but I would like to keep my schemas consistent during development. I found myself reimplementing this concept on multiple projects, so I finally got around to making the whole thing "go get"-able. Any feedback would be great. Does anyone else do something similar?
Circular refs are fine if within the same package, you just have to be extra careful if they cross packages. The compiler will yell loudly if you have a circular import though. If I were designing it, I'd only export the vars that I want in json output, and the other struct refs would be unexported (the json package doesn't touch unexported members). So then you'd have Setter methods to update the circular refs (which can also update the exported ID mentions).
&gt; Just make sure that any time you modify a.pointerToStructC from within the package you either go thru the setter or make sure to set a.StructCID to match. Yeah, that's what I meant by fool-proof. So, within the package, I'll just have to remember to not make this mistake. Not a big-deal I think for the potential value I can get through circular reference in this model. Thanks, again!
FWIW, I don't see any usages of them in the Go stdlib, except in test cases and de/serialization. https://sourcegraph.com/github.com/golang/go/.GoPackage/builtin/.def/complex64 https://sourcegraph.com/github.com/golang/go/.GoPackage/builtin/.def/complex128 (You can page through the references to each on the right side with the "&gt;" button.)
[rice](https://github.com/GeertJohan/go.rice) can switch transparently between embedded and external assets, so in dev phase you can edit them and see the change without recompiling, and embed when you're ready to publish.
Usually circular references are much harder to comprehend than tree structures and it's easy to get to a problematic state. Basically, avoid if possible, but sometimes the alternatives would cause even more problems. &gt; I'm trying to start a project "properly" by first defining the model. Start from the (user) interface - it's more important.
I'm also suspicious of many uses of `ioutil.ReadAll` instead of operating on the stream as it's coming in.
Thanks! This is for a Web-service. So, the URIs and JSON representation of the model *is* the user-interface.
&gt; Asset data can be accessed via the Asset function, which is included in the generated assets.go source file. This sentence confused me, so I went to the project page. Yes, the functionality is the same, but implementations differ. go-bindata generates different Asset functions for dev and release; rice doesn't generate anything at all for dev.
See if anything in this list is what you need: https://github.com/avelino/awesome-go#natural-language-processing
Yeah, the library falls back to the filesystem if nobody registered an embedded asset under the requested file name, which the generated init function will do. I suppose it can also be done manually in some scenario where you want to generate something in runtime and have it available through the same interface.
This is reddit. Drive-by downvotes happen. I wouldn't worry about it. Anyway, [here](https://github.com/krisalder/ml) is a *really small* project that is being used by one of my classes -- it could use some unit tests and a README; we don't have time right now to get around to it. It's not going to be widely-used, though, but if you're looking for a really simple, first-time Go project, this is an easy one. The package has no dependencies and all it does is some basic operations on slices.
What kind of application do you think this is best suited for? I'm guessing smaller apps that need to be able to recreate their DB if needed as opposed to a more managed approch of creating the DB separately or before deployment.
Yep. Might go for the zip mode instead, I haven't tried it yet.
Now make it work with Mercurial, Subversion, and Bazaar on more than just github :P You may be interested in checking out [gopkg.in](http://labix.org/gopkg.in) as well, it tries to achieve similar results using the standard go get.
You're right, this is purely a JavaScript question. But I don't even know how your Go code compiles... Use your browser's inspector tools to look at `data` and `results` to make sure it's what you expect, then change your JS to access the values you need within the object.
Besides [Subversion](https://github.com/mattes/go/blob/fix-dependencies/src/cmd/go/vcs.go#L223), [Mercurial](https://github.com/mattes/go/blob/fix-dependencies/src/cmd/go/vcs.go#L68) and [Bazaar](https://github.com/mattes/go/blob/fix-dependencies/src/cmd/go/vcs.go#L154) already come with the *tagSyncCmd*. So this should be trivial.
If your code relies on different versions of the same package ... But think about your "global" $GOPATH workspace. Different projects in $GOPATH might have different version requirements.
No #revision suffix means "master" branch. So nothing changes here. How is Godep or Goop handling different version requirements for dependencies (of dependencies)?
There may be at most one version of an import present in the final program. Godep handles this by flattening the list of dependencies; multiple inclusions are an error.
Gorm is really simple...
When I first picked up Go it was to port a fairly complex Pyramid/SQLAlchemy web app to. Even though I started coding in C, and was still actively working on projects in C#, Objective-C &amp; Java - I really wanted to go running back into the arms of Python. I fretted about not having things like SQLAlchemy &amp; the many, many libraries there holding my hand. Two times I "abandoned" the port. Luckily I just kept at it. There was something about programming in Go that gave me joy. Something difficult to put my finger on. Now that I'm not trying to shoehorn in Python / Pyramid / ORM patterns in to my Go work, it's so much more effective &amp; satisfying.
Yeah small apps where the initial data at least is easy to recreate. In my case I end up going thru spurts on projects so being able to see everything in one place helps a lot with picking it back up. If I have to dig around in the database separate from the codebase it really slows me down.
Excuse my ignorance. How would one use http.FileServer with this?
I don't think this is necessary. abc.go package abc import "github.com/russross/blackfriday#v1.1" blackfriday.MarkdownCommon() somewhereelse.go package somewhereelse import "github.com/russross/blackfriday" blackfriday.MarkdownCommon() 
&gt; Go is “garbage-collected,” unlike other statically typed languages Um?
http://www.grymoire.com/Unix/Permissions.html its happening because your GOROOT is not accessible, elevate your permissions
That package doesn't use "net", the one you're getting the error on does. That would be my guess. I'd try the suggestion. 
It's because the person who compiled the distros package messed up and the .a files last touch date is older then the src files for that package. Therefore when building your package, go build believes the .a is out of date and try's to rebuild it, but it doesn't have root permission to overwrite the .a in goroot. If you can file a bug with your distribution about the messed up dates in the package. 
AFAIK Manjaro uses it's own packages, so the issue it's not necessarily on Arch.
Ofcourse I could use existing libraries (and for JS I surely will) but I decided to implement an HTML minifier and it turned out to be pretty quick. So I continued with a CSS minifier, both written in Go. I'd like to hear what you think or if some anomalies cause bad minification results. Feedback would be great! 
Yeah, but I can at least glance over the package. :D Taking a cursory look at the package contents I don't see any issue. I did notice that there was a recent update (-2) to the package, so perhaps there was an issue that was caught and fixed since you installed it. 
What do you mean?
Open source is more than open sourcing software. It's about maintaining, triaging, and community. I know lots of people who just go explore on github for repos who needs help, and then help out just for the good feeling of doing something with others for the good sake of it – helping out where help is needed. I'd say that is a big part of open source today, and in that form, open source is the goal itself.
There is a project called slurp that's cropped up recently that should handle what you're looking for. I'd link but I'm on my phone holding a sick toddler, sorry!
Yea, I looked into Slurp. I'm still new to golang so this project is more of a learning process. Also, I tried to understand how slurp works, and I couldn't grasp it. It looked a bit hacky. link: https://github.com/omeid/slurp edit: hacky isn't the right word. It looked complicated because it was getting around the same issue I'm having.
You can, but then you have to invoke 6g/6l directly instead of using the `go` tool. The `go` tool mandates one package per directory.
And here I thought that godep dumped all the dependencies into one location, and flattened the list. If you're looking at rescoping the dependencies to a local scope, that's possible. IDK how that will change everything else though - I'm not that smart. I'd be interested to see what it looks like in the language. I still think there's merit in the idea of all go only using the master branch in each location though. Like I said before, it just seem cleaner - I'd have to see the other side before I could really make a rational call, but I compare go to ruby and the dependency juggling in ruby is a turn off.
Thanks! Will do! And yea it should be fun, even if I don't get the perfect results
Thank you!
Thank you!
Thing is, you said open source is not a goal in itself. I argue it can be. Sure, for the dude who open sources some software, it's probably for the sake of the software, but for the helpful open source garderne (thanks for the term, Steve Klapnik) who decides to help out either triaging, patching, or whatever, I argue it can be for the sole purpose of that – doing open source. The gardener doesn't care what software he contributes to. He just sees that the bug list needs trimming and trims it.
I'm pretty sure my first sentence said 'I'm looking to learn Go,' so that's my goal. I'm sorry you feel so negatively about open source that it made it difficult to figure out what exactly I was asking about.
This is the answer. At least it's the one I came to post. :)
Great to hear that you need it! You can add JS minification by adding a command for the ClosureCompiler for example, but I will not in the near future attempt to write a JS minifier. Exisiting solutions are pretty good and employ several complex methods; it is unlike CSS and HTML a lot harder to write a JS minifier. The merge function sounds like a great plan, but I believe is out of the scope of the minifier. Maybe something for later!
From the webpage: New Features: * ORM support default settting * improve logs/file line count * sesesion ledis support select db * session redis support select db ... sesesion ledis?
OP here. This basically boils down to the fact that http://www.gopherjs.org/play/#/X44ffCG1Mz just works. Previously, you'd have to annotate the call to Do with `//gopherjs:blocking` when passing it something that might block (wheras a static call to f wouldn't have this problem). This affects both interfaces and function values.
Aside from the "session" typo, it is probably referring to http://ledisdb.com/
This is a huge milestone. It enables the following things to work: &gt; In order to motivate the usefulness of adding support for blocking `io.Reader` (or interfaces in general), let me just point out the following. If a blocking `io.Reader` is supported, then it is possible to wrap a [websocket](http://godoc.org/github.com/gopherjs/websocket) connection in a way that implements `net.Conn` interface. Doing that will allow using `net/rpc/jsonrpc` package for RPC. It will also allow creating an `http.Client` with a custom `http.Transport` that wraps around [xhr](http://godoc.org/honnef.co/go/js/xhr). All that will allow running more interesting existing Go code (that relies on those low level building blocks) and more possibilities in the frontend. All that wasn't possible before, but is now. And any more number of things that you can think of.
I haven't done any forking in my go code, but http://golang.org/pkg/syscall/#ForkExec looks like a good place to start.
I was reading about that before but I was under the impression that ForkExec would just run an actual OS/cli command and capture the output. I want to be able to fork a process off at a location in code and have both of them running so that I can accept a socket connection on a parent goroutine and fork it right into a new process while the parent continues listening for other connections on the socket. The child process would be able to continue on with the executable code and share some of the same scope variables as the parent -- would have to be managed some, etc. Is there a better way to do this? Maybe i'm thinking in the PHP realm too much. I just know that I can't manage a thread/goroutine as much as I can a process and that's really important for this.
Generally speaking, forking a threaded runtime is not a good idea. Note that goes well beyond "Go" to anything that isn't a single-threaded program. When you fork, you get a _complete clone_ of the process, and if you've got the possibility of varying threads running at the time, you basically don't really know what you're getting as a result of the fork. (Again, not a Go-specific issue.) Heck, even in a single-threaded world it can be trick to know about file handles and such. It seems more likely you'd want to offer the ability to run a program and feed it a certain starting set of data, or make available certain API calls (probably remote over a network), rather than fork anything. This hasn't got much to do with Go... you really need to hold foreign code, even "trusted" foreign code, at arm's length, because even if you trust the other coder to not be malicious on purpose you can't _ever_ trust them not to accidentally do something nasty. Your original PHP solution you described in the other comment also strikes me as extraordinarily dangerous. And let me underline this again, just to be clear... while, yes, I am a person concerned about security quite a bit, _even if_ you discard the security issues this is still not a good plan because just plain accidents could do terrible damage, and everybody has accidents.
There's currently no good solution for forking with Goroutines, so you'll need to run the third-party Go code as its own process. Do you actually need to host multiple apps on the same network port? If not, you can make the "accept a connection" code part of your SDK and put it in the app's code without any forking. Worst case (if you need to share a single TCP port) you can proxy the connections through your sandbox manager and make *new* connections to the app's Go processes. On a different note: running a separate Go process for every incoming connection kills part of the appeal of Go, and you're back to the Apache multiprocess worker model instead of the much nicer epoll-backed goroutine scheduler. What are you trying to solve with the 10-second timeout? If you're trying to reduce CPU or memory usage, you might be better off directly limiting those instead of trying to influence them by killing processes (which can actually make high-load situations worse, as users will retry failing processes and load will compound). Go will be better at both CPU and memory usage if it's handling several connections in a single process.
I considered doing that too -- even with our current PHP implementation. But with PHP, it wasn't really possible to have a forked child accept the new socket connection. The parent would have to accept, then fork at that point. Can that be handled far better with Go to where I could have a different process accept the connection?
Returning a blank `MyStruct` is not inherently bad, however you will have to return an instance of `MyStruct` to prevent a compile error. func Foo(x int) MyStruct, error { if x &gt; 1 { return MyStruct{}, errors.New("foobar") } else { return MyStruct{"thing"}, nil } } In order to return a `nil` value instead of your struct, you will have to instead use a *pointer*. func Foo(x int) *MyStruct, error { if x &gt; 1 { return nil, errors.New("foobar") } else { return MyStruct{"thing"}, nil } } Unless you actually want to work with a pointer, it isn't recommended that you return a pointer here. With regards to whether it's best practice, right and proper, etc -- if an error value is present, it should be safe to assume that your `MyStruct` returned is erroneous and, as such, should be treated as useless. Returning a blank struct, or a *zero value* of a struct, isn't bad at all. EDIT: typo
As others have mentioned, what you're asking for is likely unworkable with Go. Might I suggest unit tests for your PHP codebase? Generally speaking, unit tests make up for the lack of strong-type guarantees.
Right - that first part answered it. I wasn't assuming that people would attempt to do anything with an empty struct, I just wasn't sure how to go about doing it - thanks!
It's more than just worrying about strict type definitions though. We need some of the more system level functionality that Go/C provide and where we can pre-compile to handle even heavier traffic spikes. It sounds like, although I may not be able to solve it the same way I did with PHP, there are some other ways I can still make it happen. More research to do!
That's an awesome idea, any thoughts on how API key/s would be stored and also uniqued?
Sooo, if you're talking in terms of actual speed of interpreted vs compiled languages, then yes, you're going to get hurt by PHP/Ruby/Python or whatever. Otherwise, it's time to invest in your testing more thoroughly. From a Go standpoint, I'm not at all familiar with what you're trying to accomplish. What I am familiar with is that Go is pretty darn fast. That being said, the libraries surrounding PHP via composer are a lot more abundant and more developed. While this is improving in Go land, I found that I spent a lot of additional time hooking things up in Go and trying to figure out which 10 star Go library was least likely to be broken and or break my app in the future. While Go is super trendy right now, and I admit that I've really enjoyed creating everything that I've worked on with it, you should really look at Rust. I'm not super familiar with it at all, but I think that it might be better suited to what you're looking to do. From my understanding, Rust is more like C modernized and built for web, whereas Go is more like Java/C++ mating with Ruby. Just my two cents.
There is no mechanism for compiling then dynamically loading code into a running Go program so any solution you choose here will involve combining some untrusted code with a small runtime you provide and running that as a subprocess of your main process -- if you've used appengine, it's that. Running those subprocesses securely sounds like the wheelhouse of docker or the other container tools. 
It's generally most common to put your most important functions first. Thus, all your helpers would be at the bottom.
Yeah, I knew that PHP was going to be slower, but that was fine for our MVP/PoC. Hell, i'm amazed that we were able to take a language like PHP and develop what we did with it (daemons, process forking, socket servers, IPC, etc). Looking for a lower level language to take it to the next step. I'll take a look at Rust but so far Go seems to be the answer for most of our problems. Thanks :)
Parent process running a TCP socket server would listen on say port 20050. When it detects a new incoming connection on that port, it'd spawn a child process. That child process would accept the socket connection and handle the request. So it's not really IPC/process-to-process communication but rather handling external connections. Would net/rpc still be preferred in that scenario? I figured it'd end up just the 'net' package using net.Listen(). Thank you for the links. :)
Can you modify your benchmark? BenchmarkLogxiComplex contains : l.Debug("debug", complexArgs...) Do the same for logrus: complexArgs =logrus.Fields{"m": "bench", "key": 1, "key2": "string", "key3": false} ... l.WithFields(complexArgs).Debug("debug") 
The Go Playground might have some relevant ideas, as it runs arbitrary Go code in a sandboxed environment with "simulated" fs access, etc.: http://blog.golang.org/playground
That is actually where I learned about NaCl / Native Client. :D
For anyone else having problems with the ZIP file linked on the announcement page (https://github.com/joshsoftware/golang-challenge/tree/gh-pages/data/ch1/golang-challenge-1-drum_machine.zip downloads, but is corrupt) It seems that a better link would be https://github.com/joshsoftware/golang-challenge/blob/gh-pages/data/ch1/golang-challenge-1-drum_machine.zip . It may be worth updating the link on the announcement site.
Also interested in how errors should be printed.
Regarding errors: Effective Go (the bible of idiomatic Go, if you will), states that: &gt;"When feasible, error strings should identify their origin, such as by having a prefix naming the operation or package that generated the error. For example, in package image, the string representation for a decoding error due to an unknown format is "image: unknown format"." It also mentions that since errors are just an interface, you can and should implement more complex error objects for your own purposes, that include more context. Personally, I'm using a little utility struct I've made for errors, which includes a full backtrace of the path that lead to triggering this error. It's very useful for unit tests, etc. 
Go NacCl sandbox: https://github.com/golang/playground/tree/master/sandbox 
&gt; From my understanding, Rust is more like C modernized and built for web And Go is not a modernized C built for the web. I don't know Rust hence my question - I want to build HTTP+TLS hello-world server and host it on some cloud - what are advantages of Rust over Go?
For ordering of functions I like to keep them in order of readability. Here are somethings I care about when ordering functions 1. Similar functions together 2. Public or more usable functions on top 3. Private functions at bottom
Yeah, the author plays too much video games ... ridiculous.
I'm kind of surprised at the responses here. Why not alphabetical order? "Most important" is subjective and changes over time. I get that IDEs can give you a sidebar listing in alphabetical order but nothing drives me crazier than when I DON'T have that sidebar and I can't just e.g., jump down two functions from "funcA" to find "funcC". And then wondering where I should put "funcX" if everything is out of order, etc. It's less trouble to keep everything in alphabetical order. It's predictable, and there's no question about where things go. Also, in Go I take it a step further and divide the file into public functions (by alphabetical order) and private functions (by alphabetical order).
Why not have Go manage the go routines? There's no reason you couldn't have a helper command that provides all the same functionality as managing threads. Anything else is not going to be idiomatic Go and will be an uphill battle.
The API keys/shared secrets would be associated with a root domain and/or perhaps an auth realm or user name. Here are some examples: * https://msdn.microsoft.com/en-us/library/azure/dd179428.aspx * http://docs.aws.amazon.com/AmazonS3/latest/dev/RESTAuthentication.html * http://docs.rackspace.com/files/api/v1/cf-devguide/content/Retrieving_Auth_Token.html
As per [this stack overflow post](http://stackoverflow.com/questions/1997622/can-i-open-a-socket-and-pass-it-to-another-process-in-linux) , SCM_RIGHTS is the flag that lets you do this. The go syscall lib conveniently wraps this up in [UnixRights](http://golang.org/pkg/syscall/#UnixRights) and corresponding [ParseUnixRights](http://golang.org/pkg/syscall/#ParseUnixRights) (click the function name to view the implementation). The [test suite](https://github.com/golang/sys/blob/master/unix/syscall_unix_test.go) is a good place to look for example usage. So now that we know how to send a filehandle over a unix socket, now it's just a matter of converting your TCP socket to and from a file handle. This can be done with [TCPListener.File](http://golang.org/pkg/net/#TCPListener.File) and [FileConn](http://golang.org/pkg/net/#FileConn). So putting it all together. (roughly) 1. Create and listen on your TCP socket 2. Create your child process and connect to it via a unix domain socket 3. convert your TCP socket to a file handler and pass it to your child process over the unix domain socket 4. convert your handler back to a connection in the child 5. some sort of cleanup in the parent Again, I haven't actually done any of these things, so I can't guarantee that this will work or that it will be easy That said, since go doesn't support traditional forking/demonizing, this alternate approach looks like your best bet (assuming you're on unix/linux). I'd recomend making a proof of concept to validate that this approach works as expected.
Expanding on the existing comments, it is language convention that unless otherwise documented, an error return means you __must not__ use the non-error return value for anything. This is because it's impossible to return an "invalid" answer for the non-error value in general. You might think it was "safe" to return nil, but even this is not correct. Since nil pointers can still have methods called on them and may still do something sensible, a "nil" return may be perfectly valid! It's worth saying again for clarity: In general there's no way to return an "invalid" object. As a side effect, for better or worse, I don't tend to worry too much about whether I return a "half-constructed" object when returning an error. I don't do it on purpose, but if it happens (named arguments, maybe) I don't go out of my way to "zero out" the half-constructed object, and, again, that's because the "zeroed" object may still be "valid" anyhow. It's up to the user to not use the result except for those vanishing number of methods/functions where you can deliberately get both a valid object and an error and are clearly documented as such.