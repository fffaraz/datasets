Yes, that's correct. You can build/deploy just fine if you use the official Go distribution or compile them yourself from official sources.
https://play.golang.org/p/3bfC8ao33Z You can implement the unmarshalling on the type that's at issue, and by embedding the 'parent' type you retain all of its methods and fulfill the same interfaces. You just make it fulfill one more. This is pretty much the canonical example of why interfaces are good practice, I pass the URL type directly to the format function and because it embeds url.URL which has a String() method, the formatting is fine. God knows what Ukiah Smith is smoking but his method is worse than the actual worst case (partially unmarshalling into RawMessage structs, which I can explain if required)
The above example is a simple, drop-in replacement that does what you want. A more detailed discussion on different ways to do this is [at the Go blog](https://blog.golang.org/pipelines) in particular [the section about "fan-out, fan-in"](https://blog.golang.org/pipelines#TOC_4.). Note that your current usage doesn't need anything more complex than the example at the link /u/infogulch posted.
Great question! I had not seen that before I started this project. It looks like we share the same goal with traditional posix style flags. But the first thing that jumps out at me is implementation. The setup code for pflag looks more like the flag library that comes with go. var ip *int = flag.Int("flagname", 1234, "help message for flagname") var flagvar int flag.IntVar(&amp;flagvar, "flagname", 1234, "help message for flagname") My library behaves more like Python's optparse library. One of the reasons I came to like Go is because I had a lot of fun programming in it, similar to the way I felt about programming in Python. The other thing is that flag2 generates a help message for the programmer to call within their code. I didn't read anything like that on the pflag readme. [f.Usage()](https://github.com/ProfOak/flag2/blob/master/test/test.go#L66) [How the generated text looks](https://github.com/ProfOak/flag2/blob/master/test/README.md) optparse in python: from optparse import OptionParser parser = OptionParser() parser.add_option("-f", "--file", dest="filename", help="write report to FILE", metavar="FILE") parser.add_option("-q", "--quiet", action="store_false", dest="verbose", default=True, help="don't print status messages to stdout") (options, args) = parser.parse_args() flag2 in Go (modified version of the code on my readme): package main import ( "os" "fmt" "github.com/ProfOak/flag2" ) func main() { f := flag2.NewFlag() f.AddString("n", "name", "this flag wants a name as input", "billy") f.AddBool("b", "bool", "this flag will store true if used", false) options, args := f.Parse(os.Args) } 
Yeah fair point. I should have grabbed some of my working code instead of a quick hacked up example.
I'll take a look at it, but fwiw GetXXX in Go would just be XXX. 
In terms of videos, there's also Derek Banas: https://www.youtube.com/watch?v=CF9S4QZuV30 This guy has a whole series of videos on various languages. Good overviews, all of them. 
linuxbrew already helped me two times getting Go on distros that either don't have a Go package or fail to keep it current.
nope.
Hi, The OReilly videos are a bit more expensive but they're worth it http://shop.oreilly.com/category/learning-path/go-fundamentals.do Introduction to Go Programming is great for getting started.
There's also [gorump](https://github.com/deferpanic/gorump)
Thanks for the help!
That I'm not sure about specifically. However, I'd say you could with a bit of configuration. I honestly don't see why not. 
&gt; Using them you can build almost lock-free system (Dmitry Vyukov proposed even better optimizations but we are not there yet) What do you mean? Any link about this?
Thank you, would appreciate that! As for the naming: I went for names like that after reading the [Effective Go](https://golang.org/doc/effective_go.html) article but then ran into naming collisions because I have structs with the same name. type CountryRates struct {} func CountryRates(countryCode string) (CountryRates, error){} How would you counter this? 
The Go thing to do here would be name it in the format of NewXXX. Looking in the standard library is usually a good way to learn how to best do this stuff. See https://golang.org/src/io/io.go?s=14421:14489#L423 for an example
Great, thank you. I love that you can look through all the stdlibs. Are you usually looking this up online or do you have some kind of editor trick / Dash / ... I could use? :)
Nobody is waiting. PG and SQLite are standards. But it doesn't hurt to dream.
Just looking it up to be honest. VSCode though has an amazing Go extension and when you install all the tooling it works amazingly! Also this is a great video to watch https://medium.com/google-cloud/go-tooling-in-action-eca6882ff3bc
I'm writing it just now, hang on :)
Uh, didn't know that. Switched to MIT License :)
The reason we chose GraphQL over say Cypher was because GraphQL allowed us to retrieve a graph, and not just lists. While this might seem a bit complex for simple cases, it's a very powerful result -- for e.g., in your query above, you can easily figure out which movies did tom hanks do with which directors. It won't just be a list of movies, or a list of directories. It would be a complete sub-graph with tom hanks as the root with movies and directors as nodes in the graph. You can then take this data and simplify it to just a list of movies, or a list of directors. But, you can't do the reverse (go from list to graph), which languages like Gremlin or Cypher force you to do.
Eh, of course it can be used in other apps, however those apps will also fall under the GPL license. In practice, where you can't use it is in proprietary apps since the GPL makes sure that the end user has a right to the source code should they so want it.
Why would new libraries/frameworks bring their own context, when Go now has `context.Context`?
[Déjà vu](https://www.reddit.com/r/golang/comments/4p3kg1/iris_the_fastest_backend_web_framework_for_go/) [Déjà vu](https://www.reddit.com/r/golang/comments/4ot75d/katarasiris_the_fastest_web_framework_for_go_in/)
The sender should close the channel, not the receiver. And that way you can get rid of the 'quit' channel as well. Just return from your goroutine when the channel has been closed!
copied from my comment in /r/programming This is a rather poor example of Go code - massive interfaces, and the author "doesn't believe in unit tests" - https://github.com/kataras/iris/blob/master/tests/tests.go#L3-L5 So think twice before using it -&gt; stick with `net/http` and maybe a alternative http muxer (gorilla mux / httprouter / etc) if you really need one.
I am unfamiliar with the unik platform, but as far as I can tell unik is some sort of Docker alternative for unikernels. It will use an external unikernel compiler to compile unikernels and manage them. Currently, unik uses Defer Panic's gorump to build Go unikernels. Gorump is based on rumprun which combines the NetBSD kernel and modules to provide classic operating system services (scheduler, memory management, networking). We have opted for a different approach, similar to that of the MirageOS project. Our aim is to build highly specialized unikernels, starting from a very minimal operating system. Unigornel could be incorporated into unik as an alternative unikernel compiler for Go.
Thanks for the info! Just changed the source file, now on Destruct() it will wait for the waitgroup and close the channel, if the channel is closed the poller goroutine will return from the execution
You may have better luck with a released tag (2.0 atm). Otherwise, please direct bug reports to the official issue tracker: https://github.com/schachmat/wego/issues
It was merged into /r/golang.
Thank you i'll try that.
BTW, if it's like `optparse` and you're thinking about renaming the package, you could rename it to `optparse`.
Due to the global variable https://github.com/dannyvankooten/vat/blob/master/rates.go#L25 and the missing mutex your package is not thread safe.
Some of the points that are made in the article have some value, but I think the issues presented require a far more nuanced approach than the author takes. If you'd like me to elaborate on a specific topic please ask. His main concern, that debugging unikernels in production environments is impossible or at least very difficult, is probably justified. I don't have any experience with unikernels in production. However, I don't see any reason why this problem (if it is indeed present) won't get solved in the future.
I realised this today as well, but wasn't entirely sure about it, multithreading is mostly new to me. So is this as simple as creating a `sync.Mutex`, locking it before filling up the global variable and then unlocking it again when done?
I suppose I can add some benchmarks, but besides that: - The biggest difference I can see is that I return a map of errors whereas ajg/form panics - Don't have a predetermined list of allowed time formats, can override time and any other type you wish both for field and map key. - Don't support TextUnmarshaller as it's not suitable ( noted in README ) - I'm sure there's more, haven't looked int ajg/form much yet.
I could write this in Java with half the code
Did you almost lose your vision implementing the 3d version? Because I feel like I almost went cross-eyed permanently when I made my implementation of it.
Why not tell us what it does?
Yeah, the debugging part seemed to be the best argument. Though with good logging, metrics, profiling, and perhaps Delve-remote-debugging-enabled instances, this can be somewhat mitigated. For performances, I'm thinking the only way to truly know is to benchmark on a case-by-case basis. For security: he's basically saying it is not a silver bullet. Sure, but reducing the attack surface still sound like it should help. For size: he seems to say that unikernel can be done badly and end-up bigger that some lean OS like Linux Alpine. Sure, everything can be done wrong, to be compared on a case-by-case basis again. For porting/compatibility: &gt; hope everything you need is in OCaml! That seems stupid, unikernel are designed for single apps, which most of the time are written in one language. (BTW, I'm guessing Unigornel does not play nice with cgo, does it?) So not much questions actually, it's just that your post made me discover unikernels (thanks) and I wanted the opinion of someone who already used them.
Oh hey, this is my code! I can answer that. I wrote the code because I wanted to use a non patented noise algorithm (it's not something I came up with), and couldn't find a go implementation of opensimplex. The readme doesn't introduce the concept, because I figured anyone looking for it had already been sold on this specific algorithm. If you have more suggestions, that's great - I'll spend some time on the readme tomorrow.
It was a little rough to debug, but not the worst; I based this on a reference implementation in another language - in fact, the tests verify the output against test noise generated by the reference code. EDIT: I found a blog post I wrote about making this. It includes one debugging story about how Go's high precision constants made my tests fail: http://blog.ojrac.com/opensimplex-noise-in-go.html
you can use values of type v1 in places where an interface with a matching method (or method set) is expected. using your example, here is an illustration: https://play.golang.org/p/9pqbTydv13 
Sorry I assumed people would recognize what it was when I added "perlin noise" to the title.
Yes.
Ok, thanks for the corrections. I fixed some of those, but if you find more feel free to send me a PM or even PR.
Thanks.
Exactly. &gt; BTW, I'm guessing Unigornel does not play nice with cgo, does it? It's certainly possible to write some parts of your application in C or an other language, and integrate them with cgo. However, we don't provide a POSIX-like environment, so the possibilities are very limited.
By default Gmail only allows OAuth authentication. [See the announcement](https://security.googleblog.com/2014/04/new-security-measures-will-affect-older.html). There's also a [long discussion in the Thunderbird bug tracker](https://bugzilla.mozilla.org/show_bug.cgi?id=849540) about this.
Just add "proto" tags to your structs and use this: https://godoc.org/github.com/golang/protobuf/proto (or am i missing something here?)
From /u/ojrac's source, it appears to be a means of generating graphical textures for games. Most people don't work in games programming. To give an analogy - I might refer to the Simplex Method (which is not related as far as I know), and most people would have no idea that it is used for mathematical optimisation.
[RFC 5322 defining the Internet Message Format](http://tools.ietf.org/html/rfc5322) requires that lines are delimited by CRLF. It's probably wise to stick to that, even if some implementations handle LF delimiters.
Nice Work! Looks like a great start. just some things that may be a nice-to-have that I tried to address in [statics](https://github.com/go-playground/statics): * Maybe an option to decompress files on startup or store decompressed version after first decompression to avoid doing it multiple times ( would speed up serving of files from http.FileServer ) * Support Symlinks. It's not fun but whenever I embed it's mostly my html assets javascript, css and images which a good deal of the time I need symlink folders for images etc. embedded in a CSS library. * Support for generating multiple static files within the same package eg. statically embed html assets and website certificates, where the folders happen to be at the same level in the same package. The reason I would not want to put in the same folder is when adding static files to http.FileServer I can have my sites cert files exposed. * Possibility to embed the generation command right inside the generated file using go:generate for easy of automated builds. Feel free to steal anything from my package that may help and keep up the great work :)
I don't think it works like that.
If that is the case then why the article doesn't use OAuth?
lolwut xD
No it doesn't exist. I was looking for this for my own project https://github.com/micro but there doesn't appear to be an easy way. 
But Pony is pre alpha status. Crystal is a bit better in that regard but still only at 0.18.
right. at least at first I just want it for use in RPC args/return values, ie. so I can use grpc, so I don't think that's an issue. But you're right that actually using it eg. for other implementations will not be straight forward
&gt;Maybe an option to decompress files on startup or store decompressed version after first decompression to avoid doing it multiple times ( would speed up serving of files from http.FileServer ) Given the amount of use cases for embedded assets, and each having it's own best practice for caching of the assets, I'd say it's fine to leave this feature out.
Probably because it's more trouble to implement. You need the user to open a web browser.
Glad you found it! Feel free contact me on Reddit or at rohan@sourcegraph.com if you have any questions or suggestions. :)
where did you see that pony was pre-alpha? certainly not production ready, but pre-alpha seems to be overstating it. also still worth checking out if only to appreciate some of its design ideas.
For our [projects](https://github.com/dedis) we wrote a [library](/protobuf) based on reflection which (at least to some extend) does what you describe. I would say: our lib is great for rapid prototyping but it has quite some downsides and especially the feature you are describing (generating .proto files) [exists](https://github.com/dedis/protobuf#generating-proto-files) but isn't really well tested (at least we don't really use it). But I also agree with Rob's [view](https://www.reddit.com/r/golang/comments/4p9i51/looking_for_a_reverse_protobuf_compiler_to/d4jgkci) here.
cool. thanks!
That's nice. :) I've been thinking of collecting commandline utilities written in go as a hobby and I think this would make a great addition to such a collection.
Gotta make sure the gophers you hire aren't gonna steal all your stuffed gophers, bro. 
- Inheritance trumps composition. - Just use an empty interface, then you can can pass whatever you want. - "Oh yeah, I've heard of Go, that's that new JVM language right?"
A string is a slice of bytes, but a slice of bytes isn't necessarily a string. In Go all strings support unicode via the UTF-8 encoding, which has variable width for characters - accessing the third byte in a string is not necessarily addressing the third character. The official blog is thorough on this subject: https://blog.golang.org/strings
Yep, opensimplex was made for procedural generation by the original author Kurt /u/KdotJPG, who frequents /r/proceduralgeneration.
Thanks, most of that func is based on the [stringer](https://godoc.org/golang.org/x/tools/cmd/stringer) tool, it has some pretty great stuff for making go tools. Edit: I kinda like that simplicity of your own tool, it's basicly how I started out too :D
Thanks for your suggestions. * I left out `http.FileServer` support on purpose, so 1 and 3 doesn't really apply here as it's up to the user to manually handle the `[]byte` slices returned. * Symlink support sounds like a good idea. * I'm already using `go:generate` ;)
Not just game textures, anything related to procedural generation (what Perlin Noise is pretty well known for). But yeah, point taken. I need to go outside /r/proceduralgeneration more.
This was already asked here on reddit - https://www.reddit.com/r/golang/comments/4126jh/is_err_nil_the_best_idiom_for_error_handling/ 
Don't worry about it. Unless you **need** it. Just put your packages you need in your imports and be done with it. Can read more about it here or by googling vendoring. https://github.com/golang/go/wiki/PackageManagementTools
I wrote an article a while back, it's more geared to vendoring, but it does cover most of the ways that one can handle dependencies. Hope it can help :) [go-vendoring-for-consistent-builds](https://medium.com/@joeybloggs/go-vendoring-for-consistent-builds-e0dc8187606e#.9m2urzdww) 
I actually wrote the exact same thing for a project in college, but in python. The site eventually blocked me by IP for sending too many requests. Had to tweak the script to run against allrecipes.com :) 
Can anybody elaborate on the typical problem(s) that would be solved by using this ?
Yeah it's kind of weird, me coming from PHP + [Composer](http://getcomposer.org) where we manage the library versioning because of breaking changes; simple imports seems weird unless packages rarely change in golang.
Stay away from [Godep](https://github.com/tools/godep). My team loses 30 minutes to an hour every time we need to update a dependency because it never quite does what we expect. We've gotten around it by documenting sequences of commands that should be single commands in the first place. We'd like to switch to [Glide](https://glide.sh), but we don't yet have any practical experience. What convinced me it would be saner were mattfarina's comments on [this discussion](https://github.com/golang/go/issues/13517). Among other things, he [maintains a list of use cases that a standard dependency solution would need to solve](https://github.com/mattfarina/pkg/tree/master/use_cases) and has a [great guide to prior art in other language ecosystems](http://engineeredweb.com/blog/2015/pkg-mgr-overview/).
this is _only_ ok inside your `main()` function - never anywhere else
https://github.com/pilu/fresh
Hi all, I have made a framework for my internal usage, I want to get your opinions on this. It is not complete yet, but it should be giving an opinion about its main features. In most frameworks, most of the time I do redundant parameter validations for POST requests or query parameters or URL parameters. So, I made my route handlers accept custom functions with struct parameters so that handler is only called if the request body/param/query is validated. I think it saves me time and helps me write more testable api end points. Also, I did not like using global parameters for database connections, and made my framework accept custom types and provide them to handlers when needed, using with very basic dependency injection. I know it is different than most and uses some questionable reflection methods to achieve this, but it really helped me to develop faster and I would like to hear opinions on it. Thanks.
My experience teaches me that every project **needs** to vendor, pin dependencies, not just golang. 
Dependency management in Go is kind of a joke. Since Google does things differently (huge monorep shared across the company), there doesn't seem to much motivation from the core team to solve this problem. They've left it to the community solve. Which is a terrible idea. Not only is there a like of bikeshedding about how things should work (using JSON vs yaml for the dependency manifest), there are also a few camps with irreconcilable philosophical differences about how package management should work. As a result there has been a lot of noise with a laughable amount of progress. Doing dependency management right is certainly very difficult, but compare Go's progress with Rust on managing dependencies. The Rust team took it seriously and got Cargo. The Go team didn't and as a result we have dumb things like library maintainers being told they should not vender dependencies. In the end, you should probably go with https://glide.sh/ . The glide guys/gals seem to be pretty practical and focused on shipping a useful tool. You're out of luck if you're writing a library though.
If you are working with software that constantly breaks its own api, sure. God why. Most of the golang packages will maintain a stable api for a long time so updating is a non issue and that is good enough for the layman. 
It's amazing to me that with a language and ecosystem that's so focused on being practical, teams are willing to play russian roulette with their dependencies. All it takes is one idiot who decides to violate the social contract and you're suddenly wasting time trying to figure out why something broke in subtle ways. Lots of great examples from the javascript world, but my favorite is : https://www.reddit.com/r/javascript/comments/2whrl9/underscore_18_makes_last_minute_breaking_changes/ :)
If you keep your own projects in Git, I suggest looking at using forks of libraries and adding them as submodules. A tool like https://github.com/dpw/vendetta might be helpful. Submodules guarantee exact commit of the library. Since you fork the library, you can make your own branches to have different snapshots in your projects as needed. Could be a lot of juggling initially but gives you complete control, can be automated, and it's "just Git".
Would it be nice? Sure. But in it's current state, go wasn't designed to be a language with a constantly changing api. Also, just because an opinion is different than yours doesn't mean you down vote it. That isn't what the button is for. 
There are a lot of times where the reality is some code repetition is worth the result - in this case not having to deal with arguing over the other few ways to do it.
I've just been using upstart. Is that a bad idea?
I don't see it mentioned here, so just make sure people know, Go has a built in vendoring solution. It's on by default in Go 1.6. I feel it needs more documentation, but here's the proposal: https://docs.google.com/document/d/1Bz5-UB7g2uPBdOx-rw5t9MxJwkfpx90cqG9AFL0JAYo/edit
I use fresh/docker in dev. In production I have used http://supervisord.org/ and Upstart. My recent projects runs on Docker only. 
If you work in a project-focused manner, then gb might be something to try out: https://getgb.io/ We use it at work for close to 20 projects, and our experience has been rather positive.
https://github.com/FiloSottile/gvt
We vendor using git submodules using [`git freeze`](https://github.com/nicerobot/git-freeze) (which can also subtree) and it works great. As long as you only have few projects, it requires a little more work than just letting `go get` keep all your dependencies in GOPATH. But once you're working on dozens of repositories among many developers all sharing fast-changing libraries, vendor using submodules is a huge win since all your repos will always work no matter how dependencies are modified externally. In other words, each repository is entirely under the control of the repo maintainer. They determine when to uptake library changes and can integrate as needed on different time-scales than when/how your GOPATH libraries change. Multiple repositories can each use different versions of the same library and you can work on them in parallel without them interfering with each other through the global GOPATH folder(s). Honestly, don't listen to criticism of vendoring or go dependency management. I've been using submodules to do this since before vendoring was even considered (~Go 1.2 by isolating the go build to each repository) to great effect. And you don't really even need tools, even git-freeze, to manage them, besides, of course, `git` and learn how to work with submodules. Clone all your top repos into your GOPATH (`git clone github.com/nicerobot/someapp ${GOPATH}/src/github.com/nicerobot/someapp`) and submodule libraries into the app's local `vendor/`, e.g. `git submodule add github.com/nicerobot/somelibrary vendor/github.com/nicerobot/somelibrary`, for your `import "github.com/nicerobot/somelibrary"`. Done. Dependencies maintained. To integrate with a new version of somelibrary, `cd vendor/github.com/nicerobot/somelibrary; git pull`. Dependency updated.
Personal opinion/recommendation: Use the simplest tool possible for the job. The ones I've tried and liked are [govendor](https://github.com/kardianos/govendor) and [gvt](https://github.com/FiloSottile/gvt) with gvt being the one I am using. Avoid glide.
Here's my two cents: Based on how `go get` works, here's what I'm seeing: $ find $GOPATH -type d -name '.git' $HOME/go/src/github.com/aws/aws-sdk-go/.git $HOME/go/src/github.com/garyburd/redigo/.git $HOME/go/src/github.com/golang/lint/.git ... If they're all just git repos, then writing a dependency mgmt tool shouldn't be too hard. Use Yaml for the interface and (in the beginning) don't support dependency discovery via recursion. Just let the project maintainer(s) figure out what versions they want of various projects. --- Project: Name: My Golang Project Version: 1.0.0 Repo: github.com/foo/MyGolangProject.git Dependencies: aws-sdk-go: # human-friendly label, no spaces or symbols preferably Version: 1.0.2 # commit hash, tag, or branch Repo: github.com/aws/aws-golang-sdk.git mux: Version: 3.0.0 Repo: github.com/golang-web/mux.git Then for each item in the yaml file, do this: $ git clone $dependency.git /tmp/$label $ cd /tmp/$label $ git checkout $version -b $version $ cd $YOUR_GOLANG_PROJECT_DIR Lastly, execute this for each dependency: $ go get /tmp/$label Of course, I haven't tested the above, but I do have a Golang project that has experienced a breaking change in the AWS Golang SDK -- so I can definitely see the value in a tool like this. Problems: 1. How to handle multiple projects which use the same `$GOPATH`? 2. Actually write this and find other problems... :D
Sadly mostly true. However, I would put the slow community progress down to (a) the complexity of the problem, (b) lack of clear direction from the Go team, and mostly (c) it's hard to make a lot of progress with part-time work from volunteers. Not a love of bikeshedding.
&gt; might it be a good idea to auto-seed the PRNG in Go, just like Python does? Go does autoseed the PRNG, it autoseeds it with 1. https://golang.org/pkg/math/rand/#Seed
I first thought it was the same blog post as a few days ago, but its a kind of followup, to show how to use oauth2. Thank you !
In floating point there are 2**52 numbers in [0, 1), if you pass in a max which is greater than that some numbers won't occur in your stream of random numbers. int can be 64 bits wide, so that would be quite a lot of missing numbers. You also end up with a non-uniform distribution due to the ways floats work. From a quick test with max=100 0 occurs half as many time as it should. Also python attempts to do this to start with: k = n.bit_length() # don't use (n-1) here because n can be 1 r = getrandbits(k) # 0 &lt;= r &lt; 2**k while r &gt;= n: r = getrandbits(k) return r which is the same method that go is using. It falls back to generating from floats only when getrandbits isn't defined, which it is for the builtin random calls.
oh that looks great and simple, I was going to spend my weekend writing something like this tbh. Saved me a weekend.
We use supervisord in production - we are constantly keeping two c4.2xlarge boxes at load without any problems. 
I haven't. I like my `git-freeze` because, well, i wrote it :) and i like that it's incorporated as a git command (though i need to change the flags to be consistent with git). There's a few now that support submodule vendoring. [`manul`](https://github.com/kovetskiy/manul) is the latest i've seen but still haven't tried. https://github.com/golang/go/wiki/PackageManagementTools
0 appears half as often likely because you chose the wrong rounding mode.
The vendor folder just provides a place to store code - it's not actually a full-fledged *solution*.
Yes, but the difference is you get to chose when to take the time hit when you do upgrade, so you can schedule the work appropriately.
glad to see glide there, even if it's sorta reluctantly :) glide should work equally well for libraries as for binary-oriented projects. that's very much the design goal. also, we've got a heap of changes Coming Soon™ that, with any luck, will let us get somewhere close-ish to the level of Rust's Cargo ecosystem.
The long explanation for why this is a hard problem: https://medium.com/@sdboyer/so-you-want-to-write-a-package-manager-4ae9c17d9527 EDIT: why it's a hard problem, and why the "this shouldn't be this hard" comments here are...not really accurate
lol, no good answers and seems far from consensus. I do personally like govendor, but the cli is offers too much control that leads to confusion
Right, I should have been clearer - it provides a place to store code that's used by the toolchain. Conflict resolution is one of a minor mountain of considerations. Typically "management", per the OP, entails something more thoughtful than just tossing a bunch of files into there. &gt; As other people have stated, don't vendor your dependencies if you're writing a non main package. The tip of a very large iceberg. But yes, unless you can assume the people depending on your code are using a tool that can perform vendor stripping (like glide), then it's not safe to commit your deps into a lib. But just because you don't *commit* your deps into `vendor` doesn't mean you can't use `vendor` to good effect.
Storing credentials in localStorage is [dangerous](http://blog.prevoty.com/does-jwt-put-your-web-app-at-risk). Cookies are the only correct place to store them. EDIT: ... for a browser-based thing.
In your example, where does `git freeze` come in, and how does it help manage if a dependenc's update breaks your build and you need to roll back? Do you have to go into the submodule and checkout the last working commit?
I tried using manul (https://github.com/kovetskiy/manul) in combination with govendorexperiment that is default now. It manages creating and updating git sub modules for referenced go libs that work with GOVENDOREXPERIMENT/go 1.6. It seems to work very well as far as I can see and it adds little to no overhead that deviates from standard tooling.
It's also nearly identical to the way C did, and history is replete with examples of bad things happening when people forgot to check the errors. Big Go fan, but the error handling is a weakness that I desperately hope will be corrected in the future.
This is fantastic, thanks. So much better than littering your code with if/then/else statements! No idea why you're being downvoted...
You got mentioned at the golang weekly! http://golangweekly.com/issues/115
glide will clean up vcs dirs, if you pass the `--strip-vcs` param. when the new engine comes in, there won't even be a choice anymore; vcs dirs will *always* be stripped, no options needed.
Glide is badass. 
&gt; A great rule of thumb for Go is accept interfaces, return structs. Counter-point, return `error`, not the concrete error type.
Maybe it's because I had to seed the PRNG in BASIC when I was a kid, but how does an experienced programmer see the same output out of a random function and not immediately think, "Oh, it must need to be seeded with the time"? Sure, a junior programmer wouldn't think of this, but an experienced programmer should have seen this issue a dozen times already.
Avoid Windows.
He's probably talking about the server, which can now run "natively" on Mac instead of inside a VirtualBox VM.
&gt;Can you receive the error, and not check it? You can ignore it if you blackhole it (assign to `_` variable) or calling the function without assigning its return values to any variable. If you do it though, you better have a good goddamned reason.
What do you mean by "concrete error type"?
Thanks! Did you mean `install.py` though?
Yeah, that's slightly better than C, but I'd still far prefer exceptions. Code Complete anyone?
Agile development! When you need more, compose it!
I prefer exceptions until I actually have to maintain the program or I'm taking the reigns of someone else's. I only like them if they're checked, and in that case they only add clutter over simple error values.
Create a new text file in the project directory and name it README or INSTALL. Using a pseudocode, write there the necessary steps to setup the application dependencies. Follow these file instructions when it is needed and voilà, you will have managed your dependencies.
This lesson took me a while to grasp, and I still wrestle with the idea of lots of site-specific, often duplicative, tiny interfaces. But it actually works well.
https://github.com/qrtz/livedev
This is a problem that crosses language boundaries. In any language, tasks that can conceivably take longer than half a second should be added to a queue of some sort and then you can let the user know that the task is done later. For example, in Python, you would do this using a Celery-Rabbit MQ task queue. Go gives you a range of solutions from the robust to the quick and dirty. At scale, you'll need some way of queueing tasks that is resilient against various kinds of failures (what if you have to restart the server in the middle of sending an email?). But for small projects or as a minimum viable project, you can probably just get away with spawning a goroutine and maybe using a websocket to tell the client that their task is done or have them ping some endpoint with AJAX that will return `{"taskDone": false}` and `{"taskDone": true}`. It's up to you to decide how robust you need your solution to be. Here's an architecture that is maybe not too onerous to implement. When you need to write an email, grab the database and write a new row with the email address, body, etc. and a boolean flag for sent=false. On start up, in addition to starting your router, also start a mail demon as a goroutine. Have it connect to the database every couple hundred milliseconds, find any unsent rows, send the emails, then mark the rows as sent. This will only work as long as you have just one server running. When you have more, you'll need some way to keep the mail demons from fighting each other and sending the same email more than once, so you'll probably want to learn about Rabbit MQ or some other task queue, but it's simple enough to scrape by with this database only solution to start.
Unless it's a javascript web application, that method just isn't viable. People won't be waiting on a "Thanks for registering" page for a notification to say their email has been successfully sent. I think the queue system is definitely how it has to go, but you have pointed out that it isn't going to be as simple as I'd thought to produce such a system. Are there any libraries/services for Go you might recommend or are you as new to this problem in Go as I am? 
&gt; returning structs allows the people reading your code to quickly navigate to the correct function. You shouldn't have to read my code. You should just have to read the docs. And the docs are very easy to navigate to find the types that implement an interface's function. That said, i don't completely disagree. I just don't think it's a _great_ rule of thumb. If your functions call other functions and return various instances of an interface, you must also return the interface, e.g. `error`. So I think the rule of thumb is more like, if your function is incredibly simple, return the struct, otherwise, consider returning the interface.
Hmm, but what about the flexibility that you gain in writing tests by using interfaces?
Out of curiosity, why is this the case? If you know that the error value will be of a concrete type, why "upcast" it? Is it aesthetics?
Git freeze just submodules all the imports at the current `git submodule` commit reference. It is not "dependency management" because I don't think an entirely new tool is needed for that. It's up to the repository owner to mange their exact dependencies. Yes, you have to go into the submodule and get the working commit. But that's part of any integration phase. The key is that you will not have pushed a broken application. It's like this: You see that someone merged an update to a library you use. Go into your vendored submodule and pull the commit, probably specifying the exact commit you want. Try to build your app. If it doesn't work and you don't want to update your app, simplest thing, just delete your entire local clone. Or, if you're working in it still, just revert the submodule, possibly just `git submodule update --init`. Your app still works for everyone and will always work (assuming the library repository remains and retains the commit history you expect. And if that worries you, subtree instead of submodule.)
And when they're not checked, it's always obvious and never a mystery. Super unclear why you thing a captured exception is more clutter than an if. I prefer the clear visual difference AND crashing to get-another-if statement and/or undefined behavior if someone misses the check.
Probably just means that the work you're doing is being overwhelmed by the latency and/or you're blocked on the Redis connection and need to have more available. If you're opening and closing the Redis connection per request, that would be bad. If you're serializing requests, that would also obscure the results.
Now it seems there are no tests anymore https://github.com/kataras/iris/tree/master/tests -&gt; 404
A couple of reasons: 1. Without generics, interfaces can't define generic returns, so methods like `Close() error` have to return `error`. 2. If you handle multiple error-returning functions in one function, and each function returns a different type, you'll have to either pre-declare something like `var err error`, or else use a different variable for each return value. 3. Go interfaces have a weird quirk concerning `nil`. Consider the following contrived example: func Example() *SomeErrorType { return nil } func main() { var err error err = Example() if err != nil { // This will always run. panic(err) } } In Go, an interface at runtime is represented by two words. The first represents the type, while the second is a pointer to a value of that type. A `nil` interface, internally, is something like `(nil, nil)`. However, when the typed return of `Example()` above is placed into a variable with an interface type, it winds up being `(*SomeErrorType, nil)`, which is not nil, so it messes up attempts to handle it properly. ^(Not that just panicking the error is really handling it 'properly', I suppose.) Here's a [playground version](https://play.golang.org/p/jyi4pX3TeP). I replaced `panic()` with `log.Fatalln()` because the runtime doesn't care for `nil` panics, apparently. Edit: By the way, if you want to examine the components of an interface manually, you can use [reflect.Value.InterfaceData()](https://golang.org/pkg/reflect/#Value.InterfaceData). To get a `reflect.Value` for an interface type, do something like the following: `v := reflect.ValueOf(&amp;amp;i).Elem()`, where `i` is a variable with an interface type. Also, if you've ever programmed in C or a direct derivative, one thing to keep in mind is that, despite being called 'interfaces', Go interfaces actually have a lot in common with C's `void *`, except with attached type information.
More on this: [Docker for Mac vs. Docker Toolbox](https://docs.docker.com/docker-for-mac/docker-toolbox/)
How does delivering mail cause long respose times? Are you sending via an external smtp-server or something? If so, have you tried installing something like Postfix locally and queue mails up there?
The "take interfaces, return structs" mantra works well with tests. The parts you need to mock out in unit tests are the parameters, not the results.
No it doesn't. Looking at the example in the docs (https://golang.org/pkg/crypto/cipher/#example_NewCBCDecrypter) it says: &gt; If the original plaintext lengths are not a multiple of the block &gt; size, padding would have to be added when encrypting, which would be &gt; removed at this point. For an example, see &gt; https://tools.ietf.org/html/rfc5246#section-6.2.3.2. However, it's &gt; critical to note that ciphertexts must be authenticated (i.e. by &gt; using crypto/hmac) before being decrypted in order to avoid creating &gt; a padding oracle. You will need to remove the padding yourself. But also remember, you need to authenticate the ciphertext if you are not currently. 
Personally I am well prepared to use Go indefinitely - I feel safe assuming most standard library functions are well implemented, and if something breaks I know enough to fix most anything with enough time. Having the language source code is powerful, although I should spend time learning building the go tool before Google gets shut down.
I thought I saw it a couple months ago but apparently that happened in July of 2015. https://groups.google.com/forum/#!topic/google-appengine-go/as9wUqT77YU Hey do you know that Google Fonts has a new address? It's https://fonts.google.com/
Go seems like such a great language for command line utilities. I'm hoping myself and others can get over the web apps at some point and spend some time doing cool OS things. (also I thought the website design itself is interesting: http://blog.getpelican.com/) 
Yep, that one.
Managing versions of packages is one place Go's weirdness directly mirrors Google's--there's globally just one copy of a given library in Google's master codebase, and relatedly the go tool initially shipped without the built-in version-awareness that some languages' package managers have. The community has built ways to deal (look at 'vendoring', tools like gb). Google and Go are also both weird for using static binaries heavily, but the world has generally liked that aspect of Go, except when now and then someone gets annoyed at the 'Hello Word' binary size (heh). But if you're living in Google's world, that's not _entirely_ a bad thing. The stdlib has the quality of something that's been through a good code review process. (The APIs are consistent except a few legacy things from early Go dev, and you'll find most source readable when you're curious about how they did something or some detail of behavior. I encourage following the links to source from godoc, or browsing in your go/src/.) Their priorities, even when they're not quite yours or mine, at least more often relate to things that directly help ship reliable, maintainable software, not just proving ideas somebody had. The tools in distro (fmt, doc, test, profiles, race checker, tracing) and even a lot of third-party things (static checks!) reflect that attitude too. I'd love someone to contradict me with their positive experiences, but I _haven't_ seen a fantastic way to use Go to very quickly get to your initial launch of a database-backed Web app with a complicated schema. Django and the ecosystem around it are _great_ for time-to-launch of stuff like that. On the other hand, Python/Django cause you some pain when the app gets big (I know; we manage that pain daily at work). I think of using Go rather than Python as more like building with steel than wood. That probably offends Python, Go, wood, and steel enthusiasts all in one go, but what I'm trying to say is the Go project is a bit slower and more expensive to build but the product seems pretty solid and scalable after. Like wood and steel, either can make sense depending on the situation. Like dlsniper said, Google's using too much Go to just drop it--Kubernetes is one big public project, but things like the download server you use to get copies of Chrome, YouTube's sharding MySQL proxy, a data-compressing proxy Chrome Mobile can use, etc. are in Go. Lots of smaller companies outside depend on it, too, which is a good sign for community support.
Go has alternative history, and it has nothing with Erlang. Look at Go's predecessors for: https://en.wikipedia.org/wiki/Newsqueak - 1985 year - was designed by Luca Cardelli and *Rob Pike*, its approach to concurrency was inspired by C. A. R. Hoare's communicating sequential processes (CSP). However, in Newsqueak, channels are first-class objects, with dynamic process creation and dynamic channel creation. https://en.wikipedia.org/wiki/Alef_(programming_language) - designed as part of the Plan 9 , implemented the channel-based concurrency model of Newsqueak. Also developed with participation of Rob Pike. https://en.wikipedia.org/wiki/Limbo_(programming_language) - programming language for writing distributed systems and is the language used to write applications for the Inferno operating system. Also with Rob Pike as one of developers. (modular programming, concurrent programming, strong type checking at compile- and run-time, interprocess communication over typed channels, automatic garbage collection, simple abstract data types) So, Golang is more Rob Pike's history :-) 
Docker, Kubernetes, Pivotal uses them, Heroku, WeaveWorks, but I'm not a substitute for google, check it yourself...
No, consecutive predecessors of Go are Newsqueak, Alef and Limbo. All of them were developed with participation of Rob Pike. All of them had processes and channels (and `select` construction). Newsqueak were developed in 1985 - an year before Erlang, and 15 years before Erlang became public. https://en.wikipedia.org/wiki/Newsqueak https://en.wikipedia.org/wiki/Alef_(programming_language) https://en.wikipedia.org/wiki/Limbo_(programming_language) https://ru.wikipedia.org/wiki/Go Notice, that concurrency model is quite different: - Erlang has "shared nothing" memory and single inbox per process (many-to-one message queue) - Golang has shared memory, many-to-many message queues (channels), and one process may select from many queues using `select` construction. Both Erlang and Newsqeak (Golang's grandpa) were influences by "C. A. R. Hoare's communicating sequential processes (CSP)", but in quite different ways.
I find Python an interesting example of a community-led language to pick given the decade-long train wreck that is Python 3. The main reason I picked up Go was because I came to the conclusion that it might be another decade or more till Python 3 gets fixed (if it ever does).
Only after I learned that you can sign tags and get a nice github VERIFIED badge I started to tag my releases. 
In addition to /u/dlsniper's list: caddy, influxdb, heka, all new Hashicorp stuff (vault, packer, consul, serf, nomad, otto, terraform), the grafana backend, etcd, fleet, prometheus, ... Ops in general jumped on Go since it filled a gap and allows for faster applications with lower memory footprint and no dependency mess compared to things written in the classic scripting languages that were used before (Python and Ruby mainly, before that Perl). It also allows for much more complex and time-sensitive applications - good example here is InfluxDB.
Even Bower is using Go, id that counts for something...
&gt; Bower What is it? https://github.com/bower ?
This is my last Reddit login. Good bye.
I have a question for you guys related to this: I have a project which does have tagged releases, but I mistakenly tagged my releases with "x.x.x" instead of "vx.x.x". I'd like to follow the SemVer standard. I know you can rename tags using git, but I get the feeling that this would be frowned upon. What do?
Also traefik (similar to caddy but connects to etcd\consul etc) thank you /u/arienh4 for pointing out when my brain decided to walkabout.
Just add a new tag on top of those old tags with the same version. It's ugly, but it will work, and won't break backwards compatibility. Or just start doing it moving forward.
My friend would like to add tags to an existing project. What is a sane way for ~~me~~ he/she to do this (what sort of caveats/niceties are involved such that others are most benefited)?
Sorry I should have made it clear in the original post, I'm using the SendGrid API to send emails.
I look at this as more of a call to action for the community to organically grow a better dependency management system. I do wish the go team was more opinionated about this. 'go get' is great, but I wish it did have some kind of sane version handling OOTB. Here is the thing: it's hard for a community to dictate what a language standard should be, as no single entity in that system has authority. This process is much easier if we have some affirmation by the go team that the direction we want to go in is in line with the language.
It won't pad or unpad, you have to do that yourself. Here's a reference for pkcs7 pad/unpad code: https://github.com/go-web/tokenizer/blob/master/pkcs7.go
And the CLI agent on the EC2 instances: https://github.com/aws/amazon-ecs-cli (does this make the biggest deployment of Go in the world then?)
Can you explain a bit about what you think is horribly broken in python3?
The Ericsson part was from a video I watched by the creator of Erlang. There were some internal issues there and he was able to convince the company to open source it.
I haven't had my coffee yet, so bear with me, but does this negatively affect memory usage? AFAICT if an object isn't 'published' it won't be collected until the end of the 'transaction'--whatever that may be--and that leads me to believe it'll be kept alive indefinitely since its 'local'. Will re-read once I've had coffee and a better chance to wake up.
That was my initial reading, too (that "Because unpublished objects do not have their mark bits set" clause is tricky), but the announcement email says: &gt; The Transaction Oriented Collector or TOC algorithm will be integrated with and augment Go's current low latency collector So I assume how this will work in the case of memory exhaustion, and so a full GC being triggered, is that the system will fall back to concurrent mark-sweep and the benefits gained by this new collector will be temporarily lost until there's a fair bit of goroutine activity again. So it'll proceed in phases something like this, probably: [ TOC ][ concurrent mark-sweep ][ TOC ][ concurrent mark-sweep ][ ... The concurrent mark-sweep will "mess up" the nice organisation the TOC uses, I think, so a bit of transactional "garbage" will survive until the next full collection. Or maybe the sweep pointers can be managed to avoid that.
I use SendGrid as well, and what I do, is a mix of these, while trying to minimize maintenance. In the request handlers, I send the data/html to the user so that they get a prompt experience. Then, still in the handler, I call out to the SendGrid API to send the email. I agree that the user doesn't need to know if there is an email issue, and I want to give the user a page as quickly as possible, and I don't want to have to maintain a separate system/job/queue/process to handle just sending emails. 
I assume you do this in a separate go routine then? I'm working with templates on my website and even if I place the SendGrid API stuff after `templates.ExecuteTemplate()`, the response still hangs until the handler returns.
Yes, AFAIU there is an additional overhead in this proposal.
In general, there are some techniques/methods to avoid which might help. 1. DONOT use keys command - use indexing instead. 2. DO use pipelining on large sequences of Redis operations 3. DO use persistent connections 4. DO use hashes instead of serializing a dictionary 5. DO use lists or sets instead of serializing collections. 6. DO performance test specific patterns in your code. Much of this is using Redis in the way it is intended. Just as you don't want to write Java in Go, you don't want to use Redis in only one way. Redis is key/value, sure. But that doesn't mean everything must be a string to string data type. Finally, you seem to be comparing Redis to PHP. This makes no sense. Redis is a data structure server, PHP is a programming language. They are not comparable as they are entirely different things. It would be like trying to compare an elderly blue whale with a red sports car. If you've got specific code or a specific sequence we can help better.
The catch with groupcache is that it is a write-once cache. Once you set something, it can't be changed. I really tried and wanted to like groupcache for Redskull but ultimately I've decided to use Consul instead for the things that had previously gone into Groupcache. Sure, it is an external process to interact with, but it works a lot better and is enabling significant complexity reduction. But if write-once-never-modify is what you need, along with the peering setup of groupcache being advantageous for you, go for it.
So I'm guessing the input was not properly padded then, since it isn't my own ciphertext. Anyways, thank you!
Not "How is a tag added?", rather: "Is every commit tagged?", "Is advice from someone who has kept projects tagged well useful, or is the task formulaic?", etc.
Sorry did not mean to make a comparison between redis and PHP but rather the use of golang + redis to php + redis. Though it's essentially an apples to oranges comparison in some regard, they both would function to do the same thing. I appreciate your comment though! I will try to snippet some code later :)
Sounds similar to what the java escape analyser is doing, though more generally. Reading it, it sounds like this is in addition to a generational collector, right?
Do you have any documented releases/versions? Tag those. If you don't then tag the current one as 1.0 and start from there.
I was thinking the same thing, it's kinda like stack escape analysis but for goroutines. The GC equivalent of keeping a variable on the stack. 
"My friend" will need to become more informed about releases. Thanks!
Clear, concise, and helpful! Thank you.
[Sony](https://github.com/sony), too. Edit: And [Microsoft](https://github.com/microsoft?utf8=%E2%9C%93&amp;query=go).
Given that SendGrid's entire value proposition is reliability, I'd say use a separate goroutine. If you get failures, stop using SendGrid.
Will it be possible in the future to chose the GC we want to use ( like Java )?
Which is one of the reasons why I like Go and dislike Java. Java, and, by extension, most large Java projects, seems to have no concept of sane defaults.
The difference would be at the very least that escape analysis is static and distinguish between the stack and the heap whereas here it is more of a dynamic accounting of (sooner-rather-than-later) free-able heap memory.
&gt; (which nobody will ever do) I think there in lies the problem. People put effort into tuning their jvm, they think they've got it right, and then they find out their application *probably shouldn't be generating that much garbage anyways*. I think maybe there should be fake nobs. `GO_GC_CHOOSER_9000=5` totally works for me!
How could you ever think you got it right, even.. http://stas-blogspot.blogspot.com.au/2011/07/most-complete-list-of-xx-options-for.html
If transactions are relatively short-lived (serving a web request, RPC, etc) -- which clearly seems the goal of this feature -- wouldn't this result in most of that memory being freed very, very often? I'd expect the transaction to end sooner than when the next GC run would have been.
It doesn't work well in small viewports (e.g. phones).
Great outline on data-driven testing in Go. How would a `go generate` approach like [gotests](https://github.com/cweill/gotests) fit into the picture? I like this approach because it saves me from writing boilerplate code without the need for including external libraries into my test code.
Go also draws quite a bit from the Wirth family of programming languages, in particular Oberon-2: https://talks.golang.org/2015/gophercon-goevolution.slide
It looks ok for me viewed landscape on my Samsung Galaxy. What do you have?
It looks pretty and approaching a REPL style of development. Thank you for sharing! 
How does it compare to the Micro framework ? https://blog.micro.mu/2016/03/20/micro.html
Is there actually a tools to see the last git tag (if there is) of all the dependencies of a project ? 
I was scared reading "Dependency Injecting" and was immediately thinking to a hell of reflection usage ... but this post simply describes the correct usage of an interface :-) Nice! Also to avoid stutter I would rename this: type PoemStorage interface { Type() string // Return a string describing the storage type. LoadPoem(string) []byte // Load a poem by name. SavePoem(string, []byte) // Save a poem by name. } to type PoemStorage interface { Type() string // Return a string describing the storage type. Load(string) []byte // Load a poem by name. Save(string, []byte) // Save a poem by name. } as /u/j1436go mentioned it should just be: type Poem struct { content []byte storage PoemStorage } 
But how do you "restart them on a file change"? (citing the OP) 
I use https://github.com/ddollar/forego with the command `forego start -r`which automatically restarts dead processes. In my text editor, I bind the build command to something like `ssh vagrant 'pkill myprocess'`, which kills the process running in my Vagrant box, and let forego restart it. Another tool I like is https://github.com/cortesi/modd. It's similar to forego in some way, but it is able to watch for file changes, and restart processes itself, which removes the need to setup your text editor with all the ssh "trickery" described above. A big advantage of this approach, compared to ivpusic/rerun, pilu/fresh and qrtz/livedev, is that you don't have to modify your Go program in any way. It runs exactly as in production, which is good for dev-prod parity. Moreover, you can use the exact same approach with other languages as well.
I just talk about systemd as daemon manager which is integrated in any recent Linux. However, reload with file watching can be implemented inside of OP's API processes. For the reload part, http://entrproject.org/ this project is interesting.
&gt; ...was immediately thinking to a hell of reflection usage... :-D What I love about Go is its simplicity, not only in the language itself but also with regard to the idioms that have been established in the Go community, and I try to always remember the two [Go proverbs](https://go-proverbs.github.io/) that say, "Clear is better than clever.", and "Reflection is never clear." &gt; Also to avoid stutter I would rename this:... When writing the code, I intentionally decided to use the "...Poem" variant to reduce possible ambiguity. (How many other "Load()/Save()" interfaces are probably out there?) But then, this code is for learning and thus should be clear and concise. So I definitely do agree about the stutter. It is fixed now.
&gt; Iris powered by GoLang Must... &gt; GoLang not... &gt; **GoLang** Grr... *&lt;triggered&gt;*
sudo service restart
&gt; The fastest web framework for Go on (THIS) earth Github is just github. Make a bait, get stars. By the way the iris author just went full rekt: &gt; I am not violating anything, you just hate Iris because it lives 3 months and has more stars than projects (like this) which exists more than years..anyway https://github.com/julienschmidt/httprouter/issues/148 [edit] To me this whole project name is confusing with https://github.com/project-iris/iris-go - did the kataras stole the project name also?
Most stars happened in the past few days: http://imgur.com/HlA2loO
I think the key is to be so egregiously bad that people who don't understand that no publicity is bad publicity do your advertising for you.
Wait, why is there a witchhunt posted here hiding behind a code of conduct?
I meant "what tool do you use to detect file changes (using inotify for example) and trigger the service restart". Using upstart or systemd only solves one part of the OP question. I know how to use sudo service restart ;-)
Yes, I admit I've worded my issue poorly. And, if anything, I should know better. I would have apologized for this but the initial reaction of the author was nothing but inflammatory and he locked the thread a few minutes after me opening it (so not much I could do). I won't go back and edit it now. I'll try to do better next time.
Why the required "v" prefix? I don't see that called out in the linked semver page. Is that something other systems do already?
Check out Machinery by Richard Knop. It's a port of Celery to Go. However, it only communicates over HTTP, since it's dependent on an AMPQ protocol library that does not support HTTPS. https://github.com/richardknop/machinery
To add to the other solid advice here: if you can, consider moving to an in memory cache (like LRU) and refresh your cache in the background out to redis. Depending on your use case and traffic patterns, this could help. You can even consider a wrapper around redis and check for requests that can be collapsed (held off because the same request is already issued an wait until a result comes back). Depending on the number of incoming nodes you have, if you are having a poor cache hit ratio, you could add some deterministic routing to your nodes to make better use of your in memory cache. As a side note, all of this is not possible in PHP because each request spins up its own world. That is another value-add for Go as it is long lived and you can leverage many requests together. (On mobile, please excuse typos) Cheers!
&gt; did you pay for any of kataras/iris source code in the first place? NO! THEN STFU. That's not how this works.
At work we have 3 seperate codebases that work along side eachother... slowly converting to one code base. Basically we have our load balancers sending traffic for certain endpoints to one server while others go to another. So you can start separating endpoints from php to go and gave haproxy send the endpoints to the correct server. To share data between the two you could always make endpoints that produce JSON or XML data that golang can read from the php endpoint or vice versa. Hope that makes sense.
Take the PHP code and burn it.
I love the direction PHP is going and 7 is amazing, I also really enjoy golang. What I'm trying to say is, don't be a dick.
Yes, this! This project is really neat but really emphasize that you can import and use any library instead of just the standard ones. Major bonus points if you get a hosted version of this up and running someday.
Lately he has been pleading people who submit typo fix PRs to write tests for the project.
bots, reminds me of this incident in the PHP community where [a guy lied his way to the top](https://groups.google.com/forum/#!topic/php-fig/cjLBp2weYaA) to get on the [PHP-FIG team](http://www.php-fig.org/). Updated with links for clarification.
To be fair he said he would fix that (~30 mins ago, after you made this reply).
Yes you are right! :) I am glad to see it.
Mainly backend, rebuilding large data caches, things like that. &gt; makes more sense to write a server Can you elaborate here?
Probably just my free software mindset but if iris "stole" code its an indictment of the stolen code's license. All my work is MIT or GPL. Take it and use it. I don't care if you credit me. Seems the iris guy forked it and made slight modification to it for his use case. I think that's the fundamental spirit of free software.
Like I said: "Only the license violations really need to be fixed" ... So I think we are in agreement :-) And [he said he would fix that](https://github.com/kataras/iris/issues/230): &gt; @kron4eg we are working to add licenses for all third-party libraries, I though THIRDPARTY.md was enough but it is not. . &gt; why do people recommend / star it when all the other projects are at least required to have a set of basic tests? Would you trust it in production code? Let me put it this way: I wouldn't *not* trust it *only* because of missing tests. There are some brilliant projects with almost no tests, and there are some really crappy projects with a lot of tests. The presence of tests is only a heuristic to judge its quality − not a binary switch.
No idea, I'm currently using fresh, as suggested by someone else here, but that's only good for running them in the foreground. Next step is to investigate gulp-go. 
This is one of the things Rust does well, as the borrow checker helps ensure data race freedom. 
You're right that he is violating his license. All he has to do is copy/paste a disclaimer at the top of the file. Hardly worth screaming at the poor guy. Besides, J. Schmidt *should* use a more permissive license. All this yelling over "my name wasn't included. don't use my library in your benchmarks." is so juvenile. It makes me not want to use HTTPRouter.
This comment has been overwritten by an open source script to protect this user&amp;apos;s privacy. It was created to help protect users from doxing, stalking, and harassment. If you would also like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and add [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite). Then simply click on your username on Reddit, go to the comments tab, scroll down as far as possibe (hint:use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top. Also, please consider using an alternative to Reddit - political censorship is unacceptable.
This comment has been overwritten by an open source script to protect this user&amp;apos;s privacy. It was created to help protect users from doxing, stalking, and harassment. If you would also like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and add [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite). Then simply click on your username on Reddit, go to the comments tab, scroll down as far as possibe (hint:use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top. Also, please consider using an alternative to Reddit - political censorship is unacceptable.
Do you know what ETA means? It's not a demand, not even a request. It literally just means "estimated time of arrival". All they want to know is a time frame. Maybe they really like your work and want to incorporate it in something they're building, but cannot until it has a certain feature or conforms to a certain standard. If maintaining a popular open source project is too much for you, you might want to consider handing over the reigns to someone who can take care of it until you're ready to come back.
Seems like he was being asked to stop using HttpRouter and related software for *questionable* benchmarks in particular... the kind that [misrepresent performance](https://www.reddit.com/r/golang/comments/4bw0yk/go_web_frameworks_a_benchmark_only_comparison/d1dte0i) to make it seem like a slower/equally performant solution is faster.
Ut wasn't google who thought of the name. It was the original creator. Couldn't name just go because of poor search results.
Considerations of ego aside, it's not good practice to sit mum while people spread misinformation for their own gain. You don't try and mislead people with the expectation that they're going to find out: you mislead people because you know that some people are not going to find out and they're going to make a bad decision that works to your gain. That sort of behavior should be called out and discouraged.
I totally agree. If he's producing misleading benchmarks he should stop immediately. But J. Schmidt doesn't have any right to demand they be removed *AND* say his software is FLOSS. edit: keyword being demand. he can ask (and should).
I dunno, maybe I'm missing something here but it doesn't seem like he even *can* demand that. Producing misleading benchmarks isn't a violation of the license, it's just a dick move. All I took from J. Schmidt's remarks was "stop violating the license by leaving out attribution or we'll send a cease and desist and also stop releasing trumped-up benchmarks or we'll be really mad, I guess." I don't see how releasing FLOSS software and asking people not lie about it are in contradiction. Because you can use it "however you wish, pursuant to the terms of the permissive license" doesn't mean that the creator should never ask you not to do bad things with it.
Whenever I need to write a backend and API for the native mobile project I am writing web admin with PHP, Codeigniter with Bootstrap and depending on expected number of concurrent users I am writing the API in Go.
It isn't MIT License but a BSD 3-Clause style license, which is basically the same as the Go src: https://golang.org/LICENSE I did not extend any license, it is just a regular, OSD-conformant, BSD 3-Clause license. *[Edited]* The statement you quoted is a general demand, I don't want my name or my work involved in any of these games. It is partially covered by the 3rd clause, the "no-endorsement" clause. That is what BSD 3-Clause differentiates from the MIT license. Besides that any purposely misrepresent claims are illegal by European law.
Thank you for the clarification. I was mistaken. I still believe open source code should be licensed more permissively but I understand your position in this.
I can't understand why you're getting downvoted. Must admit, I'm not super bright. But it seems to me that more and more people are more concerned with their egos than the spirt behind those licenses. 
Well... My goal is parsing the code automatically so you can just write the code without worrying about packages or where is the main function. So it will be faster if you want to test some code snippets or something like that. 
It's worth noting, though, that one of the big issues with C is that cleanup could be harder when an error was encountered -- you could end up with some nasty if/else blocks or weird flags to be sure everything than needed cleaning up up to the point of the error was, in fact, cleaned up. The go `defer` keyword basically resolves many of these cases and makes a simple return on error a lot less dangerous. You can also use panic and recover within your own code -- as long as the panic does not cross an api boundary. I personally hate throwing exceptions across api boundaries -- but that is idiomatic in a lot of languages, unfortunately
&gt; Seems the iris guy forked it and made slight modification to it for his use case. I think that's the fundamental spirit of free software. He also removed the License. In other words: He Broke said license. MIT and GPL don't allow this either. You might not care if someone takes your code and removes the License, but other people may see this as disrespectful. That is not the spirit of free software.
http://gokit.io/faq/#how-does-go-kit-compare-to-micro
just some thoughts. * Check the HTTP status instead error. * You have a race on "sites", when one go routines access it and one writes it at the same time it can crash. * dont mix the http error check with your "site is up" logic
I hate exceptions in ANY language that has them, not a complaint about a specific language. They are an idiotic travesty on any language that implements them. Sure, you can write bad code in any language, but exceptions sure help. So happy Rust went with return values. 
tl;tr? Those github issues you linked have no description. You want to warn people about the project and the author(?) because the project has github issues with no description?
Except he didn't say that. He said &gt;Any ETA when industry established best practices would be followed and tests will be added? That comes across as neutral. If I were Mr. DevOps I wouldn't want this running on my server, even if I liked the way it did things, even if it was faster for my use case than other options. If it doesn't have tests built in, and it doesn't follow best practices, it's not going on a production server. Period. There's no judgement on the character of the developer or on the library itself inherent to someone asking when they'll be able to deploy that software.
https://github.com/kataras/iris/blob/master/CONTRIBUTING.md#before-submitting-an-issue &gt; If your issue is a question then please ask the question on Gitter. Looks like he/she doesn't like project's github issues to be used for questions. Maybe ask the author on gitter? 
For example. If I'm wanna try some code -- to see how it works, how to use it, I prefer typing: import "log" import "net/http" res, err := http.Get("http://google.com/macOS-10.12-src.tar.gz") if err != nil { log.Fatal("ERROR:", err.Error()) } than: package main import "log" import "net/http" func main() { res, err := http.Get("http://google.com/macOS-10.12-src.tar.gz") if err != nil { log.Fatal("ERROR:", err.Error()) } } It would be faster and comfortable. Just to get the result faster. But yes, formatting is one of the most importance of Golang, I shouldn't go away from that. So I will add the format feature as well, and it only run in case user type in a full code. Thank you so much for your opinion :D heheh.
Here is a guess. You are using the default http client, which has no timeouts specified by default. On top of that, your schedule function continues to launch new goroutines and sleep. So a particular task could be hanging on requests and new tasks just get launched and stacked up. https://medium.com/@nate510/don-t-use-go-s-default-http-client-4804cb19f779#.ctpy9xw7m Try creating a client for your app, once, with really short timeouts, and share it across your tasks. That way it should return quickly if the site doesn't respond. 
Thank you very much! Will try those suggestions.
Anyone know what the differences between cap'n serial and flatbuffers are?
Quick note about the util package: &gt; **Avoid meaningless package names**. Packages named util, common, or misc provide clients with no sense of what the package contains. This makes it harder for clients to use the package and makes it harder for maintainers to keep the package focused. Over time, they accumulate dependencies that can make compilation significantly and unnecessarily slower, especially in large programs. And since such package names are generic, they are more likely to collide with other packages imported by client code, forcing clients to invent names to distinguish them. https://blog.golang.org/package-names Edit: Thank you for the example!
I'm not what you'd call a gopher, but I still hate PHP. Hating shitty languages transcends what kind of coder you are.
Great advice and thanks for the example. 
Read Sam Newman's book about microservices. 
If you couldn't tell already, it's a joke.
I do the exact same things for my web application. PHP + Jquery + Bootstrap allow me to do things in hours. Mock up ideas in minutes. Very quick and very fast. A lot of times, I'm already leveraging code I already have written. It's great for web admin front-ends. However, when I have a task. I use go for that. Image uploading, image resizing, heavy duty manipulations of data, multiple database operations of batch data, web scraping, email sending, the list goes on. Fact is. Go runs rings around PHP for tasks where backend processing is a huge factor. So, treat each language as separate. PHP for the front. Go for the back. Of course, Go can replace PHP on the front-end. However, for large monolithic type applications. You can't quite organise Gos folder structor the same as you can with PHP. I love Go and I was happy I took the time to learn it.
Start with the bits php doesn't do so well and replace those with go - either accessed entirely over HTTP with nginx sending traffic to specific paths to your go app instead of the php one, or do what my work have done, and send all traffic to go, then go sends back to php the requests it doesn't know how to handle (most of them, at this time). 
Alias go build to go b
https://go-sandbox.com/
I am but a simple man. sqlx, mux, and negroni are good for me. Why are today's engineers so afraid of writing code? 
It could attack at any time.
I did not try it myself already. But I've manually create some MSI packages with WiX for my Go projects, and I remember the pain doing so as a Linux-y guy. 
https://help.github.com/articles/about-stars/: "Starring a repository allows you to keep track of projects that you find interesting" That's exactly what I use GitHub stars for. Why using something else when I can use GH stars? Browser bookmarks would not work anyway, as I access GitHub from various computers and devices, from different browsers as well as from apps. And bookmark services lack privacy. All my bookmarks on someone else's computer? Unencrypted? No, thanks.
Even if the services are running as the same computer as the PHP that is gonna hit him with some pretty big overhead, even more if he has to marshal data. If he runs the services on another machine god help him.
Are you really supposed to put a v in front of it? I thought it would be the other way around
Have you heard of G1GC?
If that's how you feel, I recommend sticking to the MIT/X11 License, and avoiding the GPL (which is a much more restrictive license).
Yes, I believe so.
That was my worry. I suppose other websites simply allow the use to re-send emails they haven't received so as long as I can log errors myself, the user doesn't need to know about them.
If your looking for a process manager to reload processes on file change, I would hope that you aren't using that on production. Just my thought, but generally, having it reload configuration would be easy enough through signals.
Use a go routine for anything you don't want to wait for. (like sending email)
I think GB is the simplest way too. The strict structure it imposes makes sense and "it just works."
Nexus 6. What I see are three tiny columns. I have to zoom in to make it readable, but then requires horizontal scrolling. It would be preferable if it collapsed to a single column once the viewport width is below a certain size.
I'm still undecided to be honest. I do lean towards no v as well, though.
I don't think so.
Maybe I should be helping You instead with some question on reddit. Would that be better?
I'm currently rewriting a moderately large legacy PHP app in Go. 1. Get sessions from legacy app to work in go 2. Rewrite one endpoint in Go 3. Update Nginx config so that endpoint is handled by go, not php 4. Goto 2, repeat until no php is left If the original app is a monolith don't get yourself into divide-everything-into-microservices rabbit hole. 
This is look very promising .
Just don't get it why the http client doesn't have a timeout setting, seems so basic 
DynamoDB or the equivalent NoSQL in your favorite cloud provider 
can you elaborate why would go for No sql over sql?
Basically HN is an entry / comments site which you can use NoSQL to store both ot you can have the news in NoSQL and Disqus for comments which means you can basically build in under 10 minutes.
You *could* store things in NoSQL, but why? This seems like obviously relational data to me.
NoSQL probably would fit better the case just for rapidity in development (disclaimer: I would use pgsql cause I know it better than other). Worth rather notice that both using document DB or RDBMS you would hit the the same edge cases about comment list's length per news and comment level nesting that would require special caring (or arbitrary limiting).
I'd go with redis for simplicity. And groupcache for comments/posts past the edit window. Obviously don't need groupcache until the traffic picks up though.
If you called my complicated computer thing "a piece of piss" I'd be so upset with you.
It depends mostly on you. There are a lot solutions to choose form. Here we already had the discussion: https://www.reddit.com/r/golang/comments/4ogef4/database_for_go_web_app/ tl;dr If you want a proven solution and do not loose data take PostgreSQL.
&gt; You can still have relations with a NoSQL DB ... in the application I'm just failing to see why you would pick a NoSQL database when this use-case doesn't seem to benefit from it at all. You're basically saying "sure, you might lose some data, but that doesn't matter here, so use this lossy database". The schema is simple and there are obvious relations, so what's the advantage of *not* using a database which has good support for that?
I agree, those two actions should get separated. I wonder if GitHub sees it the same way. After all, they initially decided to use stars for both actions - bookmarking and showing appreciation. They surely thought about this when designing this feature, and--for whatever reason--they decided to do it that way. They won't easily change their minds I guess.
Thank you. Re 1: This is a good alternative approach. The dependency is injected via the interface, and this interface can be part of a struct, or can be a parameter in a function call. Re 2: Thanks for sharing this approach. Luckily, the code in my article is simple enough so that I could easily remove the stutter by just renaming the methods :)
Couchbase because I can deploy HA from the get-go. I get a NoSQL store that can be queried relationally using SQL as needed. I would use a combination of varnish and static HTML generation with a CDN for caching.
Which book would you recommend to be able to write good go code? 
For a copy not to be made the compiler would need to inline `TableName` _or_ do some spooky stuff and modify `TableName`. What I mean by the latter is since `t.M()` is equivalent to `M(t)`, the compiler would have to recognize that `t` is never used and change all invocations of `t.M()` to just `M()`. I doubt the compiler does or will do that (granted the spec does not say anything either way).
This works well as long as the interface methods only deal in primitive types. But what happens if you need a method that takes or returns an object of the same type? There's no way to retrofit that in Go, so you need to agree on a standard interface ahead of time and make every method use it. 
Postgres + a redis cache is probably a good start. A key though is to make sure the right abstractions are there in the code. Plan not to have this forever, and some day have a NoSql solution, or probably a set of stores much more complex. Doing this now would be a mistake, probably, since you should focus on maturing your app and not your backend. Hopefully, some day you'll get to the point where you have to worry about a more HA, scalable infrastructure, and at that point, good, thoughtful code will make it 1000 times easier.
I still recommend paying for the Go book by Kernighan. Really good book.
&gt; I doubt the compiler does or will do that (granted the spec does not say anything either way). Inlining is already happening, from there it's a trivial optimization to realize that there needs to be no copy. I would actually be surprised if the compiler *doesn't* optimize it away (unless you have an indirection via an interface. But even then, it should be trivial). But the spec doesn't say, so it's an implementation detail, so you shouldn't rely on it.
server programming...
Your comment has more substance than the main article, which is mainly just picking on another developer who is learning and has been working hard to make things right[1][2][3][4]. [1] https://github.com/kataras/iris/issues/200 [2] https://github.com/kataras/iris/issues/208 [3] https://github.com/kataras/iris/issues/211 [4] https://github.com/julienschmidt/httprouter/issues/149
/u/beeker1121: I cannot honestly read this and say, "How noble of you." I hope everyone will learn something from this? I know I have. First, I've spoken with Kataras quite a bit about things and he already feels awful, he wants to do things right, and has actually put a lot of effort into it. He's learning too. Second, I hope that people who are reading this will get an idea how _not_ to act, on both sides: be careful with commit history, be diplomatic in online discussions, and be patient with those who do not speak your language or understand where you are coming from. Finally, I really hope developers won't have to live in fear that their mistakes will haunt them forever in public or on the Internet because people just won't let it go. Anyway, if you have a beef with Kataras, there's nothing noble about taking it to the masses to try to shame him. Let's try to lift people up here rather than inciting everyone to go get their pitchforks.
you should maybe check the sidebar before posting: * Treat everyone with respect and kindness. * Be thoughtful in how you communicate. * **Don’t be destructive or inflammatory.** * If you encounter an issue, please mail conduct@golang.org.
The language sources are open source, however google tightly controls the language. Those not in google must toe the line or be shunned. much of the core stuff is strictly controlled by google. All of the testing frameworks are google internal. The language spec and source is opensource but the actual project is under the thumb of google. I doubt google will ever drop support for Go. Go is being groomed as a replacement for c/c++, java, python.
that only proves the implementation, though. And we all know inlining is going to happen, at least with OP's example. The important bit of my comment was whether the compiler can rewrite function calls to omit parameters.
kiss ass all you want, still wont help in your next interview....
Cannot recommend this book enough. I bought the eBook and it was great to learn with
Thank you for your post! A few days ago I was looking at this repo, and felt it goes against many best practises of golang.
This crash is NOT an NPE crash, so why is it included? var timer2 time.Timer timer2.Reset(15) // crash He even mentions this afterwards, how this is not an NPE crash. So why is it there?
Thanks! I understand _why_ it would only work for unmodifiable records, I'm just wondering _how_ it would work in this case. Don't you have to fetch the record first to find out if it's outside the edit window?
Perl doesn't "crash" in his case, it gives him a friendly message. It works as a dynamic language should - evaluating the availability of a method when it is invoked as for Go...i wonder if the compiler can be improved to address some of these issues...the case where he sets a Timer to nil seems trivial...
What's the point of a redis cache? I would just cache stuff in-memory in your Go processes, where appropriate.
It's actually not too spooky. The compiler can simply try to figure out whether the parameter is ever written to or whether it escapes. If not it could freely change the signature to a pointer type if it thinks it would benefit the performance. Not sure whether the compiler is doing anything like that. The ability of being able to call functions via reflection might prohibit such changes. 
or, you know, use in memory tables in postgres. Or simply rely on postgres itself who also caches queries...
I'm curious why explicit equality tests and "custom" failure messages are so common in Go tests. Assertion-style functions to take care of this for you seem like a great way to avoid this boilerplate. Is it something that Go's type system makes quite difficult or are there other advantages to doing it this way?
How do you ensure that v() is executed (line 22) while a is holding a read lock (line 76)? Since ugl.upgrades has a buffer of 1, go scheduler can call v() after the a releases the read lock. I don't think this is correct.
Sure, and that's probably partly why my employers have always stuck to SQL Server and Oracle, but unless the project is your primary income, being interesting is MORE important than robust because the alternative to interesting is not finishing the project at all. :) That's my main point. Also, BoltDb is used in some pretty large production sites, and chances are they need more robust than a news site does, so there are forerunners already validating it. Databases are a place where you want to be a lot more careful about selection than, say, a forum software app or something. A database is generally your "everything"... so don't use a random project on Github that you don't know, but BoltDb is a fine thing to use for a news site. If this project is your primary income, then I'd still try BoltDb this time, but I've been known to take professional risks. At this point in my career the benefits of those risks have far exceeded the losses and pain.
I was assuming removing parameters instead of taking the address which I the spec says the compiler does automatically in specific scenarios. Yes, one of the biggest issue with rewriting anything is reflection—the function that reflection looks up needs to be identical to the one the user expects they're calling. Thus the spooky 😄
I wasn't trying to prove that a the complier might do _X_, I was suggesting the compiler can't do _X_.
does anyone know how NATS stacks up against MQTT?
I didn't say I like this solution ;) It's a neat "trick", but I wouldn't use this myself. 
This isn't a problem with your Go code at all. The `andlabs/ui` library uses cgo, which doesn't come with the same cross-compilation guarantees as Go code. Since it depends on the platform-native C/C++ compiler and linker, you would need to compile this on the platform you're targeting. 
I don't have any context on how you may or may not be using MQTT (or considering using NATS), which would be helpful, but in general terms: Similarities: Both are publish-subscribe protocols, support many patterns, and are broker-based. Differences: NATS is a *very* simple lightweight text based protocol (whereas MQTT is condensed binary), NATS is stateless (whereas MQTT stores client state), and NATS isn't a committee/standards based project so more open/flexible. I'm Community Manager for NATS, so I'd be interested in chatting with you sometime further on how you use different messaging protocols...and getting your feedback/questions on NATS.
http://stackoverflow.com/questions/25218903/how-are-people-managing-authentication-in-go
so there is no way to do it on my OS X machine? Do you know another UI library for Go that is cross platform and can be compiled cross platform too?
Also, I'd love to get some more contributors for this project. It wasn't built with having a REST layer in mind, but I'm certainly open to the idea. I'd be willing to work with anyone who may want to add functionality such as that.
I use JWT https://jwt.io/ which contain the user's permissions. edit: why the hell is this getting downvoted? 
To my knowledge there is no stable (or near-stable), cross-platform GUI library for Go.. However you could serve your 'GUI' via an http server + html/css/js frontend. I know it's not the same as a native library but I think it's the best option you have at the moment.. If someone has a better idea I would be very interested too..
I meant how are you restricting access to unauthenticated users to users' personal pages ? middleware or something?
&gt; OK for that case it really isn't the best idea to spawn an http server.. I guess you chose Go because the binaries are statically linked and thus easily deployable? Yep, that's the reason. I guess a terminal shouldbe enough though. It just needs to be shown if a download is needed. The idea was to just deliver a small Go stub that will handle the download of my app + a java installation (if necessary). Is there some way to only open a terminal window if needed? 
There is a quicktemplate function that gets a string back which would make this less complicated. It will also use its own internal byte buffer. func Index(c echo.Context) error { p := &amp;templates.Main{} return c.HTML(http.StatusOK, templates.PageTemplate(p)) } Edited to remove template line
Just curious. You said that your main application is written in Java. Why don't you use Java for the launcher as well? Java has everything you need to write a "native" UI. Also using just one language for both will probably make maintenance easier in the future. Meanwhile, writing a native, cross-platform UI in Go is not easy since there's no pure Go library yet and you are forced into the C world which throws all of Go's advantages out of the window. On the other hand, if you insist on using Go and since the only thing you need is just a progress bar, it might be worth it to do some extra work and write one "from scratch" using [exp/shiny](https://github.com/golang/exp/tree/master/shiny). I don't know how easy it is but check it out.
? This doesn't work for me, since "buf" isn't defined. And after defining "buf" the only change is " buf.String() -&gt; templates.PageTemplate(p) " Or am i missing something here? Totally new to Go and i posted this example because it took me quite a while to get it right and i wanted an example to people in the same situation.
Yes, middleware that checks whatever means of auth your using (token based or session based). Basically the middleware says given request to page A does (session or token) have access to this? Yes - Continue. No - Not Authorized
Except there's no easy way to force a logout :/
You're right, I left in an extra line sorry about that. I edited the code, I have it working here https://github.com/peppage/1bwiki/blob/master/router.special.go
Yes - https://docs.google.com/document/d/1yIAYmbvL3JxOKOjuCyon7JhW4cSv1wy5hC0ApeGMV9s/pub Sorry for the delay - I use reddit quite sporadically
Thank you a lot! Edited and updated. :)
While I somewhat agree with you about quality and the fact that there should be fair amount of criticism, I also don't think that publicly attacking other people, even with noble intentions, is a good idea. It would be better if you used abstract terms in your article without pointing at anyone. That way you could prevent others from taking "bad" code into their projects and at the same time "not being a *****" to a person in question. Quality standards is very strange term. Industry, as a whole, does't like "best" things. It prefers "mediocre" a best. Is it for good or bad I honestly don't know.
It is there, because it feels like a kind of an NPE to me: it's the same cause (a null/uninitialized pointer) and it's a runtime crash. Although the types appear to be safe on the caller side (there's no pointers involved), the API is unsafe, and there's no way to figure out before running. It would be interesting to know from an experienced Go developer how frequent are such unsafe APIs in the Go standard libraries. 
a) streaming or bi-directional are not supported b) on server you can plug in any middleware you like, including one that traces requests, see "base" parameter in Server.InstallHandlers https://godoc.org/github.com/luci/luci-go/server/prpc#Server.InstallHandlers on client you can plug in an *http.Client with any http.Transport you like, including one that traces requests, see Client.C field https://godoc.org/github.com/luci/luci-go/common/prpc#Client.C
One option, since `andlabs/ui` library has its cgo tied up neatly and promises static linking, is to spin up a couple barebones vm instances to compile the binaries you need with the proper toolchains. Otherwise, you can just stick to cli, which will pop up when the application is run. If it's a dev tool, or targeted at a similar community, a terminal window isn't a bad way to go.
If you're using sessions, then the client stores a sessions id. On the server-side you have some session store (redis) which maps the session id to the user's session data. Every time a client makes a request, you use its session id to lookup the corresponding session data (permission data in your case). If you want to log them out, you just delete the entry in the session store so the client's session id becomes invalidated (doesn't point to anything). Tokens, on the other hand, are completely self contained. They have all the user's data (id, permissions, etc ...). To prevent the user from modifying his own permissions, the token is signed using a key. Therefore, if someone changed his own permissions in the token, the signature is invalidated and it doesn't work anymore. Whenever a client makes a request with a token, the server just has to validate the signature and then (assuming the signature is valid) use the permissions in the token. The problem is that, if you want to log someone out, you have no session on the server you can delete. You have to wait until they make another request to clear their cookie (or w/e mechanism you're using). You can always change the key used to sign the tokens, but that invalidates everyone's tokens.
I don't do that either in production :-) My comment was in response to the OP, which talks about the development environment. This implies frequent code reloads.
Sure there is! Use memcached or redis to store the token as a key. If it's there, the token is verboten. Simple!
Thanks for asking. The solution is not obvious. To me the best would be that the code like timer2.Reset() simply fails to compile. Ignoring this call is another option. Sometimes hiding bugs is better than exposing them like a crazy exibitionist. Check the "ignoring NPE" section where I provide some arguments about why it's bad for the user. 
Defeats the purpose of using a token in the first place. 
That's a great point. I can imagine how (foo,error) can act as a guard on the caller side to force error checking. About overusing pointers it's probably true. On the other hand there are several legit cases where some sort of "reference" is desirable. Either you don't own an object and you need to indicate that, or it's some shared object tied to some system resource, or if you have a cyclic data structure (like in the mentioned Hoare's talk) to name a few examples. 
If you don't want to let the user wait until the email if safely queued by SendGrid, then you have to queue it locally in some kind of persistent storage. This is the only way you can guarantee the delivery. One solution is to send all your emails through a local Postfix server, and it relay emails to SendGrid. Another solution is to implement some kind of persistent queue directly in your Go program.
I'd agree that it lessens part of the benefit. Upside: no need to hit the DB on unauthenticated or unauthorized tokens -- fantastic under DDOS attacks. Downside: need to hit an extremely low latency, high throughput store on authenticated and authorized (the most common case, to be sure) tokens -- but no need to store anything other than the key (or a hash of the key) in the blacklist.
&gt; Upside: no need to hit the DB on unauthenticated or unauthorized tokens -- fantastic under DDOS attacks. I don't understand. Why would it need to hit the DB?
If you're not using token based auth, then you need to authenticate and authorize against data which is almost universally stored in a DB of some sort. Perhaps I should have said datastore? If that's the confusion, apologies.
Some was... Not much tho. Which is upsetting. Go compiler and runtime use clever tricks with channels (for example direct write into other go-routine stack with unbuffered channels) and if you don't reach buffered channel capacity - it, to my experience, will not lock. As for primitives - I think it uses atomics inside tho I can be wrong. More importantly channels are MPMC which is quite hard thing to do right.
In this case I would say you don't want to be using Perl (or something like it). There are even more dynamic features like `eval` that trigger this kind of behavior, but it is all by design. This is just runtime binding in action. Even if we accept your argument that it is "human error", Perl still does the right thing...I presume you run your programs at least once before pushing them in to production? If so, you will see this error.
shiny uses cgo for the low-level bindings to the OS to create the window too. It would have the same problems. (In fact, I doubt that it's a problem that anyone can get around without cgo in a way that supports every OS that Go supports.)
I have implemented Secure Remote Password (SRP 6a) - this allows key exchange without ever sending the password across the wire. Once keys are exchanged I use 256-bit AES encryption on every RESTful call. This sets on top of HTTPS/TLS. Every request/response is digitally singed. I am working on documentation and examples. See http://www.go-ftl.com/ 
It is targeted at normal consumers. That's the problem. A terminal is not that streamlined and may be "scary" to others.
The terms are *authentication* for who a user is and *authorization* for what a user is allowed to do. "access control" is too broad and not really a term in web dev.
I detest to test! :) Without jokes usually you test to a certain level in time-effort constraints you have and then let the rest be found by battle in production. Actually some Perl guys are raging about I was unfair to them, check this out: https://www.reddit.com/r/perl/comments/4q5lik/null_undefined_errors_hell/ 
Whoops. must of misplaced my brain during that bit. thanks. http://i.imgur.com/5iof0Jp.jpg
yes, let's do everything as a fu@#ing web app. especially web browsers !!!
What is the benefit of taking on an external dependency for a library that is less than 110 lines of code? I'm curious... is it significantly better than these 12 lines of using text/template to achieve the same result? https://play.golang.org/p/T7HNBg6Ztc The only difference in functionality that I can see is that this interpol lib uses a shorter replacement syntax "{foo}", compared to the stdlib "{{.foo}}". 
Depends if the ToS is enforcable. And that depends on the country you're in. Law &gt;&gt;&gt; ToS.
Use internal/ packages. Go nuts with them. They're good.
It seems odd to ask for an example of Go code for something that can't really be done in Go. Suppose you have struct Foo with a method like func (self Foo) add(other Foo) Foo and a method which takes a Foo and uses the add method. Then later on you have another class Bar with a method func (self Bar) add(other Bar) Bar and you want to modify your method so that it can work on either a Foo or a Bar. Unfortunately, there is no clean way to do this in Go. Now suppose you had an interface from the beginning type Addable interface { add(Addable) Addable } and you made Foo implement it. Then it would be possible to later add Bar support. It's still not an ideal situation, because you have a lot of runtime type checks, but it's about the best you can do within Go's type system.
Nice and concise. I only would recommend to install Go outside the downloads folder. Surely many devops clean up this folder regularly.
Web apps allow for a unified windowing library that runs on all machines. 
Fair enough. I don't think there is a way to get the syntax for the pattern any shorter via text/template, so if that is a real concern warranting a library, then ok. As for being able to preserve the original value for unknown keys, you can achieve that with a few more lines: https://play.golang.org/p/PZDNMB8QBO Again, it may not be acceptable in terms of compactness. But I am just pointing out that the functionality is possible with a limited number of lines. 
Thanks! I updated the tutorial to install Go in the /usr/local folder: tar xvfz go1.6.2.linux-amd64.tar.gz -C /usr/local
I always just used &lt;!--
Shouldn't the files under folder `lib` start with `package lib`? What am I missing here?
I have started the gobook by "Caleb Doxsey" (before seeing this thread). So, what book do you recommend as a continuation of that? [Basically a confused golang starter here] :)
Please, no more cat/dog examples; this is the interweb, not a Uni book on Java programming from 2004. Maybe use a simple account, withdraw &amp; deposit example - at least make it something that someone MAY have to program at one point in their lives!
You can somewhat think of it like a base class, but what I wanted to point out was that Go lacks the ability for this system to function as mixins. For example, I have a series of struct types and a function that uses reflection to set exported fields. I'd like to just mix this in type Whatever struct { *Setter ExportedField string } This won't work unless I pass the reference to the type to the functions on Setter. It is a slight frustration with Go.
 thank you for the example web app .I was looking for something like this. that structure will be really helpful. as this is my first web app and I am just learning through small examples in the books. This one is really helpful for the big picture. 
thank you for the thorough explanation. you mentioned that "Give the token an expiry timestamp. When you check the token, if it's valid you issue a new one with the expiry time extended. To force a logout, you stop issuing new tokens." Is this method efficient or does it have any trade-offs?
hmm cool - was not aware of that project, will be looking into this!
Didn't came into my mind, here you go: http://imgur.com/iS18zjV Looks like the cookie stuff doesn't work as intended.
Can you write a browser no, but only a real idiot would attempt to do so. Moreover the Web combination is not nearly as slow as you think it is. Any Gui toolkit that seperates the handling of events from the description of windows with a language barrier is fooling itself.
https://play.golang.org/p/ff2KiNuJlD
&gt; Suppose I want my Animal array to contain Dogs and Cats, then I can loop through array and call arr[i].speak() method to get "Woof", "Miaow" etc (Polymorphism) https://play.golang.org/p/jsfgf7bHu_ &gt; Same in a game where you have Player, Ghost, Monster... all inheriting from GameObject base class. Looping throug GameObject array and calling tick() method then calls Player.tick(), Ghost.tick() etc Go does not implement inheritance so this is not possible in a way that 'tick' would make sense for. You can approach this solution but it would be silly. Tick is a function specialised for each type, it should be implemented by the type exactly as Speak is above. Perhaps where a little confusion comes from is that interfaces are implicit, not explicit. There is no need to make an object that is a member of a class in order to implement an interface. Any type with the same method prototypes will do fine. For example: https://play.golang.org/p/NaYX-LGoAT
My problem is more with the whole "this way is obviously superior because I like it" mentality. No, Go's structure will not always be the better option for every scenario and every developer. Evangelism is annoying, not useful. 
miaow! :) Thanks, that looks pretty interesting. I will have a play...
That's cool!
Does this mean that go is bad now? 
I would worry "lib" is kind of redundant in a path. If you're importing it, then of course it's a lib.
Neat! Thanks!
For further support of how much is possible if you start low enough, with flexible enough language, see FORTH.
Go is a procedural langauge just like C, so this is exactly what you ARE doing. In fact, methods are just syntactic sugar for a function where the first parameter is an instance of the type or pointer to said instance) that it is "attached to." Go is not an OOP language. Go is not a functional language. Go is a procedural language with a lot of convenience added on top.
Considered it, and it's definitely not fit for my purposes unless I got the semantics wrong: I want to keep doing HTTP over the connection, with chunk-encoding and maybe even Keep-Alive. A call to Hijack will drop me to pure TCP, and then I'll be on my own with the entire HTTP layer.
Yes, this right here! I am new to go and thought this article could be useful, but it really didn't show me how I'd use an interface in practice.. 
Care to elaborate? I'm new to golang and I'd like to reimplement some parts of SMBus/I²C chip access logic from python to go. Nothing real-time critical really (rockets won't be launched with this).
wat
With vim and vim-go it's just as easy as `gd` to quickly go to the definition of a function.
But that ends up in the HTML, so it's not very useful as a real comment.
Cool! that's helpful to know at least.. 
With IntelliJ you can pretty much follow both scopes and as well define different colors for them as well as notice when you are shadowing a variable.
I had no idea what you were trying to say with that example because the behaviour doesn't make sense according to the language spec and you don't explain it, so I looked at the source to see if it's maybe an interface with an implicit pointer that you just didn't explain, and no, it's a real type. So I looked at the source (you can just click on the function in the GoDocs to see the source of any function) and it's the exact opposite of a null/nil pointer dereference/exception. The code is checking if something is nil and *explicitly* panicing if so.
The video linked to at the bottom is *really* incredible by the way. This algorithm is pretty cool, and it's only ~150 lines of Go!
Actually in most editors with their go support: Emacs, Sublime and Visual Studio Code and as mentioned by dlsniper Intellij.
Go's type notation is terrible because it doesn't match the use case like C's does.
Part of the problem is that Java classes do several loosely related things: - class as namespace, e.g. math.sqrt - class as data type, e.g. Point has an x and y - class as a way of abstracting behaviors and hiding date types, e.g. a point abstract class that might store x and y or might store radians and distance behind the scenes because you can convert with a ToCartesian or ToRadial method - class as a way of making modular software, e.g. you can make a subclass of Window that overrides the DrawMenu method so that the menu is drawn with bold text or something The animal examples are bad because they're trying to show how to do modular software, but it's very obviously overkill for the problem. One of my aha moments using Go has been thinking about how structs, functions, and closures are really perfect equivalents as ways of passing data from place to place. 
Nice article. Where are people doing import math "math" That must be some kind of automated tool... 
The files directly in `foo` would be `package main`, and the files in `foo/lib` would be `package foo`. This is the inverse of having the files in `foo` be `package foo` and files in `foo/cmd` be `package main`.
Nice writeup! Thanks.
Have you tried instantiating a struct in a global-level variable and not doing stupid shit with it?
[Yep, that's a protobuf thing.](https://github.com/onsi/gomega/blob/master/ghttp/protobuf/simple_message.pb.go#L18)
&gt; types.go Unless there's a good explanation, this worries me. Putting a bunch of types in a "types.go" is pretty poor style, both because that's a non-descriptive filename, and it probably means that you're defining types in one place, and then putting functions in another.
1) I've used it on some side projects but nothing at scale. Obviously works for google though. I was passing around strings so byte conversion was easy, but it wouldn't be much harder to use encoding/gob for something more complicated. 2) HN ids are monotonically increasing, so after the first fetch I'd know an approximate filter for what should definitely be in groupcache (e.g. "smaller" ids) and what might need to be fresh. I believe returning an error from groupcache (e.g. ErrNotYetAvailable) will not be cached so future requests will work. Might be able to side-channel the GetterFunc to load the "fresh" data too... *Shrug* It'd be an experiment...
Sure. Let's put together a interface to define and struct to implement swap and clear actions. These actions are unique to the respective struct, but they're necessary for the program to work (Think of everything but main() being in a library). type SwapClearable interface { Swap() Clear() } type Point struct { x,y,z float64 } var _ SwapClearable = Point{} // Implement on the struct func (p Point) Swap() { p.x, p.y = p.y, p.x } func (p Point) Clear() { // Set z to origin p.z = 0 } type Color struct { red,green,blue uint8 } var _ SwapClearable = new(Color) // Implement on pointer func (c *Color) Swap() { c.green, c.blue, c.red = c.red, c.green, c.blue } func (c *Color) Clear() { // max out green &amp; blue c.green, c.blue = 255, 255 } func SwapAndClear(sc SwapClearable) { sc.Swap() sc.Clear() } func main() { var pt Point = Point{1, 15, 42} var clr *Color = new(Color) SwapAndClear(pt) SwapAndClear(clr) } Now, when someone is writing `func main()`(or anything else that imports these objects), they can be confident that the compiler will ensure `*Color` and `Point` implement the `SwapClearable` interface. An added bonus is the library author can use the same checks as a regression check to ensure both structs follow any changes made to the interface. Edit: FYI - these same `var _ &lt;interface&gt; = &lt;implementing type&gt;` checks are quite useful in test files, too. TDD failures on interface changes will backstop changes on the interface.
If you're just going for timeouts, honestly I'd look into using contexts to propagate the timeout and, if it times out (or is cancelled), hijack and close the connection.
Good explanation. It annoys me when people try to argue that Go is OO. While they're right that some parts of Go are very similar to, if not identical to, parts of the OO model, they're looking at it wrong: If you treat Go like it's OO, you will write bad Go code. I'll nitpick a bit, though: &gt; the first parameter is ~~the struct~~ an instance of the type (or pointer to ~~the struct~~ an instance of the type)
I'm really confused.. Is it like this? `$GOPATH/src/github.com/me/foo` - files here have `package main` and `$GOPATH/src/github.com/me/foo/lib` - these are `package foo` ? I thought that in `lib` they'd be `package lib` ?
Thanks for explaining this! I can see that it works like this (i.e. without a pointer): type Setter struct { ExportedField string } func (s *Setter) Set(str string) { s.ExportedField = str } type Whatever struct { Setter } func main() { var w Whatever w.Set("Set this") fmt.Println(w.ExportedField) } so I'm curious in what cased you rather use a pointer to an embedded type? Pointers still confuse me, so if you're up for answering, thanks for your patience.
Yes. In that example `w.Set("Set this")` automatically calls the embedded `Setter` object. The important point in that is an empty `Setter` struct (with an empty `ExportedField` element) is generated when `w` is instantiated. This is an important distinction. Unfortunately, pointer vs concrete object isn't cut-and-dry. The biggest distinction is that a pointer is able to be empty (i.e. the element doesn't exist). For concrete types in relational structures (linked lists, trees, and the like), there needs to be an exist vs doesn't exist functionality. Interfaces in the same place aren't quite as clear, because it could be the pointer type that implements the interface (meaning the concrete type ends up being a pointer to a pointer when an interface pointer is the element type). There's a balance that needs to be struck between the interface and the type (in my example, color as pointer vs a pointer to color). This is a decision that must be addressed by each interface and type, because there's no single answer that's right for all situations. Essentially, a pointer to a type is used when the object doesn't **need** to exist (to re-use the tree example, leaves won't have child objects). Created objects are filled with zero values, so new structs with pointer objects have nil pointers (indicating those objects haven't been created). Embedded concrete types are useful only as far as the default "every object is set to its zero value" is useful. 
Though common, a package doesn't have to have the same name as the directory it's in.
Err, what? How's a global-level variable different from what is mentioned in the code?
Maybe It should be changed to "By Definition: Singleton is a design pattern that restricts the instantiation to one object." If that conveys better understanding. Thanks.
Very nice! Haven't looked too closely yet but would it be possible to render a progress bar from the right side?
*mind blown* I'll need to mull this over a few times - thanks deeply for your willingness to explain this so thoroughly
What's the package for emacs ?
Not really. types.go is pretty descriptive and if you then have a file.go named after each type then it's quite ok. Maybe it just makes more sense at that point to move the types out from the common file into each file but it's not a big issue imho. 
So, I wrote out a reply last night but left it unposted and I'm not happy with any of my answers. a brief summary is type A struct {} type B struct {*A} func (a *A) Set(v reflect.Value, key string) { fmt.Printf("Setting key %s for reflect value %#v", v, key) // You can now set the field values if required with v.Elem().Field(index).SetString("whatever") } instance := &amp;B{} instance.Set(reflect.ValueOf(instance), "Hello") edit: Fixed a reference to B which should have been A. Sorry for my sketched example code, a little busy today!
JSON files aren't really designed to be written in patch form. Unless you're looking just to iterate the JSON file. Feel free to PM me example code if you don't want to post it publicly.
&gt; I find the lack of language-level clarity in this surprising There's a number of reasons behind this, for a start, Go code is compiled to a single binary, not a series of .pyc files for example (yes I know about .o) and as a result the packages become actually one package. It would be awful to say "import github.com/someurl from github.com/someurl/packagefile" Next, while bare functions are completely acceptable, most functions should be attached to types and packages also named after the types or a subset. Instead of someRandomFunc it should potentially be Item.RandomFunc and the code can belong in item.go. These rules aren't universal, and it's really down to how you personally prefer things, but this is how I see it.
Not a fan of the DSL, but apart from that I like it
It's not implemented right now, but I see no problems with implementation.
You should probably use a stream of JSON ( Eg: NDJSON http://ndjson.org or JSON Lines http://jsonlines.org ) documents instead of mutating a single JSON. Since it sounds like you can't change the input, then using upsert of all documents you want to store in MongoDB might be a solution. (How much data are we talking sbout, and how quickly do you need the new events in MongoDB?)
Analyzing code at this scale is always exciting! Thanks for sharing!
Yep :) Production is a different beast, we're all sorted out with Elastic Beanstalk and compose the endpoints behind an API Gateway so the client only sees a single subdomain (https://api.mycompany.com)
Probably rather name it argparse, since optparse is deprecated in python.
1. This has nothing to do with the question which is about json stream parsing 2. MongoDB is perfectly fine for some uses and not for others. "MongoDB" in this sentence can be replaced with any other db.
1. A fair point, if I understand the OP correctly the JSON file is being updated regularly. Personally I'd probably store its datastructure in memory (depending on the size of the data) and use inotify to update it as and when the file is updated. 2. MongoDB is never a good choice for anything. If you need a NoSQL db you should use something sensible, like postgres. 
&gt; ElasticSearch Looks interesting. Possibly overkill for OPs problem though. I'd be interested to know how large this JSON data that they're dealing with is.
This should not be a problem in well written code. In Go, files in the same package/directory share a namespace, but well written code should have very little in package main and most code in other packages. Treating directories as one package means you don't need to make files huge to satisfy your API. It may be that your package only exposes a few functions to the public but has an extensive internal logic. Because directories are one namespace, you can still arrange the internal code well. 
There are only 2 files in the stdlib called `types.go` (and one in the vet command), and they both deal with types as a computer science concept, rather than being a pile of unrelated miscellaneous user defined types. **Edit** to be clear, one enumerates error types and functions for dealing with types of errors in the os package and is probably not the best name for that even, the other deals with sql &lt;-&gt; go type mapping in the database/sql/driver package.
I really like this! Thanks for sharing! 
Does anyone know if Bleve supports maps as data types? I can't find much documentation on this, my tests say no so far :/
Hi there, I failed to mention that I called `imaging.Rotate90` before `carve.ReduceHeight` This code panics for me: https://play.golang.org/p/9mSAIoms06 (using the image in my original comment)
Yeah, not sure why prepending the salt to the password, and then using the actual salt parameter as constant from some configuration. Argon2 can take password, salt, and a secret (together with cost parameters), which is what I think the author is wanting, but that Argon2 Key() func doesn't expose. 
The code you linked does specify a crypt style format, which would need only a single column. https://github.com/P-H-C/phc-winner-argon2/blob/master/src/encoding.c#L232
it really isn't
Good to know I wasn't completely off base about Go. FWIW, I didn't think Go was OO; I've used it enough to know that much. I suppose my point is that any language or programming paradigm we pick someone can make a reasonable argument of the form: "X is easy to screw up in Y; therefore Y is bad." All approaches to programming have some sort of cognitive burden to carry in order to not screw things up too badly. So it's kind of weak if the best complaint against something boils down to: "if you aren't very good at it then you get bad results."
Totally unrelated, but can you share your PS1 from the GIF? Also I dig the library and shadowd is super awesome!
Caught the error! Thanks for your help, pushed a fix :)
Well, I outlined in my first post how I'm used to this from Node.. I see your point, too, though
Thanks for your thoughtful reply. In your example of `item.go`, do you mean that `RandomFunc` is a method on `Item`, or is it more like how there is `flag.Parse` ? 
i really wish Go had `let` or something like it to create write-once variables
gb is a build tool, like the go command is. They both invoke the same go compiler commands. 
Really late to the party, but my reason to proxy: ports lower than 1024 on Linux have to run as root or can be run as another user as long as the executable has had setcap 'cap_net_bind_service=+ep' run on it. You don't want to run your executable as root. Later, you fix a bug in your executable. You move it into place, kill -9 the running instance and wait for your process management to restart it. If you haven't don't the setcap dance again, your executable fails. So, having a proxy allows you to deploy more sanely, by allowing you to deploy and restart without running as root.
Unrelated: I'm new to Reddit (it's never too late to start using it). How can I search for a post so I don't re-post (as I did with this one). Also, should I delete this post since it is a duplicate? Thanks
Dave Cheney posted this article right before releasing [gb 0.4.3](https://github.com/constabulary/gb/releases/tag/v0.4.3) which adds the adoption of a depfile and support for SemVer 2.0.0 tagged projects.
... but some external consultant already sold management on NoSQL (no need to do database migrations anymore !!)
This article has some glaring problems, and would not be a good choice for newbies to understand HTTP connection reuse. The first is the confusion already commented on by @ratatask about TCP keepalive and HTTP keepalive. Because the second example program uses URLs on two different hosts, it is guaranteed that the connection cannot be reused. The claim that the connection will be re-used in the third example is bogus. This topic is worth looking into, but this isn't the right article to do it. -jeff
It won't work (easily) for unexported functions, but you can also run godoc locally to show all the package-level exported functions: godoc -http=:6060 Then add `?m=all` to the doc url to see unexported types/functions: [http://localhost:6060/pkg/net/?m=all](http://localhost:6060/pkg/net/?m=all) This won't work for `package main` without a modified godoc though. [CL here](https://github.com/golang/go/issues/5727) if that's what you want...
Thx! We're trying to write awesome software. Regarding prompt, it's https://github.com/seletskiy/zsh-prompt-lambda17
Awesome, thanks!
I have never found a use case for NoSQL that wasn't better served by a relational db :) But Mongo really is [an atrocious piece of shit](http://nboughton.uk/blog/ah-mongo/)
You are completely right, technically speaking it's not an NPE, but to me what exactly happens is just an implementation detail. "nil" is involved here somehow (probably it's a part of this Timer struct). When you declare a variable like so it is not initialized (according to the runtime API, but not the language spec) and inside a struct there's a "nil" somewhere (or something like "nil"). At this moment it's like a ticking bomb. How do you think a real NPE works and how is it different? Well, there's a check somewhere on a lower level that says "if obj == nil panic!". This check is either in the language VM (like in JVM), or in the CPU (in case of C), or in the language runtime (in case of Python), it doesn't really matter for the end user. In this case it's baked into runtime. I think we are mostly on the same page about it, but you're blaming a programmer while I'm blaming the language/runtime. It should be smarter, because people would make mistakes every so often no matter what. 
Thanks for this and this is definitely something to consider. I'm not tied to this algorithm, so will take a look and see if it the function is better served by another. From what I read Argon2 although new was a clear winner. Was not aware of the successful attacks on its earlier variant though :)
Stable branch is available on gopkg.in: [httpexpect.v1](http://gopkg.in/gavv/httpexpect.v1)
If only what you want is the documentation of the func/const/var then you would like `go doc`. go doc somepkg.SomeFunc To look for unexported symbols: go doc -u somefunc 
Go is *profoundly* Object Oriented.
I couldn't find, but there's a video version of these slides. http://gotocon.com/dl/goto-chicago-2016/slides/FrancescCampoyFlores_GoToolingInAction.pdf It's a nice walk through on how to improve your code. 
Thanks!!
 e.GET("/fruits/orange"). Expect(). Status(http.StatusOK). JSON().Object().ContainsKey("weight").ValueEqual("weight", 100) Go already has ways to determine if something contains a key or equals a value, and when this is too onerous there is the `testify/assert` library which provides the most basic assertions most people make in tests. This chained method style seems to be a popular way to write testing libraries but I've always found they cost an awful lot complexity and in the end are a lot less flexible than just doing it "the long way." For instance, I can't figure out: * what is the type of anything here? * what if i want to just ensure the status ISNT some kind of 400? * why does a status check return an object that has a JSON method? * what if the weight is a float, is there a fuzzy equal? Or what if weight isn't a value.. If this was _just some code_, I'd be able to answer all of these questions, because I know Go, but because everything is a function/method call, I have to read the library to do _anything_. All that having been said... I know some people prefer this style. Kudos for this contribution to the community.
Oh, interesting. So performance-wise you'd suggest using this method? I will try it out.
So it seems, thanks. I've not actually implemented argon2 yet so wasn't sure on the output style.
Dot import :(
Indeed :( I guess it[1] is not the worst usage I've seen, given they directly control the package... but still :/ [1] https://github.com/google/godepq/blob/master/godepq.go#L19
This is interesting but one thing I find is missing from all these kind of testing tools is the lack of support for non-cookie based "sessions". If, for example, my application doesn't use cookies for authentication but headers (as in Oauth2 Bearer tokens in the Authorization header) with the current API, after authenticating I would have to add a WithHeader to every successive request. What about adding a Header section to Config and a method to add common headers to the Expect object ? These headers would be added to all successive requests. 
can you upload all the presentation slides?
I'm aware of the differences. My point was that neither gb or go tools are compilers. They are build tools. That's all.
chillin'.
IMHO this is much better than the standard practice for utilities like this of putting everything in package main. I used the dot import here because godepq.go is basically a command line wrapper around the library, and doesn't import any other non-std packages.
Good idea. Probably a more generic approach? We can add a function to `Config`, which will be called for every request before sending it. And user may provide a function that calls `WithHeader`. BTW, currently it's possible to achieve this already: you can provide a custom implementation of `httpexpect.Client`, which will set request's header and pass it to a wrapped `http.Client`. Though it's not very convenient.
GC'ing is probably one of the things. And possibly IO, if you are doing any.
I'm doing a ton of bufio.writer operations are those done on separate goroutines?
Broadly speaking, yes. Your software may want to have some "good habits", in terms of pidfile handling, and catching signals gracefully, but even if it does not, all those listed process managers are agnostic. They don't care if your program is in C, Python, or Go.
Yes, you can. But parts of it seems to be a little outdated; both Ubuntu and Debian have switched to systemd (like Arch Linux).
See links in the sidebar on this page, especially the "Resources for new Go programmers". Another one is https://github.com/avelino/awesome-go with a ton of interesting projects and links. Finally, find a local Go user group (https://github.com/golang/go/wiki/GoUserGroups) and join in.
Redis is awesome. It's incredibly fast and the author has put special care into selecting the best algorithm for each Redis command. I don't understand why people would NOT use Redis. It's efficient and you can have persistence too.
I didn't really built it to compete with any other tool, just saw the possibility of adding a webocket server on top of Redis with very little code and I took it. :) &gt; I guess because of Redis, we won't lose messages if the go server crashes. Anything else? Actually not even this, because Redis PUB/SUB doesn't have a buffer with messages and neither does Philote, clients that aren't connected the moment a message is published won't get it. Can't help you with the chat solution as I don't know any open source one based on websockets, but note that Philote isn't a chat thing, that was just a sample application to show how it works. :)
SRP 6a is a key exchange. The users's password is never sent over the wire. Instead a set of large numbers generates a validated pair of unique keys (2k long numbers) that both the server and the client have. At that point the keys are hash (sha256) to produce AES 256 bit length keys. Every RESTful call is sent, encrypted, salted and with a 64 bit CCM digital signature. The server decrypts, builds the response then sends back the response with a new initialization vector, CCM signature and encrypted and signed. The 2FA happens after encryption starts - so login is fully encrypted with a second key from an iPhone/Android device or a single-use key that the person has.
wish that was a bit more documented, but I assume using runner would do what i wanted
I wasn't trying to criticize the project. I was just trying to understand the benefits of going with this approach that I might be missing. It wasn't clear from the Github page if this was an experiment or if you wanted people to (eventually) consider using it for serious use. I also asked about the next level chat app that goes beyond "Hello world" in this post because it felt contextual and I thought you might have evaluated (or be inspired by) other solutions. Thanks!
Maybe. But also, GC.
Yeah, I imagined, but I thought I'd clarify rather than risk misunderstanding, I also don't mind criticism of the tool! I posted it just to get some eyes looking at it and get feedback, thank you for taking the time to look at it and posting. The inspiration of doing this came from years of using [Pusher](https://pusher.com/) and the fact that I though it'd be fun and easy, don't know if that helps the use case you're thinking of though. 
I guess we're supposed to guess what your program is doing so we can then guess what packages it's using, so we can guess which components might be creating goroutines so we can guess which of those then create OS threads?
I mentioned in another comment. Maps and bufio.writers. It's a very simple program. 
Why build the application when you can just deploy the prebuilt binary? You shouldn't be using elb to store versions of your code, that should be the job of git or whatever svn. I never really understood why you would push your source code up when you don't have to?
it is open source, you can read all the code in the stdlib. In fact I believe that is recommended so that you can become acquainted with idiomatic go.
One way is to use [permissions2](https://github.com/xyproto/permissions2) (uses Redis) or [permissionbolt](https://github.com/xyproto/permissionbolt) (uses a Bolt database in a single file, a bit like sqlite).
If you are running a HTTP server type app, you are using goroutines... Each request will spawn a new goroutine and potentially a thread 
code: "It's the first beta implementation of our analysis described in Static Trace-Based Deadlock Analysis for Synchronous Mini-Go. There are still bugs we intend to fix." https://github.com/KaiSta/gopherlyzer 
It says that use *time.Time.
&gt; Value type &lt;nil&gt; into type *time.Time Ohhhh. It didn't sound that explicit to me sorry haha. It's working now!
Very nice! I didn't know about Centrifugo, they do seem like pretty similar ideas, I'll be taking a look at the code. :) Yes, the redis connection issue is definitely in my mind and I'm leaning very much towards changing the implementation, it has some benefits, but I'm trying to figure out a way of keeping those in a more efficient way. Will also look into gorilla/websocket and redis pipelining. Thanks for all the feedback!
In 1.5 of Go I had a bunch of problems with go-routines not working happily when combined with begin a service and a Linux chroot. My solution was a C wrapper that started and managed the Go code. I am not certain if the problems were fixed in 1.6+ of Go. This related to changing of ownership of sub-processes and not changing all the threads in the Go Program - thereby leaving some threads running as root. This would not apply to Windows - if on windows use the github.com/kardianos/service package - it works. If on linux you might consider: github.com/pschlump/daemon-it
Ask Mr commandeer, he said it.
Replace the new(Color) through (*Color)(nil)?
That's the empty value for time.Time. You can check it with the convenience function time.IsZero(). I've not used mysql with Go but in PostgreSQL the lib/pq library has a NullTime type that works great on these situations.
Very cool! Always awesome to see more audio work in Go. (shameless plug as primary author, sorry, I just wanted to let you know they exist -- I don't really care if you use them or not) [Azul3D](https://github.com/azul3d/engine) has a bunch of audio packages that you might find useful, in specific: - [azul3d.org/engine/audio](https://godoc.org/azul3d.org/engine/audio) is like Go's "image" package but for audio (defines standard formats and data types, pure Go). - [azul3d.org/engine/audio/wav](https://godoc.org/azul3d.org/engine/audio/wav) handles decoding and encoding of wav files (pure Go). - [azul3d.org/engine/audio/flac](https://godoc.org/azul3d.org/engine/audio/flac) handles decoding of FLAC files (pure Go). Lastly, to actually play/record audio (including 3D audio), you can use [azul3d.org/engine/native/al](https://godoc.org/azul3d.org/engine/native/al) which is cross-platform (Windows, Linux, and Mac) and while not pure Go is "go get"-able (no fancy installation/C dependencies are needed, they are all baked in). However, do note that this package is just 1:1 bindings to OpenAL, so it will be trickier to use than the above packages (I suggest Googling OpenAL tutorials, long term there would hopefully be a higher-level package that works with the above ones nicely). I like that your package looks so simple to play audio (in comparison to OpenAL, which is more featureful/complex), but a shame it's Windows only :(
Ideally, it would be impossible to create an invalid timer value in the first place.
Your project is great! I don't think that conditioning people to write non-go code (since the first example does not natively compile with a go compiler) is worth the convenience, but you put in all of the effort to make this cool project, so don't take this criticism for much.
Or remove the "https://" part. "github.com/tcolgate/hugot/cmd" is the go package identifier that they mean to reference. Better yet, GitHub should redirect these kinds of URLs to the master branch by default instead of 404ing.
can you post benchmarks of this vs go-cache
The two APIs are fundamentally different so I figured there's no point in comparing benchmarks? Also, setting/getting a key is just using a map.
There is link from the article to his change request which I have copied below: https://go-review.googlesource.com/#/c/24466/ That link gives more details on what was found. 
Your "tiny" cron is 50x as big as regular system cron and still requires to be run as separate daemon. So it kinda doesn't really fill the niche for "tiny" cron.
Yes
&gt; if it's valid Which annuls the point of using tokens in the first place. Checking if the token is valid means you need to hit the DB, which makes using a token pointless.
I struggle with this too. Organizing symbols is a significant task in Go for anything other than very small projects.
Dunno what's up with all the link spammers and downvoting, obviously there are use cases for anything. You should try it - personally, I ran into pain when wanting to implement references to other data programmatically, as doing consistency checks (did this page I pull up fit what I expected in context?) is about the same as making the structured tables. But setting up and learning SQL stuff is also a pain (probably the reason for the spam: money in service). Personally, I'm sticking with map[string]interface{} in memory for as long as possible during development with a database interface type, so interfacing the DB pain is just implementing the few methods inside the application.
Here's what I'd start with: type JsonToDbObj interface{} You'll want to unmarshal the input JSON text (package encoding/json) into this interface{} type, then write func (the JsonToDbObj) ToDB() DatabaseType where DatabaseType is something your database writing code can understand. [edit] To actually answer, I'd say then, if not time prohibitive, you could do a comparison between previous reads of the input JSON. Now I'm wondering if the OS package has a file monitoring...wait here you go: https://github.com/golang/go/issues/4068 Given the arbitrary nature of your question there isn't really a concrete end here outside of computer science theory. In reality, the system you describe sounds like patchwork nightmare and should be refactored if possible. Could the JSON creator just send a JSON message with the diff over a POST request instead of updating a database file? Why are you replicating a database in two forms on one drive-local system?
You don't need to write a loop in the shell to run benchmarks multiple times (for benchstat), you can use the *count* flag. go test -bench=. -count 8 &gt; bench.txt will run the benchmarks 8 times and paste the results in *bench.txt*.
I want to try to make the GoDoc the definitive source of information. I can do much better at getting examples in there. I'll think about adding a basic example to the README though anyway. Thanks.
Gorillatoolkit or Gin. REST API just don't need heavy webapp fullpage as Revel or Beego.
my personal preference is [echo](https://github.com/labstack/echo) because if you need better speed out of it you can change the engine to fasthttp
True; though most of the "tiny" aspect is in avoiding package deps - e.g. modern CentOS cron requires libselinux, coreutils, sed, and of course systemd. My main goal with this project was being able to define the cron schedule in the interpreter line of an arbitrary script for easy distribution. Someone pointed out [mcron](http://www.gnu.org/software/mcron/) as well (~32kb compiled).
This!
Gin has a session middleware that use cookies like Rails. I usually disagree with the statement "use just the standard library", some libraries like Gin and Gorm do great abstractions, saving time, and with the right setup you have a mini-Rails. Keep away from Beego, Revel and like, though. My 2 cents.
Ive tried gin, and while its good, echo feels more idomatic and somewhat easier to reason about, which is why i recommend echo when im asked about go web frameworks
Yeah, i've looked at several frameworks including revel and beego ... and i can +1 this. Echo seems to be very cool. I'm coming from PHP (Symfony2 mostly) ..... and i'm very pleased so far. I'm using echo in a combination with quicktemplate!
&gt; Checking if the token is valid means you need to hit the DB Not if you use cryptography to verify validity, which JSON Web Tokens do.
There already was a topic about web frameworks https://www.reddit.com/r/golang/comments/42krm2/echo_or_which_framework_should_i_use/
&gt; this is serious draw back with that language and it's not the only one Perhaps it's not a serious drawback so much as it is a disqualifier for using Go for legacy-style, runs directly on customer's computer style applications. Never use your forehead to pound a nail...
I like `go test -run=-`. Test names are function names, so the dash won't match anything.
Thanks! I didn't know about that. I've updated the post with this.
We are having a big debate about in-process plugins,which sucks for 3rd party vendor s or out-of-process plugins which sucks for everyone. So, yes. Want.
With your concern of life time and maintenance, like most of us, just use the standard library ! Maybe if you really need it sometimes you will use a toolkit for routing like gorilla. For middleware often it's easier to do it alone than take time to see how others do. Go std lib is still improving in this direction, adding context to request in 1.7 for example. 
I would suggest doing integration testing instead. Put your MySQL server in a Docker container (or something else) and run tests that use the db against that.
Almost always a terrible idea, yes you can... but I have seen this question getting asked *all the time* in Django projects and it never ends well, Postgres and SQlite are just too different, always test against the DB you will be using.
Don't use Revel, I tried it a long time ago when first starting out, didn't like it, it uses it's own build pipeline rather than using "go build" which kind of rubbed me the wrong way. I know there is someone out there who forked Revel to fix all it's "quirks" but I forgot the repo. Anyway, Gin or Echo are always a good choices. Beego probably isn't all bad either, but you probably want to start with something lighter like Gin or Echo. A list of frameworks I stay away from: Revel, Martini, Iris.
I don't know about companies - but I moved from Clojure to golang around 5 years ago. I had completed around 5 projects in Clojure at that point, but had grown very frustrated with the reality of dealing with the java ecosystem (my background was C, Scheme and Python, and my few experiences with Java thus far had been equally frustrating). The company I was working for at the time mostly outsourced development tasks, but there were huge swathes of data cleaning and processing that they never properly planned or budgeted for, so I ended up doing those things alone. As such I had control and I ended up doing some of those things in Go. One result of that is [this library](https://github.com/tealeg/xlsx) - I've not had need of it since I left that job, more than 4.5 years ago, but it seems to have taken on a life of it's own. 
Thanks! That's a promising direction to explore. Do you have to have any public projects applying this pattern up on GitHub or elsewhere? I'm somewhat surprised by all of the comments suggesting integration testing "instead of" unit testing. It's not standard practice to do *both*? Unit testing and integration testing really do serve different purposes.
Is L-BFGS-B available as a C library? (Go can call into C libs.) Another option could be to port L-BFGS-B from a language other than Fortran. Or write a Python program around the Python library that you found. The program can calculate all the required data, and your Go program then can pick up that data. (E.g. via stdin/stdout pipe, a file,...) Sorry that I can not provide something more helpful..
Oh wow, that's your package? I've used it a few times, thanks for initially developing it. Great great help!
Damn that looks like a nice library! I've always used xlswriter in Python for generating xlsx reports, but am certainly going to look into this...
Not really, there's no rule for that. Also the point of testing against a DB directly is that you don't have to waste all that time and mock something that you'll need to test against anyway and, more importantly, it will allow you to catch bugs that otherwise you might not catch (especially if you don't do integration tests). Imho, just test against theDB you'll be using and that's it, it will save you a lot more time and headaches down the road. 
Hah! I have a program that used that library once a month. 
"holt winters triple smooth" sounds like an awesome beer
You can use [Fortran](https://github.com/golang/go/tree/master/misc/cgo/fortran) with Go.
As a hack you can also put MySQL DB files onto tmpfs (in-memory filesystem, in many linux distros mounted to /tmp and /dev/shm). And here you go, an in-memory MySQL database.
I concur.
try out github.com/skelterjohn/wgo. it helps ease the pressure of some vendoring issues. Using it, if you 'go get (whatever the url for gin is)', it will fetch all the deps into the project's vendor dir, and let you pin (or vendor) deps there.
I don't think it qualifies as a cleaned up clojure, but maybe https://oden-lang.org piques your interest? &gt;A functional language inspired by Haskell, LISP and Go compiling to Go.
yay for pie! :) I think there are distinct advantages to external process plugins, but there are also disadvantages. Raw speed suffers in the RPC translation, but it does give the plugin implementor basically infinite choices of language to use. And of course, for security, nothing is as secure as being in a separate process, though I don't know if that really matters in most use cases. 
Epic self promotion
&gt; Ideally I try to have, by default, the fewest possible number of dependencies. In your opinion: should I wait until that issue is fixed in net/websocket or I have a bug report I can reproduce? Or would you rather switch it for gorilla/websocket? The first is my option by default, but I see both points. We've been waiting for fixes &amp; improvements to x/net/websocket for a long, long time. It's fair to call x/net/websocket an abandoned project. /u/istokeworth is correct, they are both dependencies, use Gorilla's Websockets library, it's not abandoned. 
I rarely have dependency issues. Though, we do write a lot of our libraries in house..
&gt; But from what I understand about good practice in the go community, using projects that sanely keep their master branches stable so I can rely on go get is/could be best practice This is true for library projects. If your project produces an executable you are free to use vendoring tools for transitively flattening the library dependencies into `/vendor`. At least this is what I understand from discussions like [this one](https://www.reddit.com/r/golang/comments/4cptba/best_practice_for_vendoring_in_libraries/), but it seems a sane approach to me.
&gt; Raw speed suffers That and the burden of having to manage additional processes. Although I believe the problems of a multi-process scenario are exaggerated. Sure, a process can crash but so can a shared library. And the speed problem can be mitigated, at least to a certain degree, by designing the plugin API to contain only "heavyweight" functions where the calling overhead becomes negligible.
Great! Good luck.
You couldn't just make a new reddit account?
https://github.com/Jumpscale/go-raml ;-) - go generate from raml files. generates Gorilla Muxer for routing - Still in active development RAML-1.0 - Also generates Python
Nice to hear it.
Thanks for the thanks.
Thanks for the gold, whomever that was!
My absolute pleasure :)
I'm really glad that so many people have found it useful.
How do you handle really messy XML files. I found it hard to write all parsing and type handling in go.
Glide. works with other tools like gb, uses vendor folder. Works perfect for me to make reproducible builds on jenkins. I've made a golang container with glide binary in and I just build my projects inside it. 
It's not that difficult to set up a local database to test against.
SQLite speaks a very distinct dialect of SQL, and lacks, for example, strict type checking. https://www.sqlite.org/faq.html#q3 It might suffice to some extent for developing, but you absolutely must test your code against the same database software as you run in production. Even then, it's worth pointing out that every DB implements and expands on SQL in their own peculiar ways, and every DB engine has very different performance characteristics.. Code that runs fast against SQLite might be slow in Postgres or MySQL.
Again... I'm just blown away by the assumption in this thread that one does unit testing OR integration testing, rather than both. OF COURSE you run integration tests against the same database type as production before deploying. However, you'll *also* typically have a suite of more low-level unit tests... which you'll run 1,000 times a day on your local laptop, and which will run on a CI server that ideally doesn't a database instance running on it. You certainly can have your unit tests abstract away the database. Just write a separate data-access layer for testing, which stores and retrieves entities from in-memory `map`'s or something. However, if you have access to a true SQL in-memory database, then it's one less piece of test scaffolding that you have to write. Even if its SQL dialect and behavior is different (e.g. SQLite), then at least there's hopefully *less* you'll have to write in your scaffolding layer. I'm a bit spoiled by Java, which has H2... an embedded database that's capable of emulating the behavior of MySQL, PostgreSQL, Oracle, etc. So unit testing your data layer is nearly trivial. I'm gathering that Go doesn't currently have anything like this, and I am starting to agree that SQLite doesn't really fit this niche. Its SQL dialect and dynamic typing are weird, and it requires that you have a C compiler to build any of the Go drivers. So apparently, the options at this point in time are: 1. Abstract away the database layer, by writing some test scaffolding that stores and retrieves records from in-memory `map`'s, or 2. Don't unit test. Just run integration tests against the target DB. 3. Go nuts with Docker... which is still kinda integration testing since now you need Docker available on the CI server. I'll probably go with #1. It sounds like most of the people in this thread are in the #2 camp. You certainly can make a case for that approach, but it isn't unit testing. 
I once had an afternoon of pain writing shell scripts when I naively assumed/misremembered that the exit status of 'find' would be the number of files found. Nope. Gotta look up these things.
I'm blown away by you somehow inferring a one or other approach from what I said.... My point was just to be careful. If you develop against SQLite locally you're getting different behaviour and performance from your development target. I'm not sure quite why you're jumping to docker there. It's ridiculously simple to run a local instance of postgres or mysql to develop against, no need to involve docker in the mix.
That's exactly why I don't understand your claim that you need to hit the database. Clearly I can check the cryptographic signature on the token, check the signed timestamp within the token, and compare that to the current clock to determine validity, all without needing to touch the database at all. In fact, I can build a system of expiring login tokens without needing to even have a database or any kind of persistent storage at all.
The very need of me having to ask what's the best way to handle vendoring and dependencies is proof of the fragmentation you mention. Rust is the only language that I saw being shipped with a package manager, cargo. Besides Rust, I think this fragmentation is only natural given how relatively young go is. But after reading your comment, something that I now find very, very curious is that go is opinionated enough to have shipped gofmt with the language tooling, which got rid of silly debates and made people more productive, yet it didn't do the same for vendoring (and I leave library dependencies out of question here) on 1.6 (when it stopped being an experiment). Wouldn't having a vendoring tool to fetch and flatten the dependency tree coming from the go team have the same benefit as gofmt? 1.7 could be a great opportunity to think about this. But if it is too late now, maybe a 1.8 goal. Anyways, I'll pick a vendoring tool and move on with my project.
I didn't know net/websocket was in that bad of a state, but I've been reading more about it and it seems to be the case. I would have expected a dependency maintained by google be more trustworthy. Thanks for the headsup, I'll definitely replace it.
[Holt Winters](https://docs.influxdata.com/influxdb/v1.0/query_language/functions/#holt-winters) is implemented in Influxdb in Go. Not sure about the triple smoothing part.
good way to think of it - there is only one success case but many reasons for an error....so unix-y systems use 0 as a default success valueto easily discriminate
`go version` go version go1.6.1 gccgo (GCC) 6.1.1 20160602 linux/amd64 Installed `gcc-go` from Arch's 'core' repo, and it's not aliased. **edit**: I also installed `go` from Arch's 'community' repo and it's the same story.
Till now, vendoring is the community's accepted way to manage dependencies. That said you should approach it like this: * Vendor things by hand first to see how the whole thing works. * Get tired of vendoring by hand. * Do the job easier with one of the [tools](https://github.com/golang/go/wiki/PackageManagementTools). * Profit.
Personal opinion/recommendation: Use the simplest tool possible for the job. The ones I've tried and liked are [govendor](https://github.com/kardianos/govendor) and [gvt](https://github.com/FiloSottile/gvt) with gvt being the one I am using. Avoid glide.
1. -- 2. -- 3. -- 4. Don't test state in unit tests, test behavior. If you call gorm with the correct parameters, you're good -- so long as your integration tests work as well. Testing that the DB stores and retrieves items properly is not the best way to write unit tests...
Hm. Does it show correctly when you run this? env GOPATH=/home/killallnarcissists/src/go go env | grep GOPATH
"How can I make my code faster?" is missing a couple common good checks: 1. Buffer your I/O 2. Allocate less (reuse buffer/var/use pool) 3. Adjust your parallelism granularity (make you are too fine or too course grained)
&gt; Gin has a session middleware that use cookies like Rails. It's just a wrapper around Gorilla sessions, which also pulls in Gorilla context, which is annoying since Gin already has its own solution for the request-context problem. So even "not a framework" frameworks end up bloated in the end.
&gt; github.com/skelterjohn/wgo Looks very interesting, I'll try it out.
I think I'm on step 3 now. There is also a hidden step somewhere around 3: * Write a vendoring tool that suits your needs/matches your interpretation of the problem :D
I've developed applications in both Clojure and Go at my company, with most new development in Go. Reasons for moving toward Go: * Native compiled binaries makes deployment a breeze. Using docker with the JVM and some JARs isn't painful, but it's annoying enough for Go to score some points here. * Much lower memory requirements. Clojure is a beast with memory, and more memory means more money to spend. One of our most heavily-used services tops out at about 100MB of memory, whereas the Clojure equivalent *starts* at about 350MB of memory and tops out a little short of a gig. * REPL startup time is terrible. This has spurred a movement within the Clojure community to architect applications in a REPL-friendly manner, instead of trying to model your problem domain. So what should have been simple is now a woven (or *complected* in Hickey-speak) blanket of Components and Dependencies. Whereas with Go I can just use something like `gin` and my app is recompiled *on the fly* and it's actually fast. * Too much Java interop. Java is ugly and it seems you can't write a non-trivial Clojure app without Java-isms infecting your code. Things we miss: * Leiningen is awesome * Lisps are awesome * Immutability is awesome. Code is simpler to reason about. * Ring is a phenomenal library, and every web framework supports it. Seeing stuff like [this](https://github.com/xyproto/permissions2) (look at the examples) means things are only going to get worse in the Go community. There are a hundred routers/frameworks and each one manages to be completely incompatible with the rest. Clojure has no shortage of exceptionally high quality libraries, and solutions written in Clojure seem to be smaller, simpler, and easier to understand. However Clojure brings with it the JVM, along with all its problems and annoyances. If Clojure targeted a runtime that wasn't incredibly bloated, slow, and painful, then we'd still be using it.
You can use a barrier method pretty easily with lbfgs. We're working on constrained optimization, but it's a lot of work.
Ask on gonum dev if you'd like clearer help!
To elaborate on /u/skidooer's answer: Launch returns the error `fork/exec echo "hello world": no such file or directory`. This is because you're passing `echo "hello world"` as the `Path` field to the exec.Command. The exec package expects that to be the path to an *executable*, not including any arguments to the executable. To fix this, you'll have to pass arguments separately as the Args field. See: [exec.Cmd](https://golang.org/pkg/os/exec/#Cmd). Now more general comments: - It is probably more useful to make Launch take arguments as a separate parameter. You can see in the Cmd struct docs above that the intended way to use it is to call `exec.Command`, passing both the path and args. You can then set fields on the returned value if you need to customize things. - It may just be a prototype, but in this example you're passing a bytes.Buffer as both stdout and stderr. If all you want is to get both output streams as a byte buffer, you can use [`Cmd.CombinedOutput`](https://golang.org/pkg/os/exec/#Cmd.CombinedOutput). This will start the program as well as collect the output for you. - In general, it's unusual to use channels in the way you are doing here. Typically, if a function starts a go routine and wants to communicate about its status later, it will create it's own channel internally and return it. In your case specifically, it would not be clear to me that Launch closes the channel passed as the second argument. However, if Launch creates the channel, then Launch is the "owner" so to speak, and I would expect it to close the channel at some point in the future. I hope you found this useful. Here is a sample of how I might change this code as it is now (without knowing what the long term plan is). [ports.go](https://play.golang.org/p/QgeOW8Dl2T), [ports_test.go](https://play.golang.org/p/IqAGnNFCFU)
Is it really necessary to use a framework with special DSL to write microservices in Go?
[(heavy breathing)](https://imgflip.com/i/16yp0r)
Yup! It's incredibly useful to have individuals who are able to spend the time to really dig down into tools flamegraphs, perf, pprof, etc. and also to advocate for a language.
https://en.wikipedia.org/wiki/Barrier_function
Very cool read. (I didn't even know that Twitch had so much Go behind the scenes.)
Why those guys just did not use something else like Rust, Swift or C++?
Well, apart from the obvious (productivity matters when choosing a language) one hint might be "1,500,000 goroutines per process". Rust, Swift or C++ (and, btw, really? C++? In 2016?) might not have a GC, but they have their own sets of problems.
Please don't give this as an advice to anyone. It's not what idiomatic means nor it will ever be. I can write horrible code that passes the above criteria.
Also, GOA gives you automatic swagger specification for your API to document and auto-generate clients. Try doing that with the standard library, I dare you.
This is a good question, and not one you should be being down-voted for, as it can give some people insight into pros / cons of the language for some specific use-cases. It does seem to make sense when you consider what they migrated from - the development team would likely be able to pick up Go easier than languages like C++ or Rust. And, as has been said, Go hit 1.0 before any of those other languages. I'm also not entirely sure what the job market is like for Rust / Swift right now.
[When is it the best time to do a GC](http://imgur.com/LozAZBh)
Hmmmmm while `context` is great I am not sure how I feel about it being littered all over function signatures. Could you instead take a leaf out of Go 1.7's book - https://tip.golang.org/doc/go1.7#net_http - and implement `Context()`, `WithContext(context.Context)` to shallow copy your client with your desired deadlines and whatever else? That way, you can opt-in to the full benefit of `context` without stinking up all your function calls. That's the approach I'll be taking, the next time I need to write a client library.
Let the caller handle this. Just block and if that's a problem for the caller, he will goroutine it himself.
Absolutely. But he has a good point about looking at go's own tools sources. I somehow missed that. Thanks! 
The article states "Go client library best practices"...best is said here. Best means proven to be best but who validated this. One person, the author of the article. I was duped I started reading it to think I was going to learn something to apply to my golang code base. The fact that one line can go beyond the standard 80 column length like FOREVER....let's say 360 columns if we follow this author's pattern, then off-the-shelf it makes this author's code un-printable and thus unreadable and by default unmaintainable in the long-term. The further aggravate the situation, I prefer not to depend on the compiler too much to parse through many lines to complete one statement. In other words, I'm not a big fan of lambda functions embedded within lambda functions embedded within lambda functions. To further strengthen my point, let's say two developers are talking about something not working, then what lambda function contains the bug? Where there is a bug in one of your lines of code and your line of code is 400 columns wide, then me-oh-my interpreting where exactly that bug is in that line of code is going to be fun. To maintain code in the long-term say 20 to 30 years from now, and your eyes can no longer clearly see, your technique will fall apart because none of your screens will be large enough with large enough fonts for you to read that one line completely without using a magnifying glass. I strongly suggest you reconsider: -keep your lines short -typing your functions with names -keep your function signatures short. For example 3 to 4 variables long and the strong pattern of returning a few variables and the error being essentially the last one of the returning variables. If your function belongs to a duck type, then it reduces down to zero or 1 incoming, and two returning(sometype, error). For long-term maintenance, this is best. -variadic functions are cool. They do have their place, but use them sparingly for clarity and long-term maintenance's sake. If you want to test smash a stack, start at a variadic function. -separate the different function implementations. Don't nest/embed five function implementations within each other within one function. cyclomatic complexity measures should be re-written to not only count "if" levels, but also "func" levels because when the author wrote this, lambda/anonymous/nested functions were not trendy as they are now. The greatest projects have more than one coder in them and the long-term success of projects depends on your ability to bequeath it to others and have them quickly understand them and quickly debug them. Quickly debugging won't happen with mult-level nested functions that are 800 columns wide per line of code. 
thank you for all your non-constructive comments folks! To address your concerns: - still learning Go, so please suggest a better way to learn since implementing data type seems not enough for you - I know Go does not have generics, although someone is trying to implement them so you can say I was a precursor (https://github.com/golang/proposal/blob/master/design/15292-generics.md) - a slice is an array, but you access it by reference instead of position, a Map in my implemetation is not the builtin map(), cause it was required not to use builtins; what are your suggestions to improve the code?
Though I still need to choose a way for the long running process to communicate back a result if it is run asynchronously, right? Like, if I had a signature of: func TimeConsumingTask() TaskResult then I call it as: go TimeConsumingTask() then how do I get the return value?
&gt; Why should they? Well given the context of the discussion, so that 8 man-months could have been spent on something actually productive. &gt; What problems of theirs does any of those languages solve better than Go - especially considering the fact that they came from Python? Good point. I don't know Swift, but Rust is definitely more complex of a language than both Go or of course Python. C++ doesn't even solve security for you like Rust does. I don't think even Swift does that. &gt; What was the state of Rust in 2013? This was written in 2013? Yeah Rust definitely wasn't a choice for production back then.
Gotcha, that actually makes a lot of sense. I'm still new to Go :)
Look at tests: the abstract implementation does not need to define the function which is passed as param, it gets defined into the actual implementation
If you need to further process the result from the task, just embed that in the goroutine as well: go func() { res := TimeConsumingTask() handleResult(res) }() If the caller needs to coordinate further processing outside the goroutine, they can use wait groups and channels to take care of timing and pass the result around. 
Thanks! Dry looks great, btw 
I would only use one result channel for errors and success, where I don't necessarily care whether it's from the caller or the called. However I would also add one cancellation channel as an input parameter, that the caller can also in order to signal to the long running task that the result is no longer necessary. The long running task can then select {} between this cancellation channel and the result channel for delivering the result and thereby won't deadlock if there is no reader. If the result is not a resource that anybody has to care about using only a buffered return channel instead of providing cancellation would also be an option. But it would use more resources if you often start those long running operations and at a later point of time decide that you don't need them anymore and just ignore the result (leaving the tasks further running) instead of canceling them.
You might want to read this: https://blog.golang.org/context Good information regarding context, cancellation, etc.
I would consider working with the runtime team for go to make GC improvements a very good use of time. They tanked some pain up front but improved the whole ecosystem by doing so (thanks.. twitch chat?). I would also assume some not so senior engineers got their feet wet with profiling, legitimate performance tuning, and probably a lot more neckbeardy kernel shit than they ever knew existed. This is of course assuming it wasn't one engineering doing all of this. However, rationally, yes - another language could have better solved with less trouble. Good on twitch for sounding like a cool engineering org.
&gt; Well given the context of the discussion, so that 8 man-months could have been spent on something actually productive. What evidence is there that these other languages would have been more productive than Go? In my experience with Rust and C++, you end up paying a lot in development costs because of inferior tooling, manual memory management, poor concurrency stories, etc. I see no reason to believe that these languages would be a silver bullet, and this isn't even taking into consideration the cost of porting all of the acceptably-performant Go code over to the new language.
&gt; I would consider working with the runtime team for go to make GC improvements a very good use of time. Well Rust doesn't have a runtime or GC. It's a bit lower-level than Go tho, so you could still lose overall.
As someone who writes C++ every day, I can tell you that the DIY factor multiplies significantly when you're writing C++ code. That translates into a much larger potential for bugs, because the work required to produce standards compliant code is that much more. This is important because most networking standards rely on the correct implementation of other standards to work. Go's standard library is extremely strong from a networking perspective if you're looking for RFC compliant code. The other thing with C++ is build time. With networking code, you'd be foolish not to use something like BOOST, but you pay for the convenience in terms of iteration speed on your product. For a web based company I can very easily see reduced iteration speed being a deal breaker. Lastly, you have the nature of web requests themselves - each HTTP request is independent and therefore can (and should) be handled concurrently. While C++ can do this, it is an area where it is very easy to make a mistake because the syntax of C++ doesn't lend itself well to describing the intent behind concurrent code and inferring overall concurrency structure. Again, this is an area where Go with its concurrency support based on Hoare's paper - Communicating Sequential Processes shines - it is comparatively easy to infer the intended concurrency design from Go code and more importantly, it is much easier to get it right to begin with.
traebien
traebien
It's quite likely that this is something they periodically revisited over those 8 months, as opposed to constantly working on it.
Is it not possible to disable GC entirely (using GOGC=off)?
goa uses pointers because it makes it easy to determine if you're given an empty string vs a zero value. "" is different from an unitialized (and un provided) string, so a pointer will let you determine whether you were provided that field, or whether it came empty. To fix your problem, declare your strings before your struct. See this simple example: https://play.golang.org/p/UynBuUKaEM goa is doing the right thing here by protecting you from deserialization problems with Go and zero values. 
Nice job! I'd suggest writing some tests. https://golang.org/pkg/testing will help with that. I'd also suggest looking at the lint warnings; learn to conform to godoc specifications. Here are the lint warnings: https://goreportcard.com/report/github.com/Gelembjuk/articletext [These error handling lines](https://github.com/Gelembjuk/articletext/blob/2023e034759d51e7466c18a80eaf40146aedd81b/articletext.go#L48-L49) should lose the log.Fatal, which terminates the program.
Congrats on the release. We're using Traefik as an ingress controller for Kubernetes. Traefik's docs need some work, but the software itself has worked for us quite well so far.
Ah and the "bytes" value is the number of bytes encoded by the application encoder before any higher level processing (such as compression).
Thank you.
Thank you very much!
Thanks for the help!
My company (liftoff.io) used to be more-or-less Clojure-only, and now we use Go for servers where performance matters (as well as many internal tools). I even wrote [a Clojure parser and code formatter in Go](https://github.com/cespare/goclj) so that I could write cljfmt :)
Any relation to https://github.com/go-chat-bot/bot?
And why is this?
Get over yourself.
Sublime is garbage. It's all about Atom these days.
Also how does it compare to competitors? vulcand? 
Nice and clean. I do similar things but great to see this wrapped up.
I would have to agree, while the JVM isn't a lightweight, it's the clojure core namespace, lein, nrepl and associated toolchain that are grotesquely obese.
Interesting, will look into it.
Yes.
Fixing Revel's quirks? You're probably talking about [Mars](https://github.com/roblillack/mars).
 var numbers []int is a little more idiomatic (and a little more efficient) than numbers := make([]int, 0) AFAIK, some linters complain about the latter.
You do understand that you do disservice to Rust and Rust community as whole with posts like this? Before saying Rust is fast - look here https://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=go&amp;lang2=rust Rust is faster on _linear_ code, but it's not faster with _allocation dependent_ code. That means that if you have some complex "math" functions you do get the benefits from the language design and LLVM optimizer. But when it comes to handling concurrent connections and lot's of allocating to heap (Box and Vec says Hi!) Jemalloc is not as fast as GC enabled languages. Getting pages from heap (and from OS) and returning them is not free. You could use custom allocating strategies, but writing proper custom allocator is entirely different problem. And then you have to be very careful with it. Rust has thread system but doesn't have builtin "lightweight" async primitives. That means coroutines or goroutines. I know about coio-rs and likes - they are not pleasant to work with. And if you start spawning thread on each incoming connection - welcome to 10k problem. You don't have enough memory to handle 1.5*10^6 connections. There is also learning curve and ecosystem immaturity. Not everyone wants to spend their time learning new language each week or writing proper HTTP library (which is hard - look at the spec).
&gt; Rust solves concurrency That's a lie. Rust "solves" race condition problem's by defining strict owning mechanics. It does't solves a problem handling 10k+ connections. You are welcome to prove me wrong - spawn 100k threads simultaneously and look at occupied memory.
Question: Doesn't this educate copy 'n paste programmers who do not understand the background (at all)? Is this a good movement if we use it like this? On the other hand I'm sure its good to learn if used correctly. Thanks for your opinion =)
Yes, because serious text editor must be written in HTML, JS and CSS these days.
Irrelevant. Sublime Text was made poorly in comparison to Atom. I used Sublime for over 5 years, I don't miss it. 
Right, it solves a different set of problems. However green threads can just be implemented in a library, they're not an exclusive Go features and other languages have had them a long time. Haven't used Rust for stuff like this, so I don't know whether it actually has them, but that's not the point.
It's a new language beating half of those benchmarks, I don't see a problem. And never did I say it was faster than Go. &gt; But when it comes to handling concurrent connections and lot's of allocating to heap (Box and Vec says Hi!) Jemalloc is not as fast as GC enabled languages. OK, I didn't know this &gt; Rust has thread system but doesn't have builtin "lightweight" async primitives. Again, it's a new language. There is nothing magical about Go, and Rust can solve this issue with a library easily. &gt; There is also learning curve and ecosystem immaturity. Yep true &gt; Not everyone wants to spend their time learning new language each week or writing proper HTTP library (which is hard - look at the spec). I genuinely believe Rust is not yet another random language. It's leaps beyond everything else.
Are you just repeating something you've heard? Or do you have anything to back up that statement?
Google it. There's tonnes of articles about why angular is a steaming pile of shit.
I hope you realize that there are plenty of articles that claim every framework and programming language are a steaming pile of shit.... OP made a statement and was unable to speak on the specifics of why he felt that way... Have you ever heard of the term "the right tool for the job"? Angular is an excellent tool, I'd love to see why YOU pterfer not to use it rather than "Google it you'll see how shitty it is" 
&gt; However green threads can just be implemented in a library That's doesn't work well. As you said - green threads are not exclusive to Go. Hell - even C has them as lib. But when you start to integrate them in your code, that's the moment when you realize that without other things (firstly IO, then scheduling then everything else) you didn't solve anything by introducing another lib. You could achieve almost everything by writing you own event mechanism around epoll\kpoll. But then came a complexity... Writing abstraction is not hard. Writing proper abstraction is. Go developers spent enormous amount of time in goroutine scheduling and proper writing proper IO/network/communicating abstractions so that user code works fast and properly and don't eat up all you available memory. And there are still issues. Even with all experience they have. You propose to shift this job from compiler devs to twitch devs. I'm not seeing any upsides here.
What do you use for your front end framework? It's all in how you use it... many of the problems some complain about I haven't run into because I design my application properly. There are some quirks as there are with anything that's opinionated, but if you understand them and why they happen you can easily work around them. People just tend to miss use angularJS features which make it combersome and slow... but if you take the time it works wonderfully.... especially if you're working on a project with a limited team, having everything built into and supported by angular is really nice.
What about a map[string][]float64? https://play.golang.org/p/BKTpIc6REZ Or if the number is fixed-sized https://play.golang.org/p/FUrv_7uxtY
It never dawned on me, not even for a second, to use structs :)
Unfortunately that vocal minority is inspired by the Go Core contributors [[1]] [[2]]. Here is how it works: 1. Someone reads a tweet of a Go contributor. 2. He/she adds religiousness and makes the point of the tweet more radical. 3. He/she prepares pitchforks and goes to the masses to fight those who're using the language "wrong". [1]: https://twitter.com/davecheney/status/524725761396064256 [2]: https://twitter.com/bradfitz/status/430247880184852480
I'm looking to display text with the file size next to the file name
A little over-engineering never killed nobody: Expressive structs: https://play.golang.org/p/Ph-GQLG7CR and less over-engineered, and still expressive: https://play.golang.org/p/HNwfpilUws
Because the GC pause times are a factor of the heap size. Splitting across multiple processes allow for smaller heaps and thus shorted pause times. Now that the GC pauses are short even with all users, it doesn't make sense to split anymore
A good way to have a quick check on your code is to use go report card: https://goreportcard.com/report/github.com/Gelembjuk/articletext Better: Use golint or better gometalinter everytime before you commit new code. Handle errors gracefully. You are using `log.Fatal` in most error conditions, which will exit the program immediately, instead of returning the error.
I find it best to learn from examples so this is perfect from me 
I assume that the number of days on the market will be a monotonically increasing integer with a fairly small upper bound, and that values won't be sparse, so you might as well just use an array of floats rather than a map. And unless the list of categories needs to be arbitrarily extensible at run time, I'd use consts for those rather than have to do O(n) string comparisons or use a map for every lookup. Of course, you should have a lookup function rather than allowing direct access, so that you can change the implementation later, and can check for bounds errors. For example, if you do need an arbitrarily extensible dataset, you could move the data into a relational database and still provide the same Weight API function. So my (probably overengineered) possible solution: https://play.golang.org/p/Mii12TrV4b 
Thanks for pointing that out. Makes perfect sense.
Context: Coming from dynamically typed languages with *de facto* package managers (Ruby, Python, JS), thinking more professionally about my dependencies is a new discipline for me to exercise. Instead of thinking how to bring libraries into my codebase from the very start, I only thought about dependency management when the package manager blew up. Thanks for the comments, I'm learning a ton. I should always check the source code to see if it is good quality (same for my dependencies's dependencies) before deciding to bring it to my codebase. ANSWER: Yes! It is a contrived example!
EDIT: Nvm, xxhash is not crypto secure, this is. Sorry for not really searching for what Blake2 does. Is it faster than xxhash which can do quite some numbers: - https://github.com/Cyan4973/xxHash - https://github.com/OneOfOne/xxhash (go impl)
This! However I'd add another level. Consider just starting with [net/http](https://golang.org/pkg/net/http/) (the stdlib package) and add things if you find something additional you need. [gorilla toolkit](http://www.gorillatoolkit.org/) is a popular place to reach but consider other options as well.
Not necessarily contrived but you'd have a problem regardless of vendoring. If you use two libraries that each depend on different versions of the same library, how do you expect to resolve that? But vendoring provides a solution because it namespaces each library. The solution is that libraries that vendor dependencies _should not_ expose those dependencies through their library. If they are exposed, it must be made clear that those references are not in any way related to the same library imported elsewhere.
... I mean I get what you're saying but it's not applicable to what you quoted.
In this case, "in pure Go" meaning amd64 asm.
The AVX optimized, cgo-dependent library mentioned in the README is https://github.com/codahale/blake2 and benchmarks here at ``` BenchmarkBlake2B-12 1000 2174036 ns/op 482.32 MB/s 994 B/op 4 allocs/op ``` This one gets ``` BenchmarkComparisonBlake2B-12 1000 1405786 ns/op 745.90 MB/s 514 B/op 2 allocs/op ``` So that's a 1.55x speedup, with fewer allocations. And it's crosscompile-friendly. Yay! This is on an i7-3930K (avx, no avx2). Yes I read the benchmark source, they are identical.
You are welcome! 
Thanks for the issue :-)
yes! you are right. 
I want to move towards a compiled, statically and strongly typed language to write web APIs, websites, and dev tools for my workflows. The language itself is 99% clear and easy to grasp. The difficulty so far lies in how to use go's tooling (mainly vendoring, but also guru) and how to properly make [good use of the language](https://go-proverbs.github.io). I'm reading [The Go Programming Language](http://www.gopl.io) at the moment, which is getting me fascinated by the language. I like researching a programming language a lot before writing anything big. But I guess I should stop beating around the bush and write more than I read.
I wonder if it can handle rewriting URLs in JS/CSS?
22 lines of code per year you averaged. 
you can say that, but simple google searches for golang do not pull up any resources on the fastest non-crypto hashing solution that doesn't have collision problems. every crc32 I tried either collided or was slower than md5. this is the first I'm hearing about xxhash in this thread and I plan on using that.
Thanks for the comparison, great to know. And the benchmarks are the same indeed.
As per https://blake2.net/ you can see that the 32-bit version of BLAKE2 (BLAKE2s) is somewhat slower than the 64-bit BLAKE2b as implemented in minio/blake2b-simd. However it should beat SHA256 by quite a margin. Also see here for a comparison (for golang, and blake2b): https://github.com/minio/blake2b-simd/#avx2-comparison-to-other-hashing-techniques
Ohhh my bad, I didn't realize Blake2 was actually a hashing algorithm, I thought BLAKE2 was the name of a hashing library haha. Makes sense now.
The flags thing is actually one of the reasons hugot isn't really speaking to me (the other being the license, more of an Apache/MIT fan myself). I'm looking for a more natural conversation style for what I'm building. go-chat-bot is close to what I want in several aspects, but I don't like its un-idiomatic style, which I have partially replaced with something that actually looks a bit like hugot or Caddy. I rolled my own Context though with a somewhat different semantic. In hindsight that might not be a good idea.
For pure Go, https://github.com/dgryski/go-metro is fast Other than that, you'd need a translation of https://github.com/lemire/clhash
xxhash has same collision problems as Murmur3
Hugot does have regex 'hears' handlers that you can bbe used like in hubot. Can't help with the licence thing though ;) could look at dual licence options, but that all more complicated than i can be bothered with.
Thank you! 
yes: rm -r $GOPATH/bin $GOPATH/pkg
Collided almost immediately for me
TIL Scala with Akka is poor man's Erlang.
To be fair, `Future` is a much easier concept than an actor based system and I've used it in Scala with great success. But Akka gives you *a lot* of stuff for free. 
I haven't done any straight `Future` programming, so my experience with Scala is purely based around Akka... in fact my team has this hatred for `Future`. I'm not entirely sure I understand the reasoning behind that unfortunately. I'll be sure to try writing concurrent programs with straight `Future`s at some point!
No
Not needed
 val getThing1 = Future { slow() } val getThing2 = Future { slow2() } val superThing = { thing &lt;- getThing1 thing2 &lt;- getThing2 wooHoo &lt;- WOOT(thing, thing2) } yield (wooHoo) Hope that helps :p 
Go was born (as an internal project) in 2007. So /u/tucnak has to be Commander Pike's secret secondary account :D
Hi Jeff, Welcome to Go! I hope my comment is not in poor taste, but here's my feedback: * I wouldn't use a library like this. I've written convenience functions like this many times, and don't see a reason to import an external dependency just to wrap an http.ResponseWriter. *"A little copying is better than a little dependency."* https://www.youtube.com/watch?v=yi5A3cK1LNA There's little point in calling to an external library when you can just do `w.Write([]byte("some response"))` I ran across this when looking at the gin framework the other day. ``` c.JSON(200, gin.H{ "status": "posted", "message": message, "nick": nick, }) ``` So I looked up to see what this mysterious `H` type is. https://godoc.org/github.com/gin-gonic/gin#H Turns out it's just `map[string]interface{}`. There's a certain level of functionality that external libraries provide over standard library functions/types but whenever we import one, there's a cost associated with it, and many times that cost is not justified. * https://github.com/jeffbmartinez/respond/blob/master/respond.go#L47 the json function would be more useful if it used `json.MarshalIndent`. If you want to marshal without indenting, the more idiomatic way to do that is to use json.NewEncoder: ``` if err := json.NewEncoder(w).Encode(myType); err != nil { // handle err }``` Because `http.ResponseWriter` is an `io.Writer` and json.NewEncoder accepts the io.Writer, there's no need to `json.Marshal` first. https://www.datadoghq.com/blog/crossing-streams-love-letter-gos-io-reader/
Haskell's "Great Good" tutorial is a weak copy of the wondeful Ruby tutorial by "why the lucky stiff". No need to copy a copy for Go.
Previous to last. This is a good example: respond.JSON(w, http.StatusOK, map[string]interface{}{ "status": "posted", "message": message, "nick": nick, }) 
I started using [Echo](https://github.com/labstack/echo) recently and it is really great too. I also love Gin, specially its route grouping feature. I wish Echo had it.
[Release Notes DRAFT](https://tip.golang.org/doc/go1.7). Things that stood out to me: - net/context is joining the standard libs as "context" - http.Request now has an embedded context - reflect can construct new struct types at runtime with StructOf - Solid improvements to generated code on x86-64 - compress/flate performance is much better (&gt;2x) - Lots of other small (to me) things
so what is needed? i've tried "go build -a" in the past and still ended up having to delete $GOPATH//pkg cause my build kept rebuilding existing packages
is there any generalized or well known way to do these things?
Hi there, Starting with paper is a really good advice. I would even go further and not only draw up the architecture, but draw a context diagram (who is interacting with your system and what are their intentions) and draw a flow-chart of your pages (what pages will the application have, who has access to which page, what is the main purpose of the page - we use shapes from uxkits.com for this). Ideally you would also collect something called user stories. The purpose of this is to gain an understanding of what certain users would want to achieve on your website. i.e. "As a designer I would like to see a list of all job offerings in my area, so I can apply for a job and increase my earnings". The most important part of this is the reasoning. Collecting the reasons will often lead to ideas of how to find an even better solution to the problems at hand. The next step would be to draw some basic mockups of all the pages. Once you have done all this, you will have a fairly good understanding of your sites structure and functionality and can start with the coding. My advice would be to clearly separate your backend from the frontend (i.e. we use vue.js for all frontends and are very happy with it) and fetch all data from the backend via api calls. On the backend, we tend to use the echo framework for web services, as it does provide a good balance between additional abstractions on top of the base packages while not trying to do too much. We usually put the route-definitions into separate files depending on the context (i.e. public sites, admin sites, user sites) and put the actual route handlers into separate packages. This helps to keep the boundaries between different functionalities. If the application gets really big, we split out the different modules into separate "micro-services". But this will require a more complex architecture to manage and monitor your application in production (take a look at traefik.io if you are interested in something like this). Currently we are using RethinkDB to store all data, as it is very easy to administrate and provides a cool document based storage even supporting "near real-time" change feeds out of the box. By the way, I would recommend to check out docker and start developing your application in a docker container. This will ensure it can easily ported to production systems without running into problems with configurations and such.
Scala is a poor man's Haskell.
thank you for your thorough advice. It was really informative.btw I don't have any experience with frontend frameworks . I have been just executing templates with data structs. will it be more efficient to make my site API based?and if yes where should I start?
That should help: https://www.youtube.com/watch?v=sJhhLvW-Xvg&amp;list=PLqGj3iMvMa4KeBN2krBtcO3U90_7SOl-A
thanks
Personally I have found the API based approach a lot easier for me and my team. We have a reactjs front end that runs on the client's browser, and all the actions are supported by the backend programmed in go. Say for instance we are trying to add something, on the UI side using react we make a component to provide our user with a form to enter data about this thing, its does client side validation to help the user, and when the user clicks on add, the data gets to our go server as a json. Our go server then reads this JSON file, puts the data in to a struct, we then do server side validation, yes ever everything we checked on the client side, we check them again on the server end. Then when we are happy this data is valid, we pass it to a layer in our go server that talks to our sql database and adds that information, if everything goes right we send back a message to the UI of the user, and the UI will tell our user what happened. The best thing about this approach for me as a manager is, I can allocate people to work on well defined problems. The code to our UI and server are hosted in the same repo, and thanks to this separation, its very easy for me and my team to work independently. The only problem with this approach is that, our user's browser has to download the entire UI component before they can use it. (Around 1 mb) Thanks to caching this is not a problem that happens too often.
This.
In my opinion it doesn't hurt to know what your website is doing... why... and how... I'm coming from php, mainly using symfony2 but at some point I kinda hit a wall and searched for other solutions. Go. So far I'm very pleased and at the same time angry about myself for depending on 3rd party libraries so much in my past. I missed the opportunity to learn a lot. Of course if pure productivity is required.... Go seems a bit.. Not the best choice. At the moment I'm building stuff (for example an Aerospike cache) myself for learning and boosting future productivity. 
thank you for your opinion . I am also thinking of using ROR.
hey someone just suggested me to use ruby on rails. I want to ask as I am new to web app development should I use ROR instead of Go for my first few projects to get better understanding of all these things? 
exactly @interactive it is really overwhelming and I am confused as hell. 
&gt; In this context, you wouldn't need to spend 8 months fixing and tuning GC and Go-specific problems. Rust has no GC. The presence or absence of a GC is no the sole factor in a language's productivity. In particular, had Twitch used Rust, the non-critical paths of their architecture may have taken twice as long to implement (this may not be true; I'm only pointing out that "not having a GC" is not by itself a productivity win for all applications or even necessarily this one). &gt; I'm just explaining this particular situation is what Rust excels at, and should be considered later. Yes, but Rust lags in a lot of other aspects, including many that are important for building a performant chat server (concurrency, pace of development, ecosystem maturity, etc). &gt; Um certainly not applicable to Rust. Rust solves concurrency and safety for you, fast. Rust doesn't solve concurrency; it gives you operating system threads, blocking I/O, and a Node-like approach to async IO. Rust has a ways to go before its concurrency story matures. Engineering is about making tradeoffs. Just because Rust would solve this problem well doesn't mean it wouldn't introduce a host of other problems.
1. They *can* be implemented as a library, but there are currently no stable implementations for Rust. 2. Library-level implementation is not as useful as language-level because you'll have to take care to explicitly yield, and you'll have to take care not to use any I/O which blocks (including calling into libraries which use blocking I/O). It's just never going to be as clean as Go's concurrency model (on the other hand, Go's concurrency model gives you less control, but it's the right tradeoff 99% of the time).
As a new developer I would suggest getting as far as you can without using frameworks. The reason why is that when something goes wrong, or you don't understand a framework idiom you don't have the supporting knowledge to dig into it. However this is largely biased on how my brain works and how I learn and understand things. It's personally always helped me to be a bit more reductive when it comes to programming. Abstraction is really nice and saves you a ton of time and boilerplate; it can also get you really far. It's important to understand what is being abstracted and what the constructs are.
works for my on the playground. It prints: {Preferences:[0 1 2 3] Texts:map[] Options:map[] Gender:male EMail:mail@x.com} {"preferences":[0,1,2,3],"texts":{},"options":{},"gender":"male","email":"mail@x.com"} Program exited. "
thank you, that was it!
It depends if the beginner wants to learn or stay... beginner. It's interesting to study how other languages and framework do but with the std lib of Go you have everything to do it yourself and really learn web development.
I just an FYI, I was just glancing at the code and noticed the extension function, looks like you got an OOB their perhaps in the case of a value of a single dot being passed. Also since I'm still waiting on my food and bored, I noticed you panic on a empty application name and force Init to be called, maybe it would be better to return errors in those functions since hey already return an error? Also how necessary is application name to require? Maybe have a sane default of some sort.
Yup, it's a common gotcha (even for nonbeginners) that `struct{}{}`s [always have the same address](https://play.golang.org/p/fan0tsggSa)
Very nice blog indeed. Bookmarked!
Am I missing something here? Why not just make `Greeter` an `http.Handler`? func (g *Greeter) HandleHTTP(w http.ResponseWriter, req *http.Request) { io.WriteString(w, g.Greet(req.URL.Query().Get("name"))) } func main() { http.Handle(“/”, &amp;Greeter{Format: “Hello %s”}) http.ListenAndServe(“:8080”, nil) }
Why not stop all wars and make love to each other?
Ouch. I assume that was a general commentary and not a jab :). If I am wrong or inaccurate about any of that I would love a better explanation. It would help all of us become better gophers :)
Cue the onslaught of context-abusing middleware frameworks.
Essentially, values that can only exist once you have the request. e.g. Auth tokens, user details, connection IDs. These values cannot be known or generated before and thus they are request scoped. Now contrast this with a pointer to a sql.DB struct. It's lifetime is beyond the current request as it will be used for every request and as such, it makes more sense to make it a global or something else (see http://www.alexedwards.net/blog/organising-database-access for other ways). This is just a guideline, it can change a bit. For example, the http library in 1.7 adds the server that started the handler and the local address the connection arrived on into the context because its a very simple way to allow access to those values.
What build tools are you using for your front end, if you don't mind me asking? Go seems to be lacking versus node (grunt, gulp, etc)
API gateway, references: * http://microservices.io/patterns/apigateway.html * https://www.nginx.com/blog/building-microservices-using-an-api-gateway/
General of course, small subreddits like these are great. 
Use "go install"
Strongly agree. https://twitter.com/peterbourgon/status/752022730812317696
Everyone is giving well intended advice, but I would suggest something the opposite of what they all describe. Paper, diagrams, documents, planning.. all of those things are a recipe for a large monolithic application. Don't get me wrong, careful design and architecture is important to maintain cohesion across a large set of components and systems. I'll suggest instead you write code. I'll suggest that you forget entirely about making a large web application. That shouldn't be anywhere in your mind. You should instead focus on making a set of very small web applications interact together to get the result you want. Break your problem down into separate services and create your interfaces around them. Focus on small manageable services and consume them in your web application tier. You get many many fantastic propeties from this sort of design and this a bit late for me to get into all of them but if you have questions feel free to ask I'll check back in the a.m., search Google for microservices, thats a common buzzword for this kind of design and I know I've seen at least one paper from Google on this topic. The tldr is don't get caught up in planning or design. Keep a high level vision and solve one peoblem at a time. Write small independent libraries and expose them via small independent services via simple restful APIs. Write your application tier to call these APIs. Take the time up front to write unit tests, automate your builds, deployments and rollbacks. Aiming for modern CI/CD tooling would be good but basic makefiles and some shell scripts can give a good quick ROI. Have fun. 
Fair enough - the example wasn't great. I just wanted to show how r.Context gets you the context and r.WithContext gets a new Request. In mgo, you would indeed pass a Copy of the database Session per-request. Same issue for the struct{}{}, I oversimplified and created confusion. Will update the post this morning. Thanks.
All those articles you read about angular being terrible and react is the best are most likely BS fanboy clickbate. It's comparing two very different things... In fact you can use react within angular, which I haven't had the chance of doing yet but I hear some pretty good things about that. Bottom line is Angular is a nice toolbox, and you shouldn't turn away from projects just because they use it. Also, build a small project in angular so you can make your own opinions about what you like or hate about it... that's really the only way to form a strong opinion on the topic, rather than relying on a stranger's opinion.
I'd have expected an implementation of [`bufio.SplitFunc`](https://golang.org/pkg/bufio/#SplitFunc) so that it could be used with a [`bufio.Scanner`](https://golang.org/pkg/bufio/#Scanner).
We just did this in the past week or so for https://github.com/gocraft/work -- The "webui" package exposes a JSON API, which is consumed by a React app. The React app is embedded in the binary with go-bindata. This is the commit that does it -- https://github.com/gocraft/work/commit/a2c1415609571df1b5d8a7e0e97578c05f48db99 -- you can find some notes in DEVELOPING.md as well about how to do the asset stuff.
Just setup some form of REST API and have the JS interact with that. There should be some standard way the JS expects the API to be I imagine and you just build it to those specs.
Since our front end is handled by javascript (reactjs) Go(lang) has no idea about the UI code really. Its the UI's job to talk to the back-end and do its magic. Again, separation of concerns is an important thing at work, since we have in the past have run in to several problems by not planning for this. Mainly because we started with a 1 man team ;) To answer your question, we use a slightly modified version of this (two version before the current) https://github.com/davezuko/react-redux-starter-kit To be honest changes are mainly the directory paths only, for instance, most of the ui code goes in a public directory under our go server instead of the default configured in that project. 
I'm pro-generics in Go, but how would they help with context? If `context.WithValue` and `*Context.Value` parameterized on the key and value types, how would you store the values? You'd need a map whose keys are dependent on both the type of the key and its value within that type. As far as I can see that means one of: even with generics it's `interface{} -&gt; interface{}`, runtime typing with reflect which would be more complicated but equivalent to how it is now, all keys and values can be any type as long as they're all the same type, or a dependently typed language (not that those aren't cool!). If `*http.Request` had been an interface (which I also agree with), you'd be in the same boat. You could create a request with a type safe `GetAuth` method, but you wouldn't be able to compose that with a request that had a type safe `SessionID` method without creating an onion of embedding that would need to be unwrapped in the opposite order. And you'd need to use a runtime type assertion in any case. In both cases you can achieve some level of safety by wrapping the dynamic portion. For Request is an interface you could do package withrequest //imports and stuff type With struct { //stuff } type request struct { http.Request *With } func Wrap(r http.Request, with *With) http.Request { return &amp;Request{Request: r, With: with} } func Unwrap(r http.Request) (*With, error) { req, ok := r.(*Request) if !ok { return nil, someErr } return req.With, nil } For context, package withcontext //imports and stuff type valueType int const valueKey valueType = 0 type Value struct { //stuff } func Set(r *http.Request, v *Value) *http.Request { return r.WithContext(context.WithValue(r.Context(), valueKey, v)) } func Get(r *http.Request) (*Value, error) { v, ok := r.Context().Value(valueKey) if !ok { return nil, someErr } return v, nil } (either of those could return a sane default value instead of an error, if that makes sense for the use case, though that would be dangerous in the Request is an interface example since the value might be in there somewhere and you just happened to be looking at the wrong level of the onion, which makes the context way seem saner to me) Neither of those are perfect and a bit boilerplate-y, but at least the context way doesn't depend on the order in which values are attached, which makes sharing easier. If I've missed something obvious, have some patience—I'm still metabolizing my morning coffee. I would definitely be interested in a composable type-safe solution, even if it requires hypothetical language features, but I'm not seeing anything that wouldn't require a lot of very sophisticated hypothetical features in this case. Maybe I'm looking at this from too narrow a perspective and there would be a simpler more flexible change to the definition of http.Handler itself? 
Didn't know about mmap, thanks for sharing.
If your handler needs 50 dependencies, you probably want to make it a method on a struct with the deps, or (if the deps have sane defaults) use functional options. All things are solvable without resorting to hiding dependencies in dynamic objects. 
If you don't mind using Amber or Pongo2 (or HTML) combined with Lua for server-side logic, Algernon has built-in support for JSX and caching. It's written in Go: https://github.com/xyproto/algernon/tree/master/samples/react/tutorial1 With Lua it's easier to quickly test changes to the business logic. You can call Python or Go if needed.
Thanks for the reply. We're fully on AWS, so I'm tinkering with the idea of separating the front end code into its own repo, deploying to S3 with grunt/gulp, and then using CloudFront to seam together the static assets with the API, bypassing having the server serve the files altogether. I've been curious as to how others are doing it.
Nothing. But this was not the answer to the question. OP wanted to know how to get go to take care of the backend things while js/react took care of the front end. 
Make sure you enable it so twitch saves past broadcasts in the settings else twitch won't save vods iirc. Feature was set to disabled by default to save space since newcomers would often stream and leave a lot.
TL;DR: https://golang.org/pkg/time/#pkg-constants
Can I watch training videos from 10th anywhere?
as an alternative for when you have only one key, use something like this: type contextKey struct{} var greeterKey = contextKey{}
No, you can't have struct literals as constants, so that will not compile. https://play.golang.org/p/jrViVf0hnI You can change it to a var, but there's really no difference between what you're saying and what I said, other than that you're using a more restrictive type. You can only have one value for struct{}, but there are many, many more possible ints. Again, if you're keeping context key types and values unexported, it won't matter, as you'd be writing "_FromContext" functions anyway. "type matters when comparing two interface{}" was the whole point of my comment, and example.
whoops, fixed. `struct{}`s take zero memory which is always nice, especially if you don't need multiple keys.
Clever, but why month day hour minute second year for the order?! year month day hour minute second would be oh so much easier to remember, and we could even forgive the pm.
The most readable, the second.
This looks p dope, thanks for sharing
The faster one of the first two approaches. To me, both are quite similar in terms of clarity, so speed would be the deciding factor. The last two approaches do half of the logic within the return statement - a style that I do not find particularly appealing.
Was in the market for a new/fresh look into our Resque type queue. We use go-worker at the moment, but I'm not 100% happy with some of functionality, looking forward to checking out gocraft/work :)
After a quick glance: “Forever” should come below “1 year”, not above “5 Minutes”.
Any ideas?
The second is probably the best
Er, what? This is by far the _least_ readable...
Never worked with mmap, but i'm very curious how to use mmap to implement a very big cache that dosen't have problem with GC. The big question is, if mmap is just a slice of values, how could i find anything inside it? Searching the whole slice? Doesn't seem very performatic.
Don't ignore this just because you don't write `microservices`. Yes, go-kit is a fantastic microservice framework, but it's also the best framework to write a monolithic application/webservice in. I'm an advocate for sticking to just `net/http` + a router(usually `gorilla/mux`), and I still think that if you're a beginner, or if you're prototyping a project that's the best way to write a web service. But, if you're writing something in production - use go-kit, you won't regret it. By following the service/endpoint/transport pattern that go-kit forces you into, you end up with a very clear separation of concerns in your application, and you then layer things like metrics/logging/service discovery etc later on. I'm currently building an [open source project](https://github.com/micromdm/micromdm) which is a collection of go-kit services, but they come together nicely in a single `package main` which users can download and run. On a separate note, Peter writes very clean and idiomatic Go, code and I've learned a lot just by hanging out in the go-kit channel on slack, and by reading code review comments on pull requests. 
This is an awesome idea! I had no idea you could do something like that, very clever!
Well, the implementation differs [by using a chain of key-value pairs instead of a map](https://github.com/golang/go/blob/master/src/context/context.go#L459) (Contexts come in trees), but the interface for the end user is practical the same [(`Value(key interface{}) interface{}`)](https://github.com/golang/go/blob/master/src/context/context.go#L150).
You already use selected="selected" in the &lt;option&gt; element, so it will remain the default choice even if it is not the first element.
I think the second is also the most idiomatic.
&gt; I used to think data model is the most important aspect, but I now tend to favor the applications semantics, and design the data model from that. Well, yes, how else would you come up with a good data model? Anyhow, I'd say: 1. Draw out the problem domain on paper. (Real world objects and their relationships, operations you need to perform on them.) 2. Use that to construct a database data model, assuming you need some persistent data. Decide if it's best modeled relationally or via a key/value store. Pick a database. (PostgreSQL [will work for both relational and key/value](http://stormatics.com/howto-handle-key-value-data-in-postgresql-the-hstore-contrib/) and is a good free choice.) 3. Implement a set of web services for those data objects, probably using [DAO](https://en.wikipedia.org/wiki/Data_access_object) rather than a fancy ORM since you want to understand what's actually going on. 4. Add authentication (use library middleware for this since security is tricky). 5. By this time you're probably ready to build front ends, and can decide whether to distribute your services and have the front end communicate with them via HTTP, or use Go channels, or call your API methods directly within a single binary.
The overall message is definitely right, but that last function is incompatible with any middleware framework. Depending on the complexity of your apps (if you care about using a framework or not), you may want to use things like globals (ehh), or defining handlers on structs that include your dependencies in them.
why do you think its more idiomatic?
Cool, although this is a pretty annoying thing to have to use: http.HandleFunc(newrelic.WrapHandleFunc(app, "/users", usersHandler)) Now you can't use this middleware with any middleware helper framework, as the signature is all wrong. It'd be much better if they had gone with the more standard `func(http.Handler) http.Handler` signature, with a usage like: app.Wrapper("/users")(usersHandler) Now `app.Wrapper("/users")` returns a `func(http.Handler) http.Handler`, and you can use that in things like Chi, Alice, and the like. I'm not sure why they went with that weird global function, but if they wanted to keep it, they could even make WrapHandle take an app and the pattern, and return the middleware function. The same goes for the rest of the functions in `instrumentation.go`. EDIT: This is probably a nit, but I'm not sure why the base package is so... bare. All it contains are helpers, and aliases of types in other packages (why?). And because of that type aliasing, things like the [godoc](https://github.com/newrelic/go-agent) are a little annoying to use, since all you see about the Application is "go look in api/". I haven't tried it, but I'd be wondering if editor plugins can handle finding functions on that type when it gets aliased like that. Unless there's some weird circular dependency problem this is solving, I probably would have stuck the stuff I expect people to use (i.e. the api package) in the main directory, albeit with a better package name. Though, it's probably true that most people are going to be most interested in the middleware. Anyways, I'm glad New Relic now officially supports the language. The more libraries and users the better. :)
Here're examples which make more sense than the posted one: [this](https://golang.org/ref/spec#Iota) and [this](https://github.com/golang/go/wiki/Iota#examples).
https://github.com/ardanlabs/gotraining/blob/master/courses/ultimate/README.md is the course taught for Ultimate go (the intro training course), and it was 90% reading along with code. The other 10% was Q&amp;A. 
Yes, I understand how middewares work, but that doesn't change the fact that it's incompatible with middleware libraries. For example, with Chi: r := chi.NewRouter() r.Route("/somePathWithNewRelic", func(r chi.Router) { r.Use(newrelic.WrapHandle) // nope .... } // or r.Mount("/otherPath", newrelic.WrapHandle, someRouter) // wrong signature Without the `func(http.Handler) http.Handler` signature, you can't just use it, unless you write a helper yourself to fix the library's functionality.
No. I don't believe there is much to explain in the actual program (which is hard to say with certainty, because we don't have it). I believe the invariant `len(c.wrps) == cap(c.wrps)` is very likely very natural to fulfill. I am not "going into so many words to reason about the 1 line"; if anything, I'm going into so many words to debate the readability arguments at play here. Note, for example, that the opinion that the second form is better [is similarly wordy](https://www.reddit.com/r/golang/comments/4s8yp5/which_approach_to_appending_a_slice_to_another/d5807ie). In either case, I believe the usage of `make` in this context is very much wrong and hurts readability. I also came to the conclusion, that I really don't see any reason why `c.wrps[::]` shouldn't just work after all, but that's a story for a different time.
I wrote `map[string]interface{}` because I thought it would convey things a little clearer, even though it's not totally correct. But it's raised a few eyebrows so I'll change it shortly. Thanks for the feedback.
Yes, until you have more than one handler that wants to use the database, and you either keep copying that same wrapper code for each of your handlers, or switch to something else.
I don't understand the objection. Each middleware has its own set of dependencies; making them explicit is good. If many middlewares share a similar set of dependencies, then it's very straightforward to close over that dependency state in a struct, and define the middlewares as methods, i.e. type commonState struct { db Database st Store } func (cs commonState) FooMiddleware() func(http.Handler) http.Handler { return func(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { // Access to cs.db, cs.st next.ServeHTTP(w, r) }) } } func (cs commonState) BarMiddleware(sd SpecialDependency) func(http.Handler) http.Handler { return func(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { // Access to cs.db, cs.st, •and• special dependency sd next.ServeHTTP(w, r) }) } } 
Really impressed by this - looks great.
When I said "handler", I wasn't meaning middlewares. I mean the actual, final HandlerFunc that is going to be doing the work. If I'm creating an API, it's likely that many endpoints are going to use the database in some way (or indirectly through some model, but you still need access to an instance of that, and so on). If I have a bunch of HandlerFuncs that look like: func handlerOne(w http.ResponseWriter, r *http.Request) { // want to do something with a database } func handlerTwo(w http.ResponseWriter, r *http.Request) { // want to do something different with a database } How are those handlers supposed to access that database? We've already concluded that it's a bad idea to send database handles down through contexts. The only options left are either global database handles (which means that I can only have one instance, instead of maybe more than one), or to do something like: type MyAPI struct { db Database } // some code that routes MyAPI, or even better, MyAPI is a http.Handler func (a *MyAPI) handlerOne(w http.ResponseWriter, r *http.Request) { // do something with a.db } This is similar to what you're saying in your last example, but is intended for the actual functions, and not some intervening middleware. EDIT: I think that we likely agree, but are just in a spot of differing communication. Don't take my comments as ill-intentioned. :)
That shouldn't be optimized in the parser. It's more likely to be done as a pass over the SSA representation right before code generation. As for the "where can I find info about it" part, I would have to recommend the source code directly, since I don't know of any other blog posts or tutorials on how Go does it.
I don't think there's any documentation, but SSA rules in the compiler are pretty readable. You find them in go/src/cmd/compile/internal/ssa/gen AMD64.rules and in generic.rules are the files you'll want to search for now. The rule in your example is defined here: https://github.com/golang/go/blob/master/src/cmd/compile/internal/ssa/gen/AMD64.rules#L587
Thank you, that's exactly what I was looking for!
Thanks, I'm deep diving the [SSA wikipedia page](https://en.wikipedia.org/wiki/Static_single_assignment_form), very interesting!
Go's time formatting solves the problem of taking a few seconds to Google the format string—and trades it for breaking date formats for the rest of the non-US, non-English world. For example, how do I format a date in Spanish/French/Russian/etc? Every other language: strftime("%c") Go: Oh, wait! You can't! Currently, Go doesn't have an idea of locales, so the non-English speaking world can't use dates in Go. Unless you use this: https://github.com/variadico/lctime Like Hugo might do: https://github.com/spf13/hugo/pull/2041
I made the api more restful like
Ah yes good point. I've fixed that.
How does the file sync work? Can it do an rsync similar sync? Would it be useful as a backup tool or more of a tool to keep configuration files in sync on several machines? 
&gt; Why? (Why does this behave the way it does?) Iota gets multiplied with a ridicuously large number. The product is bit-ANDed back into 64 bits (avioding overflow). The result looks like a pseudorandom sequence. The numbers added to iota and to the result seem not strictly necessary for proving the concept, this line also produces some sort of pseudo-random sequence: xConst1 X = X((iota * 0x5851F42D4C957F2D) &amp; 0xFFFFFFFFFFFFFFFF) &gt; Why? (What is the use-case?) No idea. :)
Thanks, I'll add something about it in the read me. :)
this looks really nice.
This comment got longer than I was expecting... Oops. One comment I have is about the usefulness of that `attempt uint`parameter. Personally, I would have just kept the function signature as `func() error`. Then, if you really care about knowing which attempt you're on inside the function, you can just declare a counter outside of the retry call (like you will with returns). If you don't want it, then it's not there to think about. (Another nit is that `uint` feels like a weird type. `x := 10` makes an `int`. Slice/array indicies are `int`, and `len()` returns an `int`. [I'll leave it to this somewhat old reddit thread.](https://www.reddit.com/r/golang/comments/2q5vdu/int_vs_uint/)) Another nicety would be if you could declare some list of "retryable" (retriable?) errors, then if something is truly fatal, you can get out early, rather than dealing with all of the extra retries that you "know" won't work either. (Note that the same isn't required for "okay" errors, since your attempted function can always just return `nil` instead. For example, `os.Open` can return `ErrExists`, which may not always be an error to your program.) Regarding that Dave Cheney post, you're on the right track for how you're settings things up, however you should note that in all of his examples, the functions with those options are all *creating* something. Within the scope of your library, what if I want to standardize my retry behavior, and use the same settings in multiple places? Then, I would end up with tons of calls to `retry.Retry` with the same options. However, you could instead create some sort of "retryer" (retrier?) that stores those settings, which you then call `Retry` on. If you want to keep the function in the package, you can have a default value, and call on that. This is not unlike how `net/http` has a "DefaultClient" which functions like `Get` and `Post` operate on, while still allowing you to create your own Client when you want to set it up how you like. Alternatively, a user could store a slice of those strategies, but I think it's a little less clear. Something to think about. Other than those comments, writing simple functions where you only return an error, then get the rest out just through closure-like mechanics is an awesome choice. There are some retry implementations that do functions like `func(input interface{}) (output interface{}, err error)`, which completely ruins the usefulness of static types. With this, the only thing the library ever has to worry about is running a function. The rest is up to the user. And of course, there's this: 0 == attempt || nil != err [Backwards, these comparisons are.](https://en.wikipedia.org/wiki/Yoda_conditions)
orgalorg multiplexes tar-stream containing specified files over SSH and simply untar it on the target node. It can be used for syncing files from one node to the any number of other nodes, but unlike rsync it isn't possible (at least, now) to do complex syncs like not overwriting files that are newer on the remote nodes. Basically, file upload is done by invoking: orgalorg -o ./hosts -U file1 file2 /var/files3 During that call orgalorg will ensure, that nodes from `./hosts` list will contain same set of specified files. One potential use-case, which rsync isn't seems to transparently provide, is to sync `root:root` owned files yet using non-root login. orgalorg provides privileges escalation by specifying `-x` flag, so you will login on the remote nodes by using your non-privileged account and then orgalorg will try to do required file operations using `sudo`. I found that very useful, when it's unable to do `scp localfile root@node:/var/blah` because of lack of root SSH access, but still having `sudo` on that node.
No, orgalorg ensures specified files to be in the same state as on source node. It didn't do any merge.
Any suggestions and comments on my persistent channel? It is based on the queue of https://github.com/nsqio/nsq/blob/master/nsqd/diskqueue.go and allows channels to stop and resume.
https://github.com/tucnak/telebot
Damn I would rather do `type msi map[string]interface{}` in my files than use `gin.H`
&gt; The numbers added to iota and to the result seem not strictly necessary for proving the concept I wanted to implement [LCG](https://en.wikipedia.org/wiki/Linear_congruential_generator) constants, but couldn't find out how to reference a previous constant value, so I ended up leaving it as it is now.
&gt; Why? (What is the use-case?) For learning purposes, and to make error codes look cool :)
I just started using Go ~2 weeks ago and I LOVE the defer statement! This is a great use for it!
Why use channels, then? Also, ignoring errors seems like a very bad idea.
This is cool. What is this `.rules` DSL? 
Yea, as I mentioned in [another comment](https://www.reddit.com/r/golang/comments/4sf6lh/retry_a_simple_stateless_functional_mechanism_to/d58u14x), I had actually found a few libraries that provided "retry" mechanisms. I really wasn't a fan of the interfaces of most of them, or the lack of composability and/or extensibility that most of them provided. That's why I created this lib. The `golang.org/x/time/rate` package is definitely nice, especially with it's `Context` support, but it's also a bit more opinionated in it's use case in that manner. I'd rather have immutable, composable, extensible, abilities with a simple API. Different strokes for different folks.
Yea, and that certainly works for the most basic of tasks. In fact, I often used something similar to that in many of my projects, but I realized that I had kept recreating the exponential backoff logic and was inspired to build something that was still simple to use but provided some extra power when needed. As is, the library scales from a simple call of: retry.Retry(func(attempt uint) error { return function() }) ... all the way to something like: retry.Retry( func(attempt uint) error { return function() }, strategy.Limit(5), strategy.BackoffWithJitter( backoff.BinaryExponential(10*time.Millisecond), jitter.Deviation(random, 0.5), ), ) :)
Looks good! `app.StartTransaction` is the important underlying mechanism upon which middleware/wrappers can be built. I recommend caution when using `req.URL.Path` as the transaction name: Bad requests with erroneous paths could lead to an explosion of useless transaction names.
Cool, thanks for pointers, I will check those projects out. The pattern parameter to `WrapHandle` is used as the transaction name (how requests are grouped together in New Relic). `app.StartTransaction` is the underlying mechanism upon which middleware/wrappers can be built. Here is an example (untested code): func Middleware(app newrelic.Application, transactionName string) func(http.Handler) http.Handler { return func(next http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { txn := app.StartTransaction(transactionName, w, r) defer txn.End() next.ServeHTTP(txn, r) }) } } 
Thank you!! will try this approach making separate apps and trying to put them together. 
yeah just read some ruby code . that language kind of feels ugly. maybe that's because i have spent a lot of time with Go , c , c++.
"Next generation" "Ultimate" please don't. Just don't. Talk about the actual differences, publicize the actual benefits.
link to video?
The article mentions off-hand that he thinks testify is "un-idiomatic." Any idea why? From what I've seen, it gives you good failure messages (e.g. printing expected and actual values) with way less typing.
I've sort of given up on internationalization/localization in my Go apps... the standard library isn't internationalized, and that makes the whole thing an uphill battle.
It doesn't yet. Right now it can work with the PO files directly as it parses it and load everything in memory, so it's really fast. Binary files (.MO) will be supported soon. 
I hope not! Database handles are dependencies like anything else. To keep things testable, they should be parameterized.
Hmm, alright. That's fair. The `Retry` function doesn't currently log or anything (out of scope, didn't want to opinionate the functionality towards any output generation, etc). If you need to know what number attempt that you're on, you can always pass a `strategy.Strategy` to have that log or conditionally allow/disallow the next attempt. 😀 That's why I may remove it, because the functionality provided by `strategy.Strategy` overlaps with the `attempt` parameter already.
The thing that jumps at me is that `-&gt;` and `&lt;-` will have wildly different meanings and uses, and that's surprising. 
I think restricting in the ways you mentioned wouldn't be a good idea. You might expose your own package that wraps another by using aliases, and the upstream package might also be doing the same. The users of aliases aren't necessarily in control of the things they're aliasing, limiting it to a single layer is really just going to make it significantly less useful. People can already do this as many times as they want with everything except types, so I don't see this as a big deal. 
The goal of these restrictions is to make it "less useful" (moreso "less desirable"). The proposal points to refactoring as the motivation behind such a change, so I allowing or encouraging its use elsewhere would only serve to reduce the readability of the code. The same is true of aliasing constants or functions, but that's already allowed by the `=` syntax, which is protected by the Go1 promise. Types are important here, to me, because this allows the full type functionality to be split across packages. There's nothing that restricts me from doing: type T @ L1.T func (t T) NewFunctionality() Now you're forced to read two packages (godoc/go vet/golint, too) in order to know the full functionality of a type. During refactoring I can give some leeway, but letting that escape the package's home tree is playing with fire. *Edit: &gt;expose your own package that wraps another by using aliases, and the upstream package might also be doing the same. With my restrictions, it would be impossible for the upstream package to alias anything that is already (itself) an alias. User's still can't strictly control what is aliased, but they could be confident that the alias points directly to the concrete definition.
If T is an alias of L1.T, as I understand this proposal, your func would be exactly the same as func (t L1.T) NewFunctionality() which is already forbidden.
&gt; If T is an alias of L1.T, as I understand this proposal, your func would be exactly the same as func (t L1.T) NewFunctionality() Section 5 doesn't clearly restrict this, which is part of the reason I'm so hesitant about it. If aliases are allowed to be first-class citizens, they are allowed to receive method definitions. Edit: Missed an "is"
Am I missing something or does this not actually handle the plural forms defined in the po file? I've also written a gettext package for go, but it uses MO files instead of PO and supports the Plural Forms header in your PO file: https://github.com/ojii/gettext.go
That's why Section 5 is so important. When does the package resolution force it's native restrictions? Without that decision, I'm going to read it as the worst possible scenario. 
If I make an app using gocraft/work and then cluster it (run multiple copies on different servers), I assume there will exist a reaper and requeuer for each instance. Is it a problem having multiple reapers? Or does gocraft/work use redis to coordinate one active reaper in the cluster?
ah, right. thx.
Videos from GopherCon will be out in 3-4 weeks.
Good question. Yes multiple reapers/requeuers will be running. They run periodically -- every few seconds. As long as there aren't "too many", it's not a problem at all -- operations are atomic so they don't step on each others toes, and more than one can requeue things faster. Depending on how many servers you have, we'd need to tweak the design of this. If you have 1000's of servers, that's probably too much reaping. I have ideas on how to do this better, but since I don't have 1000's of servers, I haven't prioritized it. How many servers do you have?
Boom, that's the one
Ha, I believe that I had seen this one in passing when trying to find one originally. Great to see that you used the "Strategy" name here too, it just fits. In fact, it's crazy how similar some parts of our libs are, even the functional returns and signatures are somewhat similar. Crazy. `aqwari.net/retry` looks nice, and definitely does a good job of not requiring to "surrender control", but it's a bit more limited. I love it's simplicity though. I really strove for the same goal of simplicity in `github.com/Rican7/retry`.
I thought https://godoc.org/golang.org/x/text is already the definitive package on this.
Hi, in user struct use School *School Cause right now your model reflects DB structure but you can map that with an ORM later.
Great slides and all that, but is the guiding talk online somewhere? I'd like to have some elaboration on some subjects.
Why not giving nested structs a try? https://talks.golang.org/2012/10things.slide#4 type User struct { Id int64 Firstname string Lastname string School struct { Id int64 Name string Address string } }
What do you mean? Just curious, never tried to i18n-ize a Go app, but I'm pretty familiar with gettext in general. Doesn't the std lib operate on strings/messages you pass to it?
How could it make the difference between a var assignment and a a var aliasing? It's impossible to determine it and I bet it would be impossible to determine by humans as well when reading the code.
Something like `alias identifier = otherpackage.identifier` should work for all cases I think. And the compiler can deduce if it's an alias to a function, variable or type. Question would be it is necessary to repeat the type in the new package to aid the programmer or not.
`present` doesn't work so well on mobile 
What's wrong with large interfaces? Also what is wrong with returning interfaces? I thought that was the way to go, lots of stdlib packages do it?
https://play.golang.org/p/kjruIR6b59 Only 8 bytes per string and 12 bytes per struct.
Nothing. He is arguing against returning interfaces *just to hide an unexported struct*.
They said 2-3 weeks for the talk to be online.
Please reread the [documentation of Sizeof](https://golang.org/pkg/unsafe/#Sizeof); you strings clearly take much more than 8 bytes: https://play.golang.org/p/Q-uo2tbqoB 
Yes, it does handles the plural forms defined in the PO file and also the context (msgctxt) as you can see on the test code: https://github.com/leonelquinteros/gotext/blob/master/po_test.go
I think this is just general fallout from http://www.jtolds.com/writing/2016/03/go-channels-are-bad-and-you-should-feel-bad/, about channels in general sucking, being slow and error prone. (they don't, in general suck, but in some specific cases they do; forcing people to use them means that your library can't be used by people who aren't using channels for the reasons in the linked post)
That's a different thing, and a different feature. .MO files support is expected. Compiling the translations into the binary not yet, but it could be a nice feature to have though. You can file an issue on Github asking for that feature if you need it. Pull requests are also welcome xD 
Thanks for pointing that out! I've filled an issue about that and will fix soon. I'd may also use some of your code for compiling the Plural Form expression. Thanks again! 
I tried that, but dint like it all that much. Using IntelliJ IDEA CE with go plugin nowadays.
Hmm okay but it seems I leak memory somewhere, collectLinks grows and grows and grows.
Use the Go memory profiler, let it run for 1 minute or whatever, and see where objects are being allocated.
I did - https://dl.dropboxusercontent.com/u/15900266/buf_360mb_bench.pdf. But everything I see is the growing Tokenizer.
I like that Algorithm and Transformation types are exposed publicly so folks who want to do custom stuff can compose their own. You should provide some examples in the readme on how to do that, just my 2 cents.
[Edited] Good article, looking forward to part 2. Note: the term "security" in this article refers to *Web* security. Just in case someone looks out for other kinds of security. And before anyone cries out: Yes, the article says "Golang", but only until the second paragraph. About one third down I even spotted the Real Name Of The Language. Yay! ;) And the security tips are worth reading if you plan to write an HTTP server. Tip: Have [securityheaders.io](https://securityheaders.io/) check your Web site. Get a bad surprise. Read the blog post and fix your server :) [Added] For the impatient, there is also ready-to-use middleware available: https://github.com/unrolled/secure
They can't introduce a new keyword because of the Go1 compatibility agreement, which is a shame because, yeah, an alias keyword would be much clearer.
Hi, Tasks are published to etcd, where minions are watching a queue. Most of the documentation is in the "docs" directory of the repo, while the resource documentation is at godoc. I agree that there is a need for better documentation, and I'm trying my best to document stuff while adding new features, but sometimes documentation lags a bit behind :) Make sure to check the QuickStart guide, which atm is the most complete introduction document about this project :) Salt uses zeromq and is written in Python, but otherwise they both perform similar tasks.
 I can't see how it could break any existing code as `alias` is currently not a valid keyword in these positions. Yes, it would break some existing tooling and probable tokenizers, but I guess symbols would do that too.
I meant the parser in x/net/html package is not optimized. Nothing you can do about it. Try the extra parameter with `make()` that I suggested. Something like `links := make([]string, 0, 4096)` and see if it helps any. It should reduce the number of allocations. In fact, you may allocate that initial slice outside of the `collectLinks` method and reuse it between crawled sites. Like create a type, make links slice a field in it, and attach methods to the type (i.e. make it a receiver).
That is (both) awesome and answers my question perfectly. I've come across the empty interface before but never really looked into it to see what it actually is, turns out to be quite crucial. Thank you so much for taking a minute to help me out here. :)
One caveat is (and always was) that it is only available from the U.S. If you aren't in the U.S., you might not find it, because the store does geolocation (I am in Switzlerland and can't find it - previously the store asked about your location, which is why I could imagine them redesigning it and automatically filtering the inventory). I got mine when going to a go conference in London. Every participant there got one. AFAIK the physical Google stores also sell them, so if you know someone who lives near one of those, they might get one for you.
Good to know. Could you post the link here when it's released?
I will post the full playlist when it's available.
A few lines of Go in your web app that is already in Go is much simpler than setting up a reverse proxy in front of it.
Australians also want a plush Gopher.
I can appreciate the simplicity of it, although it does mean you have to define a custom middleware signature per app, doesn't it? Makes it hard to reuse third party middleware a and things. 
You don't define a "middleware signature". You just have one function, I suppose you could say one "middleware", that does everything. Third party libraries support this sort of use already. Example: https://play.golang.org/p/ZsY9QIGs3t
I came here to say more or less this. Thanks for covering it.
Very non-inflammatory "we moved back to Python from go post" Part of me thinks a good vendoring scheme may have eased a lot of the distribution pain, but they also have some good points about a lot of things in the python stdlib being external dependencies in go. 
I'd hate to be the backend serving those requests during congestion.
We want in Vietnam too
`go-chart` is something I've been baking for fun use; would love feedback.
You should link to the parent project in your readme file, I had never heard of Govtrack before. For those like me, you can find more info at [govtrack.us](https://www.govtrack.us/) and [their api page](https://www.govtrack.us/developers/api)
Germany wants Gophers too \o/
try go-msi - https://github.com/mh-cbon/go-msi
You know you failed vendoring when someone praises Python's package management over it.
Sorry, would you mind updating your example code to a working state? I wanted to play with it but couldn't get the `PrivatePipeline` to work. For example; you're trying to access `AccountID` on an instance of `*Request`. Thanks!
Expand on that?
you can do that somewhat by changing gofmt to goimports. ``` let g:go_fmt_command = "goimports" ``` It will prioritize the standard library but it can complete any package.
I would put the resources on the network and download them when the app start. Like that it can be upgraded easily. I'm looking for a solution to auto-upgrade an exe on windows ? I think that syncthing do it but i don't know how ?
A little late to the party. That's a great pattern for handler testing, but probably TestMain should have been mentioned for set up and teardown of all test/benchmarks in the file. func TestMain(m *testing.M) { init() r := m.Run() // all test/bench functions are run cleanup() os.Exit(r) }
French want gophers too !
Yeap exactly, if you have multiple long running processes that need to be run at once and can be killed at once, this will come in handy!
The "Pipeline" functions can do all authentication. You could have a Pipeline for "Authentication Mandatory" that doesn't call the handler unless the request is authed.
I feel like the proponents for using contexts to solve the "middleware" problem must all be coming from dynamic languages. Personally I avoid unboxing interfaces like the plague. Actual interfaces are amazing.
Thanks for reading the slides and giving feedback! One thing that is important to me is being able to check out my library a year ago, run the tests, and everything work. This is a sort of litmus test to ensure that that I guarantee the behavior of my library. Unfortunately, this isn't possible if I depend upon other libraries because code.google.com was shut down and my dependency is unreachable. It is generally difficult to guarantee my code when I can't lock down my dependency versions. My dependency could change from under me. There are solutions to this in the Go community but they often work against the official Go toolchain, specifically "go get". So now I have the problem of doing "interesting" things (like you mentioned) that require complex dependencies without writing everything myself, and still working well with the default go toolchain. One solution is to use Go's implicit interfaces to allow those other complex parts to be injected into my library. Then I can use them rather than depend upon them. Another aspect is the nuts and bolts part that you mention. https://go-proverbs.github.io/ "A little copying is better than a little dependency." Nuts and bolts are tiny things that I can just copy over and use. The /vendor directory is one abstract around copying code that helps updating it when bug fixes happen. This goes against "libraries never use /vendor", but I think is ok as long as your mental model is "I need to understand this just as much as code I copy/pasted directly into my library". Another aspect of libraries that depend upon other libraries is that they can easily take opinionated stands in their API around which web framework is best, which logging framework is best, etc. These tend to leak when the dependencies are coded around, rather than coding to what works best for the library and its users. While these opinions may seem reasonable for the library author, they may not be shared by the user of your library that would rather not use logrus, and thinks log15 is better. I believe complex and interesting libraries can still be written without importing external libraries. Maybe an example would be good?
I disagree. Caddy is extremely simple to use and it handles Let's Encrypt automagically.
Nice trick. However, it will make your program ignore stdin when you pass a file directly, without a pipe: go run main.go &lt;file.txt In this case stdin file mode is -rw-r--r-- no **p** here. I think it's better to check that stdin is a character device and then ignore it.
The HTTP lib itself is well-designed. It never had an opinion on anything aside from HTTP, which is a goal libraries should strive for. If you need to add more fields to a struct (a problem which pops up all the time, not just in HTTP), the go-to method should always be embedding that struct into a new struct and then filling out the new fields in the new struct. My argument is that contexts are the worst possible solution to the problem of attaching extra data to a request. They are fantastic for timeouts (which HTTP lib should have an opinion about, requests should have a timeout channel). They are not great for extending structs. Honestly, saying "lets have a map[interface{}]interface{} so people can attach arbitrary data to my struct" is terrible design. The only other place I've seen this is in the collections/array libraries and it's only to get around the lack of generics.
fucking hate gitlab install.. went with gogs for home use
how is it different than downloading and then running the script? Are you trying to tell me that you inspect the source of every install script you use? Give me a break ...
IdeaVIM is pretty good.
Oh. You're talking about the correct use of Context, for passing through static values to other languages. In that case yeah, `map[interface{}]interface{}` is the best type to use, agreed. I just don't want to start dealing with libraries that are only usable by passing a request and a callback into it just to use it because of some "middleware" pattern becoming standard.
Vim key bindings and modes are so effective most text editors and IDEs come with plugin support for that.
Your counter is sensible, but my initial reaction was the same. I tried to type that I do inspect install scripts before running them if I don't know the source, but I think it could be a lie. I think I have a weird trust of Github and have run stuff without from there without inspection.
How would you go about adding request logging for that (i.e. logging status code and response time etc)? Just slap a `RequestLogger` function around each handler like this? http.Handle("/public", RequestLogger(PublicPipeline(SomePublicHandler))) http.Handle("/private", RequestLogger(PrivatePipeline(SomePrivateHandler))) Because I don't see something like that having a natural fit in any of the "pipelines".
&gt; we decided that we don’t want to constrain what HTTP client [...] you use in order to interact with SendGrid Wait, what. Seriously, are they suggesting not using `net/http`?
It's different in that you *can*. An attacker can even distinguish between a curl piped into a bash and a script simply downloaded and only deliver the malicious payload when it's directly piped into a shell. But, yes, that's why providing "download scripts" is pretty much universally bad. Package your shit and sign it.
It's over https. If an attacker wanted to do a mitm attack to swap out the contents, he'd need to use a self-signed certificate which curl won't accept by default.
Your argument doesn't make any sense. If you can't trust the site to send you a non-malicious script, then how can you trust it to send you non-malicious binaries or code packages, which you certainly aren't going to inspect?
You're thinking middleware still. If you want to log response time for all requests, you'd add it into the PublicPipeline, like so: https://play.golang.org/p/occbVix6ec If you want to log response code you need to pass in a fake ResponseWriter into the Request struct. If you want to provide a database handle you create a field in Request to hold it, etc etc.
&gt; Obligatory curl install.sh | sudo rm -rf /* This is shitposting at its finest... 1) the piping into bash is already mentioned by someone else 2) you change it from **https** to **http** thus adding insecurity where there was none 3) demonstrates a serious lack of understanding as to why piping into back might be a bad thing
Because the signing key never has to leave the delevopers machine. By signing the package you shift the trust where it belongs: On the dev-machine, not on a public and vulnerable server. I definitely *don't* trust debian mirrors (anyone can run one, after all), but I can still install packages from them, because debian packages are signed at the source.
&gt; it almost trivial to get valid trusted certs for arbitrary domains oh shit, watch out guys! We have an uber 1337 haxor on our hands here. 
If you never bother to learn Go well, it's easy to say you didn't gain much from it either. This reads like awkward Python with Go syntax: https://github.com/asciinema/asciinema/blob/a450a530c7ee205ce76cebcd3a7b3411ddbaaf8b/asciicast/frame.go#L29 And it seems they wrote their own even loop, calling `select(2)` etc: https://github.com/asciinema/asciinema/blob/a450a530c7ee205ce76cebcd3a7b3411ddbaaf8b/util/select.go
Using the file mode is going to give a bad experience and weird errors for *someone*. Because you can pipe *every* kind of file into a program (including block devices, regular files, terminal output, pipes…). At some point in the future, someone will do a `/dev/ttyUSB0 | ./yourstuff` because they want to have an embedded device generate the input for your program (for example) and that will be, from a file-perspective, indistinguishable from running in a shell in a terminal emulator without getting anything piped in. I think no matter what heuristic you use, it will either be a) not increase user-friendliness at all (for example, timing out after 5s or so) or b) at some point break for *someone*, who will then be frustrated by non-reproducible, intermittend, weird errors. I would just abstain from this and accept, that this is just the way it is.
resp.Body.Close() is in my original code. /* Retry requests if err != nil, sleep between each retry 'i' seconds */ var resp *http.Response = nil var maxRetries int for i := 0; i &lt;= maxRetries; i++ { Debug.Printf("start HTTP Request with: %s\n", x) resp, err = client.Do(req) if err != nil { if i == maxRetries { c.Add(&amp;c.ErrCounter) Warning.Printf("RESP Error: %s\n", err) return } else { time.Sleep(time.Duration(i+1)*time.Second + 1) Debug.Printf("sleep for %d seconds @ %s \n", i+1, x) continue } } else { break } } defer resp.Body.Close()
It's trivial because you don't need to break crypto, you just need to find the one person out of several thousands who you can convince (and convincing gets several orders of magnitude easier for a not-as-well-known domain). Humans have an error rate somewhere between 1% and 10% for highly repetitive tasks, so relying on CAs to never sign the wrong domain has about as much security as a 2-letter password. And it didn't only happen once and it didn't happen by accident. It's just a very well-known and high-profile incident and you should recognize that it only got detected, because Google controls both the client (chrome) and the domain that was being impersonated and took extra steps to detect and secure against this particular attack vector. Most instances of such an attack wouldn't even be detected. HSTS *somewhat* tries to detect against this, but it also only helps if the server wasn't compromised the first time you visited that domain and especially for install skripts it is far from unlikely that there is a very small time frame between your first webpage and the malicious download. Just accept, that TLS isn't a silver bullet and can only give you very limited protections due to the way the CA system works. DNSCrypt, again, helps *somewhat*, but isn't yet deployed to most servers and as a client you can not rely on it.
`rm -rf /usr/lib/foo`, whoops, the download cut out after `/usr` – well, there go my files.
Hi! Author here, thanks for taking the time to read the post, and especially to comment. I didn't realize passing in a file directly would have yielded a file mode without the `p`. I'll update the post in a few hours to reflect your comment + suggestion, with credit of course. Thanks again.
Oh hey this is what I set out to accomplish today.
With Vim, you're always scratching the surface though. But I assure you, after learning the philosophy around modes and some basic key bindings you'll get a productivity boost that will never go away. The only downside, at least to me, is that I judge text editors by how good their Vim support is now...
change the infinite `time.Sleep` to just `select{}` Why is `execCommands` variadic?
Matt, we have a special note for you at the end of the blog :-).
[Simplified code to demonstrate a goroutine pool](https://play.golang.org/p/7MTtXZh8BB). This is probably how you want to do it.
Ah yeah, obviously. :)
Hello, thanks a lot for the detailed output. The ability to pipe every kind of file into a program is something that I didn't think about, and I agree with both points you mentioned which concern user friendliness and unpredictability. As I mentioned in the post, I use a flag to determine when to ignore code that reads from stdin. This still seems weird to me; I feel like there's a better way. While this may not be an ideal way to handle stdin because of all the possibilities of sending input to it, being able to determine a file of a particular mode is still useful for a developer who would want that kind of control. I'm thinking of repurposing the post to reflect as such. Finally, thanks again for the comment you made to my other post on Medium regarding byte slice randomization. I've already edited the post and credited you by name. Thanks for helping me to grow!
a map[interface{}]interface{} is not really bad in itself. Generics would not be able to replace it. Or said otherwise, these are runtime generics. When you don't have a strict requirement on input data, interface{} are perfect. Now the little issue I have is that there is an invisible constraints for maps with an interface key: any type that has a slice, map, or func field cannot be used as key. Talked about it here recently: https://groups.google.com/forum/#!topic/golang-nuts/ajXzEM6lqJI
you can also have a look at: http://go-database-sql.org/
Generics could replace the uses of interface{} everywhere it's being used as a field type (like collections), I didn't suggest they could replace the context map[interface{}]interface. Also, slice, map, and func's are not hashable and comparable. You're free to just have pointers to those things as keys in a map. Slices can't be comparable in any way other than looping through the values and comparing each value. This is because anything can change the len, cap, underlying data, or data pointer at any time. So, I get that you have an issue, but how would you like those things to function as keys? What hash/comparison method would you like the maps to use?
Hmmm, I'm not sure whether to agree or disagree with you. 🤔
One particular kind of software that uses this kind of stuff is terminal software that reads passwords (e.g. gpg, su, sudo,…). All three (AFAIK) will refuse to do anything if you pipe in a password instead of attaching it to a terminal, for security reasons. And they need to disable echo'ing on the terminal to read the password. So you might get inspiration there (though AFAIK they do similar things). But, again, this will at some point piss someone off (for example, at some point, I wanted to wrap a gpg decryption and encryption into one shell-function but only reading the password once. Not possible - without gpg-agent -, as you can't get the password into gpg). Another caveat is, that people often *want* to type stuff in. For example, to write a file from the command line I'll usually do a `cat &gt; file.txt` and then just type away. It has the advantage that it will not shell-interpolate and you don't need any support from a term-based editor for pasting from X, for example. I still feel, that it's best to treat this behavior as a feature, not a bug.
Open source! Those silly mistakes always seem to make their way through... Thanks! \ʕ◔ϖ◔ʔ/
I find it disconcerting that the article doesn't even seem to be aware of https://github.com/golang/go/wiki/CodeReviewComments#receiver-names
Have you had a look at https://golang.org/pkg/sort/ ? The examples are quite good. Just call it "Go". "golang" is handy when searching :)
One extra worker reads the records and put them into the channel, worker pool (n worker, configurable) consumes from there and does stuff with your data. Easy life, easy concurrency. If you want I can give a basic worker pool channel code example tomorrow or after the weekend.
Have you (and/or the author if not you) seen [tomb]? [tomb]: https://godoc.org/gopkg.in/tomb.v2
Amazing plugin! Thanks.
Good practices should be made easy. I don't think the current state of Go vendoring does that.
Any chance of having the gopher say whatever was provided as the command line arguments? Part of the beauty of cowsaw the fact that you can make the cow say whatever stupid or insensitive message you want.
thanks, I actually looked into wix and found it to be a steeper learning curve because of my lack of knowledge around windows msi. I did happen to find other windows installers such as Inno Setup( http://www.jrsoftware.org/isinfo.php ) . The main difference was that Inno setup created a single exe rather a full MSI package. For our use case, this was fine but if deploying across enterprise companies, we would of chose WIX or InstallShield from Flexera.
that's a great idea. We're currently running into an issue of continuous deployment as well. InstallShield ( http://www.flexerasoftware.com/producer/products/software-installation/installshield-software-installer/ ) looks to solve this issue but isn't open source which Is why I avoid it. 
As a first impression, defining an abstract language above the concrete implementation seems like a great idea to me. Still in year three with Go mapping "set" into the reality of slices / arrays / maps is something I think about, so just having the perfect abstract tools and worrying about the engineering later seems like a potentially great effort saver. I don't have a CS degree or masters, just experience from computer engineering world. Is there a site like imgur for PDFs?
There's a couple of things I would learn first before going about. 1). Client/Server model 2). RESTful Services Once you gain context, you can insert any technology to do the job regardless if it's Go/Java/Ruby/Python on the backend or AngularJS/ReactJS on the frontend. 
Oh my god ! Thank you !!! yes it is a LOT more faster
I did it! https://github.com/adamryman/gophersay/issues/2 https://github.com/adamryman/gophersay
Thanks alot of good reading on that page.. 
You create [a form](http://www.w3schools.com/html/html_forms.asp), with `method="POST" action="/whatever"` and then register a handler for `"/whatever"` that uses [Request.FormValue](https://godoc.org/net/http#Request.FormValue) to extract the things entered into the form and [pass it to a suitable sql-query](https://godoc.org/database/sql#DB.Exec) (if you don't know how to write prepared statements, you might want to google that term). Specifically, you want an [INSERT statement](https://www.sqlite.org/lang_insert.html). There isn't a lot of special stuff about go in there. You need to know some basic html and sql (and a little bit of go too, yes). If you don't know either, you should look up some good beginners introductions (sorry, I have no good recommendations for this). Though beware - sql beginners introductions (particularly for PHP, which is very prevalent in that space) sometimes don't teach you to use prepared statements and instead either completely skip the issue and just make you do string manipulations, or they'll recommend something like escaping values (and then do string manipulations). Both of them are horrifically insecure and you should definitely take care to use prepared statements always :) [edit] also, I tried to find a balance between telling you everything you need to know and not spoiling the learning experience. If you just want a working thing to iterate on, let me know.
Not really... generics are a static mechanism. When you have a collection of multiple undetermined objects, interface{} makes sense. Generics makes sense when you want to restrict a collection to a specific type (type specialization). Re. the discussion on slice, maps, funcs, that's a choice that has been made. The whole go-nuts thread discusses it and the last post offers a solution.
Or https://talks.golang.org/2014/names.slide#12
https://golang.org/doc/articles/wiki/ 
Thank you. I'll try to google examples and code it
Something like this - https://play.golang.org/p/u5qJwz7VhV. Tokenbucket is a limiter that fills x times per second for each worker, so with 10 workers it starts with 10 tokens and refills every 1 second / maxWorker = 1 / 10 = every 100ms a new token is generated. That limits the worker to max 10 things per second. I use that for a webcrawler to limit the number of concurrent http requests, if you don't need that just let it out.