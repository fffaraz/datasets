Check out netdata: https://github.com/firehol/netdata
The issue is this is a govt. project, so I think my friend's authority over the direction of the project is very limited. Also, the part I am rewriting is only a small part of a larger web project, which is why I didn't want to/can't mess with the stack. However, I agree with you. If I had full control of the project I'd move the html into go templates and rewrite the whole project.
My advise is don't use something that is not widely used and supported: Twirp. gRPC is the way to go.
Nice, great work!
As someone who used both GRPC and Twirp extensively(wrote an Elixir client for Twirp), I would say if you are using one of the GRPC supported languages then GRPC is great, but from what I have seen third party libraries written in unsupported languages are fairly buggy and slow due to the complexity of the protocol. Twirp is very simple and it took me 2 days to write an implementation of it. So even if there is no implementation of Twirp in your language it's fairly easy to implement due it's simplicity. So I would suggest if you are using a GRPC supported language then use GRPC, if not go with Twirp
I'm not particularly worried about the size, overall, although it would be nice if it was a bit smaller. I'm more annoyed that the WASM support doesn't work like other languages. Maybe I'm wrong, as I've never tried it with C++ or Rust, but [the MDN documentation](https://developer.mozilla.org/en-US/docs/WebAssembly/Loading_and_running) gives the impression that using WASM from the JavaScript side should be as simple as including &lt;script type='application/javascript'&gt; (async () =&gt; { let buf = await fetch('./example.wasm').then((rsp) =&gt; rsp.arrayBuffer()) let wasm = await WebAssembly.instantiate(buf, { imports: { log: (v) =&gt; console.log(v), }, }) wasm.instance.exports.someGoFunc('This is an example.') })() &lt;/script&gt; But in Go currently, you have to also include a `&lt;script type='application/javascript' src='wasm_exec.js'&gt;&lt;/script&gt;` first, then have let go = new Go() let wasm = await WebAssembly.instantiate(buf, go.importObject) go.run(wasm.instance) which breaks a lot of the simple interface of just passing JavaScript functions to the module, and then simply getting back an exported module, as if you'd imported a library. Again, I could be completely wrong about how this is 'supposed' to work, but that's the impression I've gotten from the documentation.
I got a 404 with that link...
I'm aware how Go works - I was curious in the context of wasm, none of the examples I've come over mention it :) 
&gt; A revision identifier for the underlying source repository, such as a commit hash prefix, revision tag, or branch name, selects that specific code revision. If the revision is also tagged with a semantic version, the query evaluates to that semantic version. Otherwise the query evaluates to a pseudo-version for the commit. &amp;#x200B;
No, not really. Currently, all Go functions are called queued up on a background thread and run there, which has the potentially surprising side effect of meaning that two can't run at the same time if the first one that gets called blocks. Regardless, however, if you treat them like old-style async JavaScript functions and just pass a callback for them to call with the return called when they're done, it's relatively easy to handle in most cases. You can also create a water around the functions on the JavaScript side that wraps it in a Promise to make it a bit easier to deal with and to make it compatible with `async/await`. For an example of this being used, take a look at [the code for the playground for my scripting language](https://github.com/DeedleFake/wdte/tree/gh-pages-src?files=1).
No, I just tested it. I'm _100%_ right. If you are in a project directory with a `go.mod` file and the `GO111MODULE=on`, you can run `go get -u -v github.com/ramya-rao-a/go-outline`. If you're in any other directory, it immediately fails with `go: cannot find main module; see 'go help modules'`. I just tested this on my local computer. This is because the `go get` command needs to add whatever you're getting into your `go.mod` file, since `$GOPATH` isn't a thing anymore when you have `GO111MODULE=on`. I encourage you to reproduce my results so you better understand Go 1.11's module system.
Having been subjected to the https://blog.golang.org/pipelines pattern once, I hope I never have to read that kind of code again. It was a ~6 stage pipeline and had around as many (subtle) bugs. Why is the `filepath.Walk` API not enough? [flint issue #1](https://github.com/astrocorp42/flint/issues/1) points to the lack of recursive wildcards, but that doesn't exclude using the same API. It adheres to [synchronous functions](https://github.com/golang/go/wiki/CodeReviewComments#synchronous-functions), which I agree is a good principle.
I'll give that another try, when I tried that that before it just gave errors saying it had to be in the format v1.2.3
I haven’t tried this myself though. Just appealing to what docs are saying. Sorry if this doesn’t work or I’ve misunderstood the docs. I’ll be happy if someone corrects me in this case.
do you even `context.Context`?
I wrote my [discord bot](https://github.com/parkervcp/parkertron) in go to learn the language. It's been a while since I had even looked at writing in any language but I wanted to put some time into learning something. It was between go and python. I chose go because another project was looking at using go.
This *almost* perfect, but the fact that `go mod vendor` does not prune the dependency tree (as opposed to `dep`) means vendor directories will be *significantly* larger in this new world :/
installed it on 18.04 with [godeb](https://github.com/niemeyer/godeb) utility.
That’s a bug, not a feature: https://github.com/golang/go/issues/5083
Ok. That is reassuring for backward compatibility. My problem is a bit different. I don't need to get the package for myself or a project. It is visual studio code that fails to install the tools for Go. The error messages for every tool are the same that I reported above. If what You say is right, I don't see how the problem can be fixed. We'll have to wait for an update.
Welcome to Go
I am kind of old school does it exist a text version of this??
 There is indeed! https://tutorialedge.net/golang/go-webassembly-tutorial/
It seems to have pruned for me, my \`vendor\` directory went from 19MB to 20MB and I can't find any unit tests or unrelated files.
Wow, that's quite unexpected to me. What were your `prune` options with dep? Because this: [prune] unused-packages = true go-tests = true non-go = true has no equivalent when using modules, so I assumed a modules-created vendor would be *much* larger.
I had those same settings, I haven't dug into the differences but it seems minor, if anything. There's this line in `go help mod vendor`: "It does not include test code for vendored packages." So my guess it that it has similar behavior to those `dep` prune settings.
&gt; It does not include test code for vendored packages Ah, I must have missed that. Still, at least for our projects at work the majority of the pruning comes from `unused-packages = true` and I don't ever see that happening with modules.
Hi, thank you for the recommendation but unfortunately this library does not fulfill my requirements. .gitignore files handling is a complex thing and cannot be done using a basic walker + a pattern matcher. Because of it's weird spec, the file walker itself should handle the .gitignore files
There are a lot of reasons to like Go, but the multithreading and concurrency primitives are definitely up there. This code snippet gets thrown around from time to time, but it's one of the most beautiful examples of what can be done with the language. [Concurrent implementation](https://golang.org/doc/play/sieve.go) of the [Sieve of Eratosthenes](https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes) 
Hi, thanks you for pointing to the synchronous functions principle. I will consider it! The problem is that a full gitignore handling cannot be done with a .Walk + a pattern matcher to filter files. As it's a weird specification, it should be implemented in the walker itself. I didn't notice all the errors in the golang blog post, but I find this pattern very elegant as ot allow a very clear code like: runPipeline(stage1, stage2, stage3, errorHandler) And allow each step to be independently concurrent
I tried the example a few times and removed all files and started again and made sure go1.11 was installed but says in the browser console Go is not defined in wasm_exec.js at the line that has "const go = new Go();"
&gt; The problem is that a full gitignore handling cannot be done with a .Walk + a pattern matcher to filter files. As it's a weird specification, it should be implemented in the walker itself. Ah, so you want to traverse the file system and filter to only return the files Git would care about. I would use `filepath.Walk` and then do a post-filter by keeping a stack of looked-up `.gitignore` files. Since `filepath.Walk` returns files in lexicographical order, it should be fairly efficient, only having to search and read each `.gitignore` once. The top of the stack could even be the merged ignore list for all ancestors, making it efficient. &gt; pattern very elegant as ot allow a very clear code like: &gt; &gt; runPipeline(stage1, stage2, stage3, errorHandler) Absolutely, but you've now picked the only line out of 20 that will be clear. ;) The internals of `runPipeline` is where the bugs hid for me. Not where the pieces were chained together. &gt; each step to be independently concurrent Yes, it's a trade-off between performance and code complexity. I'd start with simple code and only move to optimizing after it's been proven to be inadequate. YMMV.
Generally no, that leads to brittle tests. As long as the public API is satisfied, tests shouldn't be concerned with how it was implemented. The only time that I might test unexported methods is when there's something with very complex logic and many edge cases, and the public API tests make it difficult to test all those cases. Even then, I would look to refactor the public API first. Code that is hard to test is usually also hard to use.
'go build' ignore vendor directory by default, If you want to build dependencies from the vendor/ directory, you’ll need to ask for it. 'go build -mod vendor'
In languages like Java and C, you have to map your CPU demands onto OS threads. But you have to manually ensure you don't have too many nor too few threads, as your performance will suffer either way. There aren't many language primitives for sharing data, so you end up managing data structure contention yourself with locks. If you forget one lock (or take a lock in the wrong order), your program now has a very subtle bug that is nearly impossible to find in testing. In contrast, go allows you to create as many go routines as you want, which means it "fits your problem" easily. The mapping of goroutines to threads is done automatically by the runtime. (So it's always close to optimal). To communicate between goroutines, you generally push data around via channels, to ensure that no two goroutines try to access the data a the same time. (You can even push pointers to data if you are worried your data is large.) For example, the \`map\` data type is not 'goroutine safe'. In other languages, you would put locks around that data to make it safe, then worry for all time that someone will access the data directly. But in Go, you can make the map private to one goroutine, and have the others send "add/remove" messages via a channel. &amp;#x200B; \&gt; What other main areas, such as interfaces, should I take the time to grok? Yup. Interfaces are what Alan Kay originally mean when he invented OOP/Classes. The other big win in Go is how much tooling comes standard. Things in other languages you would have to know about, decide on, and manually integrate into your project: &amp;#x200B; \- Worried about race conditions? No need for an add-on, just use "go build -race" \- Want to prevent regressions with tests? No problem, "go test" is your friend. \- Don't want to write a style guide? No problem, "go fmt" will enforce the one true style for you. \- Want something like JavaDoc? No problem, "go doc" is built-in. \- Want to treat Go like a scripting language? No problem, you can "go run" your files directly without an explicit compile step. \- Need a linter? No problem, "go vet" is built in. (But frankly, things that are warnings in other languages are errors in go -- and this is a good thing, it's impossible to leave unused vars or imports laying around that will confuse people down the road.) \- Need exact dependencies to ensure you build the same every time? No problem, go 1.11 now includes a standard module system that tracks versions for you. &amp;#x200B; Oh, and just for you: Not only can you [drop down to assembly](https://golang.org/doc/asm) at any time in the middle of your Go program, but the assembler is [automatically maintained by parsing CPU instruction manuals](https://talks.golang.org/2016/asm.slide#1)! 
The .gitignore spec is specific to git. Other version control systems have their own ignore specification grammars. I disagree with the assumption that a general file system walking library ought handle any particular VCS ignore specification grammar. That being said if you are aware of a library that does handle the .gitignore spec, then that can be used with any file system walking library to accomplish the task you desire to accomplish.
Thanks, this solved it. I wonder why it didn't simply check if the vendor directory is present and avoid an extra command to remember.
Thank you, but if I get rid of the src directory, where do I put config files? If I create a top-level directory (in the project) named configs - then it is at the same level of 'common' and common is source code - just seems wrong - but I can see if you think of 'configs' as a 'package' then maybe it is ok (even though configs would never contain source code). But, MORE importantly, of I adopt the above scenario, and the user builds the application - what is the standard path to find the config files... this is what doesn't make sense in the Go build system - there is no distinct path where an application will ultimately be installed - maybe it is just that Go is missing a packaging/installation component? I just see a script file that zipped GOPATH/bin/github.com/robaho/go-trader/\* and also included GOPATH/src/github.com/robaho/go-trader/configs but this seems really ugly???
Well you are supposed to study the output to make sure it works and see how it does. That was 10 minutes of work.
You are right in the sense that 5.4 -&gt; 5.5 and 5.5 -&gt; 5.6 are completely different upgrades, but if you use PHP for production workloads, that doesn't matter much in a practical sense. 5.5 isn't supported anymore, so if you want to stay on it you're foregoing security patches. Not the best of ideas. In other words, you kind of had to take the upgrade, and break some of your working code. Go doesn't give you this type of headache.
is there anything after the basics?
Oh that makes much more sense and I don't know the answer. I guess I jumped to conclusions in my above comment.
Composition over Inheritance. Inheritance is so often misused (people think it's an enhanced form of copy-paste), that having a language that forces you to switch thinking from "is a" to "has a" makes a lot of difference in code quality and readability. Another one is the ability to create named types from primitives. You aren't going to use this every day but it's amazing: type my_int int func (i my_int) Add(x my_int) { return i + x } var z my_int = 8 var y my_int = 4 z.Add(y) // = 12 This can be used in suprisingly fascinating ways when your type is defined via singleton constants.
This is the expected behavior, but I also find it confusing. It should change in 1.12. See https://github.com/golang/go/issues/24250
&gt;Aside from the advantage of being able to program in Go, is there any reason one would use it over the existing (and popular) discord.py and discord.js libraries? Because when you are running Go in production, there is a single binary to worry about that works anywhere. With other languages, you have to orchestrate the entire runtime (which version of python? How many thousands of files do I need?) and the entire dependency tree (npm install). Plus, as others pointed out, scripting languages in general will use 10x-100x more memory and it will be harder to co-ordinate many bot functions without threads (not scalable) or coroutines (not natively supported by all libraries in most languages that have them).
great talk, thanks for this!
You should add defer res.Body.Close after checking for the error. Also, you should return the error because res may be nil. and you should not create a new http.Client for each request. They have a pool and are safe for concurrent use
Thank you so much for your time and the effort , I am definitely going to buy, Slack channel could also make things simpler
Nice! Would be handy to have an IsCompressed method on the result
[removed]
[removed]
You’ll want to do something called bootstrapping. Start with a subset of C (in assembly), and then use that subset to write a bigger subset. Repeat until you have a full feature set. If you’ve never written a compiler before, start with an interpreter (in a higher level language). Then write a compiler.
That is the problem. Thank you. So it's a go limitation and not a visual studio code limitation. 
Amazing. 
https://github.com/hunterloftis/pbr https://github.com/hunterloftis/pbr2 Really interesting talk, and very well delivered
&gt; However, I never saw an accurate definition for the terminology reference type in any official documents and unofficial Go articles. You also never saw an accurate definition of the word "stack" or "heap" in the official documents. The word "escape analysis" doesn't appear in the spec either. The term "compiler" appears, but it's not defined. The usefulness of terms is not restricted to whether or not they appear in the Go language spec. Especially, as if you explain things, you are usually explaining them to people *not* familiar with Go - so drawing parallels and analogies to concepts known from other languages is not only useful, but absolutely necessary. What's more: It's not up to Go to define that term. It's a common CS term. Go can have opinions about it and it has certain slack in terms of how to interpret it. But the term applies *regardless* of any specific language. &gt; Note, the definitions from the two different official Go articles mentioned above are different. They are consistent though, if you don't view them as definitions, but as statements using the commonly used, standing definition (that you talk about below). TBH, it's a bit frustrating that the article, at length, takes various statements *about* reference types and tries to make them into *definitions of the term*. Instead of taking the actual definition and seeing to what extent it applies to Go (spoiler alert: It does). That just totally ignores the context in which the term is usually used. &gt; By this definition, an array type with a pointer element type and a struct type with pointer fields, along with map/slice/channel/pointer types, are verifiable reference types. Correct. &gt; However, this definition has not the advantage of explanation convenience. Why not? I said it elsewhere today, I say it again: This definition is the most common explanation to teach slices. "Think of them as [structs with a pointer field](https://godoc.org/reflect#SliceHeader)". It is short and immediately and completely explains both the way slices act as references and the way they don't. Note, that the definition does *not* say that any type has to be *either* a reference type or not. If you don't try to exclude, say, structs with pointer-fields, the definition is fine and has a pretty good explanatory power. In fact, I would argue that the reason you are dissatisfied with it, is that its explanatory power is *too good*. Because people commonly don't think of e.g. structs containing pointer fields as reference types - when they really *should*. &gt; By knowing some possible internal structures of all kinds of built-in kinds of types, there would be less confusions in using Go without using the reference type terminology. If someone coming from Python, Haskell or C++ asks me about behavior of slices/maps/channels/pointers that they find confusing, I will not tell them that they just need to know the implementation details of all these built-in types. That's just not a useful way to explain things and will justifiably frustrate them and make fun of this supposedly simple language…
No worries, no harm done :) 
&gt; What's the difference between `ch &lt;- myData` and `myMutex.Unlock(); myChAsSlice = append(myChAsSlice,myData); myMutex.Lock();` &gt; &gt; Is it just syntax sugar or is there some kind of optimization? Sure, that code might kinda work in the trivial cases. Now imagine your entire program is structured around communication on many different channels. If you are reading/writing to more than one channel at a time, that code will deadlock quickly. So you have to manage the locking order -- but which one do you lock first? If you get that wrong *anywhere* in your entire program, you suddenly have a very subtle, hard-to-find, hard-to-debug deadlock. Oops. Channels are not only simple to use, but they are not a loaded gun constantly pointing at your foot. You just call `select()` with all the channels you want to listen on / send to, and it makes progress [anywhere it can](https://github.com/doug/go-dining-philosophers/blob/master/dining-philosophers.go). &gt;&gt; (You can even push pointers to data if you are worried your data is large.) &gt; But then you're subject to race conditions. Not if you adhere to the [Go philosophy](https://blog.golang.org/share-memory-by-communicating) of "Do not communicate by sharing memory; instead, share memory by communicating." In other words, when a goroutine sends data to another goroutine, it should forget about the data. This structure seems odd to people who write (buggy/complex) multi-threaded software. But your entire program is now structured around concurrency of independent processes (that can easily be parallelized by Go onto a finite number of threads). Instead of YOU deciding which things are on which threads, Go does that for you. See also [Concurrency is not parallelism](https://blog.golang.org/concurrency-is-not-parallelism). 
To quote [Defining Go Modules (Go &amp; Versioning, Part 6)](https://research.swtch.com/vgo-module) by Russ Cox &gt; ## The End of Vendoring &gt; Vendor directories serve two purposes. First, they specify by their contents the exact version of the dependencies to use during gobuild. Second, they ensure the availability of those dependencies, even if the original copies disappear. On the other hand, vendor directories are also difficult to manage and bloat the repositories in which they appear. With the go.mod file specifying the exact version of dependencies to use during vgo build, and with proxy servers for ensuring availability, vendor directories are now almost entirely redundant. They can, however, serve one final purpose: to enable a smooth transition to the new versioned world. &gt; &gt; When building a module, vgo (and later go) will completely ignore vendored dependencies; those dependencies will also not be included in the module's zip file. To make it possible for authors to move to vgo and go.mod while still supporting users who haven't converted, the new vgo vendorcommand populates a module's vendor directory with the packages users need to reproduce the vgo-based build. So my read on this is that once modules and proxy servers are ubiquitous, vendoring will no longer be needed and it will become heavily discouraged and possibly even deprecated. If the default behavior of the go tool respects vendor directories then any future change to that behavior gets much messier. Conversly, if the go tool ignores the vendor folder by default, then making changes to vendor behavior or removing it entirely becomes much safer. You can tell everyone with confidence, "as long as you aren't using the `-mod vendor` flag, then you will be totally unaffected by this change."
I use visual studio code. Look it up. You need to install the Go tool. 
Gophercises are pretty damn good!
That makes sense. Still would be nice if it worked a little more simply. I know that you're supposed to use `instantiateStreaming()`, but I've been using `instantiate()` because browsers don't load `wasm` files from `file://` URLs with the right mime type using `fetch()`, so if I want to test locally I either have to run it through a server that forces the mime type or bypass it completely using `instantiate()`. The server's impractical when working with React, which I'm doing with the playground, so...
Eclipse Settings -&gt; Go -&gt; GOROOT
This might seem a little snarky but I think the important thing with go is just about everything is basic, and the more you can keep things simple and idiomatic, the more advanced you are. That said, your best bet is probably just to read a lot of Go code and try and simplify it and make it idiomatic. 
[removed]
Is this the same as C typedefs?
There's missing license
If you look in the go src tree, there are lots (more than 40) files called `export_test.go` and `export_xxx_test.go`. Some of them just export a few internal constants or package variables. Some export a non-exported function for testing. I guess if these files are in the go library source, they count as idiomatic.
Yep, the book is a sort of a pain to read at the moment. There are so many typos and grammar mistakes. Nonetheless I like how you explain things. Keep working on the book! ;)
yes. One gotcha though: this does not give you the methods of the type you are typedefing to. e.g. you'd want to add special serialization to `time.Duration`, you can't do `type my_duration time.Duration`. if you want the methods as well, you need to embed the type: `type my_duration struct { time.Duration }` the methods of embedded types are also available on the parent type.
I think you could snag a really low-priced one in the 1060 card range, especially now that the cryptocurrency scene has hit a low and I guess a lot of people are ditching their old hardware. I've ran workloads even on very old K620 cards, which I think you can get for about $40, but it's not going to take you far if you want to use it for gaming or something too :)
One thing that I'd recommend is testing non exported functions if they are a strict implementation of a documented algorithm. Such algos often have defined test suites which should be used. This applies to parsing, crypto etc mainly, but if you are implementing a formal algorithm, and it has a defined test suite, then you should probably implement it as well, even if you do not export the function. 
How would that be different from the issues of the struct?
Amidst an ocean of outdated or just plain wrong information, this is enlightening. Thank you! This is exactly what I was looking for.
Please post code that compiles. This works fine for me. package main import ( "fmt" "net/http" ) func main() { end := make(chan bool) go func() { resp, err := http.Get("http://google.com") if err != nil { panic(fmt.Sprintf("Can't access URL: %v", err)) } defer resp.Body.Close() fmt.Println(resp) end &lt;- true }() &lt;-end }
What’s with the r in the URL?
Unfortunate typo in the first paragraph: obliviously -&gt; obviously. Great article otherwise, though!
Can you change the behaviour of VSC using Go in the settings? Like setting the env-variable when it uses Go.
Read through the standard library. It is great documented teaches a good style and provides a lot of what you need.
Something like `go global get` or `go get -g` maybe. 
If anyone encounter the complication error: ``` go tool compile: exit status 2 compile: unknown architecture "wasm" ``` Please remove the old GOROOT env var you set before. This env var is not needed any more.
Still, i feel that a proxy cache is the wrong approach. Go doesn't even provide one so i have to go out of my way to find a 3rd party one and maintain it. I'll have to manually find a way to backup the proxy contents, and selectively clean the old/unused contents. I cannot even use a TTL to clean the proxy cache since i could potentially lose data. What if the 3rd party library author deletes their project or makes a force push and the proxy overwrites the good code with this? I would be screwed as i didn't had the library code on my repo nor a consistent backup.
&gt; You also never saw an accurate definition of the word "stack" or "heap" in the official documents. The word "escape analysis" doesn't appear in the spec either. The term "compiler" appears, but it's not defined. That's a strange mix of facts. Stack and heap never occur in the specs, so why to define them there? The term compiler does occur in the specs and indeed is not defined. That's because it's a well defined term. Consume source code and/or object files, spit out code for a particular interpreter. (CPUs interpret machine code.) You've argued elsewhere that the term "reference type" is also a well defined term. However, that "well defined term" has different, non compatible definitions across different languages, clearly contradicting the "well defined" claim. You seem fine with the contradiction, I do not. No problem in that, of course. I was not aware of the [commit message](https://github.com/golang/go/commit/b34f0551387fcf043d65cd7d96a0214956578f94) linked through this post. It reads, quoting "spec: Go has no 'reference types'". Reviewed and approved by Rob Pike, committed by Robert Griesemer. No this is not a call to authorities. You're fully entitled to disagree with the two guys (and probably some others on the Go team for that matter). It's just that some people, me included, share that view of the commit message, Go has no reference types. Note: don't to be confused with "reference semantics" which really is _not_ the same thing as "reference type". (type of `i` in `int &amp;i;` in some language, etc.)
I don't know how I should change the behavior of VSC. VSC is lost when working on a module outside of the GOPATH. It looks like the tools need to be updated to work with modules. 
&gt; code that is 50% error handling what kind of code isn't?
[removed]
&gt; That's a strange mix of facts. Stack and heap never occur in the specs, so why to define them there? The point is, that we still talk about the Stack and the heap when talking about Go, even though the spec does not mention them. The usefulness of terms is not determined by whether or not they appear in the Go language spec. &gt; That's because it's a well defined term. Just like "reference type". &gt; However, that "well defined term" has different, non compatible definitions across different languages, clearly contradicting the "well defined" claim. Can you elaborate? To the best of my knowledge "a type whose values refer to other values" is a pretty universal definition. I mean - it's well-defined to the degree that any term in SWE is well-defined. I agree that the definitions are generally fuzzy and insufficient (with my Mathematician-glasses on), but they are still pretty useful. &gt; Reviewed and approved by Rob Pike, committed by Robert Griesemer. Then I disagree with Rob Pike (and to a lesser degree Robert Griesemer) - at least in that reading of that commit message. But I also don't think this is a useful data point TBH. There is a difference between "language we should use in the spec" and "language we should use to explain Go to newcomers". The spec has a higher bar on internal consistency. Teaching has a higher bar on external consistency. That is, a spec should avoid technical terms that are not explained in the spec itself, if possible, whereas teaching should as much as possible use terms that are used outside of the language. I'm the first person who will correct someone who calls a type conversion or a type assertion a "type cast" in an article targeted at gophers. But it's a fine term to use, when talking to a Haskeller (when talking about assertions) or C++ programmer (when talking about conversions) having a first look at Go. &gt; Note: don't to be confused with "reference semantics" which really is not the same thing as "reference type". I'm not aware of the former. It doesn't seem like a good term ("semantics" is too general to apply to anything specific). Note that elsewhere I explicitly distinguished C++ references as well as the term "pass by reference". Which I totally agree don't make sense when applied to Go.
&gt; I really wish Golang would add exceptions No.
FWIW: My favorite example of "this kind of nitpicking terms isn't useful" is variance. The Go spec doesn't mention subtyping, yet the FAQ (and several github issues and golang-nuts discussions) still reference [covariant types](https://golang.org/doc/faq#covariant_types). Because it turns out, that even though the Go spec doesn't use the term "subtype", it still contains [a concept](https://golang.org/ref/spec#Assignability) that is conforming to the rough definition we have of subtyping (["If S is a subtype of T […] any term of type S can be safely used in a context where a term of type T is expected"](https://en.wikipedia.org/wiki/Subtyping)). And talking about it in that way is just useful when we are trying to describe the concept of variance or [why it doesn't exist in Go](https://blog.merovius.de/2018/06/03/why-doesnt-go-have-variance-in.html).
Go does have built-in handling for exceptional cases: \`panic\`. &amp;#x200B; If more than 99.999999% of your code can result in exceptional cases, you've probably done something wrong.
Assume a exported function E uses 15 unexported functions u1 to u15 to come up with it's function value. You start refactoring the package and suddenly a test for E fails. Now you have to dig through 15 functions. I know people will complain about "testing implementation details", but when your implementation is based on inverting a matrix you should have some test which verify that the matrix inversion code works. I do not advocate to test each and every tiny, helper function.
I don't think a CLI is needed... The app should require a certain version of the DB, and migrations would run to provide that. No need for an external tool/CLI. and we can still write a quick and dirty CLI for our app, like add a `-migrate` command to it... 
Don't tell him! Now his code will be full of `panic`s with no `resolve`!
What mess? My 20 years old C, C++, Java and .NET code still compile today in modern versions.
So I re-organized the package structure, and honestly it is better on some accounts, and far worse on others. Having to import those long package names is ridiculous. I know Go supports relative imports, but those are frowned upon, and not much better anyway. Why can't Go understand/determine a "root" when building, and then the packages are expected to be there, or THEN it searches the GOPATH - then you wouldn't need any of the long import nonsense, and the code would be similar to the stdlib code... This is a REALLY BAD CHOICE by the Go designers, BUT, my reading of how to use GOPATH implies that my original usage could be considered correct - clearly the code is a lot cleaner, and easier to write... (and similar to stdlib) Lastly, the "configs" scenario is now a nightmare. You can't just prepend $GOPATH, since the GOPATH can be of the form GOPATH=directory1:directory2:... The only real option is to define another environment variable that points to the "configs" path and force the user to set it. If if you determined the fully qualified bin path, it doesn't necessarily allow you to determine the config path relatively (because of the multi-segment GOPATH, or that the user can copy the binaries elsewhere). Go really needs a second level install that can package files into a known location, and then offer lib code to find the install location. It's honestly kind of a joke how poorly this is designed IMO, at least in comparison to how easy and robust it is with Java.
I think I am allergic to Javascript, because I am thinking if I can find a generator for wasm\_exec.js .
My code frequently fails. For example, every time the user enters a file name that doesn't exist, opening the file fails and that failure is carried up the call stack. Failure is a natural part of a program and should not be ignored. Instead, behaviour on failure should be deliberated and handled in an appropriate manner.
The language builders use panic/recover in the stdlib - I guess they are just smarter than everyone else...
&gt;You are reading that backwards, .0000001 percent of the code/state results in a panic. That seems like the same direction? &gt;but every decent modern language has exceptions - for a reason - they make error handling both easier and more robust. And Go is no exception. But errors are not exceptions. Errors are expected. What do you think is so exceptional about errors? &gt;Review half the public go code, I would bet &gt; 50% just ignore the error anyway using \_ - which is far, far worse Worse than what? Relying on an exceptional state to crash your problem? But you're right that sometimes the returned value is the correct value even when an error is given, making checking the error unnecessary.
&gt; I really wish Golang would add exceptions. This stuff was resolved long ago Exceptions this a non-issue Not using exceptions for regular error handling was a primary design goal of Go after the bad experiences with exceptions in Java, C++, Python &amp; Co.
With exception handling that would be a checked exception, because it is expected to be thrown in common usage, and thus the caller must handle it or rethrow. Depending on the architecture, re-thrown is sometimes the best practice, especially for GUI code, since there is usually a top-level event loop that can handle common errors like this in one place.
One important thing to note: Never let the return signature be anything but the base error type. I've seen many new Go programmers return a custom error type in the signature, causing chaos to callers above it. https://gist.github.com/abraithwaite/4d5111baffb4f42a5708da8dc4d68a0e
\`panic\` *should* be used for exceptions. That is why it it is part of the language. Errors are not exceptions though.
And checked exceptions are much worse than errors as return values because they teach people that it is a good idea to bunch up the error handling for multiple functions into one exception handler. This is generally a bad idea as it discards the state the program was in before an error was caused. The only good usage idiom is this: try { someFunction(); } catch (SomeException e) { /* error handling here */ } with a single function all in this `try` block. I can't see how this is any better than this: err = someFunction(); if (err != nil) { ... }
see https://github.com/quickfixgo/examples/blob/master/cmd/executor/executor.go and about line 76, or any of the other code in that file and you will hopefully see the folly of the question. Now you can say that the API is incorrect, but then the only case is to use panic &amp; recover. and that would be my point that proper error handling should use exceptions, and the multi-value return check the error paradigm is a very poor one.
&gt;and that would be my point that proper error handling should use exceptions You mean *expecteds*? You still haven't explained to us about what is exceptional about errors. If an exceptional case really does arise in your code, the use of \`panic\` is perfectly appropriate. It is why it is included in the language.
How do you guys make the monorepo work with Kubernetes and CI?
And the actual evidence of this is ? Yes, people mis-use exceptions, they also write poor code - but we still write code (in most cases...), and exception handling is far superior to error returns, that's why it is in every major modern language. Now, maybe Go cannot implement exceptions as efficiently as a JVM language, then that should try to be improved. The problem with panic/recover is there is nothing in the language syntax that forces the caller to handle an exception, or even that the method would throw one... 
Peter Bourgon provides a good overview of team/company best practices for planning and building Go apps: https://www.youtube.com/watch?v=PTE4VJIdHPg
I’d recommend following the instructions to install from the .tar.gz package. It’s literally two commands.
I've never had the need for checked exceptions and I found them a huge pain in the ass back when I programmed in Java more. These days I mostly program in C and error handling is just fine.
Example: https://www.jivesearch.com/?q=china+population
I would offer that you did not how to use them properly. As I stated in another comment, to do Go (or C) error handling correctly, you end up with at least 3 lines of error handling code for every method call... so for many routines the error code is more than 75% of the code base, and it obscures the logic. Exceptions done properly leads to much cleaner code IMO.
&gt;By default, why queries the graph of packages matched by "go list all", which includes tests for reachable packages. The -vendor flag causes why to exclude tests of dependencies. &gt; If the package or module is not referenced from the main module, the stanza will display a single parenthesized note indicating that fact. It's likely being imported indrectly for some tests of one of your dependencies. 
Not all functions can actually fail. The trick is to choose a design where all sources of failure are ruled out as early as possible so the core logic can remain free of error handling. In practice, it is not as bad as you say and I don't think it would be any better with exceptions.
Great talk!
&gt; And the actual evidence of this is? https://talks.golang.org/2012/splash.article "16. Errors [...] It was a deliberate choice not to incorporate exceptions in Go. Although a number of critics disagree with this decision, there are several reasons we believe it makes for better software. [...]" Also: https://golang.org/doc/faq#exceptions &gt; Now, maybe Go cannot implement exceptions as efficiently as a JVM language, then that should try to be improved. You're making things up. There's no technical barrier preventing exceptions in Go. The absence of classic exceptions is fully intentional.
That is not the proper way to use exceptions. For a large class of programs that is just not the case. Please see the quickfixgo code I cited in another comment. This is really ugly due to lack of exceptions, and trivial with them. Here is the same exact code in Java... https://github.com/quickfix-j/quickfixj/blob/master/quickfixj-examples/executor/src/main/java/quickfix/examples/executor/Application.java at line 135. But even then I would not of handled the RuntimeException there, I would of handled it on the call to crack() that way that handling code is not duplicated across the different message types.
&gt;Still, i feel that a proxy cache is the wrong approach. Go doesn't even provide one so i have to go out of my way to find a 3rd party one and maintain it. &gt; &gt;I'll have to manually find a way to backup the proxy contents, and selectively clean the old/unused contents. I cannot even use a TTL to clean the proxy cache since i could potentially lose data. &gt; &gt;What if the 3rd party library author deletes their project or makes a force push and the proxy overwrites the good code with an incompatible change? I would be screwed as i didn't had the library code on my repo nor a consistent backup. Well, the community has pretty much converged on [the Athens Project](https://docs.gomods.io) so it's a easy decision. Most people won't have to set up and maintain a local proxy. There will be a "global proxy pool" that will act as a central registry. Only large companies will want or need to set up local proxies, and they will have the resources to maintain them properly. Furthermore, Athens doesn't have the same design flaws that NPM has. Specifically, content on Athens 100% immutable. Your concerns about actions that the author could take to modify or remove a module that you depend on are unfounded. I suggest you check out https://docs.gomods.io/ as they do a fairly good job explaining the design. All that said, the Athens global proxy pool doesn't exist yet, but it's making really good progress. I suspect that it will be ready by the time go 1.12 is released and modules are enabled by default. That is the time that vendoring will become obsolete.
I didn't make anything up. I was offering that maybe it was excluded because implementing them in a statically compiled language might not be efficient enough (which was a common complaint about C++ exceptions at one time). Java/JVM exceptions are 0 cost when not thrown. Furthermore, they did implement exceptions in Go, with panic/recover, they are just not checked exceptions, so to say they left them out is nonsense, and in fact the Go stdlib authors use exceptions heavily - and it is rather poor code (for maintainability) because they don't have checked exceptions... 
&gt; in fact the Go stdlib authors use exceptions heavily Can you show us some good examples?
&gt; This is really ugly due to lack of exceptions The quickfixgo code appears to be generated by a tool. The naming is nonsensical, as are the patterns used. It's ugly because it wasn't written by a human. 
Not true. That is hand coded. The 'fields and message types' are generated. The quickfixgo I pointed you to is a user level application that uses these structures.
The way things are headed this might become the `vim` of git clients.
The quickfixgo code still seems very poorly designed. Why can every single one of your getters and setters fail? Why is your data model like that?
Download binary : [https://dl.google.com/go/go1.11.linux-amd64.tar.gz](https://dl.google.com/go/go1.11.linux-amd64.tar.gz) Save it in the Downloads folder. If you installed an older version of Go already you first have to remove it (**skip PATH setup**): sudo rm -r /usr/local/go &amp;#x200B; If you have no Go folder create go folder at usr/local sudo mkdir /usr/local/go the next step is to extract the tar file in usr/local/go &amp;#x200B; **Setup Go PATH:** If you haven't setup a workspace and PATH for go you you should do this first according to [https://golang.org/doc/install](https://golang.org/doc/install) &amp;#x200B; Add /usr/local/go/bin to the PATH environment variable. You can do this by adding this line to your /etc/profile (for a system-wide installation) or $HOME/.profile export PATH=$PATH:/usr/local/go/bin &amp;#x200B; **Setup Go workspace** If you have no Go workspace folder cereate one now: &amp;#x200B; mkdir $HOME/go &amp;#x200B; Edit your \~/.bash\_profile to add the following line: export GOPATH=$HOME/go &amp;#x200B; **Extract new Go version in usr/local:** &amp;#x200B; cd Downloads/ clear sudo tar -C /usr/local -xzf go1.11.linux-amd64.tar.gz clear source \~/.bash\_profile clear go version &amp;#x200B; If go version displays: **go version go1.11 linux/amd64** &amp;#x200B; You're good to Go! ;) &amp;#x200B;
This series of blog posts might be useful: https://fgiesen.wordpress.com/2011/07/09/a-trip-through-the-graphics-pipeline-2011-index/
BTW, I did not write or design this code. It is a fairly established package in the financial sector (although the Golang impl is fairly recent). In this case, every single function CAN FAIL, since the 'fix message spec' uses a tagged format, so a client could ask for a field that doesn't exist in the particular message being processed. So when a message is being processed the system know the type of message, but the messages contents are unknown. The consumer can expect certain fields, and if they are not there, it is usually an error (meaning the message is rejected, a rejection is sent back to the sender). What fields are expected are consumer specific (there is usually a data dictionary supplied to the sender), but in many cases the fields are "conditionally present", meaning that they are only required given other context (thus you can't fully determine a message is correct just based on the data dictionary).
But then you don't want failure as a design pattern but rather nullable types. You can get this by returning a pointer to the value instead of the value itself. This replaces all your error checks with a single large conditional to check if all pointers are not nil.
&gt; Not true. That is hand coded. Really? Why would a human write it like that? Just to point to as an artificial case for how not to handle errors?
It must be a transitive dependency, like in dep ecosystem.
So there is no way to show which dependencies requires it?
look at the encoding/json. here is some of the comments: // jsonError is an error wrapper type for internal use only. // Panics with errors are wrapped in jsonError so that the top-level recover // can distinguish intentional panics from this package.
Funny thing is this is what I suppose go mod why does - showing transitive dependencies... or it would be kind of useless. And, it actually works as expected for other packages, just not protobuf.
Yeah. They use exceptions in the JSON parser to escape the deeply nested parser state. Then at the top they carefully reconstruct what went wrong and generate a proper error. That's exactly the same way error handling has been done forever in parsers (with `setjmp` and `longjmp` in C). The key point is that the exception is tightly controlled and does not pass library boundaries so no other function needs to deal with this implementation detail.
Please read the other comments regarding the FIX protocol. The getting of any field can return an error by the specification. Tagged or variable message structures are very common. Without exceptions they are very difficult to process, or at least lead to very ugly code (as cited)
See [here](https://tour.golang.org/methods/4): &gt;Methods with pointer receivers can modify the value to which the receiver points (as Scale does here). Since methods often need to modify their receiver, pointer receivers are more common than value receivers. And, from your code, NewHouse() does not return a pointer to the House struct, it returns the a copy of House struct instead.(probably overlooked? ;) https://play.golang.org/p/BHS-3_LOzV8 
That is not correct, because you need to propagate the actual error since you need to know which field was missing in order to return that in the rejection message to the client. You can talk around this all day, but the truth is it is a poor design choice by Go. Proper exception use is settled computer language design.
&gt; Please read the other comments regarding the FIX protocol. There is nothing about the protocol that explains to me why the design choices were made. &gt; The getting of any field can return an error by the specification. The getters are a bit strange. But this part even has generated in the filename, so I'll assume the author has no control over the design of that package. But why doesn't the author bring those fields into a more sensical structure, that has already been validated for errors, once and then pass it around? Why does every function call the getters over and over and over again? But this isn't the only strangeness I see. Still thinking it has to be machine generated.
This is very common in message processing, and for something like quickfixgo it is especially problematic since it cannot trap the exceptions, and it cannot use a 'throws' to declare them.... so the consumer of the message must test for error on every method call, and when processing a message there could be hundreds... It is also very common in database systems when using transactions... when a processing error is detected, throw the exception, and the top-level that started the transaction will roll it back (as the processing could be several methods deep when the error detected) This is why proper exception handling is of great use to any message processing/translation type system, and almost all systems can be thought of as a data transformation process... (input-&gt;transform-&gt;output) thus the need to proper exception handling...
&gt; Proper exception use is settled computer language design. Citation needed.
I've enjoyed badger. I have only used it for personal things since I'm not on a team right now that uses Go at work, so I don't wind up stressing it. From my reading it seems like it should hold up quite well, though.
It is not, please read the other comments and I'm sure you will understand.That is why I also posted a link to the analogous Java code (again, I did not write it, and it is not generated) performing the same function, and how much cleaner it is - because it has exception handling. The "fix examples" are standard, and there is a "quickfix" library in C++, Java and now Go. It is a pretty decent example of how the "same code" looks in different languages, and all of the implementations are heavily reviewed, and usually coded by experienced developers that understand the problem domain and the language used very well.
The fib function redeclares x. In the same function, the if statement syntax requires a block after the test expression, but there's none.
see https://en.wikipedia.org/wiki/Exception_safety as its basis, and then see https://rucore.libraries.rutgers.edu/rutgers-lib/24257/PDF/1/play/ for how it can be put into practice. The generic error would not be workable (nor to the protocol standard in FIX). There are hundreds of message types, thousands of fields. The standard requires including a reference to the offending field (whether missing, or having data out of range), when it is a field based error. Don't get me wrong, returning a error is fine for trivial programs, but once you get involved in advanced systems, with lots of modules, it quickly becomes unworkable - especially since Go does not have type inheritance... Even when you define all of the possible errors in a 'common' package, it is nearly impossible to check that they are being handled properly, and where they are being handled... Having 'throws' and 'catch' makes this possible, and large systems require it. If you think you could identify and fix the offending client code when dealing with a "invalid message" you have some skills that other people don't posses... Especially when you are not in control or even have access to the server software you are sending the message to...
&gt; see https://en.wikipedia.org/wiki/Exception_safety as its basis (...) I don't see anything about a consensus in these documents. Which committee of computer scientists or software engineers has made such a declaration of consensus or similar? I don't know any. The only thing you did was link a PhD thesis summarising some things about exceptions and a stub article with some things about exceptions. No indicating of any consensus.
&gt; The generic error would not be workable (nor to the protocol standard in FIX). There are hundreds of message types, thousands of fields. The standard requires including a reference to the offending field (whether missing, or having data out of range), when it is a field based error. Don't get me wrong, returning a error is fine for trivial programs, but once you get involved in advanced systems, with lots of modules, it quickly becomes unworkable - especially since Go does not have type inheritance... Even when you define all of the possible errors in a 'common' package, it is nearly impossible to check that they are being handled properly, and where they are being handled... Having 'throws' and 'catch' makes this possible, and large systems require it. If you think you could identify and fix the offending client code when dealing with a "invalid message" you have some skills that other people don't posses... Especially when you are not in control or even have access to the server software you are sending the message to... The entire POSIX standard as well as most of its implementations work entirely according to such a model. If your use case is unworkable without detailed error messages, it appears that there might have been quite a few large design mistakes.
Maybe unfounded isn't the right word. What I meant to say is that Athens accounts for these possibilities and insulates you from them. If a github repo is deleted or taken down, that doesn't delete the copy in Athens. Athens is not a cache in the traditional sense in that it doesn't try to "stay in sync" with the source. If the source is changed or removed, Athens ignores that change and continues to serve the copy of the package it has.
Did you ever find 100% consensus in anything? Does lack of consensus mean one choice is better than another. Empirically, you can look at the fact that almost every (all?) major language introduced in the last 30 years has exceptions - except Go. You can read as many articles as to why exceptions are superior to error code handling, but here is just one, https://docs.oracle.com/javase/tutorial/essential/exceptions/advantages.html that describes the thought process and advantages in detail.
Okay, so there is no consensus. Just some people's opinions.
It is not "my use case", it is an accepted standard. Your citing of POSIX is it a functional specification - meaning it describes functions, so each function returning an error is the simplest and easiest to implement cross-platfrom, and since the basis of POSIX is C, which doesn't have exceptions - it was a natural fit. Still, if your read http://users.ece.cmu.edu/~koopman/ballista/tse2000/tse2000.pdf and specifically the section "5.2 An Estimation of Silent Failure Rate" you will see precisely why exception handling is superior to returning an error code.
If you example is correct, it's probably because http://google.com (WITHOUT the trailing "/") redirects to http://google.com/ (WITH a trailing "/") Note that if you fix that you will still get another redirect from http:// to https:// (in this particular example) 
 go mod why module/path
Free samples are at [https://livebook.manning.com/#!/book/get-programming-with-go/about-this-book/v-16/1](https://livebook.manning.com/#!/book/get-programming-with-go/about-this-book/v-16/1) &amp;#x200B; I am briefly looking at the book.
Cool. If you decide to get a copy directly from Manning, you can use the discount code 42gophers for 42% off.
Can you give an example of how you could write the code in Go in a better way, given that the fields need to be processed individually, and you also need to be able to report back to the sender a failure message when the field is missing, which includes the missing field identifier? I don't think it is possible, at least not easily. The encoding/json package has similar issues and that is why it needed to resort to exceptions, otherwise the error handling code is extremely ugly.
 func (h *House) AddPerson(p Person) { log.Println("Adding person") h.people = append(h.people, p) } h will be updated in tha case, as it's a pointer.
Thanks :) I been a gopher since a crazy Chinese man came into the office and went "we going to write this engine in go" that was nearly 8 years ago. Special love to beego , written by those crazy Chinese people who write good code. 
Get Programming with Go is a beginner’s guide to Go. It’s possible that it will fill in some gaps, but chances are you already know everything it has to teach. If you know others who could benefit from learning Go, it could be a good place for them to start.
I've personally migrated to https://github.com/mdempsky/gocode since quite some time. Never had to look back :)
&gt; Can you give an example of how you could write the code in Go in a better way Well, I already did give one example. Maybe I can try and simplify my point. Since you mentioned it, and since JSON should be easy for anyone reading this to conceptualize, let's use it as an example. Consider the input: const jsonData = []byte(`{"value1": "Go", "value2": 111}`) You could provide a getter to access each value. type JSONThing []byte func (j JSONThing) Value1() (string, error) { v, err := decoder.DecodeString("value1", j) if err != nil { return "", err } return v, nil } func (j JSONThing) Value2() (int, error) { v, err := decoder.DecodeInt("value2", j) if err != nil { return 0, err } return v, nil } func exec() error { j := JSONThing(jsonData) v1, err := j.Value1() if err != nil { return err } v2, err := j.Value2() if err != nil { return err } // If you make it here, JSONThing is error-free. fmt.Println(v1, v2) return nil } Or you could load and validate the values at initialization and once the struct is loaded, you can be sure it is valid. type JSONThing struct { Value1 string Value2 int } func exec() error { var j JSONThing if err := json.Unmarshal(jsonData, &amp;j); err != nil { return fmt.Errorf("error unmarshaling json: %v", err) } // If you make it here, JSONThing is error-free. fmt.Println(j.Value1, j.Value2) } I've looked through the application you linked to and the getters don't seem to do anything but read from memory and worry about the necessary type conversions. It is not clear why they each return an error rather than one error for all of them.
slightly off-topic: I don't know the full context but calling `UpdateCheck1()` and `UpdateCheck2()` in every for loop is probably wrong. In go `select` will only execute one case (the first case that is satisfied), which means for every `UpdateCheck1()` and `UpdateCheck2()` there are at most one of the results will be processed.
Hard to say with just a toy example like this, but nil is valid thing to select against, so I'd probably make `UpdateCheck` take a bool and return nil when you don't want it to run. Alternatively, if UpdateCheck is cheap, then update1 := UpdateCheck1() update2 := UpdateCheck2() if disableUpdates { update1 = nil update2 = nil } Or if the type of the chan is unlikely to change var update1, update2 chan result if !disableUpdates { update1 = UpdateCheck1() update2 = UpdateCheck2() } C.f. https://blog.carlmjohnson.net/post/share-memory-by-communicating/ for more patterns.
I've ~~written~~seen so much Python code like that...
I bought a book. Looks nice for a beginning Go programmer.
It only goes through the next iteration of the loop if an update is received (due to the possibility that many of the variables will change based on the update).
Java's CLASSPATH is horrible. It's painful to make a standalone jar file which you can simply execute, because you can't simply bundle library jars into your application jar and refer to them by relative classpath. There are tools to work around the issue, but they require a dozen or more lines of Maven configuration or similar.
Yea, thanks. I'll probably end up going with something like your second example. I appreciate the help.
[removed]
[removed]
[removed]
[removed]
\&gt; So in Go slices are what referred as **reference types.** &amp;#x200B; Nope. \`func foo(s \[\]T) { ... }; foo(x)\` cannot change \`x\`'s len or cap; what is passed in to \`foo\` is not a reference to \`x\`. [https://blog.golang.org/slices](https://blog.golang.org/slices) [https://golang.org/pkg/reflect/#SliceHeader](https://golang.org/pkg/reflect/#SliceHeader)
Thanks for the suggestion. However to no avail: go: finding github.com/stretchr/testify/assert latest go: finding github.com/stretchr/testify/require latest go: finding github.com/davecgh/go-spew/spew latest go: finding gopkg.in/check.v1 latest go: finding github.com/pmezard/go-difflib/difflib latest go: finding golang.org/x/net/html/charset latest go: finding github.com/golang/protobuf/proto latest go: finding golang.org/x/net/html latest go: finding golang.org/x/net latest go: finding golang.org/x/sync/errgroup latest go: finding golang.org/x/sync latest go: finding gopkg.in/tomb.v1 latest # github.com/golang/protobuf (main module does not need module github.com/golang/protobuf)
json.Unmarshal no longer uses panics: https://golang.org/cl/98440. And its worth noting that the line-delta of that CL is +127, -107. Which negates your point that explicit error-handling is somehow 75% of all code. Its not even a 25% increase in error-handing code alone, let alone all code.
function fib should be written as: func fib(x int) int { if x==1 { return fib(x-1) + fib(x-2) } } Note the braces is a must even if there is only 1 statement in the block, which is different to C-family languages. Also the brackets around the condition is unnecessary. Also, your return variable cannot have same name as the argument, because it will be automatically declared once entered the function. And finally, missing return outside the if block. What if x equal to value other than 1? What should the function return?
Cheers for this resource
Compiling is only one side of the equation. Code maintenance over large periods of time is the other. How easy is it to add a junior dev to your team and have that developer be productive in an afternoon? How easy is it to keep adding features? Go teams have done this successfully. I have never seen that type of low friction in C, Java or PHP. Cannot speak for .NET, since I've never used that, but I expect the friction to be roughly on the same level of Java's.
Worthy of note regarding this though: because there is no inheritance, you can't do an abstract class and delegate a method to a child class. You must use interfaces and composition for this too. Types in Go are "closed" on their own definition and do not guess which other types will include them.
&gt; when 99.99999% of the time there are no errors... This is why bad code gets writen, and is simply not true. Try implementing anything that talks over a network and wait for enlightenment. More than half of the code in those cases is guard conditions. Errors are much easier to deal with in this context. And if you have no errors/exceptions, then it really doesn't matter which one you're using.
I am reviewing the current 1.11 stdlib and it definitely has panics there - see encoding/json/encode.go line 311 so I don't know what you are looking at... so the rest of the assessment is suspect. Furthermore, there is no debating that error returns cause every method call to be 4 lines rather than 1. Still, if you look at the performance numbers you will see evidence of the claim I made earlier that Go has inefficient exception handling - thus the need to not propagate it out into general use.
&gt; And json.Unmarshal uses exceptions... And there is nothing wrong with using exceptions where appropriate. It is why the language includes exceptions. They are there to be used. If you see a valid use for them, why would you use them? &gt; and if you read what I said again, you'll see that the fields are CONDITIONALLY PRESENT. Yes, and? Conditionally validate them. JSON fields can also be conditionally present. You don't have to resort to the first example to deal with them. That would be just plain silly. &gt; So you are back to where I started, write the unmarshal code without an error check at each getFieldXXXX, it is very difficult and ugly code No, we're still on the second example. There is no reason for getters just to validate that a field is present.
Oh that's a great idea! I'm going to try that out. Thanks! 
Thanks, I’ll refresh my memory!
I don’t agree with this rationale. If you’re writing Go it’s tablestakes that you understand the difference between a nil pointer and a nil interface. I’m unconvinced that—if only one error type is possible—it’s better to return the interface and not the concrete type. One benefit of returning the concrete type is that you don’t need to document it; it seems like it could be ideal for Go to have sum types such that you could specify precisely the valid error permutations. The most convincing argument for returning an error interface instead of a concrete type is that it leaves more room for changing the error types, but this seems like an illusion since lots of code makes assumptions about the possible concrete error types, but these unofficial contracts aren’t governed by the type system.
No, you are missing my point. Most people ignore errors because they rarely occur (network errors for instance). With exception based error handling, and explicit error types it is much harder to that, so, more errors get handled. I cited the paper on the problems with the POSIX API that shows exactly that - that "return error" based handling is error prone...
I switched but ran into PANICs on code completion. Seems really unstable; I forget if it was thrown off by modules or what. Best of luck to this critical tool!
You are correct, I was looking at encode.go, my bad. But did you have a look at decode.go by chance? Specially take a look at the error handling, there is code duplication throughout the file... it's pretty bad IMO - and this is a direct result of not being able to throw a typed exception that contains the error (parsing usually) details. Here's just a sample (pay special attention to the d.saveError() calls), and this is just a VERY small sample func (d *decodeState) literalStore(item []byte, v reflect.Value, fromQuoted bool) error { // Check for unmarshaler. if len(item) == 0 { //Empty string given d.saveError(fmt.Errorf("json: invalid use of ,string struct tag, trying to unmarshal %q into %v", item, v.Type())) return nil } isNull := item[0] == 'n' // null u, ut, pv := indirect(v, isNull) if u != nil { return u.UnmarshalJSON(item) } if ut != nil { if item[0] != '"' { if fromQuoted { d.saveError(fmt.Errorf("json: invalid use of ,string struct tag, trying to unmarshal %q into %v", item, v.Type())) } else { var val string switch item[0] { case 'n': val = "null" case 't', 'f': val = "bool" default: val = "number" } d.saveError(&amp;UnmarshalTypeError{Value: val, Type: v.Type(), Offset: int64(d.readIndex())}) } return nil } s, ok := unquoteBytes(item) if !ok { if fromQuoted { return fmt.Errorf("json: invalid use of ,string struct tag, trying to unmarshal %q into %v", item, v.Type()) } return errPhase } return ut.UnmarshalText(s) } 
From the [go 1.11 release notes](https://golang.org/doc/go1.11): &gt; If you encounter bugs using modules, please file issues so we can fix them. For more information, see the go command documentation.
Understanding the difference is very important yes. However, you will break just about every package which accepts error interface. The particular issue I've seen many times is that someone returns the concrete type, the caller knows it's concrete type, but it's passed into a function for processing errors. Since the interface type was not nil, there was a bug. If you want a footgun, you've got a footgun. Updated example to show the danger better: https://play.golang.org/p/D5djq7xK3_l
From Gophercon
&gt; and the programmer has no need to detect this error condition ... removing lots of boilerplate code This is contradictory to your code example posted earlier. The caller had to check the error condition on every call to access a field. You're simply pushing the boilerplate to the caller. Maybe you've mixed up languages here, but we're talking about Go, not Java. Why is accessors returning errors the best solution here?
Link to slides themselves, instead of twitter link to slides... https://docs.google.com/presentation/d/1BzhCRi0VmOj-sJSqzxc1i5GyuNNQG3QPazzkP8NFf2g/edit
I was referreing to when coded in Java - since the call "the getter" would throw the MissingField exception, and the upper layers catch it and process it correctly. In Go, you cannot do this - each call to the getter (get the field from the map/object/whatever) needs to check if it was found (since it might not be there - it is optional so the base parser cannot enforce this), and then return the error. Lot's of boilerplate.
Thanks for the live stream
This. I wanted to learn how to do it as well. Coming from python3 getting go up and running was like 100 times faster for me. 
With respect, this isn’t breaking anything. It’s simply how interfaces work in Go. This is admittedly tricky, but it’s part and parcel of using the language. Perhaps there is wisdom in reducing the frequency with which someone might run into this—in which case you could avoid returning a pointer type or perhaps not make it implement the error interface at all (although I’m inclined to think this latter case would be a mistake) or return a pointer but make the Error() method take the receiver by value so the caller has to dereference before putting it in the interface (making it an immediate panic if used improperly). I’m not advocating for any of those in particular, just highlighting that there are other options to consider if you’re really concerned.
Of course they have done it successfully. The language is barely 10 years old and most of the projects are even younger than that. Just wait 10 years more and the language getting C, Java, .NET like market share.
I have a very hard time structuring my go projects. I never achieve something I'm content with that feels idiomatic to go.
&gt; But you have to manually ensure you don't have too many nor too few threads, as your performance will suffer either way. naive concurrency in Go also dramatically hurts performance. I think I remember seeing someone who was going to make _a super fast_ text searcher by having it spawn a goroutine per line of input. You can imagine how poorly that went. Try not to sell Goroutines like snake oil.
For anyone curious, [vscode-go](https://marketplace.visualstudio.com/items?itemName=ms-vscode.Go) is using [mdempsky/gocode](https://github.com/mdempsky/gocode) [1][2][3][4]. [1] https://github.com/Microsoft/vscode-go/issues/1645 [2] https://github.com/Microsoft/vscode-go/blob/f45e4d2/.travis.yml#L41 [3] https://github.com/Microsoft/vscode-go/blob/f45e4d2/src/goInstallTools.ts#L19 [4] https://github.com/Microsoft/vscode-go/blob/f45e4d2/CHANGELOG.md#0682---6th-june-2018
Just switched to https://github.com/mdempsky/gocode seems to work fine. I wish it had unimported-packages feature like nsf/gocode had. Any other solutions for this? I like when I can get auto-completion before I actually add import statement.
yeah... me too, I'd like that. (this was a bit the hidden agenda behind this reddit post: have people flock to mdempsky's fork and bring back what has diverged between the 2 codebases :P)
[https://github.com/tonyghita/graphql-go-example](https://github.com/tonyghita/graphql-go-example)
There is no point bikeshedding over it too much.. 
you can propagate exceptions to the proper layer with no additional code in languages with exceptions. robaho99 probably meant this.
&gt; function fib should be written as: If it's meant to compute the x'th Fibonacci number then I don't think so ;-) 
Thanks for the tutorial! The index.html file on your website got an error: The id of the button is "myButton", the js script is searching for "runButton" and the wget [...]wasm_exec.js is downloading the github html page, not the wasm_exec.js file. 
The hero we deserve
ooo, I really like that you made this with webview! It really seems to be a fantastic library. I did try out the examples they have, but I just don't have much reason to write desktop apps very often.
[removed]
Isn't idiomatic way to Iterator through the chan?
[removed]
I agree. If you don’t get that the error code handling duplication is the same argument that the error handling is broken in Go because every error handle takes at least 3 lines per method call, then yes, this discussion is pointless. 
Whats wrong with the following? mvn org.apache.maven.plugins:maven-dependency-plugin:2.1:get -DrepoUrl=url -Dartifact=groupId:artifactId:version
Awful, I'm sure. Don't do this, folks. Use GLFW and gogl, or the Go SDL bindings.
 type Lister interface { List(v1.ListOptions) (interface{}, error) } type API func(Namespace string) Lister apis := []API{ c.ConfigMaps, c.Deployments, ... }
It's great to see the author use appropriate type names all over this presentation, especially with regards to using the package name for context. This is something I feel a lot of Gophers can struggle with when coming into Go, so having material like this around is a great reference for those people. Thanks for sharing.
&gt; I was referreing to when coded in Java But I asked about Go. r/java is over there. Again, why, in Go, do you prefer to check the error every time you access a field as shown in your example code?
[removed]
Worse than Electron?
It's basically the same as Electron. I suppose it might be a little better on disk space but clients like Steam are just going to ship all of your dependencies in a hermetically sealed container anyway.
Yep, just tested it. Really bad performance. Then again, expected as we're using HTTP for a stream of all game events. 
Holy Generics Batman! I am going to celebrate for sure.
More readable: https://github.com/golang/proposal/blob/master/design/go2draft.md 
What would you recommend? Websockets?
&gt; but I'm certainly not the only one to disagree with the hesitance to abstract dependencies using basic interfaces. Never said you where :)
For retrying with multiple strategies, including back-off with jitter, may I not-so-humbly suggest my library: https://github.com/Rican7/retry
&gt; 2) Why a video was used for important announcement about Go2 instead of in-person presentation in key note session? Because Russ does not have time to atend GopherCon this year. And (I guess) it was felt that as the Go tech lead he should be the one to talk about them anyway.
Easier is a matter of perspective. For you? Yes, that would make things easier. For a system admin who doesn't know anything about Go, and wants to install your program on 50 machines, not so much. That user will be overjoyed that the go tooling pushed you towards bundling everything into a single runnable binary. They can just download a prebuilt executable (if you provide one) and simply copy it onto every machine. They didn't have to learn anything about Go to install or use the software. Single deployable binaries are many people's favorite thing about Go, and that concept is clearly at odds with external configuration files. Java [has this problem too](https://stackoverflow.com/questions/2232602/java-jar-access-external-configuration-file) when it tries to bundle to a single deployable Jar file. Because of this fundamental conflict, most go programs don't use configuration files at all. Instead, we generally prefer using command line flags and environment variables to handle our configuration [12 factor app style](https://12factor.net/config). I would have recommended this to you, but I took a peek at your code, and noticed that quickfix all but requires you to use configuration files.
Hi author here, I continually am running into problem of detecting service initialization in the context of ci and Docker containers and created this library to help and centralize application specific initialization detection. I would love to see your thoughts and welcome any and all contributions. Go was the perfect language for this utility Thank you for reading
Even more readable: https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md 
The blog post and video give a short intro/overview. Here's the proposal docs - https://go.googlesource.com/proposal/+/master/design/go2draft.md
You mad bruh? On a serious note, give it a shot. Who knows, maybe it will turn out to be good. Let us reserve judgement to release date.
It's a substantial limitation for e.g. Apache Beam implementation for Go. There are probably dozens of other projects in the data space where it's a similar case, and people opt for Java or Python instead.
1. Gophercon, like many conferences these days, is split into "keynote sessions", which are talks in the big conference room that everyone attends, and three parallel tracks of smaller talks, which compete with each other but not the keynotes. The Go team does not always have a big talk, nor even open. The opening keynote talk this morning was by Kavya Joshi and I'm sure it was fantastic. Can't think of anyone better to start the conference. https://www.gophercon.com/agenda?dates=1535414400000. Similarly, the closing by Natalie Pistunovich is also going to be great. I'm thrilled to see such great talks from the community. 2. Gophercon is at a really terrible time for me this year, being right near the start of the school year. I'm home taking care of my kids this week (not at work). Sorry I wasn't there in person. Yesterday at our annual contributor summit there were a bunch of in-person presentations for the core contributors who could make it, basically walking through the docs.
I'm posting this separately from the current links to maybe get the video into more feeds. The video is the right starting point for people who want a very very quick overview of the error handling and generics changes.
[removed]
 Thank you for your reply.
I must say, I appreciate reading these drafts. I've felt my opinions of Go's error failings were largely ignored in these types of discussions. Namely that, my opinion is that context is king here, and Go needs to help. Reading this document *(in the two error drafts)* made it clear that they share and acknowledge what I identify as a/the problem; and while the eventual solution may not fit what I think it should be, it was made with recognition and understanding of the problem(s) as I see them. That is especially helpful to see.
Not on mobile. GitHub is much more readable if you're on a phone. 
I have a similar feel. I programmed enough Haskell to know this Siren's call.
My heart skipped a beat just thinking of the lines of code that I don't have to repeat with the new error handling design.
Try the GitHub version. https://github.com/golang/proposal/blob/master/design/go2draft.md
[removed]
Even more more readable: http://golang.org/s/go2designs
Contracts seem very similar to traits in Rust. Is there much of a difference? Pretty excited about this generics draft. Does anyone have a rough idea of when this proposal might be finalized, implemented, and usable?
I really have no clue about why generics is such a big deal, byring an amateur programmer, but I kind of want them in so I don't have to keep reading other people complain about the lack.
That's completely new language...
[removed]
They stress that it wont be. We wont be having a python2/3 scenario. It will still be backwards compatible which I think is fantastic. You can carry on writing your Go code like you do today, but you might just find some helpful refactoring and handy generalised data types like sets in the standard lib to play with Overall it's fantastic news
It is fantastic news, that's for sure.
The defining of "T" is ugly in \`Sum\`. contract Addable(t T) { t + t } func Sum(type T Addable)(x []T) T { var total T for _, v := range x { total += v } return total } I'd rather something more explicit like: func Sum(x []Addable) Addable { var total Addable for _, v := range x { total += v } return total } Possibly with some indicator that the type is a contract type: func Sum(x []$Addable) $Addable { var total $Addable for _, v := range x { total += v } return total } // OR func Sum(x []\Addable) \Addable { var total \Addable for _, v := range x { total += v } return total } Or (my favorite) something pre-function-name and not parenthesis like: func (mt *myType) {type T Addable} Sum(x []T) T { var total T for _, v := range x { total += v } return total } &amp;#x200B;
[removed]
The thing is that once you add generics, a lot of patters are now subject to change. For example, the old func doSomething() (string, error) { return "", errors.New("Error") } You can do something like func doSomething() Result(string, error) { return results.Error("Error") } So the whole `handle` could be literally handled like `?` in rust (if it's an error, unwrap and pass up). It seems like a much cleaner way to do things (no action at a distance).
Despite their drawbacks, they bring more type safety, more efficiency and less redundancy (so, less bugs during maintenance, for instance).
You can do something like this: type Person struct { name string coolness map\[string\]bool } &amp;#x200B; func NewPerson() \*Person { p := &amp;Person{} p.coolness = map\[string\]bool { "cool": false, "poser": false, } } &amp;#x200B; so you can just call the \`NewPerson()\` function to initialize your function.
Hi! to create a struct in Go you can do something like: ``` s := Person{coolness: ...} ``` If you want to create the struct and later fill in the data, that is possible too. I've created a quick sample for you on Google Playground that might be useful: [https://play.golang.org/p/0BT-dW8c-xh](https://play.golang.org/p/0BT-dW8c-xh) Good luck!! &amp;#x200B;
My current vote of #3 would possibly result in this: type Set(type T Equal) []T func (s Set(T)) Find(x T) int { // and for "Sum" in the previous post var x []int total := Sum(int)(x) instead being this: type {type T Equal} Set []T func ({T} s Set) Find(x T) int { // and for "Sum" in the previous post var x []int total := {int}Sum(x) &amp;#x200B;
Thanks, thought something like that. Is there any reason I should do it that way rather than (something like) func (p *Person) NewPerson { ...} What I've read uses the syntax `func (t thingType) funcName() {}` a lot, and I don't quite get it. Is that like a JavaScript callback, kind of? Is it defining an anonymous function with params (t thingType) to return a function funcName?
Where you're doing \`defer incoming.Close()\` in that \`for{}\` loop... that deferred function never gets called. 
So in the error handling document: https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md I notice in the sample code statements like this: defer r.Close() Which, as I understand it, is not completely correct either, because the Close() can also return errors that ought to be checked. Here's a blog post that goes into greater detail: https://www.joeshaw.org/dont-defer-close-on-writable-files/ According to the draft spec, check cannot be used inside handlers. https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md#summary
Probably unpopular opinion here: my favorite part of Go was its readability for humans. To be honest, punctuation and combinations of them are not intuitive to humans. A good example to illustrate this point is Scala. In my opinion, Scala's syntax is absolutely an abomination, and this is mostly because a lot of the operations in Scala are done by weird punctuation instead of English words. Python is nearly the opposite: I can nearly write a program in plain English and it is very easy to read and parse, but Python is not my favorite mostly because of its execution speed and dynamic typing. I was reading the generics of this proposal, and the proposed syntax reminds me a lot of Scala. In addition, a few new concepts were introduced into this proposed Go 2, which will translate to increased complexity in a relatively small language. I personally really don't understand the need of generics in Go. I came from a C background (with Java as well, but I hate it). I understand that system programming is completely different from consumer/enterprise application development, because the former mostly abstracts the machine only, while the latter abstracts human activity--two totally different domain, complexity, and logic. If Google's intention is to make Go more commonly used in application development instead of system programming, I can understand this move, but I still don't like the added complexity. Just my two cents. 
These make me super happy. I'm glad the core team is tackling these issues while trying not to break the entire eco-system. Generics, better errors, and a more modular std lib and I'll be super happy. 
Aside from posting your code, you can try using the blocking and goroutine profilers to see what your application is doing : https://github.com/golang/go/wiki/Performance Be aware that the way you break up your work has an impact on how effective concurrency will be over a serial approach. If you try and spin up a goroutine for every unit of work, and that unit of work is cheaper than the cost of the goroutine with the channel communication overhead, then you are just going to slow your process down. If you have 10000 very fast tasks that you want to do concurrently, you may want to divide them into chunks and use a fixed number of goroutine workers, so that the workers are not starved for tasks as they finish the previous one and wait for the next communication. 
Is it only me that finds the new generics proposal a parentesis nightmare? It really hurts the readability of code having things that look like a function but are not a function. the authors themselves have to repeat several times that it looks like but it's not. Why not use angle brackets? just to be different? 
Prepare to get your mind blown: try { someFunction(); someOtherFunction(); moreFunctions(); iCanGoOn(); andOn(); andOn(); } catch (SomeException e) { /* error handling here */ }
Sorry .. :D I'm rough!
I would guess it's due to parsing ugliness due to confusion with less-than and greater-than operators? Obviously, other languages worked around it, but perhaps they preferred to avoid it. I kind of like Julia's workaround where they use curly braces.
done and updated on git
thank you for the clarification. that is a valid concern, i just wished that it would be possible to avoid hurting first glance readability. 
The way you illustrated wouldn't make much sense. The syntax func (t thingType) funcName() {} is just a way to define a member function on the thingType struct. It's nothing like an anonymous function or a JavaScript callback. t is not a parameter of funcName, it's the receiver of funcName (the type that the function is being defined on). Think of this equivalent JavaScript code: class thingType { funcName() {} } So your example for func(p *Person) NewPerson() ... would translate to roughly this in JavaScript class Person { NewPerson() { // ... initializaiton logic here... } } Which wouldn't make much sense given that you're doing initialization (something you'd use a constructor for in JavaScript). 
 * You can use interface{} to fill the use case of generics, but this approach is not type-safe. Your program can compile successfully but fail with type errors at runtime, which is obviously bad. * Duplicating code (aka "just copy and paste it") can fill the use case of generics, but duplicated copies of every valid class for all custom containers leads to a massive amount of noise in the codebase and is horrible to maintain. * Type checks at runtime add performance overhead. Checking those types at compile time is a performance optimization. * Type checks are noise. Compilers can automate this process, so why does Go make its programmers waste time reading and writing manual code to do these checks? 
I'm going to assume checking `Close()` on normal files are pointless until someone shows me an actual example of it causing problems. Nobody check the close system call in C and there's no reason to assume Go does things differntly. If what you actually have is some sort of buffer or network handle or an unknown io.Closer, then obviously you need to check Close(), but not for normal files. 
For `coolness["me"] = true` is `me` already supposed to be defined, or are you defining it right there? I've also updated my post with a couple other questions if you're still around, etc.
Big shout out for this great write-up by Russ. I'm half way trough and it's just amazing how much effort must have gone into this.
OK, here is a link to the same application in C++, Ruby, and Python... none of them require the verbose error handling of Go - its not the way the application is coded, it is a limitation of Go - I don't know how many times I can explain to you that it has nothing to do with the architecture - it has everything to do with the fix protocol - or any protocol that has dynamic message formats, and complex processing rules. Here (look at the "executor" in each directory): https://github.com/quickfix/quickfix/tree/master/examples/executor
[removed]
I guess... I wonder though if there was a Go version of MySQL would the mysql.conf be embedded in the binary? Seems doubtful. I guess the only thing to do is to pass a -path argument to the binary to state where to look for configuration files. I still think there is a problem between what "go" does and the packaging - which is sort of where I started... it seems that Go wants the packages to be accessible remotely, and it does the work of building the binaries, but it is missing the packaging step... The only way I can see to do this is to have people download an "installer" that includes the binary and the config files, and then asks the user where it wants to go, etc. pretty old school, and it is not really the "Go way" since Go would prefer to build the binaries itself. Kind of half-way in, half-way out... IMO. I appreciate the simplicity of Go, but it just seems like it is forcing people (or projects) to go it alone, and/or re-invent the wheel, for something that would be pretty straightforward to add to the Go platform. Just MO.
No problem - I remember having similar confusion when I first started
I see many issues in your example, for example your map is not safe.
I definitely agree with your argument here, but there is also truth in /u/1024KiB's too. I can almost guarantee that on the day of Go 2's release, if there are generics, there will be several FP libraries. Now, whether or not the majority of people actually use them is a completely different matter... 
Not exactly sure what you are looking for, but you might find this helpful: https://github.com/TrueFurby/go-callvis
Definitely agree with this. If generics go in, then the error handling mechanism should take it into account. I can't say I'm looking forward to that new way of error handling, thankfully there should be plenty of time for discussion and alternatives.
&gt; that is an important property to preserve why?
Current proposal would allow stuff like this: func MyFunc(type T, S Addable)(x []T, y, z S) T { func MyFunc(type T, Addable)(x []T, y, z T) T { How would you write both in #1 or #2 ?
I do agree about Scala's syntax being pretty horrible, for the same reason you mention about methods being punctuation, rather than readable words (and really, the main problem is a lack of consistency or... sense... for most people). However, despite generics looking sort of similar in this proposal, it does look _far_ simpler here. I'm personally in the "you probably don't need it camp", but I can see why people want it. It will enable some interesting code without code generation, I just hope it doesn't affect the type of code people write day-to-day. I find generics very usable for their common use-cases, but I have also seen them be completely abused. I think there's a line that shouldn't be crossed with abstraction, and Go and it's community has kept quite far away from it for the most part, and I _love_ that about it - that's what I hope remains.
One thing I noticed which is really interesting: ``` func Sum(type T Addable)(x []T) T {} Sum(int)(arr) ``` This reads almost like function decorator: "create a function `Sum` where the input is of type `int`, then apply `arr` to that new function". Obviously this isn't what is happening, but once you read it like that it kind of makes sense, from the caller's perspective. But the caller can also elide that type spec, so this point is kind of moot. 
The extra symbols and/or blocks of code in there are really gross. I would prefer the implementation to be simple and understandable without loads of random symbols or bloated function signatures. Perhaps that's none of those options, perhaps it's option #0.
A basic version would be: contract Error(x T) { var _ string = x.Error() x == nil } type Result(type T, E) struct { val T err E } func (r Result) Unwrap() { if err != nil { panic(err) } return val.T }
I can't think of a more pleasant manner (and it's not very pleasant): For #1 func MyFunc1(x []Addable$1, y, z Addable$2) Addable$1 { // OR func MyFunc1(x []Addable\1, y, z Addable\2) Addable\1 { eww. &amp;#x200B; For #2 func MyFunc1(x []$Addable\1, y, z $Addable\2) $Addable\1 { // OR func MyFunc1(x []\Addable$1, y, z \Addable$2) \Addable$1 { damn, that's really bad. &amp;#x200B; For #3 (still my favorite) func {type T, S Addable} MyFunc1(x []T, y, z S) T {
Why are these go routines not exiting? ========= ========== ========== 61001 - # goroutines: 202 Client Connections: 70 Memory Acquired: 255 MB GC: true Last GC: 1535491807288866410 Next GC: 256 MB Heap Alloc: 193 MB ========= ========== ========== ========= ========== ========== 61001 - # goroutines: 206 Client Connections: 71 Memory Acquired: 255 MB GC: true Last GC: 1535491807288866410 Next GC: 256 MB Heap Alloc: 227 MB ========= ========== ========== ========= ========== ========== 61001 - # goroutines: 212 Client Connections: 70 Memory Acquired: 269 MB GC: true Last GC: 1535491827348520907 Next GC: 280 MB Heap Alloc: 155 MB ========= ========== ========== ========= ========== ========== 61001 - # goroutines: 215 Client Connections: 70 Memory Acquired: 269 MB GC: true Last GC: 1535491827348520907 Next GC: 280 MB Heap Alloc: 186 MB ========= ========== ========== ========= ========== ========== 61001 - # goroutines: 220 Client Connections: 70 Memory Acquired: 269 MB GC: true Last GC: 1535491827348520907 Next GC: 280 MB Heap Alloc: 219 MB ========= ========== ========== ========= ========== ========== 
I had thought so too, but I was just emulating the format of option #0 in that expression.
Go was the most awesome language I'd ever used before. This is just gonna blow my mind apart.
Looks like. 
The curly braces (#3) improve delineation and add no additional character versus the proposal (#0). Aside from that, moving that logic to before the function name makes the function definition more legible.
Nope. You need both generics and variant types for that. Maybe in Go 3.
Another thing that kind of gets me very anxious about the proposal to add generics, is that in a certain sense I'm kind of happy that basic types are "magical". For example, right now `map`, `array`, `string` are magical, in that you can't create a "competing" map, array, or string[1]. What this means is that unlike C++, where the STL isn't magical (I can create my own STL), there is only one standard library, with one basic array type. Contrast this to C++, where you have the STL and Qt both coming with their own basic types [2]. [1]. Actually, you can. You can fork the compiler. But as long as you use "Go", you're bound to use the original, standard, types. [2]. Though C++ had it worse, since Qt actually came out with their types before the STL was usable. So it's the STL stepping on Qt's feet rather than the other way around.
You'd probably generate such code.
&gt;... if there are generics, there will be several FP libraries. There are several FP libraries for C# and Java. That doesn't mean they are very used or that codebases are full of "insane complexity". There is not truth there. Just FUD.
Actually I am more of a C programmer, but thanks for ignoring my points anyway.
simpler/faster parser.
No because I'm calling the bullshit and FUD on that guy's comment and stating that what he said contains no truth at all.
Not even a log?
Well, there is some truth though. You're right that that ability to write functional programming libraries won't make Go a functional language, but I can also guarantee that there'll be people who will try, who vouch for it's viability, and some poor saps are going to have to work with these people. It will happen, guaranteed. Maybe not in huge numbers, but they'll be there.
check, mate.
[removed]
Which code? I have used generics a few times but never made a monad (knowingly) &amp;#x200B;
[removed]
Yeah but that's not related with what that guy claimed. He literally said that codebases were going to "devolve into intractable codebases" because of generics. Having some guys playing tricks with language features (something you can find for C, JS, Python, C++, Java, C#, etc.) won't back up that claim or adding some truth to that. It's the definition of FUD.
I do agree with what you're saying there, yes. Perhaps I should have just made my comment without referencing that other guys. My true view is what I've been discussing now with you.
One neat thing about Go's current error handling is that while verbose, the flow of the code is very clear because error returns are indented. I guess syntax highlighting on the `check` keyword will be good enough to replace this though.
System programming in C++ is full of generics too. Generics is not about "enterprise programming". It's about increasing type safety, performance and reducing the number of lines you need to accomplish something.
https://media0.giphy.com/media/l41YktuUJjzzOshri/giphy.gif
Go 2 considered...generic?
Isn't contract just an interface? Other than being able to support things like addition or equality, etc. (which could be defined as methods in an interface anyway), how else do they differ?
This is really, really well thought out. While it is only a draft and a discussion starter, I am quite happy with their proposal of the `handler-check` approach. It very neatly fits most of what I've been missing and I like it with no immediate reservations. With regards to `error values`, I kind of don't like that the functions `errors.Is` and `errors.As` are kept in the errors package.. It kind of feels like how `error` was once in its own package. But I also get the hesitation to introduce a new keyword to the language.. I've always thought something like this would be a bit nicer, but I get the fact that we don't want to overload the simple `error` interface: ``` err := failing_function() if err.Is(io.EOF) { ... } ``` But I also think that the sentence "errors are not exceptional, they are expected" might actually warrant a discussion of introducing a new keyword to make this just a tad bit easier on the eyes. It is a lot better than the current status quo however, as the proposal repeatedly states. The syntax of generics is very intriguing, It does get a bit much with all the parenthesis, but I love the idea of contracts as a way of defining generics: ``` contract stringer(x T) { var s string = x.String() } func Stringify(type T stringer)(s []T) (ret []string) { for _, v := range s { ret = append(ret, v.String()) // now valid } return ret } ``` I am very excited about pretty much all these proposals. 
Nice little library you put together. &amp;#x200B; Are you familiar with [https://github.com/jwilder/dockerize](https://github.com/jwilder/dockerize) ? I hate to see resources wasted, so whenever I see signs of duplicated work, I urge people to work together if it's possible. &amp;#x200B; One thing I would recommend is explaining your use case in the readme. I believe in the containerized world (and in the distributed computing world in general) you can have no assumptions about external services upon initialization. Resources come and go and until you need them there is no point in waiting for them. For example: if a database is down and you restart your application it wouldn't start until the database or the timeout is up. That would mean your application is down as well. Your application can easily be abused for things it's not meant to do, explaining the use case that ended up being the application helps others avoiding that. &amp;#x200B; &amp;#x200B;
What exactly are you looking for? Code/file structuring?
&gt;Basically what it means is that I'm adding a new entry to the map with the key "me" and the value "true". Okay, actually all that was confusing me there then was just the example "me" sounding like a particular person rather than that it could be `coolness["cool"] = true`. So I knew it would be like `type Person struct {coolness {"cool" = true}}` but having for Person `coolness{"me" = true}` jarred me. That means it wouldn't be some kind of name error where it's not defined because it's like in python `coolness["whatever"]=True`. &gt;for your second question, you're kinda mixing up what a struct and a map is (which is something I found difficult too). A map is basically a key/value store where you specify up front what type the key will be (like a bool or a string). A struct is basically a collection of fields. So for your example you'll have something like: ``` type Person struct { name string cool bool numToes int } &gt; &gt;p := Person{name: "Aloof", cool: true, numToes: 10} Well, I got the difference between structs and maps, but I'm wondering when you're creating a struct with fields that are maps, how would you initialize those maps within the struct with keys having various different types of values, like type Person struct { coolness map[string]bool ... where `coolness` is a map with different types of values. With the map I want to initialize in that struct a analogous python dictionary would go coolness = { name: "Aloof", cool = True, numToes = 10 } which I could put in a list of dicts or something. 
1. bigger compile-time, bloated executables, lack of type information at runtime (type erasure): pick your poison(s) 2. the language is more complex, so longer to learn, and it's harder to make/update tools for the language (linters, IDE plugins, etc.) 3. when they are abused, code becomes cryptic (see C++ Boost, for instance) or at least hard to read, with absurdly complex generic types (types like [Vec&lt;Rc&lt;RefCell&lt;Box&lt;Trait&gt;&gt;&gt;&gt;](https://www.reddit.com/r/rust/comments/33jv62/vecrcrefcellboxtrait_is_there_a_better_way/) in rust for instance) and cryptic compilation error messages (C++, again). But the advantages generally outweight the drawbacks, IMO, so I'd rather have them.
For generics, I wonder why they can't just have more builtin interfaces similar to Python's magic functions (`__eq__`, `__attr__`, etc.) type T interface { Add(T) T // for + and - operators Index(i int) // for slice[int] indexing Set(i int, v interface{}) // for slice[int] assignment } type Color struct { R uint8 G uint8 B uint8 } func (c Color) Add(v Color) Color { c.R += v.R c.G += v.G c.B += v.B return c } // then you can do like var ( red = Color{255, 0, 0} blue = Color{0, 0, 255} magenta = red + blue )
On the one hand, I'm disappointed that sum types aren't being added (or even investigated), on the other hand, the check keyword almost makes up for it. 
There's the but where they demonstrate trying to cast to a particular type, that I don't believe you could express with interfaces
I assume this is go orphaning them due to the for loop not having a wait group?
Someone that doesn’t understand what genetics or why anyone wants them will not understand any of these bullet points. 
If there is no mutating going on, it sure seems like that would greatly benefit from using goroutines. Really the only way to tell for sure is to benchmark it. 
I’d say use a channel. You can spawn as many goroutines as you want to consume the data from the channel and do the work.
&gt; What if you want to handle the error in some way other than unwrapping it and passing it up, though? Then you can if res := doSomething(); !res.Success { blah := doSomethingWithErr(res.Error()) return blah } finRes := res.SuccessVal
You don't have to wonder, [cockroachdb](https://github.com/cockroachdb/cockroach/blob/master/README.md) is a fairly popular SQL db implementated in Go. It doesn't use configuration files and instead does all configuration through command line parameters. https://forum.cockroachlabs.com/t/configuration-files-with-cockroachdb/506/3 I'm sure that coming from a Java background, not having config files seems really weird, but at the end of the day there are many different ways to configure an application, and at the end of the day, they're all functionally equivalent. Java encourages config files, while Go encourages env vars and cli flags. In both Go and Java, fighting the language will make your life harder for Bo reason. Instead, try to just keep an open mind and see where the language leads you. You will learn much more that way.
&gt; I've given plenty of reasoning of why it is a problem. Why what is a problem? Have you, uh, read my comments at all? I didn't ask why anything is a problem. I asked why you think using getters that return errors is the preferred design pattern given the current state of Go. This has nothing to do with how errors are currently handled, or may be handled in the future, or how you might implement code in another language. It is simply about how you would attack a problem in Go today. Using the current specification, not a future specification. Again, why do you believe getters that return errors is the best pattern for solving this problem over the multitude of other was that the same problem could be approached with?
Not only that but C++ is not the only language with generics. No C# or Java developer create his own data structures just for the lulz or use third-party libraries for that because of some 0.1% improvement. Really, you just need to come here to see how retarded are the arguments against generics talking about things that are not happening in real life in other programming language communities.
Just a quick complain here: contract Graph(n Node, e Edge) { var edges []Edge = n.Edges() var nodes []Node = e.Nodes() } func ShortestPath(type N, E Graph)(src, dst N) []E Isn't it look bit redundant? Why \`(type N, E Graph)\`? Can't it be just \`ShortestPath(N, E Graph)\` or \`ShortestPath&lt;N, E Graph&gt;\` to distinguish from function parameters?
If it's a training what the point of randos helping you find the solution? Isn't the job of your instructors? 
The type keyword presumably is there to eliminate the ambiguity about whether the paren group it's parsing is giving type parameters or a regular function parameters. I'm not sure why they opted to use () instead of &lt;&gt;, though. There is, presumably, some reason, but I didn't see any explanation given and it is not obvious to me.
job is for pen testing, not for golanguage tutorial. and part of the training is leveraging "resources" to help. though reddit was a great resource...
If your database support JSON aggregation functions then use that to return multi-dimensional data in one query. Otherwise query for instances, grab the ids and and use where IN to fetch the related back up.
I have an open mind, the code I'm writing now doesn't need config files, but something like fix, in many ways, the config files are the "code" - so shipping and finding the default files (even as a admin) to start with, and then placing in a known directory and setting the -path option to find the files is fine... but the admin finding the initial default files is the problem... 
&gt; I'm not sure why they opted to use () instead of &lt;&gt;, though, avoiding the ambiguity altogether. Because it introduces new ambiguities: `x := Foo&lt;Bar&gt;(Baz)` -- is that a call to `Foo&lt;Bar&gt;` with argument `Baz`, or an expression with two binary operators? The latter wouldn't compile, but that would happen in a separate pass than parsing (plus, I assume there are even simpler cases that make more sense). I think we should trust that there was a lot of thought put into the syntax here :)
Ignoring a return value (including an error) in go results in the compiler refusing to eat your code (unless you do `x, _ := getValAndErr()`, but has the same smell as `try {...} catch (Exception e) { /* do nothing */ }`). So it works like a checked exception. Most people ignore errors because they don't think error first and they don't do TDD. Whether the error occurs frequently or not is totally irrelevant. Code which does not handle errors is not correct, because it will eventually fail during operation, and that is the programmer's fault, not the language's. Of course, the compiler (and thus the language) can help you by trying as hard as it can to make sure you check your errors/exceptions and thus nudge you in right direction.
&gt; I'm going to assume checking Close() on normal files are pointless until someone shows me an actual example of it causing problems. [see here](https://manpages.debian.org/stretch/manpages-dev/close.2.en.html#Dealing_with_error_returns_from_close()). C code is not a great example for how to error check. For example, lots of C code doesn't check errors on `write` (or `printf`) either, because writing to a closed pipe will send a `SIGPIPE`, killing the process by default. That's one of the mechanisms making shell pipelines abort if any part of it starts failing (so it's generally considered a good thing). There's also, FWIW, a bit of a difference between Go's `(*os.File).Close()` and C's `close` (the former wraps file-handles, does some additional work to make green threading work and also does more checks). That being said, I tend to use `defer f.Close()` myself regularly, but I combine it with a second, checked `Close` later. Make sure to clean up the fd, but still check for the error at least once. Note, that the example code does that too, where necessary.
It was creating tons of orphaned go routines - which from what I'm reading don't get reclaimed. So I implemented a wait group., using docs and examples. That broke the real-time dataness for whatever reason. Even though I should be sending data concurrently using go routines ... Then there is the connection map that saves the net.Conn of the incoming connections - map doesn't support concurrency, so I added a lock per the docs/examples. Also broken my code and no more data is sent. ugh ... 
orphaned goroutines get cleaned up when they exit on their own. if they don't exit (return from whatever function, not os.Exit) then they are allowed to keep working. I didn't notice any reduction in "realtimeness" when I was playing with the version with waitgroups. it really seems like you're overthinking this. I also don't think the connection map should be a map. It just needs to be a slice/array. But you shouldn't try modifying any data structure as you're iterating over it.
You’re probably using the wrong data structure?
if I have time, I might think about the task and see if I can come up with an alternative implementation
I was thinking that it really should just be an array of connections. I get the len - loop through them .... next iteration when there are more or less connections ... rinse and repeat... any help is greatly appreciated ... the project this is for is adsbexchange.com We need to replace out public data stream with something that can handle more connections. I'm confident Go can do this - it excels at routing data. 
&gt;Really, you just need to come here to see how **retarded** are the arguments against generics How about we leave out ad hominem? People care about Go and are putting forth what they think are valid concerns. No need to call their arguments retarded. 
I'm interested. 
Basically it will sit on our server - connect to a TCP stream from VRS (http://www.virtualradarserver.co.uk/) that outputs the Aircraftjson at varying intervals. VRS is mono and chokes at about 75-100 connections. The hokey golang app I built so far is using very little CPU and handling upwards of 150 client connections. I think it's close.
ah, right; I was only thinking about the declaration context.
I tried to lock the map using a mutex? I probably didn't do it right as the examples are few and far between. The map is the hang up right now. I'll try to use an array, saving the incoming net.Conn into the array so I can iterate over it. Assuming I can pass this as a point in time array of connections. 
yeah, I've been thinking about it more, and the map might make sense just because it's always the same cost to add or delete from it. If you use a slice, it can be expensive to delete an element from the middle or beginning.
But with the map blocking it might add a lot more complexity? I'm open to any insight/help. Feel free to submit pull requests. I'll start properly pushing anf pulling from git. I'm surprised there are no golang relays out there - seems like this would be something useful to a lot of people.
From what I understand one major use case for generics is for data containers (maps, lists, sets, trees, etc) which all have to be implemented with \`interface{}\` (manual runtime type checks) or with code generation (external tooling). Go partially solves this particular use case by provided special generic built-ins, this gives us a decent portion of what generics offers without adding nearly as much complexity to the language as other fully generic languages have. The common principle is that a data container isn't concerned with the concrete type of the object that it is handling, but it is concerned with how the objects are organized. Go, at the moment, forces us to care about the concrete type even though we don't always (logically) need to care. Common generic code would include appending an item to a list. You don't care what type it is you're appending, you only need to know that you have a list and an object that you want to add to the end of that list. The caller then passes in the concrete type at runtime and your append function performs the append while remaining totally agnostic to the concrete type that it is handling. If you can't have a generic append algorithm then you end up needing to re-implement the exact same algorithm but with different type signatures: \`intSliceAppend()\`, \`stringSliceAppend()\`, \`float64SliceAppend()\` and so on. Go provides a generic append function which is great, but you as a Go user cannot create such a function yourself. &amp;#x200B;
&gt; This is really, really well thought out. Agreed, but that's what I've come to expect from go. They've clearly made a deliberate choice from the start to minimize compromises, and to avoid creating a situation where a poorly-implemented feature becomes entrenched and creates problems later. The handler-check approach seems to me like a formal syntax for implementing an error handling approach that has been one of the core arguments for using "goto" in C.
I feel like interfaces could double as a form of contract, but you can't fully unify the two. If you have contract stringer(t T) { Stringer(t) } The `stringer` contract feels a little redundant. Of course, the contract statement takes types instead of values. If you could treat conversions as generic functions, then `Stringer(T)` would mean something, making interfaces more contract-like.
I have never seen a Java program that "did nothing", at a minimum (and its not good), it does e.printStackTrace() so at least there is some logging of the error. There are many footguns in development - I'm more concerned when a good developer has to write cruddy error handling code - but hurray! - it looks like it is going to be fixed in Go 2.0
Seems like the problem might be your device... The github page should have come up in a mobile view or at least had a link to a mobile view with a usable font size and layout.
Qt doesn't have its own smart pointers or string class?
I'm sorry. I give up. Try writing a real fix application, or any application with dynamic message formats. I gave you examples in 4+ languages and only the Go implementation needs to resort to this method. You don't understand the problem, and I don't have any more time. Luckily the Go designers have recognized the problem and it will be fixed in Go 2.0 )it appears) - the fact that you still don't understand the problem and they do speaks volumes. I'm sorry I wasn't able to articulate the point more clearly. Lastly, if you think it is just related to "fix", or this design paradigm, see https://github.com/golang/go/blob/master/src/bufio/bufio_test.go about line 405 ... this is what test cases look like without proper error handling (exceptions, or conventions like exceptions)... horrible 
oh god. I forgot to insert the links. Sorry dude. Here you go. [Parallel Sieve.](https://gist.github.com/gowtham-munukutla/a307fbe2399f14cf400cd4bfc0dbe372) [Normal Sieve](https://gist.github.com/gowtham-munukutla/a406586115dd8104976564eea8aac6d3)
Generally that means you can use whatever you find online or from other sources not that you hire other people to do the task for you. What’s your plan for keeping the job? You pay ppl online and give them proprietary code from the customer company every time you don’t know the solution and don’t bother doing the work for self-improvement? Doesn’t sound much of a long term plan to me.
I frequently use semaphores [1] to control the number of _goroutines_ running resource intensive operations. You mentioned that you are using buffered channels, but I want to make sure that you are using them this way. It is also worth to check what's the resource limit of your machine with `ulimit -a`. [1] https://stackoverflow.com/a/39776558
&gt; A combo like type T[type U] ... might work, but the benefit would only be to potentially improve the parenthesis blindness problem somewhat. It also would require the type-keyword at the usage site, which is not needed now (arguably it should…?)
Valid concern. I have been thinking about this, and I think the answer is the depth of the function handling the error. I am currently writing a webapp, with 2 basic layers. I think I will still use the normal error handling with added context in the DB layer. Because if a db function has several queries (like in a transaction), I would like to know where exactly it has failed. Otherwise, all errors would look like "pq: invalid constraint bla bla". But in the http handler, this is a great way to reduce cruft. Most of my handlers are of this form - func (w http.ResponseWriter, req *http.Request) { // decode JSON // sanitize request // get/store in DB // write response } At this level, it is great to just `catch` errors from all the top level functions and `handle` them just once in the function handler. Most of them will have enough context to point out where the error is from, and you save a lot of repetitive code.
You need another buffered channel where the size will represent the maximum number of _goroutines_ at a time. sem := make(chan bool, 100) // maximum 100 goroutines at a time. […] func queryCrtsh(sem chan bool, domainName string, wg *sync.WaitGroup, client *http.Client) { sem &lt;- true defer func() { &lt;-sem } defer wg.Done() […] } Something similar to this, give it a try and let me know if it works for you.
This is rather fantastic, I love the contract based parametric polymorphism.
You need another buffered channel to act as the semaphore of the whole operation: sem := make(chan bool, 100) // maximum 100 goroutines at a time. […] func queryCrtsh(sem chan bool, domainName string, wg *sync.WaitGroup, client *http.Client) { sem &lt;- true defer func() { &lt;-sem }() defer wg.Done() […] } Something similar to this, give it a try and let me know if it works for you.
Use a single unbuffered channel passed into a fixed number of go routines (less than 1,024) that range over the channel. Also pass a *sync.WaitGroup into each goroutine after adding 1 to it before each goroutine creation. Send the request data to the channel for each row of the CSV file. When you’re done passing in the CSV rows, close the channel and Wait() on the WaitGroup before exiting. You will not create more requests than you create goroutines this way.
&gt; If you try and spin up a goroutine for every unit of work, and that unit of work is cheaper than the cost of the goroutine with the channel communication overhead, then you are just going to slow your process down Bingo
Whoa dang. This works! This left me with an expected issue where some of the HTTP requests end up timing out from being throttled making too many requests too fast which is a great problem to have :) Thanks!
&gt; what would be the testusermac? I don't understand your question… Are you asking _"What is the value of variable /testusermac/ at the end?"_ If yes, then the answer is `f3aa89b0842002650163940ec46e309fdb9093c05fb2216267933aa5c8e031ca` But just so you know, that code is not written in Go, it's written in Node.js [1]: var crypto = require('crypto'); var testuser = '1' var hmackey = '038445bb4e33677064ff911095b2416efe272adf' var testusermac = crypto .createHmac('SHA256', hmackey) .update(testuser) .digest('hex'); console.log(testusermac); [1] https://nodejs.org/api/crypto.html#crypto_crypto_createhmac_algorithm_key_options
For a brief moment had the same thoughts, but once my eyes adjusted I realized that this 'parentesis nightmare' was always there thanks to multiple return value or func(){...}() implementation, and I have to say... the proposed syntax fits perfect for the language syntax. 
Doesn't that bring us back to square one? func something(w http.ResponseWriter, r \*http.Request) { if res := doSomething(); !res.Success { http.Error(w, "error", http.StatusInternalServerError) return } if res := doSomethingElse(); !res.Success { http.Error(w, "error", http.StatusInternalServerError) return } if res := doSomethingOneMoreTime(); !res.Success { http.Error(w, "error", http.StatusInternalServerError) return } } &amp;#x200B; vs. &amp;#x200B; func something(w http.ResponseWriter, r \*http.Request) { handle err { http.Error(w, "error", http.StatusInternalServerError) } check doSomething() check doSomethingElse() check doSomethingOneMoreTime() }
What's the use case? I assume this is for an existing product? If this is for a new product then just set up a small proof of concept and show much easier it is to deploy/test/whatever your current pain point is eight now. Either way people respond strongly to solutions that take pain out of their life. Show, don't tell, how this will make something painful easy. 
I don't think check/handle will be provide any benefit here, and I don't think that this is the problem it's trying to solve. I think the current system is just fine for the described scenario. ``` func (...) error { return errors.WithMessage(foo(), "Wrapped message") } func (...) (string, error) { result, err := foo() return result, errors.WithMessage(err, "Wrapped message") } ```
I modified your code a little bit. Right now, this seems to work pretty well. It is [uploaded here.](https://gist.github.com/coder543/b18761d653e3fa938258709c0ee05f46) I switched the argument parsing to use the built-in flag parser, so take note of the new help string before trying to run it. I also moved the end of the main function into "handleTCPOutgoing", and then made "handleTCPIncoming" the final statement in "main", without launching a goroutine, so that when that function returns, it will exit the program. That function will return if the connection to the server that is being relayed is broken. Otherwise, mainly just a few minor changes and refactoring. The stats print pretty nicely now too! Let me know if you have any questions or need any more help. This was fun to play with.
Ha! I snuck Go into our stack (websocket responder) last year. No one noticed, and it's never caused a single problem.
[removed]
[removed]
&gt; I don't want to answer these questions with simply "better performance" or "it feels good". I was in the same situation 4 years ago when I introduced Go to my team. _"Better Performance"_ was the reason I chose. I went ahead and prepared a bunch of benchmarks between two of the most resource intensive operations in one of our flag products, and the same operations using Go. It took me a couple of days to prepare everything. During the meeting, I got rid of all references of Go in the presentation, I just wanted to share the astonishing results of running the old code compared with the new code. The results included not only the load time and responsiveness of the system but also the amount of energy and consequently the amount of money that would require the company to maintain both versions running in our data centers. After some discussion, I started to notice some happy faces around the team, which included not only engineers but also some project managers. They requested a second presentation with the head of the marketing team _(who was one of the heavy users of the project)_ and more project managers. They were happy with the new numbers and wanted to move forward with the changes. That's when I dropped it… I used Go in the new code 😏 And their faces went 😱 We went ahead with the changes, and two years later all our systems were migrated to Go. **Conclusion:** A refactoring or tech stack migration is justified by how much it affects the pocket of the owner(s) of the company and/or the investors. If you cannot justify these —or any other changes in general— then forget about it. If you can show them that they can spend less money using Go because the programs run faster and/or better, consequently reducing the amount of consumed energy, and speeding the response time —which customers always appreciate— then you are good to go _(pun intended)_.
Holy fuck lol don't use nodejs. I've had nothing but pain in personal projects. Focus on the benefits of static typing in Go (because I assume typescript would be used as a bandaid). Then dig up some benchmarks. Run them locally if need be. If deployment is the biggest pain point then there is way too much ammunition to use. Especially with modules and go 2(or go++) plans being unveiled now. Side note the team can use their go skills to create command line tools, proxies, servers, APIs, you name it. So it's a useful item on the toolbelt when the team needs a utility. On mobile but I may be able to post links later. 
I'd think the computer would have to worry, because `a[b,c]` would be valid if `a` is a generic type, but invalid if `a` is a slice. But, TBH, ¯\\\_(ツ)\_/¯. People who are better at this stuff than me have spent more time on it. I don't think bikeshedding the syntax is super useful.
This is mainly for posterity at this point but was this your error? too many open files; retrying in 1s If so the root cause is described in the safety net section here: https://stackoverflow.com/questions/37454236/net-http-server-too-many-open-files-error Oddly enough this error was covered at the GopherCon in Denver today. The speaker was Filippo Valsorda and the tile was Asynchronous Networking Patterns. Not only does he build a 100 line proxy that analyzes the TLS handshake but he covers this problem you had in fairly decent depth. 
Type assertions ?
[removed]
`a(b, c)` is valid if `a` is a function that accepts two arguments, but not if it's a function accepting a different number of arguments (or if `a` is a type). 
&gt; bloated executables, lack of type information at runtime These are not properties of generics. Some implementations might exhibit them (C++ for the former, Java for the latter) but there is nothing inherent to the concept that requires them. 
Bingo
&gt; a(b, c) is valid if a is a function that accepts two arguments, but not if it's a function accepting a different number of arguments It parses the same though. It gets rejected semantically, not syntactically.
What confused me was the vn instead of the vErr. 
That is indeed an issue. Because I need to understand what the error is and return 4xx or 5xx depending on it. It is very hard to do all that in the handle function.
Again. Terrible on mobile. The github link is good on mobile. 
[removed]
You can create a static or dynamic library, just use -buildmode=c-archive/c-shared.
That’s a good point and definitely familiar. 
I tested mine on a pretty weak Linux box in the cloud, and it's interesting. if I connect 1000 clients to the server, and then send 225 messages consisting of ']' to the server, it takes about 5 seconds for the one client I'm monitoring to receive the last ']}' message. If I connect a total of 2000 clients, the time increases to about 7 seconds for 225 messages. I definitely think there is room for optimization here. If this performance isn't good enough for you, I can look at it a little more.
&gt; go has features and tooling that C and Java do not have which also help address this problem Such as? go fmt and go fix surely not.
If you like "magic" base type, you might like my "magic" builtin methods: https://github.com/lukechampine/ply The basic idea is that when people say they want "generics," they actually mean they want `map/`filter`/`reduce`. So ply bakes those directly into the language without providing any additional generic programming facilities.
The old way is just code, if it stops working then nothing will
I am mearly arguing that this does not count as a premature optimization. It is indeed an optimization and since it has been released there really can't be anything premature about it. 
&gt; Also, if i wanted to reverse engineer this.. what would be the plaintext of this: `cb15h+Mzl5pZxeNSWe3b` The plain text version of `cb15h+Mzl5pZxeNSWe3b` is `344803839941749`.
I'd start by defining the problem you need to solve and why golang solves it better than the other choices. Solved meaning fitting design requirements including the *minimum* performance and scalability requirements. It should be obvious to everyone if the performance increase in golang is needed. Also be considerate of the company. If no one knows golang except you and the problem can be solved in a language that the company has better collective knowledge of, don't switch to golang or maintainability goes out the window by your colleagues or future replacement should you leave. Make sure you can justify that golang will be easy to integrate and maintain. This is my "senior serious" answer. My casual answer is just make a quick example of the solution (if it's okay for you to do so) and give a demo. Then walk the engineers through the code. If everyone likes it then you just introduced a new language to your company. But also be okay with it if they say no. In all cases I'd sit down with your team and discuss it point blank that you want to showcase golang. Idk if it applies to you but in some orgs if you just go Wild West and use company time to build something in golang when it wasn't approved it can backfire. Might not apply to you though. Either way teams appreciate being in the loop of what others are playing around with and engineers won't hesitate to give their opinion of your approach. 
I pity programmers who learned go first.
Is that type safe though? In case of error, you can still access the nil value and get a runtime error. The big selling point of maybe/either is that the type system guarantees you can't do that. In the end, you're trying to simulate variant types using record types, and that's simply impossible. To use an argument from logic, a record type corresponds to a (labelled) product of sets, and a variant type to a (tagged) union. You can't derive an union from a product. 
For the `Vec&lt;Rc&lt;RefCell&lt;Box&lt;Trait&gt;&gt;&gt;&gt;` example, it's probably worth mentioning that the new dyn trait system allows that to be written as `Vec&lt;Rc&lt;RefCell&lt;dyn Trait&gt;&gt;&gt;` ([example](https://play.rust-lang.org/?gist=f879f1cfc10a6f4ddbbf9e1479d67232&amp;version=nightly&amp;mode=debug&amp;edition=2018)). This is both simpler and faster, as it has one less pointer indirection. At this point the part that could be considered absurdly complex is the `Rc&lt;RefCell&lt;...&gt;&gt;` pattern, which I don't really think is abuse, since those are two separate concepts of reference counting and interior mutability are useful and meaningful outside of the common `Rc&lt;RefCell&lt;...&gt;&gt;` structure. The fact that those two concepts are part of the language and need to be invoked explicitly is a consequence of rust's memory management system rather than generics.
lol no gen-
You're welcome. Any feedback is appreciated and you can open issue if you have any.
C programmer says PLONK.
do u even slack or snapchat brah
fite me IRC!
Lol no history
\+1 for your sneakiness.
Here's a bit of a nihlistic answer for you... read it only if you are not afraid of being sad... Most organizations with a vested interest in their current product are unable to move from it. It takes an existential threat to get them to move, and faced with existential threats, as many take the dinosaur route as face and overcome the threat. The way I started getting paid for using Go was by doing it at night/weekends for years to keep my sanity while my paying job made me want to stab my eyes out with crayons. I changed jobs from a C house to a Python one, still hacking Go for fun, not money. Then I found the right Go job and I took it. YMWHV. (Your milage will hopefully vary.)
That's why you have a client that is always online and keeps logs for you.
yep, last century was barbaric
You go back to being the subject of a proprietary chat software company.
&gt;the language is more complex, so longer to learn &amp;#x200B; Generics aren't monoids in the category of endofunctors or something like that, they are not difficult to understand/master. &amp;#x200B; &gt;and it's harder to make/update tools for the language (linters, IDE plugins, etc.) &amp;#x200B; No, Java has generics and advanced toolset, C++, C#, and many other languages as well. 
of course it's a linux zealot!
I agree.
&gt; Generics aren't monoids in the category of endofunctors or something like that, they are not difficult to understand/master. Yes, but they are one more thing to understand. Especially corner cases, as the devil is in the details. But I agree this is a very secondary point, even though I managed to sell go to my coworkers by telling them "but I swear you can learn go in a matter of hours, and can become almost an expert in a matter of a week" (this would not be true anymore). &gt; No, Java has generics and advanced toolset, C++, C#, and many other languages as well. Because they are old, massively popular languages. But it's hard to develop new tools for them, for instance. Let's say I want to make a cpp linter, from scratch, that would warn me when he finds I'm probably trying to dereference a null pointer (in trivial cases). How long will it take, given the complexity of the language? I would have to make a parser for the complex grammar (even that sounds like a daunting task), consider macros, templates, and deal with several types of pointers. How long would it take with a language like go?
you're just linux zealot who thinks other linux zealots are unter zealots
I would say that I like all of these designs. They recognize problems clearly and insightfully, and is well-thought. The Go team has really take their time to attempt to providing these solutions. &amp;#x200B; But I would say I am not sure about all these are good ideas or not. I like them and I think I am going to be adapted to them smoothly, but, it is hard to be sure about designs without prototyping and testing. &amp;#x200B; I think it is time to create a prototype, that at least allow to transpile "Go 2" code into runnable Go code so we can actually try and feel these proposals. Does anyone know if the Go team is going to do this? Or maybe we can spawn a quick hacking prototype?
How ungrateful can you be? These are notes offered free of cost to anyone who wishes to use them. They aren't plain transcripts or copies of the book text. It has my explanation too. If you find no value from them, you can walk right past them. 
Yea it is as I was saying in my other reply. You have a lot of costly operations like allocating a new channel on every loop, and spinning up 2000 goroutines. If you think about it, not much is being done in parallel here because all your channel operations are synchronous. You string up all these goroutines and channels in a row that are blocking on handing off values which greatly outweighs the cost of the unit of work. You would be better served in this particular problem by trying divide and conquer, where you take an existing IsPrime(int) function, start up N goroutines all sharing a single work channel, and then in your main goroutine you just loop and pump input numbers into the channel. The workers will pick them up, determine if they are prime and either print the result or send it on an output channel to be collected by a collector goroutine. 
gomobile bindings for ios and android
Would not say advanced but I think using first class functions in a proper way allows code to become very readable and extensible. *Shameless plug*, I wrote about this before: - [Clean code using decorators](https://www.bartfokker.nl/posts/decorators/) Another example: - [Do not fear first class functions ](https://dave.cheney.net/2016/11/13/do-not-fear-first-class-functions)
One problem I have with the new handle-check system is that making both `check` and `handle` keywords. Both are very common identifier names. It is going to break a whole lot of code, and I would need to find new variable names when I wanted to use them.
.. but what about my super useful helper functions, they will all be obsolete then /s func filterString(v []string, condition func(string) bool) []string { } func filterInt(v []int, condition func(int) bool) []int { } func filterInt32(v []Int32, condition func(Int32) bool) []Int32 { } func filterInt64(v []Int64, condition func(Int64) bool) []Int64 { } ... &amp;#x200B;
Copying+Pasting is an advanced programming method possible only in go. 
In case of ansible, you literally copied whole paragraphs, graphics, tables, code examples from the book. You didn't even bother to change the numbering of the tables. You didn't bother to acknowledge that you didn't write it yourselves, you didn't even bother to cite the book you're copying from. You can't just copy others work, claim you did it yourselves because you added a sentence or two and then give it out for free because you're such a nice guy. That's not me being ungrateful, that's me pointing out that you are posting links to notes you copied from others without even acknowledging their work (or asking, because I'm pretty sure you're not allowed to do that for books which are not in public domain in the first place). 
The problem is that the .gitignore spec cannot be handle to filter the results of a walker :( It's should be implemented in the walker itself. That being said, I agree with you that the file system walking library should be general, so I implemented the .gitignore spec handling as an option so you can use other patterns if needed (glob...) while being performant (do not explore part of the tree that are not needed). 
Ansible notes has large swatches of text from the book, I agree. However, saying all that is there to the notes is copied, or otherwise just transcripts is plain wrong. In my opinion, even if it were just transcripts, it is useful. Of course, it is much more than that, it has the notes from the official Tour of Go, Go blogs etc. You'll only see it if you scroll down a few pages before jumping back to reddit and criticizing. 
[removed]
one time this has come up for me was a simd accelerated math library, where you have to write the function for every primitive type - int8, int16, in32, int64, float32, float64 etc 
Ok thank you. Yeah the good thing is all code will continue to compile and work as is.
I'm not commenting about its usefulness, I'm criticizing your lack of acknowledgment. Why don't you even say that these "large swatches of text" are from the book, but present it as your own instead? 
Yes, they will continue to compile and work as is, except maybe we will need to rename all variable with name "check" and "handle". It buzzed me a little.
another alternative https://github.com/Loafter/WebTop
That's what I mean, in the current state, such code might be better to be generated instead of copy/paste/replace.
Added a note: https://github.com/darshanime/notes#disclaimer
there aren't any ^^^\(more ^^^or ^^^less) the most advanced feature is when you get to the point when you are writing good, idiomatic, understandable code and using all the tools the community developed for your benefit (it saddens me how many new gophers don't even know about the race detector) also obligatory [gometalinter](https://github.com/alecthomas/gometalinter) plug
The thing is, this would allow some sort of operator-overloading, and I'm not sure if it's a good or a bad thing. And dynamic dispatched code would run slow as hell as the call can not be inlined (at least in tight loops).
I'm personally not in love with either change. The beauty of go is it's simplicity, and both of these features move the language in the opposite direction a little. I'm also curious if the contract is necessary as it seems very similar to an interface.
Hi, author here. As a user of both travis and gitlab-ci I wanted a more unified and simple deployment experience across various providers, whether it be GitHub releases, Heroku, Firebase, AWS S3... &amp;#x200B; As said `rocket` is the *D* in *CI/CD*: it does not replace your build system but instead help you to easily push your code in your various environments (dev, staging, production...). &amp;#x200B; To do this it furnish a couple of providers where you can deploy your code. &amp;#x200B; It should be as easy as possible to use, Any feedback welcome.
&gt;How about we leave out ad hominem? Ad hominem is about attacking the person, not attacking the arguments. I'm saying the arguments are stupid because they are arguing about things that are not happening in the real world so evidence is not backing them up. I'm sorry but no, saying "but it's just my personal opinion" or "I care so listen to me" doesn't make an argument respectable. You have to at least establish some decent premises and many people here (just like the guy above) are not making that and I'm gonna call the bullshit on that.
Why the ugly curl install script thing instead of just using go get? Looks like wanting to sidestep distros, and at the same time trying to say that your master branch is not safe to use. Not a big deal admittedly, but it does raise some red flags. For me at least.
Hi, Thank you for the feedback. I have reordered the installation section. The main reason is to provide an easy way for users who not have `go` installed. As a fundamentally security oriented person I agree that it's not the optimal solution, but it provides a quick way to distribute binaries while waiting to use distros package managers which are harder to setup. That being said, the main branch is safe to use :)
i think it's a bit dramatic to say these changes to go are comparable to scala..most of the weird punctuation in scala is not because of generics
What's wrong with FP libraries? Functional programming is an amazing tool. I would love to see a Go version of Lodash or Ramda. They reduce a lot of boilerplate code and redundancy - although that's probably why some Go programmers don't like them: they think copy/paste is a viable programming method.
The sieve of Eratosthenes can be parallelized effectively. The wiki-page is pretty decent with it's section about computational analysis and algorithmic complexity. There is also a link to a parallel version in C#. https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes https://paratechnical.blogspot.com/2011/01/c-implementation-of-parallel-sieve-of.html
Wow, that's awesome! Thanks! That actually does work without having to do any kind of weird string replacing which is great and looks so much more readable.
Uh yeah. Exactly. `a[b, c]` would parse fine and then be rejected semantically if `a` is a value.
One thing I noticed is that this method works great but at a point it still runs into the issue of having too many open files. For example, with a ulimit of 1024, if I do two channel sizes of 500, I will still run out of TCP handles at around 1800-2100. What exactly is happening behind the scenes here? I noticed that it is possible to have my domain names channel fill up with basically everything and then limit the semaphore to whatever number will keep me from running out of file descriptors and it will work just fine. As I increase the semaphore, the odds of running out of handles seems to increase exponentially.
I've never really had the need for generics. If a standard container (hash table, array, struct) doesn't cut it, my need is probably so specific that no canned implementation is going to cut it, so I implement it myself for this particular use case. Generics are not needed because this implementation won't be of any use elsewhere.
&gt; You don't understand the problem, and I don't have any more time. I guess not. I truly don't understand why memory is randomly changing under the caller such that an error can occur during access. That isn't going to be fixed in Go2 though. The changes in Go2 are related entirely to generics and error handling, neither of which do anything to deal with the situation we are discussing.
Any tutorials, guides, or cheat sheets on how the write idiomatic go?
Looks very, very interesting. If I could use this to replace fat, bloated, memory gulping Jankins then that would be awesome. Can I recommend you build a Docker version of Rocket, though? The odds of me installing this on bare metal are extremely low. A Docker container means I'm going to try it out and see how it works. Rocket + Drone seems like it could theoretically fulfill both the CI and CD aspects of automated deployment.
If you are looking to replace Jenkins, I would recommend Drone. It's container based, which means rolling your own plugins is very easy, and has upcoming support for secrets from Kubernetes and Hashicorp Vault. https://drone.io
Does it support SSH and/or custom scripts yet? The last time I evaluated it, it had the CI part down pat but had very limited CD.
Yeah I think that's how it's going to have to be refactored. The data bursts can be pretty big 5000-7000 aircraft positions, sometimes 1MB. I was trying to send each one concurrently as it came time using goroutines but was having trouble with the map locks and something using more and more ram. Could the incoming buffer be an issue? Even with one built with a stream server, ram usage still climbs until it crashes. Try sending it live data streams from our live server and connecting 500 clients. server ip: 149.56.158.22 port: 63001 
I was just looking at this while load testing! Awesome!
within a reasonable time - but something is keeping them alive -- go is reporting 20-30k go routines after an hour or so
I'll test it in production today and get back to you.
How well does it run self hosted?
The code as it is right now doesn't call Close() anywhere.
Making the code so much harder to read for tooling seems like a bad idea. 
I agree with you. On the other hand, if you make the syntax too complex, you risk making it too hard to develop tools, and you end up with fewer or lower quality tools, since it takes more time to develop them. You need a good balance between them. Is the extra tooling support worth the harder to read syntax? Maybe. I'm not really sure if losing readability here is worth it.
The ADSBx project is running it on a 4Ghz+ box at OHV with 2 cores and 8 GB ram. The limiting factor always ends up being the bandwidth, at peak times the 1 second stream is a good 5Mb/s. https://gist.github.com/adsbxchange/a3ff906c8fe9859ae5ac728efca25b5c It's doing well with 60-70 connections. You can see when the data burst come and need sent. the goroutines jump and the heap alloc jumps up. 
Maybe [like this](https://play.golang.org/p/j5CvQ0MRdQt) is what you want to do?
This. Using bools to test if something is present or not can get confusing, since there are really three states for something in the map. As a bonus, you can use struct{} instead of interface{} to use a little less memory: [https://stackoverflow.com/questions/22770114/any-difference-in-using-an-empty-interface-or-an-empty-struct-as-a-maps-value-i](https://stackoverflow.com/questions/22770114/any-difference-in-using-an-empty-interface-or-an-empty-struct-as-a-maps-value-i)
&gt; The thing is that once you add generics, a lot of patters are now subject to change. I suspect, but can not prove, that the community consensus on generics that will develop six months to a year after they are introduced is that it is not Go-like to use them to do crazy control flow libraries, and the answer is to not do that. I think you'll also find that in conjunction with the other proposals that trying to use generics to handle errors is going to be ultimately _less_ convenient that using the constructs proposed. For instance, generic-based error handling has no equivalent to the scope-based `handle`. Remember, while there's nothing necessarily wrong with importing concepts from other languages, you must always do an analysis of how well it works in _this_ language before getting too excited about it. You should not let your brain credit the fact that Result(...) works in Rust as a virtue for it in Go. It must prove itself strictly in Go terms, with no reference to how well it works in Rust. Or, to put it another way, it's OK to mine for ideas from other languages, but the value of what you mind must be strictly considered in the local context. This will occur after a flurry of /r/golang submissions of all kinds of such libraries. Heck, people are probably even now starting to write them in prep for this being available. But I think ultimately we're going to see generics as suitable for data structures, and maybe a couple of other things, but not as a replacement for the existing error handling. I'm sure we'll see someone try to jam a monad library in too, for instance, but it won't be a good idea. (Another example of something that may do wonders for _another_ language, but those wonders count for zilch when it comes to analyzing them in Go.)
Hi there! I'm part of the team at Microsoft working to improve the experience of Go developers on our platform, across things like VS Code, Azure, and VSTS. As [promised](https://twitter.com/azurefriday/status/1027650725881569281), our gophers, led by the amazing Erik St Martin, took over the Channel9 studios and recorded a series of technical videos showing what we're doing for Go developers! We definitely had a lot of fun doing these, and hope you'll like them too!
Very good idea! I'm not sure to fully understand how [drone.io](https://drone.io) works (never used) but I pushed a docker image ([https://github.com/astrocorp42/rocket/blob/master/Dockerfile](https://github.com/astrocorp42/rocket/blob/master/Dockerfile), [https://hub.docker.com/r/astrocorp/rocket](https://hub.docker.com/r/astrocorp/rocket)). Furthermore as it's very interesting I will add the docker provider :) I will add documentation for it between now and tomorrow, but now you can use it: `docker run --rm -d -v $PWD:/rocket astrocorp/rocket` 
I really thought they were going to allow their idealism to win over pragmatism. Versioned modules, generics and exception handlers all going in is really going to put the defenders of them being missing in a tough spot. 
I've added a docker image for `rocket` and make it work with [drone.io](https://drone.io) so [drone.io](https://drone.io) can focus on CI, and `rcoket` will handle the CD part.
[removed]
I think the premise behind your gist is wrong. There's no need to add that you failed when calling X, because X's error will already indicate that. Doing the former would just be tiresome and introduce visual noise
So you think something along the lines of "I have copied a few things" in a general disclaimer is a good way to cite your sources, acknowledge and be fair about their work? I give up... 
 &gt; Lets put a $ in front of all variables so we _know they are variables_. - PHP
In the contract examples, I wonder why that information can't be determined from the generic function itself, at least in the case of single-type generics. But in general I like what I see. The improvements to error checking, and having generics of any kind. I have mixed feelings about generic performance initially, but much of the wording gives me hope for later improvements. They'll be useful regardless. The draft design suggests that generics may initially be closer to the slower java implementation (one version of a generic function is generated which supports all types), but comments in the draft overview leads me to believe we'll get optimized generics in some cases in the future, left up to the compiler. From the draft design: &gt; Generic functions, rather than generic types, can probably be compiled using an interface-based approach. That will optimize compile time, in that the package is only compiled once, but there will be some run-time cost. From the overview: &gt; Polymorphism in Go should be implementable both at compile time (by repeated specialized compilation, as in C++) and at run time, so that the decision about implementation strategy can be left as a decision for the compiler and treated like any other compiler optimization. This flexibility would address the generic dilemma we’ve discussed in the past. &gt; ... &gt; **Dual implementation**. We are hopeful that the draft design satisfies the “dual-implementation” constraint mentioned above, that every parameterized type or function can be implemented either by compile-time or run-time type substitution, so that the decision becomes purely a compiler optimization, not one of semantic significance. But we have not yet confirmed that.
CGO
Is there a Livestream of GopherCon?
TLDR: Microsoft is Cancer (Github now Go): GTFO! Created an Account just to say that I use VSC because it worked well in the beginning but they are now pushing intergrating with MS products and looking to move into the extinguish stages- seriously if you kill Atom! I stopped using VSC when 'Azure' was mentioned on the welcome screen. Microsoft has only added features to monetize the VSC and to tie it back to their own products. This 'lets get more users using microsoft' advert is case in point. Azure is a expensive pile of shit and you can take advantage of containers/the cloud at a fraction of the cost (and be more successful/secure) by sticking with Docker and just dropping the MS crap infront of it. &amp;#x200B;
I really don't like the way this is going. Why should I have to run a proxy just to cache some build dependencies? Not everyone can or wants to run infrastructure for such a simple task! Sure, I could always use a public proxy, but it might still delete content or disappear due to DMCA/other legal action, lack of funding or a myriad other reasons. And what about people who want to use my project in countries with shitty censorship/trade embargo issues (Iran for example)? IMHO, if someone obtains my project's source code, it should also contain any less common dependencies (like semi-obscure go packages), so they can fetch and build the project easily without relying on 3rd parties.
I should have time this afternoon to try and profile it a bit more. The locking is going to slow things down but I shouldn't be an issue until there are a great many clients.
The locking should only affect performance when clients connect and disconnect, since sending messages only requires a read-lock (which many threads can hold simultaneously), but actually changing the map of clients requires an exclusive lock.
You need to keep in mind: Go is completely pragmatic. It doesn't try to introduce generic solutions to every problem in a given domain; it gives simple tools which solve most problems, and leaves the 10% to fend for themselves. The 90% use-case of error handling is either: ``` func Foo() error { _, err := Bar() if err != nil { return err } } ``` Or ``` func Foo() error { _, err := Bar() if err != nil { return fmt.Errorf("Foo() failed: %v", err.Error()) } } ``` In other words; directly returning errors when they happen, or wrapping them with a function-specific string. The use case of "wrapping each individual error that can be returned in an error-specific string" is too rare to be useful. And the proposal solves both of those basic cases really well. ``` func Foo() error { check Bar() } ``` And ``` func Foo() error { handle err { return fmt.Errorf("Foo() failed: %v", err.Error()) } check Bar() } ```
I don’t understand the problem this solves. The issues we have with our deploy involve updating many components (deploy code to stack, run migrations, push assets to s3 etc); the issues we run into are handling errors—retrying and reverting the deploy if things end up in an inconsistent state. But this doesn’t appear to tackle those problems, it’s just a wrapper around scp and friends?
TBH, that's a *release* system, and not a deployment one. A deployment system is file distribution *and* orchestration system; you want to be the one *controlling* when and how a new release hits your production servers. I realize that the how and when varies between deployment target environments, but generally the pattern is the same: 1. copy/update your releases on production servers, 2. find a reliable way to reload/restart your services (possibly synchronized between hosts, you don't want to deploy server after server) 3. don't deploy to prod, have an option of cancelling/rolling back to previous deployment(s) PSA: While CD is a great thing to have, if you're deploying anything other than your personal blog or something directly to a prod environment, you have balls of steel (or a non-existant SLA).
I totally agree. It's conforming Go for C# and Java developers. What happened to just using the right tool.
Thanks. I think I got it.
Tell us how you really feel. 
It's still consuming gigs of memory over time. I'll set profiler on it and see what comes (https://flaviocopes.com/golang-profiling/) https://gist.github.com/adsbxchange/c10fd898fe96eca8d39d8a86a3766429
That was easy. It's running. I'll post after it runes for a while.
It runs quite well. I have been using it for a few years now, and the 0.8 branch made quite a big leap in user friendliness and ease of configuration.
&gt; What if it was of use elsewhere, and you wanted to distribute your code as a library for others? I haven't seen a particularly convincing use case. &gt; Well, without generics that is pretty darn hard. We've seen countless libraries in the Go ecosystem rely heavily on interface{} and manual type casting in order to allow end users the flexibility they desire. Can you show me a few convincing examples?
Here is a preliminary. https://github.com/adsbxchange/tcp-relay-mem-prof 
What happened here? https://gist.github.com/adsbxchange/c10fd898fe96eca8d39d8a86a3766429#file-gistfile1-txt-L690 It looks like the memory usage went way down between two samples, which indicates to me that it is garbage collecting... it just might not be garbage collecting very often since there is probably a lot of free RAM on that server and it's cheaper to just hold more memory than to be allocating and deallocating to the system. I'm not a Go expert by any means, so that is mostly speculation, but I am an experienced systems programmer in Rust, C, and C++.
Very interesting feedback! I agree that `rocket` is more a *release* system (distribute build artifacts) than a full *deploy* system. It's goal is to ease build artifacts release. It's does (and will never?) handle the orchestration parts like DB migrations, rollbacks etc... I will think about exactly which is it place in a CI/CD workflow and put it in the docs when it'll be more clear in my head. &amp;#x200B;
quoting from https://golang.org/pkg/runtime/ // NextGC is the target heap size of the next GC cycle. // // The garbage collector's goal is to keep HeapAlloc ≤ NextGC. // At the end of each GC cycle, the target for the next cycle // is computed based on the amount of reachable data and the // value of GOGC. NextGC uint64 so, it only garbage collects as much as it has to in order to keep the memory usage below NextGC, I think.
I did a few short term. I'll let it run for an hour or two, and add more files.
 [Go Experience Report: Generics in Kubernetes](https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301) [google/go-cloud](https://github.com/google/go-cloud/blob/8c7358e2efcae2e082191d531d45f4a49f5d4d47/wire/wire.go) 
[removed]
Go eliminates the "callback hell" of nodejs without the overhead of OS threads, using green threading and asynchronous I/O under the hood while shielding you from much of the implementation details. Goroutines and channels make a lot of parallel tasks easy to think about and implement. And because they're not OS threads, you can scale to countless thousands of connections with little overhead. Nodejs is very pedantic about blocking. There's no Sleep() for example, because that would stall the event loop. Your code has to return before any other events can be processed. Sometimes a small thing requires massive design changes to keep it happy. Go makes it very easy for a serial-minded coder to write proper, efficient asynchronous code, but it's not a jerk about it. A non-callback I/O operation in a goroutine doesn't lock up all your other routines like it does to the event loop in nodejs. The garbage collector is very low-latency, though it doesn't compact, so memory remains a bit fragmented. You don't get the long pauses that plague most other garbage collected languages. Overall memory usage tends to be pretty low in spite of this. There's no JIT, which eliminates a lot of memory overhead and dependencies. Everything is precompiled with zero dependencies, and the compiler supports all targets out of the box. You can compile a windows exe on linux, a linux binary on windows, etc. all easily and deployment is just a matter of uploading and running your executable. Nothing else needs to be installed on your server.
I would also test adding `runtime.GC()` to the `runtimeStats()` funciton so that it gets called every ~5 seconds or so, if memory usage is that important, since it looks like there isn't much memory actively being used, the garbage collector is just choosing not to run very often since there is a lot of free RAM available. You could also try setting the environment variable `GOGC` to something like `10` so that the garbage collector runs more aggressively. (it defaults to `100`, and setting it to `0` turns off the garbage collector entirely, so don't try `0`.)
A DMCA takedown from a public proxy pool is one of the more technically legitimate concerns, but my gut tells me that it is rare enough that to be more of a theoretical concern than a practical one. Even so, Athens is designed to be a decentralized, federated pool of global proxies. Anyone can spin up a public proxy and add it to the pool. AFAICT, a DMCA takedown would have to be sent to the owner of every proxy in the global pool that had a copy of the package. Many proxies may not even be under the jurisdiction of DMCA takedowns, so the stars really have to align for one of your dependences to suddenly become totally inaccessible.
You should be using `-gcflags 'all=-N -l'` or it will still be optimized.
Yeah, after I re-read the man page for `.gitignore` spec, I agree that the multi-directory level nature of how the ignored file system elements are described presents a very unique situation, and was about to implement some functionality that was callable from the walk callback. Furthermore, the ignore spec callable would be useful for either `filepath.Walk` or `godirwalk.Walk`.
How does reading your notes make one buy the book if you don't even cite or link it? As an author, I wouldn't be flattered, I would be pissed, because you don't even acknowledge that you copied from the book, you don't cite it, you don't include links... nothing, you just ripped off texts from the book and used the same title and expect people to recognize that it's from this book? 
It's support for "custom" stuff comes through the fact that you can use any container as a base. Not sure what you mean by custom scripts.
I have very little C and C++ experience. When I was doing real world things it was mostly ColdFuson and Java, then I got into nodejs development for a while doing messaging and a little web serving. Very new at Go, so far I like it. The ease of concurrency is what made me look into it. It does seem like it's doing something correctly. Server has 8GB and is sitting around 1.9GB in use. MEM% from the go tcp-relay is slowly creeping up consistently. Heap is stable and varies. Goroutines: 33 Clients: 66 Last GC: 1535564701628687411 Next GC: 172 MB Memory Acq: 242 MB Heap Alloc: 159 MB GC Pool Mem: 82 MB Heap InUse: 160 MB Goroutines: 37 Clients: 65 Last GC: 1535564709572555770 Next GC: 63 MB Memory Acq: 242 MB Heap Alloc: 39 MB GC Pool Mem: 202 MB Heap InUse: 40 MB Goroutines: 40 Clients: 66 Last GC: 1535564713974521039 Next GC: 60 MB Memory Acq: 242 MB Heap Alloc: 41 MB GC Pool Mem: 200 MB Heap InUse: 42 MB I added a few more mem stats. Goroutines: 33 Clients: 64 Last GC:1535565701509346482 Next GC: 65 MB Heap from OS: 82 MB Heap Alloc: 52 MB Free: 4984 Heap Idle: 30 MB Mallocs: 6136 Live (mallocs-free): 1152s Heap Released: 0 B Heap InUse: 52 MB Goroutines: 36 Clients: 65 Last GC:1535565705440219713 Next GC: 73 MB Heap from OS: 83 MB Heap Alloc: 37 MB Free: 5595 Heap Idle: 46 MB Mallocs: 6744 Live (mallocs-free): 1149s Heap Released: 0 B Heap InUse: 37 MB Goroutines: 39 Clients: 65 Last GC:1535565710002977608 Next GC: 69 MB Heap from OS: 83 MB Heap Alloc: 34 MB Free: 6209 Heap Idle: 48 MB Mallocs: 7346 Live (mallocs-free): 1137s Heap Released: 0 B Heap InUse: 35 MB Goroutines: 38 Clients: 64 Last GC:1535565715834269915 Next GC: 66 MB Heap from OS: 83 MB Heap Alloc: 61 MB Free: 6774 Heap Idle: 22 MB Mallocs: 7967 Live (mallocs-free): 1193s Heap Released: 0 B Heap InUse: 62 MB Goroutines: 42 Clients: 65 Last GC:1535565720593219289 Next GC: 79 MB Heap from OS: 83 MB Heap Alloc: 43 MB Free: 7354 Heap Idle: 40 MB Mallocs: 8532 Live (mallocs-free): 1178s Heap Released: 0 B Heap InUse: 44 MB
If `check` and `handle` are introduced as new keywords all code that uses them as identifiers would not compile, else this should be compatible. 
https://golang.org/doc/effective_go.html
I also write code like this: func process() error { a, err := foo() if err != nil, return errors.Wrap(err, "foo failed") b, err := bar(a) if err != nil, return errors.Wrap(err, "bar failed") But I think where you hang the context on the error is mostly an issue of style, not really correctness. That is, if we had func process() error { handle err { return errors.Wrap(err, "process failed") } but _consistently_, e.g. func foo() (int, error) { handle err { return 0, errors.Wrap(err, "foo failed") } func bar(int) (int, error) { handle err { return 0, errors.Wrap(err, "bar failed") } then it's the same net effect.
Up to 2.5GB used in about 15 minutes.
interesting. Did you [look at this](https://www.reddit.com/r/golang/comments/9b1wvy/can_anyone_see_where_im_leaking_memory/e51qecp/)?
I generally find mutexes easier to use than channels (far fewer hard-to-debug deadlocks) for many things. Maybe I'm an outlier. Anyway, I occassionally do have a use case for generics; it seems like it could enable parser libraries (like parsec for Haskell).
Just saw it. I will try it out. I was calling it before in the original code and it seemed to help but I had other issues as well. 
I am starting to think you are just a regular troll now. You pick something from my speech and hinge onto that to twist it with your interpretation. Such an Ezra Klein act. I clearly acknowledged that I have copied from several sources (https://github.com/darshanime/notes#disclaimer), I haven't "ripped off texts" from the books, I have quoted and expanded on them. 
Super helpful! Thank you!
[removed]
Don't distract yourself from debugging the usage the `&lt;|\*|&gt;` operator. 
Right, because the only alternative to copy+paste is monads. 
I got it. Thank you very much everyone!
Everyone's got it covered, but will raise my hand to have being caught out by this more times than I probably should. This and maps being passed by reference.
&gt; Pretty sure all implementations either generate code for each type parameter set or they erase types. So for all practical purposes, it seems like these are properties. Having type erasure and not having it are mutually exclusive, so they can't *both* be a property of a generics implementation. GP said erasure is a "drawback of generics" which simply isn't true.
Do you know what citing, acknowledgment or quoting means? My whole point is, and was from the very first post here, that it includes telling people from where you quoted something. It means that you link to sources, say that this text or that image is from this or that source. What you did in your disclaimer is just saying "I copied it from somewhere". That's not helpful, I'm really not sure how I can explain in another way. When citing your source, say what your source is, not just that you have a source. 
Could you add this to https://github.com/golang/go/wiki/Go2GenericsFeedback ?
[removed]
I use VSC on macOS to build services that can be deployed anywhere, I don't see where is VSC tied to Azure.
Thanks for your work on VSC for Go, it's great!
What do you think of replacing `handle` with `on`, as in on err { return fmt.Errorf("...") } ?
C# (note that it takes advantage of language properties that Go does not have)
Erasing types is a property of the data structure used at run time, whereas generating code for each type parameter is a property of the executable code. All combinations are possible in principle. Because of Go's reflect package, Go polymorphic types can not use type erasure. They must record the correct, complete, type, or `fmt.Printf` would not work correctly. But Go can still choose different compilation strategies.
Writing trade safe code. The web is full of tutorials from so called go gurus with racy code everywhere. Which is why I don't recommend that language to beginners in the context of writing web app. It's unfortunate that the language didn't choose to be completely thread safe, or at least come with thread safe arrays,maps and co.
You seem to be struggling more than you should have. I helped you yesterday with some of the questions that you posted. Here is the code that I wrote to decrypt your message [1]. I suggest you to read more before continuing with these posts. [1] https://cixtor.com/pastio/raw/jnaxfl
Sad ... nothing in Georgia CA
https://gist.github.com/adsbxchange/d7505fce3e54ee076a843be8a9e6e22c I added the runtime.GC() Here is the latest output. Before it was consuming enough memory that linux would start killing things off. I'm not experienced at this but it seems like something is being allocated and not released. It's not virtual memory - the OS is reading it as actual consumed and not available for use. Kill the process and the OS gets the ram back. 
That makes sense. But i already tried with go1.11 and i got this: &amp;#x200B; cannot determine module path for source directory /home/user/.gvm/pkgsets/go1.10.3/global/perlinTest2 (outside GOPATH, no import comments) &amp;#x200B;
It is also possible that Go holds on the the memory for a really long time. It is executing and allocating a lot of concurrent go routines.
Could you post your code?
I wasn't trying to suggest that interfaces could replace contracts. I was saying that, if you squint, an interface looks like a contract with a single parameter, and that maybe the language could allow you to use it that way. So func F(type S fmt.Stringer)(s S) { ... } For contracts involving primitive operations and multiple types, you'd still need to be able to define an explicit contract. Of course, the utility of `F` compared to just passing a `fmt.Stringer` is limited. It really only gives the compiler the opportunity to opt for compile-time polymorphism based on whatever heuristic it uses. I do think the simplicity of "just write the code" might be misleading. There's going to have to be encouraged practices for writing contracts, and I think in many cases, that should include preferring embedding predefined contracts over using syntax-based constraints. Puzzling out what a given syntactic invocation implies about a type can be non-trivial, as demonstrated by the rather detailed explanations in the (not) proposal, whereas the name of a predefined contract provides more direct documentation of intent as well as a hook for a more detailed explanation of what the contract means.
some of those salaries are laughable. 100-140k for a senior engineer in the bay area? You can make that and more as a senior engineer in places like Austin for example.
"github.com/dbudworth/greak" There are a lot of sleeping goroutines. https://gist.github.com/adsbxchange/ad95965de88063a71fa147235fdde2f1 goroutine 3797 [semacquire]: internal/poll.runtime_Semacquire(0xc42016258c) /usr/lib/go-1.10/src/runtime/sema.go:61 +0x39 internal/poll.(*fdMutex).rwlock(0xc420162580, 0xc426370000, 0x62000) /usr/lib/go-1.10/src/internal/poll/fd_mutex.go:152 +0xad internal/poll.(*FD).writeLock(0xc420162580, 0xc426370000, 0x62000) /usr/lib/go-1.10/src/internal/poll/fd_mutex.go:237 +0x32 internal/poll.(*FD).Write(0xc420162580, 0xc426370000, 0x61e52, 0x62000, 0x0, 0x0, 0x0) /usr/lib/go-1.10/src/internal/poll/fd_unix.go:243 +0x46 net.(*netFD).Write(0xc420162580, 0xc426370000, 0x61e52, 0x62000, 0xc4291d4000, 0x61e52, 0x62000) /usr/lib/go-1.10/src/net/fd_unix.go:220 +0x4f net.(*conn).Write(0xc420096038, 0xc426370000, 0x61e52, 0x62000, 0x0, 0x0, 0x0) /usr/lib/go-1.10/src/net/net.go:188 +0x6a main.sendDataToClient(0x5acb60, 0xc420096038, 0xc4291d4000, 0x61e52) /home/abx/tcp-server/tcp-gist-coder543.go:43 +0x7d created by main.sendDataToClients /home/abx/tcp-server/tcp-gist-coder543.go:59 +0x11f goroutine 3810 [semacquire]: 
I get what you're saying, but to someone unfamiliar with the job market/cost of living between the two cities, your statement offers no insight
by consecutive, do you mean the array of integers is sorted and sequential? Because if so, I suspect your underlying algorithm could be drastically improved by not treating each look-up as a separate operation, but instead adjusting the previous integer's result.
I think you changed something. We weren't seeing goroutines leaking here: https://gist.github.com/adsbxchange/a3ff906c8fe9859ae5ac728efca25b5c
The big difference is that contracts use concrete types, so the interface isn't boxed. E.g. if I have a `[]int` and then I make a new type `type stringableInt int` with a `String() string` method, I can do a type conversion from `[]int` to `[]stringableInt` without doing a full copy, whereas to make a `[]Stringer`, I'd need to do a copy because the interface `Stringer` is represented as two words in memory.
That’s correct, the array is sorted and sequential / consecutive integers. I’m not sure what you mean by adjust the previous integer’s result, would you be able to clarify a bit? 
Here you're using the interface as a type. I'm talking about using it as a constraint. When you write contract stringer(s S) { Stringer(s) } this tells you that `S` satisfies `Stringer`. You can then call `Stringer` methods on variables of type `S` *without* boxing them. I'm just saying that you could skip the middleman and use `Stringer` as a contract directly.
&gt; Unless, for example, your function opens up 2 different files, calls Seek, Read, Write and Close. Would you be happy with an error message like "permission denied"? Well, the presumption would be that all of Seek/Read/Write/Close would annotate their errors with the arguments that were provided e.g. the filename. So the ultimate error would be "process failed: Write /tmp/foo failed: permission denied" or whatever. &gt; you really want a unique error message for each action of the function that might fail I agree, but I think if you stick to the above convention, you'll get that unique error.
I'm sorry but it has nothing to do with 'memory changing behind the scenes' or anything of the sort. It is the exact problem that is being addressed in GO2 error handling changes, although without typed exceptions. I suggest you review in detail one of the other versions I referenced in a language you are familiar with, and you will see why the ugly Go error handling is required, and it is not required any where else. I cannot seem to explain the multi-level message processing and the requirements. I will try one more time that it may help. You can process a json file into a object with one call, and it will fail with an error if it cannot be parsed processed. But then, when you are processing the 'object' there are variable fields (for example maps), that may or may not contain certain values. So when processing the message (the object), and you encounter a missing field that is required in the current context (it is not always required - it depends on the sender, what they are doing, etc.) it is an error, and a rejection message must be sent back to the sender with a reference to the particular field that was in error.
Whole lotta blockchain on there with no description of what it's actually being used *for* just "blockchain"
&gt; I'm sorry but it has nothing to do with 'memory changing behind the scenes' or anything of the sort. Then why do you need to check for an error at the time of access? If the state of the structure hasn't changed, why would it all of a sudden randomly throw an error when you decide to access a field? By your own admission the memory hasn't changed. The result of the field is going to be deterministic. I don't understand what access-time error is possible?
if you've built the list of ranges that include, for example, "100," and your next value is 101, you can potentially just drop any ranges that end at 100 and add any ranges that start at 101. Depending on how your interval tree is set up - augmented or centered or w/e - this might be a faster operation.
Same people who bought all nvidia cards I guess.
I agree - This is why salaries should be publicly available. Everyone knows from the beginning what we are committing to when (or before) we apply
There could simply be no way to use operators on parameterized types, only methods of interfaces they are declared to satisfy. We could have smth like ``` type Int int func (i Int) Add(j Int) Int { return i + j } type Adder(type S) interface { Add(S) S } func Add(type S Addable)(elems []S) S { var total S for _, e := range elems { total = total.Add(e) } return total } ``` and use those sort of parametric interfaces instead. Types like `Int` above could be more complete and predeclared in an stdlib pakage.
I guess [numbeo](https://www.numbeo.com/cost-of-living/) should help in that decision?
[Done](https://expirebox.com/download/d8d49bcc39f58f4b1f70265efdd082c6.html)
That could also not be correctly profiling from runtime, the list of 'sleeping' routines does grow larger. https://gist.github.com/adsbxchange/ce4466ee8eb8c1fcdec19b3f15239f17 This what I'm testing with. 
This is my understanding: Whenever a new message comes in, it will spawn a batch of goroutines to deliver the message to each listening client. If some clients are slow, the messages may not be delivered by the time the next message arrives, and so the list of goroutines will grow. Once the messages are delivered, the goroutines exit. It might be good to ensure there is a reasonable timeout on the connections to prevent a client with a bad internet connection from collecting a large number of goroutines that are trying to very slowly send it messages. but yeah. idk!
That might be what's happening. I think we are on to it. We could use a channel to tell the go routine to quit? Or maybe just some sleep timer that if it go routine hasn't exited then close it and client.Close() VRS TCP just discards the bytes if a client isn't receiving them fast enough and that does happen now and then.
&gt; The reason why getting more granular isn't useful is simple: the err that is returned by Bar() will probably already embed something which indicates that it was thrown by Bar(). So why do that twice? What about inside of Bar()? You're just moving the problem up a stack, not solving it.
I think you have to do the proper Go installation first. After that, installing a Go extension within VSCode takes care of everything else. At least, that's what it did for me. (Win OS)
Yes, answered my own question, you have to have go installed and the GOPATH set before you can use VS Code to install the tools.
Hey, uh, can we get a more readable version please? /s
It'll install dependencies like go oracle automatically if you already have the go toolchain setup but you still need to do that yourself follow the guide here: https://golang.org/doc/install and add something like in your bash_profile or bashrc GOPATH=/usr/src/go PATH=$PATH:$GOPATH/bin 
"vgo" is now part of go with go 1.11 You can simply change your dockerfile to ```FROM: golang:1.11``` and then use the go build command
 // SetWriteDeadline sets the deadline for future Write calls // and any currently-blocked Write call. // Even if write times out, it may return n &gt; 0, indicating that // some of the data was successfully written. // A zero value for t means Write will not time out. SetWriteDeadline(t time.Time) error solution maybe!
You should also be aware that closing the same connection twice will cause the program to panic, so if you manually close the client, you need to make sure to call `removeFromConnMap` as well. If the client has already disconnected, there's no need to call `client.Close()` like you're doing in the first if statement.
I think this would be good.
 The beauty of the Internet and jerks. 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files 2018/08/29 22:46:07 accept tcp [::]:32001: accept4: too many open files
 {addtype}mt.Sum(x) // or maybe the following mt.Sum(x){addtype} 
Pretty sure vscode just doesn't support modules yet. I had the same complaint when using the Go 1.11 RCs. https://github.com/Microsoft/vscode-go/issues/1532
With newer versions of Go, you don't need to set $GOPATH. Its set automatically to $HOME/go.
Nice. You might want to raise the `ulimit -n` for the process as well, whatever its set to, but that's interesting. At some point, it would probably make sense to limit the number of connections that are accepted from a single IP.
It's good to close connections, rather than waiting on the garbage collector to get around to finalizing them. Otherwise you could run out of connections if the garbage collector doesn't finalize them quickly enough. I haven't checked the code, but that's probably a mistake I made, since the `removeFromConnMap` should probably make sure the connection is closed. Ideally, the garbage collector will ensure that connections _are_ closed, but if there's a lot of turnover, it isn't good to rely on it.
And some IP bans. Looks like that save few IP hitting it once a second. 149.56.40.242 34.233.208.215 34.211.149.81 just spamming it with connection requests over and over ... 
I'll add a client.Close() to that function.
We use HAproxy for everything here. Flexible and fast.
I have fail2ban on everything that's exposed. It's thousands an hour of bots looking for various exploits.
The good dev can handle the cruddy error handling. The bad one will forget to check a certain exception type. But yeah, there will be new syntax to make error handling more palatable for people who are used to/prefer exceptions, so in the end it will work out for everyone. * Note: to clarify, I wasn't defending that `if err != nil ...` all over the place is a particularly good thing, and I think the new syntax is an improvement. My point was only that checked errors are better than checked exceptions regardless of which syntax is used.
One thing to keep in mind is that C++ has operator overloading but Go does not. For that reason, it would still not be possible to create a generic list implementation that allows for bracket-style indexing among other things. I think this alone would help dissuade programmers from adopting alternate slice/map/etc implementations without proper consideration beforehand.
A stock connections is exactly what it was. Now it is stable, memory use even goes down!
Pretty good points. &gt; Contracts are nice, but where is the operator overloading? Personally, I'm still in favor of not having operator overloading. The problem of mismatch is real though. At some point we might want to consider adding Methods to builtin types (ugh). &gt; Restrictions on contract bodies I don't really understand this point. The proposal says that this restriction will probably be modified/lifted in the future. Why say that it probably has to be modified/lifted in the future? &gt; The generic dilemma The difference is, that this generic design doesn't *prescribe* where on the spectrum a solution falls. Nothing in the design *requires* boxing or *requires* full template expansion. It doesn't provide an answer to the Generics Dilemma - but it solves the *Dilemma*, by allowing experimentation in the future.
That's great to hear!
Do people actually limit their job search to a single programming language?
Just a few of the top of my head: - a better concept of interfaces than Java (C is not OO, doesn't even qualify) - no inheritance, composition only (again, C doesn't qualify, Java get's its inheritance abused all the time) - no undefined behaviours left to the whims of compiler implementors which may be used as "features" making code unportable - no magic, everything is very explicit (Java's annotations, C's deeply nested header files which bring in obscure macros) - first class support for essential data types (maps, arrays with auto bounds checking and channels) - a fast compiler, which doesn't get in the way of TDD (just `watch -n3 go test ./...`) Then you have `go get` (and now go modules) for package management, integrated support for tests via `go test` and the standard `testing` package, and `go doc` which parses the documentation on your own programs without the need for an external tool. C will still be useful in years to come for resource constrained environments (embedded applications), but Java is going to get it's lunch eaten twice, especially with Oracle's new "brilliant" ideas for it.
A FOSS substitute for GA, which you can host yourself, is Matomo &lt;https://matomo.org&gt;
[removed]
How is it doing, performance-wise? Is it still bottlenecked by network, or CPU, or anything?
I ran into a similar problem today with go:1.11-alpine. I don’t know why but it seems to need CGO_ENABLED to be set to false to work. 
Is that the streaming one on Git? I'm planning on testing it sooner and keeping working on it. I think the channels and streaming will scale better, but what you did and helped me with is working with the 150+ connections.
Prior art in Elixir, the "with" macro, snippet from some code I worked on: def create(conn, params) do source_id = conn.assigns[:source_id] with {:ok, activity_params} &lt;- JsonApiFieldsExtractor.extract("activities", params["data"]), {:ok, activity} &lt;- ActivityCreateService.create(source_id, activity_params) do conn |&gt; put_status(201) |&gt; render(:show, data: activity) else {:error, :source_id, error} -&gt; # handle invalid source {:error, :params, error} -&gt; # handle invalid params end end You can combine error handling with pattern matching, chaining the happy path case with multiple `&lt;-` (pattern matching extraction+assignments) as inputs to the `with` macro, and have granular `else` clauses for each invalid error type based on the error pattern. This both for granular errors where you need multiple error handling branches. If you just need one branch, you can just do `else err -&gt; err` to bubble the error upstream as-is (and this path could in theory be further augmented with something like `?` from Rust)
I was in your position for many years. Just use Go to write CLI tools as things come up and eventually you’ll get a chance to do web handling with Go too. That worked for me. 
junior to mid level devs usually do because they are often only familiar with one
fuckwad :)
If your goal is to make money then I highly recommend learning ethereum asap before everyone advertising jobs for blockchain devs realize they dont need or shouldnt be using blockchain, theres some good money to be made I think
What if `guard` were the keyword instead of `handle`? I think that would be less of a conflict. 
My goal is to make sustainable money, so I'm working boring normal soft eng job instead :P
there will always be another blockchain lol, i hear ya tho. The constraints of blockchain development are actually really interesting though. Normally we don't have to consider who is doing the work for a particular computation but when writing smart contracts you have to set a gas price and gas limit which when multiplied determine the total amount you're willing to pay and then how much of it is actually used is how much you do pay. That being said if you set the gas price too low nobody will mine it and the transaction will not take place and if you make it too high you could run out of gas and you'll lose the money. May have explained a few things not so great as I just started learning it but so far I think the programming constraints call for interesting solutions. I find myself wanting to use channels
D'oh! I was on my phone, and didn't actually see past the headline. Oops....
I can't believe that I actually typo-ed that. Thank you.
yes, and gotcha!
You are welcome to submit a PR. I'll be happy to look at it. 
I will be editing the videos down and posting them on our youtube channel. Also, you can see entire, unedited replay here: [https://www.twitch.tv/videos/302697340](https://www.twitch.tv/videos/302697340)
I’m a devops lead for a Python product and I would be able to focus on a lot more interesting problems if our app was implemented in Go.
No problemo!
'the first' no, not the first.
Fair point. Switching.
[removed]
Easy. Just do “go mod init ‘packagename’”
It seems like the conn.SetWriteDeadline is only for TCP buffer. So if buffer takes a while to fill or write fails it will time the connection out. server := http.Server{ Addr: ":8080", WriteTimeout: time.Second * 1, } https://blog.cloudflare.com/the-complete-guide-to-golang-net-http-timeouts/ Exposed by net.Conn with the Set[Read|Write]Deadline(time.Time) methods, Deadlines are an absolute time which when reached makes all I/O operations fail with a timeout error. Deadlines are not timeouts. Once set they stay in force forever (or until the next call to SetDeadline), no matter if and how the connection is used in the meantime. So to build a timeout with SetDeadline you'll have to call it before every Read/Write operation. You probably don't want to call SetDeadline yourself, and let net/http call it for you instead, using its higher level timeouts. However, keep in mind that all timeouts are implemented in terms of Deadlines, so they do NOT reset every time data is sent or received. https://blog.cloudflare.com/exposing-go-on-the-internet/ WriteTimeout normally covers the time from the end of the request header read to the end of the response write (a.k.a. the lifetime of the ServeHTTP), by calling SetWriteDeadline at the end of readRequest.
Bless your soul.
The thing is that I don't like either. What would probably be better is something like res := doSomething().MapErr(func proc(err error){logErrorToWhatever(err)})? With the `?` as a compiler exception which is equivalent to res, err := doSomething().MapErr(func proc(err error){logErrorToWhatever(err)}) if err.IsError { return err } So mapErr would run a closure on an `GenericError` type, logging it or whatever (maybe take a `func proc(err error) GenericError` modifying the err and passing it on) and the `?` operator would return the result error if there. Although, to be more "goish", maybe `?` should be something like `check`, as in: res := check(doSomething().MapErr(func proc(err error){logErrorToWhatever(err)})) 
Exactly. Maybe I'm short-sighted, but I see no reason to introduce this pattern as is. Having multiple ways to handle errors, where one isn't a clear win over the other, feels like a step backwards
Is there another go modules proxy?
[removed]
They are mostly higher than mine, but I'm in the Midwest. Am I getting the shaft?
So stoked.
https://golang.org/pkg/context/ https://blog.golang.org/context Maybe this takes care of sleepy slow routines. func sendDataToClient(client net.Conn, msg string, ctx context.Context) { err := client.SetWriteDeadline(time.Now().Add(5 * time.Second)) select { case &lt;-time.After(5 * time.Second): fmt.Println("EJECT!: Over 5 seconds in SendData - closing: ", client.RemoteAddr().String()) removeFromConnMap(client) return case &lt;-ctx.Done(): fmt.Println("On time: ", client.RemoteAddr().String()) } ...... } func sendDataToClients(msg string) { // VRS ADSBx specific since no newline is printed between data bursts // we use ] and must add } closure msg += "}" ctx, _ := context.WithTimeout(context.Background(), 2*time.Second) connLock.RLock() for client := range allClients { go sendDataToClient(client, msg, ctx) } connLock.RUnlock() }
That’s just not always the case and often the code being called gives garbage for making it clear where this error came from. 
Since you are using Ubuntu presumably 18.04, can I recommend using mwhudson's great Go snap package? \`sudo snap install golang\` Already updated to 1.11 and using it with VS Code every day :)
Awesome. 
You obviously never read the Kubernetes source code. Magic, it has quite a bit, given how the runtime tackles "generics" and code patterns for optimizarions. UB, there is some, when using gccgo optimizer, unsafe package or cgo. Java collections have it easy against those essential data types. Go is so good according to you yet Google is never going to put it on Android (even closed a ticket about it) and on Fuchsia is only used for some drivers.
Don’t do this.
Really sorry... Didn't mean to offend anyone.
file:/// :)
Would you say the context for using this pattern specifically (middleware, not necessarily any decorator pattern) is limited? Im thinking of even the example where you add a logger. Most of my operations tend to have multiple log lines between business logic because I need fine grained logs of everything that is going on so if i were to use this pattern then basically every function would have to be middleware, or do you find you selectively apply it to a few concepts like http, caching an expensive computation, some logging procedures, etc? Love the articles, thanks. 
Here is another version: https://gist.github.com/coder543/b18761d653e3fa938258709c0ee05f46 This is my refactor using channels. I tested it against the server and port you provided earlier using one of my cloud servers, with 195 clients connecting to my cloud server from my home network (the maximum that could be sustained continuously, maxing out my home internet connection). It used virtually no CPU and about 325MB of RAM to support that many clients. Using clients local to the server, it was able to support in excess of 2000 clients... but that obviously allows unlimited bandwidth, since they're local. The section of code that deals with concatenating buffered messages showed promising performance when dealing with thousands of local clients, but it seemed to have zero impact when testing with my 195 non-local clients. I left it in because I think it doesn't hurt much (just a message copy per message per client), and it might make a difference for a slow client... but I'm not sure. Feel free to remove that buffering logic if you adopt this version of the code. The obvious omission in this code is anything dealing with client deadlines/timeouts. I saw your messages on the topic, but I haven't had time to learn about it for myself, so I'm not sure what the right approach is there. However you modified the code to support client timeouts can probably be applied here too. This version of the code will cleanup clients that disconnect, and it will drop clients that are too slow, but the goroutine for that client will exist until it finishes sending the messages that were queued in its channel before it was deemed too slow. Without timeouts, such goroutines may _never_ exit for practical purposes if someone is using a maliciously slow client.
Just a few days after Comic Con San Diego. Coincidence?
Most definitely.
There's a lot of bad blood with Node and PHP in general that makes seniors focus on a single language. While often unavoidable in the grand scheme of things, a 100% Go job is pretty rewarding by itself, given that criteria.
A foundation is being setup with multiple contributors / hosts
Microsoft at first. Some kind of foundation later. That’s what I heard back at March. Not sure if this plan changed.
Any guides on learning eth development?
Well, depends how remote it is.
I would argue that bringing on new people and having them be productive with a go project is just so incredibly easy. It's a tiny language that you can get the hang of in a short amount of time. There's typically just one way of going about things making most code very familiar and easy to grasp, which results in less time spent on code reviews or modifying someone else's code.
[removed]
More precisely, the go tools used by VSC don't support modules yet. I can't wait that they support modules. 
Let say it uses $HOME/go when $GOPATH is undefined. This directory must have a bin, pkg and src subdirectory. And you must create one subdirectory in src per package or binary. But this is before go1.11. Go modules can be created in directories outside of the GOPATH, but modules are not yet supported by VSC. So for now, until modules are supported, create your programs in $GOPATH/src/ or $HOME/go/src if $GOPATH is undefined.
Is the website running Erlang? I see \`Server: Cowboy in the headers.
&gt;SELECT \`blogs\`.\* FROM \`blogs\` INNER JOIN jotts on blogs.id=jotts.blog\_id WHERE (\`blogs\`.\`id\` = '1')
That query looks good, scratching my head...
I've updated it with the models. The query seems to return the data with an empty array. I just need the Jott content in there. 
It’s heroku reverse proxy - the site is obvs in golang 
I won’t presume to tell you what you meant. I will say that your wording _looks_ like an attack. If you don’t care about that, fine. You didn’t have to take that edgy tact, and that’s the bullshit I’m calling. Don’t pretend that 1. There haven’t been “non retarded” arguments agains generics, and 2. That you have said anything _but_ a mere opinion without evidence. Your opinion of the real world is, at the end of the day, just your opinion. This is what reddit is. Random people giving opinions about things they care about. That last sentence added zero weight to your actual argument. It was a meta argument about how you think the others guy puts forth “retarded” arguments, and it is an opinion which is a exactly what you just criticised doing. 
Yeah, I still have a lot of respect for Sam for producing what he has, and playing the role he has played in this so far, but I have been losing that respect slowly as time has gone on because of how he's treated this situation.
&gt;I will say that your wording looks like an attack. It's an attack. But it's clear it is an attack to the arguments. &gt;You didn’t have to take that edgy tact... There's nothing edgy about it. &gt;... and that’s the bullshit I’m calling. Please explain why it is edgy. Otherwise you are not calling anything. &gt;Don’t pretend that &gt;1. There haven’t been “non retarded” arguments agains generics Here you are full of shit because I'm talking about his arguments and the ones like that. Not about reasonable arguments like slow compilation process, executable size, etc. &gt;That you have said anything but a mere opinion without evidence. Your opinion of the real world is, at the end of the day, just your opinion. No, it's not an opinion. The evidence is on github and other hosting platforms. Almost all projects written in C++, C# or Java (just to take the most popular languages with static typing) are not using their own written generic data structures over the ones included in the standard libraries. That's not my opinion. **That's a fact**. You need to learn the difference. &gt;This is what reddit is. Random people giving opinions about things they care about. So? That doesn't mean opinions cannot be full of crap. His comment was full of it. Not my fault his premise (software written in other programming languages with static typing and supporting generics are using their own data structures) is false. &gt;That last sentence added zero weight to your actual argument. It was a meta argument about how you think the others guy puts forth “retarded” arguments, and it is an opinion which is a exactly what you just criticised doing. I see the problem. Please read about logical arguments. There's a good course in edX actually. There is a clear defnition about what flawed arguments are. It's not a subjective matter.
First, I really appreciate to see feedback popping up about the presented design drafts. This is exactly what we need going forward. So, error handling. There are three general ways to deal with error ranked from worst to best: 1. Ignoring it 2. pushing it up the stack (re-throwing it) 3. acting on/handling it Your examples are focused on the second point with 3 being probably the best and 2 being the worst as this mixes handling and pushing it up (what if an upper function logs it too?). As I see it logging is the simplest form of error handling. The problem of error handling in Go imo was never the individual error check but multiple error checks with very similar code. I like to draw an analogy to a compression algorithm. You can't compress random data, in this case very individual error handling, but repetition very well. And in this point I absolutely agree. People are lazy and will be less likely to act on individual errors. The thing is that adding parameters to check/handle can be done as well with a simple function. errContext := func(err error, name string) error { if err == nil { return nil } return errors.Wrapf(err, "failed to open %s", name) } handle err { log.Print(err) return []byte(nil) } f, err := os.Open("myfile.go") check errContext(err, "myfile.go") data := check ioutil.ReadAll(f) return data This isn't that good of an example but I hope it shows the point. What we have to accept with the draft proposal is error handling becoming a bit less specific and relying more upon the good composition of errors to convey meaning.
&gt;Next time please use gist.github.com Apologies, I'll be sure to remember this. &gt;If no match was found, match will be nil. So the code should do something like.. Yeah this now seems like a stupid/trivial mistake on my part. But thank you for pointing it out alongwith the fix.
Please change the title to include 'draft'. This is not a proposal yet and still need work to become one.
The package seems to be called \`go\` here...
this was a great talk.
Heroku's reverse proxy is called vegur. There is a header `Via: 1.1 vegur`. You're probably right, because vegur is based on Cowboy: https://github.com/heroku/vegur
Ramya is one of the core devs of vscode-go plugin: https://github.com/Microsoft/vscode-go She's great!
tl;dr (fin)
&gt; Personally, I'm still in favor of not having operator overloading Me too. &gt; I don't really understand this point. The proposal says that this restriction will probably be modified/lifted in the future. Why say that it probably has to be modified/lifted in the future? Because it will only be modified/lifted if people think that it needs lifting. If nobody says anything, then clearly it doesn't need lifting.
They want 20-30 hours per week at $30k, or $20-$28/hour, and "must be an expert in Go." I think the fact that this job posting made it through to my eyeballs should be considered a bug on golang.cafe. 
I am glad that he documented his experience (I weep that it was done on twitter). Hopefully this is the end of it.
I fear we haven't heard the last of this. Stumbled this on Twitter via cheery retweet and likes where Rust folks opine on Go leaders on how to manage community. 
Nah, it seems strategic move. Comic Con visitors are mostly interested in Go. So they can take weeks of time off to attend both conferences.
As I fed back on one of the error proposals, make sure you don't evaluate the proposal based on a handful of lines that fit into a blog post or reddit post or something. Go find a nice big function you've got in your real source code that does a lot of interesting error handling and rewrite that in the new system instead. And try to find one that does _interesting_ things, not just dozens of straight returns. Your MapErr function, as specified, may look OK on one line but I can tell just glancing at it that it's going to have terrible visual redundancy if you have six or seven of those in a row. Not to mention you have a thing that looks like a method call, but isn't. In fact I'd say check and MapErr are redundant, and also, what's the Map doing there? This isn't a map operation at all. (I assume this comes through the line of "flat map" operations, which are already poorly named and indicates that whoever came up with the "flat map" name poorly understood the operation in the first place; this then appears to take map even farther away from its original meaning.)
The language has always been far less relevant to me as a senior than the infrastructure.
Very cool. I was wonder how it would be done with a channel implementation. I'll do some testing today. The final code you did with the SetWriteDeadline and the bounce them if send go routine runs for more than 5 seconds is using 16MB of ram under full load and nearly no cpu 0.7%.
This is working for me (keep in mind that the COPY, WORKDIR etc are not the lines you need to focus on here): FROM golang:latest as builder WORKDIR /usr/src/tmp COPY . /usr/src/tmp // This line after &amp;&amp; is the important part RUN cd /usr/src/tmp &amp;&amp; CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -mod=vendor -o main // command or other things here
Also running go mod vendor and committing it right now but I may move that to the docker file.
some nice parallels with redux saga
If you cannot quantify why you would use Go over those languages you are not in a position to be making these suggestions, furthermore its irresponsible to your own future and the company. Expect to be ignored in life when you make shallow assertions like that. If you want to use a new technology you have to sell it and convince everyone which means you need to not only know that technology very well but you need to know comparable technologies well.
Good catch, edited.
You're sort of relying on the `err` convention for that to mean anything. If you have on foo { return fmt.Errorf("...") } it's not really suggestive of what it's doing. Whereas `handle` is suggestive of being the complement to `check` on its own. I suppose you could make `on err` mandatory syntax, but that seems a bit more magical than anything in Go today.
I'd disagree with the typescript assertion. True go wasm is just taped together as of yet but coding in it currently you can more then definitely see the benefit of using interfaces that act like abstract classes with embedded types with js. The only issues I see is it's still beta and you still need callbacks. But I fail to see the benefit of typescript over go wasm setup.
When annotating an error, I suggest not to repeat the called method name and its parameters as the caller already knows about them. Instead, just report about the subroutine error the caller doesn’t see otherwise. I would actually want to see this approach to be applied everywhere in the std lib. 
Does Goland support go modules? I too can’t wait for go modules support in vscode.
Typescript is very mature, go wasm is not. /thread
Will there be a video of the talk? _(not sure where it came from)_
&gt; But I fail to see the benefit of typescript over go wasm setup. 0 dependencies with Go/C/C++ Libs compiled to WASM.
At least use websockets for frames, http will be incredibly slow
Sorry, no, I meant "Type conversions" instead of type casting, I always mix that language up. They reference it in this section of the draft design https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md#contract-syntactic-details Where the contract might look something like contract convertible(_ To, f From) { To(f) } to allow writing function that accept anything that can be converted to something else, e.g. anything that can be converted to an uint64 func FormatUnsigned(type T convertible(uint64, T))(v T) string { return strconv.FormatUint(uint64(v), 10) } I don't think this is behavior you could achieve with interfaces
Yeah, this was the opening talk at Gophercon this year. 
&gt; Some people just can't accept "defeat" It isn't about defeat it is a question of process. If Russ Cox clearly said "don't waste your time guys, we are working on it", then a lot of people would have spent their weekend with their families and friends instead of working for a prototype for Go package manager. It's a failure of communication, from the Go team's side. Now though it's clear. There is no "community process". The go team is in charge, so don't bother making proposals for the language. This isn't a community driven project. And it's fine. The dep dram isn't going to happen again anytime soon. The go team does its own stuff, if the community can profit from that then good. Otherwise Go wasn't made for you or anyone else. 
&gt; Nothing else needs to be installed on your server. Even no Docker? 🤔
This isn't a constructor, there are no constructors in Go, this is called a factory function.
An initializing constructor is just a name, the Effective Go itself uses this term.
Was it faster because the old code was sloppy though? Was the old code dotnet or Javascript? 
go doesn't have constructors, as someone else pointed out, and your definition of "imperative" seems arbitrary and nonstandard. you also shouldn't use the satori uuid library: https://medium.com/@theckman/keeping-important-go-packages-alive-5242917f83e8 and https://www.reddit.com/r/golang/comments/99eneg/v310_of_githubcomgofrsuuid_released/
The check/handle proposal would pretty clearly push developers towards "repeat the called method name and its parameters" and pretty clearly away from "report about the subroutine error the caller doesn't see otherwise". If this pattern is applied consistently, it doesn't matter, the resulting errors will read identically.
I'm writing this as a Go programmer. I know there are no real constructors. It's just a concept. An initializing constructor, as written in Effective Go. I also know about the issues in satori's package, I appreciate for your tip but I just used it as an example. I might edit the post in order to others don't focus too much on pointing that constructors don't exist.
&gt; Was it faster because the old code was sloppy though? I cannot say for sure, the code was written by multiple people with different backgrounds. If you ask them, they will tell you it was well optimized by their own standards. &gt; Was the old code dotnet or Javascript? It was not .NET nor JavaScript.
There can be an error creating some UUID variants. How should that error be returned to the application if not through a return value?
That's why I suggest using `GenerateV4()` instead of `NewV4()`
Yes, thanks for pointing that out! Now the count is one, but it's still hard to find those across the `stdlib`.
So if your doing it on cloud providers such as Amazon or Digital Ocean, I'd recommend [Terraform](https://www.terraform.io/). There's a couple of tutorials out there on how to get started with Amazon or Digital Ocean. Other than that, you can just jimmy up a bash script to deploy and remove the binary. 
Call a cat a cat. A function is a function and nothing else in go, which makes your point moot. Functions should return errors if needed.
Yes folks, i'm moving on. This is it. i said ages ago that i would talk about my experiences going through this, and i think it's doubly important that i do so given the outcome. i wouldn't want anyone else to have to go through what i did, and i think that getting it out in the open is the only way to move towards a better future.
&gt; That's why I suggest using GenerateV4() instead of NewV4() It's the same function with a different name. There'd be no `NewV4` anymore, as it would become `GenerateV4`.
Also most of the `os.File` constructors - `Create`, `Open` and `OpenFile` all return an error.
i get it - we definitely had bugs. One goal of the thread, though, was to try to highlight that while people were frustrated by bugs in dep (and i get it, and god do i wish we'd had more time to address them), the basis on which Russ _initially_ rejected it really had little to do with those problems. https://twitter.com/sdboyer/status/1034901232241004545 i'm pretty sure that if, say, we'd had the weight of the Go team helping us, we'd have squashed those bugs in a month. But another point of this thread was also to indicate that i am indeed accepting defeat. We lost the fight. It was a dirty one, and i hope we can make future processes better.
I'm basing on Effective Go. You could ignore it telling you not to use `GetThing()` and use `Thing()` instead, as they're both only functions. I'm not imposing a rule, just a debate over naming an initializing function. That's something I noticed about using the `stdlib` and I'm trying to share this concept with others.
&gt; just a debate over naming an initializing function. AKA bike-shedding. 
 Your opinion is purely arbitrary here.
&gt; I'm basing my argument on Effective Go. No your not, Effective Go isn't saying "don't return errors from functions".
I think it's more a suggestion than a debate. I said debate because some counterarguments were debatable. It's OK not to agree, mainly about such a harmless concept.
&gt; Stop returning errors in constructors, use imperative functions instead isn't framed as a debate.
It's not saying that but it encourages you to be sensitive about naming your functions. It even says that `ring.NewRing` should be name `ring.New`. Why bother about that? I only bother because Effective Go exists.
&gt; brought in Yehuda katz to write afresh. go mod was written by Katz !?!?
The title is like that to whet other people's curiosity, to make them curious about the text content.
Your code is printing the size of the 0th index of the "outer" array, which is `[12]string`. `len(field)` will give you the size of the outer array, which is 10.
That's the point! They're imperative words. It's all about not using the `New` word to return errors.
Okay now how would i get it return the lenght of the second dimension
&gt; The title is like that to whet other people's curiosity, to make them curious about the text content. AKA clickbait /s Nah, it sets the tone for the discussion.
Sam I respect you for tremendous amount of work you and other people have done with dep. The problem is - while dep was good solution, it never truly highlighted the problem it was going to solve using solver. Better yet, it only recently started to properly explain why it was selecting one version over other. Solution to any complex problem involves not only directly solving the problem in question, but also establishing the idea, and new rules for the solution to work properly. We all knew that current model with vendor directory was a temporary solution, but we desperately needed something that would work, and work reliably. Dep "marketing" posed it like a reliable solution. But the fact was - it wasn't. Crashes clearly showed that dep expected best case scenario (properly formated code, non conflict vendors) but the real world included malformed code which even don't compile, to which dep wasn't prepared. I mean - I can't compile without dependencies, so I can't type check code for correctness(mistakes happens), but dep expected code to be correct. The best - it would simply crash. The worst? It would froze without telling me what its doing and why. I dunno - maybe dep was lagging in slow network. Maybe GitHub went down. Maybe something else. The problem is - dep never told me. I'm sorry that it all happened like this. But at the same time I'm unsure that all that effort which went to effectively solving version problem, couldn't be used to make something more robust. Tho judging from php composer I'm unsure if solver can properly tell me why it can't solve version problem in human terms) 
what would I (the user of said library) gain by that?
If you're just doing calculations you may want to check out aws lambda, otherwise I'd recommend looking at linode for dev servers. 
😢 i'm really sorry that things have gone this way, on so many levels. A key thing i was trying to highlight was the impossible situation i was in (and, yes, how Russ' choices made it even worse). Russ set a bar that entailed i just go searching for problems. By following those rules (and hitting the bar), it set me up in a position where i'd invested all my time in only having negative things to say. Worse yet, the problems are non-obvious (but not insignificant), which make it very hard to play to the general audience...and my skills at distilling down complex ideas still need a lot of work. Now, i'm just never going to be a person who shies away from calling out harmful community behavior. And i get that it's painful to watch all this go down. The best i can say is that, even if it's not always obvious, i have never made an argument that i do not believe has a sound technical basis, erases known harms, or intentionally misleads about choices i have made, or technical costs it incurs. (Often at the cost of making my points overly verbose)
The same you gain by following (and using libs that follow) Effective Go. It depends on how much you care about those naming concepts.
```go fmt.Println(len(field[0])) ```
maybe `uuid.V4()`?
could be, but in my opinion I still prefer imperative verbs
The page says $3k for each person _(the referrer and the applicant)_. Unfortunately, their service is only available for US citizens… &gt; **Application on the waitlist** &gt; &gt; We apologize again that we can't process applications for programmers without US visas. We know that the majority of good programmers in the world live outside the US. Unfortunately we're still just a small team. Right now we have to focus on programmers who can work in the US but it's one of our top priorities to open up internationally as soon as we can. Which is quite funny because I actually passed the pre-liminary interviews last year when I was in New York. After moving to Canada, my application was rejected _(for obvious reasons)_ which is a shame because I wanted to find a remote job with an US company while living in Canada. [Hired](https://hired.com/) does the same, but at least they have some companies from Toronto, not very good salaries I have to say though.
&gt; aws lambda AWS Lambda has a max runtime of 5 minutes. In addition it's designed to _respond_ to HTTP requests.
Rust package management solution is started afresh by Katz. Original one was written by someone goes by username 'catamorphism' and it was rather unceremoniously dumped. So I don't see taking inspiration from Rust community is great idea.
Terraform looks great. It's FOSS and will solve the need of setting up and tearing down the infrastructure. https://github.com/hashicorp/terraform
Oh OK. Some Katz wrote cargo? interesting.
Got it, are you able to give any more context to the project/calculations you're doing? If you're just looking to get it up as quick as possible I'd compile a bin for Linux and scp it into a cheap instance like the ones on linode.
The Dep team didn't listen at the Go core community ;-)
You noted that Go doesn't have "real" constructors. That's okay in large part because we conventionally we use NewXxx, so I know where to look to see if there's anything special about initializing this type. I can check if the library defines NewXxx as a strong indicator as to whether the type may need some additional initialization. If I myself know I need to do extra initialization, I can just look for NewXxx rather than having to wonder if this particular author chose CreateXxx or MakeXxx or ConstructXxx. I think an adherence to "functions that return errors must use verbs" does more harm than good in this case. The established convention is useful.
what's the benefit/use of PlusCal? I can't find a succinct answer.
I see your point, and while I'm all in favour of some grammar pedantry, I don't think the distinction matters here. `new` in programming languages I normally read like a verb anyway (as in "create new"), and none of the Go tooling marks a distinction. I will also offer `gzip.NewReader` and `aes.NewCipher` as further stdlib examples...
I always think about this pattern to be followed by good docs. I mean, GoDoc is a platform given to use out of the box, we just need to comment the code and place "imperative constructors" in the right place to work like a beacon in the docs. Again, I'd have never bothered about that if Effective Go didn't exist. But it made me care about naming functions. `GetThing()` is better to link with a getter for Thing, but the guidelines say that `Thing()` is better. Why should we even care then?
That's fair, and I do respect that you are really trying to be helpful here. I feel like your message has been muddled up with politics and drama a bit. Ultimately, you want what's best for Go, so does Russ, and one solution had to "win". At this point I think it's best to just to see how it plays out with Go Modules. I can't even understand how frustrating the situation must be for you after having put as much time and effort into this as you have, but it is what it is.
It's nice to know these other examples exist, as I said there were none, but I still think there are few. Anyway, I couldn't find a single Go dev here that agrees with me, and that's OK, it makes me wonder if I'm being too harsh on the matter.
Dropping those truth bombs.
&gt; Go is not true open source project technically it is open source. It's not "open governance" or "community driven" and that's fine, it's just should be extremely clear to anyone outside google who wants to contribute to Go core ,that's my point. 
thanks. i actually think the "one had to win" approach is only half true, and part of the unhelpful perception around this process. My take is that the principles in, and some algorithms of, MVS are super useful as part of a larger system - so I'm all for collaborative effort. But his take, I think it's fair to say, is that to have a SAT solver at all is losing, because the overriding goal is "no SAT." 🤷‍♂️ 😢
It seems clear to everyone who would understand basic fact of life that one who pays ~99% funding for a project will get to decide its direction. This is true for any project. Of course some people can feign surprise that they do not get final say as community leader when there was no election for leadership in first place.
Because the added Ring suffix adds nothing of value just makes it longer
I salute your persistent commitment and general awsomeness. 
Sure, you could in theory add a new feature to GoDoc where a "constructor" can be explicitly flagged. I just don't see why that's better than following the existing convention that those constructors are always named `NewThing()`. Caring about naming functions is good. Naming all your "constructors" `NewThing()` _is specifically_ caring about naming functions. The `GetThing()` naming is actually a great example of this. Functions that return things are often named as nouns, indicating the thing they will return. This pattern is followed for functions that can also have errors. "Constructors" essentially return new things, hence their conventional name, but they also can sometimes return errors. Everything looks consistent to me. What part of Effective Go caused you to start thinking that only functions named as verbs should return errors?
I’m sure they will take some time to edit and upload, this talk was on Tuesday morning. 
[This section](https://golang.org/doc/effective_go.html#composite_literals) made me think that `New` constructors are simply boilerplate functions that initialize structs while functions named as imperative verbs usually perform an action (and the action is exactly what the verbs says) that might return either a value or an error if the action goes wrong. It's basically a boilerplate vs. actions concept.
I know it's hard to see this kind of stuff. This wasn't "the worst possible light," though. Just an unfavorable one. I held back. My reality with him privately diverged significantly from the public image.
They have an api you can use to set them up. Check out https://github.com/kahkhang/kube-linode to see how they do it (or just use it if you want to use kubernetes) 
Thank you for `vim-go` it is my go-to editor for Go.
In keeping with the pattern: contract convertible {_ To, f From}{ To(f) } // and contract convertible { _ To f From }{ To(f) } After a couple of days of thinking on this, I still like the distinction of the curly braces along with the alternate placement of the type parameters (#3). With the current location/parenthesis there is a noticeable amount of mental processing for me to parse what's happening. This may decrease with more time, but it has not decreased for me at this early stage. &amp;#x200B; Aside from that, after a number of readthroughs, the proposal is continually inspiring and looks to be significant and wonderful work.
It is! There is a env-var (I forgot its name) which is currently set to auto. If you are working outside of gopath and in a subdirectory of a module all go-commands will work properly.
Thanks! You're my hero for all your work on vim-go :)
Interesting feature, a nice bit of extra piece of mind. Wonder if there will be any tooling to build the version archives as mentioned.
Basically OP only wants to introduce Go because he wants that nice, satisfying confirmation that he has good ideas that improve workplace/product quality, but without the experience that put him in a position to have those good ideas. He's seen other people being praised at other companies for introducing &lt;new technology&gt; and what monkey see is what monkey do.
I don't see the situation like you said but quite the opposite. The Go team has listen to the community that was not satisfied with the experiment of Dep and wanted something more Goish. Package management is typically not a "Google things", with a monorepo and a fork of each dependencies they don't need it. There was a lot of feedback, cooperation and enthusiasm from the community to vgo since the first draft. We even paused waiting to see the concerns of Sam. A lot of changes, since months now!, was made after this cooperation and it will be more, the experiment continue at least to 1.12. The discussions are even more public than it was with Dep when i see the story told. It's everytime like that when we program, we try, we throw out, we try again and in the Go community we like to throw code if we find something more simple. And in the end people who want an idea about the situation will just say : show me the code ! (and take a beer) 
I like seeing these designs evolving. I hope we get more proposals soon. I'm thinking the complexity of the language will explode when generics are implemented in areas such as reading and writing code, and updating the tools to work with them, pprof, race detector, etc. But I believe the language will benefit enough that these complexities will be a small price. Stuff like compile-time type checking, better text/template and html/template, even faster code (though compile times will probably increase a lot)... So yeah, I'm excited to see where this is going.
&gt; The Go team has listen to the community that was not satisfied with the experiment what community are you talking about? who did the Go team listen? 
GoLand supports Go Modules since the announcement of vgo, yes.
What was the original code written in?
Ahh so you’re one of those assholes that the next person who comes along to maintain the code will hate.
Look at the [issues Rust has to face because of angle brackets](https://github.com/rust-lang/rfcs/pull/2527). I think parenthesis are vastly more readable (or square brackets for that matter).
If I were a bot who can't sarcasm, I'd say your _super useful helper functions_ will still exist, but the compiler will be the creator of them, it will also be the checker for their integrity and safety. You are to one providing the rules still.
It’s a simple bit of code. If they can’t figure it out just by looking at it, they have no business being there 
I've added the salary on the job view. &amp;#x200B; To be honest At the moment the code is not something I'd feel proud about, it's quite a prototype with copy-paste everywhere and used to test if the idea made sense. Once the idea is validated I will think of polishing it (add custom page to submit jobs) and open-sourcing it. Thanks anyway for the interest! I will keep you posted
Sometimes constructors can error, so naturally they need to return an error in that case. And as for naming, when I'm importing a new library it's very natural to type library[.New](https://libraryname.New) and wait for autocomplete to make a suggestion. The only option is to panic on error in constructors, which might make sense, and that's exactly what the lib you refer to proposes: u1 := uuid.Must(uuid.NewV4()) &amp;#x200B;
Awesome, thanks. I didn't know `go list` was module-aware.
i hope you get fired 
Why do spawn a bash process just to check if an executable is in the users PATH?
What's your suggestion? Try and check for a 127 exit status?
Maybe `exec.LookPath`?
&gt;exec.LookPath I'll look into it, thanks for the tip.
&gt;Really, you just need to come here to see how retarded are the arguments against generics Why did you add this to a well formed comment? You come here to see some pretty good arguments too. I mean you come here to see some pretty "retarded" arguments for generics also. It reads as a broad comment about the community. &gt;Here you are full of shit because I'm talking about his arguments and the ones like that. Not about reasonable arguments like slow compilation process, executable size, etc. Excuse me if that's not obvious. Because it's not. &gt;No, it's not an opinion. The evidence is on github and other hosting platforms. Almost all projects written in C++, C# or Java (just to take the most popular languages with static typing) are not using their own written generic data structures over the ones included in the standard libraries. That's not my opinion. **That's a fact**. You need to learn the difference. The data might be a fact, that doesn't make your conclusion about the data a fact. Learn the difference. You could, for example, make an argument as to why Go is different to these languages. There's several avenues that one could use to come to a different conclusion. Not that you are wrong here. Your conclusion is strong, but it isn't a fact. You don't \_know\_ that Go wont be different and people wont make fractured generic data structures. &gt;So? That doesn't mean opinions cannot be full of crap. His comment was full of it. Not my fault his premise (software written in other programming languages with static typing and supporting generics are using their own data structures) is false. Listen dude, you're smart. You don't need to call people's arguments retarded to make your counter argument, and the way you did it was unnecessarily and unhelpful. Thanks for the discussion though. You are very eloquent, and I appreciate being forced to think. &gt;Please read about logical arguments. There's a good course in edX actually. Thanks for the recommendation sounds good.
there are few ressources but it seems they add more and more on [https://github.com/golang/go/wiki/WebAssembly](https://github.com/golang/go/wiki/WebAssembly)
In the sense that you’re able to use it for a given purpose, yes. It’s a bit masochistic to go against your preferences because you also likely have nearly or over a decade worth of experience that tells you development in PHP just isn’t worth it. It’s a bit like buying a car, you go up in terms of class, comfort. The first cars will be junkers, but it’s more realistic you’ll go from an Audi to a BMW, than go “down” to a Toyota. Languages which have poor tooling and other bad qualities are poor choices for seniors, and it’s not hard to say why, comparatively. The most golden rule is: use what you know. Years of experience will always outweigh little/none.
It was not kobol.
VB 6 😂
Note: this just spawns external commands to do the work (on Linux).
Thank you!
If you're upgrading from 1.10, you should be able to continue with your current IDE, given the compatibility promise. I personally use VSCode, but I saw [vim-go](https://github.com/fatih/vim-go) is getting ahead of the game with module support.
[removed]
Nice. You're a wonderful human being and you've made my life slightly more pleasant.
GoLand 2018.2.2 has native support for Go Modules when using Go 1.11, with all functionality working out of the box. You can also use GOPATH projects as before.
So, does a blocking system call (io) block an entire thread or just a goroutine? There was a slide on this to the end but for me it isn't that clear.
I quite like the idea. If the NewXXX-function really does only allocation and barebone initialisation it can only fail if the memory allocator fails and you are screwedup anyways. 
&gt; What would probably be better is something like Does it really improve anything? res := doSomething().MapErr(func(err error) { logErrorToWhatever(err) })? vs res, err := doSomething() if err != nil { logErrorToWhatever(err) } Realistically, you save one line of code. No lines if err is the only return value and can be included in the if statement. But more importantly than number of lines is that nothing is really done to deal with the tiring repetition that is the main complaint about the current error handling situation.
Looks like you’re using GVM and it has boogered your config. 
&gt; You obviously never read the Kubernetes source code. True. Please point me to the juicy parts. &gt; Magic, it has quite a bit, given how the runtime tackles "generics" and code patterns for optimizarions. In that sense, all compilation is magic. This is not what I was referring to. I was talking about obscuring meaning behind constructs at the level of the programming language you are using (Such as annotations and certain types of C macros. Not all of these are bad but some of them are terrible). &gt; Java collections have it easy against those essential data types. Compare `h := map[string]string{ "a": "b" }` with this obscenity: https://stackoverflow.com/questions/6802483/how-to-directly-initialize-a-hashmap-in-a-literal-way As Pike put it, programming shouldn't be a "debate with the compiler". &gt; Go is so good according to you yet Google is never going to put it on Android (even closed a ticket about it) and on Fuchsia is only used for some drivers. They designed the Android SDK's in a way that relies heavily on (Java) inheritance, shooting themselves in the foot. Bindings for other languages would be much easier to implement if they had favored composition. This isn't a result of Go's faults, but of bad design choices and lock-in to the Java way of going things.
I seem to remember it will block the thread but the scheduler allocates an extra OS thread so that goroutines are not blocked
I think there is a little bit of misunderstanding. &gt; 4. Author merges PR, which breaks because go get -u also updated a different dependency. If I run go get -u in my project then I am explicitly asking for all packages to get updated, but this is not equivalent to what happened in the blog post. The command I ran in NPM land was effectively: go get -u codeintellify@newversion &gt; but the bot could do the same with NPM NPM does not allow this. It might surprise you to hear, as it surprised me, that `npm install @sourcegraph/codeintellify` updates all dependencies, even those completely unrelated to codeintellify and its transitive dependencies.
Bless you fatih 
Emacs. But I recommend this one for almost everything except gardening.
Personally, I've wondered for a while now why NPM and Cargo work the way they do. I didn't really start dealing with versioned dependencies until I tried working with Cargo a while back, and now I have to use NPM ^(Yarn, actually, but it's basically the same thing for most cases.) basically daily. I know there was a development history here and it's not like package management just started in the state it's currently in, but from my point of view it seems like the primary purpose of lock files is to inefficiently disable basic features promised by the summary of the package management system. The system is designed to do partial automatic upgrades, but that's bad in a lot of cases because it breaks repeatability and determinate builds, so lock files were added to allow the system to stop itself from doing a lot of what it was originally designed to do. I assume I'm missing something, but from my point of view it just seems like the whole system makes no sense. Quite frankly, when MVS was first detailed, my only thought was 'No duh.' It seemed like a no-brainer. Given the massive argument over it I assume it isn't quite so, but the more research I do into it the more confused I get.
Video tech is pretty much convoluted. However, there are basic frameworks to follow that you have a peace of mind. Look at existing technologies from capturing camera input, encoding, and delivery. Read the formats on coupling video and audio together or in different streams as well as the m3u8 file. Read how HLS technology works, ffmpeg and other tools to enable it. The major issue with this is scaling, so HLS it with existing web technology scaling practices and you would be good.
There are so many possibilities that it's pretty hard to give you much to go on. I think I would suggest figuring out what you want for your client first, and then you'll have a much more limited set of possibilities for the server. For example, there are off the shelf HTML5 video players to which you'd only need to present an HTTP stream of an MP4 video. Next you'd want to figure out how you're getting the real time video stream to your server; I don't know how these sorts of things work, but I'd guess you could find some documentation on what OBS or GoPro can stream to. Then you're probably just wiring that up to instances of ffmpeg that your server spins up. Piece of cake ;-)
Same. VSCode works wonderfully
8MB virtual stack size. I don't believe it's actually been allocated
&gt; The issue is, that the manifest was updated only for codeintellify and then all of the lockfile got pulled forward. This isn't quite right. Not *all* of the lockfile got pulled forward, just all the transitive dependencies of `codeintellify`, which is enough to cause problems.
If you want module support, you will have to wait, but I do think VS Code support is fantastic overall.
&gt; This is a problem with a poor design choice in npm, not with the SAT algorithm itself. Not the algorithm, but its implications. The requirement of a lockfile is a characteristic of the SAT solving approach. The design sorta requires an update to a) update the manifest, b) re-run the version selection and c) persist that decision. The cargo solution, AIUI, modifies this to a) update the manifest, a1) change the version of `foo` in the lockfile, a2) check if the solution is valid, b) if not, re-run version selection and c) persist that decision. I.e. if one dependency needs to move forward, all the others will still be moved forward, even if there's no actual need. This solution (AIUI) still only fixes this problem one level deep; as soon as you move past that, it remains existing. In a way, the problem *is* fundamental to the algorithm, as you can't selectively update the minimum set of packages necessary. Because the naive way of doing that (update `foo`. If any dependency of `foo` needs to be updated, choose the minimum newly valid version. Recurse) would potentially run into conflicts. That's exactly why you need to use SAT solvers in the first place. In MVS this is different. If one dependency needs updating, only the packages in the transitive dependency set that actually *need* updating, will be updated. By simply incrementing the required version of a dependency, said selective update happens automatically, recursively. That's because the naive version from above *is* what MVS does in that case and because MVS does not allow for conflicts to happen because of that. So… the more I think about it, the more I disagree with you: The problem *is* actually a fundamental problem of the chosen algorithm. No veneer of design choices or configuration gets around that.
Easy using HLS, but you will have about a 10 second delay minimum. If you don't want a delay take a look at WebRTC. Also I wrote a little demo a couple years ago for a project I was working on. With r/https://github.com/colek42/streamingDemo I was able to achieve latency less than 100ms on a local connection.
The easiest format I've found is motion-jpeg. I can upload an example later today. Most webcams support mjoeg, though you have to add some data to the frames to decode with Go's image/jpeg. It's not great compression, but it's easy to work with, and pure Go, with no licenseing worries.
that's _technically_ correct. my "super useful" was referring to have to handwrite every single one of them.
Thanks y'all!, this is what makes me happy and motivates me. Hope to bring more vim-go goodness this year :) 
To be honest, despite being an experienced programmer who is moderately well read on the topic, I don't fully grok SAT solvers enough to be certain of this myself (which is kinda the whole problem). That's why I dug around until I found the cargo pull request that supposedly fixes this issue without resorting to MVS. Between cargo's behavior and the comment claiming that yarn used to have this behavior, it seemed safe enough to conclude that isn't fundamentally incompatible with the SAT algorithm. I'd love it if someone more familiar with rust could try to recreate this scenario with cargo and see what happens.
&gt;My position is not "NPM should adopt minimal version selection to solve this problem". &gt; &gt;My position is "NPM should solve this problem. This would not be a problem with minimal version selection". Yeah, I had a feeling that was what you were shooting for, but I had to read a bit between the lines to hear that message. To be honest, the title is probably fine as-is, so long as you clearly state these 2 points somewhere. &gt;Solving this issue may be academically trivial, but I suspect practically non-trivial (I will be happy to be proven wrong here though). We will see if the issue actually gets fixed. Part of the goal in writing this up was to make the pain more visible. Yeah, the cargo solution looked pretty trivial to me, but maybe cargo is able to make some assumptions that npm cannot. Cargo's solution may be non-trivial or even impossible for npm to implement. Combining this with your points above, it's something more like: &gt;NPM should change their default behavior to fix this problem, assuming it's even possible. This would not be a problem with minimal version selection.
Yes, it does surprise me to hear that. Could you provide a source on this information? Surprising claims on the internet really need to be accompanied by evidence before I believe them. Also, does this behavior apply to \`npm update\` as well, or just \`npm install\`?
&gt; True. Please point me to the juicy parts. Here, magic to workaround lack of generics. https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301 https://github.com/google/gvisor/tree/master/tools/go_generics &gt; https://stackoverflow.com/questions/6802483/how-to-directly-initialize-a-hashmap-in-a-literal-way You apparently are stuck in 2006: var h = Map.of("a", "b")
What exactly are you doing? Quaternion stuff by the sound of it? Is your vector fixed-sized?
You can use simple tools like VLC that work well, I did it in the past to create live feeds from concerts, you don't have to start from scratch. After that, it's just about multiplexing the original feed, it's actually not that complicated. And there is webrtc to the rescue in the browser now as well.
So the history is interesting. And here is the gist of it as I understand it. When package managers were new, the problem they were solving was that updating dependencies was a pain to do manually. As a result, many dependencies almost never got updated. This is a big problem if your dependencies have subtle bugs or critical security issues that have already been fixed upstream. Back in those days, the prevailing logic was that getting the latest bugfixes and security patches was generally a good thing, and so it should be easy to get the latest version. So people made things that were more or less like \`go get -u\` was before go 1.11's modules. At the point, the best practice was * Always prefer the latest version. Of course, that only works when everything is fully backwards compatible, so it didn't work for long. Package managers needed a way for people to document incompatibilities and incompatibilities. Semver and constraints made that possible, so the best practice became this golden rule * Always prefer the latest **allowed** version. This is where SAT solvers came in and did most of the heavy lifting for us. They did a pretty good job at following this rule barring some extremely rare pathological cases that made them spontaneously combust. At this point, many of the package managers we still use today already existed. Lockfiles still weren't a thing, but some people were realizing that always being on the bleeding edge can be a bit painful. Specifically, it was a big problem that when I built the code at 8AM, you build the code at 10AM, and the build farm built the code every afternoon at 2PM, we might have ended up with 3 totally different "latest allowed versions". People needed "repeatable builds" and so external tools like shrinkwrap and bundler invented the concept of lockfiles to solve this problem. Eventually these features got absorbed into package managers. That brings us to present day. Now package managers generally try to follow these 2 rules. 1. When dependencies must be changed, prefer the latest allowed version. 2. No dependency should be changed unless the user directly **or indirectly** asks for it to change. Both SAT (with lockfiles) and MVS agree on the second rule, but they strongly disagree on the first one (MVS does exactly the opposite). To some extent, that first rule is a holdover from the early days when the problem was seen entirely as dependencies always being "too old". We had started to realize that dependencies can be "too new" when they prevented us from repeating our builds, but we still trusted rule #1 to be the golden rule and we only disobeyed it when our repeatable builds required us to. Then MVS came along as said, maybe we're looking at this backwards. Maybe repeatable builds should be the golden rule, and updating versions should only be done when it doesn't get in the way of build repeatability. SAT with lockfiles already gave us repeatable builds but only within a single project. MVS takes this concept a step further by preferring to "repeat" the exact builds of your dependencies when it can (aka high-fidelity builds). This sharing of repeatability between dependencies and the projects they import them wasn't possible when we had a hard requirement to always go to the latest version. Relaxing one requirement allowed MVS to empower the other. &amp;#x200B; Which way actually works better in practice? Time will tell, but my money is on MVS.
Hey! pion-WebRTC creator, thanks for sharing it :) /u/CrappyFap69 The nice thing about WebRTC is that you can use it to send/recv video (browser and servers) and low latency (sub second) and encrypted. However, scaling is much harder compared to traditional stuff (DASH/HLS) which I know very little about. The library has plenty of growing to do still, but happy to add anything that can make building things easier!
I have been wanting to hack something together with pion for my security cameras. There is no good open source solution for security cameras right now... Hopefully I will get some free time in the next couple months.
I've been toying with a single binary proxy from my local Go install to my docker Go containers using GOPROXY with host.docker.internal. That way I don't hit github rate limits, need to pass ssh or .netrc stuff into each container at build time, have to have Athens installed somewhere and it speeds up my builds.
This is definitely nice to have. I manually install it on all my VMs. 
Just don't. Not unless you really need to. I've worked with the kind of people who adjust the internals of things for fun. The results are usually worse than simply leaving things at their default settings.
There was some, but I finished the public API portion
Did you read the article? It is not your average "Tune your gc settings" article, it is a lot more a technical "how does the gc and memory allocator work in go" kind of article. 
[removed]
You might file an issue with the project? BTW, there's already one [demanding for the built-in types to be removed](https://github.com/golang/go/issues/19921).
+ zip.NewReader, flate.NewWriter, aes.NewCipher, cookiejar.New, ... among others return an error. 
I doubt this one will fly. I’d wager complex isn’t used in Go1, because it’s not a great scientific language. But Go2 could be, so there’s no need to preemptively stunt its potential utility as a scientific language simply because Go1 isn’t very good at it. 
I just know a whole lot of people will skim though it, imagine they understand it, then go setting environment varibles to all kinds of extremes. Understanding is great. Settings things in production environments without any idea what impact that will really have is not great.
Are they planning to also include native support for other services or is this just another attack on neutrality by Google?
I linked to the issue that contains reproduction steps in the post. Here it is again: https://npm.community/t/impossible-to-update-single-package-without-updating-its-dependencies/1156
It panics because one backslash is missing it should be \\x but I don't know why redis won't let me format that . I did replace d with backticks instead of quotes and it gave me true. Could you please explain that to me, I am a little new to programming?
[removed]
I think I'd need to contact the moderators!!!
First of all, I recommend not cursing that way. Just because you don't agree with people is not a reason to call them stupid or dumb. That sort of language makes it hard to engage with you seriously TBH. &gt; I'm someone who does want to do math with complex numbers and these types make my life worse. FTR, you first said that the argument "I don't use the types so they shouldn't exist" is "dumb". But you also say they make your life worse - which obviously isn't really true, because all you're saying is that you can't use them. They don't make your life *worse*, you just wish they'd make your life *better* instead. &gt; ecause copying the values of the vector to a complex typed variable performing the operation and copying back the result would counter act any performance gains I might get from using the builtin type Are you sure? I would expect SSA to mostly optimize any copying out. And either way, ISTM that these operations only happen in registers or the cache, so don't really matter. And why aren't you just using complex types from the beginning then? I also struggle to see how you would solve any of this (productively). At the end of the day, `[2]float32` is a different type from `complex64`, just like `time.Duration` is a different type from `int64` - even though they have the same representation. I don't understand what you are suggesting - except maybe doing an unsafe type cast between the two. Though even that wouldn't really help, I think.
Exciting! An excuse to explore a new city for some of us.
As someone who has had to muck around trying to figure out some of the problems described in this article its much more then just fiddling with runtime variables (in fact its almost none of that), it covers a little bit escape analysis, general gc overview, and real choke points or scenarios that can kneecap go's GC. 
Its allocated virtually, but its not using real memory
This is not true. The bigger the project, the harder it is to find which and under what circumstance os.Open couldn't find the file named missing.txt. This is especially when there is a third party involved like an API dependency. This is the whole reason stack traces are useful. 
You know that hexadecimal escapes can have digits other than 0-9, right? e.g. \xe0.
Ah, that's a pretty good solution to add context/detail to an error. Thank you. Handling the error is the ideal solution, but it's often not possible to handle it. So, it's best to gracefully return an error and provide a way to later know if in what circumstance the error happens. This is a reason why the "Errors Value" proposal exists. Correct? Package x might not be able to handle the error but it can wrap it in a more general error and a higher function can handle the error. That's much better than ignoring the error and pushing up the error in a way that is not possible to debug or handle. I will say, this still encourages the errors being ignored. Has someone done an analysis on github code to see how often the error handling is `if err != nil { return err}` vs `if err != nil { // something else }`?
No I didn't know that, thanks for the info
The string literal `"\x00"` is escaped: The bytes it represents aren't `[]byte{'\\', 'x', '0', '0'}`, but `[]byte{0}`. Backticks (as opposed to double-quotes) create a raw string literal that has no escaping. So with backticks it represents the former. [Check this out](https://play.golang.org/p/MPIlixv_PE0) for a direct comparison. The regular expression OTOH represents "any string that starts with a backslash, then has an `x`, then has two digits". If your string represents `[]byte{'\\', 'x', '0', '0'}`, then that gets matched, because it follows that pattern. If, on the other hand, it represents `[]byte{0}`, it doesn't get matched, because it's just a single zero-byte. The online regexp-matcher doesn't interpret the escape sequences you put in. So just like a raw string literal, if you put in `\x00`, it represents the bytes `[]byte{'\\', 'x', '0', '0'}` and matches, not `[]byte{0}`, the double-quoted equivalent. Hope that helps?
It's just supported. Users aren't forced to use it. You can still go with third-party support for the other services, I suppose. 
You are right but I don't think Google would loosen their reigns off of Go. As biased as it may be they are going to keep it as close Google as it can be. But yes totally agree with you on that aspect. 
Really? If that's the case then I stand corrected. For what I read I believe it was implied that by native support in Go == implementation in standard library.
Just to clarify: the delay might be as low as 2-3s when using HLS. The delay depends on the keyframe interval, which may be set to 1second. A video chunk is then 1second long, and you usually need at least two chunks for smooth playback, giving you about 2-3sec delay. That does tend to require each chunk to be downloaded faster than 1sec, which isn’t always an option, so usually keyframe intervals are longer, and more chunks may be added to the chunklist to allow for buffering/smooth playback.
[Cross-posted on SO](https://stackoverflow.com/q/52118362/720999).
The library's API looks decent overall. Just having a quick poke around in the code and looking at the README. It looks like you've got a type for when you use `sess.Commit` in the README. I've not done a real deep dive into your code, but I thought it'd be worth mentioning some issues I've seen here with regards to package and type naming. One example here is `memorystore.MemoryStore`. That's a [stutter](https://blog.golang.org/package-names#TOC_3.). You have some context from the parent package of `stores` (though, I'd argue that should be singular too, and just be `store`), so just keeping the package name `memory` is fine. Once that change is made, the logical type name then is just... `Store`, as in, `memory.Store`, the same logic should apply to your other stores, i.e. `redis.Store`, and `securecookie.Store`. Not sure if you caught it in that bit above yet, but another thing that's a bit problematic is that you've named your packages differently to the folder that it's contained in. I'm not sure really if this is a personal choice or what, but I strongly dislike this because IMO it makes finding code much more difficult. If you're using an IDE it's not as bad, but browsing the code can be a little more confusing. IMO, just make the folder name match the package name, except for `package main` and test packages. Overall, the code here looks good - just those naming issues that I think would improve the library. It looks like a useful library though, I'll keep it in mind for the future!
[removed]
Well, there's literally only one exposed knob: the `GOGC` environment variable. Not much to fiddle with. Which is great. And knowing a bit about the things that happen under the hood are great: it's educational and it also sometimes prevents foot ablation.
&gt; If I understand correctly, native support means that it will be implemented within the Go standard libraries, yes? No. Native means that you no longer have to shell out from node.js to use Go in Google Cloud Functions. i.e. it's "native to GCF", not "native to Go".
Thanks but multiple servers would just complicate calculations by requiring some kind of work sharing and orchestration (in addition to the "triggering" lambda functions would require).
Has written Perl, PHP, Ruby, Java, C++, and Go. Companies rely on his code. Attends Programming Conferences. Uses vim by default. Yep, definitely not a developer.
Nice! Thank you for the explanation.
For the transport part, you should use RTP and RTSP, this is normally implemented over UDP. Then go wild with codecs, for video I would recommend h264 or hevc and maybe aac for audio. You send audio and video over separate ports then reorder and sync using the RTP header. It's no small task you're undertaking here, you need to think about reorder algorythems and forward error correction as well.
Abraham Lincoln, Kurt Vonnegut, and Confucius were also prolific Go coders. Does it really matter how "famous" the people are who code in Go? Would a cult of personality of picking a language based on its star power do anything but validate [Alan Kay's assertion that modern software development is a pop culture](http://www.drdobbs.com/architecture-and-design/interview-with-alan-kay/240003442)?
If you go to https://godoc.org/github.com/robaho/keydb, compare that to some stdlib libraries you can see what is lacking. Also if you run `go vet` or `go lint` on your code they will tell you about the documentation part as well.
serverless is crap
Indeed. In my opinion you can still call yourself a programmer even if you're not doing it professionally. Developer on the other hand feels reserved to professionals.
For people for whom absolute performance is an issue, like those of us with custom extremely-high throughout high performance network servers in go, it’s important, and nice to know. And even for those who aren’t, it behooves us to know *how* the GC works and, more importantly, how to identify and measure any problems we might unknowingly be causing ourselves by interacting poorly with it. I do agree, though, that way too many people try and tweak it when they don’t need to, and way more complain about it. 
You can be enthusiastic about technology, and code, and even know how to code, and even work at Microsoft, but that doesn't necessarily mean that your main function in the professional sense is a developer (or similar label like coder, engineer,...). Some of the best technical managers which I know have learned to code or have coded in the past (as this guy), and it doesn't make them a developer. One of the best programmers which I've had the pleasure of working with - is a lawyer. Even during programming, he was very clear on the distinction - he can code, but he isn't a coder, and he wouldn't be doing that for much longer. And he kept his promise, I think in about 3 months, he was completely out of that. Say it with me: not all people who go to gophercon are developers.
I wish you luck in your endeavors
That's the whole reason why Confucius said "Wheresoever you go, go with all your heart"
This is not being asked to be antagonistic. I am literally asking if there is still a deep concern for preventing "bloat without distinction" (02:48). Can we be assured that, after a handful of significant changes bump the language version, the language will go back to being "boring"? Or will this lead to a cascade of complexity?
serverless is just being pushed by cloud providers because they want lock-in, very dubious value proposition for everyone else
There's no plans or design for operator overloading, though, right? The generics design specifically excludes it. The [draft design](https://go.googlesource.com/proposal/+/master/design/go2draft-contracts.md) says under Omissions: &gt;No operator methods. You can write a generic container that is compile-time type-safe, but you can only access it with ordinary methods, not with syntax like c\[k\]. Similarly, there is no way to use range with a generic container type. However, I do share your concern. I like the error handling proposals but I'm pretty unsure about the generics proposals, for a couple of reasons: 1. The "concepts" thing is fairly complex and will increase the learning curve of the language significantly. 2. I'm afraid that it might splinter things into old/new, non-generics/generics code in both the standard library and the community libraries. This is addressed under "Pervasiveness" in the draft design, and the direction seems good. 3. I'm afraid the compiler might slow down too much. Fast compile time's is one of Go's real strengths as far as I'm concerned. I'm definitely not opposed, and they really seem to have thought through this, but I'm just cautious.
&gt; I am literally asking if there is still a deep concern for preventing "bloat without distinction" (02:48). Can we be assured that, after a handful of significant changes bump the language version, the language will go back to being "boring"? I don't understand why you would not assume that is the case. Adding long requested features to Go after a huge period of debate over the engineering trade-offs involved itself shows a lot of "deep concern". So I see no evidence that justifies your concern. IMHO these big new changes have been considered for a long time and are just business as usual for how Go operates. Its not the first time Go has had big changes since 1.0, its just that most of them are hidden inside the runtime, etc.
I kind of agree with you. Knowing the GC-internals is unnecessary for 95% of gophers. The garbage-collector is an implementation detail of the runtime and can change anytime, it already did a couple of times. This is actually one of the beauties of Go, it just works! There is just one rule for any GC allocate as few as possible and Go does already a great job with this by its escape analysis.
If performance is so important, i would have chosen c/c++.
Wow I did not know version selection was NP-complete. MVS seems pretty genius in that aspect. 
These are notable changes and not business as usual or there would not be a version increment attached. So far, I enjoy the changes and the consideration that seems to have gone into them, but with making changes comes a sort of momentum. It's that momentum that concerns me.
AIUI, the process right now is analogous to the Pre-Go1/Post-OpenSource phase: Do a bunch of changes, settle on Go2, have another decade or so of stability.
That's good to hear. Has there been any mention of dropping anything?
The title is &gt; Native support for Google Cloud Functions in Go are in Alpha. but it's really more &gt; Native support in Google Cloud Functions for Go are in Alpha."
I find it useful for very lightweight things that can be trivially rewritten. E.g. mostly static site that needs just a touch of server.
However some companies really can't afford to run their own infrastructure for something like this. I've worked at several companies now that use this and other technology to limit the cost of paying someone in house to maintain this. It's that weird size between needs a full-time admin and Tim the slightly more tech savvy then others developer.
We did. Then maintenance became hellish. 
that is a fair point. the paradigm in general gets too much attention for me though.
I don't think "dropping" is the right way to think of it. "Changing" is more like it. FWIW, at this current pace, there is no danger of Go ever™ becoming "bloated".
FWIW, if I build a package that depends on `deptest`, dep installs `bystander v1.0.1` for me. It's not completely equivalent, as that thing is added newly (instead of only being released after I set it up initially) and I'm not quite patient enough to run through the whole shebang of setting up github repos for this. But that's exactly what I refered to with "only one level deep". You went through the thing outlined in the article, which *can* be prevented by adding the veneer talked about in the cargo issue. But once you add more levels of indirection, it becomes more problematic. Now, to be clear: Sam is of the opinion that all of this can be fixed in dep while retaining a SAT solver, by something he calls "preferred versions". I wasn't yet able to figure out how he intends to make that work or why he believes it to be preferable to MVS. To me personally that just seems to fight the complaint of an overly complex solving algorithm by adding more layers of complexity on top - which is pretty common in Software Engineering and how we added up with all of this incidental complexity in our systems to begin with. I don't understand why it's preferable to try and retain the complexity of a SAT solver, if you could also remove it. But I at least wanted to mention that there are more theoretical ideas that might prevent some of this.
&gt; These are notable changes and not business as usual or there would not be a version increment attached. Although it has been noted several times that Go2 is most likely a marketing term and that the new features will really come as point releases. Say error handling in 1.14 and generics in 1.18 (versions made up for illustrative purposes). We're at version 1.11 now, with 1.12 now in development, so we've already gone through many version increments. That much is a non-issue.
Why not make it some how a tool that you can turn on, like strict mode but generic mode. This way those who want to jump into the fire can.
True, but in my experience, everything needs to be tuned just right and you need to own the encoder in order to get that type of performance. Not to mention the client needs a pretty good connection. Low latency streaming is not what HLS is designed for. If you need to use a CDN and have lower latency DASH might be a good alternative, but definitely adds much complexity over HLS. 
It comes from perl where $ means scalar, @ means array etc
What would be the point of that though? Ignoring the mess of importing other peoples code, as far as your code goes, if you don't want generics.. don't use it, right? I'm not arguing for or against generics. I'm asking what good enabling/disabling generics could be. Thoughts?
But Vonnegut's code was not idiomatic and relied heavily on reflection, I'm not sure he qualifies.
Has anybody thought about character sequences? For example, `f[[t[[int]]` or `f[&lt;t[&lt;int&gt;]&gt;]`. Another alternative to make types more clear would be to introduce an unused character such as `f@[int]` or `f@(int, int)`, to make it clear that these are type parameters.
Out of curiosity, what would an example of that be?
&gt; Wait, how do we tell if it's a scalar variable or a hash? I know, lets put a $ in front of one, and an @ in front of the other. - Perl 
Why dockerize a self-contained binary? The app isn't the problem - it's the server allocation... and I only need one (logical) server.
Thank you, Fassbewohner, for voting on Confucius-Bot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://botrank.pastimes.eu/). *** ^(Even if I don't reply to your comment, I'm still listening for votes. Check the webpage to see if your vote registered!)
I once needed a small server side bit to serve geolocated content. Thank you eu cookie law.
Just like Lambda has had for awhile.
Google is currently pushing hard for open standards with Serverless Containers and knative. Serverless is definitely going to continue to gain traction and find its place. From what I see this is taking it in a healthy direction.
Similarly I've written some serverless functions for maintaining resources in clouds like pruning AMIs, sharing them across groups, or even sending security alerts to things like slack, basically using serverless functions as the glue to make my life easier in a cheap manner. My longest serverless functions are around 100 lines long, short, powerful, and easily rewritten.
So... why are you adding these low value comments then?
So same say that Go was used by Wallace Corporation to program replicants. And that if you convert a Go program to mp3 you can hear presidential speeches. All I know it is a programming language...
[removed]
Thanks. I’ll look into it. I read the godoc documentation and it’s really relaxed compared to javadoc
I’m on a phone so hard to research but if this means language changes just to support google cloud... bad idea. I like Go but they need to look at Kava for ecosystem direction...
The increased complexity will negate those cost savings -- friction in on-boarding new developers further erodes those cost savings. This becomes a black mark to anyone interested in purchasing your company's IP.
Barring a few exceptions, it is way more cost effective to just run a small instance or deploy a simple docker container to serve what you need. I have yet to find any real value in serverless (yet) but hopefully it becomes something you can use at scale (affordably).
This, I've had great success just adjusting the GOGC values (as most my applications are CPU bound).
If they try to tie the language to a cloud provider, they are going to lose a ton of utility. Don't pollute my language with your business goals.
It's been handy for quickly getting integration points up that do data translation up. Point say githubs post commit webhook at your lambda function, translate the payload and send it somewhere else.
No having method overloading is pretty silly though... I am not a fan of operator overloading as people always create crazy ways to interpret '\*', or whatever - so you have to read the documentation to follow anything - where are method overloading is painless and nothing is lost - having to write NewXFromInt, NewXFromString, NewXFromYYY is just silly...
Bad human.
Hi Robin, not bad for a first article. A few things you should consider adding: - if statement assignments other than errors. For example when doing a map lookup, but also the general case - switch statement explicit fallthough keyword - continue and break statements in loops - labelled break and continue statements - select statement should almost be it's own article. Give it it's own section at least.
If you are searching for a method name in a repo of a billion files you have issues. On that note, they need to address file private as well. You hard to use and IDE code complete when hundreds of methods... I propose starting file level methods or vars with an underscore... simple. 
I think many of those questions are answered just by reading the README, but to summarize: ACD only. If two go routines put the same key in different transactions, the one that commits last will be the value. Within a transaction, a go routine will not see other updates by other transactions. It is persisted, although currently not sync writes, so a hard OS crash could leave the database in a corrupt state. It uses compressed keys, not data. It supports range searches, including open-ended, that need not be read to end. Like I said, it is pretty simple, with a very simple interface - designed mainly for highly volume writes and sequential reads (although another update will improve the random access performance greatly) - at the expense of slower db opens (although I might use another file to store the partial key index to avoid this). In most cases, if you have a financial application, or mission critical application, you should probably be using a "real database" anyway - this is a tool for a more limited use case - basically designed for the persistence and playback high volume financial market data. &amp;#x200B;
Eric Raymond
 &gt; It is persisted, although currently not sync writes, so a hard OS crash could leave the database in a corrupt state. How can it be persisted - but not sync writes? 
It writes - meaning it has been sent to the OS buffers, but it does not wait for acknowledgment of the OS write. It is trivial to change the open flag to O_SYNC or some derivation, but for this type of tool, and its intended use case, it is usually too costly in terms of performance, vs the integrity risk
I can be pretty certain that searching for a method name in a billion files, is still going to have multiple matches, and if there weren't then the overloaded methods would of all be in the same file anyway... so I don't think that argument holds a lot of water - it is cumbersome especially when you need to pass concrete types that are not primitives - the methods names become unwieldy As to what I was proposing, I have already written two applications in Go, and there are of pretty small size, and the package/code protections are not that great. You either have to create lots of packages, and it you don't (like for keydb), every method is essentially public within the package... when you need local utility methods you really don't want these method to escape the file they are in... The only way around it which is pretty stupid, is to do something like: func myFunction() { fn := func myUtilityFunction() { .... } fn(A); fn(B); ... } otherwise myUtilityFunction becomes public in the package - not good for large packages - the stdlib is a prime example of where this is a problem... these packages are pretty large in many cases, then you have name collision, etc., and IDE's are much harder to use (because everything is visible). So I propose if a method or variable starts with an underscore it is private to the file. 
I found this to be a fascinating talk, and you can find the slides for it here: https://speakerdeck.com/emfree/allocator-wrestling
Are you not counting operational costs? 
I thought "learning exercise" seemed fairly descriptive.
Is there any advantage over App Engine? Its basically serverless already.
For integration testing, I like to use the `testing.Short()` flag to skip integration tests.
The other benefit of using the _test package suffix is you’re then only able to test exported methods on the package under test.
I don't want to decode or process the json - I don't care whats in it. All I want to do is take the incoming data from another TCP server, and send it to all connected clients on the tcp-relay as it comes in. One to many, more or less. I'll try it with a byte array. I assume I should use ReadBytes so as to not convert to a string in the first place? func handleTCPIncoming(hostName string, portNum string) { conn, err := net.Dial("tcp", hostName+":"+portNum) // exit on TCP connect failure if err != nil { log.Fatal(err) } defer conn.Close() //init i //i := 0 // constantly read JSON from PUB-VRS and write to the buffer data := bufio.NewReader(conn) for { // read until ] then proceed // loop forever reading TCP feed // until err scan, err := data.ReadString(']') if len(scan) == 0 || err != nil { break } // trying to solve the problem of {["ac":{....}]} // read ends up with {["ac":{....}] // so we add } for closure // but that means next burst starts with } from read // so we need to drop the first } // can we skip ahead with ReadString? // Scanner did not seem to work even with custom split // drop first { on every pass but first //if i == 1 { scan = scan[1:len(scan)] } go sendDataToClients(scan) //i = 1 } } 
Why would taking a slice of a string cause an allocation?
Why do you think DASH would be a better alternative? Iirc it’s still a http protocol, still based on chunks, so it follows it has the same limitations?
[removed]
Close but no, the gc will remove the old allocations in the loop eventually, but they'll build up fast before the gc runs. Have you considered the io.MultiWriter function? 
And yeah, use the ReadBytes function, or the conn.Read(buf) function
i hope the video comes out soon :)
You can do low latency HLS: https://medium.com/@periscopecode/introducing-lhls-media-streaming-eb6212948bef If you're in a browser, you can use websockets and MediaSourceExtensions to stream low latency frames directly. 
There’s no technical reasons beyond performance potentially that there couldn’t be an interface to get stack traces as needed from an existing error, and it’s still possible today to add them to your own errors already. I think the main argument against is generally stack traces aren’t super readable and aren’t needed until you really wish you had them, so in practice error messages are preferred until you need more debug info, after which it would be great if you could easily flip a switch in the runtime to make errors provide stacktraces. It’s possible, but someone would need to argue for it and implement it. 
this link go straight to the example, and is only a few lines of code. i will update the docs, thank you 
Ahh, today I learned! I will add this tip to the text version of the article. Thank you! :)
Very true, every unexported method within those packages can then just be considered implementation details whilst you focus on the parts of your code that is actually exported. I believe Mitchell Hashimoto mentioned that in his talk : [https://www.youtube.com/watch?v=8hQG7QlcLBk&amp;t=1467s](https://www.youtube.com/watch?v=8hQG7QlcLBk&amp;t=1467s) 
What does this driver give more than the one the community has been using for years - mgo?
gometalinter's one of checks is github.com/mibk/dupl
Feel like the name will be confused with https://github.com/getsentry/sentry 😅
Not sure if this will help, but Viper (https://github.com/spf13/viper) is pretty good, supports multiple formats and is really flexible. 
Bad bot banned
I think you solved my laziness problem of downloading my Spotify songs one by one on Youtube :D
Happy cake day! I also agree with your sentiment. I think over time the official driver will have new database features implemented quicker than mgo. The MongoDB engineering blog have a post about them creating an official driver: [Link](https://engineering.mongodb.com/post/considering-the-community-effects-of-introducing-an-official-golang-mongodb-driver)
It actually solved mine, too, that is the reason behind its birth. Nice to see I'm not the only one with that problem :D
Thanks, will read it. I literally today found out about this new driver so I was asking out of pure curiousity. Let's hope it comes out good.
Simply not true. All of those methods would declare an exception (probably IOException), and the caller would then also declare that it throws IOException, so then the high-level caller would be able to handle the exception appropriately. The public "error" in Go does not contain enough information, so the upper levels are left to casting, and having to interorgate the internal details. It is not good... Even if I wanted to try and handle these errors reported by the IO routines, iit is impossible to do so in any sort of complete fashion - not enough info. The print statements again, were left behind during development - again - a very exceptional condition that results in panic. This is a low-level library, a higher level might trap the panics and decide to attach to another replicated instances, but that is beyond this library's scope. It is extremely comment to have panics like this - they are essentially asserts to detect development errors or critical failures that the database has no reasonable way to recover from. Based on your comments, you give me no confidence in your understanding of systems programming... let alone being able to write this, or anything in a day or two and have it work... &amp;#x200B;
There should be no performance penalty unless the error is "thrown". Having to debug a large system without stack-traces is pretty futile - the standard Go errors do not have anywhere near enough info, so the the developer is required to wrap at every level - providing context - which is what a stack trace does for free...
by the way, the goto failed, and early return are definitely best practices - have been for a long time - goto failed is used from nested routines where there need to be context provided to the error before the return, or retry logic, etc. "early return" is used for parameter checks/validation.
Further more, the if (err!=nil) { fmt.Println(err)l return err} is another necessary evil during debugging (and even runtime) because of the lack of stack-traces. Just returning a error up the stack is impossible to use, because you have no idea which routine caused it.
Also, I just had a chance to check out your open-source repo, and the FIRST file I looked at had these: data, err := file_reader.read_file(fname) if err != nil { return } and then this i := bytes.Index(data, []byte{'\n', '$', '$'}) if i == -1 { panic(fmt.Sprintf("Can't find the import section in the package file %s", m.name)) } data = data[i+len("\n$$"):] So I'm pretty sure you are just a troll, because you clearly don't come close to practicing what you preach, and yet have the audacity to talk the way you do... So I'll say it - zero confidence that your critiques are valid.
None of that is *my* code...
The `error` type is `type error interface { Error() string }`; nothing at all stops you from returning whatever info you thing is necessary.
I'm pretty sure `goto failed` isn't idiomatic Go.
https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction
[ZikiChombo](http://zikichombo.org) has started an sio project which depends on host rather than 3rd party libs. It is in alpha, and [being reorganised.](http://github.com/wsc1/sio) On darwin, USB mic should work.
Maybe not exclusively, but I'm always at least interested in seeing the job ecosystem for a language, and sites like this are fun to browse. And if someone finds a job through it, then cool!
Community MongoDB driver isn't maintained any more: https://github.com/go-mgo/mgo/blob/v2-unstable/README.md In fact it wasn't updated since MongoDB 3.0. There is a fork from globalsign that is kind of alive: https://github.com/globalsign/mgo If you encounter any problem with these drivers (and you likely do), you are on your own.
I am well aware that not all deduplication is good or necessary. This does not change the fact that it often makes sense to recognise and remove pieces of duplicate code. 
Not sure why you are linking to it as your open-source work then... at https://margo.sh/ in this https://www.reddit.com/r/reactjs/comments/97fysw/whos_available_august/e4p7hwn/?context=3
yes, and then you need to write everything yourself, and do lots of casting to process it, and no stacktraces, unless you build them yourself - fairly pointless for a project of this size and complexity
Not sure if you’re dead set on building this from scratch, but this does exactly what you’re trying to achieve and it does it really well. https://github.com/Jeffail/benthos
goto failed may be idiomatic C, but it is definitely not idiomatic Go.
Codeclimate ([http://codeclimate.com](http://codeclimate.com)) also can find duplicates and integrates nicely with Github. (it might be using abovementioned dupl under the hood)
most people seem to use VS Code but i switched to LiteIDE not long ago and honestly i don't have much of a reason to go back. works perfectly well for me, though i haven't tried using modules just yet so i'm not sure if they're supported or not.
Understandable - the GC should be running on those allocations but it just isn't fast enough. I've run into this issue quite a lot with Go. MultiWriter might work in a controlled LAN type environment, but not it the wild with uncontrolled latency, connection speeds, and errs. Right now at least one connection writes fails every few loops. I don't want the write to fail and it to bail on sending data to the rest. https://golang.org/pkg/io/#MultiWriter MultiWriter creates a writer that duplicates its writes to all the provided writers, similar to the Unix tee(1) command. Each write is written to each listed writer, one at a time. If a listed writer returns an error, that overall write operation stops and returns the error; it does not continue down the list.
That does an insane amount of stuff. All I have to say is ... wow.
My first suggestion is to use `gofmt` on your code :). Secondly, you can speed this up a lot by reusing buffers. Create a single input buffer and a single hash output buffer, and you'll cut your allocations down (and thus speed up your tight loop) considerably. I can't tell if you think it shouldn't be faster than Python... but yes, that's expected :).
I also think that you should reconsider the way you manage message sending to the clients, and the management of client connections. It would be simpler to have one persistent go routine handling message sending to clients. It would have one channel for new messages to send, and one channel for new client connection. I slice of connection would be preferable to a map. This sender would detect itself when a connection is closed, it could replace that connection by the last one of the slice and shrink the slice by one element. It would check after each send if a new connection is available. If yes it appends it to the slice. When a message is sent to all clients, the buffer would be put back to the pool. The message channel should be buffered to put na upper limit to the number of pending channels. If full, the message receiver will be blocked and due to tcp backpressure, the message producer as well. 
https://www.youtube.com/watch?v=0SARbwvhupQ
So the difference between a developer and a non developer is maintaining code? So like most js developers are non developers?
&gt; vastly simpler tooling and deployment, :D You need more experience in software development
Try https://golang.org/pkg/io/#example_MultiWriter ? 
Seriously? Somebody critiqued your code so you went out of your way to view what they'd written? Ouch. I can't imagine that will make you popular, or help your project get friendly eyes.
It’s just not his primary role and his income doesn’t depend on him writing code. It’s not hard to follow the line of thought here. I cook but I’m not a chef. People do things for fun and it isn’t their main label.
Sounds like a sysadmin ;)
Use `crypto/rand` for random inputs. `math/rand` is a deterministic prng that, unseeded, may be hitting your threshold early by chance. 
What exactly is the question here? Have you proven that the results of your program are correct? It's trivial. Go is expected to be faster than Python especially for number-crunching. Btw. you can easily parallelize this task.
I edited the code -- it's cleaner now, and with `gofmt` :) Although the point of POW is to *not* be quick, the buffer point is a good idea. I should make it as efficient as (reasonably) possible, and base it off that. I just had problems with my types. `sha1.Sum()` returns a `[Size]byte`, not a slice, and so I have pains when trying to declare it in advance. // Find a byte array that hashes with a // certain number of zeroes at the beginning. func find_source(length int) []byte { source := make([]byte, length) var hash []byte for { rand.Read(source) temp := sha1.Sum(source) hash = temp[:] if check_hash(hash) { return source } } } This *works*, but I'm still reallocating `temp` every loop. I can't convert `sha1.Sum()` into a slice on the same line, I get an error: ./main.go:35:26: invalid operation sha1.Sum(source)[:] (slice of unaddressable value) Which afaik means I need to store it first, which feels a bit wasteful. I knew Go would be faster than Python, but this is *so much faster!* I wasn't expecting that. 
What is wrong with that? He was stating his critiques as they were absolutes, so instead of showing other peoples code (which I could of done to demonstrate the usage) I showed his own? Personally, when someone makes derogatory statements like "I'm not trying to be mean, but your code and your responses don't exactly fill me with confidence" then I think it is fairly appropriate to understand the critic at little better.
Use `crypto/rand` and not `math/rand`. &gt; It seems to calculate the byte array significantly faster than expected. Even when the difficulty is 15 (i.e. 15 leading zeros), it happens in less than a second. Faster than expected? 2^(15) is only 32768. adding a line to the program to show how many iterations were required shows: Found after 23905 Found after 34905 Found after 10743 Found after 35288 Found after 41495 Found after 2596 Found after 42495 Found after 7 Found after 42140 Found after 6101 Found after 30749 Found after 5010 Found after 132845 Found after 103055 Found after 2977 Found after 14944 Found after 10232 Found after 124634 Found after 4247 Found after 58 sha1 or not, you're basically just asking it flip a coin 15 times until it gets heads 15 times in a row, basically this: package main import ( "crypto/rand" "fmt" ) const DIFFICULTY int = 15 func main() { fmt.Printf("Difficulty %d\n", DIFFICULTY) fmt.Printf("Found after %d\n", flipUntil(DIFFICULTY)) } func flipUntil(heads int) int { for i := 0; ; i++ { if flipN(heads) { return i } } } func flipN(heads int) bool { all := true for i := 0; i &lt; heads; i++ { all = all &amp;&amp; flipCoin() } return all } func flipCoin() bool { source := make([]byte, 1) rand.Read(source) return source[0]&amp;1 == 1 } So the expected runtime would be "How long does it take to do a sha1 hash ~30k times". On this laptop as a reference point openssl says: $ openssl speed -evp sha1 Doing sha1 for 3s on 16 size blocks: 11607218 sha1's in 3.00s Doing sha1 for 3s on 64 size blocks: 8089153 sha1's in 3.00s so 3869072/second for the implementation in openssl, which would mean even some of the longest searches of 100,000 attempts would still be only around 30ms. &gt; I did the same thing in Python, and a difficulty of 7 took 17 minutes to calculate. I feel like something is wrong here. You did not post the python version, but it sounds like you did something very wrong in the python version.
I improved it, thanks. I still need to write the package level godoc... &amp;#x200B;
The classical way to this one is using a nonce. Like: type Block struct { payload Payload randomBuf []byte nonce int } You create a Block b, initialized with the random buffer + nonce and until b.Hash() &lt; MaxAllowed, you increase the Nonce and try again.
I use: https://github.com/alecthomas/gometalinter/blob/master/README.md#supported-linters It has dupl package for it
one step further ``` source := make([]byte, length) hash := [sha1.Size]byte{} first15 := [15]byte{} for { rand.Read(source) hash = sha1.Sum(source) copy(first15[:],hash[:]) if first15 == [15]byte{} { return source } } ```
I've worked with large config in a few projects. Here are some suggestions in no particular order: * You probably want to create a `type ModuleConfig interface` that has a `LoadSentry` method (and maybe an `Enabled` method?) so that you can iterate over each instead and don't need to be aware of each module. * I would use [mapstructure](https://github.com/mitchellh/mapstructure) (instead of yaml) to decode into the Config structs. It gives you a lot better hooks for customizing the decoding. You can unmarshal yaml into a `map[string]interface{}` then pass it off to mapstructure to do the rest. * Use types to handle custom decoding instead of having to call `resource.ParseQuantity`. You already have a `type Quantity string`. Use that type in the `Config` and in `mapstructure` setup a [DecodeHook](https://godoc.org/github.com/mitchellh/mapstructure#DecoderConfig) that checks the target `reflect.Type` and if it's `Quantity` you call `ParseQuantity`. That way errors are handled as part of config decoding and you can easily re-use the type without writing extra codein `LoadSentry` for each field. 
Thanks for your input. Since \`redigo\` also exposes packaged called \`redis\` I wanted to make it more unique so suffixed store with it. Honestly I got the idea from [SCS sessions](https://github.com/alexedwards/scs/tree/master/stores) lib.
Great article. Very balanced. I think this should be added to the [feedback page](https://github.com/golang/go/wiki/Go2GenericsFeedback). &gt;I'm against the inclusion of generics because of what they might do to programs, not because of what they do to the language. I do share this sentiment, but consider this: goroutines are a big, complex feature, despite the simple interface. I've seen bad usage of goroutines by inexperienced programmers completely ruin some codebases, which usually require months of refactoring to lose all race conditions and strange control flow. But! Does it mean that Go should've eschew this feature completely? Without goroutines, Go would be a simpler language, but much less useful, and definitely not as popular as it is today. ^(Also, in "We're loosing the simplicity of function parameter lists here" it should probably be "losing".)
gometalinter or golangci-lint are full of great checks like this. I highly suggest checking them out.
You submitted this yesterday as well? https://www.reddit.com/r/golang/comments/9bu8pn/simplesessions_go_session_library_that_is/
Certainly there is efficiency to be had and this would not support something with 10,000 connections in the real world due the client map blocking. I was going to update it to use slice of connections and only send to current number of connections at the time of send. Then I'd have to sync them to keep it safe. I'm very early on learning Go, so more complex pools, channels, etc are a little beyond what I can write. In production 200 clients will max out a gigabit link. So we just add more servers due to bandwidth requirements.
PS see this fork using streaming https://github.com/cjkreklow/tcp-relay-pub-vrs/tree/dev
You're wrong, and digging your hole deeper. The guidance in that article emphatically does not "pretty much apply" to Go because it shares some properties with C.
Also, you might want to read [http://wiki.c2.com/?StructuredProgrammingWithGoToStatements](http://wiki.c2.com/?StructuredProgrammingWithGoToStatements) and the referenced papers. There is a reason a language like Go has the goto statement - and it is just for these cases. 
&gt; The set implementation in the example section is very clean, and its element contract requires only ==. However, this is only used implicitly; map keys must be comparable, and _, ok := set[v] uses that under the hood. For a programmer to read this and understand why it was written this way requires a lot of knowledge, in a way that most Go code does not. Then use contract element(e Ele) { var _ map[Ele]struct{} } type Set(type Ele element) map[Ele]struct{} (or, as discussed in the open questions, the map-key type constrained might just be inferred)
If you use websockets you can't use a CDN, at that point might as well just use webRTC
Furthermore, the Go stdlib uses this convention in multiple places - just search for goto - you'll see it's exactly as I have described (constant/value, expr, etc.) - throughout the code base. 
That exits on a write error. I'm under the impression that if I have 200 clients to send to and err happens on client 2 .. 3-199 do't get the data.
True--if I had enough experience in software development perhaps I could single-handledly fix all of Python's myriad tooling and deployment issues. 
I wouldn't worry too much about other libraries package names colliding, you can always alias them, and if your Redis package is the only one that used it then it would still be fine. I think it's more important to have appropriate package and type names. I'd only really worry about colliding with the stdlib personally.
[https://github.com/robaho/keydb/blob/d92e979932f3537b24f0cc2531624d4dca339323/diskio.go#L87-L90](https://github.com/robaho/keydb/blob/d92e979932f3537b24f0cc2531624d4dca339323/diskio.go#L87-L90) [https://github.com/robaho/keydb/blob/9fa5d662dea414587d23681d06022acdf1b6fb37/diskio.go#L39-L42](https://github.com/robaho/keydb/blob/9fa5d662dea414587d23681d06022acdf1b6fb37/diskio.go#L39-L42) [https://github.com/robaho/keydb/blob/9fa5d662dea414587d23681d06022acdf1b6fb37/diskio.go#L73-L74](https://github.com/robaho/keydb/blob/9fa5d662dea414587d23681d06022acdf1b6fb37/diskio.go#L73-L74) &amp;#x200B; If these patterns are used in the stdlib, then I must seriously reconsider my choice of using Go. &amp;#x200B; And btw, when someone goes on to propose significant language changes and/or additions people are bound to look up what background this person has to back these propositions. If I were in your shoes I would hold off my ideas until I am more familiar with the language, its ecosystem and ideology.
[https://github.com/pkg/errors](https://github.com/pkg/errors)
Go has `goto`, but it’s limited to only jumping within the current stack frame. See this example of program that won’t compile: https://play.golang.org/p/_esK114Fjrl
The way this is written is hard to parse. The author calls the filter package a "trite indictment", but goes on to draw a comparison to the "simpler, more limited, more novel" approach to dependency management, implying that the filter package and dependency management approach have those things in common. But then why does the author call the filter package a "trite indictment"? Am I just misreading this?
As I've already said, see the Go stdlib - there are other standard usage scenarios where the handling is done differently.
I've you understood the code, you would realize there is nothing incorrect, nor different about that code than in the stdlib From stdlib crypto.go (and there are many,many others...) func (h Hash) Size() int { if h &gt; 0 &amp;&amp; h &lt; maxHash { return int(digestSizes[h]) } panic("crypto: Size of unknown hash function") } It is common practice when the error is representative of a critical failure, or a programming bug. In the other cases, if the files could not be renamed, it probably should panic - for the same reasoning - but the only reason they would not be able to be renamed would be a critical disk failure - of which there is no recovering anyway. I understand proper error handling.
I will contend that the "simple facts" are what wreak havoc on the language. The reference date is only intuitive for American users, and the American date formatting paradigm is uniquely obtuse. Opinionated decisions need to be backed up by proper research, and "it's what happened when I ran `date`" is not that, as `date` is locale-dependent. Similarly, I feel like allowing the syntax to change meaning in certain context (essentially introducing a DSL) will lead to more confusion than what it's worth. That's a whole lot of extra mental load.
In Europe, is January not the first month? Seriously, the reference date is confusing to Americans too because the time doesn’t really make sense. It’s fine though. 
&gt; The response to this was Rob Pike's filter package using reflection everywhere. No thank. I didn't choose Go so I could ditch types and get horrible performances.
[removed]
The stdlib never, ever, ever skips an error! &amp;#x200B; That being said, whatever man, I am not the first one to tell you about the flaws in your code and I certainly won't be the last. Keep doing whatever you are doing since obviously you know better than everyone else. Good luck. &amp;#x200B; &amp;#x200B;
Yes, I've proposed exceptions, generics, better packaging, and 'file level hiding'. Of the 4, 3 are being addressed for Go 2, so there must be a lot of really inexperienced developers changing Go... doubtful. It may just be that you don't understand my background, or you develop in Javascript. Denigrating someone's knowledge because they left some error case debug statements in the code, or not checking and panic an error, that would immediately cause other panics anyway (disk failure), is probably not the best way to demonstrate your competence.
The language designers are discussing to lift this restriction: https://github.com/golang/go/issues/27165
Again, for that to fail, the subsequent operations are going to fail too - and they have the errors checked. You need to understand the context of the code, or you are just being a monkey mimicking something you heard with a complete lack of understanding. I could add the 3 * 4 = 12 lines to make you happy, sure, but it makes no difference in the reliability of the system. If Go had the "handle" implemented, the code wouldn't even be changed... 