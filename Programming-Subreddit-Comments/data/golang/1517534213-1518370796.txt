If a large project were to skew as heavily by BMI compared to the general population, as most OSS projects do by gender, then yeah, that'd be a very interesting perspective to hear from in particular. Really this is not that hard.
You need to indicate the host you are connecting to. You also should link from your go container to the mysql container on a specific port.
It wouldn't. You need generics for that. They could make result a built-in like map and give it the same behavior as sum types though.
To be clear, the proposal above doesn't force "closed interfaces" to use the same underlying implementation as interfaces. They can totally be done inline as long as you have an acceptable solution to the GC and zero value problem. The idea is to expose the same behaviors as an interface (but tweaked).
Space invaders was my first real experiment too. But not in Go. It was in 1984 for PDP-11/70 on a dumb terminal. And, if I remember correctly, I did it in FORTRAN. The ships were like /OOO\ \OOO/. I think, using https://github.com/gdamore/tcell as a terminal emulator in Go could work for that.
&gt; A document store for arbitrary documents. The client sends documents to the store, whose responsibility is to store them. The store only knows about data types, but doesn't enforce a schema. Okay so if storing them is your only concern then you could potentially directly store the data into the store. Of course that could mean that a user could store an invalid JSON or even arbitrary data. Maybe some lightweight JSON validation could happen before the data is stored. Then again since you do not need to concern yourself with anything else except storing the document, unmarshaling into a `map[string]interface{}` doesn't sound too bad. I was just curious maybe there was a better solution but apparently you've already figured a satisfactory solution as expected from someone who knows the problem domain well. It seems that reflection might complicate things more and code generation doesn't sound like it would be useful. And since it's totally schema less you cannot ask the users to provide the type in a json field and use `json.RawMessage` for lazy unmarshaling. I am a too tired to think at the moment so I might be missing something but it sounds like `map[string]interface{}` is the appropriate tool for the job here.
static analysis for interfaces? In fact, Go interfaces are just a sum types, at run time. For some interface uses, compilers can do type assertions for them at compile time, but the compilation time will become longer. 
To support other terminals you can use something like this https://github.com/mattn/go-sixel .
Great post ! Just wondering, does the `go-fuzz-build` step internally builds the package with the `gofuzz` build tag ? Because you don't specify the tag explicitly anywhere.
I was very clear about my point (go read any of my previous comments), and I offered suggestions to improve the diversity effort. You cannot be acting in good faith and interpret my comment as "trying to derail diversity efforts".
Yes, it does. It needs an exported function to call, but obviously you don't want this in your actual set of APIs for your package.
They're polymorphic, but they aren't sum types. The latter requires the set of implementations to be closed.
There's something about the `usecase` package that rubs me wrong. I feel usecases are a design tool, not an implementation detail. Not every software application is designed with usecases - so your design is methodology is leaking into your implementation. Either way I have the equivalent of a `usecase` package which normally has `service` in the name somewhere.
Looks cool. Is it better than other kits for rest apis? Would you use it today to replace anything currently used?
my iterm on OSX 10.11 consumes 90% CPU and the game is really slow. takes a while until a laser beam hits an alien. Really cool blog post!
An elegant solution is just to add a select{} to the end of main
[removed]
"you already know how to google" the biggest slapdown lol
[sql.Open docs](https://golang.org/pkg/database/sql/#Open) say: &gt; Open may just validate its arguments without creating a connection to the database. To verify that the data source name is valid, call Ping. So, after `Open`, you don't have the connection yet, the returned err is not stating any facts about a connection, data source name or user credentials.
anyone willing to port this to Linux?
I mean C/C++ have existed for ages if all you wanted was pointers. suck a dick and more mature in the same comment. ez trolling.
&gt; Currently I'm using Arch Linux inside a docker container running my Window manager for everyday use(I like keeping the host clean). So how is this different? Do you mean you are connecting to an xserver, remotely? Darch is similar to Docker, in that you can share images via Docker Hub, inherit images, etc, but they are meant to be booted bare metal. That means full blown graphics drivers, regular performance, etc. You still have a host machine that remains untouched that you can reboot back into (grub entry) anytime you like. Maybe you want to uninstall Darch completely? The only thing you'd have to update on your host machine is removing the ```/etc/grub.d/60_darch``` file which configures the menu entries. &gt; you can create an image of your rice and load/port it on other machines using the same tool? Exactly. My recipes ([here](https://github.com/pauldotknopf/darch-recipes/)) are hooked up into Travis-CI and pushed to Docker Hub. That means that I can simply commit any changes I want to my operating system, and a few minutes later, perform the following: sudo darch images pull docker.io/pauldotknopf/darch-arch-plasma:latest sudo darch stage upload docker.io/pauldotknopf/darch-arch-plasma:latest On each machine I have, after running this command, I am now running the exact same operating system, bit for bit.
Neat. I've always wanted something similar. &gt; Do you mean you are connecting to an xserver, remotely? I run the Xserver + pulseaudio on myhost and pass the X11 socket to the container.. etc I love the idea :3 I'll surely give Darch a try. Thanks for sharing it with us! 
it looks *REALLY* nice though! let me give it a try :) (thanks!)
This looks SO rad. Seems like it will make distro hopping and testing various DE‚Äôs a breeze. Seems like it will also help me keep all my various machines in the same exact state with little fuss. Quick question. I skimmed through the docs, maybe I just missed it, but does Darch bootstrap your os according to your configs on every boot, or can changes to an image be persistent?
&gt; does Darch bootstrap your os according to your configs on every boot, or can changes to an image be persistent? There is an fstab hook already done that allows you to mount custom partitions to wherever (/home, /var, whatever). You write custom hooks ([simple bash scripts](https://github.com/godarch/darch/blob/develop/scripts/hooks/hostname)) if you need something more involved. I plan, in the future, to treat uploaded images (for booting) to be treated like containers, where they do preserve the state completely. Instead of using squashfs with tmpfs overlay, it will use a simple directory as a rootfs, as distributions normally do.
I think you're in the minority here. With production systems, you will normally have a caching resolver within a millisecond or two in the same datacenter. 
I appreciate the thought, but this is a fancy way to sleep in your tests, not a way of avoiding sleeping. Needing to "wait" in your tests is still indicative of a problem somewhere. However, sometimes the problem being indicated is that third-party code doesn't have the "right" synchronization for your tests, and you may not want to hack it up to include it, so I won't deny I still have the odd sleep in my tests here and there. (I'd suggest that you should never be "waiting" for anything in the package you are currently testing; there is just-shy-of-always a way to put a useful sync point in. My last resort is generally a combination of `sync chan struct{}` and `if obj.sync != nil { obj.sync &lt;- struct{}{} }`, but that can be a real life saver sometimes, especially in goroutine servers that are just sitting on a channel and dispatching requests that don't otherwise need a reply.) I would suggest that this package becomes even more useful if you use an exponential backoff instead of linear waiting. In practice one of the bigger problem with sleep is that sleeps large enough to work reliably are also large enough to add up really quickly, turning tests that ought to run in a millisecond into multi-second extravaganzas. A package that formalized an exponential backoff would help with not slathering up the codebase with `time.Sleep(time.Millisecond*100)` and such. Instead, if the first wait was for a microsecond, then 5 microseconds, then 25, etc. odds are in general you'd end up sleeping much less clock time at the very least, so this would be much faster than naive sleeping, and faster tests are a very good thing.
&gt; Bolt provides safe upgrades between database files ... Here, the "Bolt" should be "bbolt"?
Interfaces in Go have two duties, polymorphic and value boxing. The value boxing duty is really sum type.
&gt; I hate to say this, but it is a shame that the word "diversity" has just simply become a cognate for "not white men" It's similar to the [Women Who Go](https://twitter.com/womenwhogo) movement. Its own mantra reads: "Building a more diverse and inclusive golang community." But how can that be if it only includes women? 
I Wanted to set up my Systems with new os and shit next Week. This came godsend Thanks.
I use this tool that I wrote: https://github.com/peterhellberg/hiro Example of service that use Hiro: https://search.b17g.services/
Graphql and GRPC
it's missing a few features (categories, ability to send mails when a new post is sent) but I can live with(out) that for the moment. (and I'll probably try to add those.) **huge thanks**
Look I don't want to say anything bad about WWG because I think they do great things and I don't think there is anything wrong with a group of people from similar backgrounds and struggles forming groups to support each other. A quick personal story: I am from migrant parents and my father still til this day doesn't speak english beyond a middle school level (my dad's been deported twice -- makes for some good dinner conversations). I am constantly mistaken for someone middle eastern (despite being mediterranean), and it is also unfortunate that that mistake has consequences. On the outside, it would sound like we are the majority as we are Christian, but to mainline Christians in America, we are ostracized as being some crazy voodoo idol worshippers because we aren't the "right" kind of Christians. My brothers and sisters in Christ are being slaughtered in the middle east, and I can't help but imagine that if it was someone associated to Franklin Graham or some mainline protestant group that America would have already gone to war with that country. To tie that quick personal story back -- there is no one championing diversity from someone with that background, and that's okay. It doesn't make me feel "oppressed" yeah it sucks I have no one to relate to on that level but it's not because someone's doing it on purpose, and I am not going to start championing that there be more coptic or Orthodox immigrants represented, or that we are being oppressed or all this that in the other -- number one because it wouldn't gain steam, as there isn't much political capital or economic capital to gain by holding that stance, and number two the way to fix it isn't by artificially inflating it by actively seeking more people that came from my situation and inserting them into the fray just for the sake of some "diversity" initiative, and I wouldn't want it to be that way anyways. Anyways that's my two cents. But seriously don't make my post a way to throw shade at WWG it's a good group. I am not trying to stir a fight here, we just need to really think what we mean by the words "diversity" and "inclusivity" 
Is there a proposal for that?
Those aren't duties; polymorphism is the duty, value boxing is part of the implementation. Value boxing is also part of an implementation for sum types, but that doesn't mean that interfaces are sum types. Specifically, interfaces don't constitute a closed set of types, as evidenced by the type switch syntax that you cite--the type switch can't tell if you've exhausted all valid types because interfaces don't have a concept of "all valid types". That's the theoretical argument. The practical argument is that using interfaces to emulate sum types is ergonomically awful. I should be able to write something like `type IntList = Nil | Cons(int, IntList)` and have the compiler generate the polymorphic implementation. I should also be able to do *real* pattern matching and expansion--not just type switching.
`go.forum` seems very limited. I'll go with `bebop`. "cowboy bebop" ? (hopefully that won't be a rodeo :P)
I have been using [goa](https://github.com/goadesign/goa/) successfully in a project. Works very nicely and auto-generates swagger docs from your code. Then I just dump the generated json into swagger-ui to show to my PM. Has worked okay for me so far.
I'm not talking about the datacenter, I'm talking about what happens when you try to resolve a name that hasn't been cached. How about you try the exercise yourself and report back, eh?
Bolt maintainers disagree on the changes. 
I've been using go\-swagger to much success. \(There was a bit of learning curve to get things integrated in my workflow, once I sorted that out I reached a point where I can entirely ignore the generated code directory and focus on the business logic.\) What are you finding to be a clusterfuck about it? I might be able to point you in the right direction. \(Side note: I hate the annotations approach because it usually degrades into "I must manually keep my annotations up to date with the actual validation logic that happens a few lines down"\)
When we store a concrete value in a blank interface, we never care about the polymorphism thing. We just care about the value boxing thing. An blank interface type is just a struct with two fields, a type and a non-interface value. From this perspective, it is very similar to sum type. Yes, it is not closed, so it is not a perfect sum type. Type switch can be used at any scenario where sum type is needed. The only benefit of sum type comparing to type switch is it covers all possible pre-defined cases. In my honest opinion, sum type is a feature which looks beautiful but not very useful. 
Betalo.com | Mobile banking | Stockholm, Sweden | ONSITE | VISA | Full-time | Team of 6 backend engineers | 45K SEK/month+ and equity I'm Kevin, the CTO of Betalo, a startup in Stockholm, Sweden. We are building the the bank of the future here in the Nordics. We are actively looking for Go developers to join our team here in downtown Stockholm to help us build our new backend, written entirely in Go. We are looking for both mid-level and senior backend developers. Bonus points if you have worked in microservices and/or AWS previously. You can apply directly at this link: https://betalo.teamtailor.com/jobs/14348-senior-go-software-engineer
[removed]
Remitly.com | [Remittances](https://en.wikipedia.org/wiki/Remittance) | Seattle, WA | ONSITE | Full-time Looking for an SDE to join Remitly's Infrastructure team. Internal tooling is all written in Go: https://www.remitly.com/us/en/careers/1025011?from=engineering&amp;gh_jid=1025011
This makes sense since the docker containers wont have the same localhost. I have a docker compose file set up so they can communicate through a virtual network with the host location being http://goappdb:3306. would something like this work? goappdb:goapppassword@http://goappdb:3306/goappdb
the error says dial tcp 127.0.0.1:3306 getsockopt: connection refused I've reconfigured docker using docker compose to set up a virtual network the two containers can communicate through, the host of the database should be http://goappdb, do I just plug that in as the host name in a string with this format? user:password@hostname/dbname 
Weta Digital | Visual Effects | Wellington, New Zealand | ONSITE | VISA I'm a Senior Software Developer in the Production Engineering department at Weta Digital in New Zealand. While we are looking for a Senior level Python developer, we have a number of services, tools, and libraries written in Go. If you are experienced in Python but looking for an opportunity to really flex your skills in Go and make a difference at an award winning Visual Effects studio, check out this role: https://careers.wetafx.co.nz/jobs/720 
An interface is similar to a tagged union. A tagged union is a runtime implementation for the type system. But the type system can't reason about a tagged union without a formal notion of a sum type. &gt; In my honest opinion, sum type is a feature which looks beautiful but not very useful. If you're only ever modeling a world of things that are AND relationships, then I suppose not. If you have OR relationships, you need some way of representing them, and all of the mechanisms for Go are error prone and/or verbose. How would you model a JSON type in Go? This is what it could look like: type JSON enum { Array []JSON Object []struct{Key string, Value JSON} String string Number float64 Boolean bool Null }
Are you looking for one using html/template or will it be an API for an Angular / React / Vue frontend? I think it's reasonable to have very few dependencies either way. I often use [storm](github.com/asdine/storm) for data storage (though you could swap that one for a SQL database driver) and [go.uuid](github.com/satori/go.uuid) for UUID generation to use as session tokens and then have very few other dependencies. If I have something else, it's specific to the problem I'm solving.
GitLab | Engineering and Non-Engineering Roles | Remote Only | Full-time | https://about.gitlab.com/jobs/ We're currently hiring developers, managers, director level positions, and more; see https://about.gitlab.com/jobs/. We're a remote only company so everyone can participate and contribute equally. GitLab Community Edition is an open-source Ruby on Rails project with over 1000 contributors.
It looks very interesting but can someone ELI5 whats the advantage of using this over docker? I know that my question is already stupid, sorry but I don't get it. Can I use it to boot a os in a secure way to do internet banking or what's the use case? Thank you
And I couldn't recommend enough to apply for this company. I just started there last month, and my best work experience.
very interesting project ;) did you hear about [linuxkit](https://github.com/linuxkit/linuxkit) (one of the block of moby project)? Darch is something like this - you can built your own system environment based on containers?
I've been using dep
Bare metal performance with full driver support (NVidia, wifi, etc). You are literally booting a normal machine. Not a VM or a glorified chroot (containers) using kernel of the host. You can quickly swap between distros and desktop environments effortlessly. Again, all native. Also, you are forced to (in a good way) to keep your system entirely scripted and under source control.
Lyft | Transportation | Seattle, NYC, San Francisco | ONSITE | Full-time I'm an engineer in Seattle. Happy to talk about positions in all three locations. Hiring in product and infrastructure. We use Go extensively in both. PM me for details. Also checkout out specific jobs here: https://www.lyft.com/jobs 
Was using glide and moved to dep. works a charm.
I've been reading about it. It seems to be stable now and it has migration as well. I've seen they updated the documentation as well so it looks good. 
thank you very much for the explanation.
Good to hear, Glide has some issues that I would like to avoid. I assume that's why you switched as well?
Definitely! 
Used Goland and switched to vscode. 
For your Backend Developer, CI/CD is required strong knowledge of Ruby?
Appears to be ONSITE | San Francisco | Full-time
+1 for dep. it is the unofficial official dependency tool for go and has the support of the go core team. also it works pretty well
Thanks! Added the tags, my bad. :)
I've been working on a project using goa as well and it's been great.
One of the things that makes the Go community so great is that by and large they haven't made a big deal about the sex or race of the presenters who all work extremely hard to put together high quality presentations which add a lot of value to the community. There has been the same level of contributions by underrepresented communities, but the content of their talks were what was applauded. The Node community went so far to the extreme in trying to attract what they perceived would be valuable insight from other voices that they had to cancel conferences because of unachieved quotas and uninvited amazing speakers who helped build that community because a small group found them offensive. I am sure I am oversimplifying the issue that Russ Cox sees, but following the path that Node took will not improve the community. This includes underrepresented people who like a majority of Go developers use Go for their job and aren't interested in speaking at conferences.
Electronic Arts | Engineering Roles | Austin TX, Seattle WA, Vancouver Canada, Montreal Canada | Full-time | - Infrastructure Automation Hi Gophers! My name is Charles and I run Engineering for TechOps at Electronic Arts. We are responsible for automating the infrastructure that powers our games. Servers, VMWare, Amazon, Google, and Azure. We automate it all into a single platform! Our entire stack is written written in Go and JavaScript. We love open source and contribute back to the world. ** Jobs ** * https://career4.successfactors.com/career?career_ns=job_listing&amp;company=EA&amp;career_job_req_id=113676 * https://career4.successfactors.com/career?career_ns=job_listing&amp;company=EA&amp;career_job_req_id=113826 * https://career4.successfactors.com/career?career_ns=job_listing&amp;company=EA&amp;career_job_req_id=116477 * https://career4.successfactors.com/career?career_ns=job_listing&amp;company=EA&amp;career_job_req_id=113528
so did Kodak: We are running our KodakOne Project and I am searching for some more Blockchain and stellar Professionals for the Berlin, Germany Region. We have some conceptional tasks to validate and many coding stuff for different payment use cases based on smart contracts. Currently we are a team of 10 devs in Berlin and a few at some cool partners around. If someone likes to join our time, feel free to ask and answer.
Go is a language designed perfect for 95% use cases, from many aspects. You example is very niche. Go can handle it, with a not beautiful way (but it is acceptable): type JSON enum { Array *[]JSON Object *[]struct{Key string, Value JSON} String *string Number *float64 Boolean *bool Slice *[]V Map *map[K]V } In Go, if a feature can't bring many useful use cases, then it wouldn't get approved. To get it approved, the ConceptComplexityIncreasement/UsefulnessIncreasement ratio must be low. The use cases of this proposal can be satisfied by the current features (though not beautiful), so the UsefulnessIncreasement of the proposal is small, which makes the ratio large. 
https://github.com/mattn/go-sqlite3 supports `database/sql` interface standards so i would start there.
Jerf made some good suggestions about how to make the package more valuable, right now there is no benefit to it over a [for loop](https://play.golang.org/p/wx1mb9zpyYN), nits: - Run your unit tests with -race for anything that is meant for concurrent use, your test has a race condition (assigning enabled). - Consider renaming your account to "rshetty" since it just leads to portability issues, your example wouldn't run on Linux because it imports "rshetty" while your readme says "rShetty".
Those aren't type safe. You don't seem to understand what sum types are and you're not apparently interested in learning, so I'm going to duck out of this conversation.
thanks for the link
I have 6+ years of Go experience and yet they rejected me twice without any explanation, most likely because of the Ruby requirement. Not sure this is a great fit here as a result. Is Ruby required for director/manager positions? I have 3+ years of experience in C-level positions, and led teams for even longer.
Dep hangs a lot, panics, provides bad error messages, etc. but we use it since its the most official one.
I would suggest people try [bazel](https://bazel.build/) (The Go rules are at https://github.com/bazelbuild/rules_go), not only for the dependency management feature. It's compatible with standard go tools, but also has other benefits like it does not have to be under GOPATH. The dependency management on Bazel is basically define a git repository in your WORKSPACE file, something like: go_repository( name = "com_google_cloud_go", importpath = "cloud.google.com/go", commit = "166a315629914c5562c6b111cab2f80c4ea9a2ea", ) 
I know there are already a few SSH honeypot written in Go out there, but few seems has much interaction rather than logging user/password combinations. I am trying to achieve what Cowrie/Kippo does, and some of the features like SCP/SFTP, shell session recording has already completed. Next step I'm thinking of doing shell script interpretation but don't know if there are any libraries that could help me to avoid reinventing the wheel. Also I'm thinking of external logging (e.g. to logstash), since now the honeypot logging is based on logrus all I need to do is to import some other hooks available, but the problem is how many hooks I should include? Also do you guys think of any features I can work on it later on?
Hello Kevin, do you offer relocation assistance for successful candidates coming from abroad?
I guess this is about preference most of all. I personally looked into [Reform](https://github.com/go-reform/reform) and [Gorm](https://gorm.io) both have quite a different way of achieving things. I think depending on your scope Gorm might be the easiest ORM to get yourself started. 
Just write raw sql.
You do lose out on some cool NixOS stuff like isolated environments for packages, on the fly environments with nix-shell, and so on. I don't mean that as a criticism since Darch isn't trying to serve those purposes, but it would not be fair to say that Darch is a superset of NixOS by any means.
Had to upvote, being the devout Stellar HODL'r I am.
Starts in 45 minutes. Schedule: https://fosdem.org/2018/schedule/track/go/
My recommendation is to learn to use `database/sql`. It provides a common interface for any relational database you might use (sqllite, MySQL, Postgres). This means that the code you write is the same with the only difference being the driver you import. In your case: import ( _ "github.com/mattn/go-sqlite3" ) As an additional benefit, knowing SQL gives you useful, transferable knowledge. If you later want to use an ORM library you will have a better understanding and an easier time debugging issues. Useful resources: * https://github.com/golang/go/wiki/SQLInterface * http://go-database-sql.org/
You will need to add "(" ")" to be able to connect to a IP or name. "goadddb:goapppass@(127.0.0.)/goappdb" Please take a look into the full description of the DSN in the readme https://github.com/go-sql-driver/mysql#dsn-data-source-name
You will need to add "(" ")" to be able to connect to a IP or name. "goadddb:goapppass@(127.0.0.)/goappdb" Please take a look into the full description of the DSN in the readme https://github.com/go-sql-driver/mysql#dsn-data-source-name
But if you add so many features, it is not a honeypot. It is a full blown ssh server ;-)
With virtual FS, fake shell etc. it's already more than a SSH server :P Anyway, this gives an option to those who don't have the luxury of setting up a dedicated honeypot host
I'm glad someone feels the same way about Discourse! I've always felt their usage of containers is completely wrong, it's not portable or isolated in any way and requires the host to run a bunch of code. Microservices and Kubernetes would definitely be the way to go, being able to scale different parts of the backend and easily add new components would be invaluable to larger communities. I'd get started on this right away if I wasn't so busy :(
Man if you couldn‚Äôt get the job then I need to just start flipping burgers
Hey Francesc, long time viewer here. Is your talk going to be on youtube? Thanks
Yeah! It was live streamed and I'll see how we can upload it to the go YouTube channel
Awesome. 
As already explained, use https://github.com/mattn/go-sqlite3 and at least learn to use the standard sql package. A short tutorial is available here : http://go-database-sql.org/index.html (not specific to SQLIte). If you have few and simple requests, stick to standard package. Don't use external dependencies unless it give you some real benefits. If you have more requests you can use something like sqlx : https://github.com/jmoiron/sqlx . It maps queries results to Go structs, then it helps mostly with SELECT queries. You have richer packages. I wrote godb : https://github.com/samonzeweb/godb , but there are others, each with different capabilities, different approaches. I don't want to sell my stuff, choose the one that suits you. 
It's not all about experience, a lot of factors are evaluated during an interview. I don't speak for GitLab here, but it can be communication, ability to work in a team, to work remotely, and sometimes, it's just the feeling of the recruiter. I'm a recruiter too, and if someone apply to one of my postings arguing "I have 6+ years of Go experience, hire me", that would be a bad conversation starter.
Get some sleep üõè 
You say it like this was not something I had not thought about haha
Dep! Only Dep! https://github.com/golang/dep It will become an official part of Go in nearest future
Kodak too?
&gt; they rejected me twice without any explanation I guess I should've been more explicit, sorry. They rejected immediately as I submitted the resume. I don't blame them, didn't want to come off as negative, I've reviewed hundreds of resumes and shamefully I've resorted to the same keyword-based heuristics. Just wondering why they posted in r/golang, because I'd love to apply again if they're more Go-friendly.
I have crippling Impostor's Syndrome on a daily basis, so don't worry about it that much. Just figure out if you like coding, and if you do force yourself to do it even beside work (I've always struggled with that), and just build something cool - or contribute to open source. Might be worth checking these out (last 2 I found on Google just now): - https://medium.com/always-be-coding/abc-always-be-coding-d5f8051afce2 - https://medium.com/always-be-coding/four-steps-to-google-without-a-degree-8f381aa6bd5e - https://medium.com/learn-love-code/developers-how-to-overcome-imposter-syndrome-48edee803cf4 - https://www.reddit.com/r/programming/comments/4fn8go/feeling_like_everyone_is_a_better_software/
Which country are you in? That was maybe the issue, I‚Äôm not sure. Anyway, if it was the case, an explanation is still nice to have when a resume is rejected. Hiring is like any other process at gitlab, and is getting updated and improved all the time. You can pm me your resume, and I‚Äôll check if I see something wrong about it. Cheers
Ah have been to busy writing a driver against the new go 1.10+ interfaces to remember that forgoes the DSN nonsense (they are a design mistake).
Hasn't GOROOT been optional for several versions? I never set it and everything works fine.
You have inspired me. Just ordered a better mic. Should be ready for Tuesday's stream. 
`GOROOT` has (always?) been optional when using Go from your package manager or a self-compiled version; it's when unpacking the pre-compiled tarball to somewhere other than where it was compiled for (`/usr/local`) that you needed it (eg: if you unpacked it to `~/.local/go` or something). With Go 1.10, it should no longer be necessary to set `GOROOT` no matter how you installed it. From the release notes: &gt; If the environment variable `$GOROOT` is unset, the go tool previously used the default `GOROOT` set during toolchain compilation. Now, before falling back to that default, the go tool attempts to deduce `GOROOT` from its own executable path. This allows binary distributions to be unpacked anywhere in the file system and then be used without setting `GOROOT` explicitly. 
Ah cool. Looks like it was changed in Go 1.0. https://dave.cheney.net/2013/06/14/you-dont-need-to-set-goroot-really
The "A couple more changes" page link text to the release notes say "1.8"
fixed, will be updated "soon" when the cache dies
Yea. It doesn't import reflect. See https://beta.golang.org/src/strings/builder.go?s=386:479#L5
That is really weird. You can see for yourself that its just a wrapper at https://golang.org/src/html/template/template.go?s=388:824#L9
My guess it's an oversight in the html/template escaping logic. File a bug.
From Stellar Slack channel
thank you!
Filed https://github.com/golang/go/issues/23683
Slide 30 shows strings.Builder performing more slowly than bytes.Buffer at building up a large string. Any idea why? Worse slice growth algorithm?
Was on 2nd row, really great presentation congrats !
Can we make windows Dlls with this new version ?
This just popped up on my GitHub feed: https://github.com/disintegration/bebop
[removed]
Thanks for this. I've been beaten myself up recently. We transitioning to more open source and so much of what I done lately is packaging and building config files. In addition, we are stuck on C++99 building on Fedora 14. The last interview I had really tore me up, so starting a personal project has really helped me get familiar with new environments and get my confidence back.
I suppose I haven't really counted the number of lines of generated code, but for me it doesn't matter any more than the lines of code I pull in from libraries, or the number of bytes in the final binary. I rarely, if ever, _look_ at the generated code. I use VS Code as an editor and it can auto complete all the various bits and pieces I need from the generated code without having to dig into it often. Occasionally I do look at it to figure out something I'm not fully understanding about the structs and tags coming out, though.
with a similar configuration I'm getting an error saying that the mysql cant be initialized --initialize specified but the data directory has files in it
Wishing there was more part time/full time remote positions. I have a candidate with strong network stack knowledge (hardcore IP, BGP, SNMP, etc. just in case somebody thought there's only HTTP in this world ;)) and an good proclivity for cross compiling toolchains, CGO, and other stuff that's often over my head, so super senior experience. If somebody has something in these areas, hit me a comment/DM so I can connect you. &amp; mods: consider also a reversal - "Who's looking for work" type of thread. Would make more sense for my comment :)
REMOTE | Irvine, CA USA Hello Go Community. BLeve is a globally distributed team working on cutting edge projects for some of the world‚Äôs top retail brands, healthcare organizations and financial institutions. Our clients include top retail brands, startups, IoT, crypto currency/blockchain, healthcare and fin-tech organizations. We are looking for motivated and experienced GoLang devs to join us in building cutting edge platforms, apps and open source projects. Description The job is a remote position, so the qualified candidate can live anywhere in the USA. The candidate must be an energetic, self-starter who is self-motivated and comfortable working in a remote environment. Infrequent on site work may be required and travel expenses will be covered by the company. Skills &amp; Requirements 2+ years as Golang developer 5+ years of experience with software development Relevant and solid work experience with similar distributed systems Focus on writing high quality, testable and maintainable code Understanding of data structures, algorithms and design patterns Experience with monitoring and performance analysis Comfortable with Linux, Unix or OSX Experience with micro-services infrastructures Experience working with remote/distributed teams Business fluent in spoken and written English How to apply Contact us at careers@bleve.io. Please include a copy of your resume and links to your LinkedIn and Github profiles. Individuals only, no agency applications please. 
It's an open source rewrite of Google's blaze, which I've been using while at Google for a couple of years (but not for Go). Personally I've been using it for Java and Kotlin (where its advantage over other tools are a lot more clear than for Go). I've been using it in my [Go project](https://github.com/fishy/fsdb) as it gives me `bazel test ...`, as I have multiple packages in that repository.
Kodak? What's Kodak?üòÅ
If one could go get bazel, it would be a no brainer for some things...
Any feedback will be appreciated.
This could be useful. I've definitely rebuilt a lot of config loading and validation logic across multiple services; its often not safe enough to directly call os.Getenv(). The main advice I'd give; - Its not clear to me from the documentation how the YAML config file is loaded. Is it loaded at codegen and the values are inlined into the gen'ed Go code? Is it loaded at runtime and the file has to be named something special? Is it provided as a parameter? - Support loading from environment variables. They're everywhere in deployments like Kubernetes. - Support discriminating between optional and required configuration params, with errors on missing required params. There are many instances where configuration isn't required in certain environments (say, an analytics API key when running in development). - Use `dep` instead of Glide. - This matters less because this is a binary instead of a binary dependency, but you've got a lot of heavy dependencies on this for what it does. Yaml parsing is fine, of course. But Kingpin and Afero? There might be room to shed some weight here. 
1) Yes, I missed the part how the actual YAML file loaded. Will fix docs. 2) As it is a wrapper over viper, I think it should be able to access variables from ENV. Will check that 3) This is in plan. 4) dep -- need to decide on this one. 5) It makes sense to reduce the weight. I would work on that. It is useful and thanks
`byte` is an alias for `uint8` in Go. Even if you say FEND = byte('\u00c0') it will still end up as `uint8` (for example if you run `reflect.TypeOf` on it).
&gt; Basically, I just want to define a constant that is a single byte const fend byte = 0xC0 (but does it really need to be typed? It's idiomatic to use `const fend = 0xC0` and infer the type at the usage-site) &gt; Another question - how do I go about adding a byte to the beginning of a byte array? nit: In Go, arrays and slices are a different thing and we usually use slices. In particular, adding a byte to the beginning of an array isn't possible, as they have a fixed size. That being said, here are two ways: // Allocates a new slice and copies the old data over. Use this, if the original slice might still be in use in other parts of the program. var x = []byte{1,2,3,4,5} x = append([]byte{fend}, x...) // Only allocates a new slice, if the old one doesn't have spare capacity and is thus sometimes more efficient. Use this, if it's fine to modify the slice. var y = []byte{1,2,3,4,5} y = append(y, 0) copy(y[1:], y) y[0] = fend Prepending to an array is a somewhat expensive operation in every language, as it implies moving the data one slot up and overwriting the first slot. Go tends towards making expensive operations visible in code, i.e. not make them too convenient, which is why both of these are more verbose than you're probably used to. In general, this is a good thing - it encourages you to try and come up with a more efficient algorithm that does not rely on prepending to slices or to pre-allocate extra space if you can (and then reslice once you are done prepending). The Go wiki has [more examples](https://github.com/golang/go/wiki/SliceTricks) of how to do common slice operations in Go. Hope this helps :)
Hi, Thanks for responding! Yes, that's the link I went to read on those variables when I referred to the documentation. I guess I really need to understand the memory allocation concepts like you said before all this makes sense? So, in a general term where if someone was to ask you - "How much memory does your program consume?" What would your answer be? Or what metrics would you look at to really answer it? That's the kind of stuff I am trying to infer here. I am cautiously keeping a watch on memory leaks that I might introduce rather than premature optimization at this point.
Ahh I gotcha! Okay so memory is allocated to a program in two places. The call stack, usually just called the stack, and also the heap. Variables local to your function are allocated to the stack(very fast read/write) and the variable is gone once the function returns. If you declare a variable outside the scope of a function it‚Äôs going to be allocated to the heap, which is a little slower to access than the stack. Go actually chooses the location that the variable goes to automagically so these rules only sort of apply in go. At this point you may be asking yourself why doesn‚Äôt everything get allocated to the stack? Well the stack is small, only a few mb on most systems. Each function you call within a function keeps putting more and more values onto the stack. If you exceed the stack size you get what‚Äôs called a stack overflow and shit hits the fan. Memory useage is represented in mb when you‚Äôre profiling performance. So you could tell someone your server only uses 2mb of memory at peak or whatever. As far as memory leaks are concerned in a garbage collected language like go, unless you‚Äôre putting values into a global hashmap or array or other data structure and not ever removing it, you‚Äôre not going to have a leak. Memory leaks are very common in manual languages like c or c++ because someone will do a malloc() and then never call a free(). Sorry if that‚Äôs butchered as I‚Äôm on mobile. 
&gt; When writing dozens of API endpoints I would prefer not to manually type out validation rules and response handling in every HTTP handler. You could create a few helper functions and use those instead.
There's a big gap in the Go ecosystem when it comes to GUIs and the popularity of this library makes it all the more obvious.
This looks great! Using functions to get config values might make refactoring easier.
Thanks! I also read [this stackoverflow ques](https://stackoverflow.com/questions/79923/what-and-where-are-the-stack-and-heap) &amp; now I understand the stack &amp; heap a lot better. So true memory consumed would be stack memory allocated + heap memory allocation at any point in time, right? But I am guessing since stack memory is very small (and probably diff for diff environments), everyone is only concerned with heap memory allocation, which is reflected by Alloc here in my case. Would that be accurate? And talking about peak memory consumption is a good way of answering the question.
Yes it would be both stack and heap at the same time. People are definitely concerned with the stack as well as heap, just in different ways. The stack is like the heart and soul of your computer, kinda. However there are things like stackless python 
Thanks for taking the time! :)
You‚Äôre welcome! Also keep in mind each Goroutine has its own stack!
Yes, I just read that. I think I know enough to watch out for memory leaks and possible future optimizations. And if/when shit hits the fan, I will def learn more :)
What do you find unsafe about os.Getenv? Not trolling, just legitimately want to know if I am missing something.
Is there a setting to make it really, *really* slow?
https://golang.org/pkg/testing/quick/
https://golang.org/ref/spec#Rune_literals
Which country are you in? That was maybe the issue, I‚Äôm not sure. Anyway, if it was the case, an explanation is still nice to have when a resume is rejected. Hiring is like any other process at gitlab, and is getting updated and improved all the time. You can pm me your resume, and I‚Äôll check if I see something wrong about it. Cheers
I wouldn't worry about making a new post; SO/golang-nuts/the gopher slack are also good sources of help, of course :)
It's fine to update your post, but the best way to get help around here is linking to a [playground](https://play.golang.org/) that runs the code. It's fine if it does't compile or has an error, just being able to see your full program is a big help.
[removed]
Yes, it's because that benchmark is measuring how long it takes each implementation to grow the backing slice. The strings.Builder has a [copyCheck](https://www.reddit.com/r/golang/comments/7j65d0/new_in_go_110_stringsbuilder_efficiently_build/dr4zxi7/) that adds a little overhead here, it also doesn't have the built in small backing array like [bytes.Buffer](https://golang.org/src/bytes/buffer.go?s=834:852#L7). So it needs to go through more initial allocations before it's Size is that of the initial bytes.Buffer. I talked about use cases in the copyCheck link a little that I think are a better fit.
Directly accessing os.Getenv from wherever application code means you're scattering the "manifest" of your configuration across potentially tens of thousands of lines of code. Instead, I prefer to centralize all of that access into one package (usually called `config`) which acts as a layer of indirection into os.Getenv. That way I can easily see all of the config my app needs, all in a single package or file, so I can ensure the provided deployment config matches what the app is requesting. A library like this one would automate that process considerably. Additionally, I like to "dry run" loading all the config right when the app starts, then panic out right then if something we expect to be there is missing. If this ever happens in production, we can set up Kube to automatically rollback. But that's rare; more often, it happens in dev when a developer doesn't set up their dotenv file correctly. Better to fail at the start then in some edge case branch that requires some specific piece of config. Finally, centralizing it into one file gives you explicit control over behavior when they load. You can opt to mark specific pieces as "required" so they panic if they're missing, or you can keep some optional (things like analytics keys, where analytics aren't tracked in every environment). You can print warnings if optional ones are missing. Things like that.
Currently nope. Maybe you can use some OS level throttler to do the job. Just curious what is the use case behind that?
&gt; Just curious what is the use case behind that? To waste the time of the would-be attackers. It seems to me that one of the goals of simulating a realistic environment is so it takes a would-be attacker longer to figure out that they're not really logged into the box. Making the honeypot quite unresponsive strikes me as a good way to do that.
Looking forward to hearing the context around the curling rock ü•å. Apt, being a sport that appeals to the programmer's mindset.
if you use es as database, you can consider a little lib written by me http://github.com/cch123/elasticsql
I agree on renaming *ReadInCfg* to *Load*.
Please say "feels dirty" or something like for that. "Unsafe" means something different.
Just what I was looking for, great work!
Can you suggest a thin library?
It's safe to do and doesn't really have any drawbacks. In fact, that's specifically [why](https://github.com/golang/go/issues/16085) that rule [was introduced](https://golang.org/doc/go1.8#language).
Looks really promising.
I‚Äôve watched both of the videos so far, and firstly, congrats on being a content creator and trying to give something to hat will help grow the community. However, like many YouTube instructional videos, it‚Äôs not really clear who this is aimed at. On the one hand, it is pitched at such a simple level, that anyone above the most basic gopher will already know all of this. On the other hand, for those really new to the language, it doesn‚Äôt actually give any real understanding. For example, what is the advantage of using StrictSlash? The videos so far consist of little more than ‚Äútype this, type that‚Äù. For new gophers, understanding how StrictSlash impact path matching would be useful to their understanding of what you are actually trying to achieve, and what they might be able to do in the future. That‚Äôs just one example, where I think the opportunity to hit one particular audience has been lost, and the result is a kind of confusion about who the actual audience is intended to be. Don‚Äôt want to be a downer. It‚Äôs always good to encourage people that are creating content for others. So in the whole, huge congrats.
That's a pity, I just settled in Auckland..
I find code sanity is one of the most interesting feature of go compiler. Let developer forget unused stuff behind there and you‚Äôll be sure to get a less maintainable code base.
&gt; Now, Go isn't my favorite language, but it beats the pants of anything else for most web dev tasks. What is your favorite language?
That actually makes a ton of sense! Thank you
I work for a company based up north that use Go almost exclusively for backend development. I've seen a couple of the other big agencies up here also using Go from time-to-time. I think there are a few reasons why Go isn't seen quite as often: * More established and "trusted" languages are there, despite potentially being a worse choice in reality. * Languages like Node.js that seem easier to pick up have surged in popularity, especially in things like startups because a lot of people know JS already. * Go is still very young, but despite that it is gaining popularity quite quickly IMO, but still, I think it will become much more prominent given time. * Given all of the above there simply aren't as many skilled developers that know Go around. There are a lot in the world, but to build a team of Go developers can sometimes be quite tough depending on where you are. All of that being said, there are some very big names using Go. It has become a great language of choice for ops tooling, and for cloud providers too (e.g. DigitalOcean). Go _is_ great tons of reasons, but I also think that a lot of non-techies haven't really been exposed to it much yet either. Again, maybe because it's a very back-back-backend language for many. You hear about Java because it's taught at Unis. PHP is everywhere and sort of front-end, and there's WordPress, etc. JavaScript is the only front-end language of choice. Python is well established for maths and data analysis and what have you (?). C and C++ are ancient and very well known. I've mentioned to recruiters in the past that I'm looking for Go jobs (and did eventually find one thankfully), but many recruiters I spoke to don't even know what Go is! More people in general need to know about it, but that'll only happen as it grows more, organically. I think it'll happen as time goes on, and as word still gets spread about it.
We have our own; just a couple convenience methods for constructing URLs, handling errors, etc., and some base structs to help compose response objects.
&gt; or everything that embeds one of these will also require some explicit initialization Also, you couldn't ever have sllices or channels or maps of sums. &gt; Finally, sum types are much more useful if you have generics. Also pattern matching (which probably requires some notion of type constructors). Like, if we'd get sums and generics, people would start bitching about having to type-switch on their result types like they are currently about checking for errors. Meaning you probably also should throw macros in, for good measure. Honestly, I don't really see the point of sum-types for Go, you'd basically have to make it into Rust for sum types to be useful (and to me, that seems to be mostly the perspective they are proposed from; i.e. "why is Go not Rust?").
Thanks for the help! I've added a playground to my post. Had to reformat to put all my code in a single file but the exact same problem is still there.
I don't see why type constructors would be necessary or why they would be a problem. If you have generics, you have *less* of a need for macros, not more.
I was thinking more along the lines of making commands take an excessively long time to execute.
Saying to use pointer receivers until pointers and values really click for you wasn't a slight, nor does it have anything to do with your experience with pointers in general. I meant how [pointers](https://golang.org/doc/faq#Pointers) and values apply to Go. Specifically how they affect [calls](https://golang.org/ref/spec#Calls) and [method sets](https://golang.org/doc/faq#different_method_sets) which lead to the incorrect [value or pointer](https://golang.org/doc/faq#methods_on_values_or_pointers) decision you made on your struct that caused your error. Was just trying to give you a good general rule to avoid that kinda error while you get up to speed, that's all. Have a good one.
I had think of that but seems implementing a timer on every channel (sftp/scp/shell/remote exec) to keep consistency would make the code a little bit hard to maintain... Anyway I'll try to look at both solution when I think it's time to do it.
Hey, thanks very much. :D Glad you liked that. :) I'm 'bout to update it a bit, since furnace evolved a little since I drew it first. But I would like to keep it as simple as possible. Good luck! :)
In Go, a struct is just a type with some functions associated with it. An interface specifies a type with some set of functions, so anything that implements these 'functions' can then be used as this interface (it doesn't necessarily have to be a struct).
[removed]
Yes, we sure do. Hope to see your application soon!
Considering there's a bank, Monzo in UK, building their whole backend in Go, then yes, Go probably is ok.
I think that we are talking about a very good package structure. My opinion is that if you remove the unnecessary `pkg` it will become even better.
Do you know about Terraform from HashiCorp? Give it a try ;)
There is also a lightning (bitcoin) implemention (https://github.com/lightningnetwork/lnd) done in go, and I see no reason why you couldn't do payment related thingsin Go.
I am very happy with govendor. Dep is still too slow and unstable.
I have thought about that a million times and I am still thinking about removing `pkg` folder, but at the same time I think it makes sense to separate the deliveries `cmd` folder from the application code! So I live in a mix feelings about this :)
I wouldn't say that you can't do it in Go, but I'm pretty sure Monzo specifically used JVM technology to actually interface with other banks, so most of their backend is Go, but not all of it. Can't remember the source right now, was some talk or blog post.
imaxinacion.com | Data Switching | eGovernment | Lagos, Nigeria | OnSite | Full-time We are happy to talk about existing opportunities in Imaxinacion as we build African largest data processing systems in golang.
Apply anyways! Maybe you will find Wellington even more settling :-) 
Hi there, Main thing will probably be the api documentation, versioning and dynamic data struct ‚Äì i.e. same struct with different fields depending on the type. However, I would argue that you should not use dynamic data structs anyway. Good api documentation will probably be the most important things for your customers (from my personal experience).
Well you can write a grpc service and use the JVM as a local gateway that passes on requests. Hopefully very minimal code, rather annoying to keep maintained but could be worse. Anything is doable it's just how bad are the cons, I can't answer. 
Pleas please please don't forget spill the "web" word all over your text when you're talking about web applications. Go is not about web only.
https://monzo.com/blog/2016/09/19/building-a-modern-bank-backend/
Go is used in the payments world. Pros: Fast development time, portability. Cons: Dev pool depth (cost of resources). Interfacing issues are largely irrelevant as people use open formats and uses what they inherited on the backend.
They https://github.com/fritz-payment tried and failed. They removed their main repo which contained the payment logic. It was online a couple of monthssss ago. Code base was not that nice, afair.
Funny seeing this here. I was working on this exact problem earlier today. It's hard to say if Go will be a good fit for you without understanding more about our requirements. Do you deal with multiple currencies? Are you going to support more than one merchant? Is there anyone on your team experienced in go development?
Yes with multiple currencies, lots of merchants. And I didn't get your point on experienced developer. Anyway whatever programming language you use you will hire experienced developer. Put it this way. Say I want to build local payment gateway then if successful open to the world. One of guys talked about Monzo wrote their backend with go. I found that post and read. It was helpful. Your thoughts are welcome also. 
Can you explain the usecase for this? 
Would you elaborate please. Your point caught my eyes.
reptilians confirmed
&gt; &gt; It was online a couple of monthssss ago. &gt; reptilians confirmed That cracked me up! :D
Last night I thought about brushing up on Go and literally googled four "golang project structure best practices". So, yes, yes please!
I sure hope it's a PHP -&gt; Go converter.
me too :-)
&gt; Write secure Golang programs and applications &gt; Write Golang scripts to defend against network-level attacks &gt; Learn to use Golang security packages Somehow I have hard time taking seriously a book that uses the wrong language name. Online articles use the excuse of SEO. What's this book's excuse? At least they got it right in the title. üëç
This is very similar to how Qubes works. I like it! When you launch any app within Qubes, it starts a `transient` copy of the OS template (Debian, Fedora, Arch, etc). Upon shutdown, all changes are wiped. Only things like /home and /var are persisted, or whatever u config to be. This is actually one of Qubes' selling point on security: if you ever suspect you have been compromised, just reboot the VM. Maybe add that security angle to the website and description. :). Because it is one reason I really enjoy Qubes. I also version my /home config directories, to know if anything was changed. I like this Darch concept a lot. Qubes' bootloader is not flexible enough for me to switch to this Darch. However, I do see Darch as the final answer to the dozen or so Rasbperry Pi boards I am setting up especially under remote BOOTP, a few robot projects and maybe even my server and router rebuild.
Go's terrible xml support has stopped me previously. Trying to implement iso20022 made me rage quit and write it in something else.
LiveRamp | Data | NYC | ONSITE | Full-time We're currently hiring mid/senior-level talent in both San Francisco and New York (although most of the Go work takes place in NY). Our team recently open-sourced Gazette, an append-only journal which accepts byte-oriented chunks of data written entirely in Go (https://github.com/LiveRamp/gazette/) Feel free to PM me for details, but also checkout out specific jobs here: https://liveramp.com/careers/engineers/
Go is just a tool, much like Java. However, that's not the primary consideration here. Payments platforms are old and use older standards, like XML. Go is garbage with XML (thankfully, I hate that format with a passion, it definitely got abused). Java is wonderful with XML. How you intend to build your architecture is how you need to solve this question. To help out though, I am a senior engineer for a company that does pretty much exactly this. We collect data from devices in the field and relay payment instructions back to the bank. Everything except the payment engine is written in Go. We run microservices on a Nats messaging bus (wonderful, lightning fast and super easy to use. Cross platform as well). Our Go services build up data for a payment instruction and hand over the instruction to the Java portal. The Java portal posts a SOAP message through to the bank. If the bank could speak JSON, we'd be Go the whole way through. Sadly, Banks are not famed for the agility :/ But we are uniquely positioned to be the JSON portal into the bank :) We just want none of that responsibility. That's a long, unrelated story. In summary: Yes, Go is a suitable platform for payments technologies. It's nowhere near as matured as .net and Java and its ecosystem reflects that, but that's alright because the standard lib is so incredibly powerful and it's easy enough tool to pick up. If you do start looking at Go, then consider that the pool of engineers who understand and can implement a full scale, transactional payment portal is going to be a great deal smaller than on the Java side (another reason they're everywhere is they're super popular). This means they could be more expensive or just outright impossible to hire. 
Keep blogging, it's a good way to learn :)
Your question is actually clever imo, you are identifying that there is a kind of equivalence between the two, which is insightful. Or you are an experienced C programmer =) Another equivalent solution is a struct with a type enum on it, and switch statements in the functions to select the correct behavior for each variant. interfaces probably provide the 'safest' solution in that the compiler will catch more mistakes, other solutions could have better performance characteristics potentially.
You should build outside of docker and use `scratch` container to run your go app in since its a static binary. I don't see any gain to building inside docker and running inside the same build environment. 
You couldn't really do a conversion without copying the properties of legacy PHP, which would negate the advantages of Go.
Why build outside of Docker with multistage builds?
I would love a proper gofmt for PHP. I'm using PHP-CS-Fixer at work, but it doesn't fix indentation, so the legacy files all still look like crap even I format them.
One of the bigger challenges with implementing it in Go will be figuring out how to implement something like their plugin system - my suggestion would be to use some high performance messaging system / GRPC, but that will come with a cost that's higher than just having some code dropped in and executed, although it will also potentially allow people to develop plugins in whatever language they are familiar with.
Because i don't need to ship a large OS with build tools. scratch is for statically linked binaries like go
Sometimes this is not possible. Short example. All dev‚Äôs in my team using macOS. It‚Äôs obvious. But server on Linux (RH). For Go this is not problem at all. For some npm packages, etc. huge pain. Because a lot C/C++ libs, etc. So we using docker based build in this like cases. Even if using cgo you already in trouble.
Well that's what I'm saying, with multistage builds you don't ship the build tools :) https://medium.com/travis-on-docker/multi-stage-docker-builds-for-creating-tiny-go-images-e0e1867efe5a
Glancing at the blog, he uses a alpine container for the end product with no go build tools installed? 
Oh nice I didn't know about as build env
What would you picture that looking like for validation?
Go isn‚Äôt garbage with XML... where‚Äôd you get that idea?
Have a look at this post: https://medium.com/@benbjohnson/standard-package-layout-7cdbc8391fc1
That depends on what you want to validate.
I agree with a lot of your points and summary, but have a few extra thoughts for OP to add onto yours. I don't think XML is "wonderful" with Java, it just has way more abstractions available for common XML backed protocols and schemes. I also think that when hiring talent to build any system you should be looking for.. talent. An experienced engineer with 10+ years experience and multiple languages on his resume is going to easily pick up Go, as long as they seem enthusiastic about doing so. Having a single person on the team with a little experience wouldn't hurt to help get everyone up to speed but isn't really necessary, there are so few contentious things in the Go ecosystem. There will be no 4 hour meetings as a couple nerds debate the best 125mb X for J jar to save them the 8 lines of code to do a Y request because they never have even had to look at the protocols spec before.
Boulder, CO | ONSITE | Software and Quality Engineers | FTE | Fanatics Hi - My name is Dan Snyder, I'm a Sr. Tech Recruiter with Fanatics, Inc in Boulder. The Fanatics Boulder office is a 35-person (and growing!) group of software engineers, quality engineers, product managers, and designers who are creating cutting edge applications and experiences for our customers around the world. We work on a variety of projects with Engineers in our offices from San Francisco to Brazil to the United Kingdom. At Fanatics, we've developed a rich set of tooling utilities and microservices to handle the less-exciting parts of software engineering: from cloud operations, data storage, service registration, user authentication and authorization. As developers, these tools allow us to automate away the "boilerplate" features and enable us focus on the new, creative parts of projects. Leveraging these tools make writing code at work fun and painless. Check out our open positions here to apply or reach out directly to dsnyder@fanatics.com: http://fanaticsinc.com/careers/ -&gt; Open positions in the US -&gt; Select Boulder (or any other location) 
&gt; One of the things that stands out to me is how readable the code base is. Just go check out other C based open source projects and the code is nearly incomprehensible. C is not a good yardstick by comparison. The lack of certain constructs in Go (i.e. generics, exception management, ternary operator) are hurting readability. Consider this Go code for example. Can you *quickly* tell what it does? package main import ( "bufio" "flag" "fmt" "log" "os" ) func main() { flag.Parse() flags := flag.Args() var text string var scanner *bufio.Scanner var err error if len(flags) &gt; 0 { file, err := os.Open(flags[0]) if err != nil { log.Fatal(err) } scanner = bufio.NewScanner(file) } else { scanner = bufio.NewScanner(os.Stdin) } for scanner.Scan() { text += scanner.Text() } err = scanner.Err() if err != nil { log.Fatal(err) } fmt.Println(text) } Now the *exactly same* process in D language, a language designed to overcome faults in C++ import std.stdio, std.array, std.conv; void main(string[] args) { try { auto source = args.length &gt; 1 ? File(args[1], "r") : stdin; auto text = source.byLine.join.to!(string); writeln(text); } catch (Exception ex) { writeln(ex.msg); } } Exception management makes all the difference! Same code in Lisp (defun print-file (stream) (loop for line = (read-line stream nil) while line do (princ line))) (defun main () (handler-case (if (&gt; (length *posix-argv*) 1) (progn (with-open-file (str (second *posix-argv*)) (print-file str))) (print-file *standard-input*)) (error (e) (format t "Exception caught: ~a~%" e)))) 
sounds like you want us to write your thesis. 
That is not my intention. I am currently writing the thesis but I am also looking for some input form experienced gophers since I have not much practical go programming experience myself. It is still me who is writing the thesis but there is a fair chance I am missing some important points, that is why I asked for help.
I don't know if you are aware if this, but Go's concurrency model is based on [Tony Hoare's Communicating Sequential Processes (CSP)](http://www.usingcsp.com/). This page links to a PDF with his paper.
Thank you for sharing. The codebase looks logical and well organized and is a great learning resource. I'm glad you went with small libs like httprouter instead of some full-featured framework like buffalo/revel/iris/beego. Personally, since this project is just an API it is able to assume all errors can be retuned as JSON objects. I'm trying to figure out how a [mixed app handles error responses](https://www.reddit.com/r/golang/comments/7umarx/http_input_validation/). For example, a site that both serves HTML templates and JSON responses. How do you structure middleware to optionally load templates or JSON depending on what response format the client should get back for validation, internal, or auth errors. 
I think it's good to compare against java, elixir.
https://hasura.io/hub/go-frameworks [The horror...](https://i.imgur.com/ZuMnCWk.png)
Thank you, I was aware that it was based on CSP but I still have to read the Paper.
Maybe this will help? https://youtu.be/cN_DpYBzKso https://youtu.be/f6kdp27TYZs https://youtu.be/7VcArS4Wpqk I think though part of it is that this story of simplicity isn't done yet. It's not so much that go is better but that from a developer standpoint it can be better in some situations. Meaning that the design of the language was specific. Which some might say is bad but in reality it comes down to engineering for modules of languages instead of a heavy load on the developer to weild a Swiss army knife language. If for instance you see js now getting wait groups and this whole wasm thing trying to de-engineer go's concurrency model without the great type system or c# trying to muck their way with talking points through getting the same model as well, you start to see what Rob was explaining. That for whatever reason those languages had a certain philosophy and when a new paradigm comes along, they simply copy paste. Which those fundamentalist to those languages love but don't understand that when picking up the language, this new copy paste paradigm that's been inserted into their philosophy sticks out like a sore thumb. It's not so much that things are so novel in go, but that the philosophy is. This is why it's important to do things with not only a very specific purpose but also the years of experience and forsight to midigate these engineering design is possible. Or so that's my view on it but I think talking to actual language engineers will produce you better results instead of a random person on Reddit.
I was thinking about comparing it to C# simply because it is one primary programming languages.
I will definitely watch these. I see your point, I felt the same way since I first started learning Go.
This paper is a must read before discussing anything procs/cons of concurrency/parallelism systems: https://www.usenix.org/system/files/conference/hotos15/hotos15-paper-mcsherry.pdf 
Your points look great, now research them to form your own premises and conclusions. We will gladly give you feedback after *you* have gone through deductive reasoning on your questions here.
My guess is because there are several [XML issues](https://github.com/golang/go/issues/13400) are that are yet to be fixed. This makes it hard to work with SOAP and other ~~garbage~~ stuff like that. cc /u/lhxtx
Thank you I didn't know that one yet:)
Looks like Go has a few name spacing issues? Every time I‚Äôve used XML it‚Äôs been roughly the same as JSON. FUD. 
Go is good at multithreading and asyncio, but I don't think it does much if any SIMD yet. (So for example, if you want fast image resizing, you'll probably end up wanting to use Cgo.) That could be an area to explore.
Cogo Labs | Startup Incubator/Marketing | Cambridge, MA | ONSITE | VISA | cogolabs.com Hi folks! My name is Casey and I work at Cogo Labs in Cambridge, MA. Cogo Labs provides the companies we incubate with access to a centralized tech platform that they can use to bootstrap their busines\ ses. We are looking for a Software Engineer who can help us further develop this platform, making it the best possible toolchain for running marketing campaigns and launching new websites. You‚Äôll collabo\ rate with and learn from experienced engineers while making contributions that directly impact the success and profitability of teams and companies that we‚Äôre building. The majority of our core systems have evolved into highly concurrent Golang services and we're looking for folks who'd love to jump in and contribute. We're looking for junior to mid-level engineers for\ this role. Please apply directy at https://www.cogolabs.com/careers/d9dc945b-4ba0-4f34-9538-79d6eacf6ffa and mention this Reddit thread. Feel free to reach out with any questions!
[500k+ LOC Wordpress](https://www.openhub.net/p/wordpress/analyses/latest/languages_summary) -&gt; Go and the nightmare intensifies
&gt; keep consistency Why need it be consistent? Couldn't you just add a slightly random delay to every response? 
Erlang/Elixir have message passing and soft threads. Certainly worth comparing with Go. C# is a lot more traditional for comparison though 
That's a good comparison aswell instead of java. I would try to include OTP and elixir/erlang because it's also build on the concept of CSP, only way different than how go does it. 
Open the issues and read the discussions. You'll see that people have problems working with certain XML protocols and schemas. [This comment](https://www.reddit.com/r/golang/comments/7vdhv9/is_go_suitable_for_building_payment_gateway/dtro2ek/) also reports problems. Maybe you could ask for details.
Publishers want their book subtitle to have SEO keyword. 
Any chance there will be video of the talk available?
 &gt; Publisher's want their book subtitle to have SEO keyword. Is the text of the back cover included? &gt; Write secure Golang programs and applications &gt; &gt; Write Golang scripts to defend against network-level attacks &gt; &gt; Learn to use Golang security packages Because all these are from the back cover.
Don't know what you tell you. If it bothers you that much, don't open the book and look at the content.
I would like too see a graph of memory usage vs number of parallel executed processes of various programming environments. Also the cost/overhead of context switching between these processes would interest me.
Something simple like this would work: func myHandler(w http.ResponseWriter, r *http.Request) { if !IsIntegerBetween(r.Form.Get("foo"), 0, 10) { w.WriteHeader(400) w.Write([]byte("foo must be an integer between 0 and 10")) } w.Write([]byte("OK")) } func IsIntegerBetween(s string, min, max int) bool { n, err := strconv.Atoi(r.Form.Get("foo")) if err != nil { return false } else if n &lt; min || n &gt; max { return false } return true } 
Canonical | Software Engineer | Full Time | REMOTE Canonical is the company behind Ubuntu Linux. We are a globally distributed team passionate about open source. We're looking for golang developers to join our juju engineering team. Juju is a modeling and software orchestration tool that is capable of deploying to clouds, containers or bare metal. Apply to one or both of the two open positions: http://grnh.se/equgf11 For this role, we're looking for someone with python skills as well. http://grnh.se/kjgdex1 If you know golang, love open source, and want to work remotely with a bunch of other folks around the world, get in touch!
Sure would be interesting but probably a whole new topic for a separate theses. I am not sure if I want to go too much into that direction, I am trying to focus on a detailed comparison of go vs classical and not add to many extra languages. English isn't my first language either.
Love it. Thanks for writing this up!
I am planning on benchmarking both a CPU bound task (a mandelbrot set) and an IO bound task (http static file server) in both go and C# and compare the results. Not really sure how detailed results about context switches/overhead I will get from that but I saw a youtube video about the go tracer witch might help me out a lot.
FOSDEM recorded all devrooms. Videos are being released as they're processed: https://review.video.fosdem.org/overview
Haven't encountered such an issue till now. Most of our production images are running on Alpine. But, will investigate more and try to add a complete alpine based setup.
examples of usage: - static code analysis - finding code duplications - finding code violations and bugs - ast based code search - ast based code diff - building class implementation graph with code flow grap - building function/methods call graph with prettyprinter - ast based code changes - php5 to php7 or another language converter - code style fixer
1. My initial experiences with dep was not that great, but got hooked on to glide instantly 2. Exactly, glide.yaml and lock are added in a separate layer forcing docker to cache. 3. The idea behind using debian was to create an environment most familiar to the developer since they might have to install additional tools, dependencies etc. 4. Will add those flags. Thanks for suggesting improvements.
Haha! http://americanhorrorstory.wikia.com/wiki/Iris
Thanks :)
It's just a link to this youtube video. Saved you a click: https://www.youtube.com/watch?v=Lonxfp6RM8c 
Like the reasons mentioned in the post, containerization is a necessity when using platforms like Kubernetes. Our own CI system at [Hasura](https://hasura.io) makes use of [Buildbot](https://buildbot.net/) running as docker containers to build Hasura CLI, spinning up only when they are required.
No idea why garbage is crossed out here.
hahaha!
Image is built using debian and run in alpine.
&gt; I can think of 3 different types of validation The way you've coded your example, Apply() has to unmarshal the payload, validate parameters, and apply the parameters to the domain object. That's three different responsibilities that might better be packed in at least two different packages: one for the domain object, one for the event object. Where the separation of responsibilities really helps, is when you need to make a change to an event; the code that marshals / unmarshals that event's payload is a bit scattered right now. Probably not the point of your blog, but I'm a bit mystifed about your error handling at the end of Apply()... // domain object validation: check the internal consistency // of `u` after the change return validateUser(u) If your domain object isn't internally consistent, there's no code to roll back the event, and the object might forever remain inconsistent. What good is validation when all it does is alert you after a mess has been made?
Thanks!
ohaiya, I appreciate the incredibly valuable input! I'm always looking to improve upon these tutorials so I will try to expand more upon certain things in my upcoming tutorials! Again, thank you so much for your input!
&gt; Every time I‚Äôve used XML it‚Äôs been roughly the same as JSON. And that is the problem. You can easily reflect any JSON in XML almost directly. And you need to introduce meta-junk in JSON (like JSON schema) to transform random valid XML into JSON. Something like (and I am not even diving into namespace crap): &lt;a attr="12"&gt;b&lt;/a&gt; will be represented as { "node": "a", "attrs": { "b": "12", }, "value": "b" }
I am don`t know how to write php -&gt; golang transpiler, anybody else can use the library to try writing it.
Thanks.
I am planning to write PhpDocComment parser, it allows get more information about variables types, but it's still not enough.
[removed]
&gt; I have not much practical go programming experience myself. Isn't that supposed to be part of your research, to develop your experience?
IMO XML with Go situation is unlikely to improve until some enterprisey company like IBM/SAP/Oracle etc work on that. Google does not deal with SOAP/Wsdl etc so they don't care about that. And companies who deal with that do not care about Go. So extensive XML support is kind of stuck.
The problem is that you end up writing the same code over-and-over for many handlers. func commentUpdateHandler(w http.ResponseWriter, r *http.Request) { if !IsInteger(r.Form.Get("id")) { w.WriteHeader(400) w.Write([]byte("Invalid ID")) } ... } func postUpdateHandler2(w http.ResponseWriter, r *http.Request) { if !IsInteger(r.Form.Get("id")) { w.WriteHeader(400) w.Write([]byte("Invalid ID")) } ... } func userUpdateHandler(w http.ResponseWriter, r *http.Request) { if !IsInteger(r.Form.Get("id")) { w.WriteHeader(400) w.Write([]byte("Invalid ID")) } ... }
[removed]
What I am saying is that go is not my primary programming language and I have never written commercial code nor worked on a bigger project. I have already written some programs (mostly REST services) for smaller projects.
[removed]
&gt; useful for computing the state Your blog is missing quite a lot of context, so I can't tell that this is useful. Is it the case that you're going to compute state every single time you need to access the object? That doesn't seem like a scalable design.
No there isn't. Either implement something on your free time in Go to impress your boss or find work somewhere else. There is also the safest and longer road. Keep working there till you are considered senior enough to call some shots. Then write some small service in Go to introduce it in your codebase.
Other responses here either described the implementation differences and similarities between interfaces and struct-with-function-pointers or they argued for the virtues of interfaces rather than function pointers. I wanted to offer one possible justification for a struct with function pointers: if you need to mix function pointers with other fields and you know that all instances will have the same internal layout. Consider for example the [Resource](https://godoc.org/github.com/hashicorp/terraform/helper/schema#Resource) type in Terraform's provider framework. This class signifies a *type of resource* rather than the resource itself, and all resource types are instances of this same struct. They each describe their unique features with a mixture of data fields and function pointers. Notice in particular that the various functions *don't* get access to a receiver pointer as a struct method would. This is okay for Terraform because as previously noted these are representations of *types* rather than *instances*, and Terraform passes in details about the instance itself as an argument to each function as a funny sort of "receiver" with an application-specific API. To fully emulate the normal behavior of struct methods -- primarily, to give them access to shared state -- it would be necessary to employ some very un-idiomatic patterns such as accessing state via closures: func NewThing() *Thing { // NON-IDIOMATIC! var thing *Thing thing = &amp;Thing{ Val: 0, Inc: func (amount int) { thing.Val += amount }, Dec: func (amount int) { thing.Val -= amount }, } return thing } To be very clear, I offer these **not** as patterns to follow indiscriminately, but rather to highlight some practical differences between an interface type and a struct type that contains function pointers. There *are* legitimate reasons for doing all of these things in certain cases, but I would always *default* to using interfaces, both because it's idiomatic (easier to follow for future maintainers) and for the practical reasons discussed by others in this thread. 
[removed]
Congrats on your new blog! 
but does it generate static blogs
Concurrency in Go is an excellent book To get a broader view on concurrency, I'd recommend "Seven Concurrency Models in Seven Weeks" by Paul Butcher. And two summaries of papers around Go's concurrency model by "The Morning Paper": https://blog.acolyer.org/2018/01/25/a-static-verification-framework-for-message-passing-in-go-using-behavioural-types/ https://blog.acolyer.org/2017/02/02/fencing-off-go-liveness-and-safety-for-channel-based-programming/
I am going to compute the state every time I run a command (create-update-delete), yes. I rely on a projection of the state on the query side (read), because I need it WAY more often in my application. As for the lack of context: I should probably post something on ES/CQRS as I see it.
Writing a thesis involves research, and research involves asking. Asking and reading and thinking and writing. Rinse and repeat.
Admittedly I'm biased, but how common are RoR developers? I only know of maybe two people who write in Ruby.
Hugo's purpose is still the generation of static websites
Create a struct that embeds or contains other structs. A very basic proof of concept: https://play.golang.org/p/dbyok0SqT_j
Thank you! :)
Looking a the sample images, I wonder if the algorithm used by [esimov/caire](https://github.com/esimov/caire) could improve the results in some of the cases. (TL;DR: muesli/smartcrop searches for the most interesting part of the picture and crops the picture to that part, whereas esimov/caire identifies the boring parts that can be safely cut away. This way, two or more interesting parts can survive the shrinking process, they simply move closer together.)
I believe they did not remove that functionality... yet.
There's not really a great way to answer that question, but this does give a bit of insight. https://insights.stackoverflow.com/trends?utm_source=so-owned&amp;utm_medium=blog&amp;utm_campaign=trends&amp;utm_content=blog-link&amp;tags=ruby-on-rails%2Cgo%2Cjavascript
After talking with more people I decided to remove `pkg` folder! Thanks a lot for your feedback! 
Not to mention the video size it tiny on my screen even in full.
I personally consider Go kit (https://gokit.io, https://github.com/go-kit/kit) to be a rough Go-idiomatic analog to Spring.
This a a very good statement! Thanks. 
&gt; I should probably post something I'm just talking more fundamentally... when I read: &gt; Let's keep the architecture as simple as it can be: a Go service responds to the external call and directly operates on the events. I'm asking "what go service, what external call, why?" There's not even a basic context for much of this post.
I am thinking about writing a post about how I structured the project but basically it's inspired in Ben Johnson post as @FourSigma mentioned! Here is another blog post: https://peter.bourgon.org/go-best-practices-2016/#repository-structure
Calling back and forth would make it slow. How about making one call to build the whole DOM and return the root of DOM back to Go. SAX is going to be bad since you have to call the user defined function for every element.
For those who don't get it: http://knowyourmeme.com/memes/expanding-brain
I didn't do the tour of go, but it was the easiest language to learn I've ever come across. Scope is small, everything was intuitive to me. Except slices and how you work with them. Incompatible with my brain. I'll get used to it eventually I'm sure. 
What do you mean? No one ‚Äúhad a bad time‚Äù before posix AIO support for net was pulled in. If you are thinking all system calls cause a new thread to be created that is incorrect, you should read the [HACKING.md](https://golang.org/src/runtime/HACKING.md) file in the Go runtime folder for clarification.
Oh God, please no! If you want spring in go then you didn't understand go. Experience says me that there no way to change java developers mind that there's smth other than spring.
You should definitely use Dep instead of anything else including Glide :)
Yeah some people use Alpine instead of scratch for the end containers so they can remote into the container
If this is your video you should consider doing a video using CockroachDB :D
You can do that with json.Unmarshall. You can umarshall it into a map and then play around with it depending what you need. This can be helpful for you: https://stackoverflow.com/questions/33436730/unmarshal-json-with-unknown-fields Another solution is to have two structs as two possible json data that you recieve and go like 1. Unmarshal to first struct, if you get an error that it doesn't match then do 2.Unmarshal to second struct Don't forget to handle other options such as when it doesn't match any struct. Depending on what you want to achieve you can umarshal it into a map or just return that it is a bad format etc. 
There is also https://crystal-lang.org/ - familiar syntax in a modern compiled language. - unless someone wants to migrate completely away from Ruby and the likes.
I just read on here the other day about Gitlab hiring go devs, so I checked out their job descriptions and they all require years of RoR production experience. Your question is exactly what I wondered then
I would recommend using this: https://github.com/jinzhu/gorm
Have you seen the AdWords API? It‚Äôs all soap..
Yeah I meant that, but that should also include delay added to the keystrokes typed in shell and being echoed back to the client terminal(Or intruder would spot there‚Äôs a difference). Adding a wrapper around the Readwriter spawned from ssh seems neater.
And 6+ languages! Whew...
If you have a C background, it may help to think of `var s []T` as nothing but a structure hidden from you by the compiler: https://golang.org/pkg/reflect/#SliceHeader When you're passing the slice somewhere (`foo(s)`) or assigning it (`x := s`), you're copying that struct (but the the things the `Data` field points to). When you're accessing the array pointed to by the slice (`x[3] = y`), you're just using `SliceHeader.Data` as a pointer, with an offset.
I don't read hacker news, nor do I regular many programming subreddits. I was referring to personal experience. The only person I actually know who spent any serious time in Ruby [is this person](http://contributors.rubyonrails.org/contributors/nicholas-seckar/commits).
Ah, missed that. I personally am a fan of [Gin](https://github.com/gin-gonic/gin)
Neat, but [X11 is obsolete](https://en.wikipedia.org/wiki/Wayland_(display_server_protocol\)). It should support Wayland.
my troubles are more mundane than that. I understand what a slice is an how it is implemented. It is the [a:b] syntax that is just unnatural to me. So basic operations like dropping the first N values, extending the length, removing a value, I have stare and think inordinately long. I think inevitable that providing something like a Span&lt;T&gt; without having generics in the language is going to result in something a bit different, that one will have to get used to. 
Well, that depends on the other side. For example, if a bank is offering a Java based API to interface with them.
For leetcode in Go, are you supposed to solve with or without standard library packages?
Why MySQL? Postgesql FTW. ;)
One of the advantages of Go is that for the most part, you won't require large and messy third party frameworks like spring that has a substantial learning curve of its own, has its own issues and quirks to deal with and tend to unnecessarily bloat up the application.
&gt; It is the [a:b] syntax that is just unnatural to me. Simply think of the indexes as sitting *between* the elements: {a,b,c,d} ^ ^ ^ ^ ^ 0 1 2 3 4 and an operation like s[1:3] then quite naturally maps to `{b, c}`.
I don't quite know about integer in NodeJS, but if you use int instead of big.Int in Golang, you must calculate Fibonacci wrong, and not a real benchmark, as int in Golang will overflow.
&gt; The thing is I want to get data from third-party company. Which third party company?
What I don't really like about caire is the artifacts. Zoom in on a picture and you will see sawtooth artifacts in a lot of places, such as clouds. 
[removed]
You just import whatever you need, but afaik only stdlib works.
Maybe something like [this](https://play.golang.org/p/rr9S8l4bH7_8)?
Maybe something like [this](https://play.golang.org/p/rr9S8l4bH7_8)?
This is some really nice and clean go code. Thanks for sharing. :)
Fx is a lightweight DI library similar to Dropwizard. 
Doesn't bazel solve the monorepo problem?
Consider the following applications that were written in RoR, some still are: - Github - Gitlab - Twitter - SoundCloud - Shopify - AirBnb
Oh I didn't want to go that far down the list, then we get into my company territory.
There are very rare reasons not to use dep today (e.g. when you build tools for kubernetes you're still bound to glide). Go binaries in general are not truly static. They do dynamically load libc and here's the problem: Most distros use glibc, while minimalistic distros like alpine/busybox use different libraries like musl. Running Go apps on musl can fail surprisingly and the race detector _requires_ glibc. You definitely should run your production code with the race detector, preferably as a canary, at least in integration tests. That alone rules out alpine as the default distro for Go containers for me. If you use multistage docker builds, you could derive the final artifact using debian:stretch-slim which weights only 55 MiB. 
Thanks for this
I asked because it sounded like you were considering writing a payment gateway as your first foray into Go. Doesn't sound like that's the case. Expect every merchant to have its own set of quirks. Documentation accuracy and completeness tends to vary widely between merchants. Consider this a long-term commitment.
Main reason for not using dep: https://github.com/golang/dep/issues/286
Yes, it does. We attempted to use bazel first but it was too complicated for us. Since almost all of our services are already using CircleCI and makefiles, this way was the quickest as we only have to move all other repos to a single one and did the script plumbing quickly. This has been working for us so far.
Well, it is but XWayland (X on Wayland) will be around for some time yet for supporting X11-only applications. Like OP says, it's not easy to develop for Wayland yet with Go.
Even glide devs recommend using dep.
[removed]
Benefit is that every developer can built it anywhere or even locally without any access to Jenkins, AWS or any other external service.
This is cool, thanks for sharing!
Are you planning to improve the decode/scale performance? It looks noticeably slower than viewers that use libjpeg.
A co-worker recently took a stab at writing some soap stuff in Go and in that case it happened to not run into any of the namespace issues in the go library. I don't know if there are third-party libraries that can work around namespace issues, but in this case the Go solution was faster than generating soap endpoints in C# and certainly much simpler.
Wait, am I missing something here? Are they changing the way Hugo works or something to remove the stuff that makes it simple to create a static blog? 
To add to what was already said- the biggest thing ensuring X11 isn't going anywhere anytime soon is that the next ubuntu LTS will be using X11 by default.
This was as clean and straight to the code of a tutorial as someone could get! Look forward to seeing more
&gt; Consider this Go code for example. Can you quickly tell what it does? (Copy-pasted from the web) You can write bad code in any language. Here is the same Go code written in a [more idiomatic way](https://golang.org/doc/effective_go.html#if). package main import ( "bufio" "fmt" "io" "log" "os" ) func main() { var source io.Reader = os.Stdin var err error if len(os.Args) &gt; 1 { source, err = os.Open(os.Args[1]) if err != nil { log.Fatal(err) } } scanner := bufio.NewScanner(source) for scanner.Scan() { fmt.Println(scanner.Text()) } if err := scanner.Err(); err != nil { fmt.Fprintln(os.Stderr, "reading input:", err) } } It is now much easier to tell what is going on. &gt; The lack of certain constructs in Go (i.e. exception management, ternary operator) are hurting readability. Those could have been added easily to Go, but for some reason, they choose not to add it. The error handling is certainly debatable but I highly disagree that ternary operators make code more readable. Sure in the simplest of cases they might help somewhat but [Go is designed for large scale programming](https://talks.golang.org/2012/splash.article). On such a scale the feature is going to be abused sooner or later: Bool c1, c2, c3; int x = c1?c2?1:2:c3?3:4; 
&gt; Stripe I thought Stripe [used their own framework](https://www.youtube.com/watch?v=vVFEROmdCkQ)?
Thanks, I was looking for exactly this. Seems unnecessary to ship a full POSIX environment just to launch a single static binary.
Probably didn't mean for the example to save both keys as "private"
I tried to replace image/jpeg with [golibjpegturbo](https://github.com/antonini/golibjpegturbo) but it didn't help, still much slower then similar C programs. Probably scale is to blame but I will need to check that, there is a great [resize speedtest](https://github.com/fawick/speedtest-resize). I guess support for C libs bindings can be added via some build tag, just to add goiv_image_cgo.go for example, only a couple of simple functions are there.
Yes, but what I mean is what does the middleware or routing engine look like for this? Doing the actual check is the easy part.
That link was the basis for my dev work on https://github.com/Xeoncross/mid Ultimately, you still have to duplicate lots of code with either of the two approaches you show when you have lots of different params coming from the URL, Query String, and POST params. It gets ugly quick func postUpdateHandler(w http.ResponseWriter, r *http.Request) { checkID(w, r, 2, 30) checkIsArray(w, r, "options") checkIsBoolean(w, r, "active") checkValidUser(w, r, "user_id") etc... } 
Nowadays, saying "Linux" does not sufficiently identify how the system is working to be able to answer this question, unfortunately. The best way to set up a resilient system on systemd, upstartd, and with old init scripts all differ now. You should specify more thoroughly what Linux you're using and somebody can probably help you better at that point. In general, I'd point out there's nothing particularly special about Go scripts other than their general difficulty in self-daemonizing, which all supervision techniques will be able to deal with anyhow, so rather than looking up "How do I run this Go program safely?", which will have a lot of unrelated stuff almost no matter how you tune that search, you'll be better off searching for something like "supervising Linux server processes" or something like that. There's a crap ton of options, and, again, which is best depends on what your Linux system already has.
You can use [Systemd](https://fabianlee.org/2017/05/21/golang-running-a-go-binary-as-a-systemd-service-on-ubuntu-16-04/).
Of the couple of major distributions that jumped on the Wayland train, Ubuntu (probably the most widely adopted desktop distribution?) is seemingly looking for a way off again, because it really isn't production ready. "Obsolete" is more wishful thinking from your side than anything. It's at best "obsolete" in the sense that a terminal is.
&gt; then runs the site (go run main.go, handler.go, etc.). You might want to compile your program (using `go build`), so you don't need the entire development environment on your server. The resulting binary can just be started with `./main` of course. Afterwards you can use systemd to reliably start (or restart) your binary, as [shovelpost mentioned](https://www.reddit.com/r/golang/comments/7vnus3/question_about_serving_a_golang_web_application/dttoa1w/).
&gt; Ultimately, you still have to duplicate lots of code with either of the two approaches you show when you have lots of different params coming from the URL, Query String, and POST params. It gets ugly quick. Usually, you receive the body as JSON which allows for centralized validation on the model of the struct. If you are trying to cover as many different cases as possible with a single mechanism then you are looking for an abstraction which is not easy to do without magic.
Go is the "Go programming language", not _"Google's_ Go programming language". Oh, well...
‚Ä¶and the whole point of the post appears to be citing the 1.10 release notes almost 1:1.
Some things in particular I'd love feedback on: - [interruptHandler()](https://github.com/itsdalmo/ssm-sh/blob/split_and_test/cmd/utils.go#L13-L38): Imagine there has to be a better way to listen for interrupts and gracefully shut down go routines. - Related to the above: Passing done (interrupt) channels between the CLI, [Output()](https://github.com/itsdalmo/ssm-sh/blob/split_and_test/manager/manager.go#L145), [GetOutput()](https://github.com/itsdalmo/ssm-sh/blob/split_and_test/manager/manager.go#L164) and [pollInstanceOutput()](https://github.com/itsdalmo/ssm-sh/blob/split_and_test/manager/manager.go#L210). - I'm probably using too many goroutines? (Ref last point). - Tests seem a great bit wonky as well. - Function names... too repetitive(?).
Also posted here: https://www.reddit.com/r/learngolang/comments/7vo07o/trying_to_learn_go_by_making_a_aws_ssm_runcommand/ Let me know if I should delete one or the other.
Thanks for the response. I'm running Ubunutu 16.04. As others have mentioned Systemd seems like a good alternative. 
Downvoted. Reason: You might as well put a link to the release notes instead of copying over stuff from there.
Thank you for this. Seems like a great solution. I will check it out when I get home from work.
Agreed, consensus seems that go run is not for production. I'm looking into systemd later today. Thanks!
Why downvoting this post? The dude is asking the community to show him the way. If you are on average the anti framework type, well, provide an answer with your alternatives. Do not downvote simply because you see the word framework. The Go community has a long way to grow up.
I'd say Rust because: - it catches/prevents many of the stupid errors that I make frequently - forces error handling more strictly than Go (though I like Go's error handling better than exceptions in other languages) - convenient for functional-style programming (esp. the "everything is an expression" part) - generics/traits - nice lambda/closure syntax - scales pretty well in terms of abstractions, Go isn't quite as nice IMO - tests can live next to the code (same file even) - nice tooling (rustup, cargo, rustfmt, clippy, etc) Some things I like better about Go (esp. goroutines, channels and select), but at the end of the day, I feel more confident once my code compiles than Go and I feel more confident pushing my code to production. Also, we have quite a few novice programmers at my company, and I wish we could switch to Rust because it would prevent a lot of the errors we've run into from programmers unfamiliar with the intracacies of concurrent programming. It definitely has a higher barrier to entry, but you get a really nice compiler that helps detect problems before they become serious. Here's a short story, if you're interested. We used Go from the get-go to build a product. We loved goroutines, and we used them extensively. We were deploying to a single core device, so we didn't notice that Go, by default, was single threaded. When Go 1.5 was released, the default switched to the number of CPUs your machine had, and our development had all kinds of panics from race conditions we didn't know we had. We then realized that maps weren't safe for concurrency, so we had to throw in all kinds of mutexes to make our code safe, which took quite a bit of time and slowed our code down a bit. We've since rearchitected some bits of our code to be more concurrency safe and we actually use far fewer goroutines now. So yes, we made a mistake, but nothing gave us any warnings until about 2 years after we started building our product. It took us far less time to fix than the memory problems in Node.js, but it still took a lot of time. The tooling has gotten a lot better (e.g. race detector), but it's still far less convenient than Rust's static analysis that would've caught such problems before we even compiled. So, TL;DR, my favorite language is Rust because it saves debugging time while giving me nice features to build large applications with. I use it for all of my personal projects now, but I still use Go at my dayjob because we have far too much inertia and the ecosystem isn't there yet for high performance I/O.
I have a general question... I have done a little go, but used `julienschmidt/http-router` over `gorilla/mux` (recommended by some more experienced go developers I was working with, but don't recall the reason). What's your opinion on `gorilla/mux` and why is it a better choice?
Have you dropped a link to this over in one of the slack channels?
[removed]
Looks like it wasn't that urgent ¬Ø\_(„ÉÑ)_/¬Ø
You dropped this \ *** ^^To ^^prevent ^^any ^^more ^^lost ^^limbs ^^throughout ^^Reddit, ^^correctly ^^escape ^^the ^^arms ^^and ^^shoulders ^^by ^^typing ^^the ^^shrug ^^as ^^`¬Ø\\\_(„ÉÑ)_/¬Ø`
Sorry for the confusion. I recognize systemd is a service management system. I meant alternative as in a different deployment process than what I described in my original post. 
So that's where my right radius went...
Synthace | BioTech | London, UK | ONSITE | VISA | Full-time Synthace is a technology pioneer in the field of Synthetic Biology. We were the only UK company named by the World Economic Forum as one of the world‚Äôs 30 Technology Pioneers. Synthace is re-imagining how we work with biology by developing a high level language and operating system for the physical world called Antha (in Go), which is already shifting how scientists work in major pharmaceutical, agricultural, and chemical production companies. We're looking for 2 backend engineers (one more DevOps) (PERM AND ONSITE) to continue developing and scaling our products and infrastructure. The stack includes Kubernetes Federation, Go, Google Cloud, Docker, and Ansible You can find out more and apply directly here: Software Engineer: http://careers.synthace.com/o/software-engineer Software Engineer - Infrastructure: http://careers.synthace.com/o/software-engineer-infrastructure 
I really hope they bring in generics...
We use the ELK stack and Datadog in production for monitoring. You can hookup Datadog to things like Pager Duty, Slack etc to give you near real-time alerts. I recently came across https://micrometer.io which looks promising but haven't actually used so can't give any opinions on it yet!
I've starred [Godap](https://github.com/bradleypeabody/godap) for that sort of thing, but I have not tried using it.
HTML, CSS and XML don't count.
[removed]
I didn't look at what they counted, but certainly I'd agree.
ELK is great. Takes a little bit to fully get it integrated (e.g. using logging in your code and having it centralized to elk). But it works great and the Kabana UI integrates nicely in your own UI if you need it to, and gives you insane levels of looking at logging data.
Anything that gives that authentic $1/month VPS feel. The kind of box that takes 15s to load your dotfiles.
I've never needed to use $__interval in Grafana. Can you say or link to more information?
micrometer.io &gt; instrument your JVM-based application code
Missed that this post was under golang sub!üòÖ
&gt; running a code formatter on legacy code that bitter sweet feel of no version control (mostly bitter)
Thanks! What I like about Spring is it‚Äôs easy implementation of Eureka and Hystics.
Is there a reason you didn't take your YAML and essentially convert it to terraform to get some of the benefits like managing infra state? I imagine isn't a ton of fun, but in terms of feature parity with cloudformation, terraform is pretty similar. That said, I totally understand not wanting to take on that complexity as terraform is pretty rich tool that takes quite a bit of dedication vs. just using a library (godo). I'm excited to see where you take it!
That would make sense. Never done any python! 
It also misses some error checks, and the places it does error check, it does so without adding context and with just `os.Exit(1)`. Not a good idea to do that from a library.
Ugh, so bitter. These people were programming _in 2016_ without version control. I know Git is a pain to learn, but **2016**.
The issue is related to these two Github issues: * https://github.com/prometheus/prometheus/issues/2364 * https://github.com/grafana/grafana/issues/9705#issuecomment-351845061 Essentially, because Grafana allows you set the _minimum_ step size that it will use, sometimes it changes to something that doesn't make much sense given the data in Prometheus. If you refresh a graph sometimes you can end up with vastly different looking graphs as certain data points end up in different "buckets" in the graph. You can end up opening the same graph on 2 different browser windows and having them look completely different if you don't get the queries right. Here's an example video I made when I encountered the issue: https://gfycat.com/lamecautiousliger
I added a counterexample in a comment.
You should have a logging standard, something like json logs with the same fields ( same timestamp format ect ... ) across all your app.
u do logging or monitoring with ELK? these are different things. For example, do you monitor the hardware, service availability, etc with ELK? 
Honestly, I've not really looked into too many routers. I've used `gorilla/mux` (and `gorilla/pat`) for a while because they were very popular at the time, and still seem to be (and are still definitely actively maintained too!) If `julienschmidt/http-router` works for you, then go ahead and continue using it. I can see by default it recommends not using the standard `http.Handler` interface (but does have adaptors for that type), whereas the Gorilla Toolkit routers stick to the standard library methods and find alternative ways to pass in route parameters to the handler code. The only times I'd consider looking for something new would be if I needed something lightning fast, and I'd found one of the Gorilla routers to be a bottleneck, or if the Gorilla Toolkit was abandoned for some reason, or if something provided a better developer experience and it was worth switching. Maybe I'll do some more research about it and get back to you. But really, it's not a big deal IMO.
Oh, interesting. I don't really see anything wrong with that but I can understand how some people might. Thanks for the links!
Frankly, I would not have seen these artifacts for what they are, if you didn't tell me about them. Yes, it's not optimal but I could live with that.
Slack channels?
I'm glad you liked it! Looking forward to making more in the future!
&gt; For example, MySQL's wait_timeout setting will automatically close any connections that haven't been used for 8 hours (by default). When this happens sql.DB handles it gracefully. I think there are still some problems with this. See for example this thread: https://github.com/go-sql-driver/mysql/issues/257#issuecomment-53886663 Some aspects are solved, but still not all. A lot of people have their own work-around for this. Me too ;-) 
That is a good point. We do logging.. but, and this is probably not the best use of this.. we could log monitoring data and get that in Elk as well. I would suspect a specific monitoring option might be better suited, but you could do logging of monitoring data possibly which would put it all in one place.
Please don't add a big dependency like imagick. It defeats the point of a pure Go image viewer. Not trying to be snarky or dismissive, just trying to have the cake and eat it. Have you profiled where time is spent? How about doing nothing where you would render to X and compare that? Like rendering to `/dev/null`.
https://blog.gopheracademy.com/gophers-slack-community/ 
I meant to make the X code path a nop operation and then profile everything but displaying the image. In that mode you can profile everything but X and see where time is spent. If in that case using C bindings doesn't make a difference, it's probably X rendering.
Can you summarize the key differences between these two examples, as you see them? As-is, it's a little difficult to parse out what you want us to comment on.
Surely! In the top example the declarations are happening globally within the package. Then, to access the methods one would need to call `Execute()`, returning the locally scoped package `state` and executing the method you want against that. Since everything is locally scoped, all of this appears to be allocated on the stack (checked the compiler). The bottom example shows a dependency injection model, where main would handle instantiating all of the various types that need to be instantiated, and passing them to other structs to satisfy as minimal of interface contracts as can be defined. These structs appear to be allocated on the heap. Perhaps there is a less complex design pattern out there that I haven't quite considered, but these are the main types I run into. 
Hey! Thanks very much! I hope I make a good, usable library out of it. :) I'll try my best. You answered basically all of your questions. :D I had the same thought process. I was thinking of including Terraform to have all it's power but it seemed like a very bold thing to do as opposed to a small yet powerful library in the form of godo. In fact, unit testing the thing proved to be much easier than expected, which is also something that is an important point to make. Never the less, I feel the pain that parsing the yaml files will be a difficult process, but not that much now that I have the right factory for the structs. My only concern at this point is allowing functions to exists like CloudFormation does and dependent resources. Like a LoadBalancer or a Floating IP needing a Droplet to exists, and things like that. But I have ideas for that. Like creating a Chain of resources to build up. We'll see. :) Thanks for the encouragement. Much appreciate it!
I would recommend putting it in a container over using systemd. 
If you're on GCP StackDriver is nice to work with. I particularly like AppEngine but if you're already invested with K8S might not be for you.
I think the question boils down to what kind of function `one.Execute()` of pattern A is. If it is some kind of service that needs to be mocked then pattern A makes testing difficult because it is called inside `two.Do`. If `one.Execute()` needs no mocking then pattern A can work fine and an idea might be for package `two` to be under package `one` to signify the dependency, so basically `one/two`. Pattern B is better for: * Unrelated packages where usually loose coupling is desirable. * A service than needs to be mocked in order to properly test.
Glanced at your source, I think you need to move literally every sub package into internal and start at the most basic example. There are too many small packages and functions that overlap with crypto primitives. For example you have 3 identical functions that all just just change a hash size in pkg rsasha. That package also has some security issues, for example [dont do this](https://github.com/gbrlsnchs/jwt/blob/master/jwtcrypto/rsasha/rsasha.go#L57), you shouldn‚Äôt be checking for nil on use but at New and panic there. I also don‚Äôt think you should be doing range checks on the hash function and possibly changing it underneath the user since it‚Äôs an exported field. I think you need to rip out the notion of None, a lot of your surface area and abstraction seems to stem from this demand. Instead create a jwttest sub pkg to support testing without pulling in PKI. Then think about what you want the user to interact with, they don‚Äôt need a mini jwt abstraction layer with primitives to glue together. That should really tighten your packages up and allow you to lower the surface area a bit to make it easier for someone to audit.
I'd agree with this. I'm not certain where I'd say pattern A is better. Pattern A can still be mocked, but unit tests in Two would need to import `One.Mock`. That probably violates some principles, but isn't necessarily _wrong_. However, `one.Execute()` in this implementation does exactly as described. It just returns the local, unexported, state. 
http://go-colly.org/ or https://github.com/PuerkitoBio/fetchbot
&gt; we could log monitoring data and get that in Elk as well Since ELK isn't designed for metrics or monitoring, this is a non-optimal solution. ELK has a tendency to overflow when hit with too much data, and this is the last thing you want with a monitoring solution. Practicality is reduced in this mode as well. ELK doesn't offer many options for aggregating your data... so you'd be hard pressed to build monitoring dashboards that present you a complete view of your infrastructure.
From my reading of these issues, it appears the fundamental problem is that of aliasing: the metrics are scraped at some interval, and the user is attempting to bucket / window the data at roughly the same interval. Nyquist's theorem in action. You're highlighting one of the difficulties of monitoring: ensuring your services produce data at the Goldilocks rate -- not so slow that you lose granularity, but not so fast that you overwhelm your collection / query infrastructure. These are some of the challenges that lie ahead of OP: how to set the collection rate and size the infra. appropriately.
OP, you're not clear on why you want to monitor your services. If you just want up/down status, then all you need is to implement a port checker or service ping API of some sort. If you want to measure the health of your application simply, you can continue using a ping API, but build logic into the API to gather health parameters from across the service. Here's one such example: https://docs.microsoft.com/en-us/azure/architecture/patterns/health-endpoint-monitoring More robust application monitoring can be done automagically with tools like Pingdom or New Relic -- which give you API response times, DB transaction times, etc. But these tools are only useful for particular API transports / back-end technologies, and they cost $$$. You can roll your own metrics system with Prometheus and Grafana if needed -- there are tons of open source Prometheus scrapers / exporters available so you shouldn't have to do a lot of that work by hand -- but then you've added to your operational complexity. The $$$ you'd be throwing at New Relic, now gets thrown at an engineer who will need to spend the time maintaining your own stack. Also keep in mind that it's a sound practice to deploy more than one of the above-mentioned methods for simultaneous use, to ensure you don't go operationally blind should one of your monitoring services fail. You can get better advice if you give us a better definition of your problem...
If you're not going to tell us what problem it is you're looking to solve, how are we supposed to make sense of your proposed solutions?
I use GoQuery for parsing HTML in pretty much all of my scraping jobs and It has worked really well for me. 
&gt; An authentication server by it's very nature cannot be open source I don't understand how an authentication server cannot be opensource. 
YA, I Need Help
why an authentication server cannot be open source? how is roll your own possible and open source is not? the security of such server is not in the code, but in the data.
An auth server such auth0 would be authentication as a service. Since authentication requires some secret to be stored by the server - the method in which that authentication is encrypted is of utmost importance for security. Otherwise you would either a) have an open secret...no better than a plain text storing of the secret OR b) would have plain text secrets which are for various reasons, a security nightmare. On top of the issues of secrecy, a server must handle some actions "behind the scenes". Once you have given a server some credential (such as a username and password combination) there is no way to verify what the server has done with said credential. It could store it, write it to logs, send it to some other server. Anyone can claim to be running an open source version of certain software on their server, but end-users have no way to verify that the source hasn't been altered to contain some nefarious code. So servers / services cannot be trusted to be open source. That doesn't mean that all servers claiming to run open source software are liars, only that there is no proof. What you are referencing is code that allows you as an individual to run an auth server using OSS. However, there is nothing stopping you from modifying that software in a potentially malicious way without end-users ever having knowledge of your modifications. As such, the idea of an open-source auth server is essentially a moot point. There is no way to inspect and run the code that the server is running unless you have full control of the computers running the code.
There was an implicit /s on his comment.
&gt; to get github.com/joho/godotenv go get github.com/joho/godotenv
I tried all of them but it doesn't help
Yes, I did. It looks like it is not support socket client is backend
Why are you so convinced that he wouldn't control the server? Perhaps this is to provide auth to a large internal body of developers. That said, I don't buy the argument that it is somehow insecure. Most open source web apps manage sensitive data such as passwords, logs, etc. Being open source has often produced some of our most secure vetted projects. There is only risky, thin security in keeping your method of encryption secret. You should instead use tests, keep encryption algorithms current, and review code. There is nothing stopping a closed source project from being more nefarious or risky than an open source one, so mentioning that code could be changed doesn't seem to have a point.
What problem is anyone trying to solve by writing code in an easily maintainable fashion?
You're right. There is nothing stopping any server, including closed source from misusing information you provide them. I have nothing against OSS. I contribute to a few, and use numerous others. My point is that a truly open source authentication server is inherently vulnerable. Perhaps we have different definitions of what open source means. To me it means that I can see everything that software I use is doing, modify any part of it, and run it on my own machine so long as it meets hardware and software dependencies. You cannot do that when the code is running on someone else's server - OP specifically asked for something like auth0 which I took to mean an external service - not an importable library or self hosted solution. Even if OP does use a self-made or open source solution, it is only effectively open source for OP, as they are the only ones who can verify that the code on the server is unmodified. Everyone else has to take OPs word for it. I'm not saying that it wouldnt be useful, or that it wouldnt be secure. It could be and most likely is both of those things. Im saying that it is not truly open source for anyone using such a server.
Thanks. May be you know some solutions as alternative to selenium webdriver? I would like to use browser control or emulation (phantomjs) to better mask the spider and clicks
I thought you were just trolling at first. 10/10 would lol again. 
OpenID connect is essentially the authentication pattern that Auth0 utilizes. There are numerous open source implementations. Here is one written in Go by the CoreOS team: https://github.com/coreos/dex
Nothing very advanced in this talk, to be honest. It's useful as an introduction, though.
Totally. He did clarify it though at first.
I have used https://github.com/yhat/scrape for several scraping projects. But it‚Äôs only good for HTML parsing, not aware of anything headless browser-wise in Go. I always go back to node.js for those. 
Thanks all. I will try one by one tomorrow at work to see which one works best.
Yeah, I didn't notice that. :) 
http://surf.readthedocs.io/ is it something you look for?
I'm nearly new at Golang, so what should I do? If you know, can you send me a PR?
You can save the code snippet with the "Save" button. After that you just need to copy URL from your address bar to your friend. URL will look similar to the one I shared. :)
I usually use [chi](https://github.com/go-chi/chi). Pick one that has an API that you like. Don't look at performance numbers until you have profiled and routing really affects the overall performance. I don't like https://github.com/julienschmidt/httprouter because it treats standard http.Handlers as second-class. I think I also had trouble getting exactly the routes I wanted with httprouter. And the standard library mux is also ok. Only look for something else if you have a problem with it.
TBH, the resulting error message is not really helpful, especially for newcomers. (Fun fact: The Go playground [does not complain](https://play.golang.org/p/UtSOfdc3uoU) about the wrong formatting.)
If you build with CGO_ENABLED=0 and ldd reports "not a dynamic executable", what exactly might still be using glibc?
https://github.com/ory/hydra Auth0 sponsors it.
https://github.com/ory/hydra Auth0 sponsors it. 
The problem is that your code is not formatted properly. Run [`gofmt`](https://blog.golang.org/go-fmt-your-code) or `goimports` automatically every time you save. If you install the `vscode-go` extension on VScode I think this is done by default but you might have to [change it in the options](https://github.com/Microsoft/vscode-go/issues/253).
Very likely. It is necessary to study
* [Language and Locale Matching in Go](https://blog.golang.org/matchlang) * [Internationalization and localization](https://astaxie.gitbooks.io/build-web-application-with-golang/en/10.0.html)
Came here to post this: use an interface, use many interfaces if you like, but OP shouldn't bother with integration testing until he's written unit tests against a stubbed-out transport layer. Setting up a test server can be error prone, and the effort may not yield any added benefit, beyond what one can accomplish with stubs.
&gt; you need a newline after import ( and before "fmt". Not true, it's perfectly valid code.
Hey. Author of github.com/olivere/elastic here. In general, I agree. The elastic library is quite old (it started in 2013), and when I'd have the chance and time to rewrite, it would look quite different. Quite frankly, I didn't know Go that well in 2013, and you can see that in the codebase. But in general, I prefer stability over anything else, so I try to limit breaking changes as much as I can. Why did I choose a DSL? That's because elastic chose to use a style that Google chose for their APIs (see https://github.com/google/google-api-go-client/blob/master/books/v1/books-gen.go as an example). Most of the services are auto-generated from the REST API spec. I also tend to stick to the Java source as much as I can, because while the documentation on Elastic homepage is quite good, it is meant to be read by humans and is missing some subtle details. Having said that, I have a separate ES client library, currently unreleased, with a newer style that e.g. removes the need for DSL, is orthogonal in regard to services and data structures etc. However, I currently do not have the time to work on it. And: It would be very different to the current state of elastic. And that might even cause more confusion. I also saw the effort of the Elastic people to create an official client. I'm not sure about the state of it; last commits are months ago. I'd be happy if they have an official client and deprecate elastic. But I also am quite open in that I don't like their structuring of official libraries, e.g. their decision to have a separate transport and a DSL. I think it might end up very un-Go-ish. 
+1 for GoQuery -- the API should be very familiar to you if you've ever done any work with jQuery on the frontend.
checkout https://github.com/netlify/gotrue
Yet another reason to vendor *and* commit your dependencies.
I like Go except for a few things. I really don't like how repositories/projectst are supposed to be configured in Go. I have not wrote a large project in Go recently, So, My knowledge might be outdated. But, The system to import package is seriously broken and annoys me and this is one reason I don't jump on the opportunity to contribute to a project written in Go. All the import paths in a lot of projects are like, `github.com/userx/repox`. When I fork it and `go get` the fork on my pc, The paths don't work anymore and I have to change it again. I mostly used `govendor` and IIRC `govendor` doesn't has anything to fix this problem but feel free to correct me if I am wrong. And the title of thread, Once again shows that you have to have a system like npm/crates.io. 
https://github.com/femaref/go-bindata copy from late october. no clue how old that is.
npm isn't immune to these sorts of things either: https://www.theregister.co.uk/2016/03/23/npm_left_pad_chaos/
We have a backup https://github.com/containous/go-bindata if this can help
I have a copy from yesterday in my GOPATH.
Unfortunately these features don't exist at the moment. If you are interested, whole project is available on GitHub https://github.com/judge0 so you can follow updates there. üòä
That was a one time mess and when they did that, They also received a lot of criticism from people. You very likey won't see the same response if a random github user moves/deletes **his** repository. 
[removed]
I think you may be confusing "dependency injection" with "dependency injection container". DI is a really good approach, including in Go. Using a container, or autowiring, or some other reflect-based or struct-tag based magic thing is not good.
&gt; you have to have a system like npm/crates.io. It will [probably](https://github.com/golang/dep/issues/175) happen eventually.
IMO it is the right and privilege of the owner of IP to depublish that IP, if they so choose. Hosting and maintenance cost money and time and energy and if someone doesn't want to pay any of that anymore, they *should* have the ability to stop. Note, that the go-get autodiscovery actually gives you (as a user) *more* control over whether or not packages can get depublished or not. If you want a guarantee, that a packages stays public as long as you want it to, host it on a webserver of your choosing and maintain that hosting yourself.
This only partially solves the problem. If you ever want to solve your dependencies with `dep` or other tools again it will fail at that point.
I applaud this.
Just `go get^W`got it, thanks.
Anyone have any information on what happened? Is the guy alright?
I second. This was not the single repo being removed, but whole account deleted - https://github.com/jteeuwen gives 404.
&gt; And the title of thread, Once again shows that you have to have a system like npm/crates.io. http://gonuts.io/ Created years ago. And no-one uses it.
&gt; it didn‚Äôt cost him money, time or energy. Money - no. Time and Energy - I'd be careful with that. &gt; Sure, that still makes him a bad citizen of the ecosystem. I'm ambivalent about this. I think there is a feeling of entitlement towards creators of open source software and I think that feeling of entitlement is wrong. Is it nice to depublish this library? No, of course not. Does that lack of nicety outweigh the nicety of *publishing it to begin with*? Not so sure. In the end, the social contract I try to apply to open source is "I'm not paying for it, so I have no moral claim here". If I suddenly get to be subjected to other people's sensibilities of how I am or am not allowed to behave in regards to the code I'm publishing, I get dissuaded from publishing it at all. Why would I open source my stuff, if all I'm getting in return is the chance to get yelled at by strangers on the internet, because they don't like how I decided to do it?
You don't have to change your path in code if you add the remote source to your repo in the original project. Check solution #1 http://code.openark.org/blog/development/forking-golang-repositories-on-github-and-managing-the-import-path
&gt; When I fork it and go get the fork on my pc Why would you do that, though? Do you upload javascript packages to npm under their own name and npm install them, when you are authoring a PR? If not, why would you do the equivalent in Go? Just git clone your fork, like in every other language too. &gt; And the title of thread, Once again shows that you have to have a system like npm/crates.io. npm and crates.io are vulnerable to depublishing - but there it's not even in the authors control, whether or not something gets depublished. Go imports, OTOH, can't actually be censored, as there is no central authority. Dissatisfied with someone deleting a Go package? Re-upload it to a webserver of your choosing and people can continue to use it without fuzz, if they want to.
&gt; And no-one uses it. Because it's mostly isomorphic to using github. If I'm concerned about doing *that*, why would I use some other, noname provider to host my discovery, instead of just doing myself?
&gt; I‚Äôd be careful with that. Care to elaborate? He didn‚Äôt spend *any* time or energy on that repo for more than a year.
I have absolutely no clue whether or not they spend any time or energy on that (or any of theirs) repo. And neither do you. Not all time and energy (actually, I'd argue probably a rather small-ish percentage, depending on the specific software) spend on a published piece of code is reflected in published commits, issue comments or the like. Not saying this happened here. Just that I find it a bold claim to say it didn't.
I'm more worried about how the guy deleted his account, and now someone else registered it and is hosting contents there. This means anyone who isn't aware of this will now `go get` code from this new person. Who might add in something bad.
[removed]
Is back https://github.com/jteeuwen but I not sure if it the real jteeuwen
Related: https://github.com/avelino/awesome-go/pull/1675 Folks, take this opportunity to 1. change your dependency to a better solution 2. unify efforts to make this lib (one fork) awesome again. There might be a back story, but I don't know anything more than anyone else. Thanks!
Now it's back but with 0 history and only one repo (go-bindata). Did someone signed up with the same account name so go repos would not break?
How does this prove that GitHub is "crappy"?
If I just had the time... üôÅ
Someone else registered the account to get this project back online.
Sure, but there is a big difference between "I trust person X to try and keep this code secure" and "Some completely random unrelated person is now in control of the code without any announcement"
Agreed.
It doesn‚Äôt say Github is crappy. It says Github is crappy *as a package repository*. There is a reason other languages have centralized registries instead of relying directly on various VCS repositories. 
dep is going to make it easier at some point: https://github.com/golang/dep/issues/174 But yeah, clone/mirror your deps
Wait, is it possible to sign up with a deleted user's name? Isn't "delete" just "mark as deleted and don't show anywhere on Github" not allowing new users to sign up with this name?
Why should "paying for it" only be in terms of money? If you contribute to the open source software ecosystem, you "pay for" the open source software ecosystem, so that we all can benefit.
Tbh, i tried using go-bindata and I still do in some projects, seems I'll have to migrate to something better. [rakyll/statik](https://github.com/rakyll/statik) i guess?
Apparently! That's what I thought too, but https://github.com/jteeuwen shows "Joined 1 hour ago" right now, while the "jteeuwen" has definitely existed for longer than an hour. And the repo now also shows it's a fork of some other repo, which didn't used to be the case.
May i join your applause? 
I made something specifically for things like this: github.com/clly/fallingstar
Yes it is possible. I've used this "feature" before for another account. 
I know a little history. The whole user account was abandoned for 2 years, accumulating 50 unresolved issues and 18 unmerged pull requests on this project alone. The tool was full of trivial to fix but very annoying bugs. Because of the desolate state I have requested to remove it from the awesome go list: https://github.com/avelino/awesome-go/pull/1675 Unfortunately the way back machine does not archive github issues or at least not this one: https://github.com/jteeuwen/go-bindata/issues/165 which used to list most pain points of the old project. IMHO this tool and possibly its forks still are not the best alternatives to solve the design problem. 
I meant "crappy" in the context of the title, and this implies "crappy as a package repository". Sorry if this was not clear. What I meant to indicate is that GitHub is not responsible for Go's lack of a package registry service. 
I think the point is that a repo can be either abandoned or deleted, and in both cases this means the owner can completely stop investing any time and energy, but in the former case, the users have at least something to build on.
As per, feedback greatly welcome! There was a long pause in the middle of writing this whilst I was super busy. So it feels a bit rushed to me, but it might be just me. 
I have to agree here. It is highly questionable that the name can re-registered immediately. A multi-month grace period would be prudent.
It would be no different from any other non-GitHub repo. If the code at the "new" head had the commit of the "old" head in its history, it would succeed, otherwise it would fail, just like if you rebase or do any other history rewriting command.
&gt; Wait, is it possible to sign up with a deleted user's name? Yup. And before you ask yes it has been use maliciously in the past 
If you record the hashes, they can have a million malicious commits after the one you want, but your code will still be safe to checkout. Tags and branch names would be corruptable on a new pull, but hashes should be secure.
Return an error, don't exit.
This looks really neat. What's the rationale for implementing it in Go? For example, performance gains?
Out of curiosity, has anyone has attempted to build a centralized package repo for Go?
&gt; get this project back online Haha, obviously this was the goal. 
It is crappy that Go doesn't have a central package repository, and GitHub is a crappy central repository - but it is a crappy one because it does not aim to be one. I think that's all there is to it really.
This is why I wish Go didn't use source dependencies, and instead used binary dependencies, with the binaries hosted at something like Maven Central. If that had been the case, this guy deleting his github account wouldn't have broken anything. 
Except that we are seeing exactly that same response in this thread. And I'm sure some tech journos will pick it up and it'll get conflated with the whole left pad thing. Meanwhile the best responses in this thread point out why it isn't at all like the left pad fiasco, and a big part of that is *not* having a registry.
Would forking your dependencies be an alternative? 
Fork all deps and use your own forks in the project, if a dep repo gets updated review the code and pull changes from the main repo into your fork, then update your project.
I agree that Go relying solely on Github is crappy, but thankfully that's not the case. There is nothing about Go's tooling that hardcodes Github. Some libraries live on Gitlab or Bitbucket or what have you. Many of the most popular/semi-official libraries use canonical aliases, such as `golang.org/x/crypto/` which ultimately resolves to `github.com/golang/crypto/` and allows them to easily relocate. Right now, we're dependent on whatever specific host any given library is using. If Bitbucket screws up, then all the libraries that are hosted on Bitbucket with no canonical alias get screwed up. If a specific author screws up (e.g. deletes their account), then that author's libraries get screwed up regardless of where they're hosted (whether it's Github, or NPM, or whatever). Having a centralized host does not make this situation better, but often worse. When NPM screws up, _every_ node package gets affected. When Github screws up, only the Go packages canonically hosted on Github get screwed up. Again, when the author screws up, the same outcome applies regardless of whether it's a centralized host or not. The best ways to mitigate this: - Pin your dependencies to a specific commit hash (bonus points if it's cryptographically secure, which git is unfortunately not due to sha1 being weakened‚Äîbut that will hopefully improve in the future; would be nice if `go dep` supported repo-independent content verification.) - Mirror all of your dependencies. You can do this by vendoring them, or by hosting your own centralized mirror of the specific versions you're using. Maybe even a communical independent mirror would work. - Encouraging popular libraries to use their own domains for canonical repo addresses to reduce dependency on Github and make a failover switch easier. Overall, I believe a community vendor mirror would be more valuable than a centralized package host. In a way, godoc already does half the work for this, now if only we could pull from godoc's caches too.
Was hoping they weren't stopping! Looking forward to reading this. 
Itsyou.online
Maybe set the tab stop to 8? :P
&gt; I happen to have a mediocre connection, Committing dependencies increases size and Git is not particularly good at cloning a repository on mediocre connections. And downloading N repositories instead of only one will make this better?
Check out: https://usehelix.com/getting_started if you are looking to speed up Ruby using Rust.
Forking a project and using the fork is also safer than using the original (for example package dependencies) since one has control over the forked repo
I'm sure this post is buried by now, but what is anyone trying to solve by using ideal design patterns? I suppose I should do more research into great Go design. What problem am I trying to solve? Reducing technical debt and providing a clean, intuitive piece of software (in a large codebase) to maintain is the ideal. Though, based on the aggressive nature of your comment, I'd presume that isn't concrete enough of a definition to satisfy you.
Well i try to explain, we have some Circleci instances taht check that repo out before building, they started to fail today. So we investigated and created a repro under https://github.com/a-urth/go-bindata, someone signed up under the deleted user jteeuwen and forked the repro back. See https://github.com/jteeuwen/go-bindata/issues/1. My first though was well now we are the only ones that know it is ledgit, but you can actually chech the last commitshttps://github.com/jteeuwen/go-bindata/commit/a0ff2567cfb70903282db057e799fd826784d41d. I hope you can still trust sha1, at least for some time. 
it's not going to solve anything. Forking is the answer.
I know him. He was just trying to get his own project back to work. Anyway this is not long term solution. He won't have time to maintain it, besides the security issue.
Please tell him to document who he is, his intentions, etc in the repo itself. This is a very popular package, and the community needs to know it can trust the new owner.
Please add content to the repo about yourself and your intentions for the repo. This is a very popular project and the community wants to know the project is in good hands.
Like a million people. That doesn't solve any problems, though, unless you prevent people from being able to delete their own code.
I've had good experience with statik.
As left pad showed, a central package repository doesn't solve anything, unless you prevent people from removing their code.... which is problematic.
&gt; I find the whole "don't ever roll crypto" adage a bit overblown. Then you don't understand why it's become an adage. &gt; I trust people to be halfway reasonable You can't and shouldn't.
&gt; Time and Energy - I'd be careful with that. I believe it *did* cost him time and money. However, leaving the repo open won't cost *further* time and money. Just archive it and some one with time will come and fork.
Look, you're the one here looking for help, and [you're not giving us enough context to give you that help](http://www.catb.org/esr/faqs/smart-questions.html). You want to be greeted with open arms, when you can't be bothered to do your homework? That's not a realistic expectation. &gt; Though, based on the aggressive nature of your comment, I'd presume that isn't concrete enough of a definition to satisfy you. Taking the low road isn't an effective way to make your point.
Pretty much latest LOL
lol NuGet and Maven got it right
The link you provided does not resolve. I'm honestly not sure what additional context I can provide RE: Design patterns. Perhaps I just need to dig deeper and do additional research myself. As I understood it, these are both well known existing design patterns in Go. I was looking for a little further clarification on why one would choose one pattern over the other, as I was unable to put a name to either of these (short of dependency injection for B). &gt;Taking the low road isn't an effective way to make your point. It doesn't matter what I do at this juncture. You and I are the only two people reading this. You will not be convinced regardless of what I say that I've proven my point, because you already have your opinion made up. 
I'm trying to contact him, but I guess he has fallen asleep (bed time in his zone). It is a safe move not to use this lib currently... You can't randomly believe anyone on Internet after all.
I think I know the guy, and he is not the original one. Wait until he make some announce.
Any decent go dependcy tool saves commit hashes. However, you cannot check out that commit if the repository is not available anymore (or if it's force pushed). That's what I meant to say, apparently that was unclear. 
I would use https://github.com/kevinburke/h256only if possible. If you're building your own, I'd look at h256only and specifically the reasoning behind it.
Undertale is strong in this one.
In his newest video he shows a third method using recursion to create a binary tree of merged channels. It doesn't do as well as the goroutines method but is much faster than reflection.
The next few should be fairly quick! Hit a few snags on this one, too :) 
&gt; This is always a risk with any repository you use. Technically, by which I mean "there is a technical mechanism that could do this", you can trust that nobody can do that to my repositories, because I GPG sign my commits and tags. Realistically I'd guess that there's either 0 or 1 entit(y/ies) looking at this. (One of my packages is packaged in debian and there's a small chance they might have noticed this. But probably not.) But I'm at least doing my part.
If you're on the Gophers Slack, there's a #vancouver channel that might also be a good venue to advertise.
Apache Arrow is a specification for how to build efficient data structures in memory. On of the goals of Arrow is that these data structures can be exchanged between applications. An implementation in Go allows us to participate in that ecosystem. Yes, we make extensive use of code generation and generics would be a use case. As performance is a primary goal of Arrow, we don't want "generic" interface APIs all over the place üëçüèª **NOTE** I am one of the authors of the the Go package
That is very interesting, I didn't know that project. I like its approach. Thank you for sharing!
&gt; You and I are the only two people reading this. I wouldn't say so. It's not hard to see the latest comments by using a few extensions. But from the current replies (if we take out the hostile one) you replied to both and you didn't ask any further questions. Thus personally I felt you were satisfied with the answers.
My comment was assuming a case where the dependency was replaced with a maliciously altered repository. I had read your comment in relation to trust as opposed to availability.
&gt; which is problematic. If the license you choose allows redistribution (verbatim or otherwise) I don't think it's problematic at all. If you want to retain full control of your code, there are licenses available to you outside the usual MIT/BSD/GPL stuff.
It resolves, but the server's having some problems right now. Check again later, because that link is referenced in scores of journals... worth the wait. &gt; It doesn't matter what I do at this juncture Wait, you came here for help with code, how did this suddenly turn into an "I gotta prove myself" situation? That's all you... You could just have realized that you're being opaque, and that you could rectify the issue and get the help you need. That's actually a lot simpler than the knee-jerk reaction you went with instead... 
congratulations!
I don't like that you put documentation as the number 5. Together with a good README, it's really the number 1 (and making a good and useful package is number 0).
Video linked by /u/shovelpost: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Go Proverbs - Rob Pike - Gopherfest - November 18, 2015](https://youtube.com/watch?v=PAAkCSZUG1c)|The Go Programming Language|2015-12-01|0:22:29|754+ (98%)|45,974 $quote See the full list of proverbs here:... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/shovelpost ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=$comment_id\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
&gt; I know him. He was just trying to get his own project back to work. Can you ask him what happened? Why was the account deleted?
How is it a workaround? Regardless of security reasons, GitHub just goes down sometimes...
The format of the dependency has nothing to do with how reliable the source is.
Are github usernames static? if you can't change why not just implement every username ever created must be unique. I mean I'm sure the guy who deleted his acc's detail are still sitting their lol.
i have been looking into game engines today in go. Ebiten looked very interesting, but its lack of examples and documentation really turned me off. do you have any experience working with [pixel](https://github.com/faiface/pixel) or [engo](https://github.com/EngoEngine/engo)? thanks!
Yes, and even then when you want to change any of your dependencies the repo cannot be found so solving fails, because it cannot request what versions of the library exist. At least this is the case for dep. 
Sum types support decidable and exhaustive case analysis into their summands, by definition.
This is great, gives me a lot to dig through. I wasn't having much luck with my googling. Thanks much for the info!
Ebiten predates Pixel by a couple of years (early summer of 2013 vs fall of 2016)
Where is this mythical package repository that never goes down and never has packages disappear? I think GitHub does an outstanding job of serving Go packages.
Thanks for not answering the question 
Don't modern package managers verify the source hashes? Of course, that doesn't help you verifying the original source, but it should allow you to trust *any* host once you certify that you trust version X.Y.Z, no?
&gt; This is always a risk with any repository you use. Nope. Proper repos sign their shit. See every Linux distro ever. This is just lazyness.
Yup, my point was made clumsily, mea culpa, edited.
I use [Reddit Enhancement Suite](https://chrome.google.com/webstore/detail/reddit-enhancement-suite/kbmfpngjjgdllneeigpgjifpgocmfgmb) and [Reddit New Comments Highlighter](https://chrome.google.com/webstore/detail/reddit-new-comments-highl/ajdilinnnkbmpoegibgacadjlblmpjad?hl=en) for Chrome. I suppose others also use similar tools so they can keep up.
Generating a unique username would likely become something of a hassle, though. Personally I'd prefer `username/reponame` granularity, so the names of deleted repos would never be usable, but usernames could be recycled
statik is a functionally good replacement, but it doesn't have the [`.rodata` hack](https://github.com/jteeuwen/go-bindata#lower-memory-footprint) from go-bindata, which results in a much higher memory and GC footprint.
&gt; Like a million people. That doesn't solve any problems, though, unless you prevent people from being able to delete their own code. Yes it does solve problems. It makes hosting mirrors extremely easier for instance. People in the Go community are acting like package management isn't a problem, that the fact that there is no "maven" for go is not a big deal, but it is. Go community thinks because the language is fresh and new, other language's issues don't apply to Go. That's an arrogant and foolish attitude.
Does it fill you with determination?
Any solution other than forking and vendoring your stuff is going to have this issue. 
bahahahahahahhahahahahahahahahahahahahhahahahahahaha happens all the fucking time with python and gems 
&gt; Yes it does solve problems. It makes hosting mirrors extremely easier for instance. Vendoring and forking solve this as well. 
and if someone deletes it from maven. or changes the setup or maven is out of service for a while everything breaks. Fork and vendor or your ops people will curse your name.
no, neither vendoring or forking gives you a package registry.
&gt; forking your stuff is literally mirroring it. Because you're using just another source repo you can have local mirrors without issue. You don't even know what you are talking about. How do you find packages to fork without some kind of registry? 
Deletions/screwups in Maven Central are rare, but you're correct. Which is why most people who do Java use something like Artifactory locally, to cache the dependencies. That means that if 27 projects in a company use a given dependency, there is _one_ copy of a given version that has to get "checked in". With "check in your vendor directory", all 27 would have to check them in.
How do you find websites with out some canonical central registry of packages? 
Disk space is vastly cheaper than the operational overhead of artifactory. Even shitty overpriced enterprise sans. A bigger cost would be different versions inside your infrastructure and the wonderful incompatibilities they have.
Ok here's another one. Maintainer pushes a deployment on the same version number. This is a real issue that hit me with ruby gems. they changed the required ruby version without updating the version number. another gem by another dev removed functions and pushed over the top as well. 
&gt; though i do enjoy how you started with mirrors and have moved your argument to discovery. no it's you who didn't even pay attention to what I wrote at first place : &gt; It makes hosting mirrors extremely **easier** for instance. good luck finding and mirroring all go packages on github. 
It's existed since the 1990s in the form of mirrored/distributed package repositories. FreeBSD, NetBSD, OpenBSD, CPAN, CTAN, Debian, pkgsrc, Gentoo, etc You can still host on a CDN if you like but you'll have many mirrors available in case one or more are inaccessible. Plus, this allows for easy local mirroring for reduced latency and build reliability.
Looks like just a security release
Also not answering your question, but there are quite a few examples in the ebiten source tree: https://github.com/hajimehoshi/ebiten/tree/master/examples and also on the Works page on the wiki: https://github.com/hajimehoshi/ebiten/wiki/Works as for documentation, the library is relatively simple compared to pixel or engo being neither a full blown game engine nor 3d. The source documentation and the accompanying samples are reasonably comprehensive.
Dependencies being source isn't the problem. Relying on upstream developer's repository is the issue. A curated archive that is mirrored and highly available but still is just sources, is the solution.
&gt; I already fork and mirror the packages i use. It's pretty easy to have a bash for loop that pulls them all so i stay up to date. pfff, yeah, it's called plumbing and doesn't solve anything in any serious fashion. A package registry doesn't pull "all", only the tags that has been published. But go ahead show us your half-baked package registry.
&gt; Looks like just a security release hence the " [security] " prefix, for people that care about security to know about it.
I haven't finished the game but the way the main character walks, the closed eyes and the creepy bird in Bluebird of Happiness gave me huge Undertale vibes. :)
I'm not familiar with Ruby at all so maybe I'm missing something, but how is that a problem in an append-only no-delete world? For example: - Commit 1 with tag v1 is released. You are using this version. - Commit 2 is pushed, without a new tag. This commit breaks backwards compatibility (ruby version). How does this affect you? Your dependency manager's lock file should still have you pinned to commit 1 / tag 1, so a new commit has no effect on you unless you explicitly try to update your dependencies.
&gt; Maven doesn't magically solve this problem neither does vendoring, which is the solution go pundits keep on advertising like it solves anything, it doesn't. 
&gt; Is there any issue with this solution? Dependencies have dependencies that have dependencies. Unless you are willing to fork, monitor, review and update the entire tree, this is not a reasonable solution.
&gt; There is nothing about Go's tooling that hardcodes Github. `go get` has [hardcoded definitions](https://github.com/golang/go/blob/104445e3140f4468839db49a25cb0182f7923174/src/cmd/go/internal/get/vcs.go#L957) for Github and several other popular VCS hosts.
&gt; Deployments of new hosts pulled down the new 1.2.3 not the old 1.2.3 and shit broke on new hosts. Then ruby gems is not an append-only system, so it's out-of-scope for my comment. In an append-only world, the registry would ignore the second push with a 1.2.3 tag.
Yes it does, it solves the problem of the upstream going away or changing in some way you can't control. Not that it doesn't introduce other problems too, of course.
I did see the repo's provided examples, thanks. that's not really what I'm looking for. I want to see third party examples, demonstrations of use by a non-author. that's a strong indicator to me of the library's functionality and usability. &gt; The source documentation and the accompanying samples are reasonably comprehensive. this is good to know. the works page is more of what I was looking for, thanks.
&gt; Yes it does, it solves the problem of the upstream going away or changing in some way you can't control. Not that it doesn't introduce other problems too, of course. no it doesn't otherwise we wouldn't be here discussing why go-bindata was removed.
It being removed is a problem for the people who *didn't* vendorise it.
So from what I've seen, path parameters (of the type `/books/{id}`) are tougher when using the default `http` package. I use those heavily in the APIs I make. It also has a nice set of features like "URL building" that allows me to generate URLs if I know the name of a route. More can be read here: https://github.com/gorilla/mux That's another reason why I should likely link to the Gorilla toolkit and talk about it more in the blog post! For more on handling CRUD with forms and buttons, you can look here! http://www.codemag.com/Article/1511031/CRUD-in-HTML-JavaScript-and-jQuery 
Especially considering there was just an RCE discovered in `go get`: https://github.com/golang/go/issues/23672
Only to bootstrap the legacy hosting providers. There is nothing you couldn't achieve outside of GitHub.
Feel free to use vanity imports for your own projects. `golang.org/x/` actually lives on GitHub, right now, but they can change that when they want to.
These are probably more Delve issues than vs code to be fair. 
Please remember to document any CGO_FLAGS_ALLOW variables your packages needs to build, if you're using a set of non-standard flags.
Yeah we are not too worried smaller sizes in our use case, most of our blocks are &gt; 1KiB or above. 
Ah, I knew it could not have been that easy. Thanks for reminding me what I forgot about.
Why don't they impose at least a 3 month cooldown period?
I think you're right. The majority of people using highwayhash will probably be using it to fingerprint large data blobs, not as a hash function replacement for small keys for a hash table.
&gt; i have been looking into game engines today in go. Ebiten looked very interesting, but its lack of examples and documentation really turned me off. Thanks. Yeah, I admit lacks of documentation might be a problem. There are example as @illuminobster answered. &gt; I see you're the creator of ebiten. do you have any experience working with pixel or engo that inspired features in ebiten? thanks! I don't understand your question. We have been inspiring each other to some extent.
Thank you :-)
Agreed (disclaimer: I'm a developer of the runtime part, and was not involved in game designing so much). The game designer [Daigo](https://www.reddit.com/user/daigo-chan) said Undertale was inspired by another game, and Bluebird was inspired the game.
It's not a work-around. It's the only sane solution. Recording the dependency in a text file is the workaround, and a terrible one at that. Like, seriously, how is it a work around? Around what? Your project depends on some code, so you embed the code in your repo. It's just the default sane thing to do.
They are not and you can see how they don't work that way with a practical example here, which you can execute and test: https://www.reddit.com/r/programmingcirclejerk/comments/7vv3kw/in_fact_go_interfaces_are_just_sum_types_at_run/dtvt40h/ 
&gt; How does this prove that GitHub is "crappy"? GitHub isn't crappy at all. It's just that it shouldn't be used as a package repository. Go should have put their own package repository, not unlike NuGet or Maven. Come on, it's Google who it's backing it, they have the resources to do it. 
We used to commit `vendor` and, while it certainly had some downsides (occasional hassle with conflicting updates) man, I tell ya, it was REALLY nice to be able to just `git checkout &lt;branch&gt;` and suddenly be back on the right vendor situation without having to run _another_ tool and wait for it re-resolve everything (or, more often than not, do nothing!)
It *is* a workaround because it discourages use of the actual working solutions and best practices we already have for secure and dependable package management. We're not helpless victims lost at sea here, hacking private solutions against the poverty of poorly implemented dependency repositories. Not to implicitly disparage Golang, but consider the efforts of Rust in this field, they really understand how dependency management is central to a language. And another point, if you're committing deps to git, then you're wasting a swathe of git's raison d'etre. Your repo gets filled with noise, becoming little more than a glorified rollback mechanism.
Please use code blocks :) Black and white doesn't make it easy to read.
hehe. Thank you :)
Thanks for your service to the Elasticsearch and Go communities! In many ways I do think a DSL is more Go-like - it trades well-defined behavior for some verbosity. On the other hand I look at database/sql, which provides a minimal interface that covers *how* you talk to a database, without giving much thought to *what* you're saying. My preferred approach with Elasticsearch has been in line with the latter, with the well-defined interface being on the application side. I guess it's a question of abstraction and how you're using Elasticsearch - is the application a client for Elasticsearch, or is Elasticsearch a database that serves data to your application? Elastic is a great as an Elasticsearch client, but sometimes we just need an interface.
Hi, I made https://github.com/oakmound/oak. Denis Cormier emailed me about this project he made in oak (1.x, so if he hasn't updated it to use dep it will have issues because we've just pushed 2.0), if you're looking for third party examples of go game engines in use: https://bitbucket.org/deniscormier/cant-stop
Without breaking semver, you could check the created at date using github api. 
Structs, pointers, interfaces, defer, functions, closures, if/then/else, select, type conversion. These are all available in the latest release of gijit, which is now at https://github.com/gijit/gi
Set up a proxy cache then. Nexus and Artifactory exist for a reason. And they're way better at managing it. 
&gt; The game designer Daigo said Undertale was inspired by another game, and Bluebird was inspired by the game. Very interesting. What is that game that both Undertale and Bluebird have drawn inspiration from?
&gt; I've found that self-hosting go repositories is tricky and annoying because the toolchain special cases github and other popular hosts. Can you be more specific? Because I can not imagine what one would have to do with the other, given that they are totally different mechanisms.
I know it is meant as a personal project, but I personally would not mind a nice readme, comments on exported functions / types and some unit tests. Also I noticed the file in the node package starts with a capital letter, is there a reason for that?
[removed]
I'm one of the people who recreated project under own account (http://github.com/a-urth/go-bindata). And i have no relation to "new" `jteeuwen` account same as no idea why it used my project as to fork from. I've never was involved into development of this project before, tbh i didn't even use it that much. But I'm definitely willing to elaborate on its future life as much as i can. I'm not sure whether I'm the right person to be maintainer of this project but I would like to do it and even continue development.
I am confused by the mining part. The block that was last before adding the new block is the one used to provide the proof of work for the new one? 
The Moon https://en.wikipedia.org/wiki/Moon:_Remix_RPG_Adventure Not sure this is famous.
&gt; I've found that self-hosting go repositories is tricky and annoying because the toolchain special cases github and other popular hosts. true, but you can easily replicate that: https://github.com/cskr/gorepos. How that works is visible in `go help importpath`. 
This is all very much beside the point but your comment surprised me slightly. As has been pointed out, resilient package repos have been with us for several decades, initially driven by the fact that the always on internet hasn‚Äôt always existed.
Not sure if it‚Äôs of any actual use to anyone since it only allows for cpu training, but I wanted something to prototype and learn with and the other libs I found were a bit lacking in terms of features. Criticism welcome!
Agreed, I've had some problems getting prism.js to work on the new Ghost theme, I had it working before. I'll give it another go :) 
Wow, congratulations! Releasing a real game is something I have yet to achieve.
I personally like the pattern and find it useful. The biggest downside is that it can be easy to realize there are two sets of parenthesis on the `defer` line, which can confuse people at first, but most people catch on quickly. Some of the upsides: - All your teardown logic is right beside your setup logic, so its easier to make sure you don't miss anything (especially when adding new code) - B/c you are using a closure you can encapsulate and use data without making it a package level variable or returning it to the user in any way. Eg - https://play.golang.org/p/puXOMfXQbyo - this doesn't require us to give the user the time at all, but we have access to it at teardown.
&gt; Have you seen this before? Is there any drawbacks for using this technique? Yeah, it flew by my radar a couple of times :) Personally, I don't consider it very readable, it requires you to disentagle the parens and make an internal argument about what evecutes when (evaluation order of defers and all that stuff). I think it's fine to use, but personally prefer to avoid it and expand it into `cleanup := Setup(t); defer cleanup()`. It's not that much more to type, but far more obvious what is happening and why.
Right, I think short vs readable is the main fight here. 
Right, are there any other proverbs like this one ?
It always is :) And I will always err on the side of readability :)
Seems pretty similar to something Rob Pike had on his blog https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html
Or, you can turn it inside out: type test struct { x int } func wrap(t *test, meat func() error) error { t.x = 3 // setup defer func() { t.x = 1 }() // cleanup return meat() } func main() { t := test{} wrap(&amp;t, func() error { fmt.Println(t.x) return nil }) } 
That's why you should use DB.SetConnMaxLifetime() always.
I was under the impression that Undertale drew most of its inspiration from Earthbound, so this was new to me. Cool.
As someone interested in both Golang &amp; ML, this is nice. Thank you! PS. How much slower would you estimate CPU is, compared to GPU? 10x? 100x?
I will add them soonish. I haven't yet cos I was in a hurry. As for the package, no there's no reason. Probably a habit that fell through from my PHP/Java days.
Well generally, neural network training/prediction can be pretty much entirely vectorized and GPU:s are amazingly fast for that type of linear algebraic operations, for big networks it's not even close. But on the other hand, if your model is very small, then the overhead of passing everything to the GPU might be unjustified, so it's hard to give an exact approximation.
I have a very general question founded in a real need but a very limited understanding of neural networks. üòÅ I need to write code that can determine if items in a set are correlated. For instance, if I have a sets "Bob Alice Tim", "Bob Mike Jim", "Bob Tom Tim" , "Bob Tom Jim Alice Tim" then I think the strongest correlation is between Alice and Tim since they always appear together (in a larger set maybe they are together 75% of the time). However, Bob isn't correlated to anything much more than Tom because Bob is in a set with everyone and Tom is only in one set, so there isn't much relevance to any measurement. Is this type of library the correct way to go about measuring correlations like this?
Can this be used with time series data?
Ah i see! This makes sense but i would put a comment there, for later ;) 
I think you're looking for a recurrent neural net then, i.e. one that implements some notion of ‚Äòmemory‚Äô, so this wouldn‚Äôt work in that case.
For most normal users, forums don't need much - the most common case seems to be running something for your friends on a really small droplet (I believe that this case is something that discourse optimized around). That said, quite a few businesses run large scale forums with huge numbers of simultaneous users and in those kind of setups, the ability to scale and perform is $$ (although usually less than the pain of something that's a nightmare to administer).
Awesome! Hopefully that'll help others understand the use case for this. My apologies if I came off aggressive, I really am only interested in the technical aspects.
I use the "return a function to be deferred" pattern quite often in my own private code, especially when I'm writing test code, but I've resisted putting it in the public interface (i.e., "what godoc shows") of any of my modules because of the lack of a way to indicate that very clearly. In public I tend to stick to return some object that has some cleanup method, which is usually "Close" since there's probably something we're closing since most resources that _must_ be cleaned up can be "closed". Even then you may have to document that .Close() is mandatory and there's still no way to enforce this, but at least that's a semi-standard thing.
This is really neat -- thanks for sharing it! I have mixed feelings about this, though. I've been building side-projects myself, to shift my career towards data engineering (after a loooong time doing enterprisey stuff with the occasional fun thing like accessibility or early IOT)... But I keep falling in love with and getting side-tracked by Go. Thus wrecking my chances at finding a job in the US. But at least I'm having fun! =)
In training a nn, all you're really doing is presenting it with some data along with the result you would expect from that data. So if you‚Äôre creating an estimator for the XOR function, you‚Äôd present it with pairs [0, 0] =&gt; 0, [0, 1] =&gt; 1, and so forth. In your case, you‚Äôre looking to find the co-occurrence of two items, or the probability of two items occurring together, so there‚Äôs no such ideal output you could present to a supervised algorithm. I think you could use something much simpler though, like calculating a matrix containing the number of times each pair co-occurs in a set. Then it depends a little bit on what you intend to use it for, or what exactly you are trying to accomplish. I have another go library [go-topics](https://github.com/patrikeh/go-topics) which does something like that - it uses bayesian inference to find topics (of words that co-occur in different documents). But that algorithm a little bit iffy to use since you need to specify the number of topics before you compute them. :)
Related: [Start a conversation about ipfs/gx-style imports in dep](https://github.com/whyrusleeping/gx/issues/141) [Support for private/enterprise patterns](https://github.com/golang/dep/issues/286)
In that case, I'm probably too off topic and don't want to hijack your thread, but I'm trying to do a mass analysis of code so that I can measure "related" imports that aren't necessarily dependencies but where one library being present indicates that library Xyz is somewhat likely to also be used. It sounds like this is indeed not a neural net problem, though.
lol no generics
Number your libraries, one input neuron and one output neuron for each library.
interesting, thank you!
&gt;What else should I learn that would make my resume more valuable? Did you try attending college ? Having a [B.Sc. CS](https://en.wikipedia.org/wiki/Bachelor_of_Computer_Science) is quite sought after.. Gives your employer confidence that you are not just another bozo who "learned programming online in 21 days"...
Does this mean parts of InfluxDB be written in other languages in the future?
Most interviews today revolve around problem solving involving data structures and algorithms. Using Go as an implementation language, solve as many problems as you can and keep trying. The real learning will usually happen on the job with real world problems. Reading distributed and scaling problems will help. Since most companies are either implementing new products or trying to scale existing products, knowing the problem space will help.
Distributed and scaling stuff is something I'd like to learn about. Do you have any good resources?
Just stumbled upon this post after a LONG debugging session of slow GC. I have a large map of type... map[string]*CustomStruct Would this be better as a map[int]*CustomStruct at all?
Some links to get start on distributed problems: * http://www.kegel.com/c10k.html * https://dataintensive.net/ * https://raft.github.io/ For high performance concurrent programming: * http://concurrencykit.org/ * https://www.goodreads.com/book/show/3131525-the-art-of-multiprocessor-programming
http://theartofscalability.com/ is generally interesting, not just technical, imo.
Designing Data Intensive Applications is a recent modern and approachable book on practical distributed systems. Checkout Aphyr‚Äôs blog as well, Distributed Systems for Young Bloods. I recently went through interviews and had a few take home projects that were in Go. You can try those if you‚Äôd like: - Build a simple cache server that uses the Redis serialization protocol to work seamlessly with a Redis client for simple command like Put/Get. It should have a TTL mechanism and process requests in parallel. You‚Äôll need to come up with an eviction strategy (if this doesn‚Äôt make sense lookup LRU). On cache misses it, it hits a backing Redis server (you can use a library for this). It should be configurable via envar/config. - Build a wiki tracing service that finds a path between two articles. You should focus on wall clock time, not the shortest path (these are related though). Key here is to execute many paths in parallel and come up with a way to sync the threads. For both of these you should have logging, simple metrics and I‚Äôd suggest a Makefile for building it. Even better a Dockerfile / Docker-compose that brings up all the pieces for local runs. These were to just get an interview, which was 5 hours of coding / algorithms. Unfortunately, companies don‚Äôt really look for outside work, you‚Äôll need to pad your resume with 2-3 jobs. If you‚Äôre just getting started, find a company hiring ‚ÄòJunior‚Äô engineers and work on their front end code if needed - once you have 2 years+ experience you have more mobility. My experience: Amazon for 2.5 years (Java), freelanced for 6 months (Ruby, JS), startup for 2 years (Clojure), SoundCloud for 3 months (Scala- RIP) and now I‚Äôm at a huge startup in SF working in Go.
Likely to save space 
Isn't the fix to simply `vendor/` your dependencies?
Designing Data Intensive Applications looks great. Thanks for that!
I've seen this book before. It's a good book, but not for me. Thanks for replying.
You can enable verbose gRPC logging with something like this: import ( "google.golang.org/grpc/grpclog" _ "google.golang.org/grpc/grpclog/glogger" ) func main() { grpclog.SetLoggerV2(grpclog.NewLoggerV2WithVerbosity(os.Stderr, os.Stderr, os.Stderr, 2)) // ... }
I haven't graduated yet. I just started looking for a job for after I graduate. So I'm just preparing myself for the future. Google isn't gonna knock on my door any time soon lol. My fixes weren't anything huge. In fact, my issue was the very first issue filed. I needed it done, so I submitted a fix as well. It was a 7-10 lines fix.
Damn! You have worked at big places. I understood the second project - that's more of a data structure and algorithm problem, along with a bit of scraping. The first problem though - that's what I see companies doing, and I don't have a clue about it. It seems like pretty low level programming. What were you interviewing for that they gave you this project? What if I say "fuck it" to other stuff right now, and completely focus on learning AWS? Should I do that? Certifications are often neglected, but I've heard that AWS certifications hold a lot of value. Is it true?
Yep. Fully agree. I have actively pushed users to just use net/http for simple requests instead of using Elastic. Elastic, at its core, is simply a DSL and a connection pool/manager.
I was interviewing for a mid-level backend engineer role at analytics company. I‚Äôve had a very unexceptional run at things- most of my coworkers are Ivy Leaguers with multiple FANG entries on LinkedIn. One of the worst programmers I‚Äôve worked with had a Stanford &gt; Facebook &gt; LinkedIn pedigree and could barely send an HTTP request from one service to another. It‚Äôs mostly fake it til you make it and familiarity. If you‚Äôd like to see my proxy implementation you can check it out here: https://github.com/eastside-eng/redis-proxy Maybe even simpler just build a simple HTTP service from scratch (like an in-memory key val store) using net.Conn‚Äôs TCP primitives available in Go. Once that works figure out how to turn that request into a Redis byte-formatted byte array, etc. 
See [Effective Go](https://golang.org/doc/effective_go.html#defer) for a slightly different approach.
Just start interviewing, and don't expect things to go your way immediately. It sounds like you've got a very solid base for a position as a junior dev, but your fitness for a job and your ability to interview and get the job are very different things. If your school offers any kind of interview help or prep, I'd check it out and look for online resources that describe the technical interview process at various companies, and start practicing. Definitely try to get a few interviews under your belt just to get accustomed to it, and don't stake your self-worth on the outcome of any interview... it's a crapshoot even for some of the best people.
It sounds like you're already qualified for a programming job. Apply to a few places!
You sound like you're as prepared as you can be, and a bit more honestly, for a job search. If you aren't applying, start. If you are applying, you may want to spread your wings a bit. One bit of advice I find I have to give is that even when the job says "Requirements", it still just means "Our Wish List". If you meet 6/7 requirements, apply. Also, try showing up to your closest Go meetup. In terms of _learning_ something, I'd recommend learning a dynamic scripting language. Python is probably the best choice. To be entirely crass and money-motivated, you get diminishing resume returns by going deeper and deeper into one tech. Spread out. Don't ever claim more experience than you have, and don't claim to know a language you don't know, but being able to show you have a dynamic scripting language will really show that you are a well-rounded developer, not just a one-language wonder.
Where by "language framework", the author means "web framework".
I ran into something like this the other day. I took off the locolhost portion of the listen call and just left the ":port" portion and it fixed my issue. 
I saw on the twitter TobyFox and the author of MOON taking a picture together. (Toby with a dog face of course.) Btw, I am Daigo working with hajime.
Aha, excellent point. Glide would have the same problem as far as I understand.
Yes, write a method that does exactly that.
The method has to accept multiple types as a parameter.
It is possible with reflection but you would lose type safety and it is very anti-go. You would be better off writing 3 distinct functions or using code generation to create those functions.
Yes, sorry, i didnt read the question correctly and thought you wanted something like `Update(x, y int, z bool)` - which is still possible but not as nice as the version with the extra struct.
You can use functional options to "simulate" the behavior you want: type Option function(p *Person) func FavoriteFood(food Food) Option { return func(p *Person) { p.Favorite_food = food } } func FavoriteColor(color Color) Option { return func(p *Person) { p.Favorite_color = color } } func (p *Person) Change(options ...Option) { for _, setOption := range options { setOption(p) } // finish up with p } // // use like this // p.Change(FavoriteFood(food), FavoriteColor(color))
One option is to define an interface like this: ` type FavouriteSetter interface { isfavourite() } ` and then have e.g. the `Food` struct implement it: ` type Food string func (f Food) isfavourite()` and then you can pass it like so: `func (p *ParentObj) SetFavourite(s FavouriteSetter) { switch v:= f.(type): case Food: p.Food = v ... `
PGP-signed public attestation of what I had checked out and how it currently matches; I'm in no way affiliated with the current operator (AFAIK) but I hope that this will reassure people about the _current_ contents; if this satisfies you, then grab the current contents, vendor into your own namespace, and retain under your local control. Statement has a clearsign PGP signature, from a key in the strong set; dual-signed so GnuPG v1 probably will not handle it. https://gist.github.com/philpennock/3ced44038ee511f664a55b13e0be6bed
Hi everyone, I made this tool that can analyze go binaries (limitations described in the readme) and generates a seccomp profile that allows only the syscalls that the binary actually uses. Any feedback is welcome. :)
Most golang developers are hired on for back-end micro-services, and as such... those employers are looking for somebody familiar with DevOps experience. Get to know Docker and Kubernetes. Learn and study cloud platforms and services from Google, Amazon and Azure. Get familiar with tools such as CircleCI or TravisCI, Helm, etc. Learn and understand editing YAML configuration files and Swagger. All those are important, and the next step I would look into.
I made it! https://www.meetup.com/van-go/
How do you differentiate between "a" + "b", "a‚Äù + ‚Äùb" , and ‚Äùa‚Äù + ‚Äùb‚Äù ? I think it's better to be consistent and report an error in the last case, than trying to guess the users intent.
gofmt can only format syntactically valid code and if you have invalid quotation marks, it won't be valid. I'm not saying that there isn't space for a "we try to implement heuristics to parse invalid Go code that are robust to this and then pretty-print the guessed AST" but I don't think it should be gofmt; if nothing else, then because gofmt should always preserve the syntactic meaning of a program.
Epic! Attending, thanks :) 
+1 for the help, but can Go really not parse a basic RFC 3339 spec date out of the box? This is not an uncommon way of representing dates across APIs and data formats.
Set the type of Date to string and handle any parsing needs afterward. time.Time does not play nice with XML unmarshalling. type Schedule struct { Date string `xml:"date,attr"` } func main() { validXML := `&lt;schedule date="2018-01-01" /&gt;` s := Schedule{} xml.Unmarshal([]byte(validXML), &amp;s) fmt.Println(s.Date) parsedDate, _ := time.Parse("2006-01-02", s.Date) fmt.Println(parsedDate) }
I'm a dev in the US that uses Go at work. Jobs exist!
time.Time is a common format for all time types, so it's picking a default to try and parse and failing in this case. You'll need to define UnmarshalXMLAttr on a new type (or as a struct member) and then use that type as part of the unmarshal: https://play.golang.org/p/_LOw1xB6Uxt
Thanks, this is very useful.
First, good work on your open source commits! As a senior developer, most of my contributions to open source wind up being documentation, which is less impressive and less sexy than a few lines of code but still important. It sounds like you're living a life that will bring coding success, and it's possible that the bigger challenge to preparation (most of what you learn will be on the job) will be simply knowing where to look. Second, if you're living in Seattle or California, then you might be able to find some entry Go positions. In the midwest and south I think a midsize town probably only has one or two companies using Go, but Amazon, Microsoft, Google, Basecamp, BBC, Bitly, Canonical, Clever, CloudFlare, CoreOS, DigitalOcean, Digg, Docker, DropBox, Facebook, GitLab, Hailo, IBM, InfluxData, Iron.io, Intel, JustWatch, Lyft, Medium, Minio, Mozilla, NY Times, OpenDoor, SendGrid, SourceGraph, SpaceMonkey, StackExchange, Twitch, Heroku, CloudThing.io, Husar Labs, and you can't forget the Kubernetes team in Colorado! If you aren't on the West Coast around some of the big companies using Go, I'd recommend making sure you start working in C#, Java, or maybe Python positions while pursuing these personal and open source Go projects if you don't find anything quickly. Go is awesome, but since there are fewer developers and fewer jobs, an employer using Go is still look at your dev experience as a mark of an experienced developer, and all of the Go positions I've seen are looking for experienced developers. Finally, don't hesitate to apply to big name companies. The way their hiring works, apply and keep applying to new positions all the time! I used to think employees of Google, Microsoft, and Amazon had a whole different level of skill and prowess, but over time I realized that everyone is just a normal person learning their job and craft. Apply to jobs at big companies, and keep doing so. My best friend wound up getting hired at Amazon and relocating to Seattle from Michigan based upon a resume that was 4 years old (from when he first graduated college) and somehow triggered a call that wound up launching him into a role in Amazon, then Microsoft, and now Google! I happen to think he's fairly smart, but he's just a normal guy who doesn't flinch at applying to roles that take him a leap forward in his career.
doesn't need to be complicated: https://play.golang.org/p/QvG_tChT00M
http://fuckinggodateformat.com/
http://fuckinggodateformat.com/
I get the Go way of date formats, but this is an RFC 3339 spec date (and an ISO 8601 date) and it's more than a little surprising that Go's XML parser cannot properly deserialize these out of the box. It really feels like missing the forest for the trees.
&gt; You are basically on your own for all attributes fields I don't follow. Do you have a large variety of different datetime formats you're trying to parse? Most attributes I imagine you'll be unmarshalling into a number or string or similar and that will work. You can reuse this type anytime you see a date in that format and it will parse correctly. 
I'm saying this because Go will already automatically parse other dates, and this particular format is called explicitly in RFC 3339: https://tools.ietf.org/html/rfc3339 ```full-date = date-fullyear "-" date-month "-" date-mday``` I'm surprised because it seems like a very arbitrary decision and is not one I've typically encountered in other languages. I know that Go can parse arbitrary formats, but given that the XML parser will automatically convert other date formats it doesn't seem unusual to expect it to handle a standard.
I actually do have a wide variety of date time formats to parse; these are television schedule files that are used around the world, and have different types of dates and times in them.
Yeah that's a part of the ABNF format given for the standard, which is this: date-time = full-date "T" full-time It'd be a bit strange for a standard called "Date and Time on the Internet: Timestamps" to define a standard for just dates, no? I think that's where the disconnect really is here: you're expecting a timestamp type (called time.Time) to handle a format which omits time. I'm curious what other formats it automatically converts - seems to me it (ironically) tries RFC3339 timestamp and then fails if the passed value doesn't conform. 
No problem - given your usecase this is going to be a bit more painful than parsing xml normally is. Thankfully you'll only have to do this once for each different kind of time you see. 
Yeah, my mistake in a misreading. ```Pretty much, yes - RFC 3339 is listed as a profile of ISO 8601. Most notably RFC 3339 requires a complete representation of date and time (only fractional seconds are optional). The ``` An assumption I had from working so long with ISO 8601, where just a date is part of the standard (as well as just a time, and a combined datetime). A bit frustrating, as there is a lot of data out there in the world that is bound to a particular day but not any particular time of day.
i tried that hiwever it didnt help
Agreed - given your use case I can see why this is frustrating. If you get things in formats other than XML, take a look at UnmarshalText. That's what's being used in this case, as it's defined on time.Time: https://github.com/golang/go/blob/master/src/time/time.go#L1249
Have you checked out [Gorgonia](https://github.com/gorgonia/gorgonia)? It's like TensorFlow but written in pure Go. 
Why not have a function that accepts a Favourites struct, and returns the difference? You can apply the changes and take whatever action you want. If anything has changed you can react however you want. No reflection needed, I like the type safety so I would rather have a few extra lines of code. https://play.golang.org/p/miB9NpI1LUN I would probably go about this it a different way myself though.
&gt; I am only proposing that we replace them when they are used to open and close a string and **the code won't compile without the change**. Emphasis added. Working code shouldn't change ever - chances are it was intended. It is when code DOES NOT work that I suggesting we do something a little nicer than simply failing. Even if we just showed a better error message at compile time it would be a step in the right direction, but I'm not certain that the compile tool is the right place for this either.
Sorry to hear that! I hope you find a solution. 
Creating a top level comment to try to help explain *why* I think changes like this matter. I talk with a lot of newbies to programming who are learning with Go, and this is one of those things that can confuse them quickly. As I said in another comment, I'm not 100% sure that gofmt is the appropriate place for this, but ideally I'd love to see some tools designed to help newbies out with really common mistakes. Maybe it is a gofmt-esque tool that we teach people about early w/ Go and it helps output common causes for errors. Maybe it is something else. I'm not sure, but I'd love to see us doing more as a community to make it easier for newbies to debug common errors and mistakes.
This is at once astonishing and horrifying, well done.
[removed]
Oh man, no it's not! If you use dep (and probably glide as well) any update to your manifest will still fail because the repo is not available. On a partly separate note, I really don't understand why people seem to think that forking (or vendoring) every dependency is a reasonable solution. Somehow a lot of Go people seem to think that centralised immutable package repositories are somehow useless. 
Have you seen gometalinter? I speak to the general thrust of your point, not the specifics, since I'm not sure there's anything that will do that. I'm pretty sure none of those are supposed to modify code. But I think it's relevant to what you're getting at, and I'd like to see if you know about what already exists. ("No" can still mean there's a problem, but it's at least a conversation starter.)
Apart from what /u/Jelterminator said, the community server can protect you from changed tags in case the repo is lost and new tags created with malicious code. Expecting GitHub, bitbucket and a bunch of other services to prevent user deletion, re-signup etc is not a viable option. Even if behind the scenes the community server does exactly that, fork and keep the correct copy. It's still better than having no protection at all. 
So what do you with the last case? What rule do you follow to find the start and end of string?
will try that good to know I cando it, I am still new to gRPC thanks
I think the best place to do it is in the IDE. Tells them what's wrong as they write. 
Gonna be a much nicer experience now than it was before
You »ôti need to sign the CLA and use Gerrit for code reviews. Just code will be committed to Github. 
Learn how to write good cover letters (i.e. the email/message body for your job application). This probably matters more than your Go knowledge. 
What a time to be alive!
I'll learn AWS now. Thanks!
I have internship experience in machine learning with python. So I've got that covered. But machine learning didn't interest me much. I still have 5 months before I graduate. I think I'll learn AWS now while I look for a job.
There is no scenario in which you would not have to sign a CLA. Also it doesn't commit code to GitHub. All code is committed to Gerrit and mirrored to GitHub.
&gt; That assumes there is a Gopkg.toml. Without a dependency manager, it could be implemented at github level as /u/freman suggests.
gx looks very interesting, but renaming imports has been and continues to be a major pain point. :( If that were an option, centralized immutable package hosting server would have been my first choice.
The only pain point I see is handling non-go repos that will end up coming through this route, but other than that this (entire github.com) is definitely better than doing it for each and every package in my gopkg.toml file. We need to find ways to do it with other version control systems as well though.
Just to recap: you're still finishing your degree and want to know what to learn to increase a chance of getting a job afterwards. No (reasonable) company expects a fresh grad to know things like AWS. Not that you shouldn't learn it but it's unlikely to significantly improve your chances. There are 2 things you should focus on: 1. improving your chances you'll be invited for an interview. You're already doing that by creating your own projects. Don't forget to "market" those project. Create a website for yourself, add projects/portfolio section, describe the projects there (link to the project, why did you write them, if you had to solve an interesting programming problem, describe that). Basically do a little bit more than just linking to github. Also connect with other people in person. Go to Go meetups, talk with people about what they do, talk about what you did and if they work for company that happens to be hiring (which is quite often in such places), make it known that you're for hire. Create a profile on hired.com (I got a job via hired once). 2. improve your chances of passing programming interview The standard coding interview is heavy on algorithms so practice as many basics as you can. Use a website like https://leetcode.com/ (there are others like that) to practice algorithmic questions. This is much more important that learning some specific things like AWS or distributed systems etc.. In new grads companies look for strong fundamentals (i.e. know your hash tables inside out). Specialized knowledge about technologies is expected from senior devs who have worked in a given field for some time. Also read https://triplebyte.com/blog/how-to-pass-a-programming-interview and https://medium.com/@nickciubotariu/ace-the-coding-interview-every-time-d169ce1fd3fc for more tips. Finally, at some point you said that "Google isn't gonna knock on my door any time soon". Actually, Google hires a lot of new grads. You should definitely apply (see if your university can help you with that - Google does work with universities). If you get the interview and do well on coding questions, you'll get the job. In the worst case, you'll get more experience interviewing and you'll be able to improve things you were weak on in future interviews.
Just did, felt amazing!!
You got my queries absolutely right. The thing you said about algorithms, I did try it once. I see a lot of people getting into competitive programming after learning about data structres and algorithms. But that path really frustrated me. I'm not saying that you are wrong. You are correct, companies keep stuff about solving algorithms as their first round. I have experienced it as well. But if I start learning data structures and algorithms now, I would feel completely unproductive. I have the basics clear like what algo to use in what situation. But I couldn't code it just by thinking about it. I ever need to code it, I'll just look it up. I would much more prefer to got a job by learning and doing something practical, like I've been doing it so far. I'm in my second internship. I got both of my internships by displaying my knowledge of different techs. I know it's a hard and unconventional path, but that's what I want to try. I'll definitely create a website like you said. Marketing myself more, that's what I should do. Thanks a lot for the well written reply. I really appreciate it.
I'm more of a func wrapped(t *testing.T, fn func()){ t.Log("Setup Stuff") fn() t.Log("Cleanup Stuff") } func TestStuff(t *testing.T) { wrapped(t, func() { t.Log("Test Stuff") }) } fan.
&gt; Even if we just showed a better error message at compile time it would be a step in the right direction It is an ambiguous case, so an error message with potential fixes is likely the best solution. Hence me proposing better error messages when we can't automatically fix without ambiguity.
&gt; How about sed? Guessing you didn't read my comment explaining why I think changes like this matter. I think that we as a community could make Go more welcoming to newbies to programming by finding ways to make confusing and common errors easier to debug. sed isn't likely to help new programmers since they probably won't even know what is wrong in the code let alone how to use sed to fix it (if they aren't on Windows). It sounds like gofmt isn't the right place for fixes like this, but I do think there is space for improvement here and it should be explored. 
I think every case is an ambiguous case, as the compiler can never be sure what the user intended. This is why `gofmt` never does anything on compile errors, even though it can be reasonable sure that: if true { // ... } should have been: if true { // ... } Remember that `gofmt` is intended to be run on code *all the time* while people are developing with it. The fault tolerance for it is basically zero. I don't think it should ever touch code if it's not 100% sure what to do. By the way, another good example might be something like: fmt.Sprintf(‚Äú%s‚Äù is not valid", v) Here the user simply forget an opening `"`, but your proposed `gofmt` change will now hide this by changing it to something unintended: fmt.Sprintf("%s‚Äù is not valid", v) there are probably many more cases like this to be found.
Hi, Firstly thank you for your nice reply. We need to stream the data via the socket, not in web API way. After researching two or three days. It turned out very difficult to get get data from third-party socket by Golang/Echo. We decided to go with nodejs. And everything is working now with a small Nodejs Crawler. I will put the code to githup soon. 
Are there _any_ examples of instances where gofmt will fix a piece of code if it doesn't compile? I believe this is actually in gofmt's core philosophy; it doesn't operate on uncompilable code. Each of the go tools solve a very specific, bounded problem domain. - go compiles code, and reports uncompilable code. - gofmt formats existing code without changing logic. - golint reports possible non-logical style errors - govet reports possible logical errors.
hey! A gist of the code (or an example of what you are trying to do) might help! 
Right, my bad. [Here's the main parts](https://www.pastiebin.com/5a7d4511d1ed8) There's obviously more to it, those are just the parts I felt mattered. I tried to Println from the FindCountry function 
Well I found the bug. Thank you for the prompt response at 2 am almost, much appreciated.
Hey! I'm glad you found it. Does the answer look something like the gist below? https://gist.github.com/dewey4iv/c017ea69fbf6a62782c294a0c9f57527 
I think the github clone url should be like github.com/user/repo/uuid.git, where uuid is a 11-character string (learned from youtube). Here, "user/repo" is just for readability convenient and is optional.
I am glad you got it working!
I agree that having a (say) `gohint` tool for such things would be nice. The central problem though, is that what you are suggesting would require heuristics. A Go parser works on the Go grammar, so that people can unambiguously state what they mean; the grammar specifies what is valid and what is not valid and the parser knows how to understand that. Things like "using the wrong quotation marks", however, require a tool to *guess*. It can't rely on a grammar anymore and if source code does not conform to the Go grammar, it is inherently ambiguous what was meant. This is why this shouldn't live in gofmt: This fix would have to guess what was meant and would inherently *sometimes* guess wrongly. We can't have that in gofmt - heck, I would even go so far, as that *no* tool should just do that rewrite, but should instead maybe provide a hint or show a patch to the user and ask them if they want to do that substitution. In essence, solving this is *such* a hard problem - both algorithmically and from a UX perspective - that the difficulty seems incommensurate with the payoff, even *if* that payoff is non-trivial. If someone feels more optimistic about the possibility of such a tool, then they are welcome to try; and if they succeed, I will be impressed and do my best to lobby for that tool to be officially supported (and maybe integrated into the standard distribution of Go, to make it more visible to newcomers). I'm not trying to dissuade anyone from doing it, just that a) it doesn't belong in gofmt, but into a separate tool and b) I think you are underestimating the difficulty of the problem. Proof me wrong :)
(oh and FTR: I also disagree with the people who say this should live "in the IDEs". I'm a huge fan of Go's approach of having separate tools that can then be *integrated* into different editors/IDEs/whatnot. It means that no one is bound to a particular IDE to take advantage of a functionality)
Yes. &gt; We need to find ways to do it with other version control systems as well though.
What was it, out of curiosity? I'm taking a compilers course right now, so I'm really interested in what contributing to Go in this sense would look like in context of some of the stuff I'm learning. If someone wanted to add generics, for example, where would they even look to start that? We're doing type-related stuff right now (building symbol tables, checking type rules, so obviously nothing terribly advanced) so I'm interested in what this stuff looks like in a more real context.
The Go compiler source code is very readable compared to other programming languages. The runtime is a bit messy but you are focussed on the compiler so shouldn't be a problem. Have a look into the "cmd/compile/internal/ssa/gen" folder. That contains the meat of the logic regarding opcode gen and rewrite rules. To add generics would require making changes to the language syntax and scanner. Perhaps the "internal/syntax" folder might help you out. A very helpful approach is to look through CLs made to that folder. See what changes have been done. Start by making small changes. When you feel comfortable, go big !
Not gonna lie, that attitude is badass though. "I needed it fixed, so I fixed it."
While blockchains have their uses, most of the jobs around them are barefaced Ponzi schemes. If you are going to learn something, learn Kubernetes, and Docker if you haven‚Äôt already. You can get an AWS free tier instance and start familiarizing yourself with the environment. Learn SQL, e.g. on PostgreSQL. It‚Äôs a basic skill that is often poorly taught in university. Where are you based, and where are you planning to move after you graduate? My company (based in San Francisco and Tel Aviv) is always looking for golang developers and has a pretty good mentoring system.
I‚Äôve been a hiring manager for 20 years, and cover letters are overrated. Much better to spend that time making slight customizations to your resume to show skills, can-do attitude and accomplishments relevant to the prospective employer.
&gt;Isn't that a part of the language itself? The words *language itself* to me sound like the specification, the parser, the compiler, or for other languages the reference implementation of the interpreter or runtime. Those I consider considerably harder to work on and contribute to than the standard library. So while the contribution is of course great, without knowing what it exactly was I can't call it *Google-knocking-on-the-door* impressive.
&gt; If someone wanted to add generics, for example I'd start by reading [the official proposal on generics](https://github.com/golang/proposal/blob/master/design/15292-generics.md). It's not as simple as just writing code :)
‚Ä¶‚Ä¶Why does this need to live on the blockchain? This seems to be pretty vanilla: Authority verifies the identity of the user, then signs the blinded public key of the user, the signed, unblinded public key then gets uploaded to Ethereum. But why that last step? Why not just: The user keeps the signed public key. When they want to authenticate to a third party, they provide the signature of their public key by the verifier and sign a nonce? There seems to be zero advantage to store this verification-token on the blockchain, if you can also just store it on the user's disk, alongside the private key.
Ok yes, given the circumstances then needs must :/
Thanks for this great article. I have read the updated version, with `dep`. Great to be able to read the state of the art of Go with a real example. Thanks for your work.
yes, true. The main idea was to provide a decentralized distribution system, with immutable properties. Where, for example an user can just reference to the data stored in the blockchain. Let's say, for example, a health system. The user can go to the hospital, and with a QR image printed in a card, or with an NFC card, references to the data that is in the blockchain. This was just a proof of concept of an anonymous (but verified) system, that can be decentralized thanks to the blockchain technology.
Thanks for the link :) Good to know about Gorgonia.
Thanks for sharing üëç 
The workflow description on this page claims otherwise: https://github.com/golang/go/wiki/GerritBot &gt; Workflow &gt; * A user can upload a PR against any of our GitHub repos just as they would with any other GitHub project that accepts PRs 
FAQ and workflow description is here btw.: https://github.com/golang/go/wiki/GerritBot
This makes sense. Key distribution is a challenging problem for the layperson. 
ipfs? Like, none of what you are saying is screaming "I am afraid that a state-level actor could try to censor these". Especially as the state-level actor would instead just go after the ID verifier, which would be *far* more effective and efficient‚Ä¶
&gt; This was just a proof of concept of an anonymous (but verified) system, that can be decentralized thanks to the blockchain technology. Addendum: Note, that blockchains are the diametrical antithesis to anonymity. They are *all* about transparency and traceability‚Ä¶
yes, in this case, the blockchain is only used to store the Public Key of the user, to make an easy distribution of the identity. The identity is still opaque, and the user can prove the ownership resolving the challenges with the Private Key
Not that I'm aware. The only go vulnerabilities I've seen recently are CVE-2017-15041 and CVE-2018-6574. However, they are vulnerabilities in go get, not really related to execution of compiled go binaries.
I understand what you are doing. I'm just also saying that I believe that the blockchain is neither useful nor necessary for this. But anyway.
Sidenote, but why does twitter interpret readme.md as an url and thus directs user to whatever malware is probably there?
This has little to do with XML parsing and more with reading a file line by line and doing some string manupulation. Also, the JavaScript implementation is very callback-heavy. I'd be interested in a comparision where the JS version uses loops instead.
Yep definitely, and it looks very promising. I've had thoughts about if there could be some kind of super high level interface to gorgonia, like a keras in golang.
Frankly, so would I. I've been working on one that has a worker per core, where each worker simply takes an element and parses it. However, even when I use StartElement.Copy() to ensure that a worker receives a current copy of the element (as the main thread may have moved on by then), I run into XML parsing issues. This seems to happen because Decoder.Token() is only valid for any given element until the next call to Decoder.Token(). I have yet to figure out why Copy() doesn't seem to fix this, but I'll let you know when I have some progress on the issue.
It might be a vocal minority. I'm leaning much more towards a single place for packages to live. Preferably ran in some sort of official manner, but something like PHP's Packagist would be good.
It is a very minor bugfix for a regex pattern in `go get` vcses. Currently the [only open PR on GH](https://github.com/golang/go/pull/23755) No fancy compiler level work.
I'd agree with 85% decrease in processing time, but in terms of the increase in performance that would typically imply it's ~6.7x faster?
The list of TLDs is huge, and getting bigger every day. Weird functionality.
This post about [adding a keyword to Go](https://phfilip.com/a-short-guide-to-adding-a-keyword-to-go.html) from almost a month ago may interest you. Very to-the-point.
Inheritance is ugly and it is especially bad for beginners.
personally i like the thought process on what he/she is doing. decentralized distribution system where there is no longer one owner. This could easily be used with healthcare. lectorlector keep up the good work! 
great idea!
Nice idea, thank you for sharing.
&gt; Go doesn't support inheritance. It has a new and improved solution ‚Äì interfaces and embedding support code reuse and polymorphism. It's not new.
Goody gum drops!
&gt; decentralized distribution system where there is no longer one owner. blockchains are not the only distributed systems, they are not the only immutable distributed storage systems and they are not the only systems without a single owner. Blockchains have two advantages that other, cheaper systems don't have: Preventing double spending (which is completely useless here, there is no harm in having multiple signatures stored) in combination with censorship resistance (and even that, only as far as it regards censorship at the entry of the system - resistance to takedown is also abundant in other systems). So, no, sorry, this would not be an argument for using the blockchain. And all of that being said, it is not even *beneficial* here. I don't see a material difference in storing a reference to a signature in the blockchain vs. storing the signature itself. Signatures are small - very similar in size, in fact, to said reference. If you can carry that reference and the associated private key around, you can also carry around the signature. All you are introducing is an unnecessary roundtrip and dependence on the internet. &gt; This could easily be used with healthcare. I sure as hell don't hope so, given the lack of anonymity. Again, blockchains are the antithesis to privacy. Their whole *point* is, that any piece of information can be end-to-end tracked. If you want a anonymous, distributed storage, that is censorship resistant, upload it via Tor to ipfs. But really, just put the damned signature on the same smartcard that carries the private key and be done with it.
you are so passionate about this, i had to read this twice. I will think on what you said. 
I don‚Äôt wanna sound like a grumpy old man. But why is people writing blog posts like these? Creating a dead simple function and then make it run concurrently with goroutines, without any jazz... Why does that need a blog post?
The P in PKI is a hard problem, it's why PGP isn't more widely used for things like authentication. It would not be useful to simply store the key on your hard drive because you are omitting the entire point of doing so: creating a web of trust so others may authenticate your identity. Today we support this process based on participation in larger webs of trust like PGP [key servers](https://en.wikipedia.org/wiki/Key_server_(cryptographic)). Different key servers exist for different trust groups, no single public audit trail of these systems exists and due to the simplicity of the key servers it takes a very high baseline technical aptitude to _safely_ have a public key. You can't just store a "public key on the hard drive". You need to store it offline and have it never touch a computer that connects to the internet, using it _only_ to sign a signing key which you then sign additional keys for your devices. Now if a device is compromised you may revoke that devices key with the signing key. In the unfortunate event your signing key is compromised you can still recover by revoking that with the offline signing key. Note we have barely scratched the surface here. If your argument is that a user could provide a key to a website during registration and authenticate with it, how do you handle every scenario listed above? What happens if their key is compromised do they have to contact every single site they ever signed up for (given the process is so easy and the fact a general scheme will have general users- we should assume they won't log or audit this well). What happens when affiliates of these websites are provided the users public key for marketing / correlation, do you think the websites will properly notify every past affiliate when a key is invalidated? You are going to run into cases like this if you try to manage your identity relationships with each individual system. I am not saying that a block chain is the right answer, I would have to _REALLY_ think it through to see if any portion of it could be re-purposed for PKI. But I am saying that your answer is not feasible in the real world or it would already exist, and key servers wouldn't. I personally commend ops research here and think we should continue trying to think of ways to bring a cryto scheme like PGP to more than highly organized webs of trust comprised of technical users. Something like letsencrypt for PGP would be fantastic.. 
&gt; you are so passionate about this, i had to read this twice. I freely admit that I'm frustrated by the recent fad to put stuff on blockchains that don't actually benefit from it. Blockchains aren't *that* complicated. I feel that if you are developing software for the blockchain, you should be expected to have an understanding of what they bring to the table, whether that is actually beneficial for your usecase and what their real and potential harms are. If you start with an actual *problem* it's usually pretty obvious that "blockchain" is not even a remotely sensible solution to it.
It's sad that people don't see sarcasm when it's literally pointed out to them...
Yeah that embedding magic is neat. I'm not sure though I understand it's internals though. I tried with this. https://play.golang.org/p/1YOJVa3epD-
It's sad that people don't see sarcasm when it's literally pointed out to them
Hey there - I didn't downvote you but I also didn't pick up on your sarcasm. Next time use a /s ?
After so many similar comments over the time - this doesn't really look like as sarcastic one, sorry :)
For the Go newcomer, it is.
Using dates (without time of day) in business code is far more common than using dates and times together. In fact, dates are more common than floats, let alone complex numbers. There's a strong case to be made for having an easily handled date-only format in any programming language used for business. In fact, perhaps `2018.2.10` should even be available in the language syntax, i.e. if the number's got no dots, it's an integer, if one dot, a float, and if two dots, a date. So we could do: `2018.2.10 + 30 == 2018.3.8`.
Care to make a proposal for this?
You might find my Go [date-only data type](https://github.com/lpar/date) useful. It includes JSON marshaling and unmarshaling support.
&gt; //WHAT TO DO WITH ERRSTR, YOU CAN DECIDE I would have appreciated it if the article showed proper/elegant error handling. &gt; Why does that need a blog post? I tend to agree but on the flip side, the more articles we get about Go the better. There's no way to control the article quality anyways. I think a better article would be one that would compare using channels vs waitgroups for different occasions and mention pros and cons of each.
But then wouldn't that also inheritance new and improved for anyone who is a newcomer to a language that has inheritance?
Yes, use https://github.com/golang/dep
Don't be a jackass.
I don't think there's an all-in-one shot like you want short of deleting vendor and re-initializing it. `rm -rf vendor` `govendor fetch +e` 
Yes, they've already started to adopt dep, given all other package managers are started to be flagged as deprecated. Stop using anything else and switch to dep.
Got your point. Guess my previous comment was a bit off the mark. I think what the author means is that inheritance is a well-established paradigm whereas Go's alternative solution is---compared to inheritance---both new and improved. (For comparison: The concept of inheritance was first seen 1969 in Simula and gained popularity through C++ since 1985 and Java since 1995. Go 1.0 appeared 2011, and to my knowledge(*) it is the first language to combine embedding and interfaces for achieving code reuse and polymorphism.) (*) Disclaimer: I am not a programming language historian.
Huh..? The entire design revolves around key distribution, hence I used PKI for reference in how that is done. Your argument was to store the key locally, but that removes key distribution.. which sure makes block chain useless, but as I‚Äôve already explained your public key that no one trusts is useless as well. You are essentially arguing his design is useless by providing our own useless design. I don‚Äôt feel like you are giving this five minutes to decompose what it solves and just focusing on criticism to the blockchain aspect. Read my post, it describes a real problem. This persons work is an interesting and well thought out approach to solve it even if it has its flaws. Your analysis of it was overly simple and solves zero real world problems, in fact your ‚Äúsolution‚Äù could be considered the actual problem this person is solving: how to get the key from your disk into a ring of trust. You don‚Äôt have to accept this and are entitled to your opinion, I just don‚Äôt see any merit in it despite how passionately you seem to be about it. I have nothing else to add.
actually, I just switched to dep seeing that it's the preferred tool now, but dep is causing another issue. I have just one dependency and it's pulling down what seems to be an older version of it. Why is it doing that?
I did a quick search on GitHub: * [19k projects are using Godep](https://github.com/search?utf8=%E2%9C%93&amp;q=filename%3AGodeps.json&amp;type=) * [11k projects are using dep](https://github.com/search?utf8=%E2%9C%93&amp;q=filename%3AGopkg.lock&amp;type=) I think it's ready for use in production, it's actually incredible how well dep works considering what it does. Only once did I run into an issue because a project heavily modified code vendored deps (without forking), which is not something you should be doing, ever.
It may improve your life to know that you can rsync Git repositories.
If the project has tags then dep will pick the latest tag by default. You can edit Gopkg.toml and change 'version = "^1.x.whatever"' to 'branch = "master"' to always take master. Also "dep init" will write out an initial Gopkg.toml that will lock to you to the same major version. If you always want the latest tag version, you can just use a blank Gopkg.toml and then "dep ensure -update" will always move you to the latest tags. Or you can change all the version constraints to branch
Storage is cheap, almost to the point of being worthless.
Why not just create a new struct after unmarshalling the data with all the correctly parsed info? You don't have to pass the struct used to unmarshal the data directly.
working on it- golgi.
Except that everything you've just said is wrong.
I've been using godep and govendor on older projects. Switching to dep was seamless. I see no reason to go back. That said, I still have some projects that use Heroku and unfortunately Heroku still does not support dep, which is sad.
Ok :)
The point of the article is pretty clearly to quantify the popularity of several popular Go packages that, presumably, are of general interest. I'm not sure why you're so salty about this. Maybe this YouTube video will help: https://www.youtube.com/watch?v=L0MK7qz13bU
&gt; Using dates (without time of day) in business code is far more common than using dates and times together. Facts not in evidence.
yes, I'm absolutely agree with what are you saying. It's true, here the blockchain is not really needed. I just tried to do the proof of concept, to make it in a distributed way over blockchain, but, for sure, I'm agree with you, and for a 'real world' project, I'm agree to don't put this over the blockchain. With some friends, we always say a joke, that is 'blockchain all your problems' (here the meme https://cdn-images-1.medium.com/max/500/1*Y3ty23vRKnuaMrM4KNciEg.jpeg ) Thanks for your comments TheMerovius
Maybe if the Go community wasn't so actively hostile to anything with the whiff of "theory" or "computer science", then people wouldn't consistently get these things wrong.
There is a bug on the mobile site that doesn't render your superscript. He truthfully may not have seen it.
Not open source, but we used dep for our dependency management. We went from using scripts using git subtrees to dep.
Thanks!
Unmarshal the data into what? There are a couple of libraries that will unmarshal into maps/lists, but I was trying to stick with the standard library. One solution I've seen is to create an intermediary struct that you unmarshal into, but I don't really want a bunch of extra structs lying around who's sole purpose is to parse out a common data type before sending effectively casting it to the correct type.
The term "business code" is so broad that it doesn't really mean anything. For example, I work for a business that does event-driven workflow systems where precision is key; I hardly if ever deal with anything other than full timestamps of various formats. So in my business, your premise that dates are far more common than timestamps is incorrect. In fact, I don't even think your premise holds in the large, though I'd be open to that idea if evidence was provided for the claim. Go was designed for the express purpose of solving problems at Google for which C++ was being deployed. You can bet that if they frequently dealt with dates alone, there would be more default support for that. Any proposal for adding syntax to the language must clear a high bar, and with good reason. Google builds huge systems that are meant to last a long time, and so they'd rather trade some verbosity for clarity. Adding syntax necessarily makes the language more complex, and it is difficult to go back to simplicity once you start down the road you're suggesting. 
I used the term "business code" broadly so I wouldn't have to produce evidence, and there's no shortage of people willing to write up proposals for a language change to Go. In my mind, *business code* is accounting, stock control, banking and insurance, payroll, marketing reports -- anything with a turnaround of 1 day, the stuff originally automated in the 1970's. Dates are far more important than complex numbers in this sort of processing. I'm not saying Go's intended for these types of systems, just that there's a case to be made for inline syntax for dates in such systems (and suggesting that yyyy.mm.dd is the best format for it). 
Nothing like a zealot who believes in The One True Way(tm).
I'm confused now. Am I a zealot or a jackass? It's hard to know what I should be, if I'm honest.
&gt; I am going to compute the state every time I run a command (create-update-delete), yes. Essentially, then, instead of CRUD, you're bundling a write with every operation: "CR",R,"UR","DR". That's not going to scale.
Yes, by just using `go get` the library would be gone for you if you lost your local copy (since `go get` downloads the repo locally) Dep addresses that problem by using [vendor directories](https://golang.org/cmd/go/#hdr-Vendor_Directories). Granted, if you chose not to commit your vendor directory then you would largely be in the same boat as with just using `go get`. By using the vendor directory and committing it to your repo you save yourself from your dependencies being deleted, having breaking changes on the head of the branch, or having commit history overridden. Dep's documentation goes over some of the benefits of committing your vendor repo [here](https://golang.github.io/dep/docs/FAQ.html#should-i-commit-my-vendor-directory).
No, building the state doesn't mean you are writing anything. If you are interested to the subject, please follow the links in the post for an introduction to event sourcing and CQRS.
No, none of it's new. Honestly, people is this the first time you've seen this stuff??? Because this is all pretty normal.
Thanks for your interest. My first implementation was using XML parsing. I'm working on a version using XML parsing and go routines and will update the post when I have some numbers to show for it.
Yup :-) And as others have pointed out, I might be able to take advantage of go routines to speed it up even more.
Not worthless though especially as things add up. Not to mention having a smaller database in general makes lookup/insertion go faster. They're not going to archive every deleted username just because of the corner case of a popular repo owner deleting his account, someone else snapping it up and using it maliciously. You should be responsible for the third party libraries you use not the host. 
[removed]
If you're using consul, you can do something like: - set an environment variable for each container `SERVICE_8080_CHECK_HTTP=/api/v1/status` as an example to periodically hit the endpoint of your service - use consul's health api to check for any services that are down https://www.consul.io/api/health.html#list-checks-in-state - post to slack, do whatever
I had hanging problems on Ubuntu, `-v` helping diagnosing it though. It was a problem with git not being authorized to download from a private repo. Ending up having to cache the credentials and then run it.
So far I'm not seeing a reason for Go 2.x. The 1.x series is awesome. I don't think along the lines of, "... but language X has feature Y so I must have it!". I picked Go for the sum of what is offers, which includes what was left out. So many languages have "all the things", and it doesn't make them better in my view. I'm hoping for many more years of clean, uncomplicated, stable development with Go.
TL;DR - I'm looking to build tools to make debugging common errors easier. This is my first step - a website and a "database" of common errors (it's really just markdown files used to generate the static site w/ hugo). If you frequently experience an error in Go feel free to submit an issue w/ the error, or a PR with a new page for the site. Once I get some good data on the site I'm going to look into creating a `gofmt`-esque tool (like `goimports`, `gofmt`, and `goreturns`) to be added to build pipelines and help provide hints for common errors that occur at build time. After that I'm not sure - I could try to get something to wrap `go run` and suggest fixes, but I'm not sure if that would work well. Regardless, this site should be useful in its own right, even if other tools are never built.
dep is absolutely ready for production use. We use it on every project we have, with the exception of the few projects with native dependencies which dep doesn't handle.
The time table was roughly sketched out in the talk and blog post.
Great report! Would you mind linking to the issues you filed, so I can watch them?
[removed]
That isn't true anymore: https://github.com/heroku/heroku-buildpack-go/blob/master/README.md Been using dep on Heroku without any issues
Oh I hope generics never end up in go
I think Go is so good already that it ought not make any big changes for quite some time. Instead, a strong focus on performance would continue to pay off. Especially continuing the good work that's been done on the GC would be valuable. I especially would like to see Go be considered viable in areas where conventional wisdom says GC languages won't work - and that all mostly comes down to performance.
Go 2 is a *great* place to file feature requests that you don‚Äôt really want to deal with or discuss.
to everyone in the thread who are using dep. Could you please help me if there's anything I can do to achieve the following: [Gvt](https://github.com/FiloSottile/gvt) lets us define an import path different from the download path. e.g. Download path: github.com/user/pkg Import path: user/pkg It's just something we require in my company, I know it's not a standard usecase, but we need it.
I tried to use `dep` in a Goa project. My only issue is that `dep` does not handle binary tools like the goa binary, which is a dependency if you have to use Goa. So, if your project uses protobuf or other codegen tools which require a binary to be executed from cmd line, you won't be able to use `dep`. The only way around this is to use virtualgo - which to me is a bit of an overkill. Hence I went back to usual go-get style. Relevant discussion here - https://github.com/golang/dep/issues/1572
Fair enough. Thanks for the links!
I shifted the Go project I'm actively maintaining to it. No issues.
Do you mean something like this: https://golang.github.io/dep/docs/Gopkg.toml.html#source
I found it hangs under the following conditions. 1. You have circular dependency issues at the repo level. 2. Large submodules in your dependencies. 3. Github credentials not cached, no ssh keys. 4. known hosts file is not updated. We just fixed these issues in our CI/CD and common repo and it works great.
You're being downvoted, but you're absolutely right. 
As an aside: if you depend on a library you don't control, try to create a fork of it and depend on that instead. I know it kind of blows having to maintain a fork (as in, bring in new commits every now and then) but if the functionality is key to your product, it's much better than having the dependency disappear one good day.
Dependency management is one thing I've never disliked about Go. All these dep tools cause more problems than they solve in my experience.
When Go doesn't have generics, and you have to implementace them yourself. https://medium.com/@arschles/go-experience-report-generics-in-kubernetes-25da87430301
Auto-update and staying safe from force-pushes or compromised accounts are at odds with each other, at least without signed releases (and there are probably several threat models where signed releases aren't sufficient). The best thing you can do for this case is to vendor your dependencies and update only to commits you trust. I like gvt for this.
I mean auto update of the forked repo from upstream not in my vendor directory. If I vendor my deps, upstream can still be deleted. So I need a fork.
It's really dissatisfactory, that the author of that post has not replied to [my comment](https://medium.com/@Merovius/aiui-runtime-object-7504a600dd09) yet. I remain convinced that this problem has nothing at all to do with generics and is based on a fundamental misunderstanding by the author.
Although I wouldn't use it often, it would be amazing for low level libs
It's not your prompt?
Doesn't the lock file protect you from having breaking changes on the head of a branch? If you did tell dep to update your deposit thought it worked like most other package managers and got the same commit when you run ensure again without updating.
This is simply not true, you still have issues when a dependency is deleted or force pushed. You don't have these problems at build time anymore, but when you ever want to add or update a dependency you still have this problem. Dep can then not reach the repo or find your pinned commit, so the solving fails. 
If you have an immutable central package repository where people are not allowed to delete published versions then you do not have the left-pad problem. Indeed npm was little better than github.com, but you don't have to make the same mistakes as npm when you create a go package repository. Take a look at crates.io for something better: https://doc.rust-lang.org/cargo/reference/publishing.html#managing-a-cratesio-based-crate Your argument against centralised package management is basically saying: It can still be fucked up and then it will be as bad as what we have now. So let's not even try to fix it. 
Oh boy, yes!
I don't think so. My prompt ($PS1 environment variable) looks like this: `%{%f%b%k%}$(build_prompt)`. And actually on daily uses I don't see percent sign in my prompt - I'm using agnoster theme from oh-my-zsh. But, you may have right, as after adding another defer defer fmt.Println("DEFER 3") defer fmt.Printf("DEFER 2") defer fmt.Println("DEFER 1") I don't see this percent sign anymore. I don't understand what's going on but thanks to you I think I'm on the right track :)
ZSH prints the `%` with an inverted background colour to warn you that your last line of output had no newline character. See the PROMPT_SP option. http://zsh.sourceforge.net/Doc/Release/Options.html#Prompting
Unpopular opinion I know but I strongly agree with Merovius. Too bad the author never replied.
[Typical.](https://www.reddit.com/r/programmingcirclejerk/comments/7wkmbc/dependency_management_is_one_thing_ive_never/) :-/
I'm not missing generics. So far building real projects that have real users/transactions etc I've survived with composition and interfaces. 
I suppose you could use the [reflect](https://golang.org/pkg/reflect/) package although it really isn‚Äôt meant for this purpose.
Simple project. I would appreciate if you take a minute to review the code. Open to pull requests, github issues, or send me a message here. Thanks guys :)
I‚Äôd struggle with dep, especially when trying to pull in sub packages. It‚Äôs unfortunate, but the only way I can get it to work reliably is to remove vendor and Gopkg.* and do dep init again.
We built this bot [gallienii](https://github.com/containous/gallienii) to keep our forks synchronized on [Traefik](https://github.com/containous/traefik).
Dep breaks my workflow, and I know I need to change but it goes something like this: I've used cobra before, so I start coding against an API I already know. The code competition isn't working, and I realise I don't have the package. I can't type `dep ensure -add github.com/spf13/cobra`, because my code doesn't compile at the moment. Infuriating. I wish `dep add` was a first class citizen. I'm ok with `dep ensure` cleaning my vendor directory, but I feel like I have to put place holders in my code instantly to stop it being removed from the vendor directory. 
thank you!
Yep.
What specifically are you hitting as a problem? 
IANA cryptographer, but at first read it looks decent? What I really wanted to say is, thanks! I am just now running into a use case for this or something like it. Good job! =)
&gt; dep ensure -add github.com/spf13/cobra will add it without it being imported yet by your project and say """ "github.com/spf13/cobra" is not imported by your project, and has been temporarily added to Gopkg.lock and vendor/. If you run "dep ensure" again before actually importing it, it will disappear from Gopkg.lock and vendor/. """
not if you have syntax errors in your code
I just broke my code (literally typed junk string main.go) and it worked fine... not sure why I can't reproduce, what error does it give?
&gt; recent incident with go-bindata What happened? 
&gt; I don't want to lose my dependencies. A central immutable repository allows me to do that. As long as you put a lot of faith in it and hope it doesn't then turn that dependency into a cash-grab (npm has raised $10,600,000 and counting). 
Oh look, it's this article again...
Question: what are the kinds of problems/pain-points where I should be thinking "hmm... this is a sign that it's time to look into dep" ?
Personally, I would drop the padding and strictly enforce the key size. For crypto stuff, it's better imo to give library consumers as few ways to shoot themselves in the foot as possible. Truncating passcodes is not a great idea. Cryptographically hashing to a static length could be an alternative.
I don't want a critical built in dependency on a select group of individuals. Github is the current flavor of the month, but tomorrow it could die, my vendor'd stuff would still work and I can migrate to the new hotness notGithub.com ... These central repos have always fallen into issues, npm failed often and then leveraged the failures as a reason to raise money, 10+ million dollars. Rubygems got so freaking confusing with the whole Ruby Central / Ruby Together (again, worry about funding and cash) that people were donating money places thinking it support Rubygems and Bundler when it didn't.
Links broken it seems.
i found [xz](https://github.com/ulikunitz/xz) and it works thank you
ye it was fun to dream about getting into that room again this year (serious queues)... really really wish it was moved to u
Error handling is a big part of programming. &gt; almost the half of my functions are error handling Sounds like you are missing something. Check some error handling techniques: * https://blog.golang.org/error-handling-and-go * https://blog.golang.org/errors-are-values * https://commandcenter.blogspot.com/2017/12/error-handling-in-upspin.html 
I would just hate to see go become java 
In your last example, when using case table testing, wouldn't it be more constructive to use the ```t.Run()``` function?
Great idea! I will keep an eye on my error messages, to help growing the list.
lack of support for private repos is stopping us from adopting it, so we are still using `glide`
&gt; Has dep hit 1.0 yet? No. &gt; Is dep included with gofmt, govet, go? No. But that is a stated long term goal of the project. &gt; Can dep specify version numbers, VCS tags, commit hashes? Yes, yes, and yes. &gt; Can dep mark a developer dependency (e.g. linters) as distinct from runtime API dependencies? Yes. It can also ignore directories of dependencies without go code (like for protos).
Hey /u/Spacemit, I wasn't aware of `t.Run()`, what advantages does it have over the method I've described? 
Thanks for the video! I was actually also expecting a failure case, to see what that looked like.
&gt; One solution I've seen is to create an intermediary struct that you unmarshal into, but I don't really want a bunch of extra structs lying around who's sole purpose is to parse out a common data type before sending effectively casting it to the correct type. This is exactly what I was trying to say -- unmarshall into a temp struct created solely for that purpose, then copy/parse out fields into the actual struct you want to use. I agree that it feels like a workaround, but not too much extra to wrap in a black-box method, at least conceptually. JSON goes in, the struct that you want comes out, and the internals just do the thing, however ugly (and it's not _that_ ugly tbh).
https://golang.org/pkg/testing/#hdr-Subtests_and_Sub_benchmarks
would you please provide me a link to the package, because i can't find the package (go-lzma)
Probably could be easily fixed with a pull req, just clicking the repo and looking at the Reader's Read method shows a [allocation](https://github.com/ulikunitz/xz/blob/0c6b41e72360850ca4f98dc341fd999726ea007f/reader.go#L340) that could easily be removed, as well as the [Sum](https://github.com/ulikunitz/xz/blob/0c6b41e72360850ca4f98dc341fd999726ea007f/reader.go#L351) method. Probably wouldn't be too bad after those two changes.
It causes `go test` to regard each case as a different sub-test. This would be more apparent with `t.Fatal()`, where in a `t.Run()` it wouldn't stop the remaining cases from running. It also prints each sub-test when using the `-v` flag, and allows you to even run specific sub-tests (or group of sub-tests!) with `go test &lt;test_name&gt;/&lt;sub-test_name&gt;"` The change is also not major -- using sub-tests the code would look like -- for _, test := range tests { t.Run(test.Name, func(t *testing.T) { if output := Calculate(test.input); output != test.expected { t.Error("Test failed: {} inputted, {} expected, received {}", test.input, test.expected, output) } }) } Here's a documentation link on sub-tests -- https://golang.org/pkg/testing/#hdr-Subtests_and_Sub_benchmarks
Dropping the padding in favor of hash sounds like a great idea. That would also fix key size to 32, no matter the length of the pass phrase. 
i am a newbie, would you explain more
ahh, that's pretty cool actually! I need to look into that and possibly include it in the next video! Much obliged for showing me this!
&gt; read them all but not convinced yet This is not about getting convinced. This is about applying the techniques mentioned in those sources to improve your error handling. &gt; there are better ways to solve that without the boilerplate If you know of a better way that could be implemented, including all the affected changes on the compiler, the tooling while staying orthogonal to the rest of the language features and not adding significant complexity to any of the aforementioned, then you should create a [proposal](https://github.com/golang/proposal).
My pleasure :)
There are too many tutorials using external dependencies. Your last post used gorillia mux. It's completely unnecessary; the std lib is more than capable and more important to learn.
It is powered by github pages, you can visit this link anyway https://github.com/jinzhu/gorm/blob/gh-pages/documents/associations.md#self-referencing-many-to-many-relationship Is it a DNS issue of domain gorm.io?
it seems like the part of this library that ensures any level of application level security is the pad, which is a globally accessible string. if an application using this were compromised, it would be trivial to pick the pass from environment (as this is a likely delivery mechanism for containers) and scrape the address space for the pad to decrypt this data. what would the guidance be for a developer to secure both the passphrase and the pad per application in a way that is safe against a compromised application? because it seems a compromised node would compromise the entire fleet that shares a pad, or shares a password that exceeds key length maximum. separate question: why choose this approach over using RSA/x509 PKI? or a more comprehensive open source solution that has been independently audited like HashiCorp Vault?
Had no problem with the gorm.io link
&gt; It's really dissatisfactory, that the author of that post has not replied to my comment yet. I remain convinced that this problem has nothing at all to do with generics and is based on a fundamental misunderstanding by the author. Disclaimer: I'm not the original author. I read the article and your comment. I'd agree with you that the original author didn't describe what he means with "solving the problem with generics" very well. Having siad that, I think you misunderstood the blogpost. Your comment mainly deals with de/serialization, yet the blogpost mentions de/serializatin only as an aside. The core issue is, IMO, is that Go's type system only supports limited/loose way to associate types with one another to express their commonality. Basically the only way to do that in Go is to define an interface that has a unique enough footprint (to not be accidentally implemented by some unrelated type) and implement it, but even then you can only work with the type in terms of that interface, you pretty much loose the original type in the process. Things like "this function returns the same type it gets as an argument and that type satisfies some contraints" or "these two variables are the same (arbitrary) type which belong to some group" etc. cannot be expressed in Go. On the other hand with generics you can for example define a function that takes an argument of some specific type that belongs to some group and perform operations on it and pass it along to other generic functions or return it back as the same type, etc. For example, look at their [`ObjectConvertor`](https://godoc.org/k8s.io/apimachinery/pkg/runtime#ObjectConvertor) - with generics, all of those functions could be type-safe, not to mention there might not be a need for that convertor in the first place. The whole problem would proably be easier and more robustly solved with explicit interfaces + generics over interfaces or perhaps with inheritance or with both. But this is probably difficult to see for people who don't appreciate any of those concepts... 
damn strings! interesting. This I did not think of, glad you commented. So far from hearing feedback, I am considering: * It is up to the developer to implement hashing and actual user input (not hard coded) * Keep padding around. If using a 32 bit hash as key, the pad essentially has no effect. * Allow programs to have unique pads, in the case of an empty pass phrase. In this case, the compiled program is the key (which can be extracted if compromised) &gt; what would the guidance be for a developer to secure both the passphrase and the pad per application in a way that is safe against a compromised application? At the moment, I think its good to leave it up to (and remind) the developer to implement their own hashing and handling of the actual password input (typing the password, hitting enter). I may add an exported Hash() as a courtesy func. &gt; why choose this approach over using RSA/x509 PKI? or a more comprehensive open source solution that has been independently audited like HashiCorp Vault? The seconfig code is easy to understand. Although its not as comprehensive or sophisticated, I think it will make up for that with it's ease of use. 
Tried and true it not; it‚Äôs not necessary in most services, especially well constructed 12-factor pattern small services. I have built and deployed dozens of go services into production in multiple companies even when needing dynamic properties in routes, it‚Äôs simple enough to slice up the string and get what you need out of it, all with the std lib. 
I do use dep, `dep ensure` can't solve after a repo is deleted. `dep ensure -update` will silently update commits behind a tag if the new owner put up malicious code and re-tagged things.
Thank you for the first solution comment on this thread. I will check this out and report if I see something that I need missing from here.
What is with the Go community and it's hatred for external libraries?
I just tried again and it worked without issue. Thanks for your interest :) Perhaps it was related to me using the latest version rather than the release - my fault entirely.
How easy would it be to release this game on PC probably Steam?
I wouldn't call it hatred. I'd say it is part of the Go philosophy which includes [keeping the dependency tree at a minimum](https://www.youtube.com/watch?v=PAAkCSZUG1c&amp;t=9m28s).
&gt; How easy would it be to release this game on PC probably Steam? Technically easy with Ebiten. Actually this game has been mainly developed on desktops. We don't plan to release the desktop version yet though. For one reason, the UX would be much different between mobiles and desktops. The portrait screen might not fit with desktop environment in terms of UX. &gt; Also, I might be blind but I cannot find a link to the appstore or playstore in the http://blockbros.net/bluebird/en/. There are banners for Apple Store and Play Store: https://itunes.apple.com/app/id1329132932 https://play.google.com/store/apps/details?id=com.rpgsnack.dreams
Okay cool. Adblock was blocking the banners for some reason. I can see them now thanks.
thank you
Thank you for this, now at least we can talk about whether the problem exists or not. At least we will move forward. Principals and Practicality need to walk hand in hand. We use a garbage collected "safe" language because managing memory and pointers ourselves, while principally solid and always correct, can lead to a lot of situations which we do not want to deal with on a daily basis. There is a valid trade off to be made there. One we should seriously consider in this case as well. We wouldn't need dep to exist principally, vendor directory was enough, but we do practically. It's not that the other people writing dependency managers were incompetent or not doing enough, it's that the flaw was inherent in the design of the ecosystem. If everyone is given a responsibility, nobody has the responsibility. I will re-iterate, we do not manage memory, not because we can't, but because we need not to. A central solution part of the language avoids a lot of needless conflicts in implementation. Go is filled with decisions like this. Go fmt is another. &gt; Gofmt's style is no one's favorite, yet gofmt is everyone's favorite. The problem of potentially lost dependencies exists. A person we trust can have their website/username taken down or delete it themselves when they move on with their lives. It's not without precedent, it happened literally 2 days ago with one popular package. This is symptomatic of an underlying issue. With a central package host, it is their responsibility to manage and maintain the packages, ensure availability and prevent unauthorised access. A breach of that trust is a big deal and people are hating on one such example on this very thread. Contrary to the popular belief here, I would argue that is a good thing. We have one group of people to hold accountable. If they slip up, we suffer. Because of that responsibility, the group has to be very very careful about the choices they make. When we have decentralised providers, we claim that it lowers the attack surface. I contend that it multiplies it. It is now the responsibility of each one of the service providers to solve all these problems individually. They might not even be worrying about these things, these are not the top 5 things they need to worry about. They are not here to host *just* Go libraries after all. There is a reason behind using libs and not implementing our own hashing algorithms in security. Even when I check my vendor directory in, ignoring all potential conflict resolution and bloat. I am still left with the problem that dep or any tool will fail as soon as remote vanishes. If I am updating any dependency, I could totally miss that the commit hash for a tag changed to something malicious. People say that Github and the likes should be solving this problem. But it is not their primary job. They are hosting code for other people. We decided to use github and other services because it felt like a good idea. One often cited solution to that problem is to maintain forks of all repositories I use myself and update each dependency with each commit I trust myself. i.e. do what the central package host would have done for me, myself. I use dependencies so that I can focus on what API the dependency exposes. So that I do not have to look at the underlying implementation or their development cycle. If I have to maintain forks of my deps, now I do. Expecting each and every developer will most likely lead to one of two situations. 1. People will just swing it, like most people have already. That package that got deleted caused an uproar for precisely this reason. 2. People will come up with a tool to automate forking and updates, which is exactly like the central package host problem, now on the shoulders of whoever writes that tool and on developers who use it, who might have various degrees of familiarity with the nuances of these problems. 
&gt; The core issue is [‚Ä¶] I disagree. That is not the core issue *the author is complaining about*. I agree that what you are describing is the core problem generics solve - but it is unrelated to the actual complaints brought up in the article. It also doesn't make sense to say "you have to implementace them yourself" in relation to this and this article, as that is not a problem that Kubernetes `runtime.Object` solves. Like, if they'd built a static analysis tool that makes sure that the `runtime.Object`s you are passing around conform to some notion of subtyping/parameterization, then, sure, they'd implemented generics. But they didn't. It is fair and true to say, that generics could be used to type-check the code more strictly -- but they wouldn't solve any of the *actual problems* mentioned in the article, which deal mainly with types not being known at deserialization time. The "Why this isn't great" section mentions three main and one "additional" problem -- the additional problem is what you describe, the three main ones are completely unrelated to generics. All in all, the article does mention things that would be better with generics (and I acknowledge that in my comment), but a) only as a side-note, b) as unrelated to the "type system" that they claim Kubernetes built which should be obvious because c) it is inaccurate to characterize this as them implementing generics or a type-system themselves, because it's not a problem they are actually *solving*. And of course d) the author probably would've noticed, if they'd actually have been more specific, instead of making broad claims like "this could be solved by generics". I agree that generics would make things better in the Kubernetes codebase. But the way it would is not the core thesis of the article, the article is &gt;80% inaccurate and thus, is a poor source to quote in favor of generics. And *if* you quote it, then you definitely shouldn't just blindly repeat their core thesis. &gt; But this is probably difficult to see for people who don't appreciate any of those concepts... I *so* hate, that on the internet, people always say that you either have to agree with them or be ignorant. Trust me, I know and appreciate these concepts. And I'm not even disagreeing about their usefulness. It is possible to *both* acknowledge the advantages a feature has *and* be intellectually honest about what problems it does and does not solve.
&gt; So please write tutorials to showcase that. [shameless plug](https://blog.merovius.de/2017/06/18/how-not-to-use-an-http-router.html) :)
Node ptsd
Love it (and Gonum). Only trick with installation, for people new to go I‚Äôm plot, is make sure you have Mercurial installed before running go get. Gopdf, a dependency of Gonum Plot, uses Mercurial for version control, not Git. So if you don‚Äôt have Mercurial installed, an error will be thrown during installation. While the error is self explanatory, easier to know up front.
Gonum really needs to add some examples to their readmes
Hey Jinzhu thanks for creating gorm.
&gt; but they wouldn't solve any of the actual problems mentioned in the article, which deal mainly with types not being known at deserialization time Where are you seeing this in the blogpost? I can only see deserialization being mentioned twice and in both cases alongside other operations such as serialization and conversion. Of those, your complaint applies to de-serialization only, because that's the one case where the type cannot be known ahead of type. In the other cases, though, it can, the first listed example is &gt; `NewEncodable`: takes a `runtime.Object` and returns a new `runtime.Object` that can later be encoded with the right encoder This seems like it would benefit from generics. Anyway, I still think the core issue is type association of some kind, the first point in the "Why This Isn‚Äôt Great" section directly leads to this. &gt; it is inaccurate to characterize this as them implementing generics or a type-system themselves, because it's not a problem they are actually solving. I agree they didn't really build a type system. However they built a system which performs some operations over a set of types, which is typically a use cases for some features Go doesn't have. I also agree with you that generics is not a solution to the problem they mention, at least not directly. The claim that "this could be solved with generics" is a wild one that they didn't elaborate upon and I don't think it's true stricly speaking, at least the way it's put in the blogpost. On the other hand, I'm not sure I see how the problem could satisfactorily be solved _without_ generics. I suppose inheritance could in some ways supplant it, but then again my impression is Gophers _hate_ inheritance while generics would be probably more agreeable upon... &gt; I so hate, that on the internet, people always say that you either have to agree with them or be ignorant. Trust me, I know and appreciate these concepts. Sorry, I didn't mean you specifically, that was a more general statement. I've been told many times by Gophers that the concepts mentioned bring more troubles than they solve or are downright useless etc. 
&gt; Where are you seeing this in the blogpost? Actual *problems* mentioned: &gt; If you try to decode, convert, or something-else a runtime.Object, you‚Äôll get an error if you didn‚Äôt install its GVK already. &gt; As a user of these packages, you have to remember to put an anonymous import somewhere in your package if you want to do anything with a runtime.Object &gt; It‚Äôs unclear what package you need to anonymous-import into your package to get your Object to ‚Äúwork‚Äù &gt; It‚Äôs unclear which (if any) type registries are concurrency-safe None of these have anything at all to do with generics. &gt; Additionally, since there‚Äôs a runtime-defined type registry, anyone writing Kubernetes core code needs to add manual type assertions and registry lookups anywhere that deals with runtime.Objects. This does. I acknowledged that and it's a well-understood usecase for generics. It's the only problem in the article that is actually related to generics and it's a side-note. And it is baseless to talk about Kubernetes "reimplementing generics" to solve this problem because a) they don't reimplement generics and b) they don't solve it. &gt; Needless to say, if we didn‚Äôt have this runtime ‚Äúinstallation‚Äù thing, we‚Äôd end up with less core code and less confusion for callers. No idea where this assertion comes from, it seems simply false to me. &gt; Generally, these applications crash with error messages like ‚Äúno kind is registered for the type ‚Ä¶‚Äù (see the source for notRegisteredErr for details). Nothing to do with generics. &gt; the root cause is that the type system is built at runtime, so type checks ‚Äî aside from the obvious interface implementation checks ‚Äî must be done at runtime. This seems to be misidentifying the root cause. To me, the root cause seems to be that the type information was not compiled in, not whether that type is parameterized or not. --- The vast majority of actual *problems* mentioned in the article have nothing at all to do with generics. Most of the actual discussion space is also dedicated to the type-registry, which, again, has nothing at all to do with generics. &gt; Anyway, I still think the core issue is type association of some kind, the first point in the "Why This Isn‚Äôt Great" section directly leads to this. What do you mean by "type association" and what does that have to do with generics?
`t.Error("Test failed: {} inputted, {} expected, received {}", test.input, test.expected, output)` This is wrong, this is Rust style string interpolation. You should be using the correct [Printf verbs](https://golang.org/pkg/fmt/#hdr-Printing)
&gt; None of these have anything at all to do with generics. The convert and something-else (which probably alludes to encoding and other operations) are related to generics in that they could be type safe and potentially the could operate entirely with the information provided by the type system rather than requiring a type registry and previous runtime type registration with the registry. As for the other ones I agree that they don't really have anything to do with generics. &gt; And it is baseless to talk about Kubernetes "reimplementing generics" to solve this problem because a) they don't reimplement generics and b) they don't solve it. I agree. &gt; No idea where this assertion comes from, it seems simply false to me. I suppose they mean if some of the information could be encoded with the type system. This is of course is very much language-dependent and various languages provide various means to do this. &gt; This seems to be misidentifying the root cause. To me, the root cause seems to be that the type information was not compiled in, not whether that type is parameterized or not. Yes, but that's the point - to compile it in, you probably need means to express that information. &gt; What do you mean by "type association" and what does that have to do with generics? I mean being able in general to express relationships between types in the type system. Support for this is extremely limited in Go. For example being able to express that one structure is a newer version for another structure. For example in C++ you could easily create a typedefs in both structures that would refer to the other one. In Rust this would be done with traits and associated types. In Java is somewhat more limited in this compared to previously mentioned languages, but I suppose you could use generic interfaces for example. It could also help that in Java objects are covariant with their interfaces unlike in Go. Inheritance is also a way to associate a bunch of types (for example, all the types from the type registry could inherit a common base, that would be a classical example). In any case, once you have means to express these relationhips, you will very likely want generics to able to leverage them. For example, you could have a function like this (pseudocode): func DoSomething&lt;T: GVK&gt;(gvkobject T) { var latest := gvkobject.toLatest(); // This return the type T::Latest as defined by GVK ... do something with the object ... } So, in conclusion, while I agree that the problem described in the blogpost is not solvable _directly_ by generics _only_, I still think generics would be an important part of a "proper" solution. 
&gt; Why not use a lib which makes things easier, is used everywhere, and homogenizes how you route requests across all of your APIs? - novices shouldn't build routers, they need to learn the stdlib and language features (that's why they read tutorials in the first place), - when they know how stdlib works, they know their *needs* and they can expend to third party packages that satisfy them, - if you'd skip those things you might end up with the wrong choice, because you made that choice for [all the wrong reasons](https://www.reddit.com/r/golang/comments/57w79c/why_you_really_should_stop_using_iris/), - I'd argue that novices shouldn't have a need for homogenized API layer(s) yet, as they should still be learning what style works for them, and their projects actually should be those *trivial APIs* which you mention While it's easy to recommend [go-chi/chi](https://github.com/go-chi/chi) for routing needs (it's really great imho), or gorilla/mux, or a significant number of other routing packages, you possibly making the novice skip of a very important question: "why would I use this router?" or "what problem am I trying to solve?". Part of the problem would be solved if some routing package would be considered as *official*, or at least close to something like that (see `dep` for an example). I actually have a chapter of "choosing a router framework" in [API foundations](https://leanpub.com/api-foundations) where I (as a novice would), made the mistake of choosing a routing framework, which had a significant pitfall. Ideally, I could have omitted that whole chapter, but I did want to show what happens when you're choosing software based on some external reference like curated lists or github stars. Unfortunately, this pitfall sometimes hits more experienced programmers as well. So yeah, I agree with you, the stdlib doesn't shine in the router category, but if you're a novice, it should be a requirement, so the underlying principles are well understood. You don't need to write regexes or whatever, but you should know what limitations you're trying to overcome.
I don't maintain forks, I commit my vendor directory. As I did in every single language I have ever used for decades, central repository or not. Why? Because I understand that MY repository has to create reproducible builds regardless of what happens on the internet. It is my firm belief that people who don't commit a full working tree that can build their software are acting irresponsibly to the point that I question their basic competency. As for something malicious happening, that can happen with central repos, and has, repeatedly. Someone hijacks a package and posts a newer version that does "bad things"(tm). Tools like dep can also absolutely deal with a repository being deleted forever, you can ignore it or from your old vendor directory bring it into your top level project or a fork. A dependency going away is a fundamental problem your project has to solve. Centralization fixes a few problems at the cost of creating a massive one, IMHO. A central repository can fix the "package vanished" problem -- which isn't even a big problem if you vendor. It can aid in discovery, because most things will be on it -- but I think just using google, https://godoc.org/ and http://go-search.org/ do the job very well and give you multiple options. The cost of getting those two benefits is a lifetime of support, maintenance and centralized control... the shutting down of alternatives before they even exist because a winner "was picked" and likely some level of corporate control if Google runs it.
Just committing your vendor directory gives you these benefits at much lower cost with a tool like dep. Forks are required if you want to have changes on top, but seem like overkill for simply vendoring. 
Not sure why downvoted, that is correct. dep ensure versus dep ensure -update. 
&gt; The convert and something-else (which probably alludes to encoding and other operations) are related to generics The questions isn't "would generics be used there if they exist", but "would generics solve the problem". And no, they wouldn't solve any of those problems, at all. The stated problem is, that you get an error if you did not include the proper type into your binary - that error won't go away with generics. &gt; they could operate entirely with the information provided by the type system rather than requiring a type registry and previous runtime type registration with the registry. Generics do not solve the problem of having or not having a type-registry. They also don't solve the errors you get if you want to decode a type but do not have the type information handy. That is *exactly* the point. I don't know why this has to be repeated so often: The type registry is about enumerating all serializable types. Generics *do not provide you with a way to enumerate types*. And if you have a way to enumerate types, it does not matter whether or not they are parameterized or not. Yes, generics could be used *in addition* to a type registry. And then they would solve the *orthogonal* problem of needing type-assertions. But the two problems and solutions are completely independent. &gt; I mean being able in general to express relationships between types in the type system. Not a problem the blog post actually talks about, from what I can tell. Also not a problem that needs solving here, from what I can tell. &gt; I still think it is evident that generics would be an important part of a "proper" solution. I strongly disagree. And I think that would be pretty obvious, if instead of handwaving and saying "if you squint, you can kinda see how generics could be used here" the author (or you) would actually take any sort of parameterized types and would actually try to describe en detail, how they would solve the problems brought up in the blog post. Because I'm pretty sure they simply don't, at all. But anyway, this is going in circles.
&gt; strawman This is something that literally happened, it is not a strawman. It is what happened to the biggest centralized repository we have an example of. 
It happened to one, doesn't mean it needs to happen to all. The strawman is assuming it will happen everytime with every implementation. As I've said on the comment that you responded to. Bad implementation != Bad idea.
&gt; I don't want to lose my dependencies. A central immutable repository allows me to do that. Committing your vendor folder also allows you to do that. &gt; I lost upstream and nothing builds vs someone is squatting on the fancy name I like. If your code breaks nobody else is responsible except you because it's your code. As soon as you depend on something, it is now in your code and it is therefore your own responsibility.
Ya. Lesson learned ;) 
The more dependencies you have, the more a new person to the project has to learn. As others mentioned node has this problem but so does java. To do real service development most people have to also know spring boot, plus IOC, often hibernate, and other libraries. Cognitive load is a real thing and it slows down development. This all said, everything is a tool; from language to pattern, to library. Use the right tool for the job. But to do that you need to know your options.
i think the fundamental idea of a ultra-repository maintained by an elite few becoming a single point of failure for a community is a terrible idea. I think the IDEA is terrible. 
They actually did, if you look at the source. Looks like it was messed up by following a list item. Here it is, as they entered it, sans list item: var buf bytes.Buffer _, err := data.WriteTo(&amp;buf) if err != nil { return nil, err } return &amp;buf, nil
Then we should have ways to solve the problems the ultra-repository aims to solve. I get tied to the development cycle of each dependency I use. That's a burden on each developer in the go community. More than that, I am at the hands of security and trust maintained by whatever hosting provider or worse, whatever vanity url service the maintainer uses. All code signing etc kind of solutions are possible only when I have a At this moment, if I update, dep will update the commit behind a tag. A tag that one always assumes to be consistent. The fact that I can't relax and know that upstream is ok for all dependencies of a project, is fundamentally broken. &gt; alternatives before they can even be born So does go fmt, or dep, but it became necessary.
Just an fyi, if you‚Äôre into image analysis, ar/vr stuff, gonum isn‚Äôt fast enough Opencv is going to be 2-3x faster, and if you have a gpu available, faster still If you end up using opencv on aws, make custom build and disable some instructions that aren‚Äôt available on the gpu instance
Sorry, I didn't notice, as it renders fine in Now For Reddit.
&gt; Committing your vendor folder also allows you to do that. dep fails to update altogether if upstream goes missing. dep updates commit hashes behind tags if they changed on upstream. It doesn't protect me from `myrandomsite.com` falling into the wrong hands. A central repo would cause such an uproar, I would know what happened. If I were not checking this reddit, I wouldn't even know some package changed owners. I am not sure which of my deps did before today. &gt; As soon as you depend on something, it is now in your code It certainly is, but if I can't trust the entire chain of how I got the code and each update, now I need to review and vet each and every update I make. I trusted the dev who wrote that code, I trust that they would follow semver. I can relax and allow path level updates. "It must be some small bugfix, probably good for me." I do not trust a random dude who got hold of that username/domain in between. I could be chasing a deadline and pull in a new dependency from someone I trust, it is very easy to overlook updates in such situations. 
Great discussion - Will definitely keep this all in mind! I'll link to the article for the sake of context: https://pragmacoders.com/building-a-json-api-in-golang/ I think there's also something to be said for the utility of teaching newcomers how to install dependencies. If I removed 'gorilla/mux' from that tutorial, suddenly there's no good way to explain how to use 'dep' and there'd have to be a bigger chunk of the tutorial dedicated to regular expressions (a notoriously ugly and hard to explain, if extremely useful and versatile tool) to accomplish the same goal. It's not necessarily what I want the reader to come away remembering. Even if it's useful in a different way. I can see the other side of it - Modern frontend JS tutorials might start the tutorial by having the reader install 10 libraries and build tools. They then have to make a choice to take a detour and explain them or to skip the explanation and get back to the task at hand. Can easily be overwhelming to the reader and put them in a niche of tools not optimal for them (without them knowing it). I think in the context of that previous tutorial, I'm OK with the choice I made. Though I could potentially create or link to an article with more detail on how to use stdlib instead of the extra dependency. To give the reader the option to dig into the alternatives. Good discussion, and I'll definitely keep it in mind, the desire to use stdlib unless there's a clear reason not to, for future tutorials! Now is there anything you'd like to see built and explained, beginner-to-intermediate-level with a dependency tree of appropriate size for the problem? ;)
&gt; I don't maintain forks, I commit my vendor directory I'll start doing that I guess. It will add a lot of bloat and muddies my merge requests to the point where code reviews will become really painful. But as there is no alternative, I will be forced to. &gt; A central repository can fix the "package vanished" problem It's not just that, github usernames are re-used within minutes. Other sites might have the same problem. The malicious code problem is solved easier in one place than in multiple. Especially with vanity domains in the mix. A central repo can also make code signing restrictions stronger. All problems we've discovered till now and the ones we will discover later will be strictly solved faster in one place rather than all over the internet. Some website owners won't even hear of the issue. I did not know of go-bindata changing owners at all. That is scary to say the least. I trust dev A will write great code. I have been using A's code for years. 1.0.1 to 1.0.2 is a simple change, A follows semver, it won't break anything. I check the release notes they look good. I have a deadline coming up tomorrow, let me just update and commit it. &gt; because a winner "was picked" The alternative makes it very very difficult for companies without a dedicated security auditing team to move forward with trust. I'll most likely stop updating dependencies unless I really need a feature. Will most certainly lose a few security patches here and there and be a sitting duck. Is it my fault? Technically yes. Sure! But at this point I am also a victim of a very broken process. People in general tend towards least effort. The least effort way right now is to trust that all upstream service providers are taking good decisions and doing their best to serve a community that is not their majority user. I would rather have one service provider fail and fail big enough for me to know that something really bad happened and I need to worry about it than have some tiny dependency of a dependency pass code review because we were on a deadline and nothing ever happens...
Do you have any benchmarks which show where OpenCV is much faster? I bet the Gonum folks would be quite interested in that.
&gt; I don't maintain forks, I commit my vendor directory. Do not use the same user name and pic on github and reddit if you are going to lie. &gt; acting irresponsibly to the point that I question their basic competency. I am sorry you feel like that about [yourself](https://github.com/robertmeta/scrapewebcomics/blob/291c590cc/oursuperadventure.com/main.go#L12)
should have been a bit more clear if you take sufficiently large matrixes and operate on them, such as 1920x1080(for example, but you can see differences at much smaller sizes, such as 600x400), opencv makes use of simd, avx, etc.
I suppose. I mean you can always go back and improve the article based on the feedback.
I think this is an area Go core team should work on. There‚Äôs no reason we should have to use Cgo to get good matrix performance. 
&gt; to magically solve all your problems Not necessarily. I understand that it is easier for one body, who has the responsibility to ensure availability, immutable packages and strengthen trust between me and the developer will take steps to do so. If the central entity fails, I will most likely hear of it. I want to know that I can set `^1.0.0` and not have my world shatter and not even know about it. &gt; Vet your dependencies. Yes, I do when I import a dependency the first time. But over time I build trust with the developer(s). That helps me focus on the problem I am solving right now and not worry about their code all the time. Same as garbage collection takes away my problem of dealing with memory. Can there be a leak/bug in go? Sure! Is it my fault for having used go? Yes definitely. But I trust the devs and the entire distribution. I do not check in complete go source and builder because I have very high confidence that I will get the go source authors of go wrote.
&gt; Yes, I do when I import a dependency the first time. Okay then if that is your idea of vetting. Then how about minimizing your dependency tree?
true, however, I wouldn't hold my breath on this happening soon, their goal seems to be server side stuff, and gc latency personally, I try to use the right tool for the job started of with go because the 'processor' is a headless server, constantly crunching; it was apparent almost immediately(~2 weeks in) that it isn't performing fast enough, quickly translated the code to c++(+1 for pretty fast translation) and the speedup was interesting to say the least, then, after further optimizations on the c++ side, we got faster, then we got into the gpu stuff and it was very clear that c++ was the right tool for what we were doing go is still being used in orchestrating aws instances, apis and such, because it's the right tool for those tasks, would have been great to use go for the processor too
Trust me, in my company, I am the one fighting to have as low dependencies as possible. I might sound like one in this context, but I am not trigger happy dependency freak downloading 1 liners like leftpad. But when you have service providers that allow reusing names, having even 1 dependency is scary. I can't trust that the code behind it is going to remain the same unless I lock down each dep to the commit id. At that point I risk missing security fixes because I was busy doing something else. I am not arguing that there is a silver bullet or a clean fix. If there were, we'd all be agreeing and doing exactly that. We're all smart people here. I am arguing that the current solution isn't enough, it depends on a lot of service providers maintaining the highest level of scrutiny. If one central service provider can make mistakes, all of them can. And that central service provider has a responsibility to fix it, most of the third party ones don't. If go-bindata was hosted on a central provider, it would have become immutable by now. Github has no such obligation. Let alone other providers which are lesser used. Or `mycompany.com` type urls.
Never really thought about it, I've been developing desktop apps for years now and it has always worked. It might be time to adapt to the new times, not sure. There are so many options and technologies that I don't know what to go for right now.
IDE: [Goland](https://www.jetbrains.com/go/) by JetBrains so will feel very familiar to you. There is also large support for VSCode, since you already use Intellij, Goland is a great option. Build tool: Many people use Makefiles. I grudgingly us them as well, but I don't like them. Another option is [GoGradle](https://github.com/gogradle/gogradle) since you are already use to Gradle. I haven't done any serious GUI work in Go (or anything for that matter) in a long time, so I can't definitely say what is and isn't possible, but I would look at the [qt](https://github.com/therecipe/qt) which is a very rich cross platform GUI framework in C++ (or is it C?). With the Go bindings to qt, you should be able to do everything you need. For example, the [TabView](doc.qt.io/qt-5/qml-qtquick-controls-tabview.html) might be what you for for TabPanes from JavaFX.
Really interesting, thanks for the list. I'll check each of these one by one, this really helps a lot.