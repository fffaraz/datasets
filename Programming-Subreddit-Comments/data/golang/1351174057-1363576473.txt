i believe you mean: _, closed := &lt;-intv 
&gt; Do not optimize too early :-) This is true. The profiling tools for Go are simple and effective. Go code also tends to be quite easy to optimize because the profiler usually points exactly at the problem spot.
Pretty cute. These benchmarks aren't terribly done actually, since they do so very little and have been reviewed by so many people now. Python's probably the most impressive though, both in that it can do it in literally one easy to read line and in that it reaches Go-like performance. But then again, I always knew Python was great if you used it right.
I just compared both yours and axwalks — both are essentially the same in speed, with axwalks edging out just slightly (11.4s versus 11.7s). Yours is definitely more readable except relies on the assumption that the text file has line breaks — which may or may not be a reliable assumption depending on the context. Both are good 4 seconds slower than my original (buggy) version. I'm surprised at the difference.
ReadString() is generally much, much slower than just using ReadLine() (and then string(read_data) if that's your fancy). You can almost always get around the prefix nuisance by using a large buffer (say 10MB).
Is the `Title` function implemented in go itself (I expect it likely is), or delegated to C code?
I thought about using ReadLine, but the docs made it sound like an internal implementation detail.
Delicious dogfood.
Interesting - I found negligible difference. It just occurred to me that my version is still broken, because you might end up with multi-byte runes crossing a buffer boundary.
Whose NDAs? Where was that discussed?
The point was that most usage is internal tools and internal servers, and we can't really describe those without explaining internal things. As far as user-facing things, Google Code Project Hosting is increasingly using Go, but they're not ready to discuss all the details yet (and some features are not yet public), and the Google API serving stack uses Go, indirectly, as part of their backend. But depending on how indirectly, a lot more stuff at Google uses Go. dl.google.com was notable because it's such a rewrite and total jump to Go. We're going to keep publicizing Go usage within the company, though, whenever we can.
There are C++ libraries for almost everything, and they're generally quite nice. People often pick C++ because of the libraries, rather than the language they want to use. (e.g. having to SWIG something so it'll work in Python). Actually, dl.google.com many years ago was once in Java, before it was C++, but it was apparently having too many memory problems and was rewritten in C++. I've never found or seen that codebase, though, and I'm not sure whether they were using NIO or not or why it wasn't performing. I'm not exactly sure what you're referring to that Go and Java's performance characteristics are more comparable. It's true that they're both garbage collected at least. But I find it easier in Go to avoid generating garbage in the first place, which means the GC runs much less often. Anyway, it wouldn't surprise me if in a few years dl.google.com is rewritten yet again, if something better comes along, and/or the new code janitor has a different favorite language that they're good at.
&gt;I'm not exactly sure what you're referring to that Go and Java's performance characteristics are more comparable. I should've said limitations rather than characteristics. It wouldn't surprise me at all if it were easier to avoid heap allocations in Go (although the entirety of goroutines and channels rely on GC existing, so I'd have to wonder why you were using the language at that point). It would also not surprise me that Go is better for memory usage as well but Java's throughput is at least pre-1.1 Go, better on average by quite a bit. Whether or not the improvement in throughput is worth everything else you sacrifice, depends on your use-case. I'd tend to think not and that most people could suffice with Go. Nevertheless, back to what I was saying about limitations. This is speaking from anecdote here, if you've had a different experience or have numbers to the contrary I am intensely curious and would love to hear what you have to say. With that said: if you need to really squeeze every last ounce of performance out of your project, generally you are (depending on specialty/project) looking at C, C++, Fortran, or Ada. Everything beyond that usually involves an irreconcilable loss of control. Am I off the mark?
You don't realise how much we need to defend Go due to the lack of dogfooding. Please do reports like this more and think about putting this on the Go blog.
I wrote a static image file server in go and it kicks ass.
Go is brilliant for server applications.
I'm also not sure what you mean by throughput here. I'm sure Java these days can easily push a lot of bytes and max out a single machine's network card. And so can Go. It comes down to what language lets you do it most comfortably. That's quite subjective, but for me, that's Go. Objectively, I don't know what throughput benchmarks you're referring to.
Sorry, I need to update a couple of bits of the article. CGO won't work with those instructions as-is because it isn't supported in ARM on 1.0.3, which is the latest stable release available for download without going to the mercurial-based golang repo. I'm working on a more involved followup post that involves using the toolchain to build various third party bits needed to get the full Go experience (git, mercurial, etc for 'go get'), and then using mercurial to pull down the latest source code, which is recommended for ARM development. 
http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=go&amp;lang2=java I am most certainly not talking about maxing out a network card :\
http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=go&amp;lang2=java
Oh, I'm not too worried about the shootout. Remember that the shootout is multiple things: it's comparing speed and also comparing lines of code. We'd rather win on lines of code (which we always do against Java) and catch up on speed over time. The Go shootout programs are written in a more idiomatic style to show nice, small Go code, rather than the fastest possible Go code. A lot of them could be faster at the expense of writing longer, uglier Go code. We'd rather accept a shootout performance loss today and fix the compiler and runtime to make the clean, idiomatic code fast. And Go 1.1 (tip) is much faster on a lot of those. See http://code.google.com/p/go/source/browse/test/bench/shootout/timing.log It's getting faster all the time, and when we have performance problems in real code we profile and just tune the parts that are slow. (making simple things into uglier things, but only as-needed) Our regexp package is also not highly optimized like the C versions which everybody else uses, which explains the notable outlier. But at least Go is fast enough to permit writing a regexp engine in (and image libraries, and crypto, etc). The regexp package will improve.
Go could very well get to be faster than Java, it'll be a long hard road, but it could be done. Getting it to be faster than optimized C or C++ is...ludicrous and basically assumes that Ken knows something about compiler optimization that the entire rest of the industry does not. You don't want to take your hero worship that far.
Questionable indeed. If I saw this in a source file, I'd NOPE and walk away.
You seem to have such a strong opinion already that I'm not sure it's worth having a discussion. What do you want to do?
Java is pretty fast, safe, but is tedious and doesn't let you control memory. C++ is fast and tedious and does let you control memory. Go is between in-between on speed, but getting ever closer to C++, is safe, lets us control memory way more than Java, and is not tedious. That is why I like Go. It's the fun of scripting languages (not tedious) but the speed of C++ (nearly) and lets me write safe, readable code without threads or callbacks. 
&gt; Yes, all benchmarks are lies, etc. Well, just have a look a the flame war it started on /r/haskell \^\^: - http://www.reddit.com/r/haskell/comments/120h6i/why_is_this_simple_text_processing_program_so/ - And the best answer: http://www.reddit.com/r/haskell/comments/124bg6/response_to_why_is_this_simple_text_processing/
&gt; Does tip support ARM/cgo? yes 
You don't need to use a variable name for the function: http://play.golang.org/p/6h_pAeC57I
I think the guy in the next cube over gave me an odd look because I saw this code snippet and said out loud "I hate you". nope.gif
I wonder if it's possible to do even cooler things like add non-printable utf8 characters.
Thanks -- I didn't know about talks.golang.org
I never suggested Go would be faster than C or C++ optimized code. All im saying is that with the rate that Go is growing, and the design of the language, it may very well be easier to write faster code with less headaches. The philosophy of bell labs has always been write code that works first and only optimize if the performance gains are reasonable. You cant expect all software to be optimized, sane and correct. The bottleneck is always human error and judgement. Not the language's potential. Considering that sites like reddit are built with python, the speed and resource conservative benefits of native compiled C/C++ is moving more towards low level OS kernel development while high level languages are used more often for things like web applications and desktop programs. Go is special in my opinion because it trys to take the best of both worlds and not replace any language, but rather take alot of the good from the whole potluck of experiences out there. We can argue pros and cons of x language vs go, but in the end I believe such debates are missing the point of why Go is such a great tool to use. 
From his announcement on Twitter: "There is no video yet but I believe it is coming." http://twitter.com/rob_pike/status/261979230039064576
I was putting together notes for an article to cover almost exactly this material when I got the link to this video via twitter yesterday. But it's ok; now I can pare down what I was going to say and just link to this at the top of the article as an excellent introduction to the basics :)
Maybe instead of `T`, use `interface{}` to make it be more Go-like?
I like this one even better :d If you then define an f-function in the same file, import the 'f' from another file, the fun can start completely. http://play.golang.org/p/YcXCC5EQOO
&gt;minimalist wiki in Go to host Go snippets. &gt;And the wiki should run a distributed cluster with no central points or some random shit. &gt;And every currently-being-edited article is represented by a goroutine. This is the correct answer.
Anyone else actually excited?
Indeed he can, but if he's going to post it here, it would be nice to have some explanation of what it's for and why we are supposed to take notice. Or should I start posting random links to random pieces of code I happen to be writing for my own purposes, with no explanation? "Here's a UTF-8 encoder.... here's a function which parses the contents of the Unicode SpecialCasing.txt file... here's a partial implementation of a red-black tree insert function..."
No. That's not what the downvote button is for.
Oh wow having git and go get on the arm chromebook will be just so awesome... Though in retrospect it's kind of annoying how Google didn't just build in the whole thing behind the dev mode in the first place. 
y u no a ^ b ^ c?
That's what I first tried -- I was baffled myself but a\^b\^c and a\^c\^b and b\^a\^c and b\^c\^a etc. did *not* all produce unique values.
This should be a community project. If we all really want this, then we should all build it rather than putting the work on one person.
You could run your legacy ruby code from within your shiny new Go based infrastructure. 
* gofmt and use tabs for indentation. * use http.Error() to send an error status code when you have an error in your http handler. * There is no point in using " defer c.Close()" at the end of the function you may as well just call c.Close(). It's convention to defer the close() call straight after the Dial() so the reader can clearly see that it will be properly closed. 
The compiler doesn't care but defer exists to let you tell "this needs to be closed later" right after opening the connection. That way you pretty much can't forget to close the connection and you don't need many Closes in case you have more than one return in your function.
Instead of using fmt.Println(); os.Exit() to have a fatal error, consider using log.Fatal().
Any reason you need to use println()? tpl := "Loadbalancer starting on port: %d, redis_key: %s, geoip_path: %s" println(fmt.Sprintf(tpl, *port, *redis_key, *geoip_path)) could be const tpl = "Loadbalancer starting on port: %d, redis_key: %s, geoip_path: %s" log.Printf(tpl, *port, *redis_key, *geoip_path)
* One small style point I like to follow is separating standard library imports from others. You could always do this with separate import declarations, but even cleaner is to separate imports into groups with a blank line: http://play.golang.org/p/w84u1rWGNX Go fmt will nicely order imports within a group, but otherwise leave the groups separate. * As others have mentioned, use the log package. Consider when you want output going to stdout, stderr, or somewhere else. * Should your ClientIP function be implemented with http.SplitHostPort maybe? (Guessing here, but hard-coded delimiters always catch my eye.) * One more silly little thing, fmt.Println("") I used to type this until I realized that fmt.Println() is enough.
Also, get rid of \_ in function and variable names: start_server -&gt; startServer.
This is not really a flaw, more of a style disagreement, but I dislike the way you've broken up main into three functions. Main is short and concise, but it isn't clear from looking at it which of those three functions can fail and how. This criticism wouldn't apply if the main function started getting big, of course, though in that case I'd recommend returning errors from the functions that could fail, instead of exiting directly. It's an entirely minor point though. It's more my personal preference than anything.
That is very good to know. I really appreciate all the help I’ve gotten in this thread.
It's already using goroutines due to being a http.Handler. But since the package level variable is only modified before any other goroutines are launched the reads will be safe.
I don't post every line of code I've written on reddit. If someone is going to post a link to some code on reddit, I think it's only reasonable to include an explanation of just what the hell the code *is* and why it is interesting. A blind link to a random source repository is a big waste of everyone's time. It's true, it's not that there is a surplus of bad github links being posted to r/golang, but there *is* such a surplus being posted to r/programming, and to hackernews. It's just spam and I'm tired of it.
Usage of a global for Redis was mentioned in the comments for the pool implementation. Thank you for your suggestions for improvements.
Fair point, my initial remark was quick and grumpy, not really considered to start discussion.
Too many files. This isn't Java. Put this all in one file for now and break it up once you have enough code related to a certain topic. You're just making it harder to navigate, not easier. Use factored import syntax whenever you have more than 1 import. Put a blank line between standard library imports and 3rd-party imports, sorting each block: import ( "fmt" "net/http" "github.com/foo/bar" "github.com/yyy/zzz" ) 
Well XOR is associative, so all of those values should equal each other[^[1]](http://mathworld.wolfram.com/XOR.html).
Slow to load pages or slow to convert (according to the timer below the result)? The web server is basically just a machine under my staircase, on the home DSL connection, so not exactly blazing. Over the local network it's serving pages in ~0.1 seconds, which seems fine considering the "server" is 7ish years old and only has one core. :)
Slow to load (and I see why now), but posting a website you run out of your house on to reddit? You are a braver man than I... :P
20/2 Mbit connection, and a default conversion takes ~250kB of html, so I should be able to serve 1 per second or so. Doesn't seem too dangerous, considering this is a fairly small subreddit. Although, if people decide to use max width settings, it can grow up to 4MB of data, which is kind of painful.
Was anybody else expecting [this pic](https://en.wikipedia.org/wiki/Pic_language)?
I can't get enough articles about how much more productive and perfect Language X is than Java, C, C++, and so on from someone with no Java, C or C++ experience. Not all Java code is industrial. And saying Scala compiles down to Java, and is thus a bloated language, shows a misunderstanding of Java, Java Bytecode, and Scala. I like Go. But this article is hyperbolic and annoying.
That would be quite useful, and, I would think, not terribly difficult.
So what you're saying is that you didn't put the effort in to learn Python and as such, it's a bad language? Yep, the logic checks out guys.
I hate to say it but I'm terribly productive in C++(11).
Arguments of how Go is "better" because clean, idiomatic Go code is more readable than amateurish C++ are not good arguments. There are C++ gurus out there who can whip out some truly terse and concise C++ code that will make Go look like Java in comparison. In the end, it all just devolves to an e-peen contest. I really like Go, but I'm starting to find articles like these annoying. Go is not a replacement for C, it's not a replacement for C++ and it's not a replacement for Java, or Clojure (not "Closure", as the article says) or Lisp or Prolog or X. Why can't Go be in its own niche? I'm a polyglot programmer. I do C# in my day job but will also do C++, Javascript, Python, whatever the task at hand calls for. I don't try to replace Python with Javascript or some shit, that's just asinine. I notice a lot of self-taught web programmers are always jumping on the latest bandwagon for the wrong reasons. "I tried Python! But too much white space! I tried Django but jumped on Rails! Then PHP! Then Sinatra! Now Go! Yay!" Just use whatever tool makes sense, stop trying to find "the ultimate one to rule them all". 
Well volunteered!
He was honest. He "had a rather bad go at python." Then he said there was nothing wrong with it. What world do you live in where everyone has to think like you do? He's expressing his distaste. I don't like pickles. Am I somehow illogical or stupid?
Quote where I blame python. ...I'm waiting. You guys seriously cannot handle any level of criticism can you? I don't like python because of the whitespace sensitivity. I stated that up front. I do still know Python. I just prefer to use subjectively better scripting languages. You guys need to chill the fuck out. Running people off for having a different opinion is a very 1920's attitude.
Actually, pickles are pretty good.
As someone who favored/favors Perl (and CPAN), was exposed to Java, tried Ruby and Python (found them lacking/not different enough), programs in Objective-C, etc. I have to say that Go is different. Go is good. Go gets a lot of things right, not just as a language, but as a platform. Fast-compiling to a binary on linux, darwin, AND windows? Yes please. Dependency hell/management baked into the language? Yes please. No separate .c/.h files to manage? Yes please. Go is not just another Ruby/Python/C#, it is something different and something *better*.
There are [similar libraries for json](https://github.com/str1ngs/jflect), it should be possible to follow a similar interface :)
Why would you hate to say that? Good for you!
Python produces very interesting and identifiable patterns from the way the indents match up. Check out a few large files on github, and zoom out. Most likely not remotely what you are talking about, but still pretty in a mathematical kind of way. Also, you forgot a quotation mark. Its like a missing paren in that I immediately noticed and wanted to fix it. =P
I used to refuse to eat pickles. And then I actually tried one. From then on out its been pickles on everything!
Oh my God CPAN was horrible. Had to deal with that for a job once. Many many hacks were needed.
I say , lucky SOB. Last time I had to write C++ code, I felt like chewing my fingers off. 
D really needs a corporate sponsor. Really. Andrei (who works on D's STD lib) is a research scientist for Facebook. I keep hoping that one day Ill hear mention of D replacing C++ there.. And I do believe it is being used for some things there, but not widespread. My fingers are crossed! I'm really excited about the fact that most of the popular new languages are Compiled, rather than interpreted. I'm sure the hardware guys are thanking us. =P I wish rust would stabilize a little more, so I can give it a go. Its almost to the point I can justify it. I'm sorry, had a few drinks and I'm ranting.
Well, any one would be a start... ;)
And just in case you were about to mention that it's not idiomatic to prefix types in Go with T or t... I'm well aware of that. ;)
Don't like that because it's not as self-documenting to an outside package user, I'd have to document which 20 possible types could the dreaded interface{} be, plus keep that updated ... and then, only from my own use-cases I could already predict I'd have to have those 20 type switches on interface{}s in *all kinds of places* when using this package. Also this would be an interface slice []interface{}, so essentially for real type testing I'd have to pick the first element if there are any (another if, another switch etc etc) just to get to a damned material or light or image declaration... iterate all decls in all image-libs in the []libImages slice. OK not too bad but ... just doesn't feel as "sound" somehow. It's probably a psychological thing, how can I get rid of that nagging feeling that interface{} type switches are just a dirty hack best to be avoided? ;D Anyway, this way, while clumsy and self-repeating, is still way more usable and more convenient to code against for the outside package user including myself. Since the Collada spec only seems to change every 5 years or so thankfully, this isn't too bad. Still, that's some stupid work right there a compiler could have done for me... or, true, a code generator, but *then* you're really getting sucked down into the rabbit's hole...
I agree, generics would be useful sometimes. I hope you are at least using a small script to generate that file though.
The alternative - using interface{} and type slicing - is "fine I guess" but results in a leaky abstraction in that a user might find herself having to constantly re-affirm the types that she put in to the calls in the first place. I find it very annoying, and it is absolutely the least pleasant part of writing Go code. Around the office (which is a Python office), when Go gets talked about it usually goes like "Go seems awesome but that error handling / garbage collection stuff seems like a huge pain." I am trying to switch that to "Go is awesome and the error handling makes sense when you get used to it (GC is fine), but damn I miss dynamic typing / generics".
FWIW I totally agree with you regarding generics. I think the rhetoric that `interface{}` solves that problem is just a flat out lie. It solves a *different* problem - which in my mind is more like a unified type system, the One True Base Class, if you will. Lisp macros are the absolute shit though, not only do they generically create functions based on type but they can also create entire forms during their instantiation. A good book to learn about Lisp macro craziness is Practical Common Lisp by Peter Seibal.
It looks like a better long-term approach would be to build up the various structures using reflection, as done by encoding/json. It would make the code cleaner and clearer, remove initialization complexity, simplify adding new types, make your code less brittle in the face of changes, and make it easier to maintain. The down side is that there is that the reflection code is involved and requires a deep knowledge of both the reflect package and Go type system. But the encoding/xml package that would give you a good starting point, and all the complexity would isolated within your encoding package, which can be extensively tested. If this is a toy project for you, then it may not be worth the effort. However, if this is going to be a long-lived project with a number of users (as your comment implies), I would strongly lean toward that approach.
First thing I disabled when I installed GoSublime in Sublime Text: gofmt-on-save. Great formatting for the compiler I'm sure, but one that Nopes me out, as the guy who spends hours, days, weeks dutifully composing and more importantly reading all that code. If anyone ever wanted to fork my stuff, they could surely just gofmt it themselves. Secretly hoping this is going to become a slogan among the Go guerilla / caveman coders: "go fmt yourself!"...
I stopped reading when I saw you stopped reading.
Perhaps a more important problem is when you add type #21, it's very easy to forget to add a case clause to one of the type switches, and the compiler won't warn you at all since it doesn't realize that the interface{} is supposed to be one of a fixed array of types. 
In my opinion, the decision to implement a new cross-platform GUI toolkit a la Java is very bad. Java's history of toolkits has been extremely unsuccessful, with only about 2 programs that I can think of that are even moderately worth using -- and both unpleasant. By contrast, supporting an already established GUI toolkit by having quality bindings to it is a very good idea -- for example, Python's support of everything under the sun, and notably GTK. Speaking of GTK, Go already has bindings for it, and GTK is fairly cross-platform. Realistically though, the dream of cross-platform GUI toolkits is likely never to come to fruition. Simply: there are already "standard" toolkits on each platform that the operating systems want you to use to be able to fit into the look and feel of the rest of the system. The best thing to do is to write your "app" as a cross-platform library, and then write separate GUIs for each system, fitting the HIG (human interface guidelines) that each system provides (Windows, OSX, and GTK all have them). So no, I don't believe this is what Go needs. On the topic of generics... I see the need for a feature like this, but I sincerely hope that the geniuses at Google can devise a better system than what Java/C++ offer. Both systems are really really trashy for different reasons. Just about any long-term C developer will tell you that C++ templates are synonymous with "the devil". Personally, I'm not too put off by interface{} &amp; reflection, but I understand that it's far from ideal.
But then you miss out on all those really insightful conversations about indentation: call_function_foo(arg1, arg2, arg3) #vs. call_function_foo(arg1, arg2, arg3)
I'm all for collaboration, but not on the code-file level. If someone at some point "takes over" one of my packages or individual .go files, I'm most likely "done with them" and they can gofmt them as they like. I even believe thanks to Go's common style of having small self-contained packages rather than monolithic libraries, even individual packages can be done by individuals alone, then linked together as needed. But if I ever were to participate in an intra-package collaboration, then good news, we can have multiple .go files form a single package, some of them may be gofmt-ed, others not.
What do you use instead?
Cross-platform toolkits (Swing, Qt) have failed. Today's cross-platform UI layer is the Web.
I do agree that `go fmt` would be useful here, but I really don't want people to encourage this sort of one-off dismissal here on /r/golang - let's do better than that.
It looks like you're using Hungarian notation, but I'm not sure if you're using `t` for `type` or for `struct`. I guess that's why I generally don't use Hungarian notation.
Thank you! 
We could build a site like http://www.140byt.es/ that combined user gist.github.com with http://play.golang.org/ for testing. Someone would need to make the wrapper site - everyone else can just go nuts.
If someone has gone out of their way to make their code harder to read then not reading it is a perfectly reasonable response.
It's not my intention to make my code harder to read for everyone else. It's my mission to make it as easy to read as possible for the one person who will most likely read it the most, most of the time, for the time being. That there is a tool out there that will make it also extremely easy to read for everyone else is a great bonus. But why should I run it myself just for this one instance of showcasing a small situation where generics would have been of great help?
Yeah it's called gotgo. Last time I looked into it, I decided against using it, though right now I can't remember why. Should look into it once again...
It's not hungarian notation. I don't prefix every string with s, every float with f and so on. Just types and interfaces. I first tried coding like that: type Foo struct {} type Bar struct { Foo Foo } var bar Bar bar.Foo = Foo {} Couldn't see the woods for the trees that way. Having TFoo and TBar is a clear "don't even need to think about it" indicator that works great for my heavy reliance on auto-complete and just makes me that much more productive.
You're actually make it harder to read for yourself because you're avoiding learning to read the standard style and are instead importing some style that you're used to from some other language. A lot of the style issues aren't even correctable through gofmt, things like the way you're naming variables, types, interfaces, receivers and the way you've got files with only a few lines of code in them. 
Pretty good stuff! I did consider this approach, not sure why I didn't go for it. Would have simplified things indeed. It would kinda-sorta OK to have all 20 element types implement an IElement interface, because the user could safely assume that when working the "Materials" library, its elements would all be TMaterial. (Bear with my notation, you get the idea.) They'd still have to use a type specifier on the IElement, as in elem.(TMaterial) but I guess that wouldn't kill them. Now if I hadn't already implemented all 20 types as fully-typed collection types, I'd go that route. But since I have, I'll keep it and save myself and others numerous .(type) converter calls ;) &gt; I will ignore your pride Thanks, it's not about pride for me here. I love gofmt, because it lets everyone else who wants to, understand and read my code more easily. I also love that I don't have to use it myself, so that **I** can also understand and read it more easily. Save for this one instance of show-casing a potential generics use-case here on reddit, I'll be the one reading all this code the most, most of the time. I like to keep it in what's the most readable format for me, knowing safely that if anyone ever wanted to read it themselves too, they could do so easily with gofmt. Guess next time I'll use a gist that's a gofmt-ed version of my own repository's .go file version. I didn't expect everyone to get that worked up about it, when the issue here clearly was just a "peek into my generics desire". &gt; since you're embedding tLibraryBase anonymously, you don't need to name it. This is equivalent: I know that. I just find it a lot more clearly spelled out where that's coming from when revisiting such code later on. Another one of those "don't even have to think about it" things. Also, actually that's an interesting question -- I have something like this elsewhere: type THasDoodad struct {} func (me *THasDoodad) init () {} type THasThingy struct {} func (me *THasThingy) init () {} type TElement struct { THasDoodad; THasThingy } func newElement () (el *TElement) { var el = new(TElement) el.THasDoodad.init(); el.THasThingy.init() return } If I just did el.init(), which one would it pick?
"Pedantic and tedious"... yeah, after this thread full of really rather off-topic gofmt remarks, iknowthatfeel.jpg
&gt; go nuts I see what you did there. That sounds like a great idea though, I may give it a shot if no one else wants to try.
I think the dynamic typing was in regards to generics. That is, every dynamically typed language supports generic programming techniques trivially. If a language can't get me generics, it should at least have the courtesy of getting out of my way and letting me write the &amp;\*#@ code. :-) 
Yes, but don't you think "I don't have anything useful to contribute" would be a better comment? If you didn't read the code and don't have anything useful to contribute; sure, fine. don't read the code. *dont comment on it either then*. 
That's too bad, though I haven't found the desire to use Go for non-server programming yet. Cheers. 
That a tool like this doesn't already exist goes well with the unnecessarily verbose output of xml.Marshal as evidence that the golang community has not (at least until recently) been especially interested in XML. Looks like that's changing...
Works for me: $ cat flag.go package main import ( "flag" "fmt" ) func main() { s := flag.String("test", "", "Test accepting a string") flag.Parse() fmt.Println(*s) } $ go build flag.go $ ./flag --test "foo bar baz" foo bar baz $ ./flag -test="foo bar baz" foo bar baz EDIT: Brain fart.
Instead of writing this comment, you could gofmt the code twice.
Yes, the problem was mine. I was passing through parameters in a script using: gocmd $* Instead of gocmd "$@" Thanks.
Yes, the problem was mine (in the shell). I was passing through parameters in a script using: gocmd $* Instead of gocmd "$@" Thanks.
You can use the rewrite feature of gofmt to get an approximation of generics. $ gofmt -r 'List -&gt; IntList' list.go | gofmt -r 'Item -&gt; int' package list type IntList struct { item int next *IntList }
The verbosity I see in Go 1.0.2: * paired opening &amp; closing tags with no content where a single &lt;element/&gt; would do. * xmlns declarations repeated in child elements where equal declarations on parent elements would be inherited anyway. It's no big deal to me, I'm just noticing xml is not a preferred encoding.
Don't resist this, man. Just use go fmt. It makes everything nice and consistent.
You cannot use Web UI layer for everything. For eg, complex GUI for many scientific, medical instruments needs native desktop interfaces.
Would be awesome if there was an x-platform Go binding to either the **WebKit** or **Gecko** rendering libs, and if such a binding could be easily hooked to an OpenGL framebuffer (which itself would be either the one corresponding to a GLFW window, or one corresponding to an OpenGL texture object). Why would this be great? Well, GLFW (which has a solid Go binding) gives us very basic x-platform windowing (open/close, resize, set-title, keyboard/mouse input, optional event hooks / callbacks for all those, and OpenGL context creation for further content drawing of any kind). And OpenGL: we have at least two solid Go bindings here. So all we need for client-side "app-native" GUI is WebKit or Gecko, and **voila!** -- "easy x-platform desktop GUIs in Go": make them look &amp; feel like a native OS app or like a contemporary web app, your choice; it's all in your CSS (or lack thereof). HTML+CSS+JS are just a great language trio for defining both really simple and really intricate GUIs. Why adopt a Swing or Qt or Gtk or WinForms or Cocoa or whatever monolithic one-sided GUI design approach, when those two web renderers have been in the making for a decade, have been massively optimized and are getting improved on daily by most dedicated skillful developers, based on the daily real-world feedback of probably over a billion or so active users...
OK, OK... I'm on it ;) https://github.com/metaleap/go-xsd WIP.
It makes me sad that Firefox nightly trips up bad on this site... Guess the once-great giant is starting to get old and slow...
I would guess not; they likely contain their size as well as the raw bytes (thus a byte slice).
Strings know there length so they don't need to be null terminated. Since slicing a string gives you another string there is no way that they could be null terminated
Thank goodness they're not, C-style strings are a hassle. They are prone to buffer overruns, and getting the length is O(n).
Yes. Under the hood strings are just byte slices with UTF-8 encoding. It makes the handling much easiert. If you are working with cgo, a cast to C.String will convert it to a null-terminated string.
Under the hood, a string is 2 words: a length and a pointer to bytes elsewhere in memory.
They don't have to be UTF-8. They just hold arbitrary bytes. Go source code has to be UTF-8, so string literals in UTF-8 end up being UTF-8 strings, but you can do: s := "\xff\x00\x7f\x80\x81\x82\x82\x04" ... and represent any binary data. 
In general, turning into a giant will do that to you...
&gt; It's still a little rough around the edges, but I think it's far enough along people could find it useful. [Worked for Netscape](http://diveintohtml5.info/past.html)
There's a "cheat" to solving sudokus incredibly fast, which is ... solve them backwards! If a sudoku is taking long to solve, chances are you had bad luck and started solving it from the wrong end. As an example, the "sudoku_difficult" puzzle is solved in 6ms if done in reverse, as compared to 92ms for going at it from the front. This is obviously extremely dependent on the puzzle at hand, but the idea should be possible to implement with Goroutines, where we can simply run the regular and the reverse solvers in parallel. If there's a good way to abort, anyway.
Hah! Thanks that was a good read. Does make me wonder if any email clients generate message bodies with a type of application/xhtml+xml - enmime doesn't look for anything but text/html right now.
Ouch, maybe I should just shelve my version completely. I produced some randomized puzzles, and this particular sudoku takes my solver ~1000x longer than the DLX version: .15.....................8....6....1..3.2.....2.............8..2........6......... 
I'm personally a bit tired of all the introductions to Go that get posted here. Where is all the cool, advanced stuff?
Why are you writing it then?
Seriously, you should watch the golang google group. People announce their cool projects.
"Done" -- mostly. I think. http://www.reddit.com/r/golang/comments/13272k/asked_11_days_ago_for_a_tool_to_generate_go/
Actually need to do more testing. Major focus last few days was "just generate packages that will in fact compile". Now I focus on "let's see if those generated packages actually work". But as far as the makepkg/tests/rss prog goes, seems to be "generally working as expected". Gonna test more sample files and XML formats, before declaring this thing officially "done at last".
You sir are a scholar and a gentleman, I'll be playing with this extensively today.
Good man!
My reasoning is that Go is still pretty new to a lot of people and having a wide range of resources to learn from never hurts. I agree that I'd like to see more advanced stuff to help me learn even more, but I haven't really found much of that yet. If you know of any resources, please post them!
Doesnt the need for this suggest some deficiency within the language? Edit: http://www.recursivity.com/blog/2012/10/28/ides-are-a-language-smell/ 
Nah don't think so, what kind of deficiency are you thinking of? Generally speaking, a need for some specific *library* is never an indicator of a deficiency in its *language*, as that language was used to express said library fully. Ultimately, that's like saying "oh you wrote a fibonacci function? Doesn't your need for it suggest some deficiency within your computer's processor?"... think about it. OK I guess code-generation is a special case -- you could argue "your compiler should provide this type of code-generation so you don't have to". While that may be true for generics, there are many other needs for code generation that compiler writers shouldn't have to worry about predicting them all. For any given compiled language out there, there are myriad code-gen frameworks or libraries as well. In scripted languages people do it all the time and just don't even think of it as code-gen, "hey I just run this concat()'d string through Eval() quickly and proceed with life". So, don't see a language deficiency in Go here at all...
What language comes with a code generator for matching XML specs? This is really silly.
Any code that can be generated beforehand can be generated by the compiler with sufficiently good syntax or language features (macros, introspect, dynamic type composition, etc.). Compare for example, all the code java IDEs generate with the obviation scala's syntax provides. 
substitutionGroups now also supported. Still all quite brute-force, will have to spend another 1-3 days optimizing where possible. But kinda sorta does the job for now -- can use the generated packages already. They will become smaller / more streamlined shortly, but from what I can see they can certainly already be used for encoding/xml.Unmarshal()...
Did you read the slides? It's not just a high level intro. Half the talk is a walk through of a real Go program.
&gt; Compare for example, all the code java IDEs generate... Isn't that what this tool is doing? what... you think IDEs work by magic?
Nice. You can speed it up even more by looping over just one variable instead of x and y for the loops where it is possible. Instead of: for y := 0; y &lt; 9; y++ { for x := 0; x &lt; 9; x++ { num := b[y*9 + x] Try something along the lines of: const ( maxi = 9*9 ) for i := 0; i &lt; maxi; i++ { num := b[i] 
Yes. That's my point. IDEs cover up deficiencies in the language. You shouldnt need code generators to code. http://www.recursivity.com/blog/2012/10/28/ides-are-a-language-smell/
Looks nifty, but what is this trying to achieve? Just to see output immediately in another window?
Yes, this script runs any new files through the `go run` command as soon as they are saved. A lot better than saving, moving over to the terminal and running it with `go run &lt;filename&gt;`. I actually have a terminal window and an editor opened side by side in one monitor, so this works very nicely, Screenshot: http://i.imgur.com/vAEpR.png
Yeah according to the readme for that project it uses some OSX specific API. Not sure they both achieve the same things but it does the job for me
&gt;How do you come to the decision to use the pointer to *Room, instead of a "whole" Room, early on? Basically, the cost of passing it around. If you have a data structure that isn't small, you use a pointer. If you use a pointer, whatever knows about that pointer can modify that data without having to make copies. In his example, he probably didn't really need to use a pointer because it is small, but considering Andrew's examples are for showing off the usual workflow of go programs, in practice something in a role similar to Room would probably be large enough you'd want to use a pointer. Also, using a pointer to prevent making copies probably is less work for the GC.
I do not think that would be idiomatic Go. The data isn't magically changing; you should be able to tell if a function is going to modify a pointer you pass to it based on the function's name. If this bothers you, you should definitely pick up some functional programming because (most) functional languages feel the same about side effects.
A related question: say you have structs containing structs containing structs containing... how would you decide at what level you would use pointers?
That was a legitimately educational article for me (although I immediately reached the same conclusion about Go not really needing it). Thanks!
Read the functions like this to understand pointers. /* "That person over there entered a room. That person decided to trash the room." When this function returns to where rm.Enter(p) was called, the calle room variable isnt modified itself when p trashes the room. Rather a copy is trashed. However, since p is a pointer to a person. If p.Trash(rm) did something like. p.numberOfTrashedRooms++ in its function body that change would persist after the function returns. */ (rm room) Enter(p *person){ p.Trash(rm) } Basically everytime to enter a function you are entering a whole new scope. Which means that each variable is unique between { }s. Passing a pointer is a way for changes to that variable to survive without explicitly returning another copy of the same variable. 
&gt; "Well then, have gofmt rename it for me and I will gladly accept it..." I thought you weren't going to run go fmt? And may I ask what part of how go-fmt formats things that makes it hard to read for you?
No wait, the issue is another one. Just did a simple separate test pkg+cmd combo. For this, the error msg is "identifier too long" instead of "name too long". I'll keep on searching...
If you're interested in writing a Go app that monitors the file system, you may find the [fsnotify](https://github.com/howeyc/fsnotify) library to be useful.
Nice job!
I dislike that you can name your function with a nonsensical ʹ but you can't end it with a descriptive ?
I pondered this question at the beginning too. Here is my breakdown on pointers. If we ignore the issue of memory copying, the most important feature that pointers give us is a way to make writes to an object (struct, int etc) easily visible across the program. I can write two functions. One which takes the *value* of an integer and one which takes a *pointer* to the integer. func incValue(v int) { v++ } and func incPointer(p *int) { *p++ } if I start with a simple integer and call each function once i := 0 incValue(i) incPointer(&amp;i) println(i) // i == 1 Will print '1' to the console. The work done by incValue() is not visible because it increments a copy of i while incPointer() accesses i itself. That is all fine and good, but we don't use *int very often, but *struct is very common. So I will repeat the example with a struct. type person struct { person string age int } With two functions that increase the age. func happyBirthdayVal(v person) { v.age++ } and func happyBirthdayPointer(p *person) { p.age++ } We have the same issue as above. The happBirthdayVal() function is more or less worthless. It increases the age of a person struct but that write is lost. We can fix this by changing it to. func happyBirthdayVal(v person) person { v.age++ return v } Updating a person's age now looks like p := person{name: "Jeremy", age:21} p = p.happyBirthdayVal(p) or p.happyBirthdayPointer(&amp;p) So here we can see a key property of values and pointers. With a pointer value we can communicate back with the caller by writing to the structures that out pointers point to. With values we can communicate updates by returning the updated value explicitly. However, not everything needs to update its arguments. Sometimes we just need to read our arguments and here values can be helpful. func canDriveValue(p person) bool { return p.age &gt; 19 } func canDrivePointer(p *person) bool { return p.age &gt; 19 } These two functions are equivalent. But the first function is safer because any writes that we might make to person (althogh we don't make any here) will never effect the person we had originally. A problem I have now is that this advantage of values is harder to express in short examples. The safety we get from values becomes more and more important as systems become larger and harder to understand. But if we close our eyes and imagine a large industrial strength server application the fact that I am handing off a value to a function instead of a pointer means I don't have to read all the code inside that function to be sure that a buggy update is not made to my data structure. In practice you will probably find that the majority of arguments are pointers in Go. So a good guide would be to use pointers unless you can see a real benefit from using a value. (There is a whole other argument about pointers and performance. Pointers prevent unnecessary copying, values stored inside structs can help with data locality. In practice it probably won't matter much)
In the absence of Uriel this place doesn't seem to get much activity so I thought I'd do my bit. Slides: http://talks.golang.org/2012/chat.slide EDIT: older version of this talk? http://www.reddit.com/r/golang/comments/tmwvv/talk_by_andrew_gerrand_go_code_that_grows_with/ 
That is a great write up with good examples. Thanks.
This is obviously a very negative post about Go, but I think it's always good to be aware about what others are saying and even help them out when they are misguided...
I hope there is a recording. I'll be driving all night and will miss the live stream. :(
Awesome!
ask for invitation on Google + to lagomeetup to join 
watch live: http://www.youtube.com/channel/UC1bO7eI1bIa6XV9rZSjhikg?feature=guide 
I agree, I'll have to keep this one bookmarked.
I think this is the one you're looking for: http://www.youtube.com/watch?feature=player_detailpage&amp;v=hYChwpI3NhE#t=120s (skipped the first two minutes, as they were unedited parts of where they still were setting up the screencast)
* http.FileServer special cases index.html and redirects it to /. The other implementations probably don't do this so the benchmark is not measuring the same thing. * on my Linux desktop an appropriate GOMAXPROCS setting gives a 3x improvement * using the tip rather than 1.0.3 gives another 20% 
That line graph made my left eye twitch. I guess technically it's a graph of server performance over the time that he made each version....... no, I'm not giving him that. Make them bar graphs dude.
The folks on #go-nuts were very helpful with the review, Here are a the review notes: https://codereview.appspot.com/6850101/ , hope others find it useful 
You also have to set the the sent headers to be the same. 
Caching the file in memory, avoiding opening a new file handle for each request... That'd probably get you pretty far.
So reuse the slice, growing it as needed. Eventually it'll reach the optimum size. 
It looks like it has more to do with not creating a new thread for each connection.
Recording of the Los Angeles Meetup #2 - Introduction to GO - The Go standard library Part 1. Slides: https://github.com/lagomeetup/talks Please send comment and send suggestions or erratas if we said something that is not accurate. 
You could use a sync.WaitGroup to handle the processOnly case. Create a WaitGroup (lets call it wg), call wg.Add(1) before firing off each goroutine and then have each goroutine call wg.Done() before finishing. In main you would wg.Wait() before exiting. This would add some overhead for the http case too, if that's a concern you could make all this conditional. Edit: removed a nonsensical bit
The first implementation actually kept and reused the buffer. I ditched that implementation in favor of the current one because I think the buffer is too rarely used to keep it. A program – in my mind – shouldn't print it's stacktrace more often than maybe every hour. Having a possibly large buffer (think a couple thousand goroutines) lying around in memory didn't seem like good design. Also: Could you specify what you meant by *“not doing any favours by releasing memory at every moment you don't require it”*? As far as I know the Go runtime keeps the memory allocated and is just redistributing it. So OS-level reallocation is not necessarily happening.
[code](https://gist.github.com/4147299) fprintf: 18566.14, 18997.93, 19213.67 req/s io.copy: 18488.61, 19968.76, 20554.21 req/s new fh/read: 9474.14, 9664.41, 9224.40 req/s Go does not create an *os* thread for each request, though there is a slight overhead in launching a Go Routine per request. As a reference, the OP's code serving a file containing the same string as my tests: 8290.11, 8094.53, 7799.60 req/s 
Yeah good call about both SIGUSR1 frequency, and allocation strategy. I've reread the code and noticed you retain the best `n` for next time. I was too hasty in my criticism, apologies.
Thanks for sharing this, but is there going to be a HD version of that video?
"This video has been removed by the user." [This one](http://www.youtube.com/watch?v=ObbRiJEKSBM) seems to work, though.
Started watching, but was put off by how unengaging the speaker was. The idea of one hour listening to that speaker was dreadful. Sorry if this comes across as harsh. Downvoted. 
Ah, they cut out the cruft at the beginning and end I suppose. Funny, I can see the re-encoding artifacts. Or is that an unsharp mask filter?
&gt; What I wanted to show was the development time to write a basic file server So why does he conclude that the Go version "wins" when nginx is both much faster and requires no development time?
I can't speak for everybody but it might be that people coming to go do it because they appreciate the bare to bones feeling, the lack of cluttered layers and API. You might find a correlation between the liking of go and the disliking of ORM. Personally I always found that ORM mainly gives the worst of two good worlds. Other explanations may be that * Go is still young, so many lib/solutions aren't yet present. Making a good ORM takes time and involvement * ORM are mainly used in corporate non innovative environments, where Go is only starting to appear * OOP is very light in Go and Go coders tend to think less in objects * lib creators may be more interested in the NoSQL trend those days * the database/sql API is easy to use and less verbose than most equivalents in other languages and it already does transparently many type conversions
Take a look at the slab allocator as used by the Linux kernel and others. The idea is to save on both memory allocation/free time and object initialisation/destruction time by allocating 'slabs' of objects. When an object in the slab has been used and is freed, it isn't completely destructed. Say the object contains 5 lists, you'd empty the lists but not delete them. So when the object is re-used for a later allocation, less initialisation must be performed. It's not a method that fits every use case, but it's certainly helpful where you have large objects with complex initialisation (as exists in operating systems kernels). In Go, I imagine slabs could easily be implemented as arrays and/or slices.
int is indeed word sized. A word on 32 bit CPUs is 32 bits, on 64 bit CPUs it's 64 bits. That's what word means and that's why int doesn't have a specified size (like int32). The major reason why int is variable sized is that by default array/slice lengths/indices are ints which need to be 32 bit wide on 32 bit address systems and 64 bit wide on 64 bit address systems (e.g. so you can have a byte array of more than 4 GB on 64 bit machines).
That is what I thought. But I just whipped up a little unsafe.Sizeof(...) for an int on an x86_64 Ubuntu vm. It printed 4. It's a somewhat old compiler now (~6 months) but I didn't expect that. Could you give it a try on your pc and tell me what you get. Edit: Just confirmed I was using the right compiler echo $GOARCH amd64 arch x86_64
I'm not sure it's Go + ORM, or just dislike of ORM in general.
I would have to agree, as well as some of it may be some of the dislike of ORMs is also just the developers view on ORMs. Personally with Perl being my first language I did a lot of work using Perl's [DBI](https://metacpan.org/module/DBI), which Go's database/sql reminds me a lot of. Both handle talking to the database for you very well, they both support query binding, I don't have to layout my databases schema in a way that an ORM can read to be able to do complex queries and/or joins, and much more. I have found that because of the way database/sql API works I have not seen a need to use a ORM in Go.
&gt; OOP is very light in Go and Go coders tend to think less in objects This is the second time I've come across this sentiment on the topic so I'll definitely keep it in mind! I've mostly been doing Ruby lately so, I'm starting to experience the troubles of misapplying designs already. Hopefully not for long. &gt; the database/sql API is easy to use and less verbose than most equivalents in other languages and it already does transparently many type conversions I was trying go-couchbase and had a similar reaction. I was thinking "ok, I need to cast this, and get this value in" only to realize the simple record struct took care of getting the json in and out sanely. Thanks for the input.
Thanks for link, checking it out.
I could be missing something, but it seems like you are decrementing 'nodes_left' twice unnecessarily on line 49 and 55 in https://github.com/kjk/kjkpub/blob/master/gobench/bintree3.go Which, if I'm not going insane, would mean it uses twice as much memory as it should...
&gt; ORM are mainly used in corporate non innovative environments, where Go is only starting to appear Yeah man, Rails is basically the same as COBOL, right?
making an ORM is typically a bigger undertaking in statically typed languages, and takes a lot of knowledge of the type systems at hand, so, off the bat, it's just not as easy to do in Go. E.g., ActiveRecord, the ORM in Rails, uses Ruby's method_missing functionality to allow the developer to just name nonexistent functions and then compute their role at runtime. That's not possible in Go, since you can't call nonexistent methods. That's one very extremely over-simplified example of one tiny portion of what ORMs do (and is not at all meant to be representative of the problem in its entirety), but it's the *type* of difference that makes implementing an ORM comparatively more nuanced in a statically typed language. another factor is that the landscape of databases is undergoing a lot of fracture right now, with so many different models currently being tried out. When Rails was getting started, for example, the community behind it (i.e., back end web developers in general, not Ruby developer specifically) was more unified in using relational databases. it's partly a language thing, partly a cultural thing of the specific people using Go, and partly a market thing right now. Now, that's not to say that Go won't see useful database *abstractions*, it's just unlikely that they'll look much like the ORMs of other languages, because Go's type system is significantly different than many other languages. E.g., Ruby and Python's type systems are less dissimilar than Go and Java/C#. &gt;Is it something about how it can handle serializing structs on your behalf? well, no; that's only a part of what an ORM does. E.g., if you have some application-level object that associates to N tables in a relational database such that the saving of the object demands saving N rows (one per table), and they must be inserted in a particular order and executed as a transaction, the transaction management is something that goes a bit beyond mere serialization that would fit within the purview of an ORM. The MongoDB driver mgo, for example, serializes structs to BSON in a way that's very easy to use for the developer, but that also has a lot to do with the fact that it's *only* doing serialization, not transaction support, because that's inherently how Mongo works.
Are they 64-bit on tip? I thought I saw something to that effect on the mailing list.
For short code, normally I just use 'run': go run concurrency_example.go
It takes a big man to admit his errors.
The code looks fine, except for a few hardcoded strings, like this from the "fileHandler" function: } else if path == "/wm" { path = "/weltmeister.html" Taking strings as parameters and/or using const () at the top may be cleaner. When that's said, it's nice to see Go taking over tasks for which it should be really well suited for.
Thanks for the suggestion and the feedback!
It's so dangerous to philosophize about languages you don't code in...
I believe this is a wee bit old, but still a good watch because of the Google search engine example.
So if I am interested, then because you are not, that invalidates my views?
I'm gonna go ahead and state the obvious. The fact that you took the time to response instead of going about your day means you care.
It is very old. I apologize to anyone who has already seen it. I posted it because I hadn't seen it before, and I thought that I had seen all of the Go videos on youtube.
&gt; Go does error handling by returning multiple values from a function, where the second return value is expected to be a value of type error. This makes it sound like functions in Go always return two values, the second of which should always be an error. A less ambiguous way to put it is that Go allows functions to return multiple values, and handles errors by optionally having one of those values be of type 'error' -- by convention the last, but this is determined by the return signature of the function.
Yeah was just about to comment about this as well but seems that it's the only thing discussed here at the moment. Anyways, creating section "Error handling" and only showing example that completely ignores the error really is a bad thing to do. Even changing the "_" to "err" in the example code while leaving the "can be ignored with _" part there is much better, now it's just encouraging people to ignore errors.
&gt; I could easily just do this in Ruby, my language du-jour, but ... [I] won’t have access to all of my system’s resources due to the GVL1. Not a problem at all when you're blocking on I/O.
It honestly shocks me that people are still making mistakes like this. I'm sure Instagram are aware they use plaintext cookies, but just don't care. There probably wasn't a need to write a PoC for this, but it's nice to see Go being used as many places as possible.
It's especially interesting because `go run` was being used. Much like the user looked at it like a simple script, not a binary he wrote.
I hadn't seen it, so thanks.
A short example would be helpful - not sure where to start when looking at the pkg docs.
I haven't written one myself yet, but you might look at "example tests" to get them into your go docs, a la: GOROOT/src/pkg/image/decode_example_test.go 
The Go official Hello World example ignores the error from `fmt.Println` too. Then again, if that fails how could you possibly handle the error?
Using a file system and using a simple, hierarchical store for small bits of data in an application lead to different design choices.
In a way, yeah. Seems silly though, given the decades they existed beforehand.
It's an object store where you can store and retrieve Go objects. Assuming your objects are structs or maps, you can also add indexes on top-level elements resp. keys, and query your objects. All the data is stored locally in the filesystem.
Except filesystems won't have any assumptions about the data stored in them, index parts of it, and allow queries based on these indexes. A filesystem is a key-value store, but what I built puts a layer on top of a key-value store.
Good article. I would bring up this oddity up on the gonuts mailing list. I'm sure someone will chime in on why or opps. 
You might be interested in https://en.wikipedia.org/wiki/SkyOS#SkyFS , file systems in general maybe doesn't go to this level of integration but I don't see any reason why a filesystem can't have these features especially with FUSE in existence
Not to disparage the author or project, because this does look pretty neat, but I think it's nearly insulting to call this a "SQLite equivalent." The SQLite team puts a ridiculous emphasis on QA and testing. (http://www.sqlite.org/testing.html#coverage) Simply put: SQLite is _not simple._ Or perhaps more accurately, its _deceptively simple._ -- It's going to be very hard to even approach their level of completeness. I think by equivalence the OP must mean: stored to a file, and fairly "plug and play." -- Which is a fair assessment in some regards, but there's just _so much more_ to SQLite than meets the eye.
Hm, I found https://groups.google.com/forum/#!msg/golang-nuts/4RUj8UJGbUA/8bumqbNlbD0J and that suggests that it's actually considered a feature for both cases.
I had noticed that functions do this, but never other types. I'm still not convinced it's a feature, but it probably doesn't do much harm. It's like finding out that you can unclick your seatbelt even when the car is in motion: if you feel unsafe, don't do it.
Did somebody ever handled the error returned by `fmt.Println` ?
What's wrong with using `go run`? I think it's a nice tool for compiling and running the thing you've just compiled.
I saw this after those "now exploits are being written in golang" posts from last week. Very nice!
From the announcement: &gt; First, _[go get]_ doesn't support package versioning – it always installs latest version. If someone wants to install previous one, he/she has to use git/hg/svn/bzr manually. Therefore, package authors are forced to maintain backward compatibility since first commit. If they want to remove some API, they should use a different repository. This is only half-accurate. There is a contract between both the package authors _and the package users_. If the upstream package API changes, there needs to be a period of backward-compatibility in which downstream users are expected to make the transition. It doesn't necessarily have to work back to the first commit. If it is completely impossible to resolve this API skew, then yes, it becomes a different package altogether. Once you remove two legs and nail a beak, webbed feet, and wings onto a dog, it's not a dog_v2.01.07a. It is a duck. In general, this is exactly the transitive dependency problem that go tries so hard to avoid. If package _A_ depends on _B_ and _C_, and _B_ also depends on _C_, then _A_ and _B_ had better agree upon which version of _C_ they will use. If this is impossible, they need to depend on different targets. Calling it "versioning" simply side-steps the issue that _A_ and _B_ cannot share a _C_. Criticism aside, it's always good to see more options available in the go community. Packages and APIs do change, so philosophy aside, I hope this site makes go more useful to a broader audience of developers.
&gt; There is a contract between both the package authors and the package users. It should be. But broken links on Go Projects Dashboard shows that package authors don't care. They may not even know their packages are actually used. &gt; Calling it "versioning" simply side-steps the issue that A and B cannot share a C. Typically, A and B should both depend on version "1.\*.\*" or "1.&gt;=3.\*" (1.3.\*, 1.4.\*, etc.) This way they can share. (It's not implemented yet, but planned).
Neat, I believe more scientific libraries like this need to be written in Go.
From a brief look the code commonly ignores errors and has obvious race conditions in it's handling of files. It's a bit worrying. 
Definitely, it will draw more Perl and Python users. 
Thanks!
Glad you read the source, I tried to document the interesting parts so other Go programmers can use it to write their customized proxies. Thanks!
Yes, the code ignores some errors that can be ignored safely but maybe I'm missing something important, it would be nice if you could be more specific, specially the part about the cases that could produce race conditions, that way I can fix the code and learn something else. Thanks.
&gt; This is only half-accurate. There is a contract between both the package authors and the package users. If the upstream package API changes, there needs to be a period of backward-compatibility in which downstream users are expected to make the transition. It doesn't necessarily have to work back to the first commit. This is a hassle for both package users and maintainers. As a user, I should be able to lock into a version and *never* have to worry about it changing, ever. Why do I care if the API completely changed in version N+1 if version N works for me? And if I do want to upgrade, it's nicer to just look at the version number difference and know whether the intervening changes were backwards compatible or not (possible with a semantic versioning-like scheme). And as a package author, instead of having this "migration period" and worrying about giving users time to adjust to API changes, wouldn't it be better to be able to just bump a major version number and be done? &gt; If it is completely impossible to resolve this API skew, then yes, it becomes a different package altogether. Once you remove two legs and nail a beak, webbed feet, and wings onto a dog, it's not a dog_v2.01.07a. It is a duck. I know this is the popular view of the Go community, but it doesn't make sense to me. I'd rather ship my library early, start using it, and then change the contract later if that makes sense. (The pre-1.0.0 part of semantic versioning is useful here.) Completely changing your package name when it becomes backwards incompatible is unreasonable, and maintaining backwards incompatibility indefinitely leads to bloated, crufty libraries. Practically speaking, I bet it's a lot easier to get most maintainers to stick to semantic versioning than to get them to change package names when breaking backwards compatibility. &gt; In general, this is exactly the transitive dependency problem that go tries so hard to avoid. If package A depends on B and C, and B also depends on C, then A and B had better agree upon which version of C they will use. If this is impossible, they need to depend on different targets. Calling it "versioning" simply side-steps the issue that A and B cannot share a C. Each version is a different target. With go nuts, A can depend on C v0.0.1, and B can depend on C v0.0.2. The 'C' you get inside package A is v0.0.1, and the 'C' you get inside package B is v0.0.2.
I'm looking to go into a mix of Computer Science and Biology, so this is wonderful news. Many thanks for posting it here.
Or equally viable, fork the target repo on github, set it to whatever version you want. That way, you're absolutely guaranteed nothing changes or goes anywhere. In my experience of the "real world" people like to have local clones of upstream repositories regardless (so that companies can know for sure that their dependencies will be downloaded quickly and reliably). I feel that the Go devs were trying to get away from maven/ruby style repositories with the introduction of the go get tool, and this doesn't really solve any problems that can't already be solved.
I did my undergrad as a double major in CS and Math, with a concentration in Bioinformatics. Courses have never been much of a problem for me, so it's hard for me to give you a good picture of course load. I graduated with 160 credits in four years, where the requirement was 120 credits (i.e., an average of 6.66 classes per semester versus 5 classes per semester). Many of the classes I took were extra or not required, and I had to take a few extra classes because I transferred---so that many extra credits won't be required in all cases. With that said, depending upon the school you go to, a double major in CS and Biology could be a lot of work. Particularly when you get to upper-level bio courses where you might have to spend a lot of time in a lab. Personally, I wouldn't worry about course load being a problem until it *becomes* a problem. I've had many people in my life advise against certain decisions because it would result in "too much work." I listened to them the first couple times, and I regret it. I haven't listened since, and I'm glad I didn't. You've got to find the right course load for you. I will say though, that a dual degree in CS and Biology will look *very* attractive. Particularly since most of the criticism in the field is along the lines of "biologists don't know to program" or "computer scientists don't know enough biology to properly solve problems."
Earlier this year, I started on a Go library for [reading SAM files](https://github.com/pgarland/goSAM). It's far from complete, and I haven't touched it in several months, but it might be a useful starting point for others.
&gt; Each version is a different target. With go nuts, A can depend on C v0.0.1, and B can depend on C v0.0.2. The 'C' you get inside package A is v0.0.1, and the 'C' you get inside package B is v0.0.2. This is a bad, bad thing. Just because it hasn't bitten you ;) doesn't mean it's acceptable. It's called [dependency hell](https://www.google.com/search?q=dependency+hell) for a reason, after all. And just because it's _possible_ to do something doesn't make it a _good idea_. Allowing version skew is generally considered a _bad idea_ among practicing professionals... at least the ones I know, who _are_ still practicing. (The rest of your points seem to rest, shakily, upon this assumption that allowing version skew is a good thing.)
I hope someone can prove me wrong someday, but in the meantime I'm going to boldly claim that this will never work. Why not? for the same reason this would work: http://www.gonuts.io/-/doc/versioning . IMHO, if developers were prepared to do all that, then they'd seek an easier route, i.e just give the package a new path e.g. `github.com/a/b/v2` when there are breaking changes. 
&gt; It's called dependency hell for a reason, after all. From the [wikipedia definition of dependency hell](http://en.wikipedia.org/wiki/Dependency_hell) (or any other definition) please describe to me what part fits the scenario I gave. &gt; Allowing version skew is generally considered a bad idea among practicing professionals... at least the ones I know, who are still practicing. &gt; &gt; (The rest of your points seem to rest, shakily, upon this assumption that allowing version skew is a good thing.) Well, I definitely claim that having library *versions* is a good thing, despite the Go community's apparent rejection of them. I'm not sure I understand your point here. Can you state it a different way without appealing to authority?
That is a formal definition of a very simple and intuitive concept: your version number is X.Y.Z, and it changes as follows: * Z is incremented for bugfix releases * Y is incremented for backwards-compatible minor releases * X is incremented for backwards-incompatible major releases Semantic versioning is a nice, sane versioning format that already sees widespread adoption.
This reply is great! thank you for your time, I should go back and check those functions again, in my defense I duplicated many functions and just adjusted little things to accomplish specific tasks, guess I should be more careful. Thanks!
Have a look at [GoProxy](https://github.com/elazarl/goproxy) maybe we can share some code.
The one thing about programming is that the more languages you know, the better a programmer you will be. Go will probably expose you to unfamiliar paradigms, in particular goroutines which are a pretty neat form of achieving concurrency without the hideousness of threading. You will also be familiar with a new tool that may be useful to you in the future. (It's good to be able to say "hey, *x* language would probably be the right hammer for this job" because you're already familiar with it.) Go can be used as a general purpose programming language, from writing systems programs to even high concurrency web apps, although with the latter, I've found NodeJS to be slightly superior. It's a very fast language and extremely frugal with memory, which is one reason it stands out and is particularly useful as a systems programming language. It's overkill for scripting though! In any event, you just should learn it for the sake of learning it. You may like it, you may not, but you'll be better off as a developer because you learned it.
There was [a related question on Stack Overflow](http://stackoverflow.com/a/11465231/263525). For me it's fantastic for server stuff, especially when you need concurrency.
All the discussions I saw (none recent) concluded this wasn't for soon. This doesn't look like a trivial task. Was there recent positive discussions or announcements ?
No I don't think there's anything upcoming. A lot of work needs to be done, especially with the GC, before it's ready for prime time on Android. I very much prefer Go to Java so here's to hoping!
I agree. I'll just add it's also very good for small shell utitilies.
I'd like to see that, but I see more problems with the sandboxing (would it need to be packaged uncompiled ?), the authorizations, all mobile API, widgets, and so on.
Honest question : does NodeJS really offer "high concurrency" ?
NodeJS is not a language. And comparing NodeJS to app written in Go is an insult.
At the moment there are no reliable crossplatform bindings available. I use [gothic](https://github.com/nsf/gothic) which is a tcl/tk binding written by me. It works for me on linux, with minor adjustments will work on macosx/windows. So, basically I write gui in TCL, but in tight cooperation with Go. For example there is no need to use TCL's events, I can just fire a goroutine with for loop and a time.Sleep inside instead of timer events. Works fine.
&gt; Programmers who have been around for a while know that async style of programming existed before Node.js. Of course it has. The reactor pattern, evented IO, etc are all wicked old and probably older than me. What's your point? &gt; Programmers who have been around for a while know that there are better ways of writing concurrent applications. Depends on the application. Actors can be better where you need to spread work over many distributed nodes. Threads can be better for GUI applications. Fibers (at least Ruby's notion of them) can be good if you enjoy misery. Concurrency can be achieved in many different ways, and again, it's best to use the most appropriate hammer for the job. There's not a golden hammer. &gt; Programmers who have been around for a while know that there are much better designed languages than JavaScript. Without a doubt. JavaScript's not beautiful, and its prototypal inheritance model is retarded. It also has a lot of baggage. I never commented on the beauty of the language. Again, what's your point? &gt; Programmers who have been around for a while know that Node.js is framework written for JQuery kids(Ryah Dahl words). Client-side JS development is very different to server-side JS development, with pretty much the only common component being the language. Again, what's your point? In all of the above, I'm just not sure what your point is. In fact, I'm not even sure what you're arguing against. All you've done is regurgitate tired flamebait to someone who doesn't think NodeJS, JS, etc is always teh awesomez secret webscale sauce!!!11one!! Programmers who have been around for a while know that different languages, patterns, frameworks, and libraries are useful and appropriate in some cases and it's a matter of picking what works best for the problem at hand, taking into account all relevant factors. Anyway, Mr Troll, thank you for playing. Better luck next time. (Oh, and thank you for downvoting all my comments. That sure showed me how wrong I am!)
The point is that it's not reasonable to choose a broken language, spaghetti-style coding and framework with creator that sold the trademark and left and the maintainers moving away.
&gt;It's great for handling thousands of simultaneous connections you might want to check some benchmarks.. https://github.com/ericmoritz/wsdemo/blob/results-v1/results.md thanks, but i stick with golang. 
It's not a broken language. It might not be your favorite (nor is it mine), but I can successfully solve certain problems with it, while achieving availability, reliability, and responsiveness requirements, *and* make money too. I was able to do it more effectively than I could with Java, Ruby, Python, or Go. I'd have preferred to have used Ruby tbh, but EventMachine is poorly implemented and prone to both deadlocks and livelocks, and Ruby 1.9 MRI is slower than V8. I'm not a fan of Java or Python, and in early tests Go wasn't performing as well as I'd have hoped. &gt; spaghetti-style coding Yup. Callback hell can be a pain and it's more difficult to debug. &gt; framework that the creator sold the trademark and left and the maintainers moving away. Lul wut? The ecosystem is healthy. Look, JavaScript/NodeJS/whatever is useful *sometimes*. I didn't argue it was appropriate all the time, or flawless, and I'm quite forthcoming about its shortcomings.
Hello, and welcome to Simple Benchmarks Are Evil. I'll be your host, notadutchboy. Stick with Go. It's a fine language and there's nothing wrong with it. In fact, I like Go a lot and it's got a strong future. Those benchmarks don't say Node is poor for handling thousands of connections, and I can think of many things that perform far worse. I didn't say Node was the absolute best, nor did I say Go was bad in such situations either. Anyway, if the absolute best performance is necessary, I'll stick to C! Those benchmarks are dubious (EC2 has notable variances in performance) and are really benchmarks of websocket implementations. Not every application that handles simultaneous connections uses websockets. There are also lots of other factors involved in choosing a language/framework/VM than just the raw performance. I've said it elsewhere and I'll say it again: Node is not the best for everything. Node has warts. Node has issues. Node is not a silver bullet. Node is not a golden hammer. Node is appropriate in some cases, especially where there are other factors than just performance, and very inappropriate in others. Go is sometimes great and is far better in some cases. Simple benchmarks, as the ones you linked to, shouldn't be the sole determinant as to which language/framework/VM/whatever you choose. Edit: On a side note, in tests I did a while ago I found Go to perform on a par with Node when using AB, but slightly less reliably. I wasn't testing websocket implementations though. Edit 2: I wrote some simple and evil NodeJS vs Go servers and benchmarked them. They both performed practically identically. There's not a significant difference between the two performance-wise. Over larger numbers of requests (&gt;100,000) with 1,000 simultaneous connections, Go was the one that had failed connections whereas Node had none. Go is great and often appropriate, but Node is better in some situations.
Not with that attitude!
I'm curious: why would you be connecting to an SMTP server from your web app with SSL? That's really only useful when you're on an untrusted network and you don't want your super secret emails to be eavesdropped. I'd have to read the RFC again but I don't even think the credentials (if any) are sent in plain text. SMTP relay is always plaintext anyway. I can't comment on the MySQL drivers as I'm a Postgres boy. :-) Debugging Node apps isn't fun and they can be very brittle. The ability to code in a synchronous style using fibers is the one thing that was so promising about Ruby and EventMachine. The trouble is EM is shoddily implemented and prone to deadlocks and livelocks. A simple server with Thin, EM, and Sinatra is dog slow and failed connections are the norm, probably because the GC doesn't properly release the file descriptors under load.
More information: * http://gofy.cat-v.org/ * https://groups.google.com/forum/?fromgroups#!forum/gofy * https://code.google.com/p/gofy/ From what I can tell, the intent of the project was never to be taken seriously. Perhaps it was an attempt to learn the language and have a little fun at the same time.
It's aiju's project. While he is a clever dude, there is basically no chance of this coming to anything useful.
&gt;why would you be connecting to an SMTP server from your web app with SSL? Sometimes you have to do this to pass security audits even if the 2 servers are on their own VLAN or dedicated internal network (eg, connecting via a private switch)
Doesn't matter, nice hobby project still :)
Realise earthbound that Go is *only three years old.* It has come this far in three; imagine what the next three will have in store!
&gt; although with Ruby/Python it's harder to cleanly work around this without using a reverse proxy or an alternative implementation Allow me to point you to the [multiprocessing](http://docs.python.org/2/library/multiprocessing.html) package for Python, at least. I admittedly haven't done much in the way of web development with Python, but from personal experience the multiprocessing package works rather well for other tasks that need to take advantage of multiple cores.
I've had vague ideas about something like this. Amazing work!
The Tour of Go is brief enough and gives you enough of a feel for it that you owe it to yourself to try it.
scanned through the source, looks pretty complete.
Nice job. Best one I've seen so far.
now it is a stable one
yeah, i maybe inspired by beedb. i haven't scanned the code of hood
Pretty useful. I've taken a stab at adding MySQL support, seems to work pretty well.
Thanks! There's some useful stuff in there that I may try to rewrite in my 'style'. It looks like it ultimately boils down to using a lot of interface{}, still, though - the two packages seem about equivalent in that regard. Although I do notice that they use the type 'Stream' to wrap the equivalent of what I call 'chan proto' - I might use the same thing myself.
my favourite https://code.google.com/p/gofy/source/search?q=fbi&amp;origq=fbi&amp;btnG=Search+Trunk
I've enjoyed working problems from the Rosalind site (http://rosalind.info/) and after working a number of problems I've accumulated a small library of useful routines. I've considered publishing it in some form, but being writting to support small and somewhat contrived problems, I'm not sure it would be useful for real world tasks. The cool thing about biogo is that it was developed specifically to support a real world application, so it's kind of guaranteed to have some relevance.
I'm sorry, but "use Node.js over &lt;any language with a modern threading runtime&gt;" is not perfectly good advice.
Node is actually pretty good for app engines. Of course, you're better off in all cases just building a browser that has access to more system resources.
This is only interesting if you've been blindly using PHP for your server side code. This isn't really a unique advantage of Go, could've been done in C#, Java, C++ etc..
Was totally expecting an anti-MySQL rant.
I think you skipped the 2nd paragraph... "easy to deploy", "very small footprint", "clean and readable", etc. Those don't apply equally to those languages. ;)
Is this available somewhere or is this just a teaser post? (That's not meant to sound upset).
 "Low power" is a relative term. I've clocked a lot of time on g++ on sub-100MHz machines. I bet Go compiles just fine, assuming it has the necessary architecture support.
Compile for ARM in your desktop &amp; execute in pi
I just did it yesterday. TL;DR - Works pretty good. Setup: * RPi (512MB version) * [Archlinux ARM](http://archlinuxarm.org/platforms/armv6/raspberry-pi) * [go-hg in the AUR](https://aur.archlinux.org/packages/go-hg/) (with a couple changes) I actually ended up building everything on the RPi. Mostly because I wanted to get an (intuitive) feel for the RPi's performance. Building Go itself definitely took a while (less than an hour), and compiling Go packages is quite fast. I was able to download, install and run my [window manager](https://github.com/BurntSushi/wingo) written in Go. `go get` had some problems and I ended up having to download some of the dependencies manually. (Wingo is a pure Go window manager, so the dependencies are all pure Go packages.) The only real problem I ran into is that the RPi firmware by default runs the X server in 16 bit mode, which sucks (and results in Wingo painting distorted graphics). I fixed that by changing [a couple settings in /boot/config.txt](https://github.com/raspberrypi/firmware/issues/41), specifically `framebuffer_depth=24` and `framebuffer_ignore_alpha=1`. The performance was better than I expected, but still a little sluggish. (There's likely no hardware acceleration going on in my window manager, since it's doing all the rendering in Go.) But it was certainly more than usable. My experience with the RPi is basically, "really cool to use for almost anything other than desktop use." But in general, Go works great. Wingo and its dependencies are in the ~40,000 LoC area and everything worked perfectly (except `go get` had a couple of weird issues). N.B. I didn't do anything special to build Go from tip as far as setting up a swap. Archlinux ARM mounts /tmp as tmpfs already, and I have the 512MB model, so there weren't any memory issues.
My first quick and dirty solution would be simply grepping the code base for assignments to underscore. grep -r "_ :?= " src/ However, I don't know of any real tools for this.
Ah, I see. You could try writing something of your own using the `go/*` packages in the standard libraries to parse and check the code. The [gofix tool's source](https://code.google.com/p/go/source/browse#hg%2Fsrc%2Fcmd%2Ffix) might be helpful.
You're right, fixed. Thanks !
A lot of these kind of tools are waiting on the go/types package to be completed since they'd all have to implement most of it anyway. Static analysis for finding unassigned returns values that are of type error should be trivial to write once this package is complete.
A suggestion for your benchmark, instead of looping upto your own value of N, use b.N from the testing package (http://golang.org/pkg/testing/#B). This will allow the testing package to calculate the time per operation.
The API of the package is modelled after the [libxml SAX interface](http://www.xmlsoft.org/interface.html). I hadn't actually seen the Token() style interface. The downside to my current API is the need for a pile of functions for events that are unnecessary. I may refactor to be more like the XML package.
Done. Thanks for the suggestion :)
I started refactoring to use the the Token() interface, but found that it requires the parser to hold a lot of state, because it can only return one token at a time. (for example the "start database" opcode needs to trigger the "end database" token as well). I'm also curious about how much throwing around structs in interface{}s everywhere will slow things down (probably not much). This being said, I may continue this refactor in the future.
Yeah, I realize that. I had to do a test refactor to answer your question :)
Could anything be done with the official Go package to make it more rpi friendly? 
Ok. I'll test with Rpi once 1.1 is out. Thanks. 
Nice. For the curious, here are the results from a fairly recent mac book pro: $ go test -bench=. testing: warning: no tests to run PASS BenchmarkBinaryTree17 1 4426168000 ns/op BenchmarkFannkuch11 1 4045467000 ns/op BenchmarkGobDecode 100 19307630 ns/op 39.75 MB/s BenchmarkGobEncode 200 9585430 ns/op 80.07 MB/s BenchmarkGzip 50000 70412 ns/op BenchmarkGunzip 500000 4922 ns/op BenchmarkJSONEncode 50 63143480 ns/op 30.73 MB/s BenchmarkJSONDecode 10 245723000 ns/op 7.90 MB/s BenchmarkRevcomp25M 5 819907600 ns/op 309.99 MB/s BenchmarkTemplate 5 366567400 ns/op 5.29 MB/s ok _/Users/xxx/go/test/bench/go1 35.983s $ go version go version go1.0.3 Edited for formatting and added the go version.
I wrote 3 web applications in Go and just wrote an article describing how Go supports writing web applications: http://blog.kowalczyk.info/article/uvw2/Thoughts-on-Go-after-writing-3-websites.html (summary: very well).
This is awesome. Thanks! 
you might want to look into how other plugins use a temporary buffer for output. E.g. the pylint plugin that is part of python-mode.
Thanks for the tip :)
Nice. The script I wrote is coming in handy for experimenting.
No, having each project have to be a GOPATH is terribly inconvenient. You realize this quickly when you try to use a library someone else has published where they'd assume you'd do this. Just put your sourcecode in the toplevel. Import it as "github.com/you/project" and use it. If you want a subpackage, `mkdir` something and have "github.com/you/project/sub". This is quite common and works seamlessly with every tool.
http://tip.golang.org/pkg/go/types/
&gt; Instead just push the executable's to it after development. Presuming you can cross compile to ARM processors from your main development machine. 
http://golang.org/doc/install
Rewrite trivial apps you like/have written in Python in Go. You learn Go and flesh out the Go ecosystem at the same time.
It looks we can install Go without Homebrew, from [http://golang.org/doc/install](http://golang.org/doc/install): &gt; Mac OS X package installer Open the package file and follow the prompts to install the Go tools. The package installs the Go distribution to /usr/local/go. 
I'm a Windows(XP)-based Python guy, I learn and use go now. install the Go compilers [http://golang.org/doc/install](http://golang.org/doc/install) use a decent Editor (to me, it's WingIDE on Windows XP for Python, Sublime Text 2 on Mac OSX for Go) Read the doc [http://golang.org/doc/](http://golang.org/doc/) Write as many code as you can~
Package management..?
The books and community links are good, but honestly, if people would just read the few concise docs on golang.org, they'd get most of what Dave has linked to.
Because homebrew can keep not just Go up to date, but also git, Ruby, Python, netcat, cowsay, etc.
I started working through [https://github.com/sdegutis/go-koans] this week. I wish there were more, but I like it and maybe seems lightweight because go is. 
That's pretty fair, I've seen more than a few uneducated rants about workspaces. Some idiot on HN created a troll account just to moan about it, only to have his problems answered only to moan more...
Absolutely this. I learned best by recoding project euler solutions that i had solved in python again in go. It's a good approach because you know the algorithm and there is a declared "right" output.
Exactly my approach with any new language. I have one problem (#31) solved in eight languages.
&gt; Moderators: Please add link to Cheny's list in the sidebar. Done.
I think "link" is the wrong word. It can certainly link with ObjC code - there just needs to be a C interface in between.
[evidence](https://github.com/skelterjohn/go.wde/tree/master/cocoa)
I agree with all points. The only thing that kind of annoys me with Go is that programming in it tends to be really boring. It just doesn't have the excitement of Ruby or Perl.
This part has made me stay behind in Python for my work for now, but the excitement of delivering faster software keeps me tinkering in Go in my free time.
(also came from Python) there's not a lot of good articles about programming Go, but there are great Python articles about a variety of topics. Once you grasp the fundamentals (not too hard, go through tour.golang.org, make a few trivial things that you had already written in Python, do that for a few weeks or a month), start reading articles about new topics you're not familiar with, that are written in Python. I have never written a Lisp interpreter, so I read Norvig's [How to write a Lisp interpreter in Python](http://norvig.com/lispy.html) and [translated it to Go](https://github.com/jordanorelli/skeam). That was a really helpful learning excersize. I'ms tarting to do the same thing with apgwoz's article [Parser Combinators Made Simple](http://sigusr2.net/2011/Apr/18/parser-combinators-made-simple.html), since I never knew what parser combinators were, but I was curious, and the examples are all in Python. That and I write web apps in Go. Oh and the Rob Pike talk [Lexical Scanning in Go](http://www.youtube.com/watch?v=HxaD_trXwRE) was probably the most helpful video I watched. His talks are really good in general. Actually all of [the Google i/o talks about Go](http://blog.golang.org/2012/07/go-videos-from-google-io-2012.html) are worth watching.
What's the *excitement* that you're talking about? 
The question is if it's just excitement from something being new or from something that actually is fun.
This has been my experience as well - Go feels very fun to write programs in.
I program both Python and Go. I'm currently teaching my girlfriend programming, and I'm teaching her with Python, but I do all of my own new work in Go. There's just way, way more beginner literature out there for Python, and much more library support. Go is a fantastic language, perhaps even my favorite, but so far the ecosystem isn't really mature, and it doesn't really have anything that is geared towards teaching people new to programming. You could in theory use Go as a first language, but I think reality would prove this to be impractical. Even for my own work I find myself having to build a lot of things that I would get for free in Python. I have my student reading [Learn Python the Hard Way](http://learnpythonthehardway.org/) and [Think Python](http://shop.oreilly.com/product/0636920025696.do), since I'm always of the opinion that it's good to see things explained by multiple sources. She's doing well and seems to enjoy both texts (or maybe she's just being courteous since I bought the second book). There's also [Python for Kids](http://shop.oreilly.com/product/9781593274078.do) for the youngins, but I've never read it. You simply cannot find such diverse beginner resources for Go.
I'd go with Python to get kids (or other newbies) started. Sort of more akin to what used to be QBASIC back in my time... Go has a lot of goodies in it that are extremely useful to programmers who're aware of programming basics and have a rough idea of computing hardware / OS internals. But they'd just distract from the basics of coding to a beginner and confuse uselessly. Going with Go, you'd soon have to explain curly braces and pointers, type conversions, heck types themselves -- needlessly for beginners who can achieve productive interesting results that much sooner (and for the time being, simpler) with Python (or Basic, fwiw). Once they fall in love with programming -- if, that is -- then they'll love upgrading their skills to Go to take advantage of its benefits and systems-specific optimizations over Python. I remember when we had Turbo Pascal in high school. Many people sort of understood the basics -- though most never understood the fascination -- but when we got to pointers, they got all sorts of confused.
I was also pretty worried about having to explain types and type conversions. The braces and semi-colons seem less confusing if you don't know any different.
I do like the fairly large amount of teaching resources for Python. that makes it easier to get everyone started. Learn Python the Hard Way is great. Think Python is new to me (thanks). What sort of things do you find yourself frequently having to create in Go?
These are strange installation instructions. $ go get github.com/axw/gocov $ go install github.com/axw/gocov/gocov Don't do that, just do $ go get github.com/axw/gocov/gocov And the path setup? export PATH=$PATH:$GOPATH"bin" Huh? Most people don't have a / at the end of their $PATH/$GOPATH [**edit:** also, $GOPATH is a list of paths] so this won't work. Instead, you can do something like this (adjust the path to wherever you want to put Go packages): export GOPATH=$HOME/go export PATH=$PATH:$HOME/go/bin **edited** to fix suggested PATH configuration, thanks burntsushi
cool :) I wrote this, glad to answer any questions
 export PATH=$PATH:$GOPATH/bin That is doubly bad advice, since `GOPATH` is a *list* of paths, just like `PATH`. (Commonly, `GOPATH` only contains a single path.)
Hm, I hadn't considered this since I use GOPATH as a single path. Do you manually put the particular bin paths on $PATH or do you have a script to do: for _, p := range strings.Split(GOPATH, ":") { append(PATH, p+"/bin") } or whatever the stupid shell equivalent would be?
Thanks :)
This is great that they've updated app engine to work with go workspaces, but imo i think it is a mistake to have magic hidden listener that depends on the global http.Handle(Func) s. One nice part about ListendAndServe is that it could take an optional http.Handler. While its use is probably a corner case, I'm sure some have found it useful. I think a better implementation would of been for a appengine to provide a package that you built against which would provide its own ListendAndServe function so that the operation was explicit, and not hidden.
There's little practical difference between http.Handle("/", handler) and, say, appengine.ListenAndServe(handler) Also, if things were as you suggest then everyone would need to write a main function containing exactly the same thing. All App Engine apps run web servers, so the system just does it for you. I just don't see the point in more boilerplate.
Because it's supposed to act like production App Engine, and that's how that works. The entry point isn't main, it's a path. In your app.yaml you can even have different paths go to different languages, IIRC. Want to have your own root handler? func init() { http.Handle("/", yourHandler) } Done. e.g. https://github.com/bradfitz/camlistore/blob/master/server/go/appengine/camli/main.go and see its http.Handle("/", root)
I wish someone would *port* SDL, WxWidgets, GLFW, OpenAL and friends to go. It'd be nice to be able to "go get" an entire app, without having to fiddle with third party libraries.
Go right ahead! Completely rewriting GLFW in Go for example would be incredibly pointless IMHO. It works great, the Go binding is flawless, even being so much slimmer than SDL it has years of development and bug-fixes behind it, I made it work under all 3 big OS'es without issues. Not sure about the other 3 libs, but generally, I **vastly** prefer fiddling with 3rd-party libs to rewriting them in Go, repeating their mistakes and bugs, and lose weeks or months in the process.
 go get github.com/BurntSushi/wingo Boo ya.
and my final update before bed: http://play.golang.org/p/wRdDJ8meEO (buffered the channel, used range instead of normal for loop)
Yes, because the function receivers are values and not pointers, they are being passed by value and thus copied to each method call. This is actually more performant for small structs.
1. Point your browser of choice to http://golang.org 2. Read the tutorials, FAQs, etc 3. Read the spec (very concise, easy to read, *fun* even) 4. Play around on the Go Playground to get a basic "feel" for it (no need for IO outside of fmt.Printf and friends at first). I'd focus on how interfaces work (surprisingly different from other languages that have a similar concept) 5. Stop trying to "translate" Pythong/C++/Java code that's already in your head to Go, start thinking in Go (you'll know it when it happens) 6. Have fun
My theory: since at least 2 structs are empty, their values essentially occupy 0 bytes, versus 4 or 8 for a pointer. Still hard to believe somehow though...
Go has copy-by-value semantics in all cases. Sometimes it's cheaper to copy a small struct than it is to copy and pointer and maybe deference it. Either way, benchmarks should be done if there's any question.
I was actually thinking about writing some basic code to do this, but I didn't even think about the tough cases like circular dependencies; I just wanted to get rid of the ugly pointer representations from my structs. I'm definitely going to use this for testing. Thanks
So probably, in this case, video chip and cpu should not be emulated in separate go routines :) We made a similar design choice about the interaction between the ULA and the CPU in GoSpeccy. Please, see this: https://github.com/remogatto/gospeccy/wiki/Architecture An excerpt from the document above: "While it may seem the Z80 CPU and the ULA are good candidates for being mapped to distinct goroutines - since in a real ZX Spectrum they work in parallel - from an emulation perspective it does not make much sense to emulate them in parallel. The reason for this is that the coupling between CPU and ULA is too strong, thus placing the CPU emulation and ULA emulation in separate goroutines would require either a lot of inter-goroutine communication or a lot of locking, and it would also increase code complexity. In consequence, the whole emulation core is basically just one goroutine." 
What is considered "small" is in the eye of the beholder. Always test if you care about this type of performance; I've passed what I consider moderately sized structs (256 bytes) by value after testing and verifiying the performance increase of doing so on my hardware. 
Using floats for prices? Yuck! :-)
Well... yeah. :P &gt; Either way, benchmarks should be done if there's any question.
Kind of, except for the whole proficiency thing... I just like dabbling.
Yeah, I caught that. I was just trying to give a more concrete definition of what small is for future readers. 
You can't serve different paths by different languages; that's versions. Each version of an app can only use one of the runtimes.
Everyone seemed really interested in this so we figured why not. Glad we could help. 
There's nothing too fancy about it, but it serves mostly as a demo for the conntrack package. It's certainly cleaner, and more reusable code than the original netstat-nat which was written in C by D.Wijsman
( ͡° ͜ʖ ͡°)
Did you try checking your emulator with test roms? I'm using those to debug. I'm interested in how many tests pass. 
I tried a different approach. I ripped out crcs that are used to verify the registers after a test and tried using that as a regular unit test. Problem is that even tho values on registers are the same, calculated crc is different. I'm kinda stumped at this point.
Poor Chumby, just sort-of got bypassed.
sessions: Gorilla sessions weren't interfaced at the time I was working on it. Apart from forking the code base, there was no way to make it backed by Redis. File based sessions would tie the sessions to a particular server, which I'm not keen on doing, plus my servers run on EC2 which is dog-slow for file i/o. Writing a session handler isn't particularly hard. It made more sense to write it myself than to fork the existing package. This is a common problem with existing third party Go packages: they don't do nearly enough to merit using outside code. In my mind, if you're going to add a dependency to your project, it should be something non-trivial. securecookie: didn't exist when I needed it. logging: ok, that's... just a link to the standard library. Logging is more than just "select a file and write to it". template caching: the thread in question is discussing the template caching in the wiki codelab example. That's written at the application layer; it's not a package that can be imported, so it just serves to prove my point that it's something that you write into the application layer yourself. Additionally, all it does is store template output in memory; it doesn't persist across webserver restarts, and it has no cache invalidation mechanisms (e.g., cache representations should time out or become invalid following some event). The template caching in the wiki example is just an example; it's not a production-quality template caching layer. object cache: this one I could have used, but again, that source code comes from Google itself, because it's borrowed from Vitess; it's, in my mind, a reach to call that third-party code. It does look like good code, but, again, it's in-memory, so it won't survive a webserver restart. For a system where you're going to recompile the app in order to deploy a new changeset, having to invalidate your entire cache every single time you want to deploy a code change is a no. twitter client: I tried a number of twitter clients. They all fail at either providing proper error handling, timestamp handling, or covering all the endpoints. Some just do streaming. Some just do the REST endpoints. Some just leave fields off. Some don't implement all the oauth stuff. The one you referenced hasn't been updated since the release of Go1. It also doesn't support any of the new stuff, since Twitter put out a new API. I'm also deeply skeptical of using a library that doesn't bother to turn a timestamp representation into a time.Time object. both of the resizers weren't around when I needed them, but they do look like good libraries. They actually both look much nicer than what I ended up using, since mine only did nearest-neighbor scaling. I found some code to borrow on one of the mailing lists, but I still had to piece it all together by hand. It's annoying to me when people say that the Go package landscape is already there. It's not. That's totally normal, and should be expected for a language that only hit 1.0 last March. Python, Ruby, and even Perl have set the bar really, really high for a third party ecosystem. Go isn't there yet. It *will* get there. I'm positive of that. So positive, in fact, I'm effectively gambling my career on it becoming true. But please don't misrepresent the situation by pretending that the ecosystem is more mature than it is. Doing so will only give people false expectations and leave them disappointed. 
False. Your position is too simplified. Even decadent. If you didn't care about the joy of programming and only focused on the problem itself, you wouldn't buy a laptop that looked good. Your computer would be bare bone motherboard with some wires all over the place. It does the job just as good as your sleek MacBook, doesn't it?
&gt; Alternatively, Go provides first-class functions and closures, which are commonly used for namespacing in languages like JavaScript. I'd recommend against doing that. Javascript programmers don't do that because it's a good idea in general, Javascript programmers do that because at the moment that is the _only_ way to provide safe namespacing, and the benefits for them outweigh the costs of an approach that is definitely generally worse than proper language support (which they are scheduled to get, though who knows when they can count on it). If you already have safe namespacing in your language, don't do that.
Good work I can definently put this to a good use. Also an excelent example for learning go. Since I am new to go I was wondering is there a way for adding additional processors beside forking the project? And in general what are the options for go apps to load dynamic binaries?
Go apps are statically compiled, so really with current structure the only way to add a processor is a fork and optionally pull request. I thought a bit about having plugin system where I would call external binaries (akin to `external` processor, but more sophisticated) with some environment and they will tell somehow what to change, but decided against implementation. I personally had no need (naturally, I did everything I needed as a processor), and thought that I should wait for use cases to arise to think about one. Though I would love to see ideas or patches. :) Not guaranteed that I'll accept them though. :P
To my understanding, closures are (relatively) slow, so I'd use them with discretion if I was writing anything performance critical. However, they certainly can be elegant, so I wouldn't shy from using them.
Absolutely, but that's usually just using closures as what they are. That's a good thing. But doing some weird thing with returning a closure closed over half a dozen "private" functions is probably never the right answer in Go. You already have private interfaces, private types, private methods, namespaces, etc. Javascript is rapidly becoming the new BASIC, with people dragging idioms out of it inappropriately to other languages, mistaking essense for accident. Best not to encourage it. It'll happen enough on its own anyhow.
I was only thinking in terms of private fields when I wrote that... definitely would be messy if it was a function returning a hash of closures or something. A similar concern came up on the Google Group so I went ahead and removed that sentence for any new readers. https://groups.google.com/d/msg/golang-nuts/OWINbSIe5hc/AH1bEDKpo68J
Hey, cool! It's so nice to see people engaging with feedback. For the record, I liked the rest of the article. I did not fully realize the bit about how the composition meant that always have a receiver that is of the original type, and how that means a naive template pattern (one of my favorite OO patterns) implementation based on false inheritance ideas doesn't work. If you wanted to do it, you'd have to do something more like: type Template struct { whatever ... Impl TemplateImpl } func (t Template) TemplateMethod () () { ... t.impl.SomeMethod() ... } type TemplateImpl interface { ... SomeMethod() ... } Interestingly, to me this more correctly states the relationship I usually have in mind between the template and the implementors, which is that the implementation classes are subservient, and it's generally an error to override the template's methods.
If you were truly performance bound you wouldn't be using Go...
It's not just you. I had the same problem last month with the [Go for C programmers](http://talks.golang.org/2012/goforc.slide) slides, which seem to use the same system.
&gt; To my understanding, closures are (relatively) slow They are? Could you expand on this, or do you know of a good article going into this? Would love to learn more. Now I do assume they might put some additional pressure on the GC due to closed-over pointers and what not, but in terms of pure execution speed (in a compiled static language such as Go) -- they are "slower" at runtime? Or the call overhead takes longer? Or...?
It would be awesome of someone would volunteer to fix this :-) https://code.google.com/p/go.talks
I'd love to fix it, but I don't have the slightest inkling of the technologies involved :(
That was fantastic, I wish I worked with Rob Pike, he is my hero.
Actually I'm not a big fan of crossposts but in this case it may make sense. Thnx
Is there a reason Go is never mentioned in the description? Just curious.
What level of experience are you looking for? I'm currently in the middle of a PhD but looking at how to transition away from research into a software development role after I finish (PhD is looking at Underwater Acoustics monitoring, I do embedded Linux development to build the monitoring tools). If you have previous experience hiring for these sort of jobs and don't mind me asking, how would having a PhD be seen?
We didn't dare to ask for it ;). Seriously it would be really great but is not mandatory. 
I was just wondering: how on earth do you actually *start* writing an emulator? Are the open specifications for Gameboy color (or other emulators), or is there open documentation? Or do you check out other's source code? What's the general procedure here, is what I'm looking for.
Just a good understanding of the language - combined with some practical knowledge. We have developed a distributed, cross platform, client-server based Check-in/Build/Test system. The experience was so convincing that we plane to replace/add other parts as well in Go.
Sorry I didn't answer the PhD question. I have a PhD myself and did it help. Honestly I don't know. In respect to hiring PhDs: We made very good experiences with the last PhDs we hired. In my opinion the key things are what you picked up during your PhD time and/or what skills you could develop. Hope that helps ... 
Is there a requirement to speak fluent German? 
 Your comment is extremely shortsighted and not even the least bit constructive. I was previously using python on some apis at work. They needed to be faster and do concurrent requests. Go gave me the speed-ups I needed along with a nice, readable, and scalable codebase.
 Will get around to testing whether our not their is a performance win here or not, but my initial guess was that with structs this small it wouldn't make a huge difference.
Thanks! And, I will. :-)
Option C: shoot whoever decided to have their API return json like this.
Fair enough. 
is this some sort of multi-line string literal? I don't think gofmt will mess with the contents of your data since that would be changing your programs behavior... If you post the relevant code, it might help Here is a line from the Effective Go guide ... &gt;Indentation &gt;We use tabs for indentation and gofmt emits them by default. Use spaces only if you must. http://golang.org/doc/effective_go.html#formatting
Hm, I'm not very experienced, but my first thought was that type Mixed could be implemented more nicely with embedded structures: type Mixed struct { Person Place } The second thing that occurred to me was that both solutions sounded like too much work for anyone to be happy with, so I did a bit of digging. What turned up \[[1](http://blog.golang.org/2011/01/json-and-go.html)\]\[[2](http://nf.id.au/go-maps)\] was the *empty interface*, which looks quite useful. One can assign values of arbitrary type to an empty interface like so: var foo interface{} foo = *[literal of any type]* Subsequently, you can either use a *type assertion* to retrieve a value of that specific type, or (if you don't know) use a *type switch* to test for the correct type: bar := foo.(*[that type]*) switch bar := foo.(type) { case *[name of a type]*: case *[name of a type]*: .... (Those examples are almost verbatim from [1].) The JSON package uses this to allow you to Unmarshal arbitrary JSON structures. From [1] again: var foo interface{} err := json.Unmarshal(*[JSON source]*, &amp;foo) bar := f.(map[string]interface{}) for key, value := range bar { switch foobar := value.(type) { .... This example involves a few things which I don't have much experience yet, notably *range*, but the interesting things are (1) that the type assertion of *bar* requires it to be treated as JSON data in that it has strings for keys, and (2) that the unknown value within bar can be extracted by assigning *bar* to the tuple *key, value*. One caveat I have about the example is that it does not *explicitly* allow for recursive structures (JSON objects within JSON objects), which would have type *[string]interface{}*. I can only tell you that I would be astounded to find out that I couldn't do that. Back to the example in the blog post. Unfortunately I'm in the EST zone, and my bedtime in night. I am very, *very* interested in finding out, however, what would happen if one tested for the struct types *Person* and *Place* in that type switch. Call me naive, but I suspect that it might work.
the Twitter streaming API works like that, too.
I generally use the [json.RawMessage](http://golang.org/pkg/encoding/json/#RawMessage) type here. You can unmarshal the original tying to a slice of json.RawMessage structs, each of which can be unmarshaled conditionally to the corresponding type. now... the article doesn't state the desired ending output. It doesn't, for example, tell us if we're interested in preserving the order of the input, or if we should separate the structs into slices of their associated type. Since the blog post examples performed the later, I will as well. anyway, I'm deeply suspect of anything that involves repeating the name of the field and doesn't use the struct tags. That's going to be very prone to regression bugs. I would just unmarshal each item to a json.RawMessage, and then unmarshal each of those with each of the potential types, checking for validity along the way. It's not the most efficient method, but it will detect errors along the way, it's easy to understand, and it's going to be fast enough for most use cases. I would do it this way: http://play.golang.org/p/IqWLPtqhEf 
The point I was trying to make is that very likely it was you who didn't know how to make Python faster and not Python's inherent performance. I'm generalising but I find this tends to be the case.
- Fluent in English language - Good knowledge of the German language
No, not for the job. But for getting around in the south of germany some basic knowledge could be beneficial.
I do know how and did make python faster and using gevent. The resulting code didn't feel pythonic though despite me banging my head at it for aa while. Go made it easy, clean, and faster.
I think this is just what I need to handle some JSON on a project I'm working on where there is a base of standard fields and objects, but the user can and probably will add additional ones beyond that. I was having issues trying to figure out how to unmarshall these in to some kind of structured data.
Right so, you changed for aesthetic reasons and not for performance ones, in the end?
You can use print and println instead of fmt.Print. It is actually better because it is easier to find debug print statements. Instead of just commenting DoSomething(m) out you can replace it with // DoSomething(m) _ = m In this case there is no need to replace m with _ in the above code. The guy should learn how to work with the language instead of trying to bend it to his own ways. Look up idioms on google.
Didn't notice this on the doc. Thanks!
`print` and `println` are there for debugging/bootstrapping purposes. They aren't part of the spec but I don't think they are disappearing from the `gc` compiler any time soon. I agree that the errors are annoying sometimes but it has made my code a lot cleaner.
The author complained about module import because he likes to debug with print: "I'm a firm believer that printing stuff to screen is a programmer's best debugging tool,". That is why I said he should use print instead of fmt.
 func trace(s ...interface{}) { if (doTraces) { fmt.Println(s...) } }
so on other modules you have the exact same problem only with importing "trace" instead of "fmt" ?
You're right.
I understood that and I did not mean to argue against you or anything. I just wanted to add that they are not guaranteed to stay in the language. (Which I phrased horribly wrong because they actually are part of the spec.) http://golang.org/ref/spec#Bootstrapping
Why debug with fmt.Print? There are two better options: * Good logging, and log to a file. You can keep the debug logging statements in and just change the minimum level of logging output if you don't want them spamming up your log. This accomplishes the same goals as printing to console, but actually persists and the code can be used later, say, in production, and still be useful. You can keep your logging import around because there's always other stuff you're going to want to log regardless. * Use an actual debugger. I've never used Go's debugger, so I'm not sure if there are significant flaws in it, though. I may be totally missing the mark, though, because I'm generally an applications programmer (C# is my primary language) and not a system programmer.
You make a decent point, and I for one upvoted you because the `_ = m` idiom is a handy one that I didn't know about, but it doesn't negate the point that the author was making. It *is* annoying to have to make sure that every single time you compile, there are no dangling imports or unused variables. There should be a flag for turning those errors off. Call it something like `--development-mode` or `--allow-bullshit`, so it's obviously not for production use, but help the developer do their work, don't hinder it.
I agree with the unused import/variable thing (it'd be nice to have a compiler flag for development which turned this error into a warning), but it is certainly not enough to keep me from using this magnificent language.
You can also use the underscore with imports. import ( _ "fmt" ) http://play.golang.org/p/Uo7ogT38x2 The thing to remember is that by requiring such strict import dependencies, go can compile things faster as it wouldn't have to search and include code not being used. Granted that this is paramount for large projects, it may feel more restrictive when playing around.
Wouldn't that make the "io" module unusable though? Or can you use it under its default name "fmt" even when it's aliased to _ ?
This sounds like reasonable ideas, however in practice there is often no much faster way to track down the problem than to sprinkle a couple of print's in appropriate places. I have used both debuggers and logging code in various projects/languages quite like you suggest, but i think in 80% cases it's just quicker to do with temporary print statements which are deleted afterwards.
When I wasn't proficient with a debugger I'd use print statements. Once I integrated a debugger into my workflow I've found that I debug code significantly faster. The amount of guessing that can be involved in printing the right thing at the right time can sometimes be a bit of a hindrance to productivity, whereas with a debugger I can set a few breakpoints around the area in question and step through it, often getting all the information I need in one build-run cycle without having to think through all variables I may want to inspect before running.
It's quite easy to make a plugin that can import and drop imports with a few key presses. The vim plugin included in the Go distribution provides :Import and :Drop commands so you don't need to jump around the file when you need to do that. I program Go on an almost daily basis and the import thing doesn't bother me at this point. I think it's a good feature from a maintainability perspective. 
Speaking of which, I haven't gotten a look at GDB with Go in almost a year. How is the integration now? 
I've experimented with using build flags to completely disable error logging... in particular with OpenGL &lt; 4 where getting the last error is an expensive operation. Something similar might be a possibility for trace: https://github.com/nathany/mantle/blob/master/core/gl/%2Bdebug.go Though I think the suggestions to use println or logging are more suitable in most cases. 
The module has no name so while it is loaded and the module's `init` function is called, you can't use anything from the package. Example: http://play.golang.org/p/I_pu9oG1uF
I really dislike this suggestion. It trades unused foo errors for *silent* unused foo errors. It may not technically be a compile-time error anymore, but it's still an error in the sense that you don't want it in your production code. This is why warnings are good - they don't stop your workflow, but are still highly-visible.
To followup, I got this working. Except that I have 'expandtab' on, so that my vim editor replaces tabs with spaces as normal. Then, gofmt fixes it up with real tabs when I save.
It wouldn't matter if they did drop out (besides the inconvenience in this context). We're talking about temporary printing statements to help trace through execution without resorting to a debugger. If you need to send formatted output as a matter of standard program execution, you will be importing *and* using `fmt`.
Ok. Thats what i thought. So I guess my point is that this doesn't really save any jumping around verses just deleting or commenting out the import? 
Having the default value for a string be "" is brilliant. Other languages always have to have some method called empty() (or similar) that checks for an empty string or a nil value.
A third option would be to use a TDD process to verify what code is doing. Though that might be in combination with the other options, it's nice to keep any temporary debug printing in the tests rather than production code when possible. Alternatively, a really simple way to keep fmt imported even while commenting things out is to just fmt.Println("some dummy text") that is left in until ready to commit.
Exactly, same for all others slices/arrays too (len==0 is nil). (Well actually the spec says slices are initialized to nil. But you can still check for len and append to them, so never need to check for nil.)
It's probably quicker to type `gg&lt;some number&gt;ji//&lt;Esc&gt;` than to type `:Drop "encoding/json"` (and it's even worse if the package was from Github or a similar code hosting site). Not that I don't like the Vim Go plugin though, it's very useful.
&gt; _ = m Which should produce a warning...
That's right. Oh, and yeah i meant 'set expandtab', but you got this right. Cheers. 
actually, checking for `nil` in the case of slices is at best pointless and at worst dangerous because a zero-length slice (e.g. `make([]T, 0, 16)`) is not `nil`, but you still can't do e.g. `slice[index]` so you should always write that check as `len(slice) != 0`
The compiler takes the address of the receiver automatically if there aren't other interpretations. e.g. var mu sync.Mutex mu.Lock() gets rewritten by the compiler to: var mu sync.Mutex (&amp;mu).Lock() 
This is just nitpicking.I agree that it would be nice to have compiler option to allow unused variables etc. but this issue is not the greatest transgression of go. There are other things forced upon programmers by the language creators and if you tried to force such things on your fellows on your own this would probably result in your throat slit at a coffee machine. For example, you can not use the following construct if x == y { How many programmers perished on the issue of where to put { ? Or another thing you must name public functions like "PublicFunction" but private function "privateFunction". How many holly wars were waged over how to name your stuff? And now these ignorant language creators made this choice for you. I have not used a language bofore go with such strict restrictions on style. I am not sure if it is good or bad BUT in my opinion go has so many other good features that I am willing to trust the language developers on this one for now. Rob Pike is a fvcking brain, maybe these restrictions of his will make me a better programmer.
i didn't know that. thanks.
SEX DURMAAR BN 
wut
I actually think the issues you name are minor ones. The reason there are holy wars about those issues in other languages is because using a consistent style is important, and the language allows multiple styles, not because one style is going to save the world and the other is going to force you to eat babies. By enforcing a certain style, the holy wars become irrelevant. Whether or not having the opening brace on its own line is inherently better, it is no longer an option so no time will be wasted arguing about it. On the other hand, never allowing dangling imports means that the programmer will frequently be taken out of the flow of their work, which means it is a restriction which decreases the programmer's productivity, whereas enforcing a particular coding style will not, following a sufficient learning curve for getting the accepted style ingrained in your motor memory.
The length of `make([]T, 0, 16)` is [0](http://play.golang.org/p/990Zv7yGkr). **edit** -- that is, you *can* distinguish between nil and [], but they're both 0 length and you can't ask for elements from within it.
That's what command aliases are for. You can also alias for common packages too. 
Whenever this topic comes up, I'm reminded of a compromise I thought up once. Basically, have a flag that, when used, makes it *illegal* to use local identifiers beginning with `_`. Here's my reasoning: 1\. Changing an identifier to begin with a `_` is similar to commenting out offending lines of code in that: - you have to acknowledge each unused identifier, and - you have to undo it each time you want to use the identifier again, but better in that: - you can target a single variable instead of a whole line of code. 2\. Using a `_m := m` statement is similar to doing `_ = m` in that: - you have to acknowledge each *potentially* unused identifier, - you don't have to undo it each time you want to use the identifier again, and - you don't have to change every statement that assigns to the unused variable, but it's better in that: - the compiler is guaranteed to generate an error for each occurrence of the pattern once you remove the compiler flag. 3\. It's similar to a compiler flag that silences the errors in that: - you can choose to no longer get notified about unused identifier errors as long as the flag is enabled, but it's better in that: - you can still catch some of the cases that are actually bugs while the flag is enabled since you disable the error on a case-by-case basis. 4\. It's similar to a compiler flag that turns the errors into warnings in that: - you can compile code containing unused imports and variables, - you can turn all unused imports and variables into errors again by removing the flag, and - you can still be notified of unused identifiers while the flag is on and check to make sure it isn't a bug, but it's better in that: - you can't accidentally overlook a new instance of the unused identifier error because it's lost in a sea of warnings you've chosen not to worry about for now. ---- There are a couple of design considerations: 1. **You still have to change your code in order to remove a specific unused identifier error.** This might be annoying if you just need a binary so you can see if another package compiles against it. However, there are all kinds of unnecessary sacrifices to correctness you have to put up with in this case (you also have to complete all statements and ensure every path in a fiction returns a value). This is more an argument for having a flag to only compile the interface of a package and ignore any errors that don't affect it. Besides, you can mitigate the annoyance by anticipating when you might not be using an identifier yet and silencing the error for it up front. The cases where you actually want to execute the code without even looking at potential errors and this isn't sufficient seem limited to me... 2. **Once you've removed an error, you don't see it again until you either specifically re-enable it or remove the compiler flag.** If you still warn, even once you've overridden the errors, you can make sure you don't forget that there might be problems until you remove the flag. However, the warnings aren't very useful once you've decided you're ignoring them for now and just generate noise. Potentially, they could be reduced to a single warning: "warning: this package contains silenced unused identifier errors; compile without *flag* for details." This might be a worthwhile tradeoff. It violates the "no warning" principle, but minimally. As long as it doesn't open the flood gates to other optional warnings to the point of it getting out of hand (this is debatable and I don't claim to have the answer), then it should be okay. 
&gt; I've never used Go's debugger, so I'm not sure if there are significant flaws in it, though. On the Windows platform I added Go support to the Zeus IDE and one of the first things that did work was the gdb debugger support. Here is a video to prove it: http://youtu.be/84i7H-E0YUM It might not be as slick as the Visual Studio debugger but it does work.
&gt; but doesn't Go have an actual debugger? The gdb debugger works just fine. 
lol hentai spam
Seems like you want to use a package from the experimental tree: http://code.google.com/p/go-wiki/wiki/InstallingExp
This link is really helpful, thanks!
The Reddit API comes to mind.
Did you set your `$GOPATH`?
Right, I'm only summarizing the talk for those who don't have time to watch the video. 
Very cool!!
If you're using Sublime Text 2 it's super easy. Simply install [GoSublime](https://github.com/DisposaBoy/GoSublime) and it will do this (and a whole lot more) for you automatically.
&gt; To help keep your code in the canonical style, the Go repository contains hooks for editors and version control systems that make it easy to run gofmt on your code. &gt; &gt; For Vim users, the Vim plugin for Go includes the :Fmt command that runs gofmt on over the current buffer. &gt; &gt; For emacs users, go-mode.el provides a gofmt-before-save hook that can be installed by adding this line to your .emacs file: &gt; &gt; (add-hook 'before-save-hook #'gofmt-before-save) &gt; &gt; For Eclipse or Sublime Text users, the GoClipse and GoSublime projects add a gofmt facility to those editors. &gt; &gt;And for Git aficionados, the misc/git/pre-commit script is a pre-commit hook that prevents incorrectly-formatted Go code from being committed. If you use Mercurial, the hgstyle plugin provides a gofmt pre-commit hook.
It was admittedly a scattershot comment. It's nearly 5am for me, just trying to tire myself so I can get some sleep. I'll read more thoroughly next time :)
Relevant commit: https://github.com/colemickens/gopcap/commit/18d1b0c33c149731053d5b2a9926f45af084d5a3 Note that I commented out some IPv6 code which I didn't bother trying to make work in Windows and I switched inject to sendpacket. I guess this one too (with the other in mind, I made a mistake in this commit) for the cgo flags: https://github.com/colemickens/gopcap/commit/3307a9a59c826f4ebf8332c1a16caba72c31258b Your stuff looks *really* nice. If I hadn't abandoned/put aside my project I'd definitely switch over to it.
while I personally agree, that doesn't mean that someone shouldn't post a tip regarding non-Free software, nor even that one shouldn't use it... Not sure as to the point of your comment.
If your using vim + syntastic I have a syntastic fork[1] that will gofmt your src on write. I tried to get it merged a while back, but was at odds with the syntastic maintainer on automatic style formatting being out of scope for syntastic. On top of that my PR got semi hijacked by another contributor and for the moment I have given up trying to get it merged. Syntastic + go works really well. I suggest any vim users check it out! [1] https://github.com/ghthor/syntastic
My manual attempt at this is here: https://code.google.com/p/gopacket/source/diff?spec=svn8349c8e84ded5695b956a8f16faff2e81b3e1dd9&amp;name=winpcap&amp;r=8349c8e84ded5695b956a8f16faff2e81b3e1dd9&amp;format=side&amp;path=/pcap/pcap.go I don't have a windows box, so I can't check this out myself. However, if someone wants to pull down branch 'winpcap' and test it out, I'd really appreciate the help!
This is true, but also rather unfounded paranoia, and still doesn't give a point to your comment. If you want to use Free software you're free too, you're also free to make an equivalent of GoSublime in your Free editor of choice and talk about that here too. I'm sure that everyone here is aware of the differences, and if they choose to use a non-Free editor they have that option (if you don't want them to then you have no right to use Free software). I'm not saying that you can't make comments like this (though they will likely and hopefully be downvoted), but I just wonder *why* you posted it, as of now it just seems like a troll attempt...
What does WWW::Mechanize do exactly? I tried looking at the examples, but the Perl made me stab my eyes out and now I'm blind.
go fmt has always puzzled me. Seems to me there are two paths: 1) Have a strongly opinionated language that dictates formatting rules (eg. python, ruby to some extent) 2) Allow users to do whatever they like (eg. c, java, etc). This middle road 'there's one way to format your code' as an opinion, but not making in mandatory, or part of the language spec... seems odd. Why bother? There will always been people that ignore the advice, and do their own thing. Trying to 'close the gap' and get everyone using go fmt is an impossible and endless task unless you pick path (1). Seems like an odd endeavour to be pursuing. 
I haven't found any packages that haven't been fmt'ed.
Yes. I did as well. That's why I haven't pushed the issue further. Here's the problem. I was updating syntastic so it used the go tool instead of 6g and so it would work with _test.go files. This is all merged and work's great. I realized implementing the above on my underpowered netbook that it I used fmt to syntax check and bail with those errors first and only run the compiler when fmt returns zero errors shortened the feedback loop immensely, which is the whole point of syntastic. This is merged and works great! To be continued... tired of typing on my phone. But I'll explain why I use my fork of syntastic and what I think we can do to fix it in another reply in the not so distant future.
Well the html parsing package is just getting ready to move from exp/html in to the Go stdlib for the 1.1 release. Perhaps after that's in place someone can develop something like WWW::Mechanize. It's a bit hard to do unless you have HTML parsing available, and that's no easy task in itself.
This is awesome work. This helps considerably with something I was planning on picking up. Well done!
Nothing wrong with highlighting a cool part of the article, especially since most people use Sublime Text it that nugget was a bit buried.
Even Python only dictates indentation, and would also benefit from a tool like gofmt. Most code I've seen does not actually follow PEP-8.
It sounds like you want something like Selenium Web Driver with Go. I've not used it with Go, but have good experience with Selenium. Here's a Go library for it, https://bitbucket.org/tebeka/selenium And if you want to read more about web driver, http://seleniumhq.org/docs/03_webdriver.jsp 
Completely agree, just wanted to highlight the relevant bit of the article.
I've been wanting to try out Casper and Phantom, haven't gotten to it yet. Also, you don't have to use Selenium just for testing. I've written several tools (in python) that use Selenium for parsing and scraping, works very nicely for it. 
&gt;Also, you don't have to use Selenium just for testing. I've written several tools (in python) that use Selenium for parsing and scraping, works very nicely for it. Fair enough, but this is something I'm thinking of distributing, so requiring a Selenium install would be a pretty heavy load for users.
As the original author of gopcap, I need to ask: why do you think was that fork really necessary? I'm always open to improvements.
There's a bunch of reasons, and believe me, none of them reflect poorly on your code. The first is maintaining backwards compatibility... since this exposes an entirely new API, merging this into gopcap would break all current gopcap users. Since I am also currently a gopcap user (a bunch of my older code uses it), I'd really not like to see this happen. That said, I think gopacket's API is one of it's strongest points, especially its use of interfaces and its pluggability, so extending the current gopcap interface while maintaining backwards compatibility was a non-starter. The second is speed. gopacket is very fast, but gopcap is still faster, due to some of the assumptions it makes (it assumes ethernet packets, for one thing, and it isn't pluggable, meaning it drops some layers of indirection). I've worked really hard on making gopacket fast, but for a vanilla IPv4/TCP packet, gopacket is still a good deal faster. At its fastest, gopacket was taking around double the time to decode one of those packets. There have been some recent regressions due to stack growing/shrinking in tight loops (runtime.morestack/lessstack) that have made gopacket even slower. It's no slouch: 1.77 us per packet on a single 3.2GHZ CPU. But gopcap is around .6-.8, if I remember from when I benchmarked it. The third is simply naming: It seemed weird to throw pfring support into something named 'pcap' :) Note, though, that the pfring support is general enough that it can be used with gopcap's decoding (it just returns a byte slice, which can be passed into a gopcap.Packet). To sum up, I'm very happy with how gopacket's turning out, but I'm also very pleased with some of gopcap's characteristics, and I don't want to break the current users of it.
Likewise, an in-memory cookiejar is coming to Go 1.1. After both of those are in, this would be much easier.
Interesting. I think there needs to be some sort of blurb about why I would want this beyond the quick one line description. Is this a alternative to [gitolite](http://git-scm.com/book/en/Git-on-the-Server-Gitolite)? Or is it something else?
That would be awesome! Yep that was [ChristophMartin](https://github.com/ChristophMartin) and I who fixed that up.
*explanation cont.* #**PostWrite and PreWrite**# Syntactic is bound to the PostWrite event. The example usage of using gofmt as a filter uses the PreWrite event to filter the buffer before writing it to disk. If you combine these 2 methods even if there are errors identified by gofmt, it is invocated twice, every time a go file is saved. #**Solution in my Fork**# The solution in my fork runs gofmt, checks for errors, if there are errors it bails and Syntastic does it's job. If there are no errors then it filter's the current buffer through gofmt BECAUSE the first invocation is run on uses the file on disk, not the buffer, so if gofmt did any reformatting this needs to be reflected in the buffer. This solution runs gofmt once if there are errors and twice if there are no errors, but the second time it only operates on memory and doesn't write to disk. #**Fmt command shortcomings**# The Fmt command provided by [misc/vim/ftplugin/go/fmt.vim](http://code.google.com/p/go/source/browse/misc/vim/ftplugin/go/fmt.vim) butchers folding. This was really getting at my Goat and, looking back, I solved it by moving the fmt'ing into Syntastic because I was trying to fix my govim workflow all at the same time. Maybe if we fix the Fmt command to respect folding then the PreWrite solution will function equivalently to my Fork, albeit invocating gofmt twice every save regardless of error status.
Yes, it is an alternative to gitolite, but it uses a different approach: instead of using a git repository as storage, it uses a database, and you talk to it via an HTTP API, instead of command line. The main point was adding a simple yet powerful application programming interface for gandalf (we use it in [tsuru](https://github.com/globocom/tsuru).
I've taken your code up to start my first steps with Go. I've been going over you example now, and I have a question. - How exactly are the URLs relativized? Is that built into Go templates? I was trying to see how I good relativize some internal URLs in the page template, but they didn't seem to be processed. I noticed somebody had forked your code and inserted some relativization code in the the Markdown processor, so I took that change and changed the order in the config file. Templating stuff first, and markdown last. This doesn't seem to have any effect though. - Should I solve this by using UrlTo in the template? This then supposedly means there is some processing done after the steps of the cfg file are done. - If I use multiple template files, will there be any distinction by file, or will all the blocks I define over a few files just end up on one stack? I.e. does making multiple files make any difference for the program or serves it only to help me the user? - Last Q ;) What is an elegant way to move files up a folder? I've been using a Jekyll like organization with blogposts in /_posts, but I rewrite them just to /post-name. Thanks!
This problem is solved by Haskell as well with type classes. A few instance declarations would get you the same thing, except you'd actually be being more explicit that both "Get"s are in fact the same "Get" and not just a coincidence of naming, and allow for situations where the name or signature of Get doesn't match exactly. In C++/Java/C# you could use an interface and two proxy classes to do the same thing but it's quite a bit more verbose, without gaining any expressiveness over type classes.
This article has a lot in common with http://blog.golang.org/2010/04/json-rpc-tale-of-interfaces.html and I think both offer some solid examples.
Alternatively, here is a python mechanize version to read: http://wwwsearch.sourceforge.net/mechanize/
Well actually, the resulting code in python was too slow too for my purposes. I suppose I could have made the python code faster, but when I asked myself it it would be worth it and considering my experiences so far, I decided it wouldn't be. I see what you're getting at though.
I got a binary running a few months ago on Android, but I just invoked it via command line. I'll have to take a look at your code later and invoke it via java which is, IIRC, what you did here.
I believe you would use the unmodified library *types* (think, "classes") and then invent your own *typeclass* (think, "interface"). It's unfortunate that Haskell uses some words differently than the languages most people are used to.
What you would do in Haskell is create a new type class and then *explicitly* (this is the part that differs from Go) mark the type as an instance of that typeclass. E.g., it might be something like: class EmailHeader h where headerGet :: String -&gt; String instance EmailHeader MimeHeader where headerGet = mimeHeaderGet instance EmailHeader Header where headerGet = mailHeaderGet This would assume that the types MimeHeader and Header were already defined somewhere and that the functions mimeHeaderGet and mailHeaderGet were already defined somewhere.
While strictly true Go does make it trivially easy either via Embedding or the type statement to add methods to an already existing type. type MyType OtherType Or: type MyType struct {OtherType} now you can add methods to MyType. the embedding case preserves access to the OtherType methods while the "alias" method above it does not. If all you need is to satisfy an interface though the alias may be preferrable.
Merged some changes into head, and Cole has tested on win32 and win64. We should be good to go.
On the Windows platform, the Zeus IDE can run gofmt on file save using a simple macro: http://www.zeusedit.com/zforum/viewtopic.php?t=6819 Jussi Jumppanen Author: Zeus IDE 
This is fantastic.
I just whipped something up for this this morning: fmt.Fprintf(os.Stderr, "Proceed? (yN) ") yesNo := "" fmt.Scanln(&amp;yesNo) if !strings.ContainsAny(yesNo, "yY") { fmt.Fprintf(os.Stderr, "Quitting.\n") os.Exit(0) } 
&gt; In this case, the author sort of "got away" with something, I agree, but I think you can also argue that Go's policy of loose interfaces defined by method names/parameters/results is designed to make it more likely that you can "get away" with things. This comes at the cost of type safety, of course, but it also has benefits, as this examples shows.
If you have it stored locally (most likely if you have not explicitly removed it), there is no problem and you can rehost it or package it some other way if others need to get it too.
I love how well Go resolved things that are out of scope of typical language problems, yet are of most importance for daily work with a language. `gofmt`, building tools magic, concurrency model encouraged (leading to easy to grasp and refactor designs). If I were to use any language in new upper-level project I'd go with Go. But I hope that Rust will borrow all the good ideas from Go soon.
In Andrew's talk a few months back, he also mentioned this. Don't be dependent on external links. If you're using code from a public repository, you should clone it to your 'local' repository to prevent this 'link rot'.
Can you explain to me what your code is using?
Why does it immediately exit the program when ran?
&gt; If you're using code from a public repository, you should clone it to your 'local' repository to prevent this 'link rot'. How does this work with open-source projects, where you don't necessarily have a "local" repository, and you want everyone to be able to compile?
I can confidently assert that Rust will never take off in its present form.
At the first line (of readLine), I'm creating a new bufferd io reader, taking input from the standard input. The second line, I'm reading in a whole line of text, untill a new line is enterd (return-key, etc.). If an error occurs while fetching input, the program quits and prints out the error. second last line, I remove the newline from the input before returning it as a string. Hope that's a decent explenation enough.
Isn't that problem kind of similar to the issue of forking and merging? EDIT: Also, you can use gofmt to easily replace one string with another in an entire project.
&gt; The language has a huge up front cost, similar to Haskell, with no demonstrable advantages. Say what you will about type safety not being worth it, but this is a flat out lie. Type safety *is* an advantage. It just comes with a cost. Some programmers are more willing to pay that cost than others. Please don't generalize to all programmers based on your own needs. And the costs of Rust versus Haskell are completely different. Haskell encourages a functional style of programming and imposes lazy evaluation upon you by default. Both of these things are absent from Rust. (But of course, Rust bring complexity from other places, like its pointer types.) Personally, the jury is still out on Rust. It just hasn't been used yet. It may be the case that pointer usage is obvious in the vast majority of cases, depending upon the idioms that arise. As of right now, it looks complex. But that doesn't mean it is *necessarily* complex. N.B. Pointers are just examples. Obviously there are other areas of Rust that add complexity, like regions.
Debian packages are kept in their own git repo. So you'd just keep the dependencies either in that repo or in sub-repos.
Yeah.................................. Your point being?
Or use MPL 2.0
This is great. Going to save everyone a ton on bandwidth cost and also make web apps more responsive. Thank you.
I'd suggest to invest time in improving [llgo](https://github.com/axw/llgo) and writing an LLVM backend for Epiphany than doing a straight forward port of Go.
Hmm... I may invest time in this. Is there an emulator for the chip? 
Also I agree that llgo is a good idea, but going beyond that and working on a backend is counter productive. Work on go's backends and make them better. Even better make a llvm bitcode -&gt; gc asm translator. 
There's a simulator over at Github (https://github.com/parallella and http://forums.parallella.org/viewforum.php?f=13). People over at Adapteva are very enthusiastic and helpful. They'll support you as much as they can. Hope this helps. Thanks for the interest. This is their twitter account (https://twitter.com/adapteva), their CEO's maintaining it (his name is Andreas Olofsson).
I think you're right. What the Adapteva people said is that the contractors asked too much money for the LLVM port to Epiphany and they went with GCC instead. Personally I like LLVM much, much more. Would love for it to be ported over to Epiphany. Anyone willing to do so would be kind of a hero :) Since that would unlock amazing routes for Parallella boards and their developers to go down to.
This article was great. I come from the land of C#(and Python, js) and this really cleared up a lot of questions I had about how OO works in Go.
Why UDP? What use is an RPC server that may fail to execute commands without warning?
"but your scientists were so preoccupied with whether or not they could that they didn't stop to think if they should."
Sometime you need to execute a remote command on a server but you don't want to wait the end of the processing or you don't care if the command fail because it's not critical... and udp is faster than tcp...
Comments! It was a pretty easy read, but commenting the right way lets you auto-generate documentation. Why wouldn't you take the few extra seconds to put a small comment at the top of everything you export? Also in your deploy.sh you're copying the dir to /root. I hope you aren't running it as root.
Using ~ would be better even if you run it as root imho.
Oof. I'm glad you had fun writing this in Go, but please please please don't ever use this for anything in production. [Read this](http://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/).
If you _need_ to execute a command, you can't use this. UDP can and will drop packets without warning. If you had fun writing this and learning stuff, great. Please do not deploy this anywhere, ever. It is a brutally insecure and unreliable replacement for a tiny subset of ssh's functionality. (`ssh target remote_command`; do you not "care" if it succeeds and just want to get on with it? Stick a `&amp;` on the end. You can also feed STDIN to the remote command or get STDOUT out of it. Tired of entering your password? Learn how to use keys. SSH has the security of the remote OS on the other end; need to limit the execution to a single command? Learn how to tie keys to commands, allowing relatively safe delegation.) I know that sounds like criticism; I really don't intend it to be. It's great that you're learning how to do this, no sarcasm. I'm just really getting the sense you still haven't quite grasped the implications of deployment from your other replies. Don't do it. It will lead to pain.
And why not test against "math.SmallestNonzeroFloat32" to check if the float64 is too small?
You may already know this, but keep in mind SmallestNonzeroFloatNN is not the same as a "MinFloatNN" (which isn't really defined in the math pkg but anyway).
This has some pretty awesome documentation! My hats off to the authors.
Very interesting design!
Thanks! I have made some trade offs, but it fits some use cases very well I think.
The documentation looks really aweseome, but the name will probably make it awefully hard to google.
Unlike the language Go ;) Edit: But yeah, I am open to a name change. I am not completely happy about the name even if I haven't been able to figure out a better one yet...
Very interesting. Are there any plans for atomic increments or other commands that Redis supports?
awesome project. Thanks for zond
Reminds me a little of Cassandra. Ring based architecture. A kind of gossip protocol on routing exchange. Tombstones etc. This looks easier to operate though
I'll echo a number of the comments here - this is an interesting project. A few things jumped out at me while exploring it. The documentation is fantastic, especially for such a new project. I applaud the effort here - this couldn't have been easy. I am interested to know what your intent is long-term. This is a very serious piece of software you're building, and I want to take it (and you) seriously. The issue I run into here is I have no idea who you are. In the case of Redis, while lacking a lot of the features you're supporting, I know who Salvatore and Pieter are. More importantly, I know the project and its architects aren't going to vanish overnight. While it takes time to cultivate that sort of reputation, we could start with your name and background at the very least. While it will improve with time, it's worth pointing out early on: bits of your codebase are exceedingly dense. Especially in places like the radix node module. While it may be jarring to you at first, giving "go fmt" a chance in this area might be a good idea. Please don't take any of what I've said as criticisms outweighing the outstanding work you've done so far. I'm impressed, and you should be proud of this project.
The test x &lt;= math.MaxFloat64 will only ever be false if x is infinite. A 32-bit float can represent infinities just as well as a 64-bit, IIRC.
Ah, that makes sense, thanks.
I think the project just needs some people to give it a try with non-critical data. Then, if that goes well, people will use it with more critical data, trust it a bit more, etc. I have no idea who Salvatore and Pieter are. But I do know from experience that I can hammer the crap out of Redis for months/years without a single worry. This seems to me like an in-memory version of Riak, with a bunch of Redis-like operations thrown in, which is very cool.
Interesting. Re: Iteration order Anyone have neat ideas on an ordered key map? Something that iterates based on insertion order or some sort of order? Without having to duplicate the key list...
The function isn't supposed to catch underflow.
Because the keys are unordered, you'd either have to make your own map implementation, or use a structure containing a map and key slice (but you said you didn't want to duplicate the key list).
It's good that you like the documentation. It has been one of my biggest priorities for many of the reasons you mention in your post. This kind of project needs to build trust, and good documentation will probably help. My intention is to build something that I can use in future contracts, something that does what Redis does but with operationally simpler and safer scalability. To make this a real option, I need others to use/fix/bugsearch/improve the project, and I need it to gain a pretty wide user base. My long term goal is to make it self sustained FOSS project where my input is only worth as much as that of any other team member. I am http://www.linkedin.com/in/oortcloud, if that is of interest. Yeah, some bits are dense. I have prioritized cleaning and refactoring the bits of the code that are publicly exported, to simplify for others to dig in, and there are definitely parts I haven't yet reached in that respect. I run `gofmt -tabs=false -tabwidth=2` each time I save a file, so I do gofmt :)
What you said. That is my vision.
Actually maps in go are not that great. Recently I came across 2 issues with them: You can not modify structures that are kept in maps. type S struct {x, y int} m := make(map[int] S) m[0] = S{x:1, y:2} m[0].x = 3 You get "./test.go:8: cannot assign to m[0].x" You have to do tmp := m[0]; tmp.x = 3; m[0] = tmp Which is very unintuitive because in most other languages m[0].x = 3 works. Garbage collection and maps suck together. Basically I needed 2 big maps int-&gt;float32 around 120 million entries in each. I was filling the first map using info from the second then cleaning the second filling from the first and so forth a few times. After a few iterations the program ate 7Gb of memory and crushed happily. I tried dereference maps and create new ones, I tried deleting elements nothing helped. At the end of the day I put call to runtime.GC() every 10000 iterations of inner processing loop. This helped keeping used memory at aroung 3-4 Gb but increased running time 4 times or so. People who implemented the same problem using C++ map reported that they stayed below 2 Gb at all time and their runtime was very small compared to mine. Moral of the story: dont use maps if you need to allocate and deallocate big number of objects. Use slices and do mapping by hand. EDIT: ok seems my post started a small flamewar. The fact that "m[0].x = 3" is not allowed is a design decision that is connected not only with map implementation but also with other features of the language. This syntax is not intuitive that is why I don't like it. There are a few discussion on the mailing list about this feature: http://code.google.com/p/go/issues/detail?id=237 http://code.google.com/p/go/issues/detail?id=3117
That's because unlike in other languages, go maps store the actual struct value and not a reference to it. Change it to map[int]*S and m[0].x=3 will work.
I love it when authors actually put time writing the documentation for others so others can easily start contributing.
In the case of arrays and slices, the memory location is guaranteed to be known at runtime so you can modify a non-pointer struct inside a slice or array. In the case of maps, the memory layout may vary dynamically and the accessor is probably a call into some internal map_retrieve(key) C function. So without a pointer that function would return a copy, your modification to that copy would be immediately useless and not reflected in the map. Just keep in mind that arrays are simple linear-memory locations. Basically a long ordered strip of values. Same then for slices that represent a sub-view into such an array. However, a hash-table may not be laid out in such a straightforward linear fashion in memory, indeed their stated need for fast arbitrary read and write times may involve them shuffling their data around, bucketing and re-bucketing a map's keys and values in crazy ways and what not. So while it might be nice if you could treat a map like an array or slice for the above stated use-case of struct types, as soon as the size of the struct exceeds the size of a pointer that might be highly undesirable... since maps and arrays/slices under the hood are as different as they get, I don't see a strong need for "consistency". They're different things, they address different needs, they have completely different memory-usage and performance implications. OK, they both have a length and can be iterated over, so having len and range for both is really the only "consistency" needed here.
&gt; In the case of maps, the memory layout may vary dynamically and the accessor is probably a call into some internal map_retrieve(key) C function. Slices are also dynamically allocated with make, they can be anywhere in memory and you also need to call some kind of function to calculate position of an element. Yes, a slice access function is much simpler but it is executed during runtime as in case of map. You can somehow assign to an element why cant you assign to part of it? This works tmp := m[0]; tmp.x = 3; m[0] = tmp Why cant compiler do this for me? If it is not efficient just make huge fvcking banner in the description of map. &gt; I don't see a strong need for "consistency". Ok, you then probably love C++ where you need a head the size of a planet to store its specification along with all corner cases. I am strong supporter of the principle of least astonishment so this kind of stuff bothers me. PS: I don't say go sucks but this stuff must be emphasized in the documentation. I don't like stumbling on compiler error and then having to search for answer on forums in case of trivial language constructs.
Compare these two simple programs: package main import "fmt" func main() { var value = []int{0: 1} var internalpointer = &amp;value[0] fmt.Println(*internalpointer) } http://play.golang.org/p/iZe85Z90AN vs. package main import "fmt" func main() { var value = map[int]int{0: 1} var internalpointer = &amp;value[0] fmt.Println(*internalpointer) } http://play.golang.org/p/9jYYvPTyie The first one does what you would expect. The second one does not compile, but gives the error "prog.go:7: cannot take the address of value[0]." It's just a side effect of the fact that maps are able to rearrange themselves whenever they want, so you can't get a stable pointer to a location inside of the map. You also can't take the address of a string index because strings are immutable. 
Have you posted your issue with your 120 million map entries to the golang-nuts group / mailing list? Who knows, chances are one of the core hackers might be quite inclined in tackling some optimization for such use-cases. Go is a young open-source project compared to "other languages", as I'm sure you're aware...
&gt; Hehe, somehow I'm actvally increasingly glad Go in its cvrrent state pisses off people like yov... really ;-) I am not pissed I don't care I have nothing at stake here. I try go because it is different from other languages I know. But it seems that some people in go community take critique of the language as an offense. &gt; people like yov... really ;-) So personal attacks, nice ...
Well I retracted that *way* before you replied, so essentially the personal attack was a subsequently voided knee-jerk on my part. So big deal. The rest of the argument still stands... ;)
No problem, happens sometimes
&gt;It sounds like the HTTP interface is less capable than the gorpc interface. This will alienate non-Go users. I would suggest either making the HTTP interface fully capable or (probably better) ditching gorpc and using Thrift or similar language agnostic RPC system. No, the HTTP interface can do everything the native interface can do. It just offloads a bit more routing on the nodes that the native client does for itself. This can cause a few more hops, which in addition to the JSON encoder being slower than the gob encoder will cost some performance. &gt;It would be useful to get some indication of performance. From the architecture documentation it sounds like there is quite a lot of overhead for distributed set operations, and in my experience at scale one of the big problems becomes inter-node communication. Not that much overhead. No more than it takes to stream ~~the sets~~relevant parts of the sets over the network. But the set ops are fast. What costs are inserts and deletes. My MacBook Pro does about 30-40k puts per sec on a single node with a million keys. Edit: The entire sets are not necessarily streamed. Intersections only stream enough of the sets to identify the resulting intersection.
Some decent discussion also here: http://news.ycombinator.com/item?id=5181949
While 'go get' uses simple and useful conventions, it has some drawbacks: * third-party repository can be renamed or removed completely (yes, this happens); * third-party repository may be broken at times (this happens, obviously), and you have to checkout working revision manually; * two issues above results in deployment hell; * as maintainer of third-party package, you MUST change import path if you introduce incompatible changes in your code - but most maintainers don't really care because they don't know if their code is actually used by someone else. I'm actively working on http://gonuts.io project, which amplifies 'go get' without breaking Go conventions (GOPATH, import paths, etc). [EDITED: formatting; original comment was written from phone, sorry)
If you're worried about code changing out from under you, just fork it to somewhere you have control over and use that, importing only changes that you have tested not to break your stuff. It's not really a big deal. [edit] And yes... don't use relative imports. That's a terrible idea. It means your code won't be go-gettable, you'll have to figure out the dependencies and deploy them manually... which defeats the whole purpose anyway.
Half the thread is bitching about the name, another nearly half the thread are loose comparisons to GHC. HN's comment threads are interesting, but the ones related to Go are always a bit special.
I think it would have helped if somewhere it actually said what it was. It took me a good minute to figure it out, because there's literally zero information about that.
&gt; This can actually happen with ruby and Python projects just as easily. That's why you have a `Gemfile.lock`. I think Pip has the same thing. Obviously you need to exercise caution when upgrading dependencies (in any language), but if you're using Bundler or Pip properly you won't get random mystery upgrades that surprise you when you didn't think you were changing anything.
I have by now realized, that my UI is rather bad. The Alias dialog is missing some explanations as well. I will get on that asap.
googability might be as well as critical as good documentation for project success. I really urge to evaluate a name change.
GOPATH is pretty much equivalent to workspace on your average IDE (solution on Visual Studio). IMO it makes no sense to *not* use per-project GOPATHs.
I think per project go paths is a pain in the butt for no good reason. Why do you need more than one gopath? All the dependencies are stored by URL anyway, so it's not like you can get conflicts. I can see having a two-path gopath, first one is for external dependencies and the second one is for your own code you're working on locally. Other than that, this whole gopath switching thing seems to be a relic of times gone by.
Suggestions?
Yeah agreed, I'm also not seeing the point of this so far... Especially since I re-use the vast majority of libs, external as well as own ones, across a number of multiple projects. I wouldn't want to keep local copies of those in sync manually. 3-8 times the same **go get -u**, and then various directories xcopy ops? Puleeaase...
&gt; third-party repository can be renamed or removed completely (yes, this happens) This doesn't affect your local copy. And others are free to re-rename the local paths if they don't want to update the import statements in the .go source files. Sure it's messy, but any kind of dependency management is always messy sadly. At least I didn't run much into versioning hell yet with the libs I use (Go package/lib authors overall seem to be rather careful and sensible about unneeded breaking API changes), and at least we get static linking. Having to very very rarely manually manage the local src directory tree with regards to package "URLs" is in comparison somewhat acceptable to me.
If you are on a Linux system, use lsof (with various combinations of flags, -p $PID is probably most useful to you) to find out what files are open. This will be more trustworthy than any answer here. Windows has tools for this too, but I'm not sure what they are.
Good idea, I will try that out. I was wondering in the general case, though. I can't imagine I'm the first one that wants to pipe reader to reader to something else via a function return.
If I were you I'd rather err on the side of caution, keep track of both the os.File and that Reader, and close the thing when done with it. Can't be too hard and also ensures your code does not rely on some "implicit behind-the-curtains black magic". I mean, you open it, you close it, right? Certainly the GC shouldn't be concerned with special OS resource handles IMHO.
It's not too hard to use [cgo](http://golang.org/cmd/cgo/) to interface with the GNU Scientific Library. I'm not aware of a complete wrapper, but some code exists in the wild which handles pieces of GSL: [A wrapper for GSL vectors and matrices](https://bitbucket.org/fhs/go-gsl) [Pure-Go implementation of GSL integration, randomness, statistics](https://github.com/mingzhi/gsl-pure-go) I have written some wrappers myself for GSL [root-finding](https://github.com/tflovorn/scExplorer/tree/master/solve) functionality, as well as [integration](https://github.com/tflovorn/scExplorer/tree/master/integrate) and [fitting](https://github.com/tflovorn/scExplorer/tree/master/fit).
&gt; While in theory no APIs should break in a patch release, it does happen from time to time (eg: https://github.com/net-ssh/net-ssh/issues/80). Indeed, this very issue affected me and my company, so I know this pain. But this issue may be solved with RubyGems – just install previous versions. It doesn't possible with `go get`, you have to use git (and hg, and svn, and bazaar (!)) manually. &gt; Some authors even use dep&gt;=2.3, which is even worse. I see two typical use-cases for dependencies: major version (X.*.*) and major and minimal minor (X.&gt;=Y.*). While different import paths may solve first problem, second is harder. Those two use-cases will be supported in nuts. Others - only if there is a valid and common use-case. I hope it will be possible to enforce compatibility with new `go/types` packages.
Scientific computing is all about the libraries. The only reason NumPy is even a thing is that you just use the Python to set up calls to the libraries, which do all the real work. If you tried to write actual math code in Python, it would be horrible, Python is a horribly slow language for the actual math bits. If you're really into scientific computing, I'd recommend chasing the libraries rather than trying to jam them into Go. I don't really see any advantages in the language itself for scientific computing; it's a systems language, not a math language.
&gt; any kind of dependency management is always messy I can't agree. There *is* a sweet spot between `trunk` and `gopher-1.2.3+lala-12~5`. &gt; At least I didn't run much into versioning hell yet with the libs I use (Go package/lib authors overall seem to be rather careful and sensible about unneeded breaking API changes) Dependency hell is rare while we have few packages. But I think it will limit a growth of our community.
&gt; just fork it to somewhere you have control over and use that, importing only changes that you have tested not to break your stuff This complexity is a function of a number of dependencies. While you have 5 third-party packages, life is good. You don't even need `go get` – you can use vcs manually. But I once worked on a project which used a lot of Ruby gems. 134 of them. Most of them were on GitHub, but some on Google Code and BitBucket (at least Launchpad was not present). One particular third-party gem was stored in self-hosted svn which typically did not work. RubyGems.org and Bundler allowed us to stay alive with this amount of code. Even when RubyGems.org was down, `gem server` saved us. I have a strong sense of fear when I think about 134 forks (there is no "Fork Me" button in Google Code).
My scenario – Go app is working on production system. I want to make sure I control all dependencies. Also let's assume I don't want to use nuts. I use GOPATH=app. `go get` everything into it. Store the *whole* GOPATH in my repository.
We have submitted a paper where Go was used to build a tool to compress all know protein sequences. We didn't use anything fancy like the "cloud" or MapReduce, but &gt; The inexpensive concurrency is really appealing to me was quite pertinent. We used concurrency heavily in our compression program, and benefited greatly from parallelism. However, things were still fairly slow. And I wanted to see if we could do better with C. So I re-implemented the entire program in C---which included a [multi-producer/consumer queue](https://github.com/BurntSushi/clibs/blob/master/libds/queue.h)---to see how much Go was killing us. It turned out that the C version tended to be slower. We believe it was due to the fact that our program is allocation heavy (on the order of tens of GB) inside threads, which was a problem with the conventional `malloc`. We believe Go works well because it does something smart with thread-based memory arenas. We could have continued down the path of finding a better malloc (tc_malloc?), but at this point, we felt our decision was justified to use Go. My apologies that I don't have more details. Hopefully our paper will be accepted for publication, at which point, I'll be happy to publish all code and try to do a more honest analysis. On another note, I'm using Go for another problem related to protein structure. Raw speed isn't as important in this project, but the project has tons of moving parts. The `go` tool and the type system really work in my favor here.
How do you deploy your app?
it depends on my mood :) sometimes I just ssh in and do the code change on the server then `go install` and `supervisorctl restart` other times i do the change locally, recompile and `scp` the binary up... with that said, some people might not have it that easy
That's really interesting. The information you included about the comparison between C and Go was really illuminating. Thanks burntsushi.
For what it's worth, it's trivial to try tcmalloc. Install the library (via your favorite package manager on Linux) and link with -ltcmalloc.
That's not trivial when you're running programs on servers you don't have root access to. My main point isn't that "Go is faster than C." It was that "Go was fast enough." i.e., it was worth the trade off.
Have the program monitor it's memory usage and fire off the gc? Also don't allocate/free like nuts, you should be sharing/handing over memory allocations as much as you can.
Are you sure you don't have any memory leaks? That symptom sounds like one (or a few)... you should get a profilier (like goprof) and see where the memory is going. Does each HTTP request require memory to be stored? Do you end connections and clean-up memory once an HTTP connection disconnects? Have you thought of ways you could pre-allocate all memory before handling any connections?
What would you expect Go to do when it reaches this limit?
&gt; it's a systems language, not a math language. No operator overloading either, so there's always going to be some awkwardness to certain things.
I guess the only thing that might help is for Go to be aware of this limit so it calls the GC before allocating more.
I don't think there are any memory leaks... I just do quite a few allocations in each request, and I would prefer not to have to change that. IMO, pre-allocating all the memory would kinda remove the point of using Go in the first place.
Good point -- I'll update the article when I get a chance.
Can you share some source code that reproduces this issue or go into more detail? I work behind a server I wrote in go that proxies between other servers, one serving images. These servers run for the whole work-day and although there can be peaks above 10m (e.g. when I load a page with lots of images all being served at the same time with random sleeps for testing) the avg memory usage is below 5m for all servers. So this constantly rising memory use doesn't sound normal, unless maybe your server is constantly being hammered and/or it allocates that much data in the first place
It sounds like there's an issue of not releasing references to memory that doesn't need to be used anymore....
Okay, then I think you shouldn't preallocate. You do have to do some memory management i.e. make sure you stop pointing to memory you no longer want. This issue totally sounds like your code is holding on to requests (our some data) long after you have any use for it.
Might be interesting to follow along. This is the first year that all of the labs and homework are being done in Go, rather than C++. 
There's a google plus group that sounds like what you're looking for: [go.science](https://plus.google.com/communities/115354877257015196825). [Original thread](https://groups.google.com/forum/?fromgroups=#!searchin/golang-nuts/scientific/golang-nuts/QBwBWtr7NzU/AbjfsWa50KoJ) where they discuss the groups creation.
My code right now doesn't close any connections after it's done with them; it lets net/http handle them instead. Is there something I should be doing after I'm done with a request, such as closing it?
List of other university courses in Go from Uriel's site: http://go-lang.cat-v.org/university-courses This should probably be migrated to the Go wiki at http://code.google.com/p/go-wiki/w/list . In fact, I'll see if I can get that done.
I do not know enough about the http package to answer your question. To figure it out, I would study the doc and the relevant code. I would try to follow the life of an http connection through the package code.
If you disable GC then you can't run it at all. Calling runtime.GC() will have no effect. 
Well... that makes manually calling GC pretty useless if you want to control GC pauses...
The GC triggers once you'd allocated a certain amount of memory. By default it triggers each time you double the amount of memory. eg. 2MB, 4MB, 8MB, 16MB, 32MB etc. So if you've allocated 16MB the GC won't trigger again until you've allocated 32MB. Forcing GC will help a bit, but you really want to figure out how many requests you can actually process with your memory limitations and rate limit that. 
That's not what disabling the GC is for. If you want to control where GC pauses occur in single threaded programs then you can set the GOGC variable to an amount larger than you expect to allocate and then call runtime.GC() manually. The better option is to preallocate this memory and use it from a pool. In a concurrent environment manually calling GC doesn't really make sense since you can't syncronise with the other threads to decide when it's ok to GC at which point preallocating and reusing from a pool is your only option.
I'm not the author, but a friend of him. Got his permisson to spread the word. EDIT: Huh, that's weird, he posted [this himself here](http://www.reddit.com/r/golang/comments/187hjf/bigcanvas_an_infinite_online_canvas_that_anyone/) yesterday. Why didn't it take off then?
Cool, someone started making [some music sheets](http://bigcanvas.frozenfractal.com/#yr,pE,109,205) on it. It's nice how responsive it is. I haven't noticed any seams between the coordinate blocks at all, which is pretty neat, too. Erasing would be nice. From an implementation perspective, those could just be white strokes, which could still be trivially appended to his flat files. If there's any unused bit, that could be used to distinguish between white/black. I believe that would be all the necessary implementation on the server side. Anyway, it's a fun toy, which seems really well implemented.
WebSockets absolutely support binary data. It's been a frame type since the beginning. The problem is that Javascript does not.
Boy, that sure is a lot of penises.
Gaaah, I totally missed that! Even the JavaScript API does support it, at least according to spec: http://dev.w3.org/html5/websockets/#dom-websocket-binarytype Not sure if browsers implement it. Well, that's for the next iteration I suppose...
This is awesome. One suggestion for whatever it's worth: Don't break the browser back button. Use the google maps style of having a "link to here" button. 
I enjoyed the talk *even though I probably will never use anything I learned from watching it* - it's just plain intellectually stimulating enough to be enjoyable on its own.
The [Go Specification](http://golang.org/ref/spec#Numeric_types) states that *uint* and *int* are either 32- or 64-bit. Does that mean that they are machine sized or that the size is completely implementation specific and they will later specify a constant size like said in this post.
Something I never saw in posts about Go (either as good thing, or a bad thing), is that by simply grouping some vars how easy it is to indicate relationships between them, and protect all of them with having a mutex in the group. var ( countLock sync.Mutex inputCount uint32 outputCount uint32 errorCount uint32 ) Of course you could do the same in type declarations as well.
Oh I'm curious, got more info on your project somewhere, or even github/bitbucket? During the very slow progress of my hobbyist "[go:ngine](http://github.com/go3d)" project, I haven't had a single need for op overloading or func overloading yet. You're just used to that from C++, I guess. Now if Go *had* that stuff, I'd have used it, no doubt. But their absence has not slowed or hampered me in any way.
Wait... it's not that the location of the Mutex var itself determines "which vars are locked", is it? That would be a ...surprising... language feature.
&gt; Another example of Go’s modernity is the decision to make the directory the fundamental unit of packaging. I haven't been around long enough to judge (as in: I'm too young to know what it was like to program in the 70s, or anywhere in the past century really), but this has a distinct "everything old is new again" feeling to it.
Well sure I can code without them but the biggest deal was I had to inline all the math in the physics engine for performance. The other problem is users that use my engine needs to remember all the functions for each situation, SetPosition SetPositionFloat AddImage AddImageID etc. As you see I need to choose between performance and user friendly ways all the time. I'm using Go from its beggining when it didnt had windows support and before weeklies so I do know and love Go. I also understand that some of my problems can be solved with better compiler optimizations. But again its hard for the users to remember all the functions names and use functions instead of operators. Edit: example for function overloading https://github.com/vova616/GarageEngine/blob/master/engine/components/tween/Tweens.go#L66 (the users can create the struct by themselfs but its requiring them to remember all the struct varibles)
Nope, it doesn't. He simply means that it is visually clearer which vars belong to each other, because they are grouped in the same `var` block.
One thing I agree would be really good is better inlining support or control. Now the inliner has gotten a lot better but it's still quite limited. At the very least the current "a func that calls another func/method is no longer inlineable" constraint is really annoying. Now, as of yet it doesn't seem to be bottlenecking me per se, but we just *know* the program (or if we inline manually --which I'm refraining from for now-- the programmer) is doing more work than it/he should have to. But then, I'm refraining from physics as well, hoping I'll be able to bind bullet there when the time comes. Purely focused on the rendering part for now.
It means that they are implementation specific. Previously, all implementations had 32-bit wide integers by default. This has changed in the latest revisions, and they are now 32-bit on 32-bit platforms and 64-bit on 64-bit platforms. There is no reason why a 64-bit implementation can't choose to make them 32 bits wide. If you need an integer of a specific size, you must use int32/uint32 or int64/uint64.
Why not just distribute the binary with the assets in a zip file, with a script to put stuff in the right place? If you're producing a binary and expect people that don't know go to be using it, why make them compile it? That's what I do for gocog: https://github.com/natefinch/gocog. I compiled binaries for anyone who doesn't want to compile it themselves. Also, I highly recommend not structuring the repo the way you have, it'll break "go get", which is one of the most useful things about Go. It's far better to write your code for people who do know Go, since they're most likely to be the ones compiling it. And for people who don't, they'll at least get a feel for the language. Put the main package in the root of the repo. Have the assets in a subdirectory (to keep things neat). Keep the meat of the code in a subpackage (in case anyone wants to reuse it outside your binary). Include a setup script in the root of the repo so it's easy to find. It's still only a two step process to download, build, install, and setup.: "go get &lt;your repo path&gt;" // downloads and installs the go code, with a subdir for the assets $GOPATH/&lt;your repo path&gt;/setup.sh // distributes the assets to the right place and installs the service 
Probably better to put them all in a struct, so it's not just visible grouping, but logical grouping as well.
Write your install script in go. Then you can "go get app-installer; app-installer".
1.I gave them both of the options 2.I don't think its user friendly enough when you make people search and remember struct variables when they only want simple action 3.CreateHelper8(target, typef, from, to, time) is better than Create(&amp;Tween{Target: target, Type: typef, From: []float32[from.X,from.Y,from.Z], To: []float32[to.X,to.Y,to.Z], Time: time, Algo: algo, Format: format}) The point is I can find huge amout of overloading to this kind of functionality and I dont want the user to break his head to make simple actions 
Definitely Go got a lot of things very right: * syntax is almost perfect for C-like language * `defer` (just like D's `scope`) * decision to force one formatting only is so, so great (more languages should do it) * explicit concurrency encouragement is great idea * duck typing * tooling is superb If not a heavy GC reliance Go would be perfect for me. It's good that Rust shares a lot if Go, though Rust has some weird syntax in typesystem (pulled out of ML and not fitting well with brackets, IMO) and is not yet stable enough.
Without having looked at the tween code: Well, since from what you just wrote, CreateHelper8() predefines the algo and format to use, you'd probably not name it CreateHelper8() but CreateFooalgoBarformat() which might actually be simpler to grok for your lib user when they later on go back re-reading their own code. At least he never has to juggle: "8 different overloads with slightly different semantics but all with the same name ... now which one of those did I use ... let me compare the args I used with the docs..." in his head. Now, wow! Actually that seems more user-friendly to me! Holy manoly, another case where a restriction of Go was unexpectedly beneficial in hindsight...... ;)
I agree that sometimes its better just using different naming and I actually do use SetPosition and SetPositionFloat and not SetPosition2 but this kind of long functions are not working good with this approach CreateTweenAlgoLoopFormat(..) CreateTweenVectorAlgoLoopFormat(..) CreateTweenYAlgoLoopFormat(..) CreateTweenVectorAlgoLoopFormatCallbackSyncTillCookies(..) CreateTweenYAlgoLoopFormatCallbackSyncTillCookies(..) CreateTweenAlgoLoopFormatCallbackSyncTillCookies(..) I suppose the last 3 are little bit too much and you can just create the struct by yourself.
Yeah but if they all had the same name I would get a double-headache... ;)
Anonymous structs and embedding make this much better: var count struct { sync.Mutex input, output, error uint32 }
yup I hate to look on 24 functions that having the same name :o 
Your FK statement, or username column definition, needs to be changed in the readme https://github.com/husio/dbo/blob/master/README.md BEGIN; CREATE TABLE IF NOT EXISTS user ( id INTEGER PRIMARY KEY, name TEXT NOT NULL UNIQUE ); CREATE TABLE IF NOT EXISTS profile ( email TEXT PRIMARY KEY NOT NULL, username INTEGER UNIQUE NOT NULL, FOREIGN KEY(username) REFERENCES user(name) ); COMMIT; 
Well, I'm no expert, but as I understand: structs indicate memory layout, and slices are just smart pointers to arrays (so under the hood also contiguous layout). So you can [for example pass around pointers](http://play.golang.org/p/UBu1pED0df) or sub-slices to re-use allocated variables. Considering Go does everything pass-by-value it's good to use pointers and reference types where sensible anyway. For large structs/slices, that can minimise garbage creation/collection a lot: instead of a whole object, only pointers have to be collected. It also reduces memory fragmentation. Just make sure you don't have a single pointer somewhere that prevents an entire slice from being garbage collected. &gt; Also in D I can use manual delete and also schedule the GC collection manually. There's no delete, but you can invoke the GC at will: http://golang.org/pkg/runtime/#GC
To add to that, you can disable automatic invoking with runtime.MemStats.EnableGC = false
the lexer for [my language](http://github.com/bobappleyard/ts) is based on the ideas from that talk. it works well enough, but i'm planning on making an iterative compiler which will probably be based on regular expressions
Doesn't that turn off the GC entirely?
Maybe because I linked to the thing directly, not to the blog post? :\
Yeah, that might have been better. I initially did it this way to aid debugging; it's really annoying if you refresh and get thrown to a random location. I could use local storage to persist the location, I suppose.
So from Rob Pike to [Russ Cox](http://swtch.com/~rsc/regexp/regexp1.html), eh?
this is super duper nitpicky, but just to toss it out there for posterity, they're called struct literals. It's in the [composite literals](http://golang.org/ref/spec#Composite_literals) section of the spec.
i have also written a thompson lexer, but yeah i've written an extension that uses the standard regex library and in there is a class that employs the same trick as the semi hidden Scanner class in Python's standard library (use capturing groups to decide which token matched).
I don't immediately see whats wrong, but something that might help is the 'go env' subcommand. Incorrect assumptions about my environment variables is what held me up when I was starting.
Ah, that's definitely it: GOARCH="amd64" GOBIN="" GOCHAR="6" GOEXE="" GOGCCFLAGS="-g -O2 -fPIC -m64 -pthread -fno-common" GOHOSTARCH="amd64" GOHOSTOS="darwin" GOOS="darwin" GOPATH="" GOROOT="/usr/local/go" GOTOOLDIR="/usr/local/go/pkg/tool/darwin_amd64" CGO_ENABLED="1" I just had to run export GOPATH to make it pick up the environment variable. Thanks!
Does /Users/ctesibius/hack/go exist? Also, you don't need to include /usr/local/go in GOPATH, if you run `go env` you will see that GOROOT has already that value
Yeah, I wouldn't fix the back button if it meant breaking refresh... but your local storage idea sounds like a great way to keep all of those functions working the way they should.
Yes, the directory exists (as shown above). I'll remove /usr/local/go. I couldn't find anything about the interaction between the two environment variables.
When I did the same thing, the problem was just like it says: permission denied. Unless you are root, you can't write to /usr/local/.... I then ran it like this: sudo go get code.google.com/p/go-tour/gotour and it worked a treat.
&gt; I then ran it like this: &gt; sudo go get code.google.com/p/go-tour/gotour &gt; and it worked a treat. No! don't do that!. Fix the problem instead. You fix it by making `GOPATH` work instead. What you've done here is set yourself up for problems later. You'll find this out with permission denied errors as soon as you install with sudo a package that at some point in the future needs re-compiling.
I did not know that. Of course, I just installed it last week, so I haven't encountered any problems like that. I will take a look when I get home. Thanks for the heads up. 
It looks like the professor maybe could have pointed students to a few more things directly than just golang.org. Some complaints include lack of a debugger when there is one (gdb) and lack of IDE when there is one (Zeus). I feel like making a thread on the mailing list for students to ask questions and be answered by the community could have been really beneficial. Also, one student complained it's a pain to setup a go environment: all you do is install the language and export some environment variables. Java installation is the same thing but only one variable.
Regarding Java: I don't remember ever having to manually set any environment variables for Java. That said, I still prefer Go for its syntax and its ease in doing concurrent programming. I just wish its garbage collector is as good as Java's.
No sure what is the success story here. As much as I love Go, porting several packages from Python to Golang does not count as success.
&gt;I just wish its garbage collector is as good as Java's. I don't know if he's still involved in the project, but Robert Griesemer was one of the primary creators of Golang. Griesemer worked extensively on Java's HotSpot VM.
Your IDE might not require you to set the CLASSPATH variable, but at my university even the intro courses in Java force students to use the command line and either set the CLASSPATH var or explicitly define the classpath using the switch on the javac binary.
At least it's not one of those "every time you click the back button the site automatically forwards you back to the current page twice. Now you are stuck and have this page TWICE in your back button history!"-monstrosities.
My assumption is that the complaint about the Go environment is with its enforcement of a specific directory structure in a specific location. This is not familiar, in that most other languages do not have such restrictions. Java is not the same, in that it does not require *all* Java source be under one common directory.
Every time I see a headline like this, I think, "is there no end to what people ca do with those little black and white stones?"
Success for the developers. They get paid to write Go code.
Unless that was what they wanted to do and they did it...
Sort of testing the water, so it'd be great to hear any comments on content and format. I will add an RSS feed shortly for those who'd prefer it in that format. Full announcement here: https://groups.google.com/forum/?fromgroups=#!topic/golang-weekly/d2k1zuCh0L4
Hey, I assume you are Matt. I'm a huge Go fan. Here are some suggestions about topics, based on my own experience: * It would be awesome to have something like http://wiki.nginx.org/Pitfalls. I know this is more of a wiki, than newsletter, but maybe you could write from time to time about best practice. * Another point is the growing amount of libraries solving similar problems (http://go-lang.cat-v.org/library-bindings). It would be cool if you could write about the state of such libraries, and maybe recommend which one to use. 
Wow, didn't notice that, sorry. I've cut the styles out here: http://golangweekly.com/archive/golang-weekly-issue-1-plain.html Looks a bit wonky, but it is at least zoomable. I'll look at changing the template for future issues.
Great suggestions, thanks. I'd really like to have a strong focus on making libraries visible to the community - including announcing things in need of maintainers, etc.
Awesome, hoping with Go 1.1 just around the corner we'll have a lot more activity.
body {-webkit-text-size-adjust: none} is the problem.
Awesome idea. Here's another topical niche that should be of great interest to lots of Go coders yet isn't very widely written about -- could be a weekly column or some such: Internals! What happens behind the scenes of various Go constructs, and implications! -- particularly for people who aren't coming to Go from C and can't always guess what the generated machine code does exactly. The official documentation and mailing list always have this "it's implementation-dependent, not lang-specific, a Go programmer shouldn't have to worry about such things" stance. But we all know we have 2 major compiler implementations at present, and having a better idea of behind-the-curtains internals should only serve to write much better Go code in many situations, without necessarily devolving into lots of dirty hacks...
Thanks! I'll update the template for next week's issue and regenerate the others.
Sounds good - though I guess I'm not in a position to write this sort of thing myself, as I picked up Go relatively recently. Is this something you'd be interested in writing about?
Thanks for the feedback - it's really appreciated!
Matt, I've been following you since Coder Weekly #1 and I've been wanting to pick up Go for awhile now. I think that this is the push that I needed. Just wanted to say thanks. 
Thanks for the GO-ld ;D
Good stuff!
Awesome :)
I definitely love the format so far. Here are some things that I've thought about recently: * With Go 1.1 coming up, I think it would be great to have maybe either a tip or link to article on upgrading/migrating to the new version. Sometimes it's easy to let things fall through the cracks or just not notice changes and new features. * Maybe we can feature a Golanger once in a while for their contributions to the community. * I think it would be helpful for everyone to see popular questions answered from StackOverflow. If something gets quite a few votes, it means that others may benefit from the solution. * Maybe we could have mini challenges or problems to solve every once and a while? Maybe to see how people solve certain things with Go or to just sharpen the saw. * Many times people don't know how to contribute back, so maybe it would be cool to have featured issues, bugs, etc. for popular Go projects or even Go itself.
Go is young, so production deployments that are well documented help other people decide to adopt the language. The deployment was a success, and their choice of Go was a success. Plus many people who love to write Go are getting paid to do it now. Lots of winning all around. 
&gt; Of course, you have to compile that as a shared object with GCC. You don't. If you want your C code to be used by languages other than Go, sure, go ahead. But if you just want to use it from Go, you can just put /* #include "libfoo.c" */ import "C" and it will work the same way. You can put any C code in that comment, actually, so you could skip out the C file and put /* int foo() { return 1; } */ import "C" You can mix this all up and include a shared library with some glue to help the Go interface. For instance this [readline binding](https://github.com/bobappleyard/readline/blob/master/readline.go#L56).
Yes, RSS would be much welcome :)
It would be cool if you had the demo running somewhere, instead of having to download something to run it.
Err, this does look interesting, btw
So who is going to be the first one to write a omegle clone?
I'm not a part of the project, but I know there is a demo on the site showing a full app.. Actually, it's on the side bar. Edit: You still have to copy &amp; paste the code, though. I know the project is fairly new, I would expect to see a demo running live, soon.
Here's some ideas: * do you work with Git? Write a little script/menu system to automate some of the stuff you do that's tedious eg cleaning up old remote branches. Or do similar in your preferred source control system `for i in 'git branch -r' ; do` `for&gt; echo $i # delete this branch?` `for&gt; done` * choose a small C library from sourceforge, etc, wrap it in Go using CGo * use Linux? Both Network Manager and wicd suck - write a [go run](https://wiki.ubuntu.com/gorun) script to manage your network interface, join it to wireless networks, set up some static routes, setup proxy settings and some ssh tunnels * do you have your daily config files (editor, music, tools) under source control? A go run script to automate changing these settings. 
Do you like online games? You could write a basic server emulator for some game. A lot of free MMORPGs have their protocol documented fairly well. It's a big project to complete 100% but writing server that allows walking around, chatting and some other basic features is quite educational project.
Rewrite Node.js in Go
Surely it's not because it already exists that it can't be a good hobby project?
I meant the text chat only. And what Go project is that?
This is surprisingly hard because the built-in http server doesn't give you good events. For example, if you block a request for a while, you don't know when the other side has disconnected. So you really have to write your own http server from scratch to do this right.
There's a standard library to parse Go code. Start by parsing a file or package and spitting it back out. (This is only a few lines of code.) Then actually inspect the AST and either report interesting statistics, produce warnings, suggest improvements, or improve the language. That last option is fun. I have a pre-processor that lets you write the expression "%d %f"(x, y) to do printf-style formatting in a terse way. You'll learn a bunch about the language by manipulating its AST.
Static web site generator? Nagios in Go?
Check out [the blog post](http://frozenfractal.com/blog/2013/2/6/bigcanvas/) and [the penises](http://bigcanvas.frozenfractal.com/#E,1,16,329). Might be slightly NSFW because... well, penises.
If not a server emulator, any game worth playing can benefit from external calculators or planners.
Something useful would be a validation library 
* it's a gui tool - makes it hard to copy and paste configs * no support for adding scripts to be run on up/down * gets in the way of tools like Kismet
&gt; I think it would be great to have maybe either a tip or link to article on upgrading/migrating to the new version. Existing projects should not require any changes. Go 1.1 will be fully backward compatible with 1.0.
That's true. Game servers just came to mind because they tend to be concurrent by definition and it is surprisingly easy to get started.
Awesome! This is exactly what I've been looking for the last week or so (assuming it does what it says it does :D). I'll have a go with it once I finish with playing OpenGL.
(1) Write Conway's Game of Life (2) Improve it This has provided me many hours of edutainment. And it's a project you can realistically do in a day.
It says right on the documentation you need to close the response, do you do that? http://golang.org/pkg/net/http/
A networking library that implements framing on top of TCP. Everyone needs it.
Someone even drew a [vagina](http://bigcanvas.frozenfractal.com/#yO,1U,92,451) - which pretty much never happens in these bathroom-wall situations.
I think it's pretty handy. Makes it easy for me to connect to a wireless network. Aren't NM's preferences also saved somewhere in your home directory? Last time I installed a different OS on my / partition, all my network settings were restored. About adding scripts: you are right on that. I'm not sure how it interferes with Kismet, but I've had that same problem before indeed. Didn't know NM was the culprit there. Although for the 'common' user, NM makes networking (and mainly connecting to wireless network) a walk in the park.
I don't think people use the word Nifty enough. I'm spearheading the revival.
https://github.com/drone/jkl This one is based on Jekyll.
&gt; wicd suck Eh? Wicd is awesome. It has a command line interface, a curses interface and a regular ol' GUI. You can also drop scripts in `/etc/wicd/scripts`, and they'll be run at different stages of connect/disconnect.
But I'm using a ResponseWriter, not a Response. In [this] (http://golang.org/doc/articles/wiki/) tutorial by the Go team it doesn't close anything...
http://tip.golang.org/pkg/net/http/#CloseNotifier
Useful tool to have... I wonder how I could get my SDL based game to cross compile too... mac and windows libs are different.
Write a Go compiler for asm.js http://asmjs.org/spec/latest/.
&gt;This works with at least one version of clang that existed at one moment in time. No guarantees about clangs past or future. I'm not sure I'd say that "Golang now builds using Clang" based on that statement there.
Pretty standard disclaimer in the software industry although it is not usually explicitly written. Could have mentioned the working version though.
I did not know such a movement was taking place. Interesting.
You've got to start somewhere. 
Bladerunner reference = automatic upvote
is it open source? where is the code?
While I'm glad you've promoted the gogl package, you're linking to my dev fork and not the upstream repo. I can't guarentee that my fork will exist in the near future. Please update the link. The upstream repo is here: https://github.com/chsc/gogl
BTW, for the integration, stats stuff, this GSL repo is probably the way to go: https://bitbucket.org/mingzhi/gsl
Nice. I'm more excited about that for projects that I don't have on my physical computer, seeing as most of my Go code searching is done via `grep'.
I soooo wish Android SDK had Go support... although NaCL with Go support would be even more interesting, then a single Go source compiled for every platform in 1 shot. Hopefully NaCl will help kill Java.
I was talking to the devs working on NaCl and they said code generation for closures was a problem for go on nacl support. So this would make go friendly nacl support a bit more within our grasps. :)
Excellent. /mrburns
FYI, I changed llgo to use the pair-of-pointers scheme a little while ago. Have been too busy to play with PNaCl recently, but there's no reason why closures would not now work in it.
Anyone, please explain for me this part: &gt; **Backwards Incompatibility** &gt; Supporting code written in C or assembly will need to change, for three reasons. First, ordinary funcs must account for the gap when computing argument offsets. Second, a func value has grown in size from one word to two words. Third, calling a func value requires passing the second word as the gap argument. This means that C or assembly code written for Go 1.0 will not be compatible with Go 1.1. Package authors will need to use +build tags to select between Go 1.0 and Go 1.1 implementations. This kind of incompatibility is allowed by the Go 1 contract, which only makes promises about Go source code, not about C or assembly. C or assembly code written for Go 1.0 is already incompatible with Go 1.1 on 64-bit platforms due to the change in the size of int, and we can provide a tool to point out offset mistakes and even rewrite assembly files (based on the asmlint I wrote for the int change). What is `argument offset`?
Russ is talking about the offset from the start of the stack frame (the frame pointer).
Interesting. I wish Atlas were open source to have a peak.
@axwalk Thanks for your reply, i.e., If I rebuild all, it don't have any problems?
Unless you are writing Go functions in C or asm (or do really peculiar things with reflect/unsafe), then you will not be adversely affected. The changes are relevant to the C/asm compiled with 9c/9a.
Thank you.
Not for the faint of heart: https://groups.google.com/d/topic/golang-nuts/nvhkd5yZBXs/discussion
IIRC from the IO talks, NaCl operates by validating jump targets against static metadata. Dynamic code generation poses problems because, well, it's dynamic - NaCl doesn't know about the jump targets, so the calls would fail security checks before being dispatched. (you probably know this, but other readers may not)
Could someone explain the two pointers implementation having "obvious drawbacks"? I'd think getting rid of dynamic code gen would allow you to reduce icache utilization (due to duplicated generated code), reduce icache invalidation, and reduce the total size of a closure. It seems like there are points for and against both sides.
Great example. If you could show how to use the benchcmp script that would also be useful. 
Take a look at [fibonacci.go](https://github.com/ChristianSiegert/go-testing-example/blob/master/fibonacci.go). I wrote three Fibonacci functions (the ones that are benched in [fibonacci_test.go](https://github.com/ChristianSiegert/go-testing-example/blob/master/fibonacci_test.go)). The first one, *Fibonacci*, implements the basic algorithm. It calculates the Fibonacci number for a given *n*. For large *n*s, like 50, this functions needs several minutes until it calculated the result. The reason is that due to the nature of the algorithm, the Fibonacci number for *n* is the sum of the Fibonacci numbers of *n-1* and *n-2*, which in turn are each the sum of other Fibonacci numbers. To get the Fibonacci number for n=50, the function must calculate all Fibonacci numbers from n=49 to n=0. *FibonacciFast* and *FibonacciFastest* avoid recalculating already calculated Fibonacci numbers. They do so by storing the result in a map, in my example named *lookupTable*. The map's key is *n* and the value is the calculated result for that *n*. Since both *FibonacciFast* and *FibonacciFastest* use *lookupTable*, I must make sure that when they are benchmarked, there are no results stored in it. Otherwise it would skew the benchmark results if one function has to fill the lookup table and the other function starts with one that is already filled with precalculated results.
This looks nice but it also looks like the 5-6 other go rest frameworks. This is the only one that has stood out as having something new and some unique features: https://github.com/emicklei/go-restful I finally settled on it after trying nearly every other one out there including my own attempts and manual usage of gorilla, net/http.
As with the other go web frameworks, it's a little bit "insert dummy storage API here". Really need someone to write a proper cross-db orm.
Yeah. After reading I was like "so where's the github link?!"
Sweet! I assume this will make creating Go closures much faster, since the instruction cache no longer needs flushing after dynamic code generation. Can anyone confirm?
Check also https://github.com/goerlang/node/blob/master/examples/gonode.go for usage example
Nice!
First thing you'll want to do in your main() is runtime.LockOSThread(). This one: panic: runtime error: call of nil func value [signal 0xb code=0x1 addr=0x0 pc=0x0] goroutine 1 [syscall]: github.com/go-gl/gl._Cfunc_glCreateShader(0x8b31, 0x1e000000280) /tmp/go-build588713281/github.com/go-gl/gl/_obj/_cgo_defun.c:674 +0x2f github.com/go-gl/gl.CreateShader(0x8b31, 0x1e000000280, 0x4a507c, 0x0) /tmp/go-build588713281/github.com/go-gl/gl/_obj/attriblocation.cgo1.go:4141 +0x23 main.main() /home/dicks/Documents/go/src/SDL/sdlgl2.go:45 +0x1ad gives us a hint. So "call of nil func value" in gl._Cfunc_glCreateShader. Did you init the GL package? I see an SDL init but no GL init................
runtime.LockOSThread() Gives the exact same error, the packages seem to handle mutexing threading already hopefully making that redundant. The gl package has no init, Viewport is the init of sorts... I have a feeling the damn thing depends on glew which is broken... may have to try using freeglut inside instead.
Actually go-gl do have an init function, gl.Init(). https://github.com/go-gl/gl/blob/master/gl.go#L1144
&gt; runtime.LockOSThread() Gives the exact same error Yeah, I didn't mean to imply that this was the cause of your issue. &gt; the packages seem to handle mutexing threading already hopefully making that redundant. Whatever mutex threading the other packages do isn't really relevant IMHO for this: *if* you want to ensure that all your SDL-windowing and GL-binding calls are always at all times happening inside the exact same OS thread that originally created the window and the GL context --personally, I *would* want to ensure that at all times-- then only runtime.LockOSThread() can guarantee that.
Like Russ' proposal? 
Not exactly the same, but similar. It may end up the same later.
You could follow along with the lab work from this [class](http://pdos.csail.mit.edu/6.824/index.html). Let me know if you do and we can compare notes.
Yes, Go is open source: hg clone -u release https://code.google.com/p/go
Found it, although I get the same error no matter where I call it, hmm...
Well there's 3 things a game has, graphics, input, sound(and networking in my case), freeglut "just werks" and does two of the three, it's very C-like(C is my main language, not C++), but that's not a bad thing, just feels weird using in Go. I'd have to find a lib that handles sound then, something multi-platform. That's a nice looking package, will play with it, although I have to stick with raw OpenGL so I can restrict myself to only using the features of ES 2.0 so I can easily port around later. Tried SDL because it has ports to ARM-Linux, initially ES1, but ES2 works(somewhat) now too. Go has excellent standard libs... only if there was some semi-official graphical packages, Obj-C and C# kinda have that, although they're monsters... it's for the better keeping Go small.
Totally agree, something like c++ odb library : http://www.codesynthesis.com/products/odb
&gt; I gave up on SDL Same here but I found GLFW works great, and so does the go-gl/glfw binding across all 3 OSes...
Platform/Go version? Glew is pretty broken, so far I've been unable to figure out why. Best current explanation is that the linker doesn't like linking static libraries. It's not all the glew functions, just the ones that are dynamically loaded at runtime. This hasn't seemed to have a whole lot of exposure, seems like nobody is even attempting to use glew features. So, keep us updated if you make any progress, know that you aren't suffering alone :)
1.0.2 AMD64 Linux Since you say glew is broken... I'll skip that and try freeglut, it's very simple, C-like and always 2-4 years behind the OpenGL spec. I can't even get glfw to go-get, all sorts of random deps for some reason... i'll clean it up then try it. I'll start with freeglut 2.6 because it's in every repo, then 2.8... even though 2.6 is really old, 2009, all you really need is OpenGL 2.1 since you can then do a modern ES2-like program using frag/vert shaders... if it works.
&gt; I can't even get glfw to go-get, all sorts of random deps for some reason Just double-checked all .go files in go-gl/glfw, there aren't any non-standard imports. Chances are, you didn't fetch and install libglfw (glfw.org) before doing the go-get....
I have it but it wants lxde packages... lxrandr and stuff.
This guy's blog has a lot of good posts. 
Hmm. Too bad then. Can't remember having that issue back when I last tried Go+GL programming under Linux (way over half a year ago with the previous GLFW version -- switched back to Win since then, simply for the better/faster GL drivers), but then I never really cared whatever dependencies the package manager reported and just went ahead installing what I needed regardless of whatever deps it comes with... Point being, once libGlfw is properly fully installed in your system (you say you "have" it but do you have it installed?), the rest should be a "breeze", within whatever limits your GPU's Linux driver &amp; GL implementation may or or may not have...
I think what you are looking for is append() which is under builtins in the package docs. parts = append(parts, myString) I hope that gets you going in the right direction. 
The glfw c library has to be compiled as a shared library, which it isn't by default. First thing I'd check.
You're looking for map I think, http://tour.golang.org/#36 
[This](http://play.golang.org/p/fP9EFJCGBb) sorta does what you want. If you want to index with a string, you have to use a map, as /u/rossj mentioned, and a map must have a value type, so you can't have strings and ints in the same map.
One small change I'd add. Instead of type Closer interface { CloseWrite() error } Better idea might be to extend the net.Conn interface like this, which keeps the usability of net.Conn: type Closer interface { net.Conn CloseWrite() error } See http://play.golang.org/p/pxq7twXhQa for example
For even more idiomatic go combine the type assertion and the if condition into one line: func shutdownWrite(conn net.Conn) { if v, ok := conn.(Closer); ok { v.CloseWrite() } } If the interface is only used locally you can also use an anonymous interface: func shutdownWrite(conn net.Conn) { if v, ok := conn.(interface{ CloseWrite() error }); ok { v.CloseWrite() } } 
Depends on your needs. In the example, it was unnecessary. Go certainly makes it easy to change if it becomes necessary, so personally I'd stick with the add-it-if-you-need-it approach.
Oh God, Why? A big part of what makes Go awesome is you don't have to deal with event soup and callbacks to get simple concurrent operation. 
Thanks, I'll keep this in mind as I develop code. This wasn't for processing forms, though it is for logging apache stuff into a mongo database, so the fixed size index isn't ideal for the task since I'll never really know what parameters may be part of a url.
That is super sweet. #### GOLANG INCREASED TO 26
Ringo! or even better for googling: RingoDB Some others that sound kinda like orc language: Gring (go ring) Grash (go hash-ring) I'll try to brainstorm some more. I suppose that "Go" shouldn't even necessarily be in the name, as this project has a wider audience that just the golang community.
I think that only happens on ARM. From the mailing list: Thanks to andrey mirtchovski here is the reformatted Raspberry Pi data, go version devel +ddb9e6365e57 Wed Feb 20 15:35:27 2013 -0800 linux/arm vs. go version devel +e00da5e201e5 Fri Feb 22 17:16:31 2013 -0800 linux/arm benchmark old ns/op new ns/op delta BenchmarkBinaryTree17 131488202467 112637283111 -14.34% BenchmarkFannkuch11 61976254131 61972329989 -0.01% BenchmarkGobDecode 424145307 383073401 -9.68% BenchmarkGobEncode 115032849 120332484 +4.61% BenchmarkGzip 13868472766 13493855517 -2.70% BenchmarkGunzip 1728657231 1680585482 -2.78% BenchmarkJSONEncode 2374700526 2377737536 +0.13% BenchmarkJSONDecode 5110739064 4877799205 -4.56% BenchmarkMandelbrot200 96515515 96478503 -0.04% BenchmarkParse 216403777 214091185 -1.07% BenchmarkRevcomp 192566195 196115543 +1.84% BenchmarkTemplate 6090635318 5572935111 -8.50% benchmark old MB/s new MB/s speedup BenchmarkGobDecode 1.81 2.00 1.10x BenchmarkGobEncode 6.67 6.38 0.96x BenchmarkGzip 1.40 1.44 1.03x BenchmarkGunzip 11.23 11.55 1.03x BenchmarkJSONEncode 0.82 0.82 1.00x BenchmarkJSONDecode 0.38 0.40 1.05x BenchmarkParse 0.27 0.27 1.00x BenchmarkRevcomp 13.20 12.96 0.98x BenchmarkTemplate 0.32 0.35 1.09x
Another good one is http://www.youtube.com/watch?v=3DtUzH3zoFo.
In some ways, this is prophetic. How he mentions that he wants to write a webserver in Newsqueak, or bring the semantics of channels to C++, it shows he passionate he was about these concepts at the time. And fortunately, he brought them all into Go. (also, Ken Thompson sits in the first row, as you can see in one of the shots rather at the end)
I'm pretty sure it was after this talk that inspired him to revisit a lot of these ideas and eventually led Go's inception.
The story goes that work on Go started very soon after this talk because in giving the talk rob was reminded of all the good things in newsqueak, alef and limbo.
Skipping the boring critique of "omg we don't need another configuration file format because X is good enough..." The lexer is based on [Rob Pike's talk](http://cuddle.googlecode.com/hg/talk/lex.html#slide-7). It's my first parser of this sort. There are pieces that I'm not happy with (too much complexity), but on the whole, I'm reasonably OK with it. The parser isn't great. But it's small. So I can toss it out and start fresh if I get unhappy. The reflection part is pretty cool---the magic is in [a sort of type unification](https://github.com/BurntSushi/toml/blob/master/decode.go#L68). I didn't look too closely at how the `encoding/json` or `encoding/xml` operate, but I am very pleased with how the reflection stuff turned out. The trickiest part was probably [realizing that pointer types needed to be initialized](https://github.com/BurntSushi/toml/blob/master/decode.go#L226) when following the references. I know I still need to expand some of the allowed types, particularly numbers---but that's not so interesting. I was surprised to see how easy it was to handle slices and maps through reflection; I thought it might be harder than it was. The reflection is why I bothered posting it here. I really **love** the way the Go standard library leverages reflection to parse data formats, and I think the ecosystem as a whole could use more of it. I have no idea if my handling of reflection is naive. Do dragons await me?
We know Heroku has moved on from Doozer, and if they're not going to maintain it, then it would be polite to delegate that responsibility to a group that _is_ interested is doing so, and perhaps bless the new 'official' fork. Creating github organizations is trivial, and it only takes a few people to aggregate all the existing outstanding patches and merge any issues into a standalone repository. Even if the new project doesn't have any heavy development, it solves the problem of they're being 5 forks each with incremental ongoing work.
Nope; but this might help: https://groups.google.com/forum/?hl=en&amp;fromgroups=#!topic/doozer/RjcFI05qLno
[Meta] I find that the adjectives and impressions titles of programming articles have are inversely related to how many people use programming language/library/feature/etc. &amp;nbsp; [Examples: Most Popular to Least Popular] Java XXX sucks! Why are you still using C++? C#?! Microsoft Shill! PHP? Hack-fest! ... Javascript is kinda cool... Python Rocks! Ruby FTW! ... Functional Programming is a new Paradigm! Go is from Google so it automatically rocks! Your language is just a subset of Common Lisp. 
&gt; Go is from Google so it automatically rocks! I'm pretty sure that was the biggest cause of the initial *backlash* against Go.
Couldn't have asked for that thread to go any better. Great example of open source community.
Damn I should really see what the subreddit is. I came here expecting to see an actual railgun blowing holes in stuff.
Such a shame I can't read the code. I wonder if there is anything like this that is open?
Initial? 
Your language IS just a subset of Common Lisp :P
This new mode is really great! Emacs with: - this new go-mode - gocode - goflymake + flymake-cursor - yasnippet + yasnippet-go - http://www.let.rug.nl/~kleiweg/go/go-emacs.html makes a great Go dev environment!
☃^☃^☃^☃^☃^☃^☃^☃^☃^☃^☃^☃
Looks like it has happened.
Yup, nice to see open source working. For those of you playing along at home, bketelsen wrote up some notes from the meeting: https://groups.google.com/forum/m/?fromgroups#!topic/doozer/oUuhBwQ_Ga4
oh hey i raised that issue glad theyre getting round to it
I would recommend having words be a []Word instead of a map for the reasons frou said. When posting to goplay it's nice to make it runnable. I made your example more runnable (still no user input, but at least printing) and changed to []Word, which you can see here: http://play.golang.org/p/63zXl_6w2O 
Oh, I see where the probem is! Thanks! I did not know the range thing, I'm looking at it. Will update post (and pm you) when I will have a fully runnable program. I am making this for myself, and every people in my class. Go is just amazing, I will build a windows binary for those :) Next step is to add download of the list for the internets.
An upcoming addition I have pending is integration with godef (https://code.google.com/p/rog-go/source/browse/exp/cmd/godef/godef.go), an awesome tool for finding the definitions of symbols. This includes function definitions, local variables, struct fields, global variables and pretty much everything. That'll allow extremely fast navigation in go-mode.el
you get a better compiler support, and less of the gnu virus
I actually agreed with a lot of your post except the last three basically. In fact, I hear the bitching about Go's Google heritage than I hear about it being "automatically rocks"ing because it's from Google. The last line, I guess... just... "K."
Appengine feels limiting to me because everything is so sandboxed. Great for gazillions of users and a high level of security, though.
Ah fuck, I was in Montreal last March.
will go there
Skynet
&gt;will go*lang* there
only if I want to be easily findable.
Awesome. I'd kick in $20 to help pay for dinner (pizza?). Any other volunteers?
I cannot open the Google docs link for the reasoning. Short version? I get the "it isn't in the spec" part. Is there more?
It doesn't, it would appear: &gt; prog.go:13: cannot use x (type []byte) as type []interface {} in function argument
my question is why it doesn't. doesn't `byte` satisfy `interface{}`?
Edit: title should be "why doesn't this variadic work?"
https://code.google.com/p/go-wiki/wiki/InterfaceSlice
Wow, your first post in 4 months. Do you still lurk reddit?
How are you not a mod of /r/wow?
The clock in the playground is deterministic to aid in debugging. Click on About for all the details. (Hat tip to #go-nuts for the answer)
Time begins at 2009-11-10 23:00:00 UTC to aid **caching**. Click on About for all the details :).
I wish there was a recording of the SPLASH talk available.
It does change. Have you tried sleeping?
I found that go-nuts post too when searching for the video, but it doesn't seem like it is going to happen. But yes, the essay is quite good.
What does this have to do with golang?
&gt;"Because of the scale of Google data, however, R is typically only useful after a massive data aggregation step has been accomplished .... and there are several Google-developed scripting languages that can be used for this purpose, including Go." I wanted to point out another example of Go being used in production and that Google is dogfooding it in house. 
&gt; Google-developed scripting languages including Go &gt; scripting languages including Go &gt; scripting languages &gt; scripting What the heck did I just read...
From the "About" button: &gt; In the playground the time begins at 2009-11-10 23:00:00 UTC (determining the sigificance of this date is an exercise for the reader). This makes it easier to cache programs by giving them deterministic output.
The makefile presented in the article makes me sad. Make is a dependency management tool, and they use none of its capabilities and may as well replace the makefile with a shell script. Doing a "clean" as a part of the build seems in bad taste as well: it duplicates your clean target and makes dependency tracking useless. You should let Make handle regeneration of auto-generated files if an of your inputs change instead of doing a clean build every time. I know Go compiles fast, but still...
On Win, just comment out that line. 
Taking it a bit further: http://play.golang.org/p/3gv7-RPt7O The simple Spinner type implements Tick and Done methods. Call Tick to update the spinner, and Done to clear it. The SpinReadCloser wraps a ReadCloser that updates a Spinner on each Read, and clears it on Close. 
Hah, very nice!
Nice, thanks for adding that.
Why not use https://github.com/adoxa/ansicon
 Being the one who wrote that 'article', I agree with you on most counts. However, it is not intended as a guide to 'best practices of GNU Make'. It is just a very quick and dirty write-up on one way to do automatic code generation for Go projects, written in response to a question on G+.
An alternative method of embedding static data (html, css, js, images) is to use nrsc (bitbucket.org/tebeka/nrsc/nrsc), which will zip-up a directory of files, concatenate it to your executable, and allow easy access to the attached files. I use this system to embed a full-blown web client into my server. The main advantage: you can deal with the data as if it were on the disk and make embedding optional. I do this for my dvid project. Your system for converting data to Go files makes sense if you are trying to save on text parsing time, so maybe for large slice data.
Elaborate, please? Perhaps cite your source?
Say ticker := time.NewTicker(...) This allocates unmanaged resources that will never be freed unless ticker.Stop() is called. Garbage collection will not free these resources. If you call time.Tick(...), a new ticker is created and ticker.C is returned. Therefore you have no possibility to free the allocated resources. If you call time.Tick(...) repeatedly, you have memory leak.
Sure? So you know that this leaks memory and yet you present it here where other people will pick up bad habits? ticker := time.NewTicker(50 * time.Millisecond) defer ticker.Stop() .... case &lt;-ticker.C: would only have been one line longer.
http://github.com/nf/ has some of my personal stuff. http://golang.org/src/ has stuff I do for work. ;-) My talks contain some good samples, for instance: [a simple programming environment](http://talks.golang.org/2012/simple.slide) and [code that grows with grace](http://talks.golang.org/2012/chat.slide). 
You're being a bit combative. Why didn't you just include the fix in your first comment? I didn't think about it when writing the sample, because it wasn't the focus of what I was doing. Thanks for pointing it out. I updated the sample.
The new mode is brilliant. 
This looks good. I might be able to go back to Emacs from sublime. Sublime tends to die horribly when a test crashes the wrong way.
This does look really good. I've never used emacs before but this has piqued my interest. I wonder how good the autocomplete is. I tried to use `gocode` for Vim but it's not as useful as I'd like. (I'm used to GoSublime where it will also suggest parameters based on their type. Whereas `gocode` seems to suggests variables in scope, regardless of the parameter's expected type.) I wonder if this plugins' auto-complete is a little bit more... complete.
I don't think the gocode bindings for Emacs have any parameter completion at all. At least I am only used to completing method names. I know that GoSublime uses gocode too, so I'm wondering how hard it would be to port its behavior to Emacs.
Not sure, but it's [open source](https://github.com/DisposaBoy/GoSublime) so it's definitely possible. Just from glancing at it, I think most of the magic happens in `margo9` which seems to be a web-server [written in Go] servicing requests in JSON. (It looks like Margo internally uses `gocode` for some of the dirty work.) So really integrating it w/ another project shouldn't be too hard. I think the Python bits are just to integrate `margo` w/ Sublime Text and provide "snippets."
Cool. Check out this project for another example of SSE https://github.com/antage/eventsource
Quick note, you can grab go-mode with Emacs's built-in package manager (`M-x package-list-packages`) if you add the MELPA repository. (add-to-list 'package-archives '("melpa" . "http://melpa.milkbox.net/packages/") t)
Personally I'm always skeptical when it comes to those package repositories, mainly because it's usually some 3rd party who is uploading the package, and not the package author himself. They're nice as long as whoever is uploading them keeps doing so, but at some point, they'll probably become stale and out of date.
Why do WebSockets require a separate server? They only require another handler and javascript.
Surely there's a method to `git pull` your repo using the marmalade build-system? Note: has never written a marmalade-enabled plugin.
Note that interface{} comparisons are slow. You will have to create custom types for every key/value-type pair. Talk about generics...
Is it threadsafe? How does it compare to Google's LRU https://code.google.com/p/vitess/source/browse/go/cache/lru_cache.go
Happy birthday Go
Can you explain why it won't be garbage collected if there are no references to it? Not sure if golang uses a reference counting garbage collector, total noob here.
Hi, I've had the opportunity to work with the HPCloud recently (there's a $20 credit for the first three months to all new accounts, btw). So inevitably I ended up writing some bindings in Go. They're very rough at the moment and my own API will surely not be stable, but I wanted to throw this out there to see if anyone else is working with this platform.
For the same reason that you have to close files you have opened. The resource is unmanaged, i.e., it's not managed by the garbage collector.
You can all go fuck yourselves.
BSD is fine for me. I don't like the chains of the GPL. &gt;Here's my bits of data, use them if you find them useful.
&gt;Here's my stuff. Use it to take your users freedoms away, if that's what you're into. &gt;Here's my stuff. Use it to build DRM. ...
&gt;Implying psd, docx, exe.
Again implying that I am forced to use them, or any software.
Let's not devolve this discussion into petty insults. &gt;Implying I have to eat.
Would be nice if the creator posted a file format normal people could actually use. Edit: FFS, it doesn't work in Google Docs either.
As pointers/references go, these aren't even that much of a special case. Anyone can whip up types like this: // Hey lib users, this is "basically a reference type"!.. type MyRef struct { myptr *SomeType myindex int } What would be neat was if it was trivially easy to have indicate a type's size in an editor using the *go-code* auto-completion-demon, whether GoSublime or Vim or... each function definition one writes, one could immediately decide -- do I want to copy this or ref this.
Slice, map and chan are only special due to their ability to be generic. You can make you own reference types by putting pointers in a struct.
I'd love to see C++ style duck typing generics in Go. It could hurt compile times a bit though. Simply generating and compiling N more functions doesn't sound bad when you remove all the template metaprogramming horror though.
I hosted a pdf here (since it is CC-BY-SA): http://golangweekly.com/files/go_for_pythonistas.pdf
The writing style is a bit breezy, but seems OK so far in the sample chapters. It seems he's about half way through the standard library, I would estimate he won't be complete for at least another year. [The code from the book is on github.](https://github.com/darkhelmet/go-thestdlib) I personally haven't decided to purchase the book yet. I'm still looking through the sample code to see what I think of his coding style.
Sample page 7 first text line: &gt;Remember to `Close` the original `io.Writer` you passed in followed by the `tar writer`. It's the other way around. He explained this before and it's correct in the code. What should I make of this?
$39 for a 179 page pamphlet. Yep.
[Discussion over at hacker news](https://news.ycombinator.com/item?id=5365096).
Excellent! Thank you.
The Go version of a Python tuple is a struct, not an array. 
Step 1: Took Rails out of the picture.
All I could think while reading was, is this really about how good Go is, or more a bout how bad RoR is.
This looks really great. I had been meaning to write something like this myself, but could never get to it. Definitely going in my box of tools. :-) Thanks!
Maybe a little of both? I'm pretty sure RoR has its uses and Go definitely has its own problems. Go just seems to be by far better tool for the job in this case.
Very interesting. Thanks for doing that
I've only used .NET MVC4, Go and PHP. So I can't really speak to RoR's performance. But Go is my favorite of those 3.
Yeah, my pamphlet of Jewish sports legends was complementary, what gives?
&gt; Sick of theoretical examples only suitable for documentation? Get real world code, like supporting gzip bodies from HTTP clients and a look at a timing attack (and how The Standard Library can help prevent it)! WTF aren't these types of examples in the library documentation to begin with? WTH should I have to pay 39 bucks to get something that could, with a little bit of thoughtful documentation, come ... er... standard???
"Tricky" but you get used to it very quickly.
See https://groups.google.com/d/msg/golang-nuts/VeJTB9dhhK4/hFsAdgPzvkUJ And try this: http://play.golang.org/p/QqXtPKrmEj
That was one of the first things I learned when I started Go. "I assigned this variable in a conditional block, why is the value not... ohhh, `:=` **re**assigns." Seems like we can chalk that up as a rookie mistake, not sure it's worth a blog post.
Sharing by communicating: var ( messageCacheInput chan *message = make(chan *message) messageCacheRequest chan (chan []*message) = make(chan (chan []*message)) ) // messageCacheManager manages the message cache. // // When a message is sent to messageCacheInput, it overwrites the oldest element in the cache. // // When a request is sent to messageCacheRequest (messageCacheRequest &lt;- request), it sends a slice of the cache elements to the request (request &lt;- reply). // The messages are ordered from oldest to newest. // If request blocks, nothing is sent. func messageCacheManager() { cacheSize := config.CommentCacheSize cache := make([]*message, cacheSize) head := 0 for { select { case input := &lt;-messageCacheInput: cache[head] = input head = (head + 1) % cacheSize case request := &lt;-messageCacheRequest: reply := make([]*message, 0, cacheSize) for i := 0; i &lt; cacheSize; i++ { message := cache[(head+i)%cacheSize] if message != nil { reply = append(reply, message) } } select { case request &lt;- reply: default: } } } } 
Apparently, that's what MELPA is doing. Fetching the go-mode from Go's hg repository. So that's cool, I like that. Marmalade, on the other hand, completely relies on manual submissions unless I am terribly mistaken. And whoever submitted go-mode there once has stopped updating it. That's also part of the issue: There are multiple package repositories, with different versions of the same package, different procedures, and so on.
It's like the Python packaging index then. It's a good idea but ultimately fails when manual submissions are required.
I end up structuring code differently in order to make it look decent on Kindles and in the PDf.
I could use some interpretation and application.
Go has always used epoll for goroutines blocked on the network. But now the goroutine scheduler itself is aware of epoll (or kqueue, etc), so goroutines are run quicker and scheduled onto a more ideal processor than before, and with fewer locks involved. 
Will this be available in 1.1?
Yes, you're correct, and that's what I am saying, though I'm not saying it very well. Will revise.
Will there be a recording of the talk?
The website [Go by Example](https://gobyexample.com/) mostly covers the language itself, though some of the later examples use parts of the standard library. In general the documentation for the Go standard library on the website is fairly good. There are some examples in there, but the coverage there is far from complete. For experienced programmers, it may well be enough, but some people may want more examples.
&gt; I end up structuring code differently in order to make it look decent on Kindles and in the PDf. Good to know. For the code itself, I prefer looking at it in my favorite editor. BTW, I don't tweet, so is there some other cannonical way to send corrections to you? Can/should people open up issues on Github?
GitHub issues work, or there is http://thestandardlibrary.com/feedback.html
Thanks :)
I'm confused. Did goroutines previously get scheduled and then unschedule themselves if epoll didn't give them anything to process? 
It's not fully precise yet. The stack precision isn't done, and some types of objects on the heap can still confuse it and be treated conservatively. But it's more precise.
Previously the poll server stuff (epoll or whatever) was implemented entirely in the net package, in pure Go. When they were blocked on a Read or Write, they'd detect that, register with the pollserver (pure Go), and wait on a channel for when they should try again. So then a goroutine would wake up when epoll_wait returned, process the events, tell all the registered waiters (sending on channels), and then they'd be runnable (since they received on their channel) and try again. Later that was extended to good effect to have N poll servers (one per CPU, up to some limit). It all worked very well, but the goroutine scheduling still had one global lock and didn't have any CPU affinity. The scheduler is now much smarter and has fewer locks, and the epoll_wait stuff is now integrated right into the scheduler, without ping-ponging around different goroutines like before. 
Is there anything like Rails for Go? Revel maybe ?
I haven't seen the point of investigating web frameworks for Go because Go's standard library is so good at it. I do have 1 small bit of code I share across my Go web projects that is a mux for HTTP methods, but that is it.
Ah I see, as someone who has never done Web Development, Rails and Django arereally helpful.
And they are really great at that.
these numbers seem very impressive. Unfortunately, I don't really understand them. What does this mean to an application developer that uses Go, but has very little knowledge of the runtime's internals?
Nice util, good way to learn the language. Few things that I immediately see. The levels should be in your const block, as should the map -&gt; names. Your definitions of the levels should use 'iota'. Your copy of LstdFlags should use log.LstdFlags. Minor nit, your lookup function should use len(LevelNames) instead of 7, as well as your bounds checks in ParseLevel.
Cool! I wanted something like this, and probably would have built it if you hadn't.
Do it anyways, it's good practice! There's already 40 logging packages out there, what's one more?
Wait, one of the complaints was that there's no user management library, so then you wrote a user management library, but you're still abandoning Go, because... I'm confused.
that's just one of many libraries i need. i wrote it and decided that if i write all of the things i need, it'll take too long. while it was fun to write libraries like that, it also takes a lot of development time out of the actual project.
Hopefully the user management library will be kept up-to-date and not abandoned. It's rather nice.
That's the spirit!
It's just a matter of perspective. With many mainstream languages, I often think "damn, this great idea I just had was already implemented in a bazillion ways". With Go, I think: "So much room for activities!"
People are creating now the ecosystem of Go. If you are joining today Go, contribuite to its success is necessary. If you want something superior you must give something in return
He/she's not abandoning Go, just choosing another tool that better fits whatever the project in question is, based on the development time necessary to fill in the gaps in the ecosystem. Sounds like a fair conclusion, not really a critique of the language or anything.
I'm glad you released the code. It really contributes to fixing this problem of having to write things from scratch. Hopefully some day it wont be a problem at all anymore.
&gt; A bit more digging and I found that the issue was around the default timeout values set by the Go HTTP server. The default settings allowed clients to use HTTP keep-alive to keep their connection indefinitely, essentially resulting in an ever-growing collection of open file handles. Setting the default read and write timeouts to a sufficiently low value stopped the problem completely. How do you do that?
 srv := &amp;http.Server{ ReadTimeout: 2 * time.Second, WriteTimeout: 2 * time.Second, // ... }
"Go" is ungooglable. 
Using Golang is a common idiom because, even if you deny it, it's hard to google, especially if Google hasn't figured out yet that you do a lot of Go work. It was more of an issue when Go was relatively new, but it stuck around and still has validity.
Are there any tools that help manage the GOPATH for you? The less thinking I have to do, the better
Forking to "freeze" like this is fragile. Say you release some package that points to your frozen dep. Someone copies your code. From their perspective, your repo is now the authority.(and tracing forks back to the original is not always straightforward, should they want the original author's updated repo)
I'm pretty excited to use this! Been waiting for it. I wish Mozilla would implement PNaCl into Firefox.
The linked patchset is for linux only -- is KQueue/IOCP/etc already integrated with the scheduler, or will Linux be the only Go1.1 environment where the scheduler is integrated with the I/O?
I know this post is pretty old, but do you happen to have that PKGBUILD around? I can't get it to compile :(
Hmm. My RPi is in the closet, I'll try to dig out the memory card tomorrow and see what's on it. I don't recall making any major changes though... Are you having problems with memory? What is the compile error?