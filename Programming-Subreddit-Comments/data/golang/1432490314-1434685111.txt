IntelliJ is working on making the Go plugin for IDEA "production quality", including source-level debugging, by August 2015. I can't say if the current release already has good debugging functionality: https://github.com/go-lang-plugin-org/go-lang-idea-plugin LiteIDE also has debugging: https://github.com/visualfc/liteide I understand you're looking for a debugger, not an IDE (I hear Go developers are not very fond of IDEs ;), but since both are open source, maybe you could try to find out how they deal with debugging.
As someone who has been doing heavily threaded apps for going on 20 years -- log based debugging has long been my only true and trusted friend. Debuggers just tend to suck with concurrency (and that is minor concurrency, dozens of threads, not millions of goroutines) -- so does logging, but less. The amount of money I have spent on "premium" debuggers supposed to "make debugging threaded code easy" over the last two decades is insane -- and I always returned to 'I will just log it'. At this point I can't tell if it is Stockholm Syndrome or not -- but I find debuggers generally are far too costly to use (time wise, effort wise) and have a very poor return on investment. The only thing that I have changed in the last decade is from mostly unstructured text logging to mostly structured logging in accessible formats (json, xml, etc). 
Actually, the plugin is most stable and completely functional. For me it works really fine.
If you're trying to debug web-based applications, I've found something like this to be very useful at times: * Make sure you escape the output! * Only use this in a development environment or mode. Do not do this in production! package main import ( "fmt" "html" "net/http" "github.com/davecgh/go-spew/spew" ) func handler(w http.ResponseWriter, r *http.Request) { w.Header().Set("Content-Type", "text/html") fmt.Fprintf(w, "Hi there, %s!", r.URL.Path[1:]) fmt.Fprintf(w, "&lt;!--\n" + html.EscapeString(spew.Sdump(w)) + "\n--&gt;") } func main() { http.HandleFunc("/", handler) http.ListenAndServe(":8080", nil) } [update: added the html.EscapeString() and added warning to not use in production.] 
There is also https://github.com/yosssi/gcss, which is written in pure Go. 
You can sort of use it on Go code (either gccgo or standard) and it sort of works on mostly uselessly trivial code -- the problem is it doesn't understand all the specific internals... and -- as every debugger I have ever used -- is useless with concurrency. As for "basics" -- what does that mean? breaks points... stepping... what? The problem is most real go code is likely to have concurrency, hundreds of goroutines as a floor, and millions isn't that unusual. How do you debug a million goroutines with a debugger -- heck, how do you do 900? Those 900 are mapped across X hardware threads applied to Y cores. Debuggers just don't seem to scale well to lots of little things running at the same time. Logs work because they are highly tool friendly -- dump the logs as something like json, filter, filter, filter, parse, puzzle, replay... and that tooling you write can be reused, because the truth is -- a lot of concurrent bugs pop up occasionally, not every run, so even if you were willing to step through 900 goroutines -- you might not even find the issue on that run. Honestly -- if Go is the first one to crack this problem I will be delighted, but I don't have high hopes. I suspect the reason we don't have a "Go debugger" yet is -- it would be as worthless as all the other debugger for concurrent code. 
&gt; neither our clients or our monitoring systems indicate a problem. Right. There is no error logged when HAProxy isn't listening, so how would you know? - If a client gets a single error, and the site is still up immediately after, would they call you? (Really?) Even if they did, would anyone "connect the dots" to haproxy? (If it's out to lunch for 100ms and you get 100 requests per second, you will average 10 errors per restart. If your site has 300 active users at a time, they will only see one error every 30 restarts, on average. ) - Assuming haproxy is out to lunch for 100ms, and your monitoring checks every minute, monitoring won't see the problem 599 out of every 600 restarts. If you restart haproxy every day, it will take 1-2 *years* for your monitoring system to notice the problem. - Most monitoring systems won't alert unless you are down for a few seconds. So it's likely that your monitoring will *never* alert you to the problem. I'm not saying you have to address the problem, only that you have to understand the trade-offs. You can restart every day and still claim "five nines" of reliability (assuming nothing else goes wrong...). But you can't ever claim 100% uptime.
&gt; I'm too hot! Hot Damn!
Thanks man
Interesting, why do you use structured logging formats?
[TotalView](http://www.roguewave.com/products-services/totalview) always seemed to work quite well, although I've not used it in several years. A short overview of debugging threaded code using TotalView [link](https://computing.llnl.gov/tutorials/totalview/part3.html) edit: added overview comment and link
Besides the error handling point, the post mostly seams like a rant on go syntax .. meh indeed
Yeah. I've also used the encoding/gob trick, but it feels really stupid to do so, but it does work. I haven't benchmarked how big penalty there is to use the encoding/gob when compared to a manually written deep copy routing without reflection, but I'd guess that it usually isn't too much.
Local variables don't show if they are held in registers. See [https://github.com/golang/go/issues/2430](https://github.com/golang/go/issues/2430) However, LiteIDE uses gdb, so sometimes it will work, sometimes it won't.
I use them because it's easier to build up context in sophisticated ways. Your typical logging package might print out the function, line, time and an arbitrary message. Well what if I also wanted to know, say, what database I was connected to, or what HTTP request I was serving? I can push that into the logging context and it pops out along with whatever messages I log in that context. Combined with something like graylog, which allows you to search and filter on those fields, it can get really powerful
Would you happen to have a code sample you could share? Are you using existing libraries to do this or rolling your own, or both? Thanks.
Thanks for the recommendation. I have actually purchased TotalView in the past -- it was "meh" to me as product, solid by not standout, and the licensing model was painfully complex based on developers, processes/cores (and weird caps on threads) -- has something changed recently that I should be awre of?
It lets you dump easier to parse and more data rich formats (trees of stuff, specific datatypes, etc). Just the other day I had to run a one off data recovery bit of code on a node, few hundred lines of code doing something rather trivial with two DBs. I dumped the logs using https://github.com/Sirupsen/logrus in json output mode. Just a boring "the facts" sort of log, few million rows of (changed X to Y related changes changed A to B and C to D and E to F). Couple days later -- it came back we had missed another table related to the X to Y change (but only where A = "value"), so I just did an ioutil read of the json and a decode into a structure and started looping over related chunks of data, and since they all lived in a single json object, it was profoundly easy -- took a few minutes to write. 
This is by no means a bad habit - using stack dumps and variable dumps is a reasonable method for troubleshooting problems in a development environment (a.k.a. "fixing bugs"). Instead of printing the values to the HTML response, you could also just log them: log.Printf("Spew: %v\n", spew.Sdump(w)) As others have pointed out, Go does not currently have a first-class source level debugger that is easy to use when debugging multi-threaded applications (like all web applications). You just need to use these techniques appropriately.
Nothing public, that might change. Have a look at [this](https://structlog.readthedocs.org/en/stable/), which is where I got the idea from.
Yeah, the naming on that is bad. The problem is that RGBA values are stored as uint8, then when you call the RGBA() method on a color it returns the color in a 16 bit space (max of 65535) but stores that in a uint32 so you can multiply it without risking overflow. clampUint makes sure that I stay in the 16 bit space while maintaining the color values as uint32s. I found that some of the crazy calculations needed for color distance had the potential to overflow the 16 bit space.
What is the actual context where you are having this problem? There might be other solutions to the problem, i.e. using mutexes/goroutines in some way.
I know. Just poking fun at you. The second wtf is "if v &lt; 0 {" :)
What kind of code generator? I tried to google around but found nothing. And I agree, I don't like code generation at all, it just makes the entire compile phase more complex than it should be.
We wrote one. I think it is not committed yet, but will be soon .
Cool, thanks.
Nice work!
What are the advantages over messaging services like AMQP (RabbitMQ), Redis, or ZMQ?
If you're building complex deployments with multiple services, and potentially multiple hosts, you really should look at orchestration via Juju. It'll let you use the same setup to deploy to local containers, virtual machines, bare metal nodes or into any of the major clouds. There's a little bit to learn up front, but it'll pay you back. http://www.ubuntu.com/cloud/tools/juju
We were debugging just 2/4 processors with 2/4/8 cores per processor, so nothing close to what you're dealing with. Would you mind listing a couple of the other debuggers you've used that you think might be worth looking at? 
I think named return values are fine as long as you (1) always provide explicit values to return and (2) don't use them at all in the body of the function (outside of deferred closures) unless they are invariantly directly returned. There are some exceptions to this, such as an error return, which might be nil or err, but otherwise, that's how I think they should typically be used.
Let's say that you get to the end of your function and you just do something like "return 42", and that at some point in your function you had a "defer myFile.Close()". The execution order would be to return 42 and then call myFile.Close(). So this way, you have no way of modifying what you return based on whether the Close() is successful or not. If on the other hand you're using named returns, and you have something like "return err", the defer can modify the returned value before it is actually passed to the calling statement. It's one of the properties of how defer works in Go. As far as I'm aware, this is the only way to return the result of a defer in a function.
Do you use Juju in production? I've yet to hear good things about it as compared to Salt/Ansible/Puppet/Chef
Fantastic, can't wait!
Yes, we use Juju in production (I work for Canonical).
It looks like a nice process-based protocol-agnostic RPC plugin implementation. As mentioned on the github page, there are some advantages to using multiple processes rather than dynamic libraries: primarily protecting against crashing your main app of the plugin crashes. Even Google Chrome (and soon Firefox) use a very similar approach. There are also downsides to the approach, too. If you need to transfer a lot (and _I do mean A LOT_) of data between the application and plugins, then you'll suffer from performance issues due to the memory copy overhead. One solution to this is a memory mapped file, but AFAIK it's not super simple to set up / is platform-specific. Overall, if you need plugins for your application it's an approach that works great and this package looks like it does it for you simply :)
The biggest risk imho is it using stdin/stdout to communicate, which can be problematic if you output stuff by accident. And downside, there's quite a bit of overhead compared to a native function call: serialize, deserialize, execute, serialize, deserialize for each call, and the (de)serialization probably uses reflection in Go, which isn't exactly fast. I had been considering of writing something similar myself, having encountered many situations where plugins would have been practical, or even needed. Certainly going to try it out.
[There is another library for Go plugins: Pingo]( https://github.com/dullgiulio/pingo)
I think of it as being like a web service that is always available, and way way way faster than taking over the network. Both require the serialization overhead.
Some interesting comments have got buried due to the OP's unpopularity! So stuff we could take from this: - Formal verification tools for Go (like JML for Java or ACSL for C) could be interesting to some people to refine code further. Adding verifiers and provers seem like a natural extension to the existing Go checking tools. It probably just needs someone with cash and requirements to fund it and make it happen. - There is a question of how to find the best projects for Go when there are so many alpha projects out there. So could this be automated, e.g. based on automated checks and measures of code quality (e.g. how much testing)? Measures are always difficult, though, as even a code coverage percentage tells you nothing about whether all the tricky corners of the testing space have actually been touched. Measures can always be intentionally or unintentionally gamed. Actual experienced humans are the best judges. (Personally, whenever I find a human recommendation of a good project in an area I'm interesting in, I make a note of it, because searching for it later I'm unlikely to find it.) - Self-classification of projects as alpha, beta, stable could be useful to help people find the stable projects without doing loads of research into all the alpha-level projects. If someone claims their project to be beta or stable, then perhaps some review or voting process could exist to put it onto a "community-recommended" list. (That is, if the community cares enough about helping make the best projects more visible.)
For what it seems, it just accepts any kind of plugin. Is there any intent in the future when loading a plugin validates that it conforms to a pre-defined interface?
Pie is really just intended as a very simple way to bootstrap the communication between the main application and the plugin. You could certainly build on top of it to make a more framework-y thing that does what you wish. 
You might be able to use defer and recover. defer func() { if err := recover(); err != nil { foobar() } }()
Good advice. Thanks. Can you tell me why errcheck is useful? I'm not getting it from the index.md
/me sips coffee, smugly
In Go it's possible to ignore errors, especially if they're the only return from a function you trust, like `fmt.Printf`, or `filehandle.Close`. errcheck tells you about them.
In general you shouldn't do this, as unless you know exactly what you're recovering from and how to recover from it, you're just putting your program in an unknown state — better to crash and know what happened.
Ahh, the good old [C++ tadpole operators](http://blogs.msdn.com/b/oldnewthing/archive/2015/05/25/10616865.aspx). **EDIT:** Behold the [Nya Operator](https://play.golang.org/p/gDNhGMGf4x). Does nothing, but adds cuteness to the code -\^+\^-
This might be, perhaps in combination with ledisdb, my only option. Hoping there's a golang-only sqlite library out there but I might just plain be SOL. Thanks for trying to help!
have you seen https://github.com/onsi/ginkgo ? Imho its the better solution for tests.
 I'd rather go for y + 1 than ^^^^^^^^ or ~~~~~~~
Odds aren't in your favour I'm afraid - there's a large difference in manhours between linking a library and rewriting it from scratch. Sqlite has years of effort behind it, don't know if there's a strong desire to duplicate that.
Yeah, and re-implementing it definitely bears with it a great deal of risk. Just because the standard is fleshed out well doesn't mean that a re-implemented codebase in another language will be "bulletproof" or all that solid. Agree that odds aren't in my favor! Are there any other SQL-based embedded DBs you know of beyond SQLite? I've been looking lately at Firebird embedded, but I have to distribute application binaries :/
Amazing work on the plugin, it's really an indispensable tool!
How about ql? https://github.com/cznic/ql/ (Or tiedot)
If I were writing this in C, I'd probably use `socketpair` and do communication over the unnamed UNIX domain sockets that could be passed across the `fork`. Since Go can't fork, though, this is probably the best way to do things portably. (If you were doing Linux-only, you could use the "abstract namespace" of UNIX sockets to do the same thing without dealing with the filesystem.)
I could easily replace os.Stdout with os.Stderr, so that the developer can't accidentally shoot themselves in the foot (and writes to os.Stdout would still get written to os.Stderr). I could probably stub out the os.Stdin pointer, too so that no one else can read from it. (either null it out or replace it with a File that just always returns EOF).
Agreed, it's a one stop for a complete and powerful go dev environment. Thanks for your hard work. 
What about https://github.com/google/cayley ?
Do you mean [OpenID](http://en.wikipedia.org/wiki/OpenID)? (Potentially overlapping use case as OAuth, but completely separate implementation). The only discussion I see is on [this page](http://steamcommunity.com/dev) about OpenID.
Haven't seen this one before - I'll take a look at it, thanks!
After further investigation it looks like it is indeed a hellishly convoluted process (though if you could simplify and automate it, you'd be a hero to many). I've found cross-compilation to be really easy with Go, and I've been using SQLite extensively **on OS X only**, and for some reason it never occurred to me that these two pleasurable experiences would be nigh impossible to combine. Now I'm kind of bummed… What was it that turned you off with ql? I've never used it, but it seems like if you're using their database/sql driver it would be basically identical to the experience of using the database/sql driver for SQLite (albeit without having the full power of SQLite at your disposal).
I agree wrt performance. But socketpair isn't linux-only, it's been around since 4.2BSD.
Perhaps reconsider the embedded requirement? SQLite binaries already exist for windows. Your REST server could just connect to that as the backend data store. I'm guessing you really want to minimize your installation steps, but that may be untenable considering your goals.
Thanks so much 
Very nice
Did a quick implementation of the OpenID system from Steam a few weeks ago. I can post the source if you wish to have a look ? Will have to clean the source code from various proprietary information, but should be able to get a copy up either later today or tomorrow.
I know nothing about how compilers work. Out of curiosity, does the compiler actually *do* anything when it encounters this, or does it know how to optimize it away?
Actually I understand it now just wondering it says don't use nonce or discovery cache and to use an alternative. What should I use??
For the server its important to add monitoring. At a basic level you can use an outside service (like pingdom, but there are many others) to monitor an HTTP endpoint, but you probably want a deeper level of monitoring. A lot of companies use nagios, but a more modern approach would be hashicorp's consul. It's also useful to keep track of metrics. The monitoring should catch total failures (HTTP is unreachable, a machine is dead, etc..) but it probably won't tell you much about reduced performance (and even if it did it almost never tells you *why* something is behaving badly) I've only ever used graphite, but there are a lot of other products out there too. Just build a bunch of graphs to chart usage, request times, etc... and leave a window open all the time. You'd be surprised how many issues you can spot before a user ever realizes something is wrong. The game client is trickier. At some point it will have issues (at a minimum someone's machine will do something strange which you didn't account for), so having a path for users to submit bugs would be good. If you can add something to the program to make that easier that may be worthwhile (some sort of "your program crashed, would you like to send an error report)... but the truth is most games don't really do that. They just have a forum setup somewhere. Outside of that it really comes down to testing. You can harden your software by throwing realistic usage at it. That can be hard for something brand new (because you probably don't have any real idea of what the traffic will look like) but you could also try pushing it until it breaks. See how many connections a server can handle, at what point the database starts to slow down, etc... I think though for almost all software it's also a matter of flexibility going forward. You're not building something that's perfect, but if you keep an eye on it and have a good foundation, you should be able to address any issues that come up quickly. MMOs are notoriously bad at launch, so I'd guess you will have a fair bit of headroom when it comes to what users will put up with.
I meant windows :) (or rather, I meant that it wouldn't work on windows)
&gt; `++` and `--` increment and decrement the variable, respectively. These operators have no effect on the value stored a++ modifies the value stored at a.
&gt; ` =( )=` goatse operator...
huh, well if Google does it ... I'm just kidding, thanks I'm leaning towards going with interfaces because I appreciate the structure and ease of mocking.
Thanks so much. I was looking at the openid-go package and it said to use something different than nonce and discoveryCache as it lives in memory forever and won't be destroyed. Any idea about that?
Cayley author here. I like Bolt, as I hand a lot of the semantics off to the backend. Happy to talk at length about indices and graph data though! 
Referential ambiguity. "These" operators are prefix `^-` and `-^`, not postfix `++` and `--`, and don't alter the variable they're applied to.
This is pretty awesome. Kind of inspiring, really. Makes me want to make a roguelike in Go at some point.
by the time you vet a library aren't licensing issues resolved?
I use your plugin every day. Thank you for continuing to work on it. You're an asset to the community. 
I just pulled down the latest godep and I don't see a `pkgset` command. Where is this from?
;)
Makes sense
:)
You changed the path of the source. You will need to rewrite those imports to the new path. The key here is that the error is informing you the path your trying to import (original) doesn't exist (because you moved the code to a different path)
Interessting. Thanks. If would follow this post and make changes in "server.go", and someone would "go get github.com/you/cooltool.git" wouldn't they also "go get" the original version and use "server.go" from this version?
You work directly on the original version. Your fork only exists on github. When you finish editing server.go then instead of pushing to the original, you push to your fork with: git push fork Your fork will then have the new version of server.go and finally you can make a pull request to the original repository to accept your new server.go from your forked repository.
tl;dr (from the blog): &gt; interface{} is a wonderful thing to have, except in the most frequently called sections of you code.
my bad, sorry &gt;.&lt;, it's gvm that has that command. I use gvm to version my go binaries and pkgsets. Godep to handle the versioning of the packages. Autoenv to set everything whenever i get into the package folder. The only trick is always use: gvm pkgset create --local Godep has issue following symlink (https://github.com/tools/godep/issues/115), too bad, but still the best setup i got so far.
The combination of a ON(&lt;time&gt;) with a OFF() seems odd to me ? I would expect the ON(&lt;time&gt;) to disable the vibration by itself after 1 second ? //Turn on Android vibrator for 1 second if _, err := vibrator.VibratorON(1000); err != nil { //Turn off Android vibrator if _, err := vibrator.VibratorOFF(); err != nil { 
Sounds like you're using gvm + godep to do what wgo does by itself :)
Google pays the developers of Go to build a language to meet the needs of Certain Google development teams so it would seem perfectly logical that an internal tool is solely based an their needs. Then they have this tool away to be used by other people but O fail to see where that would really require them to bend to the communities will, they could very well have kept this locked away behind closed doors at Google and never released it. If they don't need, it probably won't be added. It's the benefit of owning the software. If it bothers that much you can seek out other languages as options for your projects - or if you work on Go you would have a harder time getting away from it. Berating Google does nothing productive and paints you in a negative light. I don't like some things about Go, but that's what makes Go Go and not something else so I suck it up and move on with my life. 
So the reported 2-3x slowdown in 1.5 compilation is due to the conversion from C to Go, but since this code is not yet optimised for Go (being mostly an automatic conversion from C), in future versions would we be likely to see this speed up again as the code is refactored? (I guess we will ...)
I think this little demo shows that Go is great choice for writing multiplayer server for web games. The server is sending the entire canvas image at 30 FPS to player 2.
Have you tried the [log](http://golang.org/pkg/log/) and [syslog](http://golang.org/pkg/log/syslog/) packages?
SWEET!
Yes, thank you! I was just wondering yesterday if I should have the whole `src/github.com/user/package` directory structure. It looked weird on Github. Then I saw the `notgood` directory here. Maybe Dave should consider a note about conventions relating to this or changing "hello" to "notgood" at [http://getgb.io/docs/project/](http://getgb.io/docs/project/). I was confused, because I saw that and some other projects out there which didn't use the full import path convention. Of course, it really is just the same thing as with `$GOPATH`, but it seemed less obvious before. And thanks for `gb`, Dave!
&gt; I was uncomfortable until I tried it. subjectively I find this … subjective :) If you're fine with it, that's ok. I'm not ok with rewriting, I think there are better ways to achieve the same goal. &gt; Which naming rules? The two rules at the top of my presentation, I consider this axiomatic. &gt; automating this is fairly trivial, do you have an example where it's not? These are concerns gathered from https://groups.google.com/forum/#!topic/golang-dev/nMWoEAG55v8. &gt; there is no accounting for taste, but when is it worth the trade-off? I don't think import rewriting is acceptable under any circumstance, so my threshold is very low. &gt; prefixing is a total function, what dangers are introduced? is this jumping the gun? (sorry, couldn't resist) I don't understand what you wrote. My point is that rsc added the canonical import path because he feels that the same package appearing more than once in a dependency graph is a serious problem. I agree with him, so if import rewriting also rewrites the safety check he added, that seems like not much of a safety check.
Are there any specs for JWT? I couln't find any on the http://jwt.io/ site...
It seems strange to me that the runtime, including the GC, is written in Go. What happens if the GC code, written in Go, attempts to allocate memory via "foo := new (Foo);"? Would some kind of deadlock or exception occur? In short, how did they manage to write a GC in a GCed language?
Also look at [logxi](https://github.com/mgutz/logxi), it's structured and 12-factor app compliant. The nice thing is everything is configurable by environment variables including 256 colors
&gt; What happens if the GC code, written in Go, attempts to allocate memory via "foo := new (Foo);"? Would some kind of deadlock or exception occur? My first guess is that this may simply be an example of "[Don't do that then](http://www.catb.org/jargon/html/D/Don-t-do-that-then-.html)" (maybe enforced by the compiler using annotations?) In other words: presumably all memory the GC needs is either pre-allocated or stack-only...
Of course. (Also that's not an opinion.)
Yes there is, on the jwt.io website, at the top, you have a "IETF" link, which will lead you to the [IETF draft](https://tools.ietf.org/html/draft-ietf-oauth-json-web-token-32).
I do seek out other languages, but at the same time I can see Go's strong points. I didn't say that Go was an entirely bad language! Strong Windows support, minimal syntax, goroutines and super easy deployments are things I really enjoy in Go and are the reasons why I still use it for my projects. For situations where I need smaller binaries, I'm looking at Nim (now that 1.0.0 is released). For web stuff, PHP is still my main choice. The things I don't like about Go are things like the ones I mentioned. I can't fork a Go package without also telling my users "oh yeah, you need to go-get it and then move it to a different spot" (or maybe I'm overlooking cleverness in go get and it actually looks at the source to determine the target download directory). I can't keep a specific version of some dependency without using 3rd party tools or resorting to "git commit all the things!". Maybe I expressed my concern badly in the previous post. What I wanted to say is that I can feel Google's strong influence on the language and its ecosystem, and not all of Google's choices are necessarily ones that are useful for the "general public". If you choose Go, you are at the mercy of Google. And in the last years, that has proven problematic for me. (Rust, for comparision, feels much more community-influenced, even though it's steered by Mozilla. Not saying that Rust is better or worse than Go.)
I'm not arguing, just want to learn the go way - I'm sure there are advantages I have yet to discover. Still, opening a bunch of files and changing the same string, is, what I call, hardcoded. 
You should invest in a tool that automates that for you. 
I am actually using Nonce and Discovery Cache at the moment for the sake of getting it working and continuing development. From my understanding, this isn't such a huge deal as long as you only have one server. Granted, it isn't good practice to use it. My plan for the future once I make more progress would be to change this and use something like mysql. Once I do so, maybe I will post something online for everyone else to reference. 
answered
Sorry but that would imply writing a properly formatted file (like ELF on Linux, PE on Windows etc). That's not my point here. I'm trying to inject bytes into an memory space and execute them directly, there is no physical file in the hard drive.
shared libraries, that one is great, wohoo!
Still, I think the stack is GC-managed too.. Not sure how you can circumvent using the stack.
This.
IIRC Go always makes sure to leave at least some number of bytes free on the stack when calling functions unless it knows for a fact that the called function doesn't need that many. Among other things, the code that allocates a bigger stack when it's about to run out uses that. So it might be able to fit in that space. Alternatively, it might just have reserved one or more pre-allocated stacks big enough for the GC so that it never has to allocate them in out-of-memory conditions.
Yeah but if you check the stackoverflow question, I added 2 test instructions (NOP and RET) and they were executed. Someone was even further and did this: http://pastebin.com/eHb6zMyD which is also working and when I replace the codes with something else, it wont run
I don't know exactly what these tools (godep, nut) do wrong, but with true vendoring you only have to clone one repository and run "go build" and you always get the same result.
Sorry if I came off as hostile at any point, it was not my intention.
I'm simply trying to execute a shellcode in GoLang. Like this C code for example: http://pastebin.com/AnsHdX9w
It should be able to manage its own stacks once the runtime/gc has been bootstrapped.
Although I'm good with static binaries, it's good to have the option.
I didn't perceive it as hostile at all. I really appreciate your help.
hooking system calls is the first thing that comes to mind. there are any number of usage cases though.
Vendoring and dependency management is definitely being worked on, but with the 1.5 freeze now in place there wasn't time for anything to make it into the Go tool. The Go team is aware of the problems the diversity of vendoring tools causes, especially for those new to the language. If you're interested in contributing to the discussion, take a look at: https://github.com/kardianos/vendor-spec
Try [getgb.io](http://getgb.io), a project based build tool for Go that doesn't use import rewriting.
Plugins loaded in runtime, writing plugins for C programs in Go, loading shared libraries written in C in Go programs, and shared libraries for Go. That Go produces static binaries by default is cool, but not having the ability to easily load shared libraries was a major downside, where people had to jump through many loops. The main way of doing this was launching another executable and communicating with it over a unix socket, stdin/out, TCP or some other IPC mechanism - which causes a huge amount of en/decoding and communication overhead. 
yeah, check the answer below for more examples
so here: https://github.com/debasishm89/C-Codes/blob/master/shellcode-exp.c we have a working C example. I did ported it (except the shellcode itself, which im using other - tested and working fine): http://pastebin.com/mRjGL6G3 is not working either.. i believe is a pretty decent port and it should work but nothing so far.. Windows 8.1 x64
It was done, thanks. I was just wondering why I couldn't access those cookies myself.
I've thought through this as well, but I don't know for sure how to distribute the application and installer such that it'll have the right binaries together on Windows and register it as a service on startup, etc. However, maybe you're right - perhaps I need to get off my posterior and look that up anyway. Thanks man.
Good question. Basically, the QL docs say (copy/pasta): &gt; QL is a SQL-like language. It is less complex and less powerful than SQL (whichever specification SQL is considered to be). The problem here, for me, is an unknown. I don't know how QL differs, specifically, from other SQL databases. I don't know what features it's lacking that I may need through the life of the project, and I really don't want to make the mistake of going with a data store that I'll have to distribute an "upgrade" for later on to migrate data out of one and into another.
I've got a Windows 8.1x64 host I could build on, but I have -no idea- how to build CGO binaries on Windows. Though I'm sure that's traveled territory by now so I can do the google. ;-) I appreciate the input here, though - thank you!
So what happens if there's a bug in the 1.4 compiler that prevents some future change from compiling? Does 1.4 get fixed to say 1.4.1 and then 1.6 or whatever is recompiled? What kind of issues does that cause, I imagine it's a thorny problem.
* Common Mistakes in Go: [Slide](http://www.slideshare.net/spf13/7-common-mistakes-in-go-2015/) * Concurrency Patterns: [Slide](http://www.slideshare.net/arschles/concurrency-patterns-48668399)
In that case it just means your bootstrapping procedure goes one level deeper. Compile Go 1.4 with C -&gt; compile Go 1.5 with Go 1.4 -&gt; compile Go 1.x with Go 1.5 (for instance). To clarify, that would be the procedure if Go 1.x absolutely could not be compiled with Go 1.4 (i.e., the Go 1.x compiler has to make use of a language feature that Go 1.4 doesn't support). If there were a bug in the Go 1.4 compiler I'm sure they'd just make a Go 1.4.x to fix it.
The community doesn't have a good working solution. They have hacks and workarounds. Any claim otherwise is stockholm syndrome. That's why there is 50,000 community driven solutions.
After 5 years we don't have a de facto working solution. That is the problem. The Go tooling, primarily because of "go get", has inadvertently created the problem, so it is time for the language team to provide a solution and put this issue to bed. 
Man, just FYI, calling me a liar is abrasive and makes me not want to try to communicate with you. I would highly suggest a lighter touch if you want meaningful feedback. Python has PIP, which is probably the best of the bunch. However, all of them suffer from the following : * Ruby, Python, Perl (any of the *PANs) generally require the same treatment as go, namely saving off important codebases that need to be "frozen" at a moment in-time. Python is admittedly the best at this, and I haven't tried Perl in production in a decade, but CPAN's lack of proper packaging and version support was pretty well known ( I can't find the link now, but the Debian article on why they created .debs for Perl libs instead of using CPAN was telling : https://wiki.debian.org/PerlFAQ ) * I don't know much about the CLR, but it's been described as yet another DLL hell, but this time with the GAC. * Java. Given your tone, I can't tell if this is a troll or not. A) this is a community solution, and B) you should checkout package management with Maven (or Ivy) and the need for things like Artifactory. I wouldn't call this a "success" for the language. * Haven't checked out Rust enough to comment, same with PHP (sorry, I never really treated PHP as a "real" language, but I own up to my bigotry here) &gt; I'm pretty sure once go gets a proper package manager you're going to use it. And i'm really sick of people like you pretending they are satisfied with the status quo, that's really a mentality I hate in the Go community. "go get" shouldn't be part of go compiler anyway. That's a serious mistake the go team made. It should be a tool that can evolve on its own without needing releasing a new go version. I'm going to chalk this up to you having a shitty day and taking it out on the Internet. There isn't any sensible argument in this. Sorry this sucks for you.
Dave Cheney explains it on this page for his new "gb" tool. He also has links to a presentation he gave at GDC Berlin. http://getgb.io/rationale/ If you would like to talk more about it after reading this, I would be glad to.
I get your point. My experience tells me this is true with pretty much every language I've used, so I guess I didn't expect Go to solve it. Also, the 'go get' method pretty gracefully solves a bunch of problems I experience with both Java, Node, Perl, Ruby, and Python projects, namely how to effectively address a codebase without baking something into the language itself (Java's import paths are the most famous example of a good idea gone horribly wrong ; I'm looking at you, packages that still use the root without prefixing a TLD). I see what people are shooting for, but there's a ton of anger and hate over a problem we, collectively, have faced for years. I guess I don't see why the Go team has to fix this. We can fix this, probably better than they can (since we control the code ; they just control the language).
Huh. I guess I don't assume that just because something isn't supported well that it has to be fixed by the Dev Team. I guess I don't get the logic. Doesn't GB "sit on top of go" and provide this very functionality? What am I missing here?
If there was non-optimal code in the C compiler, which compiled the Go compiler, how would the Go compiler become optimal?
gb does not wrap the Go tool, this makes it different to all the other solutions out there. 
OK, I'm clearly not getting this. Sorry, thanks for trying.
OK, I think I figured out where I'm confused. So, there are two parts to this thread : * Supporting better versioning of 3rd-party libraries * Tools that attempt to take on this task I don't have any issue or question about GB's goals. What I don't understand is why the Dev Team needs to change anything, at all, given that GB seems to be solving this issue? Making life easier for GB is a great goal, but I'd rather have them focused on other things. Why is this a pressing issue, and specifically what is being requested of the Go Team? Am I being nutty here for asking for technical documentation to a problem with a major language?
Hey there. I'm the author of that blog post. I wrote that post after finishing http://tour.golang.org/ and watching a few Go talks on concurrency. I personally find the best way of learning is to just try things, so I recommend building a base knowledge of Go concurrency patterns (very useful for a web scraper) and finding some non-go-specific posts on web scraper design (although not required). It's a pretty open-ended project and there are a lot of different way to go about it, so be creative and have fun! Also, screwing up the first five times you write it will teach you a lot more than getting it right the first time by reading someone else's tutorials! :D I'd be happy to help out as well if you have any questions.
gb is only concerned with providing a project based approach to building go code that let's you achieve repeatable builds by including (vendoring) all the source of your dependencies in the project. Giving go packages versions (in the way we understand it from other languages) is a different, and independent problem to the one gb is solving. 
&gt; One question though - do I need to do anything special with go get? gb doesn't use go get, and gb projects are not go gettable. Its a different format. 
Ok great thanks for the advice! Also thanks for that tutorial, it seriously helped
Those both look really interesting thanks!
My opinion is quite opposite. Go was designed for large teams (Google). All the tooling and straight forward code makes it easy for any new member to understand the code easily. So, I feel its more suited for large projects compared to small hobby ones. Also, I feel that once Go solves some basic problems for enterprise properly ( like dep. management ), we might see an increase in enterprise usage.
Hm. I can't get this to work. All I'm getting is: cannot inline gotos without type information But, I don't have any gotos anywhere... :( grind -diff file.go
My tip is to scrape from the [edit page](http://monsterhunter.wikia.com/wiki/MH4U:_Item_List?action=edit). Then you can write a simple regular expression to match all the fields, like [this](https://regex101.com/r/jT3hR8/1).
Well, in Russia such contradicted situations are described by phrase "One doesn't have sex because of having acne, and does have acne because of doesn't having sex". All you need to do is start new enterprise level project with Go and not with Java solutions. It would be hard to explain to your PM, but if you can, this will be example of using Go in enterprise.
&gt; it seems to have come under a lot of criticism in regards to how well it actually works in industry. Really? By whom? I haven't seen this at all, in fact rather the opposite... depending on your definition of "industry", I suppose. &gt; I wouldn't be surprised that if Go doesn't end up tackling the enterprise server-side programming market, I really don't agree, I think Go is perfectly suited in that environment. And projects like [go-kit](http://gokit.io) will help get it there.
Interesting. Can this handle wildcards? Is it a true tree lookup?
I said *if* Go doesn't take off in that environment. I'm not saying it won't, I just mean that even if it doesn't, I think it will still find a place in the niche I'm describing.
&gt;No. How did you get from "if err != nil" to monad? The reason people don't like this is because it's the same error handling as in C. C, which is not exactly well liked for it's error handling. At the time of writing this article, the account had a name "the Rental monad". You can see it by disabling JS. &gt;This is true. This is why people hate Linq in C#, and why no one uses SQL &lt;/irony&gt;. Are you sure you're not mixing up Declarative or Logical with Purely Functional here? &gt;Depends on the industry now doesn't it? How does PHP thrive in embedded programming? How does PHP thrive in programming of telephone switches? Half the worlds communication passes through Ericsson switches, which uses Erlang, a functional language. The author [does](http://www.cirello.org/2015/03/2015-03-20-simplicity-to-achieve-vs-to-express/) note that Erlang is the most used of FP languages, and attributes that to the fact that it comes with "batteries included".
Linq is just map/filter/reduce with names that match SQL, as that is what people are used to. Functional usually is declarative. The author might note that, but his assumption is incorrect. Node.JS is heavily used, but doesn't even come close to having "batteries included", especially when compared to Erlang. It's also funny that he mentions Robert C. Martin, who has held numerous Clojure workshops, and even says Clojure should be used for everything, yet Clojure is not considered mainstream, even with more batteries than Java. In any case, everything he mentions in his rant is criticism that could've come from users of any language. Java users don't enjoy C-like error handling, or the lack of generics. C# users don't like that, without generics, you can't use functional constructs like map/filter/reduce. Why he singles FP out, and purely FP especially (which is what? Only Haskell?), is beyond me.
Haha, I was wondering why I was getting so many new twitter followers recently. I see this guy linked to my post "why everyone hates go".
I totally agree. The benefits that go brings to large projects are also enjoyed by small projects. I've jumped into Hugo, a relatively large side project in the scheme of things, and the fact that the code is all very straight forward meant I could get hacking very quickly. 
I actually find that the "large team" features just mean that my side project code is of much higher quality than it otherwise would be. 
Well somebody has a bee in their bonnet. I didn't realise Programming Languages were teams and that we were in a battle for the death. Or that you could only pick one. I'm also confused by the idea that functional languages such as Haskell and Lisp somehow "Lost" this battle. Plenty of fads have come and gone in the last *57* years and Lisp is still here, and going strong, with modern dialects such as Clojure having quite strong following both in acadamia and for serious industrial uses. Haskell - especially in the last few years - is rapidly gaining traction as a serious industrial language, with heavyweights such as Facebook using it in production, along with its ML cousin OCaml. In the last 15 years I've watch Perl, PHP, Python, Ruby, Javascript, and Go gain rapid adoption as "The next big thing", and then rapidly fall from grace after a few years when the next one comes along. And you know which languages just kept being used through that period of time without all the fanfare, are still going strong, and aren't likely to go anywhere soon? The main ones that come to mind are: C, C++, Java, ML, and Lisp. I use Go, Clojure, Scala, and Haskell at work in various contexts and they all have thriving ecosystems and are great languages for their problem domain. tl;dr Go is a perfectly good language for what it's designed to do. But it didn't "Win" any more than FP "Lost". Edit: &gt; OK, now - let’s check what Haskel offers. One package which last update is from October 2014. And no manual According to that very page - 22,000 downloads, 737 in the last 30 days, last updated "19 May 2015", and with a link to documentation and examples here https://github.com/fpco/http-reverse-proxy and here https://hackage.haskell.org/package/http-reverse-proxy-0.4.2/docs/Network-HTTP-ReverseProxy.html By following the documentation I was able to build an example reverse proxy in under 5 minutes. {-# LANGUAGE OverloadedStrings #-} import Network.HTTP.ReverseProxy import Data.Conduit.Network main = do let settings = serverSettings 8080 "*" let target = return (ProxyDest "www.reddit.com" 80) runTCPServer settings (rawProxyTo $ \headers -&gt; return target) 
&gt; The reason people don't like this is because it's the same error handling as in C. C, which is not exactly well liked for it's error handling. But, go doesn't have the same error handling as C. Because C lacks multiple returns, errors are typically the only return, or they're set as a global variable to be inspected. Very much unlike Go. People complain about error handling in Go because exception throwing has made them lazy. It also made their code not handle errors very well.
First thing, you won't win any respect from the LISP community by conflating Lisp with FP or with the idea that FP dates back to Lisps inception. Lisp is not a FP language, any more than it is an OOP language. It's capable of doing both those things, but it's not a requirement. There are dialects of Lisp that are pure functional languages, but they're not the norm and this certainly wasn't the case in 1958. To my knowledge the idea of FP arose in the 1970s.
As it happens, Go was born at about the same time I gave up on FP (in the form of Clojure and Erlang) as a viable solution for most projects. 
Fastest performance would be a regex on the HTML response from the server. Fastest dev would probably be GoQuery: https://github.com/PuerkitoBio/goquery Lots of tutorials on outputting content to a file. With CSV just be sure to scrub the data for commas before writing to your file.
The main gripes about Go error handling stem from two main points. - Failure to handle an error means it'll silently be ignored and your code will continue executing as if nothing happened. It's fail-dangerous by design. - Go effectively uses a tuple / product type to represent a value that can be one thing or another, instead of a union type, and then relies on null checking instead of case analysis. The idea of returning an error type instead of throwing exceptions is a good one, it's just that - compared to other implementations of this idea - Go's is a bit lacking. They could (and should) have used a union type instead, which would have worked better, been safer, and wouldn't have added any significant complexity to the language. Then there's the gripes about how verbose Go's error handling is. Other languages provide ways of plumbing this back up the stack without needing to be so explicit.
This is a new Go package, which uses yamux for the underlying connections. It's still WIP, but any feedback is welcome. 
&gt; C, which is not exactly well liked for it's error handling. I think it's worth mentioning that if C had Go's `defer` and return tuples, it would be well received as the alternative indeed leaves us all wanting. Go's take on error handling is an iterative improvement upon C, and does well for this.
I was hoping for the same but did not find anything
I agree completely about the discussion needing to end, as do the authors of godep, nut, vendor, wgo and gb. * Go 1.6: I don't know yet if the proposed vendor-spec will be supported by the go toolchain in 1.6, but I will be advocating for that path. * Used in Google: Google is a fairly unique setting. One codebase worked on simultaneously by &gt; 25,000 software engineers with comprehensive pre-submit checks that make it very hard to 'break the build'. Google also has legal, regulatory and SOX compliance requirements that most teams don't have to worry about. For those reasons, the extent to which this standard is used within Google is beyond my predictive powers. * Vendoring without import path rewriting: Absolutely. We (those who have been working on the vendor-spec) have been very careful to allow for both approaches - vendor-path-rewriting vs gopath-manipulation. We realize that it will not be possible to get the entire Go community to choose just one path. 
What a crappy article(s). Can someone explain where it he got the numbers that FP aficionados are the majority complaining about Go? Because if it is just speculation, I don't see why FP and not OOP. The major complains about Go are lack of generics and exceptions, jargon from OOP world. So I would say about Java/C#/C++ people... It seems to me that he doesn't know shit of what he is talking about. Even all the "facts" that he give of Haskell (the others I cannot say) are wrong. He should learn first before going on a ramble. It just transcribes as ignorant.
Even using interfaces as a method to prevent from binding to a specific storage technology, I have found it very difficult to architect an application that is flexible enough to allow swapping out of storage mechanisms at will. Moving between two RDMS, or moving between two KV stores is pretty simple, but architecting in a way that would allow you to move between, say, MySQL and DynamoDB has proven to be quite difficult. I would be extremely interested in seeing any examples of storage layer abstractions that provide enough flexibility to allow for my latter example.
@duncanfoo yes, gb-vendor is used. However I made the note that it's up to the user how to handle. This example is somehow opinionated. It tries to get the it right how an open source project should be written and layout in `gb`. I'm not trying to reflect my own opinion btw, this will and SHOULD shaped by the community itself (dave, contributor, etc..) 
It also assumes that you can't just get a static binary of the Go 1.5 compiler to build with :)
Except in C you can ignore a return implicitly, just like you can ignore an exception implicitly. In go it is a compiler error to ignore a multiple return so you can't really ignore the error if you want to use the returned value. Both the ignoring an error from the return and not knowing what exceptions can be thrown has burnt me in the past so I truly hate them.
Seems more or less the same as ngrok?
I like what `gb` is doing, but I just dislike the aesthetics of having to move my code from the root of the repository (where it's easy to `go get` if people want to do that) to `src/github.com/joeshaw/mythingy`. It feels too much like Java's `java/com/github/joeshaw/mythingy`. Am I being unreasonable about that? Seems like two ways to deal with that are a symlink back to the root of the repository, or have a separate `mythingy-gb` repository that uses something like git subtrees to include my source. With the separate repository, on one hand I like the idea of separating the code of the project itself from the code of its dependencies. On the other hand, the reality is that I would need to update two repositories often anyway, and the likelihood of failing to update one or the other is quite high.
If you've got a really large app, you probably will end up at least somewhat bound to a storage app, even if only accidentally. If you've got a smaller app, the key is for the interface to be expressed as semantically as possible... supposed you want to "create a user", which involves taking in 10 bits of data and doing a series of things in various DB tables. You don't create a method for each thing you're doing in the DB; you put in your interface a CreateUser(...) call. The more successfully you can do that, the easier it is to migrate later. Yes, you can end up with 50-100 things like that. If you want, you can split the interface into related bits and compose them as needed, but that's more so the godoc looks nice... Go won't be confused by the large interface. On the one hand, you might feel in the end like you're writing a lot of redundant code... on the other, especially for SQL databases, you're likely to find yourself doing more advanced usages of SQL more casually than almost any ORM would ever let you do, so, I actually find in favor of this approach. In any real database the SQL queries may _superficially_ look very similar to each other, but in practice there's less redundancy there than it appears. (I think SQL is just a bad syntax from the 70s and a lot of the visual redundancy is simply SQL redundancy.) The reason big applications tend to still end up bound is that no matter how hard you try, some of the semantics of your first storage layer will still leak in.
[Image](http://imgs.xkcd.com/comics/haskell.png) **Title:** Haskell **Title-text:** The problem with Haskell is that it's a language built on lazy evaluation and nobody's actually called for it. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1312#Explanation) **Stats:** This comic has been referenced 43 times, representing 0.0659% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_crntbcv)
Very nice fatih! ngrok 2.0 actually uses the same approach multiplexing approach via muxado (https://github.com/inconshreveable/muxado/tree/wip) Of course, there's no Go API and 2.0 isn't open source yet. Very cool!
A golang talk happened this morning at the Lenoir, NC extended Google I/O.
&gt; The author's point of citing that Haskell and Common Lisp lack 21st century concessions like HTTP proxies It looks to me like the last commit to [http-release-proxy](https://github.com/fpco/http-reverse-proxy) was 9 days ago. There's also an example: {-# LANGUAGE OverloadedStrings #-} import Network.HTTP.ReverseProxy import Data.Conduit.Network main :: IO () main = runTCPServer (serverSettings 3000 "*") $ \appData -&gt; rawProxyTo (\_headers -&gt; return $ Right $ ProxyDest "www.example.com" 80) appData and that entire library consists of a single file, which is fairly short (around ~250 lines of actual code, minus all the comments, imports, etc.). Does such a trivial project *really* need commits at more than a 6 month interval?
Yep.
It's already taking off (adopted by Dropbox, Facebook, Netflix, Canonical, Mozilla, and thousands of start-ups and smaller companies you've never heard of, including the one where I work). It's emerging as the leading language in the current generation of cloud infra (Docker, etcd, consul, Kubernetes, Vitess, etc). I find it hard to see what can curb this growth and adoption in a significant way. Looks like Go found its niche, and this niche is exploding at the moment. Maybe I have some sort of confirmation bias because I'm part of this community, but over the 2.5 years I've been working with Go, it has turned from a hipster language to a force to be reckoned with.
Is it really 2-3x slower for the general case?
Considering that Go saves Google money I'd say that Go makes money for Google so maybe that's why the complaint is shut down all over the place?
Is go a programming language? Does it know what HTTP is? Then you can use it as the backend of a website.
Scroll to the bottom: http://caddyserver.com/docs/faq
Hoping the next step for xkcd_transciber will be automatically detecting and linking relevant XKCD's.
Will it make any difference in benchmarks, if GOMAXPROCS is set to "number of CPUs available" - 1? I've read somewhere, that we should give one CPU core to the OS context switches, etc. Can anyone test? Thanks in advance!
/u/jbuberel, many Go users have waited for years for a "official" solution to dependency management (their words, not mine). Does this mean they will have to wait til at least March next year for an answer ?
I could see it making a difference and that makes sense for applications in use but benchmarking is supposed to be done on an otherwise unutilized machine to minimize effects like this.
Didn't we reach "1.5 feature freeze" a long time ago? 
&gt; Except in C you can ignore a return implicitly, just like you can ignore an exception implicitly Yes, C gets this wrong as well. &gt; In go it is a compiler error to ignore a multiple return No it's not. x, err := doThing1() y, err := doThing2(x) This will compile correctly, and has undefined behaviour. At best, you'll get a NullPointer immediately. At worst, a null could propagate into your application state and raise its head somewhere completely unrelated, being extremely difficult to track down. Many other languages that use return values for error handling instead return a union type. `Success(value)` or `Failure(reason)`. The compiler then ensures you've handled both cases. You can also use a bind() function to hide the error handling plumbing under the hood if you don't want to be explicit on every single line. &gt; Both the ignoring an error from the return and not knowing what exceptions can be thrown has burnt me in the past so I truly hate them. One of these will fail safely. The other will fail with undefined behaviour. 
&gt; I've read somewhere, that we should give one CPU core to the OS context switches, etc. Not sure what you mean here. The OS scheduler is going to constantly be switching contexts on all of the cores regardless.
You're going to get 12 different replies from 10 different people because the use case is extremely common - nearly anything will satisfy. I could easily recommend something as simple as SQLite based on those requirements, because I don't know what you're trying to use this for, what you're connecting with, how much you're writing, what the read vs. write access pattern will be, how long the data needs to be retained, etc.
You haven't ignored the error, you are choosing not to check it. That is a big difference, if you try to write the code with no reference to the error you will get the compiler error. I don't know what you are getting at but blowing up a stack is never safe.
No, don't do this. Even when compiling, you should always use the # of CPU Cores in order to fully utilize them all.
I don't have hard numbers... but GopherCon.com blog.gopheracademy.com www.gopheracademy.com and 3 other smaller sites are all served on a tiny VPS. The only time the load on the machine goes above 1% is when Caddy is doing a git pull and hugo re-build of each of the sites. Performance is awesome.
&gt; You haven't ignored the error, you are choosing not to check it. Or you were in a rush at 5pm on a Friday and missed a case. It's far, far too easy to accidentally let an error case slip through unless you're extremely vigilant. The point is that Go style error handling can be done in a way that doesn't let that happen by mistake, but Go doesn't do it. &gt; I don't know what you are getting at but blowing up a stack is never safe. What does any of this have to do with blowing up the stack?
But all the hipsters have moved onto "The next big thing", desperately trying to convince everyone they meet that this new toy is the bestest thing ever, and that we should use that instead. Some of those languages remain somewhat successful because they found a niche. But they are no longer "Cool", others rapidly lost adoption the instant something else came along. The point is that Lisp, ML, etc remained strong throughout that entire time. To dismiss them because the author didn't find one specific obscure piece of functionality in their standard libraries after 5 minutes of googling is to ignore the fact that they have survived where countless others have come and gone over the decades, often reinventing the same wheel pioneered decades before. When a language family is still relevant and going strong after 57 years, it must be doing something right, and to so casually dismiss Lisp shows a complete disregard for reality. Chances are, Lisp will still be around in another 50 years, well after most of the other languages on that list are forgotten. To be clear I'm not really a fan of Lisp so aren't defending out of any fanboyism, but I'd have a hard time finding any real criticism of any modern dialect other than perhaps not liking S-expression syntax. 
Hey folks, I wanted to share with you a plugin I made for Atlassian Bamboo. This plugin has a set of tasks for building and testing Go projects, including automatic dependency fetching via Godep. Test results integrate with native Bamboo test reporting. Please take a look and provide comments! Source is available on [GitHub](https://github.com/handcraftedbits/go-bamboo-plugin). Please feel free to open issues for any missing features. The top item on my list is supporting go test -cover output with Bamboo's native code coverage functionality.
Just added a followup with more details.
Not /u/rsc, but [The Go FAQ](http://golang.org/doc/faq) answers a lot of questions on why does Go lacks this or that feature, including generics, exceptions, assertions, etc.
Important background reading, also by Russ Cox [The Generic Dilemma](http://research.swtch.com/generic)
Very nice summary, thanks! One nit: http://rogpeppe.neocities.org/error-loving-talk/index.html#29 &gt;Similer to fmt.Errorf "Simil**a**r"?
It was all about android and the google app. Couldn't help myself from taking a nap.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**The Practice of Programming**](https://en.wikipedia.org/wiki/The%20Practice%20of%20Programming): [](#sfw) --- &gt; &gt;___The Practice of Programming___ ([ISBN 0-201-61586-X](https://en.wikipedia.org/wiki/Special:BookSources/020161586X)) by [Brian W. Kernighan](https://en.wikipedia.org/wiki/Brian_W._Kernighan) and [Rob Pike](https://en.wikipedia.org/wiki/Rob_Pike) is a 1999 book about [computer programming](https://en.wikipedia.org/wiki/Computer_programming) and [software engineering](https://en.wikipedia.org/wiki/Software_engineering), published by [Addison-Wesley](https://en.wikipedia.org/wiki/Addison-Wesley). &gt;According to the preface, the book is about "topics like testing, [debugging](https://en.wikipedia.org/wiki/Debugging), [portability](https://en.wikipedia.org/wiki/Porting), performance, design alternatives, and style," which, according to the authors, "are not usually the focus of computer science or programming courses". It treats these topics in case studies, featuring implementations in several [programming languages](https://en.wikipedia.org/wiki/Programming_language) (mostly [C](https://en.wikipedia.org/wiki/C_(programming_language\)), but also [C++](https://en.wikipedia.org/wiki/C%2B%2B), [AWK](https://en.wikipedia.org/wiki/AWK_(programming_language\)), [Perl](https://en.wikipedia.org/wiki/Perl), [Tcl](https://en.wikipedia.org/wiki/Tcl) and [Java](https://en.wikipedia.org/wiki/Java_(programming_language\))). &gt;*The Practice of Programming* has been translated into twelve languages. &gt; --- ^Interesting: [^Financial ^engineering](https://en.wikipedia.org/wiki/Financial_engineering) ^| [^Rob ^Pike](https://en.wikipedia.org/wiki/Rob_Pike) ^| [^Computer ^programming](https://en.wikipedia.org/wiki/Computer_programming) ^| [^Brian ^Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+crokwhq) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+crokwhq)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Would it? The slides with error checking were before that one. It was the exact same code example but with error checking. That slide, at least for my interpretation, is basically saying since we are not checking for errors then it means that there are no errors.
&gt; Conventionally in Go code, all errors are checked. Code won't pass code review if it's not checking its errors Well... that is true for all languages. Be it error values or exceptions. &gt; but the convention is strong enough that in practice you get the readability benefits I talk about. Fair point. If the "talk" was aimed at the convention and how to enforce the convention, it makes sense. Just beware that errcheck will not catch all use cases.
&gt; spend such a large amount of time literally mocking those who leverage generics in other languages and want to use it in Golang I don't think this is a fair characterization, and I challenge you to cite such an incident. There are two scenarios in which I can see the generics question could be met with derision: 1. when it is raised as an our-of-context non-sequitur (such as the linked HN thread) which happens so often that it's frankly ridiculous, and 2. in the cases where the questioner uses a tone of "You guys are ignorant morons, why don't you just implement generics!" Such people rarely want to actually hear the answer.
I'd be wary of comparing Go to English, since the latter won its dominance through cultural imperialism*, not any sort of pragmatic benefits :p. *Not a sociologist, but I think that's not too far off the truth.
The data is so small you could store it in memory and occasionally write out to a JSON file. You said you have about 65 bytes -- allowing some overhead, maybe we'll have 300 bytes total per sample. 8640/day * ~300 bytes * 1 year = ~1GB /year That's not much, and you can query by anything you want.
Why not use a global map hidden in the inject package? What's the use of inject.New()? You want something global, but you initialize a new instance. Does that mean that some data is instantiated and some are shard globally? That seems quite complicated.
How does rust fit into his 3 categories.
Rather than playing the man and not the ball, why don't you respond to /u/enneff 's question ?
This guy has some serious problems. This is not the first time he has commented extremely angrily in a relatively benign conversation. Check out his comment history.
You could denormalize to id, timestamp, from_server, doc_id, key, value. Indexes on (key, timestamp) and (timestamp). doc_id used to group k-v pairs from the same log event together.
That's exactly what I was thinking, I just didn't use the right terminology :) So, I'm eliminating these possibilities: * postgress (sqlite should be fine -- and easier) * cassandra -- couldn't get it working on OS X for my PoC I'm going to try all of these, and see how they work: * Sqlite3 * couchbase * influxdb I'll post a github link when I've got something useful.
Good luck! I've messed with couchbase at work before. Performance is phenomenal, but the hardware requirements are astronomically higher than sqlite - they are almost diametrically opposed in what they provide. I wouldn't bother with it unless you need that much scalability (or maybe you just want to mess with it for kicks, which I totally understand :) You may also want to take a look at rethinkdb. Haven't used it yet myself, but its design and interface are interesting. Hardware reqs are also a lot lower than couchbase.
&gt; Personally I don't have the knowledge in compilers/language theory to do it. Part of the problem is that it really is a "devil in the details" sort of problem. At a high level it looks easy, you "just" do something. But you start getting into the details, and the pretty model just comes apart at the seams. It is also really amenable to a common argumentation model where someone has this vague, fuzzy idea of how something can be done, and whenever you raise an objection the person just waves away that particular problem, perhaps even rationally because the problem alone is easy to solve. But the totality of the situation is still quite hard, harder than the consideration of any individual problem would demonstrate. If you properly try to construct a _concrete_ model that can actually be attacked and defended, and does not permit this sort of dancing, it turns out to be very difficult. I'm still not convinced it's impossible. I've fiddled around myself. I haven't come up with a perfect answer but I think there's something in the fact that interfaces are already half of generics, and the Go generic answer strikes me as something that extends them the rest of the way, rather than sitting to the side. (Generics _interacting_ with interfaces is probably impossible, but interfaces _extending into_ generics might yet be possible.) But I've put, oh, three or four hours here and there into the idea, and it's still got problems, especially around various-sized ints being passed in, which is, alas, one of the core use cases.... (I haven't taken the time to analyze whether changing the calling convention to accommodate generics might be possible.)
In case of Java, a proper IDE analyses Javadoc associated to the method (i.e. the @exception section) and shows to the user when looking to the method as a tooltip or on another panel (it varies per IDE and how it's configured). I don't use Java so I can't say for sure. But I would bet that eclipse or IntelliJ has such feature. It's like a basic requirement.
You should check out the golang-nuts mailing list, particularly the posts of Go team member Ian Lance Taylor. He and others have already written volumes on the subject of generics and Go, so you should excuse rsc for not dissecting all the issues in his HN post.
Analogy time: Slices: I hand you a drill and say "You can use this to make holes in any of these specific types of material." Maps: I hand you a hammer and say "You can use this to put any kind of nail into any of these specific types of material." Generics: I hand you a black box and say "You can configure this box to do anything to anything." Can you see how the third is a totally different class of problem? The former two are very easy to specify and implement, while the latter adds another dimension to the problem which increases complexity geometrically. &gt; I really suspect, once again that the go team did something that doesn't allow them to had generics later ,because it would mean refactoring a good part of the compiler codebase. We just totally rewrote the GC, translated the runtime from C to Go by hand, machine translated the entire compiler from C to Go and are about to undertake a massive refactoring effort to make the compiler code base more idiomatic. We're not afraid of a bit of hard work. In any case, you needn't rely on your suspicions. This discussion has already happened at length on the golang-nuts mailing list. You can read deeply about the technical issues there.
Because maps, arrays, and slices actually dodge some of the core problems. All of them still have a fixed-size representation regardless of what you put in them (in array's case, that fixed size is 0, but that counts). Go would like type GenericPair struct { first &lt;A&gt; second &lt;B&gt; } to be two bytes if A and B are `byte`, and bigger if &lt;A&gt; and &lt;B&gt; are bigger, but not to simply box A and B unconditionally. Since generics aren't in the languages, you don't have any issues with higher-order generics in maps or arrays. (The ones we can do still compose pleasantly enough.) The specialization of these three cases simplifies the problem significantly... it gets crazier if you actually want: type SameTypedPair struct { first &lt;A&gt; second &lt;A&gt; } and _that_ syntax is grossly inadequate because within seconds of making this legal, _somebody_ will define type ListWithSpecialElement struct { special &lt;A&gt; list []&lt;A&gt; } and before you know it, someone wants ListWithSpecialElement&lt;map[&lt;A&gt;]&lt;B&gt;&gt; or something and it's all crazy under the hood. And this is still simple, go check out the STL for how _this_ goes. type SortablePairList &lt;A, B&gt; interface { SortFunc&lt;A, B&gt;() func (la &lt;A&gt;, ra &lt;A&gt;, lb &lt;B&gt;, rb &lt;B&gt;) int } Implementing that raises even more fun issues with code generation. Before replying with the simple, obvious answers to all of these problems, bear in mind that A: this isn't necessarily anywhere near all of them and B: reread my second paragraph above. It isn't enough to solve everything in isolation, you have to solve everything simultaneously.
No, it shouldn't excuse rsc. When you make a public statement in our area with bland statements without any technical substance it is merit of heavy criticism. More so, in HN, that isn't focused in Go ecosystem, he shouldn't expect that people are aware of the discussions on golang-nuts mailing list. Now, what you mention seems very interesting. I searched for his name + generics, but what I find is most people in how to use language or comparing to other languages like rust :| The noise ratio is very high to get any useful information. Do you know exactly what is the thread that he talks about the effort on tackling generics and the issues that he faced? That would be great.
So... The whole slew of features that are coming to 1.5 are... snowflakes? In this particular case, generics, it should be immediately obvious that the reflect package would need some changes in order to work post new feature, no? As for the language itself, I haven't seen yet a language that's so young and small but still enables people to learn it fast, have good performance out of the box. Oh that I can read fast and have excellent tooling around it. Perhaps it's annoying that some features from x y z language are not present in Go but once one stops thinking in x y z and focuses on the problem and the solution the coding part comes much more natural that in other languages. Perhaps it's a good thing that the Go team is so strict about new things and that Go is an 'engineering' approach to the 'which language should I use?' and not a cool hipster language that's jack of all trades and master of none.
The Go standard library is a good place to look.
It's an incredibly subjective term. Can't really be proven or disproven. 
Well, then... I'm embarrassed now. I'll see myself out.
Ok so there is a whole lot of discussion on how to correctly deal with dependencies. The way go natively deals with it is to directly check out imports by the path given in the import. It is a domain address.
&gt; I'm not sure why (maybe brainwashing), but to me, something doesn't sit right with hardcoding dependancy repositories directly in the source code... There are two Go topics that have been discussed to death - generics and dependency management. Just Google it I'm sure you'll find plenty of discussions about the rationale.
the problem isn't so much these URLs, but the way packages are fetched when you use "go get" command line. It doesn't matter if a package is called "foo" or "example.com/foo" , you cannot target a specific version of "example.com/foo" with go get and force foo dependencies to be a specific version. The go team didn't clearly think about the consequences of these choices when they created the go tools, a pattern that is seen often in go ecosystem. Now the argument is "go get" isn't a package manager then what is it ? it certainly does fetch dependencies which is half the job of a package manager. the second argument is "it works at google", which is a bit scary because it means the community needs are not a priority , if it works for google it's good enough. A third argument is "well fix it in userland", which means people using incompatible package managers that don't work with go get at first place. Finally the vendoring argument : but vendoring isn't package version management. I like go, but I'm now heavily questioning my investment in the language, due to some kind of denial coming from the go team and also some part of the go community that defends these choices to death. Instead of coming clean and saying this or that choice was a mistake because it doesn't scale, it's spun as a kind of "philosophy". The right attitude now is caution , and just look at how the language an its tools evolve up til v2 .
And thats what i like! I do not want a package manager to do some magic. Actually i do not want to have a package manager at all! Go get does all i want - if there is some version mismatch, good, i have to sort it out. I dont want to have some version issues pop up later in production.
Goroutines are a feature of the Go runtime. The Go runtime is (was?) written in Go, C, and asm. This gives a good explanation of the runtime that I think will answer your question: http://www.quora.com/How-does-the-Go-runtime-work
Okay, where is the source for the goroutine scheduler or the go statement? I think I would understand a bit more if I see how the code works.
&gt; Sure, if the developer remembered or bothered to put the @exception documentation in. And that assumes they even know if their function can throw... which means knowing if any function they call can throw, and any function those functions calls... it's a nightmare. Sure, it's a nightmare. But if you have a lib that is not properly documented, as I said before, the exceptions will be your last concern. Sure no exceptions is better, but if you are reviewing the code (that was the original point) the lack/wrong documentation will make it significant harder (with or without exceptions). You seem to be misreading my comments. I'm not saying that exceptions are good, or that are safe. Just when reviewing code, with proper documentation and IDE they are shown when looking to the method signature. Take notice, that I'm not saying that reviewing code is easier with exceptions, it's actually the opposite since it hides cyclomatic complexity. &gt; When I was working full time in C#, unhandled exceptions were the number one bug in production. In fact, almost all non-trivial bugs were unhandled exceptions. Really? I work fulltime in C# and have no such experience. Sure there are unhandled exceptions, but that is the symptom of a bug not the bug itself. If I try to access an index outside of an array. Is it bug that I didn't catch IndexOutOfRangeException? No. The same with NullPointerException, ArgumentException, etc... Actually it's much worst in production in presence of a bug to not trigger an unhandled exception and just go unnoticed. 
No, they are not exported by the `runtime` package.
You probably mean "in the standard library", because the language specification is this document: https://golang.org/ref/spec It does not talk about the packages and functions of the standard library. The lowest level of functions are system calls. They are calls to the operating system kernel. The system calls needed by Go are exported in the syscall package: http://golang.org/pkg/syscall/ However, most of the runtime functions are not exported, only a few: https://golang.org/pkg/runtime/ 
Thank you again. I didn't know about system calls, and the syscall package. So, Go uses syscall for low-level functions, and they seem to be written in Assembly and Go. And this is why there is no need for C anymore.
Well, actually to be good at something cannot be described as a defect, IMHO. :) Indeed, I can confirm is very very good for personal projects: I am running one, and it is **fun**. It makes funny to program, and: very very often you get at a point you planned 1-2 hours to code, and you finish in 15 minutes, or so. This is because you discover some "surprise" like some library function which is doing exactly what you have in mind. So yes, I totally agreee, it is a language for personal projects. About the point "personal is not enterprise", I **don't** agree for several reasons. 1. Just for an example: Linux kernel was a personal project. having a personal tool means you can write a prototype quickly. After you show the prototype, if your idea is good, then you have the others joining and making your chance to become the next enterprise. How many good ideas we lost just because the guy which had the idea had not enough time to develop a prototype? 2. All developers team I have seen are made of individuals. (Maybe I should work in a Borg cube to see non-individuals :) :) ?). Jokin apart, golang itself has a nice structure in packages, which are then structured in files as like you want. So to break a task in pieces is very easy, under the point of view of agile/scrum. And it comes with native methods to include git code, which is a **cooperative** tool. So it makes fun for developers **AND** is ready for [git , svn and others](http://golang.org/cmd/go/#hdr-Import_path_syntax), since the beginning. About point 2, of course some bad "project manager" could fail in distributing tasks. Of course some bad "software architect" can fail to structure the source code. But, in the other languages when you have _bad project management_ and _bad software architects_, you fail as well. Where _fail_ means your product will never be successful: because it is slow, buggy , high time to market, and so on. I think there are no programming languages which can get rid of human incompetence: no language ever. I don't think being so good for personal projects will **stop or prevent** golang to be a corporate language. Maybe it should have more libraries for corporate infrastructures, a bit more focused to integrate with Confluence/Microsoft Active Directory/Exchange or whatever. But here you go into a patent infringement chapter, and I can understand google will be very conservative about it. 
s/not/now/ I think you mean
https://github.com/drone/drone/tree/master/server
Keep in mind that this should all become unnecessary with 1.5 - see this slide from Andrew Gerrand's talk at the GoSF GopherFest last week: http://talks.golang.org/2015/state-of-go-may.slide#13 It won't give you the same runtime isolation as pie, but the performance should be better.
&gt; Couldn't this sort of thing be built into the compiler, mainly to stop all the whining about generics? I think you severely underestimate the amount of whining (especially from non-gophers) about generics that will still happen about something like this being included into the toolchain. I don't see any kind of "full generics" being included in Go in the foreseeable future because of all the design issues that have been discussed. I was looking at `gen` because I wanted something that was compatible with standard Go, and had minimal impact on the build process. It seems like code generation is the way to do it for now, to ensure compile-time type safety. Ideally, there would be a way for `go build` to detect a change in type-writer (the generic class) and run `gen` automatically. I need to play around with `gen` more, but just having a decent solution for various kinds of simple containers is a boon at this point.
It's nothing to do with Github, it is a means of fetching dependencies from a URL. For instance, you can also find go repositories in bitbucket.
here is my version: https://github.com/dim13/captcha if you have searched first, you didn't need to write it yourself ;)
Nothing comes for free ;-) Russ Cox recently wrote this post to HN that might address your question: https://news.ycombinator.com/item?id=9622417
&gt; The point is that Go style error handling can be done in a way that doesn't let that happen by mistake, but Go doesn't do it. Like how?
That's a really depressing list.
Most types will not actually do anything if there is a queued error, making checking once at the end the same as checking after every operation.
There is a blog post which describes in detail how to use GoQuery to crawl posts from reddit and stores it into a database. http://intogooglego.blogspot.co.at/2015/05/day-7-goquery-html-parsing.html
It's somewhat skewed, but if nothing else the list implies most projects these days are web based.
Since I didn't find it in the thread, I guess I'll just put this here :) When a Go app crashes, the stack traces are written to ~~STDOUT~~ STDERR. That being said, there are 2 ways I know of to capture get that into a file: 1. If you're running on Linux / OSX, you can just redirect STDERR to a file: func RedirectStdErrToFile(filename string) error { // Open the file you want to log to, so you can get a file descriptor errorlogFile, _ := os.OpenFile(filename, os.O_WRONLY|os.O_CREATE|os.O_SYNC, 0644) // Duplicate your file descriptor, replacing os.Stderr return syscall.Dup2(int(errorlogFile.Fd()), int(os.Stderr.Fd())) } 2. If you are running Windows, you would need another executable that runs your server and restarts it whenever it crashes. That allows you to also capture STDERR of your server. An example for STDOUT can be found [here](https://gobyexample.com/spawning-processes). Just replace StdOutPipe() with StdErrPipe(). EDIT: Stack traces are written to STDERR, not STDOUT.
Yep - good point. The 1.5 release will allow you to generate a .dll/.so that could be called from C. I'm assuming it also means you can invoke it from other languages that support calling into native/compiled libraries (Python, Java). But I should probably verify that :-)
thanks this is totally helpful as i get this code finished.
Go's I/O framework is pretty good, no doubt about it. I just find it funny how people are praising Go's I/O framework, as if it was something new or completely different. Same ideas can be found e.g. in java.io package from 20 years ago, and even back then it wasn't anything new, just an application of [decorator pattern](http://en.wikipedia.org/wiki/Decorator_pattern) io.Pipe() has its uses, but using it just to avoid allocating buffers? I don't think it's one of them.
The other commenters below mentioning the documentation are incorrect. ** IT IS COMPILER ENFORCED ** In java, you have the following: public void foo() throws SomeException { throw new SomeException(); } You cannot throw an exception if you have not added the "throws" for that exception, or a direct parent of it, to your function. This is compiler enforced. Similarly, I cannot now call "foo()" unless I either try/catch the error, or the function I'm writing also explicitly says it can throw that exception. This forces you to think about the exception, whether you want to handle it or throw it, and actually enforces it. In the case of Go, you say above "pass the buck" completely unironically when "if err != nil { return err }" in go is *exactly the same thing*, just more verbose and requires the programmer to not screw up !=/== and actually think about it or run a third party tool. In java it is always clear what will throw an exception and what kind of exceptions it can throw, it's clear if your function re-throws it (implicitly or explicitly) or handles it, and more, all based on the compiler enforced 'throws' statement. In Go, you don't get most of that. You can't tell what types of errors a function returns as an 'error' unless the documentation lists it correctly. You can't tell if a function has ignored the error by accident without running a third party tool. You can't create hierarchies of errors that are nearly as robust (though your library means to do some of that).
You'll get burned using `io.Pipe` like that. There's non-trivial synchronization overhead. (See: [three mutexes](https://golang.org/src/io/pipe.go).) An allocation is still cheaper than 3+ locks, launching a goroutine, and executing a closure. (Don't forget that your closure arguments may escape to the heap as well!)
As you wish. ;) Committed.
I don't understand. Almost any modern language does this. 
I spend most of my days not working in a modern language.
Not to mention, if buffer allocation is a problem, you can allocate from a pool. The http package uses sync.Pool to manage buffers internally. 
I'm less concerned about calling Go dlls from other languages, and more concerned about allowing others to write plugins that work with a Go application. I'm not sure that you can call Go dlls from other languages, since Go needs the runtime for things like goroutines, and to have garbage collection, etc... at least that used to be a reason why Go wasn't able to be used from other languages, I haven't looked into the details of what 1.5 might change for that. 
maybe you're on windows? on *nix, an unquoted semicolon indicates the end of a command rather than an argument.
In practice (in my experience), what ends up happening is that most functions end up with "throws MyBaseApplicationException" where MyBaseApplicationException is the base exception for every custom exception in your entire application, because otherwise every time someone changes a function 6 levels deep, you have to add a new exception to the list of everything above it... and then you can break people's code that you don't even know are calling your function. So, sure, you're right, you know it can throw... but just like in Go, you can't tell what the actual list of possible errors is. I'll grant you that Java has the ability to enforce a list of errors that a function can produce.... but in practice it's very rarely used in full applications because it's such a maintenance burden. While if err != nil { return err } may be passing the buck, it's at least *visibly* passing the buck. Looking at the code, I can immediately tell that the function might exit at this line. Compared to using exceptions, where you can't know where the function will exit unless you read the signature of every function called. This was a revelation to me when first writing Go code. I could write this code: DoX() DoY() DoZ() and I could know, without a doubt, that I'd always call all three functions. I didn't have to worry that one might not get called because of an exception from one of the first two. Now, sure, maybe that code might often look like this: if err := DoX(); err != nil { return err } if err := DoY(); err != nil { return err } return DoZ() ... but even then, I *know* that the later functions might not get called. In the equivalent java code, I don't know, unless I go look and see if DoX and DoY can throw. Sure, in the IDE, you can get a hover over that'll tell you. But that doesn't help when you're looking at your code on github, or when you're looking at a diff from git, or 1000 other places where you're reading code and *not* in an IDE.
Something interesting that's been proposed for Rust is to have explicit error propagation using `?`, so instead of `try { foo(); bar(); baz(); } catch { ... }` you'd have `try { foo(); bar()?; baz(); } catch { ... }`. This way, you always know which parts of the try block could potentially give rise to an error. Obviously, this approach couldn't really be directly translated to Go (it relies on variant return types to return a result or an error, and fits better with Rust's approach to syntax sugar than Go's skepticism of superfluous syntactic constructs), but I thought it would be relevant insofar as it fits in the spectrum of explicit and implicit error handling, particularly around compound try blocks.
&gt; ...people are praising Go's I/O framework, as if it was something new or completely different. Did you observe that recently?
Beyond the fact that using goroutines and io.Pipe is more expensive and needlessly complicated, making your example more efficient is actually quite simple. Firstly, the json Encoder and Decoder types are meant for streams of json objects, not individual items. You'll find no performance benefit using them in this context over just using json.Marshal. (the package does its own internal buffering like a bytes.Buffer). Writing from an encoder to a bytes.Buffer just makes an extra copy of the marshaled object. I'd recommend simply using json.Marshal, then wrapping the resulting []byte with a bytes.Reader.
Yes. But that is not the issue. The issue is that you are not forced to check the error. If you forgot to check at the end, the code is still considered perfect valid. And the error goes unnoticed...
I mostly wrote up this because I couldn't find any smaller examples of using io.Pipe(). The reason I didn't use Marshal in the first example was because I wanted to keep the code diff as small as possible. You're absolutely right that streaming is the use case here, there is just only so much of it you can do in a small example like this.
I have a three leveled slice: SectionSlice []*Section Section struct { ID string Label string `json:",omitempty"` ... more fields Groups GroupSlice } GroupSlice []*Group Group struct { ID string ... more fields Fields FieldSlice } FieldSlice []*Field Field struct { ID string ... more fields Default interface{} `json:",omitempty"` } SectionSlice is the root of these slices/structs. On SectionSlice there is a function receiver ToJson() string. The final SectionSlice is in production minimum 15.000 lines long. I've changed the ToJson() function to all three versions discussed here: This is the benchmark: var bsstj string // BenchmarkSectionSliceToJson 300 5826655 ns/op 1378568 B/op 17275 allocs/op &lt;-- encoding/json NewEncoder io.Pipe with io.ReadAll // BenchmarkSectionSliceToJson 300 5582783 ns/op 992781 B/op 17255 allocs/op &lt;-- encoding/json NewEncoder with buffer // BenchmarkSectionSliceToJson 300 5613962 ns/op 1134998 B/op 17258 allocs/op &lt;-- encondig/json.Marshal func BenchmarkSectionSliceToJson(b *testing.B) { b.ReportAllocs() for i := 0; i &lt; b.N; i++ { if bsstj = packageAllConfiguration.ToJson(); bsstj == "" { b.Error("JSON is empty!") } } } 
thanks go-bootstrap is quite helpful!
Nice! I would also be interested in seeing the difference in peak memory usage (especially when doing this concurrently) as that should be the use case for io.Pipe().
Awesome, thanks! :) Edit: what if they introduce another error? Your map lookup will return `nil`.
FIY, for both /u/dim13 and /u/haisum, `RemoteAddr` is usually IP:Port, not just IP. And with nginx or other proxies in front of Go, it will be the IP of this proxy, not the user. reCAPTCHA's API says `remoteip` is optional, so IMHO it's better not to send it at all.
I searched! Every module had outdated api call, so had to make myself. Google now recommends sending post request to "https://www.google.com/recaptcha/api/siteverify" with post variables secret, remoteip and response. All other packages send requests to "https://www.google.com/recaptcha/api" 
To be honest, I didn't know until your post, that there is a new API. So, thank you too! :) Not sure, when 2.0 was introduced, but a year ago (as I wrote my package), 1.0 was the only way. UPD: it may be outdated, but since its wide usage, the old API will IMHO persist for long-long time. UPD2: crosslinked in my readme to your version as for 2.0 version. No need to implement it twice. :)
s/linux/unix/g
Down-voting warrants a comment. C'mon, help a gopher out.
/.*n[iu]x$/
I'm not trying to be a troll, but out of curiosity, if you're on Windows what non-modern language are you working in? If you say C++, I'd ask if you didn't actually mean Visual-C++ which is not quite the same.
If something is fun, that doesn't make it funny. Common ESL mistake. :) :) :)
Sqlite3.
Marketing is the soul of... programming?! 
At least the release announcement uses the term "Go" instead of "GoLang" as on the [project's GitHub page](https://github.com/spf13/hugo). 
Fair argument. I will have that in mind on the next crossroad.
Thanks a lot. Loving learning new things. :)
Awesome work and I'm even mentioned :-)
Is your code not exactly accurate or is pageBlock supposed to be the entire 1 gig file ? SectionReader should work with a *os.File. But otherwise cool tip, I wasn't aware of SectionReader before.
Data races will be encountered with stack.Context if anything interesting needs to happen. Considering `http.Handle("/", stack.New(mwOne, mwTwo).Then(handler))`, if the context is sent off in a goroutine within mwTwo after ServeHTTP is called (e.g. logging which should not delay the sending of the response to the client), potential data races with the post ServeHTTP code of mwOne will need to be resolved. The most immediate solution is to protect the context with a mutex. But, then lock contention comes into play (though, I think it much less an issue than that found in gorilla/context due to a global map's broad scope). net/context is a safer, cleaner, and more complete solution (https://blog.golang.org/context). Key handling, type assertions, deadlines/cancelation... It's worth reading about. Outside of the implementation of a context object - Another issue I had with stack is the function signatures. Please read the conclusion of the blog article above for why I felt most drawn to using net/context. Request-scoped data is an important need. Let's adopt Go Team prescribed solutions, whenever possible, so that we mitigate any fracturing of the community. Also, I wanted to be able to set an initial context. While I think it will be seldom used, the freedom relieved a sort of pressure for me. It just seemed appropriate.
Imagine you have type 'Result' with two possible values - Success(x) and Failure(err). That way you're forced to either blindly destructure the value (Which will panic instead if silently failing), use an `if` or case statement first (to provide explicit error handling, like Go), or use a bind operation to chain computations, like functional languages. I.e. (To use some Scala-ish code an example), you could: Blindly destructure: The `val Success(x)` means "Assign this to X if it's a success, otherwise panic" val Success(x) = doThing1(); val Success(y) = doThing2(2); return x + y; This code is similar to the previous `Go` example, but if one of these functions returns a failure then it'll panic instead of silently continuing with undefined behaviour. No extra burden on the programmer, but removes a common source of bugs. Use a case statement. val x = doThing1() match { case Success(x) =&gt; x case Failure(err) =&gt; panic(err); // Or (more usually), instead of panic'ing you'd provide an alternate code path } Use recover val x = doThing1() recover { case SomethingWentWrong(e) =&gt; alternateValue(); } Use an `if` statement val x = doThing(); if( ! x.isSuccess ) panic( ... ); Use a bind operation x &lt;- doThing(); y &lt;- doThing(x); yield x + y; This last example is the generally preferred way to handle it. In this case the resulting function will itself return a Success or Failure implicitly - the `&lt;-` operator in this example could be thought of as a macro that does the `if` check for you and returns an error immediately if that line fails. Effectively this gives you the same simplicity that Go "Error as a return value" does, however without undefined behaviour if you forget to handle a case, and the ability to keep the error handling plumbing below the fold if you want to. However because you now have an actual 'result' value you can manipulate instead of having to unwrap immediately, you can pass it around, defer checking it, and do all sorts of cool things like: Try the first operation, and if that fails try the second one. If that fails, the whole line fails. You can chain as many as you like. x &lt;- doThing() orElse doAnotherThing(); Run an operation directly on the 'Result' type without unwrapping it x &lt;- doThing() map (x =&gt; x * 2) Take a list of results and convert to a result of lists. customerIds = List(1,2,3); // This will take a list of ids and return something like [Success(customer1), Success(customer2), Success(customer3)] customers = for( id &lt;- customeIds ) yield fetchCustomerIfFound( id ); // This will take that value and convert it to Success([customer1, customer2, customer3]); // However if any of those lookups failed, then you'll instead get Failure(reason). yield traverse(customers) 
No problem. Please also see these benchmarks - http://pastie.org/10217315 And, I forgot to mention that Chain has a merge function to merge chains (thanks to a suggestion from /u/skelterjohn - iirc).
I said a few things about you myself. And that bastard down the street, too!
I tweeted at you but I liked what you did so I wrote Snake the same way, hope that is cool with you. https://github.com/adamturner92/gosnake
Actually is EFL mistake. I speak italian, french, german and English. Typical 'mirkin mistake ;)
This looks pretty good to me. It seems to combine the ease of use of alice with net/context. I'll need to find some time to sit down and play with it.
Yeah, the docs on this project are pretty solid.
Author here (of the post and part of Siesta). I can answer potential questions.
I'd ditch the iframe feature - my browser goes directly to the page half the time (but not all the time?) after it loads the iframe anyway. Users are capable of opening new tabs with the links they care about - you don't need to keep a superimposed navbar around for them. If that were gone, there'd be no need for a second (full-URL) clickable link below the title of each article - the article link would *be* the link, and users can copy the URL off of that if they desire. The tag cloud also isn't all that useful; especially since they aren't clickable - they only serve to cause a lot of visual confusion on each element, since they've got a lot of borders, text, and even images. Instead of listing each article's tags under the article, use a search feature to prompt the user for tags - like you might see in stack overflow. That's the only time users care about tags. The short description of each article is also useless, and seems to be taken from whatever the first line of the article is. This seems to give a lot of "golang: Go (golang) is a general purpose, higher-level, imperative programming language." and "Prerequisites Docker To follow this tutorial, you need a working installation of Docker on your computer. Golang Golang will be useful in this tutorial to test our web server" Those quotes aren't useful. If there's going to be a short description, make it useful to your target audience. Something like "Describes how to build containers as part of a Jenkins build step" or "High-level overview of Docker's purpose and usage". And having the comments box's border not line up with the content pane's border makes the site feel like it's not being shown as intended. Give it a `padding-top` to match the "stargazer vs drops" tab bar's height. EDIT: as a followup, i'd consider "plain english" CSS classnames bad form. For instance; "ui dividing header" is not one class, but three separate ones. You don't need those three, because the "ui" class is 1) not descriptive, because the whole page is a UI and 2) isn't used consistently between all the elements which have it (some are text, some are divs, some are images, etc). Give it a name like "dividingHeader"
Thank's for the great feedback! will go back and edit the descriptions. As for the iframe, i think the guys are still working on it and it will be much better. if it could pre-load the pages, i think it would be much easier than keeping tabs open.
Looks clean and simple enough. Examples perhaps can be more meaty. Something more practical, like composition of authorization, work processing, error handling/exiting half way.
Indeed. Unfortunately we (well, mainly I) just haven't had too much time to make better examples. The project is 8 months old and we *just* got around to this post. That did give us a lot of time to play around with some interesting patterns. Thanks for the ideas. My goal is to start a small series of blog posts that each show some interesting usage of Siesta.
Prefect - I love it!
Meh, I think something like this one day could appear in the toolchain. Gofmt is regularly touted as one of Go's best features and it is not actually a part of the language. There's also no reason to regenerate these every time you compile.
refresh the project and you should see it there.
I suspect that the file is being written, but not where you think. Compile and run this program. http://play.golang.org/p/C-N1zdJalN
By refresh the project do you mean clean and save? Because neither of those worked : /
file.Close() doesn't seem to be giving me an error when I step over it in debugging. Since I'm new to GDB I could be very incorrect though
&gt; i think it would be much easier than keeping tabs open. Please, no. Don't hijack the user's browser like this. Your audience is people who know something about Go and Docker. They all know how their browser's built-in functionality works and probably have their own workflows that work well for them. Iframe and JS trickery accomplish nothing positive and can *only* annoy them. Personally, if I hit a site where middle-clicking to open a link in a new tab doesn't work, or the back button breaks, etc, I just close that tab and make a mental note to never go back to that site.
It's easier to google "Golang" than "Go"
TLDR; use "git diff -w" to ignore space changes. I understand some people might not know that yet, but the post's pretty light on content.
Why would there be a whitespace change if both commits were gofmt'd before commit?
...why?
I doubt the person is using a go fmt on save or similar policy unfortunately. Though in languages that don't have go fmt or similar I push for (at work and in my own code) a policy of keeping those commits as two actions. `change type, commit, change whitespace, commit` much easier to manage and any modern vcs has minimal cost for additional commits.
In my personal experience, programmers new to Go who are experienced with traditional free form languages might only understand creating a diff while ignoring whitespace in an academic sense (because it's of fairly limited use for those languages). It almost makes sense to do diff with ignoring whitespace by default with Go, because so long as everyone uses gofmt, whitespace is of very little concern.
When the maximum length out of all of the identifiers in a struct changes, all of the types after those identifiers have their indentation level changed to match the new maximum length identifier. So if you change a single identifier (or add a new one, or delete an old one), the indentation of each type could potentially change.
Ah, that makes sense. Thanks for explaining.
Can anyone help me? When I run this driver I get the error message that oci8.pc is not in the pkg-config path but I have set it using set PKG_CONFIG_PATH=C:/users/x/..../pkgconfig Not sure what is going wrong.
This isn't unique to gofmt. It's a problem in any environment with a strictly enforced style guide around indentation. The fix is the same regardless.
I believe this (actively maintained) full implementation was created by the same author: [https://github.com/nictuku/dht](https://github.com/nictuku/dht)
Choosing the right tools (here: programming language) for the job is important. However if you just want to learn programming, you should choose a well documented general purpose language, best with a huge user base. There are quite some possibilities here but Python surely is a valid choice. There are tons of tutorials/free books/etc about Python. There exist good resources for Go too but not nearly as many as for Python. Don't choose Go because it's from Google. It's no argument for a first(?) language. Also chances are good your focus/direction will change over time. If you made up your mind and think Go is the way to go.. then just learn it. It's a great language. I just feel Python may be a better choice for an introduction to programming (if only for the mass of resources). Good luck
I'd say first master writing down (simple) algorithms for simple problems on paper then jump into programming. Seriously. This will help you a lot more that you can think. My CS teacher used to say: Anyone can press buttons, not everyone understands why. Once you get this step nailed down, you can dive into learning a programming language. As for the programming language, while I have yet to learn Python, I think it could be a good choice. Jumping into go should be easy as well. I'd say just try a few simple examples in a few languages, Ruby might be another choice(?), and see which one feels easier to do stuff in. Caveat: if you want write software for games for example, Python might be nice to learn but then you should switch to C/C++ (or even Java??). If you want to do web, Go, Python, Ruby, PHP (yes, I just wrote PHP) for backend, Javascript for frontend might be a bit better. If you want to do mobile development then Java (Android), Swift/Objective C (iOS), C# for Windows. Finally, if you want things that can be done for multiple platforms, or you are not sure what to pick up, you have Java, Go, C/C++ might be worth having a look at. Once you find something you like to program, you'll do it much more easily and efficiently and you'll be able to learn things faster. From &lt;insert-programming-language-here&gt; to Go will be a small step but please don't do it for the wrong reasons. I've seen a bunch of people saying they are experts in &lt;random-language&gt; that looks cool in the LinkedIn profile / CV but when I've interviewed them they couldn't handle basic questions. Learn what you like to write software in and do it to the best of your skill. Finally, don't worry if you got it "wrong" the first time. There's no "right" and "wrong" when it comes to programming, it's just experience that will build up if you are dedicated on it. Hope it helps.
It's a concern if you change string messages for example. But that's the cost of aligning the variables/types this way. Like some things in gofmt, might not be one's personal preference, but the consistency within the community is worth it.
One possible explanation might be that you can get what you want out of sub classing and inheritance from Embedding in Go, which is pretty straightforward. Whereas solving generics problems effectively in Go requires thinking about them in a distinctly different way (like the sort package).
Embedded types and the way interfaces work is a good enough solution for me in most cases. But the lack of generics is gruelling, just introduces way too much boilerplate and code repetition and goes against the purpose of Go being an expressive language. To be honest that's probably the biggest minus for me personally and it got to the point where i started moving away from the language. Hopefully in future versions the team comes up with a solution, but using code generators as part of your build process and telling me that that's perfectly fine is not OKyy. After all the purposes of choosing Go (or any other language) would be that you want nice, clean, maintainable and expressive code. But if you can't express something as common as "I want a list of type" in a type safe manner, you are bound to end up with something that's unpleasant to read and work with, hence the complaints. So to answer your question: The lack of sub typing is addressable by the tools Go provides, the lack of generics is not. The other thing i was really unhappy with despite the recent decision that vendoring is the way to go. I just think this is moving is backwards and not forwards. There are so many good dependency management utilities that could've been used as an example. While i get the technical difficulty of implementing generics, i can't find a good enough explanation of why vendoring is the recommended approach to dep management.
Awesome, it worked like a charm. I also use a json rpc like protocol so your snippet is even better.
I'm curious to know what you need generics for so often that it's turning you away from the language. Certainly there are some domains that use a lot of algorithm-style programming that could be annoying without generics... but I find that most of the domains that Go targets (command line applications, server applications, and web servers) aren't actually that heavy on the algorithms.
Actually, I miss methods overriding; i.e. A.foo() , B.foo(), B descends from A, calling A.foo() on a B instance, actually calls A.foo() while you want B.foo(). The rest is fair enough.
It's a compile time check on runtime behaviour. (All errors occur at runtime, but you can provide compile time checks that those code paths are handled, or at least acknowledged). 
Why not start with Go? C: Too low level, manual memory management is painful and error prone, portable code is difficult. Learn as first language if you are into embedded systems or OS programming only. C++: Too complicated, too many concepts, too many ways to do things. You would learn C++ and not programming. Python: Nice, why not as a first language. But there is no real advantage to Go. Go and Python are very similar. Modern Python tends to lean a bit too much into the complicated/fancy/clever camp of programming (like C++) so it might be less suited to learn how to make computers do what you want them to do. Java: Keep of. Instead of learning to program you will learn to use and IDE and external build tools and monsters like Spring. Was okay 15 years ago, too fancy now as a starter language. C#: A bit like Java but confined to Windows. Fortran: Well, no. Scala, Haskell, Rust, D: Not as a beginner language. JavaScript: A mixed bag; you'll have to cope with JavaScript one day, possible sooner than later but start to learn programming? No. You should not base your decision on stuff like "is suitable for Cloud Computing". Any language is useful for "cloud computing". Base your decision on how well your first language teaches you how to program a computer. Implementing the algorithms found in TAoCP (Knuth) or Algorithms (Cormen, Leiserson, Rivest) will be dead simple in Go. Writing good code is easy in Go. Go works well on Mac. Linux and Windows. With Go you can focus on writing code, i.e. actual programming. So why not Go? 
Inheritance is often seen as a bit of a broken feature actually. (see: Prefer composition over inheritance http://en.wikipedia.org/wiki/Composition_over_inheritance). Please note "prefer", sometimes it *does* have it's place. Compared to generics which are very very useful. 
IMO, it has to do with that inheritance is much much less useful than generics. I've been searching for a few years and I still haven't found something that would benefit from inheritance (when you have interfaces and embedding). Most of the time I needed to use inheritance was because I wanted to easily embed something or wanted to use interfaces, but the language support for them is terrible (I'm looking at you Delphi).
&gt;The most code repetition I've experienced is stupid for loops, like what would be .Contains() method in other languages.... but that code is so trivial, I don't even consider it to be a problem. It starts trivial, but can grow ugly quick, especially if you want the for-loop to be performed concurrently. Something like pmap in Go would be nice, but cannot currently be done in a type safe way.
Since there are tools like godep/gb/gost it's even less of an issue. Maybe in a future were some go packages have grown really large it might bog be as feasible to just throw all of them into a single git repo but thats a later problem..
I kind of need the 5 minute version. Is there a slide deck available anywhere? 
It's possible, but not likely to happen any time soon. I would suggest using a different programming language. Perhaps C# could do what you want. It has an asynchronous programming model using tasks (https://msdn.microsoft.com/en-us/library/dd537609(v=vs.110).aspx). `Task.Run` is basically equivalent to the `go` statement. `Task.WaitAny` is like `select` and you can implement channels using a `BlockingCollection` and the `Add` and `Take` methods. C# has been ignored by many programmers because Microsoft made it, but it has a ton of features.
Thanks!
Then if any language is useful for cloud computing, what would you say is special about Go if anything? Sorry, I'm a newb here when it comes to this stuff. I've just been reading a lot of different articles about which programming languages are suited to doing different things and everywhere I have read says Go is built for cloud computing. 
The problem is that people keep comparing Rust to Go, which imho is completely wrong. The comparison between Go and Python on the other hand is perfect: a lot of stuff that I would have writtin in Python, I now write in Go. Hell, most stuff that I used to write in C, I now write in Go, and am not afraid to mix them (unless having to cross-compile, then cgo is a pain). The only thing I'd compare Rust to is C++: they target the same use-cases.
Considering there is no descends relationship in go (i.e. no inheritance; embedding is composition, not inheritance), method overriding makes no sense in go. 
This is a little verbose, but it does what you want. https://play.golang.org/p/ZXudlXBdty
&gt; Can you give concrete examples of collection types you need that could not be satisfied by maps and slices? &gt;So my question is, what kind of containers were you creating that you really wanted to be generic? In my experience, most of the time, people write a generic container and then end up only using it with one type (or a few tightly related types, but they could make it one type if they tried). Skinny already mentioned a few, but the list can go on and on really. You might want immutable ones, synchronized ones, different types of buffers etc. And I get the argument that I can implement my SortedSet for my custom type that I need and it would work. The problem is that everyone in their repository will have a slightly different implementation of SortedSet that works with their slightly different types and thats where the mess begins. Instead of having a unified Go.collections where you get expected behaviour across projects, you end up with custom wrappers and custom collections implementations all over the place and Im sure you agree this cannot be a good thing in the long run if you want to have maintainable code. A typical example of what I mean is: https://golang.org/src/container/list/list.go So list is a list of Element, and Element is essentially a wrapper of interface{}. So let's say someone else creates MyListImpl, now doesn't take Element, but it takes MyElement. That's my main problem with portability because every library author will have their own Collections impl. What is inside of Element. For example a List&lt;Element&gt;, right now can mean a List of 1 Element with Value of type A, 1 Element with Value of type B and C. That's not great. Those are all questions that bother me and the compiler should know the answers.
Just grab gozim-1.0-arm-linux.tar.gz from https://github.com/akhenakh/gozim/releases extract it with tar zxvf gozim-1.0-arm-linux.tar.gz Create the optional index ./gozimindex -path=yourzimfile.zim -indexPath=yourzimfile.idx this gives you a full text search on the article's titles Start the web server as follow ./gozimhttpd -path=yourzimfile.zim -index=yourzimfile.idx and launch your browser to http://yourip:8080
I can relate to the article, i am not a developer and have recently started to look into Go. As a part of learning i try to look into different code bases written in Go, reading and understanding the code is much easier as compared to other languages. I also like how some people call Go a "better C", while some call it a "better Python". Go positions itself nicely in between them and can only hope it becomes their goto language.
The layout is a little weird. When I did a go get of the repo I got an executable named "cmd" installed. I'm guessing you meant to install a command called "mop". I recommend you rename the directory from "cmd" to "mop" or put the source a folder deeper within "cmd". However, what I recommend seems to have been suggested a year ago without success, so perhaps you want your executable called "cmd" for some reason.
Or perhaps people aren't actually frustrated (as its apparently gaining popularity) and its just an argument in a sounding box often repeated by folks who haven't even touched the language. I'm sure there are people that are using it that want generics but it doesn't seem like they are the ones carrying this argument.
The secret about languages: the application should decide which to use. Languages are tools and do not all solve the same problems. Find a cool project and pick a language to solve it. Be a problem expert first, tools expert second.
Really? every time I run into generated code, it's a huge blessing. It's guaranteed to conform to a standard. It's real actual code that is easy to reason about. If you trust the template, you don't even need to review it. For example, the syscall code in Go.... all the API calls are generated. It's a bunch of unsafe pointer conversion crap, and you can just totally ignore it and assume it's correct, because the template has been proven correct by people before you (and if there does end up being a bug, you fix it in the template and just regenerate).
OrderedSlice? Slices are naturally ordered. OrderedSet makes no sense. Ordered maps, sets that aren't map[T]bool, trees and tries would certainly be nice. The easiest way to support immutable datastructures is to not mute your datastructures.
Also take a look at goamz: http://github.com/goamz/goamz
Because when swapping composition for inheritance you feel clever (and your code is better, too). When you swap boilerplate repetition for generics, you feel dumb, since writing the extra code is more-or-less mindless.
Good point! I'll do so.
On the .gitignore - totally glossed over that while developing it. Will fix. On the main() in helper.go - I thought every package was supposed to have a main() xD oops! Will fix as well. On underscores - I'm coming from Python/PHP/JS land...with an internal style guide that everything is underscored. So I tend to write things underscored now rather than camel cased. That's purely my fault :) thanks for pointing that out! I'll fix. On params being lowercase - also +1 on pointing it out, will fix. On unit tests - exact reason I didn't write them, and I'm not 100% versed on Go unit testing yet (currently learning), so will write them when I'm comfortable with them. As to talking to servers, that's a very small part of the whole thing - the parts that will have to be tested are the data collection etc. The server can be mocked (did this in a different Python project before)
Could one only provide an immutable API for a type that's internally mutable? I don't know Go well enough to know if that'd be enforcible.
Responding to your subsequent edits, `interface{}` in this case isn't the despicable anti-pattern... it's just a request for `encoding/json` to use what it uses for interface{}. It isn't truly "unrestricted". And for edit 2: No. `encoding/json` is a simple library. It has many weaknesses if you stress it, and you'll have to go find a more complicated library. Among its weaknesses is that it shares something that is true of a lot of static languages with simple JSON libraries, which is that if your JSON is _not_ implicitly a statically-typed document, it has a hard time dealing with that. You'll end up having to do some manual work.
Template.new() is required, even if it's name is `"" `
I've filed github issues and had (presumably amazon employees) someone respond with a fix almost immediately. Great work! A lot of the code is, probably necessarily, generated and could be a bit nicer at times, but overall it's great to have an official version in Go.
Yes! Fantastic news! Go almost has my entire preferred stack now, well supported. I chose the right language.
I agree with the Scanner pattern. People try too hard to make things work with range, when you can write a normal loop easily enough. The goroutine and channel could be useful if you want multiple goroutines to be able to consume values from the reader and do processing with them. But using it just as a pipeline that works with range is a huge waste of resources. The goroutine brings up a 4k stack, the channel has a mutex and a lot of its own overhead.... or you could just write a loop.
Duck typing.
One sub-question to this.. If I have an unbuffered channel and a producer writes to it and blocks, why doesn't the consumer that's waiting to read get priority scheduling? I would expect that with 1 consumer and multiple producers all going full-speed-ahead, the scheduler would try its hardest to give that consumer dedicated cpu time and yet it doesn't. With enough producers, the consumer can be waiting several milliseconds to get a chance to read.
Sets should be map[T]struct{}, by the way.
Actually the channel in this case may indeed improve performance. This program will probably be IO bound - limited by the speed at which you can read rows from the file. With a single thread of execution each row of the file will be read and then processed sequentially. With separate goroutines the 2nd row will be read while the 1st row is still being processed. If IO is slow this can have a significant impact on performance. Rather than being a waste of resources, using channels and goroutines utilizes the resources you have rather than leaving them idle. You have a bunch of cores and a ton of memory - if they make your program faster why not use them?
Everything is a tradeoff. Channels aren't free, spawning goroutines isn't free, and cleaning up the garbage from them isn't free. Yes, in this case, the IO may be a limiting factor... but even then, using the goroutine is only better if your application doesn't have anything else to do. If you're serving 100 requests at the same time, the blocking IO will just give another request some time to do some processing, and the extra goroutine will likely not make a difference to your average response time (it might make it even worse as the scheduler has to switch back and forth a lot). Like most things when it comes to performance, it depends. But I wouldn't prematurely optimize with such a complex configuration unless I *knew* that the IO was a significant drag on response time... and even then I'd do a lot of testing to make sure that the added goroutine actually helps.
For something like this I wrote a consumer pool like structure that would scale up and down creating more consumer go routines based on how many users were connected. I suppose in your situation you would want to scale based on number of in flight requests. Here is basically the pattern I used with an example dummy app. http://play.golang.org/p/gEZdu4hDPr *update* - better protection on the counters.
Neat! I tend to use [go-hashids](https://github.com/speps/go-hashids) for smaller values, like auto-incrementing database IDs. Best part is that [hashids.org](http://hashids.org) has implementations in multiple languages.
What's wrong with base64.URLEncoding.EncodeToString(…)? It's probably faster and probably safer. e.g. in basex.go:119 you first cast string to []rune, which is probably an expensive operation and then cast rune to byte, which looses information. If I use "äöüß♥≠≤⇒↦⇐" as the input string, the result is encoded to an empty string.and decoded to "0".
&gt; OrderedSlice? Slices are naturally ordered. I thought that if I appended something to a slice, it was appended at the end and not in order? &gt; OrderedSet makes no sense. OrderedSet makes perfect sense if you want to iterate the contents in, say, alphabetic order. I do this from time to time in Clojure(Script). &gt; The easiest way to support immutable datastructures is to not mute your datastructures. And we know how that works in a real project. The best way I think is to have a separate type for it. Preferable something that is efficient to create a new version of, like a persistent HAMT.
What I think makes Go special: It is a tiny language with just a few building blocks which work together very smooth. It is low-level enough to write fast and machine-suitable code. It is very high-level to be really productive. It has a strong focus on "get the shit done". Its standard libraries offer the right level of customisation for the everyday jobs. It is built to promote good programming style (details below). It is easy to work with due to good tooling, and easy fast compilation. A lot of voodoo nonsense and bikeshedding you'll find in other languages are suppressed in Go. Code formatting: gofmt. Returning List&lt;C&gt; instead of ArrayList&lt;C&gt;: It's slices (or maps) all the way down in Go. Limit each method to exactly one return but throw happily whenever you get stuck: Not in Go. Design your code for testability (with the help of IOC containers): Just test it, no bullshitting in Go. Project setup: mkdir instead of maven archetypes. Programming: Done in any editor, no fancy IDE needed. Documentation: Written for humans, not for machines. 
I think you would show them the ease of using the live-reload tools like gin-reload and\or maybe revel (which has built in live reload). This might sounds strange, but using this tools gives to newcomers the feeling of usage server side script for programming and users will not afraid compiling nature of the go. 
Hmm... I was actually thinking about avoiding frameworks completely, and at most demonstrating a simple 3rd party go get for a very specific task (uuid generation perhaps?). 
An app that pings every valid IPv4 address and logs which addresses respond within 100ms. Should be a good excuse to use goroutines. 
I agree that for this example (calculating the distance for a csv file of points) using channels does not help. (It's actually slightly slower) This is because calculating the distance is trivial. But I think most data pipelines are going to do more work, and in particular there's usually an IO stage at each end of the pipeline. Something reading in data and something writing it out. And in that case you will really start to see a difference. It becomes max(t1, t2) instead of (t1 + t2). I agree that the model doesn't work as well for a heavily-loaded HTTP server, but I'm not sure if that's at all typical for a data pipeline. Like you said the Go http server is already running each request in its own goroutine, so doing more work for a single request is probably just stealing it from others. I think, if anything, the Pipeline-Stage model would be an example of over-engineering rather than premature optimization. In practice having seen systems built around the model, it pays dividends fairly quickly. But I agree it wouldn't help the trivial example in this article.
Changing the algo behind the scenes breaks the API (because existing passwords will no longer match). To be blunt, I'm also not sure what this package offers over the x/crypto/bcrypt (https://godoc.org/golang.org/x/crypto/bcrypt) package. The bcrypt package also has a much easier to grok API: `GenerateHashFromPassword` and `CompareHashAndPassword` being the core. The `Set` and `Verify` methods in your package are far less clear. Further, your original PBKDF2 implementation only used 2048 rounds, which is *extremely* low and doesn't give me a ton of confidence as to whether you read up on the implementation. PS: That article is from 2013 - I would still argue for scrypt over bcrypt. In fact, I wrote a [scrypt package](https://github.com/elithrar/simple-scrypt) that matches the bcrypt packages' API to make it easier to use.
&gt; we could create an application context that wraps sql.DB and anything else we might want to use like in this article[2] . Of course this approach could lead into trouble with concurrent access assuming we include something unsafe in the struct. As the author of that article: `*sql.DB` is safe for concurrent access. Most data-store connection pools are (but it always pays to check). If it weren't, the overhead with setting up/tearing down new connections would be painful. In fact, I called out the need to pay attention to that in the article ;) If you want a really simple setup, just go with a global. Keep in mind that too many globals can get away from you - it's nice to know *where* things are being passed/used sometimes. Hence why I'm a fan of the approach in [Ben's article](https://medium.com/@benbjohnson/structuring-applications-in-go-3b04be4ff091#9e7e) about having your own `DB` type that embeds `*sql.DB`. It also makes it easier to test.
It does break the API except I only just released this 50mins ago :) Indeed, it only offers an alternate API, which was why I wrote this. Fair enough, will look around a bit more and decide on bcrypt or scrypt before people start using this.
nice idea. one of my original ideas was a rudimentary web crawler, but with the html parsing it might be out of scope, this might be a simplified version of the same principle.
Thanks for the feedback all
When putting examples in your front-page documentation, it's nice if you put the output as well
I have set GOMAXPROCS to the amount of cores on the machine.
Some interesting food for thought... One of the consumers in question did nothing more than keep a running average, max, min, and sum of the times being put into the channel. Everything would put a time into that channel. Most the time, the channel would have a few hundred elements in it... But every now and then, possibly due to GC or bad scheduling or something, the consumer would get no time and the channel would back up to thousands. Ideally it would be totally unbuffered but that seems even worse. If a consumer did *nothing* but read from an unbuffered channel, how long might you be blocking trying to push onto that channel? I will have to mock up this test to explain my problem better. Even with thousands of producers you would expect none of them to be blocking very long... 
This is cool!! OT: I still don't see a good package to manipulate Google Docs, specifically spreadsheets... that would be high on my list more than S3, personally. Anyone know of one? I searched around 6 months ago and came up short.
Indeed. And both `base64` and `base32` (and various third party `base58`) packages allow you to define your own alphabet (of 64, 32, or 58 characters respectfully) if you need/want. If you really really need a different sized alphabet I'd probably start by cloning Go's `base64`.
Simplistically when you create something in Go it will automatically allocate enough memory for that object. For example: x := make([]byte, 1000) Will allocate 1000 bytes of memory. Eventually when `x` is no longer used it will be freed by the garbage collector. A common pattern in Go is to append to a slice: xs := []byte{} for _, b := range someBytes { xs = append(xs, b) } The way this works is that every slice has a length and a capacity. `append` will just put the byte in the next element of the array until the capacity is reached. At that point it has to create a brand new array and copy over all the old values. If we had created the slice with an initial, larger capacity: xs := make([]byte, 0, len(someBytes)) We could avoid all the allocations (meaning creating a new slice) and copies. This comes down to optimization, but the design of the language is such that it's not the main thing you should be thinking about. The whole point of garbage collection is that managing memory is error prone and tedious, so a lot of work is going into making the garbage collector as clever as possible. I'm not sure there are any red-flags here, outside of standard programming ones (code that would be bad in any language). If you have a program where such optimizations are necessary there are some strategies you could use - like the pool in sync - but I'm not sure how often you would need to actually use those strategies.
Ironically, the base64 URL encoding doesn't work well in URLs (the = is problematic). The `-` and `_` characters can also be problematic. Base58 might be a better option. It's used by bitcoin addresses.
I'm currently on mobile... So how exactly does it set the variables? Does it write to to the .shellrc files? Or are changes stored in /etc/profile? :o
Wouldn't it be a better idea just to learn how to set environment variables in your environment?
Yeah probably. Have you tried doing this in windows or OSX? It's surprisingly complicated. I made this so I could give new users an "easy" way when setting up their environment. I'm already teaching them about Go and basic terminal stuff, the fewer things I have to add to that list, the better.
bashrc for bash. I avoided /etc/profile because I wanted per-user environment variables. I could add better support for linux, but there are just so many different possibilities. Bash seemed the easiest route. (and I added fish cause that's just what I use)
That's really cool. I dind't know that env variables could be stored in the .shellrc file!
I think you'd get much better feedback if you posted a working code sample or link to a repo/gist.
This might help you with that: https://github.com/GeertJohan/go.rice
glad to hear it!
A few tips: - Learn how godoc works; don't use /* */ comments everywhere. Take a look at how it appears right now: http://godoc.org/github.com/gustavokuklinski/klever - Use gofmt - [This line will be problematic](https://github.com/gustavokuklinski/klever/blob/4286fcba10344f5a1ad748ce7c2e7f174c3cc24d/klever.go#L48) if there's an error parsing the template, since it's writing to the response right away. You might want to buffer the result then check for errors, and if there aren't any, *then* write it to the response.
&gt; In other words the compiler is "analyzing" code to determine whether or not pointers ever "escape" a function. Good answer. That helps. Thanks.
The trivial example has a nontrivial memory leak. Everyone that uses the iterator and doesn't finish contributes to the leak. Most of the time where I'm tempted to use channels, I find there's another simpler, more performant, solution. They are useful anywhere it's useful to use a threadsafe queue as that's what they are. The only real sugar is select, and even then I find that this gets relegated to longer running processes.
I'm not sure you're understanding what I'm saying, so I'll simplify. Let's say I want to make a static html server. Obviously, the Go code would be pretty trivial. In my serverproject directory, I have main.go. When I do a `go build github.com/username/serverproject`, I get an executable in my current directory. Because I have to specify a path in the code (relative or absolute), I need to know where the files are. I probably shouldn't assume anyone with the executable has the assets at `/home/name/go/src/github.com/username/serverproject/assets`, so I probably want to always output (with go build or maybe something else) a directory with the executable at the root and the assets inside a subdirectory... But I'm not sure if that's good practice and even if it is, I'm wondering if there's a way to do that. I could use something like gulp or a makefile to do it, but I think that isn't really the "Go Way" 
Of course not :) It means it's structured as: github.com/ thockin/ src/ // Your code in $PROJECT/src server.go vendor/ src/ // Vendor code in $PROJECT/vendor/src/&lt;import_path&gt; github.com/ gorilla/ sessions/ securecookie/ mux/ tv42/ slug/ jmoiron/ sqlx/ Read this for more info: http://getgb.io/docs/project/ PS: Fixed indentation. My comment had it right.
And the fewer things they learn the harder it will be for them to understand how things work and get basic stuff like this done without help (Google). I think you are doing them a disservice. Also, playing around with env variable is trivial once you learn it and a regular user shouldn't be concerned with this things and a developer should be laughed at, if for his/her OS, changing an environment variable is not known after some time. 
And the more things you throw at them on day 1 the more likely they are to throw in the towel and give up. Go itself has installers for different operating systems. Those installers already update your PATH without bothering to teach you what PATH is or how to manually update it. Are you suggesting that this was a bad move by the Go team and they should've just included documentation for manually installing Go from the command line? Updating an environment variable in windows involves going to an archaic UI that gets hidden further and further away with every version of windows. The windows development model is such that many developers (not just users) never have to touch a command line or their environment. Every version of OSX changes how per-user environment variables are set. Most developers who use OSX just use bash. But those environment variables won't get passed to Atom (or any other text editor) unless its started from a terminal. But even if that weren't true, how is handing someone a block of arcane bash to copy and paste any better than just doing it on their behalf? And linux is a complete mess with no agreement between distributions, shells or desktop environments. But I figured anyone using linux probably doesn't need my help setting environment variables. (or they're probably using bash and it will do at least that) I'm not teaching users how to use their operating system. I am teaching them how to write programs in Go. If Go didn't require a GOPATH it wouldn't be an issue. But it does. So rather than get bogged down in this I set it to their HOME directory and move on. We can always cover it in more detail later.
not the best idea. i had a quiet similar task as an assignment at my university. we did it only with 50.000 ipv4 addresses. after a few test runs my account was suspended, because i pinged some c&amp;c servers. So be careful from where you run this program
I still don't understand. Who unpacks my git project into this structure? And how do I git operate on it? Do you have a github repo with vendored deps that I can just 'git clone' and 'gb build all' ?
It's checking to see if *any* binding escapes its declaring function, not just pointers. If so, then they are candidates for being hoisted out into the heap. Whether or not this happens depends on other factors. Immutable bindings can stay on the stack and closure gets a copy. Or if the compiler can prove that the binding is only used by calls further down the call stack (a so-called 'downward funarg') then the binding could potentially remain stack allocated. But if the escaping binding escapes up the call stack (a so-called 'upward funarg') or outward, e.g. it is captured by a closure that is returned from the declaring function, or stored in a global, or used to start a goroutine etc, then the binding will have to be heap allocated so the it can survive the pop of the stack frame for the function where it was created.
In addition to /u/calebdoxsey's good answer, the direct answer to the question in the title is: You don't need to know anything about it. It's a compiler optimisation.
&gt; One of the consumers in question did nothing more than keep a running average, max, min, and sum of the times being put into the channel. In that _particular_ case, the channel overhead is almost certainly dominating the overhead of doing the math in question. You might be better off just wrapping a lock around the relevant data. Then you'd pretty much only have cache coherency to worry about. It may be enough to carry the day. Go, perhaps frustratingly, does lack some tools that makes this level of performance easier to obtain in some other specialized environments, such as the ability to ask "What CPU am I currently on?" and using that to key into a set of statistic structs for each CPU, to be collected and merged together later by some process that only does so when you care about the results. You could also potentially see a win by simulating a channel with a buffer &amp; a sync.Condition, and making it so when the consumer gets the Condition's lock, it entirely empties the buffer.
Here is an example of a sample gb project, [github.com/constabulary/example-gsftp](https://github.com/constabulary/example-gsftp) And some documentation [getgb.io/examples/sample-project/](http://getgb.io/examples/sample-project/) 
Have you looked [here](https://github.com/google/google-api-go-client/blob/master/examples/drive.go) and [here](https://developers.google.com/drive/v2/reference/files/get)?
For the OAuth2 part, is that what you mean? EDIT: I didn't see a way to read a spreadsheet.
&gt; "server" instances which each receive a "sysUtils" object Judging from the lowercase of sysUtils, I would assume all your handlers are in the same package. If that's the case, this approach would work fine (and so would a global variable). The whole point of putting it in the "root" context (from which all request contexts are derived) is so you have an easy to reason about, simple and reliable way to pass around common state *across* API boundaries (i.e. packages). When you have handlers and tests involving multiple packages, having all your stuff in a common location is very helpful. Before I used context I tried putting "InitXXX" methods in every package and calling them from main. The hacks and workarounds I had to do to get tests spanning multiple packages to work was far uglier than using context, and avoiding circular dependencies in your tests becomes very difficult (because you have to InitXXX every other package you depend on—even indirectly—in your test's init). Again, if all your stuff is in the same package, (such as the "service" package in /u/TornadoTerran's comment), you don't have to worry about this. If you have any workarounds for this I'd be very interested. I like static typing too! No one wants to use `interface{}` if they don't have to. TL;DR: You gain an easily mockable, easily testable reference to your DBs across packages.
I'm not following. This seems like you might be thinking in another language. Please, if you are willing to share, explain why other packages would need to share the DB connection from your main. I wonder if you are misusing packages as a way to structure your project files. Another thought to consider is that if you are reaching for interface{}, more often than not, it's not the right solution. In other words, without seeing code, I suspect that there are other design issues causing the overhead you are trying to avoid. Apologies if I'm being dense.
Done.
Yes, I would have laid it out the way the notgood directory is set up in that repo: https://github.com/fatih/gb-example/tree/master/src/notgood Not sure why this is not considered good. It's for commands and not libraries, isn't it? Libraries even if they're my own I would put in the vendor tree. (Maybe I'd rename it to libs or something instead.)
I've used this with great success in the past for packing along static assets, etc. https://github.com/jteeuwen/go-bindata It was used for bundling the pre-packaged views with authboss (via go generate) https://github.com/go-authboss/authboss/tree/master/internal/response
Deciding how to split packages up is definitely one of the hardest parts of maintaining a large project. Ultimately it's personal preference, but I've found that splitting packages by concept/feature is better than having packages by "function" like handlers/models/views. There is a certain point where your project just gets too big to shove unrelated handlers all in the same package. Plus, by keeping the code hitting the DB outside of your main/handlers package, you can create common components re-usable across multiple services. For example, an API server for a mobile app and a batch job that crunches data could share code. So let's say you're making something like reddit and have a `user` package that handles authentication and user profiles, and then a `article` package that handles the article submission process. Both of them have to look at the database. The article package depends on the user package, for keeping track of submitters and comments. In your main method, you could call `user.Init(SysUtils{db, ...})` and `article.Init(...)`. This could put the DB connections in a global, or a handler struct or whatever. This is fine, but now let's try and write tests. In article/article_test.go you could put something like: func init() { testDB := ... Init(common.SysUtils{testDB, ...}) user.Init(common.SysUtils{testDB, ...}) } And achieve the same thing. But let's say our user package is too big now and we want to split up the user profile-y bits and the authentication bits, so we make an `auth` package. Now, even though your `article` package doesn't directly depend on `auth`, you still have to call `auth.Init(...)` from `article` tests so that your `user` package doesn't break in mysterious ways. Suddenly you can't refactor anything, like splitting a big package into two, without breaking every single one of your tests. You can't make a common `init()` that Inits every package either, because that would be a circular import. However, if you use context to keep track of your databases, everything is very easy to share. Just make a package that sets up a common testing context with all the necessary DBs and such inside of it. package testhelper import ( "golang.org/x/net/context" "github.com/me/my-cool-project/config" "github.com/me/my-cool-project/db" ) var ctx context.Context func init() { ctx = context.Background() ctx = config.NewContext(ctx, /* test config data */) ctx = db.OpenWhatever(ctx, "test database") // etc etc } func Context() context.Context { return ctx } Then you can just use `testhelper.Context()` in all your per-package tests. There's no need to init anything because every package can get the information it needs from your context. In other words, it's much easier to have packages grab the settings they need rather than be handed them. Context is immutable, so if you need slightly different settings for a particular test it's easy to create a new child context deriving from testhelper's without affecting your other tests. Although x/net/context uses `interface{}`s on the inside, you are encouraged to hide that implementation detail by using unexported types as keys and FromContext/NewContext functions to wrap the type casting ugliness (see the official blog post on context for more info about this). I'm curious to what your solution would be for this. Would you put all your handlers/DB code together in the same package? Test everything from the main package instead of per-package? I think the majority of projects never reach a size where thinking about this is necessary, but it's been something I've struggled with for a while now. I found x/net/context to be the cleanest solution, but I'm always looking for improvements. Edit: fixed code and formatting.
&gt; Who unpacks my git project into this structure? And how do I git operate on it? Nobody, the project is your git repo, you just check the entire thing in. &gt; Do you have a github repo with vendored deps that I can just 'git clone' and 'gb build all' ? yes, here is an example of a sample gb project, github.com/constabulary/example-gsftp And some documentation getgb.io/examples/sample-project/
&gt; Reproducible builds that used convention over configuration with a plugin architecture. Nothing has changed, gb is still 100% convention over configuration. &gt; Then came the vendor config file and now this. Every update comes with more "features" that feel like accidental complexity. All gb cares about it your source, in `$PROJECT/src` and the source you depend on in `$PROJECT/vendor/src`. You can just copy the source with cp, or rsync. Or, you could set up git submodules, or svn externals if your politics allow. Or, you can use a plugin, like gb-vendor, which is completely optional. Then end result is always the same, _somehow_ files get on disk in the project structure that gb expects, and it builds them. You don't have to use gb-vendor, it is completely optional.
path is not the best package to use for: https://github.com/gustavokuklinski/klever/blob/master/klever.go#L21-L33 Take a look at path/filepath instead.
I think including your HTML templates in the git repo is a good idea. Maybe under assets sub folder.
If you dont want to implement it yourself, you can use any third party service which provides "backend" for your autocomplete so it frees you from autocomplete related work. Disclaimer: I run such a service - Autocomplete as a Service - http://aaas.io/ 
That consumes less space than the original bytes.Buffer, but I think you can trim it some more. My solution consumes three machine words and the winner so far consumes just two.
Iny my example the point is that `service` directory contains only integration layers, configuration and initialization. All feature code base is in lib (its temporary place for packages that at some point maybe evolve into separate project). But lets stay with your idea. We have to packages `user` and `forum`. In a `forum` pakage there is a method that makes SQL query with `JOIN` to get all posts with author data. So you need to provide `user.User` struct to `Scan` method. Then in a `user` package you need `forum.Post` struct as type for `user.User.Posts` field. In my opinion there is realy no way make one monolitic project in Go without `semi-flat` directory structure.
It's a performance optimization whereby values that don't outlive a defined scope can be put on the (already allocated) execution stack instead of allocating memory from the heap for them, which can be really expensive, especially if done repeatedly. Anything that lives on the heap is collected by the garbage collector, whereby values that live on the stack get "popped" off when they're not needed anymore by the program flow. So values on the stack are cheaper in that aspect as well. Normally, if you use `new(...)`, you get a pointer to a newly heap-allocated object. However, if the compiler can determine that the pointer never escapes the scope in which it was instantiated, then the pointed-to object may be placed on the stack, relieving the garbage collector of having to collect it later.
Here's an 8-byte io.ReadWriter that supports Len and Cap: http://play.golang.org/p/5JToJmiREb ...and a 4-byte io.ReadWriter that mostly works and supports Len and Cap: http://play.golang.org/p/ccXSt7qZmN
Agree, however it's up to you how you handle it. I've add it to the readme: https://github.com/fatih/gb-example#questionsconcerns A suggestion was to put it under `/src/gb-example`, so inside your `/src` any code would import a package as `import "gb-example/snakecase"` 
If you only want to read the content of the spreadsheet, then you could download it in XLSX format and use [xlsx](https://github.com/tealeg/xlsx) to read it.
This is now changed to this layout. Check it out: https://github.com/fatih/gb-example 
No problem. If you look into it we actually allow overriding of the packaged assets as well by specifying a directory with the files. If you have any questions feel free to message me. 
Yeah, I needed this specifically as separated functionality and mostly for performance (notice the Writer.Reset()). But when combining only one slice could be used, giving 3 machine words (also the int for reading pos). I suppose the reading pos could be rid of by advancing the beginning of the slice. A slice is really just two pointers and you needn't more!
&gt; Are .7z files incompatible with archive/zip package? 7z is not related to zip at all.
Actually I've been doing the same thing on my heroku applications. "Deferring" queries and heavy calls, answering requests as quick as possible. Good tips.
Welcome to Go. The "Go way" is to **never** ignore errors. uuid, err := uuid.NewV4() if err != nil { return "", err } return string(uuid), nil
Thanks for the reply, perhaps you can weigh in on the other question I asked /u/Ainar-G
Nope. Go values simplicity over being able to do things on one line. If a function returns multiple values, you are prevented from using it in inline ways like chaining on method calls to single parts. 
Another alternative is to wrap it in a function that either returns the value or panics if the error is non-nil, a la [template.Must()](http://golang.org/pkg/text/template/#Must).
finally....
That's what reflect.DeepEqual() is for. If it returned true when given two values of different types, what's the point of having it? Maybe you need to be using this instead of assert.Equal? https://godoc.org/github.com/stretchr/testify/assert#EqualValues (although I don't see a corresponding NotEqualValues function - that might be something to raise an issue about).
It seems to work ok if you follow the instructions on https://golang.org/doc/install and make sure you install to /usr/local/go oh, and you MUST put export PATH=$PATH:/usr/local/go/bin export GOPATH=&lt;path to go path&gt; in your ~/.profile not ~/.bashrc
This breaks the Go oracle for me. main.go:33:2: could not import golang.org/x/crypto/ssh (cannot find package "golang.org/x/crypto/ssh" in any of: ...
Only google knows.
Just in case you aren't riffing on that username: Until Go 1.5, [GOMAXPROCS](http://golang.org/pkg/runtime/#GOMAXPROCS) defaulted to 1. This means all (non-systemcall) goroutines are multiplexed on a single thread, even if there are more cores available. 
:))
This behaviour is as to spec [0]. An integer-literal is an untyped constant. It gets assigned a type, when used as an expression (i.e. the call to reflect.DeepEqual). As DeepEqual takes an interface{}, the type infered is the default type for integer untyped constants, which is int. As mentioned, DeepEqual returns false, if types don't match, so you have to make the types match (by making x an int, or making the untyped constant to a constant of a different type). So, not a bug :) [0] http://golang.org/ref/spec#Constants
Thanks for playing!
Writing a robust, full-featured backup system is really, really hard. I admire your enthusiasm to build this in Go, but have you already evaluated the two most widely used open source backup tools: * http://www.amanda.org/ * http://blog.bacula.org/ If you need something you can rely on, I suggest looking here first.
Always interesting to hear from naysayers, though my impression was that the author was appealing to emotion more than reason.
User google_you already posted this. 
&gt; Why the heck is Go making me care about pointers at all if it is a GC’d language? AFAIK it's to give programmers the ability to either copy data and use more memory or share data but worry about consistency and slowing the GC. Am I off base with that assessment?
Don't forget the native types where C# uses either ref or unsafe.
Can you think of a reason why passing a struct would be superior to passing a pointer to it, from a language design perspective? There's the argument that it guarantees the function can't modify the content of the struct, but the same guarantee could be made with, say, a keyword which then triggers a compiler enforcement or runtime error. I think his point still stands. Its good to have choice, but I think this is just a relic of Go's C origins. 
I would also mention the use of URLs for dependency management, though it kind of falls under go get. If github ever goes bankrupt basically every go program in the world will be unable to compile. The same is not true for something like npm or pip, because we could create mirrors and all you'd have to do is change the npm repository url you hit. Very concerning. 
I agree with his points on tooling. Hopefully, as ecosystem goes more mature, these issues will be solved. A package manager like npm would be nice, as well as getting rid of $GOPATH and `go get`.
Yes, exactly. And what's more... You don't need the source to run the application. Anyone with the binary keeps on using it. And only the application maintainers need to worry about fixing up the repos.
The go way is really not to do "fluent" style coding, i.e. foo().bar().baz(). Line returns are not your enemy :)
True, but copying memory also isn't free, and its a necessity in a lot of functions which pass pure structs. COW helps here but I'm not sure if a language which always had to dereference in functions (IE: java) would be strictly slower than a language which sometimes had to COW in functions. Again, nice to have the option, but its also nice to have simplicity and there are arguments for both.
They would still be able to compile. You just wouldn't be able to fetch the packages with `go get`. People use their github url for namespaces so that `go get` will work, but it' still just a name to the compiler. As long as you got the code it will work just fine regardless of where the code is hosted.
There is always [gb](http://getgb.io), a project based build tool for Go. 
Theres is a blog comparing the "big three" of web scraping: http://intogooglego.blogspot.co.at/2015/06/day-13-comparison-of-html-parsers-for.html
Thanks.
eeeeehhh I hear this often from non-Golang users. Have you used the language? I like it but I don't ever see it replacing Java for Android development. It has to many quirks and is extremely rigid, which are fantastic for specific tasks, but limit its scope of use. Go might replace C++ in the NDK, one day, but for whatever reason C++ compiles to much more optimized machine-code than Go. As that is one of the main purpose of the NDK, we'll c. C++ is also very popular with game developers, so I really don't see Go replacing the NDK anytime soon either.
GXUI's last commit was over a month ago, and that makes me sad.
swift really is taking off for app development on iOS devices. While there's a lot of that "we're not forcing you to use swift" stuff being said, the fact is it's Apple's way forward, and within a few years the majority of Apple developers will be using it. Swift isn't necessarily gaining popularity based on merit, it's largely gaining based on position. But you wouldn't write your http microservices with it.
&gt; Can you think of a reason why passing a struct would be superior to passing a pointer to it, from a language design perspective? You've narrowed the question from "why value structs vs. pointers" down to "why is one or the other better to pass to a function", but in the process you've lost a lot of the distinctions. It's not all about just passing things around. The ability to have a true array has significant performance implications if you want to write code that goes fast, and it's an unmitigated advantage over languages like Python than simply don't have it. (At the language level, that is; NumPy has them, but only by writing lots of C code, and not for generic python types.) If you care about performance for some reason, a language that automatically boxes _everything_ and automatically allocates what those boxes point at without giving you any control starts you out in a state where your maximum performance has been lowered by a significant amount before you even start writing code.
&gt; This actually works fine for unit tests on single files, but good luck getting any idea of integration test coverage across an application. Why one would want to check what the percentage of the external package is covered with your tests? If the external package is part of your project then you may want to reduce the number of packages you have.
I agree that Go's use of pointers is a great way to specify when to copy memory v. when to just reference it, but I wish there were some way to distinguish copy/reference from nullable/non-nullable. Nulls (`nil`) are super-useful, but it seem to me the question of whether to use one or not is separate from the question of whether or not to copy a data structure. For example, let's say you're marshaling some JSON into a strong type. If you have an optional substructure, you need to make it a pointer, so that it can be null. But memory-wise, you probably want the whole JSON object to be together insofar as that's possible.
Swift is gaining a lot of popularity for the same reason that some years ago the iPhone made Objective-C a very popular language. [Tiobe sucks but shows this case very clearly](http://www.tiobe.com/index.php/content/paperinfo/tpci/Objective_C.html) In the current day, if you want to code for iOS you have 2 main options, Objective-C or Swift. And logically people are shifting to Swift being the better of the two.
Well Xamarim is gaining popularity day by day. I wouldn't be surprised to see C# become the main language for mobile in the future.
&gt; **Go race detector** &gt; &gt; This one is actually kind of nice, although I’m sad it has to exist at all. And what magic the OP suggest instead? Massively slow down all code all the time by effectively making `-race` the default? Forcing all data to be (expensively and restrictively) copied to each goroutine? Add complex "owner-ship" rules/syntax (doesn't Rust go that route?) &gt; The annoying thing is that it doesn’t work on all ‘supported’ platforms (FreeBSD anyone?) FreeBSD has the race detector since Go 1.4 (Nov/Dec 2014). More than half the time the OP was working with Go. It's no surprise this is a very platform specific feature. &gt; and it is limited to 8192 goroutines. In practice, I'd think this would be only a minor annoyance. If I ever hit this limitation I'd probably use a build tag (or just run-time config) along with `-race` that limited the scale of goroutine creation (e.g. scaled back the number of workers, etc). Did the OP look to see if that's a hard limit or if there is an easy-ish way to override it? (e.g. is it just a constant in the runtime that could be changed?). &gt; You also have to manage to hit the race, which can be tricky to do with how much the race detector slows things down. That's not my experience. The race doesn't have to happen, you just need to have written and read from the same variable *at all* without any synchronization in-between (e.g. the detector doesn't care if the write has completed ages before the read). &gt; **Channels/mutexes** &gt; &gt; Channels and mutexes are SLOW. Adding proper mutexes to some of our code in production slowed things down so much it was actually better to just run the service under daemontools and let the service crash/restart. Wow! WTF? Does this guy have no clue what can happen with [data races](https://software.intel.com/en-us/blogs/2013/01/06/benign-data-races-what-could-possibly-go-wrong) and why only a freaking moron would purposely leave data races in or purposely write racy code. Avoiding data races **is not optional**. There are sane ways to write non-racey code without too much overhead. Sticking your fingers in your ears and humming real loud hoping it's not a problem is not a sane way to deal with data races. &gt; **Crash logs** &gt; &gt; When Go DOES crash, the crap it dumps to the logs are kind of ridiculous, every active goroutine (starting with the one causing the crash) dumps its stack to stdout. This gets a little unwieldy with scale. RTFM and set [`GOTRACEBACK`](https://golang.org/pkg/runtime). 
I'm a java engineer. This will take some getting used to. So far I love the language though. Its everything I've ever wanted as a Linux developer
Really? That's what you're crying about? s/github.com/newgit.org
Agreed! Positive discussions on which languages and tooling are best for which project. If you're looking for 1 language to rule them all... Good luck. 
I think it was stated that the tooling aspect was intentional allowing the community to dictate the tools they need/want 
For anyone wondering why it was set to 1 instead of NumCPU() until now, here's an explanation from Andrew Gerrand: https://youtu.be/S9Bu6fZnLGM?t=322
I posted this request on WatchPeopleCode: Something that goes well beyond "this is how you write a RESTful service that returns a hello world json object." Something like: * This is the problem * This is the data model. Talk about some interesting decisions made, how people can make mistakes in this. * This is the RESTful representation of the data model. Decisions &amp; mistakes. * This is DB representation of the data model. Decisions &amp; mistakes. * This is how and why we decide whether we want to use any router, orm, etc (preferably not, because if the learner isn't going with your tool, then it's harder for them to transfer the knowledge) * Writing the go code. Decisions &amp; mistakes. * Making it concurrent. Gotchas. * This is how we deploy. Talk about a few alternatives. * This is how we debug. * (Bonus) A part of this communication makes more sense if it's full-duplex. So, this is how you create a WebSocket version of the service. REF: http://www.reddit.com/r/WatchPeopleCode/comments/2xl3iv/requests_thread_viewers_what_streams_do_you_want/cp1mi05
Are you interested in constructive criticism?
You've got it locally if you've compiled it before. 
What the fuck is "Antigen"? I hoped your README would tell me, but it doesn't. And googling words like this doesn't help either.
Or create an alias in /etc/hosts
Yes, definitely. Always looking to make my code more idiomatic.
Having done both Android and Go development I'd take Go over Java any day. The thing holding it back appears to be that you'd need to completely rewrite the Android API in Go which I doubt will happen anytime soon. That's unfortunate.
Yeah it just shows how cumbersome and annoying Objective C is. Apple pulled off the jedi mind trick with its customers so everyone who wants to leverage their marketing prowess puts up with their bullshit.
What is the main difference to rust? Because the goals and at least some of the syntax seem very similar to rust.
Fixed :)
Xamarim has a lot of potential, its also nice that C# and Java are practically the same language. But their IDE isn't that great and there isn't really a good C# IDE for Mac. Also when I use it I feel like I am just writing two separate apps with just my model code being shared, which I would rather just write it natively and use something like J2objC or RoboVM for my Models. So I prefer to go the Cordova Phonegap route, with iOS's WKWebview we just saw a huge performance gain for webapps on iOS. Also nothing does adaptive display like HTML/CSS :) Javascript is a real PITA for large projects, but I have been using Dart recently and have been very impressed. 
I guess the compile times would amazing. Sometimes i compile my project a few times, just to reassure myself it actually compiled. I would hope they would allow for a less ridge compile because the refusing to compile with unused vars/imports kills me and it makes testing out new libraries/features painful af
With fmt.Printf("type of ms: %T\n", ms) you can check the type of ms. ms := MyStruct{} type of ms: main.MyStruct ms := reflect.New(reflect.ValueOf(result).Type()).Elem() type of ms: reflect.Value
How does one manage a connection pool? 
Cordova has major problems for any serious app. I suppose if you feel like it gets you launched quicker maybe its worth it, but any competent iOS developer will be much faster building a mobile app using the tools Apple provides. It was certainly true when I had to do it with Android. Things don't look right, apps crash all the time, it eats memory like crazy, it sucks your battery dry and interfacing with native code is hard - which is particularly painful because you almost always have to interface with native code since it doesn't support all the features you need. Someone should figure out how many apps start as Cordova and then switch to native.
&gt; Rust is quite a security focused Rust is focused on type safety and memory safety, not security. Those are different things in general with only small overlap (e.g. bounds checking).
Ooop, sorry I meant safety not security. I find that the borrow checker, and ownership, etc. make the development time a little bit slower than C. So I wanted to write something like C, but more modern; taking features from various languages like Go, Rust, and so on. 
Not sure I see your point. You can see that I've printed out the type of each object in the code... The question is how to create an equivalent type to an explicit declaration. 
Just to clarify, It's more direct to use TypeOf instead of ValueOf. t := reflect.TypeOf(result).Elem() ms := reflect.New(t).Elem().Interface()
This looks pretty cool. I looked around and didn't see anything about concurrency. Is this just up to the user to figure out?
I don't know Swift super-well, but I believe it also has a good Option-type.
Hi, I'm one of the main developers. * Right now, it looks like generated binaries will use some functionality from libc (mainly for OS access, like file reading). As with everything, that might change. * The language and compiler are very incomplete, and currently only one of the tests compiles with the LLVM codegen. The parser is much further along than the codegen right now. Personally I don't think it's ready to be posted to reddit so I was quite surprised to see this link on my front page. * I'm not sure about how serious it will become, as I'm not the creator. I really would like to see it become mature enough for low-level development though.
I'd say /u/mvtmrs answered the first two points well, as for my own view on the third point (as the initial creator of the compiler)... I'm not sure. It mostly started off as a fun side-project, and an attempt to make what _I think_ to be the perfect language. That being said, I would like to see it grow to be a more stable, mature language that could be used seriously in a production environment.
I've been hearing murmurings about of `go get` for a while now. What exactly is wrong with this tool?
`go build` becomes roulette 
[Protothreads](http://dunkels.com/adam/pt/) might be interesting to look into!
Thanks, I'll save that for later.
Scala also has an `Option` type, and its use *greatly* simplifies code relative to returning a null reference.
Go implements optional values via multiple return values. Instead of: func f() Option&lt;T&gt; {} You have: func f() (T, bool) {} As long as you don't ignore the boolean (or error) you don't have to worry about dereferencing a null pointer. In other words although the type system doesn't prevent it, the compiler does. For: x, ok := f() You've gotta do something with OK or the compiler will complain. You can still shoot yourself in the foot if you so choose, but its done a lot to prevent that from happening.
Good point. In that case you couldn't have user.User.Posts (you'd have to do something like forum.PostsBy instead) but it doesn't read as "MVC" as some people would like. I think a semi-flat directory structure is totally valid approach if you have a reasonably sized project.
Try godoc.
You can't have a package name starting with a digit in go. Try sevenzip.
No it doesn't. Use math/big I don't care.
You got a nice Go project on github. It depends on some packages that you haven't put in your GOPATH. So, you `go get` those packages. Then you invoke `go build` to build your nice Go project that depends on some packages you haven't put in your GOPATH but you just have now. Will it build successfully or not? This question is like halting problem at current state of `go get` and `go build`. Unless you invoke those, you cannot answer. I'm just kidding. In short, you cannot guarantee rebuildability using `go get` since it gets latest version of dependencies at the time of invocation. You get around this using some form of proxies and/or vendoring. 
I thought I was going to have to rag on this but I agree with this scant article except for the part about the lack of rich GUI applications which has nothing to do with the language.
Code using setgid/setsid and friends were always broken. Making a wrong program worse is no sin. The same thing will happen with 1.5's change GOMAXPROCS=NumCPU(). Race conditions that were hidden by the fact they were on a single thread will become more apparent. But the code was already broken, since the compiler only generates correct code in the face of no data races.
&gt;The less good: System-level programming Well, except where it's been [spectacularly successful](https://www.docker.com/whatisdocker/)...
All it takes to “unbreak” code is a call to `runtime.LockOSThread`.
Can you explain the difference between gb, and godep ( https://github.com/tools/godep) with vendoring but no import rewriting? I don't understand it.
I wpuld love a survey of godep, gb-vendor, nut, jd, and any other semi-popular vendoring products.
Nah, the point still holds. Docker provides a robust set of tools for manipulating and linking Linux containers, but isn't an "extremely low-level system component" like the author was referring to. If Linux container technology itself were written in Go you'd have a point.
Sorry, autocorrect :)
Its only lack of libaries.
I wrote one as well, inspired by Gom :) https://github.com/pki-io/fdm
The link doesn't work as posted because it is duplicated, but once you get to the article it is a nice read.
`Setuid()` et al apply to the current os thread process only, because it naïvely calls the setuid syscall without thought of how users would expect it to behave like the glibc `setuid(2)` wrapper. And that's a bug, sure, it makes things harder. But with 1.4 even that was removed, so once again we have code that works in one version of Go, failing in the next one. This is the second time I've wasted time on this kind of things, and it gets tiring. I hate to think how things will break when we *don't* have a compatibility “promise”.
Proper link: http://steved-imaginaryreal.blogspot.ca/2015/06/the-flub-paradox.html Go is only mentioned briefly in a single paragraph: &gt; That's also perhaps why so many words are wasted on flaming Go; a deliberately simplified, anti-theoretical language that is gaining ground, particularly in the business of writing server software. Go is like a predatory shark appearing amongst dolphins; competition for resources that also eats your babies. It is that terrible thing, a rising Blub.
Does gb-vendor rewrite deps on their way in? E.g. my project already vendors D1 at branch B1 as vendor/src/D1.B1. Now I want to vendor D2 which also uses D1. I want the tooling to walk through all of D2's files and change them to reference myproj/vendor/src/D1.B1 Does gb-vendor handle vendoring deps that use gb-vendor themselves? E.g. my project already vendors D1 at branch B1 as vendor/src/D1.B1. Now I want to vendor D2 which also uses gb-vendor and vendors D1 at branch B2. I want the tooling to realize the D1 versions are not compatible and warn me and then import the new dep as vendor/src/D1.B2 and then walk through all of D2's files and change them. But this can get complicated recursively. But I think it needs to be handled. We are experiencing something like this right now with godep and it sort of stinks. Help wanted.
Go is written in Go, so I guess you know the answer to your question.
Why? Simple `ls **/*.c` from the Go source code tree root shows that almost all C files left are there for cgo and testing. Or do you mean the assembly?
1.5 dropped C files, but yes, Go is written in Go now, and every major programming language is written in their own language, it's a sign of maturity.
You can write a new programming language in any language, for go specifically look at https://golang.org/cmd/yacc/ and https://github.com/golang-samples/yacc, also look at https://golang.org/src/text/template/parse/lex.go, http://golang.org/pkg/go/ast/ and https://golang.org/pkg/go/parser/ if you're on the 1.5+ branch you can look at the package files for source. there is also https://godoc.org/golang.org/x/exp/ebnf read http://www.amazon.com/dp/0321486811/ and research everything relating to http://dinosaur.compilertools.net/
What does "project management" mean? I don't want to sound like I disregard the effort put into the tool, but without the vendor plug-in gb just looks like a clone of the go tool sans GOPATH.
...javascript?
You have to rewrite the source or you have to have recursively deps management.
libcontainer was introduced in dockers 0.9
Its more, there is a thing, which has warm blood, 4 legs, and barks. Therefore the compiler considers it both an animal and a dog. 
Is my assumption correct, that this does not work well with tools that operate on GOPATH like the Go oracle?
Actually you're just making an argument for why "Can I write a programming language in $X" can be answered without knowing the value of $X. 
Sure, and that's why I said its mostly true.
there are multiple reasons why i wouldn't call JavaScript a mature language, considering it's a loose implementation of the ECMAScript specification that has several different vendors who all implemented it differently as a result causing very minor inconsistent issues causing for a uniformly chaotic language.
And wgo. It looks interesting and complete solution but not really popular 
If something depends on GOPATH and your gb project is not in GOPATH I'd imagine it would not work.
Go is only mentioned in one spot, but the article applies very well to "Go vs. X" arguments, where people say X is better. The point is that languages should not be judged by the number of features they implement, and that one language is rarely purely "better" than another. I like Go better than Python, but Python is better for math/science DSLs... ok. I like Go better than C, but C is better for memory constrained environments and programs that are extremely sensitive to latency... ok. There's always going to be a situation or environment (both deployment environment and development environment) where one language seems better than another. But it's not a black or white thing, and it's definitely not purely about the languages themselves.
I've always loved the Blub paradox. If you'll allow me to be snarky... Java programmers seem the most likely to suffer from Blub-itis :)
Gotta say, love the advice here (read your blog a few times). I'm curious why you chose Linode instead of an in-memory database like MemSQL?
thanks! I appreciate it! On this project the database is hosted on linode because that's originally where the entire app was hosted. It was by the client's suggesting to migrate over to heroku and I've had nothing but great experiences with it, but the only real cost effective solution for a MySQL instance with Heroku is ClearDB which is slower than our Linode instance. I tested out Google Cloud SQL and was VERY slow because they don't like you to run joins. I've actually looked into MemSQL after they announced their community edition and am hoping to look into it in the next few weeks and write a follow up article once I finish the implementation on how that process went and some stats on performance. I'm not a DBA by any degree, but MySQL managed services are so expensive (rightfully so) but it's hard to justify the cost of them at the moment where I know enough about it to get by without any performance issues.
I keep seeing the argument made that the Go team needs to bless a tool. But did Sun or the Java standards body bless Maven and then Gradle or did they just carve out their own popularity? It seems the community came together and standardized around a solution but I could be wrong.
I think it works fine if you're building binaries as the steps are pretty simple. You clone, then "gb build". Then move binaries wherever you want them. However, what if a library is a gb project. How is that going to work? I suppose you'd want to copy all of it's vendor/src to your vendor/src and then copy the library itself to your vendor/src. Maybe not so bad? "gb-vendor fetch" I think would need to be more intelligent to handle this case. Then, do you also handle converting other types to gb projects (godep,nut, etc)?
&gt; You have to rewrite the source or you have to have recursively deps management. That is correct, the project owner will have to undo that insanity before they can successfully vendor that code.
&gt; Does gb-vendor rewrite deps on their way in? No. gb does not encourage rewriting dependencies, and gb-vendor does not rewrite dependencies.
&gt; Having said all that, I believe it doesn't actually use GOPATH, the root of the project is computed every time gb is run. This is correct, gb doesn't use GOPATH, the root of the project is detected automatically.
Thanks. I've fixed that mistake
Every other tool wraps the Go tool, trying to make GOPATH work for it. Gb doesn't use GOPATH and so doesn't need to wrap the Go tool. http://getgb.io/faq/#why-not-wrap
When these things are resolved would you still expect javascript to be written in JavaScript?
Yup, that will happen. At the moment I'm reusing go/build for package resolution, but we'll write our own soon. It should be noted that go/build doesn't actually build go code, that logic is locked up in cmd/go and is not reusable. I hope this is something gb can improve on. 
I've used Docker inside a Vagrant VM running Ubuntu. It's not incredibly convenient, though.
I think the first tool to do this even close to sanely wins. Ideally it warms you and offers you choices in case of conflict.
Is this philosophical or a point in time? I was considering prototyping the logic I sketched elsewhere in this thread.
&gt; Is this philosophical or a point in time? gb-vendor will not rewrite dependencies. I think it is a mistake.
This would be nice, but is not possible. Go packages do not have versions and there is no way to query a go package's source for it's release version. This is not to say that go packages _shouldn't_ have release versions, they absolutely should, almost all of the last few years flailing around with the dependency management problem are a direct result of this.
You need to view my answer in context of the question I'm answering. In case of deserializing, say, JSON into a datastructure, the absence of a value can still only be represented by 'null' if you have a reference type, or a default value in case of a value type. I don't see how multiple return values help in this regard.
The process of vendoring intrinsically has a version, and most such tools leave that as an artifact. If I vendor a project that has a Godeps.json file, use that. Likewise the nut config file or whatever else. If I try to vendor a project that has no such artifact, consider that it is master@head. Why can't that work?
Yes and no... Go would actually have some trouble binding to most GUIs because existing GUIs use the _heck_ out of inheritance. The correct way to use a GUI is to take whatever the most complete version of the "thing" you are trying to build is (Window, Frame, TextEditor, RichTextEditor, HTMLEditor, etc), inherit from it, and customize it to do what you need. The binding part wouldn't necessarily be a problem if you create a type per original element, but programming in the GUI would become klunky when inheritance doesn't "work" properly. I say this without reference to whether this is a _good_ thing necessarily... it's just how all major GUIs work. To some extent, it's why HTML interfaces work with Go... in some sense, HTML interfaces don't much work with _anything_ compared to native UIs, with that client/web server/server boundary written so strongly into the system and causing so much trouble with anything trying to cross between, so HTML interfaces can work as "well" with Go as they do anything else. Haskell's actually in a similar place... as long as there's already that client/server mismatch that almost everybody faces, they're not particularly worse off than anybody else.
You really don't understand Go until you realize that Google wrote it to 1. Write web servers that 2. can be easily modified by huge teams 3. quickly. All the stuff that people complain about is irrelevant when one of the most important types in your system is `[]byte`. One or two goroutines per connection is a fantastic way to operate. Everything else that happens to work is almost an incidental surprise of a system that was optimized for one use case. Command-line tools in particular is an amusing result, considering how far away it is from "Cloud Server".
Gopkg.in has some well-defined heuristics for diving version. I think that perfect is the enemy of good here. If I vendor from git branch A and then vendor something that itself vendors from branch B, A and B are close enough to versions to put in front of a human and ask for a decision. I was going to try to hack this into gb-vendor, but I guess I will start elsewhere instead. I am not in love with the redundant paths of GB, but it sure seems like a better foundation than the standard tool, and your involvement lends it a certain gravitas.
You don't have to continue to include a full URL in your package names, see the examples I posted. 
The problem is, at the end of the day, gopkg.in still points you to a branch, not a specific revision. It does not guarantee that you'll get the same code today and tomorrow. In fact, it's actually worse than that, because it finds the newest minor version branch of the major version you give it, so if you ask for v2, you might get branch v2.0 today and v2.1 tomorrow. That's not to say that I don't like gopkg.in, I do... but it has some serious flaws (mainly because it is go-get compatible).
&gt; The problem I have with gb is that it completely screws with the 'everything is a library' concept in Go. Right now, most Go projects on github are a bunch of libraries glued together by a main.go or multiple Go files in a main package. &gt; This makes these packages a lot less go-get'able, while still relying on all the other things being go-get'able, so it screws massively with the ecosystem imho. &gt; Now I'm no fan of how packaging/dependencies is handled in Go, I absolutely detest vendoring, but sadly there are no other options that I know of to avoid the problems you'd otherwise have. While it's good that there are initiatives exploring options, I'm afraid that in the long run, this-one will cause more damage than it would fix. ^^ This! 100 times this! While I am a fan of Dave Cheney and his work I am very afraid that this particular project/idea/option will cause more damage than it would fix. Even worse, I feel that this one is being very heavily and aggressively pushed onto the community. We get 2-3 go gb posts every few days from the authors themselves and when new gophers ask questions about $GOPATH, they are sneakily being lead to the gb project page. Let's not forget that Go, except an awesome programming language, it is also a *programming environment*. Notice how Andrew Gerrand, in these [two](https://www.youtube.com/watch?v=XCsL89YtqCs) [videos](https://www.youtube.com/watch?v=2KmHtgtEZ1s), writes, documents, tests and distributes Go code using only an editor and the go tool. Please, pretty please, let's not forget the go values of simplicity and orthogonality. 
&gt; While I am a fan of Dave Cheney and his work I am very afraid that this particular project/idea/option will cause more damage than it would fix. How will gb cause damage? It is an _option_ for teams writing solutions in Go, along with roughly 2 dozen other tools proposed over the last few years. If it doesn't suit your needs, then you can ignore it. I have been very clear to point out that gb is intended initially as tool for projects, not libraries (although many want to use gb for libraries) because it is those projects (think juju, docker, coreos's confd, etc) that have already created their own hand rolled methods for managing their own dependencies. How is gb any more or less damaging than the splintering that currently exists? &gt; Even worse, I feel that this one is being very heavily and aggressively pushed onto the community. That is a fair criticism, I apologise if you feel my promotion of gb has been overly aggressive.
If you want a specific version guaranteed forever and always you HAVE to vendor. That said, a git sha is at least enough to crystallize an exact moment in time, even if history might be rewritten to obliterate that sha. If the vendoring tools don't help here, though it becomes an entirely manual and very painful process.
Those lex and ast packages you linked are the lexer and ast for the Go language itself, not a general package for the construction of any language. `go tool yacc` is very good, however. [Nex](http://www-cs-students.stanford.edu/~blynn/nex/) is a good choice for a lexical analyzer. I've written a very simple JS interpreter in Go and in C. With garbage collection turned off it is 3-5 times slower in Go than in C (and if the GC decides to kick in while running, woah baby). But that's kind of expected considering how many years we've been optimizing bison, lex, and the rest. Its a fun exercise for learning but it would take a lot of optimizing and a deep understanding of the Go language to make it worth writing a serious compiler in (both things the Go team has) (and neither things I have). 
An odd way of doing things but certainly not impossible. An easier task might be to just write an interpreter. When your interpreter sees a `console.out("")` in your language the Go interpreter just takes the string in there and executes `fmt.Printf("")`. Or whatever.
&gt; 1 - lots of rants about Go problems (lack of generics, the guy that after one year quite go with a very valid bunch of criticism regarding tooling, another guy saying the his goal in IT is to be away from maintaining Go code) etc etc "There is only one thing in life worse than being talked about, and that is not being talked about." - Oscar Wilde &gt; 2 - The fact that it seems Go community is actually less active, than say, Rust. As of the moment of this post, there are 41 active users here and 85 in Rust subreddit. You need to widen your net. To throw out a few stats. There are currently 1000 users on golang-nuts IRC, 2200 on the gophers slack #general channel. Over 100 Go meetups around the world, https://go-meetups.appspot.com/ (page down :( thanks meetup.com), 10 Go conferences this year, the largest featuring 1500 Go developers. Twitter #golang vs #rust is tilted much in favour of the former. https://github.com/golang/go/wiki/GoUsers. http://gophervids.appspot.com/ &gt; 3 - Lack of mention of Go in lasted Google I/O. Meh, looks like it's just Android I/O now, no biggie, we have 9 other conferences. &gt; 4 - Very few job openings for Go. (Even in Who is Hiring in HN). I don't believe this is true, North America is crying out for Go developers.
Well, technically if you tried hard enough you can write V8 natively in Node/io.js, JS preprocessors things like CoffeeScript, LiveScript, and TypeScript are all written in their own languages.
&gt;1 - lots of rants about Go problems (lack of generics, the guy that after one year quite go with a very valid bunch of criticism regarding tooling, another guy saying the his goal in IT is to be away from maintaining Go code) etc etc People complain about lots of stuff. The fact is that many people are using Go in production today. “There are only two kinds of languages: the ones people complain about and the ones nobody uses” — Bjarne Stroustrup &gt;2 - The fact that it seems Go community is actually less active, than say, Rust. As of the moment of this post, there are 41 active users here and 85 in Rust subreddit. That's a ridiculous metric. &gt;3 - Lack of mention of Go in lasted Google I/O I think Brad Fitzpatrick said something about I/O being mostly about Android. Anyway, even if it wasn't at I/O, there are conferences that are all about Go all around the world and many meetup groups. GopherCon, GoCon, Gophercon India, GothamGo... How many Rust conferences are there? People are building solid, production software in Go *today*, not just writing blog posts about the perfect language of tomorrow.
It's called bootstrapping. Think about C. Did you think that aliens somehow left a C compiler binary for us to find? :) At first, there was only assembly (and assembly is directly mapped to binary machine code). So someone sat down and wrote a basic (and completely unoptimized) C compiler by hand in assembler. But at that point, we suddenly had a compiler (not a very good one) and we could start writing a compiler for C in C, compiled by our "first" compiler. We actually still do something like this today if you install a stage 1 Gentoo for instance. It includes a binary of GCC, optimized for a generic architecture. You then proceed to compile your own GCC for your specific architecture and then use THAT compiler to compile it once again (so your optimized compiler compiled the compiler you're using now).
The thing is, how a lot of Go applications are written (mine are at least) - is you create some sort of library, and build a (relatively) small front-end for it gluing it together. The sheer amount of go libraries out-there, small and big, are a testament to that. The general aproach in Go is that you create standalone packages and glue those together as an app. The `GOPATH` has it's share of problems, but for that, it is perfect. It is one of the most underestimated advantages of Go: it encourages writing reusable libraries, pretty much all libraries are open source and easily accessible. I have been coding for over 20 years now, and this is the first language that makes diving into library code not only easy, but seem like the most sensible thing to do. I'm not sure this was on purpose designed to be this way, but it doesn't make it less awesome. What happens now with `gb` is that you enter the 'project' mindset. The bad thing is that even in this article they do a bunch of stuff, and then when it comes to libraries it's 'oh well, figure it out yourself'. There are quite a few problems with this: packages inside the project become less a standalone thing, and are buried inside another project. It means that on github for example, it would be under `http://github.com/username/repository/src/packagename`, which is a lot less accessible than `http://github.com/username/packagename`. Not only that, but who says it's even go-get'able from non-gb projects? The packages in your `src` folder suddenly don't follow the `github.com/user/repo` naming scheme anymore, so the code will not be compatible or work outside of this project - which is **BAD**. Very few people are going to write their own packages and then vendor them themself in their own projects - which is a hassle, things need to be in sync, you can't just push changes you made in your vendor dir back to the original repo, ... Even fewer people are going to look into advanced scm features like `git subtree` to organise their project source-code in a way that their own libraries are standalone. The really bad thing is that `gb` makes some things easy that ARE problems, but at the same time they unwillingly screw up the Go ecosystem, while still relying on it.
Regarding (4). After I added golang to my linkedin profile, my inbox exploded with jobs and I still get lots through. I'm based in London. 
No, we don't have code that *works in one version of Go*, your program was always broken. 
Definitely it did not happen to me - added both Go and Golang in Linkedin no results. I am based in Benelux area.
1. **"There are only two kinds of languages: the ones people complain about and the ones nobody uses."** To pick just a handful of projects and companies using Go: [Projects] *Docker, Juju, NSQ, Cockroach, Hugo, Gogs...* [Companies] *Bit.ly, Baidu, CloudFlare, Heroku, DigitalOcean, Disqus, Dropbox, Github, New York Times, Twitch, Tumblr, Twitter...* These are just the tip of the iceberg. Currently in the startup community, Go isn't the #1 language, but it is probably #2 after Javascript(Node). Obviously will take many years to catch up in popularity to much older languages (legacy has roots). 2. Judging a community by its Reddit popularity is an ill-advised strategy for making career decisions. Look at REAL projects shipping in Go versus Rust, this is profoundly unfair of course, Rust just hit 1.0 -- give it 3 years and see where it is at. Go is never going to be sexy, Go is pragmatism given form. Rust just hit 1.0 so activity is at a bit of a logical spike. Both are pathetic shells of C/C++/Java/Javascript/PHP/C#/Objective-C/Python/Ruby popularity. To view it from a different lens: https://libraries.io/ 3. Go is an open source project, not a Google project. Also, Go has its own conferences, being a part of Google I/O is irrelevant (and probably belittling and negative). Gophercon this year is likely to be the last single track one cause they are getting too huge. Gophercon in 2 months, Golang UK in 3 months, GothomGo in 4 months. You could live a fairly busy life JUST going to Golang conferences. 4. Go is an exceptionally easy language to learn, meaning you often don't need to bring in "Go specialists", you get good general developers (probably specializing in a more challenging tech) and they can also do Go, because Go takes about a week for a novice programmer to get their head around. Additionally, generally you are posting on boards like "Who is Hiring" when you are having a hiring issue. I have hired for a very hard to fill role (Erlang), and we posted EVERYWHERE and it tooks MONTHS to get the right person. Hiring for Go on the other hand has been a "just pick the best candidate and see if they are willing to learn Go". &gt; So the point is, is it safe to attach my wagon to Go? Go takes almost no effort to get up to speed on -- what are you "hitching your wagon to"? It doesn't require that level of commitment. Anyone who hitches their wagon to a single language is probably going to turn out to be a terrible developer regardless. Learn many, don't be religious about it, be pragmatic. Languages are tools, nothing more. If you only know how to use a hammer, everything will start to look like a nail. **"Learn at least a half dozen programming languages. Include one language that supports class abstractions (like Java or C++), one that supports functional abstraction (like Lisp or ML), one that supports syntactic abstraction (like Lisp), one that supports declarative specifications (like Prolog or C++ templates), one that supports coroutines (like Icon or Scheme), and one that supports parallelism (like Sisal)."** &gt; Is Google, or any other big company for that matter, willing to push Go forward and improve its market share? It doesn't need a "big company", Go is basically crushing it. I hardly could imagine a stronger place for a language that hit 1.0 about 3 years ago. It is serving massive traffic (100 billion+ a day via BFE team) at Baidu, it is at the heart of Docker, it is being used by tons of companies you know and depend on (listed above). 
When I was starting out in my career, I wish that I had more perspective on how "coolness" maps to actual career prospects. I just sorta stumbled into a Java career path... because when I came up in the late-90's, that just happened to be BOTH the cool new "hipster" trend of its day AND a legit sea change in the business world as well. For newbies today, seeing a different fad on Hacker News every other month, I imagine it all must be very confusing. So at high level, I will tell you that worrying about "choosing" a programming language is only relevant in small startups. Not even all small startups, either. In more established companies, or startups who pattern themselves after established companies, there are programming languages deeply entrenched in that type of work. * If you're doing systems programming, then the industry standard is C++. Various people hope for this to eventually be replaced by Go, or Rust, or D, or something else. But C++ has been the standard for 30 years, and there's little sign of that changing any time soon. Really, it's only relatively recently that C++ finally supplanted C. * If you're writing business software, then the industry standard is Java. C# is also a standard for companies tightly coupled to Microsoft systems, and with the cross-platform expansion taking place right now perhaps C# will rival Java more strongly in the near-to-midterm future. However, today Java dwarfs everything else in the enterprise. * If you are doing web development outside of an "enterprise" context, then there is a lot of fragmentation. PHP, Python, Ruby, and more recently Node.js. If you look for work in this field, then you will have to make more decisions about which language(s) to deep-dive with the furthest. However, even here it is not as bleeding-edge as the front page of Hacker News would have you think. Node.js for example has been around for 6 years now, and lots of people in forums like this are already bored with it and wanting to move on... but it's just now really STARTING to gain traction in the employer world as a career path. So if making a paycheck and starting a career is important to you, then you should primarily focus on one or more of these languages as your foundation. Some people will tell you to move to the Bay Area, or to hang a shingle and do freelance work, but you really need to build some experience first to be competitive along either of those paths anyway. Learn something established. It will pay your bills, and make you a more well-rounded coder with insights about the strengths (and weaknesses!) of Golang in contrast. As for which "emerging" languages to explore from there, don't worry so much about silly metrics such as who's logging into which subreddit at any particular time. Language fads on Hacker News and Reddit are *ridiculous*. Ten years ago, everything was Scala. Five years ago, Node.js was going to make the JVM irrelevant within a year or two. Three years ago, we were all learning Go. Last year, Rust became the darling. Mark my words, Elixir is going to be the next thing. What do all of these have in common? There are very few jobs available for any of them outside of the Bay Area, or outside of a job you create for yourself through freelance work (which is more about being a professional salesperson than being an engineer). I believe that Go is a strong candidate for establishing itself in the future. It cuts across all three of the industry types I bullet-pointed above, and is increasingly backed by Google (I can't remember the last time I watched a Google event in which all of the live coding demos weren't using Go). However, I'm not so hell-bent on working with any of my side languages that I'm only looking for related jobs *today*. I learn them to make me a better coder overall, and I lobby to use them for particular projects where they make sense. But it's professionally unwise (and makes you a lesser coder, also) to not have a firm foundation in some industry-standard language first.
There are more developers at Google using Go than there are users of most sub-reddits.
I've had my suspicions that this person is just a troll. They keep claiming to use Go but they're one of the first to run in bashing it in just about any area. Obviously there's nothing wrong with asking how Java's build tools reached their levels of popularity.
&gt; So the point is, is it safe to attach my wagon to Go? The simple answer is: no. You need to learn additional languages. You're probably asking the wrong question though. You should figure out what it is you would like to focus on: * What area of development (web, mobile, backend, frontend, etc...)? * What kind of company would you like to work for (small startup or giant corporation)? The area of development has a huge impact on what languages you need to know. If you are in the web space you need to learn HTML, CSS and Javascript. If you are in the mobile space you need to learn Java for Android and Object C (or Swift anyway) for iOS. If you want to work on more systems-level applications (or games) you are going to need to learn C and C++. And the kind of company also has a huge impact. Most larger companies are very conservative in their technology choices. They probably use Java, so if you want a job there you probably need to learn Java. Many small startups are much more willing to take bigger risks. In my experience they aren't only willing to use multiple languages, but expect you to be comfortable doing so. All that said I think Go is definitely worth learning. I don't know your background, but if you're coming from a dynamic language (like Ruby, NodeJS or Python) Go can help transition you to strongly-typed languages. It's a very accessible and productive language: you can get started in a few days and the actual language is fairly minimalistic. And there are also real gems in the way Go was designed that are good things to learn. Spend a few weeks reading / watching some of what Rob Pike has to say about programming and you'll be much better for it even if you don't end up using Go in your job. Learning Go will make you a better programmer.
We didn't start the flame war but we will *finish* it.
NullString is basically Option&lt;String&gt;. Generics would make it a lot more usable, as you now either need to disregard type safety, or need individual Option types for different constructs, which a (de)serializer cannot make use of. Go, should they ever introduce Generics in a 2.0 release, should eventually get rid of 'null' and only rely on Option&lt;T&gt;. You would then have one way to represent missing values regardless if it is a reference or value type. I've worked with C# the last six months. ?? was in use all the time. It also works with 'null' and not only Nullable. Throwing an exception is only done when 'null' is ambigious (in case of a Dictionary, is null the value for the key, or does null mean it doesn't exist?), and in such cases you always have a predicate you can call (.hasKey in the case of a Dictionary). In regards to JSON. Numbers are restricted to JS numbers, which are 53-bit ints or a 64-bit float. In strongly typed languages, JSON numbers can be represented as longs or doubles just fine. A slice or a map is heterogeneous if it's defined as map[interface{}]interface{}. Though you probably wan't to avoid that if you're the one defining the API. The fact that Go can have any value for a key and JSON can't doesn't really matter for Go. Go can just require every key to be used in serialization/deserialization to implement serializable and deserializable. Both Go maps and JSON objects are unordered. So the order of keys can't actually matter. Rejecting null or missing fields is ok only if you don't want optional fields.
Well, on a technical level you're on the right track then. However, from an education perspective, you run the risk of just implementing Go in Go, leaning on the fact that you're in Go, and ending up writing something that is secretly just an overcomplicated string search-and-replace that isn't really doing anything interesting, and fooling yourself into thinking you understand more than you do. If you're going to go with this approach, I extremely strongly recommend implementing a language that is in a completely different paradigm than Go. Lisp would be particularly easy, lots of discussion out there that's easy to find, and be sure to implement some form of macro to help make sure you're really doing some compiler-type work.
Learn one of these, and you'll always have a job: - Javascript/CSS/HTML - Java - C++ - C# - Python Ruby is almost in this list, but Ruby on Rails has the potential to just be a fad, so I'd be careful about banking my career on it. However, for right now, it's still a highly desired skill. You can put Swift/Objective-C in the same bucket. Engineers that can build iOS apps are always in high demand, but it's a very targeted skill that is not generally applicable, so I'd make it a secondary rather than a primary focus. Anything else is going to require some looking. Sure, for the right company, having expert Haskell/Erlang/C skills could make you a shoe-in, but for many many companies, it's not a skill they're going to even consider. Go is a great language, and I think it will explode in usage for networked servers... but it's not really big enough right now to bet your career on, unless you already have a ton of experience in other languages.
&gt; 1 - lots of rants about Go problems (lack of generics, the guy that after one year quite go with a very valid bunch of criticism regarding tooling, another guy saying the his goal in IT is to be away from maintaining Go code) etc etc Pike said go design is "done", another Go team guy in a podcast said no significant features will be added to the language. I think things are pretty clear, Go will never have generics , if this is something you can't live without, do not use Go in the hope that maybe it will get generics, or feature X or Y, it won't, period. Some People have been asking for other features for years, until they stop asking and stop using Go... Same with the tooling, do not expect anything from the Go team at that point. It seems there is a debate about a manifest format for dependencies however, I have no idea where it is heading. &gt; So the point is, is it safe to attach my wagon to Go? Is Google, or any other big company for that matter, willing to push Go forward and improve its market share? No you shouldn't. Because you'll hardly make a career as a Go developer. Go is so opinionated I hardly consider it a general purpose language. It's a missed opportunity if you ask me,but it's not the first time some people design something with potential but also a totally lack vision. Go might be a blueprint for a future language with CSP that will satisfy more developers. Tldr; don't invest heavily in Go, try to look at other potential languages , one of them might be the language of the future, maybe Rust, Nim, Crystal , but not Go.
Predictions are hard. Predictions about the future are extremely hard and error prone.
tl;dr learn Haskell /kidding!
&gt;Pike said go design is "done", another Go team guy in a podcast said no significant features will be added to the language. I think things are pretty clear, Go will never have generics https://www.reddit.com/r/golang/comments/36n8hd/go_is_unapologetically_flawed_heres_why_we_use_it/crg3maa?context=3
I agree half-baked solutions are a huge issue for go dependencies. I would suggest then perhaps you don't need to jump ship on the go tool, you just use better dep tooling. Have you looked at https://github.com/kardianos/vendor ? To get started: cd $GOPATH/src/github.com/GoogleCloudPlatform/kubernetes vendor init vendor list vendor add -status ext Now you may use the go tool normally. For kubernetes, using "vendor list" is particularly instructive in what dependencies are currently used.
I think it is very safe to attach your wagon to Go. I will go a bit controversial here and say you should go all-in on Go. Here's why: * The language spec is tiny, you can go crazy at it for 3 weekends and get a handle on all its features. * Lack of generics is never a problem at all. For custom "generic" structs, `go generate` is more than enough. * Haters gonna hate, I work at a company that doesn't advertise on using Go and yet, the entire site-engineering team use and LOVE Go. There are a lot of companies like that, e.g. Dropbox or Stripe. * Once you see high performance daemon consuming only 11MB of RAM, it's hard to go back to the past. * Once you see how trivial it is to deploy a single binary executable to production, it's hard to go back to the past. * In terms of popularity, sample sets matter. [GitHut](http://githut.info/), for example, tells a different story. Go is much larger than Rust. If you have not catch my drift, Go is very safe and you should go all-in.
Lots of great comments here - I'd read them all because they all offer great views. I'll just get to the meat of the question. Yes. Yes. and more Yes. We talk to gophers from a wide range of companies throughout the world pretty much everyday ranging from small one person consultancies to companies with over a thousand engineers in them. Companies from social/mobile startups to oil companies to banks. It's our viewpoint that Go is not only going to be a "great ride" in your wagon but it's going to become the next great language. Go is the future.
What makes this more efficient or better than the os package? AFAIK the go runtime uses epoll under the hood too, so what makes this more efficient than the native file support?
The Go runtime only uses epoll/kqueue/etc for network sockets. This package exposes a general API for using epoll/select for any file descriptors.
Awesome I'll be sure to take a look 
I've used both together. There is one gotcha with using pgbouncer. Go seems to wrap SQL in prepared statements if there are placeholder values. Depending on your pgbouncer configuration this may require the explicit use of transactions. This is true even of select statements. Just a heads up.
It's not safe to attach your wagon to anything. You get safety from adaptability. 
Original author here: Nice work! I was (still am) a go n00b and was more interested in the distributed database aspect than the language itself :P
That looks close to what I want. I am trying to work out more detailed pseudocode describing how I think it should work. I think it should be more flexible and more human-feiendly.
People interested in extracting data from consul might also be interested in the consul-template or confd projects.
The point of my post was *not* to use `c.RGBA()`. But don't worry about it.
I've been keeping a search out for "golang" in indeed postings, but haven't seen many at all that list go-specific jobs. When I *do* see it, it's in a sentence like "desirable experience with Java, Scala, Python, Golang..." What's your source, dave? 
Big software companies want their own programming language, both for prestige reasons and to cover their backside against incompatibilities against their software from the platform below. That's why Microsoft created C# and Oracle bought Sun for its crown jewels Java. It's why Apple created Swift and Google "owns" Go. But of course Google doesn't own Go, they just "own" it because they can fork and replace it at any time. There's been exceptions in the past, like Python and Lisp, but generally even IBM owned IBM/Cobol and PL1, and Burroughs owned Algol. So based on that, I'd say Google will continue backing and promoting Go if only for prestige. 
Also, it's a fair bet that every one of the GopherCon sponsors, and the speaker's employers are hiring.
And envconsul. 
I don't have any sort of bash completion setup, but I do have this snippet from Rob Pike which I enjoy a lot `CDPATH=.:$GOPATH/src/code.google.com/p:$GOPATH/src/github.com:$GOPATH/src/golang.org/x` 
Very cool!
You definitely need to check out http://kubernetes.io/ if you're thinking about migrating over. Kubernetes will make life extremely easy if you're using a mircroservice-style architecture, as it will handle scaling, scheduling, failover, etc.. Docker/Container-based systems are also what's 'hot' right now (and for good reason), and are essentially a requirement for kubernetes. Depending on what you're utilizing with GAE (datastore, etc..), it may make the transition a little more challenging, but being PaaS agnostic is extremely nice.. Good luck.
For the record this is the benchmark I used: https://gist.github.com/vmihailenco/a6ff627e8d3613b28e1e .
Unfortunately I do use datastore and memcached. Memcached isn't that big of a switch, but I do rely on datastore's "infinite scaling" when it comes to storing data. 
Thanks for your advices, some are now committed.
We use this package in production, allows our devs to not need a local consul instance to still be able to test their code, but in production and staging it connects to Consul's KV API. I think another advantage it has over `envconsul` is that your application can read them with no reloads needed. Allows us to turn on/off logging without rebooting our application.
Make questioning if I should trust the word of some people around here.
which golang MongoDB driver are they talking about? isn't there more than one?
Stop being so emotional.
IIRC, [mgo](https://labix.org/mgo) is the de-facto standard.
I guess I just have read many of these: http://blog.parse.com/learn/how-we-moved-our-api-from-ruby-to-go-and-saved-our-sanity/ Maybe fad is the wrong word. But I think it's going to start dropping in popularity at sites where scaling is likely to become an issue.
Last year I knew that Google was working on Go APIs for all their cloud services, but at the time it wasn't complete. I just had a look at the repo for it, and it seems to be a complete package, even if it's in Beta (we all know how Google are about that). You can check it out here: https://github.com/GoogleCloudPlatform/gcloud-golang
OK, thank you.
You can [try to get the core dump](http://stackoverflow.com/a/2067406/1892060) which could be useful. If this keeps happening, and the reason is nowhere to be found, it may be worth it to open an issue.
Awesome, does that mean you'll be dropping your prices as well??
skeleton is the working example of a REST API server. The link is at the top. Toy and tinker with either package as you wish to extend on that. A few starter db statements, routes, custom handlers, etc, are already included to give you a head start.
um... first line is the link... dude
That's nice! I would add UUID and SSN.
By UUID I mean [this](http://en.wikipedia.org/wiki/Universally_unique_identifier). It's useful for mocking data for DBs like Cassandra (UUIDv1 I believe) etc.
With "ei" you can chain functions, it's usefull to do middleware transformations. I just added middleware support ;)
I'm the owner of that github repo. While a fair amount of work has been done, a lot still has to be addressed. The reason the repo has been quiet since March is because the SPIR-V and Vulkan specifications were still in flux and incomplete at the time. I will likely resume work on it once Khronos settles on the final versions. Given I have a lot of other things going on in my life at the moment, I can't guarantee that though.
it's OK, I solve the prob I just put the Sinks in the main function,it was in the handler and on every incoming http request, The "stream" object seems to iterate over all the Sink instances then it add a sink on every request.
Garbage collected languages aren't terribly good at high performance graphics. If you are pushing performance (and would benefit from a higher performance api like this), any gc is going to make you skip at least 1 frame. No gc can be tuned well enough to have no pause and not slow down the application. Also, go doesn't have interfaces for memory mapped io, so you might end up having to write a lot of glue code in C or Cgo, depending on how prevalent those apis are. Goroutines are a big win with blocking io, since the runtime can keep all the cores running without threading overhead, and you can write ordinary synchronous code (no callbacks). With GPU command buffering, go routines don't matter as much since adding commands won't block. Goroutines also still have overhead, so you still wouldn't want to spawn a goroutine for every little object you wanted to render and try to parallelize that way.
everything from chance.js
Do you have any sample code for this? Do you init db connection from main(), add it to context, pass the context to handler and then pass the context from handler to your models?
Pretty much. Only difference is that the models are never passed a context - only `sqlx.Ext` (which the handlers derive from the context).
While I am no expert with graphics, I would like to point out that Java is garbage collected and there is plenty of game development done in it. As far as go, there have been significant improvements to the GC, as it is now concurrent (http://www.youtube.com/watch?v=S9Bu6fZnLGM&amp;t=1m56s). Furthermore, GC can be disabled entirely in Go.
Another No-SQL DB in the market, but written in Go. Looks a very promiscuous idea put another one in challange with MongoDB or CoachDB. Lets wait for a while and see where it goes
Shameless plug: https://github.com/eanderton/grapnel This is basically a take on Bundler/Cargo for Go, with some extras thrown in. Supports version pinning, import URL rewrites without touching your code (for coping with stuff moved from code.google.com), and will work even if gopkg.in is *down*.
And that would put users of TFS, mercurial, Perforce, SVN, and bzr where?
This totally ignores a valid use-case: I want to vendor a project (a main and all its pkgs and deps) into my tree so that it can be built and distributed alongside the rest of my project. If that project has vendors deps, I *must* retain those. What I think you are arguing is that a single binary or even family of binaries must flatten, and I think that is probably fine, but let's not ignore the case of multiple binaries in a single repo, please.
This one seems to be new-SQL.
Not everyone uses or needs vendoring. Why is this an issue?
There's already a thread: https://www.reddit.com/r/golang/comments/39fxba/the_go_tool_gets_experimental_support_for/
Three things that might be useful: * Static mappings [ host-header: blah.me.com -&gt; host1:8080 ] * naked domain mappings - me.com and www.me.com all go to marathon "me" app * TLS termination - this is really easy in Go, and would be particularly useful here with a wildcard cert. I may send a PR for some of this if I have time. Thanks for sharing!
Because you could not vendor non-git packages, and you don't control what the external lib you need uses.
Concurrent GC isn't enough (I was specifically talking about this when I said "no gc can be tuned well enough"). If you look at the slides, the goal is no more than 10 ms pauses. In order to render 60 frames per second, you need to render a frame *every* 16 ms. If you take more than 6 ms to render a frame, 10 ms will always cause a frame skip. If you are taking 15 ms per frame, a single garbage collection might make you skip 2 frames in a row. The slides also show running application code for 40 ms out of every 50 ms. If you garbage collect every 50 ms, you are going to skip at least 1 frame every ~3 frames. Java has the exact same issues. Games written in Java have the same problems with skipping frames and GC. I've never seen a java game that was sufficiently graphically intense to take more than 6 ms per frame, run at 60 fps, and not jittery. There are some ways to get around this in garbage collected languages. You can allocate big byte arrays and manipulate them without pointers (there are a few libraries that do this very performantly for simple things like caches). The lack of pointers and individually allocated objects keeps pauses really short. However this quickly breaks down when you want to do complicated things, since you have to throw away all the properties about Go you like (gc, methods, interfaces, type checking, etc.). At this point, you are better off writing in a different language. You can turn off GC, but you better not allocate anything! You can attempt to do this in Go, but it will limit the dynamic content of anything you program. If you have 1 screen with 100 monsters, 1 screen with 100 people, and 1 screen with 1000 items, you need to have all of that allocated simultaneously at all times, even though you don't use any of it simultaneously (and you ideally need to pre-allocate it, so that you don't generate garbage while appending and modifying datastructures). If you don't really care about 60 fps, not skipping frames, and doing intensive rendering, then Go, Java, and whatever else are perfectly good languages, but then you also wouldn't care about Vulkan.
Would you mind expanding on this. Go get is able to do runtime switching between multiple version control clients. What limitation is there to prevent expanding each to handle their version of submodule / externals?
&gt; You can turn off GC, but you better not allocate anything! You can attempt to do this in Go, but it will limit the dynamic content of anything you program. If you have 1 screen with 100 monsters, 1 screen with 100 people, and 1 screen with 1000 items, you need to have all of that allocated simultaneously at all times, even though you don't use any of it simultaneously (and you ideally need to pre-allocate it, so that you don't generate garbage while appending and modifying datastructures). How is this done in c++ / c# / whatever is used these days? Edit: What I'm wondering is if non garbage collected c++ == non garbage collected Go, with the exception of mature supporting libraries to tackle common game development tasks. It sounds like the issue of having to watch what you allocate (and do not) exists in either language. Are there also tools to help with this that Go does not have? Edit 2: I wonder if a quick framework around packages C and unsafe are the way to go? http://blog.golang.org/c-go-cgo. I would still very much like to hear how this is handled in a language without GC.
Oh wow, thank you for pointing this out. Looking through the repo, it's clear to me that this is not a Go project, per-se, but rather a project which builds a massive container that contains binaries built from Go source? I would expect that a flat space for 100% of all the third-party binaries would indeed be disastrous, as you have explained (and implemented). So I have to ask: is the proposed solution in the article a panacea here, or is there something else we're all missing? I say this since I've never seen anything Go-oriented at this scale before.
So is there any alternative besides C/C++ for "serious" game development? I know a lot of people use C# for gamedev, but it has GC as well (how do they deal with it?).
I have questions on the original proposal which have not been answered yet. I suspect that kubernetes is at the edge of what is normal for go, but I don't accept that it is wrong. Coordinating multiple git repos would be even less pleasant.
&gt; I suspect that kubernetes is at the edge of what is normal for go From my vantage point, that's the case. To me it looks like there's room for a more elegant solution. What is needed is some way to manage multiple dependency graphs, so you can tend multiple Go binary builds from a single point, with an arbitrary level of dependency intermixing and isolation, so you neither repeat yourself, nor alter a build's graph to fit into some bigger picture. FWIW, even the venerable Make has a hard time with that. Honestly, I don't think I've ever seen a build system that did this in a declarative fashion - it's always a pile of BASH calling to, or being called from, Makefiles and what-have-you. That said, it's certainly not fun to do it that way.
I like that idea. If someone one wanted a group of data i could populate a struct of information to return back to them. Person, Contact Info, Address, etc... Can you think of any other groups i can put together? In regards to your rand comment can you better explain? I wasnt able to follow.
Is there a better way to allow a layman to edit page content than a CMS?
doubtful! I'm just curious why you'd go with a CMS on golang vs a CMS on top of a different language thats more traditionally web friendly
Cool, thanks! Which version do you prefer personally?
Am I the only one that loathes "go watch this video" references? I don't have an hour to watch people talk about stuff. Where's a transcript? Where are the slides?
Given the announcement of basic vendor support in 'go build' what changes for gb?
&gt; I don't have an hour to watch people talk about stuff. That's exactly the reason why I linked a 10-ish minutes talk instead.
I don't have any minutes to watch a video, period. I can read a transcript or slides while in the car (wife driving) or in the crapper or while my kids are playing. Videos are a very poor way to publish one's thoughts on a subject.
Ya that looks like a great package. Ill definitely see if i can grab anything i missed. Thanks.
Awesome, thanks!
I'm going to get so much shit for this... But I think in a language like go a general CMS won't become to popular.... Build your own custom CMS per case basis 
Does it need fast storage? If so, just put some [RAID](http://www.informaticapressapochista.com/wp-content/uploads/2012/09/RaidSpray.gif) on it!
With some effort, is it well possible. There're dozens of AAA titles developed with Unity or UnrealEngine, all with GC.
Actually that wasn't entirely clear from the proposal. So if you vendor a library that has its own vendor directory, does that also get considered by the build tool?
Would you repeat that in every source file in your codebase that needs that import? What would happen if you forgot to change one?
Supporting diamond dependencies is a good thing IMO, although it may bring more code into your project, at least it's correct (see kubernetes - Etcd example above)
Super awesome.
I played with Rust and its Cargo today, I was thinking about same tool for Go as I liked it very much. And Here it is! Thanks.
You're welcome. It's very much a work in progress, and it's a little under-documented, but I'm hacking on it and improving it as I go. Feel free to contribute!
Yeah, when writing Grapnel I considered something like that. Then I learned that symlinks are not portable to Windows, nor do they work on shared/mapped directories between Windows and virtualized environments (like Linux running within a VM). I think this is why everyone is all about "vendoring" since it's the only portable solution, without forcing everyone to download their own copies of dependencies - which is problematic with `go get` since it only knows how to get HEAD instead of the version the author intended.
You can override methods just fine: http://play.golang.org/p/SaFNwVSsQC
&gt; since it only knows how to get HEAD instead of the version the author intended. Fixing that sounds like a better approach.
Go is web-friendly. But, I can give two reasons - security and performance. e.g. Wordpress doesn't have a good track-record on [security](https://blog.sucuri.net/2015/04/security-advisory-xss-vulnerability-affecting-multiple-wordpress-plugins.html) nor performance, many other share the same problems. Although, this is mainly an implementation issue - but it seems it's much easier to make security/performance mistakes in PHP.
I think its easiest to understand Mesos and Marathon by checking out their websites: https://mesosphere.github.io/marathon/ and https://mesos.apache.org/ but you can see them as your own container hosting for distributed systems and micro services. Problem is neither of them really offer a good proxy/load balancer right out of the box. There are other 3rd party solutions but many of them require a bit of work to run. Moxy would just be a single binary that you start and that's it pretty much. It listens to events (changes) inside Marathon if applications are started/stopped/moved/etc and directly updates its configuration/proxy settings on-the-fly. Every app would live under its own (sub)-domain and that would be the way Moxy would proxy its traffic to the different apps. Not sure if this answers your question :) 
I run Docker in development. I'm writing a NodeJS app and I installed Node and some other dependencies and created an image. When I develop I fire up a container, mount my source in it and start a webserver in the container so I can visit the app. I start another container, mount the source in it to and start a grunt task which watches for file changes and recompile my app on change. This works because the source of the app is both mounted in my 'webserver' container and in my 'autobuild/autoreload' container. The interesting part of my Dockerfile: RUN apt-get update -qq &amp;&amp; apt-get install -y -qq \ ruby2.2-dev # For compiling SCSS to CSS. RUN gem install compass RUN npm install -g grunt-cli bower COPY tools/ /root/tools The `tools/` directory contains a little script to install Node and Bower packages. During development these packages change often and I don't want to rebuild the whole image when I add a new package, so install them afterwards. When I add a package I run the script inside the container. #!/bin/bash # Install node modules and bower packages. set -e # NPM failes to run this as a 'postinstall' command inside Docker container. # It failes with: # npm WARN cannot run in wd @ bower install --allow-root (wd=/data) # Therefore must be ran manually. bower install --allow-root npm install grunt build 
Thanks a lot, but a few questions regarding your points: * Static Mapping - I guess this is meant for apps running outside Marathon? * Naked domain mappings - you mean matching in the style of .***me.** ? To match www.me.com and me.apps.example.com? My idea was to match based on app.domain.com to make it in style with other PaaS solutions like Heroku. This would easily permit you to just add a wildcard dns entry (*.domain.org) and point it to the proxy IP and you would directly have all possible sub-domains available for apps. * TLS termination - this could be a nice optional feature for the people who wants to eliminate the extra step of putting a second proxy in front of moxy just to terminate SSL/TLS. Regarding the domain part I also thought of adding the possibility to parse optional ENV variables from Marathon were apps can specify custom domain mappings. In case you don't necessarily want your app-name as the domain name. Thanks again and PRs are always welcome! :)
Nice work!
It's not intended to replace godep. The idea is that you can still use godep to manage what is inside the vendor directory (keeping track of the version of each repository, updating them and so on). The difference is that your users will not need godep to build your project and that godep (and other tools) can be simplified.
"The syscall package is therefore outside the purview of the guarantees made here." https://golang.org/doc/go1compat
I don't know about a "CMS" per se, but I think something like ActiveAdmin for Rails would be really useful. i.e. something that lets you define your models that users can edit, and lets you use any database.
make the compiler barf on multiple versions of the same package being imported?
Typically, assembler is specific for each architecture. I think what RP is saying, is that they have their own custom assembler that can be compiled to machine code for different architectures. See https://golang.org/doc/asm &gt; The most important thing to know about Go's assembler is that it is not a direct representation of the underlying machine. Some of the details map precisely to the machine, but some do not. This is because the compiler suite (see this description) needs no assembler pass in the usual pipeline. Instead, the compiler emits a kind of incompletely defined instruction set, in binary form, which the linker then completes. In particular, the linker does instruction selection, so when you see an instruction like MOV what the linker actually generates for that operation might not be a move instruction at all, perhaps a clear or load. Or it might correspond exactly to the machine instruction with that name. In general, machine-specific operations tend to appear as themselves, while more general concepts like memory move and subroutine call and return are more abstract. The details vary with architecture, and we apologize for the imprecision; the situation is not well-defined.
&gt; Same with the tooling, do not expect anything from the Go team at that point. Two days after your comment, the Go team is proving you wrong by announcing that the go tool will support vendoring of dependencies, with no modification of import paths: https://groups.google.com/forum/#!msg/golang-dev/74zjMON9glU/4lWCRDCRZg0J They listen to the community, and they constantly improve the runtime and the tools.
The guy typing on his keyboard during the talk, and near the mike is so annoying...
Env style variables aren't a bad idea for domain names - jwilder did one like that for registrator/consul. Static mapping - yes for apps outside marathon. I may have some that run standalone, and don't want to run multiple proxies TLS termination will make things pretty complicated, so it's probably only useful when there's a single domain and wildcard dns entry. Thanks for this! 
Part of the link is missing.
&gt; TLS termination Added support for this now. Also made some refactoring and config is now set in a toml file. :)
I understand now, it's some good ideas and should not be that difficult to implement. Will put that on the list!
Yes, the library will use its own vendored dependencies. But the app depending on the library will not. It's by design in Russ' proposal. If you want to make sure you have only one version of each dependency, then you have to "flatten" them by searching for all vendor subdirectories and merging them back in a vendor directory at the root of your app.
I was excited until I saw the GPL license. Please consider something more permissive. 
ASM is the lowest level but the least portable.
I would say #2. The brackets make it so your indentation is not syntatically relevant, which is good as indentation is formatting and formatting should not be syntax, formatting should be something you can freely change in your editor to suit your personal preference or editing environment. Someone on an 80x25 terminal might want to set their ts=2, someone editing in a web based IDE might want to have hard tabs represented by a pretty indent.png or whatever they want..it shouldn't change the functionality of the code. You can also freely re-order the bracketed code without having to manually fix the indentation. For that matter, you could just not indent it at all and rely on ~~gofmt~~ pseudocodefmt to indent it all for you. 
&gt; Progress takes forever with circuitry. Circuitry shouldn't dictate assembler syntax. We can improve assembler syntax/tools without having to change CPUs.
The biggest problem with gopkg.in is that it's Git and GitHub specific. :(
Too bad I also have a package named "goble" that also does BLE stuff :) http://github.com/raff/goble 
Note to myself. "Search available packages before reinventing the wheel" haha :)
Not that I'm aware of, no. And not for other languages, either. I considered something like that at one point, but it seemed like it would accelerate the possibility of conflicting imports, accidental or otherwise. After all, there are innumerable import statements in a given program. A central config file is harder to screw up, IMO.
It will be added in future commits. Maybe over the weekend when I finish writing api and doc :)
&gt; There’s one more related problem with forking: suppose we also depended on a package that depended on goamz, for example, https://github.com/ryansb/af3ro. If we don’t do anything more, af3ro would use the original goamz, which would lead to two copies of goamz’s s3 package in our binaries. This might work, or it might not, depending on how that package works, but either way it’s wasteful. To avoid duplicating that code, we’d have to fork af3ro also and rewrite its import paths to use our forked goamz. You really don't ever have to rewrite imports if you don't need/want to support go-get. All you have to do is make sure the code you want to use for goamz is in $GOPATH/src/github.com/goamz/goamz and go build will Just Work™. It doesn't know or care how the bits on disk got there. You just git clone your own goamz repo into $GOPATH/src/github.com/goamz/goamz (or git remote add, etc) ... bam, now everyone importing goamz imports your code. That seems less confusing to me than having code that says it imports "github.com/goamz/goamz" actually importing some other code that does not live in that directory (or even worse, having import statements that bear no resemblance to a real URL). It also means there's zero work to do at compile time other than compiling the code. 
real programmers code in binary ;-)
It's more like "assembler"/"machine language" is a textual notation for the instructions of a particular CPU architecture. It is by definition not portable to other architectures. It *is* the lowest level in the sense that it maps more or less directly to the bit patterns fed to the silicon. Assembler will never go away as long as we want a textual representation of machine instructions.
Then there aren't any real programmers anymore.
I gave Kubernetes a try both on a manual install on GCE and by using Google Container Engine (GKE). Compatibility issues on GKE bit me (I tried to go from v1beta1 to v1beta3 replication controller specifications) but the local install worked well. Even survived a few etcd issues I had.
Don't expect good Cocoa bindings for Go. It's possible to do but the mismatch between how Cocoa/Objective-C sees the world and how Go sees the world means that bindings will be slow, tedious to write and awkward to use. Consider calling a simple Cocoa function like [NSButton setTitle:"foo"]. In Go, strings are binary blobs (possibly in utf8, but that's not enforced, so you really don't know the encoding). In Cocoa, strings are UTF 16. In a hypothetical Go binding, if you do button.setTitle("foo"), "foo" has to be converted from byte string to UTF16, which is expensive (compared to function call) and you need to write a wrapper that does this conversion for every function that takes NSString as an arg. That's a lot of wrappers. This is only one example of Cocoa and Go mismatch. Cocoa is an object-oriented, dynamic runtime. Swift was explicitly designed for Objective-C/Cocoa interop. Go wasn't. 
If you want to join just put your github username on the comments Thanks
GB (http://getgb.io) is really really close to the 1.5 model. GB currently requires a src directory at the root of your code, and a src directory at the root of the vendor directory, and doesn't support multiple vendor directories the way the 1.5 spec does... but if your project works with gb, moving it to 1.5 vendoring would just require removal of the src directories. so gb would look like: $PROJECT/src/root_of_your_code $PROJECT/vendor/src/github.com/foo/bar etc and 1.5 would look like $PROJECT/root_of_your_code $PROJECT/vendor/github.com/foo/bar etc 
The author has been around for awhile. Sometimes the author takes breaks (works on other things) and sometimes I think he just doesn't always push to github right away. There are a few outstanding pull requests, but not a huge amount. This isn't a javascript framework. Ask you question again in six months if you still feel it is an issue.
I'm the creator of https://github.com/gographics org and https://github.com/gographics/imagick binding. What about moving repositories to gographics and using it as your community? I'll give you ownership, off course. The imagick binding received many contributions from other guys, including a guy that works for Weta Digital, which is a well known FX company. BTW I really liked your logo and community name. We could use both for the "gographics" org.
While I agree with the author on most of the points, it feels like the entire post could have been reduced down to "Go is going to succeed because it doesn't suffer from syntactic diabetes". 
As someone who has admittedly drank the koolaid on the design principles of Go, I think that there is a moment when certain people just "get it". I find that programming language background has some thing to do with this. I came from doing python for years as my primary, and a lot of the " zen of python" carries over quite nicely into Go. However I also have a lot of older java heads on the team, and they simply don't see the benefit of having a simple language with less features when you "could just build it in java". This jives a lot with what the Go team saw when people started adopting it. They expected more C or C++ guys using it, but found a very high amount of python shops picking it up. I think this is because those people have a background of dealing with a high level of complexity in code, and after so many years they would rather have that then trade in some features, mostly around keeping your code more DRY. I used to miss generics a lot, but have come around to having more boilerplate code, and that not necessarily being that bad of a thing. It alleviates a good amount of bugs that come from having generic programming, and really doesn't affect understanding the code in a negative way. One thing I would like to see is a dynamic scripting language interpreter or integration, kinda like lua with C, where I could do a quick prototype for new features and not have to worry so much about marshalling data types. Quick prototyping is a very powerful tool for business and I'd really like to see the team address it. 
I'm ready for all the downvotes that I'll receive for posting this here, but for me the syntax in GO seems really weird. I really gave it a chance and tried to learn it but the syntax turned me off. I would take Java, C#, C++, Python syntax anyday over what GO has. Just my personal opinion.
love/hate ratio of programmers using Go?
I found it weird at first too because I was so used to Python, but Java? C++? No. Shoot me. 
Maybe this is it for me too. Maybe I haven't spent enough time with it so it can start to make sense.
For example, := vs =; if/for not having the (); func - why not function, do we really save that much time/space with four letters less? Any IDE/Code editor has autocomplete for this. And on overall first impression. I'm sorry I'm not able to give more constructive feedback.
Not exactly a CMS, but perhaps Algernon (https://github.com/xyproto/algernon) can cover some of the use cases? You can write self-contained dynamic web pages using Amber (easier to write than HTML) and Lua. 
I didn't find those weird but I did find the trailing type declaration weird at first. But soon it made sense to read things that way. This is a function/variable and it returns/is of the type X.
My ideal programing language would be statically typed Python so something with Python's syntax but Java/C#'s performance.
No, they really don't, and some people prefer not to use auto complete even when it is available.
Getting caught up in syntax is kind of silly. Would you level those same complaints against LISP or Haskell? Because I assure you those are incredibly powerful useful languages.
I have been working on Mongolar for some time now. It is getting close to a full release. Just making the data exchange from post and from the DB more sane. Mongolar will easily be extendable, and it will have a command line interface called kahn. http://mongolar.org/ https://github.com/mongolar/mongolar
My colleagues find it baffling that I don't use an IDE for anything outside of Java. I think for some people, an IDE is The One True Environment
I don't use an IDE either and I never missed having one. I prefer to understand what the commands I type actually do; an IDE is doing too much magic for my taste.
Well, many IDEs also set up a build system for you and integrate features to build GUIs. You end up with source code and configuration files the IDE wrote for you. If you know the IDE very well you can understand why it wrote these files in the way it did, but you often don't. I prefer not having features I don't understand and not having magic to having magic and cool features but being unable to understand my own project. Also, using an IDE often makes it harder for other people to work on your code because depending on what features you use, they might need to use the same IDE just to work on the code.
&gt; I used to miss generics a lot, but have come around to having more boilerplate code, and that not necessarily being that bad of a thing. It alleviates a good amount of bugs that come from having generic programming, and really doesn't affect understanding the code in a negative way. I don't think Go is a bad language at all. I like most of it. But I do think the lack of generics (or some analog for generics, and no, code generation doesn't count) is a flaw, and I think your answer is bordering on Stockholm syndrome. How is having *more* boilerplate code reducing the number of bugs? More lines of code usually means more surface area for bugs. And when this boilerplate is typically a result of copying and pasting function definitions, the odds for bugs go way up. Subtle bugs resulting from missing a change when copy pasting affect even the most seasoned developers. [Check out this blog post from intel](https://software.intel.com/en-us/blogs/2015/04/22/the-last-line-effect). So you're raising the odds of bugs bugs both by increasing LOC and using an "out-of-band" technique for duplicating code (either copying and pasting and forgetting to change something, or using some sort of code generator which fails to take into account a change and results in a bug you can't actually see in the source). And even if those things *weren't* true, generic programming is easier and faster to read and to write. &gt;It alleviates a good amount of bugs that come from having generic programming What sort of bugs are you referring to?
There is a bit of an anecdote about on of Google's founders suggesting them use func instead of function. They also wanted to create a language that didn't need an ide, if you need an ide to do something why is it in the language? 
&gt; It alleviates a good amount of bugs that come from having generic programming Like what?
That will be awesome and I really be glad to contribute with the logo and name, I know that all the projects are still WIP but the point is to build something cool around those ideas 
I may not understand what you mean in regards to a "C and Lua" scenario, but there's https://github.com/Shopify/go-lua which is an implementation of Lua in Go. I haven't tried it before but since Shopify is using it in production, I assume it's decent.
Every language you mentioned has dramatically more complex syntax than go.
Don't worry, you'll always be downvoted for entirely subjective opinions. Nothing wrong with your opinion but you could try to at least back it up.
I'll agree with it being similar to `int`, but I also think that the words "begin" and "end" are pretty arbitrary. When I used the word "standard", I wasn't referring to a literal language standard.
Well, `begin` and `end` were used by languages like pascal before the conventions from BCPL took hold in language design.
No, I'm aware that they're actually used in a number of languages, they just seem more arbitrarily-chosen than `function`. I don't know, this stuff is all pretty subjective anyway.
Nim and Crystal fill that role rather well. 
I simply meant the ability to write a code module that has dynamic/weak typing and can be natively interpreted by Go. This may already exist and I may be ignorant of it. I haven't found this, however, and I'd like a solution that was endorsed by the Go team. 
Yes, but mgo is the one listed on mongoDB's website. 
Your English understanding is correct. Doomed to is usually for bad things, whereas "Destined to" would be the positive equivalent. The title comes across as a little odd, which is an intentional poetic choice by the author. Now I'm thinking aloud. Why does this title work? I think it's because "destined to" still implies active effort, while something that is "doomed" does not. Someone who is destined for greatness can fail, for example a basketball player destined for greatness gets injured or a student gets mixed up in drugs fails out. Something that is doomed will have the bad thing no happen no matter what. If you're doomed to fail, even if you're awesome there's nothing you can do. So, saying that "Go is doomed to succeed" implies that no matter what steps Go takes, it is going to succeed. Doomed does cast a negative shadow, but that's the poetic license. 
I'm with you, it took me three or four tries to really see what Go was doing. The first time i quit because it enforced K&amp;R bracing. Who does that? Who makes a *bracing style* something that's language-enforced? The second and third times I quit because I just couldn't handle other odd things. It was always something with Go, something enforced that didn't jive with how I thought about code. I hated it. But I could never stop thinking about its good features. The concurrency, error handling, the `defer` keyword, cross-compilation, static compilation to real binaries, and so on. I just kept thinking "this would be *perfect* if it was just a little different*. But I eventually realized that there is no "perfect", there's only a tool which does a certain range of tasks. And Go does tasks that Java/C# and perl/python/ruby have been doing, but it does them far better (and more natural) way than any of them. Just my two cents. I hope you give it a few more shots, and give it time. Maybe you'll have the same experience, there really is a lot to love about it.
Thanks a lot! Your comment blows away my confusion.
Doesn't marathon "ships with a simple bash script that pulls the set of services from the marathon api and updates an HAProxy config." ? http://blog.factual.com/docker-mesos-marathon-and-the-end-of-pets
This is possibly not the best argument against Generics, considering it almost immediately goes on to use an example of modern Java - with generics - to do something that wouldn't be possible without. The argument made - holding off on a feature for a language until you can be sure you're doing it right makes sense. But that doesn't mean you should actively fight against the concept of generics. That's just sticking your head in the sand. It's a limitation in the language that was very intentionally left out because the expected use-case didn't really need them - but for tasks that *do* require Generics, Go falls flat very quickly. It's as simple as that. tl;dr Stop trying to position generics as a bad thing, and instead accept Go for what it is and isn't. The lack of generics *is* a major, showstopper, crippling problem for some types of code, and completely irrelevant for others. 
I use SublimeText which has autocomplete for most of the repetitive things.
I guess you never wrote some code with IntelliJ. The live checking for errors as you type or how it can refactor the code is amazing. I mostly use SublimeText but you just can't deny how amazing IntelliJ is.
I will definitely continue keeping my eye on Go. 
I don't want live checking for errors. I had that with previous IDEs I used and it was one of the first features I turned off. When I'm writing programs, it can take up to half and hour before my code compiles again because I'm adding a lot of stuff and parts of it aren't finished. It's super annoying when an IDE constantly interrupts my programming flow with warning messages because I cannot ignore those. Yes, I know that this is not going to compile. It's going to be fixed up in 10 minutes when the corresponding part of the program is done. Don't annoy me. Refactoring is useful and if there was large and tedious refactoring going on, I might use an IDE just for that task because I like to use the right tool for the right job. More often than not, `sed` is a fantastic tool for refactoring, too.
&gt; And how is "fmt.Fprintln" easy to read? I guess "fmt" stands for "format". I don't know what the F is for. "Format"? Seems redundant. "fmt" is very *Unix-y*, *we have no vowels to spare* style... :p &gt; The naming scheme [...] C# uses upper case for methods. But in any case, most of your points boils down to what you are personally used to. I don't know if upper case for methods and functions is less or more readable: maybe it's a wash. Personally I'm more used to lower case.
I just don't understand why you wouldn't just take an interface type with a declared method structure in your example. I guess it's just a different way of looking at things but I would prefer to have the methods that accept my parameters to have a defined type. If you have a futures object that needs to call a method, just describe it, yo! Take the two seconds it takes to think about your overall architecture to think if this object should have a defined method type. You know, it sounds like the same type of people that hit you on not catching the correct exception in your try block. If you cared so much about the exception, then declare it properly. I guess I don't understand the need to abstract every single line of code. Guess what, you're probably not that great at writing code, just like every other human being, ever.
f in Fprintln is from file (file print line), so you see that it's not that readable. My comment was not about fmt (even tough this way of abbreviating it also seems a bit weird to me), it was about Fprintln. And I agree the maybe most of my comments boil down to just the way that I was used until now with all other programming languages and I suspect it's not just me. Many others might be turned off by things like this. If they would've just tried to have a syntax more close to other programming languages or at least don't abuse abbreviating things it would've been much easier for more people to get into GO.
And Facebook. 
Lisp has a minimal syntax but it is not used by the majority of programmers.
The functionality of go build is very simple and completely documented. The same cannot be said about the build mechanisms employed by many IDEs.
Even "goviewer" would have been a lot better. What matters is the repo name, which resembles the project name, not the organization/repo name.
Syntactic diabetes means too much syntax sugar. What languages have too much sugar, in your opinion?
"begin" introduces a block or section and "end" ends it. I guess you could call it "commence", "start" for begin and "fin" for end, but I don't know... "function" isn't really a function. It's a block of code with a single entry point and I guess a single exit point that can have arbitrary side effects, and may also return a value. It could also have been called "subroutine" or "procedure". So in that sense it is also an arbitrary name.
i find it weird too - but more so because go looks similar enough to c , and c does it the other way around. not just c, but many others. it feels like reinventing the wheel, and i find this the most annoying thing about any language, none more so than pythons printf wannabe
the traditional () makes it more readable. at the very least it is more standard. why the silly need to replace if ( cond ) do_something with if cond {; do_something } makes me grind my teeth
Do you have any example code of using context.Context and sqlx in this way please? Very interested in how this all fits together.
Most of the fmt package inherits naming style from C. They did not just make up bad names, 
&gt; if/for not having the () Having the () is very C-specific, and all languages trying hard to look like C included this oddity. You won't find such a thing in Python (which you mention), ML languages, Lisps, Erlang, Lua, Pascal-like languages, ... Fun thing is, I think Go's syntax looks weird because it tried to escape from C syntax but... well, nowadays a languages cannot succeed if it does not have pairs of { } everywhere, so... They had to do it. Consider Go is a Pascal with { } instead of begin-end and without colons between var names and types, and you won't find it weird anymore.
'function' is arbitrary too. It could be 'procedure' (languages that use begin/end tend to make a distinction between functions and procedures). Calling 'function' something that performs a side effect but produces no result is very arbitrary. It could be called 'routine', 'subprogram', 'lambda', too, as languages used to do in the past.
http://blog.gopheracademy.com/gophers-slack-community/
... so, notice anything similar in Part 3 of [this books](http://www.uml.org.cn/c++/pdf/DesignPatterns.pdf) table of contents? I'm searching this text in vein for the use of the word "java"
http://ecs.victoria.ac.nz/foswiki/pub/Main/TechnicalReportSeries/ECSTR11-01.pdf comes to mind if you'd prefer something in English. Note: it's pretty old and mis-characterises some language features in it's initial discussion.
Go is similar enough to Java that there is going to be some carryover there. The flip side of [doomed to succeed because it's so simple and that's great for large teams](http://www.reddit.com/r/golang/comments/39pnt7/why_go_is_doomed_to_succeed/) is that there will be a need for design patterns. On the other hand, the language is also different enough that the design patterns may require some thought and a blind port from the Design Patterns book isn't necessarily going to be a good idea. For instance, the Design Patterns book was based on a language that didn't have closures, and a lot of the design patterns are in whole or in part a way around not having closures. A casual examination of these suggests to me that this is just a blind port. Also, they may not all be implemented correctly, even on their own terms. [Facade](https://github.com/monochromegane/go_design_pattern/blob/master/facade/facade.go) seems to be missing holding references to the things the facade is a facade over. i.e., PageMaker really ought to be holding references to a database and an mdWriter, and the MakeWelcomePage ought to be using those references. Again, the actual implementation present there is simply a plain function masquerading as a method on an empty type.
Meh. There are a hundred things I *hate* about Go (both syntax and semantics) but this is a really trivial thing that you get over pretty easily.
What does the fox say?
I don't have any specific projects, but I have a few github repos that might be useful for web mapping: https://github.com/paulmach/go.geojson https://github.com/paulmach/go.vector_tile and https://github.com/paulmach/go.geo which has basic operations on points, lines and paths. A project that is mapping related and uses concurrency to parallelize the processing is https://github.com/paulmach/slide Yes, a shameless plug for my code, but you might find it useful as a starting point at least.
A factory of factories, how *bourgeois*!
The first option looks perfect, thanks! I didn't realize From() accepts join statements.
Those types of interfaces seemed pretty common as I flicked through
And yet there is uintptr.
To quote from the text of the GPL: """ This General Public License does not permit incorporating your program into proprietary programs. If your program is a subroutine library, you may consider it more useful to permit linking proprietary applications with the library. If this is what you want to do, use the GNU Lesser General Public License instead of this License. """ Feel free to read the entire thing and decide yourself.
**uintptr** could be **uintp**. Of course, **uintptr** is bad designed, but that does not mean that **fn** doesn't would do ugliest Go.
Sure, there's some measure of thought behind every oddity in Ruby (even rspec!). But the point isn't "this was useless", the question was more "why are any of these necessary?" There's no need for blocks, just have function pointers (or delegates); JS and Go are very readable (and writable) with that model. There's no need for `if`/`unless`, just use if and the universally-recognized `!`, *every other language* does very well with that model. Other languages do the same work without the unnecessary distractions, and they're easier to read and write because of it. There's too much cognitive overhead with bloat like the above. I already need to keep a mental model of my structures, data flows, and overall business logic, I shouldn't need to keep piling on language syntax and "gotchas" on top of all that - the language should *enable* me to write good code, not make it harder to keep everything in mind and encourage me to write an unmaintainable mess of implicit contracts and obscure features. &gt;Even C has syntactic sugar Immediately before I noted that "Other languages all have a certain amount of sugar", I wasn't saying C was free of it. Only that it's much more reasonable than other languages.
http://harmful.cat-v.org/cat-v/
&gt; There's no need for blocks, just have function pointers (or delegates) I have to disagree here. Blocks serve a specific purpose, and while they are (ab)used a lot for DSLs, they recognize the need to regularly pass a single method to another method. I actually find the syntax easier to read compared to other languages (javascript comes to mind, python with its very limited lambda), it's just so easy to lose track when doing stuff in e.g. js. I do a a lot of data processing, and writing it in a functional way is very nice in ruby. I like C#s way with `x =&gt; x % 2 == 0`, but that still is in the method call list. It's just so easy to navigate if you need to supply additional arguments, e.g. with reduce: arr.reduce(1) { |result, current| result *= current } instead of arr.reduce(1, (result, current) =&gt; result *= current) Just go by the parantheses and you know exactly where the processing happens. I actually do miss this type of thing in go, but it's not made to be functional. No contest regarding the unless. I always found it ugly. And even regarding everything else you said, I can see what you mean, I just don't agree with it.
&gt; Outside of OP, who's trying to position Generics as a bad thing? I'm sure the majority of Go users are aware of the limitations and accept the trade-off, but there's a very vocal subgroup that argue to the death that Generics are a bad thing every time the issue comes up. It's almost become a trope at this point. &gt; Also, do you mean "Generics as Java has them" (which arguably is a bad thing), or "Generics as type polymorphism"? Generics in Java are still better than no generics. They screwed up variance, but for the most part it works well enough for typical OO code. Parametric polymoprhism is certainly implemented a lot better in, say, Haskell - but this doesn't mean that Java generics are so flawed as to be better off without them.
Ok. Giving permissions in 3...2...
This was an enlightening thread. Thanks! The [Go Concurrency Patterns: Pipelines and cancellation](https://blog.golang.org/pipelines) link within the thread was an interesting read as well too.
I find myself doing this in long chains of map/filter in JavaScript and Haskell. Declare your transformation up-front, then declare all the specific implementations below.
All keywords should follow a same pattern. Your example about `fmt` is not valid because is a package, not a keyword. No matter it is well known, a good design should have consistency. An example of poor consistency is the english language, which grabs too many words from other languages (`museum` is a latin word, `unique` is a french word, ..). Languages with strong consistency can be any latin language like spanish, french, italian, etc and all them are known by its good design because most of its words are translated from a vulgar latin following a specific pattern. For example, in the spanish language a `tweet` is translated to `tuit`, and this has its own verb which is `tuitear` (`tweet` in english). Therefore, each language must have its own pattern (and if it should create new abbreviations, so be it for good design).
&gt;However I disagree with the sentiment that more code provides more "surface area" for bugs. Code isn't a surface area, nor should all code be treated equally in terms of risk assessment. I'm going to disagree with your disagreement, but don't really care enough to argue the point. Additional totally redundant boilerplate is all negatives and no positives, and absolutely can introduce bugs. Not all LOC are equal, but more LOC when you don't truly need it is a bad thing. &gt;If you have code that is for an object that is-mostly-but-not-really-like the data object your are working on, you have a problem. One problem right now is that there are many Go libraries and applications that *do* need to operate on something generic, but their only option is to use `interface{}` which is far less safe (and probably less performant, since you have to type check and type convert at runtime) than a reasonable generic implementation. You will see lots of "idiomatic Go" out there accepting `interface{}` function arguments. Yes, use of generics when dealing with complex types could potentially introduce further bugs if you're not careful. But consider the following cases: * What if you want a function that involves basic arithmetic, and you don't care what type it is, but you know you need to operate on int32, float64, etc. You have to write 4 separate function definitions; possibly 8 definitions if you want signed and unsigned. If you have any idea how arithmetic works on both ints and floats, then pasting similar functions 4 times is definitely going to be uglier and more bug-prone than a single generic function. * What if you want some sort of dumb container type to hold arbitrary elements? This container doesn't care about the implementation details of what it's holding, so there's no real risk of generic-related bugs. Developers should have the option of generics. The fact that some experienced Go devs already abuse `interface{}` to approximate generic functionality is probably the strongest argument that people want this.
As the original video said repeatedly, that may not be true *today*. Language design is hard and fairly permanent (at least if you want to be considered a "real" language and not just an academic toy, something scala flirts with heavily). I guess I'm looking for someone who wants generics badly enough to actually modify the compiler and show us all what that looks like. In abstract, squint-hard-but-ignore-the-details land I totally agree that generics are great. Like libertarianism, I've yet to see a workable plan from where we are now to where people want us to be. As to Java, well, that's arguable to me. Generics are great, but erasure makes meta-programming far more challenging, and makes many other features more complex (thankfully, the presentation linked talks about ways they're alleviating some of the warts). The bigger problem comes in when you're talking about *all* of the features generics bring ( the ? operator, for example : https://stackoverflow.com/questions/897935/when-do-java-generics-require-extends-t-instead-of-t-and-is-there-any-down ). The idea of being able to have type information inside collections is the 99% use-case. It just drags a ton of baggage along with it. I'm willing to wait.
Aha ! Thanks it looks interesting :)
"prolific" could even be an understatement - if(cond) is in C,C++, Java, C#, Objective-C, Scala, Groovy, Perl, Awk .. and even that bastard child from the union of mute and a blind, Javascript. That's a big footprint ... imho, i find C syntax is very readable. The fact that it is often used in low-level situations, where minimising resource requirements is paramount. This means a program tends to be more verbose that say Python .. but this shouldn't be confused with a restriction in the syntax. 
i cant believe how cool this is :D
I think we can all agree that lisp is easier to read than perl. 
&gt; I just don't understand why you wouldn't just take an interface type with a declared method structure in your example. In that case, wouldn't you have to cast the actual type you wanted back out of the interface type anyway?
`alias ccat='pygmentize -g'` I consider dogs better than cats, so I do `alias dog='pygmentize -g'`
Try downloading the latest version of bcrypt from https://go.googlesource.com/bcrypt.git
&gt; This General Public License does not permit incorporating your program into proprietary programs. Of course, it doesn't. It applies to the "covered work", but doesn't change any source file license.
Yes, but in that case, you're wanting a pager, aren't you.
Not necessarily. Perhaps I'm not in a terminal multiplexer and need to see something from a file for a command's arguments. I'm not saying that this utility is filling a void that's been empty for far too long, what I'm saying is that there's a use case for it and "why did op even bother" is criticism without any constructiveness behind it.
Why check if the stack len is &gt;= its cap? By definition, the length can never exceed the capacity.
Ah cool. I think I'll wait until someone does a fairly hardcore review of it first then :D
Neat!
I tried running some of the examples on the go playground, like http://play.golang.org/p/ioPFvWslUs &gt;Error while loading "/tmp/sandbox453356728/a.out": Cannot open NaCl module file Using the wrong type of nexe (nacl-x86-32 on an x86-64 or vice versa) or a corrupt nexe file may be responsible for this error. The go playground isn't really the place to fuzz-test your code, but that seems like a weird error to get. edit: Also, I guess I should comment on the actual article too -- great work. I had no idea this existed and it looks like something that will lead to much better tests, so thank you for sharing.
&gt; **func**tion (and not **f**unctio**n**) I always thought of it as **f**u**n**ction, actually...
1+, I was gonna say the same thing;
Whoops! Sorry for that. Just fixed it. Thank you for pointing it out.
I personally believe that especially for Go, online resources are more than enough to get you started. You should check out [Go Object Oriented Design](http://nathany.com/good/) from Nathan Youngman who is also a Rubyist. [Effective Go](https://golang.org/doc/effective_go.html) should also help you a lot to learn to write idiomatic code. If you really insist on books, check out this [curated list](https://github.com/dariubs/GoBooks) of Go books. Also it might be worth to wait for [The Go Programming Language (Addison-Wesley)](http://www.gopl.io/). 
Go for Rubyist...whoda thunk it! Do you know of any ETA for that?
You are right. But back then Stringer was not written at all :) I wrote it one year ago. I should mention it in the blog post. 
You probably should....it looks like everyone all over the internet is keen to tag you for this one today.
Thank you!
You'll need -r for less to process the colour codes IIRC
You could also `alias puppet="source-highlight -fesc -o STDOUT -i"`. There's a section with all alternatives in the README: https://github.com/jingweno/ccat#alternatives. I would argue though, `ccat` is more hackable and is or will be better than other alternatives.
Anyone looking to do crypto in Go would be well served by looking at Google's own implementation of [NaCl](https://godoc.org/golang.org/x/crypto/nacl/box) for authenticated encryption.
it may occor race condition. it've better to add mutex#Lock/Unlock.
In the linked text a word "nonce" occurs 86 times. It's referenced in sentences, that say "never reuse a nonce", "send a nonce and compare", "nonce can be a random generated bytes", "this or that cipher take this long nonce" etc. but there's not a single word explaining what is it, heck, maybe even example on recording and replying ciphertext showing the problem. I'm not sure about the rest, just checked this out of curiosity. I wouldn't personally buy this book.
&gt; and most important of all, more usable for people. I strongly disagree.
Could you elaborate?
Sounds like a problem with your gopath - https://github.com/golang/go/wiki/GOPATH Does your hello world example compile and produce an executable on that machine?
Not sure what point you're making. 1. The distinction between binary and source is academic. If you don't distribute the binary then license doesn't matter because GPLv2 (or BSD or most other open-source licenses) only kicks in upon distribution. People don't spend time picking licenses without assuming that their code will end up in someone's binary. I also don't see why you believe that open source projects don't distribute binaries. 2. Hugo already uses GPLv2-like license so is not pertinent to my point that BSD-licensed projects would not use GPL-licensed code (and, somewhat ironically, Hugo uses blackfriday for markdown rendering, which is BSD licensed). If you believe that BSD (or MIT or Apache) licensed projects don't have problems including GPL code that I challenge you to find a single example where that is true. I've seen my share of projects and have never seen that. I certainly wouldn't use GPL code in BSD projects because, as explained, GPL subsumes BSD when included in the project. 
Thanks for the info Trevor, and all the best with your book.
Yeah, current implementation is not thread safe. Will point it out in the readme and push an update soon to make it thread safe
The lightest weight database tool I've seen is [scaneo](https://github.com/variadico/scaneo). All it does is generate functions to convert `*sql.Row` and `*sql.Rows` into any struct.
&gt;there is not much features in Go, [Less is exponentially more](http://commandcenter.blogspot.gr/2012/06/less-is-exponentially-more.html)
Do you compile a package with `package main` defined as the first statement? Or does the project require you to build the binary from a sub directory such as github.com/user/project/cmd/ (instead of github.com/user/project).
I agree with you on this. I'd love to see articles where Go is used for OS, networking stuff (non-web or non-http)
calling go functions from js, huh? i can finally write a plugin framework that doesn't look like garbage.
There is no chance that Go will compete with web frameworks like Django at any point. Saing that Go is perfect for startup is not that easy. I would even say that most of them should avoid Go, expecialy if feature rich frontend is required.
Can you go into a bit more depth as to why you say that choosing Go (presumably as the server side language) would have a negative impact on a feature rich front end?
Why? You can build a backend in any language and still have a feature rich front end. 
In startups -- I think frameworks like Django are all but dead. I don't know anyone using them in a startup founded in the last few years. Generally most shops go with a "big split" infastructure. Build an API layer with Go, Node, Java or PHP and then build front-ends for it -- generally one front-end in Java (Android), one in Swift (iOS) and one in either a framework like Rails or a pure JS setup (Angular, React and friends). Django is disturbingly complex when you get beyond trivial use or want to do something that cuts against the grain -- I speak as someone who migrated a rather large political blog during active campaigning season. 
The point is that you need all this features like user management, permisions, mailing, form validation/rendering, migrations and many more that you can get from plugin based architecture. With tool like django you can have it in hours instead of days/weeks or months in worst case. Startup needs to save money. Deployment itself is not a big deal for startup. Its not a Spotify thats deploy every few minutes. Usualy it happen every few days. 
Be careful, there's a semantic difference between those which can bite you. A ticker fires at regular intervals, whereas most people call `time.After` in a `select` case. The time it takes for you to do work outside of simply waiting is accounted for in a ticker. For example, here's `time.After()`: for { // do some work select { case &lt;-quitCh: return case &lt;-time.After(1 * time.Minute): } With `time.Ticker`: t := time.NewTicker(1 * time.Minute) for { // do some work select { case &lt;-quitCh: return case &lt;-t.C: } In the `time.After()` example, you do all the work and then wait a minute. It doesn't matter if the work takes one second or one hour, you end up rerunning the job one minute after it's finished. In the ticker example, the time it takes to do the work is accounted for. If the job takes one second, you end up waiting only 59 seconds. But if the job takes an hour, the ticker gets backed up. You will start another hour-long job immediately after this one is finished. Depending on your uses, you might want one kind of behavior over another.
These articles emerge after new criticism articles, so I personally glad to see such responses. They also may be important for newcomers, and there are a lot of them.
I'm not really sure why you've been downvoted into oblivion for this comment. There's definitely some merit to it. I work in a shared office with a fair number of Ruby and PHP developers. Their projects are not grand in scope, their data and API demands are relatively small. They're not writing enterprise software, but they're also not aiming to write the next Google, Amazon, or Facebook. At that small scale things like Ruby on Rails or Django are very good bang-for-buck solutions because a small codebase makes sense to be monolithic, and the tedium of things like a raw SQL are abstracted away in a "good enough" fashion. Go (and its ecosystem) has strengths that are different from Django/RoR and it's a great fit for those: high performance, service architecture, easy deployment. Maybe someday it'll compete with Django/RoR on its strengths, but not today.
Context of this: https://groups.google.com/d/msg/golang-dev/74zjMON9glU/nGuRNwTkdW4J As part of the vendoring proposal, `go test -vendor ./...` will also test all the vendored code as well. That's definitely not something I want, but /u/rsc considers this an orthogonal issue and opened http://golang.org/issue/11193. This appears to be his first stab at the problem.
Yeah this is the kind of article that makes /r/programming hate Go even more.
Instead of passing an expicit `nil` you can also declare `var requestReader *strings.Reader` as `var requestReader io.Reader`.
Have a look at [Why is my nil error value not equal to nil?](https://golang.org/doc/faq#nil_error). Once you send a nil "*strings.Reader" it is transformed to an interface with type "*strings.Reader" and value "nil", and as the FAQ states: "Such an interface value will therefore be non-nil even when the pointer inside is nil." I fixed it up. Also, no need to send pointers to maps: https://play.golang.org/p/4ZaPD4leNr 
Wow. Talk about an unforeseeable side effect of reflection. One would expect that a nil value, when [passed by value](https://golang.org/ref/spec#Calls) into a function would be equivalent to passing the nil literal. I've been operating under the assumption that interfaces were there purely for the compiler and type system, guess this is a wakeup call to dig even deeper into reflection, even if I rarely use it. In any case, thanks for pointing me in the right direction!
The lesson I've learned recently is that a lot of cheerleaders are answering the wrong questions. Many think the question is "why is Go better?" In fact, much of the establishment is asking things like "explain to me why I should ditch a decade's worth of Python code and start over?"
No one should *ever* just ditch a decades worth of python code and start over. But, if you haven't started yet go is a decent language to start with. And, If you have something that python isn't cutting it for performance/concurrency wise Go is a decent language to replace it with. If the establishment is asking that question then they are asking the *wrong* question
There is no chance that web frameworks like Django will compete with php at any point. ..until it did. I wouldn't even say Django has any serious marketshare at this point, certainly less than PHP had at its peak. And prior to that, Perl seemed impossible to replace. Prior to that, C seemed like the be all end all.. So I guess my point is, if you ever think your framework/language of choice is the final one and that nothing will ever subplant it, history says you are wrong.
Hey man, you're preaching to the choir. :) But this attitude is something I'm starting to run into, and has a sentiment that is echoed many places online. It's not uncommon to see resistance to a new language/toolkit. In these situations, nothing short of being established for *years* first will turn heads; facts, science, and evidence be damned.
Sure, but the underlying issue is caused by a decision about how to make interfaces support reflection by implementing them as a box for the underlying value, not the interface specification itself (which is remarkably [simple](https://golang.org/ref/spec#Interface_types), in spite of the examples). This indicates that there may be other implementation niggles caused by supporting reflection; being cognizant of all the possible actions through reflection will let me infer more about the underlying implementation.
As pointed out on [StackOverflow](http://stackoverflow.com/a/30862883/55504), your benchmarks "look good" because your slice resize code is completely broken (you always [copy zero bytes from the old slice](https://github.com/alediaferia/stackgo/blob/e09f705575a7720c1ff7eb492931899bb62f9d9d/stackgo.go#L41-42)). You've made the common mistake of focusing on premature optimisation and benchmarking before even having a test that verifies basic functionality (e.g. pushing until at least a single resize occurs is an absolutely required test). It shouldn't be needed for identifying such basic tests, but you could use [Go's test coverage tools](https://blog.golang.org/cover) to see what critical parts of your code are not being run by the tests at all.
What is passing on the mind of the people that decide to write this type of fanboyism articles?
I totally agree, "it's not reasonable to have to explain which 80 you mean" :) http://play.golang.org/p/asDxoojxGc
http://sia1.subirimagenes.net/img/2015/06/16/15061609174074176.png look I'm doing this project of code open but I run the command go build and build install does not generate any error to me and either generates me the binary .exe help please I am rather new to using Goland already read the documentation as I did test the hello example world and there if generates me the binary but this project does not create the binary thanks for your help
_Simple_ and Go, Dart, Angular.... is just wrong.
It's not quite up to 1.0 status yet... needs tests, but it's mostly working, and I'd love to get some feedback on it. I first heard about [diceware](http://world.std.com/~reinhold/diceware.html) during the recent [Lastpass intrusion](https://blog.lastpass.com/2015/06/lastpass-security-notice.html/), and hadn't ever heard of it. After reading the process, I knew I wanted to write a Go application I could give to my friends and family that would be too lazy to do it with dice (and for my own edification, of course).
People like to talk about the things they enjoy. That's human nature. For bloggers that means writing "fanboy-ish" blog posts. They key words being _blog post_. If there's no value for you here then maybe you're not the target audience. Unfortunately for /r/golang there's not much happening in the gosphere, so a lot of these simple blog posts get submitted. Can't blame people for submitting the only content there is to submit.
Thanks for getting it to compile! I'm still fuzzy as to why that works... I know that the interface method is bound to a pointer so the first thing i tried was making a map of map[int]*Widgets but that took me down a whole other rabbit hole...
You could also remove the pointer from the method receiver like: func (b Button) WidgetName() string { return b.Name } Maybe [this little tutorial](http://nathanleclaire.com/blog/2014/08/09/dont-get-bitten-by-pointer-vs-non-pointer-method-receivers-in-golang/) can help you?
Its not about Django/RoR/Symfony2, python or php or any particular framework. Its about Golang where you do all (or almost all) from scratch or full stack monolithic framework. History never have seen any language that instead of doing few steps forward was doing few steps back. Golang introduce some serious complexity in doing stuf generic. In my opinion StdLib almost hit borders. Golang is great language (my first choice and language that i use commercialy) but based on experience that i have got working in startup, there is a lot other solutions that from buisness perspective gave more. 
The most long winded hello world ever
I guess its not so much dereferencing... I guess my question is why does Func1 work but Func2 not? https://play.golang.org/p/D953fWdBY-
Here is an example of what I was trying to achieve (kinda...) Why does Func1 work but not Func2? https://play.golang.org/p/D953fWdBY- 
Func2 requires Person to be a pointer. If you change Person like so https://play.golang.org/p/WmmLYZTlTQ, both functions return a value.
So since Func2 requires a Person Pointer, you pass in a Person Pointer to execute, and when execute accesses things like Data it auto-dereferences?
Because you're passing a person **value** into the execute function so it can only access the function on the value. If you pass a person **pointer** into the execute function by changing line #25 to tmpl.Execute(os.Stdout, &amp;Person{Name:"Bob"}) by adding the **&amp;** before the person struct literal, then both Func1 and Func2 will work as expected.
You have `func (b *Button) WidgetName() string`, that is, you defined a `WidgetName()` that can be called on a `*Button`. You also have `type Widget interface { WidgetName() string }`, which says that a `Widget` can be anything that can have `WidgetName()` called on it. Because you declared a `WidgetName()` for `*Button` and not for `Button`, that means that a `*Button` is a `Widget`, and a `Button` is not a `Widget`. The literal `Button{ ... }` is a `Button`, while `&amp;Button{ ... }` is a `*Button` (a pointer to an anonymous `Button`). Therefore the second one is a `Widget`, and can be placed into the map, and the first one isn't.
Sounds like it was fun to put this together. Any thoughts on when, in your opinion, Dart and Angular2 will be adopted by enough of the web dev community to be considered mature and/or mainstream?
It's poor form for the name of your package to be different to its import path. 
I'd use that anki deck if/when released.
Yes of the few I quoted the "4 Days of Go" made chuckle so much :).
No, you're absolutely right. Lately, "API" has been conflated with "RESTful API". With Go, being a more "systems" level language than specifically web related, I usually interpret "API" to mean a library. Anyway, this article has nothing to do with building an API. It's got a single function that simply says `// Code`! Nothing but blogspam, IMO.
I don't think you're far off: var pixels unsafe.Pointer var pitch int err = texture.Lock(nil, &amp;pixels, &amp;pitch) if err != nil { panic(err) } for x := 0; x &lt; w; x++ { for y := 0; y &lt; h; y++ { (*[w * h]uint32)(pixels)[y*(pitch/4)+x] = 100 // whatever color you want } } texture.Update(nil, pixels, pitch) texture.Unlock() The main differences: 1. divide the pitch by 4 since its in bytes but you are using uint32s 2. lock / unlock outside of the loop 3. use two loops for x &amp; y so the break condition is obvious `w` and `h` have to be constant in this example, but it really just needs to be a large number. This is a general trick when using unsafe pointers which you can also use to do zero-cost conversions: https://github.com/calebdoxsey/tutorials/blob/master/integration/shm/main.go#L86. I'd recommend making something like a Pixels or Bitmap struct which you can use for your drawing code, then passing that into the SDL methods. It could be as simple as: type Pixels struct { unsafe.Pointer } And just add methods like: func (px Pixels) Get(x, y int) uint32 func (px Pixels) Set(x, y int, color uint32) So you can hide the type conversions.
Interesting to know, but is there a reason why Go was designed this way? It seems like a huge gotcha and I don't understand why all nil comparisons aren't considered the same. I can't think of a reason where having an interface with a type but a nil value is helpful other than creating potential places to panic. In this case, the calling function performs a check for nil and then panics because a nil value was passed in.
I read the title as: "Building a simple web app in Google's own backend language with Google's own frontend language and Google's own frontend framework".
A somewhat related project: https://github.com/ry/v8worker v8worker only communicates with Go by passing string messages. This seems to offer a richer integration between the two languages.
I think this is just basically [this](http://play.golang.org/p/WxliCAQPzR)? var re = regexp.MustCompile("[^a-z0-9]+") func slug(s string) string { return strings.Trim(re.ReplaceAllString(strings.ToLower(s), "-"), "-") }
Hah, yes :). Nice one.
It looks like you're treating parameters incorrectly. For example, a POST can have body parameters AND query parameters. You just have a single WithParam() method that adds query parameters if the method is GET and body parameters if the method is not GET.
How does it differ from testify?
Testify is a pretty big and heavy testing library, that completely changes the way your testing code looks. With testify, you use assert statements, rather than functions off of the standard library's testing.T. The OP's package is very lightweight that uses the standard go testing style of normal if statements and calls to t.Errorf
This. Our large apps all have only one file, which is a main package, and is only about 50-100 line long. And it's the only place where the flags are parsed. I don't know if it's a good idea to have a main package with over 1000 lines and more.
I know, and thank you for that. This isn't against you or anyone who submits posts or links to /r/golang, but rather against those who write such blog posts. The title is a click bait, the post has next to no actual content, and then there's author's shameless self-plug at the end. As for me, I'd like to, but Go hasn't been much in use where I work recently, so I'm afraid I don't have any useful Go info to share (apart from the info I share on StackOverflow).
Yep, libraries should be dumb about how they're used. I do like avoiding global variables whenever possible, though. Using flags as globals almost always makes your code less testable and more intertwined.
I mostly wrote this to get to grips with the standard lib ast package which as it turns out is quite an interesting and useful package. Any comments or suggestions are welcome.
Do you know about franela/goreq? Been using that for a while and it's pretty simple.
As someone learning Go, this is a very well-written article. Thank you for sharing. 
agree but will be slow.
+1 for init()
Does it work with the normal go package selectors, like ./... ? That would be a lot more useful than a single directory. I don't remember offhand how to translate a package selector into a list of packages, but I'm sure it's in the library (or a similar library) somewhere. 
https://godoc.org/github.com/kisielk/gotool
It's just a puff piece for non-techies about how Go is going to surpass Java in popularity. Don't bother reading.
I always agreed with everything in the article, but it still doesn't make a very good argument. &gt; And if the native byte order really does matter to the execution of the &gt; program, it's almost certain to be dealing with some external software that &gt; is either wrong or misguided While that is certainly true, I might still want to be able to deal with external software, that is either wrong or misguided. For example the i3 IPC interface left the byte order intentionally unspecified. Of course that was a mistake, of course it was misguided, but that's how it is and I still want to communicate with i3 using go. That being said, a native byte order can easily be implemented as a separate package, with build-flags for different architectures. But I still find it crazy, that this is not simply provided by the binary package.
What is missing from the binary encoding package? 
This works well for this use case as there are other attributes to an attachment that could be used. Cheers!
Go was created for the type of network servers Google creates. Go is in use on several Google projects. I wouldn't call that small network servers. What common development options do you feel is lacking?
Pushed! Improved coverage but haven't updated readme benchmarks yet.
&gt;but its lack of common development options makes it a no-go for serious enterprise and business use &gt;or do you genuinely not know? Lack of common development options? I genuinely do not know. Can you elaborate?
I'd say that such an article is still worth reading. It's fairly small and the fact that it is in Yahoo finance should mean something. I have no clue who might be still using yahoo nowadays but it should still mean something, right? For me, the best quote from the article is: &gt;Consider also that programmers working on your complicated Java or C# app may not stay with the company for as long as it takes to finish that same app. When you hire a new programmer, even if they're proficient with Java, it'll still take them a lot of time to understand what the heck was going on with the last guy. This is exactly where Go shines and it's because it was designed that way. There's no templates, no macros, no method overloading and a dozen other features that would make a new programmer scratch their head to understand what the previous one was doing. Go is a pragmatic language made by engineers for engineers. On the other hand, the worst quote of this article (which is what probably turns people off) is: &gt;"They just want to look good to their bosses." I believe that the average gopher that "get's it" is more concerned about producing quicker, higher quality and sturdier software that is easier for them, their team (and the new devs that will come) to maintain than showing off to their bosses.
I've been using sloc (https://github.com/flosse/sloc). It's written in Go but works for more languages than just go. 
: ) Agreed
&gt;&gt;When you hire a new programmer, even if they're proficient with Java, it'll still take them a lot of time to understand what the heck was going on with the last guy. &gt; This is exactly where Go shines and it's because it was designed that way. There's no templates, no macros, no method overloading and a dozen other features that would make a new programmer scratch their head to understand what the previous one was doing. Go is a pragmatic language made by engineers for engineers. I'm not convinced Go will outshine Java/C# here. Generics in Java are trivial to understand and method overloading is easy to follow due to the power of java IDE's. The most complicated part of either of those languages is the web of inheritance someone can weave but again a good IDE makes short work even of that. Usually the biggest hurdle for understanding to me is not the language so much as the full architecture of what they built. 500,000 lines of code is going to take a while to understand regardless what language they use and if they over-engineered the base system its going to take even longer (and yes they can over-engineer it in any language regardless how pragmatic it may be). tl;dr I don't believe the time it takes to pick up a codebase is as much a product of the language as it is the size and complexity of the application.
Needless to say, I wasn't expecting this to be (a) picked up by Yahoo Finance or (b) so heavily misquoted. A few clarifications: * Super mega click-bait title. Oracle was never mentioned. * The writer confuses C# and C++ in a few places * The last quote was originally "Mainstream programmers don't want to engage in programming language debates. They just want to be productive, pay the mortgage, and look good to their bosses." * I specifically said that it was not our goal to be at the top of the language ranking charts, but that "We just want to make Go as useful as possible to the widest range of programmers as possible. If we were able to knock Java off the top of the chart in 5 years, that would be great." 
I hear you. The original quote was actually: It was not our goal to be at the top of the language ranking charts, but that "We just want to make Go as useful as possible to the widest range of programmers as possible. If we were able to knock Java off the top of the chart in 5 years, that would be great." 
This article ignores the fact that business systems have a certain intrinsic complexity and that these complexity must be handled somehow. A good approach to handle complexity is to build abstractions and this is a big weakness of Go. The language is too simple,but in to build some useful abstractions and the result is repetitive code all the time. Maybe you don't need to learn many concepts, but you'll have a hard time to find the actual (business) logic in all the clutter. Try this piece of Scala in Go: val myList = List(Some(4), None, Some(5), None, Some(6)) myList.flatten.map(x =&gt; x * x) // result: List(16, 25, 36) First, you wouldn't have the abstraction about missing values (`Option` with the concrete types `Some` and `None`). Second, you wouldn't be able to reduce the list so that you have only the actual values (and `None` filtered out). Third you wouldn't be able to map the list entries to other valuese so easily and less error prone. In Go you would have auxiliary lists and for loops all the time. And this is only a little example of little useful abstractions. Think of a big system where you have thousands of such pieces of code, and think of a lot of dump Go code doing the same over and over again. No, thanks!
Good call. I'll ask him on that.
i would like this tool, but i don't think there are enough badges, so i cannot verify the integrity of your code. from my perspective you're a flippin idiot that has never written a line of code in your life. get some badges you berk.
1. There is no internal competition between the Go and Dart teams. Each language has very different origins and goals. Go was designed as an alternative to Java and C++. Dart was intended to be a better, type safe JavaScript. Two very different beasts. 2. That was a topic of discussion just this morning, actually. We don't have any plans to build a go2webassembly compiler. But it would be an interesting experiement.
Oh dear, you have given them a tool to "propose" generics ... Again, and again, and again, and again. 
&gt; https://mholt.github.io/json-to-go/ Do you know of something like this for csv files? If not then I might try to make of port of json-to-go for csv. Really liking caddy too! 
If generics are implemented in a way that doesn't ruin the language, I wouldn't mind them.
In most native languages the debug flag turns off debug symbols, optimisation is a separate setting.
Hmmm, I don't, but that's a cool idea. I recommend using [Papa Parse](http://papaparse.com) for parsing the CSV sample. (There I go again - another shameless plug!) (Thanks for your comment, by the way - glad you like it.)
If you care about understanding the workings of the "actual code" on the JVM, it's already too late. There is no way you understand what is going on in the JVM.
&gt; &gt; Particularly ___if___ "compile for debug" also shuts off all optimizations I qualified it for a reason.
Someone is trying to short oracle and lift Google stock up 
Already in r/golang: https://www.reddit.com/r/golang/comments/3a8onw/how_google_thinks_it_can_knock_one_of_oracles/
And a way to quickly close most such proposal briefs (the first step is opening a *brief* [GitHub issue](https://github.com/golang/go/issues?utf8=%E2%9C%93&amp;q=is%3Aopen+is%3Aissue+label%3AProposal)) as duplicates.
Interesting, You can find project here: https://github.com/phonkee/patrol
http://stackoverflow.com/questions/24117063/is-a-program-compiled-with-g-gcc-flag-slower-than-the-same-program-compiled-wit According to this thing `-g`does not screw with perf, people have a tendency to use debugging or optimizations, because if you use optimizations it can screw with your debugging. I totally agree with you, that in some cases debugging can change the situation, but I would rather the less intrusive way of doing that which to me is the equivalent of `-g`, I just need to attach the debugger and I don't need to worry about some other program modifying my source that seems to do basically the same thing? Also putting breakpoints in code doesn't sound that easy to work with.
This is an educated guess: When you do non-blocking operations on sockets in Go, the scheduler handles this by using the system call `epoll` on Linux. `epoll` takes a bunch of file descriptors and returns whenever at least one of them is ready (e.g. has data ready). This is great if you have many sockets that rarely have any activity, but it's not so great if all those calls to `epoll` return almost immediately. `epoll` does work linear in the number of file descriptors it is passed (because it has to check if each one is ready), so many async reads suddenly take `O(n)` where `n` is the number of clients, instead of `O(1)` when each thread blocks on "its" socket. -blocking sets the file descriptors in blocking mode, essentially forcing Go to use blocking semantics, and thus avoiding the overhead of `epoll`.
What are badges in this context?
And for shit like this is where things like Javascript and PHP are born.
Don't worry, given go current type system, technically go can't have generics without breaking backward compatibility. In fact, Go type system is so restrictive it leaves very little room for extension. And according to this article ( http://www.businessinsider.com/google-go-update-from-jason-burberel-2015-6 ) , "Go is done". Not that I agree but people shouldn't hold their breath and think they are going to get any new feature. They wont.
would love to see this sort of error reporting
I'm wondering, what do these people regard as the "Go community"? The go-nuts IRC channel and the Google group? Because a code of conduct sounds okay for these places, even considering the OP took the liberty of introducing political themes such as multiculturalism and the like instead of the natural intention of a CoC: "just try to be nice to each other", but outside of that? I certainly don't want any part of a corporate environment led by non-technical people in FLOSS.
Ancient reply, but for posterity: Note that the reason for unique per-request CSRF tokens is to protect against http://breachattack.com/ which uses body compression analysis to determine secrets (CSRF tokens being one of them). The [nosurf](https://github.com/justinas/nosurf) library from Justin that this project consumes (to a very large degree!) has the rationale documented.
I'm all for being decent human beings toward one another, but what's with all the now ubiquitous written codes of conduct for every programming community? Are people expected to act differently when interacting with Ruby developers vs. Go developers vs. Haskell developers? Shouldn't all of this be common sense anyway? Regardless of whether or not a conference website or an IRC channel displays the official community code of conduct, if someone is being shitty toward someone else because of their gender/race/orientation/whatever, have a serious conversation with them, and/or kick them out.
This is one of the reasons I love Go. After seeing the Gophercon code of conduct I just felt so much better going.