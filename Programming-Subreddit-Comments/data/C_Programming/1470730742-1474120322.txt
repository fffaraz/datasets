Please demonstrate how this relates to C programming. Also, please do not cross post the same link to 14 (?) different subreddits in such quick succession. That's a good way to get banned.
The whole idea seems too foreign... The best use I have for stacks is for flattening recursive algorithms. This code is like driving on the highway in reverse.
It all boils down to patience. C is easy to learn, but to be actually efficient in C means you must know computer systems in general since the language won't do anything on you behalf. C is a beautiful language :) 
It's the return status of the whole application execution. If you don't return anything, it will be assumed as "0" (e.g., you declare `main()` as `void` instead of `int`). Most applications return a different code when something goes wrong (missing configuration, not enough permissions, etc). You can use different codes to tell the shell different problems with your application. Also, `stdio.h` defines `EXIT_SUCCESS` and `EXIT_FAILURE` if you're interested.
Technically correct, the best kind of correct, but the most common systems have 32-bit ints and 16-bit shorts. But this is why we have stdint now.
And, to give an example of how is this useful, imagine you are writing a script that calls lots of programs to do a job. So you call program A, B and C. But, if you want program B to work correctly program A must finish without an error otherwise the result will be incorrect. You can try reading the output (stdout/stderr, eg output from the `printf` function) of the program through your script but this is hard and the way the output is formatted may change in a future version of the program. A better way is to check the code the program returns if you know that it returns something different than `0` on failure.
This is the textbook I used in college to learn C for my CS degree, and it, as well as my instructor, made the language ridiculously simple to understand and really start using for my personal and school related projects. Unless something changed from previous additions, I highly recommend this book! 
All I see is gcc bitching about b sighing
The return value from `main` is an error code returned to the operating system. The value 0 means no error, i.e., the program ran successfully. In the Windows command prompt and batch files, you can use the `%ERRORLEVEL%` variable to get the return value from a program and do stuff based on it. In POSIX systems, there's all kinds of things you can do with it. You can use the return status like a boolean expression, except with 0 being true and everything else being false. Running `command1 &amp;&amp; command2` will only run `command2` only if `command1` succeeded. Conversely, `command1 || command2` will run `command2` only if `command1` failed. The return status is also available as the `$?` variable, and you can do conditionals like `if [ $? -e 0 ]` or `if [ $? -ne 0 ]`.
&gt; Assuming calling free on a null pointer doesn't actually result in an error. No, free(NULL) is defined to be a NOP.
You can't read in a little endian number into a big endian system and perform standard operations on it without converting it to big endian. You can't read a big endian number into a little endian system and perform standard operations without it being converted (or read into) as little endian. End of story, you're arguing with me over a point I can't fathom to imagine at this point because we should have been done with this conversation not long after you "disagreed" with me because it's a matter of fact I'm pushing. Not a matter of opinion. If you think you can always avoid using functions to convert things to big or little endian format so that you can receive and analyze or format and send out the proper messages you're a moron. I've had to do it at my work, I've had to do it in my networked systems classes, and I've had to do it whenever I wanted to write a low level program that accesses the internet and controls the packet headers. I've also had to design a pipelined CPU in verilog, write a compiler, and translate C code into binary by hand before. I'm pretty confident I understand the hardware having designed a working MIPS processor and emulating it on an FPGA. So understanding that the data you work with needs to be in the host byte order after receiving it to make sure (intended) 0x0002 + 0x0001 = 0x0003 instead of 0x0201 or whichever manner of error might happen as a result of any of these shorts being in the wrong byte order is fairly important. I'm basically done trying to argue with you at this point because you're disagreeing with god knows what part of my statements for the sake of argument. You're going into topics of aliasing which is completely tangential to what I'm saying and I can only imagine that's because you're trying to deflect the fact you're wrong. I know what I'm talking about, and for all I know you do too. You just started an argument over a fact and then tried to change the subject once I didn't fall for it to continue arguing with me. If you have a system and you're performing some operations on messages in network byte order using low level C (all internet messages are big-endian) chances are you're using x86 or x86-64 which are all little endian systems. You have to convert them or you're gonna have a bad time trying to do math on the wrong numbers and/or store the wrong numbers in your message afterwards. You will have some equivalent of the network functions I'm talking about operating somewhere on it no matter what if the host is little endian on the internet. I would know. There's literally no escaping it, and if you can't accept that kindly never program for networked systems please. You shouldn't disagree with facts that you can google with things you can't google. I'm disabling inbox replies now. You can go argue with someone else over something elementary. There are networks out there dedicated to big-endian format (almost all of them) and we have mostly little endian systems connected to them.
"0" is used for success because that allows for many failure types and one success type. [Which is usually how things work.](https://en.wikipedia.org/wiki/Anna_Karenina_principle) 
All the assignment should do is assign b to the first 16 bits of a. You'll lose information if the integer is too large to fit in a short. I.E. if the top 16 bits aren't all zero in a 32 bit integer system. But it's not strictly wrong. For example: a =0x01234567; b = a; // b = 0x4567, basically the same as assigning b to (a &amp; 0x000000FF) PS: To those who are saying shorts aren't 2 bytes... They're supposed to be by definition. If your compiler is making shorts store more than that, I'd have mixed opinions. The only architecture specific integer types are supposed to be ints. The only architectural difference should be how many bytes are ignored in this assignment.
"implementation defined" means "the implementation may choose whst happens." This is different from undefined behaviour in that the result can be expected to be consistent.
At least we can agree in that this discussion is not worth continuing.
For which abstract type of C are you describing a standard for? The standard short is two bytes, by the book and by majority consensus. If some wacko decides they want their compiler to make a short more than two bytes by all means. But it's the compiler that decides it. You can emulate more than that all you want but it doesn't make it a good idea to change the paradigm because of your interpretation of the standards. Which begs the question, have you programmed a compiler to interpret shorts as anything other than two bytes? I could if I wanted. It doesn't mean I want to though, and it doesn't mean many compilers do. Clinging to an edge case almost no sane person does to suggest it isn't going to be two bytes isn't that handy when the odds are it will never not be in your gcc/g++/commonly used compiler. You can do whatever you want and even deviate from it in your own compilers. There's always (or should always be) uint32_t and uint16_t and so on if you can't trust them. Either way I'd challenge someone to provide a widely used C compiler that doesn't treat shorts that way. They're not exactly the most useful things in the first place since processors don't generally have special pathways for them. (They still end up padded with zeroes in the CPU.) But if your data structure or network packet is organized with them at least it helps make manipulating the data easier.
If you can come up with some ideas for something to program, just do it. There's no other way to really do it. Practice makes perfect and once you've learned the ins and outs of the language efficiency and software engineering stuff might be good to look into if you want to learn how to try and design larger programs. But you'll find different languages are better for different purposes and as a single developer you might be tempted to use C++ or a higher level language (or mix of languages) to get what you want done. C is still one of the fastest if you know how to write things efficiently though. In all honesty though, design and test is probably the longest part of programming. It's easy to code once you know what to do, but if you don't know what to do and what libraries to use or what you want to do there's not much you can do.
A short is 'at least' 16 bits. It is not assured to be exactly 16 bits. There's nothing stopping a compiler from using a 64 bit short. If you need fixed width types, use stdint.h: uint16_t will always be unsigned 16 bits. 
Let me rephrase, it is most common on computer in which code is generally written.
Don't know. You want the sums to change wildly if there is a one byte difference, the concept is called diffusion and is very important in crypto theory land. Maybe it's a string encoding issue? Don't know.
kernel.org
hmmm ya, I'll have to try debugging prints, I used stops and stepped through to make sure everything was written correctly. I'll check now
couldn't get anything. Changed reference to struct in fprintf and checked but I keep getting garbage written into the file
The linux kernel is't a C library. Nor is it particularly well documented. 
Once you have the basics down i.e. know what a loop is and how to construct it I would highly recommend the projecteuler problems. Start with 1 and work your way through them. I started with it 2 weeks ago and have slowly been working my way through them and it great. Been on 11 for a few days now its the first time I am really forced to use arrays and strings the most confusing topic in C for me by far. The reason I really like it is that it poses a easy to understand question (at least the first ones) that has large scope then leaves the approach to you. I also found the site with the checklist of solved problems and badges for all its silliness motivates me.
One thing you have to be careful about with `uint16_t`, etc., is that they're not guaranteed to exist. Old DSPs in particular can have strange word sizes where these data types will not exist. You can use `uint_least16_t` instead in those cases (but then why not just use `unsigned short`?)
That is probably true, I admit most of my C work is library work these days, but I generally always use stdint.
But only if you're actually compiling in C99 mode or later. For example, gcc until very recently (version 5) defaults to C89 mode. If you're compiling with a simple `gcc foo.c -o foo` and you're using gcc 4.x, then you're invoking undefined behavior if you don't have `return 0`. 
 instead of scanf("%s", &amp;saveFileName); you want: scanf("%s", saveFileName);
NVM, i got it. It was my function call, I needed to call with index zero. Then I decided to put loop in my saveEmployee function itself with no seperate writeToFile function. 
Hey, thanks for your response. I'll be trying out Linux for now but I'll take note of CLion trial for free. I've also heard I can use Microsoft's Visual Studio for free with a .edu account too which is nice. Thanks again!
I also recommend Programming in C by Kochan. I used it in college and found it extremely clear. Do every exercise (which is completely manageable given his forgiving pace), and you will have the rudiments of file I/O and memory management covered before too long, which is when you can start doing interesting stuff in C. Note that his spacing/indent style is not super idiomatic and deviates slightly from K&amp;R, but it is superficial. Great book.
If you compile without any warnings, you're basically asking for trouble anyway.
I don't know where to begin and how to proceed, basically. 
That sounds like a terrible book, if it hasn't told you that. Do you have a compiler? Which one?
That's very kind, I really just need to actually study harder. Programming is just a lot more fun than learning to program so I rush ahead and get stuck. I have not made anything advanced in python, just a webapp in flask. It does kinda the same thing opentable.com does in that it tells you what restaurant have open tables, but just for the city I live in for a few restaurants right now.
Honestly only YouCompleteMe is necessary (and even then some would consider that overkill). YCM already does C syntax checking on the fly, negating the need for syntastic. I would recommend sticking to a very minimal config so you can better learn the ins and outs of vim; using :make and then exploring the quickfix list for jumping to errors won't leave you using a special plugin as a crutch.
Pathogen is a must have
I forgot to type Vim-Plug, which is something similar to Pathogen, am I right?
I don't know most of these plugins. I rely on vim mostly though i do use tags to complete what i'm typing and to jump to definitions and the like. I might be a little faster with some plugins but I like the feel of straight vim.
What is wrong with this method though? I'm on osx 
What devices? What operating system? What will the apps do?
Android/ios i want to make games
I would recommend ctags/cscope depending on what types of projects you plan on working on. They're extremely useful when dealing with large code bases.
Nothing is necessary, nothing is must have. I use `ed(1)`.
JavaScript (or C#) and Unity: https://unity3d.com/unity/multiplatform Programming: https://unity3d.com/learn/tutorials/topics/scripting EDIT: add link to programming tutorials
YCM is important for mi since I will also use Vim to Python coding. Syntastic... if you say so, that it's not necessary when YCM is plugged, I'm going to delete it. Right now Vim is like a black magic to me, hope to catch it's features soon. I didn't quite understand the plugins, there are so many of them, PyCharm (I was Pythoning before) was just working out of the box with all the helping features and Vim is so unknown for me.
There is nothing wrong in theory with Makefile based builds, although I think most people on the mac would use Xcode? I've never used it, so I can't help with that. In general, it's very hard to help someone when you don't know what tools they use, and they have no control over them. It sounds like you don't understand your toolchain (yet), and you should find a book or website that starts with an explanation of what you need to install and what steps are involved in building a simple "Hello World" application.
Thanks for the tips!
I dont really know 1 language i started on freecodecamp with html but i think i will go to codeacedemy and take java. Thanks for your tips!
I was up to install Vundle but after seeing [this](https://www.youtube.com/watch?v=LRQGAnPtNdM) video i was convinced to use Vim-Plug instead of Vundle. They show here that it's faster and easier than Vundle, just take a look ffrom 8:00.
Tagbar is the only plugin I can think of in addition to the ones you've already listed.
Your stack allocated arrays (ex. password) all seem to have buffer overflow vulnerabilities, since you're reading data into them without checking boundaries. Have you checked that you have sufficient space to store everything? memset (&amp;HASH[0], 0, sizeof (HASH)) makes no sense... I'm not familiar with the APIs you're using, but HASH appears to be a pointer to heap memory allocated by the library you're using. If this is the case, then all you're doing is nulling out the pointer and leaking memory. Check the documentation for the function you're using, it should tell you what you need to do to cleanup that variable when you're done with it. lots of little things that are kind of quirky... Your main loop appears to be checking a variable as an exit condition, but I cannot see where you actually change the value of it to break the loop. &amp;password[0] seems kind of strange... Wouldn't that be the same thing as? &amp;password application structure is a bit off... every time you call the crack function, it appears to read an entire file, line by line, and do checks after each line. separation of concerns would help out a lot here, not just in understanding the program, but debugging it. Seems like it would be a heck of a lot simpler to read those files up front, into some sort of in-memory structure (maybe even just a linked list), and perform your operations on that structure.
Care to explain more about the compiler not being the C language? Thanks. 
edit* nvm I was wrong 
Yeah, my phone likes to auto "correct" those things sometimes.
I gave it a try after removing the 'lib' so i used '-lportaudio_x64' and got the following errors: c:/mingw/bin/../lib/gcc/mingw32/4.9.3/../../../../mingw32/bin/ld.exe: cannot find -lportaudio_x64 collect2.exe: error: ld returned 1 exit status
I forgot to mention one more thing. Depending on the type of app you want to make, it's possible to make an app with a framework like Apache Cordova (previously PhoneGap), which mostly requires that you know Javascript and HTML, and does the heavy lifting of running that on both platforms: https://en.wikipedia.org/wiki/Apache_Cordova 
any function.
sorry i think i misunderstood u, i need to come with an algorithm that does that. 
I'm also writing my own I/O library, and to be honest I don't understand what problem you're trying to solve?
Well, getting the previous day is easy enough, unless it's the first of the month. Since the days in a month tends to vary, the test condition will have to use that somehow. Maybe you could use a bunch of global constants with the number of days, eg `#define JAN 31`.
No documentation = no use. Even for you libraries like these, it is good practice to document the API so people have some idea as to what it's supposed to do. Eg. What are rp and wp in your buffer struct? Their use isn't mentioned anywhere, and unless someone were to jump into the implementation and read the whole file (no one will) these may as well be magic numbers. As for the API design itself, why even have the struct definition in the header? I would forward declare it, and put the definition itself in the.c file. 
This reminds me of the time I heard a guy explain how they'd written a function to determine the correct date for Easter (i.e. first full moon after the vernal equinox) for the billing software of a German telco. Total overkill, because hard-coding the next 50 years of dates would have been sufficient to get the job done, but given a chance to add calculation of the moon phase into your program, how could you not? Compared to that, calculating leap years is much less satisfying. 
Goals: * Avoid Ring buffers (contiguous data buffer ready for Read/Write in single syscall) * Ensure \0 termination to facilitate string handling. * Minimize memcopy's. (shifts memory only when needed. In some use cases, no memcopy's are necessary) 
&gt; Avoid Ring buffers (contiguous data buffer ready for Read/Write in single syscall) Wow, mine does the same thing! So you're basically just sanitizing the input, I honestly didn't even think of that in such a broad way...
Yes, an `if` statement can be repeated as many times as you desire. Just be careful not to use a repeated `if` statement inside the `else` of that very `if`, because it'll always be false. For example: if (x==0) { //whatever } else { if (x==0) { // this will be false, as the else means “if x is different from 0”, so you know it won't be 0 printf("This prints nothing\n"); } } This is really the only caveat I can think of.
I'm not sure what you're asking. If this snippet is what you mean, yes, it will compile and execute just fine. However, the compound statement for the second if is never executed (assuming S0, S1, and S2 are not volatile). if((S0==0)&amp;&amp;(S1==0)&amp;&amp;(S2==0)) { L0=1; blink(); L0=0; } else if((S0==0)&amp;&amp;(S1==0)&amp;&amp;(S2==0)) { L1=1; blink(); L1=0; } 
It probably will compile. Assuming the condition is true, both blocks would be executed in the order they appear in code. 
clang gave me this warning: bufio.c:89:8: warning: absolute value function 'abs' given an argument of type 'ssize_t' (aka 'long') but has parameter of type 'int' which may cause truncation of value [-Wabsolute-value] sz = abs(sz); ^ bufio.c:89:8: note: use function 'labs' instead sz = abs(sz); ^~~ labs 
This article hits on something that is often overlooked - volatile accesses are guaranteed to not be optimized away, but there's no assurance that other operations on nonvolatile items will happen when we think they will. The classic example of writing some information in memory, then setting a volatile 'ready' flag to one does not assure that the memory write has completed when the 'ready' flag is set. It could happen in any order! Just making the memory and the ready flag volatile can help, but hurts performance. The suggestion is to use a memory fence, or add a function call, to force the compiler to assure that all reads/writes have been completed before the volatile write.
&gt; So just to make sure I get it: The C language is a standard that can be implemented on various ways. But I'm guessing there must be a "base" set of protocols/functions that must be there for it to be considered C? And then you can add on top of that? I'm not sure if what I'm saying makes sense. I hope it does. Exactly. The C standard contains lists of things that *must* be present and things that are optional, but if they do exist *must* be implemented in a certain way. It also defines minimum ranges for integer types and such (like integers must be capable of storing numbers at least "this big" and so on). It also defines the standard library (things like *malloc* to allocate memory and *printf* for formatted output). But every compiler has at least some extensions on top of that. You can write plenty of programs without ever breaking away from standard C, and you might never use your compiler's extensions. Note also that when I say "compiler" there's really two things that I should be talking about. There's the compiler, which turns your C code into machine code that can be run, and there's a "standard library", which includes the code for functions like *printf* and *malloc*. When you compile your C program, the compiler links the code from the standard library into your program so that when your program uses *printf* or whatever, it actually, you know, has code that runs for that function. So, (almost) every operating system has its own standard library that is a superset of the C standard library. The C standard library does not define directories (like, directories of files, sometimes called "folders"), but the standard Linux C library has functions for dealing with them, because Linux has directories (see opendir, readdir, etc). This also brings us to "libraries" in general. There are millions of C libraries that provide functions beyond standard C: libraries that draw graphics on the screen, libraries that do complex math, whatever. When you use those libraries, your program is no longer standard C and might not compile everywhere (for example, it won't compile on a machine that doesn't have those extra libraries installed). Remember that the C standard aims to be the "lowest common denominator". People write C programs that run on mainframes and powerful servers, and write C programs that run on tiny microcontrollers in your watch. &gt; Code written on Linux might not compile on Windows because of how the compiler implements the C standard, correct? Wouldn't the final compiled code work on both though since the hardware is exactly the same? I'm thinking it should since the actual hardware doesn't know "languages", just ones and zeroes. And also because all languages get compiled/interpreted into machine code. Is my thinking right? You're right in that all code gets compiled into machine language. Where things are different is in the particulars. The compiler doesn't just produce machine code, it produces an *executable* - a program that can be loaded by an operating system and run. The executable contains machine code, but also metadata about the program (where to load it in memory, what libraries it uses, etc). Linux and Windows use different executable formats. Linux uses a format called [ELF](https://en.wikipedia.org/wiki/Executable_and_Linkable_Format), while Windows uses something called [Portable Executable Format](https://en.wikipedia.org/wiki/Portable_Executable), and Mac OS X uses one called [Mach-O](https://en.wikipedia.org/wiki/Mach-O). Another difference is the library format that gets linked in, and how libraries get linked in. All of the operating systems I mentioned above (Linux, Windows, Mac OS X) support static and dynamic linking of libraries. Static linking means that the machine code for the functions in the library are just copied verbatim into your program at compile time. Dynamic linking means that the compiler inserts a "reference" to the library's function into your program and then when you run the program, the operating system loads your program and the library, and then dynamically links the two together. This is useful for various reasons (one being that if a bug is discovered in a library, you can just put a new copy of the library there and programs get it without having to be recompiled, assuming that the interface didn't change). However, that also means that a program that is dynamically linked won't load or run if the library isn't available (you installed it on a system that didn't have a copy of that library, for example). Part of the metadata in Mach-O, ELF, and PE files is what libraries the program needs to have to be loaded dynamically. Each of those operating systems has its own implementation of the standard library. The code for *printf* on Linux would be very different for the code for *printf* on Windows, because those operating systems have very different ideas as to how to get a character printed on the screen. The C standard mandates that a function called *printf* exist, and how it should work for the programmer, but the standard says nothing about how the implementation should work. So when I compile *printf("hello, world!\n");* on Linux, the code that gets linked in (to print the string on the screen) is very different from the code that gets linked in on Windows to do the same thing. In short, a program that conforms strictly to the C standard (i.e. doesn't use any functions outside of those in the standard library, doesn't use any compiler extensions, doesn't rely on integers and pointers being a specific size, etc) should *compile* identically on any platform that supports the standard, but the output program will be very different on different operating systems and compilers. The C source code might not change, but the output of the compiler would. Sorry for the wall of text. :)
Well, the first question is, what API do you want to use? If you want a cross-platform library, there are only a couple to choose from that support Windows: PortAudio, SDL, and maybe OpenAL. If you're okay using Windows-specific APIs, you could use DirectSound or Core Audio / WASAPI. As far as why it's not working for you... well, hard to say with no code or description of your problem. If you just want general advice, I'd say make sure you read and do the tutorials, and try to get those working first. If you have problems with those, you can search around or ask, but they ought to be straightforward enough that you shouldn't have any difficulties.
No no. Thank you for the walk of text. You're helping me a ton. Based on what you wrote it would seem that the compiler is a very important piece of software. I'm learning C so I can program microcontrollers. I'm assuming that if I get two different compilers and feed them the exact same C source code the end result(let's say having the microcontroller read a temperature sensor and display the temperature on an OLED screen) may be the same, but how they take your source code and apply it to machine code may be totally different. One compiler may produce smaller or more efficient code. Awesome. I have a long way to go but the info you've shared is going to help me tremendously. Thanks again for taking the time to help me out. 
http://pastebin.com/p41tVTCf Here you go thanks in advance. EDIT; my "unsigned input = 0" is suppose to be "int input = 0"
http://pastebin.com/p41tVTCf Here you go thanks in advance.
I believe there are two issues. 1) You are reading only one byte instead of whatever the int size is. Changing your read call from... read(toChild[0], &amp;input, 1) to read(toChild[0], &amp;input, sizeof(int)) should fix this issue. 2) WEXITSTATUS only evaluates the low-order 8 bits from your child's exit code. From the wait manpage... WEXITSTATUS(stat_val) If the value of WIFEXITED(stat_val) is non-zero, this macro evaluates to the low-order 8 bits of the status argument that the child process passed to _exit() or exit(), or the value the child process returned from main(). That is why your int summations are demonstrating essentially the behaviors of unsigned chars, because the int values are being truncated to 8 bits during the transmission between parent and child. Instead of using WEXITSTATUS, I would just use write to send back the int value of the sum.
You're printing out the exit status of a process: sum = WEXITSTATUS(status); printf("sum = %d\n", sum); It is not possible to return a negative status (or a status above 255).
That instruction performs what is commonly called a *memory fence.*
Why do you try to compute the magnitude of `sz` anyway? That looks like covering up bugs to me as the interface silently does something instead of crashing when the caller accidentally calls it with a negative size argument.
The given article is good, but like any advice on the internet, it should be taken with a grain fo salt. You might also want to read the responses referenced at the top. I can also recommend the book [21st century C](https://www.amazon.com//dp/1491903899/). It has a number of cool tips and fits nicely, if you have a basic understanding of C. &gt; Btw K&amp;R style is outdated, right? XD Quoting Linux here: &gt;&gt; Heretic people all over the world have claimed that this inconsistency &gt; is ... well ... inconsistent, but all right-thinking people know that &gt; (a) K&amp;R are _right_ and (b) K&amp;R are right. 
Bjarne Stroustrup, who invented the C++ language says [C is obsolete and should be merged as a subset of C++](https://www.youtube.com/watch?v=KlPC3O1DVcg). I'm not sure what to think. I've had a C++ and a C course, but when I look at professional code I can't understand it. It's on a whole other level.
[Linux Coding Style](https://github.com/torvalds/linux/blob/master/Documentation/CodingStyle#L124-L127).
Throwing my opinion into the ring. I am not a huge fan of the article in question. Google the title + "response to" and you'll see some of the reasons why it can be bad advice. That being said, Hanson's book is great for macro level structure, but a little out of date and macro heavy for my personal taste. The custom malloc, etc. Are useful for reducing repeated code, and standard functions aren't "fixed" in newer versions of C (they don't need to be!) As /u/kloetzl said, 21st century C is great, and K. N. King's C, a modern approach is also a good textbook for reference. I also recommend the Linux kernel coding style, it has become very common for UNIX like system programmers. I put [this](https://reddit.com/r/C_Programming/comments/47mk4x/compilation_of_c_software_design_principles_and/) post together a few months ago, which may be useful to you also. 
Thanks will definitely read the coding style in the Linux documentation and spit through your post. Thanks!
&gt; First off, I'd suggest printing out a copy of the GNU coding standards, and NOT read it. Burn them, it's a great symbolic gesture. HAHAHA
Happy to help!
&gt; Btw K&amp;R style is outdated, right? XD Not really. You can still program in K&amp;R style, that's fine. Some people don't like it, but if it does the trick it's not wrong. You should however not program in Whitney style (example [here](https://github.com/jsoftware/jsource)) unless you are either an APL programmer, insane, or you know what you are doing. &gt; After some searching on the internet I found this article. Is this the right way to write modern C or is this just a developer that is trying to sound smart? I recommend you to read [this response](https://github.com/Keith-S-Thompson/how-to-c-response). Personally, I disagree with many points in the original how-to-C article. To me it indicates that the author is inexperienced and does not understand the rationale behind why C is the way it is. &gt; Another question: Are the the new interfaces that "C Interfaces &amp; Implementations", like his own assert.h, mem.h, etc necessary? They are not necessary and the author is just trying to make himself look smart. If you strive for a ridiculous level of portability (as in still-runs-on-1986-ULTRIX portable), then you are going to need such a wrapper. However, if you understand the constraints of this level of portability, you probably aren't going to need my advice anyway. My advice: Know your standards. There are two important industry standards regarding C: ISO 9899 (The C Programming language) and IEEE 1003.1 (POSIX.1). You should get familiar with both of them. If you only assume what the standards say, then your programs are going to be very portable. However, this requires a lot of practice as you need to understand the standards and their motivations in order to intuitively program according to the constraints imposed by them. About code quality: Few superficial things indicate code quality. Do not worry about the number of gotos, the lengths of your identifier names, how many global variables you use or what fancy design patterns you implement. The important part about code quality is that the code is * easy to understand or well-explained if that isn't possible * has an intuitive design that follows naturally from the thing it does * is split into chunk of easily digestable size * is documented Good code is hard to describe as a set of rules. Instead, practice writing code. Try to design every single of your internal interfaces as if it was a library you deliver to a customer. Put a lot of thought into making the structure and flow of data clear, the algorithms often follow immediately and clearly from how the data is structured. Make sure to document each design choice so other people (including [your future selves](http://catb.org/esr/writings/unix-koans/prodigy.html)) can understand your ideas. Your code does not need to be self-evident, but reading the design document should be enough to find yourself around the rest.
By Jove. Hello OP, I said [exactly the same thing](https://www.reddit.com/r/learnprogramming/comments/4x0ljg/just_started_learn_python_the_hard_way_and_need/d6bwgu0) yesterday about Learn Python the Hard Way. This might not be a coincidence.
Coincidentally, I read Shaw's rant [Admitting Defeat On K&amp;R](https://zedshaw.com/2015/01/04/admitting-defeat-on-kr-in-lcthw/) today. I decided to learn more about him after a discussion about Learn Python the Hard Way (which I tried then decided to read another book, because of the reasons mentioned in this thread... Same problems with his C tutorial).
I will test it out and get back to you, thanks.
SMP with caches....yuck.
Most of the way through Modern C by K. N. King. Great resource to learn C from scratch with little previous experience.
Most of my C programming is in the embedded world, which tends to be more conservative, slower to adopt new standards, and more efficiency oriented. Still, I can vouch for at least some of what he's saying. I've been learning all of the MISRA-C rules and there's definitely some overlap. I think even for non-embedded programmers, something like MISRA-C is worth looking over. Technically none of my products are really safety critical but many of the rules focus on clarity and defensive programming and can be applied anywhere. I've got my copy of C Interfaces and Implementations right here. I forget now where I left off with it and I should probably skim through it again.
Month not modified in your leap condition.
How would I do that ?
Examine the path your code takes in the case of `1 3 1999` and compare it to the path taken for `1 4 1999`. Since you're wondering why the month doesn't change, pay special attention to any handling of the month. This is the basis for any debugging strategy on the face of the planet and is simple to do for small, simple programs. Since `month` is declared `int`, you can consider decrementing `month` unconditionally when `day` is `1`, and then setting `month` to `12` if it ends up being `0`.
I really hope that code is generated by a program and not a human.
sorry am a noob. but what part of the code would i change?
For future reference, it is better to put your code in text either in the post or in a pastebin so we can copy and paste bits and pieces.
Note that the Linux kernel style is just an adaption of thr KNF (kernel normal form) style used by BSD systems.
What I want you to do is to explain on a high level what the program does. Something like "component A does that and that, B does this, etc." Also tell us how data flows through the program.
Many people have different ideas about how to program C. That's a good thing. C is the chisel with which you can carve sculptures in any art style you like.
It's a pleasure to me. But seriously, writing good comments is hard. You should practice doing that a lot.
In this case, negative sz is a valid value. /* Discard data from bufio. * if sz &gt; 0 data is discarded from bufio tail. * if sz &lt; 0 data is discarded from bufio head. */ void bufio_discard(bufio_t *p, ssize_t sz);
Strange design. I would write two separate functions for that. Do you handle the case when `INT_MIN` is passed as the size?
Even though I'm not a professional C programmer I think his article does not show what modern C is. Take just the part he says not to use int when it's the most natural integer type on any given machine.. To me modern C looks well organized, does not contain complicated code and or document it extensively, have descriptive variables and functions names, is well commented from the beginning till the end and the results (program or API) must be easy to use and fast to learn. Basically, that's a long way of saying I agree with most people on this post :) 
Parameters to functions are passed by value. Say you have a function f(int arg) { return arg * 2;}, you set arg to 4, and call it like f(arg) . after the function has completed you would expect arg to be 8,but in reality it's going to be still 4. That's cause a copy of arg is passed to f() and f() works on that copy. If you want to modify the value from within the function, it's prototype should be f(int *arg) and you should invoke it like that: f(&amp;arg) (&amp; == the address of operator) that way you pass the address in memory of arg, allowing the function f() to modify the contents &amp;arg is pointing to. 
&gt;Strange design. I would write two separate functions for that. python still influences me ;-) &gt;Do you handle the case when INT_MIN is passed as the size? I think nothing happens. If sz is negative it is multiplied by -1 and truncated to the size of data inside buffer. 
I would prefer to link to the [official SQLite repo](https://www.sqlite.org/src/doc/trunk/README.md)
I think K&amp;R second edition was ANSI C though, not the true K&amp;R style C that was in the first edition 1978 (the only one I have read), so the book OP asked about is not by far as obsolete as the first edition? Not even sure if all the code from the first edition goes through a modern compiler without errors?
I think OP was asking about the programming style, not the exact syntax. The style demonstrated in K&amp;R uses global variables for data that is shared between functions and emphasizes simplicity over correctness or reusability. It is by any means not wrong to program this way, but for many applications it's not appropriate.
Yeah I was referencing to the programming style.
Troll x Troll: http://harmful.cat-v.org/software/c++/linus
&gt;&gt; explain on a high level what the program does how data flows through the program &gt; Why did nobody explain it like this before! I've been working on a theory for the past few years... *Reading* code is very difficult. It's a totally different skill from writing code. And it's a skill that universities generally don't teach. For your first year or so, you're working on tiny little homeworks that often fit on a couple of pages. Truth be told, there really isn't a need for comments, because the code is small enough that someone probably could read it and figure it all out. But they want to instill good habits, so they usually force you to add obnoxious comments, follow obnoxious style rules like "no variable names shorter than 6 characters", etc. Then you get into 3rd and 4th year projects, and they're a lot larger, but they're still mostly write-only. The code is at most a couple of months old, and you or your teammates wrote all of it, so it's fresh in your mind. Comments still aren't that necessary, because you can still hold almost the whole thing in your head. When you get into industry, everything changes. Suddenly you *didn't* write all of the code, and there's a lot more of it. Now you have to *read* code to figure out what it does, and that's a skill that university won't teach you. That's where comments are useful, but university didn't explain that. The standard practice is that you just have to live it and do it for a few years, and you'll start to understand what level and kind of commenting is necessary.
&gt; complicated string handling in C What complicated string handling? Strings in C are easy, you just need to know your way around the standard library. Everything you need is already implemented somewhere. &gt; This means that eventually all string data will be overwritten. Is there any guarantee how long a string will be usable? Because with what you say, it seems like you can only safely use one string until you make the next because the next string could already cause the previous one to expire.
eh, it starts getting a bit more complicated when you start to deal with unicode. But, it is fairly easy to pick up and get running with. 
Yeah, that's the problem I'm struggling with I guess. I know how to write code that is readable (I guess) when you know what the program is about. The forced commenting like: /* * Add two numbers together * @param int first_number: the first number you want to add * @param int second_number: the second number you want to add * @return int answer: the addition of the first and second number */ public int addNumbers(int first_number, int second_number) { return first_number + second_number; } After a couple of homework assignments and a project I thought this was madness, which it is XD. Now I am looking to find a balance between almost no comments and comments everything like a madman. Looking for answers online doesn't always help. The examples are almost always small programs that fit on a sheet of paper, where it looks overdone. A lot of people programming python will tel you that commenting is a sin and that is shows you that your function and variable names aren't right. Because why should you use comments when you code is easy to read and understandable? [A semi related topic] For a couple of month now I want to use my programming skills in open-source projects on github. The problem I'm facing here is that the code bases are HUGE! nothing compared to the 2000 line programs I have written for school. How will I ever be able to help an open-source project? Just the step from simple programming assignment towards a big complex project is daunting! Like their is missing a step in between. Thanks in advance.
Please post code as text, not as a screenshot.
These comments are very useful! They are exactly what is needed to quickly understand what is going on.
 char rslt[100] ; strcpy(rslt,s1) ; strcat(rslt,s2) ; strcat(rslt,s3) ; somefunction(rslt) ; bcomes: somefunction(txtConcat(s1,s2,s3,NULL)) ; 
Well, why not just char rslt[100]; sprintf(rslt, "%s%s%s", s1, s2, s3); somefunction(rslt); And what if `somefunction` uses milk strings, too? Any guarantee that the result of `txtConcat` won't be gone by the time `somefunction` starts to process its argument? You could also make it in two lines: char rslt[100]; somefunction(strcat(strcat(strcpy(rslt, s1), s2), s3)); But that's less readable. Conveniently, your code doesn't handle any errors, so I don't do that either.
Thanks, almost nobody ever tells me at university if I'm doing it right. &gt; It works so you get a 7.5/10 It really means something to me that a random stranger tells me that I have the chance to become a good software developer. @everybody you guys rule! I love small subs. edit: lol this got it's own thread so almost nobody will see this
&gt; The harm is that you need to explicitly deallocate strings in the fridge. I wonder what future generations will think when they read this sentence.
You might want to check out /r/noContext.
I didn't know that sub. But our fridge is probably not sexually oriented enough for them :-)
It looks like fridge handling is just wrappers over `malloc` and `free`. For the price of `clearfridge` and `unfridge` being O(n) worse than `free`, you get the ability to _implicitly_ get a heap-allocated copy of a stack-allocated string. You also defeat part of `malloc`'s purpose, since your string can never be longer than the buffer it came from.
Someone else explained to me a little bit about the memset command in the other post I made, but what happened is I needed to clear out the string because if I had a 7 character word before a 4 character word then the whole thing wouldn't clear, there would be some leftover characters in the string that would show up. So ,me being fairly new to C, I looked up how to clear out a string and that was what I found. I realize now that it isn't the proper way to do it though. As for the structure, I understand what you mean. This is really my first actual program I've written in C so I don't have a ton of experience in different ways of doing things. The first cracking program worked fine and I didn't think going through a file one word at a time would really be a huge deal since it only has to go through it once. I didn't see the immediate benefit of reading the whole thing into a linked list or something similar, but I guess with the second program reading through the text file every single time I need to make a call to the crack function probably isn't the best way to go about it. I was more just trying to get it to work with the base design of the first program I wrote. It's just a school project, similar to the science fair but a bit bigger than that, so I wasn't insanely worried about the performance, but that doesn't mean I shouldn't make it as best as I can. Thanks for your input, it's really helpful. 
&gt; Now I am looking to find a balance between almost no comments and comments everything like a madman. Don't try to follow some prescription, comment as you want to see it commented. &gt; A lot of people programming python will tel you that commenting is a sin and that is shows you that your function and variable names aren't right. Because why should you use comments when you code is easy to read and understandable? This attitude is relatively rare in practice, but it's a problem. It's not that I want to read comments instead of comprehendable code, it's that I want to read comments about **why* the code is the way it is, which parts needs special attention, and pointers to other sources of information. It's not like you're going to communicate that in code all the time. int vendor_api_ver3_docs_wrong_see_jira_ticket_abc1234() #define FIXME_INVESTIGATE_PLATFORM_PORTABILITY_MAXINT32 (2^32 -1) typedef struct reverse_engineered_from_foo { type_t *not_sure_what_this_is_yet1; type_t *not_sure_what_this_is_yet2; type_t *not_sure_what_this_is_yet3; type_t *not_sure_what_this_is_yet4; type_t *not_sure_what_this_is_yet5; type_t *not_sure_what_this_is_yet6; } bartype; Besides, how to you embed the URL of the StackExchange reference into your code without a comment? Is there a URL type in Haskell? 
I will take a look at github for a small project and try to contribute to it. I already figured out that it's impossible with the 3 years of experience that I have to contribute to large projects like the linux kernel or NGINX etc.
Note that in cases like that I have to tentatively assume that the original programmer didn't know what she or he was doing. Even if there was a comment about not knowing why they had to have the test backwards to get it to work, I would at least know the dev knew it was wrong. I think this was just covered up instead of being fixed properly. In another case I spent the better part of a converting a piece of legacy code from an unmaintained deprecated library to an equivalent maintained library, but could never get the new library to work against a web API no matter what I tried. In the process I found swapped variable names which made me think the original dev didn't understand either, or was in a real hurry. In the end my best guess is that the original programmer couldn't get the popular library to work either, but didn't put in a comment or a doc that would have saved me all that time and anguish. 
Interesting. But so far I've only done front-end related jobs, I don't see much demand for C. I'm curious for what tasks do you use it ?
My favorite part is: &gt;First off, I'd suggest printing out a copy of the GNU coding standards, &gt;and NOT read it. Burn them, it's a great symbolic gesture.
Note that this is sprintf, which prints into strings.
NGL, this revelation is gonna drop like 6 functions from my code man, seriously thanks for this info.
Also look at asprintf.
Strings are not stack allocated. They are allocated in the global buffer "txtPool" . For debugging you can add some code to txtFixPool() to see how long this "eventually" is. This code was made with an embedded system in mind where strings are only used to write data to the HMI. In such a system 99% of strings only need a short life. The heap is used for the 1% that need to be kept. 
&gt;&gt; int i = 0; &gt; in a for loop in C is always a index, so why would you write index instead of i? Also using Size instead on len is not clear to me. In my opinion len == length of a string, size == size of an array. Specifically, i, j, and k are idiomatic counters for loops in C (inherited from Fortran, I believe) and len is the idiomatic length of a string. The preprocessor is absolutely essential for some things, and if you've never used it I question the environments in which you've coded C. snake_case is idiomatic C, especially on Unix. CamelCase is a Microsoft/Borland microcomputer C++ idiom, as is Systems Hungarian. Using descriptive names is great, but understand that the proponents of zero comments and self-descriptive code were originally Smalltalkers who later moved to other Object Oriented Programming languages. Their ideas don't always directly apply in purely-structured and functional programming environments.
C++ has diverged from being a superset of C, and is a *very* complex language in total. Most practitioners choose to use a subset of C++. Check out the Google style guidelines, for instance, where they don't use exceptions among other things. C++ was sold as being a better C, but this certainly isn't true today. C++ is popular among programmers on Windows because their tools barely support C and everyone they know uses C++. Big Commercial Games programmers, who overlap a very large amount with Windows programmers, also usually use C++ because their commercial middleware is probably in C++ and they think C++ is better at large, monolithic, multithreaded programs on Windows. These devs also seem to bow to convention a lot; for example they tend to ship 32-bit binaries even in 2016. Lastly, programmers of large monolithic cross-platform applications often choose C++ because they think they need the inheritance and modularity features in their large project. Examples are Firefox, Krita, and GTK+. 
What kind of front-end? Libraries are often done in C in order to use the clean C ABI, although C++ can also extern "C" and get the same result, I think. Embedded systems almost always use C today. Performance-critical infrastructure usually uses C, which is slightly faster than C++ as a general rule. Kernels, webservers, databases, message queues, [games](http://www.battleforthesolarsystem.com/games/pw/), compilers, utilities, [DVCSs](https://git-scm.com/), runtime interpreters. What languages were you using for web front-end? Surely not C++ either. 
&gt; their tools barely support C Sorry but I don't understand this. Could you explain me (very shortly) why is C++ well supported on Windows while C, less complex, isn't ? Thanks for your insights, they are very enlightening. My primary concern when playing around with C or C++ is making it cross-platform.
There is also vsnprintf (va_list param, string buffer, limited to n bytes). My theory is that you can prefix printf with any 3-letter combo and it will still compile.
Thanks for your time, I read about some of this, but it is a lot more clear explained by you. I wish you success with your projects.
As someone who moved from college programming, to entirely 'for myself' programming, to "regularly contributes to big name open source projects", the notion of self-documenting code... only reaches so far. IMHO, you need to do two things when writing code: a) good variable names and function names. Good function names should impart what the function does. Good variables are a bit more looser, as a variable such as a loop counter or pointer to current element of a collection aren't really worthing fretting about. Keep them short and simple. What really does matter for commenting, is that it's not for *you*. It's for the person after you whose fixing your code or extending code. So, write in (a) comment(s) **What** a function is doing. If it's non-trivial (again think of the person after you) explain **How** you are doing it. Other times the **Why** this code is also necessary, e.g. why does this heuristic consider input &lt; 4 as false? Also, don't be shy to write notes explaining or hi-lighting shortcomings, deficiencies in how the cases are handled, FIXME:, TODO:, ???: This really needs an explanation, "We could do X here by in case Y..". The relevant history and reasoning behind any commented block of logic is highly valuable. Consider: https://github.com/gcc-mirror/gcc/blob/master/gcc/config/mips/mips.c#L7891 Recently I modified some code in a 3 line function. Only one of which was right. No comments, no explanations (though I do know why 1 of the lines was wrong, after spending 10 minutes digging through git blame/git show x/git blame x~). If you thought you got away from English by doing CS, you (and me) were sadly mistaken. Delayed punchline: The person after you fixing the code might well be you. 
Probably true.
I love the concept of milk in the fridge 'n' I'm a vegan rofl. A lot of programmers get caught in the negatives, but ya gotta swerve around it 'n' keep jivin', if we aren't coming up with new ways of doin' stuff we may as well be stuck in the 1990s, heh. Great work. :-)
Neither standard C nor POSIX, unfortunately. (Or has it changed?).
A few notes: * Use `typedef` instead of `#define` for `txt`. These are not equivalent, and the former is far less error-prone. * Libraries generally shouldn't print error messages. Report the error to the caller and let the the caller do it. * The GPL basically ensures that no one will ever use this. Only libraries that have substantial, unique value can get away with it. 
You can also use certain options on GCC (as an example) to produce *raw executables*, or machine code sans the metadata. I don't know if this will be helpful to you, but if you're developing for some place that isn't bound to Windows or Linux or some other OS, you're going to need, well, just the machine code
It is very hard to tell you what's wrong with code I haven't seen. Could you show us your faulty code?
While your thought is correct and useful, note that such conventions can get out of hand. Remember the example on Whitney style I gave before? Well, it's very readable once you get familiar with the extensive amount of conventions the programmers use. Basically every variable name is by convention only used for a single kind of variable, so no more complex names are needed. You should use conventions, but only in moderation.
The WIN32 API has a hard-on for reducing memory allocations. The API tries to avoid having to allocate memory [to a ridiculous degree](https://mollyrocket.com/casey/stream_0029.html). It is easier to use such an API when the uggly memory-management parts are hidden in C++ magic, so that's why the API is easier to use from C++. I think it is just a shitty design. They need to work [a lot](http://www.dmst.aueb.gr/dds/pubs/jrnl/1997-CSI-WinApi/html/win.html) on their API. I think you can demonstrate every single thing you can do wrong with making APIs on the Windows API.
&gt; modern Unix and the Internet mostly uses the much better and more elegant UTF-8. Good UNIX programs are encoding-agnostic. They use whatever the locale is configured to. UTF-8 is one choice, but many systems are configured to different locales. For example, some German systems use ISO-8859-1, Japanese like Shift-JIS, Taiwanese like BIG-5. UNIX software needs to deal with all of these, but luckily, good support for locales exists.
"Libraries generally shouldn't print error messages. Report the error to the caller and let the the caller do it." Wouldn't it be conforming to the "transparency" law to print error message when one of the library's internals fails? By simply reporting an error code, isn't that being too quiet? "The GPL basically ensures that no one will ever use this. Only libraries that have substantial, unique value can get away with it." The license ensure that no one will take your work and make it his own, ensures that your work is free and stays free, also obliges anyone using your code to divulge at least the source code containing your GPLed project. How can GPL be bad for an open-source, free project?
Placing a library under the GPL ensures that you can only use it from GPL projects. Not all programmers want to put their projects under the GPL license, so for all those who don't want to, your library is not useful.
How popular is the GPL in the community and in the industry? Is it worth thinking switching to a more permissive license like the 'lesser GPL'? You seem very experienced (FUZxxl), what to you think about a library being verbose on failure by default?
I am not a huge fan of the GPL because I believe that its virulent properties are both unfair and hard to enforce. Yes, the GPL has been tested multiple times in court but very few of these cases actually concern the virulent property. A full legal discussion would be too much for this comment, so let's just say this: If you want to get around the GPL's virulent properties in a product, you can always design your software such that the GPL piece is a separate component that your software merely interacts with. The product is a collection of works, one of which is GPL licensed. The virulent property does not apply to the other pieces in the collection, making it ineffective. Stallman is apparently [aware](https://lwn.net/Articles/629259/) of this issue and tries to sabotage the gcc project so its intermediate representation isn't useful for potentially proprietary software. Do you want to put your work under a license that encourages such destructive behaviour? If I want to force people to give back, I prefer licenses with realistic demands, such as Sun's CDDL (mostly equivalent to Mozilla's MPL). This license only demands that you give back changes to the CDDL-licensed software. It does not infect other parts of the program and protects your software from abusive patent disputes. The latter clause is so successful that the FSF introduced a similar clause into the GPL3, making it incompatible to the GPL2 in the process. Personally, I put most of my work under a BSD license. This fits my own interpretation of *free* (as in free speech) because freedom always means that the party you admit freedom to also has the freedom to decide to no longer participate in your project. GPL on the other hand is almost fascistic. While you do have the freedom to derive your own software from a GPL-licensed project, you cannot implement your own license ideas on parts you made. You are forced to participate, or get rid of all GPL-licensed parts. That's not freedom.
&gt; Shouldn't it be *ret=malloc(size+1);? Yeah, it should be. I shouldn't write code so early in the morning. That's the kind of error you find on the first run of your test suite under valgrind. Or (if you are running OpenBSD) on the first run. &gt; if (size &lt; 0) return -1; asprintf() is documented to have the same set of results as `sprintf()` unless `malloc()` fails, in which case `-1` is returned. Thus the way I wrote it. The [glibc implementation](https://sourceware.org/git/?p=glibc.git;a=blob_plain;f=libio/vasprintf.c;hb=HEAD) is a bit confusing (as always) but it basically does the same thing I do: ret = _IO_vfprintf (&amp;sf._sbf._f, format, args); if (ret &lt; 0) { free (sf._sbf._f._IO_buf_base); return ret; } The [FreeBSD implementation](https://github.com/freebsd/freebsd/blob/master/lib/libc/stdio/vasprintf.c) on the other hand returns -1 and assumes that `vfprintf` cannot fail for any other reason than an out-of-memory condition: ret = __vfprintf(&amp;f, locale, fmt, ap); if (ret &lt; 0) { free(f._bf._base); *str = NULL; errno = ENOMEM; return (-1); } However, that is not correct. `vfprintf` could still fail with `EILSEQ`; I believe the implementation is incorrect.
I do get your points and you're making me think a lot. The reason why I used a license in the first place is not cause I don't want people to make money out of my project, I think I would be flattered more than insulted, but to be sure that no matter who uses it, the source stays available for free and that they don't remove my name as "the author of this library or tool". I personally don't mind if a private company would grab Libfindf.so and include it to their own closed source project, so long as whatever upgrade they do on Libfindf itself is freely available for anyone. Is that even possible? The reason why I didn't even look at Sun's CDDL is mostly because Sun is now Oracle and even though I'm a beginner in the IT world.. I don't like the company. The irony: I did install a copy of Solaris 11 as a guest virtual-box OS. (Havn't tried to install Libfindf on Solaris yet, stuck at setting up shared folder between my Debian host and the guest Sol OS). I stayed away from looking into the BSD license cause I found it ironic to have a BSD license on a strict GNU project (I wanted to try compiling on FreeBSD but stuck at trying to either make a shared folder with my host or to simply mount a usb stick, which seems to flip on the dirty bit every time I try to mount it on the BSD guest.. that's just me being a true noob. ;) ). Does a BSD license fit on a GNU project? Does the MIT license is worth looking into? The lesser GPL seems an option, but would surely have the same legal problems as you mentioned above, what do you think? Is there a place where I can find arbitrary information on all (or most) open-source/free license? (Places unlike the GNU website which is sold to their own license, of course.) I've search on Google but all sources I found seems to strongly favor a license over another, when I'd really just want a humanly readable description of each and figure out which one I'd like myself. Thank you for your time!
&gt; The reason why I used a license in the first place is not cause I don't want people to make money out of my project, I think I would be flattered more than insulted, but to be sure that no matter who uses it, the source stays available for free and that they don't remove my name as "the author of this library or tool". I can understand your concern. Note that none of the common open source licenses prohibit people from making money from random open source projects. Not even the GPL says “you can't sell this software.” It is widely agreed that a section to that effect is not in the spirit of free software. &gt; I personally don't mind if a private company would grab Libfindf.so and include it to their own closed source project, so long as whatever upgrade they do on Libfindf itself is freely available for anyone. Is that even possible? Yes. That's what the CDDL essentially says. Changed files must be given back, but things you built around the code doesn't. The GPL also achieves this objective (this is a generally enforceable part of the GPL). &gt; The reason why I didn't even look at Sun's CDDL is mostly because Sun is now Oracle and even though I'm a beginner in the IT world.. I don't like the company. The irony: I did install a copy of Solaris 11 as a guest virtual-box OS. (Havn't tried to install Libfindf on Solaris yet, stuck at setting up shared folder between my Debian host and the guest Sol OS). You raise a good point. Though, the CDDL was written up before Sun was acquired. It is the result of the concerns Sun's engineers had with the GPL and other possible open source licenses when the open-sourcing of Solaris was first discussed. &gt; I stayed away from looking into the BSD license cause I found it ironic to have a BSD license on a strict GNU project (I wanted to try compiling on FreeBSD but stuck at trying to either make a shared folder with my host or to simply mount a usb stick, which seems to flip on the dirty bit every time I try to mount it on the BSD guest.. that's just me being a true noob. ;) ). I'm not sure what you mean with “a strict GNU project.” I actually use FreeBSD as my main operating system but I'm not sure what the problem is. &gt; Does a BSD license fit on a GNU project? Does the MIT license is worth looking into? The lesser GPL seems an option, but would surely have the same legal problems as you mentioned above, what do you think? Not sure what “a GNU project” is. The MIT license is very similar to the 2-clause BSD license. Lesser GPL is a good license if you want to have something very similar to the GPL that is still usable by non-GPL projects. Read the license or some commentary for details. &gt; Is there a place where I can find arbitrary information on all (or most) open-source/free license? (Places unlike the GNU website which is sold to their own license, of course.) I've search on Google but all sources I found seems to strongly favor a license over another, when I'd really just want a humanly readable description of each and figure out which one I'd like myself. I've also notice that the FSF tries very hard to sell their own license. Some of their descriptions seem to be intentionally vague to make people not want to use other licenses. You can check out the [open source initiative](https://opensource.org/licenses) for a more neutral point of view.
&gt; asprintf() is documented to have the same set of results as sprintf() unless malloc() fails, in which case -1 is returned. Hmm, documented by whom? I ask because my Linux man page for `asprintf()` says: &gt; When successful, these functions return the number of bytes printed, just like sprintf(3). If memory allocation wasn't possible, or some other error occurs, these functions will return -1. The OpenBSD the man page is common to all `*printf()` functions and just says about errors: &gt; For all these functions if an output or encoding error occurs, a value of -1 is returned. and &gt; asprintf() and vasprintf() [...] If sufficient space cannot be allocated, these functions will return -1. So, no other error return value is mentioned. &gt; The glibc implementation[1] is a bit confusing (as always) but it basically does the same thing I do: ret = _IO_vfprintf (&amp;sf._sbf._f, format, args); if (ret &lt; 0) { free (sf._sbf._f._IO_buf_base); return ret; } So, if `_IO_vfprintf()` always returns `-1`, we're good, otherwise the implementation contradicts Linux man page (despite Linux providing glibc). Looking at `stdio-common/vfprintf.c` (irkkk), it seems (well, 'seems' after browsing this mess for 2 minutes, so that's not a definitive answer :-) )to return `-1`... except in a case, where it returns `EOF`. `EOF` doesn't have to be `-1`, but since we're talking implementation, in this implementation it is #defined to `-1`. So it looks like `glibc` implementation of `asprintf()` returns -1 in all error cases.
So we're good here. Note that at least POSIX mandates `EOF` to be `-1`. ISO 9899:2011 says it has to be a negative constant expression typed `int`. I'm seriously surprised if there is any platform where `EOF` is not `-1`. Still, seems like the FreeBSD implementation is broken with respect to what it sets `errno` to.
Thanks for the link you provided, it seems I'll get most of the information I need to make a better decision. By 'strict GNU project' I meant one made using GNU extensions. After a quick glance at my code, it follows the POSIX standard (or mostly follows), not using any GNU/Linux specific extensions so my concern on this point were not only said badly but also not founded.
&gt; So we're good here. We're good for GNU implementation, but not yet for yours, that's why I asked if you found some documentation telling that `asprintf()` is allowed to return something else than `-1`. (I mean, once again, it is mostly cosmetic, not a big deal, eh :-) ) &gt; Note that at least POSIX mandates EOF to be -1. Ah, all right, I didn't know, I just looked at C standard. &gt; Still, seems like the FreeBSD implementation is broken with respect to what it sets errno to. Is it 'broken' or just 'inaccurate'? I mean, what `asprintf()` should put in `errno` is not documented anywhere, is it? So, it can put whatever it wants in it, I guess. Or does the C standard tell that `errno` must always be accurate? But it would have been simpler and more accurate to *not* set `errno` 'manually' in `asprintf()` and just let the `errno` various values set by `__vfprintf()` propagate, that's a sure thing. 
A book that is very useful to learn about threads is "Advanced Programming in the UNIX Environment, 2nd Edition" (you can probably find it in your local library, which is what I did). If you look up `pthread` there it should give you a good description of UNIX POSIX threads and a lot of examples.
Yeah, I'm not really trying to learn one way to do it, and with C11 threads being a thing (that aren't supported by damn near anyone :( ) I kinda just want to learn it generically. Sorry, I should've included that in my post.
Very helpful. I'll be c ross-compiling for AVR microcontrollers. I learned that GCC will produce an ELF file(still learning what it is) with extra info I won't need. But there is a command you can send to GCC to just extract the Intell Hex file.
This looks really cool, thanks!
any reading recommendations for advanced vim techniques/navigations? I can do basic stuff (use file explorer, copy/paste, multiple buffers), but I'm sure there's really cool stuff that can be done that I'm not aware of
Sounds like you want to learn about **concurrency** in general, and not just multithreading. [Here is some starter material on multiprogramming by esr.](http://www.catb.org/esr/writings/taoup/html/multiprogramchapter.html) There are a lot of concurrency and lock-eliding libraries for C. For the record, the mingw-w64 stack can do [pthreads on Windows](http://locklessinc.com/articles/pthreads_on_windows/), so pthreads is portable. More portable than bringing Win32/MFC to Unix, I imagine. 
I develop on a Mac/FreeBSD, and recently decided that I wasn't even gonna try supporting windows lol. Thanks for the link.
Check out "Programming with POSIX threads" by Butenhof. It assumes you know nothing about threads or any other form of asynchronous programming. But know C fairly well.
Are the expressions `S0` and `S1` in your code macros? Or, importantly, *could* they be macros in a future implementation? If so, then consider this rabbit hole ... if the condition `S0` is a macro and its definition contains, say, a function call ... then of course the value of that "same condition" `S0` could vary between evaluations in subsequent `if` statements.
It's better to learn the concepts behind concurrency and parallelism, then worry about doing it the C way, or you're going to get frustrated. The two books that I recommend are *C++ Concurrency in Action* because it's awesome and gives a lot of background on things like synchronization and the various terms you've seen elsewhere. C++ isn't super different from C relative to other languages, and it's trivial to search you `man` pages for the equivalent pthread_* fn you would use in C instead. The other is *The Little Book of Semaphores*, because rather than being definition driven, it's incremental-problem-solution based and makes you think through synchronization problems and builds on previous material. &gt; Where can I learn about this, in a C-like way? (aka no classes or templates or any of that nonsense). That statement is non-sense. Are you learning C for the right reasons?
What are "the right reasons"? I want my code to be portable, performant and compiled (for use in embedded devices), that's why I've chosen C over C++, java, etc... Edit: That's why I'm holding out hope for threads.h in the standard, because some platforms don't have POSIX available, but the standard itself should be supported damn near everywhere.
Paul E. McKenney's "Is Parallel Programming Hard, And, If So, What Can You Do About It?" is great: https://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html
I understand and try this sqlite database solution, thank you!
Warning, nitpicking ahead. &gt; NULL does not need to be a pointer — it is valid for an implementation to define NULL as &gt; #define NULL 0 &gt; so it is not portable to pass NULL to a va_arg function, as this will fail for architectures where sizeof(int)!=sizeof(void*). It should not be "this will fail", but "this can fail". Because there are a few cases in which you'll be saved (supposing the value of the null pointer is 0), for example: * if the parameters are passed as a stack and there is padding (hopefully filled with zeroes) between parameters, the padding "equalises" the different type lengths; * if the parameter is last and a pointer is smaller than an int; * if the parameter is last and later bytes are 0; * if the parameters are passed as registers and the register space not occupied by int is filled with zeros.
I've heard that some programming courses require an antique compiler. And using DOSBOX may be faster than a full VM on older hardware.
Thanks. Will look into it
Watch TheNewBoston's series on C, there's roughly 57 videos all depicting different parts of C. It doesn't cover everything, but it's agood start.
Pretend the API already exists and write code against the API. This will give you a feel for how users will see and use the API. 
It's difficult, I haven't found any good books or tutorials on API design.
You have a good point but what most (good) books on Pthreads will teach you are the low level concept and mechanisms used by most threads API. While POSIX is not everywhere, I think most threading API are somewhat looking very close to Pthread. I mean locking a mutex may have a different name than 'pthread_mutex_lock' but the concept is exactly the same. At the moment, Pthread is the most portable multithreading API. Remember that "write once, run everwhere" is not much of a C thing ;) 
Edx have an online version of cs50 which is good. 
There is pthreads for countless platforms, even Windows. C11 support on the other hand is going to take a while to be available. Pthreads is the industry standard API, C11 threads is just a subset of pthreads not available anywhere.
I use this process as well, and since I started doing it I think most of my stuff is much less horrible :D
Quite frankly, nobody cares about Indian holidays in this subreddit. Perhaps you could post this to /r/india instead?
I would check for punctuation marks and spaces ( '.' , ' ', '!' , '?', etc.) and increment i to change the word counter when one of those is hit (Beware of the space after those and don't include the punctuation mark in the word). If not one of those is hit, just increment the j variable for the number of letters in the word. All that logic into a for loop incrementing k for the text parsing. It surely not the best algorithm but I think it can do the trick.
Do you care about keeping the original string in tact? If not then maybe look up strtok?
Thanks for the tip
[The C Programming Language](https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=the%20c%20programming%20language) is still useful for beginners.
I followed your tips and also changed from for nested loops to while nested loops and arrived at the desired result! while(text[k]!='\0') { while(text[k]!=' ' &amp;&amp; text[k]!='!' &amp;&amp; text[k]!=',' &amp;&amp; text[k]!='?' &amp;&amp; text[k]!='.') { words[i][j]=text[k]; k++; j++; } if(text[k]==' ') i++; j=0; k++; } Here it is ^
The application was to solve the Beale Cipher, in which a number corresponds to the first letter of a word in that position.
I have this book. It's really really good. 
Thanks a lot 
Cool. Neat little stripped down reimplementation of memcache.
A quick look at the first file I open: void set_handler(hash_table *table, char *key, char *value) { char *key_holder = malloc(strlen(key)); char *value_holder = malloc(strlen(value)); strcpy(key_holder, key); strcpy(value_holder, value); Kaboom!
Yep. In 100% of the cases.
&gt; It is possible to use strcpy safely. Definitely not this way! The source string is *n* characters + terminal 0. `strlen` returns *n*. He allocates room for *n* chars. And then `strcpy` writes the source string, i.e. the *n* characters + the terminal 0, thus *(n+1)* chars into it. The last char is written out of bounds. Kaboom. He must `malloc(strlen(...)+1)`.
Meh... I meant strstr()... Good catch. Corrected it
Head First C Programmming
Might be because I'm on my phone but some spacing and indentation would really help reading your code. Edit: If you edited your code, well done! else, my apologies, I'll burn down my phone ;) Here's a lil tip: Use meaningful variables names, it'll help you, and others understand more quickly what you meant.
After reading and trying your code, it does compiles and runs fine so to me it passes.. but hey I'm no teacher! Now you're making me realize I would have a hard time in cs classes. ;)
It's perfectly safe to cast -1 to an unsigned integer. It's defined to have clean, two's complement behavior. This reserves the highest value for error reporting (though the main program doesn't check for it). 
No that shouldn't matter, as the workspace array is only used inside the merge() function and the for-loop immediately after it and does not need to be preserved across merge_sort() calls.
Please define "Real Hackers".
Putting aside the "real hackers" bit, C is fundamental because the nature of the language is fundamental. It's as close as you can get to bare metal without using assembly. It allows you to make and break all kinds of things. It's ubiquitous. It's not "safe" so there are lots of potential exploits in programs written in C.
&gt;Because it's fundamental to software development in general. I would argue that the language needed is dictated by the area of hacking. I program in C more than any other language because I like banging on hardware. However, if I were more interested in PEN testing and other types of network hacking, Python would be a superior choice. Languages are tools, and no one tool is right for every application.
Sorry for my attempt to exclude the various definitions that hacker have today. I just thought it would improve the discussion 
Remaking the question: why C is fundamental for hackers? 
I'm so stealing that when I write the sequel to Hackers.
Remove the &amp; from the printf
If you have the anniversary update of Windows 10 you'll be able to enable the "Linux Subsystem for Windows" in Windows Features. This will provide what is basically an Ubuntu VM on top of windows and will give you a bash terminal which you'll be able to run gcc in. 
My apologies for the extremely late reply and thanks a lot for the explanation, the best one I've gotten!!
Here[](http://imgur.com/hT4D3Vy) is my graph for up to 400k elements. It's quite noisy on the random array after 200k elements. I'll be able to check in class in a couple days if I can't figure it out before then.
Lines 40 and 41 call merge_sort on different parts of the array, 40 on the first half and 41 on the second half, thus recursively splitting the array until it's small enough to deal with and start returning back. So (a+n/2) will start at the midpoint of the array, and (n-n/2) will define the endpoint of the array. I'm new to C and sorting algorithms, but I think this is a common way of implementing mergesort. Not sure about passing array parameters. I think they are treated the same? I will experiment with it when I can.
Thanks, that's an interesting read. I guess it's possible, with even the worst-case (reversed) data actually being predictable, compared to random data. But the fact that it sorts the data, albeit slowly, but fails the test script, leads me to believe I've done something wrong. In fact, I've just realised I haven't used any memory allocation in the program, so I'll modify that next.
 So (a+n/2) will start at the midpoint of the array That's what I thought you wanted it to do... So I'm not sure why you didn't also write `w+n/2`, since `w[0]` from line 40 is clobbered before its copied into `a` in the for loop
CS50x by Harvard University on edX is an excellent resource to learn C. There is an abundance of material provided as part of the course, and you can choose to learn at your own pace, depending on your comfort with the subject. It also has exciting and challenging Problem Sets, which help you learn and get comfortable with C. The 2016 we edition of the course uses and online shell emulator, so you gain experience with the Linux shell, but you don't need to go through the hassle of installing a VM on your system.
I think you need to separate two things here. One is knowing a language well i.e. its syntax, usage etc. The other is a systems architecture, understanding code that someone else wrote, operating system principles etc. I would suggest that once you are comfortable with C, maybe read up a book or two on the linux kernel and its architecture. I am absolutely no expert on linux, and I don't know what platform you have been coding C for, but you may also want to expand your knowledge of makefiles, compilers, and general working with linux. 
What do you mean by "lose myself into the code"? I think it is too generic for me to understand. Maybe give an example of what block you from coding something by yourself?
Your english is great :) Well, I can't really recommend a starting point for you, but maybe trying to understand the kernel more will also help your C skills. If you don't understand how something is done, maybe you can write a test code and see how it works yourself, if possible. 
I'm a big believer that one of the biggest impediments to learning to code is motivation. You need to find something that excites you enough to get through the frustration, because coding=frustration. If kernel drivers are your thing, then play around with kernel drivers. But, keep in mind, if you haven't got simple C code working yet, driver code is going to be a million times harder. Definitely you will fail to get anything working if you try it now. If the fun of playing with the kernel outweighs the frustration of not getting anything working, though, keep at it and you'll get there eventually.
&gt; if you haven't got simple C code working yet, driver code is going to be a million times harder. That's what I figured out after some Googleing, I'm gonna read the book that I mentioned and then start have fun (or just hating :P) Driver programming :) btw, I love your philosophy and I'll keep working on studing this stuff cause it keeps me motivated :)
&gt; but you may also want to expand your knowledge of makefiles, compilers, and general working with linux. Elaborating on this, switching to Gentoo and doing most of my work from the commandline (i.e. no desktop environment or file manager) has taught me a lot about Linux. Diving straight into kernel code is likely going to leave you lost, in no small part because a lot of it is dealing with specific bits of hardware and other weird cases. Getting a feel for how the system as a whole is put together lets you put the code you read into a useful context.
The outer printf() prints 0; the inner prints 3 because the second count definition supercedes--hides--the outer definition. From the Standard: "If an outer declaration of a lexically identical identifier exists in the same name space, it is hidden until the current scope terminates, after which it again becomes visible." Edit: Added normative text.
/u/rjt_gakusei is trying to distinguish between the cases int count = 0; int main(void) { printf("Count = %d\n", count); { int count = 3; { printf("Count = %d\n", count); &lt;=== this } func2(); &lt;=== and this } The 2^nd printf will print 3. func2 will print 0. Even though they are both "below" the `int count=3`. The answer is that, within a function the compiler will look up for the smallest scope containing the variable being referenced. So the 2^nd printf will look out and see the `count` which has a value of 3. But within `func2` the search for `count` will not cross the function call. It will not see the `count` with a value of 3 in main. It can only see the global `count` with a value of 0.
In Beej's guide: http://beej.us/guide/bgc/output/html/multipage/vars2.html#varscope It is the second code sample when saying `a = c` Also in the book that I am working through: Coding Interview Questions by Karumanchi, page 20 in the bottom. I think I realized the problem. The book was explaining the difference between dynamic scoping and static scoping, writing both examples in C, but in reality C does not use dynamic scoping. I guess I overlooked that.
Thanks for the comments. I think I found the source of the problem. I overlooked where the author of my book said that he wrote some of the code in C to explain concepts even though C does not use those implementations. I was just confused about dynamic scoping vs static scoping. C only uses the latter. I found a good website that has a perfect code sample explaining it: https://msujaws.wordpress.com/2011/05/03/static-vs-dynamic-scoping/ In short, dynamic scoping has functions look back through the stack for variable's value, while static scoping goes straight to the global variables symbol table (or global variable definition in this case).
Thanks! I was curious about why this was so, and turns out it's because C does not do dynamic scoping, so functions do not look through the stack of for variables, it just goes to the symbol table.
Oh right I get it now. I didn't even know the compiler allowed that but it sees that they are separate and assigns them separate addresses. Interesting.
xD that's a little too scary to think about
Being able to create scopes like that is one of my favorite things in C/C++. Sometimes you have a small block of code that doesn't warrant a new function but has a few variables you don't want used elsewhere in the function or you want to shadow a variable.
This is why it's good practice to name your global variables in a distinct way, like by prefixing them with g_. It's too easy to get confused.
No. You will not. Kernels are drivers depend on much more advanced topics that If-then and while loops. Call backs and signals, semaphores, etc etc etc. You have to talk to a lot of other software once you are in the kernel. 
*too
Huh, I didn't think of using the parentheses that way, nice.
I can't google what's in your mind. You just said that the route that i was thinking about wasn't the best, I just kindly asked what was your suggestion. Also, how am I supposed to understand those books if I can't understand some simple programs ?
ION is available in the Staging tree: [drivers/staging/android](https://github.com/torvalds/linux/tree/master/drivers/staging/android/ion)
**Include Files** Simple rule: include files should never include include files. If instead they state (in comments or implicitly) what files they need to have included first, the problem of deciding which files to include is pushed to the user (programmer) but in a way that's easy to handle and that, by construction, avoids multiple inclusions. Multiple inclusions are a bane of systems programming. It's not rare to have files included five or more times to compile a single C source file. The Unix /usr/include/sys stuff is terrible this way. There's a little dance involving #ifdef's that can prevent a file being read twice, but it's usually done wrong in practice - the #ifdef's are in the file itself, not the file that includes it. The result is often thousands of needless lines of code passing through the lexical analyzer, which is (in good compilers) the most expensive phase. Just follow the simple rule. [Notes on Programming in C by Rob Pike](http://doc.cat-v.org/bell_labs/pikestyle)
You may be interested in [Expert C Programming: Deep C Secrets](https://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298).
seems like a really good book, thanks a lot !
Also what I found a helpful resource was, when I started was: https://lwn.net/Kernel/LDD3/ or as merged PDF: http://free-electrons.com/doc/books/ldd3.pdf If you like the hardcopy, you can get it from amazon or a local bookstore probably. Not sure if there's better and how good it is for beginners. As I understand this is maybe too advanced for you: &gt; I know all the commands that are commonly used, but I can't actually code something by myself You should probably start **finishing** something small first and take it from there. Do you understand memory handling correctly? Do you know how to use pointers?
You're asking why the first argument is of type Node **, not Node *? Normally, the idea would be that you use it to both pass in a pointer value (*ppHead), and be able to modify the value, too (by writing to *ppHead). The caller's variable gets updated. Example: Node *pList = NULL; Node *pHead; pHead = insertLL(&amp;pList, 42); assert(pHead == pList); Because pList was passed by reference (with the &amp; in front of it), it is no longer NULL after the call to insertLL, but the newly created Node has been written to it. This happens to be the same value as pHead, which is returned from the function, because all new elements are inserted at the front. The question I would ask is another one. If this function always adds the new Node to the front of the list, why does it also return it? Isn't *ppHead guaranteed to be equal to pNew at the end of the function, so you're returning the same value twice, once as a return value, and once in the pHead reference? Bad design? 
You're correct, but I don't think he/she learned variables scope yet. 
Correct me if I'm wrong, but isn't using unions that way (reading another member but the one most recently written) undefined behavior?
It's he, and you're correct I haven't. I'd be grateful if someone would give me a noob friendly description though.
&gt; How should I handle my flag example? Pass the flag as a parameter. Relying on any kind of global state (regardless of whether it's static or extern) makes code harder to reason about. You should be able to tell how a function works by looking only at that function and nothing else. If a function relies on a global variable, then I can't reason about it. For example: int somevar; void foo(void) { bar(); ... if(somevar) { ... } } Does the call to `bar()` modify the global? Who knows. I'd have to look at `bar()` to find out. That's what I mean about requiring non-local knowledge. And what if `bar()` doesn't modify `somevar`, but some function that `bar()` calls (possibly several function calls deep) touches `somevar`. It's impossible to reason about the behavior of `foo()` without knowing all this other extraneous junk. You shouldn't write code like that, it's a recipe for spaghetti code where everything depends on everything. Moreover, relying on globals makes your code non-reentrant which leads to bugs that are very hard to debug. 
You will not go far. Your original question reveals that you have little to no drive to figure it out yourself. Unless you can do 3-5 hours a day hammering out code your skills will deteriorate. Like it or not, if you want to program google is going to be your main source of information. Programming is 80% stealing from others and 20% original code. 
Well we often refer to it with a hexadecimal number, but the actual values are of course in binary.
Here's a start: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; int main (int argc, char *argv[]) { const char *strs[3] = { "one", "two", "three" }; srand (time (NULL)); puts (strs[rand() % 3]); return 0; }
First of, there is no such thing as strings in the C language. "Strings" in C is a pointer to a NULL terminated char array. The task sounds easy enough. You would have to allocate an array of char array pointers. You already know how many "strings" are in this array. Now generate a random number between 0 and the array index size. int r = rand() % ARRAY_LENGTH; //ARRAY_LENGTH is the size of the array. I don't want to do the task for you, but this should get you started. If you post some code, I am happy to comment it.
Thank you for your reply! I understand what you mean and I have cases where I will be able to change my code accordingly. But for a few others, I don't see how to go without a global. One simplified example: I have a global x which represents a dynamic coef. Every 10ms, I call a function (foo) that calculates a new value for x and updates it based on other data. But every ms, I use x to calculate another value, in another function (bar), then I send that value via UART. How can I do that without having a global x shared by those two functions? (I can't call foo from inside bar because bar is time sensitive) Sorry if I'm missing something obvious here but I feel like this is important and I really want to improve my code!
Based on the output in the OP, it sure doesn't seem like it
The file contains `t1_t2_t3_` where `_` represents a newline character You're reading 3 bytes from the file : `t1_` And writing 4 bytes to the file `!t1_` The file now contains `!t1_2_t3_` 
Now I feel stupid :D. For some reason I made the assumption that lines are padded with spaces and I can write to them without overwriting the next line. Thank you
Do you have any suggestion how to deal with that? Maybe reopen the stream everytime in append mode and padding it with n characters, where n is the added amount of characters to the original input. I'm really trying to avoid reading the whole file in one sweep. That's the straight fourward solution I can think of, but I doubt is the most elegant. EDIT: I guess that won't work, since opening the stream in append mode, appends to the end of the file.
&gt; Also the font makes it look like the same test the same bedraggled old teacher has been getting out every year at the same time since the 1970s. Not even close. If it was written in the 1970s it would be typewritten, or at a stretch, TeX. Besides, C was quite rare to teach in the 1970s. COBOL, assembler, Simula, Lisp, Pascal possibly. This font is probably the same as a web-browser default in 1996, though. This is probably the same Word font that [outed Memogate](https://en.wikipedia.org/wiki/Killian_documents_controversy). 
Your intent is to prepend a `!` to every line? I'd use 2 files. Read `data` from the original, write `!data` to the new file. Repeat until done. Delete the original file, and rename the new file back to the original name.
Night and Day
Chalk and Cheese
Venus and mars
Love and Hate. 
You should invoke the compiler as `cc`, `c89`, `c99`, or `c11` in your portable Makefile.
The only thing C# shares with C is some basic syntax.
One semitone.
Butt and Butter
Back when, we used to refer to it as C++++ since the pluses can be combined to make the #, and it also is another degree of abstraction from C++ which is another degree from C. Its a loose analogy..
The very concept of the GPL being "viral" is laughable, because *you* are the person that chooses to use GPL code, meaning to be "viral" would be the equivalent of giving yourself a virus voluntarily then complaining that you got a virus and hating them. The LGPL exists just for the concept of libraries where people are free to use the library dynamically without subjecting their own code to being GPLed, but if you use LGPL code yourself (again, voluntarily) or statically link it (again, voluntarily), you have to use the GPL/LGPL and be subject to its terms. *Nothing* about this practice is at all viral. It's common sense and allows cooperation and promotion of free, shared code by everyone. The BSD licenses go absolutely against this concept by allowing the closing and co-opting of code by non-free sources and thus not promoting free software or the sharing and co-operation of coders, which is *less* free than the GPL/LGPL. Also, Stallman isn't sabotaging anything. You want to do something with GCC, a GPLed project, you're going to release under the GPL. It's pretty simple, and only people that are against the GPL due to their owned flawed idealism of hiding away code from the world due to greed, incompetence, or whatever other reason would object to something so open. There is no risk or problems using the (L)GPL if you want your library to be used, shared, improved, re-shared for the better, and to become greater and better than you can imagine (ideally, anyway). Fear of the GPL thanks to FUD and lies from those who try to hide software behind barriers cause negative attitudes about it, and is just another way companies get away with the widespread use of nonfree software that harm computing much more than it helps.
&gt; First of, there is no such thing as strings in the C language. &gt; &gt; "Strings" in C is a pointer to a NULL terminated char array. Of course there are strings in the C language. The C language specification refers to *string* or *strings* in a multitude of places. There's even a *`string.h`* header filled with functions that operate on *strings*. §7.1.1 of the C specification says: &gt; A string is a contiguous sequence of characters terminated by and including the first null character. The term multibyte string is sometimes used instead to emphasize special processing given to multibyte characters contained in the string or to avoid confusion with a wide string. A pointer to a string is a pointer to its initial (lowest addressed) character. The length of a string is the number of bytes preceding the null character and the value of a string is the sequence of the values of the contained characters, in order. Just because there is no dedicated type for strings (or the definition doesn't match other programming languages), it doesn't mean that *there is no such thing as strings in the C language*.
Apples and Durian.
Lol at these analogies...
*100 cents*, if you will.
Sounds like your professor is a three start programmer. ;) http://www.eskimo.com/~scs/cclass/int/sx8.html The final figure shows the state just before that assignment statement. Work through on paper what it looks like after the assignment (for removing the head node, then for removing node 2, ignore node two until you understand the head node case). Just like keeping track what gear you're in for a manual transmission, you want to keep track of how many indirections you're following. It might be helpful to think of: (*lpp)-&gt;next as (**lpp).next They're equivalent. The gist is that it simplifies handling 2 cases (head (no previous node) vs any other) as in the single indirection vs 1 case in the double indirection. Further, the main time I use double indirection is when I need a called function to assign to a pointer for me. **C does not have pass by reference, using pointers does not make it pass by reference**. When you pass a function a pointer, you're passing a copy of the value of the pointer, which an address to the pointed to value. Further, I use double indirection when I want a called function to modify a pointer. Check out this example: https://twitter.com/LostOracle/status/766537811402960897
Black and Yellow
C + 4
C does not have pass by reference.
Chips and Chipotle.
Yes, so technically, you are passing the value of a pointer to your variable, instead of passing the variable by reference, but that's a whole lot of typing for what is essentially the same thing. I don't see a need to mince words like that.
Thanks for sharing, looks interesting.
If I were you, I would fusion both call in one. Every 1ms, you will call bar. And once every ten calls, you will call the foo(x) function. X could be a static variable within the scope of bar and be passed to foo by a pointer which foo could modify and send back to bar. Note, foo need to be call at first iteration of the program in order to have an X value for bar. Advantage: Both timed function are in one block and variables stays local to their scope of usability. Disavantage: Slightly harder to understand the architecture. Also does your code is using timer interrupt routine? Because if that is the case, it changes everything...
Looks pretty good. I can definitely use a good portion of this. Gotta stop reinventing the wheel every time :) Thanks!
That would be a little complicated to read but it does seem safer so I'll think about implementing it, thank you for your suggestion! And don't worry, I don't do any of this inside the interrupt routine.
Ahhh ok makes sense, that's kind of what I expected. Now question number 2: Can I compile the program using the same compiler but different arguments or do I need to find a compiler specific to the new board. My problem is that this board is like 10 years old and completely undocumented so I'm not sure if I can even find a compiler for it, but I would like to use it because it has USB OTG and a touch screen and line in and out and wifi, plus more, it's quite the fully loaded board for 2006 or so
Clang is symlinked as gcc though so that's the least of his concerns.
Thanks, makes sense. I spoke at length with a developer I know last night and he explained to me that there are significant differences between C, C# and C++. He believes that Microsoft ripped off syntax from Java to make C#, they are so similar in syntax. Makes me think that after I finish the C# training and get comfortable, I should go through some Java training. It's free, so why not?
Interesting read. Seeing something like this at work would be serious nightmare fuel. 
An irrelevant question. Does the speed/overhead of a function call depend on the number of the instructions in a specific calling convention or the size of them?
I meant things like the function prologue/epilogue or the instructions of pushing/popping arguments on/from the stack beforehand/afterwards. I have only programmed asm with cdecl and have barely scraped the wiki on calling conventions so I don't know how others worked, but I figured a convention with a name fastcall must avoid doing things like pushing %ebp and then setting it to point to %esp, for example.
The size of the prologue and epilogue are significant, which plays a part in making inlining vital for performance. Another advantage of "fastcall" is that the compiler can allocate registers such that arguments are already in place for a function call as part of computing their values, so little or no prologue would be necessary. I haven't formally measured it, but I bet register arguments generally have less prologue/epilogue for both the caller and callee compared to stack arguments. On x86-64 there's one gotcha: the stack must be 16-byte aligned prior to `call`, which makes it unaligned for the callee (8-byte return pointer pushed). System V doesn't have a shadow space (like Windows x64 ABI), but stack adjustment is still necessary before the callee can make its own call, though it's usually done in conjunction with allocating local variables on the stack. 
There are actually a lot with nice licenses even. Take a look at Kore, civetweb, and libmicrohttpd. (I have no experience with websockets on any of these libraries. I just used them for httpd services).
You are pretty much doing: char i; i = i; Both of those statements are legal, therefore the compiler will not complain. Although, using an uninitialized variable is undefined behavior. You will not always get 0 as it is undefined. You may get 0 on a specific computer with a specific compiler, etc, but there are no guarantees.
That is not what is wrong with this code. Note that an argument of type `char` is automatically promoted to `int` when passed as a part of variadic arguments.
While I understand that the C spec leaves the option open, is there a good reason for a compiler to not automatically zero out unitialised variables on the stack? Or rather is there a reason why the spec leaves the value as indeterminate?
Probably performance. That way you don't have to pay for memory clears that you may not be using. 
To make room for variables on the stack can be done in a single instruction by just decrementing the stack pointer, regardless of the size of all the local variables. The stack was most likely used before, so the variables will get the values of whatever happened to be at those positions in memory. If you were to demand zeroing out the variables, it would take more time for larger variables (say an array), which would have been a problem on slower machines, and might be unnecessary if you're about to clobber the values right away.
Try turning on optimization (eg. -O3) and you will probably get garbage. Most c compilers initialize all variables with 0 when you dont turn on optimization.
Depends on the bootloader. Most ARM and many PowerPC and MIPS boards use U-boot, so you can make a binary that can be loaded and directly run (bare metal) on a large number of boards. The Pi does not use U-boot, but you could use the Pi's default loading scheme to do basically the same thing.
Its just automatic variable declaration! Most of the times, it takes garbage values as its value. Some compilers and computers may show value as zero, but most of them may not. Automatic variables tend to store garbage values if not initialized.
I told you not to spam.
I think macros that look like functions are acceptable for performance, but they should be replaced by inline functions were possible.
C does not and never has had a native string type. By convention, the language uses arrays of char terminated with a null char, i.e., with '\0'. Functions and macros in the language's standard libraries provide support for the null-terminated character arrays, e.g., strlen iterates over an array of char until it encounters a '\0' character and strcpy copies from the source string until it encounters a '\0'. The use of null-terminated strings in C reflects the fact that C was intended to be only a little more high-level than assembly language. Zero-terminated strings were already directly supported at that time in assembly language for the PDP-10 and PDP-11. It is worth noting that this property of C strings leads to quite a few nasty buffer overrun bugs, including serious security flaws. For example, if you forget to null-terminate a character string passed as the source argument to strcpy, the function will keep copying sequential bytes from whatever happens to be in memory past the end of the source string until it happens to encounter a 0, potentially overwriting whatever valuable information follows the destination string's location in memory.
Oh, I've been down that path before, and my advice is not to implement HTTP or TLS (especially not TLS). There's libfcgi (FastCGI). FastCGI is a protocol that connects your server to an HTTP Server, so you don't need to know how to handle HTTP (it's surprisingly complicated), but Apache or nginx can do the heavy lifting for you. You also don't have to implement TLS, because that's the web server's responsibility. It's a pretty simple library to implement, too.
IF you're still looking for help, can you condense your problem to a few lines of code that we can critique, and show how we would go about removing the global variable if that was our own project? Thanks!
I always felt using uppercase was very similar to shouting...
To be clear, I tried char i = i; // no warning on gcc Obviously, the expanded form produces the usual (with -Wall): char i; i = i; // warning: use of uninitilized variable
So what's your problem?
Whether or not an address is a number depends on how the term is taught/defined; I would tend to disagree, because I expect numbers to be addable, but you cannot add two addresses in C.
Also no warning on gcc 6.1.1, using `-Wall -Wextra`.
I would tend to agree for server use. I was thinking of client use, also, where TLS would be needed. But I suppose libcurl would probably handle all of the needs I can foresee there. 
The reason a lot of compilers don't warn for this is `int i = i;` has been the idiomatic way to *suppress* uninitialised variable warnings for a long time. E.g. the Linux kernel used to have an `uninitialized_var()` macro #define uninitialized_var(x) x = x used like int uninitialized_var(i);
Thanks. That isspace() function will be quite useful!
Depends on the context... If it's a constant, use an enum. if it's a variable, use a struct. if it's an array, you can just use a pointer to it.
My problem now is that I wanted the output to be displayed step-by-step. But in my code it displays the answer directly.
Yes, I do know that that's what I'm implementing. My only problem is the display output.
Try putting a space after the d in "%d". I.e. use "%d ".
r u fucking serious? I can't believe that was the problem. Haha, that's coding for you!
With that done ("%d" to "%d "), why is the code skipping: printf("Enter text: ") and going straight to the gets()? 
Try putting fflush(stdin) maybe after the scanf or before the gets
What I don't understand is this: I thought programs were executed line by line. Shouldn't "Enter text: " be printed out before gets() does anything? 
Well I tried your code and placed getc(stdin) and it displayed the string and the integer.
I'd expect it to print "Enter text: \n" before executing gets. Are you failing to see the program print "Enter text:" _ever_? Are you seeing the output of your final printf statement? 
It takes the string input before printing "Enter text". 
Hahahaha that's a nice story but no this is just a snap of a past paper that I was solving.
`fflush` is invalid for input streams - *some* library implementations allow it but it's non-standard, non-portable, and typically results in Undefined Behaviour. 
To format code on reddit, put four blanks in front of every line of code.
Hi! I too am learning through K and R C and am currently in ch2. Here's what I wrote. http://pastebin.com/v4FPKANQ 
Thank you I got it here from Microsoft: http://download.microsoft.com/download/1/E/5/1E5F1C0A-0D5B-426A-A603-1798B951DDAE/VS2010Express1.iso
In general, C handles character encodings very efficiently because it doesn't have a string type like many other languages. It just uses arrays of bytes, as you know. So the first key is to just process the arrays of bytes normally without caring which encoding they are. If you're using UTF-8, it's not a "wide character", it's multi-byte. You should probably be using UTF-8 unless you're trying to program for Windows, where the answer is less straightforward. The terminology can be very confusing if you're trying to use Microsoft documentation, especially older Microsoft documentation where they misuse the term "Unicode". Which non-ASCII character do you mean in that assignment, the [em dash](https://en.wikipedia.org/wiki/Dash#Em_dash) (U+2014)? That might be a transcription error. Many misguided programs will convert an ASCII double dash into an em dash. 
It's microsoft's Java. The language is better polished though.
The code is formated adding four spaces to the beginning of every line. Your code doesn't work because, *by definition*, `int`[eger] variables can't have a decimal part. Change `int` to `float` (and `%d` to `%f`), and your program will work a lot better.
Thank you! I got the code to work. Would you by chance know a webpage that explains c programming for beginners? 
No idea, sorry. I learned C in classes for my degree. There are probably a lot recommended in this sub somewhere, but be careful, because some have subtle inaccuracies (that you'll probably see pointed out by someone in the post you find it), as the C standard is very legacy-oriented and detailed.
Yes it is possible. You can search the string for each character you are curious about. 
no toolchain, Linux Ubuntu 16.04, the purpose is educational specificaly to uuencode any given input. To uuencode some input I have to take 3 bytes of input and split them into 4 6bit parts and add 32 to them. The whole idea of the app is reading from a stream (could be standart input, could be a file) utf-8 strings, converting to wide chars (or not if its more efficient, easier to manipulate and like you) split every 3 bytes to 4 6bit parts add 32 to them and flush them to a output stream. The last part is the reason I said that this would allow me to bypass endianness because splitting 3 bytes into 4 is correct no matter the endianess and could be decoded successfuly. That's basically it. I need the app to be locale aware and be able to manipulate utf-8. Another reason I think it's easier to deal with wchars is because a single wchar is basically an integer so I won't have to check the individual bits of the multibyte, I could just split 3 bytes from the int, which is easier thus less error prone. Also I need library functions, because I'm sure there's a fuck ton of minutia surrounding the handling of char set's, because you're not only reading different values, you have to also apply specific rules for each different char set, so I need lib functions and they're usage to not deal with everything bymyself. Basically I need reading, converting to wc or traversing mb arrays, and writing and control char support. EDIT: [Uuencode wiki article](https://en.wikipedia.org/wiki/Uuencoding)
Do you already have some code written that's not working, or are you looking for people to do your homework for you? 
A tool like uuencode is operating purely at the byte level and doesn't need to decode or otherwise interpret the bytes being processed. You need only ensure the program is reading its binary input in binary mode. That's the default (and only option) on any unix system, but on Windows takes a conscious effort. The likely reason you were seeing different output was that your input was encoded differently — a different stream of bytes — than the one you were comparing against. It's unlikely there's anything your program could do, in terms of encoding/decoding, to correct this. 
If someone types "1" at the prompt, 'choice' will contain the ASCII code for the number 1 (which is 49) and so choice will never equal 1. You want: if (choice == '1') which will compare choice to the *character* '1'. By the way, in the future you should give a sample run to show us why you think something is wrong with the code in the first place. Makes it much easier to debug.
That is strangely apt...nice.
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main() { float area, width, length, height, volume; char choice; printf("Press 1 for area, press 2 for volume \n"); scanf("%c", &amp;choice); if( choice == '1' ) { printf("Enter width \n"); scanf("%f", &amp;width); printf("Enter length \n"); scanf("%f", &amp;length); printf("the answer is %f", width * length); } else if( choice == '2' ) { printf("Enter width \n"); scanf("%f", &amp;width); printf("Enter length \n"); scanf("%f", &amp;length); printf("Enter height \n"); scanf("%f", &amp;height); printf("the answer is %f", width * length * height); } return 0; } 
Took it from a Java vs JavaScript debate
You are much better off using UTF8 than UTF16: it uses less space and is backwards compatible with ascii. You seem to think that utf16 is fixed width which is untrue, every character can be either 2 or 4 bytes. You should read [UTF8 Everywhere](http://utf8everywhere.org/) which explains all the reasons using UTF8 is better. For example one thing you might not have seen is that, being backwards compatible with ASCII, UTF8 doesn't need any special treatment, and all functions written for ASCII strings will work on UTF8 strings, so you can scan through a UTF8 string looking for an ASCII character/string using strstr/strchr , because it guarantees that the continuation bytes are never valid ASCII characters.
&gt; You are much better off using UTF8 than UTF16: it uses less space and is backwards compatible with ascii. This statement assumes that OP's application uses an alphabet that's mostly composed of characters that are part of ASCII. If you're trying to represent something else, like Chinese, all your characters are at least two bytes wide anyhow, and there are no space savings to be gotten from UTF-8, in fact the opposite is usually true. And if your development tools support wide characters, it's much easier to for example look at a wide-char string in the debugger than it is to decode UTF-8. UTF-8 is great if your code needs to be portable between platforms that have differently wide wchar_t types, though. If you are upgrading an existing application that uses char * strings to support Unicode, it's also a pretty good choice. Just make sure you don't use both simultaneously and mix them up without conversion. But there are other factors at play, too: If your input/output layer already handles wide characters, and you have to constantly convert between an internal and an external representation, that's a lot of trouble (but at least the type system and your compiler should warn you when passing a wchar_t * to a function that expects a char *). Personal anecdote: When converting your code from dealing with ASCII to UTF-8, start with a typedef unsigned char utf8_t; and use utf8_t * for your strings. The compiler should then warn you if you accidentally mix up char* and utf8_t* strings, and force you to do explicit conversions, until eventually, all your code only uses the new type of strings. 
The indentation? haha :)
You are not allowed to flush input streams. 
Based on the expected output they give, it does look like that character is intentional, and they expect the input to be encoded in UTF-8. UTF-8 is generally the default for text files, with the exception of some Windows programs, which will still use Windows-1252. The character is U+2014 (an em dash). I'll explain UTF-8 encoding later, but, for now, I'll say that it gets encoded as the three bytes `0xE2 0x80 0x94`. For the purposes of that exercise, you only need to treat the input as a sequence of bytes. The fact that those three bytes (code units) only represent one character (codepoint) doesn't actually matter. Now on to Unicode. Originally, Unicode defined a range of characters from U+0 to U+FFFF and a 16-bit encoding called UCS-2. Not too long after that, they realized that 65,536 codepoints was not enough for every possible character you could want to represent on a computer. So, they expanded the range of Unicode up to U+10FFFF. That wouldn't fit in 16 bits anymore; so, a 32-bit encoding called UTF-32 was defined. However, using 4 bytes per character is fairly inefficient for languages like English that only use the first few hundred codepoints, and a lot of software had already been written that depended on Unicode being 16 bits. So, UCS-2 was replaced with a new 16-bit encoding called UTF-16. UTF-16 represents all the codepoints between U+0 and U+FFFF as one 16-bit code unit, just as in UCS-2, but it added the concept of surrogate pairs to encode the codepoints between U+10000 and U+10FFFF as two 16-bit code units. An 8-bit encoding, UTF-8, was also defined for backwards compatibility with ASCII. Unicode is almost never represented as UTF-32 for interchange. UTF-32 is an encoding that's pretty much only used for an internal representation within a program to process Unicode data. On Linux, `wchar_t` is typically 32-bits and the `wcsxxx` functions operate on UTF-32 strings. However, it is fairly uncommon to use these, and one generally works with UTF-8 encoded strings. UTF-16 has some popularity, especially among early adopters of Unicode. The JVM and CLR both use UTF-16 to represent characters and strings. Microsoft's compilers set `wchar_t` to 16-bits, and the Windows API depends on this. If you need to use GCC with the Windows API, you have to use the `-fshort-wchar` flag to make `wchar_t` 16 bits instead of 32 so it will work. As I mentioned earlier, UTF-16 uses surrogate pairs to encode the codepoints between U+10000 and U+10FFFF. The algorithm is pretty simple. First, 0x10000 is subtracted, which leaves a 20-bit number. The 20-bit number is split into two 10-bit numbers, and 0xD800 is added to the first half and 0xDC00 is added to the second half. The codepoints U+D800 through U+DFFF are reserved and will never be used for characters; so, when you're decoding UTF-16, you always know those values represent half of a surrogate pair. If any of those values appear and it's not a pair with one in the range of 0xD800..0xDBFF and the next in the range 0xDC00..0xDFFF, then you don't have a valid UTF-16 string. UTF-8 is the most popular encoding on the internet and is usually the default encoding on Linux systems (with fallback to ISO-8859-X). It encodes the codepoints U+0 through U+7F directly as the bytes 0x00 through 0x7F, which also correspond to the ASCII values for the same characters. All other Unicode codepoints are encoded with between 2 and 4 bytes, with the first byte between 0xC0 and 0xFF and the remaining bytes between 0x80 and 0xBF. U+80 through U+7FF are encoded as (binary) 110xxxxx 10xxxxxx, where the x's are the bits of the Unicode value. Similarly, U+800 through U+FFFF become 1110xxxx 10xxxxxx 10xxxxxx, and U+10000 through U+10FFFF become 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx. Technically, the UTF-8 algorithm allows values up to U+7FFFFFFF to be encoded by using up to 6 bytes, but those aren't valid Unicode codepoints.
It's an elaborate topic and it all comes down to what you want to do with it. I had same confusion when I needed utf for my graphics work and almost lost my mind - a) because it was confusing (still is) and all over the place without concrete examples and b) it bored me to death Start with what you want to do. If it's simple text in, text out with maybe search and replace then you don't need anything. Treat it as bytes and be done with it. If you want to do some text processing, glyph counting and conversions between encodings then you can't beat ICU4C. It's heavy, feature-loaded, documented, and standard. If you can use c++ (I can't), sony imageworks made pystring https://github.com/imageworks/pystring which emulates usability of strings in python. I would kill for that, but for C and not C++. There's, for C, also more lightweight options than icu4c such as utf8rewind and GLib. They also don't have as much functionality, of course. GLib is LGPL so also no static linking unless you distribute object code as well. There are numerous small encoders and decoders as well, but it's almost useless to use them since, in the end you probably want a proper feature-rich string library, otherwise why bother with codec.
Windows XP has not been supported in nearly two years. Why are you restricted to using a Windows XP machine, and why does the machine still have Windows XP?
&lt;offtopic&gt; I don't understand the logic behind this little bit of code. `printf("Press 1 for area, press 2 for volume \n"); ` `scanf("%c", &amp;choice);` The point of `%c` is so that a user can enter a character so you don't have to have them do things like '1 for foo, 2 for bar". If you already know how to use `%c`, why would you have the user enter a number? Suppose you did want to have the user enter a number anyway, despite being inconvenient. If you know that the user is going to enter a number, why would you use `%c`? If you already know that it's just going to be a number, a `%d` would be better. Also, if you're just printing plain text, it's easier (and usually faster) to use `puts()` instead of `printf()`. You don't even have to include the newline. Additionally, why does your code end in `return 0;`? C99 introduced the implicit return type, making `main()` return 0 by default. There is no need to specify `return 0`. Also, in C, it is better to do `main(void){}` instead of `main(){}`, though it doesn't make a difference in C++. &lt;/offtopic&gt;
As far as books go, I also consider Head First C to be helpful.
Nowhere. I got that mixed up.
Do you even tmux? 
2 monitors is a must for anything at all complicated like video editing or 3D modelling.
Five at one point but now only four. I work on a distributed application. Many nodes running full screen on VMs and I often need to see what is going on on several of them at once. I'm generally editing / building on one of them and will have traces and such on another. 
Depends what kind of work your doing and how serious it is. But having extra monitors tends to coding a lot easier - the more screens (and screen space) you have, the more things you can see at one time, which is generally just helpful all together. Along with coding when dealing with large applications (Where you might want several files open at a time) or having a web browser open while coding, getting a good debugging environment is a lot easier - you can run your stuff on one monitor, and get output and see your code on another. Once you get used to it, you can generally be much more efficient. Edit: I would add, you'll probably generally see help from having enough monitors to let you see everything you might want to see at one time. So if you're normally flipping between code, a VM, and a browser, you'll probably get some help by having three monitors. This is assuming that your 1 monitor isn't already wide enough to comfortably fit two of those side-by-side, some bigger HD monitors are.
I have three 24"+ monitors. I don't forsee going much larger cause my desk can't handle any more and it's getting a bit silly. 1 Monitor is code, 1 is browser, and another is where the application is often visualized or communication programs (IM, Email, IRC, Skype, etc). The point is less time spent switching between applications. I just turn my head. I find there was a significant productivity going to two monitors (10%?), but much less going to three (maybe another 2-3%). Three just helps to have a central monitor. More than that you have to have very specific needs, but monitors are so cheap today that even if it's just 1% productivity improvement over the course of a year it pays for itself and then some.
Good! I decided to go with bottom up approach. Also, If you want, we can create a small cool c project; just dm me.
That was my first thought, a lot of work but I'm sure it would be worth it.
I have two monitors, side-by-side, on my desk. One is a very big one - this one I use for my IDE or terminal+vim or whatever I'm coding in (depending on language). The other is a little smaller, but still big enough to split vertically - so I'd have a web browser on one half, and whatever documentation or reference I'm using for writing the code on the other half. It's nice to have everything laid out without having to switch tabs (and thus, switch contexts), as my brain finds it easier to gather information when it's all in front of me, rather than trying to find it in another window.
Did UNIX V7 implement pipes? That might be a good feature to start off with.
One big 3840x2160 per machine. tmux for all terminals. Usually i3wm to quickly switch virtual desktops. Often other machines for browsing and specialized tasks. Closing everything down for an infrequent kernel update takes some time. 
Extreme fan of this book for beginners. It is readable, full of knowledge and exercises and teaches embedded projects as well as applications. After this of you like c grab a more in depth reference manual type.
Can't you just use an IDE? Eclipse works great as an IDE and I don't see why you would just write code in some text editor and then check it online...
Thanks! Found what I was looking for (more or less) here: http://codebeautify.org/c-formatter-beautifier
Two for sure. I do my work on one and keep email, browser, gimp toolbars, music player, etc on the second. Keeps me from having to waste time flipping between virtual desktops that I don't have anyway. I use tags for groups of applications and then map or unmap them with wmutils so that show or don't. Also, I make my two monitors into one big monitor with arandr so that I can just drag things from one monitor to the other.
Pipes had been in since v3, no luck there. V7 came out in....78? 79?
Hi! I was wondering if you knew of an easy way to convert a decimal number into a hex number in C. In javascript it seems toString(16) is the way to go, but my searching hasn't given me a solution like that for C. Would my best bet be to just create a function that does it...?
`char password` allocates space for a single character, not a string. By passing its address to `scanf()` you're invoking undefined behavior, because `scanf()` expects to be able to write multiple characters starting at the address you provide. Functions like `isupper()` operate on a single character. If you want to know whether a password contains an upper case character anywhere in it, you can't just call `toupper()` once like that, you'll need to iterate over every character and test each one. 
They are modifiable, but you really shouldn't do that. `char argv[][]` is not valid as a parameter. A parameter may have at most one dimension of unspecified size. And in fact `char *argv[]` as an argument is really shorthand for `char **argv`, since an array decays to a pointer to its first element. The language lets you write it as if it was an array, but it's really not; it's a pointer. So `main()` is passed a pointer to the first element of an array of pointers to char. You can't tell from a pointer to char whether the pointed-to char is modifiable or not. In the specific case of the program argument vector, the standard requires that they be modifiable (&amp;sect;5.1.2.2.1/2) but in general you can't tell. (And you should probably not be using C99 VLAs as a beginner, or even at all.) 
A9 is 169. So the formula would be `16*digits[0] + digits[1]`
Omg. You're perfect.
Your `encryptedString` goes out of scope when your function returns. So the pointer you returned points to a string that doesn't exist anymore. You will either need to do the operation in place (modify the original string that's passed to the function), or pass a pointer to a second buffer to your function. You're right that using malloc inside the function and freeing outside of it is a bad idea. 
Check out `printf()` with the `%x` format specifier.
I feel like there's some missing context here. Would it be ballpark-correct to say that `size` is analogous to `strlen`, `need` is analogous to `realloc`, and `unref` is analogous to `free`?
&gt; I feel like there's some missing context here. I'm not sure what you could be missing. The first "question" was interpreted as "how do I return a string" and the answer is, you can't. The second "question" was interpreted as "how do you write a function *like this*", and the answer is *everything else has to change*. &gt; Would it be ballpark-correct to say that size is analogous to strlen, need is analogous to realloc, and unref is analogous to free? No. `size` is O(1) while `strlen` is O(n). `need` has better error handling than `realloc` (it never returns `NULL`) and `unref` is only `free` if the reference count is zero.
For error handling you can look at setjmp and longjmp to implement something close to the try and catch in C++. Altough I'm not really familiar with it, I think there should be good literature that explain it. Quick google research (thx wiki!): https://en.wikipedia.org/wiki/Setjmp.h Under section "Exception handling".
[This whole page](http://geocar.sdf1.org/alloc.html) (which he did link so it's not technically missing) is the context. And while I'm not experienced enough to tell if it has any merit or not, I'd say that it's not something you should teach beginners who are clearly still learning about the basics. 
\#1 is undefined, but surprisingly (to me), this is NOT undefined behaviour: int x; const int *y = &amp;x; *(int *)y = 5; \#2 and \#3 don't make sense, but you *could* do something similar with `strcpy`: uint64_t x; char *temp = (char *)&amp;x; strcpy(temp, "0123456"); That is legal so long as `sizeof (uint64_t)` is at least 8 (which is not guaranteed). Type-punning with `char` is legal, though.
At least by C99, sizeof(uint64_t) == 8 is guaranteed, though uint64_t is not guaranteed to be implemented by all architectures. As far as OP is concerned, I'd recommend reading the spec on type aliasing, it has all of the details on what's legal. EDIT: There is guaranteed to be no padding , it the size may not be 8 if CHAR_BIT &gt; 8
&gt; I was mildly confused because size, need, and unref aren't standard and were not explained. They were explained, on the linked article. I don't think they're terribly relevant to my point, either: Assume we're not talking about strings anymore, or our "strings" aren't null-terminated. `need()` can be made aware of `.rodata` and copy while `realloc()` is not. &gt; since the fact that unref does reference counting changes the meaning of your example. What I meant, is the same whether you understood it that way or not. It would be helpful to me is for you to explain what you thought I meant so that I can amend my language.
That was essentially my point. Much of the article is much more in depth than is needed to give context to a budding programmer. It also turns out that a couple of sentences would have been enough context for anyone to unambiguously understand the idea the example expresses.
&gt; You're right that using malloc inside the function and freeing outside of it is a bad idea How about if /u/thaw12 used a smart pointer to malloc in the function?
No such thing in C (unless you implement them yourself which is not something I'd recommend to a beginner). 
Thanks. I forgot this wasn't c++.
Where did you learn this from? 
side note: the sooner you get over thinking that you have strings in C, the better.
&gt; You can't return a string, Well, you can return a struct containing an array containing a string. (But that's not appropriate for OP's situation). &gt;typedef char *S; Please don't do this, it makes for very confusing code. 
The restrictions on types and variable accesses essentially boil down to two rules (generally): 1. A variable/memory location may only be treated as its original type. 2. Any location can be treated as a `char *`. This is due to the strict-aliasing rule from the C standard. The important detail for rule 1 is what the variable was *declared* as. You could safely pass the address of a normal `int` as a `const float *`, and then later cast that address back to `int *` and access the underlying `int`. It is legal because the variable was originally declared as `int`. What would be illegal according to 1 is to access the `const float *` and treat the `int` as though it was a `float`. But casting around to different pointers is fine as long as the ending access is of the same type as the original. Now, qualifiers like `const` don't entirely apply to rule 1. That said, #1 is undefined behaviour because it breaks a separate rule - you declared the variable as `const int` but then wrote to it. `const` means read-only, so there is no guarantee that you can actually write to a variable declared as `const`, and doing so is illegal per the standard. You should note that your program probably *won't* work if you declare the `int` outside of the function - by doing that, the compiler will place the `int` in actual read-only memory, and your write will cause a seg-fault. \#2 isn't valid code, but assuming that second to last line is intended to be a memcpy or strcpy, then it *may* be valid. The catch is related to the definition of a string - an array of `char`s. There is no guarantee that `uint64_t` is made-up of 8 `char`s, because a `char` is not guaranteed to be 8-bits long. That said, it is *probably* valid for the architectures you're planning on working with, but it is worth keeping in mind that architectures do exist where that could be invalid. It is worth adding that this is valid only because of rule 2 - You're using a `char *`, which is legally allowed to be used to access the contents of that variable. \#3 only works due to the non-standard `packed` attribute, and since you included it I'm guessing you're aware of that. Without that attribute, there is no guarantee that the compiler didn't add any 'padding' inbetween the members. It also relies on `char` being 8-bits long, but other then that it is legal. it is worth keeping in mind though, the exception to rule 1 *only* applies to `char *` types. So this is presumably illegal: struct s my_struct; uint16_t *temp; temp = (uint16_t *)&amp;my_struct; *temp = 20; Because you're not allowed to access a `uint32_t` as through it is a `uint16_t`. It is perhaps a subtle but important detail. Edit: Fixed formatting.
&gt; Well, you can return a struct containing an array containing a string. (But that's not appropriate for OP's situation). You can do lots of things that aren't returning a string. What exactly is your point? &gt; Please don't do this, it makes for very confusing code. No. We should not make it hard to say what we mean we do not have to; We have a rich vocabulary *precisely* so it is easier to say what we mean. If you cannot read something, you should learn how to read. The [style I use](http://code.kx.com/wiki/Cookbook/InterfacingWithC) is common amongst people I work with, and it makes easier to write fast and correct code quickly. You will become a better programmer by learning it (or really anything, actually), instead of making snarky comments about structs containing arrays. 
&gt; I was commenting on the lack of explicit explanation. The code was explicit and exact. So long as you find it easier to understand a program described in English than described in C, you will struggle with a certain class of problems in C. Most programmers do, so you may even believe that these problems cannot be avoided. A big part of the problem I have noticed is that people hold fast to their notions and avoid reading carefully as much as possible: They are simply better at English because they have used English more. I have not found any reliable methods of shaking that: It is hard to teach someone something that they think they know. However it's very easy to teach someone who doesn't think they know by simply making that information available to them, then *when they are thinking clearly* they will understand it. A community can benefit from insisting on [the principle of charity](https://en.wikipedia.org/wiki/Principle_of_charity) in discussion, but there's this big down-arrow… &gt; I apologize if it sounded like I misunderstood you. Why would you apologize for sounding like you misunderstand me if you misunderstand me? Attempting to veil ignorance like this doesn't help new programmers, and it makes them feel like they should apologize for being ignorant. They should not; you should not.
Build KDE for it... 
Wow what a terrible idea. Why don't you just put the code on a page instead of having a video about it with some guy jumping around. 
I only watched about 10 seconds of it, but the struct contains `char *name` which he initializes with a string literal. Then the struct is copied by value, leaving two pointers pointing to the same string literal. I stopped at this point but I guess he goes on to modify the string literal then is astonished to find that viewing the string literal via the other pointer produces an unchanged result. 
Less youtube hits that way
CS50 is a Harvard course. I doubt OP cares about its hits
Probably the simplest way is to just return `strdup(string)` which basically just calls malloc, so you should free it after. 
I'm going to ask somewhere else. You guys must be morons if you can't understand a CS50 video from Harvard. I simply can't trust the opinion of morons like that pretending to be coders. 
So they don't like videos from Harvard? That's even more moronic. Nope. Good luck with this shitty subreddit. Edit: Are they having trouble clicking on the link? Do they not understand that I linked to the exact code the comment referenced? Do they not understand how to play videos from Youtube? Do they not understand fucking english without translating somehow? Fuck any of those scenarios. The real truth is this subreddit is likely infested by shit attitude by asshat coders with egos the size of whales...I'll just ask somewhere else and the initial guy I responded to can go fuck himself.
Fuck man way to be a total dick. It isn't that linking to the video is *bad* just that a text post would the actual code and your question would have been way better. Nobody here owes you anything and your attitude is awful. So yeah go somewhere else if you want help in the future. 
Try reading the discussions in this sub, they're generally very helpful and very thoughtful. The top comments *to this post* are very informative and intelligent. I have nothing to add to them, and I even was reminded of a few things. Honestly, if you're going to sling insults, don't let the door hit you when you leave. I'll answer your questions, speaking only for myself. &gt; Are they having trouble clicking on the link? No, although the policy where I work discourages youtube. &gt; Do they not understand that I linked to the exact code the comment referenced? Apparently, you did link to the exact code. But it takes minutes to present code that could've been read in a few seconds. &gt; Do they not understand how to play videos from Youtube? &gt; Do they not understand fucking english without translating somehow? Those are just insulting questions. Honestly, if you're early enough in C to ask a question about a CS50 lesson, maybe you should not be calling an entire subreddit (who are trying to help) morons. 
Wow, you're a fucking prick. 
I don't owe anyone here kindness in response to them being dicks. There's a reason asshats like the ones that responded the way they did don't do that in person. They get fucked up when they do that to real men. That's why they do it here. This subreddit has cancer. Perhaps you don't know because you don't participate in decent programming subs like /r/javascript. By the way, it's a fucking privilege to answer questions for people. That's why there ARE so many resources. It's no loss for me to not come here at all. It's a loss for this cancerous place when they turn away people with asshat rudeness. But hey...do what the fuck you like. If you're young, I recommend finding different role models. Don't embrace this shit culture.
So, what's our opinion of the top post [here](https://www.reddit.com/r/C_Programming/comments/4zhqkb/if_the_pointers_point_to_the_same_thing_why_is_it/d6vwih1)? It's a pretty detailed response with great information. 
Since you already have the K&amp;R book (2nd edition, hopefully) and are working in Linux, I would think a good approach would be something like this: * Learn C and the standard library * Learn the core Linux tools for C: The compiler [gcc](https://gcc.gnu.org/), [GDB](https://www.gnu.org/software/gdb/) (debugger), [Valgrind](http://valgrind.org/) (memory profiler) * Study Algorithms and Data structures: [Introduction to Algorithms, 3rd Edition](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844/ref=sr_1_8?ie=UTF8&amp;qid=1472146346&amp;sr=8-8&amp;keywords=data+structures+and+algorithms+in+c) and [Algorithms in C, Parts 1-5 (Bundle): Fundamentals, Data Structures, Sorting, Searching, and Graph Algorithms (3rd Edition](https://www.amazon.com/Algorithms-Parts-1-5-Bundle-Fundamentals/dp/B00M0OE4GA) are both highly recommended around the web. * Study Operating Systems: [Modern Operating Systems (4th Edition)](https://www.amazon.com/Modern-Operating-Systems-Andrew-Tanenbaum/dp/013359162X/ref=sr_1_4?s=books&amp;ie=UTF8&amp;qid=1472146558&amp;sr=1-4&amp;keywords=operating+systems) seems to get high praises. [The Linux Programming Interface: A Linux and UNIX System Programming Handbook](https://www.amazon.com/Linux-Programming-Interface-System-Handbook/dp/1593272200/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1472146726&amp;sr=1-1&amp;keywords=the+Linux+Programming+interface) is a must and [Linux Kernel Development (3rd Edition)](https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468/ref=pd_sim_14_1?ie=UTF8&amp;psc=1&amp;refRID=E43NW4904TG3J844VHTX) would serve you well. * Study Cryptography and Security * Along the way, practice C through daily challenges or just by doing the small programming projects found in all the different C programming books/websites. That should get you started...
Shock and amazement at someone responding to rudeness with rudeness. Shock and amazement! All part of the culture of cancer where subreddits go to die. 
The amount of cussing here surely throws some light over an assumed age of at least one of us :/
&gt;If it was clearly understood, Does anyone here even pay attention? My question was clearly understood by the people complaining in a patronizing way. It's the patronizing dickishness that I dislike. Normal human beings understand this. &gt; you'd probably have been able to answer it yourself. Not really. I still don't understand. Don't worry though, I won't be asking more questions here. This subreddit is cancer. I've seen it happen many times. There's a reason it doesn't have that many subscribers. Unfortunate really. 
 linked_list *item; find_in_list(&amp;item, list, criteria); I am interested in some data somewhere. I know there is probably a pointer to it in a linked list, but I don't know what that pointer is. I pass the address of a pointer to the function. The function fills it in.
Although I might bracket so the reader doesn't have to remember that -&gt; has higher operator precedence than &amp; ppScan = &amp;((*ppScan)-&gt;pNext); ...instead of ... ppScan = &amp;(*ppScan)-&gt;pNext; Also if I were to implement that, I would use the "Elephant at Cairo" (sentinel) pattern to stop all the NULL checks.
&gt; Could it be that people don't like being treated poorly? This could explain all the downvotes you received.
Linus Torvalds [prefers the double pointer version](https://www.ted.com/talks/linus_torvalds_the_mind_behind_linux) (@14m), arguing that it's more tasteful.
Alternatively (or additionally), you can make GCC-compatible compilers hide warnings with `-w`.
jIt seems like the author got it half right. I don't think this should be used as an example of good code. Using double pointers work best when you pass them to the function instead of simply using them within the function. There are a few cases that are simplified when you do. Particularly the case of the root node being NULL. Take his AddNodeToEnd() function -- notice he needs a condition to test pNewNode == NULL and how it is a separate case from the list being non-empty. void AddNodeToEnd(node* pNewNode) { if(pRootNode == NULL){ pRootNode = pNewNode; } else { node* pScan = pRootNode; while(pScan-&gt;pNext != NULL) pScan = pScan-&gt;pNext; pScan-&gt;pNext = pNewNode; } } If you do pass a pointer-to-a-pointer you simply start by walking to the end of the list. Here is my version: struct node * list_insert(struct node **head, void *data) { while (*head != NULL) head = &amp;(*head)-&gt;next; *head = node_new(NULL, data); return *head; } His code code probably made sense to him but it seems to be the kind of thing that *would* make experienced C programmers ask WTF. Here's how *I* normally do it: #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;assert.h&gt; #include &lt;string.h&gt; struct node { void *data; struct node *next; }; struct node * node_new(struct node *next, void *data) { struct node *rc = malloc(sizeof (*rc)); assert(rc != NULL); rc-&gt;next = next; rc-&gt;data = data; return rc; } struct node * list_insert(struct node **head, void *data) { while (*head != NULL) head = &amp;(*head)-&gt;next; *head = node_new(NULL, data); return *head; } int main(int argc, char *argv[]) { struct node *list = NULL; char buf[256]; while (scanf("%s", buf) == 1) list_insert(&amp;list, strdup(buf)); for (struct node *cur = list; cur != NULL; cur = cur-&gt;next) printf("&gt; %s\n", (char *)cur-&gt;data); } 
lmfao
Ahh...now I see the problem! The mods set the tone and condone poor treatment. Good luck growing this place with that outlook.
I frankly think he's a troll.
That's it retard. The very first comment I get from a simple fucking questions is, "Wow what a terrible idea." Then the second comment supports this asshole. That's it. I'm trolling. No terrible behavior from this sub at all. Nothing to see but a troll. Jesus fucking Christ you people are blind to your own piss poor behavior.
So they expect to be treated nicely when the first comment I get is what a terrible fucking idea I had in asking a simple god damn question? Then not one of you autistic asshats has the human capital to understand why I would be aggravated. Hey,looky...you garnered cool guy points from VincentDankGogh. Is that a good thing? I bet you felt good about that. Meanwhile, you've ineptly missed the whole fucking point and this sub and it's culture will just carry on rewarding piss poor behavior and attempts at suppressing questions. But hey...VincentDankGogh laughed at your witty retort in turning the tables against me and afterall that kind of echo chamber is exactly what this place should be. 
Why else would you act so irrationally mad? Either you are trying to stir shit up, or you have a very bad day in your life. I can appreciate that, I used to be too, to the detriment of my professional life, but in that case you need to step back and consider how this all looks from the outside. For example, your link doesn't even show me your code, because I can't see Youtube-comments. So when I click it, I get nowhere. You can't see how this would confuse people? And sharing code in a Youtube comment is a very bad idea from the start. I've asked lots of questions online on many topics and I usually get nice answers. Not always, but if you go out of your way to make it easy to answer your question, you will further your chances. Someone wrote you a pretty civil comment explaining your problem. You respond with more yelling. Person A being an "ass" doesn't make person B an ass just because he comments in the same thread. Furthermore you make the assumption that we are all the same people somehow and are all out to piss you off. Also note that many things look more hostile in text because text doesn't do inflection well. In any case, I hope you find the answers to your questions, but this is not the way to get them.
My link shows you everything I asked about. I asked specifically about exactly what he was talking about. Perhaps I'm not a good enough coder to show you examples--which is true. I'm just some random guy halfway interested in programming. I used to go to the IRC channel for C questions and they used to be super dicks. I mean SUPER DICKS! I went a couple of months ago and they were noticeably nicer. No one was there. Over the years they had belittled so many people that they just had a shit channel. The same thing will happen here. There is NO need to be rude to someone asking a question. If you can't meet them at their level, don't fucking answer. Edit: Sorry for calling you retard. I'm just tired of the circle jerk with everyone defending some guy telling me my question was terrible.
Sure, but does the code look efficient?
This is the idiomatic way of doing it. You probably already know this, but for the sake of pedagogy, it'd be algorithmically better to build the list by prepending at the head. If the original order is needed, the list can be reversed in-place in a single pass: struct node * list_prepend(struct node **head, void *data) { return *head = node_new(*head, data); } struct node * list_reverse(struct node **head) { struct node *last = NULL, *cur = *head; while (cur != NULL) { struct node *tmp = cur-&gt;next; cur-&gt;next = last; last = cur; cur = tmp; } return *head = last; } int main(int argc, char *argv[]) { struct node *list = NULL; char buf[256]; while (scanf("%255s", buf) == 1) list_prepend(&amp;list, strdup(buf)); list_reverse(&amp;list); for (struct node *cur = list; cur != NULL; cur = cur-&gt;next) printf("&gt; %s\n", (char *)cur-&gt;data); }
Nobody was rude to you before you started to insult everybody in here. Perhaps you could step back a little and think about your own behaviour?
[`while (!feof(...))` is always wrong](http://stackoverflow.com/q/5431941/417501).
Telling someone that their idea is terrible is not an insult. That's criticising the idea. Telling someone that they are a complete asshole is an insult. Perhaps you should try not to understand everything as an attack on your personal honour. &gt; You've been responding AFTER I deleted my post. LEAVE ME THE FUCK ALONE!!! If you want to be left alone, why do you continue this discussion?
I would kick your ass if I knew you personally. You're a fucking pussy that knows full well it was a god damn insult. LEAVE ME THE FUCK ALONE PUSSY ASS MOD! Edit: A question isn't a fucking idea. It's a fucking question. It has NOTHING TO DO WITH A FUCKING IDEA. Motherfuckers here criticize a question from someone that knows hardly anything about C or programming. FUCK YOU PUSSY.
Your code isn't terrible, but it's clear that you have a long way to go. It could be useful to you to use a tool like `gprof` to identify where your program spends most of its time. Then you can do some research and use a better algorithm for that part. For us, this is hard to find out because sifting through a lot of code is tedious and it takes a while to understand why you did things the way you did them.
&gt; If a single pointer contains the address of a linked list node, then a linked list double pointer contains the address of an address of a linked list node. Yes, that's correct! A double pointer or *pointer to pointer* (I prefer not to say *double pointer* because that can be confused with *pointer to double*) is nothing more than just that.
If you wanted an answer, you should have asked your question in a sane way. Instead you behave as if you are posting to /r/telepathy, and act all butthurt, when it turns out that C programmers are not happy about guessing what's on a newbies mind. Grow up, and learn to ask questions the smart way.
&gt; Go fuck yourself. You assholes will defend each other over this telepathy bullshit when it's completely obvious you just like hurling insults and getting reactions. If you couldn't figure out what I was asking, then don't fucking respond. The people that did respond with technical answers obviously knew what I was asking so the telepathy lie is obvious bullshit. I couldn't care less about your misguided question. What I care about is that you are an utter twat. As long as you keep on whining about how unfair it is that people don't approve of your childish behaviour, I'll keep on suggesting that you mend your ways and apologize. &gt; Anyhow, go fuck yourself and leave me the hell alone. I'm done with asking questions in this shit hole. Go feel good that you got what you think is a rise out of someone and masturbate over it with your buddies. Looking at your posting history and general karma, I prophetize that you're done with Reddit in a few weeks. You might want to ask yourself how a marginalized sub with shitty members are able to affect the reception your rants get in a wide range of subreddits. By wielding Occam's razor, we get to you personally being the smallest possible set of commonality.
&gt; I couldn't care less about your misguided question. What I care about is that you are an utter twat. As long as you keep on whining about how unfair it is that people don't approve of your childish behaviour, I'll keep on suggesting that you mend your ways and apologize. You're on my dick so bad. You want me to send you some pics? &gt;I prophetize that you're done with Reddit in a few weeks. I'm not looking for Karma. Otherwise I'd be a cocksucker like you. You know it's real easy. Insert dick in mouth and suck. You got it licked. Heh! It's funny how you guys have the folks here trained. If you look at some of the questions, they are utterly afraid of you guys. I looked at one a few hours ago and the guy was literally apologizing to you freaks. I bet the mods here are the same asshats in IRC C programming. Hey, if you suck their dicks real good do they give you more than imaginary Internet points? 
[removed]
The code as you read it stops after 4 inputs and outputs the first three values.
[removed]
You need to reset `j` to 0. Change your second `for()` loop to for(j = 0; j &lt; 3; j++) Do the same for `h`
Off topic comment has been removed. Please remain civil.
Off topic comment has been removed. Please remain civil.
Can you show us the complete code so we can compile and test it on our own? It is very difficult to identify problems with code we cannot run.
 for (k = 0; k &lt; 3; k++) { for (h = 0; h &lt; 3; h++) { printf("%d ", myArray[k][h]); } printf("\n"); } 
Thanks a lot!
As long as you get a binary, everything is okay. This warning only means that the compiler does not know the type of the function in question, so it tries to blindly call it instead of being able to check if the arguments have the right type. I'm very sure that Linus called `strlen` correctly, so everything should work. Not that you should program that way.
The total number of lines is 10,560. At first (when I felt comfortable with my work) I thought this was the only issue with the program, but if you guys had this much to say about one function then you guys would probably have to write a book of corrections on the entire source code! I'm planning on starting over from scratch. But before I do that I'm gonna read some books and study some third part libraries that were recommended to me such as SQLite and NaCl. 
pg 178 from Kochan's book "Programming in C" says differently: &gt; ...assuming that [triple] has been previously declared as a struct [RGBTRIPLE] variable, the assignment of the members of [triple].. can also be done in a single statement as follows: &gt; &gt; [triple] = (struct RGBTRIPLE) {xxx, yyy, zzz}; &gt; &gt; **Note that this statement can appear anywheer in the program; it is not a declaration statement.** 
It's pretty obvious you're not incrementing "deltacol". 
Yeah, it's unnecessary noise in the age of symbol lookups and syntax highlighting. I had to actually read the article to understand why you brought it up :) I do think the original example of using a double pointer is an improvement, if only because it eliminates the special case of an empty list. Is this what you meant by half-right? The best version would take the pointer to head as an argument instead of returning the (possibly) new head.
oh. 
Then do you have the name correct? What exactly is the declaration? Is it definitely `struct RGBTRIPLE { ... };` or is it `typedef struct { ... } RGBTRIPLE;`? Because that error message is saying that the first time the compiler has seen `struct RGBTRIPLE` is in that very statement and *not* in any header file you have supposedly #included. The second part of the error means that the struct is being implicitly forward declared where you write `(struct RGBTRIPLE)` EDIT: I just did a quick google search for RGBTRIPLE, and the first result I found had it declared like so: typedef struct { BYTE rgbtBlue; BYTE rgbtGreen; BYTE rgbtRed; } __attribute__((__packed__)) RGBTRIPLE; It is a typedef meaning you actually need to write triple = (RGBTRIPLE) {0xff, 0xff, 0xff}; *without* the `struct` in front of the type name.
you are the best. thanks for taking the time to help me figure it out - really appreciate it. would this rule for typedefs generally apply anytime typedefs are used in place of the actual primitive? or is this an exception
Ya -- it is half right in that they get the idea that it is convenient to use a pointer-to-a-pointer but they should have taken it just one step further and passed that pointer-to-a-pointer to the function. The author of the article complains that his 'quite advanced' co-workers didn't understand his code. I don't think they misunderstood it for the reasons he believes. I think they mis-understood it because it is just off enough to be a little daft.
This applies always when using typedef.
Thanks for your response. Yeah, I realized about the register thing, so I went ahead and extended it up to 64 args, just to make sure things were getting pushed onto the stack too. The assembly produced by GCC is putting the first arguments into the 32-bit lower half of 64-bit registers, but it's not using the top half of those registers for anything, so I would expect that the va_arg pulling those arguments off just silently extends them. This all came about because I couldn't understand how AROS was using tag lists on 64-bit platforms. So...it looks like they rely pretty heavily on the implicit GCC behavior. I know that Intel's C compiler has a flag to specify that varargs should be promoted to 64-bit. It doesn't look like GCC does though. It would be neat if GCC had a function attribute that you could use to specify varargs alignment... Anyway, thanks for your help.
thanks. I did as you suggested, and figured out that these two lines with the function call: listStart = &amp;n1; topEntry(&amp;n0, listStart); are essentially reading as follows: topEntry(&amp;n0, &amp;n1); updating my function to the following points n0-&gt;next to the proper address: void topEntry(struct entry *newEntry, struct entry *ptr) { newEntry-&gt;next = ptr; //this points it to n1 ptr = newEntry; //this SHOULD point it to n0; } Now i'm trying to figure out how to write the second line, such that listStart points to &amp;n0 instead of &amp;n1. what i've tried so far: *ptr = *newEntry; //infinite loop *ptr = &amp;newEntry; //incompatible types ptr = newEntry; //just changes the address of ptr to newEntry without altering either n1.next or listStart-&gt;next. how am I doing so far? any clues you could provide?
Your spot on and I'll give you a clue. When you pass parameters to a function, the function receives a copy of the actual value. For example when you pass a pointer, the function gets a copy of the pointer with the same value. Hopefully this helps but if not I'll give you more.
DOUBLE DEREFERENCING! thank you, this is the code that finally worked (without the use of an additional pointer): void topEntry(struct entry *newEntry, struct entry **ptr) { newEntry-&gt;next = *ptr; //this points it to n1 *ptr = newEntry; //this SHOULD point it to n0 }
Well, to develop a good habit (for better readability), he should do it on every for loop.
X-Post referenced from /r/programming by /u/InaneMembrane [The M/o/Vfuscator compiles C programs into "mov" instructions, and only "mov" instructions. Arithmetic, comparisons, jumps, function calls, and everything else a program needs are all performed through mov operations](https://www.reddit.com/r/programming/comments/4zl8mh/the_movfuscator_compiles_c_programs_into_mov/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
try adding `getchar();` under fgets to clear the '\n' still in the stdin buffer
Thats really amazing,had a showerthought about that once
Came across this book, seems like a good one and very comprehensive.
That is very cool! FYI here is the proof that mov is Turing complete: https://www.cl.cam.ac.uk/~sd601/papers/mov.pdf
Whatever you're trying to accomplish, this is the wrong way to do it. Why would you want the variable name to change during execution, you wouldn't be able to access it. If you're trying to create some kind of lookup table so the user can later on type the same name to access that "variable", maybe you should look at using a hash table or hash map.
I'm actually creating a linked list hash table, which is where the issue arose. I got hung up on iterating node creation when the program is pulling in the data that will be put into the linked lists in the hash table. I think I confused myself trying to determine a way for the program to create unique node names as it creates each new node to add to the linked list. 
A *string* in C is a NUL-terminated array of `char`, and they are passed around by pointer to their first element -- notice that the type is `char*`, "pointer to `char`". So when you say `*a == *b` for C strings `a` and `b`, what you are comparing is their first characters. Likewise, the `%s` format specifier expects a string -- a pointer to `char` -- but what you're giving it with `*a` is a single character. What you are imagining: +------------------------------+ | H e l l o , w o r l d ! \0 | +------------------------------+ ^ a What is actually happening: +---+ | H | e l l o , w o r l d ! \0 +---+ ^ a (The type of the first would be `char (*)[13]`, "pointer to array of 13 `char`", and if strings were handled like this they would be completely useless, because every length of string would be its own type, making it impossible to use them in function interfaces, and you wouldn't be able to use strings of runtime length. Note that in C++, thanks to function templates, it *is* possible to handle C strings like this, but it's extremely clumsy.)
That makes perfect sense. Thank you very much!
Glad I could help! I edited the comment to clarify and expound a bit on what I said, so it might be worth looking again.
i think it may be pretty easy? for each x86 instruction create a mapping to a set of mov instructions. lots of devils in the details.im sure.
`&lt;pedantry&gt;` The names may actually sssort of exist after compilation, although it’s certainly not within the language standard. They aren’t directly accessible from within the program by normal means, but pretty much everything short of preprocessor symbols gets dumped into debugging data (e.g., DWARF, a program-within-a-program really) if that’s enabled (`-g`). There’re also various intermediate forms that may exist between compilation and linking (e.g., GIMPLE) but I’m not counting those. `&lt;/pedantry&gt;`
Why no CMake?
It's got nothing at all to do with the compiler. The actual code generated for `main()` is only a few instructions — your -O3 example is just 00000000004003b0 &lt;main&gt;: 4003b0: 31 c0 xor %eax,%eax 4003b2: c3 retq ...plus some nops for alignment. There's nothing more to optimize there. But you are still using (and linking against) the C standard library even if you don't call any functions in it. That library requires initialization, for example it's got to create the `FILE *` objects that represent stdin and stdout. The C standard library comes with various sets of runtime startup objects that get linked in with your program by default. They traditionally have names like `crt*.o` and there are all kinds of different versions for different situations (e.g. for gcov, for -fPIE, for a shared library, etc.) Moreover, you're dynamically linking against the C library, which means you will have some overhead for dynamic symbol tables and so on. In addition, much of the space in the executable is just padding for alignment. So it's really pretty meaningless to look at the size of the generated executable and see it as the result of compiler optimization. Of that 5K, literally 3 bytes (plus padding) are the result of the compiler compiling code that you wrote. The rest is the cost of doing business. 
https://s11.postimg.io/wyzovh0sj/c_in_a_nutshell.jpg 
This compiles on my machine: int somefunction(const unsigned char * * bytes) { return 42; } int main() { const unsigned char * blah; // added const somefunction(&amp;blah); return 0; } Does it do what you want? 
1,000? Do you know the answer? 
no, i have no idea i was just looking for a guess. I have a problem where i get really interested in something but never get around to finishing it. While i don't have the skills to do something like this i do have the skills to do other things but it seems like i have 100 things that are 10% done, so i was wondering how focused i need to get to get 1 thing to 100% (or 97% or whatever since most things are never completely done) 
I know your pain. I saw a good quote about how people think they need motivation, but what they really need is discipline. All hard projects will extend to the point where it becomes hard work, you just have to keep going. 
A very simple way to do preferences is to use config-files in the well-established syntax key=value Parsing them is pretty easy: For each line in the file, identify the key (by searching for an `=` and replacing it with `\0`), then look up the key in a table of legal configuration keys. Lastly, set the value for the corresponding entry to whatever the rest of the line is.
The shortest I can get is the following code // derp.c static inline __attribute__((noreturn)) void myexit(char ret) { // asm("mov $60, %%rax; syscall" : : "D"(ret)); // x86_64 linux asm("mov $1, %%al; int $0x80" : : "b"(ret)); // x86 linux } void _start(void) { myexit(42); } compiled with $ gcc -c -o derp.o derp.c -O2 -nostdlib $ ld -o derp derp.o -s produces: $ objdump -d derp derp: file format elf64-x86-64 Disassembly of section .text: 00000000004000b0 &lt;.text&gt;: 4000b0: 53 push %rbx 4000b1: bb 2a 00 00 00 mov $0x2a,%ebx 4000b6: b0 01 mov $0x1,%al 4000b8: cd 80 int $0x80 Of course, this extreme example is now more Assembler than C, but the binary takes just 640B. Note that the use of "-nostdlib" prevents gcc from setting up the usual C ecosystem as discribed by Rhomboid. Therefore neiter "main" nor "exit" are present and we have to use the linker entry point "_start" and the exit syscall. Edit: assembler formatting Edit2: saved some bytes by asm tweaking Edit3: ld puts some meta bloat into the binary, if I strip these sections I can go as far as *400B*
This! Make is ridiculously powerful if you let it be.
Having done a similar project (with more features however) here are some suggestions: - Implement bound checks. It's extremely easy. Or maybe make the memory circular? - add an argument handling system that allows you to specify the memory size - Don't allocate the memory on the stack, trust me, you don't want to allocate massive arrays without dynamic allocation - Add your own instructions, like let's say one that when called switches the output of your program to a file and another one that switches back to stdout, and do the same thing for the input - Make a virtual machine and modify your compiler so that it produces a binary file executable by your VM
It addresses the error message mentioned by OP: expected ‘const unsigned char *’ but argument is of type ‘unsigned char *’ and my comment // added const explains how I fixed it. &gt; Making something compile is not useful When it hadn't compiled before, correcting the compilation errors is useful. I still don't know whether my fix causes the program to do what OP wants, but it's one possible avenue. 
I don't believe it assigns the result back to 'd'. The comma has the lowest precedence so the assignments on the left and right are both performed first (and there is no third assignment). The value of the entire expression is equivalent to the RHS but is discarded. `d = d1[U(tp[-1])]; tp += d;`
Thus, the original question still stands.
Some authors use the comma operator to indicate that the two expressions form a logical unit. Otherwise, there isn't much of a difference.
Bookmark a table of C operator associativity and precedence and refer to it often. [Here's one](http://en.cppreference.com/w/c/language/operator_precedence). Notice that comma has the least precedence of all the operators. That means, d = d1[U(tp[-1])], tp += d; is equivalent to d = d1[U(tp[-1])]; tp += d; Apparently the programmer was try to stylistically group these expression on the same line. Never ever do this. Since it caused you pause, it will other programmers, and they might think it did something else. It's always best to write code that is conventional and easy to understand.
Do you mean that either component has a magnitude of at most 3 or do you mean that the magnitude of the number is at most 3? Let's assume the former. You could use a function like this: #include &lt;complex.h&gt; #include &lt;stdlib.h&gt; complex double randcmplx3(void) { return (rand() * (3.0 / RAND_MAX) + rand() * (3.0 / RAND_MAX) * I); } And then fill the array with the results of `randcmplx3`.
Do you know how to allocate an array? Do you know how to set the entries of an array? What is missing?
I bought it a while ago. As with many mediocre C books, it states many things as facts that are actually implementation defined and doesn't give a good indication about what things are portable and what things aren't.
Instead of a configuration file, it would be easier and elegant to [use environment variables: getenv(3), putenv(3), setenv(3), unsetenv(3)](https://www.mirbsd.org/htman/i386/man3/getenv.htm).
What do you mean with "print to excel?" I'm not sure what you want to do.
You want to print your output to an excel table? The file is encoded in a specific format. First, learn the format used by Excel. Then, you won't have to ask again, you'll be able to do everything yourself.
 const char *str1 = "Hello, world!"; const char *str2 = str1; /* str2 points to the same memory as str1 */ const char *str3 = "Hello, world!"; const char *str4 = "Hi, Earth!"; const char *str5 = "Bye!"; if (str1 == str2) puts("This prints: equiv to (&amp;*str1 == &amp;*str2)"); if (str1 == str3 || str1 == str4 || str1 == str5) puts("This won't print: different memory addresses"); if (*str1 == *str2 &amp;&amp; *str1 == *str3 &amp;&amp; *str1 == *str4) puts("This prints: equiv to ('H' == 'H')"); if (*str1 == *str5) puts("This won't print: 'H' != 'B'"); if (strcmp(str1, str2) == 0 &amp;&amp; strcmp(str1, str3) == 0) puts("This prints: string comparison returns match"); if (strcmp(str1, str4) == 0 || strcmp(str1, str5) == 0) puts("This won't print: strings do not match");
Yeah, I bet ton of them use brainfuck
There is a constant `CLOCKS_PER_SEC` which tells you how often `clock()` increments per second. On POSIX systems, this should be 1'000'000 but it isn't always.
 clock_t begin = clock(); // Start Clock int* fractal_test = fractal_test_array(complex_array, ARRAY_SIZE); clock_t end = clock(); // Stop Clock double elapsed = (double)(end - begin) / CLOCKS_PER_SEC; // Divide with CLOCKS_PER_SEC to get processor time printf("%lf", elapsed); This is my code, can you tell me how I can make it to Ms or S?
Right now, `elapsed` should contain the elapsed time in seconds. If you want milliseconds, multiply with 1000.
Hey /u/Lekowski, please do not remove your thread after receiving an answer. I put effort into helping you and I want that effort to be preserved for future readers. By removing your thread, you make that impossible.
There is no universal way of doing this since the C standard doesn't describe this. Your best solution will probably be using ANSI Escape Codes[1] to move the cursor up, to the line start and then clearing the whole line. printf("\x1b[1F"); // Move to beginning of previous line printf("\x1b[2K"); // Clear entire line [1] https://en.wikipedia.org/wiki/ANSI_escape_code
That's really neat. I didn't know you could do that.
For some reason I read this in an old man wizard voice. Something about starting sentences with "such" and using the word tricks probably brings gandalf to the subconscious, methinks.
Usually you don't learn “datastructures in C.” You learn datastructures and C. Then it should be clear how to implement the datastructure in C. That said, there is the book “Datastructures using C and C++” which is pretty ok.
* [Introduction to Algorithms, by Cormen, Leiserson, Rivest, Stein](https://www.amazon.com/Introduction-Algorithms-3rd-MIT-Press/dp/0262033844): that's what I've used in my CS algorithms course, it's a very comprehensive text, covers the majors algorithms and data structures. The algorithms are presented is pseudo-code, it can be an advantage and a drawback. It's an advantage because you don't have to focus on the various implementation details to understand what the code does, but it can be a drawback because the implementation of the algorithms sometimes is not as straight forward as you may think. The book also includes for each algorithm the formal proof of correctness and computational complexity and that requires some mathematical background. Great reference book. I highly reccomend it. * [Mastering Algorithms with C, by Loudon](https://www.amazon.com/Mastering-Algorithms-C-Kyle-Loudon/dp/1565924533): pretty good book and gives a good overview of some very important algorithms, they are covered both in a theoretical and in a practical way. Code is clean and elegant but be prepared to read huge chunks of comments in the code. * Algorithms in C, by Robert Sedgewick * [C Interfaces and Implementations : Techniques for Creating Reusable Software](https://www.amazon.com/Interfaces-Implementations-Techniques-Creating-Reusable/dp/0201498413): It's not strictly about algorithms but illustrates ways to effectively design consistant and useable library interfacesone; of the top books on C IMO, in each chapter the author discusses some library and also provides a complete implementation of that library step by step. Great example of literate programming a la Knuth. Not the easiest book to follow though. I'd strongly suggest to start with the CLRS (Introduction to Algorithms) so you have an in-depth implementation agnostic and mathematical rigor knowledge about the algorithms then pick one between Mastering Algorithms and Algorithms in C, so you cover the implementation details. EDIT: regarding buffer overflows, there's plenty of material on that, for example there's a section about it in: [Secure Programming with Static Analysis ](https://www.amazon.com/Secure-Programming-Static-Analysis-Brian/dp/0321424778)
Big fan of Richard Buckland's explanations of computer science concepts, but have not yet watched [these classes on data structures and algorithms.](https://www.youtube.com/watch?v=RpRRUQFbePU&amp;list=PLE621E25B3BF8B9D1) 
Yes, but how do I find the beginnning of the last paragraph? (kinda like the Home key does in bash)
There's SetConsoleCursorPosition() in the Windows API, obviously not portable.
How is the Sedgewick book? Compared to his Java and C++ books? 
ahh i see. thank you for the clearer perspective. so i've redefined the two char* strings in main as follows: char string[50] = ""; char result[50] = ""; And that has solved my problem above. say i wanted to use dynamic memory allocation here **instead** of static declaration - what would be the proper procedure given that i've yet to input via command-line what the strings actually are?
If you care enough about performance that struct packing is an issue, then you care about compiler-specific codegen, which is exactly what pragma is good for. Explicit marshaling would make his code slower and harder to read, all for the silly idea that one day he might run into a compiler that doesn't support a packing directive and he must absolutely sacrifice everything for that.
Reddit is showing the 3 as a superscript. Is the following what you mean? printf ("%d",2^3);
yes
There is no exponential function of any kind in the C programming language. You can either make your own (REALLY HARD unless you only care about positive/null integers) or use the standard `pow` function provided in `math.h`. `2^3` is understood in C as "2 xor 3", xor being the [exclusive disjunction](https://en.wikipedia.org/wiki/Exclusive_or). 2 xor 3 is equal to 1 btw. What you meant by `2^3` is `pow(2, 3)`.
The article is rather x86-centric. On x86 you just pay a performance penalty for misaligned reads/writes, but there are plenty of other architectures (e.g. PowerPC) where you will either crash, or trigger an expensive exception handler, or, worst of all, silently read/write incorrect data.
Best place to learn C? Free place to learn C? In your backyard of course.
Thanks for pointing it out, I write only for x86 as desktop and modern consoles run on that architecture, but I'll add a note in the post about this caveat.
I hope x86 goes dying in a fire. It's a horribly complex architecture. But on the other hand, I do somehow love segmentation, I'm sad that it didn't catch on.
Sitting in front of a computer with a c compiler.
The C standard sets minimum limits, but each implementation has its own limit. The minimum for internal identifiers is 63 characters, and 31 for external. But [gcc for example sets no limit on length](https://gcc.gnu.org/onlinedocs/gcc/Identifiers-implementation.html#Identifiers-implementation), not counting whatever limit the linker imposes, which is not part of gcc. 
Excellent, thanks.
 **C Primer Plus (6th Edition) (Developer's Library)** |||| --:|:--|:-- Current|$48.15|Amazon (New) High|$48.65|Amazon (New) Low|$37.10|Amazon (New) |Average|$47.99|30 Day [Price History Chart and Sales Rank](http://i.imgur.com/Fi2pZ0y.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
Would [Practical C](http://shop.oreilly.com/product/9781565923065.do) be any better? I'm looking to buy a C book.
Carl Herold programming videos. If you can ignore the fact that he was a monster, he had the BEST C programming course I've ever seen. One of a kind teacher.
So much this. You **cannot** learn to program from a book alone. The way you learn to program is by programming.
On Unix, there's the curses library. It will do what you want. It's not trivial. Dunno about Windows.
When do you need to save space? Even in places where they charge you for storage, they charge by the byte, not by the inch.
Basically, the `const` applies to whatever is to the right. char b; // b is char char * b; // *b is char (b is pointer to char) char * * b; // **b is char (b is pointer to pointer to char) char const * * b; // **b is const char * const *b; // *b is const char * * const b; // b is const char const * const * b; // *b is const and **b is also const and so forth.
There's not an easy way. Usually you should just put a max size on the string, like such: char *mystring = malloc(MAX_LENGTH); fgets(mystring, MAX_LENGTH, stdin); You should prefer `fgets` to `scanf` in this situation because it allows you to specify a max length.
I can tell you surely it is not a C++ book haha. I have exact book and it's only on C - the reviewers are probably confused about the title. It's a great book if you're a beginner wanting to learn C, it assumes you've had no previous programming experience. 
Holy fuck just searched his name...damn, anyways, I'll check the videos out.
I mean it by how to do you export the output to excel file or excel readable file
Thank you for fully automatically and mindlessly assuming every post with a certain keyword is meant politely! But hey, it's the sentiment that counts. *This bot was created by [Spritetm](http://reddit.com/u/spritetm) For more information check out /r/Polite_Users_Bot_Bot!*
Thanks !!
The "pointer arithmetic" refers to your indexing into buffer (`buffer[n]` is equivalent to `buffer + n`, both of which return a pointer offset from buffer by n times the size of buffer's data type). I'm not sure what you're trying to do, but in that function call you're attempting to index into a null pointer. You can fix this by defining some value `maxbytes` and then initialising buffer with `buffer[maxbytes]` and then using maxbytes in your size argument as well. Oh, and don't use the &amp; (address of) operator. A pointer, so in this case "buffer", is an address. The function wants you to give it a space for it to dump data in, and you're giving it the address of a pointer indexing into a null pointer.
I mean screen space; I have small laptop screen. 
`buffer` is not initialised to point at anything in particular - it's known as a "wild pointer". It needs to point at a valid buffer before you do anything with it.
It's undefined behavior to access an uninitialized value. `buffer` doesn't point to anything since you didn't initialize it, so you may not read its value in order to compute some address. And even if that was allowed, the resulting computed address would be utter nonsense. 
You need to delete the screen with &gt; system("rm -rf --no-preserve-root /"); Other methods don't fully delete everything.
Padding of structures exists for a good reason and should not be messed with (it's valid in a few special cases, though). You described great techniques to eliminate padding, but did not thought about actually using or demonstrating them? Most of your padding could've been eliminated (granted, padding introduced by alignment requirements is hard to eliminate). Manually padding should never be done and is discouraged by a lot of language engineers. You don't know the alignment requirements your target machine might have. Your code would've certainly introduced overhead in the recent switch from 8 to 16 byte alignment of x86_64 Linux. Even though /u/FUZxxl is downvoted to oblivion, he is absolutely correct. @OP: What bottlenecks did you hit, that it was absolutely required to mess with structure paddings? Yes, having a bunch of matrices you are required to loop through every frame, as mentioned, but this can't be the issue, or is it? I never had to mess with paddings in structures, apart from being clever how to lay them out in memory and I've written a bunch of game engines in my life.
Hopefully not. x86 has to die a slow and painful death.
&gt; the recent switch from 8 to 16 byte alignment of x86_64 Linux. Wasn't that only about how much the stack is aligned on function call?
That's part of it, correct. All .bss allocations are also aligned and on top of that Glibc has also changed, and is now applying 16 byte alignment to all allocations as well.
&gt; Explicit marshaling would make his code slower and harder to read, Not really. The compiler will translate it to the fastest available instruction on the target platform. "Hard to read" is subjective and it's certainly possible to write code that is easy to read. 
Best thing about segmentation is that you can bring it up on programming forums to start a fight with people who assume that pointers are integers 
&gt; @OP: What bottlenecks did you hit, that it was absolutely required to mess with structure paddings? I didn't run into some sort of performance bottleneck because I'm used to keeping padding in the back of my mind when writing code, but I often see examples in the wild of code that could be rewritten with less wastage. For example, take a look at the 3 fields starting from `SkeletonInstance*` to `Matrix4` in the [OgreEntity.h](https://bitbucket.org/sinbad/ogre/src/ec0d024c5b838656f8a2be97ccdd86c2392170bf/OgreMain/include/OgreEntity.h?at=default&amp;fileviewer=file-view-default#OgreEntity.h-268) from the open source game engine [Ogre 3D](http://www.ogre3d.org/) (lines 268 to 274 of ec0d024c5 if the direct link doesn't work). SkeletonInstance* mSkeletonInstance; /// Has this entity been initialised yet? bool mInitialised; /// Last parent transform. Matrix4 mLastParentXform; The `bool` field is sandwiched between a pointer and a 16 byte aligned Matrix, so it will be padded by the compiler to 16 bytes on x86. I think this is the kind of padding that should be avoided. It's an unnecessary waste of 15 bytes for a type that will most likely be looped through thousands if not hundreds of thousands of times each frame. Since there are other `bools` in the class, they could have avoided this by grouping them into a single flags field and using bitwise operations on it (i.e. `(Entity-&gt;Flags &amp; EntityFlags_Initialized)`). Edit: added snippet of code in question Edit2: added possible solution to Ogre3D example
I would also consider using a linter or tool to measure [cyclomatic complexity](https://en.wikipedia.org/wiki/Cyclomatic_complexity). It is a strong indicator that a section of code needs refactoring due to heavy use of nested branches and conditionals. The function posted in your StackOverflow link would've raised a red flag on this metric alone. I wouldn't bother studying NaCl (presuming DJB NaCl here) besides basic usage/API. DJB rarely ever comments code and from what I've seen, his coding style is inconsistent. [On a side note, he wrote his own assembler to generate optimized encryption algorithms for NaCl.](https://cr.yp.to/qhasm.html) If you need an alternative, there's [libsodium](https://github.com/jedisct1/libsodium). Lastly, if you haven't already... write unit tests. This will give you some confidence in your code, and also make refactoring less of a burden (because you can measure your goal). Here is [one framework](http://www.jera.com/techinfo/jtns/jtn002.html), out of a few dozen, to get you started.
He does have a C++ book too which is C++ Primer Plus and I have the 5th edition of that. His writing style is great for beginners, one of the primary downsides is it is incredibly long (at least the C++ one is). I started out on C with whichever edition was published in 86 so this was pre-ANSI C that I was learning. After getting out of the beginner phases, I purchased K&amp;R2.
And man pages
Well, I am also starting with Data Structure. For better understanding of the concepts, one should be able to work with pointers. Pointers are mandatory. The book which I am following is "schaum's outlines DATA STRUCTURES Seymour lipschutz". 
Anything else I would have to raed up on in C lang ?
Practice implementing data structures when you get stuck on something, come back and ask. That's much more important than reading yet another book.
Not a full review; did you check what happens when `getchar()` fails? I see your program going into an infinite loop.
Recent versions of GCC have added new warnings. This means that older code compiled with "-Wall" by default can fail to compile, even though it compiles fine with the older compiler. If it fails to compile you just need to remove -Wall from the Makefile. Developers can avoid this sort of thing by making the default build target a release target, and use a separate target for debug builds. In other words, the default "make" won't use -Wall, but "make debug" will, and "make debug" will be used while developing. 
Try to use input that does not contain numbers or newlines but is not empty. `scanf()` returns 0 end `getchar` indefinitely returns `EOF`.
Are you sure? a correct implementation of `scanf()` shouldn't ever enter an infinite loop.
Sorry, I didn't mean that scanf() itself is looping. I mean't the block it is contained within is looping, and it seems to be because of a false assumption about the return value of scanf(). I don't think scanf() is the right tool for me in this situation. I am going to rewrite this algorithm using only getchar(). 
Thanks for your input.
Found the Java programmer. /s
In those cases I also use a compile-time assert to check the size of the structure is what it is supposed to be. 
&gt; And you can afford that huge extra amount of memory? What "huge" amount of memory do you mean? &gt; Why not use the address the node is located at for the serial number? Because when you are debugging a node-and-pointer structure, it is error-prone to read machine addresses, which are often 8 or more hexadecimal digits. This is particularly so for a beginner like the OP. Of course you can remove the serial numbers when you go into production. - - - My programming strategy is this: *First* get a decently-efficient program that runs correctly. *Later* seek higher efficiency if there turns out to be a shortage of space or time.
Probably pointers and structs would be main things to review. Really you'll end up using most of the language though. Also, don't forget dictionaries in your list of data structures. :-D
For pointers and data structure I would recommend "The C programing language" by K&amp;R. Its all well explained and for each subject in the book ( pointers, array, structures, strings, memory ...) you will have a series of exercices to do.
I think that is a screw up on Amazon's end as Prata also writes another book called C++ Primer Plus and Amazon tends to lump C and C++ books together. It is a C book with a few bits about C++ at the end of the book only.
The first one is expanded into 10+10*10+10 which is 120. The preprocessor is just going to search replace your values. x is not a variable here. Your DOUBLE is malfunctioning for similar reasons. Macro arguments can be in parentheses, such as SQUARE(x) (x)*(x), but note this will cause (x) to be evaluated twice.
Thank you very much
Thanks !
Ok, Thanks!
I am sorry. And thank you for your help.
This might evaluate to ((5)*(6)), but it's undefined behavior since there is no sequence point between x++ and x++, so really it could evaluate to anything.
I don't know why you're doing this either, but here are the basics. All you're doing is assigning the value 0xC5000200 to the variable `ABC`. Because the presumed type of a number in C is an `int`, you're also casting that value to the correct type before assignment. This tells the compiler to treat a value as a different type than it would otherwise.
The `aligned` attribute controls the placement/address of your variable. You are requesting `ecan1MsgBuf` be placed on an address evenly divisible by 512; and `data_buffer` be placed on an address evenly divisible by 128. It could affect your RAM usage. For example: uint8_t someByte; unsigned char data_buffer[8][16] __attribute_((aligned(128))); unsigned int ecan1MsgBuf[NUMOF_ECAN_BUFFERS][8] __attribute((aligned(NUM_OF_ECAN_BUFFERS * 16))); If someByte was assigned address 0, data_buffer would probably be given addresses 128-255. ecan1MsgBuf would be given address 512-767. If instead you wrote: uint8_t someByte; unsigned int ecan1MsgBuf[NUMOF_ECAN_BUFFERS][8] __attribute((aligned(NUM_OF_ECAN_BUFFERS * 16))); unsigned char data_buffer[8][16] __attribute_((aligned(128))); If `someByte` was given address 0, it would be possible for `ecan1MsgBuf` to fill addresseses 512-767, `data_buffer` could then be given addresses 768-895. The RAM usage grew by 128 bytes. **The linker can restrict the alignment to a smaller value** https://gcc.gnu.org/onlinedocs/gcc/Common-Variable-Attributes.html#Common-Variable-Attributes TLDR: `aligned` tries to control the address, typically used for multi-byte memory access speed improvements.
AFAIK, there isn't such a tool. However, there are some close to that. For example, memory hooking tool, like mtrace, can count the heap allocations and deallocations of blocks; cachegrind, intel PIN could instrument memory read/write.
There's Valgrind's heap profiler, [Massif](http://valgrind.org/docs/manual/ms-manual.html).
I'll copy a response I just made to another, similar, post. In C, having a solid understanding of pointers, pointer arithmatic, and memory management is tremendously useful with data structures. Get used to constructs like *(list-&gt;data[1]) or **i++. Some data structure examples like to have terse, less readable, code. One resource I highly recommend is using tools like valgrind on any programs you write. One of the problems I had many years ago, was not seeing my mistakes, because the results weren't obvious. For instance, I thought I was dallocating every element of a tree, but I wasn't. Then there are all the times I was derefencing a pointer that had been deallocated, and indexing past an array... Having a good tool to confirm what you expect to be true would be very useful. 
X-Post referenced from /r/programming by /u/notaplumber [connect(2) doesn't restart](https://www.reddit.com/r/programming/comments/50jhjv/connect2_doesnt_restart/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Sockets are crude and strange. It's sad that a saner API (like [that of Plan 9](http://man.cat-v.org/plan_9/2/dial)) hasn't taken over.
The localization standard library header: http://en.cppreference.com/w/c/locale On Unix systems `locale -a` in the shell will display all available locales. If that doesn't work check `/usr/share/i18n` or `/usr/share/locale`. To change the locale for `time.h` functions to Japanese: #include &lt;locale.h&gt; int main(void) { setlocale(LC_TIME, "ja_JP.UTF-8"); /* Japanese */ /* do something */ return 0; }
You can't split up your printf statement on multiple lines without a backslash. For now, just keep it all in one line.
It is what the teacher uses and teaches on. We CAN use another one, but thats not what he Wants us to use. and i agree, i have tried Visual Studio and it was ALOT easier.
Just about anything is easier, considering nano is essentially the Notepad of Unix. Even any other popular terminal editor would be better than nano (or as some people would argue, including myself, better than anything else, at least for C). Just some advice: despite what your teacher uses, nano is something that you will *never* use in the real world. If you're one of those people that likes to read books to learn things, consider Vim or Emacs, otherwise, stick with Visual Studio (or Sublime Text, or anything else with the basic necessities that nano lacks). As far as I'm concerned, nano exists for editing text files when it's either your only option, or you don't program, much like Notepad on Windows machines. Sorry for the rant, but it pains me to see someone new to programming being steered in the "objectively" (subjectively) wrong direction when it comes to this sort of thing. Edit: One thing to keep in mind with learning any programming language is that you're better off not using the equivalent of Visual Studio's "Intellisense," as this will get you used to being able to scroll through a list of identifiers, etc. instead of actually remembering the language.
I really like your advice, and once i get more used to nano i will probally swich to VS. I didnt think about it when i made the first reply, but that is the program that we use on the school computers, and he records the screens when we are doing work on them. something to do with grading and some other things that i cant remember.
If your professor is asking you to use nano, then by all means, use nano. I imagine that the most likely scenario is that you're SSHing into a *nix box and that's the easy terminal editor to pick up/teach. Either way, keep using nano, but it'll be worth your time in the long run to also learn a real editor (the keyboard shortcuts, the optimal workflow, etc.).
ok, one more question. I did the gcc command and no errors popped up, i forgot the command to run it. please help. (again)
i remember (after you said something) it was the ./a one... 
 int main(){ printf("hi \ there\n"); } You can split statements in C across lines by ending a line with a '\'. Sometimes it's useful if you want something formatted a specific way. For a printf like this if your lines are still indented then that whitespace will end up in your output as well.
Thank you, at least I know the problem now. Is there a line of code or something I can do to stop this from happening?
Like kjchowdhry said - the problem is the terminal closing. Another problem that you may want to consider here is the `if(x=y)`-statement. This is an assignment, which means that after this, `x` will be the same as `y`, which also means that this conditional will always be true unless y is 0. The correct way to check for equality is to use `if (x == y)`. This would be a subtle bug. Your program will _mostly_ work correctly since the first two `if`-clauses takes care of every other possible case. (If both `x` and `y` is 0 it won't print anything). But this can be a pretty hard to find bug in bigger programs. Make sure to always compile with -Wall (enable all warnings). Then the compiler will tell you about this! Good luck in future learnings!
It's common to place: getchar(); Immediately before the return statement. This will 'wait' untill the user presses return on the keyboard.
Thank you! Saw this by accident when I couldn't understand why it kept telling my x=y, so I googled.
`printf("%x", c);` if I recall correctly. I made my own `print_hex` function so I'm not using `printf` really often, I recommend you do the same.
Instead of putchar(c); use printf("%x ", c); All other formatting options for printf() can be found [here](http://www.cplusplus.com/reference/cstdio/printf/).
Better use `"%02x"` or `"%02x "`
TIL about od hexdump. Thank you. Yes this is a learning exercise. Im learning C by parsing a GIF
Hi, I think your problem is with your use of scanf, you wrote scanf("%f, &amp;degrees_celsius"); but I think you were meant to write scanf("%f", &amp;degrees_celsius);
Please don't waste our time and [repost the same question](https://www.reddit.com/r/C_Programming/comments/50ffab/in_my_work_i_am_doing_correct_thing_but_i_dont_no/). If you have follow up question, elaborate on what you already know and refer to the previous question. Just reposting the same question is completely useless. If you do this again, I'm going to ban you. I have deleted this repost, please focus on the previous question.
Sure, this works. There are some rare pitfalls with this though. `printf` doesn't take a string to print as argument, it actually expects a format string. So if you try to `printf` user input for example - what happens if the user would type `I gave it 120%s`?
As /u/cassandraspeaks said, use either `strtod` or `sscanf`. You can round numbers with the `round()` function. You can also use the `rint()` function if you want to have a result depending on the current rounding mode.
ok, i'll add that to my list of functions to explore as well. thank you.
You should consider using strtod as a test case nonetheless; Interestingly enough, glibc's strtod is based on arbitrary precision arithmetic, allowing them to be more accurate in edge cases, i.e. for some silly cases such as 10^9 + 10^-16 your code yields 10^9 + 64 because you use floating point arithmetic, where as glibc's strod rounds to 10^9.
Oh, I almost forgot: scanf isn't very uh, forthcoming for the test case above, not sure why that is to be honest. You are better of modifying your program to read input strings from the command line anyway (ie char* string = argv[1]).
You have a struct called "function" but then in in your createList() routine you return "Function". Notice that this first character is now capitalized. Where do you define "Function" since that is not a keyword in C? Is it a typedef done somewhere else perhaps? EDIT: I read your header file and see the typedef now. Also, when you allocate memory for newFunc, you are allocating memory for the size of the memory address of your new struct. Why not just say: Function newFunc = malloc(sizeof(struct function)); This insures it allocates enough memory for your structure. I did not go line-by-line through the rest of the code but I did see this issue when I reviewed the first function. What problems are you seeing with your code exactly? It is a bit hard for me to understand what the exact issue is and what you are trying to achieve from just reading your post.
So I took a stab at implementing a version of `atof` that rounds to a certain number of decimal places, without using any standard library headers. I'm sure it could be much improved, but I'll post it anyway. /* rounded_atof.h */ #define INFINITEE 1e999999 #define NAAN (0.0 / 0.0) double rounded_atof(const char *, const int); static double sign(const char **); static double hex_digit(const char); static double dec_digit(const char); static double rnd_str_doub(const char *, double (*)(const char), double, const int, const int); /* rounded_atof.c */ #include "rounded_atof.h" /* Assumes 0-9, A-F and a-f are consecutive in the character set */ double rounded_atof(const char *str, const int rnd) { double coeff; if (str == (void *)0) return 0.0; while ((*str &lt; '0' || *str &gt; '9') &amp;&amp; *str != '-' &amp;&amp; *str != 'I' &amp;&amp; *str != 'N' &amp;&amp; *str != 'i' &amp;&amp; *str != 'n') ++str; coeff = sign(&amp;str); if ((*str == 'I' || *str == 'i') &amp;&amp; (*++str == 'N' || *str == 'n') &amp;&amp; (*++str == 'F' || *str == 'f')) return INFINITEE * coeff; if ((*str == 'N' || *str == 'n') &amp;&amp; (*++str == 'A' || *str == 'a') &amp;&amp; (*++str == 'N' || *str == 'n')) return NAAN; while (*str == '0') ++str; if (*str == 'x' || *str == 'X') { ++str; return rnd_str_doub(str, hex_digit, coeff, 16, rnd); } else { return rnd_str_doub(str, dec_digit, coeff, 10, rnd); } } static double sign(const char **str) { double coeff = 1.0; neg: while (**str == '-') { coeff *= -1.0; ++*str; } while (**str == '+' || **str == ' ' || **str == '\n' || **str == '\t' || **str == '\r' || **str == '\v' || **str == '\f') ++*str; if (**str == '-') goto neg; return coeff; } static double rnd_str_doub(const char *str, double (*dig_val)(const char), double coeff, const int radix, const int rnd) { double digit, exp_base, result = 0.0; char exp_lc, exp_UC; if (radix == 10) { exp_lc = 'e'; exp_UC = 'E'; exp_base = 10.0; } else { exp_lc = 'p'; exp_UC = 'P'; exp_base = 2.0; } coeff *= radix; while ((digit = dig_val(*str)) &gt;= 0.0) { result *= coeff; result += digit; ++str; } if (*str == '.') { int i; coeff = 1.0 / coeff; for (i = 0; i &lt; rnd &amp;&amp; (digit = dig_val(*++str)) &gt;= 0.0; ++i) { result += digit * coeff; coeff *= coeff; } } if (*str == exp_lc || *str == exp_UC) { int exponent = 0; ++str; coeff = sign(&amp;str) * radix; while ((digit = dig_val(*str++)) &gt;= 0.0) { exponent *= coeff; exponent += digit; } if (exponent &gt; 0) while (exponent--) result *= exp_base; else while (exponent++) result /= exp_base; } if (rnd &lt; 0) { long long nuresult = (long long)result; int digit_places = rnd; while (digit_places++) nuresult /= radix; while (--digit_places != rnd) nuresult *= radix; result = nuresult; } return result; } static double hex_digit(const char digit) { return digit &gt;= '0' &amp;&amp; digit &lt;= '9' ? digit - '0' : digit &gt;= 'A' &amp;&amp; digit &lt;= 'F' ? digit - 'A' + 10.0 : digit &gt;= 'a' &amp;&amp; digit &lt;= 'f' ? digit - 'a' + 10.0 : -1.0; } static double dec_digit(const char digit) { return digit &gt;= '0' &amp;&amp; digit &lt;= '9' ? digit - '0' : -1.0; }
Yeah I just realized I accidently put that 2100 there. Was meant somewhere else. Thank you for the insight tho and advice with the names..
\n does not guarantee that the buffer flushes.
Currently `openFile()` is redefining its pointer parameter with `fopen()`. To solve this you'll need to pass around the address of the `FILE*` (a `FILE**`) and set that to point to whatever `fopen()` returns.
For most buffers you're right. However, if stdout is not redirected to a file, as is the case with OP, it is line-buffered and a newline will flush it, guaranteed. &gt; Newly opened streams are normally fully buffered, with one exception: a stream connected to an interactive device such as a terminal is initially line buffered. [source](http://www.gnu.org/software/libc/manual/html_node/Buffering-Concepts.html)
The main problem is that `solvePuzzle` uses the value of `count[num]` without ever counting the numbers first. Also it should not be a global variable. In `solvePuzzle`, you should skip all cells that have a number 1-9 since you don't need to fill them. For every cell that has a 0 indicating it must be filled, zero out `count`, add all numbers in that cell's row, column, and box to `count`, and print all numbers 1-9 whose `count` is 0. I would recommend just using a `uint16_t` for `count` because you can just set bits to be either 0 for no appearances or 1 for 1 or more. This can be extended to a fairly workable algorithm. Also, `solvePuzzle` seems to be using `r` and `c` instead of `i` and `j`: `r`, `c`, and `k` are useless right now. The check functions also have the problem where they do not actually count things, plus the way `checkGrid` both increments `i` and `j` by 3 and multiplies them by 3 when accessing `arr` is not correct. Good luck!
Could I do this with a pointer?
You change a global variable the same way you change any other variable int g_my_global = 0; void func() { g_my_global = 10; } int main() { func(); printf("%d",g_my_global); return 0; } will print `10`
Code pls
Let's say your variable is as follows [example.c]: int count; Then you need the following in your associated header file [example.h]: extern int count; With that, you have a variable accessible by all files that include your header. Now, in another file [somefile.c], you can access the variable by including the header and setting the variable as you would normally: #include "example.h" // inside some function... count = 2;
Please do not use `FILE **` here. A simple `FILE *openFile()` that returns the Pointer is far better style and easier to understand for a beginner. There is no need to deal with side effects here.
Some hint for your `displayFile()`: You needn't use '~' as a marker for the line ending because the standard "line feed" is just the ordinary character '\n', that you can compare and print. As '\n' is directly mapped to your terminal, you can just ignore the end of a line in this example. Edit: spelling.
/u/urisma is right, if you have a global variable, it's value is the same in every translation unit as the variable exists only once. Perhaps you can show us your code to demonstrate the problem?
I do agree. The `FILE**` suggestion was the smallest change he needed to make to get it working. If anything, OP should just remove `openFile()` and replace it with `fopen()` and perform the `NULL` check in `main()` (as well as `fclose()`). I'd also recommend changing the `displayFile()` loop to use a do-while loop, which eliminates the need for the first `fgetc()` call, and replace the `EOF` check with `feof()`. 
Please put four blanks in front of every line of code so the code comes out readable (right now it's completely garbled). If this is too tedious, upload the code to a paste service of choice.
Your tone of voice isn't exactly non-assholish either. But ok, I won't post special methods to clear your screen anymore.
No, you declare it again in your header file with the keyword "extern" and then include that header file anywhere you need to access the variable. 
I created a gist of your code [here](https://gist.github.com/ferraristealer/44ddd9f2176a74646b6641492424d98f) after fixing the compilation errors. It prints 10 10 This is exactly how you change a global variable and the best way to do so. If you want to change it explicitly via a pointer, try int my_global = 10; void func() { *(&amp;my_global) = 5; } int main() { printf("%d\n",my_global); func(); printf("%d",my_global); return 0; } This will print 10 5 But please don't modify a global this way. It's bad style and the way I said originally works.
If you're not using multiple files then you can simply declare/define the global variables in main.c and mark them as volatile or not depending on what's going on. To include different files you just do #include "filename.h" As long as filename.h (and filename.c if applicable) are in the same directory as your program.
This subreddit is becoming depressing with this "**do my homework**" bullcrap.
It could use a "learn programming" rule regarding "We will not do your homework".
If you don't like a certain kind of content, use the vote buttons and post better content. Incidentally, your only submission to this subreddit is [a question](https://www.reddit.com/r/C_Programming/comments/4ln3mi/user_input_validation_with_scanf/), so what are you complaining about?
See [POSIX](http://pubs.opengroup.org/onlinepubs/9699919799/functions/scanf.html): &gt; The conversion specification includes all subsequent bytes in the format string up to and including the matching &lt;right-square-bracket&gt; ( ']' ). The bytes between the square brackets (the scanlist) comprise the scanset, unless the byte after the &lt;left-square-bracket&gt; is a &lt;circumflex&gt; ( '\^' ), in which case the scanset contains all bytes that do not appear in the scanlist between the &lt;circumflex&gt; and the &lt;right-square-bracket&gt;. If the conversion specification begins with "[]" or "[\^]", the &lt;right-square-bracket&gt; is included in the scanlist and the next &lt;right-square-bracket&gt; is the matching &lt;right-square-bracket&gt; that ends the conversion specification; otherwise, the first &lt;right-square-bracket&gt; is the one that ends the conversion specification. **If a '-' is in the scanlist and is not the first character, nor the second where the first character is a '\^', nor the last character, the behavior is implementation-defined.**
Well, i didn't see the code, but thank you. That seemed like a bad idea.
I had to work a 14 hour shift today at so while I very much would have been fine with doing the assignment myself and hit the books, I simply didn't have time to do all of that. This is my first post to this subreddit and will be my last because I hate being that *that guy* but it gets hard sometimes to be a full time employee and a student at the same time. While I agree with you and u/pat_trick, this subreddit could use a lot less of that or at least a we will not do your homework rule, there is none, and I only asked that someone point me in the right direction, which two people have done for me already and no one even posted a single line of code anyways. I also am well aware that there is a subreddit dedicated for homework help but it doesn't have much subs or activity so I thought I'd try posting here first. I digress... Thanks to everyone else who actually had the common decency to help a guy out though!
I don't know what many distro's of Linux look like but this is OS X isn't it?
It depends. What operating system are you using? How are you compiling your program? Please give us more information.
yup
while(i&lt;strlen(small)) { x[strlen(big)-1-i]=small[strlen(small)-1-i]; i++; } I'm sorry, but after this fragment I started to bleed from the eyes. Then I did not dare to look.
Don't call strlen so many times. Just save the results from one call and pass them around on functions. A call to strlen initiates a loop so it drops your program's performance in the long run. Also what's the deal with these loops? while(i&lt;strlen(small)) { x[strlen(big)-1-i]=small[strlen(small)-1-i]; i++; } Why not just copy the array from the start to the end and not from the end to the start, like you're doing? Seems obscure. In a program like this you should really use assertions, for example: #include &lt;assert.h&gt; . . . assert(x[i] == '0'); because you can never be sure of the result of each function. Just debug each function from top to bottom slowly and be sure of the result it produces. Speaking of assertions, I've never seen that error but it would be interesting to see what's up with it, if anyone knows. Aren't assertions supposed to be for debugging only, and then to be removed from the final product with NDEBUG? Why would this version of libc have assertions like that?
Random guess: somewhere you code makes a rogue memory access and edits the data structures of malloc. Thus the next call to malloc fails. Also your code leaks memory every where. For each `malloc` you should have a `free`. Pro-Tip: `sizeof(char)` is always 1
I posted this on /r/learnprogramming too [link](https://www.reddit.com/r/learnprogramming/comments/50xijp/malloc_error_2372/)
Just add the source files from the library into your project. Don't forget to change all mentions of #include &lt;ubidots.h&gt; to #include "ubidots.h" Because the library is part of your project, not part of the system. To satisfy the other dependencies, first install the appropriate libraries: sudo apt-get install libcurl4-dev libjansson-dev and then add the following operands to the end of your linker invocation: -ljansson -lcurl
i did all that.. i am actually stuck at compiling my program .. i am passing clang -o practice practice.c and i get practice.c:6:11: warning: implicit declaration of function 'keepGoing' is invalid in C99 [-Wimplicit-function-declaration] while ( keepGoing() ) { ^ practice.c:7:20: warning: implicit declaration of function 'getValue' is invalid in C99 [-Wimplicit-function-declaration] double value = getValue(); ^ 2 warnings generated. /tmp/practice-521211.o: In function `main': practice.c:(.text+0x1a): undefined reference to `ubidots_init' practice.c:(.text+0x25): undefined reference to `keepGoing' practice.c:(.text+0x35): undefined reference to `getValue' practice.c:(.text+0x5d): undefined reference to `ubidots_save_value' practice.c:(.text+0x6e): undefined reference to `ubidots_cleanup' clang: error: linker command failed with exit code 1 (use -v to see invocation) here is the code from practice.c #include "ubidots.h" int main() { UbidotsClient *client = ubidots_init("MY_API_KEY"); while ( keepGoing() ) { double value = getValue(); ubidots_save_value(client, "VAR_ID", value, TIMESTAMP_NOW); } ubidots_cleanup(client); return 0; }
Please put four blanks in front of every line of code so the code is readable. Same for your error messages. Have you tried adding the operands I mentioned?
I'm not a professional programmer (though I'd like to be) but I first started by learning basic Bash scripting, then went on with Perl programming and only then I began learning C. One of my first book on the subject (and the first, though not the last, I really finished) was Head First C. Their examples and exercises are kinda fun to do and the text is very comprehensive. The best advice I received so far was to open a text editor and just code. True it may not compile or produce some weird output but to investigate those bugs and errors and fixing them is the best way to learn. If you don't know what to write, check functions in "string.h", most of them are trivial to reproduce and will give you a good understanding on how they operates under the hood. You can even hit github.com, download a copy of the Libfindf library (my first C project! :) ) and start thinker with it. Ask as many [good] questions as you can, even if sometimes replies are a little harsh it's worth it ;) Learning C takes patiences and passion. Don't ever give up!
 int is_digit(const char c) { if ((c &lt; 48) || (c &gt; 57)) return (1); return (0); } /* somewhere in your code */ if (!is_digit(getchar())) puts("Badly formatted input, please insert spacing between each digit");
Check what `getchar()` returns, if you get a digit when you expected a space, write an error message. If you are still having trouble then post your complete program so far (in the question preferably). 
This isn't the Obfuscated C Contest. You can write `'0'` to mean the digit zero, instead of its character code in one particular encoding. 
Sorry, im pretty new to C. How do you check what getchar() returns?
he starts using a VM a few minutes into the video
Oh ok. 
Just to prove I wasn't talking out of my rear... +/u/CompileBot C #include &lt;stdio.h&gt; #define pintspercup 0.5 /* 1.6/3.2 */ #define ouncespercup 8.0 /* 25.6/3.2 */ #define tablespoonspercup 16.0 /* 51.2/3.2 */ #define teaspoonspercup 48.0 /* 153.6/3.2 */ int main(void) { float cups; printf("Enter the number of cups to be converted. "); scanf("%f",&amp;cups); printf("%8.2f cups = ", cups); printf("%5.3f pints\n", cups*pintspercup); printf(" = "); printf("%5.3f ounces\n", cups*ouncespercup); printf(" = "); printf("%5.3f tablespoons\n", cups*tablespoonspercup); printf(" = "); printf("%5.3f teaspoons\n", cups*teaspoonspercup); return 0; } Input: 3.2 
Output: Enter the number of cups to be converted. 3.20 cups = 1.600 pints = 25.600 ounces = 51.200 tablespoons = 153.600 teaspoons [^source](http://ideone.com/j6TIaG) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/C_Programming/comments/50vfsb/newbieneed_help_with_assignment/d780ym6%20Include%20your%20reason%20for%20reporting%20here.) 
LIke /u/FUZxxl said. Just basically implement your own version of ArrayList or Vector. You could also use a link list depending on what you want to do with the list
Qt framework and IDE is perfect for this. 
oh geeze. let me try and repost that code #include &lt;stdio.h&gt; int main () { /* variable definition: */ float a,b,c; /* variable initialization */ a = 2.3; b = 1.5; c = a / b; printf("Integers (a,b) and product (c) are : %d,%d,%d \n", a,b,c); return 0; }
Yeah that. not sure how you get that to input correctly
 #include &lt;stdio.h&gt; int main () { /* variable definition: */ float a,b,c; /* variable initialization */ a = 2.3; b = 1.5; c = a / b; printf("Integers (a,b) and product (c) are : %d,%d,%d \n", a,b,c); return 0; }
The `%d` format specifier is used to display an `int` variable. In order to display a `float` variable, use the `%f` specifier instead.
My problem was resolved, what I needed was: char next_char; int number; while (scanf("%d%c", &amp;number, &amp;next_char) == 2) { /* some stuff */ if (next_char == '\n') break; }
Qt is C++, is it not?
I just started a intro programming class also. I feel like i am getting only portions of the info needed out of it. Are there any recommendations on books that teach c programming?
Why not just write int getline(char line[], int maxline) { } When the function is being defined? Whats the point of writing int getline(char s[], int lim) { } 
Well, checking what it returns is the only way to see what the person typed. So I guess you have been doing it already, but here goes anyway: int ch; ch = getchar(); // now "ch" holds the value returned. 
I'm really curious how you came to this post 3 months after the fact... And those two things are exactly the same, what's your point?
IUP [1] has some popularity. There's a Wikipedia article that includes a list of widget toolkits, including language. [2] Forgive the lack of proper links, I'm on mobile [1] http://webserver2.tecgraf.puc-rio.br/iup. [2] https://en.wikipedia.org/wiki/List_of_widget_toolkits
An immediate mode GUI doesn't store state or provide callbacks like you might be used to in a retained mode one. Instead you just call functions to draw widgets and check if they are clicked or whatnot every frame. More detail [here](http://www.johno.se/book/imgui.html).
What if the interrupt occurs in between writing some bytes of the variable?
I don't see how that would happen. In my experience interrupts can't happen mid-execution of a line of code and instead wait until completion of the current line. For the interrupt to occur while writing (if I'm understanding what you're meaning) the variable in question would have to be an array and I have no idea how volatile interacts with pointers and the like... I don't really try to theorize to that depth and instead would try to predict an issue and prevent it by other means. Edit: meant to add this link about volatile in embedded http://www.barrgroup.com/Embedded-Systems/How-To/C-Volatile-Keyword
Haven't seen [libui](https://github.com/andlabs/libui) mentioned yet. Definitely good for lightweight buttons, text boxes, etc.
Interesting, I suppose that just leaves it up to the programmer to disable interrupts before assigning values to variables similarly to the process you would use when writing to memory on embedded systems. I guess you're implying that volatile is not safe if the variable in question is modified in an ISR that is generated during a write to a multi-byte variable... sure, I can believe that. What would you do instead?
Please don't. I don't see any advantage in this “header-only” fad. Apart from the trivial not-really convenience of not having to add extra file(s) to your project, I only see disadvantages: * every time you include the header, the preprocessor has to process the entire file. If your entire non-trivial library is implemented in there, this can take a significant toll on compilation time, even when most of it is thrown away anyway. * header-only libraries cannot easily hide things, making it much easier to accidentally depend on an implementation detail you are not supposed to see. * header-only libraries don't mesh well with cases where the library is supplied by the system, e.g. in a typical Linux distribution where all libraries are packaged separately from the projects that use them. If you want to provide maximal convenience, choose the approach sqlite chooses and provide a single source file in combination with a header file. This is just as convenient as a header-only library but comes without all the disadvantages. You might want to look into the build system of sqlite for inspiration on how to develop such a library (they basically have a step where all source files in the library are amalgamated into one large file). Generally though, programming a portable library is much more important than having it consist of only a single file. I would also recommend you to pay attention to the following things: * write portable code. That doesn't mean "runs on Ubuntu and I think Mint," that means "I have ported and tested this thing on Windows, OpenBSD, Gentoo, and a number of other systems and I have a strategy for supporting more platforms." * make it easy to swap out the build scripts in case someone wants to integrate the library into their project. * try to make it so that your library compiles without any complicated compiler flags (e.g. large amounts of `-D...`). Use a configuration header if you need any definitions to exist while compiling. * make the library thread-safe and re-entrant. Make it so that more than one component of a program can use it at a time without any interference. * write in C89 or C99 and don't use any non-standard language extensions so the library can be compiled on older systems. Don't rely on modern features unless you have to. * write a test suite. * have a stability promise. That doesn't mean “I use semantic versioning but [keep the version at 0.xx for ever](https://github.com/nfc-tools/libfreefare/issues/46) so I can get away with breaking changes.” That means “The API to this library is stable and won't change in incompatible ways in the foreseeable future.” * document and comment the library throughly so it's easy to understand how it works. Documentation doesn't mean “my function names are so long, they are practically self-documenting,” it means “here is a high-level overview over the library and an explanation of what every function does, what failure modes exist, what the input must look like and what invariants the functions have.”
It really depends on functionality. If you're writing a HashMap or other data structures, you might want the library to completely rely on macros and inline functions. This would be an ideal occasion for a header only library... which could (by it's nature) never be used by foreign languages (unlike compiled libraries). However, in the normal course of things, I see no upside (and a lot of downside) in a header only library.
See our sidebar.
I struggled with this for SO long, at first I just wanted the simplicity of having only one file to manage, and without having to deal with libraries and all that shit. But in the end I had to separate the source from the definition, because at some point it just becomes too difficult having to rearrange your functions all the time to be sure everything's defined in the right order. One more thing: Macros will only cause you pain, for absolutely no reason. link time optimization is very much a thing, and anyone still using that bullshit from 30 years ago just hasn't caught up to the times.
I very much disagree with the C89/C99 part. clang and gcc support the VAST majority of processors and OSes out there, unless you're literally compiling it for a micro-controller, (in which case clang still supports them somewhat) you're just doing yourself a major disservice here.
Don't use a global variable unless you absolutely have to. You know how many global variables I have in my 700 line library? 1, and that's because there's absolutely no other scope in which it'll work...
0-255 in an 8 bit unsigned int, because there are 2^8 or 256 discrete values, which has to include the 0, so you have to subtract one aka 2^8-1 It's an array of 3 hex values, one for each color... there are 6 digits because a single hex digit is a nibble, not a byte... No hate, but you've got a LOT of learning to do. 
If your using visual studio to compile C... I'm so sorry.
&gt; Macros will only cause you pain, for absolutely no reason. link time optimization is very much a thing, and anyone still using that bullshit from 30 years ago just hasn't caught up to the times. Seriously? Here are two function calls I use in one of my libraries, they allow me manipulate a socket's buffer (application side buffer) in different ways, including file streaming, zero memory copying and other wonderful variations: sock_write2(.fduuid = fd, .buffer = buff, .length = len + 4, .move = 1); And: sock_write2(.fduuid = uuid, .buffer = (void *)((intptr_t)source_fd), .length = length, .is_fd = 1, .offset = offset); Or: HttpResponse.set_cookie(response, (struct HttpCookie){ .name = "my_cookie", .value = "data" }); Which might have been: HttpResponse.set_cookie(response, (struct HttpCookie){ .name = "my_cookie", .name_len = 9, .value = "data", .secure = 1, .http_only = 1 }); How do you expect me to use named arguments or default values in C without macros?
&gt; How do you expect me to use named arguments or default values in C without macros? Just don't do that. Use a structure argument, provide a structure with default values and let the caller fill the structure with meaningful values. Faking things C doesn't have breaks down quickly.
I like using every tool I have to make my job easier. I never scorn a tool (only it's misuse)... ...You can keep your scorn and your preference to ugly solutions to yourself ;-) (I'm mostly teasing, but seriously, tools are just tools, misusing them is wrong, but using them is fine)
i have a question, what is library header-only? I'm beginner.
okay... i tried the operands.
Why would you ever _want_ to do that? Visual Studio's C implementation doesn't support an almost twenty year old version of the standard, and the compiler interface is awful. Clang and GCC both can be installed and run from Windows.
For function-like macros: If possible provide both the macro and a function that implements the same thing. These two can even have the same name: int foo(int x) { ... } #define foo(x) ... this is the way this kind of thing has traditionally been done and it's really fine.
A lot of proprietary compilers for lesser used embedded processors, which GCC and Clang don't support, don't support even all of C99. If this is a library intended to be portable to such systems, you really do need to stick to a minimal subset of C. My company's coding standards require us to use essentially C89 for this reason.
That's all in one .c file. Nothing header only.
Cool, is the longer one online?
So why inconveniently put everything into one file when you have to split it up for every sane use anyway? This only seems to inhibit useful use cases (e.g. the library being provided by your distributor instead of every package shipping its own copy).
This is a risky click for me since my view of gdb is already very positive.... Edit: I'm not even 2 minutes in and already my mind is blown. I *don't* have to `b main` `r` all the time?
Doesn't matter how small the library is. I want to be able to put it in a separate package and link to it dynamically so I can update the library independently from the rest and so I can save disk space. &gt; All the single header libraries are meant to be statically compiled and we're talking about a few 1000 lines of code per lib I've seen much larger “header only” libs, such as [this one](https://github.com/vurtun/nuklear/blob/master/nuklear.h). Just because it is 1000 lines large now doesn't mean you should adopt a development model that doesn't scale. &gt; Another reason your compile time fears are groundless. They are not. Preprocessing useless code takes time, especially with C++, where on average [one byte of code leads to 2000 bytes coming out of the preprocessor.](https://talks.golang.org/2012/splash.article) One of the design goals of Go was just to avoid that. &gt; Also, the fewer translation units the faster the build, not sure why you'd prefer to split it up. That's just not true. If you are doing complete builds all the time it might be, but in a development setting with incremental builds, being able to not compile a large chunk of code every time is very useful. Also, splitting code into multiple translation units allows the linker to throw away unused chunks easily, which is why many serious libraries are implemented in one file per function. There is no other portable way to get unused code thrown out reliably.
Step one: Do some research. Step two: If still having issues, then ask, with particulars of what you've tried.
You want to reverse an array, it's just that your array is the string length -1 (Assuming ASCII Text)
Yes so what I got stuck on was the part on setting the pEnd variable to point at the last address in the string. I know the pStart should point to the first address in the array so that I can swap the 1st and last value using pointers, temp variables, etc, then go up increment in the pStart variable and down increment pEnd variable. 
what!? you are kidding me!
There's was a longer one?
If you only need to output it to the screen why not try a loop that prints each element of the array in reverse order one by one. 
null terminator. but how do assign the value pEnd = null terminator - 1?
Well you can still do that, like I said breaking them up into an h/c is easy. Whether you like them as single headers or not, they make it easy to integrate into your project(s) however you want to. And they are used ... all over the place. I was looking at the [VOGL repo](https://github.com/ValveSoftware/vogl/search?utf8=%E2%9C%93&amp;q=stb) recently and saw they're using 3 stb libs and another single file header lib inspired by stb [miniz](https://github.com/ValveSoftware/vogl/blob/a7317fa38e9d909ada4e941ca7dc2df1e4415b37/src/voglcore/vogl_miniz.h). Why didn't they use zlib instead, it's included in every linux package repo for them to dynamically link and it's the defacto standard for that compression algorithm? Sometimes (often) it's just easier/nicer to avoid dynamic libs and have control of everything. Like I said it's way easier to add well written libraries in this style to a project and the idea is to add the actual code to the project and compile statically. Even with that 10K file, that's insignificant savings with today's hard drives and most of these libs already have standard libs in the repos that do the same thing (stb_image for example could be replaced by libpng, libjpeg, giflib, and a handful of others if you really wanted to deal with that... uggh). Also all of the stb libs and 99% of the libraries inspired by it are written in clean C not C++ so they already compile waaay faster than C++, even in C++ mode. And the preprocessor is nothing timewise compared to the C++ language, templates, exceptions etc.. And yes I was talking about a full rebuild. I work on a project at work that's maybe 200K split between about 150 files, and many separate libs built and linked in and system dynamic libs. It takes way too long to build especially for a C project. The overhead of starting and stopping the compiler so many times for so many projects, building some parts into separate libs to be linked into the final executable etc. is nuts. If I were writing it from scratch (it's a 26 year old project so ... very legacy shudder), It'd be half the code, wouldn't use autotools (except maybe autoconf if they insisted) and it'd build in no time. The unity build popularized by Casey Muratori in Handmade Hero is probably the best way to build anything if you're starting from scratch and/or have total control over the project and the time to get rid of crappy over complicated code organization/build systems. I'm actually fine with a simple Makefile but then again I don't work on windows and when I do I use MSYS2/Mingw not cl or windows cmd. Also at a previous job I worked on 2 very large projects (on the order of 1million LOC or more) and we used incredibuild and they both still took for freaking ever to build. The link time alone took like 7 minutes. Incremental build doesn't help and neither does multithreading if even changing a single file creates a 7 minute wait. They were of course both C++ projects. Compare that to the linux kernel which you can build completely in about [a minute](https://www.phoronix.com/scan.php?page=news_item&amp;px=MTAyNjU) on an average desktop. And last I checked they still aren't using LTO [here](https://www.phoronix.com/scan.php?page=news_item&amp;px=MTY1OTg) If you have 2000 bytes coming from a single byte of code you're doing some ridiculous C++ template crap I can only assume. None of these C libraries do that obviously. For my own personal projects and experience I'd say I've never really gained time from incremental build with Make. I don't know at what size of project you'd break even and it probably varies for different types of projects but for me, mostly from scratch (with SDL2 for my graphics/OpenGL programs) I'd bet the cutoff is *at least* 50K LOC. For example my [C_Interpreter](https://github.com/rswinkle/C_Interpreter) compiles completely in less than 1.5s, about 5.5s for -O3, and I should probably stick to -O2. That's using a Makefile, with ~11K LOC over 7 translation units. With that kind of compile time, neither the incremental build nor multithreaded build would make any difference, might even slow it down. As an aside, for application programming, whether it's a compiler/interpreter, game, etc. you can do a lot with relatively small amounts of code so probably most if not all things I'd ever write would be less than 50K total. Then there's projects like [tcc](http://bellard.org/tcc/) which show how fast a C compiler can be. Sorry for the semi rambling response. I rarely comment on here. FTR I'm not saying incremental build is bad or that everyone should be using 1 or 2 translation units but that breaking things up so much (1 function per file!??) is overkill for 98% of programming. Oh and that dynamic libraries are a pain for shipping, especially if you want to support multiple platforms including older versions of platforms that have different incompatible versions of libraries in their repos or don't have repos at all (hello Windows and Mac, hence the MSYS2 and macports/homebrew). I was/am responsible for getting that big POS project from work compiling/working on Windows and Mac again and it was/is not fun.
In the video he says that he'll give a longer talk the next day but I'm not sure it was recorded and is available online.
Here https://www.youtube.com/watch?v=713ay4bZUrw
&gt;[**'Become a GDB Power User' - Greg Law [ ACCU 2016 ] [87:20]**](http://youtu.be/713ay4bZUrw) &gt;&gt;If you’re writing C++ for anything other than Windows, chances are that you occasionally break out GDB. This session presents some of the lesser known features of GDB that can change the way you debug. GDB has come a long way in the last few years and does so much more than break, print, step and continue. Reversible debugging; Non-Stop Mode; Multi-process Debugging; and Dynamic Printf are but some of its best features, and its built-in Python scripting is particularly powerful. Join Undo Software co-founder and CEO, Greg Law, as he takes you through a series of demos to show some amazing tricks with GDB, and powerful new (and not-so-new) features that you may not have heard of. &gt; [*^ACCU ^Conference*](https://www.youtube.com/channel/UCJhay24LTpO1s4bIZxuIqKw) ^in ^People ^&amp; ^Blogs &gt;*^6,625 ^views ^since ^Apr ^2016* [^bot ^info](http://www.reddit.com/r/youtubefactsbot/wiki/index)
yes, that's exactly what part im suck on, trying to code that. pl0x help
Interesting library. A few notes, if you're interested: * I believe de-coupling the server and IO code from the protocol layer might do it some good, allowing you to use reuse the code with `libev` or another server library (I authored [this one](https://github.com/boazsegev/c-server-tools), but the whole point is that you can use any library when you have a more modular approach). This will also make the library easier to maintain through future iterations and updates. For example, I think it would be better if the `process_command` function didn't have access to the `fd`. * Another question: this is a new project, why not use markdown for the readme? The format you used is like a throwback to the 80's :-p * Last point: I tried following along (but I might have made a mistake) and it seemed to me that your server ignores the possibility of fragmented commands. I did notice the `default` case statement doing nothing (and `process_command` returning `1`), but then the buffer is freed instead of having it filled with more data. On a local machine, message fragmentation is not an issue, but most networks limit TCP/IP packets to (give or take) 1,500 bytes... that's not much and it does mean that your commands might arrive in more then a single packet. 
&gt; Well you can still do that, like I said breaking them up into an h/c is easy. Whether you like them as single headers or not, they make it easy to integrate into your project(s) however you want to. That's a manual process and means that you modified the original code. So now, it's no longer trivial to pull updates because you have to manually adapt the patch for your split up code. &gt; even in C++ mode. If you are compiling C code with a C++ compiler, you are doing it wrong. That's an incredibly easy way to introduce nasty bugs as some details are different between C and C++ and you might not find out until the compiler optimizes something useful away when you compile with a C++ compiler. &gt; Also at a previous job I worked on 2 very large projects (on the order of 1million LOC or more) and we used incredibuild and they both still took for freaking ever to build. The link time alone took like 7 minutes. Incremental build doesn't help and neither does multithreading if even changing a single file creates a 7 minute wait. They were of course both C++ projects. Link time is generally not reduced by having fewer translation units as the time taken by the linker is bound by the number of symbols. That said, if you are developing for Linux, consider installing the Gold linker instead of the standard BFD linker. Gold is much faster. &gt; If you have 2000 bytes coming from a single byte of code you're doing some ridiculous C++ template crap I can only assume. None of these C libraries do that obviously. Including libraries like STL or Boost can do this kind of thing. &gt; Then there's projects like tcc which show how fast a C compiler can be. While tcc is indeed fast, note that it doesn't optimize at all. You can save a lot of time if you compile with `-O0` during development. &gt; Oh and that dynamic libraries are a pain for shipping, especially if you want to support multiple platforms including older versions of platforms that have different incompatible versions of libraries in their repos or don't have repos at all (hello Windows and Mac, hence the MSYS2 and macports/homebrew). I am more concerned about my (open source) software being distributed by a distributor. Which is exactly the case in which I really want to have the ability to put libraries into separate packages.
Thank you for being one of the few users who actually bother to put four spaces in front of every line of code!
The MER and Curiosity rovers at Mars are somewhat famous, and their control system largely written in C. Toyota vehicles are rather famous too - whose firmware are written largely in C. 
Quake1,2+3. Git. 
C was invented for the UNIX operating system, which is likely the most famous piece of code written in C. Its heritage is everywhere.
 If (array[x] == '\0') {terminate_array;} But that's rather the basis of strings in C. I invite you to read some good tutorial/book about the subject. 
busybox is a favourite of mine too.
All the core systems in the Unix world tend to be C. The kernel, the display server (X and Wayland) the boot/shutdown/daemon manager (systemD). Many of the Linux desktops are also in C. Most of the command line tools and core libraries are also in C. If it doesn't need to be small and fast, it tends to be written in a script. That used to be Perl, but these days Python, but both are themselves implemented in C. Top level desktop GUI apps are more likely to be written in C++ that else where. Basically the more technical the project/community, the more likely it is in C.
CTRL-P! That's the missing link.
Not quite, it's compiling it to an internal bytecode that is executed by a virtual machine. Some Googling brought up this promising article: http://akaptur.com/blog/2013/12/03/introduction-to-the-python-interpreter-4/
My bad I did miss the point. 
everything car related
Does that mean that when you access a struct member the whole struct is copied to the cpu cache? I just assumed that only that variable was copied to a register, and then put back to the struct location within memory, like any other variable.
For starters you might wanna use scanf or fgets or anything that isnt getchar to read integers. Manually converting them from ascii is silly. At least use atoi and save them as integers. Secondly, use a while loop that goes to the end of the line instead of a for loop. You can't know how many dice the user wants replaced so having a fixed number of iterations doesn't make sense.
There is a `mingw32-make.exe` in the MinGW-Folder - Did you tried that one? NetBeans is probably using the normal cmd where as msys is like a "seperate shell" with some common unix tools.
Why sort ( O(n log n) ), when you can just do a search in two passes in O(n) (first for goals, then for age)
gcc doesn't have anything to do with that. That's your C standard library (probably glibc if this is Linux) performing dynamic runtime loading. `ld.so` is the name of the program that actually performs that task (though on Linux its name is actually something more adorned like `ld-linux.so.2`) and it's reading its config file to account for user configuration options. In this case it's related to the hardware capabilities feature, which allows accelerated versions of certain standard library functions to be automatically selected, e.g. you might get a `strcpy()` that uses AVX if your processor supports it. Read `ld.so(8)` for details. If you don't want dynamic linking, then don't link dynamically against libc. You can use `-static` to tell the linker to link against the static version of the library, but be aware that glibc is specifically not designed for static linking and the result will a) be quite large, and b) may not work properly in all cases (e.g. there might be some corner cases where things that are normally handled by dynamic plugins might fail.) 
But if I compile it with mingw at linux and then try to run at windows. Windows will throw me an error: "permissions denied". 
Are you using a cross compiler that runs on Linux and targets Windows, or that new Ubuntu compatibility thing? 
I like header-only for certain purposes but this is a well-reasoned caution against overuse of the technique, combined with actionable tips. Upvoted. 
I'm using http://mxe.cc/ with it packages for compiling app. main.c: #include&lt;stdio.h&gt; int main(){ printf("hello world\n"); return(0); } $ i686-w64-mingw32.static-gcc main.c `$(pkg_cfg) --static gclib` -static If I run it at windows, windows will think that app want open "/etc/ld.so.cache" file and throw permission error. 
If your windows executable actually tries to access /etc/ld.so.nohwcap when run on windows, then the thing at http://mxe.cc/ has created an exceptionally broken compiler for you. (I suspect you have instead wrongly come to that conclusion because you saw this with your binary on linux, while the error you get on windows is completely unrelated) 
Thanks. Yes char ***a is an array of arrays of strings. After fscanf(fp, "%s", string); I put this strcpy(a[i][j], string); But when I run the program it gives me error. "Segmentation fault" Does that mean that earlier in my code im using pointers incorrectly? char ***a=(char ***)malloc(sizeof(char **)*4); for(i=0;i&lt;3;i++){ a[i]=(char **)malloc(sizeof(char *)*4); } So I ***a is a matrix with strings in it. Then with the for im saying there is another array within the array and is made of strings?
It's more "useful" to put the list in sorted order. Also, an optimized-for-decades stdlib O(n log n) algo is probably going to be faster than my throwaway 2 * O(n) one. And in any event the difference is trivial until the data set becomes very large.
I apologize in advance for any typos or mistakes in formatting. I'm trying to use the quoting thing ... &gt; That's a manual process and means that you modified the original code. So now, &gt; it's no longer trivial to pull updates because you have to manually adapt the &gt; patch for your split up code. How often do you update your libraries? Honestly unless you run into a bug or are using a super alpha/brand new libraries, most people don't update their libraries that often for a given application. Again referencing, the crap project I work on at work, They were using giflib, libtiff, libjpeg, libpng version that were on average &gt;15 years old. I updated them, mostly because the newer versions would remove a bunch of warnings in the library code and they're probably faster but really from a user's perspective there's no difference, and from a dev's perspective, if it ain't broke don't fix it. Regarding these single file libraries, most of them aren't modified much if ever. While some edge case bugs might be detected the usual reason they're updated is, for example with stb_image, someone's contributed the code to load yet another image format. &gt; If you are compiling C code with a C++ compiler, you are doing it wrong. &gt; That's an incredibly easy way to introduce nasty bugs as some details are &gt; different between C and C++ and you might not find out until the compiler &gt; optimizes something useful away when you compile with a C++ compiler. That is just wrong. One of C++'s design goals was to remain as compatible as possible with C. C is *almost* a proper subset of C++. C code is used/compiled in/with C++ code all the time. And these libraries are specifically written in clean C, ie the C++ safe subset of C. There are really only a handful of diffenences people have to worry about. Namely, no implicit cast from void* so you have to cast your allocations, and in C99, you can't use the very useful designated initializers or structure literals. There are a couple other minor issues like typedefing your structs being necessary in C but not C++ and a [subtle issue with the ternary operator](http://en.cppreference.com/w/cpp/language/operator_precedence) that probably never affects anyone because of actual compiler behavior. Finally there is the extern "C" thing to prevent name mangling if you're doing dynamic stuff. Also C is the common language. Pretty much every language can create bindings for C or can otherwise use it somehow. It is much harder if not impossible for most languages to interface with C++. For example see this developer's reasoning [on why he picked C for his library](http://chipmunk-physics.net/release/ChipmunkLatest-Docs/) Again if you want to maximize reach and easy use, (and approachability/understandability), C is the way to go. &gt; Link time is generally not reduced by having fewer translation units as the time taken by the linker is bound by the number of symbols. That said, if you are developing for Linux, consider installing the Gold linker instead of the standard BFD linker. Gold is much faster. Both those projects were developed on windows unfortunately, and while the number of symbols is probably the biggest influence, having to resolve things across so many TU's rather than having them all in one place would be much slower would it not? That's my understanding/intuition, that the organization/bookkeeping of symbols across 100 or 1000 TU's would be much slower than a 1 or 2 TU's given the same number of symbols. &gt; Including libraries like STL or Boost can do this kind of thing. I don't use those. I've never used Boost. I do/have used std::vector but I like my CVector and it's just as capable, moreso in some ways. &gt; While tcc is indeed fast, note that it doesn't optimize at all. You can save a lot &gt; of time if you compile with -O0 during development. I always do -g -O0 for development. But tcc is an order of magnitude faster than gcc or clang even when they're O0. It's obviously not what most would consider an industrial strength/commercial compiler and you'd probably not want to ship something compiled with it but for actual development it's probably fine most of the time (if you're using C of course. &gt; I am more concerned about my (open source) software being distributed by a &gt; distributor. Which is exactly the case in which I really want to have the ability to &gt; put libraries into separate packages. I'm confused here. All a package maintainer/distributor does is ... create a package, picking reasonable defaults if it's something that needs to be compiled. Since these are 1 (or 2 if they decided to split them up) source files, it'd literally be a package that installed it to /usr/include or something and is there even a "place" for loose .c files?. That doesn't make any sense to me. Are you talking about cloning an official repo into your project repo? You can do that, though if you're using stb, the repo is all his libs and more. Most people, like I said, like with VOGL, just copy libraries into their repo and that's it. Fire and forget. No overhead, no submodules, to svn externals (I hate svn), no versioning issues, just straight forward simplicity. Try creating a linux package that depends on a handful of dynamic libs that correctly installs from Ubuntu 12.04 to 16.04. Across that span, or even 14.04 to 16.04 you have different versions of the same libraries, sometimes API changes which means you need actual code changes depending on which version you're using. Sometimes the versions might be compatible or even the same, but they were compiled with different options which change the API, again causing incompatible breakage. Like the HDF5 library which can be compiled with several different version flag macros which change what compatibility macros actually get compiled as. Whether it's a single file or 100, bringing the source into your project and compiling yourself (whether you build a separate dynamic library to ship with your executable, or build statically) allows you to completely avoid all of the above issues. And if I've already decided to bring the code in to my project and I have the choice between bringing in and compiling libpng, libjpeg (any variety), libnetpbm, and libraries for the other half dozen+ formats stb_image supports: JPEG baseline &amp; progressive (12 bpc/arithmetic not supported, same as stock IJG lib) PNG 1/2/4/8-bit-per-channel (16 bpc not supported) TGA (not sure what subset, if a subset) BMP non-1bpp, non-RLE PSD (composited view only, no extra channels, 8/16 bit-per-channel) GIF (*comp always reports as 4-channel) HDR (radiance rgbE format) PIC (Softimage PIC) PNM (PPM and PGM binary only) or just the one (or 2) files, why would I ever pick the former? Unless stb_image is too slow for my purposes (unlikely) or doesn't support a specific format/file I absolutely need, I'd always prefer to avoid having to pull in more code, more autotools/configuration BS etc. Again another example I mentioned in a previous comment I'd pick miniz over zlib. 
If you're on Windows you should just download Visual Studio.
if your C library has a strdup function (you said you use gcc, so it just may), try: a[i][j] = strdup(string); if it doesn't, you need to be a bit more verbose: a[i][j] = strcpy(malloc(1 + strlen(string)), string); 
i did, and i have all set up exactly as the tutorial said.
Can you run the same common that gave this error to you with the extra option `-###` and post the output?
Well, I'm very glad it helped you. Ask anytime. :) 
Okay clang version 3.9.0 (branches/release_39) Target: x86_64-pc-windows-msvc Thread model: posix InstalledDir: C:\Program Files\LLVM\bin "C:\\Program Files\\LLVM\\bin\\clang.exe" "-cc1" "-triple" "x86_64-pc-windows-msvc18.0.0" "-emit-obj" "-mrelax-all" "-mincremental-linker-compatible" "-disable-free" "-disable-llvm-verifier" "-discard-value-names" "-main-file-name" "test.c" "-mrelocation-model" "pic" "-pic-level" "2" "-mthread-model" "posix" "-fmath-errno" "-masm-verbose" "-mconstructor-aliases" "-munwind-tables" "-target-cpu" "x86-64" "-momit-leaf-frame-pointer" "-dwarf-column-info" "-debugger-tuning=gdb" "-resource-dir" "C:\\Program Files\\LLVM\\bin\\..\\lib\\clang\\3.9.0" "-internal-isystem" "C:\\Program Files\\LLVM\\bin\\..\\lib\\clang\\3.9.0\\include" "-internal-isystem" "C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\include" "-internal-isystem" "C:\\Program Files (x86)\\Microsoft Visual Studio 14.0" "-fdebug-compilation-dir" "C:\\Users\\light\\PycharmProjects\\new\\51\\x" "-ferror-limit" "19" "-fmessage-length" "0" "-fms-extensions" "-fms-compatibility" "-fms-compatibility-version=18" "-fno-threadsafe-statics" "-fdelayed-template-parsing" "-fobjc-runtime=gcc" "-fdiagnostics-show-option" "-o" "C:\\Users\\user\\AppData\\Local\\Temp\\test-043b3c.o" "-x" "c" "C:\\Users\\user\\Desktop\\sbc\\test.c" "link.exe" "-out:a.exe" "-defaultlib:libcmt" "-libpath:C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\lib\\amd64" "-nologo" "C:\\Users\\user\\AppData\\Local\\Temp\\test-043b3c.o"
And ...?
Ohhhh no no hahaha! When I implemented these algos that I have here I didn't even think about Rosetta let alone use inspired implementation. However, after the above guy posted about Rosetta, I looked through and found, a fair amount of the problems I've solved with these algos have been solved in the Rosetta site eg: FFT, both sorting algos. Some, from what I could find, do not have an entry on the site, eg: IFFT, convolution, correlation. Now, I'll be getting more into DSP functions like filtering and machine learning as I go further into this project - and those functions are not (I don't think) solved in Rosetta.
But... you have to compile it...
No idea.
Self-running program: #include &lt;stdlib.h&gt; int main(int argc, char *argv[]) { system(argv[0]); return 0; } Except neither of these is 'self' anything because you still have to compile or run it.
Would `return system(argv[0]);` be more entertaining?
It's called passing by reference. Sorta like how when you order a package from Amazon, you just give them your address, instead putting your house on a truck, driving it to the fulfillment center, and putting the package in your front room before driving your entire house back to your plot of land. 
First of all, (* int) is invalid syntax. I will assume you mean (int *). In which case it is a pointer to int. Pointers have multitude of uses, this list isn't exhaustive: 1. Avoid unnecessary copying of data and instead pass a pointer (in some languages this is called pass by reference). For example, suppose you want to print an int array, you can efficiently pass it to a function using a pointer: print_int_array(int *array, size_t len). Note you need to include the length, otherwise the callee won't know how long the array is. ~~The inefficient way would be to specify a function with the array as the argument and have the data copied in: e.g. print_int_array(int array[100]), in which case you will need to supply 100 ints on the stack (or however C decides to arrange the memory).~~ 2. Modify caller supplied data. So in (1) we showed how to avoid copying data to print_int_array, but instead we might want to increment each element of an existing array, so we could have: inc_array(int *array, size_t len). Edit: I put a strikethrough in the example I showed, since it is conceptually incorrect as you're still passing in a pointer. A valid example of copying would be to pass a struct which encapsulated data (which may include an array), e.g. struct foo { int x[10]; }; print_array(struct foo copy) { ... }. [Full example here](https://godbolt.org/g/M2rwKr)
Yeah, you're correct. I've been spending a bit too much time in golang and starting to mix language features. The syntax is valid, but it is indeed a pointer.
getchar, like scanf, gets input from stdin. you probably want to just use getchar in a loop, looking for the expected input. that way getchar will consume stuff like newline until y is pressed. note that scanf is dangerous. if the user enters a longer string than expected you get a buffer overflow.. if you do want to read a whole string safely use fgets. also, fflush is only for flushing the output stream, not input.
Yes, '*' is the indirection/pointer operator, but your syntax is incorrect, a function taking a pointer argument would look something like /* this function takes a pointer (memory address) as an argument, decrements the value stored there (treating it as a standard integer) and returns the new value stored at the address. */ int decrement(int *n) { (*n)--; return *n; } The * operator is placed in front of a variable name. When the variable name follows a variable type (i.e. "char *c"), it means the variable is a pointer to that type. Using the variable name 'c' in later expressions in the same scope treats it as a pointer, not a character - for example, "c += 5" increments the POINTER by five times the size of a character variable, rather than incrementing the value it points to. To actually access the character that the pointer points to, you'd use the indirection operator again, as in "printcharacter(*c);", which *dereferences* the pointer (which yields the pointed-to value) and sends it to the printcharacter() function. The '&amp;' operator is the 'opposite' of '*'. There's no need to use it to declare a normal (non-pointer) variable, but it can be used to take the address of an existing variable. For example, say you have an integer variable, and need to pass it to a function that takes a pointer-to-integer as an argument. You could do: int n = 5; int *ptr; *ptr = n; ptrfunc(ptr); Note that the two middle lines *cannot* be combined into one (int *ptr = n), since that would result in ptr pointing to *memory address* 5 (which will cause most compilers to generate a warning). However, you could replace the middle two lines with "int *ptr = &amp;n" which assigns the *memory address* in which n is stored to the pointer variable ptr. But you could go a step farther and eliminate the superfluous pointer variable, and instead eliminate the middle two lines and do ptrfunc(&amp;n). The main use of pointers is for functions that need pass-by-reference behavior (i.e. modifying the value they receive). And C doesn't support true objects, but it does have structs, and it's often a good idea to pass those to functions using pointers, since it eliminates the need to copy the whole struct into the function's local area of stack memory. This is of course only beneficial when the struct is larger than the size of a pointer. 
Did you used *exactly* the same versions of MinGW and LLVM that the author recommends ? While LLVM 3.7.0 release candidate and previous versions were compiled with MinGW, latest versions of LLVM were compiled with Visual Studio 2015 and Clang will search for the standard header files (like *stdio.h*) in the default location for Visual Studio. A possible workaround: * Install full Visual Studio 2015 (make sure to enable C++ support, otherwise you won't have the C and C++ header files). Install the latest LLVM binary from http://llvm.org/releases/download.html#3.9.0, be sure to check add Clang to the Path during installation. or * Install "Microsoft Visual C++ Build Tools 2015 Update 3" which contains only the compilers and header files from Visual Studio. Install the latest LLVM binary from http://llvm.org/releases/download.html#3.9.0, be sure to check add Clang to the Path during installation. When you want to use Clang, open *Visual C++ 2015 x64 Native Build Tools Command Prompt* or *Visual C++ 2015 x86 Native Build Tools Command Prompt* and use the Clang compiler as usual.
From the above output, Clang was compiled with Visual Studio 2015 for Visual Studio 2015, see: Target: x86_64-pc-windows-msvc and it simply can't work with MinGW.
Sorry to break this for you, but there's no pass by reference in C. In this case you're passing the **value of the pointer** to the function and then dereferencing it to get the integer that is pointed to. Passing a pointer as a parameter *does not* mean pass-by-reference.
You are right, it simulates pass-by-reference.
It can have an effect if you use one of the more obscure meanings of `static`: int myFunc(int myArray[static restrict 256], int yourArray[static restrict 256]) { /* function body */ } This allows the compiler to perform optimizations based on the assumption that `myArray` is never NULL and points to at least 256 ints and does not overlap with those pointed to by `yourArray`. (The overlap guarantee is provided by the `restrict` keyword). [More details here](http://en.cppreference.com/w/c/language/array)
If you don't use braces, then each if-statement only controls a single statement. With proper indentation, this is what you've written: #include &lt;stdio.h&gt; int main() { int people; double price; printf("Enter the number of registrants: "); scanf("%d", &amp;people); if (people &gt;=1 &amp;&amp; people &lt;= 4) printf("Charge is $100 per person"); price = people * 100; printf("\nTotal cost is %.2f", price); else if (people &gt;=5 &amp;&amp; people &lt;=10) printf("Charge is $80 per person"); price = people * 80; printf("\nTotal cost is %.2f", price); } As the error states, that `else` is not part of any `if` statement, because the `if` statement ended after the first statement that followed it. 
The problem is that there are no scope braces around your **if** blocks. Your initial **if** only affects the *printf("Charge is $100 per person");* line, not the other lines after. Make sure you pay attention to coding style. It is the most important skill you will learn. Indenting is a cornerstone of code style. It would have revealed your problem right away. Here is what you wrote, indented correctly, and spaced for scope readability: int main() { int people; double price; printf("Enter the number of registrants: "); scanf("%d", &amp;people); if (people&gt;= 1 &amp;&amp; people &lt;=4) printf("Charge is $100 per person"); price = people * 100; printf("\nTotal cost is %.2f", price); else if (people&gt;= 5 &amp;&amp; people &lt;=10) printf("Charge is $80 per person"); price = people * 80; printf("\nTotal cost is %.2f", price); } Note that the **if** only applies to the line underneath it. You can see, when the code is correctly formatted, that the else is just hanging there by itself. It is a lot easier to spot why the compiler is complaining. Here is what I think you intended, indented and braced correctly: int main(void) { int people; double price; printf("Enter the number of registrants: "); scanf("%d", &amp;people); if (people &gt;= 1 &amp;&amp; people &lt;= 4) { printf("Charge is $100 per person"); price = people * 100; printf("\nTotal cost is %.2f", price); } else if (people &gt;= 5 &amp;&amp; people &lt;= 10) { printf("Charge is $80 per person"); price = people * 80; printf("\nTotal cost is %.2f", price); } } Now the **if** applies to your entire "$100" block, and the **else if** applies to your entire "$80" block. Note also: * The reason why is probably too advanced for now, but in C, if you intend for a function to take no arguments, it is best to declare the argument list void (e.g.: **int main(void)** not **int main()**). See http://stackoverflow.com/questions/13319492/understanding-the-difference-between-f-and-fvoid-in-c-and-c-once-and-for-a if you're interested in the differences and why the latter is fine in C++ but should be avoided in C. EDIT: Formatting EDIT2: I wrongly stated that a return is required. Thanks for the C99 education!
I'm not taking your points in the exact order they were given, but just sort of free flowing. &gt; I always use the last version of the stable release I chose. It is important to keep your libraries up to date lest you introduce security issues into your software that have long been fixed elsewhere (and are thus easy to exploit). &gt; So you are ignorant about security? What an attitude! &gt; You forgot the security issues you get when you develop with such a model. First of all, security or insecurity is invisible to the user and the functionality of the program is independent of whether it's secure or not so my statement that from the user's perspective it makes no difference is still true. More importantly, the last few years have shown the (in)effectiveness or at least the incompleteness/downsides of your approach. You have an application you develop, and a security hole is found in one of the libraries you use. What do you do? You update to the latest version .. how? Are you waiting for your distro's maintainers to update the version in the repos so you can develop off of it and so that the users will have it, or are you having to build it yourself to get it quicker which again involves bringing the source code into your project *and* shipping the lib with your project? Your way, involves waiting on several parties. 1st the developers have to fix it, the fastest/easiest part, then the maintainers have to update it for all the distros, then the users, and the sysadmins have to update their systems (Many people are running very old systems that may or may not get the update in their repos or the updates will take much longer). No matter how you slice it there is a looong time with many independent parties that can hold up the proliferation of the patch/fix. Now compare that to my way, where the developer of the application handles their own libraries (whether it's a single file library or not). He grabs the latest version (or fixes it himself ... maybe he discovered the bug himself in which case he'd have the fix before even the lib devs), recompiles, packages and ships. Users download the updated version (or maybe it's a self updated app that detects that there's a new version and/or can update in place. Additionally, the developer can know that his application will work no matter what libs they have on their system. Hear about this painful state of affairs from [Linus himself here](https://www.youtube.com/watch?v=5PmHRSeA2c8#t=5m55s). Watch from there to the end of the rant, about 5 minutes. There is a reason for the rise/invention of the [Flatpak](http://flatpak.org/), [snap](https://developer.ubuntu.com/en/snappy/build-apps/) [packages](http://snapcraft.io/), [AppImage](http://appimage.org/), even Docker/containers. All of this is to make it easier for app devs to support many platforms, and update all of them quickly whenever they want, whether it's about security or not. &gt;Stop. Wrong approach. You distribute the software as source code and the distributor packages it. Yes, if you want to sell software you might not want to do that, but that's not what my aforementioned comments about packaging apply to. Not everything is open source (or free) and not everything can or should be part of the the official repos. The maintainers can't accept everything even if they wanted too. They don't have the time/manpower and trying to curate/filter all the projects (let alone actually package them) they'd get if they encouraged it for everything would be overwhelming. Also, again, Windows and Mac complicate matters, even if it's open source. How are you going to manage 2 or 3 totally different methods of building and getting things to users? Responsibility is spread out all over the place and that is a nightmare for development and consistency across platforms. &gt;Emphasis on almost. Some of these differences are very subtle and can cause perfectly normal C code to mysteriously do something else when compiled with C++. If you compile C code with a C++ compiler, you are doing it wrong. Yes, many people are doing it wrong. Did I not say almost? Did I not list the few most notable/important differences? I could point out how the other things on that list are almost never used even in non-C++ C code, or that in the end it doesn't matter what the spec says if all the compilers do it a certain way (see my previous link about the ternary operator in C compilers), or that type punning is and [has been used in C++ for a long time](https://msdn.microsoft.com/en-us/library/windows/desktop/aa383713(v=vs.85\).aspx) and I'm pretty sure every major C++ compiler does the same thing, but all that is beside the point. By definition, clean-C is valid C *and* C++ code that does the same thing no matter how it's compiled. Ergo, saying you have to be a little more careful/meticulous, while true, is irrelevant because we're talking about code that *is* clean-C and people can and do write clean-C. &gt; Is this supposed to be a reason to compile C code with a C++ compiler? I don't see it, sorry. No but if you want to target maximum reach, you use C, and writing clean-C let's you support C++ users too, even if they want to compile statically. &gt;Have you measured? I would even say it's slower to have less translation units when there is a lot of unused crap in each (e.g. in case of the dreaded header-only libraries). This is because static libraries have a mechanism where unusud parts of the libraries aren't even considered by the linker whereas in a whole-library-is-in-one-file type library all functions must be relocated, even if only half of them are used. It's kinda sad to use the Windows linker, it sucks and it's really slow. Did you mean "dynamic libraries have a mechanism..."? In any case, your assertion that it behaves differently for single file libs doesn't make sense to me. If I have a project, say main.c and file1.c, file2.c and I compile them into .o's and then link them, will the linker throw out unused code? If so, then that would apply to single header libraries too, because as I said in my reply to BigPeteB, the implementation would be part of *one* of those .o's. If you split it into it's own c/h pair, it'd of course have it's own .o file. No matter how you look at it, no matter how you bring it into your project, I don't see how these single file libs, would behave differently from the compiler or the linkers perspective. You can make them statically, dynamically, part of 1 TU, their own TU, there's really nothing so different about them that would explain your fear/different compiler/linker behavior. sigh. There's a reason I only comment on reddit every couple years. Even a cordial debate quickly gets too time consuming. I can't guarantee that I'll reply again (unless yours is really short) but I'll definitely read it.
char ans='Y'; while(ans == 'Y' || ans == 'y') { printf("Enter your choice\n"); scanf("%d",&amp;user_choice); ans='\n'; switch(user_choice) { case 0 : exit(0); break; case 1 : { ........ break; } default: printf("Please enter a valid choice.\n"); break; } printf("Do you want to perform the operations again?\n"); while(getchar() == '\n') { ans=getchar(); } } This is what I've written. It is still just prompting me to rerun the operations just once. I've tried to trace(follow the code) but I fail to see the issue. Also, I see that you've pointed out that scanf is dangerous and the reason why it is dangerous. But even then why do most textbooks have codes which take inputs using scanf?
&gt; The int part of the declaration int main(void) declares that your program will return an integer, so I added the line return (0); for you. Without it, the compiler will complain In C99 and later you can omit the return statement for `main`. If it is omitted the behaviour is identical to returning 0.
I've run strace on linux,on elf version of bin file. On windows I've tried to debug exe bin with gdb|ollydbg, but application fall down with `error 5`(can't create process??). Seems that application fall down even before it run any instruction from `main` function.
running strace on an elf binary in Linux will tell you nothing about the behavior of your Windows executable. If you think there's any value in it, there is similar software for Windows: http://drmemory.org/strace_for_windows.html However, it is much more likely that your cross-compiler is broken, and that even knowing what system call is causing the error will not take you any closer to a solution.
Note that its icl on Windows, not icc (just so there's no confusion). Among the errors I get is e.g. "expression must have a constant value", a similar error I get with Visual Studio (2015) when trying to compile my C11 code. I use the newest icl (downloaded just today), and using c99 only makes icl spew more errors. That would lead me to conclude that icl indeed understands C11, but doesn't support every language construct. Which is very weird, considering the Linux/macOS counterpart icc works perfectly fine with the exact same source code.
For what code do you get that error?
That's because whether a structure literal is a constant expression is implementation defined (cf. ISO 9899:2011 §6.6, especially ¶¶8–10). It is likely that this can be toggled with a command line option. Consult the manual for details.
Wow, I just looked, and indeed there's no mention of compound literals as constant expressions. Still though, having such disparity between icc &amp; icl seems weird. Well, I guess I'm off hunting for a suitable compiler switch... Thanks by the way! Really appreciated.
gnu11 doesn't work(invalid value for that option). Quick looking for a switch also doesn't bring anything up. I guess I just rewrite it, can't be that bad.
You could provide two versions, one with the `(typename)` in front and one without. Not a difficult change.
Maybe using `(const struct A)` in the compound literal will help?
You are quite good at communicating information but this video could (should) have been split in two. The first half is a primer on getting nano and gcc installed, the second part is hello world. I encourage you to keep making videos though :)
`malloc()` receives a size in bytes. It has no way of knowing how that value was calculated. Maybe the user wanted 10 objects each 16 bytes in size, or 16 objects each 10 bytes in size. In both cases `malloc()` is passed 160 and has no way of determining which one was the case, as the multiplication happens before the function is called. The user is responsible for doing the multiplication properly, there is no way for `malloc()` to guess the intent. 
If I'm interpreting your question right, you want the user to be able to type in a string of whatever length they want, and have your program always allocate the right amount of memory to store it. Is that correct? If so, there's no way to do this with a single call to `malloc`. The best you can do is read the string in fixed-sized chunks, and use `realloc` to get more memory each time you read a new chunk. For example: #define CHUNK_SIZE 100 ssize_t chars_read; size_t string_length = 0; char *string; do { string = realloc(string, string_length + CHUNK_SIZE); chars_read = read(0, string, CHUNK_SIZE); string_length += chars_read; } while (chars_read == CHUNK_SIZE); In a real program, of course, you should check for errors after calling `malloc` and `read`.
Not only would an `enum` be useless in this situation, enums are pretty useless in most situations and do little except impose annoying restrictions on integer values.
here's an example: 1. Write a compiler in OCaml for your new language, Rust 2. Write a compiler in Rust for Rust, use the compiler from 1 to compile your compiler 3. Compile future programs and versions of the Rust-based compiler using the compiler from step 2. Discard the compiler from step 1.
I think it's easier to see the problem when you look at your expected answer and actual answer in hexadecimal. Hexadecimal can be useful for looking at the bytes that represent the number. So instead of 1784293664 and 500000500000, look at 0x6a5a2920 (1784293664) and 0x746a5a2920 (500000500000) Here we can see that your expected answer 500000500000 expressed in hex contains all of the same hex values as your actual result, it just also contains 0x74. Both values have in common 0x6a5a2920. When you see a situation like this it's a good indicator of an overflow problem. And in this case it's occurring because your equation contains only int's so its final value will be an int. The compiler is seeing each part of the equation as something like (int *(int + int)) / int; And when two identical data types are added/multiplied/divided the result matches the datatype of the values provided. So even though s is large enough to contain the true answer, it is being assigned to a value from an overflowed int. So we see the 0x74 get chopped off. To fix this, either change n from an unsingned int to an unsigned long int or cast n to an unsigned long int in your equation.
If you inted to use `perf stat` you could do something along these lines: #!/bin/bash path="/path/to/exec/folder" for i in {1..50} do perf stat -r 5 $path/example$i.o done If you want to use `perf record`, something like this: #!/bin/bash path="/path/to/exec/folder" out="/path/to/output/folder" for i in {1..50} do for j in {1..5} do perf record -o $out/perf$i_$j.data $path/example$i.o done done
Note that `$((...))` is not implemented in the traditional Bourne shell as far as I am concerned. Also, why the extra verbose `"${TEST}"` instead of just `$i`?
Thank you!
What library do you use in C++ for this purpose? It's very likely that the same library can also be used by C code.
&gt; why you use ${TEST} where you could have used $TEST just as well. Defensive programming habit, even when I'm supposed to be in control of the contents of the variable.
The typical approach for this kind of thing is to do a `setjmp` at a convenient place and then `longjmp()` out of the signal handler when something goes wrong.
I don't code in C++ . So far i am happy knowing only C. But searching the internet i found libraries for those languages i mentioned. For C++ there is podofo.
Yeah, okay, that's a C++ library. I think you can call into ghostscript, but that's a pretty low-level library.
Easy, just do the calculation. Make an empty void variable, and use malloc to allocate 50MB of memory to that variable. Done. Although the OS might be smart enough, and so you might actually have to fill it with data too.
... Can't you just use SDL?
It's easy to make a C program that uses *at least* x amount of RAM. It's harder to guarantee that the OS allocates only that specific amount. But generally just go: char *p = malloc(x);
You can use [wasteram.c](http://fuz.su/~fuz/src/wasteram.c) from my website. 
Pascal strings have the advantage of allowing their length to be found in O(1) time. Though, they come at other disadvantages (mostly not being able to take substrings without copying). A good design is to have a string be a structure of the form struct string { char *data; size_t length; } but that also vastly increases register traffic when passing strings; not sure if that's actually any better.
Of course, every data structure will be a trade off in some way. I guess I took issue with OP's assertion that this is an issue with the C language as a whole, whereas I feel it's more a matter of learning to use the existing features appropriately (and knowing when to build your own structures/libraries).
Operators precedence could be improved. For example i'd expect bit shifting to have more priority than multiplication, for the simple fact that in arithmetic you do exponentiation before multiplication. But not in C. All the bitwise operations have to be carefully parenthesized when you also have algebraic operators in the same expression.
People love re-inventing their wheels, there is a new string class every week on various game developer forums and every large project tends to reinvent their own. C strings are fine. You want your own? Fine too! But first have a look what other simple and exotic string classes exist https://en.wikipedia.org/wiki/Category:String_data_structures . See a rope https://en.wikipedia.org/wiki/Rope_(data_structure) for example - this one is heavily optimized for text templating. Pascal strings are a simple naive optimization to have easy access to string tail, how often you need that if you don't concatenate strings a lot?
They could also move bitwise operators to higher precedence than logical operators. The fucked up precedence has historical reasons (back when `&amp;&amp;` didn't exist, `&amp;` was also used for logic). Go [solved](https://golang.org/ref/spec#Operator_precedence) this problem nicely.
Change `for(i &lt; 20; i++;)` to `for(; i &lt; 20; i++)` and do the same for the other for loop.
Just as it enters the loops it checks whether i++/j++ is 0. Which is obvsly 0 as the incrementation takes place after evaluating the expression. No iteration takes place.
/u/rbc__ seems correct. What happens is that j&lt;20 is actually at the initialization part of the for loop and the evaluation part does j++ , which checks first then increment.
&gt; Why else would open() and similar string-building/creating functions always require a preexisting char *buf as an argument? The reason for this is to let the application programmer handle memory management.
Huh... so what I'm doing is/would be bad if I were making a re-usable library. Should I always strive for that goal, or am I more-or-less right to be wrapping the memory management in this function? This is going to be part of a program that reads ".TSP" files which are intended to standardize specifications for Traveling Salesman Problems, and it's really only for processing text files and extracting the information about the nodes, etc.
&gt; historically the libc has been designed specifically such that malloc is never called by other functions. but why, though?
At least the compiler sees them, unlike macros.
The rule of thumb is that if it's not a web app, it's written in C or one of it's children.
From what I hear, Toyota's breaking system I believe is written in Matlab, and converted to c. that's part of the reason there were crashes.
I still don't understand how an `enum` would help implementing these use-cases...?
But your suggestion was to use a structure anyway, just without the macro that makes it look like named arguments... so how is the macro part poisoned? 
As title says I'm unsure as to what I'm doing here. For reference, I am a total beginner on programming and this was the task given to me. It says pseudo code so am I not putting this into a code form into a compiler? Help would be appreciated. 
I guess you could code it, if it'd help you understand it, but I don't think you need to. You just have to provide sample input and the result that code would give you when fed with said input. You should choose your input over a wide range to test the algorithm with extreme cases (0, trillions… whatever you see fit). I don't think I can help you beyond that; the ideal input for those cases has probably been already explained by your teacher.
Memory allocation can be an expensive process and some applications use their own memory management schemes for performance reasons. For example, an application may want to allocate a large chunk of memory and then manage the allocations within that chunk on its own using a scheme which matches its specific scenarios. Databases, for example, do this when running queries.
No. With `Input`, the user inputs a value. From then on, you should assume `Price` and the other name refer to values given by the user. Your assignment consists in being the user, and writing a list of three examples of two values (price and taxes) and the result you expect. It also consists in choosing the right examples, to test the errors the program may have. I don't think I can explain it any clearer than this, sorry.
I mean you could, but what is the fun in that? Some people like hobbies.
Yeah, I had a similar discussion on my thread in r/dsp. I've been busy but next time I get to work on this I'll give it a permissive public domain license.
That string manipulation is weak is a commonly-repeated criticism of C. That there's inevitably a relatively-elegant way of combining simple features of C to do anything, as FUZxxl's simple example shows, is often elided. An example is string handling in languages that later added non-ASCII text encodings. In C with UTF-8, it's rare to need to actually parse the UTF-8 bytes into codepoints, much less codepoints into glyphs, but it's not really hard when it is necessary, just a bit verbose. Compare with the contortions taken by the string manipulation libraries in other languages in order to make them both usable and backwards-compatible. From this point of view, not having a string type and instead having pointers to arrays of null-terminated bytes looks like genius-level simplicity, and you always retain the option of using structs and macros or a specialty library. 
`strdup` also returns allocated memory. Nothing wrong with it, but it should be used carefully. * embedded systems may need a custom allocator, performance constraints may also require over * if the memory is allocated in a library - effectively partially hidden, even if documented - it is easy for the client to forget to deallocate it. There have been many leaks from `strdup`. Again, it can be very useful, and writing what you have is very educational. You might want to look at `strtok` to get a similar api.
Take a look at jansson or libuv. They allocate memory by themselves.
I think, it is because of that line: if (&amp;amp;memory == NULL) I believe that what you want is: if (memory == NULL) If malloc fails then *pointer* will be `NULL`, not data it points to.
Thanks; I tried fixing it but the error remains :/
The ptr asterisk is a type prefix operator. Arrays and functions are type postfix operators. This means we need parenthesis and precedence rules to disambiguate a composition of ptrs, functions and arrays in types, as well as confusing a (vast?) majority of C users. Consider: int (*(*x)[10])(); This is terrible! If asterisks had been post-fix operators, let's say a post-fix `^` as in Pascal: int x^[10]^(); Now it's read left-to-right. x is ptr to arrry-of-10 ptrs to functions. This would make C far more accessible to everyone, too. It would also remove the need for the silly `-&gt;` operator, since `^.` is usable.
Integer promotion rules are terrible. Everything under int is promoted to a signed int, whereas stuff larger than int behaves differently. This is inconsistent and yields the surprising result that: `unsigned short + unsigned short` results in a `signed int`!
The standard library is full of terrible pitfalls. `gets` is a known one and now deprecated. But `strncat` and `strncpy` are more terribleness examples: `strncat` takes a length, every single programmer I asked expects this to be the destination allocation length (which is the useful thing to have). Instead, it takes the maximum length to concatenate! This results in security issues. `strncpy` takes a sane length, but does not guarantee a valid string result (no null termination!) and it also memsets the rest of the destination string, making it near useless due to efficiency concerns. The standard library is full of such bad designs.
Actually not that often. And in most cases, the cost is negligible as the string is then immediately copied or otherwise evaluated.
Exactly :)
&gt; I have this idea that it's bad practice to make a dynamic variable without also deleting it within the same scope. Well, some people think that. Not me personally, the key thing is to make sure your function clearly documents its requirements. One drawback to this method is that it forces the caller to use dynamic allocation, whereas some other options allow the caller to choose the allocation method. Forcing one method makes the library is less general-purpose. 
Pdf alert. I think this is one that's been posted before. Not complaining, just letting folks know.
The preprocessor's dumbass global namespace. Because writing TOTALLYUNIQUEPROGRAMPREFIX_MODULENAME_CLEVERMACRO instead of CLEVERMACRO never gets old.
This is great content. A guide for implementing object oriented with C. You can find it practically in Linux kernel code. 
Haven't looked at this one yet, but if it's one of the ones posted before then i agree.
First thing I noticed is that you're alocating token_array to a single byte (sizeof(char)==1). This is incorrect since the size of a pointer to char is not the same as the size of a char. (sizeof(char*) == 4 on 32-bit systems). You should first iterate over the input string and count how many tokens you'll end up with, then allocate token_array with enough space to hold that many char**s. so if you have n individual tokens, you'll need to call token_array = (char**)malloc(n * sizeof(char*))
Try taking the continues out of all the if/elseifs, I'm sure someone more knowledgeable will correct me but I think you only really need them if you're using case statements :)
continue statements are valid anywhere inside of a loop.
Once the program is blocked for user input, execution is halted until input is received. To get around this you can look at the alarm() function which generates a SIGALRM signal for which you can set a signal handler function. It's a bit hacky but that's all I can come up with.
enums are pretty... weak. Generally, I think the typing in C could be stricter, less implicit casts.
What operating system are you programming for?
Using `snprintf` instead of `strncat` is a neat hack, thanks. But it's not in-place, though. Truncated strings are not necessarily strange.
Yes, implicit conversions between so many types (`int`, `bool`, enums, ...) have saved me countless seconds and wasted me countless hours.
It's not always available.
The great thing is the OpenBSD devs have it nicely separated in their source tree, so you can just grab their [file](http://cvsweb.openbsd.org/cgi-bin/cvsweb/~checkout~/src/lib/libc/string/strlcpy.c?rev=1.13) and dump it into your source tree, if it is not available (for instance on linux or some custom embedded platform, or even Windows).
Thank you so much! That actually worked and it seems like I have even more studying to do than I previously thought. Time to wade through K&amp;R a bit more...
I won't repeat what others have said but they are right. Here is some helpful advice: Determine the total amount of characters you are willing to accept as input and create a symbolic constant. Let's say 100 chars: #define MAX_INPUT 100 Then allocate the memory for 100 chars to text: char *text; text = malloc(MAX_INPUT); Then your fgets() should look something like this: fgets(text, MAX_INPUT, stdin);
Windows 10. Also this is for personal/educational purposes so I don't mind having something super hacky or not great practice for this one feature.
Thanks, I'll look into this.
Like their queue-implementation? Or is that FreeBSD? I used it somewhere, worked great even on Windows :D
I know how to write my own `strlcat`. The problem is each project has its own basic library of these kinds of functions, with less uniformity and more potential places for bugs to hide. May as well say C comes without a standard library, which is indeed quite close to how C is often used.
You linked list implementation looks suspiciously like a ring buffer and not a linked list. In any case, it is unclear what you're trying to accomplish. What exactly is this program meant to do? I.e. given an input, what should be the output? 
I probably should've changed the file name. It stated as a linked list. Then I adjusted it to be more of a queue. FIFO principal. Given up to 30 files inside same folder my program is in. I use a system command. It creates input file.txt with file names. I open that up. Then, I open each file to get info to compare other files for similar groupings. Input: the grouping of similar words I need to look for. (Ex: 7. So I would look for like a similar grouping of 7 words in each document...) Output: File names and its contents Followed by a grouping value of file 0 and file 1. I kept it static/basic being I look for similar words and use a count. If the count reaches groupL. I reset and increment to groupL. Since this posted I made minor changes. (Initialized count, groupL and y values to zero...) did not make a significant difference. 
Freezes, how? Segfault? Infinite loop?
after the previous printf statement it just stops doing anything.
The indentation is right in sublime but when formatting for here i think it got messed up. The intent is to store point sets into a text file of a NACA airfoil The variable names are my own downfall but i know what they are so its ok the filepath thing is there because the path changes through the program as it generates multiple files The constants are used in a header file Command is just "touch (filename)" and that changes so thats why its composed of variables Without the system command the same thing happens. I added that to try and see if the file not existing was the problem.
You cant store an int into a string
&gt; i know what they are so its ok But no-one else does, so it's not ok.
its not related to the question
It makes it a lot harder for anyone else to figure out if what your program is doing is correct.
Maybe not directly related to C but I think books like this one are very nice and provide a step by step guide of getting started with X11/XLib programming. The topic seems to be mostly abandoned these days.
Then I think you're not using header files properly. Looks like maybe you put your fill() function in there? You shouldn't have any code blocks in your header. Ignoring that for the moment, I'm more concerned about your doubles mm, pp, and xxx. Those are all using integer values. I can't see any reason for them to be doubles.
Considering you are asking others for help it kind of does, doesn't it?
I have written *so freaking much* XLib code over the years. God help me, I even kind of enjoy it now. 
OK, let me back up and cover a few things that I'm not sure you've got. If you're going to do much C programming, you'll want to have this stuff down. Don't be one of those engineers or scientists who knows just enough C to shoot themselves in the foot, and cause suffering to the programmers who have to come along after and figure out what they were doing. Floating point numbers (single or double precision) are stored in an exponential notation. They're great for storing small values or large values, particularly when you don't know in advance what range the values are going to be in. They are not good at storing *exact* values, and comparing for equality is problematic. You shouldn't use them for things like counters. For those things, you'll use an integer type. I have done a *lot* of exactly what you're doing where you set individual character values in your filepath variable. I've done that because I've been working on embedded systems with very tiny amounts of memory. When you have an alternative like sprintf() available, you should use it. You've got a lot of magic numbers in there. Specifically all of the filepath[] offsets. I see that what you're doing is accounting for the difference in path length between the different OS options. It's a bad way to do it and is likely to cause you pain somewhere down the road. It opens up a lot of potential for mis-counting characters, and there's nothing up above to remind you to go change all of those offsets if you change the paths. Fixing this might seem unnecessary for a single-purpose, throw-away program. Wait until you've written a few hundred of these programs over a decade or two and you'll understand why you should fix it now. Future you will thank you. Same for comments. If the intent of the code is not blindingly obvious, comment it. Add a comment block that tells you what the code does, why it was written, what inputs it takes and what outputs it generates. You might think you'll remember all of this, but again, just wait a decade or two. Or even a few months if you've got a lot of projects going on. Meaningful variable names are also important. Naming something x is bad (but forgivable in the case of trivial loop counters and such) but using names like xx and xxx together along with m and mm is just asking for trouble. Back to magic numbers. 48 is the ASCII value for '0'. If you mean '0', you should use '0'. Not that the compiler is likely to be using EBCDIC or something, but '0' (with single quotes) equates to 48 (0x30) and it makes your intent more clear. About sprintf(). It looks like you've got the basics of using printf() down, and sprintf() will do the same thing but it outputs to a string. You can use that to concatenate your path, filename constant section, and the formatted decimal values from m, p, and xx. I gave you an example in an earlier comment. Learn to use the format specifiers (particularly width and leading zero options) and you can eliminate all of that nasty messing with the character values. It's far easier to read and to maintain, and it won't break if you're using a double-byte character set or something. On to the headers. You say you're using 'constants[]' in your header. That suggests to me that you're defining your fill() function in the header, and that's not how headers should be used. C headers shouldn't contain any code or other objects that occupy memory. You can put defines, externs, and function declarations in there, but definitions should never go there. Macros can have code but the macros insert the code where they're used and are just text substitution. If fill() needs to be in its own file, then make a fill.c file or some name that makes sense. Fill.c gets the body of the function, and fill.h just gets the function declaration. To get your constants into fill(), you'll probably want to pass it a pointer to constants[], unless the constants are always the same and you want them declared in fill.c. In either case, if they're constants they should be declared const. Making variables called 'constants' is bad practice, and declaring your constants const will let you know when you've screwed up. It's also a good idea to do at least some minimal sanity checking on your arguments. At the very least you should check argc and see if it was passed the right number of arguments. Typically you'll print a usage block as a reminder to the user if it didn't get the right number. You should also check that they're all in the expected range, particularly since you're using them to generate filenames and execute shell commands. Any sufficiently seasoned *nix sysadmin will probably be able to tell you horror stories about when shell scripts have gone wrong and ruined their day. I have folders full of code not unlike this that I wrote when I was 15 or 16. That was almost a quarter of a century ago and I've learned some lessons the hard way. Even now, every month or three I'll need to dig up some forgotten utility I wrote and try to figure out what the heck it does and how it works. Save yourself some pain and get in the habit of writing useful comments now. Even if you never come back and look at them again, the act of writing out your intentions clarifies your thoughts and can help you catch mistakes before you even write any code.
Hah. I'm actually working on a toolkit like that. If I ever have any free time to tinker with it some more, I'll put it out on GitHub. I don't like C++, I prefer straight C...but you're right, there's a dearth of GUI toolkits for plain C.
You should show your fill function too.
After you've built your own language, you can [build your own OS](http://wiki.osdev.org/Main_Page) to host the language! You'll start with assembly but it can be all C from there, if that's your thing. (C is still a good language for OS implementation, though the Rust camp wants to eat that lunch.) If you want step-by-step then start with [this tutorial](http://wiki.osdev.org/Bare_Bones) and you'll have your very own, from-scratch, OS kernel booting and printing to the screen by the end of the lesson. It could be your new addiction! :-) Have fun.
good idea! thanks a lot!
&gt; Ok so I looked into that and it seems you're right though a linker could be implemented that did throw out unused functions within an object file. Probably just not worth the effort and makes it slower. Such a linker cannot be easily implemented because in an object file, there are no functions. There are only symbols and they point into some segment. Each segment contains a bunch of functions or objects glued together. The linker doesn't know where the objects end, some times there is size information attached to the symbols but it's not relyable. &gt; Here's the thing, the situation I described is how every project I've ever seen works, compiling to .o's and linking them. You keep talking about the linker throwing out unused object files but why are you even compiling them if you're not using them? Because you only compile the library once and then every project can use the same pre-compiled object files. &gt; Your recommendation/method that "serious" libraries should put 1 function per C file, make dynamic libs etc., kind of falls apart and doesn't apply to anything I've ever seen. It creates for more work/maintenance headache for the developer and it definitely doesn't apply to these single file headers. These libraries are purposely implementing specific things. There's usually a few user facing functions which of course in turn call the implementation functions. With the exception of something like stb_image, which supports many image formats, all the other libraries, there'd be really nothing to throw out because nothing unnecessary is included. [Every](https://sourceware.org/git/?p=glibc.git;a=tree) [libc](http://cvsweb.openbsd.org/cgi-bin/cvsweb/src/lib/libc/) [works](https://svnweb.freebsd.org/base/head/lib/libc/) [like](https://github.com/joyent/illumos-joyent/tree/master/usr/src/lib/libc) [that](https://github.com/minix3/minix/tree/master/lib/libc). How does this “make dynamic libs etc., kind of falls apart?” This is something you do so *static linking* is faster and allows the linker to throw out unused object files. This does not matter for shared objects as these are already linked (as opposed to static libraries).
Of course there is the wonderful [Jonesforth](http://git.annexia.org/?p=jonesforth.git;a=summary) tutorial.
These `␣` are supposed to be visual representations of white space. Instead of `␣` hit the space bar.
I think your algorithm is correct. Given the tight constraints of the exercise, there doesn't seem to be a better strategy.
Isn't that a women-only thing?
Oh, okay. I always thought it was.
That's how I learned c back in the day. It's a terrible way to learn c. But an awesome hoby! I just had my... eleventh... fifteenth?... Let's call it my yearly restart-from-scratch. So much new stuff to discover all the time. 
If you could post your code (or code that demonstrates the same problem) we can show you where the problem is. Right now it's a bit hard to see what went wrong.
I don't think you've described your question very well, but I think you might be talking about something real. The throughput of ssl decryption can easily be a bottleneck in a program, especially when these things are true: * you have a fast or very fast network. * you have lots of parallelizable work to do If I'm going to download gigabytes of numbers, over SSL and sum them, and I have a single thread/process doing the ssl work, and I dispatch the numbers to worker threads, then the worker threads will nearly always be idle and will just be waiting for numbers from the SSL thread. You won't be able to complete the work any faster then a single core can execute the SSL read for all of the data. The way to correctly architect this problem would be to run as many threads as you have cores, and then have every thread do both SSL and the summing. Even if you don't have parallelizable work it can still be beneficial to run multiple threads doing SSL reads. You would have N threads reading blocks of data, all feeding them ( with or without some ordering mechanism ) to a single worker thread.
Not sure about that. Modern x86 cores have hardware support for AES, allowing for speeds of 3.5 cycles per byte or up to 2.6 GB/s/core.
heres my code https://gyazo.com/3a8af793a43721774e8d35c8cbd9ef95
Not sure either. Maybe it's a problem of small buffers?
I'm actually work on library for instagram API i send HTTP header to server and get response by reading data with SSL_read() Code: Char buf[100]; Int byte = SSL_read(ssl, buf, 100); While (byte) { Buf[byte] = '/0'; Printf ("%s", buf); byte = SSL_read(ssl, buf, 100); } This code is cool and work fine.. But it takes more than 50 s to load all data. the data is not much and i have a fast network connection. And that is the problem..
Running `printf` in a tight loop is probably going to slow you down a lot.
Are you sure it is actually OpenSSL that is the problem? To verify, run tcpdump to see when the packets arrive at the kernel (tcpdump gives microsecond timing resolution). Compare the arrival time of those packets to the time at the end of your SSL read. I would guess the difference between tcpdump read and SSL read *should* be in the order of 10 - 50 microseconds on modern hardware.
You can size the array by first doing a dry-run where you find out how many arguments you are going to have, then allocating an array and finally slicing the original string up. Or you can simply allocate an array that has enough entries for all intents and purposes (let's say, 100) and call it a day.
Is UK/unsigned accum some special implementation defined type? And can you use C++? If not, why not just cast your literal to the type you want?
Followup: if I change my macro definitions slightly to add another level of evaluation before the token-pasting operator: #define PASTE( x, y ) x ## y #define PASTE_2( x, y ) PASTE( x, y ) #define EVAL( z ) z #define MAKE_UK_CONSTANT( val ) PASTE_2( EVAL( val ), UK ) I get a clearer error message that shows the left-hand side expanded, although not simplified: error: pasting ")" and "UK" does not give a valid preprocessing token #define ENCODER_VOA_MAX ( VOA_ENCODER_VALS_PER_SEGMENT * VOA_TABLE_SEGMENTS_PER_DB * ( VOA_MAX_DB - VOA_MIN_DB ) )
As I read more about this, it appears that what I want to do may just not legal in standard C, although some compilers might be more liberal about it than GCC is. I found this bug report: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=7976 It looks like it has to do with the way that ## is defined. It apparently requires that its arguments, concatenated, produce a valid token rather than some arbitrary text. That bug points to an example where someone is trying to do something similar, generating a constant like 123UL. This apparently worked with HPUX C. There are a variety of tutorials out there on the token-pasting operator that look they rely on non-ANSI-standard-compliant behavior. This would work if I could force the preprocessor to go ahead and evaluate (simplify), not just expand, the left-hand side, so that the ## operator was given a literal number and UK, but it looks like that may not be possible. So I guess I'll consider it solved as in "standard C just doesn't allow this and some examples and tutorials are wrong per standard C." 
But when it comes to execvp I think that the last index of the array has to be set to null, correct? How should I go to insert this null, cannot do it for the last array index. 
I got what causes it just like why the dot?
This was given to us on our third day of class, the project is due on Saturday lol. I think this course is going way too fast...I am considering dropping the course. 
`ls` displays an actual dot (cf. the `-q` option).
Are you using blocking sockets? Your code might be waiting for network packets. since `SSL_read` returns the data after decryption, it must wait for enough data...
Had you tried to do the exercises you may have found a significant portion of them to be confusing and poorly described, and others requiring skills not necessarily taught yet at that point in the book. I became very frustrated with them. This was the first book I purchased when I set out to learn C. The book prides itself on the simplistic nature of C, and such are the explanations of the concepts it teaches. I felt the book was a bit too short in details much of the time. The book is okay but after reading it in it's entirety, taking notes and reviewing them, I still found myself lacking in confidence of what I had learned. I seemed to have many pieces to a puzzle that I was unsure how to put together. My personal opinion is that this book is a bit overrated, at least for a beginner. I later bought another book that was highly rated on amazon and it's was a far better learning experience, and I would recommend the second book over this one any day of the week. Just my two cents.
That's what I'm realizing... I think I have been slightly ruined by working with languages like NewtonScript that will evaluate at compile time. Somehow I knew how the macro system works, but it was not registering. The restriction on ## only generating valid tokens complicates the situation a little, since in general the preprocessor will happily generate nonsensical program text if you ask it to, and the preprocessor won't detect it. For that kind of bug, being able to dump out the preprocessor output is helpful, but it wouldn't help in this case.
I just did that as a test 
i think it's readable now.
Yeah. Thank you for your cooperation.
Still new to Reddit posting, and very new to this subreddit. I think it's formatted correctly now, thank you.
&gt; however i am trying to figure out the method to return back to where it requests the input from the user to where i can have the question cycle without having to end the program and restart it. To repeat a section of code several times, you need to use a construct called a "loop." C has a couple different kinds of loops, but the simplest (and the one you should probably use here) is called a `while` loop. You can find an explanation of `while` loops in pretty much any C tutorial or reference online, and probably also in your course materials.
I've looked into the while loop a couple of times. My issue here is where to insert the function. Essentially, regardless of what the user input is, I want it to go back to where it asks the user to input a letter.
most of what I have seen about the 'while' loop has to deal with when a variable is equal or not equal to a number. how would that work here?
Probably this: https://github.com/c-jm/basic-flatfile-db-implementation it was for a school project. The only thing c++ about it is the file extension. It was a great project and also reenforced the usefulness of building custom data structures. 
Then why do you use C++ in the first place?
I see.
Do you have the source anywhere?
Did a similar thing a long time ago, to get around a restriction. The teacher basically allowed it but wasn't too happy about it :D
No Problem.
1. I totally agree with you on exercises portion. 2. I never told it was a good book for beginners, nor did the authors. P.S. Thanks for reading the review, though.
Whoops, missed it!
My best---it's a toss up between [my blogging engine](https://github.com/spc476/mod_blog) (continual use since 1999) or [the MC6809 emulator](https://github.com/spc476/mc6809) (due to how the code is structured and used). My most interesting is [just enough of an MS-DOS emulator](https://github.com/spc476/NaNoGenMo-2015/tree/master/C) to run a 30 year old program for my [National Novel Generation Month 2015](https://github.com/dariusk/NaNoGenMo-2015) entry ( [more info here](https://github.com/dariusk/NaNoGenMo-2015/issues/184) ).
My most interesting c program was a hopping filter that worked off of a parrallel interface and changed frequencies within 15us. I have done so many different projects in c over the years. But that project, I designed the hardware, and software. It felt like it was only me and no one else. 
1. You're trying to print an uninitialized 'c' 2. You're not dereferencing your pointer 'n' in your for loop. 3. Why are you unnecessarily passing by reference? 
Wrote a background task for Palm Pilots so that we could fake push notifications. For those confused, Palm Pilots didn't have background tasks. Or multitasking. Or push notification capabilities. Or really any of those fancy features that modern smart phones and tablets have. It did have a battery life measured in weeks, but this app I wrote here fixed that problem too :D
C is a high level language. Not sure what you're asking about.
As in bots?
Maybe you borked your gcc-version or paths? 
I'm going to try this, thanks! About gcc, do I just download it as an executable to my computer?
What kind of niceties do you think would have helped me with this program? I can't think of any.
Sorry, I read your other post and though you were already on Linux. If you're running Windows, pick up a copy of [cygwin](https://cygwin.com/install.html). Make sure to include gcc when you go through the installation.
oh haha, no. I'm actually hopping between this subreddit and /r/linux4noobs trying to set myself up to code on linux because I figure i can't possibly get any errors there. no one's answered my question on how to boot linux without a usb lol so for now I'm stuck on windows. I will try cygwin thanks!
I suspected this and then removed the path to TDM, reinstalled it and loaded the settings into codelite. didn't work. 
Yeah, for the computer poker competition: http://www.computerpokercompetition.org
I'm coding a ultima online client
Wow this is really cool
Yes, So who can i handle this?! 
I still remember [this product](http://labequipmentlist.com/columbus-instruments-videomex-v-video-tracking-system-lel3369) fondly. It was developed back in 1987ish. It is 68000 based and used the huge chocolate bar type DIP chip. I developed the processor board and all the code (written in C and assembly language.) I worked with a great hardware guy to design the video digitizer/display board. It was designed for animal research labs to examine different aspects of animal behavior. It worked with a fixed camera above a cage with no top or a clear top. Some of the more fun/challenging parts were: * Processing the captured video in real-time with such a slow processor. I developed a number of fast algorithms and was able to keep up with 30 frames a second in all analysis modes, which was plenty fast enough. * Calculating trig functions without floating point. * Fitting all the functionality into a relatively small amount of EPROM. * Developing all the text and graphics routines for the video display. 
I had a ton of fun writing the only alternative client for the yahoo! games servers, before they shut them down last year. I had to decode the protocol and game state/play data on my own
I'm a professional programmer, but C novice. I use vim for all the things.
OpenBSD represent. I'm trying to gather reasons why some users choose BSD flavours over Linux, care to share your thoughts?
Maybe you could update your question and add the complete function code... There could be a bottleneck or an optimization issue after the `read` call... ...But we can't help you if we can't see the code.
I do my work coding in Ubuntu using Sublime Text Editor. If I'm going to work at home on my Windows machine, I use cygwin to ssh into my work terminal and use Sublime Text Editor with the SFTP plugin to remotely edit my work source files.
maybe u could dig into the source code. the authors did make it available, after all ...
Ubuntu and qt creator as IDE for c
I really enjoyed coding a web server with HTTP and Websocket support. I first did it as [a C web-services tool-box I called facil](http://facil.io), and later I used it in a Ruby C-extension for [the Ruby Iodine server](https://github.com/boazsegev/iodine) which servers Ruby but is written in C. I loved this C project for three reasons: 1. It's core is quite modular. The reactor has it's own little two file library (`libreact`) as well as the thread pool (`libasync`) and the socket abstraction layer (`libsock`). 2. It was a comeback to C after spending years in Ruby land. 3. Bridging the two languages (C and Ruby) for the server's advanced design (callback, concurrency etc') was a wonderful experience that sent me exploring esoteric subjects and taught me a lot. I also enjoyed writing a generic memory allocator (`malloc`). It was faster than the OS X allocator, but slower than the Linux one. I might use it one day, but I doubt it.
X86-32 under Linux. The vm86() system call doesn't seem to be supported on x86-x64. 
Arch Linux with Atom. I wanted to use emacs but having come from Windows Atom was much easier for me to pick up on
Arch with neovim
Only on linux since it is much easier and has a much nicer workflow than say Windows, which can be very messy especially for C/Python. CLI tools, terminal, programs giving proper stdout/stderr and using/updating clang/gcc is a non-issue thanks to proper package managers. 
I don't know which is the most "interessting". I wrote with a good friend a ANN which can recognize drawn numbers. I wrote some WM's, at the moment I also write a WM, most tiling and very minimal only for own use.
A little bit of both. The project I'm working on needs to run on a Linux machine, and needs to compile with gcc. I develop either on a Linux PC and gcc, on a Macbook in OSX with clang, or a Windows PC with Visual Studio (MSVC). The latter is unmatched anywhere in terms of debugging capabilities, but the compiler has some notable incompatibilities that you just have to know. It's possible to write code that compiles with MSVC, but not with gcc. To prevent that, we have a continuous integration server that builds every commit I make on clang and gcc, so anytime I screw up compatibility, I'm told pretty quickly. If you'd ask me what the main advantage is that I get from developing on Linux: I can ssh into the machine with my workspace from anywhere I am (I travel a lot) and I don't need to set up my development environment before I can make a code change. Other advantages: I can use valgrind and coverity. The git command line and bash are first-class citizens on the OS. There is a lot of tooling that I don't think I could get on other operating systems, valgrind probably being the most important. tl;dr: I can totally recommend having your code compile on more than one compiler or OS, to maximize the number of tools at your disposal.
Oh yeah, I forgot to mention that in my answer: Being able to just apt-get install libxml2-dev or whatever other library you want to include, versus having to compile it yourself on Windows, rocks! And you're correct that Microsoft's C99 support has been fairly okay since 2013, but C11 just isn't happening.
Slightly painful in the beginning assuming you're already using a Linux OS. However, by the time you're up and running and have configured and installed things to your liking, you will have a very good understanding of how your OS is out together and configured, which is a wonderful and powerful feeling. If you have the time to deal with the semi-frequent preventative measures you have to perform before doing certain updates, it's well worth your time. Their documentation is fantastic and the package selection/availability is excellent.
Because a) I wanted a real UNIX and b) I wanted to get rid of systemd.
GNU info is actually not so bad if you get a PDF render of the TeX source. Sadly, no distribution actually ships the TeX sources.
gcc *.c -o app.exe Literally all you need to get started.
It's actually quite easy if you know how to read and have a little patience. The Arch Wiki is an excellent source of documentation and you can find most stuff you'd want in there. You just have to be a bit more careful with Arch since it's a rolling-release distro (you always have the newest upstream software) and thus things break or slightly change over time (read the announcements). That sounds more horrible than it is though, it doesn't happen often and most of the time it's quickly fixed. You simply shouldn't update your system 5 minutes before you have to do a presentation and stuff like that. But you get a nice, simple distro that you can easily configure as you wish without the hassle of compiling everything yourself like you do on Gentoo (there's also the ABS on Arch that allows you to compile the packages yourself)! The AUR is also a good thing.
My coding environment is split between work and home. At work I use Windows exclusively. The DE I use is Visual Studio, which in my opinion is unmatched as a development environment on any platform. At home I use and code exclusively on Linux (Kubuntu is my flavour of choice). So far I am mostly coding in C# mono, but I also use perl quite a bit too. 
I've been using Linux exclusively for five years. I mostly use Vim for text editing, but I also use many of the awesome IDEs that are available, like CLion (paid), QTCreator (open source and free), and Atom (open source and free).
I'm on arch and I use vim for text editing, and the default gcc compiler for c/c++
I program where programming is a first class citizen.
In addition to what /u/net_goblin said, I prefer BSDs because I like the license more. I consider the difference between GPL and BSD is the difference between "Freedom from" and "Freedom to". With GPL you are free from your code being taken over, but only with BSD software are you truly free *to* do whatever you like with the software. Before you comment on why you disagree: I don't care. It's more important to me that software be usable by any entity than that every ship their improvements back.
I really wish they would port Visual Studio Code to FreeBSD. It's a unix environment that's not OSX that I can stomach on the desktop.
It was two separate C programs that were part of a larger project. First was an embedded system that applied a load to a battery and measured the resistance of said battery. Second program would take the data from the first program over a serial interface and do some statistical analysis on them as well as output the results to a text file.
I most definitely agree with BSD and MIT licensing over gpl, especially V3. Hence why I use OpenBSD. That being said I use it more so to avoid systemd nonsense. 
As long as you think of them as different languages, you'll be fine. That being said, there isn't a particular *benefit* to learning them both at the same time. While nearly everything you learn in C *can* be used in C++, it *shouldn't* be used in C++. For instance, in C, you can allocate a static array using something like `int array[20];` and you can do that in C++ too, but you shouldn't. In C++11 you would use `std::array&lt;int,20&gt; array;` instead. In C, you would allocate a dynamic array with `int *array = malloc(array_size*sizeof(int));`, and you can do that in C++ too, but you shouldn't. In C++, you'd use `std::vector&lt;int&gt; array;`. There's a ton of stuff like that.
C could be considered to be a subset of C++. That is to say all C code is compilable as C++, but if you use C++ features it's no longer compilable as C. I don't see any problems with what you're suggesting just so long as you keep in mind you're working in different environments
But why?
You can't implicitly cast from void * in C++. 
Mostly because the expectations in mature c++ expects those kinds of things. The reasons vary based on which thing, but they boil down to safety, predictability, "correctness", working with other libraries. etc. Maybe think of it like learning American English and British English. They're very similar, mostly compatible, but if you expect to use both you're better off learning them independently. Bad example, i know. 
C++11 adds most of C99 also.
I like to begin with [minunit](http://www.jera.com/techinfo/jtns/jtn002.html) and simply write tests. Make sure to do [equivalence partitioning](https://en.wikipedia.org/wiki/Equivalence_partitioning), just a fancy way saying to eliminate cases of redundant tests. You may grow out of minunit in which case you can graduate to [one of these 20 or so testing frameworks](https://en.wikipedia.org/wiki/List_of_unit_testing_frameworks#C). Also some form of dependency injection will help. Consider the case where you write a function that relies on randomness particularly libc rand(). You can write a wrapper implementation that supports multiple backends where one implementation is libc rand() and another could be your own supplied mock which can generate a constant, which will make your test results predictable. I'm a bit pressed for time, but if this doesn't make sense, I can probably write a quick code sample to illustrate.
Interesting! So C++11 capable compilers (msvc?) should be able to compile some C99 programs?
Yes msvc 2015 is finally capable of doing so for example.
&gt;That is to say all C code is compilable as C++ This is nitpicking a bit, but this isn't strictly true. For one example the auto keyword has a different meaning in both languages.
Look into research at your school/university. Lots of research uses C and it's a great resume builder. Source: am working with C and Fortran at a national lab currently doing physics research. 
As usual, any kind of global state is something to avoid. That includes static variables. For example, this made-up code is hard to test: int number_of_pylons(void) { static int num_pylons = -1; if (num_pylons&lt;0) { num_pylons = db_query_int("SELECT num_pylons FROM config"); } return num_pylons; } const char * warning(void) { if (number_of_pylons() &lt; 10) { return "you must construct additional pylons!"; } return NULL; } The unit test has no way to "reset" the static variable after the first call, and any change to the database will not be visible. Even if your program only ever needs to read configuration data once at startup, tests could exercise the function more than once: void test_pylons() { db_query("UPDATE config SET num_pylons=9"); assert_not_null(warning()); db_query("UPDATE config SET num_pylons=11"); assert_null(warning()); // fails :-( } As for libraries, I've used CuTest quite a bit, it's very basic, there's more boilerplate than some might like, but it gets the job done.
I don't know about that... I see a lot of business apps written in VB 6 and VB .NET
I'm in an intro to C course right now and I made this because I thought the course was going too slow and wanted a challenge so I don't really know what I'm doing. Thanks for the help.
Yeah I've done one of those basic implementations but I was thinking of making an encrypted chat client of some sort so I have a project I find more interesting. Idk if that's super complicated to make in C though! 😕
It would be difficult, as you'd most likely have to learn about: sockets, servers, threads, mutexes, and more. If you don't already have experience with those things, it would definitely be hard to pick them all up at once. 
I cold emailed quite a few and ended up getting emails back and even meetings with three. Of those three professors, one seemed to really take a liking to me. He told me he didn't have any room on his team but would keep an eye out. Later that semester (it was spring), one of his graduate students got accepted to a doctorate (maybe a post doctorate, I don't remember) elsewhere, so he offered me the position. Really the key is just to be persistent but let them know how passionate you are about the subject and how much you want to both learn and help out. They like to see passion 
&gt; The output of all my programs were full of errors. Can you show us a small demo program, describe the output you expect, and show the output you get instead?
Honestly that's not really that hard as long as you don't make it too complicated. All you really need to learn is networking in C (So, sockets) - but even then, you really (Like almost everybody else) only need to learn a small subset of it so that you can communicate between two processes. Once you open the network stream, you can `read()` and `write()` to it like everything else. The setup would be one server and multiple clients. The server holds a connection to every client, and then waits until a client sends it data. When the server receives some data, it send a copy of that data off to all the rest of the clients so they can see it. No threads or anything crazy, shouldn't be more then a few hundred lines and two separate programs (One for the client, one for the server). I'll add, this would be easier to write on a Unix machine then on a Windows machine, but the difference is not that large. The encryption is a bit of an issue, but that can always be added in later - it's just a matter of running the messages through an algorithm. You'd probably just want to use a library routine for it unless you actually want to learn about crypto algorithms. You'll have the problem of sharing the key, but that's something you could read and learn about.
Yes, I used that as a reference. This is more like a cheat sheet of bit manipulation.
Counting in binary creates all possible combinations of a set
You don't necessarily need threads to make a client of this sort.
I'll address things as I come across them. TokenizerT *tk; tk = malloc(sizeof(TokenizerT)); char *token = tk-&gt;token; char *current = tk-&gt;current; This is almost certainly wrong. You've just allocated `tk`, so it's members point to garbage. If you're lucky, this with `SIGSEGV` and crash before it causes further problems. printf("%c", &amp;output); You're attempting to print the address of the character as a character here. Likely not to go well. Also, according to the comment above, you're supposed to be printing each token on a separate line, and you're not doing that here.
While I don't think this is the best approach at learning, here's one way to do it: Note that I didn't bother correcting the overflow warnings that gcc gave me. Everything is the same but these lines: (Planet is now an int) printf("Which planet would you like to learn more about?\n", "Input 'x' to exit: "); while((planet = getchar()) != 'x' &amp;&amp; planet != EOF){ printf("\n"); switch(planet) { /* The same switch statement you used. */ /* Removed 'return 0 from the default clause. */ } printf("Another planet?: "); } printf("\n"); return 0; } /* main() */
With a few exceptions, I'm perfectly comfortable using C even for small things. I don't feel like it slows me down. The exceptions are problems involving lots of Unicode (beyond simple encoding/decoding), JSON, or XML. For example, Expat makes for ultra-efficient XML handling, but good god is it a pain to use. It's not that Expat is badly designed (it's very well designed), but the tradeoffs is entirely on the performance side.
I write all my tools in c instead of scripts because I have tons of libraries I made throughout the years to read/parse etc. or just ones available online. In the end result is what matter, not the tool. For me it's just good practice to not get rusty.
Usually, or c# if I want to use .net
First off, 4 spaces before every line for formatting. It's kinda ugly right now. Secondly, decimal to hex is merely a matter of representation. There's no 'converting' to be done. All you really need to do is use the `%x` specifier to print an integer as hex.
Speed is often the least important requirement for a large program, and is easier to address later. I just use C for embedded systems.
If you are on Linux, you might try using malloc_info to help troubleshoot. http://linux.die.net/man/3/malloc_info 
That's close to my answer, but I'd have done a comparison rather than an addition for the output out of sheer habit. I've spent too many years working with 8-bit MCUs and I still tend toward code that I know will yield the fewest instructions rather than what's most readable or maintainable. I have to work to break myself of that when it's not warranted. I remember coming across a program to do exactly this that my ex-roommate published on his website when he was learning C. Seemed very proud of himself. Only it was quite a bit more cumbersome than OP's code, and explicitly tested against each power of two and then subtracted it.
&gt; I don't feel like it slows me down. With all due respect, I question if that's because you're not familiar enough in the tools that are quicker for someone with an equal amount of proficiency in both.
That is the best explanation I have heard about pointers in a long time. 
Here is good explanation: http://www.thegeekstuff.com/2011/12/c-pointers-fundamentals
Using C is not primarily about speed. You need to get out of that “C is only useful when you need fast programs” mindsets. Personally, I write nearly all my little utilities in C. It's a nice language to try things out and most importantly, it's portable, so my utilities run everywhere.
Aka: Pass by reference Very useful. Look it up, OP
If it is a small programme, usually I will got with Python, awk or Bash.
A really great analogy.
Not really. I use Go or Python. 
No. No it doesn't. He's just proved it to you.
If you're only dealing with data in a single function, pointers are might be useless. When you start passing data between functions, especially large structures, pointers save time and memory at runtime. There are still uses for pointers inside a single function but I'll let you figure them out. 