*one of us*
It's written by the guy who literally created the language
http://aa-project.sourceforge.net/index.html
&gt;On your last point can you explain? I have taken courses in C but I have not sat down and read K&amp;R, what type of understanding am I missing? A couple of recent threads highlighting the last point: https://www.reddit.com/r/C_Programming/comments/7p9583/supposed_undefined_behaviour_in_lecture_handouts/ https://www.reddit.com/r/C_Programming/comments/7mj20p/is_beejs_guide_to_c_recommended_to_learn_from/ 
I have heard about this but , and sorry for saying this , but I need to use SDL to make my own program. Thanks !
Looks good, does it also have a dark theme?
Learn C the hard way is pretty high up there.. 
Yes as gedit or gnome builder, you can set to use the dark theme variant.
C How To Program -&gt; K&amp;R -&gt; the Go programming language
C# is off topic in this subreddit. Please ask C# questions in /r/csharp.
Do you even need to use SDL for this? It’s not like you have to display the image. You could just have it print the resulting ASCII to stdout.
Unfortunately i should be able to save it as a jpg or other image format. Plus i don't know of any other way of doing pixel manipulation with just C. 
Unix philosophy: split it into 2 different parts. One that outputs the ASCII art as text, and one that given some text it renders it to an image.
Unless OP went out of their way then it should use the desktop theme.
Yes I think you have the right idea. I would create a ranking of ascii char's 'brightness' (which you could calculate by the ratio of bright pixels in its bitmap or something). Then, reduce the resolution of the grayscale input image to something reasonable, and get a range of the brightness of the resulting image. Finally, segment the range by the same number as in your ascii brightness ranking list, and match up the 'pixels'. 
Will try to do that , cheers for the idea!
Thats the problem i have no idea how to segment the image with a given size , cause if i can split it it to the size of my mono sized font then ill be able to print mainly a 1 to 1 ASCII image. 
Oh man... I did this when I was learning C about 25 years ago and I think I remember how I did it. It was pretty much brute force. I started by drawing all of the characters on the screen with text drawing commands (this was in Borland's BGI graphics library) and then using the 'get pixel' command to count the pixels in each character block. Then it loaded the image on to the screen and used more 'get pixel' calls to sum the intensity of each character-sized block on the screen and found the closest intensity match from the table it generated in the first step. 
I know K&amp;R is the best , but I asked a specific question about what of the books , I referred above , is better ? Why do most of the guys here not answer the real question ? 
I'm still unclear on what you are trying to achieve. The input is an image. You want to output a JPG. So what is the relevance of ASCII? Take a step back. Fully explain what you are trying to achieve, *not* how you have decided to do it.
Did you put the `favlib` rule above the `install` rule? If so, it becomes the default rule, so `install` would not happen unless explicitly invoked. What if you put the `favlib` rule at the bottom and made it a dependency of the `install` rule?
So , sorry for the late response i had to sleep a few hours, I need to convert a image into ASCII art. 
Do not spam.
That is what AAlib _does_ though, yet you state you can't use it. I'm unclear on why. Could you make a clear and complete statement of your actual requirements please?
Thank you for your feedback! How could it be rewritten (redesigned) to avoid multiple return points?
&gt; Multiple return points in a function is bad form why? &gt; and variables should be initalised before first use. OP is doing this &gt; Assigning variables inside a condition statement is also bad form why? &gt; potential for undefined behaviour. how?
Because the assignment states that im only allowed to use sdl2. Thats the only requirement , C and SDL2 .
I would say that for a small function like this, multiple return points are okay, as it is very readable. Idk whether it impacts compiler optimization. It appears that all variables are assigned a value before being referenced. Is there a corner case that I'm overlooking? I'm less familiar with the numerous undefined behaviors in c. Is there undefined behavior in this code? Or maybe there is potential to introduce some in future edits? 
Just write return ((fd = fileno(fp)) == -1) ? fd : (((fstatus = fcntl(fd, F_GETFL, 0)) == -1) ? fstatus : (fstatus &amp; O_ACCMODE)); Much clearer obviously. In all seriousness, as others have said, multiple return points in a short function like this are likely fine, and clearer than trying to avoid them. The real alternative is to set a variable "retval" or something that holds your intended return value, and put the following code in an else clause. But I think that is harder to read. 
Multiple return points in a function is bad form - You make the function harder to understand C is a procedural language, start at the top, finish at the bottom. and variables should be initalised before first use. - He hasn't explicitly initalised them at the start of the function. He's just relying on them being assigned before being read. Assigning variables inside a condition statement is also bad form - It's harder to read and easier to misinterpret. potential for undefined behaviour. - in this istance he's used brackets, but if he didn't have brackets around the assignment he couldn't guarentee the function is called before the == is evaluated. 
&gt; sometimes returning a literal -1 would be faster and smaller than copying a variable to the return value I actually spent a little bit of time wondering if I could simplify/obfuscate the code a little more because the constant being returned was the same one that I had just done the comparison with, but gave up. &gt; using an intermediary variable and having the code iterate over all the other if clauses before finally returning the intermediate variable is also time &amp; memory consuming Agreed, although in this case the entirety of the rest of the code would be in two else bodies, so just an extra jump, no extra comparisons needed.
Something like this: int get_accmode(FILE *fp) { int fstatus = fileno(fp); if (-1 != fstatus) { fstatus = fcntl(fstatus, F_GETFL, 0); if (-1 != fstatus) { fstatus = fstatus &amp; O_ACCMODE; } } return fstatus; } I have a habit of writing the literal first in a condition statement because the compiler will error if you type = instead of == by mistake.
Thank you! Yeah, I kind of realized the design problem 10 mins after posting this and solved the thing writing two separate functions and documenting the fact in the api doc.
Ok , I need to create a C program using SDL2 that takes JPGs and converts it to ASCII art . It takes the intensity of each pixel and then replaces it with a ASCII character of the same/approximate intensity . Mainly , the program takes the values of pixels/areas of pixels and instead of displaying the pixel i output the character its replacing . I need to use SDL2 and C cause thats what my teacher gave me to do , I wish I would be able to use AAlib but i can't.
&gt; Only as a beginner, maybe I can't be bothered to argue any more; but you shouldn't assume the competence level of someone performing future maintenance, I can't understand arguments against writing code that's easier to read. Even as an experienced coder: a = f(); if(a == -1) is easier to read than: if((a = f()) == -1) 
In what form is the output required?
Thank you for your effort! Why you got rid of `fd` variable? Is there any particular reason for using only one variable?
&gt; Multiple return points in a function is bad form - You make the function harder to understand C is a procedural language, start at the top, finish at the bottom. Quite on the contrary, I believe that exiting functions as early as possible is extremely good style because it makes the control flow clearer than a cascade of nested if statements. &gt; and variables should be initalised before first use. - He hasn't explicitly initalised them at the start of the function. He's just relying on them being assigned before being read. Definitely no. If you initialise all your variables without having the initial value mean something you just hide errors. Compilers are very good at spotting accesses to uninitialised variables, if you initialise all your variables, you remove the compilers ability to warn you that you forgot to set the variable to the value it is supposed to have (as opposed to a dummy initial value). &gt; potential for undefined behaviour. - in this istance he's used brackets, but if he didn't have brackets around the assignment he couldn't guarentee the function is called before the == is evaluated. Parentheses do not change evaluation order. They are needed here for grouping because `==` has higher precedence than `=`.
&gt; What if you put the favlib rule at the bottom and made it a dependency of the install rule? Actually, could you be a bit more explicit what this should be? De-bugging has been...interesting
I prefer if (a = f(), a == -1) because this way of writing it conveys a connection between the function call and the result test, showing that they belong together and expressing clearly that error checking has been performed. Though, I don't do this very often as function calls tend to get long, making the if statement even harder to read.
Assuming no optimisation it just saves an int worth of RAM. Embedded habit...
Nothing I haven't written myself, (not counting the standard library, tho technically I have contributed to a couple of those too, so...).
&gt; potential for undefined behaviour. - in this istance he's used brackets, but if he didn't have brackets around the assignment he couldn't guarentee the function is called before the == is evaluated. That's not undefined behavior, that's unexpected behavior.
Don't rewrite it. Multiple returns are not a bad thing.
Got it! I guess `fstatus` should be renamed though: the call `fcntl(fstatus, F_GETFL, 0);` looks a bit weird to me. As already mentioned, this approach increases nested ifs and indentation levels, is that a concern for you? For me it is, since I like to stay inside the 80 columns and code without much "nesting" is more easy to follow (to me), thats why I tend to "exit early".
A JPG/other image format or just ASCII text if I wont be able to output a image.
I'm the author for [facil.io](http://facil.io). I'm currently completing a major rewrite (see the [reHTTP branch](https://github.com/boazsegev/facil.io/tree/reHTTP)). I know that some parts of the code (mainly the HTTP parser) require unaligned memory access (I'm working on fixing that), but it should work on all X86 chips and the newer ARM chips (ARM specifications v.6 and up). If you find the library lacking in features that you need, let me know. Some things, such as a router, were left out for now due to conflicting approaches (where different approaches are better for different implementations). I hope to find a good enough approach that will fit most use-cases. I personally took more time on supporting Websockets, native Pub/Sub and JSON than RESTful semantics, but I'm open to any suggestions.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [boazsegev/facil.io/.../**29e6a4d722709cd37670eb601c6c15066918b2cf** (reHTTP → 29e6a4d)](https://github.com/boazsegev/facil.io/tree/29e6a4d722709cd37670eb601c6c15066918b2cf) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dsts6vp.)
I thought that was C++ ... does it have C bindings?
Then compile with `-Werror=parentheses` :P
What would that option do where someone has put if((a = foo()) == -1) ?
There are [a few C bindings](https://github.com/google/protobuf/blob/master/docs/third_party.md), pick one you like.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [google/protobuf/.../**third_party.md** (master → 47b7d2c)](https://github.com/google/protobuf/blob/47b7d2c7cadf74ceec90fc5042232819cd0dd557/docs/third_party.md) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dstujlw.)
https://kore.io
&gt;Part of the reason I dropped fd was because I didn't understand the name. fstatus is fairly self explanatory name. fd isn't. `fileno()` returns a file descriptor (fd); `fcntl()` takes a file descriptor as first argument and in case of `F_GETFL` as second argument, returns the value of file status flags (fstatus). I took that name straight from my manual (`int fcntl(int fd, int cmd, ... /* arg */ );`), I thought it was pretty "idiomatic" in the unix-like environment, if I remember correctly, there is a function called `fdopen()`.
gee, thanks confuscius for those wise words. You have any knowledge of those libraries AT ALL ? 
Of course it can, it possible with almost all languages. The only problem with it is that it creates high complexity in the code, which make it hard to work and test your programs. Problems are getting hard to be detected, and although there are programs as checkmarx that helps with it, I try to avoid it as much as I can.
Assuming the compiler does register allocation, no storage is actually saved. However, the program is now significantly harder to understand. Don't program this way.
glib is nice.
In C, there is not a single general-purpose library that is as comprehensive and widely used as STL+Boost. You often need to use multiple libraries at the same time. Of the libraries you mentioned – glib is comprehensive, but the performance of its containers is generally subpar. tbox lacks English documentations. Don't use unless you are a Chinese. qlibc only supports string hash tables. Other container types seem weak, too. libmowgli doesn't have a hash table. klib was developed by me, so skip. apr is mostly used for a portable system interface. I don't work on Windows. Not sure how much that additional layer is justified. Another library that is worth mentioning is [stb](https://github.com/nothings/stb), developed by one of the best C programmers in my view. If you need a red-black tree, [FreeBSD tree.h](https://github.com/freebsd/freebsd/blob/master/sys/sys/tree.h) should be a nice choice. Again developed by a great programmer.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [freebsd/freebsd/.../**tree.h** (master → fae11c6)](https://github.com/freebsd/freebsd/blob/fae11c6a87317bb8e47be4bc5bfb1894af89304b/sys/sys/tree.h) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dsu52gu.)
Just browsing right now, but this lib looks great!
What exactly are you trying to do? Return an array of row names? strcat() won't help with that.
&gt; What exactly are you trying to do? It's a lot to get into...R/C interface gives me a headache. I basically just want to take this function: void query_row(char **input, char **dbfile, char **query) { db_row_set_t *row_set = get_query_rows(*input_file_name, *dbfile, *query); if (row_set != NULL) { for (size_t j = 0; j &lt; row_set-&gt;n_entries; ++j) { print_db_row(row_set-&gt;rows[j]); } } } and modify it as the comment above states, so as opposed to printing to STDOUT, we use `strcat()` to define and return a large char array. 
&gt; Explain, in clear, simple terms, what you want the function to return. What is in this array? So what is being said above (and let me know if this isn't clear) is that as opposed to printing each tab-delimited row "field" via `print_db_row()`, concatenating these together into one char array " row1name\trow2name\trow1name3\row4name". Then, as the commenter above states, "return the resulting char array into the corresponding element of result". (I'm interpreting her/his comments as well). The reason why `char**` is due to how R and C communicate with one another. &gt; Without knowing that, this fixation on strcat() screams XY problem. It might be suitable, it might not. Without a bigger picture... Who knows? The fixation is solely interpreting the comments above in the SO question, which gives the entire background of integrating C code with R (cf. http://adv-r.had.co.nz/C-interface.html)
(Plain) Text files do not contain font information. You need to change this setting in your editor.
I'm not going to claim this is the _bes_t way, but you could simply switch from using printf to fprintf and create a FILE* that's backed by a buffer in memory.... Some details here: https://stackoverflow.com/questions/539537/how-to-write-to-a-memory-buffer-with-a-file
That helps a lot. But what about multiple rows? Is everything going in one single string? Figure out how much space you need for it, malloc() that much, and, yup, strcat() away (Or keep track of the current end and use strcpy() instead). 
The thread title has nothing at all to do with the real problem (which seems to be: how to output to a memory buffer instead of to stdout).
&gt; But what about multiple rows? Is everything going in one single string? It's not the best solution, I know. &gt; strcat() away (Or keep track of the current end and use strcpy() instead). I don't understand. Could you be more concrete?
That's a fair comment; I accept that.
The problem with strcat() is that every time you call it it has to find the end of the destination string. So something like: for (int n = 0; n &lt; LEN; n += 1) { strcat(output, arr[n]); } looks like it's an O(**N**) loop at first glance but is actually O(**N**^2 ) (or something similar; I'm rusty). If you have a pointer to the current end of the destination string, you can just strcpy() to that, and advance the pointer to the new end, and repeat until done, instead of having to constantly look through an ever-growing string for the end. 
&gt; taller than it should be In addition to what u/dragon_wrangler said, monospaced are not always square; in fact it is common for the fonts to be taller than they are wide. You might need to include "square" in the keywords you search for.
Ok, that bugs me a little that out of nearly 1,000 lines of code, there's not a single comment. How do you work on a project of any size with no comments at all? Even if your code is readable and straightforward, it seems exceedingly tedious to have to stop and read the code to figure out where you are. On the topic of small text editors, [kilo.c](https://github.com/antirez/kilo/blob/master/kilo.c) is pretty neat. I've got my own modified version I'll have to post some day. Mine is further stripped down and rewritten to work without an operating system on a small embedded device, and does the rendering line-by-line to save memory.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [antirez/kilo/.../**kilo.c** (master → 62b099a)](https://github.com/antirez/kilo/blob/62b099af00b542bdb08471058d527af258a349cf/kilo.c) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dsurhjo.)
I will be adding comments in a future build. &gt;How do you work on a project of any size with no comments at all? By knowing what the code does. I'm not really sure how to answer this. I wrote the code so I sure as hell know what all of it does without comments. 
Libmicrohttpd
What everybody else said, but you can ~kinda~ do some Unicode tricks to change fontishness, since you care more about glyphs than characters here. For example, U+3000 and U+FF01 through U+FF5E are fullwidth variants of U+0020 and U+0021 through U+007E respectively, and ranges U+2100–214F (Letterlike Symbols) and U+1D400–1D7FF (Mathematical Alphanumerics) include a few font variants of letter and digit chars. But otherwise monospacing is entirely a function of the rendering layer, and without embedding the text-to-be-monospaced in something like RTF, an MS Word file, an HTML file, etc. etc. you aren’t going to be able to control much.
Well, I'm guessing you're either pretty young or just haven't spent a lot of years coding. I've written thousands of lines of code in the past year. Do I know what all of it does without reading comments? Yeah, if I stop and think about it. Will I remember what it does in a year, or three years, or ten years? I'll still be able to figure out what it does, but I'll have undoubtedly forgotten a lot of the *why* - right up until I try to 'fix' something and remember why it was done that way in the first place. Do yourself (and anyone who ever has to work with you) a favor and get in the habit of documenting as you go. Getting into a consistent style that's compatible with Doxygen or similar is helpful. Before you start a function declaration, write a sentence or two about what the function will do, what it returns, and maybe what uses it. Your coding style is kind of dense and blocky. Whether or not you put braces on a new line and how you organize your variable declarations is a personal preference, but it does impact the visual flow. With no comments, the dense style gets harder to pick through. You've also got a lot of 'magic numbers' in your code - constants entered directly with no description why symbolics would make the intent more obvious and would make modification simpler. If I was considering that code as part of a job applicant's portfolio, it's the lack of comments that would stand out the most to me. I can remember a time where I was proud that I could keep all of these projects in my head and didn't think I needed to leave any more obvious notes to myself. 25 years later, my code is much more sparse and averages about a line of comment for every two lines of code. It costs you very little extra effort at the time, and pays off hugely down the line if you do it right. At some point the idea of being the inscrutable coding badass becomes less appealing than actually getting the job done and making code that you can live with for another 5 or 10 years. Documenting and organizing your code is as much a part of the craft as writing the code itself. Code alone is never enough for a serious production environment.
First add a * to your return type. I haven't compiled or tested this and it's an ugly way to do it, but it will probably work. Add this in front of your for loop. result = (char**) malloc(row_set-&gt;n_entries); Add this in your for loop. int len = strlen(row_set-&gt;rows[j]-&gt;row1name); len += strlen(row_set-&gt;rows[j]-&gt;row2name); len += strlen(row_set-&gt;rows[j]-&gt;row3name); len += strlen(row_set-&gt;rows[j]-&gt;row4name); result[j] = (char*) malloc(len+1); strcpy(result[j], row_set-&gt;rows[j]-&gt;row1name); strcat(result[j], row_set-&gt;rows[j]-&gt;row2name); strcat(result[j], row_set-&gt;rows[j]-&gt;row3name); strcat(result[j], row_set-&gt;rows[j]-&gt;row4name); After you used the result, don't forget to loop free the strings and afterwards the char* array.
First add a * to your return type. I haven't compiled or tested this and it's an ugly way to do it, but it will probably work. Add this in front of your for loop. result = (char**) malloc(row_set-&gt;n_entries); Add this in your for loop. int len = strlen(row_set-&gt;rows[j]-&gt;row1name); len += strlen(row_set-&gt;rows[j]-&gt;row2name); len += strlen(row_set-&gt;rows[j]-&gt;row3name); len += strlen(row_set-&gt;rows[j]-&gt;row4name); result[j] = (char*) malloc(len+1); strcpy(result[j], row_set-&gt;rows[j]-&gt;row1name); strcat(result[j], row_set-&gt;rows[j]-&gt;row2name); strcat(result[j], row_set-&gt;rows[j]-&gt;row3name); strcat(result[j], row_set-&gt;rows[j]-&gt;row4name); After you used the result, don't forget to loop free the strings and afterwards the char* array.
First add a * to your return type. I haven't compiled or tested this and it's an ugly way to do it, but it will probably work. Add this in front of your for loop. result = (char**) malloc(row_set-&gt;n_entries); Add this in your for loop. int len = strlen(row_set-&gt;rows[j]-&gt;row1name); len += strlen(row_set-&gt;rows[j]-&gt;row2name); len += strlen(row_set-&gt;rows[j]-&gt;row3name); len += strlen(row_set-&gt;rows[j]-&gt;row4name); result[j] = (char*) malloc(len+1); strcpy(result[j], row_set-&gt;rows[j]-&gt;row1name); strcat(result[j], row_set-&gt;rows[j]-&gt;row2name); strcat(result[j], row_set-&gt;rows[j]-&gt;row3name); strcat(result[j], row_set-&gt;rows[j]-&gt;row4name); After you used the result, don't forget to loop free the strings and afterwards the char* array.
Don’t take this badly, but your code is already doomed: char buf[1000000] = {}; No assert. No comment. No todo. I suspect the code will crash on big files, but I am not even sure, I am not going to look in the rest to see if there can be an overflow. And why is buf initialized when it is overridden next line? No one knows. Then you have huge functions. This is a maintenance nightmare. Sometime it is ok to have long and simple functions, but yours aren’t. And nested ifs. A lot of nested ifs. This means bugs, probably. And god forbid adding a feature that would change that control flow. The style is inconsistent, you seem to be using pre or post increment/decrement without any style. Inconsistency is something you want to avoid. As the GP said, no comments. But it seems so fashionable those days to avoid commenting, that it is hard to complain — unfortunately. By properly commenting, you ask yourself *what* everything does, and it often lead to insight like ‘mmm, I’d rather refactor in something that is easy to document’, improving code quality. And, finally, absolutely no tests. This means that any change of the code can break anything else. Not saying everything has to be tested (well, it should, but it can be hard in a text editor), but the lowest-level function definitely should. So, on one hand, it is cool that you have completed something, and running code beats perfectly designed in existing code all the time, but on the other hand, the result should probably be completely rewritten.
I'm very good at programming, PM your stuff if you want help 
Good point! However I soon realized that the whole query for this type of information, so the problem this function solved, was a design mistake.
It’s *technically* correct. The best kind of correct! I’d call C++ a superset of C, and then - mathematically speaking - C would be a subset of C++. 
Shameful
Except that it's not - there are many examples of legal C code that will not compile in C++, so it's not a strict subset.
Then I stand technically corrected. Thank you. 
To extend /u/SantaCruzDad's answer, I [compiled a list](https://stackoverflow.com/a/31505447/417501) before.
Dude, I was watchinga video by some professor about Unicode, he got a LOT wrong, like that UTF-16 doesn't have surrogate pairs (he completely acted like they didn't even exist) and a bunch of other stuff, about UTF-8 being wrong too, like saying that there can be 5-6 code unit long UTF-8 strings, which is just not true, it's limited to 4 code units per code point, period. Both of these facts have been true for decades at this point.
`**` means array of array, the first asterisk is to select the string, the second is to select the char. In order to pass a single string out of an array of strings, you need to do something like `strcat(string[x]);` where X is the string in the array of strings you want to give it.
He must have confused UTF-16 with UCS-2. 
Yeah my Systems prof said the same thing in college. Most of my professors were very out of touch with the actual state of programming languages. 
Only while Unicode is clamped at 0x110000 codepoints. There's nothing in *UTF-8* that says four is the limit; Unicode ceilings at that value because of UTF-16. It's gaily extendable to six bytes long (0xFC lead) without changing anything in the UTF-8 specification itself. 0xFE and 0xFF are currently undefined, preventing seven or eight byte runs without a major specification advance.
You may be technically incorrect, but I would say the spirit of the idea is true. While there are some technical differences, you can logically think of C++ as a superset of C. If I was teaching a beginner I might myself present the idea as a generalisation, with exceptions.
**If I were**
Yeah I just edited that in lol I will freely admit that the main reason I like daydreaming about an unclamped UTF-8 is because I want a unifying encoding for any and all data composed of variable-length atoms, and UTF-8's mechanism almost works for numbers of any size (as it is already just encoding numbers; merely ones that have a non-numeric human meaning)
You should look into Exponential-Golomb coding aka RICE (well it's a variant, I forget how the family tree works out exactly) it's pretty cool, and UTF-8 uses it's own variant of it to say the size in bytes. Basically you just write X bits as a size field, a stop bit (which is the opposite of the value used for X, usually the stop bit is 0 but technically it can be either a zero or a one) then you write the actual value with X number of bits, it's a pretty cool little format.
Nah, I get what you're saying because of math rules but when people say "subset" in the real world, they are ususally refering to *proper subsets*. But as you said, you are correct.....technically,
Can the mods ban this commie fuckin bot
My boss and I were receiving some instruction from a contractor partner of Oracle for development in this ERP system. My college courses were done almost exclusively in C# but the programming for this system was in C. But as the instructor is going about walking us through their APIs and how to compile on Windows I ask him to what standard is this version of C so I can look up some reference material online. He says he doesn't know. I press him a bit and he says "its just generic C/C++." Even fresh out of college me knew that C and C++ are not Tomato Tomato. I can't get a legit answer out of the guy and I look at my boss out of sheer exasperation and he just shrugs and tells the guy to continue. 
This is mostly done by C++ programmers. Do they want to at least pretend they are using a good language by having a subset of one? Are they that envious of C? :p
Look. I wrote this in three days on my spare time. As I said before "I'll also be doing a clean up in the next build.". I'm aiming for less than 600 lines of code. And I will be rewriting the "huge functions" you are talking about.
Those that can, do. Those that can't teach ?
&gt; I've written thousands of lines of code in the past year. So have I. Pixt is a personal project I wrote in three days on my spare time. Thanks for the honest and critical feedback though.
There are, in fact, a number of things in C that have qualitatively different meaning in C++. For example, in C, `struct foo {};` must be referenced as `struct foo` unless it's `typedef`ed. In C++, the same `struct`, even without the typedef, is considered a complete type with the complete name `foo`. Also, `auto` has been deprecated in C++ since 2011, and is now a type deduction keyword. So while `auto i = 1.0f;` may declare `i` as an `int` in C, C++ will deduce `float`. [This page](http://david.tribble.com/text/cdiffs.htm#C++-vs-C) is old, but lists many of the differences that make a C program fail to compile or behave differently when compiled as C++. Wikipedia [lists more](https://en.wikipedia.org/wiki/Compatibility_of_C_and_C%2B%2B).
I'm trying to get into the industry while simultaneously avoiding C++ and Java. Let's just say... it isn't going well.
Which are usually C++ programmers. Most C programmers who say something about other languages, here C++, usually know enough about that language to judge correctly. As Torvalds said: It's a good thing Linux is not in C++, just to keep the C++ programmers out.
The video came out well after UCS-2 was history and UTF-16 was established tho. I think I read that it was published like 2-3 years ago.
Why did C++ deprecate auto? I thought that was like, one of the huge points c++ programmers talked about a lot.
bad professor
Literally me irl, and literally me irl. I just don't like OO. What are the benefits of putting the functions with the data they operate on? it just bloats both your compile time and run time size. You can do inheritance more or less in regular old C, you can do pretty much anything you can do in those languages in C, I mean C++ has a few nice features, like operator overloading, and implicit struct keyword mapping (not sure what to call it, where it knows the variable you're trying to set) is kinda cool, but it's not worth it to switch over to a whole other language for with all of it's bloat. IDK, I'm just tired of the circlejerk in the industry about how we all need to worship at the alter that is OO.
You may be missing the point here. Take a look at this chunk of code: typedef int auto; auto i = 1.0f; If you compile this as C, then `i` will be an `int` with value `1`. If you try to compile it as C++11, you will (should) get a compiler error. **Edit:** Oops, I was wrong. In C, `auto` is a storage class, like `static`. It is the default storage class, meaning that the variable's allocation and deconstruction should be handled via it's scope. Source: http://web.archive.org/web/20130927234242/http://itee.uq.edu.au/~comp2303/Leslie_C_ref/C/CONCEPT/storage_class.html#auto
I can only assume that a lot of professors have been teaching long enough to be out of touch with the field, or may have never been in the field very long at all to begin with. A number of the recent computer science grads I've interviewed or hired have had unusual misconceptions that seem to originate from opinionated professors.
I was under the impression that all C was valid C++. Is this not the case? Do compilers bother checking which language you're writing before starting?
It is, in fact, not quite the case. Compilers will not check which you are compiling before you start (although some like MSVC will try to infer based on file extension, but you can override this with flags). Incompatibilities between the languages will simply cause the build to fail. Most C code will compile as C++, but there are a handful of areas that cause issues. Specifically, C has a few features that C++ doesn't (such as variable-length arrays), C++ has a lot more keywords (class, private, protected, etc) that will cause a C++ compilation error if used as a name in C code, and a few keywords that don't mean the same thing in both languages (for example, auto is a storage class in C, and tells the compiler to infer a variable's type in C++). Other than a handful of corner cases such as these, C is a subset of C++.
Those aren't competing versions, they are just changes to the language over time. Anyway something like C11, as described at https://en.wikipedia.org/wiki/C11_(C_standard_revision), has minor additions, which may or may not be used in this code, but what does that matter? It's clear what "generic C" means, and trying to pretend you don't is just being pedantic. "OH BUT DOES THE CODE USE quick_exit OR NOT, I MUST KNOW RIGHT NOW!!!"
**C11 (C standard revision)** C11 (formerly C1X) is an informal name for ISO/IEC 9899:2011, the current standard for the C programming language. It replaces the previous C standard, informally known as C99. This new version mainly standardizes features that have already been supported by common contemporary compilers, and includes a detailed memory model to better support multiple threads of execution. Due to delayed availability of conforming C99 implementations, C11 makes certain features optional, to make it easier to comply with the core language standard. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Yes. Off the top of my head, c++ has different rules about implicit casting than C does, so for instance `int *x = malloc(sizeof(int));` will compile in C, but in C++ will give an error about assigning a `void*` to an `int*`. When you're writing c++ you typically invoke the compiler in c++ mode, like `g++` or `clang++`
 int class;
Not really. A lot of systems (especially of the embedded variety) only support up to ANSI C which comes from way back in the 80s. Asking which C standards are supported is a very valid question.
It's always a good idea to compile C code with a C++ compiler. The extra type checking is worth it alone.
Actually in the example I give, C++ is more prone to errors. By casting to (int *), you make it so that the compiler doesn’t give an error if malloc isn’t defined and the return type is int. 
Yup, and the extra benefit of the (int*) malloc() in C land really helps out during times of sleep deprivation. writing the mistaken char* bytes = (int*) malloc(sizeof(int) * 10); when an array of ints was wanted will give a nice error. Its like double entering a password when signing up for something.
Try compiling designated initializers as C++
What the hell is `linked_list`?
Bunch of subtle differences that are likely to screw you over. Simplest example: $ cat &gt; foo.c #include &lt;stdio.h&gt; int main() { printf("%d\n", (int)sizeof 'a'); return 0; } $ cc -o foo foo.c &amp;&amp; ./foo 4 $ c++ -o foo foo.c &amp;&amp; ./foo clang: warning: treating 'c' input as 'c++' when in C++ mode, this behavior is deprecated [-Wdeprecated] 1 $ Also, C++ standards don't have everything that C11 has.
It isn’t a problem of the text file, but a problem of the software you use to print the text file. You can use some software to turn you raw text file into something pixel precise (ie: a command line to generate a png image from text, or a pdf. Google would be your friend). Alternatively, you can output a formatted text document. The easiest way would be to output an html document, and put your text between &lt;pre&gt; tags.
“Tollerant” to errors, in the last graph. Should be “tolerant”, unless you want to be tolerant of tolllerant... 
On mobile here, so not complete: * maybe you want to start the scanf format string with a '` `' to ignore leading spaces in the input * You maybe want to calculate finAmt as initAmt - wdrlAmt - bankCharge (I don't know the assignment though) * You forgot the `\n` at the end of the printf statements. Misc.: I'd abbreviate withdrawal differently, at least I had to always check how it was written and it's meaning wasn't totally obvious to me at first.
Though only ANSI C is a subset of Objective C, C99 and C11 no longer are.
People like him is why we have CESU-8.
I would bet that they know the difference but phrased it poorly. But if they consider their self to be a teacher, they can't be sloppy about that. Some professors/departments don't really consider teaching to be part of the job description
Is this the only restriction you have? Consider using `strsep`, or `strcspn` instead.
&gt; widrlAmt%5==0 &amp;&amp; finAmt &gt; 0 &amp;&amp; 0&lt;widrlAmt&lt;2000 &amp;&amp; 0&lt;initAmt&lt;2000 This won't work - especially " 0&lt;widrlAmt&lt;2000 &amp;&amp; 0&lt;initAmt&lt;2000". "0 &lt; x &lt; 2000" should be "x &gt; 0 &amp;&amp; x &lt; 2000" By the way, with these code challenges, what they tell you in the input is not what you have to check for, it's the expected input. It's basically telling you that you won't have to handle cases where the balance is higher than 2000. [Here's a solution.](https://onlinegdb.com/HyALiDkBM) 
Or even just strchr() if you're only splitting on a single character. Basic idea: you have a pointer to your current position in the string. Find the next delimiter character. Set it to `'\0'`. Now you have a single element. Do stuff with it, and move your start-of-string pointer to one past that previous delimiter. Repeat until there are no more delimiters.
Write two helper functions: `next_word` that skips all whitespace until a non-whitespace char is found, or returns NULL if reached NUL. And `skip_word` that skips to the next whitespace char. Your loop becomes: for (int i = 0; (line = next_word(line));) { arguments[i++] = line; line = skip_word(line); if (*line) *line++ = '\0'; } 
How do I set it to '/0'?
Thank you raj this is what I had done previous https://gist.github.com/anonymous/4023cc31a2820a4aab6fe2466d66b77c
[This](https://www.reddit.com/r/EtherMining/comments/6hhvzz/anyone_have_any_idea_how_to_use_the_claymore_api/) will probably help you more than anyone on this sub will. The gist of this process will require you to POST to your miner, default port is 8800, with the request for miner stats and parse out the hashrate from the response. Then when that value falls below 200, send another POST with the proper request to restart the miner. Specifics on the requests can be found in API.txt, a file provided with your claymore install, but also [shared via pastebin](https://pastebin.com/A3nqiU7b) in the thread I linked above. All that being said, you don't need to use C for this. There's definitely value in learning how to use [libcurl](https://curl.haxx.se/libcurl/) for this (assuming your machine is remote), or opening/reading/writing a socket (assuming a local install), but there other languages that won't require as much background and will probably allow you to implement this more quickly than C. Good luck, have fun, hope this helped.
&gt; `for(int i = 0; i&lt; strlen(line); i++){` &gt; `i &lt; strlen(line)` Don't do that, it makes it have quadratic time complexity xD (for what should be linear time). Just check if `line[i] != '\0'`. &gt; `if(&amp;line[i] == " ")` Wow. That's not how string comparison works in C, that compares pointers. And why would you want to use string comparison for that? It's a single char. Use `line[i] == ' '` &gt; argcptr[j] = line[i]; Why are you storing the char at the beginning of the word in `argcptr` ? My understanding was that `*argcptr` will be set to the number of arguments found in the string. Because in C `argc` usually denotes the number of args `main` receives. Yeah you can avoid using helper functions, but it makes the code almost unreadable. That's why i suggested using functions: it's more elegant. If you want to do this without using other functions, i suggest you model it as a state machine.
Does this homework assignment require you to use a dynamically allocated array? Because if you have to do a lot of deletions at arbitrary indices you may do better to use a linked list. That being said, depending on the other requirements of the project a linked list may not be best, it's just my recommendation based on what little I know about what you're trying to do. The general process of deleting words at a given index will be: 1) receive index via input from the user 2) locate the entry at that index 3) remove the entry 4) adjust the list of words With a linked list steps 3 and 4 are basically one in the same. With an array step 4 requires you to rewrite significant portions of your array. Hope that helps.
1. This is not a C++ subreddit. It is C (and not C++). 2. Without looking at your code, it's probably your algorithms and data structure choices, rather than your choice of language causing your code to run too long.
Okay fine just convert it to C. It would help. Bruh, its the slow input Scanner class which is causing TLE and not the algorithm.
Somebody definitely can, but it won't be me. Firstly, because this is the C programming subreddit, not r/cpp_questions, and despite what a lot of people seem to think C and C++ are not the same. Secondly, you put [this link](https://pastebin.com/k8iF64sy) in the title of your post, which meant I had to copy and paste it into my browser to even look at your code. Finally, I have no idea what this code is trying to do. You haven't provided any indication of what your goal is. If I had to guess, the TLE error you're getting has more to do with your implementation than it does with the language you're using. I recommend refactoring your code and trying a method that is less brute force. Hope that helps.
Should go for all c++ keywords, right? int new; int delete; int public; Coming to think of it, some of those keywords are kind of likely to pop up in some headers you might use, so, probably not such a good idea after all...
 *pointer_to_current_position = '\0'
If you want to delete an element from an array and resize it, you have to allocate a new array of the desired size and loop through and copy the elements you want. Shout if you need further explanation. Like has been said by others, it's pretty redundant using dynamically allocated arrays with the use of magic numbers. 
This only happens when you don't include stdlib.h and when that happens, both gcc and clang will give a warning that malloc is not declared. Making sure your C programs are C++ compatible is a good practice when you write libraries, in particular macro-based libraries. Many think [stb.h](https://github.com/nothings/stb/blob/master/stb.h) is a wonderful library. It casts every malloc call.
Thanks for the reply. The title of the assignment is Dynamic Memory Allocation. So malloc and realloc isba must here. Basically my assignment is to take words from the user when a space seperates each word from another. Then i need to print the names in a list. And then i need to open a menu which gives the user 4 options. 1.delete a word by typing its index location on the list. 2.add a new word to the list in the location the user specified. 3.swap any 2 words the user chooses by typing thier index. 4.exit. They told us not to assume the length of the text and not to waste memory. Each string in the end needs to be fit exactly to a memory block fit to its size. 
A linked list will require you to use dynamic memory allocation anyway. Effectively, you're going to need to be able to perform arbitrary deletions, insertions, and swaps. Since that's pretty much all you need you should use a linked list, because these operations are some of the few examples in which a linked list is a better option than an array. The strings themselves should still be stored in character arrays, and in that instance you will need to use malloc as well in order to insure that you're not wasting memory. If you have any more questions or concerns I'm happy to help.
&gt; char* bytes = (int*) malloc(sizeof(int) * 10); You should have written the following. char* bytes = malloc(sizeof(*bytes) * 10);
Please put four blanks in front of every line of code so your code comes out readable. Right now it's a garbled mess. You can also use a paste service of choice to upload your code and link it here.
Put 4 spaces in front of every line to get Reddit to show the proper formatting, or use a code sharing site
https://codeshare.io/GAy6Yr
This is just my personal preference, and I expect some to disagree, but I don't use single line if statements. I always add the curly brakets.
Good to know. Do you know specifically where the differences are? There really should be a matrix somewhere.
- num_symbols is a constant that acts like a define, I'd prefer to see it in all uppercase. - `code_to_symbol` function declaration returns an int, but the types in symbol_list are of type `char`, which it returns - symbol_list can be const - you do a lot of `c = getchar()) != EOF &amp;&amp; c != '\n` and similar code. I'd prefer to see this factored out into some sort of `eat_whitespace` function or macro. This can help cut down on some of the visual clutter that comes from the `while` and `do ... while` loops - The variables `sym_read` and `sym_guessed` make me think that the values they hold are symbols, not an index and number of correct symbols guessed, respectively. These names could be better - A generic `get_valid_input(valid_inputs, error_sting)` would help a lot as well. Basically, it would loop until the user gave an input that was in `valid_inputs`, then return whatever the valid input was - `int secret[NUM_FIELDS];` can be in main - Not sure if you can change what C standard you're using, but I prefer &gt;= C99, so you can mix variable declarations and code. It's especially nice when working with nested scopes; declaring variables at the smallest scope possible helps prevent errors. - make your parameter names better. `n` -&gt; `num_fields` - in C, when you have a function that takes no parameters, be sure to add `void`, e.g. `int myfunction(void)`, rather than `int myfunction()`. The first means "a function that takes no parameters", the second means "a function that takes an unspecified number of parameters of unspecified types". Fun fact: this behavior is not the same in C++
Basically, everything added after C89 is bot available in Objective C.
I recommend changing the spelling of 'Congratualtions' ;) Other people have made great suggestions. Something I do that makes my code more readable is to break up conditions for if() statements into multiple lines with indentation **when the conditions are long-ish**, so for instance: Instead of if ( callthis_function(par1, par2, par3) == TRUE &amp;&amp; (structure.variable == X || otherstructure.variable == Y) ) I'll write if ( callthis_function(par1, par2, par3) &amp;&amp; ( structure.variable == X || otherstructure.variable == Y) ) { } Your expressions aren't that long, so meh. But personally I would break something like while ((c=getchar()) != EOF &amp;&amp; c !='\n' &amp;&amp; isspace(c)) up that way. while ( (c = getchar()) != EOF &amp;&amp; c != 'n' &amp;&amp; isspace(c) ) Vertical space is cheap and I like using it. I know some people like short, compact code, I'm not one of them. 
I don't see any reason to cast, because C and C++ are different languages. You should never use `malloc` in C++ except in very narrow contexts (to explicitly avoid calling constructors or destructors), and should almost always use `new` instead. C's implicit casts allow more expressive code, at the cost of type safety. C++ allows templates and has `new`, which couples both memory allocation (`void* operator ew(size_t)`) and object construction (object construction). You should not mix the two, since this may easily lead to dangerous code. C is not C++, and you should compile C code with C compilers, and C++ with C++ compilers. Writing C compatible with C++ is great for headers, but not source files. Use C-specific features, and modern C (C99/C11) to your advantage.
&gt; The most compelling and often quoted reason is that not including stdlib.h would result in a segmentation fault on 64-bit systems. That's not the most compelling reason cited: &gt; * It is unnecessary, as void * is automatically and safely promoted to any other pointer type in this case. &gt; * It adds clutter to the code, casts are not very easy to read (especially if the pointer type is long). &gt; * It makes you repeat yourself, which is generally bad. &gt; * It can hide an error if you forgot to include &lt;stdlib.h&gt;. This can cause crashes (or, worse, not cause a crash until way later in some totally different part of the code). Consider what happens if pointers and integers are differently sized; then you're hiding a warning by casting and might lose bits of your returned address. Note: as of C11 implicit functions are gone from C, and this point is no longer relevant since there's no automatic assumption that undeclared functions return int. The three first are absolutely relevant, and "being compatible with C++" is not a good reason to throw them out the window in my opinion. I'm writing C, not C++, they are different languages.
Pop quiz. Which of the following is correct, i.e. correct code and also allocates the right amount of memory that the programmer intended, and produces no errors or warnings when compiling in C99 mode with maximal warning level unless otherwise noted: 1. `a = (char **)malloc(7 * sizeof(char));` 2. `b = malloc(2 * sizeof(int));` 3. `c = malloc(sizeof *c);` 4. `d = (int *)malloc(sizeof(int));` 5. `e = malloc( 5 * sizeof *e );` 6. `f = malloc(sizeof(double));` Answer key and posted in reply to this (not sure if this sub supports spoilers?) I agree that people on the internet are overly dogmatic about this topic. Addressing your specific concerns: &gt;When you don't include stdlib.h, both gcc and clang will by default warn you malloc() is not declared Those are not the only two compilers in the world. &gt;Primarily for portability. This is critical when you call malloc in headers used by C++ programs, There is no such thing as portability between languages. Your C program won't work if run by a Python interpreter, should I criticize it for not being "portable to Python" ? The word "portability" means that the same code , or perhaps code with slight modifications, will work on *different systems* using the *same language*. Further, having executable code in header files is widely considered poor practice in C. &gt;This is critical when you call malloc in headers used by C++ programs This will lead to undefined behaviour in C++; it "working" depends on compiler specific behaviour not guaranteed by any standard. You must use `new` in C++ to create objects of dynamic storage duraiton. Supposing that all the conditions in the checklist are met: * You're writing a header that will be used from both C and C++ programs * Your header has macros that call malloc * You don't care about people not using recent versions of gcc or clang then you could cast malloc in those headers. However it does not follow from this that you should cast malloc in other situations in C. &gt;, though not to my flavor as it increases the chance of `p=malloc(sizeof p)` typo This argument is worthless in light of the fact that `p = (int **)malloc(sizeof(int))` typo is equally possible. 
Answers: * 1 is wrong. * 3, 4, 5 are correct. * 2, 6 have insufficient information. If you actually did the quiz then you will realize the main point of this whole topic: **minimizing the chance of runtime errors**. With the pattern `p = malloc(N * sizeof *p);`, you can read just that line and know that if it compiles correctly then it must be correct. No other pattern has that property. With the pattern `p = (T *)malloc(sizeof(T));` , *and you are using a C99 compliant compiler*, you know that if it compiles correctly it must be correct. Non-compliant compilers may or may not warn about failure to include stdlib.h. With the pattern `p = malloc(sizeof(T));` you are protected against failure to include stdlib.h, but you are not protected against typoes. IMO it's pretty clear that this last pattern is the worst of the 3 options because you cannot check it for correctness as easily as the others. I suspect you avoid `p = malloc(sizeof *p);` simply because you don't find it aesthetic.
I work at a company that is very strict about what applications you can have installed at your workstation, and does not allow compilers of any kind. I am also taking CS classes at a local university. The online C compilers allow me to do simple programming exercises while I have downtime at work. So they are useful in certain cases.
&gt; I'm writing C, not C++, they are different languages. However it is somewhat common to write libraries that are intended to be usable by programs of both languages, with the code in the header being in the so-called "common subset".
Just put the second do while loop in a function and then call that function in place of the original do while loop.
Sure. I just wanted to be brief and to the point. I think using those keywords is an excellent way to troll C++ programmers :D
Casting the return from malloc is always wrong. This is a debate that flares up once in a while and always lands overwhelmingly on the side of casting being not just unnecessary, but actually wrong. Visit the question on stackoverflow if you want to see a large summary of the arguments. The only alleged advantage of it is that it allows you to shove your code through a compiler for a different language. Doing so is at least irresponsible if not outright dangerous and most likely just lazy since no reasonable build systems should have problems compiling certain files with a C compiler and others with a C++ compiler and then linking them together. There are no technical advantages to doing it, a few minor technical disadvantages and lots of aesthetic disadvantages (in my opinion casts are the tool of last resort, code that contains casual casts shows lack of control over the code or bad type choices and it is a major code smell).
&gt; With the pattern `p = malloc(sizeof(T));` you are protected against failure to include stdlib.h, but you are not protected against typoes. You can try to compile the following with gcc: void main() { int *x=malloc(sizeof(int)); } You only see warnings but not errors because int is implicitly converted to pointer (right?). Missing stdlib.h will cause the same bug regardless of casting. Whether you see warnings depends on the compiler you use. &gt; [Calling malloc in c++?] will lead to undefined behaviour in C++; it "working" depends on compiler specific behaviour not guaranteed by any standard. You must use new in C++ to create objects of dynamic storage duration. Reference? malloc is just an ordinary library function. What can lead to undefined behavior in c++? Yes, malloc() does not trigger constructors, but we don't expect that in the first place.
&gt; Casting the return from malloc is always wrong. You need to explain what actually goes wrong. The top voted answer in that SO thread is biased and flawed. The first three bullets are really one: you type more. This is won't make programs error prone. The last one, missing stdlib.h, may lead to errors, but leaving out cast has the same issue – in C, it is ok to implicitly convert int to pointer. I am not saying casting is universally better. I am saying casting is not worse than no casting. At the very least, it is not "wrong".
I should point out that one of your most compelling reasons to cast `malloc` is caused by very bad code... **The following code is a mistake(!)** (which often hunts me when I need to refactor someone else stuff): widget *p; // then you write lots of other code here p = malloc(sizeof(gadget)); You **should** really write (the **DRY** version): widget *p; // then you write lots of other code here p = malloc(sizeof(*p)); Which is also why we **don't** cast the `malloc` - it allows us to safely refactor code without repeating ourselves in ways that might cause bugs that are hard to spot (don't repeat the type in the `sizeof`, don't repeat the type in the `malloc` cast, keep your code DRY!). The **Only** reason to cast malloc is in header files for C++ compatibility... which sometimes uses the famous: #if defined(__cplusplus) // ... #endif Having said that, **yes**, I cast `malloc` in header files that use `inline` functions that need to be C++ compatible. This is the **exception**, not the norm, because **[code should be DRY](https://code.tutsplus.com/tutorials/3-key-software-principles-you-must-understand--net-25161)**.
Yes, but then I use #ifdef __cplusplus extern "C" { #endif
&gt;You only see warnings but not errors because int is implicitly converted to pointer (right?). There is no implicit conversion from int to pointer in Standard C. However common compilers provide such a conversion, and even do it without warning in some cases depend on compiler switches. I'm not sure what you mean by "Missing stdlib.h will cause the same bug " . If you don't miss stdlib.h then there is not a bug. &gt;What can lead to undefined behavior in c++? [See here](https://stackoverflow.com/questions/40873520/reinterpret-cast-creating-a-trivially-default-constructible-object). `malloc` doesn't create objects in C++, it only acquires storage with no objects in it. 
That doesn't really have anything to do with the issue of casting malloc inside such a header
`extern "C"` doesn't mean "compile as C". If using a C++ compiler than all the code is "compiled as C++" regardless of that.
&gt; I'm not sure what you mean by "Missing stdlib.h will cause the same bug" . If you don't miss stdlib.h then there is not a bug. You said "With the pattern `p = malloc(sizeof(T));` you are protected against failure to include stdlib.h", which is wrong if compilers do implicit int-to-pointer conversions. `p=malloc(sizeof(T))` is no better than `p=(T*)malloc(sizeof(T))`. &gt; malloc doesn't create objects in C++, it only acquires storage with no objects in it. This is exactly what I mean by "malloc() does not trigger constructors", but reading uninitialized malloc() memory is a bug in C, too. It is perfectly fine to use malloc in C++, as long as you know what you are doing.
I wouldn't say you should avoid malloc in C++. For basic applications there is no need but if you want to do proper memory management you will find malloc to be very handy and then use the new (ptr) operator afterwards.
&gt; Note: as of C11 implicit functions are gone from C They were gone from C in C99.
Another possible reason is that malloc() et al are library functions. You can override them with `LD_PRELOAD=libfoo.so ./bar`. Sometimes this leads to significant performance boost when the program calls malloc frequently from multiple threads. I don't know if there is something similar in C++ and I don't know how often C++ programers use non-default allocators, either. Just sayin.
"You should never use malloc in C++ except in very narrow contexts (to explicitly avoid calling constructors or destructors)...". Malloc serves a very narrow purpose, and that purpose is when you are explicitly decoupling memory allocation from object construction.
&gt; which is wrong if compilers do implicit int-to-pointer conversions. I stipulated that the compiler was invoked in C99 standard mode (which does not have that implicit conversion). Not much can be done about compilers ignoring the standard. &gt;This is exactly what I mean by "malloc() does not trigger constructors", but reading uninitialized malloc() memory is a bug in C, too. It is perfectly fine to use malloc in C++, as long as you know what you are doing. To be clear, this is UB in C++: #include &lt;stdlib.h&gt; int main() { int *p = (int *)malloc(sizeof(int)); *p = 5; // undefined behaviour here - the left-hand side of `=` must designate an object that already exists } If you doubt that this is UB or want to argue about it, don't bother replying -- it's already covered in depth on the question I linked to, I'm not interested in re-hashing the same argument 
You are probably very bad to program because program webapps is easy lol
You don't need to reply any more. I have read all comments in that thread. To anyone who has read to here: this is just a wording game in the C++ standard. The above is a correct C/C++ program. &gt; in C99 standard mode (which does not have that implicit conversion) `gcc -g -std=c99 -pedantic` compiles void main() { int *p=malloc(sizeof(int)); } without errors.
That should genuinely be the "youtube for programmers"-slogan. In my days, when men where still men, and a byte was still just 7-bits; if you were to altavista "how to C" you would be referred to a meticulous well aligned ascii document that began by describing how atoms are formed in a super nova, and continued from there. Pure brilliance. "Good gél", or whatever kids call it these days, the same term and you are presented by an uneducated mildly retarded child, always with an aggressive cold, spelling out his name in notepad at half a character per second. As a video. Rololol bilbo swaggins yolo 420 get reeeekktttt or gtfo or horse on a head fu lol.
All versions of gcc I tried produce a diagnostic message for your code. Maybe you are trying to be smarmy about the fact that the error message says "warning" in it. If you go back to the top of this chain you will see that I wrote "produces no errors or warnings" 
I think there’s a difference between “allowed” and “correct”. The fact that the standard allows it does not make it correct code. Coding guidelines and principals still apply. Re-specifying the type makes the code rigid and eventually fragile. It’s allowed for good reasons which are edge case related, but it isn’t correct code by any measure. 
In my comments I use "correct" to mean "complies with the standard". 
There is a technical advantage to `p = (T *)malloc(sizeof(T))` when compared to `p = malloc(sizeof(T))`. Namely that you can visually spot some mistakes which would silently cause the wrong mount of memory to be allocated. 
Try https://github.com/sdelrio/claymore-exporter
`p = malloc(sizeof *p);`
If you’ve got a `typeof` operator, you can do something like #define make_new(expr)((__typeof__(expr) *)malloc(sizeof(expr))) to maintain DRY and include the cast for type-checking.
I was talking about comparing the two patterns `p = (T *)malloc(sizeof(T))` and `p = malloc(sizeof(T))`. It is quite common on stackoverflow , reddit, and other programming forums for people to "correct" the first by recommending the second.
You could argue that `new char[]` could be used instead.
I agree it’s not pure-as-the-driven-snow C, but most of the compilers I ever have to deal with are GNU or GNUish, and if you’re in C++≥11 you have `decltype` which would work the same way in this specific case, so …(shrug). Although using `typeof` actually lets you do both S *foo = make_new(S); and T *bar = make_new(*bar); whereas a `decltype` version should break on the first one IIRC. For `malloc`ated arrays I actually think using the compiler’s type system is better as long as the array size is static—almost nobody ever checks for overflow on that multiply, and it’s the sort of bug that would easily go unnoticed, whereas the compiler should complain if you exceed `SIZE_MAX` in an array type. Idunno, this probably shouldn’t show up in super-portable or production code, but for fiddling-around code it’s good enough. For something like kernel-mode source code where you’ve got a closed ecosystem and probably a specific handful of compilers you’re targeting, I can see it being useful.
I'm sorry if I came out a bit harsh. I actually liked the approach to keeping things DRY. I just wouldn't use it except for the edge cases where header compatibility involved handling `malloc` for some reason. As for a compiler array type, I'm not sure what you mean. If you're referencing an array on the stack (an actual C array), than yes, I agree... but sometimes they expose stack overflow risks when the sizes are dynamic. Also, consider [a single header HashMap library](https://github.com/boazsegev/facil.io/blob/e4a94cc4a9ad8261a0b1fa7739546b7f42ccd7a8/lib/facil/core/types/fiobj/fio_hashmap.h) (though C++ has it's own types, sometimes the STL is avoided for compatibility with an external API). In this case, an "array" will be dynamically allocated and overflow risk management would be required.
&gt;Look. I wrote this in three days on my spare time. As I said before "I'll also be doing a clean up in the next build." I think it's safe to say that most of us here - probably a very large majority - started coding as a hobby. We've all been there, and we've all written plenty of 'throw away' code that we never expected to look at or work on again. The feedback you're getting here is all stuff you should take to heart if you're going to be serious about programming, even though you might feel it's unfair for a project of this scope. Going back through a project and adding documentation is fine, and in fact you should do that from time to time to make sure everything is up to date, but you should be writing your initial comments continuously as you go. It helps clarify your thoughts (in the style of 'rubber ducky debugging' I've caught stupid mistakes just by having to stop and write out in English what I'm doing) and it needs to be part of your normal work flow. Writing [dumb code](https://hackernoon.com/why-senior-devs-write-dumb-code-and-how-to-spot-a-junior-from-a-mile-away-27fa263b101a) doesn't seem sexy and it slows down your marathon hacking sessions, but these are habits you want to develop early. Getting your code under a certain number of lines should *not* be a goal unless you're writing it for some kind of [competition](https://www.ioccc.org/). Optimizing for object code size can be a valid goal - I'm an embedded developer and the very largest devices I work with have 1 MB of flash and 128 KB of RAM - but your source code should be optimized for readability, modularity, reusability, and resistance to errors. The code I write now is quite a bit less visually dense than what I was writing 20 years ago, or even 10. For &gt; 90% of my code, I'm the only person who will ever read or modify it, and I own the company - I'm not doing things that way for the sake of meeting some arbitrary company standard or because my coworkers will murder me for writing awful code. I'm basically the epitome of the self-taught cowboy coder, or at least that's how I started out, so understand that this isn't coming from some ivory tower CS academic. It's all from long and painful personal experience. Doing this stuff right takes longer up front, but it'll save time in the long run. As for stylistic details, read a few coding style guides. Doesn't really matter whose - my own coding standards are based largely on the Barr Group's embedded C standards - what matters is that you take the time to read them and understand *why* each rule was set. You can break rules, but know what rules you're breaking and why. Scan through that kilo.c code when you have time. It's a useful comparison here because it does essentially the same thing as your code and in a similar size. You can jump to almost any point in that program and from just what's on your screen at the time figure out where you are and what it's doing. I picked a random spot in your code and ended up around line 767. I figured out what this chunk of code does, but it took me a bit to process it, and a single comment like "convert every four spaces to a tab" would have made it far more obvious. You can also refactor that so you've got a function that converts spaces to tabs and then it'll be more clear, reusable, and you can write tests for it to show that it works right. Going back up a bit, you've got "if(savePrompt &amp;&amp; enteredChar == 10) {...". If you used '\n' instead of 10 it would *do* the same thing, but your *intent* would be more clear - comparing it to a character constant reminds you that it's a character value (and not a count or something) and makes it obvious to those who don't remember their ASCII codes that it's a newline you're looking for. Like the article linked above says, anyone can write code that a computer can understand, but the trick is writing code that a human can understand. Always use the representation that most accurately captures what it is you're trying to do. If you got a text editor working in three days of tinkering, that's great - you've clearly got the interest and enthusiasm. Now you need to develop some discipline and workmanship, because just cranking out working code is just the start.
Thank you so much for this feedback! I’ll take it to heart. I think I’ll read up a bit more on coding practice and standards and then rewrite the text editor. I do want to become a better and more disciplined programmer. Thanks again!
Hmmmmm..... $ grep -rw new linux_kernel_download/ I would not be surprised to find a few there...
So you are arguing that one should always use this pattern because it's useful in the rather rare edge case that you are writing a C header with inline functions that use malloc that is likely to be used in C++ programs? Why not... just use this pattern in that exact case and then canonic p = malloc( sizeof (*p)); elsewhere?
This is ignorant to "sum up" the thread and state your -- debatable -- conclusion as a fact. Fun fact: Interpreting anything that's a standard, a law or similar is very much *a wording game*. Although I would agree that mentioned code is not UB but it *could easily lead to UB*. The thing is, if you allocate memory for an object but do not construct it, the object might be in an unspecified state, this is especially true for classes but I'm not sure about integral types like `int *`. Whatever the case, the allocation is definitely not UB. What's definitely UB is to do something with that object that uses something of a state, especially trying to deconstruct it or other things. But as also mentioned, apparently the assignment operator does only work for... objects, which does mean the behavior of the assignment is indeed UB. It's very much likely to work in the `int *p` case but likely to blow up lateron or in a more complex example which makes using malloc in C++ at least an anti-pattern because it's behavior is contrary to anything you'd assume in C++.
Use `WIFSIGNALED(status)`. See https://linux.die.net/man/2/waitpid
Nice ! But it gives me an integer and when I parsed it with `strsignal()` I've "HANGUP" but I need the full error : "segmentation fault (core dumped)". Is my job to print this full error message ?
Put four spaces in front of the line so your code is posted correctly. In general, array indexing and matrix indexing are pretty straight forward.
That is pointer arithmetic. Basically, if say, you have an array int arr[n] then arr will be the *memory location* of the first array element. Then, arr + 1 will be the second, arr + 2 the third etc. For a 2D array like int arr[m][n] the element row, col will be arr + row*m + col. For example, arr[2][5] == *(arr + 2*m + 5) For pointers, you use the * (star) operator to *dereference* it, meaning you get the value of the memory location stored in the pointer.
The blog post I mentioned defines: #define MALLOC(type) ((type*)malloc(sizeof(type))) It will only work with `MALLOC(int)`, not `MALLOC(*p)`, but this is good enough in practice and uses the standard C only. We can extend the definition to #define MALLOC(type, len) ((type*)malloc(sizeof(type)*(len)))) int *x = MALLOC(int, 1); and define CALLOC/REALLOC the similar way. I see this is the better approach overall. It is clean, is c++ compatible, imposes type checking and minimizes the possibility of any typos. The downside is you need to define extra macros. &gt; I much prefer to code in C when I code in C. I only code in C, but those use my code are not. They have done various non-standard things but for good reasons on their side. For example, they include my macro libraries in C++, copy my .c files and compile as c++, and copy-paste c functions to their c++ files. Simply adding a cast makes all these work and has almost no side effects. Why not? I don't like C++ overall but I like to work with C++ programmers.
What error message? 
No, you format that yourself, for example with `strsignal`.
this one : "segmentation fault (core dumped)" or this one "floating point exception (core dumped)"
You'd have to print something like that out, yes.
&gt; I would agree that mentioned code is not UB This is all I wanted to say about that code snip and you confirmed it.
But this is *my* interpretation with a significant lack of knowledge and some other quotes of the *standard* say otherwise, so I'm not sure *at all*. So no, no confirmation for you, please do read the statement in the context of the whole post.
I forgot to mention that your example code does not correctly handle failure of `fork` or `execve`.
Pointer arithmetic and array access are related: arr[i] === *(arr + i) &amp;arr[i] === arr + i
error output now in OP.
*facepalm* I need more coffee.
I use my own library for generic data structures: https://github.com/MichaelJWelsh/cdsa 
K&amp;R's not even 300 pages.
&gt;This basically means that most C++ code is triggering UB Well, my code isn't. You'd have some work to do to argue that "most" is. Many people take the view that the standard is defective and the code in question should be well-defined; but no proposal to fix it has been accepted yet. A proposal has been made: http://wg21.link/p0593r1 
&gt; the compiler must issue a diagnostic message if p = malloc(X) occurs without malloc having been declared. Only if you are using a c99-compliant compiler as you said previously. C99 compilers also issue warnings for `p=(int*)malloc(X)` if stdlib.h is missing. Then what makes non-casting better? You haven't explained.
I'll consider this. I'm taking the other commentor's suggestion of the cryptography challenges, because crypto and security are interesting to me and are actually fields I wouldn't mind making a career in. Maybe when I'm more skilled I could have greater contribution.
&gt; when you are explicitly decoupling memory allocation from object construction. What's the problem domain where you have seen this? Thanks in advance. 
No, C89 compilers must also issue a diagnostic. 
Also a good point. Except when you need `realloc`. Which, again, is rare.
A specific use-case could be relocatable types. You need to relocate types which have constructors and destructors, do not store pointers to internal buffers (like, Facebook's Folly implementation), and do not contain virtual methods (since virtual implementations are strictly undefined), and therefore need to move a type from one buffer to another. The cheapest way is to avoid calling a destructor, and use `memcpy`, from raw bytes to raw bytes, ensure the destructors for objects in the old buffer are never called, and ensure the destructors for objects in the new buffer are called. This can have very notable performance benefits, so it should not be dismissed out-of-hand. There are rare cases where it makes complete and total sense to decouple allocation and object instantiation, but those tend to be very rare and also tend to be easily isolated into re-usable containers or types.
I mentioned C89 in response to your introduction of C89. The diagnostic required in C89 is assignment of integer to pointer without a cast.
You first mentioned c89 to argue no-casting is more likely to trigger warnings, not me. What is the exact section where an int-to-pointer warning is "required"? I was only searching words "warn" and "convert/conversion" in the c89 spec. I may have missed it. Honestly, this is the first time I carefully looked into the C spec.
If you already know python and java, I would supplement what you learn from a book with something like [Project Euler](https://projecteuler.net). There really is no proper substitute for a good C programming book.
I will be checking out that repo hopefully asap. If it's not too far over my head, and it doesn't get buried under my other TO-DOs, I'd be happy to contribute.
I'd like that, but even GNU ls is 5305 lines of code. Not sure what simple program is actually simple.
That's because of the many options for example -R. Don't implement options other than -l.
I'm wondering, if I want to use this, do I put the .h file in my include folder, .c in src and compile with my project or compile this independently and link it? What would be better and why?
Project Euler was crucial to my learning of C
I only glimpses over but some changes I'd recommend: * use `(void)` instead of an empty parameter list, because otherwise your functions take an unspecified number of parameters in case of a lone declaration or, in any case at least don't have a prototype. This way you could call any of those functions with parameters and not get compile time errors in virtually all cases. * Use compound initializers for stack allocated structs, just looks nicer * Make compilation-unit-local functions static, I'd say it's good practice in general despite not needed here. * In the Makefile use other automatic variables more extensively (`$@`, `$&lt;`, `$^`, ...).
Really? I think Project Euler is awful for learning programming, it's just solving math problems. You could write the shittiest code and solve PE problems, and you learn nothing when it comes to C. Also C doesn't have builtin arbitrary precision arithmetic, so it just makes things needlessly harder. Python would be a better pick. 
It’s funny how you don’t realize that learning the constraints of C is crucial to learning it. 
The Makefile is needlessly complicated anyway CFLAGS := -Wall -Werror -pedantic -std=c99 kilo: is enough. Or even CFLAGS := -Wall -Werror -pedantic -std=c99 if you can be bothered with running `make kilo` to compile instead of `make`...
One could argue about the one source file to make it more simple as a tutorial and for beginners to follow, but that's open for discussion so I didn't mention it, albeit I agree with you on that.
Using the wrong tool for the job doesn't make one better with it.
whatever...
If the “job” is solving short but complex math problems, I think C is fine for the job. I disagree with that statement in general anyway. 
You can do either process you just described. As for which one is better, they will both end up doing the same thing. The only caveat is if you dynamically link instead of statically link the independently compiled header/source file. In this case, your executable will be smaller in size, but it may not be as portable as you would like. You would be able to run your executable on your PC, but for someone to run the executable on their PC they would have to have the header/source on their PC as well. Because the binary size for even the most complex data structure available is so small, I would recommend just putting the header in your include folder and the .c in your src folder, and then just compile with your project. With C’s horrific build system, simplicity is often the better solution imo.
No one actually uses K&amp;R C anymore though 
You're right there but I guess the code wasn't POSIX anyway, so I didn't bother with that. But yes, the flags should've been set instead and even the default rule for building a binary would've sufficed here, so no need to use automatic variables at all even.
What makes you say that? 
It's really a very advanced book 4 beginners, we created a discord yesteryear and we had incredible amounts of dropoffs and headaches in the group using that book. Better look for a modern C book instead, read my posts here on reddit to find my personal recommendation 👌
What I should have written is it's a decent book, but an outdated standard. Modern C examples won't compile with `gcc -ansi` flag set. 
Thank you for the information and the link, I will definitely check out your posts :) 
À
Unfortunately for you K&amp;R is an ancient tome of an outdated syntax of pre-standard C, and makes for poor reference to learn modern C. Unfortunately, the C community is cultishly dogmatic in their worship of the infallible word of K&amp;R, that it was a good idea 46 years ago and can't possibly be improved. If you think there has been any sort of innovation since, you're wrong. Mind you, I do love me some C, I'm only speaking out against the cult of C.
Looks good. Couple of pointers: * Don't make non-pointer paramters `const`. I doesn't make sense, because in C everything is passed by value anyway. So whenever you call a function, a copy of the parameter gets pushed on the stack. It's there for you so might as well use it. * `wrdlen` should be of type `size_t`. `size_t` can hold the size of any in-memory array, that's guaranteed by the standard. It's not a bug to use `uint64_t`, but `size_t` is more appropriate * make the const arrays `static`. A dumb compiler might allocate those const arrays everytime it enters the functions. `static` makes it so those arrays have global lifetime. * pretty sure you're accessing mem past the end of the array [here](https://github.com/archmirak/b64codec/blob/56a32e3f08942223a873ad795a3b245c6079bcd7/b64codec.c#L38). The loop condition allows you to access only `wrd[i]` and `wrd[i+1]`. But you're also accessing `wrd[i+2]`. * Compile with warnings. There are some lines where you have undefined behavior because you're using the postincrement operator multiple times with no sequence point inbetween. * Functions should do one thing and do it right. Both base64 functions do two things: allocate memory &amp; (en/de)code. At least you're checking the return value of malloc, but imo they shouldn't allocate memory. The destination address could be placed on the stack, along with the max length to avoid buffer overflows. This way allows me to use your functions with a buffer i've already allocated: maybe on stack, or maybe on the heap, or even global. Doesn't matter.
This paragraph applies to the Unix community as a whole.
`0x214afffc` decodes as `addi $t2, -4`. Take a look at the `union opcode_t` struct on [this mips emulator](https://github.com/ferraristealer/EntroPS2/blob/master/EntroPS2/mips.h) to see how to decode an instruction into the individual bits.Then, look at [this dispatch code](https://github.com/ferraristealer/EntroPS2/blob/master/EntroPS2/r5900.cpp#L1482) to see how decoding the instruction itself works. Source: I wrote that code. sorry about the C++, but it shouldn't be too difficult to follow.
Whoops, didn't realize it was private. I've marked it public. I also edited my answer to elaborate a bit more.
I wouldnt use a lot of the stuff in the book given its age, but it is an excellent display of how to describe a language and design pedagogical examples. I read it from cover to cover for that reason.
Shhh don't say that. It isn't safe. They'll find you.
AFAIK the second edition of the book (which is always recommended today) is standard ANSI C (C89). The truth is that C89 is the most widely used standard: it is *the C*.
As do I.
Yeah, I think the 2nd edition is a wonderful book, and a pretty good starting point of you want to start learning basic C. The 1st edition should not be recommended in my opinion. It's not standard C
sub_set.card is set to 0 and never incremented. So `x_is_in_set` checks 0 elements
Never mind. I guess you have to post somewhere before you see your stupid mistake. I needed to update the cardinality of outputSet within the loop in the function combinat each time, rather than just at the end when it was finished.
That's patently untrue. You can use designated initializers, all the newer headers, variadic macros, _Generic, single-line comments, inline functions... You can even use weird language extensions like __auto_type. I'm not aware of anything from C99 or C11 that *isn't* compatible with Objective-C.
Yes thank you! I caught it too and did a ninja edit to set the cardinality at the end of the loop, then realised after that, that that was the wrong place to do it and it needed to be incremented at every insert. You were very quick to figure it out! It's my first time trying this approach to sets as structs. Wish there was a library... 
and gnu ls has about 3000 lines more fluff than it needs.
There is still some floating out there. My first build break at my last job was because a code change I made was standard ANSI C, but we were still using pre-ANSI C compilers (mixed with current GCC compilers, which made it all very fun)
Part of the problem is so many people recommending it started with another programming language and already knew the basics when they read K&amp;R. If you look at the preface it makes it clear it's not meant for beginners: "The book is not an introductory programming manual" is right there in the book.
&gt; pre-ANSI C compilers (mixed with current GCC Kill it with fire, please!
Literally how is that repeating yourself? Actually, that's kinda interesting, getting the size of a pointer, but I mean it's kinda redundant...
typeof does not exist in C...
Don't worry, my degree required me to learn 16-bit 8086 assembly.
[#define a ++a](https://ideone.com/7XiqDh)
What is your issue
I find programmers in general to be weirdly dogmatic about a lot of things that don't really matter, and yet extremely disorganized when it comes to actual practice. I realize I work in the ghettos of the coding world, but just once I want to be brought in on a project that *wasn't* authored by someone suffering from disorganized schizophrenia brought on by years of drug abuse. They could put their brackets on whatever line they wanted.
Context: https://stackoverflow.com/questions/48270127/can-a-1-a-2-a-3-ever-evaluate-to-true
Making a paramter `const` does make sense. Even if it has no mechanical difference; it's like a note to any future editor "When this function was written it was expected that this paramter would never change."
Please explain how you think this would work?
Do you know what ++ does?
It prints 1, as you would see if you followed the link in the comment you originally replied to.
&gt; Is it ever possible that (a ==1 &amp;&amp; a== 2 &amp;&amp; a==3) could evaluate to true, **in JavaScript?** I fail to see the relevance.
I see that that's a link now... And I see that you put the hash define after the variable declaration. I concede I'm retarded. While I'm sure this is a learning exercise I'd like to point out if you wrote code like this in a professional environment where code was audited to meet safety requirements you'd be cruxified.
It's not my code...
&gt; $^ GNU make's manual gives its use in an example...
It's the origin of the question, now getting ported to other languages.
Clever, but I'm pretty that that's invoking undefined behavior as an lvalue is being modified more than once in a single sequence point. Also the order of evaluation of sub expressions is also undefined afiak. But it's still neat, imo.
`&amp;&amp;` is a sequence point.
Yes, you're right. I made a mistake. I should've noticed that.
That's what I was thinking indeed. Anyway I've just pushed a major commit, hope it has addressed the major issues.
Yes. If a is a _Bool (or bool with stdbool.h or C++). In C++, you could overload the assignment operator to behave like that but this is a C subreddit.
Notice it's not mentioned [in the specification](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/make.html). It's generally not available outside of GNU Make.
I said warnings, not errors. If you don't cast, you still get warnings, not errors, because in c89/c99, it is legitimate to implicitly convert int to pointer. It is frustrating that many of you insist missing stdlib.h is bad for casting, but conveniently ignore/neglect that missing stdlib.h is equally bad even if you don't cast.
&gt; to put a bracket on its own line or not is fairly humorous Where you put a bracket is a code style thing. I have my own preference but a programmer should ultimately follow the project's prefered code style. Otherwise, when another programmer runs the linter it will generate diffs in unrelated lines. Spending significant time arguing about brackets is obviously counter-productive, pick a style and stick to it. &gt; Most dogmatic conversations fall into this category for me. Vim or Emacs? Brackets on their own lines? ++i or i++(because ++$i in php is a whole 33% faster!)? Vim vs Emacs is a subjective conversation, yes. I prefer `i++` (or whatever is used throughout the project) for readability because it doesn't call attention to itself but it is a very minor thing. All the other stuff you mentioned are very much more important but also very much more difficult to deal with. But yeah, if you have a coworker that submits terrible code, doesn't accept criticism but is anal about trivial code style stuff then I see the irony.
I'm curious when the last time you compiled with `-std=c89` is because that's what I write at work and it very much is *not* "*the* C"
It does in GNU/-compatible C, which is why I prefaced my comment with “If you’ve got a `typeof` operator.”
"Whats a terminal?"
Let's not ding community college.
The superfluous `const` clutters the prototype with meaningless information for the caller, and you'll almost never see it used like this in practice. It definitely doesn't belong on the prototype. It seems like the prototype and definition *might* be allowed to differ in regard to `const`parameters, like this: int foo(const int); int foo(int x) { return x; } Neither GCC and Clang nor complain about this, but I can't find where this is explicitly permitted in the C specification. If this is valid, then sure, make your arguments `const` in the definition, *but only if it actually catches real bugs*. Pointer to `const` has helped me on a few occasions, but I literally can't think of a single instance where a `const`parameter would have caught a bug. For me to use it this way would be a poor use of time.
A poor waste of time? I know some people in my office type like two fingerd retards; stopping to look at the screen with every other character. I on the other hand can type a five letter word in less than a second. It's not meaningless information, I've already explained it's meaning. I do it to aid future maintenance.
Arguments are always passed by value in C, so it's *meaningless* information to the *caller* to make parameters `const`. (Pointer to `const` is something entirely different.) It cannot serve any purpose in a function prototype. That's what I meant. Using superfluous `const` isn't just about typing speed. It's more clutter on the screen and more cognitive overhead. It comes at a real price, and it should be at least worth its extra burden.
This is great, I was just looking for something to use for base64 embedded glTF models. Bookmarked.
Glad to be of help, if you need anything just pm me :)
Doing this kind things really raise the amount of complexity within the, detecting an error in these situation may be hard, that's why I'd consider doing that again. Of course you can always use one of those program, as checkmarx as help. But I don't really like using external programs. 
Ive see one article about pitfalls in all most popular programming language... Just avoid them!
Most of these aren't necessarily pitfalls with C, they're either just typos or simple formatting errors. The first one is literally just an additional character and not a language issue, and the second one is a mistake a complete rookie might make when writing out a number.
It is meant "to be fun", calm down!
We're not in /r/funny.
thank you that seems to work!
Indeed, and if warnings are enabled (as they always should be) then any decent compiler will flag these simple mistakes.
All of them are undefined behaviour. In C99 all require a diagnostic; in C89 only #3 requires a diagnostic. 
Suppose, you are never in /r/funny haha
C89?!
Yeah, and the first one being used as a rationale for prefixing member vars with m_ is ludicrous.
I'm confused, why does the author recommend to avoid vi in his solution to the third issue? Is he implying that it doesn't support syntax highlighting? Because it does, vi and all of its derivatives support syntax highlighting with a single line in your config file.
Better known as the oft requested "inlinedammit" keyword.
Please don't post this sort of content.
No blog spam please.
What are you trying to achieve by forcing the compiler to inline your function (and thus probably generating suboptimal code)?
force inline one line SSE functions, since im putting my SSE vectors in a union it's acting all weird and becomes even slower than normal operations (when adding two vecs and other similar operations). I can provide a github if you'd like.
I would place the function in a header file and declare it as static inline. In C99 this will result in the function being without distinct binary representation and being 100% unlined.
&gt; keep management out of the code This is the best standard I can think of. 
I'm using intrinsics. I'm not sure why its not inlining, and no I'm not using optimizations because I want to test for the worst case where there is nothing to enhance the code. I'm not sure if this part is relevant but I'll include it anyway, my function take a union as an argument and gcc was loading my vector (which is a union that consists of an __m128 and an anonymous struct with 4 floats, x,y,z,w) one float at a time which was causing quite a slow down. After changing it so that so it takes __m128 directly I saw a massive improvement in speed, I then decided to look at the performance of an inlined function and it looks to me like it improved the performance by more than double.
gcc produces really crappy code when optimizations are turned off.
which actually works well for me. I want that crappy code. I can't control the flags that other people use but I can control my code to make it work quickly no matter what optimization level the compiler is using.
Some? Most embedded and OS system applications...C99 is bleeding edge.
I use gcc 6.2 in C11 mode for embedded development 
Thanks for the reply, I honestly just misread the title of the thread, I apologize for the confusion. I'm just stressing myself out about what language I should be using as a base to learn. 
No worries everybody was a newbie once. As to your stress: This is just my opinion, so take it with several large grains of salt, but I think you'll be all right as far as the language thing goes. Java is a perfectly fine first language and in reality what you want to learn is how to program, not how to use language X or Y. I'm sure if you continue your education you'll eventually take an operating systems course, and that will be in C so you'll get a good introduction there. I personally believe that every programmer should learn C because it's the backbone of everything we do in Computing but I don't necessarily think it needs to be the first thing you learn... One again, I'm just some guy on the internet so what do I know
That's not C and not relevant.
&gt; I'm a college student who recently decided to switch my major to Computer Science. My programming 1 and 2 classes are teaching me Java. However, I keep hearing from other people that c++ is the better language to learn. Programming is just the vehicle for computer science. If your college has a good computer science program it won't matter if you learn using Java or some other popular language. &gt; I'm new to this stuff (computers in general), so I can't really decide one way or another. Also, I can't change what the professor is teaching, being Java. Any thoughts/ideas? You can certainly learn both languages. Eventually you'll want to maintain fluency in a few languages spread out over a spectrum of uses. And once you learn "how to program", you'll find that picking up a new language is fairly easy. For now, the most important thing is to learn "how to program". And for that you'll need to stick to one language for a while, often beginners will get caught up in the intricacies of each language instead of the "how to program" part which is more important.
Hmm. Your university and it's professors are saying they are going to teach you computer scienc with Java, one of the two most used programming languages in the world, and you wonder whether you should listen to "other people" including anonymous posters on reddit. Hmm. What to do, what to do. So if you decide you need to learn C++ instead, then what are you going to do?
Stopped reading when author said `forget about vi` and it's not C pitfalls.
When you say "nothing happens" is there some kind of error? If not then it probably compiled successfully. 
No was bcc is not a proper command or script , 
did you work through the textbook? I'm thinking of reading and working through it.
&gt; I'm not using optimizations There you have it. If you turn off optimizations, the compiler is not going to inline functions. Inlining small functions (`-finline-small-functions`) is enabled at optimization level `-O2` and disabled in general on lower optimization levels. It's a stupid idea to want your intrinsics perform well without optimizations. I recommend you to just compile your code with optimizations turned on and advise users of your library to do the same. &gt; EDIT: also while I have you here how am I supposed to compile this if I want to create a static library? I put the attribute tag in the header but it's not working and it tells me there's no function body, am I supposed to put the body in the header in this case? or put the tag in the c file that gets compiled to static library? If you are using C99 or above (make absolutely sure not to compile in GNU89 mode which has different inline semantics), you can define a function as `inline` without `static` or `extern` in a header. This is called an *inline definition.* It is used for inlining the function, but not to generate code for the function. A normal definition of the function must exist somewhere and the compiler may use it if it decides not to inline the function. In exactly one translation unit, you should generate a normal definition of the function by re-declaring it without `inline` or with the `extern` specifier. The idiom looks like this: /* in foo.h */ /* inline definition */ inline int foo(...) { ... } /* in foo.c */ #include "foo.h" /* upgrade inline definition to normal definition */ extern inline int foo(...); You can also simply use `static inline` functions everywhere, but then code duplication may happen if the compiler decides not to inline one of the functions.
&gt; I want that crappy code. WTF? That's just stupid. You want the compiler to generate good code for your inline functions but then you also don't want to allow the compiler to generate good code by enabling the optimizer? That really doesn't make a lot of sense at all.
On Windows, ".app" is not a proper file extension for a program. 
Then make the filename "Capp.exe"...?
If it's not recognised you've configured PATH wrong. 
I was thinking about the personal project thing, but this a real good suggestion too.
Make sure you log out/in after updating your path.
You could use the visual studio compiler from the command line. 
Your error means that it can't find the gcc exe. It is located somewhere in your MinGW folder. Find out it's name (probably something like "Mingw32-gcc.exe" and either rename it to gcc.exe or change the bit at the end of the path variable from "gcc.exe" to the actual name.
true always equals 1 so the expression (a==1 &amp;&amp; a==2 &amp;&amp; a==3) will never evaluate to true. Am I missing a joke or something?
To be fair, superfluous information *is* allowed in the standard. For instance int foo(int x[static 17]); declares a function foo taking an int array containing no fewer than 17 elements as a parameter. Really, the compiler can't enforce this (at least, most don't because it could incur a huge runtime cost), so it's the same (to the compiler) as writing int foo(int * x); the difference being the added documentation you get from adding unnecessary details. From the user's POV, it may not make a difference to use const or not. From the maintainer's POV, it could certainly be useful (ensuring that the arguments to the function are never overwritten in the function).
&gt; improving speed by a significant amount &gt; I'm not using optimizations I... I don't even know what to say. How about trying the thing that actually works? 
Your Makefile looks needlessly complicated. Why don't you just make an explicit list of source files somewhere and then use implicit rules as make has been designed for?
I think I understand that my original logic was wrong. Also just to make it clear only the test program was compiled without optimization, the library itself was compiled with -O2 just on case that wasn't clear.
I typed it wrong in the gist, OBJ_DIR should be SRC_DIR.
a little harsh but fair enough, it made more sense in my head but I guess that's not how it works.
The `[static 17]` isn't superfluous. It's part of the interface and is something the compiler can potentially check, even statically: int a[16]; foo(a); // a potential compile-time warning foo(NULL); // again here On the other hand the `const` in `int bar(const int);` means absolutely nothing to the caller since it's passed by value. There's nothing actionable about it, so it's superfluous in the function prototype. 
In today's day and age, there is only a single proper reason not to turn on the optimizer: if you want to debug code the compiler otherwise transforms in incomprehensible ways. However, for this situation it is acceptable to have sucky performance and that's not the situation you should tune your code for either. Rather, it is of much greater importance to maintain an independence from a concrete compiler by avoiding unportable constructs like `__attribute__`.
You can update the gist if it contains an error.
Anonymously? I don't see the option?
I’ve used `typeof` in GCC, Clang, and ICC and it works in all three AFAICT. Even weird GNUish stuff like typedef __typeof__(__builtin_choose_expr(sizeof(int) &gt;= 4, 1U, 1UL)) atLeast4Bytes_t; works.
alright that makes more sense. looking at it now the idea was a bit stupid. I was thinking I should I provide an option for both types of functions, where you have the "normal" functions that only have the inline keyword and then optional support for gcc, clang, and msvc forced inline in case anyone ever needs it, should I just stick with non forced inline only instead?
I would avoid forced inline attributes. Just use a normal inline keyword and call it a day.
got it, I'll go do that, thanks again.
Because $^ expands to `$(SRC_DIR)/hash_omp.o $(SRC_DIR)/some_other_file.o $(SRC_DIR)/another_file.o` and none of these GCC is able to use as a source file. I suggest you use something like ALL_SRCS := $(shell find $(SRC_DIR) -name "*.c") HASH_SRCS := $(filter-out $(SRC_DIR)/$(EXE).c,$(ALL_SRCS)) HASH_OMP_SRCS := $(filter-out $(SRC_DIR)/$(EXE_OMP).c,$(ALL_SRCS)) HASH_OBJS := $(HASH_SRCS:$(SRC_DIR)=$(OBJ_DIR)) HASH_OMP_OBJS := $(HASH_OMP_SRCS:$(SRC_DIR)=$(OBJ_DIR)) $(EXE): $(HASH_OBJS) # Compile hash $(EXE_OMP): $(HASH_OMP_OBJS) # Compile hash_omp
What does "will not compile" mean? Does it give you an error message? What is it if so? 
not familiar with AVR assembly, i just googled the instructions. never tried to go this direction, but here, try these: * wouldn't lds and sts take a pointer???????? * is your syntax right? * it MIGHT work (access, not increment) if it's a constant, maybe if it's a constant and the volatile is gone (it could work theoretically, but i dont know if the compiler will do it) * add a _ in front of the variable in the assembly block void foo(void) { uint8_t test1 = 0; uint8_t volatile *testptr = &amp;test1; __asm__ __volatile__ ( "lds r31, _testptr\n" "inc r31\n" "sts _testptr, r31\n" ); }
 int my_var = 123; char* str = "Hello!"; //------------------------------------------------------------------------------ void foo(void) { return; } //------------------------------------------------------------------------------ int bar(int a) { return a + 10; } //------------------------------------------------------------------------------
Use Extended ASM: https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html A raw reference to `test1` from inside the assembly won't work because local variables don't have assembly names, only global variables do. Locals will either be in a register or on the stack somewhere. Extended ASM serves as the glue between these register/stack locations and your ASM code.
I've tried that but none of the examples compile. For example, if I use the constant literal "I" it compiles, but if I use the proper constant of "r" it does not: __asm__ __volatile__ ( ... clipped "lds r31, %0\n" ... clipped :: "r" (test1) );
The documentation and its examples can be a little difficult to follow, but you probably want something like this: __asm__ __volatile__ ( "inc %0\n" : "+r" (test1) ); or maybe __asm__ __volatile__ ( "lds r31, %1\n" "inc r31\n" "sts %0, r31\n" : "=r" (test1) : "r" (test1) : "r31" ); But I agree with other commenters who have asked, why not just write `test1++` or `test1 += 1` in plain C code?
I don't care about this at all. It's a petty thing to argue about, and anybody with an opinion needs to keep it to themselves. It doesn't matter how much space is between functions. As long as you're indenting the code between the braces (and if you aren't ... who let you near a compiler?) there's plenty of visual indication made with the function declaration itself. Anything more is unnecessary. Note that I'm not arguing that there should be exactly one space or any other standard. I just don't care. Put in two or three for all I care. It simply doesn't matter. One thing that does bother me, though, is when there's a comment block between each function at the function implementation. This is fine at the declaration, where you're providing API information and the like, and the header is the right place for that so other programmers have the information they need to use the function, but too often it gets copy/pasted at the implementation as well. And then any change needs to happen at four places: declaration, definition, and two comment blocks. One of these is 100% redundant.
Yes, the first my mind was exactly the same expressed. Given the fact how much time was spent to write and debug this code as well as to provide test suite, I was really disappointed to meet such comment on review, especially since this colleague is nice and talented guy.
The argument isn't against documenting the function (even if it is kind of boilerplate), it's against doing so where the function is *defined* in the `.c` file rather than where it's *declared* in the `.h` file. If you give users a compiled library and the `.h` file, putting the documentation into the `.c` files will have done them no good at all.
Yup, and that documentation goes in the header file, not the implementation.
hmm never thought of that, thanks
AI personally don't mind where it goes. Or how many spaces people use. As long as it's consistent throughout the project; at the very least consistent throughout the file.
"Doesn't work..." is not an error description. What happens and what do you expect to happen instead?
It wont compile, and there isn't a descriptive error since it's GCC asm() macros.
I’d try register unsigned dummy; __asm__ __volatile__( "lds %1, %0\n" "inc %1\n" "sts %0, %1\n" : "+m"(test1), "=&amp;r"(dummy)); (void)dummy; If AVR has condition codes (no idea) then you need to include a `:: "cc"` clobber also.
&gt; Most of my function needs to be written in AVR for bitbanging Are you sure? I don't know anything about AVR, but I know GCC is really good at turning C code into assembly. If all you need to do it a bunch of bitwise operations like shifts and masks, then just write it in C and let GCC figure out the best way to do that in AVR assembly. GCC understands that stuff quite well, and will correctly generate specific efficient AVR instructions like `swap` given verbose-looking C code like `((x &amp; 0xf) &lt;&lt; 4) | ((x &amp; 0xf0) &gt;&gt; 4))`. The only thing you should really need inline assembly for is special operations that don't have a representation in C nor a compiler intrinsic, like say an I/O assembly instruction. In that case, you should use the minimum amount of inline assembly possible; make liberal use of the "r" constraint, and let GCC choose which register to use. Most of the time you shouldn't need to write load and store instructions or use specific registers in your inline assembly; the compiler knows more than you do, and can assign registers to avoid a lot of extra work.
I'm not good enough in AVR assembly to know what `lds` does, but it seems that you might need to specify `"m"(*test1)` as the operand so gcc generates an appropriate memory operand for you.
Well, you're using inline assembly, so now you're responsible for making sure the assembly that it generated is grammatical and correct (just like you're responsible for making sure the C code you write is grammatical and correct). You need to look at the assembly. Use the `-S` flag to GCC. When you do, I'm guessing you'll have a line like `lds r31, r24`. Even not knowing any AVR, a quick Google search taught me that that's incorrect, unless you have a symbol *in assembly* that's named `r24`.
If you're being told to do it a certain way, then by all means do it that way. I always adapt my style to the code base or client I'm working with.
Stick with the style of the code you're working with. What's so hard about that? If it's your code, and your project, and you're not being paid for it, write it however you want. If it's your job, do what you're told....there's no point not to fix it to look like the rest of their code. 
Yes it is: https://gcc.gnu.org/onlinedocs/gcc/Simple-Constraints.html
What are you trying to do? Then what is the alleged error message? 
2 things wrong with this statement: 1. You didn't *try* to answer my question from 12 months ago. Your what is known as a help-troll. You don't actually help people, you masquerade around as a helper *asking* people if they need help, and then proceed to troll them. 12 months ago you said this to me **"Are you sure this is what you want to do?"** and now you say **"Are you sure?"**. Then you troll me with **"Uh-uh. No way. I want you to say why you want to do this, because I'm still not convinced you actually need to."** some more. You're a troll. 2. Your attitude towards myself and others on this forum is a "fuck you" attitude. We come here to ask for help, **not to ask for your opinion on whether we need help**. PS: I ended up getting help from /u/FUZxxl who simply answered the question at hand rather than troll me with "are you sure you need to use assembly?"
Seriously though, I too wonder why you want to use inline assembly for this. Using pure C with volatile pointers is probably much cleaner and easier to maintain. Inline assembly should only be used as a last resort as it is notorious for being unportable, hard to maintain and fragile. Inline assembly should only be used in production code after the programmer has throughly understood what assumption the compiler makes about your inline assembly and how to state all relevant invariants so the optimizer doesn't perform unintentional optimizations. From your posts it is clear that this understanding does not yet exist and furthermore, I do not see any compelling reason to use inline assembly for this task either. So why do you insist on using it?
That documentation is linked in the [very top comment](https://www.reddit.com/r/C_Programming/comments/7sgl73/how_do_i_use_a_c_variable_inside_a_gcc_asm/dt4nn9t/) to your post.
&gt; So why do you insist on using it? I am first and foremost, an assembly programmer. Most of my projects are bare metal &amp; done in C/ASM. I am significantly more comfortable coding in ASM than in C, and I am very comfortable coding in C. I have coded in both for roughly 20+ years. &gt; Using pure C with volatile pointers is probably much cleaner and easier to maintain. Yes. &gt; Inline assembly should only be used as a last resort as it is notorious for being unportable, hard to maintain and fragile. Yes. &gt; Inline assembly should only be used in production code after the programmer has throughly understood what assumption the compiler makes about your inline assembly and how to state all relevant invariants so the optimizer doesn't perform unintentional optimizations. Yes. &gt; From your posts it is clear that this understanding does not yet exist. Your post is based on a series of (incorrect) assumptions about me, my skill level, and my experience level. I have C code that generates the bitbanging I need. All hardware is tested. Now it's time to convert the working C code to working ASM code, which as you can imagine, is very similar to the structure of the working C code. Why? To shave nanoseconds of time off a few bits which is all that is needed for an ATmega2560 to drive 1024 NeoPixels off a single pin, at 1.4MHz, at just under 60fps. Both the AVR and NeoPixels are being used way out of spec. Fine-tuned assembly and a peak or two at an oscilloscope are my only chances getting something this extreme to work. My work should ultimately be even faster than [**Josh.com's**](https://wp.josh.com/2014/05/13/ws2812-neopixels-are-not-so-finicky-once-you-get-to-know-them/) solution.
I understand your intent. Please read the documentation other people linked carefully. Make sure to specify every invariant carefully as the compiler assumes that your assembly changes nothing but the exact things you specify. Also experiment with different compiler flags.
The reason I don't answer the questions you ask is because *I don't understand them*. I mean, yes, I literally understand what the question means and could probably come up with a correct answer, but I don't understand why you ask *that* question instead of a different one. If you would just take a minute to explain things, then maybe *I* could learn something. Seriously. *You* could have taught *me* something. I could have learned that maybe AVR has lots of assembly instructions that can't be represented by C code. Or maybe that GCC's optimization for AVR sucks. In this case, now that you did finally give an explanation in [another comment](https://www.reddit.com/r/C_Programming/comments/7sgl73/how_do_i_use_a_c_variable_inside_a_gcc_asm/dt4xbbw/), I learned that GCC's optimization for AVR is fine, but that some bitbanging applications need extremely tight timing on the order of cycles (which is several orders of magnitude faster and more precise than any bitbanging I've worked with). See? I just learned *two* things. One is a fact about AVR and bitbanging. The other is that I now have enough context to understand what you're doing, and why you're asking *this* specific question. Even so, I gave you the best answers I could. I don't use inline assembly enough to know which specific constraint was needed to get your code to compile, but I was pretty sure one of them would work. I also gave a suggestion about using a simplified form which omits the `ld` and `st` parts of your inline assembly; did you try that? Because I did. https://godbolt.org/g/MXkEZN The short form, as well as a hybrid that specifies separate inputs and outputs but still omits the loads and stores, seems a lot simpler to me; GCC will automatically generate any loads or stores only as they're needed. (At one point I got it to generate `ldd` and `std` instructions, too, but I lost it when trying to trim down my example.) Maybe it won't suffice in your actual code, but since I only have the example code you provided and asked to see working, it seems like a better solution for that. And yet (now that you've gotten the solution you wanted), I'm going to ask another question: Why use inline assembly, instead of separate assembly functions? It seems like just coding some functions in a separate file of assembly code and calling it from C code would be easier to code, and could possibly perform better or more predictably since it might open up options like skipping leaf function entry/exit code and otherwise not having the compiler generate extra code that you know you don't need. If it won't work, then a simple answer like "My actual code is much more complex than this example, and inline assembly works better than separate assembly functions" would answer the question sufficiently to assuage my curiosity. It only takes a few more seconds to type than the rude "No" that you usually provide. But on the other hand, maybe it *would* work and it *would* be better... in which case, you're welcome. We can only provide such answers by understanding what you're asking, and that means asking questions of you. If you refuse to cooperate, don't complain when you get poor service in return.
Code::Blocks is an integrated development environment (an IDE). It is often bundled with MinGW, which is a windows distribution including the GCC, the GNU C compiler (or GNU compiler collection, depending on context). I assume you mean IDE and not compiler. If so, your answer is "it probably wont affect anything". The only thing I can think of is how your code ends up getting compiled. Code::Blocks has its own build system stuff, so if you create a project and add a .c file, it should "just work". In other IDEs (like CLion, my personal favorite) you must write the build scripts yourself; it's not done automatically. Code::Blocks is fine. For an absolute beginner (and a student especially), it's best to eliminate all variables between how you write/compile/test/run code, and how the grader writes/compiles/tests/runs code, so I'd recommend just using Code::Blocks.
The's an IDE, not a compiler. It probably has some compiler bundled with it, though. gcc or clang are the usual suggestions for C.
Clang, gcc, icc or the vs compiler are my choices
Thanks, my teacher goes straight into the code and brief history than the applications we use. I like knowing how it all works not just the typing in code aspect. It took me 20 minutes to figure out that I had to direct codeblocks to the complier in the settings tab. I’m eager to dive into this, but it’s all a little overwhelming right now. 
You can probably find HTTP/1.1 fuzzers that will help automate the process. I'm @64 on GitHub in case you're wondering.
&gt; bash &lt;(curl -s https://raw.githubusercontent.com/boazsegev/facil.io/master/scripts/new/app) appname There, already broken.
At least he shows us how to use vim.
&gt; code::blocks &gt; compiler XD
&gt; then just write it in C You obviously don't know his use case completely and you're giving your opinion instead of just answering the question. Are you sure you know this isn't stackoverflow?
Technically obviously wrong but practically yes it is and there is nothing wrong with that. If you had huge cancer tumors growing all over your body it would be true that you are a subset of those cancer tumors.
&gt; "You should never use malloc in C++ Doesn't a non overloaded new operator call malloc?
Is the query NULL-terminated? If not, it will run out of bounds if the URL ends with `&amp;` and probably also with `[`. P.S. Back does not work on your web page. It's really annoying.
Don't waste time on this as there are a million more out there. Eg. why use klib when you can use concurrencykit that gives all those data-structures but with lockless synchronization. Then there are others that implements data structures in asm. Just rolling out your own "general" code as the need arises has always been better than spending a week evaluating and integrating other people's code. If avoiding rework is the aim then I do that by keeping a snippet folder and I copy paste stuff from it into projects as needed. 
GNU GCC. It is ubiquitous and is great!
Hi @VincentDankGogh, Cool! I didn't know about fuzzers all that much and didn't think to use them as testing tools. And thanks for PR and review on GitHub. It's been helpful.
&gt; Is the query NULL-terminated? Yap. NUL termination is added to the query data when it's parsed. However, I don't see how ending with `&amp;` would run out of bounds? &gt; Back does not work on your web page. Really?! Which browser (seems to work on my Safari)? Is it a specific page? I'm using GitHub pages, they're all static with no Javascript to speak of (except for changing themes). If you had a bad experience I would really like to change that. 
&gt; There, already broken. I didn't understand...?
&gt; However, I don't see how ending with &amp; would run out of bounds? In checking for `&amp;amp;`, it does not check whether there are enough characters left. But if it is NULL-terminated then short-circuit evaluation will catch it. &gt; Really?! Which browser (seems to work on my Safari)? Is it a specific page? Oh, I see, it happens only on links that don't work (http, websocket).
&gt; it happens only on links that don't work (http, websocket). Yeah, I'm still working on the documentation... once there's some content there, the page will be scrolling back and forth and it will be possible to see the links work. &gt; In checking for `&amp;amp;`... Oh, yeah, I was assuming the NUL when coding that. I didn't even notice. Nice :-) 👍🏻 
Today I learned about the [M/o/Vfuscator](https://github.com/xoreaxeaxeax/movfuscator). A compiler that emits only `mov` instructions.
Install Qt Creator, then go: Tools - Options - Build &amp; Run - Compilers and select clang. For educational purposes you might also edit your code in some standalone editor (vi, emacs, Kate - depends on what Linux distro you prefer) and compile with clang on command line. ;)
&gt; So I just started an introduction to C programming at my college. This is the very first sentence the OP used. So, what's so funny? There are no stupid questions, just stupid answers.
&gt; It took me 20 minutes to figure out that I had to direct codeblocks to the complier in the settings tab The Code::Blocks site isn't clear, but there is actually a specific download that includes the compiler and installs it configured for you: codeblocks-17.12mingw-setup.exe is the correct one. &gt; I’m eager to dive into this, but it’s all a little overwhelming right now. Which is probably why your instructor is starting off with an IDE like Code::Blocks before delving into the details regarding object code and such.
I thought that since the script is open source, it's easy to read it and make sure it's safe to run (also, it doesn't require `sudo` or anything). How is it less safe than `brew &lt;package&gt;`, `gem install` or any of these package management tools? and how would you recommend that I fix this security concern? 
&gt; Why use inline assembly, instead of separate assembly functions? I like being good at inline assembly, since it helps out a lot in saving time, being able to mix C and ASM code inside the same files. I am also really new to *nix related programming tools (GCC, G++, GDB, etc) and I would like to learn more about them. I almost exclusively use Microsoft/IBM/Intel tools from years past, I am very good at them. But they have some differences in syntax/cmd-lines compared to newer *nix related tools.
&gt; How is it less safe than brew &lt;package&gt;, gem install or any of these package management tools? and how would you recommend that I fix this security concern? These package management tools usually verify the authenticity and integrity of the downloaded package and often do not execute any package-supplied scripts or have someone vet the scripts before publishing a package. Piping a shell script from the internet into bash is the worst possible way of doing things. No integrity checking is performed (what if someone broke into your server and changed the script?) and the user has no way to check what the script did afterwards as it was never copied to a file. I'm not saying that providing a shell script for the user to execute is wrong, but the instructions should be different. Something like this is reasonable: 1. download the script 2. verify that the checksum matches the checksum we posted in a digitally signed mail. Make sure to verify the digital signature, too. 3. mark the script as executable and change into an appropriate directory 4. execute the script This way, the integrity and authenticity of the file is verified and manipulation is much more difficult if the user decides to follow these steps. The user can still decide to ignore security and pipe the script directly into bash, but then it's his own decision to do so. Do your users a favour and make everything secure by default.
&gt;In today's day and age, there is only a single proper reason not to turn on the optimizer: if you want to debug code the compiler otherwise transforms in incomprehensible ways. Also compilation times.
Character `'\n'` has the value 10 in most character sets. So you're cutting off the first 10 characters of the string you're printing out. It's doing exactly what you're telling it to do. Also, `printf(variable);` will do bad things if there's a percentage signs in the string pointed to by variable. Always use `printf("%s", variable);`
&gt; Well, it is a global variable in OP's sample code I swear it wasn't originally and was edited after my comment. But there's also a chance I have terrible reading comprehension. Who knows?
You could be serving different content to the cURL user agent than you serve to browsers, for example.
Oh I was not aware of that, that's good to know. I changed it to `printf("%s\n", ptr);` and now everything works just fine! Thank you!
You can also fo `puts(ptr)` which does the same same thing.
I'm going to second having Clang at least as a secondary compiler it has great error messages that can save you a ton of time. (especially if you want to write some complex macros.)
&gt; inline assembly, since it helps out a lot in saving time, being able to mix C and ASM code inside the same files Yeah, come to think of it that's what most inline assembly I've used is for, too: tossing in small bits of assembly in the middle of C code, to do things that can't be done in C. I would still advocate for using [built-in functions](https://gcc.gnu.org/onlinedocs/gcc/AVR-Built-in-Functions.html) (a.k.a. compiler intrinsics) whenever possible. It meshes a lot better with C code, compared to the very convoluted syntax required by inline asm. It's also more portable between compilers; *if* they both support an intrinsic, it will probably look the same in both, perhaps with only the name being different, whereas extended asm syntax can vary much more in terms of the constraints and modifiers that the compiler uses. And the compiler understands what the intrinsics do, and can optimize and reorder them as it sees fit, whereas inline asm tries to bypass the compiler. It's important to note that inline asm *tries* to bypass the compiler. Many C programmers, old and new, still have an old mindset that the compiler just translates C code one-to-one into assembly code, but that's just not the case with modern C compilers. [Even the `volatile` qualifier doesn't automatically prevent it from doing funny things with inline asm.](https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html#Volatile) (In fact, even the `volatile` qualifier on a variable is widely misunderstood and misused to provide thread-safety, which it emphatically does not do. I've seen compilers reorder memory accesses involving volatile variables such that it violates the intended thread-safety.) Using inline assembly to achieve a specific sequence of assembly instructions, particularly for precise timing, can be a risky game. The assembler will *never* alter any of your code (not counting high-level assembly features in ones like MASM or NASM), whereas the C compiler *might* alter your inline assembly code by reordering it within the function, duplicating it, or removing it. So you need to be sure to examine the actual assembly output from the compiler with `-S` (or by disassembling the compiled code) to make sure it did what you wanted. You can make it a lot more predictable by structuring your code to help enforce boundaries. For instance, you might put a particular block of inline assembly into a function by itself, and mark that function as "always inline". This will really give you the best of all worlds: the assembly is right there in the C code, so you don't need to jump through hoops to compile a separate assembly file. Just like an intrinsic, the C function will nicely encapsulate the operation and its inputs and outputs. When it's inlined, the compiler can optimize around it, so if you had a block that produces multiple outputs (which you can only represent in C using pointers to out-parameters), if you specify the output constraint as `"=r" (*pOutput)`, the compiler can determine whether the memory addresses are actually needed, and if not, no unnecessary memory accesses will be generated. Having it in a function will also create sequence points (which I believe inline assembly does *not* necessarily do) so that it doesn't get reordered, but the compiler may also choose sensibly to duplicate it or reorder it to improve the efficiency of loops, branches, and memory accesses, and you can probably worry a bit less about it doing so knowing that it will only make changes that won't affect the performance of that particular block of assembly.
&gt; You could be serving different content to the cURL user agent than you serve to browsers, for example. Actually, I can’t. GitHub is serving the content... ...but I do agree with your point. It’s really hard to vet code. But I think that’s part of being Open Source. 
to be fair, VS17 has added support for most of C99.
C11 added support for the `asm` keyword, you should avoid gccisms when possible.
That'd be news to me, but fair enough. I was pretty sure, there were still quite significant things missing.
What operating system are you using?
Try putting \n at the end of the string.
You safequard the checksum by posting it as a part of an electronically signed message signed with a published key.
It doesn't. Show all the code, could the &lt;null&gt; be coming from a previous line?
I'm no expert but I think when you use %s it expects a variable - It goes to the address of that variable and reads all the characters from that address onwards, 8 bytes at a time, until it hits a null terminator. In this case, you've said you want to use %s but then your variable isn't actually a variable so it doesn't know what to do. It can't get an address from it and so it's saying the memory was empty. My terminal wouldn't even let me do that - It said I had a syntax error.
if you're looking at this https://atom.io/packages/gpp-compiler then use this compiler http://www.mingw.org/ /mnt/c and so forth is referring to the windows subsystem for linux (I assume) and if it's something you want to play around with https://docs.microsoft.com/en-us/windows/wsl/install-win10
If the `,` wasn't there then the 2 strings would be concatenated. If the `%s` would then be accessing a undefined address. The program might crash, might print &lt;null&gt; or might print something else.
Passing a string literal is fine here.
Or use well known error codes if( address &gt;= NUMBER_OF_BLOCKS) return ENXIO; if( !deviceAvailable()) return EBUSY; if( someOtherError()) return E...; ...
I like the `errno = ENOTSUP; return -1;` approach... it speaks to me in a language I've had to learn for system calls, so I know this language well.
The original vi did not. nvi, the BSD version of vi does not. Busybox vi does not. POSIX does not require vi to have syntax highlighting. What you call "vi" is likely a symlink to vim, which is a superset of POSIX vi and thus has additional features like syntax highlighting.
`clang -std=c11` gives me no diagnostic output whatsoever for the above `typedef`. (Using version 3.9.1.) The `__`s on `typeof` should prevent it from kvetching regardless of language mode, at least in theory.
Utter nitpick, but technically the intermediate `main.S` should have a lower-case `s` at the end instead—the compiler will see the uppercase `S` and assume that it needs to be preprocessed, whereas the lowercase `s` indicates it’s just assembly.
If you are writing a linuxy device driver, yup, code to the posix interface. If you are not, using posixy error codes is just plain confusing and makes people think, incorrectly, that something at the system level returned such a code. 
All very well if and only if one thing, and only one thing in your routine sets errno to ENOTSUP. If there are two or more and you get a ENOTSUP.... ahh, what exactly was the problem? Good luck debugging that unless you can hook a debugger to the thing when it is triggered. 
Then it sounds like your functions are doing too much and a refactor is in order.
Not as confusing, IMO, as error codes which change from build to build.
Hi i tried downloading clang but now i'm not sure what to do. 
ok so i downloaded clang. What now?
&gt;Provided it is kept up to date on every release. Isn't that the big problem with using __LINE__? Move some code around in a release, and the line number changes and you have to dig back through your previous versions to see what line was where. IMHO, it's better practice to #define all of your error codes. You can add string tables for user-friendly output if you want (I'm working mostly in the embedded world and there's not always room for strings) but more importantly the higher layers can handle return values in a consistent way. If you're worried about collisions in your return values, make your return type sufficiently large that you can add a module-specific prefix. For example: #define ERR_WIFI 0x10000000 #define ERR_AP_NOT_FOUND (ERR_WIFI | 1) #define ERR_INVALID_PASSWORD (ERR_WIFI | 2) When a higher layer does get an error code passed back to it, you can mask the module-specific part and use that to construct a more friendly error message, e.g., "WiFi error 1" instead of "Error 0x10000001".
You write code and compile it
I don't see this working when file1.c:100 can fail and file2.c:100 can fail as well.
In Xcode `typeof` results in a compiler error, in C11 mode. not sure which version of Clang it's using since Apple changes the version number.
Is it an error from an actual call to Clang the program, or just an editor giving you a squiggly-line because it doesn’t grok the syntax? AFAIK Clang’s always been mostly-GNU-compatible and GCC’s had `typeof` since at least 2.95, if not earlier. I know for a fact the bog-standard Darwin Clang supported `typeof` as of late 2010, though my experience is from command-line usage.
&gt; what if someone broke into your server He basically thinks you're dumb and github, package managers etc. are not dumb. Frankly I regret about the human time that was wasted when he though of that comment that basically suggested a documentation change to tackle "security" issue, you replying to him and me reading that conversation. 
try asking on r/cpp, this is a C (not C++) sub.
oh, true, thank you :)
This is a developer friendly way to deal with it, unfortunately usually the user is not the developer. You may use this for debugging purposes but then again, gdb is better for that.
&gt; Isn't that the big problem with using LINE? Move some code around in a release, and the line number changes and you have to dig back through your previous versions to see what line was where. This issue is specifically apparent with shared libraries. When they get patched, recompiled and updated, programs using them will not even notice a difference except the error messages will no longer make sense. I kind of like the idea of having better error messages, but the formatting of your code should not affect its semantics.
It doesn't. Post the smallest possible complete code which reproduces your problem. Post it online here, with correct formatting.
Second. It's a constructor function. Do the malloc inside create_ht(). Stackoverflow: https://stackoverflow.com/questions/3774193/constructor-for-structs-in-c
Depends on the interface. I often prefer the first design as it allows the user to allocate the structure on the stack, but the second design has advantages too.
I agree. I usually (though not always) prefer the first. It's one thing Objective C did well with, I think, separating out allocation from initialization. It opens you flexibility for different ways of allocating an object (from malloc, on the stack, or even something different, like from a memory pool).
Depends. The first gives them a lot more flexibility in where the data is stored (stack, heap, data) since the constructing code doesn’t need to care able where the memory lives. The second, especially when combined with opaque pointers, is how encapsulation can be accomplished, and it’s a familiar pattern (particular since it’s very likely almost any API requires a destructor)
Sometimes you can't really allocate it on the stack. e.g: if `hashtable_t` is: typedef struct { size_t n, cap; list_t buckets[]; } hashtable_t; 
Indeed! Which is why I said “the second design has advantages, too.” Though, really, this sort of hash table design might bite you later as it precludes any change to the number of buckets.
Handle errors in C by checking the return values of functions you call. Then react appropriately. If you need some sort of `finally` construct, consider the following design pattern (assume `foo`, `bar`, and `baz` allocate some resource): if (foo() == -1) goto fail0; if (bar() == -1) goto fail1; if (baz() == -1) goto fail2; /* success path here */ return (...); fail2: free_baz(); fail1: free_bar(); fail0: free_foo(); return (...); /* failure */
When I was learning C in college 2 years ago most students used vim or code block i used Xcode and it was amazing, it helped me to write code faster But I always compiled ansi c to make sure it is bulletproof we used gcc for that 
Seems like you didn't understand what I was trying to say either.
wdym? you can `realloc` it provided it is on the heap. Clients shouldn't assume its address remains fixed, so storing the address of the hashtab is no-no. That's a disadvantage, yeah. But it's the same with many dynamic array implementations i've seen that pack the data together with a header.
**Opaque pointer** In computer programming, an opaque pointer is a special case of an opaque data type, a datatype declared to be a pointer to a record or data structure of some unspecified type. Opaque pointers are present in several programming languages including Ada, C, C++, D and Modula-2. If the language is strongly typed, programs and procedures that have no other information about an opaque pointer type T can still declare variables, arrays, and record fields of type T, assign values of that type, and compare those values for equality. However, they will not be able to de-reference such a pointer, and can only change the object's content by calling some procedure that has the missing information. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
I don't think I'm smart enough to grok this.
I mentioned that. There is a trivial fix though: add a level of indirection. 
Yeah, but then there is no need to force dynamic allocation of the structure.
well you need to try to install it, and then you need to use clang.exe instead of cl.exe to compile with if you use the command-line like I do. 
The comma was a typo 
&gt; C definitely has exceptions While I agree that `setjmp` and `longjmp` are probably the most versatile way to implement try/except blocks, this statement is wildly misleading. C does not have exceptions. C provides tools that allow you to implement your own version of exceptions. It's kinda like saying C is object oriented. It's not, but if you really want to use some object oriented principles and have the patience, C provides you with a means by which to do that. In both cases, just because you can do it and there are common practices doesn't mean that it is by any means standard or that the language provides that structure for you. because it isn't and C doesn't. All that being said, I think your example code is significantly lacking in common practices. At the very least I recommend something more akin to Chapter 4 of *C Interfaces and Implementations* by David R. Hanson, but I've found more modern, versatile, and most importantly free [examples floating around the net](http://www.di.unipi.it/~nids/docs/longjump_try_trow_catch.html). Hope that helps.
You're missing a comma and causing undefined behavior by having a format specifier but no argument for it. Your compiler isn't warning you about this?
In your opinion is there a reason to use `goto` over `setjmp` and `longjmp`? Or is it more a matter of what you need for a given scenario? Generally I see far more support for `setjmp` and `longjmp`, but I think that has more to do with a general aversion to `goto` statements. Thanks in advance.
No, not a peep. Using Visual Studio Community.
I have it linked below, but just in case it gets buried, [this](http://www.di.unipi.it/~nids/docs/longjump_try_trow_catch.html) or a variant thereof is usually what I use. Hope that helps.
A longjmp is a non-local goto, the least structured tool in C. Definitely prefer goto and use longjmp only when you really need to jump across stack frames.
I never thought about it that way, thanks!
If you really can't make up your mind, just do both, and let the user pick which they want: hashtable_t *create_ht(size_t nelm) { hashtable_t *ht = malloc(sizeof(*ht)); if (NULL != ht) { init_ht(ht, nelm); } return ht; } You do need to think carefully about the names that you use, though. The opposite of "create" is usually "destroy". The opposite of "init" is *also* usually "destroy". You'd need to change one or both of those pairs. My company uses "ctor/dtor" rather than "init", which then lets us use "create/destroy". Alternately, you might prefer verbs like "new", "free", or "delete". Oh, and you need to figure out whether you even *need* a destructor (or whatever is the opposite of `init_ht`). Oftentimes you don't, as a C struct can usually just be freed and forgotten about. But it might be useful to have one that would either destroy and free all the objects that the hashtable contains (if it would know how to do so), or perhaps just assert that the hashtable is empty.
`operator new` may call malloc, but there are no guarantees in the standard. But that's missing the point regardless. `operator new` throws if the function was unable to allocate memory, and placement new constructs an object. Unless you specifically want to decouple memory allocation and object construction, you shouldn't use malloc. If you want to, there are rare, but very valid uses-cases. For example, in low memory conditions you might rather choose to free some other memory if malloc returns `nullptr`, and then reattempt. Another example is relocating types using `memcpy`, where you need raw buffers without initialized values.
I typically wrap the pointer into the type itself. For instance, I would, in the source file, declare a struct struct hashtable_s { ... }; and in the header file use the following typedef typedef struct hashtable_s * hashtable_t;
Thanks. Do you really use this in production code? I mean it has a Duff's Device, you can't nest it, it does seem a little esoteric. I did mention exceptions, but I presume they're not required for robust error handling, meaning in C you'd have to apply certain design patterns and be disciplined and rigorous about it. I'm not one to consider goto harmful, unless a better construct is available, so I don't mind using it, however I don't like to repeat code, because that's inefficient and it invites bugs. So I guess I'm not really looking for a way to bolt exceptions onto C, I get that you can sorta-kinda do it, I'm more looking for how C programmers solve it using C concepts, what are the strategies they apply, maybe for example by saying: "don't allocate and process and deallocate in the same function, these are separate concerns." My point is, I'm thinking that you can't improvise this stuff for every call you make, because you get a combinatorial explosion of possible double-frees, use-after-frees, memory leaks and other nasty surprises.
My understanding was that this release was supposed to include the retpoline stuff, but I can't find anything in the changes about it. Can anyone c/d?
This is basically what seems to be the norm, and when cleanup needs to be done immediately, put the cleanup code in a function that can be called from either the success path or the error path?
Yes. This is possible, too.
Yes. This is possible, too.
GCC(and Clang) has this great printf format and argument checking that would catch this.
GNU yeahhhhhhh
What if you don't want to malloc
Two comments: the `_t` postfix is reserved. With this design one has to go through an extra pointer for lookup.
Huh. Didn't realize that any suffixes were reserved. I knew about leading underscores, but not this. Thanks for the tip. WRT your second comment, that shouldn't matter, no? That doesn't effect the interface, and an optimizing compiler can easily mitigate any small loss in performance. 
I have used this in production code, though the more I'm learning the more I think there's some stuff I may need to go back and fix. Previously I had thought it would be sufficient and reasonable for most any error handling, but I'm definitely leaning away from that now. That's not to say it doesn't have some applications (if you need a try/except in my experience it will probably look something like this) but there are simpler methods of error handling that use less overhead, like u/FUZxxl's `goto` example, and will be just as if not more effective. I suspect if you need something more robust than these it will depend largely on your use case, environment, etc... Sorry I can't be more help.
&gt;The first gives them a lot more flexibility in where the data is stored (stack, heap, data) since the constructing code doesn’t need to care able where the memory lives. What would the reasons be for storing it anywhere other than the heap?
Turns out that was exactly what was happening because OP was missing a comma in his actual code.
yet i got downvoted
No. The meltdown/specter stuff broke way too late to make it into this release. I think there's been some relevant commits in the gcc 8 branch. 
The first is a sort of constructor function too, except it doesn't allocate. I don't really see your point.
Thank you! I promise I was planning of freeing everything when I was done with those pointers. I guess I just wasn't thinking about what was going on conceptually in order to recognize what exactly I was doing. Pointers and memory allocation are still tricky topics for me! I will definitely try valgrind as debugging via print statements hasn't been going so well for me...
Here is a js implementation: https://www.movable-type.co.uk/scripts/sha256.html, the page includes the source code. Should be easy enough to implement the same in any other language. 
Or you can link [the official repository that is written in C already.](https://github.com/openssl/openssl/blob/master/crypto/sha/sha256.c)
Hi, Aaron Gifford maintains an open source implementation here: http://www.aarongifford.com/computers/sha.html
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [openssl/openssl/.../**sha256.c** (master → 3e524bf)](https://github.com/openssl/openssl/blob/3e524bf2d1748f6757c1f64d63779d4d04f7a859/crypto/sha/sha256.c) ---- [^delete](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dt97t1r.)
`&amp;a` is the address of `a`, not its value.
What output are you getting exactly?
1. You should really get a text editor more useful and capable for programming. [Notepad++](https://notepad-plus-plus.org/) is a good start. 1. `scanf` takes pointers; you're giving it an uninitialized value directly, so `scanf` is going to write the parsed integer to *whatever the value of r happens to be*, which is almost certainly not going to be r itself. Call it as `scanf("%d", &amp;r);`. 1. `printf` does NOT take pointers; you're giving it the address of `a` to print as a floating-point value, and the address is almost certainly not going to have a bit pattern of a float. Call it as `printf("Area = %g\n", a);` 1. Unless you have specific reason to use `float`, prefer `double` over `float`, and in this particular case, over `int` as well. 1. It's not 1989; you don't have to declare your variables at the top of a function and fill them in later. This is a great way to forget to initialize them all before use, and accessing an uninitialized variable is how programs break. I suspect this is what you're seeing, but given that the two errors I describe above both induce Undefined Behavior, there's really no way to even speculate about what's happening. So, here's a correct version: #include &lt;stdio.h&gt; int main(int argc, char* argv[]) { const double pi = 3.14; printf("Radius: "); // Declared directly before use double r; scanf("%f", &amp;r); // Declared directly at use double a = pi * r * r; printf("Area = %f\n", a); } 
After two instances of undefined behavior? Nothing meaningful.
Main has to return an integer as it's declared as an integer. Add return 0; before the last brace in main.
Add `/Wall` to your compiler settings; poke around the Build menu I believe?
Crucified.
~~Javascript~~ C is so fucked up you can get it to say that the sky is green, the moon is a giant Camembert and pigs regularly take to the skies, just by asking the wrong questions. The same goes for most ~~duck~~ weakly typed languages. Computers will do what you ask them to do, and many languages are abusable. 
Thanks for actually answering the question. Why this dude would link to a js implementation on a C subreddit is beyond me.
Still it improves readability so it is not a bad thing to have.
well that was fun
There's an implicit `return 0;` at the end of main() these days.
Things have gotten better (since they stopped getting 9k in funding a year, and started getting sometimes even 100 times that), but... There's so much wrong with OpenSSL. [OpenSSL is written by monkeys](https://www.peereboom.us/assl/assl/html/openssl.html) [More context](https://www.reddit.com/r/programming/comments/9zprk/openssl_is_written_by_monkeys/) For a simple hash function, use another implementation. There are many good ones.
A few additional notes: 0. It would appear that I linked to a file within the project rather than the project itself. I can't see how to change the link in the title, so I will leave it as is. My apologies for the inconvenience. 1. There is a notable lack of comments in my code. This is because this was meant to be a quick solution to the K&amp;R exercise, so I didn't rush to add documentation. The purpose of functions should be clear from the names provided in the associated header files.
DEV C++ is OK.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [LoupVaillant/Monocypher/.../**optional** (master → 93e89bf)](https://github.com/LoupVaillant/Monocypher/tree/93e89bf0a34df28e51e61da2fceba5f41fb17c98/src/optional) ---- 
You should pick one of C and C++. The two languages differ quite a lot in how people write programs in them.
Nice article but it should really clarify that most of the stuff it discusses is GNU make specific. For example, both SUNpro make and FreeBSD make behave significantly different with respect to what automatic variables are set and what their values are.
That article is not about C. Not even the JNI example is about C. Removed.
I don't know about any online courses that uses C or C++ as language of implementation, you could however try following the one you are currently enrolled with the help with one of Sedgewick's books. If i remember correctly has written one for C++ and one for C
You only need C...forget everything else haha
This one looks comprehensive: [Data Structures and Algorithms in C++](http://www.udemy.vip/data-structures-and-algorithms-cplusplus-for-interviews). If you take it, share your experience one you complete it.
Calling any statement (like storing function pointer in an array) before `main` can be done with a function attributed `constructor`
Like it's been stated, it's a memory leak, but why are you using malloc anyway? It's a void function so it's not returning any pointers to those char arrays you've assigned to the heap so there's no point. You could do what you're trying to do with just normal fixed-size char array buffers.
I always use [Brad Conte's implementation](https://github.com/B-Con/crypto-algorithms). It's public domain and ready to drop into any project. 
[xpost from /r/programming](https://mort.coffee/home/obscure-c-features/)
Do not blog spam.
Sure I can C's type system is barely existent and can be gaily suborned with a pair of parentheses. Predictability doesn't mean anything when `void*` exists. C's type system doesn't have strings or arrays, let alone objects or enums. JavaScript doesn't have enums either, but I'm not here to defend JS. JavaScript doesn't randomly decide you forgot a length counter or a null byte and depart the buffer. JavaScript doesn't silently truncate numbers. I write C for a living; how much would you like me to go on? 
No i'm reffering to [this book](https://www.amazon.com/Algorithms-Parts-1-5-Bundle-Fundamentals/dp/0201756080/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1516984464&amp;sr=1-3&amp;keywords=sedgewick) and also [this one] (https://www.amazon.com/Algorithms-Parts-1-4-Fundamentals-Structure/dp/0201350882/ref=sr_1_7?s=books&amp;ie=UTF8&amp;qid=1516984502&amp;sr=1-7&amp;keywords=sedgewick). Yes they're little old, but still valid ! If you want something more recent you can try [this](https://www.amazon.com/Data-Structures-Algorithm-Analysis-C/dp/013284737X/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1516984607&amp;sr=1-3&amp;keywords=data+structures+and+algorithms+in+c%2B%2B)
Nice thank you 
Unless your library is recompiled every single time the other code is, this won't work. C doesn't encode the types in the function names, so you'll create a situation where the library expects one type but the code calling it provides another - aka Undefined Behavior. Your CPU will catch on fire, and a singularity will be formed that can only be stopped by an Alchemist with a true philosopher's stone. IOW: You're trying to solve the wrong problem, or you're solving it the wrong way
To clarify, the libraries in question are not intended for standalone delivery, but rather, components that can be used in superset projects - like in embedded systems.
Simple and funny way of explaining. Great video. PS:Atom's colorscheme are alwats top notch!
None of your examples support an argument that C is superior to JavaScript, only that they are different languages. Your initial position, "it's pointless to ask how to make a nonsensical statement, that was initially asked about JavaScript, in C, because JavaScript is bad and C isn't," doesn't hold, because both languages freely and directly provide ways to make the nonsense legal. JavaScript's mechanism for doing nonsense requires mucking with types; C's with text. They're still both nonsense, and calling out JavaScript as being awful because it does type coercions is hypocritical at best when C also has type coercions. We can throw examples at each other all day; the point remains that C is still weak and abusable, if by different means than JS.
Just pick one type and stick to it. This kind of shenanigan rarely actually makes the library any better, usually it just makes it more complicated to use.
This guy is badass thanks for sharing 
That's what was throwing me off. I downloaded the community one but there was no student email requirement so I thought maybe chose the wrong version. 
What does your library do? Containers (e.g. set/map)? Generic algorithms (e.g. sorting)? Or others?
This whole channel is fantastic, and very helpful. Thanks!
#include &lt;stdio.h&gt; #define 'KILOTOLb' 0.453 int main(void) { float kilo, lb; printf(" Enter your wieght in kilo\n"); scanf("%f", &amp;kilo); lb= kilo * KILOTOLb; printf("%f lb= %f kilo", lb, kilo); return 0; } 
Yes. You just... do the math int miles_to_feet(int miles) { return miles * 5280; } Your problem, besides your syntax being incorrect on your `#define`, is that .453 is the coefficient to convert pounds to kilograms (i.e. 1 pound is .453 kilograms), not kilograms to pounds, which is 1/.453, or ~2.2
They are, for string literals, you're not using a string tho...
I have tried them all. Always fall back to vim
Read the OP again.
Sure.
What do you mean by cross platform in the context of low end smartphones? What OS runs on the devices you are targeting?
Fork creates a new process. Good for parallelism, just like pthreads, but harder to synchronize than pthreads. Google "thread vs process" to get much more detail. Clone is a Linux implementation detail it seems (although it can be used if you only want to target Linux). Stick to either forking or pthreads, based on if you want multiprocess vs multithread.
[imgui](https://github.com/ocornut/imgui), maybe? I'm not really a GUI programming expert but AFAICT it has minimal dependencies, is easy to integrate, and easy to use.
!redditgarlic
!redditgarlic
!redditgarlic
[**Here's your Reddit Garlic, foomly!**](https://i.imgur.com/dYGNvmR.jpg "Reddit Garlic") /u/foomly has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
[**Here's your Reddit Garlic, B-Elgy!**](https://i.redd.it/0cy3nmwrucwz.jpg "Reddit Garlic") /u/B-Elgy has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
[**Here's your Reddit Garlic, mrlinhhandsome!**](https://i.redd.it/0cy3nmwrucwz.jpg "Reddit Garlic") /u/mrlinhhandsome has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
[**Here's your Reddit Garlic, talalshindo2!**](https://i.imgur.com/dYGNvmR.jpg "Reddit Garlic") /u/talalshindo2 has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
[**Here's your Reddit Garlic, Shred_Durstt!**](https://i.imgur.com/etMqixE.jpg "Reddit Garlic") /u/Shred_Durstt has received garlic 1 time. (given by /u/pythonETH) ^I'm ^^a ^^^bot ^^^^for ^^^^questions ^^^^^contact ^^^^^/u/flying_wotsit
You are right! I missed the “library“ part! Thought OP was asking about GUI. Sorry for that!
Fork is used to create new processes. Pthread is used for multithreading. The main difference between processes and threads is that threads share a single memory space where as processes have each their own memory space. Clone is a linux specific low level system call and can be used to either create processes and threads.
Please stop that.
For the next time: Please always submit links as link posts. If you want to add some commentary to the link, just add a comment to the comment section. Do not post links as self posts. That's not how reddit works.
get a book...
 // turn A into b #include &lt;stdio.h&gt; void main() { char c = 'A'; printf("from %c ... ",c); c=c+33; printf("to %c !\n\n",c); printf("(sorry couldn't resist)\n"); } 
wow, over-engineered as fuck. not to mention it uses stuff well beyond ch1
TLPI \m/
probably want to look in stdint.h for portable types such as int32_t that would be mapped to either int or long depending on the target platform. that is, if the toolchain provides such a header
Thank you very much for your feedback. My initial thoughts about the problem were that the logic could be simply implemented as a DFA, running with appropriate side effects (keeping track of delimiters, etc.). However, keeping track of each of the side effects in main.c would have been tedious, so I separated the logic into separate files - one to handle creating a DFA from a string (this way, the delimiters in question can be changed with just a few minor edits to main.c), one to handle storing previous positions of importance in the source file, and one to encapsulate the logic for each delimiter. To this end, I let myself "cheat" and use prior knowledge I have of the C language. Though, I still consider myself to be a novice, so I decided to try reading through K&amp;R for the first time, as per the suggestions of others on this forum. However, that being said, I am curious as to what you would recommend I take into consideration for future programming. Was it a mistake on my part to abstract out the logic for delimiters so that any arbitrary pair could be used (for instance, main.c could easily be altered to support HTML comments if necessary)? Generally, do you think one should program to the task at hand, or should one consider potential reuse for their code in future projects?
https://en.wikipedia.org/wiki/Fork_(system_call)
What a great attitude.
You're setting yourself for a much harder task than the exercise asks for. You're right about using a DFA, but that can be constructed a priori: as a switch or using transition tables. There are no side-effects to it: you just count brackets and push them on a stack when you're outside comments/strings/char literars. If when encountering a closing bracket the last one pushed on the stack isn't of the same type then there's a syntax error. At the end also check you're in the 'outside' state and that the stack is empty. That's all there is to it: no need for dynamic memory allocation, structures, pointers. Arrays, processing input a char a time and switches/loops are all that one needs to know about to solve this exercise. &gt; Additionally, would you recommend that I "unlearn C" while working through K&amp;R, in the sense that I should not rely on previous knowledge of the language and stick to the material that is covered up to a given point? Of course not. But it's not absurd to assume the exercise is meant to be solved using only things described up to that point in the book. 
So this is intended to replace cmake/make in the build process correct? I’m new to the c world hah Looks really interesting I’ll have to give it a go.
This is a great start and hits on an interesting topic. many, many years ago when I was coding Pascal in college, I wrote the same program, but went one step further to implement code to find the key length for a Vigenere cipher based on the Friedman test that I read about in David Kahn's "The CodeBreakers." Link to Friedman Test: https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher#Friedman_test. Basically, if you take your cipher text and cut it in half then superimpose one half over the other, you can then check to see how many matching letters you get. If you then bump one half over by one and check again and check the number of matches, you will find that the number of matches will go up when you have the two halves synchronized as far as being enciphered with the same keyword letters: FISHFISHF|ISHFISHFI Key SENDTHECA|SHTODORIS Plaintext XMFKYPWJF|AZATLGYNA Cipher It's not too hard to write the code to implement the test
Note: I'm not a expert at [Vigenère cipher](https://en.wikipedia.org/wiki/Vigen%C3%A8re_cipher). I also didn't test the application (the original nor with my suggested changes). In your `viegener` function: * Instead of allocating inside the function, accept a pointer that you can write to. (You don't have to accept a size parameter, because it is implicitly `strlen(message) + 1`) * `malloc(sizeof(key))` is wrong because `sizeof(key)` will return the size of the *pointer*, which on my machine is `8` (64-bit pointers). So on longer messages, you will write out of bounds. * You expect the size of the `key` and `message` strings to be equal (and even `strrepeat` it if they don't match in size), but couldn't you just use `key[i % strlen(key)]`? So you don't even need the `strrepeat` function and save some memeory. (And cache the output of `strlen` so you don't need to call it every time, kinda like you did with `key_message_size `) * You try to `find` a letter as a index to an array of the uppercase english alphabet. However, C guarantees that the letters are in order, and letters are basically just numbers. So instead of `find(CHARACTERS, key_value)`, you can just use `'A' - key_value`. * For `'A'`, `find` returns `1` (aka it starts with 1). So a key with `'A'` and a message with `'B'`, it does `1 + 2`, which is `3`. Used as a index to the `CHARACTERS` array, it is `'D'`, but it should be `'B'` (So it should do `0 + 1`, which is `1`). So `find` should preferably return a value beginning with `0`. * `CHARACTERS[cipher_text_index] &gt; 26 ` is basically true, since in [ASCII](https://en.wikipedia.org/wiki/ASCII) (the most common encoding), the value of `A` is `65`, which is already over `26`. I think you wanted to default invalid characters to `A`. * Invalid values would probably produce garabage, you might make sure you're operating on letters with [isalpha](https://www.tutorialspoint.com/c_standard_library/c_function_isalpha.htm). If you don't, then you can just simply copy it to the target string. `main` function: * `printf("%s\n", cipher_text);` can be "optimized" to `puts(cipher_text);`. * You basically have some code repeating to match the key with the message. If you're using my proposed changes, this isn't needed anymore, but a way to "fix" this is by introducing a new pointer, that is by default `NULL` and always `free` d. If the key and message length don't match, you set both `key` and the new pointer to the same pointer, so when that happens, the correct pointer is `free` d, otherwise `free` with a `NULL` pointer just does nothing. Like: char *alloc_key = NULL; if ( strlen(key) != strlen(message) ) key = alloc_key = strrepeat(key, strlen(message)); /* ... */ FREE(cipher_text); FREE(alloc_key); return 0; Note to your (now obsolete) `find` function: for ( int i = 0; i &lt;= 26; i++ ) { This for-loop goes to numbers 0 to 26, or 27 numbers. You're accessing one past the array if it isn't a letter in the array. Change the `&lt;=` to just `&lt;`. Note to your (also obsolete) `strrepeat` function: * The `count` parameter is confusing. It suggest it it the amount of repeats to do, yet you do `malloc(count)`. In `main`, you pass `strlen(message)`, so if you fill it with a string of that size, you're also missing the `\0` terminator. * In the loop, you do `strlen(repeat)` *while* constructing the string. Because you don't terminate it correctly yet, this is undefined behavior. * In the loop, you can also use the same modulo-thing. * You never write a closing `'\0'`. Also, you never check the whenever any `malloc` calls failed, so your application could easily crash if there is not enough memory.
wow, am so happy, you took time to point this out. I will save this answer for future reference :thumbsup:. You are the best
I see. Thank you for your insights.
It sounds like you're getting confused by all the different meanings of `*` depending on what context it's being used in. `char*` very much is the type of a in your examples (there's also no need to cast malloc() and calloc()'s return value) ... Personally, in a declaration I put the \* next to the variable, because its less confusing given this unfortunate quirk: char* a, b; Are a and b the same type?
While I agree with you that "*" is part of the type, so it must be closest to char, the problem is that according to C grammar rules the "*" binds to the right, not to the left. That means: `char* a, b;` Declares **only one pointer**. If you want to declare too pointers, you have to do: `char *a, *b;` That's probably why many people prefer to use the `char *a` form.
I mean, it makes sense in a very twisted way. Feels a bit IBM-esque if you ask me.
Would've been nice if we used postfix instead of infix for all decls. Change function decls to: &lt;return type&gt; '(' &lt;parameter decls&gt; ')' &lt;name&gt; eg: int(int) foo // 'foo' is function that takes an int and returns an int and array decls to: &lt;elements' type&gt; '[' &lt;size&gt; ']' &lt;name&gt; Then declaring a pointer to a type `T` is as simple as appending '*' to `T`. And this works in all cases. Here are a few examples: int *a ==becomes==&gt; int* a //pointer to int, no change int *a[] ==becomes==&gt; int*[] a //array of pointers to int int (*a)[] ==becomes==&gt; int[]* a //pointer to an array of ints void *(*a)(void *a) ==becomes==&gt; void*(void*)* a //pointer to function that takes 'void *' returns 'void *' double (*(*a)())[3][4] ==becomes==&gt; double[3][4]*()* a //pointer to a function that returns a pointer to a 3x4 array of ints No need to place extra parentheses because the postfix notation defines the order implicitly. It looks odd at first for functions, but it makes complicated decls a breeze to parse. The 'right-left' rule still stands, it's literally right-to-left parsing :P
&gt; However, C guarantees that the letters are in order Strictly speaking this is only true for digits (ref. 5.2.1-3) and letters could potentially be out of order. In practice, character literals will virtually always be ASCII, and therefore in order as described. &gt; `printf("%s\n", cipher_text);` can be "optimized" to `puts(cipher_text);`. Compilers will usually do this on their own (in hosted environments), so just stick with the form that's clearer, or easier to maintain. 
That's basically how the declaration syntax in Go works, except their syntax is the other way round which matches the way the type is pronounced. A *function taking a slice of integers and a pointer to a byte returning a string* is typed `func([]int, *byte)string` in Go.
I think I'm too young to understand what you mean by that xD By the way, the thing is that if you want to take this statement void *a = malloc(sizeof(something)); and divide it in two lines, you would write: void *a; a = malloc(sizeof(something)); so the assingment to a pointer doesn't get the asterisk if it's on a new line, while it gets the asterisk if it's on the same line of the declaration. At the same time: int *a = 3; has no point while [...] *a =3; is correct. if you instead use the asterisk next to the type int* a = 3; is as wrong as writing int* a; a = 3; quite the mess!
But then `int[2][5] a;` declares `a` with 5 rows of 2 each, whose last element is accessed by `a[4][1]`, this would be extremely confusing having to swap indices around between declaration and access. Personally I like the "declaration matches access" method that C uses. You have to learn the access anyway, so it kills 2 birds with 1 stone . 
Came here to make this point. Binding it to the type will make the assumption all following variables are pointers
Damn, right. Then you gotta change order to prefix, so you end up with Go's decls FUZ mentioned.
&gt; &gt; However, C guarantees that the letters are in order &gt; Strictly speaking this is only true for digits (ref. 5.2.1-3) and letters could potentially be out of order. In practice, character literals will simply be ASCII, and therefore ordered as described. So it's perfectly reasonable to just assume they're ordered, but it's not guaranteed. Oh, seems I just mis-rememered it. An alternative to the array of the alphabet would be using a string (`char alphabet[26] = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";`) instead of the somewhat annoying `{'A', 'B', 'C', ...}` &gt; `printf("%s\n", cipher_text);` can be "optimized" to `puts(cipher_text);`. &gt; Compilers will usually do this on their own (in hosted environments), so just stick with the form that's clearer, or easier to maintain. Again, this is true, but I still wanted to point out that the function exists. ([Even with `-O0` gcc and clang use `puts`][o3compilersputs]) [o3compilersputs]: https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQAGAOgA4BOAKwB2IQEZ%2BkqVNIArEGNKtmtUAH0NyUgGdUAV2LIOAcgCkAJgDMeWslZ6sAalOWAwtoL5U3BC%2BynOAEELa1t7Jxd3AmIbYB8/AOCrGzsHTGc3D3RWPAAjeMt/IJCU8PTI5AIATwAHTAKipNDUiLdmbW1MYgIGxL6rLCobdIAxACVsbAgagEpnYQAhZ0FXRMd1xypiTEwoWZmXJY3TFbWNmoyAEUcAOQBVABkHw431k9Wgt%2BFLvqDkBGYxEcrgAEoExoFXAAVbBjBgnBbmABsJ2uLjR5nMgQWrku2BGAHEQQBJABSAGkHgBZG4AeQACgBFOFQu4ANQA6gANACaAC0LOZDol/oDHAAqRweYjbOrMAgQUVAyUAa0wVVIjhsBEcaD09AOlgWIoByscADc8JhgJhaF1FaaJY41RrdY7JQBbTAdZg2w3G4pBbWOD3MGwQYOA4BaN1iyVR80I1FzUyLX6BdZ4KiOCCOKPIRxgMDoxyWRwptOfDZUGoxehUCBZLpkZyY4m0bR6KhDZBW%2BiOWh6D25LqOVDZqND20EQX%2Bs7rbYEAy0RxiYVV1M/DdVpVOl1XPPEYCJwQLNeCH5Gs67z3e7S%2B8qWa4JhFCi/r4I7926vA1BBdNQCEwAAPHUS3uJ4PzOLMcylaJ2FoCAXTmIsS2lBCIC9H0/XLeYAwzDZ9zQ6JZUweUkPVTV0NtTC7wfGY5yrdZez/ACgNAg9LWtW17RdUgsPvP0P1eWttQbQULEEbR3loQVNRY/9iEAkCCEYgj1nGSYKKqNTXk0qYFLYlTdI2Rdl0cThhPmLcCOvX9FOUjiSy4m07WIbT%2BLooSryrUT6wgCTzCkmS5J/VilPY1SrP0xV7KM0CTLM4gV0snzgm%2BdMbzgmVMDlBUsr4rV%2Bz1A08PTdZ2k6bpc33VCn1uR4HnLKCvzjRxSPlA9Q1YVhUGQRV9ANFqCODWQD1S/C3irGggVzYM8HGl4FsiXVBrAo0tQsY1zCWCtJuOJitWzGr1QRPBUSuEswDMFZOGu5rDszRa0vnI7YOoxCOtUy76pKnUDkexxcm2ZgVSsqb1Pa3KyJnU9ZC2hGLwPF0ztRKzN3KqGl2SqG8qgjLA0CYMhlodAHTFNg/2YEcCGk09UXkx1zTYPRMD2s4zhm2D5uepZlrcEtkSWhGdtw1N9szY681YKmabphZzqR9FnJZ9J2cBpKV2W0W1zS14MY3AnbKrTXHAAWl1/CDc/G2spcnj3IKyjYzNAT6LK7cCO0PAAC9MEA511TUN2bTUb2/YPD7tLU69v0MiKVK6thev68PMHHaOTM5khuf7fnrgmrUMlcQOqmDrz/bT4Wdq2sXK0h17dxdNRmfsR9riIPQajqdyUdPRXLhM5jHRD/3W9Zg9O%2B7%2B1R9Ri8h%2BcQ7g2bmwsGAg8SbJ0FwUhGE4U1Zvx7Z8Gip1Ue1FXkCN9XiBt4haFYQYTVz6PmOl%2BKuKE9Ai/SavksTrLpfdetcQwVx/mvMWQVHBCz1gdSG8dHKwwVhdEsd9d6PwRAgyK4CQIoMKNApEGQRjAjBPfPe8JTxYJUjg4CF0QAkJ3g/OECJLLvlgRDL4NkzimyoaBdGxQjbGBmEoEAxhBDGFILQURnAJGoFESXXQBgjCtksGICRBBpFCOESqEAqjuCCE4GIXgqiDFGJMYoVgoiAAsEiPQKE4JwSRmjSByOMBI7QXBSAaOMDI4RcBYBIDQB6GoeB2BkAoANYJoSugoDsCoYABjHFDFYEBYgHiIC5GcbkGwgIqiiLUaQIJXp6C0loKwPJPiJFYFDKodgzj8DbEqHgc03pnEgUwMgPQQF8kSO1JgSxlSvExDsZU4RyhVAgA0GoLQORcgeMgMI1ANQCB4DoB44wZtaQyJ0PoQwHAxBjNEeIpxgzXHAV4EiM2SIrG6nGcARwghuA8E4DmXAhAc4hEUMCVAUSwkqIOcCdRmiGKkB0eYfg3BzDCCsZwa5lgkSCF4JwaFxiRHGBsSc7Zrj3GeO8b40g/jEAoB%2BSEsJ5BKBBNJTE5AwBhDmFIMk1J6TMmDOybQXJPTCk/OKQQUp5T6mYBqcAOpgyGkdJWS09Z2z2mdO6cYApfSBnbOiHgEZ%2BK7mTM0EoPI8yICLOWasjsojNnbMUXshQhyxESKkac0R5zLnXMcNGAswhIWvPwEQIEnzNSuBJdEr1VhzBzFcEC0Z2jdEQsxFYsQnBo2WCsEiGNFjrHWucdinQuLgWWvMKm21bivFZtIC0tJhqQBWKAA%3D%3D
Makes sense :)
 &gt; "char*" is not an actual type Yes, it is. A pointer type describes an object whose value provides a reference to an entity of the referenced type.
the best way i saw it explained was "the contents of *a* have type of char, therefore *a* itself is a char pointer"
`clone` is really useful in theory—both Pthreads and `fork` (also `vfork`, blecch) are implemented on top of it in Linux—but it’s a little difficult to use in practice because it doesn’t set up a lot of the more traditional POSIX thread niceties like `pthread_create` does. You might not need/want that stuff, but if it’s missing it becomes more difficult to use other software (e.g., libraries, or anything involving TLS sections) unless you set all that stuff up yourself and basically make it compatible with glibc-Pthreads. `fork` is fine for larger-granularity parallel processing like batch compilation or what have you, but it makes it much harder to do fine-grained stuff without memory sharing tricks, it makes it harder to coordinate between processes quickly, and it makes context-switching more expensive in most cases. If you’re sharing most stuff across processes, you’re also raising kernel memory usage significantly because it can’t share stuff like file descriptor tables, signal handlers, page tables, memory maps, etc. as easily. If you’re doing really fine-grained stuff, you’re often better off just starting up a fixed batch of worker Pthreads and using your own scheduler queue(s), or even doing scheduler queue(s) on top of an OpenMP `parallel for`.
You Need to initialize the va_list Here this is a very basic example https://www.tutorialspoint.com/cprogramming/c_variable_arguments.htm
And then the va_list is passed to vprintf
I'm still not sure how I would pass the va_list in though since printf accepts the dots?
The va_list is passed to vprintf http://en.cppreference.com/w/c/io/vfprintf
No, have a look at the link you need to iterate through the arguments 
Also, I recommend against casting calloc or malloc, it's bad practice.
If I'm declaring two pointers, I would do something like: char* a; char* b; I do this because it is easier to see what type 'b' is if you have a long string of declarations. White space is free, so use it.
Is the class going to be based upon, and expect the usage of, the Windows version of Visual Studio? If so, then I'd recommend setting up a VM on your mac and using the Windows version of Visual Studio. I do everything in Linux, but even I have a Windows 10 VM with Visual Studio for such situations. 
You're using a function named printf() that's not the standard one? Err... that doesn't sound right.
I means it (my app) can run smoothly on old Android phones (512GB Ram, single core 1Ghz CPU, 8Gb memory...), old iPhone (3GS, 4, 4S...), slow expensive (to users) network connection (2G, 3G) in rural areas such as China, Vietnam, Cambodia, India...
I would have done that #ifdef LAB_DEBUG #define debugprint(...) printf(1, __VA_ARG__) #else #define debugprint(...)
I saw Dropbox, Mailbox having the same approach as you described. Since I have to optimize for very low-end smartphone (512Gb ram, single core 1Ghz CPU, 8GB memory and old android phone; iPhone 3GS, 4, 4S...) in expensive (rural areas in Vietnam, Indochina, China, India, Africa ..) and low (2g, 3g) network connection. So, I have to reduce both size of app and its data consumption while improving performance.
Hi, what do you mean? Please elaborate on my situation. Thanks
Roman equivalent of integer number in C Run this online, online running link is provided in the blog. http://problem-discussion.blogspot.com/2018/01/roman-equivalent-of-integer-number-in-c.html
Note that the correct spacing here is const tidyLocaleMapItem *TIDY_CALL getNextWindowsLanguage( TidyIterator* iter ) as we have a `TIDY_CALL` function whose result, when dereferenced, has type `const tidyLocaleMapItem`.
No blog spam please.
Old-school? As far as I know, any decent C programmer still ends up writing code like this. 
But a decent C programmer should write easily maintainable code by writing easily readable code or at least comment the code.
exactly the point I was going to post! I always do *n because of the declares only one pointer issue....
here's an example: void glPrintf(float x, float y, font_t *fnt, const char *fmt, ...) { char text[256]; va_list ap; va_start(ap, fmt); vsprintf(text, fmt, ap); va_end(ap); basically this is the var args bit of an OpenGL version of the normal printf the text variable ends up containing a formatted string with the values specified...
I'd argue K &amp; R should have show both, because the *++s may have enlightened a number of people...
On Android, you may be worse off using C++ in terms of size, even worse if you are bundling large C++ libraries with your app. When building in Java (on Android), a lot of functionality is already built into the system and Java apps leverage that and tend to be smaller in size. I don’t think you will have size as issue with iOS :-). But still better to to build in C++ for the sake of common code base.
One big difference is that the "static int test = 1 " variable in void t1() is just in the scope of the function, no other function can see this value But the global "int test = 1" is visible for alle other functions, below the definition and declaration
Note that `test` in `one.c` has external visibility, so it can be used from other translation units. So it gets tagged as a `.globl` symbol. Other than that there is no difference: both get placed in the `.data` segment of the resulting binary. What's interesting though is that the local static's name gets decorated, as it can be seen [here](https://godbolt.org/g/PhbXrf). `x` becomes `x.1796`. What's interesting about this is that `.` is not a valid identifier char, so you can't refer to it with an `extern` decl even if you wanted.
Interesting, why is that? My teachers were vague about it and I can't find a good reference for this kind of style problems
I just use getopt() or getopt_long(). Screw writing my own option parser for each program. Though the pointer manipulation stuff is something any even halfway competent C programmer should be comfortable with, and it's more the point of the exercise.
It's a quote from the standard.
This is easy to read, easy to maintain and what should the comment say? `/* This code does what it obviously does. */` Of course, today, you'd probably just use getopt if it was available because it's faster to type.
woah, that's quite impressive. these days, i'd usually just use `getopt()` for something like that...
[removed]
The Plan 9 libc does something similar, though it hides it behind preprocessor macros. [at the end of libc.h](https://github.com/brho/plan9/blob/89d43d2262ad43eb4b26c2a8d6a27cfeddb33828/sys/include/libc.h#L727)
You are passing pointers to the values in your printf (using &amp;). Pass the actual value (without &amp;).
Nice philosophy xD
Stop posting this.
I program a lot in C++, but I don't think like that at all. And I can't really imagine anyone who is decent at C++ thinking that, C++ programmers are generally a lot more worried about types compared to C programmers. The creator of C++ also touches on this subject in a FAQ: http://www.stroustrup.com/bs_faq2.html#whitespace
You don't mention an OS or type of shared memory, but here's a few guesses: https://linux.die.net/man/7/shm_overview https://linux.die.net/man/2/shmget
atomic_flag_test_and_set() always uses the same memory order (seq_cst), so if you just stick with it instead of the explicit version there's no chance of an issue.
`/* you are not expected to understand this */`
Why do you spell it “MAN Page”? It's short for “manual page”.
You'd better wrap that macro in `do { /* ... */ } while (0)` or it's going to bite you in the ass.
From my `diff`ing of the output from `-S` with GCC 4.8.5 sans optimization, it doesn’t look like there are any real differences in generated code. There’s a slight difference in the label name and ancillary goop around `test`, but otherwise it’s the same. If you declared `t1` as `static`, you’d probably see some real differences, especially if you enable optimization. The only thing I can think of that *can be* different between one.c and two.c as they stand would be that in one.c, `printf` could potentially alter `test` (not that it would be a good idea; neither would it be a good idea to assume otherwise), so `t1` will have to reload and spill `test` in between calls to `printf`. two.c doesn’t need to do that—it can potentially cache the value of `test` in a register across the `printf` calls, since `printf` can’t see `test` at all. More generally, the compiler can tell whether variables are potentially accessed or used in some way if it puts the effort in, and how you specify storage class, scope, and access in your declarations can greatly affect what optimizations the compiler has available. Note that it’s not necessarily possible to determine whether a variable *isn’t* used/accessed; the compiler will hopefully assume that a variable might be unless it can prove conclusively that it can’t, barring undefined/unspecified behavior per language specs. E.g., altering a value in memory from a debugger or via an incorrectly aliased pointer might not actually change the value of the variable that supposedly lives in that memory, but the compiler doesn’t have to care about that because it’s outside the bounds of what the language allows. If you make a global, externally-visible variable like your first `test`, the compiler would assume that it can be accessed arbitrarily when control passes outside its “observation.” (A `volatile` variable could be changed at any point.) For example, before `main` is called, the assignment `test = 10` could be issued, which means its value upon entering `main` can’t be predicted. And as noted, the next iteration’s value of `test` can’t be predicted from the current value because `printf` could change it outside the compiler’s view. If you make a `static` global variable, the compiler can (theoretically) assume that, unless its address somehow escapes from the compilation unit, all uses of the variable must occur inside the declaring compilation unit. If you make a `static` local variable, the compiler can assume that, unless its address somehow escapes from the containing function/scope, all uses of the variable must occur in the declaring function/scope. The compiler has basically the same level of theoretical introspection into these two cases, since it can see everything inside the compilation unit at once; in reality, it’s usually somewhat easier to predict usage within a single function/scopre, since differences in argument or externally-scoped values can cause an explosion in the number of cases the compiler has to consider. If only the compiler is able to optimize things, compilation units are the outer bound for this kind of analysis, but with link-time optimization the linker can potentially make similar guesses as to access/use with respect to all LTO-enabled objects in the statically-linked portion of the final executable image. If LTO is enabled for everything and libc is statically linked in, it may be possible to completely eliminate `test` in both examples, and just pass values 1 through 10 to `printf` directly. It may even be possible to emit a single `fputs` call of the string `12345678910` to `stdout` instead, with no `t1` or calls to `printf` either.
It's completely unnecessary, and one more thing to edit if you change the type of the pointer. The canonical way to allocate memory is either foo *p = malloc(n * sizeof *p); or foo *p = calloc(n, sizeof *p);
The main problem I see in this code is that it uses assignments in the middle of a larger expression. A `while (1)` loop that includes an `if` -- `break;` would make the state changes much clearer, and the code would be more flexible.
Won't it stop at the first debugprint found?
Your use of `,##` is just fine for GNU-compatible compilers, but bear in mind it’s a GNUish extension that’s outside the bounds of the C language itself. If you’re going to use it, make sure you or one of your headers has issued an assertion beforehand about the compiler type with something like #ifndef __GNUC__ # error "this requires a GNU/-compatible compiler" #endif (I assume you’re not using Microsoft compilers for OS development, because of course. FFR, Microsoft compilers allow you to just do `,__VA_ARGS__` since they’ll [allegedly per Microsoft docs so who knows what really happens] chop off a trailing `,` automatically. They also treat `__VA_ARGS__` oddly in some cases though. Microsoft-“compatible” emulation modes in other compilers will not necessarily reproduce either behavior faithfully.) Also, the standards get a little wishy-washy on whether an empty `__VA_ARGS__` is permitted at all—most compilers only allow empty varargs as an extension—so #define debugprint(...) \ do if(LAB_DEBUG+0) { \ printf(stdout /*← angers the gods*/, __VA_ARGS__); \ printf(stdout, "\n"); \ } while(0) or something along those lines would be C99-compliant and portable outside the GNUniverse. C89 doesn’t support varargs macros at all, though you’d be hard pressed to find a compiler without a mostly-C99-capable preprocessor these days. Also, whoever decided to take a `FILE *` as the first argument to `printf` deserves a thorough bitching-out, or else shout “Have at thee!” and dramatically stab them through the orbital socket with a rapier—whatever gets the point across with sufficient force. Do not emulate their behavior outside of a masturbatory-experimental setting.
 unsigned int hexa; unsigned int hexa2; unsigned int comb; comb = (hexa&lt;&lt;32)|(hexa2&lt;&lt;16); hexa and hexa2 haven't been read yet. Do the calculation *after* you have something to calculate with.
You're using hexa and hexb before initializing them; that's undefined behavior and you could get all sorts of garbage as a result. If you fix that so you're shifting and or-ing valid values... What happens when you shift a 32 bit number (which is almost certainly the size of an int on your platform) by 32 bits?
it only returns the second input
Okay so i moved it before it prints out the merged results. Would the next thing to do be to seperate the shift and the merge or leave them together like it is?
The formula should be - comb = (hexa&lt;&lt;16)|(hexa2); You move the hexa digits to the upper 16 bits of the 32 bit integer, but you don't need to move the hexb. For example, if hexa = 0x1234, hexb = 0x5678, above formula will give 0x12345678.
Ah okay. With the new fix, how would i get it to print the decimal equivalent? It gives me a number that is not the decimal equivalent 
No, why?
Something is wrong because the deciaml at the end of the merge returns negative and not the decimal form of the merged hex. I changed the &lt;&lt;16 to hexa2 because the second input has to be the most significant digits #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main() { unsigned int hexa; unsigned int hexa2; int comb; //User enters first hexadecimal and prints the result printf("Enter a 4-digit Hexadecimal:"); scanf("%x",&amp;hexa); printf("The hexadecimal %x in decimal is %d\n",hexa,hexa); //User enters second hexadecimal and prints the result printf("Enter a 4-digit Hexadecimal:"); scanf("%x",&amp;hexa2); printf("The hexadecimal %x in decimal is %d\n",hexa2,hexa2); //Hexs are merged comb = (hexa)|(hexa2&lt;&lt;16); //Prints new hex and its decimal form printf("The new hexadecimal is %x ",comb); printf("and the new decimal value is %d\n",comb); }
I ran your code on this [C++ IDE](http://cpp.sh/3ikuv). It runs fine for me. What values are you entering?
I entered 1234 and then abcd
Its suppose to give me 2882343476
But you're printing out a *signed* int, with the last bit a 1. So it's a negative number. 2882343476 can't be represented by a signed 32 bit int.
Yeah I read that void* return types will adapt automatically. By the way, if you put it in two lines, you'd have to write int *p; p = malloc(n * sizeof *p); Which can be a good way to explain to students which is the number and which is the pointer
&gt; throws if the function was unable to allocate memory So what? Malloc will return NULL if it doesn't find virtual address or if it doesn't find memory if kernel is configured for deterministic memory allocation. Is throwing exception better and thus you're bring it up? &gt; a useful abstraction that you should generally use Yeah right. We're retards and strawsoup is saving us with these abstractions. C++ isn't a cancerous growth on C. C++ abstractions have always helped. Which is why we see projects like jenew, tcnew and we don't see shit like jemalloc or tcmalloc. &gt; Unless you specifically want to decouple memory allocation and object construction, you shouldn't use malloc. If you want to, there are rare, but very valid uses-cases. What! I guess what I'm working on and getting paid for must be really really rare work. &gt; For example wtf are those examples? Does anybody understand what (and why) he's talking?
Know what, I'm going to be very nice, and give you a quick crash course to C++'s objects, even though you've been nothing but rude and routinely thrown slurs at me. When you do the following: ``` std::string s; ``` It call's the constructor of `std::string`. When you do `std::string* s = malloc(sizeof(std::string))`, you're allocating memory for a string, but you're never initializing that memory: that memory is junk. Actually, C++ doesn't alloc implicit conversions, so you have to `static_cast&lt;std::string*&gt;` on the pointer (the point of the post, actually). To initialize it, you have to call a constructor, but you can't do it how you would in C. In C, you might do `int* i = malloc(sizeof(int)); *i = 5;`. In C++, doing `*s = std::string()` will invoke the move assignment operator, on a type that has not been initialized, which invokes undefined behavior. You want placement new, which would be something like `new (s) std::string();`. To shorten this, we can do `std::string* s = new std::string();`, which is a lot more idiomatic. If we call `free()` on this allocated pointer immediately, we fail to call the class's destructor, leading to a memory leak: all the resources held by `std::string` are not freed (although in actual code this is unlikely to lead to a real memory leak, as `std::string` actually uses the stack for strings below ~15 characters in most implementations, and then uses the heap). It gets worse. If we have have the following code: ``` void do_something(...) { char* s = new char[200]; compute_something(s); delete s; } ``` If compute_something throws, the destructor will never be called. However, if we use a class to wrap this, we can then safely guarantee that memory is freed even if an exception is thrown. The nitty-gritty I'll leave to a better [explanation](http://www.bogotobogo.com/cplusplus/stackunwinding.php),but it's why you should rarely call `malloc` in C++, and even then, using `new/delete` should be done sparingly (and solely within the context of classes or code guaranteed not to throw, to avoid resource leaks). C doesn't use constructors, destructors, RAII, or exceptions, and therefore none of these rules apply. C is still useful as a language, and fits many important uses C++ does not. None of this is to insult C. Each of these abstractions in C++ has costs, often in compile times and binary bloat. But if you have them, you should use them. That means, rarely use `malloc` in C, and never confuse C and C++ as the same language. Partial C compatibility is a huge contributor to the success of C++. C is still a great language. But we should stop treating them as the same thing. C is not C++. C++ is not C. Don't confuse the two, and you can write great code.
How ~~Old School~~ Skilled Programmers Process Arguments
%u
Thanks. Updated.
 $ apropos precedence operator (7) - C operator precedence and order of evaluation $ PAGER=cat man 7 operator OPERATOR(7) Linux Programmer's Manual OPERATOR(7) NAME operator - C operator precedence and order of evaluation DESCRIPTION This manual page lists C operators and their precedence in evaluation. Operator Associativity () [] -&gt; . left to right ! ~ ++ -- + - (type) * &amp; sizeof right to left * / % left to right + - left to right &lt;&lt; &gt;&gt; left to right &lt; &lt;= &gt; &gt;= left to right == != left to right &amp; left to right ^ left to right | left to right &amp;&amp; left to right || left to right ?: right to left = += -= *= /= %= &lt;&lt;= &gt;&gt;= &amp;= ^= |= right to left , left to right COLOPHON This page is part of release 4.04 of the Linux man-pages project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at http://www.kernel.org/doc/man-pages/. Linux 2011-09-09 OPERATOR(7) 
http://en.cppreference.com/w/c/language/operator_precedence is probably a better listing. It doesn't have the ++/-- flaw that the quoted manpage does.
That's probably the one I'd go to if I googled it. And thanks for pointing out the flaw, probably would have just blindly followed it if I only looked at the man page.
Thanks for pointing that out, would have probably blindly followed the man page otherwise.
http://problem-discussion.blogspot.com/2018/01/calendar-in-c.html
In case anybody was trying to compile this but unable, `getch` is a DOS/Windows-specific function that reads a character from the terminal without line-buffering. `getchar` is about as close as you can come on UNIX-ish systems without twiddling the TTY flags, but you’d need to enter the everything up until the next line break, at which point `getchar` would start seeing characters come in. The intended use of Esc might also break things a bit, since even in raw mode you’d have a hard time telling a straight Esc from a Meta/Alt prefix.
I'm would assume so but wouldn't any code I write on the Mac version work on with Windows? And what is VM? This is all new to me. I only have Java experience. 
So does this mean I can't do all the programming for this class on a Mac? And what's AFAIK?
Don't forget Derek Banas [Link](http://www.youtube.com/playlist?list=PLGLfVvz_LVvSaXCpKS395wbCcmsmgRea7)
`unsigned` is fine for a 16-bit number, but use `unsigned long` for a 32-bit number, with format `%lx` or `%lu`. C is not like Java, where the sizes and ranges of types are guaranteed—the C standards only prescribe *minimal* ranges, beyond which implementations vary. Per standards, the`unsigned` range must be ≥16-bit, and `unsigned long` must be ≥32-bit. (Signed integers are just shy of those ranges; e.g., `int` runs from −32767 to 32767 because you’re not guaranteed two’s-complemente representation under the hood; the two’s-complement minimum would be −32767.) Most modern architectures will be ≥32-bit so `unsigned` will be big enough in practice, but unless you’ve been given a specific target ABI or explicitly asserted about the range, you shouldn’t rely on that. In a more-real-worldish application, you should be using the `&lt;stdint.h&gt;` types like `uint_least16_t` and `uint_least32_t` for this, but this is close enough for learning. A lot of schools also mandate C89, which doesn’t include `&lt;stdint.h&gt;`.
Sorry to be a debbie-downer but that seems like a lot of work writing a game using just C and no libs... If you really want to go the "close to the metal" route I'd suggest at least doing something with OpenGL, otherwise Unity is nice and has plenty of tutorials
No but that is really cool! Thanks for posting.
Why not use a SQL database?
What editor is he using when he starts writing the C code @ around 8 minutes?
No. While it is possible in theory for Microsoft to create a version of Visual Studio for OSX that can cross-compile to Windows, there would be no way to actually run the programs under OSX, and therefore no way to debug them unless you had a second Windows system that can access the same filesystem where the programs are being developed. Microsoft isn't going to do that. The version of Visual Studio for OSX is almost certainly limited to creating OSX applications. VM is shorthand for virtual machine, which should not be confused with a JVM. A virtual machine in this context is an environment that runs on your computer that you can load an entire second operating system onto and that will run at near-native speed. Virtualbox is a popular free virtual machine platform that runs on OSX, Linux and Windows. You'll need a copy of windows to install onto it though. Most university students can purchase a copy of Windows 10 for very little through your campus computer store or online. You'll need to find out from your school though. If your class uses Visual Studio for Windows, and you are expected to develop programs for Windows and submit executables that will run on Windows, then you'll need a Windows system to do this. Either a bare-metal install of Windows on a PC, or a VM on your mac. Get this set up now. Don't be caught trying to figure out how to complete your assignments the day before they are due. 
His own.
You're not helping.
Doesn't make a lot of sense to start all over. Why not embed SQLite to have a SQL database system in your application?
&gt; it works for some matrices but not all. What do you mean by that? What do you expect it to do, what does it actually do? 
Re-inventing the wheel can be a great way to learn, and give better insight into how to build on top of those much better built wheels in the future.
C++ is off topic in this subreddit. Please post C++ questions elsewhere, e.g. in /r/cpp_questions.
It can be fun learning expirience and nowhere does it say it doesnt use opengl. 
scanf couldn't match the integer, thus doesn't write a, thus a is unitialized, thus it's unspeci what's written.
Not unspecified, but undefined. So that program could just as well print “your mother was a hamster and your father smelled of elderberries”, or make demons fly out of your nose, or kill your dog and set fire to your house.
&gt; Me too. I also forgot about `apropos` `man -k` is shorter...
If you initalise `int a`, you'll see that instead of 2, you'll get whatever number you initalised `int a` to. If you change `"%d"` to `"%c"` you'll see that `int a` will be set to the ascii value of the character you type. I haven't looked at the internals of scanf, but I would guess that because you've specified `"%d"` a decimal int, it validates the input and discards it because it isn't an int. 1 minor point. You've specified the return type of main as int, but not put a `return` at the end of main. You should either change the return type to `void main(void)` or return an int at the end of main.
&gt; prefix and postfix ++ and -- have different precedences Sure, but give me an uncontrived example of code where that matters enough to justify the increased compexity of the man page.
The last point is wrong, do not change the return type to `void`, that is non-standard! Also, since C99 no return from main is an implicit `return (0)`, the code is completely fine. Also, if you change the scan format code to `%c` you should also change the print format specifier since usually `sizeof (int) &gt; sizeof (char)`.
&gt; it validates the input and discards it because it isn't a decimal number. Yes, which would be obvious if the OP checked the return code from scanf...
Thanks.. didn't realize the a was never given any value by scanf..
Thanks.. didn't realize that a was never assigned any value by scanf.. but what do you think is the reason behind the output 2?
yeah i understood that a was never assigned any value by scanf. But why exactly is the output 'always' 2? Is it only for me or everyone else.. I recompiled it many times and tried.. But still the same outpout..
It's just whatever was previously stored in the ram before your variable was put there. That's why it's a good habit to initialise ints to zero when you declare them. Though a lot of people here will get angry at that suggestion and call it a redundant waste of time, here it would have been a slight clue that scanf wasn't making an assign.
Thanks ... :) 
Just to clarify OP if you try something like this: int main(void) { int a = 0; int retVal = 0; retVal = scanf("%d",&amp;a); printf("Input: %d\n", a); printf("retVal: %d\n", retVal); return 0; } You'll see that scanf returns 0 when you enter a char and it doesn't make the assignment, and returns 1 when you enter a decimal and it does make the assignment. So if you want to be more thorough you can validate the output of scanf before you try to use `int a` in the printf.
Thanks for taking the time to reply :) .. Yeah i should've checked the return value of scanf.. Never thought about it .. Thanks :) ..
That's okay. From my experience of this subreddit there are a lot of condescending arseholes who rather; than helping you out, will just have ago at you for not knowing something. I'd rather try and be constructive.
Just in case you are thinking of the Big Black Book: https://github.com/jagregory/abrash-black-book
Doom uses BSP rendering not portal rendering.
I think this: when you declare your integer a, it is allocated at some place in the memory with the bit set to the number 2 (due to some previous operations done at that location). Because you never assign anything to a, the previous value of the location is printed. This value could have been anything, but probably you have been testing your program and one of your test cases was the number 2? 
It's either allocated from stack or a register is used, either way it may be hold old data. This can even be reproduced semi-deterministic sometimes, if said register was used before in the always same way.
Implicit code is better than non-standard code that's possibly even UB. No return if you don't care is absolutely the way to go.
I totally disagree with the comment above, see my answer here: https://reddit.com/r/C_Programming/comments/7tzsho/what_is_the_reason/dtgtjew?context=3
yeah, that must be the reason...
yeah .. may be ..
yeah i agree with you that it does hide errors..
It’s specified by the C89 &amp;seq. in a couple places—as well as in the varargs promotion rules, the spec for `printf`’s `%c` says it takes an `int` and converts it internally to an `unsigned char`—so it’s safe regardless of the signedness of `char` or anything beyond the lowest `CHAR_BIT` bits.
Are we suppose to do this exercise with just the chapter 1 material?
the online **[html](http://www.jagregory.com/abrash-black-book/)** version.
On Reddit, you should indent your code by four spaces to have it displayed without formatting. #include &lt;stdio.h&gt; #define 'KILOTOLb' 0.453 int main(void) { float kilo, lb; printf(" Enter your wieght in kilo\n"); scanf("%f", &amp;kilo); lb = kilo * KILOTOLb; printf("%f lb= %f kilo", lb, kilo); return 0; } 
&gt; They are, for ~~string~~ literals, you're not using a string tho. Character.
Code compiled on a Mac would not run on Windows, or vice versa. It's possible to write code that would *compile* on both Mac and Windows, but you have to watch what you're doing. If you know Java, you shouldn't have any trouble with C or C++, other than the frustration when you discover all the libraries and stuff that C doesn't have that you got used to in Java. I do feel a bit bad for you that your professor is teaching you Microsoft C. It's not exactly standards-compliant (I think that the latest version of VS2015 only just caught up with the C-89 standard). And forget about Posix. Still, once you know the language yourself, adjusting to C under Unix shouldn't be too hard.
My professor, who has been very little help, emailed me back when I asked for guidance and simply said: "Visual Studio is a bad choice for a Mac. There are plenty of free C/C++ compilers and IDEs for it. Google "Free C++ IDE Mac". I previously said that we are to use whichever compiler we choose just that it has to compile with Virtual Studio. I did download Xcode but I haven't messed with it yet. He previously told us: "For compatibility with my compiler, the following must be used: #pragma warning(disable: 4996) #include&lt;string&gt; #include&lt;stdlib.h&gt; #include&lt;time.h&gt; system("pause"); // before return in main" I have no idea what any of this means yet because I haven't finished the reading. I'm so used to my java class using net beans where everything was much more straightforward and it wasn't online so I could ask plenty of questions. So basically can I include whatever that aforementioned stuff is in Xcode and make it compile with Virtual Studio?
ugh... thanks. I didn't pay close enough attention to the github page and what I was linking to.
Those are all pretty reasonable. The pragma is a compiler extension that tells the compiler to not generate warnings about Posix incompatibilities. The three includes are very standard C header files — this suggests that your professor has some specific programming exercises in mind, as the header files you normally use depend on the functions you're calling. The system() call is a C function that tells the system to run the "pause" program and then return. The "pause" program is the classic "Hit any key to continue..." program. I use it all the time in my batch file; it keeps the terminal window from closing when your program finishes.^1 If you're on a Mac, Xcode is the one to use. It's free, it's supported, it's on the App Store, and it contains everything you need to build for MacOS or iOS. I've been programming under MacOS for over a decade and it's what I use. If you stick to the rules, the code you write under Xcode will compile under Visual Studio. I know, because that's literally what I do for a living; I maintain a very large project that has to compile under both. ---- ^1 About the "pause" program: it doesn't exist in MacOS, so if you call it from within your program, you'll get an error that says `pause: command not found`. It's simplest just to ignore that, but there are things you can do to make it go away if it really bugs you.
This is all a huge relief to know. I read the reviews of my professor and they were all extremely negative and suggested that he doesn't help at all, just tells you to read the book. Even implied that he didn't want me to come to his office hours, which by the way is at a different campus, because that's when he goes to the gym. But anyways, so as long as I include those headers in my program it should compile for him? I assume it'll save as a .cpp file? I'm meeting with a tutor this week to help walk me through the first program. Just want to make sure I have a everything set up, otherwise they can't help me much lol. Also, thanks for all the insight. I was almost considering withdrawing from the course because of how lost I've been. 
your link is what led me there so its all good.
The tutor will be very useful. In my experience, when learning a new language, getting "Hello world" to compile and run is half the battle.
Show your code.
This sub is for C, not C++. Try /r/cpp_questions
oh my bad, thank you
Depends a lot on your OS. SDL is fairly popular and portable for low level graphics stuff, or there's GUI toolkits like GTK+.
i believe its in line 80 because if i comment out line 80, the program completes however i have no way of knowing if the strcpy command completed as i am unable to print it.
You're problem is your giving printf a character when it's expecting a string.
I did that so that as I read in with printf I could verify the string. The in the next loop I am trying to copy the item in sName (a regular array) into studentName (a 2d array). Then when I print the 2d array I get a segment fault. 
Also your for loops are jacked and your strcpy will only every copy the first student name.
dog, read my comment
Sorry yes I did that as a test and forgot to change it back before posting. I was trying to see if it would print the first name but still didn’t. 
I am confused as to how sName is a 2d array. 
How do I give printf a string rather than a char?
You need to keep in mind that a "string" in C is just a pointer to some memory holding some characters. So for your 2D array called studentName, everything in the first dimension (i.e. just one set of square brackets) is just an address to the memory holding the characters that will make up whatever student name is at that index. So in order to give printf a string you need to give it the address of where that set of characters starts. Which in this case will just be studentName[i]
So if I removed [j] and the 1 in the loop, it should work?
When you have just one set of square brackets it's a 1D array. char sName[5] would just be an array of 5 characters. char sName[5][5] would be an array of arrays of 5 characters. This makes it a 2D array. You can keep adding brackets this way to create as many dimensions as you want.
See for yourself.
Ok so since I initialized sName as char sName [][] it’s 2d and in the scanf sName[i] i is the location of total strings in the array. So if there are 5 strings sName [5] is the 5th value. 
That's more or less correct. Except that since arrays start at 0, sName[4] is the 5th value.
Look at the standard string functions [here](http://en.cppreference.com/w/c/string/byte) for anything that looks useful.
That won't work if the search string straddles a buffer boundary.
Yes! I assume you meant the strstr function! It worked thank you!
The best solution to this problem is to read the file with fgetc and implement a state machine. A bit like this: int state = 0; int c; int found = 0; /* open the file and handle the command-line arguments, as usual */ while ((c=fgetc(fp)) != EOF &amp;&amp; !found) { switch (state) { case 0: /* looking for # */ if (c == '#') { state = 1; } break; case 1: if (c == 'A' || c == 'B') { ++state; } else { if (c == '#') { state = 1; } else { state = 0; } } break; case 2: if (c == '#') { found = 1; } else { state = 0; } break; } fclose(fp); if (found) { printf("Found the marker.\n); } else { printf("Did not find the marker.\n); } return 0; } 
Several methods. If you're on Linux using Xorg, you can include the X11 header files (and link against the libraries) to create a new window that you can draw to directly. There are some drawing functions in the X11 library, as well. On windows, there's probably something in the Windows.h header file to create a new window. If you want to make things like GUIs, you can use frameworks like GTK+ or Qt. If you want to use acceleration (graphics cards) as opposed to software rendering, you'll need to use a graphics API like OpenGL, Vulkan, or DirectX. The problem with these is that they need a surface (or frame buffer, in other words) in order to operate, and the way of creating a surface is different for each operating system and compositor, although I'm sure the documentation available for OpenGL, Vulkan, and DirectX include methods for doing so on a variety of platforms. A great, cross-platform option mentioned by /u/raevnos is libSDL. To create a window in libSDL, call SDL_NewWindow. Once you have a new window, you can get its surface by calling SDL_GetWindowSurface. Once you have the surface, you can do whatever you want with it. You can even reach into the struct and directly modify the pixel values. More info [here](http://wiki.libsdl.org/SDL_Surface?highlight=%28%5CbCategoryStruct%5Cb%29%7C%28CategorySurface%29) as well as the [SDL API reference](http://wiki.libsdl.org/APIByCategory)
No need for *replacing* here. Just print anything up to the `#A#`, then the value of `a` and finally the rest of the line.
All modern graphics, even 2D, is done by programming the GPU's 3D pipeline. Gone are the days where you simply write to an area of RAM. Now you provide a payload of both data and instructions that is uploaded to the GPU for execution and processing even for simple things like 2D sprites. If you want to learn that process I would recommend diving into OpenGL. It's fairly low level relatively speaking, so it has a strong learning curve, but there are tons of tutorials and resources online. If you are just interested in setting individual pixels on the screen, a library like SDL is what you're looking for. Because on the back end SDL is doing the process I described above, actually setting individual pixels by looping in code is pretty slow. However, it is pretty fast with textures (basically areas of RAM that you designate to be an image and can upload to the GPU for fast drawing) so if you want to go that route it will be much easier to learn than OpenGL but will still be a similar process at a high level of uploading bits to the GPU and telling it where and how to draw. Depends on what you feel like you can bite off an chew, but I feel confident recommending either OpenGL or SDL or perhaps even both as SDL has been designed to interoperate with OpenGL. Both libraries are cross platform. Good luck!
&gt; if (c == '#') { &gt; state = 1; &gt; } else { &gt; state = 0; &gt; } `state = (c == '#')` :P
I guess that's [it](http://lmgtfy.com/?q=read+csv+file+in+c).
Yes, I thought of that, and also using the ternary operator below. But I wanted to keep the code as simple as I could on the assumption that OP is a beginner.
The input your program gets from the user after your first scanf isn't just a single character, its that character and the newline. Your scanf reads the character the user has typed but then leaves the newline character - the newline character is then read as the input to the second scanf.
Well what if the getchar() function isn’t an option? This isn’t really homework, just me trying to learn C and messing with code. I tried deleting the white space in between the scanf strings but then it just totally skips getting the users last initial and favorite number and instead just randomized them. Is there a way to do it without the getchar() function?
I found the issue. It was just spacing issues with the format strings 
try adding return 0; on a separate line beneath printf just above the last curly bracket.
it’s good practice to finish every main function with a return statement. This is how I would write your program: #include &lt;stdio.h&gt; int main() { printf(“welcome to C!\n”); return 0; } //end of program I haven’t written much C in the past year but I think that should do it. You’re not far off, but this is what I would do differently.
Try asking in r/csharp, or start doing your own homework. This is the subreddit for the C programming language, which is very different from C#.
I think I may be doing something incorrectly with creating the file or where I'm storing it because I created a new file, copied the default "Hello World" file that is there when you install Xcode, pasted it in my new file, and it crashes. 
You may want to try reinstalling Xcode or compiling your file differently - maybe try using vi or vim inside of terminal. there are many tutorials about how to go about doing this online.
C# is off topic in this subreddit. Please post C# questions elsewhere.
I downloaded Xcode and can't figure out what I'm doing wrong. I create a new file and literally copy and paste the default "Hello World" code that is there when you install Xcode and the program crashes with this error: clang: error: linker command failed with exit code 1 (use -v to see invocation) 
Note that it is optional in C99; see 5.1.2.2.3 in C99 TC3.
Give us the output of `-v`. It will show what libs and paths `clang` uses on your system.
Omitting the return statement from main is valid in C99, and even if he's not using C99 then it should have caused a compiler error, not a linker error.
OP, try opening a terminal and running the following command instead (replace main.c with the name of your .c file): clang main.c It'll generate a file called a.out, which is the compiled program. If this works and xcode does not, then that proves there's something wrong with xcode.
Thank you, I figured it out!
Thanks
Sure thanks!
Sorry, should have clarified "identifier "atof" is undefined" although I have the includes that worked in the 2008 version (modified with the 'c' for example math became cmath).
Try `std::atof`
atof is declared in &lt;stdlib.h&gt; http://en.cppreference.com/w/c/string/byte/atof
Ah sorry, my mistake. I didn't see a C++ subreddit so I wrongfully assumed this was a C/C++ subreddit.
http://learnopengl.com is a fantastic resource. The name is super generic, but it's the best content I've seen for learning modern OpenGL from the ground up. It uses a C++ library to do maths, but there's C equivalents and nothing is C++ specific really.
https://en.wikipedia.org/wiki/The_C_Programming_Language http://cs.indstate.edu/~cbasavaraj/cs559/the_c_programming_language_2.pdf
https://en.wikipedia.org/wiki/The_C_Programming_Language http://cs.indstate.edu/~cbasavaraj/cs559/the_c_programming_language_2.pdf
It's not "crashing". "Crashing" would mean that the program compiles, and runs, but then exits without doing what it's supposed to do. You're getting a compiler error.
C++ is off topic in this subreddit. Please post C++ projects to /r/cpp.
My mistake. Either way I still don't know what's wrong. 
I haven't. Could you elaborate? 
Could you tell me how to get there? Is that within the program?
r/cpp don't worry I think we all made that mistake at one point.
That was it!, thank you. 
C Programming - A modern approach by K. N. King and Modern C by Jean (available on the author blog for free).
Your entry point (main) is wrong. your main should be `main(int argc, const char *argv[])`
That's assuming his project is set up to compile for C99, OP, in the build settings search for "C_Language_Standard" and make sure it's set to either C99 or C11.
No, it's not. `int main(void)` is also a valid entry point. https://port70.net/%7Ensz/c/c11/n1570.html#5.1.2.2.1
Your program needs a newline at the end of the string it outputs. It also needs to return an exit code (0, in this case.) But other than that, it compiles and runs perfectly: $ cc -o tester tester.c $ ./tester welcome to C!$ so there's something funky about your Xcode installation or with your project files if you're using the IDE.
If you're running it through an IDE instead of a command line, you have to tell the IDE not to close the window when the program exits. There's some shortcut for it, or a menu option, or something, in Visual Studio, I'm sure.
Tried that..still doesn’t work 
Now, are any of these included by default in common Linux distros such as Ubuntu or debian? At least, any of them other than the X11 and Windows.h stuff?
If you want to develop for them, you may need to install the development packages for your distro. These will include the necessary header files. For me (Manjaro), the header files are included in the distribution packages, so there was no need for me to install separate development packages, but I think that's unique to Arch-based distros, so you may have to figure out what the development packages are called. These are the relevant packages that I used on Manjaro: - For GTK+, the package was called GTK3 - For Qt, the package was called qt5-base - For OpenGL, the package was called mesa - For Vulkan, the headers were in a package called vulkan-headers and the library, itself (libvulkan.so), was in a package called vulkan-icd-loader - For SDL, the package was called sdl2 Sorry I can't help you much wrt other distros. I'm most familiar with Arch-based distros. You should query the package database of your distro to try and find what you need. I think these days most distros have a website where you can search for various packages to find them by name. [Here's Ubuntu's, for example.](https://packages.ubuntu.com/)
+ for Handmade Hero. I've watched a few of his streams, and, although it goes a little slow, since he's developing in real time, he explains everything very clearly.
[C99](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1256.pdf) [C89](http://read.pudn.com/downloads133/doc/565041/ANSI_ISO%2B9899-1990%2B[1].pdf) Same for both. &gt; 5.1.2.2 &gt; The function called at program startup is named main. The implementation declares no prototype for this function. It shall be defined with a return type of int and with no parameters: ```int main(void) { /* */ }``` or with two parameters (referred to here as argc and argv, though any names may be used, as they are local to the function in which they are declared): ```int main(int argc, char *argv[]) { /**/ }``` or equivalent; 9) or in some other implementation-defined manner.
That's the worst possible attempt at a fix and a really bad habit. Use your tools properly.
Memorizing standards isn't my style. Thanks for the info tho.
&gt; I was thinking about making those functions extern. So all the user would have to do is copy these libraries to his project and declare somewhere else the function and the variable. Sounds like a good choice. It's common for micro controller libraries to work this way: require the user to provide functions that are platform specific.
Alternatively you could make the user pass a function pointer to the send function. On the other hand, microcontrollers and function pointers might not be the best combination.
use linux and gcc, the beginning will be a little hard, but later on it will be much more rewarding.
You can pass macro definitions to both clang and gcc using the `-D` flag, so you can use a shell script or a makefile to compile for different targets. Otherwise you could create multiple header files, one for each target and the user has to include one or the other.
I just tried on a Windows machine here and they even support designated initializers and compound literals. I'm literally (haha) baffled. Just be sure to use /TC and then you can basically work. Crazy how MS caught up on the modern times :)
if you think that's cool checkout handmadehero 
Microcontrollers have generally low clock rates, this is significant overhead for an mcu. When sending data one generally wants to do this as quick as possible to conserve power. Also, personally I wouldn't mess around with pointers in an embedded project since they are hard to debug (especially so in an embedded controller).
I wish anyone told me that earlier :) now trying to learn vim gcc and gdb. Can you recommend a tutorial for the most important functions of gdb?
Unfortunately, my tutor had to cancel so now I have to figure this out on my own. I installed a C/C++ plugin in Netbeans because that's what I'm used to using. I wrote a program and everything works fine. Now, my issue is when I try to create a new file I end up with the same problem. Can I not have multiple files within the same project the way you can in Java or do I have to create a new project every time I want to write a code?
I have built embedded systems this way, and I think it is a very good approach. Here are some additional tips: 1. Put the interface definitions in their own header instead of making extern declarations manually in each file that uses the interface. This makes it easier to change the interface without forgetting to update the consumers of the interface, which will lead to nasty bugs the compiler won't catch. 2. Keep different interface implementations in their own directories which are separate from their public interface headers. You choose the implementation to use by which directory you put in your Makefile or other build system. For best compiler optimization opportunities, you can still easily expose all the code in your set of directories in use on the current target for whole-program optimization. In this way, interface consumers don't have to pick the implementation ahead of time, you can change implementations without changing any C code, and you also don't have to pay for the indirection of function pointers. You get multi-target code, and it also enables cheap off-target unit testing of code using the interfaces by creating a host-friendly implementation with lots of debug/trace output. This can help a lot in solidifying your core algorithms by running them on carefully constructed test data that exercises all the code paths on your host, and reduces the testing feedback loop considerably for areas where it can be used instead of on-target testing.
I'm afraid at this point, you need to find someone who knows this stuff to sit down with you. I know how it feels, when I first got started writing drivers in Visual Studio, I was almost desperate to advertise on TaskRabbit or something for someone to help me out. As for me, I'm afraid I'm old-school here. I write my C code in an ordinary text editor (MacOS has vim, it takes a while to learn, but it's SOOOO worth it) and compile my code from the command line with "cc".
Looks like you were downvoted for this, but I'm going to agree. On sufficiently small systems, the overhead for dereferencing a pointer can be significant. On my larger (10s of kB of RAM or more) systems I definitely make a lot of use of function pointers.
Thanks, indeed I was referencing MCUs with 256 Bytes of ram or less with Frequencies below 1MHz.
The way your describing it is very common. There are some other ways of doing it as well. Particularly for my smaller 8-bit projects I'll often have a generic header like "hardware.h" that holds hardware-specific #defines and such, and I might define a SEND_BYTE(x) macro (or something more specific like MOTOR_CONTROL_SEND_BYTE(x)), and then the macro can be an alias to a function call or it might be inline assembly for the sake of efficiency. On larger systems I'll often have an init() function that takes a function pointer to register a callback, or it might take a pointer to a whole structure with callbacks and configuration parameters. For a static configuration, that reduces the RAM requirements to a single pointer, rather than potentially many pointers and parameters. Most of the projects I'm working on now go a step further and use an AUTO_INIT() macro that defines their entry point. The macro adds a structure containing a pointer to the init function (plus a startup priority number) to a reserved memory section, and at startup the system iterates over the list and calls all of the init functions in priority order. This lets me add a module just by adding the files to the project, without having to modify *any* code if I do it right. I can easily set up multiple builds with different combinations of modules without having to mess with macros and conditional compilation for function calls.
&gt; but it’s so darn clever and concise meh imo most C code is like that I guess it's orgasmic to new guys
I am actually not really good with gdb
I thought this was kind of nitty until i read the article. I don't find all four points to be all that persuasive but he had me at the first one: null pointer deference is undefined behavior. That's enough for me to always check.
He posted again......already reported.
Not persuasive. The malloc api is fundamentally broken and meaningless. I _always_ wrap it in something that checks for null and dies. No, I don't try and handle it, madness lies that way. (Want to print an error message? Good Luck with that. Odds on something along the way tries to malloc some memory...) Far worse are those who clutter the code with checks for null.... with pages and pages of intricate spaghetti of untested and untestable code to try handle it. And guess what. Every damn time I have actually taken a close look at such malloc returns null handling code.... It's broken. Yup. Won't work.
Which post do you mean? All posts I see from him are in a different subreddit.
Do you provide any clues whatsoever as to why you HCF? As in, do you purposefully write to 0? `*(void *(0)) = 1;` or do you return an error code and hope that it can be given back to you?
Using decimal represented integers to then divide by and calling it shifting (effectively it is, but not functionally) is really strange... 0x80 is bit 7, the highest bit, on. More obviously represented as 0b10000000. If that bit is set in the current working variable `byte` then print 1 otherwise 0. Then do a pseudo-shift left by 1 so what was once bit 6~0 is not bit 7~1, and you can test the same bit position again
I'm normally fan of these viva64 articles, but this one was under-researched: chromium hooks the allocator and crashes the process if it were to return null. Omitting this piece of information makes the whole article invalid.
The mask is being applied because they want to process the input `value` one byte at a time. Suppose `value = 0xAABBCCDD`. On the first iteration (when `byte_iterator = 0`), the mask is `0xFF000000`, so &amp;-ing that with `value` yields `0xAA000000`. In other words, we've isolated one of the four bytes. This result is then right-shifted 24 bit positions to arrive at `byte = 0x000000AA`. This then repeats with `mask = 0x00FF0000` and a right-shift of just 16 positions to get `byte = 0x000000BB`, and so on... Please note that this code sample is pretty unusual and, in my opinion, not well written. I've never seen somebody choose to use division to perform bitwise shifts, because C provides operators (&lt;&lt; and &gt;&gt;) precisely for that purpose. Also, while masking is a useful technique to know, it is unnecessary for this situation since you can just loop through all 32 bits at once. No need for nested loops. uint32_t value = 0xAABBCCDD; for (int i = 0; i &lt; sizeof(value)*8; i++) { if (value &amp; 0x80000000) //Is left-most (most significant) bit set? putc('1',stdout); else putc('0',stdout); value = value &lt;&lt; 1; //Shift whole number left once. } putc('\n',stdout);
&gt;Using decimal represented integers to then divide by and calling it shifting (effectively it is, but not functionally) is really strange and unintuitive... Right? It's a super weird way of doing it. &gt; 0x80 is bit 7, the highest bit, on. More obviously represented as 0b10000000. If that bit is set in the current working variable byte (bitwise mask 0x80 and byte) then print 1 otherwise 0. Then do a pseudo-shift left by 1 so what was once bit 6~0 is not bit 7~1, and you can test the same bit position again I understand that 0x80 is 128 (position 7), but I don't get this line: unsigned int mask = 0xff000000; for(byte_iterator=0; byte_iterator &lt; 4; byte_iterator++) { byte = (value &amp; mask) / shift; // Isolate each byte. why is the value of the byte being ANDed with the mask? What function does that provide? 
Yeah, it's a weird way of presenting this info by the author. &gt; for (unsigned m = ~(~0u &gt;&gt; 1); m; m &gt;&gt;= 1) { I'm still pretty new to C and haven't seen the tilda syntax before. What does that do? I know &gt;&gt; shifts the bits to the right. 
Chromium code dosn't contain malloc functions. They are in libraries. I want to note that this is **unacceptable for libraries**. The library does not know where and how it will be used.
It's bitwise not. Turns all 1s into 0s and vice versa.
Thank you! That's what was throwing me off--I didn't switch 0xFF000000 to bytes in my head as I was reading this. Yeah, this sample is super weird. I've seen some bitwise operations in C before and everyone seems to use &gt;&gt; and &lt;&lt; instead of calculating out 2^x. Some of the examples, in my very limited experience in C, are super odd in this book. However, it makes sense that some of the code in here is weird as this book is ultimately about exploit development. Exploit code doesn't necessarily needs to be stable long term; it just has to get you a shell once.
Ohh dang, thanks. That's a new operator for me.
On the embedded system I wrangle I record a (binary) error into flash and take the shortest possible path to reboot. And yes, I inspected every damn line on the way to reboot that it doesn't try malloc anything. Everything on the call graph is statically allocated and a big fat comment warning of the dangers of trying to malloc in each routine on the way. In the posixy world, abort() is usually enough. In the linuxy world the OOM killer is awake and all hell is on the loose anyway. Hint for the unwary: Yup malloc lurks in the bowels of some printf()'s. Don't think you can go printffing useful information after malloc returns null. Madness lies that way.
 int *array = malloc( 5 * sizeof(int)); array[0] = 0; ... array[4] = 4; /* Oh no. I need to add another number */ /* array[5] = 42; ERROR - out of bounds */ array = realloc(array, 6 * sizeof(int)); array[5] =42;
Thanks :) 
&gt; static allocation for the designed for worse case works far better. I am reading DNA sequences from files and/or pipes. They can range from a few nucleotides to several MB. Thus, one has to use dynamic memory allocation. &gt; The malloc api is fundamentally broken and meaningless. I agree. It should return a pointer and the number of available bytes at that position. That would make it far [better and composable](https://www.youtube.com/watch?v=LIb3L4vKZ7U).
:O you're not checking the return value
So this is their way of shifting and masking 8 bit chunks out, to then shift and mask out single bits from. of your # is 0x12345678, masking it to 0xFF000000 will result in 0x12000000. Which they then shift right 24 bits (3 bytes) (or divide by (256*256*256) per their method) to just have 0x12, then the inner loop goes over that 8 bits 1 bit at a time
mmap is a marvelous beast. mmap the entire damn file and just treat it as an in memory array. Not enough RAM? No problem! The OS just "forgets" it until you walk that way again (it can always re-page it in from disk if and when it needs it.) By far the simplest and fastest and most robust approach!
Thanks! :)
My example also uses `int` instead of a structure. /u/nice_remark will obviously do everything correctly.
&gt; mmap is a marvelous beast. It is, but I can't mmap pipes. &gt; The OS just "forgets" it until you walk that way again. Not if I have to correct the file contents ie. the pages get marked as dirty.
Mmm, mmap it to a rw file and then suck it all out of the pipe and into the mmap'd array. The kernel then pages dirty stuff out to disk as you run around the array and just does "The Right Thing" depending on whether the page is dirty or not. If it's clean and needs the ram it just "forgets". If it's dirty, it writes it out for you. You don't need to think about it. (much). Often is you peek under the hood malloc is doing mmap anyway... just in a dumb way. I once was asked to look at a production system that was too slow, and it was doing thousands of seeks and reads and writes... I deleted most of the code, replaced it mmap() and sped it up by a full factor of 40. I love mmap, but hate malloc(). 
Of course, glad to provide it. I generally try to remember behavior that changes between standards, and what doesn't, rather than memorize individual standards, because it helps me avoid undefined and unspecified behavior.
I help maintain a library, and part of the inherited legacy is that you can set your own legacy allocator, and when the allocator fails, you have a longjmp that can handle the situation specific to the OS you're working on. The default, internal allocator simply abort()s. I'm not a true-blue C guy, but seeing a solution like this gives me a lot of respect for the true-blue C guys and their wiley ways to make things cross platform. 
:O oh no, his system might not have 192 bytes of memory :O
:O it could have, but it might be severely fragmented because of previous mallocs
I have always had one issue with this. Lifelong malloc-checkers can help me out here. The basic principle is "never write code you can't test". Untested code is really no better than undefined behaviour. So what does your test suite look like for your code that handles a bad malloc? The only thing that I've been able to come up with is using something like `ulimit` to limit the size of your virtual address space, but that becomes a little bit gross if you're using a lot of virtual address space for non-malloc related things. Is there a more elegant way to test it?
&gt; You can use their implementation out of their codebase But then you'd have to licence your code under the same licence as OpenSSL. This is one reason people avoid OpenSSL (as well as the fact that it's full of shoddy code that undoubtedly has many security exploits waiting to happen). 
IRL books provide slightly better retention than ebooks. Source: some study I read back in sophomore year. 
You can copy the source code, as long as you attribute it and preserve all the licensing, making it clear where it comes from. Usually, you'd want to keep it segregated to their own files to make perfectly clear where the licensing applies. You'd be right if it were LGPL or something, but none of the licenses they use are copyleft. In this case, it would be considered a derivative work. SHA256 can go wrong, but it really shouldn't with good tests (You should be testing every odd corner case you can). It's pretty easy to get some subtle things wrong to cause incorrect output.
People go back and forth on whether to check malloc’s return value. On one hand, if a system is unable to allocate memory, things are pretty borked already. It’s going to be tough to fail in any kind of graceful manner or even report the exact nature of the failure, all without further allocations during error handling. On the other, it doesn’t hurt to attempt to handle this in an appropriate way, by printing pre-allocated error message strings.
Write wrapper functions for malloc and friends, use them instead. Then in test mode you can replace it with something that, say, randomly returns NULL instead of calling the real malloc(), a realloc() that always returns new memory instead of growing an existing region, etc.
And then what do you do? Limp on until the next malloc() and print another? And another? I notice that I have been [downvoted](https://www.reddit.com/r/C_Programming/comments/7ukaxh/why_it_is_important_to_check_what_the_malloc/dtl4m99/) to oblivion for saying I always "check and die if null"....... ...but I really wish some of the downvoters would explain what they do instead. Because if they claim to handle it.... maybe they should invite me to their next code review and (lots) of experience tells me I will point out at least one bug in their handler. Usually those who check for malloc returning null and attempting handle it are in the second category of defect free programs. The first category are so simple, they obviously have no defects. The second category are so complex they have no obvious defects.
All the gcc user manuals are [online](https://gcc.gnu.org/onlinedocs/). Same with gdb and binutils. Or you can browse them locally through info with the appropriate documentation packages installed.
By handle I mean perform as many of the following as possible: * Present a message to stderr * Pause user jobs * Free resources * exit(1)
Free what resources? Heap and fd's will perfectly reliably be freed on process exit by the OS. What user jobs? Do you have multiple threads whirring? Child processes? 
Emacs or die!
C Programming - A modern approach by K. N. King or R&amp;C. Both teach C89. But King's cover C99 too! 
Writing C in a programming oriented editor (ever seen somebody try to write code in Notepad or Nano? It's not pretty), and compiling by hand in a shell is the way to start. People who get dumped in a magic black box of an IDE that hides all the details suffer for not getting a chance to learn how the tooling around the language works. Use them for bigger projects, sure, but not the one or two file programs used in beginning classes.
By user jobs, I mean any active workflows that the user may interact with, such as bank transactions, merchant orders, video streams, basically anything that should be neatly tidied up before a big ol segfault. By free resources, I mean anything that has been acquired, whether atomic locks, file handles, PID files, network sessions, or external resources like printer spools.
The [parent](https://www.reddit.com/r/C_Programming/comments/7ukaxh/why_it_is_important_to_check_what_the_malloc/dtlon9b/) post I was responding to explicitly said he freed resources then invoked exit. I was wondering what resources he is referring to. 
&gt; I do not want a war; Are you serious, you can not discussion editors/IDE without war on other hand. my opinion is vim **and** emacs is the best choose one of them. or you would prefer to use both by *spacemacs*
Good luck trying to unwind any transaction "in flight" from an arbitary point in your code( or any library code) that mallocs.... I bet you won't do it right. (Hint: There are malloc's in all kinds of fun places you might not expect) Getting database style ACID properties right yourself is really really hard. One of (the many) reasons why we use DBMS's is that somebody has invested an amazing amount of thought and care and testing to give you ACID properties. If you peer under the hood of an ACID db, they don't try persist or rollback things whilst the shit is hitting the fan. They rollback partial transactions resulting from a crash at restart when things are back to a sane environment, before they open for business. ie. You _never_ attempt to roll back transactions while the shit is busy hitting the fan. And Streams? Any streams will be torn down by the OS on process exit. Sort of the whole point of an OS. No matter how looney userland is... the kernel is rock solid and will wipe the userland slate absolutely clean.
These wrappers also provide the opportunity to "poison" memory returned by malloc during testing by filling it with garbage before handing it to the caller. void * xmalloc(size_t z) { void *p = malloc(z); if (p) memset(p, 0xa5, z); return p; } It's an easy way to catch those uninitialized memory accesses early.
There used to be a C conference, but one year everyone ended up at the wrong address due to an invalid pointer.
valgrind and AdSan are my go to tools for finding bad accesses. Back in the day there was a debugging malloc library called ElectricFence that would align stuff with page boundaries and use memory protection so that either trying to read after, or before (but not testing both at the same time), would cause a segfault. Then you'd fire up a debugger and inspect the code dump to figure out where the problem was. And it wouldn't do a thing for finding memory you own but used before initializing. Life is so much easier these days.
Because C is standardized, and doesn't move nearly as fast, or add and remove nearly as many features as C++ does.
I do C programming in Kwrite.
Cause C is ubiquitous thus so no need to promote it as those crappy PL do! 
I'll be honest, I didn't really like the article. His points are fine I suppose, but he claimed he was going to explain why the EFL Core devs were wrong but he never actually did. And that's because, well, they weren't wrong. All his arguments hinge on the idea that `malloc` can return NULL. But he never addressed their entire point, which is that on a system like Linux `malloc` will *not* return NULL unless you have run out of addresses in your address space (Which isn't going to happen on a 64-bit machine). Even if the system runs out of memory, `malloc` will still return valid addresses, and it is not until you attempt to access that memory (far past your NULL check) that you will have problems, and at that point there is nothing your program can do - either the kernel starts swapping to disk, or the OOM killer wakes up and starts killing processes. Neither of those things are something you can do anything about in your code.
Not sure if you mean that chromium doesn't contain calls to malloc, or that chromium code doesn't contain the implementation of malloc. Both would be false, at least on Linux. Chromium contains a modified copy of tcmalloc.
Gdb manual "get GDB-PEDA" or gef or pwntools 
There's very little development of C. The last C standard was released 6 years ago and before that 18 years ago.
&gt; I notice that I have been downvoted to oblivion for saying I always "check and die if null" I don't know why you have been downvoted for saying that, since all you're saying is that you never work on programs that require handling a null from malloc.
not moving doesn't mean there are no new uses and application though
not convincing. there are new applications of C so should talk about it
Okay then C is boring
Nobody's bothered to sponsor one.
wonder why?
A few years back someone tried to organize one but I guess it fell through. https://www.reddit.com/r/programming/comments/t0aza/c_conference_a_conference_about_c_planned_by_me/ 
&gt;Back in the day &gt;Electric fence I used electric fence in college. And that was like.. 2 years ago. Damn. Also what did you mean by AdSan? Couldn't find anything on google.
I have thought about use `memfd_create` and then `splice`ing the pages from the pipe into that (or may be `copy_file_range`). However, I am not sure if it really is worth it. `read + realloc` is just so much simpler.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [bumblebritches57/BitIO/.../**BitIOLog.c** (master → 7e967a0)](https://github.com/bumblebritches57/BitIO/blob/7e967a0dc6379a0bccebdd265de7dcf424403e0e/libBitIO/src/BitIOLog.c) ---- 
I personally just check and log if a call to calloc is null, but I'm assuming that some allocations will be massive, and they'll fail just because they're too big.
&gt;also GUI so... emacs then?
I really don't see the point of conferences for programming languages. "We did a thing using a tool that's for doing things." *applause* How is this not a circlejerk? There are no conferences about hammers either. "I hit a nail and it went into the wood." *applause* 
C is a hammer. Everyone knows how to use it. And those who don't should get a book. Not go to a conference where the presentations would be made by equally inexperienced people because the actual professionals wouldn't turn up to a conference that can't teach them anything new.
I think this is the most realistic answer.
Previous discussions on this subject: * [are there any C conferences?](https://www.reddit.com/r/C_Programming/comments/6i2w8a/are_there_any_c_conferences/) * [are there any good C conferences out there ?](https://www.reddit.com/r/C_Programming/comments/397bnx/are_there_any_good_c_conferences_out_there/)
Everybody should learn how to use `ed(1)`. It's one of the most useful tools provided by UNIX.
I haven't worked in really big projects, so I can always do manual printf debugging. That's why I stick with notepad++ or gedit, and occasionally I use codeblocks if I don't need a makefile... The biggest project I worked on is a max/msp object, I didn't setup the debugging environment, so I did manual debugging again :P
There are no c conferences because c isn’t constantly being updated. Updates in c would cause a chain reaction for higher level languages to update as well. This is the reason objective c is dying out with Apple and they are pushing swift. That being said, c is not dying and I don’t see it dying any time soon. It is essential for very low level programming such as file systems and is as close to hardware as we can get without bumping down to assembly. C is still fairly easy to program in compared to assembly or binary if anyone can do that. 
It's still around? Wow. The address sanitizer that clang and gcc have. Compile with `-fsanitize=address`. `-fsanitizer=undefined` is a good one, too.
My question is so what if the memory is corrupted one instruction before a crash?
Linux's coding style is very well managed, so I don't know what you're complaining about...
After reading the introduction I expected something like a remote code execution in chromium due to not check malloc return code, not just stating that null pointer dereferencing is undefined behavior.
If the idea is to avoid duplication of work, why did you reinvent the logging-library wheel? `jpVector__erase` makes many calls to `memcpy` but actually it only needs one. `jpVector__expand` doubles the size of the buffer, which is not great for fragmentation. See [this blog post by Chris Taylor](https://crntaylor.wordpress.com/2011/07/15/optimal-memory-reallocation-and-the-golden-ratio/).
For reference: the [Linux kernel coding style](https://www.kernel.org/doc/html/v4.10/process/coding-style.html) guide
- Your logging functions assume that stdout and stderr can handle ANSI escape codes, which isn't guaranteed to be the case, or may be undesirable (e.g. if you're redirecting to a file). - There's quite a lot of duplication between `jpLog__info`, `jpLog__warn` and `jpLog__exit`. I'd probably have a more generic logging function and set things like the colour, level and output stream with it. - `jp_vector.c` has `#include "vector.h"` which I'm assuming should be `jp_vector.h`. - A Makefile that built these as shared objects wouldn't hurt.
This is absolutely incorrect. See my comments elsewhere: https://www.reddit.com/r/cpp/comments/7uj99c/why_it_is_important_to_check_what_the_malloc/dtldrvi/ and https://www.reddit.com/r/cpp/comments/7uj99c/why_it_is_important_to_check_what_the_malloc/dtm97ca/
Good catch! I should make the ANSI escape codes an optional part of the API. How would you suggest I do this - separate functions, additional parameters, or a settable state within the unit? Also, do you have any recommendations for a good, portable logging API that I can use as a reference (or just use instead)? Thanks!
[This link](https://stackoverflow.com/questions/1597405/what-happens-to-a-declared-uninitialized-variable-in-c-does-it-have-a-value) will most likely provide the answers you seek :)
Thanks for the input! BitIO looks really useful. I'm needing to handle unicode UTF-16 values in a current project, and BitIO would be great as a reference. I'm curious, what are your criticisms of Kernel Style and what style do you conform to and why?
when you declare a variable they are not initialized (tho some compilers will initialize but it's not part of the standard). You basically just get a place in memory and there might be something there already (left by some other program). It's basically luck that sumOfSquares is always 0 good C practice is to always initialize your variables. C will happily let you do stuff with whatever is in those variables but if you are doing something potentially dangerous (like DB operations) this will bite you in the ass
Hmm, since both hofko's variables are declared within the main function, shouldn't they both be initialised to random huge numbers? Why is the first one treated as a static variable and the second treated as a local if they're both local to the main function?
If you compile with warnings turned on (-Wall -Wextra` for gcc and clang), the compiler will point out a lot of mistakes like these...
Well when compiling with the -Wall option in gcc, the compiler doesn't point out anything. 
as far is I'm aware....pure blind luck. though I suspect it might be a compiler quirk. I avoid undefined values and behavior like the devil so I'm not as familiar with the assignments rules here as I should be :/ .
Well, I understand that I should initialize variables. I forgot that when I first wrote the code, and then I found this issue and it made me curious why does it happen. Thanks though for the explanation.
That is true, yes but it might be luck just as /u/gardyna said. 
It looks like shit is what I'm complaining about.
Yeah, I know; I've read it. Popularity doesn't make it hard to read.
worked for me https://i.imgur.com/7rD6xTA.png a good tool is to use a linter, like syntastic for vim.
The problem is when I try to access members of the structure array. For instance, trying to print out a member of the first structure will produce an error. The line I am trying is below `printf("%s\n", str[0]-&gt;name);` 
It will warn about using uninitialized variables.
How does it look like shit? Can you even present a good argument as to why?
Interesting. Doesn't work for me for some reason. Will definitely take a look at syntastic, thanks.
Nice try. I am mostly working on x86_64. Also, [totally checking for overflow](https://github.com/EvolBioInf/andi/blob/3596fb0518c5bdd776b0e68316247478f395df7c/src/process.c#L331-L335). 
I mean, you weren't checking for overflow in the snippet you commented so how was I supposed to know that 🤔🤔
I have gcc version 5.4.0 20160609, so it's not that old..
What's the exact error message. For this error some compilers give you suggestions on how to fix it.
&gt; For example, assuming more than a single object is created in a single program, than it's likely the older blocks of memory will be simply assigned to the new object I agree that any program non-trivial enough to be useful will be allocating objects of more than one type. But very often, a program will have a single type which accounts for the _majority_ of its allocations. &gt; Once we use whole pages for reallocation, there's almost never any need to copy the data from the old block. It depends on the implementation language. Certainly this is true in C. In C++ though, copying is much more common because `memcpy` is only a safe way to copy some types of object. The same is true of C structs too (consider for example a small-string struct which contains a pointer to either a small internal buffer or to an externally allocated buffer). Stipulated, creating a non-relocatable data structure is often just a bad idea. Facebook selected 1.5 for their optimised vector implementation, [`folly::FBvector`](https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md), and they claim to have benchmarked this on real applications pretty extensively. On the other hand, I believe Stepanov selected 2 for the original STL implementation and the GNU libstdc++ has kept that choice. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [facebook/folly/.../**FBVector.md** (master → 5359a76)](https://github.com/facebook/folly/blob/5359a76065f742fea96ae27a557487f85ee5e2be/folly/docs/FBVector.md) ---- 
%a is documented at http://en.cppreference.com/w/c/io/fprintf But because you didn't pass a double to satisfy the %a, the behavior is undefined; It doesn't have to print `0x0p+0`
&gt; But very often, a program will have a single type which accounts for the majority of its allocations. When a single type accounts for the majority of the allocations, than it is even more likely that fragmented memory unites will be recycled in new object instances (as the sizes have a better match factor). I think this situation still supports my observation about fragmentation being a non-issue where allocation size is concerned (while copying data remains an issue). &gt; It depends on the implementation language. Certainly this is true in C. Many other languages are implemented using the same system calls under the hood. So although it might not be true for all languages, it's true for more than just C. &gt; In C++ though, copying is much more common because `memcpy` is only a safe way to copy some types of object. That's a great point. I guess I was referencing cases where objects grow internally, managing their own memory, such as dynamic arrays, hash tables, dynamic strings etc'. In cases where the objects are embedded within the container (rather than attached to the container by reference), than it's a whole different ball game (and it's also one of the reasons I prefer C over C++). &gt; Facebook selected 1.5 for their optimised vector implementation... And yet, when `jemalloc` is detected, they switch to the `jemalloc` allocation bin model ... which is a factor of 2. Which brings up another point. When using powers of 2 for memory block sizes and growth, there's less of a chance to experience memory "slack" (where the allocator allocates a larger chunk than requested due to "bin" matching concerns). 
Thank you! And thank you for the link! So I take it that undefined behavior means the compiler author can have the compiler do whatever he thinks is appropriate under the circumstances? Is 0x0 basically the default memory address and lacking a value it's printing that address + an offset?
`error: invalid type argument of ‘-&gt;’ (have ‘struct _section’)`
There's no default. If you called `printf("%a",1.1);` then one way of doing this is that 1.1 is pushed on the stack, the address is the string is pushed on the stack, and the function is called. Printf would see the `%a`, read a value off the stack and treat it as a double. If you call `printf("%a")` then there's no double pushed on the stack, so when printf read from the stack it would read an effectively random value. But the C-language doesn't say that this is way calling a function has to work, or how printf has to work. So the language can't define what happens when you break the rules. printf might read a random value, or it might crash, or it might always read 42.6 somehow. In your case it happened to see zero. It might print something else if you run the same program tomorrow. And if I compile the program and run it, then it may do something completely different.
As said by raevnos, definitive reference is online. This being said, I found that the first part of 21st Century C by Ben Klemens give you a quick an efficient overview. It helped me to get back on track after a 20 Years hiatus in C programming in a *nix based environment. I skimmed over Part II (dedicated to the C language itself) but didn't find it very interesting.
Or the compiler might do something not specifically chosen by the compiler authors. UB happens at compile time, the effects if any can happen at either compile time or runtime. https://xkcd.com/571/ 
Your idea of using extern functions is totally fine; my company uses that a lot in our software, and I've seen it in other vendors' libraries as well. It could be referred to as a "callback" function, but to most people that implies a function pointer. Instead, a more accurate name might be an [inverted dependency](https://en.wikipedia.org/wiki/Dependency_inversion_principle) or an "inverted call[back]". Others have made good suggestions about how to structure the header files for this. I would also suggest that you may want to use `char` rather than `uint8_t` (although it really depends on the protocol and the transport). Some DSP-focused chips don't have byte granularity, and so `sizeof(char) == sizeof(short) == sizeof(int) == 4`. In that case, `uint8_t` wouldn't even be defined since there is no type that holds *exactly* 8 bits, but presumably such a chip could still use a UART or other transport to send and receive 8-bit characters, which would be appropriately represented by a `char`. Meh, I'm probably getting too technical and too far into edge cases. A better suggestion, though, is to allow sending more than one byte at a time. Depending on the transport API being used, repeated function calls to send a single byte might be really inefficient. Nicer if you ask them to implement `ssize_t Send_bytes(const void* buf, size_t count)`, and the user can either pass the buffer easily to their API, or can trivially write a loop to pass it byte-by-byte if they need to. Note that I also changed the return type to `ssize_t` so they can return how many characters were written, just like `printf(3)`. (Almost; `printf(3)` returns `int` because it predates `ssize_t`, but interfaces that have been able to change like `write(3)` and `send(3)` do use `ssize_t`, as should you.) Granted, it may not be obvious how to recover from failure, but at least you'd have the ability if you wanted to. I'd also question why the user needs to provide the definition for `Byte_Counter`. If your code is calling `Send_byte()`, why can't it keep track itself of how many bytes were sent? Why is that the hardware's job. Lastly, it's really helpful for users if you carefully and thoroughly document the interface and what they have to implement. Even better is if you can provide example implementations that they can read, or even compile and try. You could have a "dummy" implementation that just does `printf("Protocol would write 1 byte: %#hhx (%c)\n", byte, byte);`, or you could use trivial file APIs to open a serial port (`/dev/ttyS0` or `COM1:`) and write to the serial port. If you're writing and testing on a microcontroller of your own, it wouldn't hurt to include your implementation for that microcontroller as a "reference" implementation; users on the same microcontroller can probably use it as-is, and users on others can use it as a guide to see what needs to be done on theirs.
 printf("%% is what you want, when you want a literal percent sign.\n");
 printf("%% is what you want, when you want a literal percent sign.\n");
That's 2 major versions out of date
Ebooks are a good pocket reference too.
Thanks, I had the first one in my Amazon wish list already, I’m probably going to purchase a couple of books; one being K&amp;R.
Third one can be a good timeout book :)
Read up on Pointers and how they work.
sorry pal, wrong door. this sub is about C programming. just because your language of choice has a "C" in it's name, doesn't mean it qualifies.
I believe there should be a discussion first about how this is going to be done "technically" so I can identify how I can assist. But, if you're speaking in general, I'm in the gaming industry and I'm good at managing projects and bridging between the artists and developers which was my main role on my last career, and as a co-founder many things should be done by me including securing funding, getting our team incubated, but those tasks have their time. For now, I want someone who likes the idea frst then we'd discuss many stuff.
Convert the int to a string using sprintf() and iterate through the string using array/pointer indexes. Look at the sprintf documentation to learn how to use it
You can read a single character at a time and check to see if it `isdigit` or you could read a string (`fgets`), then loop through them.
Is this an int you want to count set bits, or a string you want to count the number of '1' characters in?
[This FAQ](http://c-faq.com/stdio/scanfjam.html) explains what happens when scanf sees something that's not valid for what it's trying to read.
What do I use to capture the input if not scanf? Pardon my dependence. Instructor dumped the assignment on us last minute and has not gone over capturing input or validation. I have found many articles saying that scanf is not advisable but have not found an alternative.
`scanf` is a pain in the ass. It will leave failures in the input stream, and you'll still have to handle them. It's much cleaner to read everything in a block with `fgets` and then parse it. You are right though, he has to check the return value to use it sensibly.
So you want the number on a line by itself? Then check that what follows is a '\n': `if(scanf("%u", &amp;num) == 1 &amp;&amp; getchar(c) == '\n'){ ...`. Also notice the `&amp;`: `scanf` works with addresses.
All I want is to do is capture input, and validate that it is an integer. scanf is merely all I have learned so far
Can be done without `getchar` as well. Grab the next char with the same `scanf` and then check that it's a newline.
Our 2nd year C course enforced **not** checking it as a style guide point which would accrue loss of marks for violation. Personally, I always check it but I do agree that if the system is not allocating memory via `malloc` then there are probably bigger issues at hand. Regardless, I always tend to prefer the path that gives the greatest resilience (who knows, maybe I'd get roasted at a real code review).
`*` is multiplication. If `level` is 2, then the value of `bit1 * level` is double the value of `bit1`, which just happens to be the value of `bit2`.
Guess I was overthinking it, this makes sense. Thanks!
Some things I noticed: * You don't need to call your variables "argc" and "argv". Call them "c" and "v" instead. * `--argc&gt;0` would work just as well as `--argc` * `(*++argv)[0]` is the same as `**++argv` * `argv[0]` is the same as `*argv+1` * `*s!='\0'` is the same as `*s` * The curly braces around the loops' bodies are superfluous I might be missing some more
This? int countDigits(int number){ if(number &lt; 10) return 1; else return 1 + countDigits(number/10); }
I literally did in the other comment.
Thanks for these tips, annoyed I forgot about the loop bodies not needing braces. I've updated the post with your additions.
The first thing you need to be able to do when you learn to program is to have a precise understanding of the problem you are trying to solve. If you can't state the problem clearly in a natural language, you are likely to have difficulty expressing a solution elegantly in a programming language.
For those who don't happen to know this identity: double log10(double x) { return log(x)/log(10.0); } 
log10() is a standard C99 function, too! Though that formula is good to know if you ever need a log of a base other than 10, e or 2.
Format code with 4 spaces, not those funky underscore things.
is x a char[]? then the solution is strlen() 
Using strlen would be preferable to manual indexing 
I might be stating to obvious here, but if you're unaware of this it might be illuminating - multiplying by a power of two is equivalent to shifting left. I.e. i*2^n is the same as i&lt;&lt;n (usual caveats apply - e.g. n &gt;= 0, n less than the bit width of i) Personally, I find thinking/coding in terms of shifting, as opposed to multiplication by a power of two, is usually more intuitive.
Vim + Tmux + gbd + a good coffee is all you need to be productive. IDEs might be good in the later stages of your learning since they hide a lot of fun things under the hood, whereas an editor would require you to set up the tools just the right way and will teach you a lot about the internal working and connection between your tools. 
For the theory, bit operations are just linear algebra over the field with two elements where each bit is interpreted as one vector element.
Does that directory exist? You print out a message if opendir() returns null, but then you go on and use the null pointer anyways. Also, running your program in a debugger will help show you where the problem is. 
Careful: x may not be 0, otherwise log10)x == -inf 
fgets and sscanf for example. Or multiple calls to getchar.
Can you precisely define the question instead of having everyone here waste time? Are you scanning a string or an int? If it is an int, why are you talking about scanf? Why is your example a binary number? It is 8 hours after submission, is it too much to ask that you give a freaking example of what you are looking for? 
My math library abuses this unfortunately, but it would be almost 6x as many lines of code without it.
I’ve tried a few different options in the last few years....Netbeans, Eclipse, QtCreator, CodeBlocks, Codelite, Kdevelop They all have drawbacks and missing features when compared to Java, python or C# IDEs. Mostly I was looking for the level of support for refactorisation that IDEs provide for other languages. At the end of the day, I settled on Sublime Text about year ago (after a brief stop with Geany which imo is more of an editor than an IDE). As an aside, I moved my project to cmake which makes hopping between IDEs a breeze since it can autogen the needed support files for the different IDEs. About a month ago, I tried Kdevelop4 and for whatever reason, I like it and have been using that. As for vim and emacs - I use vi when ssh’ing into boxes and never got my head around emacs :-)
Ok great, when I put -O2 option it did warn about uninitialized variables. Thank you.
Will do, thanks.
Why call strlen when you already know how long it is from the return value of sprintf?
Atom + gcc in terminal(linux)
Given an integer x &gt; 0. We always have: x = a * 10^k (1) Where: a: [1, 10) and (k + 1) is the number of digits of integer x, k&gt;=0 For example: 6789 = 6.789 * 10 ^ 3 So, (1) =&gt; k = log10(x / a) = log10(x) - log10(a) (2) Since a: [1, 10) =&gt; log10(a): [0, 1) (3) And k is an integer (4) (2), (3), (4) =&gt; k = floor(log10(x)) Let n be the number of digits that we want to find, as mentioned, n=k+1. So n = floor(log10(x)) + 1 or int(log10(x)) + 1 like the one I answered.
Perverse option: move the declaration of s to main's parameter list main(int c, char**v,*s){...}
Not at a computer, but if you can have some warnings you can drop the include, and int for the types, as int is the default type.
Even simpler. No need for recursion: static unsigned countDigits(unsigned x) { unsigned ndigits = 1; while(x /= 10) ndigits++; return ndigits; } The recursive version wasn't tail recursive, but it probably got optimized into a loop anyway. Really i don't understand why some people insist on using floating point math or converting it back to a string lol, when all it needs is a couple of divisions.
73 characters main(int c,char**v){for(char*s;--c&amp;&amp;**++v==45;)for(s=*v+1;*s;puts(s++));}
I really like the increment inside the `puts` call.
paid shills and brainwashed goys are down voting this
Well, `log_10` is neat and IDK how much time takes the convertions and logarithm evaluation, but at first glance it has O(1) against O(n) to any `n` digits number. And not that `unsigned int` will have that much digits to make a difference anyway...
I will research these, thank you very much!
Well let's see how a IEEE 754 compliant implementation looks like. From `glibc`'s source files: [e_log10.c](https://github.com/bminor/glibc/blob/master/sysdeps/ieee754/dbl-64/e_log10.c) does some preprocessing then computes the log using something that looks like the formula `log10(x) = 1/log(10) * log(x)`. Where `log` is the natural logarithm. Now let's look at how log is calculated: [e_log.c](https://raw.githubusercontent.com/bminor/glibc/master/sysdeps/ieee754/dbl-64/e_log.c) is made up of one mammoth of a function that computes the natural log. As you can see there's a lot going on there: the function has to handle NaNs and +/-INF and then it uses a bunch of polynomials to approximate the log. &gt; but at first glance it has O(1) against O(n) to any n digits number. I'm pretty sure you can't compute the integer part of log using O(1) standard arith operations (+-*/).
The directory definitely exists. It works fine in eclipse.
Bear in mind, that even if printf is called. You may not see anything on the screen if a seg fault occurs before the output buffer is flushed. I would put a return statement after printf, just to be sure.
*If you want to get the number of digits to use to display the number in binary.* I'd use *unsigned* int for `x`. Then you can, in GCC, even use the function `__builtin_clz` which will give you the number of 0s before the first 1 counting from the most significant (leftmost) bit. #include &lt;limits.h&gt; unsigned bin_digits(unsigned x) { return ((sizeof (x) * CHAR_BIT) - __builtin_clz(x)); }
thanks for the advice. the printf now works correctly if the directory doesn't exist. However, i still get a segmentation fault even if i use "." as the directory
[This library](https://github.com/caseyscarborough/libcrypt), no? It looks quite straight-forward, what exactly are you having problems with? 
I would make the logo a blue C, like in the title page of [The C Programming Language](https://www.amazon.com/gp/product/0131103628): https://i.imgur.com/yMpmgEp.png
It's [lib*g*crypt](https://www.gnupg.org/software/libgcrypt/index.html), based from GnuPG.
Digits when converted to base 10? Or digits in the base 2? 
Good idea, I like it!
Oh, of course it is. What issues are you having, or questions are you trying to answer? 
if you're using scanf you might as well load your number as a string first and then convert it into an int: char buf[32]; scanf("%s",buf); int numDigits = strlen(buf); int number = atoi(buf); 
It's a relative path, though. Does it exist relative to your current working directory when you run it and get a crash?
No blog spam please.
Your post got caught in our spam filter, I apologize for the inconvenience.
I cant seem to figure this out... I need to output using modulus: Please enter the amount to be paid: $8.68 GST: 1.13 Balance owing: $9.81 Loonies required: 9, balance owing $0.81 Quarters required: 3, balance owing $0.06 Dimes required: 0, balance owing $0.06 Nickels required: 1, balance owing $0.01 Pennies required: 1, balance owing $0.00 I can't output the values properly. I know int are supposed to be whole number thats why i multiplied by 100 then i used mod to get the remainder and output it to my balance owing. 
Any fractions is lost when converted/assigned to an integer. So things like `int quarters = .25` makes `quarters` equal `0`. This also means when you try to multiply an integer by `100`, the fraction doesn't magically appear. So either use only floating point numbers or use integers as the lowest unit (pennies?) and convert to an float when displaying.
I think the term you want to read up is [recursion](https://en.wikipedia.org/wiki/Recursion_%28computer_science%29)
**Recursion (computer science)** Recursion in computer science is a method where the solution to a problem depends on solutions to smaller instances of the same problem (as opposed to iteration). The approach can be applied to many types of problems, and recursion is one of the central ideas of computer science. "The power of recursion evidently lies in the possibility of defining an infinite set of objects by a finite statement. In the same manner, an infinite number of computations can be described by a finite recursive program, even if this program contains no explicit repetitions." Most computer programming languages support recursion by allowing a function to call itself within the program text. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Yeah I know it's meant to be done with recursion. I've only ever really done very small methods with recursion in Java. Never on a larger scale, especially with respect to going through directories.
&gt;100 to a looney (whatever that is). Skip the decimals entirely. The Canadian dollar coin has a loon (bird) on it ;)
you just write a function lets call it "scandir" which takes one parameter - the name of the directory to scan. the function steps into given directory and looks around. for every directory it finds, it calls itsself with the found directory name and for files and stuff it does what ever your assignment requires
I don't see that working. It steps into the directory and finds 5 directories inside it. It steps into the 1st directory and scans it again and finds 5 different directories. Then it steps into 1 of those and only finds files. It changes all the files. How does it go back to where it found the 5 files before that?
Those algorithms seem like they will help. I'll look into them. Thanks
it doesn't need to go back - the function just returns and thus the caller is running again. that's basically one of the most common uses of recursion. you just have to wrap your mind around it once - it's pretty neat from there. 
I figured it out, thanks all! :)
I like tabs for indentation, followed by spaces for alignment. It doesn’t break alignment, but it gives you all the benefits of tabs most of the time.
But for my assignment specifically, I would need to go back so I can go through the other directories.
Here is a bunch of issues: 1. `typedef uint8_t _UINT_;` Are you seriously limiting the length of a string to 255 chars? 2. I don't like going through a pointer for the string. 3. `std::string::size()` is an O(1) operation, yours is O(n). 4. Your malloc macro sucks. It hides the fact that you have memory leaks in `string_init` and `string_find_raw`. Also 2. takes share of the blame. 5. &gt; str.c:563:9: warning: Value stored to 'match' is never read match = false; 6. Line 413 is a null pointer dereference. 7. `string_swap` is terrible. 8. `string_reserve`: why do you realloc, twice? 
&gt; Are you seriously limiting the length of a string to 255 chars? \*laughs in Pascal\*
Never use floating point for currency. Count cents with integers. And that will actually solve your problem too.
that's the point that you're not actively need to go back because of the recursion-mechanism. either run with the visualization u/tehcyx provided or just implement it (for the beginning with just visiting every directory).