I'm not usually a fan, but I did as well. Why would I pay so much for a book that's almost twice my age?
ProgramConfig is a big old bunch of global variables. Generally speaking, code is easier to understand if everything determining the function's behavior is a function parameter. I'd suggest trying to do that as much as possible. 
I'm also not comfortable having so many global variables, and, having some experience with functional programming, your message resonates with me. But say that after calling `parse_args` in `main`, I use a `process` function that will actually describe the program logic (so as to keep `main` as simple and clean as possible). Are you suggesting calling `process` with every one of my options as parameters? Not that large function signatures are scary, but they don't look very pleasing to the eye and could quickly get out of hand if my program had many more options available. The new approach I can think of now thanks to your comment is: declaring the `ProgramConfig` struct inside of `main`, passing a pointer to it to `parse_args` (which will internally change its fields), and then passing a copy of said struct onto all of the other functions that might need it. That way, `program_config` is outside the global scope, always inside a function scope, and only mutable inside `parse_args`. Is this better?
First thing : forget about fork, use threads instead. Second: what are you currently doing to use multiple clients? Poll? Epoll? 
Out of curiosity, were you using scanf() at any point prior to the getchar() call?
Yes.
What do you consider "the basics"?
I know you have *a* solution, but if you didn't figure out the root cause already, that's it. The behavior behind scanf() can be less than predictable. In your case scanf() read up to the new-line '\\n' (from pressing the enter key to submit your input), but left the new-line itself in stdin, which was subsequently picked up by getchar(). &amp;#x200B; It's preferably to use fgets() to read a string, and if you need to convert it to an integer, parse the string it gets with strtol().
u/Drach88 made some really good points. Besides that, since your goal is to build an OS, I would recommend starting from some skeleton code and filling in the necessary parts. This will help you understand OS concepts as well as make your C better. For this, I highly recommend [MIT's 6.828 course labs](https://pdos.csail.mit.edu/6.828/2018/) (whose material is available for free online). Then you can probably build your own OS from scratch after that.
Line 12. It's assignment, not comparison.
Sorry for very brief answer, I can't go into details atm. You're declaring a single byte (char) variable. Then you take an address of it *and* filling this address with a string. Non empty char strings are always two or more bytes (a symbol + terminator). Of course you're going outside of the legit memory for your single byte variable. In production code this will lead to random crashes and/or wrong data being read. You are absolutely obliged to use malloc or some other way to create a continuos block of memory and then use scanf with fixed maximum length of symbols to be entered. 
*YOOOOOOOOOO!!!!* It's your **1st Cakeday** barzo0! ^(hug)
Umm, line 12 is just a closing brace for me. Could you mention the contents of the line?
while(*p = *t++)
Yeah, it‚Äôs supposed to be that. I‚Äôm copying stuff from the addresses t into the in p. The loop ends on encountering a null character. K&amp;R does this, and even recommends remembering this ‚Äúidiom‚Äù, to quote.
Hmm, interesting. I‚Äôll look into that.
You need to learn the tool chain. I recommend 21st Century C. You need to learn the standard library. I recommend The Standard C Library by Plauger. You should learn Linux and it's programming interface. I recommend The Linux Programming Interface by Kerrisk. You should learn about implementing common data structures in C. You will need to write your own. Also look at Expert C Programming: Deep C Secrets at some point. 
I do not understand your comments in the code (language barrier, sorry), but, this is what I understand about it. Correct me if I am wrong: You are using TCP. On the server side, you are creating a socket, accepting a new connection and then forking to a different process. In the parent, you will continue the loop and accept new connections and fork new child processes to handle every client. On the client side, you are connecting to the server and sending some message. Receiving some reply and then in a loop, sending a message, forking off a new process to receive a reply, then repeat. &amp;#x200B; This is my suggestion: A lot of problems will occur because you do not seem to be sharing memory between your processes on the server side. You said &gt;I left out some of the code proprietary to the Clientes structure as I am sure that is not the problem. If your clientes structure never gets updated for the child processes with information about new clients, how will the child processes know whom to send information to? Are you using pipes, mailboxes, shared memory or some IPC mechanism to send information between the children and the parents? I would recommend using threads. It is a lot better for what you are doing and makes it easier to scale. &amp;#x200B; If I understood incorrectly, please clarify so that I can try to understand and suggest something better.
Don't use fgets
But scanf only lets me print out a string until there's a space
There's a way to circumvent this. 
Which is...
It‚Äôs not skipping. Scanf is leaving the new line in the buffer. So when it gets to fgets it‚Äôs only reading the new line 
Thanks, I'll look in to it
`getline`
scanf("%[^\n]s", variableName);
1. The validation of the options is your job. The necessary logic can be transfered to dedicated functions. 1. You can, as you mentioned, declare the option struct in `main`, call the parse function and then pass the struct to your main logic function. Sounds good to me. 1. Instead of separating the flags to single `int`s, you can combine flags into one variable, e.g.: ```cpp typedef enum { empty = 0, debug = 1 &lt;&lt; 0, mode = 1 &lt;&lt; 1, other = 1 &lt;&lt; 2, ... } flag_t; flag_t flag = debug | empty; if (flag &amp; debug) ; // debug flag set ... ``` 1. I don't think there exists a best pratice for C, only good and bad practices. It depends on the environment, requirements and goals of the project.
Thank you
üëçüëçüëçüëç
Operating system, terminal?
You understood coreectly dont worry, about sharing memory I am using mmap and i can share data between processes, I tested this and the data is shared, I even have the id of each corresponding socket,but the problem is the send() function when anyone who isnt the last child process tries to use it. Regarding threads,its what I want to use but this is an assignment and I need to use forks.
I used libsndfile many years ago... good memories!
Thank you for the clarification. I understand it better. It seems you have taken care of the data sharing aspect then. 1. Is there a reason why you are not using select(), poll()? 2. Where do you get the bad file descriptor? 1. On client side or server side? 2. Also, parent process or child process? Another recommendation. In your error() outputs, mention the process name ("Child 1", "Child 2", "Client 1", etc.).
1.I have actually been looking into select() and pool() do you have any examples you think are helpful? 2:Its in the server side. When I try to use send() to a child processe that isnt the last ine registered. I think it's worth mentioning that echoing works on all child processes. Thank you for you time and your help!
&gt; printf("\033\[1;31m");// RED This should be `printf("\033[31m");
This link might help you in general. [https://cs.nyu.edu/courses/spring13/CSCI-UA.0201-003/lecture24.pdf](https://cs.nyu.edu/courses/spring13/CSCI-UA.0201-003/lecture24.pdf) 1. Beej has a few examples. You could also check the man pages for examples. [https://beej.us/guide/bgnet/html/single/bgnet.html](https://beej.us/guide/bgnet/html/single/bgnet.html) 2. I see. I have a couple of questions. 1. When you accept an file descriptor for client 2 on the server side, how do you ensure client 1 also has the same file descriptor open? Just copying the number "3" from one process to another will not ensure it is an open file descriptor for both processes. You need to "pass" the file descriptor from one process to another. From this line, `newIdSocket = ClienteAEnviar.idSocketPers;` it seems you are simply assigning it. Please read this. [https://stackoverflow.com/questions/2358684/can-i-share-a-file-descriptor-to-another-process-on-linux-or-are-they-local-to-t](https://stackoverflow.com/questions/2358684/can-i-share-a-file-descriptor-to-another-process-on-linux-or-are-they-local-to-t) 2. Try to close file descriptors when you are not using them. &amp;#x200B; Beyond this, I do not know how much I can help. Good luck! :)
Ooh a new C sub, thanks! Would make a nice sidebar addition.
windows and codeblocks
This is a C language sub and not C#. Try r/csharp
This is not a good method long term. scanf into char buffers run the risk of overflows and has some other problems. I would rather recommend you use fgets in both places. Then use sscanf to scan the number from the first fgets call. The second one can use the same buffer which it'll overwrite. 
Don't worry a guiding hand is what I wanted! Thanks you for the links and all the help hope you have a nice day!
Thank yoooouuu. I‚Äôm learning to code to eventually focus in audio programming.
Good luck! I have been trying to figure out for a while how everything works and just trying to make sense. Ironically, I was in the shower and it hit me so I decided to share the little sight I have. 
Awesome, thanks. hopefully i can do the same one day, and maybe i‚Äôll shower! I read a lot of advice for skipping C and going straight to C++, but i‚Äôm genuinely interested in C and I‚Äôve been enjoying a few video courses and books. However, not many resources have been very.. uh.. engaging? I much prefer learning methods around building practical projects rather than just explaining what is what. Do you have any suggestions on resources in C for stuff like that? ‚ÄòLearn C the Hard Way‚Äô kindof does this but i‚Äôve read too much criticism of it to take it seriously.
u/Drach88 Thanks for the response man. This will really help me out. This is really helpful &amp; i will try solving those problems in the upcoming days &amp; get back to you (in your inbox), if that's ok for you? Thanks for the response again. Its greatly appreciated.
Thanks for the heads up &amp; linking me to the MIT's 6.828, i will check that course out &amp; try working with it. I heard somewhere that [OPS-Class](https://www.ops-class.org/) is a good source for learning the basics of operating systems as well, not really sure what language is used in this one &amp; if its good enough.
No worries
&gt;Do you have any suggestions on resources in C for stuff like that Personally, I don't believe there is just 1 good source to learn C or any language for that matter. The way I learned was I just found a topic I was interested in that I had no experience with (in this case audio programming and playing music from a file) and found many different sources ranging from medium articles to official documentation. I also like to pick apart example programs because a lot of tutorials will just hand you something, but I find that not fulfilling. I like to fundamentally understand how to use everything so I can be more effective and feel like I am legitimately learning the material effectively. Another reason to read from many different sources is so you can take in which practices are more widely used/professional. If you narrow to one source, you can find yourself using the good and bad practices from that tutorial. &gt;I read a lot of advice for skipping C and going straight to C++, but i‚Äôm genuinely interested in C I have also put a lot of thought into this. On one hand, C offers an extremely lightweight compiler that can work on practically any system and is pure grind for maximum efficiency, while C++ can be a more fluffy but still equally efficient and useful language that focuses more on OOP. The thing that took me a long time to realize, is they are both just tools on a toolbelt. Each problem requires a different tool to solve and sometimes C++ just makes more sense because it adds a lot more flexibility for practically the same performance. I took the "C is just more pure" but in the end, I found it was a bit narrow minded and not always practical. Anyways, these are just my thoughts, how you can find them helpful and they answer your question.
Lovely response, thank you!
Have you tried godbolt.org?
I tried that, it still gives me the segmentation fault error when i pass wave into my last function which prints what kind of wave it is using if elses(wanted to use a switch but it says in my assignment to use if elses) thanks for trying, i'll just ask my TA to help me finalize it.
I love small easy to read code that does big things
&gt;godbolt.org Perfect. Thank you !
It depends on the system. Some runtime linkers do not have the ability to resolve library dependencies recursively, so your own binary needs to reference everything. Moreover, it's possible for the library not to properly declare its dependencies in the library file itself. This is always the case for _static_ libraries, since `.a` archives simply don't have a way to represent this information. Since `curl-config` doesn't know whether you'll be linking to a dynamic or a static version of the curl library, it just emits all the dependencies it knows. You can avoid unnecessary transitive linking in some linkers. GNU `ld` has the `--as-needed` option (so it's also usable as `-Wl,--as-needed` from GCC). With this option, even if, say, you use `-lssl` on your compiler or linker command-line, the library will only be added to the binary's dependencies if you actually directly use a symbol from the library.
Basically a multiple choice quiz , I don't get how to do that output key
Windows doesn't by default support ANSI escape sequences as far as I know.
Try ¬ªModern C¬´ by Jens Gustedt.
Why online?
I'd suggest learning about whatever programming environment interests you. My personal life favorite is Club programming Volume 1, because I like to write graphical programs with Linux, and the cookbokk aplroach isn't too outdated. Due to the cookbook nature, though, I'd also suggest a book on data structures in general, which demonstrates the possibilities of what the code can do with well designed data. 
üëåüëåüëçüëç
K&amp;R is from a different era, don't take it's style or all recommendations as gospel.
The sine generation looks... well, awful. Is it just me or am I missing something?
Your source code is really clear and easy to read.
Thanks for feedback! 
Thanks
i must be missing something here but in Matrix44f lookAt(const V3f from, const V3f to) you seem to be returning a local variable....
Returning a local variable is ok in C. Returning a pointer of a local variable is not. 
I rocommend that one. It's split into levels. You can skip over some of them and still get a good understanding of how c works. 
Haven't read the book but I was a c++ programmer and picked up c like nothing. I didn't even read a book tbh, just picked up some coding challenges.
You're not using anything from `endian.h`, so you could just get rid of that (non-standard) include. I looked because I was wondering why you'd even need it. 
No. `#define` is the correct answer. The name that comes after `struct` is called a "tag". The two words together name a type. You can create a *one-word* alias for a type using `typedef`. If you want to alias the tag, your only option is `#define`.
not afaik. Not sure why you want todo this though. &amp;#x200B;
Thanks for the answer and the insight. :) I will leave this question open for an hour or so just to see other comments.
Why delete it at all? It's a great question.
Its more of a riddle for myself i came across. 
No i mean flair as solved :) &amp;#x200B;
Ohhhh haha.
Its more of a riddle i tried to figure out :)
Helping on an open source project written in C is about the best way I know to do this. You'll certainly improve your skills by working on real-world projects that people actually use, but it has the added advantage that your commits will be public. You can just list it on your CV and potential employers can actually look at your code for themselves.
Here's some sample code for enabling color in the windows console currently used by your program: [https://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences#samples](https://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences#samples) It looks like if you copy the code up until the wprintf lines your color codes should work after that. Obviously this is a Windows only solution though and don't forget to add #include &lt;windows.h&gt;
 struct Student { int id, grade; }; 
Yeah, I understand that I need to add a custom structure, and what the embedded variables need to be, I just don't know how to modify the code below, to allow for the change. I'm VERY new. Thanks for the reply though.
Oh. I was planning to use it in the stl loader since the datum in the stl file are little endian. Used in ints but seems I forgot the floats. Tho unnecessary for modern desktop cpu's. I'll either fix it with an alternative macro or remove it completely. Include is also in the wrong file :). Thanks for pointing out.
If you use the code I posted as a template and fill in details from your example, you're practically done; it doesn't get more difficult than this.
Started? You've practically got him finished! ;)
That particular pattern is actually super-useful. I honestly use it all the time.
Do you already know Objective-C? If not, that would be a good start because it fits nicely also with your current job.
Rather than asking for someone to hold your hand, show that you've put in the effort by explaining what you've tried (including research) and asking specific questions. I'd recommend reading the man pages on `pipe` `dup` `fork` and `exec`, then read up on how file descriptors work in Advanced Programming in the Unix Environment.
Auch Javascript. 
You could also use a [sentinel value](https://en.wikipedia.org/wiki/Sentinel_value). For example, if your user wishes to exit the program they would enter a non-valid student id like 0 or -1.
**Sentinel value** In computer programming, a sentinel value (also referred to as a flag value, trip value, rogue value, signal value, or dummy data) is a special value in the context of an algorithm which uses its presence as a condition of termination, typically in a loop or recursive algorithm. The sentinel value is a form of in-band data that makes it possible to detect the end of the data when no out-of-band data (such as an explicit size indication) is provided. The value should be selected in such a way that it is guaranteed to be distinct from all legal data values, since otherwise the presence of such values would prematurely signal the end of the data (the semipredicate problem). A sentinel value is sometimes known as an "Elephant in Cairo", due to a joke where this is used as a physical sentinel. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
ah, okay, its something I've always avoided, must of ended up forgetting that!
thank you.
Up
Look into Exercism.io. That should keep you busy for a while.
[Advent of Code](https://adventofcode.com)
That sentiment is early 2000. It's now the most popular language and for good reasons. Mostly spat on my gruntled java developers who haven't accepted that it's a dying language. Modern javascript can be written elegantly, pure functional stuff. Developer experience with the tools and can be awesome. Node is a fabulous back-end. We did large scaling money transaction stuff with it. Good choice, worked well. Also works well for fullstack stuff and Electron is solid approach for some plat independent desktop apps. Did those too, so I am talking out of experience here. Shit can be done with it, and plenty is. But that applies to any language. It puts dome responsibility on the coder since everything goes. So it's like, if your flat is shitty, you're a slob and always late then... Maybe not a good choice.
I've been preconditioned to always add () != 0. What I ment was that old books tend to contain stuff like unlimited strcats, shell examples with $\* instead of "$@" etc.
thanks mate!
r/git2du/pointnova Write yourself a Git!wyag.thb.lt ÔøºShare3 23 r/grateful_dead3du/Bman1973 This is one of most enthralling Other Ones ever - 9/03/72 Boulder Colorado (Filler from Dick's 36)youtube ÔøºShare8 52 r/C_Programming3du/gurugioResource A short document for large scale C programming ÔøºShare14 68 r/git4du/ivster666 Best way to organize a shared Dotfiles repository for multiple machines? ÔøºShare15 11 help to start C wsppan ‚Ä¢ 5d People always struggle with C when they start from scratch or come from a higher to lower level of abstraction. I struggled with this for a long time till I did these 4 things: Read Code: The Hidden Language of Computer Hardware and Software Watched all 41 videos of Crash Course in Computer Science Grabbed a copy of C programming: A Modern Approach and used it as my main course on C. Followed this Tutorial on Pointers and Arrays in C until I fully understood pointers and memory management. The first two really helped by approaching C from a lower level of abstraction (actually the absolute lowest level and gradually adding layers of abstraction until you are at the C level which, by then is incredibly high!) The third is just the best tutorial on C. By far. The 4th is a deep dive into pointers and by far the best tutorial on pointers out there.
If all you want is consistency you can go the other way and typedef an anonymous struct as each of the types. Then you would use both without the struct keyword.
yeah or just typedef foo\_t aswell: typedef struct foo_t foo_t; typedef foo_t bar_t; should work
I would recommend starting off by learning problem solving and the basics of computation. I would also recommend not using an IDE to start off and instead using a text editor that supports syntax highlighting and the terminal - this will let you learn the process of building programs that goes on behind the scenes in an IDE.
Thanks, have to check those out! 
I'm by no means an expert but I very much enjoyed working through the book, for what it's worth. 
Hi, there are some advices. 1) Implement of a stack 2) Implement of a simple memory allocator 3) Implement of a simple file system 4) Implement of a simple parser for your own programming language 5) Implement of different algorithms for random numbers generating 6) Reimplement of standard math functions, such as sin, cos, tan, etc. 
It's pretty good. Get the 5th addition. I prefer these 2: 1. C Programming: A Modern Approach 2. Modern C (free)
I think you are making this unnecessarily complicated. Let's start with the basics. Do you know how to swap 2 numbers? void swap(int *a, int *b); &amp;#x200B; &amp;#x200B;
Hey, I wrote the things to look for &amp; approach used when integrate cimgui with your SDL 2 + OpenGL 3 app. At the end of the article, there is a **working project on Github** to look at. I hope some of you will find it useful!
Is there a ‚ÄúC for Dummies‚Äù? I find those books give a steady learning curve, that you can then supplement with deeper and deeper material
Side note: POSIX reserves the `_t` suffix. It's generally advisable to use a different naming convention.
I taught C in college for a few years. It's a really good book.
I taught C in college for a few years. It's a really good book.
Most likely not optimal solution, but you could save prev links, unlink both nodes and then insert\_after them back, with 3 cases: yprev == x, xprev == y, or were not next to each other.
You didn't say exactly what wasn't working, so I'm going to guess your list order gets lost because you're reassigning your pointers in the incorrect order. &amp;nbsp; I changed the notation a bit for my explanation. I am numbering the nodes 0,1,2,3 instead of W,X,Y,Z. Underscore for the links, meaning 0_n means "node 0's 'next' pointer". 0_np means "node 0's next pointer's previous pointer. I hope that makes sense. The order you want is: * 1_n = 2_n * 2_p = 1_p * 2_np = 1 * 1_pn = 2 * 1_p = 2 *2_n = 1 &amp;nbsp; The reason the order matters is that if you think of the pair that is flipping as a single unit, you need to swap the links that go out of that unit (between a swapping node and a non-swapping node) before you swap its internal links (between the swapping nodes). I could relabel the pattern above as follows (thinking of these as the source and destination of an "arrow" representing the pointer relationship were establishing/changing. * in-out * in-out * out-in * out-in * in-in * in-in
Array access notation is just syntactic sugar for dereferencing a pointer offset. Do what you like.
There are two main cases: 1. The two nodes to swap are next to each other, 2. The two nodes to swap are not next to each other. common steps: 1. right pointer of the first node to point where the right pointer of the second node currently pointing. 2. left pointer of the second node to point where the left pointer of the first node is currently pointing. If the nodes __are__ next to each other: 1. Make left pointer of the first node to point the second node. 2. Make right pointer of the second node to point the first node. If the nodes are __not__ next to each other: 1. make left pointer of the first node to point where the left pointer of the second node pointing currently. 2. make right pointer of the second node to point where the right pointer of the first node currently pointing.
Nobody is gonna tell you the steps to do. Just split each up address between the .‚Äôs then convert to binary using bitwise ops.
currently working through "C Programming: A Modern Approach:, and it's the first time I've been able to make any headway with learning a programming language.
What have you tried so far? 
K&amp;R
as usual: pls provide full code. what print() does - code?
Thanks!
The scancode returned by the backspace key is system dependent. You can typically configure this in your terminal emulator.
[https://pastebin.com/K5xQ7UzS](https://pastebin.com/K5xQ7UzS) &amp;#x200B; VIDEO\_ADDRESS is 0xb000 MAX\_COLS is 80
don't you need to add \\0 to those strings?
Array indexing requires an extra index. Which this function avoids. It might compile down to few op codes, but I doubt it matters. I think its just a style of the time. &amp;#x200B;
C does it automatically when you declare them using double-quotes.
Would you mind checking to see if that 4th link is correct? It gives me an error (on mobile). I‚Äôll check again when I‚Äôm at a PC to make sure something odd isn‚Äôt going on
Look at the types of the strings you declared. Generally in C when you use double-quotes you use the const char* type.
Not necessarily. Regardless, changing it to use `const char*` doesn't fix anything.
I think his sight has met a limit. Try Web results A TUTORIAL ON POINTERS AND ARRAYS IN C by Ted Jensen ... PDF https://pdos.csail.mit.edu ‚Ä∫ readings ‚Ä∫ poi...
can you share hardware platform, C revision , compiler you use? is the difference always in using array of chars vs pointer? what if you switch the order : pointer first, array second use array twice with different strings... 
But it does make a difference. When you declare the type as char[] it is equivelant to saying char[] str = {'f', 'o', 'o', 0}; which is a mutable, normal char array. Meanwhile, making it a char* is declaring it as a c-string. I looked it up just to make sure and found this: https://stackoverflow.com/questions/8302290/why-does-char-cause-undefined-behaviour-while-char-doesnt 
I do not see how your SO link is related to this case, SO is about changing const. In this case neither array nor pointer are changed, see posted code of print() in another thread.
I was talking about the solution that was offered in the link
I read reply and all comments I have not found anything related to this case. can you please copy-paste here what exactly in SO post can be helpful here?
'''When you initialize an array with a literal, the literal itself still exists in a potentially read-only region of your program image, but it is copied into the local array''' It is stated to emphasize on the difference between using the different declarations. I am dearly sorry if I wasted your time. 
just do it twice.. struct foo { *members* }; struct bar { *members* }; it's two different structs, they just have the same members and compatible types lol
yes there is 
Hardware is relatively cheap, you can buy a dev board for sub $30 dollars and just use the supplied IDE to program the device. Edx has a free embedded class and I believe they use the TM4C123 board and it's like 30$
Thanks for the explanation. I'll be trying this out tomorrow. &amp;#x200B;
Program the chips that control the flaps of an airplane or the motor in vibrators. 
`itr-&gt;stack - 1` causes undefined behaviour, this is bad code. 
Which is nothing to do with the question in this reddit thread
I would guess there is some problem with your startup procedure (what happens before `_main` is called) that the string table isn't being initialized correctly in memory, or requires special code to access (some platforms have different memory page for constant data). 
You can do everything you want with C. There is no single most interesting thing you can do with it. The limit is what you want you think you can do.
To me its OS's and microcontrollers
gee - ya know I never realised that!
This isn't a C syntax issue. Check the generated binary for memory locations of the string literal constant. It's likely your linker script is bad. 
This is running on QEMU as an x86 (32-bit) program, compiled with GCC 6.3.0. The difference is always in array v.s. pointer; the order doesn't matter.
The terminal emulator is returning `DEL` -- I checked that. However, it is being translated to `C-h` by the time it reaches my program.
&gt;Also avoiding frame functions Can you elaborate on what you mean by that? In a little terminal game I've been making I use functions that create new frames for all kinds of things. For example: When the player gets into an "encounter" it calls a function called encounter_sequence, which initializes the enemies and calls all the functions and animations for the encounter, and then all of it goes away when the encounter is over. It's a totally different scope from the main loop. Is that bad practice? 
&gt;what are the programming areas c language is best suited for Embedded systems. 
That's cool. What did you do it for?
For what it's worth, you're getting downvoted because the responses you've given sound like someone who knows something, but doesn't quite know enough to realize they don't understand the context of original problem. The OP is doing kernel development, not working on a simple C assignment for an intro class or a data structures class. The problem the OP is facing isn't about *using* strings, it's about *making* the infrastructure that strings use -- ie, he's working on the stuff that's going on under the hood. (As such, it's wise to assume he understands how memory works, as well as the specific usage of the const modifier, and he knows that arbitrarily adding a const modifier in this case would do absolutely nothing). Similarly, he's not *using* printf, he's *building* a print system call itself. I'm not saying this to discourage you from participating in helping people out -- but just to highlight that this isn't just a case of someone being mean to you on the internet. :)
Thats a possible solution. you have to duplicate the code for the members however
I'm a gamdev. I use C only with no C++. Thus this workflow allows me to integrate imgui to my game.
You should start by googling the definitions of frame and leaf functions. It will be obvious quickly.
What I was able to turn up suggests it's not a problem unless memory is limited. But mostly it's talking about low level stuff that's a little beyond me. Are there reasons beyond limited memory or readability to avoid using functions as separate scopes to organize a simple game?
Whenever you do assignments like this, draw out the relationships on paper (with pointers etc) and label everything (in next/prev) etc. Then go through your algorithm step by step and see if it does what you think it does.
* Make game with it. You can do things ranging from ground up like high performance math operations for things like matrices, vector transformation taking benefit from SSE/AVX from CPU for parallel computational to boost things up (this part highly recommended to look at cglm), 2d/3d graphics programming with OpenGL, add ability for game to connect to the Internet via curl C API, etc. * Write web app/service/backend stuff with C ! I know this might sound like crazy but it'd be made easier and sound possible with thing like Nginx's Module for someone to try and limit tech stack to work with.
https://sourceforge.net/projects/picsim/ ??
I feel like I'm being trolled.
...also: check out Picaxe, it's a somewhat easier to work with setup for doing PIC chip development and they have some super cheap little starter kits so you can start doing cool little test projects.
You're not. I've been teaching myself C and I do this a lot. Share your knowledge and help me ikprove my habits.
Unless you‚Äôre doing extremely heavy performance optimization, you shouldn‚Äôt worry about the cost of a function call vs inline code. There are many other places to look before that, like the order of nested loops over arrays, unnecessary copying, etc
I checked the binary, and the strings are both there. I suppose I could try a different compiler/linker?
Big O notation right? I know of it but haven't taken the time to learn it well yet. I'm probably lucky my game is small and light on resources. 
It's possible, but I don't think so. Since I'm using C to write a kernel, the C code is quite literally compiled into x86 machine code and appended into my boot process, which simply reads the kernel off of the disk and puts it into memory (then executes it starting at `_main`).
same same
Big O complexity is often the first place to start yes. The things I was mentioning were more about the next step of ‚Äúconstant factors‚Äù thatbig O ignores. But if it‚Äôs fast enough already, then probably don‚Äôt worry about it, especially for this project. Unless you‚Äôre making an action game in the terminal somehow, or doing a ton of dynamic generation or something, you‚Äôre unlikely to encounter serious performance problems.
I‚Äôd recommend the ST Nucleo Series of ARM based dev boards coupled with their TrueSTUDIO IDE and STM32CubeMX config tool https://www.amazon.com/dp/B07JYF8RRB/ref=cm_sw_r_cp_api_i_y0AJCbFBDH6J9
It works just fine. It's a roguelike with JRPG style battles. Why I ask is that the "battles" are activated by calling a massive function I made called "encounter_sequence" which has its own main loop and many functions that it calls until the battle is over. Using pointers the party members' stats are changed during the battle but other than that everything that happens during thr encounter "instance" goes away when the encounter ends, the function ends, and the scope returns to the main function. The enemies themselves are instantiated as a struct at the beginning of the encounter and never even exist in the main scope. It works really well and I'm very happy with it. I just wanted to make sure it wasn't some obvious no-no.
Don't worry about frame or leaf functions unless you're optimizing a specific section of code. For your purposes, writing small functions for specific tasks is a good practice. You don't want to do something like calling a frame function inside a deeply nested loop for example, though.
[http://virtronics.com.au/Simulator-for-Arduino.html](http://virtronics.com.au/Simulator-for-Arduino.html) This is a simulator for the arduino platform. Arduino is very well established, and the actual hardware can be quite inexpensive once you feel you're ready to actually build a project. The simulator above has a free version with some limitations, but the pro license is (currently) only $19, if you decide you like it enough to invest. [http://virtronics.com.au/Simulator-for-Arduino.html](http://virtronics.com.au/Simulator-for-Arduino.html) Official arduino hardware is pretty inexpensive, with an Uno running only $22 at the moment. A "starter kit" which includes a solderless breadboard and various components, will run you upwards of $90. Depending on what your goals are, I would also recommend u/deftware 's approach and pick up learning with a PIC as well. PIC and AVR (Arduino) have long been the big competitors in the uC world, so if you're looking to be a professional embedded dev, you'll want to have experience with both. 
how long it take to make the render of the cat ? Nice project btw
Curiosity. And sometimes I'm working at a generic machine, so by the time I set up my workstation with the various installing and configuring, that's sometimes an hour of my time gone. 
Same Same ... I think it is the most complicated programming task, needs a good knowledge of concurrency control, thread processing, practical knowledge of how a OS operates and most importantly a good knowledge in data structures and algorithms. Eg project :- Designing a basic Shell which supports basic unix commands, Dispatcher shell or you may contribute to open source project such as linux kernel .
https://gnu-mcu-eclipse.github.io There is a fork of qemu hosted there, which can emulate a decent number of MCUs
I had an old laptop that I ran Lubuntu on for school. One day, the fans went out, and while working to fix/replace them, I decided that whoever designed the laptop did so without considering repairs, so I decided to throw it out. Went to the store to get a cheap thing to put Linux on, but fell in love with a Legion (Lenovo fan ‚Äî have a P51 as well). My P51 can‚Äôt use WSL, but boy do I use it on the Legion ‚Äî more than I do the rest of Windows. I don‚Äôt have any real complaints about it except for the speed. It‚Äôs very slow. I do like the lack of a desktop environment. I can use Vim and Emacs in it, and all of the development I do works on any recent Ubuntu deployment. I can develop a C server in the Linux environment and can easily connect to it on the Windows without the need for a remote server. So far, no limitations. Overall, it feels as though I‚Äôm SSHing onto a server and developing there, which is how I‚Äôd normally develop on a Windows computer. The only difference is that now I can work without an internet connection.
I haven't used it in a couple of months but I just kept running into limitations and strange issues. Eventually I decided to run a Debian VM, only to find it has about the same performance as Debian WSL. Go figure.
I use WSL to SSH into other computers and also to write code using Nano. I generally have two WSL windows open, one on the left with the code, and one on the right with the output log. I have installed GCC inside WSL and use it to make text-based programs. I just feel more at home in Linux than trying to do the same in Windows with CMD or straight Powershell.
I've run Ubuntu on WSL even on a super low powered Celeron with an MMC hard drive and it seems pretty snappy and quick. I'm surprised you're having trouble with the speed of it.
I use Ubuntu in WSL and I have a server that has the same LTS version of Ubuntu. I write code using VSCode or Sublime Text and then compile it in Ubuntu on WSL. Then, if I can, I'll test it there and move it to my server afterward. My server is headless so it's the same experience basically as WSL without the limitations I probably should note this is a home server that I use for my own purposes and not a production server running business code.
It‚Äôs incredibly noticeable when I‚Äôm trying to install anything. Trivial package installations can take a significant amount of time, for both the downloading and building portions. Outside of installations, I haven‚Äôt done a lot where I need to pay attention to time. Soon, though, I have to process a corpus of Latin texts, and that‚Äôs not a light job.
it has to do with the speed of their filesystem translation layer, the io performance is really horrid ‚Äî it takes me a good 20 mins to untar a gcc release ): other than the io perf, it‚Äôs pretty good though
Sounds like I shouldn‚Äôt do the Latin work in WSL then. It‚Äôs all file manipulation and takes a solid 40 minutes on a normal Linux machine.
The only thing I hit is that it's 64bit only. So when I have old 32bit sensitive stuff I have to mess with it elsewhere. Otherwise it's great, I found some tutorials on setting up sshd and it's nice being able to ssh into my machine. 
Qemu. It's awesome! That said, plenty of CPU Cores can be found in mame. 
I stopped reading when you said Java is a dying language. It's okay for you to live in a bubble, but there is a real world out there contradicting your stupid ideas. Javascript is a shit language. 
Are you trying to learn assembly, or trying to learn inline assembly?
As in: do you already know assembly?
Read the [manual](https://gcc.gnu.org/onlinedocs/gcc/Using-Assembly-Language-with-C.html) on this matter. There isn't anything more you need to know if you already know how to program in assembly.
Yeah, some basics of 8086
The stl files can be found on (thingiverse.com) . Anything that has lots of triangles will be slow since we need to check for every triangle for every pixel. The cat was around 15-20 minutes at 8 threads if i'm not mistaken. On the other hand, the calibration cube takes few seconds. 
They are both there, but what are the memory locations? The first one is stack memory, the latter is a specific segment which will be specified in the linker script. https://www.google.com/amp/s/www.geeksforgeeks.org/memory-layout-of-c-program/amp/ Check that the addresses are valid at runtime. Check architecture documents etc.. 
If you end up buying hardware, I'm learning with the PIC curiosity board for 8 bit microcontrollers (https://www.microchip.com/developmenttools/ProductDetails/DM164137). It's about $18 but I got it for just $9 during a sale. It includes a nice MCU with lots of features to test.
I ran into problems with serial comms; it seemed that commands like "lsusb" weren't working properly. But then I'm a bit of a noob so I don't know of it was just that WSL doesn't have a kernel or that I don't really know what I'm doing. Everything I was doing worked on an actual Linux machine tho.
XImages are accessible at the pixel level. I haven't worked with nurses in this manner, but it should be simple to translate a pixel's rgb (or whatever) value to a rgba value that a program can reproduce as a pixel somewhere else. There should be as few examples of this on the web, and the libXpm library contains routines that can translate the pixels to a xpm file. Other output formats are available, although I haven't worked with them. To get a x, y coordinate from a data stream, the basic formula is (Pixel_n / row_size ) + (pixel_n % row_size) It seems simpler to me to maintain the data in a one dimensional array, and fold the coordinates this way, than to try iterating over a multidimensional array. Also, you might check out Imagemagick as an external program to create another Image format. Most of it has a command line interface, which in this case night be less cumbersome than the Gimp. 
Related only in spirit, there's still this macro (ifdeffed out though) in certain stdio.h /* * This has been tuned to generate reasonable code on the vax using pcc. */ #define __sputc(c, p) \
Latter string probably goes to .rodata or similar region, separate from normal data. Will adding const for str1 also break things ?
Have you tried mmapping it with sequential access hint, then looping \*p++ \^= \~0; ?
thanks for the detailed answer. i still can't figure out though how i would get the `color_pair` value at some x,y in ncurses. I have tried the `wget_attr` method but it doesn't returns any color pair values for me. I can't find any other API for retrieving attributes
If you want to go into embedded I recommend these things: # Don't use an IDE at first. I generally recommend that, but for embedded even more. Every board works a bit different and usually every vendor ships their own IDE, so getting used to "one" IDE is no use. If you can setup the whole thing w/o the IDE you always have the same workflow. In a company that might not always be possible (since only with IDE you get support etc.), but even then the knowledge of the inner workings help immensely. # Emulators QEMU is a nice emulator. However most of those emulators don't emulate the hardware to the spec! That means that you can run most software for that hardware also on the emulator, but not vice-versa. Picking up a cheap board is more "real". # OS / eco-system Obviously there's the big player ARM but if you're not doing assembly this isn't really much change. The bigger difference is between the boards and what comes with them. STM boards come with their own OS and framework for embedded systems, and so do many others. Each working differently (and having other bugs or total design flaws). There's Arduino which is mostly targeted at beginners and packs its own IDE and compiler (not C, not C++, some weird mix). But unless you want to just do something and not learn how it "really" works I recommend *against* Arduino. Some chips come with FreeRTOS a rral-time os by Amazon, which -- honestly -- is surprisingly good. # No framework You can of course always go completely without any framework and build your own OS -- very exciting! You need a board that also comes with all the hardware registers documented of course, but mostly this is the case. --- Bottom-line: I recommend to use no IDE but manually cross-compile and flash and learn how this works, usually using some kind of serial connection. I currently work on Xtensa ESP32 chips which are *really* simplistic. Also comes with FreeRTOS and all is done using Makefiles and is quite transparent how it works.
Get rid of that one-byte-at-a-time tail (which is buggy btw, you don't perform any bit flipping there). Your failed read returns how many bytes are left in the file. So you can seek set and read all that in one call. Depending on your file size (and hence the tail length) this might take a lot of time. Other than that if you are running a release build you should be plenty fast already. To assess your quality of implementation I would perform a single read and a single write of the unmodified file then compare against that baseline. After that you can try multithreading to further improve performance but make sure not to cause false sharing if you do.
The most likely issue is that your kernel expects to be loaded at a particular address but the loader is putting it somewhere else. Thus the string constant is not where the program expects it to be. Can probably be fixed with compiler/linker flags. 
I'm sorry, I didn't follow you. What is memory mapping? And what is sequential access hint? Could you explain it?
That's been a big complaint I've come across with it though it sounds like it has gotten much better over the last couple years and still aims to improve
I think he means mmap(), which kinda places the file into ram, and accessing the data in ram with pointers 
&gt; This code takes around 10-20seconds to run for a 366MB file. Even for an HDD this is terrible: 18.3 - 36.6 MiB/s, modern ones can do sequential reads at about 80-150 MiB/s (note that write speeds aren't as important here, because the writes are done async by the kernel &amp; the HDD controller, so your program continues executing even if no data has actually touched the HDD). So yes, there is room for improvement. Try mmaping the files, as was suggested. 
I've loved my experience with Linux outside of the text editing in it for coding purposes. I tend to use vscode for coding then ftp my stuff over to my class's server for compiling. Cmd and Powershell just don't feel the same.
I'd recommend to call either getaddrinfo or inet_pton to validate ip addresses. There's quite a few nuances to it, both for IPv4 and IPv6. For getaddrinfo pass the AI_NUMERICHOST flag to avoid dns lookups. 
That would be a screen attribute, which might not map directly to a color depending on the machine's display driver. If the system has a gui, then maybe it would be better to draw in a X window, which has full color support in the API, and the mechanism to translate that into a corresponding pixel value for the display. If using the ncurses interface is necessary, though, then the program might just need to map whatever attributes are there to the rgb value or values of your choosing, if the attribute provides enough detail to do so. To get the actual content of a character cell though, it might be necessary to peek into the window's buffer if you can do that - assign a color based on the character (eg a line drawing character) and it's attribute also. 
I need to invest in putting my own little home server together. I actually have a server to mess around with website building but this just made me think to check what is running on it. Not a home server but I got some personal server space for crazy cheap a couple months ago.
Yes, in combination with CLion. There are indeed some performance and implementation issues as already mentioned, because WSL is not a VM nor a dedicated linux host, but for me it's sufficient.
I do. But not really. If I‚Äôm programming something graphical I use the windows compiler alongside the improved build tools on Linux. Because WSL can run Windows binaries, if u compile something for windows on WSL and then run it from WSL it‚Äôll actually show up on windows. Otherwise I try to stick with Linux compilers and environments when possible. Eg. For this java assignment I had I wrote a makefile to build everything. Windows make equivalent hasn‚Äôt been updated in over a decade and I really liked the new features on the Unix version. Anyways now I‚Äôve switched to rakefiles which I love way more, but I‚Äôm having to deal with the fact that ruby refuses to accept any windows Paths on my Path variable and warns me consistently about it. So either ditch all those good windows binaries or put up with a warning that‚Äôs trying to get me to just delete my entire environment.
Have fun! :)
Check if the character is one of `0123456789abcdef`? You can also use `isxdigit` from `ctype.h`.
FWIW: It doesn't place it in ram. It just places it in your process' address space. 
Right off the bat, it's worth mentioning that a long is a 4 byte number. The maximum number that 4 bytes can hold is 2147483647 (which is much smaller than 4444 4444 4444 4444). The point? Use a long long to hold the credit card number if you can. If not, you can try a double. Without having read all of your code, it wouldn't surprise me if this is the problem. The ccnumcheck wouldn't catch this because when you overflow a typed variable, getting a large negative number is not an uncommon result.
If you are on unix, see mmap(2) and madvise(2) manpages. Just for fun, I tried it myself [https://pastebin.com/GPvng60U](https://pastebin.com/GPvng60U). 366 meg file. crappy old 32bit laptop, SSD though. FreeBSD. fread/fwrite took just under 4 seconds mmap without MAP\_NOSYNC took 5 seconds. mmap with MAP\_NOSYNC took 1 second.
Are those with a cold disk cache? And you're doing it in-place, his programs works with 2 files. With a cold disk cache and a 512MiB file i got `2.15s` with both files mmapped, and `2.54s` with only the input file mmapped. A quick benchmark with dd gave me 542MiB/s reads, so effectively working with 2 mmapped files i get half of that. Which is not surprising maybe.
Books? I just read the [GCC manual] and looked at some [existing source code]. I'm not an expert at assembly programming, though. I just learned what I needed to do what I want. [GCC manual]: https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html [existing source code]: https://git.musl-libc.org/cgit/musl/tree/arch/x86_64/syscall_arch.h
WSL is a bastardized Linux environment. It works, and it's neat, but the little quirks like the aforementioned message queues make it not ideal. [Vagrant](https://www.vagrantup.com/) was pretty much designed for this. It gives you a reproducible environment. Do you remember all the 'apt-get install libsoandso-dev' that you've done inside your WSL to get your c code working? Another option is Docker, although it's not much better than WSL for doing development in. Your best bet will always be a real Linux machine.
When I take out the outer do - while loop, the program works fine. I've tried printing out the ccnum and ccnumcheck and it comes out as the same the number I input. The only problem I'm having is that if the input validity is not zero and it will asks for a new input. But even after putting in a new input, the program will still use old input for the rest of the calculations. I tried your advice and changed ccnum and ccnumcheck to long long but it still doesnt work.
What didn't you like about text editing in Linux? Other than LibreOffice's imperfect compatibility with Microsoft Office, `gedit` and `nano` have never failed me. Is it related to line endings (Windows' `\r\n` vs Linux's `\n`)? If it is Visual Studio you want, it is available as a `deb` or `rpm` for Linux directly on its website. Cmd and Powershell definitely are not as useful as opening an Ubuntu WSL window, which actually opens faster then Powershell. They just do not feel as complete and some of the idiosyncrasies, such as Windows' backward slashes for file paths and other funny-business. WSL definitely helps make me feel more at home on Windows, but I still prefer using a full Linux machine if I can.
When you use the literal `"hello"` in your code, this itself is an allocation of constant data. `label` probably ends up pointing directly at that constant data, instead of being its own array. Alternatively there might just happen to be a 0 after the end of `label`. Don't rely on this :)
What's the difference?
&gt; Don't I have to allocate a memory for '\0'? Yes you do. &gt; But if I run this program it prints hello. Undefined behaviour. It just so happens that it seems there is an `\0` after it, but don't rely on this.
The problem there is probably Windows Defender. Add an exclusion for the WSL folder (and turn off indexing for it). Here, time for untarring gcc-8.3.0 was 7.5 minutes with Defender on. 57 seconds with it off. An Ubuntu VM completed it in 45 seconds. This is on a SATA3 SSD.
yes, you need to allocate extra char for '\\0' char label\[5\] = "hello"; is allowed, but '\\0' is not actually added, and compiler will not warn you char label\[5\] = "hello#"; here compiler will warn that initialization string is larger than array size not obvious :(
Vscode is available on Linux too, btw.
Assembly uses an assembler to translate programs from assembly language into object code. The author of an aseembly program is pretty much in complete control of the content and structure of the program. They can do whatever they like, whenver they like, however they like. The assembler eats the code using pretty widely-accepted syntax, spits out the object file, and that's that. Inline assembly is a special sub-language used inside a C program. The author of inline assembly code is working with a compiler, not (directly) with an assembler. There's no real standard for inline assembly code; one compiler vendor might make inline assembly work one way, another might have a different syntax. The author of inline assembly has some control, but has to play by the compiler's rules for the inline routine -- the way it manages the registers and stack, in particular, have to be compatible with the aseembly code's context in the rest of the program. Learning assembly is about learning the processor; about learning programming, and learning which rules to follow when (and when to not follow rules.) Learning inline assembly is mostly about learning the compiler, it's environment, and rules ... and is probably something best for someone who already knows assembly, generically, at the start.
From looking at inline assembly, the syntax looks the same as standard assembly?
Those are the most interesting things for the language the C Standard was written to describe ("Ritchie's Language"), where many actions are generally processed in a documented fashion characteristic of the environment--hardly surprising, since they fit well with the purposes for which that language was designed. Unfortunately, some compiler writers seem to think the name C should be applied only to a language where "behave in a documented fashion characteristic of the environment" is replaced by "behave uselessly unreliably unpredictably". Unfortunately, modern that compiler philosophy ignores the best feature of Ritchie's Language: compilers can support a wide range of environment-specific behaviors without having to know anything specific about them. This makes the language especially useful in cases where the programmer knows things about the environment the compiler writer doesn't (and in some cases can't possibly) know. If a compiler processes loads and stores of `volatile` objects by preparing for them as they would calls to unknown functions which accept the address/data as parameters, then almost any action the environment might trigger in response to a load or store could be supported by the compiler without having to use any special syntax, and without the compiler having to know or care what particular effect the load or store might have. A programmer, for example, might configure an embedded environment to allow the use of something like: extern volatile uint16_t *background_out_ptr; extern volatile uint32_t background_out_count; void await_output_completion(void) { while(background_out_count) ; } void start_output(uint16_t *buff, uint32_t count) { await_output_completion(); background_out_ptr = buff; background_out_count = count; OUTPERIPHERAL-&gt;REG = 1; // Enable interrupts from appropriate peripheral } to allow client code to request that data be transmitted from a buffer "in the background". A Ritchie's Language compiler won't have to know about any means of performing background I/O or care what the system might do with the storage identified by `buff` between a call to `start_output` and `await_output_completion` if user code never accesses the buffer during such times. Because some environments have many ways by which loads and stores can trigger "interesting" effects, while others have none, the authors of the Standard deferred to compiler writers' judgment as to what form of `volatile` semantics would best fit their customers' needs. Unfortunately, some compiler writers interpret that as encouragement to require that customers use special syntax whenever they need semantics beyond the bare minimum the Standard mandates, rather than supporting whatever semantics would be appropriate for the implementation's target platform and application field. 
Also only string literals are null terminated not character arrays right?
Also only string literals are null terminated not character arrays right?
It prints "-10" for me. How are you compiling and running the code?
I quickly tried and I'm not seeing it. Not sure why it would behave differently on your end. Instead of the if-statement you could just use **printf("%3d", y\_axis);** to align your output. It's not the cause of the missing sign of course. &amp;#x200B;
I guess you mean 'brace-enclosed list of initialized for array member ' - this construction is never terminated with zero or anything else.
Any reason you specifically need to use C or C++? You‚Äôre going to have a lot of modifications for the wide variety of different platforms your aiming at. Just the browser automation, I‚Äôd go Python. The Selenium and Requests packages worked flawlessly for me, scraping data and page navigation flows really well. And it‚Äôll port easier. No re-writing of the code, just get an environment it can run in. Selenium can look complicated but just look for examples similar to what you‚Äôre trying to accomplish, and build from there. 
Yes. 
.
I‚Äôve never used it before, but [PhantomJS](http://phantomjs.org) seems to have some weight in this field. You could look into that. There‚Äôs also [Selenium Server](https://docs.seleniumhq.org/download/) which seems to be something you can just call from C/C++ over the network. Or you could do something like this and develop an API or something on a server that you could send and request data. Neither of these may work perfectly in your case, but they seem to be the best bet, from what I can tell. C/C++ is a little bit away from the abstraction of Web Browser automation, without heavily hard coded development differences for different platforms, I would presume. 
You can use headless chrome. https://developers.google.com/web/updates/2017/04/headless-chrome There may be enough there for you to make exec calls to the cli, but there‚Äôs also an RPC type protocol that you can interact with the control it. I don‚Äôt know if such an sdk exists in C or C++ yet, but maybe you could implement it. Additionally, there is an SDK in Go. You could compile this in go and link it into your project. 
if validity is not equal to 0, you print "Invalid credit card number", and then you restart the process. I think you need to set totalDigits back equal to 0 (in the if statement where you check validity at the end). Make sense?
Since I don't have dual booting set up yet all I have access to is vim if I wanna text edit, as far as I know so that would be why though I could've specified I didn't have access to an actual machine, just terminal
Good to know, I'll keep that in mind when I can get dual booting set up. I just only have either wsl or ssh into my class's server to work with for now
I'll take a look at that when I have time. Thankfully wsl's quirks isn't to pertinent for me since I have my class's server to work on. Still nice to get people's input on it though haha
If you want a character array to function like a string (for the purposes of print functions, strcpy, strcat etc) you must allocate memory (ie an extra byte) for the null terminator, and set that value yourself. When you declare a string literal, the compiler includes the terminating zero for you.
It's printing correctly because you got lucky, and there was a 0 after "hello." On a \*nix system, you can inspect it yourself with `objdump -d ./a.out`. Your string literal should be in the read-only data section, .rodata.
To me the main problem, oyher than the super slow filesystem, is that Windows aoos like IDEs or Text editors can't access the environemnt of WSL for debugging, linting and version controlling... I just ended up using Scoop in powershell and doing everything in the Windows environment. Now I'm on native Linux and I just like it more
Yes. Unless you need to change them, string literals should generally be used like this: const char *my_string = "My string literal!"; The compiler will take care of counting the string and nul-terminating it.
Excellent points. I gave been diving deep into the language and I hear your sentiments all the time. Among others. The language is beautiful and simple and powerful. As intended. 
It is less error prone to initialize a character array like this: char label[] = "hello"; The compiler will add the '\0' for you.
What is wrong with using Nano? In case you did not know, it is a terminal program just like Vim except that it is much friendlier. Just run ‚Äúnano filename.ext‚Äù and it will open. Do your editing by moving around with the arrow keys just like normal. To save, use Ctrl-o. To exit, use Ctrl-x. Nano is pre-installed in every machine I have come across.
[removed]
If I add `const` to str1, the program won't even compile.
If you don't specify the length of your array and initialise it with a string literal or specify a sufficiently large array, it is going to be NUL terminated.
I'll look into that but I dunno. I don't like only being able to move around via arrow keys I guess. Very used to using my mouse to scroll and click around larger files at least.
Sounds like you're comparing some bits of code you found rather than the definitions of the comprehensive definitions of the different languages. A deeper comparison will reveal the differences; remember to also compare different solutions for different vendors on different platforms.
not only 'change them'. using array is also useful to get correct size without strlen() char str\[\] = "hello"; printf("%lu**\\n**", sizeof(str)); this will give you '6' (including terminating zero) char \*str = "hello"; will give you the size of the pointer depending on the HW platform &amp;#x200B;
Mouse scroll is generally bound to the arrow keys, so mouse scrolling works fine in Nano, but that is probably a function of the terminal emulator, which may differ. Nano is meant for when you do not have a mouse, such as when you want to edit a file via SSH on a remote computer. If you want to edit files locally with a GUI, use Gedit, Visual Studio, or Notepad++, all of which are free and open source. They all have advanced features such as code highlighting.
Nano... so does that mean your choosing nano over vim or emacs or u just haven‚Äôt tried either of them yet?
I‚Äôd definitely suggest trying out vim or emacs. You should at least be passibly familiar with text editing from the console (for git commits, or small scripts or mediocre tasks) and seeing as vim is part of the posix specification (and is therefore available on most linux distros by default) and that emacs is designed to provide close access to the terminal/shell, if your planning to stay on a shell for quite a long time either and/or both are must have skills to add to your tool kit.
No, not a flame war! I kind of knew this would start one. I am not interested in a long debate about which one is superior. I am listing my opinions below in case you want to know my reasoning. If you would like to teach the OP how to use a different system, knock yourself out. Nano, in my opinion is far easier to use than Vim. I have not used Vim or Emacs very much, as most guides use Nano. This gives credibility to the notion that Nano is easier to pick up for beginners. I suggested it because it is the most similar to the usual GUI text editors and I only had to show the OP two keyboard combinations, both of which are shown on the bottom bar of Nano. So yes, I am choosing Nano because I have not used Vim or Emacs extensively and I do not want to. I am not one of those people who learned Vim or Emacs on Unix back in the Eighties. It is what I am used to and if I want more features, I will use Visual Studio, Code Blocks, or some other IDE.
Most scanf formats skip over whitespace. Its presence matters, not how much. Also read this: https://latedev.wordpress.com/2012/12/04/all-about-eof/
Heya, hope this helps. So, bottom line is that you'll generally want to avoid using the scanf functions, especially when you're also using fget functions, because the way they interact with the input stream can be a bit weird (e.g. scanf will sometimes leave a \\n in the stdin buffer which can make fgets ignore the next input because it'll read that instead). If you look at `man sscanf` (yours may be different due to architecture): The format string consists of a sequence of directives which describe how to process the sequence of input characters. If processing of a directive fails, no further input is read, and scanf() returns. A "failure" can be either of the following: input failure, meaning that input characters were unavailable, or matching failure, meaning that the input was inappropriate (see below). A directive is one of the following: ¬∑ A sequence of white-space characters (space, tab, newline, etc.; see isspace(3)). This directive matches any amount of white space, including none, in the input. ¬∑ An ordinary character (i.e., one other than white space or '%'). This character must exactly match the next character of input. ¬∑ A conversion specification, which commences with a '%' (percent) character. A sequence of characters from the input is converted according to this specification, and the result is placed in the corresponding pointer argument. If the next item of input does not match the conversion specification, the conversion fails‚Äîthis is a matching failure.= The important part here is that any amount of whitespace is matched - **including none**. So when you have your sscanf directive defined as `%s\t%s\t%s\t%[^\n]`, that's telling it to ignore whitespace characters because you haven't put any in there (except tabs). If you're set on using sscanf, you'll want to put spaces in your directive (and even then it might still behave weirdly. I'd strongly recommend using fgetc to iterate over each line until you hit a \\n or a \\0 character, then getting the next line or closing the input stream and exiting respectively. If you've any more questions feel free to ask away, and if I've made any mistakes please do correct me - I'm always happy to learn :)
zeefze
zeze
could‚Äôve sworn i disabled it, but i‚Äôll check again; thanks for the heads up
Thanks for all the info!!, now I understand why scanf is doing this in my code, I read the links and I'll be making changes also in my eof because I also didn't know that I shouldn't be using !feof(fp) so I'll change it cause of it's risks with error so I'll write it in another way.
Also I had tried using strtok this way inside my while loop but it did the same thing with where the spaces were present, it moved it to the left so it saved what should be op (from the second column) as if it were from the first column that is lb., I also tried changing the " " with "\\t" in all of them and it also didn't work. fgets(line,100,fp); char* lb = strtok( line, " " ); char* op = strtok( NULL, " " ); char* oper = strtok( NULL, " "); char* comm = strtok( NULL, "\n"); printf("%s\t%s\t%s\n",lb,op,oper); &amp;#x200B;
Browser Engines aren‚Äôt methods to automate browsers, they are how the browser operates. Gecko is Mozilla‚Äôs name for their Browser Engine that handles parsing of HTML and such in a browser. WebKit is Apple‚Äôs version. Essentially you just need a way to emulate or manipulate properties of a browser engine with another program, hence, the browser automation. What exactly are you trying to accomplish? 
Unlike scanf, for strtok space and tab are distinct characters...
Thanks!!, so then neither fscanf or sscanf should I use when dealing with white-space because it ignores it, so that is why it's eating the spaces because it ignores them. But if I used fgetc, I searched how to use it and found that I could use it like this int ch= fgetc(fp); while( ch != EOF ){ printf("%c", ch); } it worked!! exactly as fgets, so I will try with strtok, I already have this but it still gives me error and am searching if I'm using it incorrectly inside the while loop because it gives me a lot of NULLs int ch= fgetc(fp); while( ch != EOF ){ char* lb = strtok( line, "\t"); char* op = strtok( NULL, "\t"); char* oper = strtok( NULL, "\t"); char* comm = strtok( NULL, "\n"); printf("%s\t%s\t%s", lb,op,oper); } &amp;#x200B;
I recommend you use a couple of functions like char *skipSpace(const char *p) { while(*p &amp;&amp; isspace(*p)) ++p; return (char *)p; } char *skipNonSpace(const char *p) { while(*p &amp;&amp; !isspace(*p)) ++p; return (char *)p; } These will let you walk through the various parts of the string. You can break it up into pieces by overwriting whitespace with NUL.
azz 
I've done a bit of reading and strtok is a bit odd. In essence it binds itself to whatever variable you give it, then each time you call it again it returns the next token. What you'd probably want to do if you want to split it by tokens would be to read in each line of the file using `fgets`, then call `strtok` on the line until it returns NULL - which indicates that there are no more tokens. This would look something like char lb[256]; // Line buffer char* token; // Token pointer while (fgets(lb, 256, fp) != NULL) { // Read each line token = strtok(lb, " \t\n"); // Read first token do { printf("%s\t", token); // Print token } while ((token = strtok(NULL, " \t\n")) != NULL); // Read next token printf("\n"); // Add newline so output isn't all on one line } Note that for each subsequent call of strtok on a line, you should pass NULL as the first argument so it knows to continue on the same string instead of starting over. Hope this helps! 
Do you ever initialize mainCtx?
Looking at the documentation, the context functions can only take `int` arguments and you're trying to use a `size_t` one. That's certainly a problem, especially on systems where they're different sizes.
Anyways, the problem seems to be that 1024 bytes is not enough stack space. Increase `STACK_SZ` to 2048 (Which happens to be the value of `MINSIGSTKSZ` on my system, see `man sigaltstack` for details) and it works for me.
You have a bug in your program. Run it in the debugger and it'll stop at the fault instead of showing an unhelpful message box
That error is for a video game, using MS Visual C++. I suggest you try Googling that error, or checking with the games user base, or trying a different sub, as this is for C Programming, which is not the same as C++, let along MS Visual C++. &amp;#x200B;
Okay, I'll try it like with what you wrote, since I have never used strtok, I'm still learning how to use it, so just to be sure, when strtok reads the line, it will also read the space so it will save in a way it maintains the order when it gets to parts like this CLOOP JSUB RDREC READ INPUT RECORD LDA LENGTH TEST FOR EOF (LENGTH = 0) COMP ZERO &amp;#x200B;
 #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #define BUFFER 64 int string_to_double(const char *, size_t, double *); int main() { char strd_buf[BUFFER]; double result; printf("Insert double:\n"); fgets(strd_buf, BUFFER, stdin); string_to_double(strd_buf, strlen(strd_buf), &amp;result); printf("Double: %f\n", result); return 0; } int // why not void, I see no real benefit of the returns string_to_double(const char *str, size_t len, double *result_ptr) { if (len + 1 &gt; BUFFER) // I'm not sure why I should use that return -1; // but okay *result_ptr = strtod(str, NULL); return 0; } I don't know if this is what you were looking for
That doesn't work properly if the string passed to string_to_double is not null-terminated.
\`strtod\` only works with null-terminated strings and \`str\` may not be one. You need \`int\` as a return value to detect if the input string was a valid number.
 #include &lt;stdio.h&gt; int main() { char str_one[5] = {'h', 'e', 'l', 'l', 'o'}; char str_two[] = "hello"; int i; printf("\nstr_one: %lu\n", sizeof(str_one)); for (i = 0; i != sizeof(str_one); i++) printf("[ %02i ]\t%c\n", i, str_one[i]); printf("\nstr_two: %lu\n", sizeof(str_two)); for (i = 0; i != sizeof(str_two); i++) printf("[ %02i ]\t%c\n", i, str_two[i]); return 0; } Output: str_one: 5 [ 00 ] h [ 01 ] e [ 02 ] l [ 03 ] l [ 04 ] o str_two: 6 [ 00 ] h [ 01 ] e [ 02 ] l [ 03 ] l [ 04 ] o [ 05 ] str\_two\[5\] is '\\0', but printf won't print a visual character. &amp;#x200B; char str\_one\[5\] = {'h', 'e', 'l', 'l', 'o'}; Here you give each position in the string a character and if printf gets the end is luck-based because it looks for the next '\\0' behind it, which could be directly after or x byte later, where x could be about any number. &amp;#x200B; char str\_two\[\] = "hello"; Your compiler does everything, he uses 6 bytes of space, puts hello into it and ends it with a '\\0'.
Yeah, but that's something I check when I get the string. If I want the len and check with strlen() to get it, I already read out of memory... &amp;#x200B; In my example I defined the max-len before
[https://www.reddit.com/r/C\_Programming/comments/b2eovy/convert\_nonnull\_terminated\_string\_to\_double/eisbb2h](https://www.reddit.com/r/C_Programming/comments/b2eovy/convert_nonnull_terminated_string_to_double/eisbb2h)
[https://www.reddit.com/r/C\_Programming/comments/b2eovy/convert\_nonnull\_terminated\_string\_to\_double/eisbb2h](https://www.reddit.com/r/C_Programming/comments/b2eovy/convert_nonnull_terminated_string_to_double/eisbb2h)
Hot cache. Each just repeated until stable result. My cached disk read speed is 1900 MB/s with 32kB or bigger blocks, but only 1100 MB/s with 4kB blocks. I wonder how large chunks the mmap uses, hw page or fs block ?
As a test case, replace the `main()` function body with: double result; string_to_double("12345", 2, &amp;result); printf("Double: %f\n", result); return 0; I passed `string_to_double` a length parameter of 2, meaning that it should only treat the first two characters of the first argument as being valid. This code should therefore print `Double: 12.000000`, since it should stop reading after the second character. However, it actually prints `Double: 12345.000000`. This indicates that it is reading past the end of the string!
In your existing code you could do `char buf[len+1];` instead of using the maximum size, once you checked the size isn't insane. And the `*buf == '\0'` test could come before `strtod` call since you don't use the result of the call in the case. One way to avoid the buffer would be to use `sscanf` which does allow field width to be specified, but the code for that is also ugly since the width isn't known until runtime: char fmt[30]; snprintf(fmt, sizeof fmt, "%%%zuf", len); return -(1 != sscanf(str, fmt, result_ptr)); 
Now I get what you mean, but that's not undefined behavior and the problem is not the missing '\\0' &amp;#x200B; int string_to_double(const char *str, size_t len, double *result_ptr) { if (len + 1 &gt; BUFFER) return -1; char buf[len + 1]; int i; for (i = 0; i &lt; len; i++) buf[i] = str[i]; buf[i] = '\0'; *result_ptr = strtod(buf, NULL); return 0; }
That works correctly, but the code effectively makes a copy of the input, which is exactly what the original poster was trying to avoid.
One of the best habits I learned from this forum is to use -Wall whenever possible. 
I cannot alter the const char \*, so I have to get some memory to get a '\\0' in there. I'm not proud because it won't work in a lot of cases: int string_to_double(const char *str, size_t len, double *result_ptr) { if (len + 1 &gt; BUFFER) return -1; // please just don't use it, result_ptr won't carry more chars than sizeof(double) *result_ptr = strtod(memcpy((void *) result_ptr, str, len), NULL); return 0; } &amp;#x200B;
Yeah, to avoid a very hacky, ugly solution (or a buffer in the function) everything should be done before or avoid using a const char \* to alter the string directly &amp;#x200B; The only thing I could think of was using len or result\_ptr as a buffer (which shouldn't be done and won't work in all cases)
Yeah, I managed to fix it now. Your suggestion gave me an idea of what was wrong with the code. The new input was overwritting the variable and it was using it for the computations. But it kept printing " Invalid Credit Card number " because all the "a-th" variables still has stored value , so I needed to reset it back to 0 in the ' if validity is not equal to 0 ' statement. I also stumble upon other problems that wouldve occured in the program and I needed to set totalDigits back to 0 in the first " if totalDigits &lt; 13 " statement and also the if statement that you suggested. Thank you very much for your help. I'm very happy that the program works the way I intended to now.
‚Äò-Wall -Werror‚Äô- if now you can only fuck up on purpose.
This is a C subreddit, not C++
char \*str = "hello" gives 5, since this is a pointer shouldn't the '\\0' be added automatically and return 6 instead of 5?
Also only string literals are null terminated and not the character array right? I also have a question: char *arr = "hello"; printf("%ld\n",sizeof(arr)); //this prints 8 instead of 6. Why? &amp;#x200B;
If this is not just for testing things, consider allocating the stacks in such a way, that you can munmap() a region below each stack. To catch overflows.
size of calculates the size of variable. in our case it is pointer, which is always(\*) the same for any type of data it points. int\*, char\*, double\* - will be the same size. for your platform it's 8 bytes. does not matter where this pointer points to. for array - sizeof() will provide the size of array
some more example: char \*arr = "hello"; sizeof(arr); // 8 arr = "Hello, World!"; sizeof(arr); // still 8
so 8 bytes is automatically allocated for char\* pointer??
This subreddit is about programming in C. For tech support questions, please post in /r/techsupport.
yes, that's the length of memory address in your platform don't be confused: 8 bytes are for the address. not for the characters in initialization string. ini-string memory is allocated separately. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
If you program that way, you are a bad C programmer. You do not ignore warnings. You carefully consider them and after you determined that the warning is not indicating a problem in your code, you disable it.
Someone: My program doesn't work! Me: Compiles Compiler: Warning, warning, warning, ... Me: There! Fix it. They: *fixed them* Oh, the problem has gone away! rinse, repeat. Sadly they don't even learn. Alternative ending: They "fix" it by disabling the warnings or something similar.
I am actually confused isn't pointer dynamically allocated? If I do sizeof(\*arr) will it return 6??
Does -Wall include -Werror?
So I had a little confusion while reading the gcc man page. Does this combination of arguments turn all the minor syntax warnings that still compile into full errors that prevent compilation?
let's assume your variables are in function void func() { char \*p = "hello"; // 'hello' is static mem somewhere outside the function, size 6, p is allocated in stack size 8 char a\[\] = "hello"; // s is allocated in stack, size is 6 (including '\\0') another\_func(p); // the address stored in var 'p' will be used as a param, addr will point to 'static mem somewhere' another\_func(a); // the address of the 'arr' will be used as param, it will point to 'arr' in stack } &amp;#x200B;
Every warning is an error. That's one of the first things one should have learnt when programming. 
Nope. These days, quite a few warnings are superfluous and annoying. I typicall compile with `-Wno-parentheses -Wno-braces` (not sure of the exact name for the second one right now). In gcc, `-Wno-unused-result` is some times needed, too due to their broken semantics.
Even worse is when ‚Äúwarnings‚Äù are just someone‚Äôs preference in syntax. Java is especially annoying with that.
These two warnings are exactly about this issue.
This flew over my head, thanks for pointing it out.
Yup, increasing `STACK_SZ` solves the problem, thanks for the help.
Yes, -Werror does that. -Wall adds more warnings, -Wextra even more.
 #include &lt;stdio.h&gt; #include &lt;string.h&gt; int main() { char *arr = "hello"; char ar[] = "hello"; printf("arr: %lu\t%s\n", sizeof(arr), arr); printf("ar : %lu\t%s\n", sizeof(ar), ar); arr = "bye"; printf("arr: %lu\t%s\n", sizeof(arr), arr); /* ar = "bye" printf("ar : %lu\t%s\n", sizeof(ar), ar); */ return 0; } The ar = "bye" is committed out because it'll give an error: make test4 cc -O2 -pipe -o test4 test4.c test4.c:17:12: error: array type 'char [6]' is not assignable ar = "bye" ~~ ^ 1 error generated. *** Error 1 in /home/sinus/c_code (&lt;sys.mk&gt;:85 'test4') Output: arr: 8 hello ar : 6 hello arr: 8 bye So it's pretty simple, char \*arr and char ar\[\] are different types :)
Use gets() function char str[100]; gets(str);
-pedantic for extra points
Yeahh, I learned about the getline stuff, but I was just wondering if what I was saying is correct. That cin does not get any whitespace (without getline) and that storing a string variable can get whitespace 
/r/Cplusplus 
1. [Never use](https://stackoverflow.com/questions/1694036/why-is-the-gets-function-so-dangerous-that-it-should-not-be-used) `gets()`. 2. You're asking about C++, but you've posted on a C programming subreddit. You would likely receive more reliable answers somewhere like /r/cpp_questions. 3. In C++, the behaviour you described is correct when using `&gt;&gt;` to obtain a string. To work around this, look at `std::getline()` or `std::fgets()`.
Oo I was looking for a C++ subreddit but this was the best I could find. Thanks! 
Update your own picture\[\]\[\] while you draw.
You can't go wrong with `-pedantic -Wall -Wextra -Werror` :)
Screw that. `-Wall -Wextra -Werror -pedantic` for life!
Pedantic can be a bit overkill at times, but all code at work uses the other three!
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Indeed. The more warnings the better, also, I fix them all. 
I bet you're fun at parties 
My work says "don't have any warnings". They don't listen to that themselves. The current working branch has 7,000+ warnings in it.
I understand, thank you! I've already got a VM going :)
Ah, those are very helpful thank you! 
If they pull in external libraries -- Open source code, for example -- you often have little choice but to live with warnings.
To be fair, the second one was likely added after the SSL bug, and the first is a very common mistake people make. if (a=b) ... instead of if (a == b) ... &amp;#x200B; I agree, they are both style things, but requiring the extra parenthesis to demonstrate that "yes, I really mean an assignment here and to compare against the second value alone isn't zero" isn't a horrible decision, and likely stops enough bugs to justify its existence. 
That's fair. I've used vim a bit already. I think doing stuff on my class server through putty acted kinda weird or something which is why I was adverse. I got Ubuntu installed so I'll be looking into these more
&gt; To be fair, the second one was likely added after the SSL bug Nope. This warning warns you when you leave out braces around initialisers for substructures or array members. I typically leave them out as they are just useless noise. &gt; if (a=b) ... instead of if (a == b) ... It's not the `(a = b)` I have a problem with, rather it's clang's insistence that `a + b &gt;&gt; c` or `a &amp;&amp; b || c` or `a &amp; b | c` warrants a warning. Because apparently people are too stupid to understand operator precedence rules. I dislike having to write superfluous parentheses, so I turned of this warning. For assignments, I started to turn `if ((a = b) == c)` into `if (a = b, a == c)` for better readability.
&gt; For assignments, I started to turn if ((a = b) == c) into if (a = b, a == c) for better readability. How in the hell is that better readability? a = b; if (a == c) {... } is more readable than both, and doesn't have me going to look up comma rules.
&gt; How in the hell is that better readability? In this case I agree it is not. The typical cases I have are `while` loops: while (optchar = getopt("...", argc, argv), optchar != EOF) switch (optchar) { ... } while (c = getchar(), c != EOF) ...
I can see that. And I tend to agree that "for style"-only warnings are bad ideas (which was the basic starting point.) In this case, I would actually prefer the styling of: while ( (c = getchar()) != EOF) { ... } Mainly because the comma operator isn't used frequently. I'll confess, wI may even write the line as: for (c = getchar(); c != EOF ; c = getchar()) { ... } And then cringe at the same statement twice in a line (but, realistically, the compiler will deal with the assembly instruction ordering in both cases.) 
&gt; And then cringe at the same statement twice in a line (but, realistically, the compiler will deal with the assembly instruction ordering in both cases.) The problem with having the same statement twice is that you may forget to update one when updating the other. In my opinion, you should not get near a C compiler if you don't know about the comma operator. That's a fundamental feature of the C language and not knowing about it is inacceptable.
It took a little while to work then all out of the C code. The Java code, on the other hand... well, it reports 1000 warnings every time, but that's because Java has a flag to stop printing warnings after it hits a certain count &gt;.&lt; Those warnings will be of different severities. You might want to hit it with Clang's scan-build, which is a static analyzer. It'll tell you which ones are most likely to cause the biggest problems. At least that will permit prioritization.
Converting a string to a `double` is not a fast operation. The time needed to copy the string beforehand is insignificant compared to the time the conversion takes. I wouldn't worry about this too much.
Well, that's a nice bit of gatekeeping you have there. The comma operator is one of those operators that could literally be dropped from the language without losing any expressiveness.
&gt; Well, that's a nice bit of gatekeeping you have there. The comma operator is one of those operators that could literally be dropped from the language without losing any expressiveness. You could drop a lot of the language without losing expressiveness. It just gets more tedious to express what you want. And yes, I am keeping the gate here. Is it too much to demand that habitual C programmers actually know their language?
"Know the language" to your specific criteria, yeah, that's a bit much. I am a habitual C programmer. I don't use the comma operator simply because it doesn't come up as often as bit-manipulation or function pointers. I also use parentheses around expressions like ((a &amp;&amp; b) || ( b &amp;&amp; d)). I don't want to care about precedence to work something out. It doesn't hurt to add the parentheses in that case. And if your expression becomes that complicated, I prefer to make it even more expressive: If ( isCornerCase(a,b,d)) I've been bitten too many times by me or others doing cute "oh, it's C, it'll work fine this way" things to know I'd like to have a bit more typing to tell others what I'm up to. 
&gt; I don't want to care about precedence to work something out. The precedence is the same as in mathematics: multiplication before addition, conjunction before disjunction. It has been this way since the 17th century. &gt; And if your expression becomes that complicated, I prefer to make it even more expressive This is often a good idea.
The issue isn't so much "syntax preferences", but rather the fact that if someone never uses certain constructs deliberately, any code using those constructs would be *likely to be have in a fashion other than intended*. Consider, for example, an expression like `u16a &gt; (u16b - u16c)`. Perhaps the author of the code intended for the code to behave like `u16a &gt; ((int)u16b - (int)u16c)`, or perhaps `u16a &gt; (uint16_t)(u16b - u16c)`. If a programmer never deliberately compares signed and unsigned values directly except in cases where one is a *directly* promoted value of a small unsigned type, however, then the expression `u16a &gt; (u16b - u16c)` would *definitely* be a mistake and having the compiler notify the programmer of the mistake would be more useful than assuming that the programmer meant `u16a &gt; ((int)u16b - (int)u16c)`. Personally, I would have like to have seen the Standard allow implementations to accept or reject at their leisure programs whose behavior could be affected by whether short unsigned types are promoted to `int` or `unsigned`. Allowing implementations to accept such programs would allow implementations to be upgraded to C89 compatibility without forcing them to reject pre-existing code which relied upon the behavior the Standard happened to adopt, but allowing implementations to reject such programs would help encourage clearer and more portable coding practices going forward. While the fact that `-Wall` would cause a compiler to assume a programmer never deliberately used certain constructs might seem annoying, such an assumption goes along with the commonplace meaning of the word "all". A programmer who enables all warnings can easily discover which ones are useless and turn them off. By contrast, if `Wall` didn't enable warnings that a programmer might have found useful, the programmer would likely never know to look for them. 
You're asking about C++, but you've posted on a C programming subreddit. You would likely receive more reliable answers somewhere like /r/cpp_questions.
An approach I employed some years back, before I got in-circuit debugging equipment, was to write code in such a way that it could compile either with my target platform's C compiler or with Microsoft C++; compiling with the latter would produce an executable that would establish a TCP socket to a separate application I'd written to emulate the hardware. If the application performed e.g. \`LATD |= 128;\` that would, through the magic of macros, get translated into something equivalent to \`portBytes\[0xF8C\] |= 128;\`, which would then via the magic of C++ get turned into \`portBytes\[0xF8C\].wr(portBytes\[0xF8C\].rd | 128);\`. The \`rd()\` function of \`portBytes\[0xF8C\]\` would then output a sequence of bytes meaning, effectively, "read I/O address 0xF8C", receive a byte in response, and its \`wr(X)\` function would then output a sequence of bytes meaning "write I/O address 0xF8C with X". The emulator application would then have a table of I/O addresses and functions that it would invoke in response to the received data. Not all I/O was simulated using individual I/O port reads and writes, but using that recipe avoided the need to define individual packet types in the protocol for every kind of I/O in the system. Things like an external flash chip were handled by having TCP "commands" for reading and writing various sizes of blocks, since supporting such commands was faster and easier than trying to emulate everything at the I/O register level, but for things like controlling I/O pins using the hardware registers was simpler than using anything else. An advantage of this approach is that the emulator's windows could be used to examine the state of various emulator objects (like the flash memory) while the main program was paused. Perhaps Visual C++ offers a way to pause one thread and have the debugger active while other threads remain live, but I don't know of one. Using separate applications joined by TCP socket was effective for this. If I were to do such a thing again, rather than using hardware debugging tools, I might arrange things to use a browser app rather than a Windows app, and vary a few other details of the implementation, but the approach is one I found useful and could use again if I were developing the right kind of app and hardware debugging tools weren't available. &amp;#x200B;
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead. Also, it's unlikely that you are going to get good answers unless you specify what you mean with ‚Äúprint out.‚Äù Print a picture? ASCII art? Unicode symbols? Display graphics? Generate Postscript? There are many different ways this can be understood, so please be specific and name the operating system you are programming for and how exactly you imagine the flag to be displayed. 
Different tool sets will often use different syntax, even when targeting one particular processor. If the target platform would allow one to execute read-only data as code, and would allow a relocatable function to be expressed using a fixed blob of bytes, something like: &amp;#x200B; // Put appropriate sequence of bytes into the string literal union {unsigned char dat\[16\]; unsigned long forceAlign;} const myCode = {"\\x12\\x34\\x56\\x78"...}; // If targeting ARM, code addresses need LSB set as shown below union {unsigned char \*asChar; void (\*myFunc)(exec); } const myFuncHolder = myCode.dat+1; &amp;#x200B; \#define myFunc() (myFuncHolder.myFunc)() &amp;#x200B; would likely be portable to a wider range of C implementations for the target platform than would code which tries to use inline assembly directives. Such code wouldn't work on implementations that target other platforms, of course, but that would likely be just as true of code that uses inline assembly. &amp;#x200B;
That's a named initialiser. It allows you to specify the structure members you want to initialise by name instead of by order. The same can be done for arrays.
Oh, ok. So, if you were initializing a structure out of order you want to do this: .name = "little_idle", .owner = THIS_MODULE, and not this?: name = "little_idle", owner = THIS_MODULE,
\`-Wconversion\` as well
Correct! The second one does not do what you expect.
`-pedantic ‚ÄîWall -Wextra -Wconversion -Werror` then!
Good to know. Thank you!
`malloc` and `free` have some housekeeping information somewhere. Often it is just before the pointer that `malloc` returns to you, but doesn't have to be.
They don't use external libraries. :(
I wish I could tackle the warnings, but when I last brought it up I was told "that's not a priority".
If `itr-&gt;stack` is pointing at any element of an array other than the first, or if it's pointing just past the last element, `itr-&gt;stack - 1` would have well-defined behavior. I still dislike the repeated accesses to `itr-&gt;top` within the loop, however. Pulling it out to a `register`-qualified object of automatic duration and adding a `register` qualifier to `p` will allow gcc to generate more efficient code for the loop even with *all* optimizations disabled than it would be able to generate if used in a project that required `-fno-strict-aliasing` but had all other optimizations enabled. 
Most standard malloc implementations don't do this and you *shouldn't* try to write outside of the area malloc has given you. And if you free something it's gone. Don't try to read it again, it might work at first but it will mess up quite seriously. This is called use-after-free.
&gt; Often it is just before the pointer that `malloc` returns to you It is almost never there, because that's really bad for cache performance. The allocator generally keeps track of large allocations in some sort of tree structure, and small allocations are taken from large slabs that are subdivided into blocks of equal size. So the pointer you pass to `free()` should point either to the start of a large allocation or to somewhere within a slab. In the former case, the size is stored in the tree; in the latter, it is a property of the slab.
Unfortunately, I don't know of any nice way to tell gcc or clang that a structure type without a tag should be usable for inspecting common-initial-sequence members of other structure types, at least in cases which don't actually involve aliasing such as: typedef struct { int x; } T1; typedef struct { int x; } T2; union { T1 v1; T2 v2; } uarr[10]; int read_T1_x(T1 *p1) { return p1-&gt;x; } void inc_T2_x(T2 *p2) { p2-&gt;x += 1; } int test(int i, int j) { if (read_T1_x(&amp;uarr[i].v1)) inc_T2_x(&amp;uarr[j].v2); return read_T1_x(&amp;uarr[i].v1); } The Common Initial Sequence rule would suggest that if e.g. `uarr[3]` holds a `T2`, then it should be possible to use `uarr[3].v1.x` to inspect `uarr[3].v2.x` since both are members of a common initial sequence. During the execution of `read_T1_x, storage accessed via `*p1` isn't accessed via anything else, so there's no aliasing there. During the execution of `inc_T2_x`, storage accessed via `*p2` isn't accessed via anything else, so there's no aliasing there. Within `test`, all accesses to `uarr` that will occur during the lifetime of each pointer which is formed from it will be made with that pointer, so none of those pointers alias anything. If `T1` and `T2` had matching tags, gcc would treat them as compatible types. The only way I know of to force gcc to honor the Common Initial Sequence Rule given the code above, however, is to grossly disable optimizations either by blocking the in-lining of `read_T1_x()` and/or `inc_T2_x()` or using `-fno-strict-aliasing`. 
Your post got caught in our spam filter. I apologise for the inconvenience.
Writes C and invents everything themselves? Where can I submit an application?
&gt; too stupid to understand operator precedence rules C's precedence rules are not very intuitive. I've been writing C for 25 years and I still need to check `operator(7)`, mostly when dealing with bitmasks
While I can understand this, the C compiler should never by default warn about correct, sensible, and valid C. Yet clang warns by default about constructs like `a &amp;&amp; b || c`.
It is mostly about style, having little to do with performance.
Also `-Wno-type-limits` for portable programming, because the "always true" conditions it reports might not be always true on all platforms. `-Wextra` specifically exists for all the warnings which might be false positives. Turning some of them off is usually better than adding workarounds that make the code uglier and harder to read.
This brings back memories!
Also, I think you misspelled "Rust" /s
&gt; They "fix" it by disabling the warnings or something similar. For most of the late 1990s / early 2000s, it was widely known within the FreeBSD community that you shouldn't use `-O2` due to bugs in gcc's optimizer. Until someone decided to tackle the issue and traced it to incorrect annotations in some of the FreeBSD kernel's inline assembler code... (To be fair, there was a brief window in 2007 where we turned `-O2` off again due to an [actual bug](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=32500) in gcc 4.2.x)
Can you show us some more of your code?
C does not have a string type, so you're probably compiling as C++. In C the type would be char*, a pointer to a character array. There is string.h as part of the standard library, and it contains the function strcmp, which is used to compare strings. It returns 0 if the two strings are equal. So you could have if (strcmp(q, "no") == 0) { // enter the case the user answered no. 
O‚ÄôReilly books, or instead of defaulting to Python for the next personal project you should use C instead. you‚Äôll learn on the way to your goal.
IMHO [this youtube playlist](https://www.youtube.com/watch?v=UILNmv2kFMc&amp;list=PLCNJWVn9MJuPtPyljb-hewNfwEGES2oIW) is the best, especially if you are on linux (otherwise you'll need to get familiar with the terminal but if you know Python it shouldn't be a problem, no use of CodeBlocks here) [here](https://github.com/staropram/c_tutorial) you'll find the github repo. Then, the best way to learn is, of course, to code. In my experience, forking a simple program like [noice](https://git.2f30.org/noice/) and implementing some simple functionalities was a great way to learn. In general, reading source code and trying to understand what's happening, checking the C standard library, is the best school. If you don't know [suckless](https://suckless.org/) allready, check out their software.
Wholeheartedly agree. I also find str.at(&amp;str, 10) ugly since the call to self/this isn‚Äôt implicit. The overhead is also unnecessary. 
For implementations targeting small platforms with simple memory architectures, it would often be there. On more complex memory architectures, it may be advantageous to keep most or all of the bookkeeping information elsewhere. It's also possible for an implementation to keep most of the bookkeeping information elsewhere in an area separate from the allocated blocks, but have each block preceded by a pointer to its associated bookkeeping information. The latter approach will allow code to search for a free block without having to examine many widely-scattered block descriptors, but still make it easy for code to find the descriptor associated with a block that's being freed without having to "search" for it. 
Yep, compiler bugs do exist, but compilers are so widely used and thus really well-tested in production. However, most people don't ignore those warnings because they think it's a compiler bug, but rather because they think "eh, it's just a warning". For most of `-Wall` and `-Wextra` "just a warning" is simply an understatement.
Write your program in python, compile it with c compiler, fix the reported errors, compile, fix, compile, fix until it works.
Do you like object-oriented C?
TIL you can do this! int a[] = {[0 ... 9] = 1, [10 ... 99] = 2, [100] = 3 }; Cool! 
If the input string will be of the form 1234.56789, with at most 19 digits before and 19 after the decimal point, use type \`uint64\_t\` to compute the values to the left of the decimal point, the value to the right of the decimal point, and a power of ten corresponding to the number of digits to the right of the decimal point (so for the above example, the values would be 1234, 56789, and 100000). Convert the power of ten to a \`double\` (it will be representable precisely), divide that into the fraction. Adding the whole number portion will yield a result that is rounded to within a fraction of a unit in the last place (ULP).
You could try gatling.
What is your question?
How could I accomplish what I described?
gcc -w
Legend programmers are those who debbug the error with in minutes.
&gt; Yep, compiler bugs do exist, but compilers are so widely used and thus really well-tested in production. My point was that we ‚Äúfixed‚Äù a bug in our code by blaming the compiler.
#include the algorithm sources' header files in your new comparison program/file and use them there? Is there some reason this isn't an option? I'm assuming they either already have headers or are written by you, in which case just create headers if you need them and go from there.
&gt; The latter approach will allow code to search for a free block without having to examine many widely-scattered block descriptors That's not a problem. The common technique is to store the ‚Äúblock descriptors‚Äù for the free blocks in the blocks themselves.
Some of the new ones about string truncation are what bug me. I *know* it's a non issue based on what I'm doing, but GCC doesn't have the same understanding...
Did you write these algorithm files? If so, cant you just \#include them and go from there? You should be able to write the implementations so that they return whatever it is you need (a record of the algorithm's progression -- e.g. comparisons, exchanges).
Thank you. I will take a look at it.
The stack allows 11 items to be pushed to it.
/r/cpp_questions
The free blocks *themselves* are going to be scattered around memory. If one is using a platform where every memory access is just as fast as any other, that's not an issue. If, however, one is using a platform where memory is divided into 64-byte cache lines, and the first access to a cache line will take 100 times as long as any subsequent accesses to part of the same cache line, it may become a significant issue. Things get even worse if one factors in paging. If a large chunk of memory contains an alternating mixture of 96-byte objects that are rarely used and 4000-byte free blocks, an attempt to allocate 5000 bytes could end up having to visit a different page for every block, either "tagging" the page if it's in memory, preventing it from being swapped to disk (making it necessary to swap out something that would more likely have been useful) or else requiring that the page be fetched from disk. Tracking free blocks using the space within them can sometimes be absolutely disastrous for performance when memory is short, possibly degrading *overall* program performance by an order of magnitude or more.
Thx! &amp;#x200B;
Yeah, I see, incorrect condition in the isFull() method, thank you. I will fix this. The condition must be: return stack-&gt;stackPointer == SIZE - 1;
&gt; If a large chunk of memory contains an alternating mixture of 96-byte objects that are rarely used and 4000-byte free blocks, an attempt to allocate 5000 bytes could end up having to visit a different page for every block, https://i.imgur.com/CDqD1KV.jpg
What have you tried so far?
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Yea, understood that -- it's just a common thing to do that, unfortunately.
There are many ways malloc/free/etc. are implemented. Some techniques which work well on small systems with simple memory architectures can perform very badly with some larger and more complicated memory architectures that add caching, paging, and other such issues. You suggested that "The common technique is to store the ‚Äúblock descriptors‚Äù for the free blocks in the blocks themselves." I know that systems which use paging generally avoid such techniques, but it didn't seem clear that you did, so I offered an explanation of what would happen if such techniques were used on a system that used paging. Perhaps I should have added a parenthetical note In short, tracking free blocks using space within them can be disastrous for performance (consequently, well-designed systems won't do that).
Let's start with your main target. All you need to do there is add some directory names: bin/quantization: build/main.o build/quants.o build/energy.o build/word.o build/wordSet.o build/inputHandler.o However, at this point I would usually gather the sources with `$(wildcard src/*.c)` and then do the appropriate [substitution reference](https://www.gnu.org/software/make/manual/html_node/Substitution-Refs.html#Substitution-Refs) to make a list of objects (`$(SRCS:src/%.c=build/%.o)`). That's up to you. Of course, now `all` is incorrect: all: bin/quantization Let's talk about that pattern rule. Let's ignore the header file dependency for a moment, and just add the appropriate directory names: build/%.o: src/%.c $(CC) $(CFLAGS) -c $&lt; -o $@ Notice you have to be explicit on the output file name as well, since it's going to a different place. But back to dependencies, because they're a bit different. The first thing you need to do is tell the compiler where to find the files to include. This is done with a `-I` flag, so you'll want to do: CFLAGS += -I include (Technically you'd want this in `CPPFLAGS`, but `CFLAGS` is sufficient for now IMO). And now for the fun part: telling make about the dependencies. I guarantee what you had before was insufficient to completely describe the dependencies. Sure, when `%.h` changes you need to recompile `%.c`, and you could put that in the pattern rule, but surely there's some additional dependencies on other header files. At a minimum you'd want to include some more dependencies: build/main.o: include/quants.h include/energy.h #etc... But even better is to ask the compiler to produce these dependencies for you. I like doing this by adding `-MMD -MP` to your `CFLAGS`, which will tell the compiler to create a `%.d` file with the dependency information. You can then import these dependencies into your Makefile with `-include`.
Check the return value of `scanf`. Refer to the `scanf` manual for how to do that.
The return value of `scanf` is the number of parameters that were successfully assigned to. Since you're probably using a simple `scanf("%d", &amp;input)`, you would expect this to return 1. If the user enters a string then it will return 0. However, the text is still there waiting to be read, so you need to handle the error somehow. Maybe read and discard anything up to the next space or newline? Alternatively, you might consider only ever reading text from the user, one line at a time. You can then parse this string for data, and report an error if you can't. That's actually my preferred method.
&gt; There are many ways malloc/free/etc. are implemented. Some techniques which work well on small systems with simple memory architectures can perform very badly with some larger and more complicated memory architectures that add caching, paging, and other such issues. Exactly. And you are mixing them all up... No performance-oriented allocator would service 96-byte requests from the same arena as 5,000-byte requests.
Hi r/C_Programming, I received some good tips from the sub last time I posted regarding further optimization areas for `nnn`. So here's v2.4 - with a reduced binary size and lesser memory usage! Thanks!
Since it appears you're using the linked list implementation, these are constant time -- O(1) -- operations. This means that the time cost of the operation doesn't grow as it only involves a fixed number of tasks for the input. For contrast, if you had a "contains" operation, it would be O(n) because the time cost of the operation would grow as the number of elements (n) increased (because you have to search through the list of up to n elements to perform the operation).
Thank you, this is working. However, how would I clean out what the scanf after the user inputs a string?
You like warnings? `splint -strict ...` [**-strict**](https://www.math.utah.edu/~beebe/software/c-tools/splint.html) Absurdly strict checking. All checking done by checks, plus modifications and global variables used in unspecified functions, strict standard library, and strict typing of C operators. A special reward will be presented to the first person to produce a real program that produces no errors with strict checking. 
what if i wanna have subdirectories in src ? 
I tend to do something along these lines... SRC:=$(wildcard src/*.c) OBJ:=$(SRC:src/%.c=obj/%.o) here obj is your build directory main: $(OBJ) g++ $(OBJ) -o main $(LDFLAGS) $(OBJ): obj/%.o : src/%.c $(CC) -std=c99 $(CFLAGS) -c $&lt; -o $@ this has the advantage that and .c file you drop into the src directory automagically gets linked into your application....
At that point you probably want to go to a recursive make (where each subdirectory gets its own Makefile ... but see also "Recursive Make Considered Harmful") or to something like CMake.
#include &lt;cs50.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;math.h&gt; #include &lt;string.h&gt; #include &lt;time.h&gt; int main(void) { printf("Welcome to"); sleep(1); printf("\n\n"); printf("üö∫üö∫üö∫ üö∫üö∫üö∫üö∫ üö∫üö∫üö∫\n"); printf("üö∫ üö∫ üö∫ üö∫ üö∫\n"); printf("üö∫ üö∫ üö∫üö∫üö∫üö∫ üö∫üö∫üö∫\n"); printf("üö∫ üö∫ üö∫ üö∫\n"); printf("üö∫ üö∫ock üö∫aper üö∫üö∫üö∫cissors!\n"); sleep(2); printf("\n"); printf("My name is Kreg\n"); sleep(1); printf("I am an unstoppable robot.\n"); sleep(1); printf("I cannot be beaten at Rock Paper Scissors.\n"); sleep(2); string q = get_string("Are you ready to play?\n"); }
Yeah, I am doing linked lists. That clears it up. Thanks!
`fflush(stdin)` is undefined behavior. Instead, you need to read and discard each character individually, maybe with `getchar()`: while((c = getchar()) != '\n' &amp;&amp; c != EOF); 
Always remember to test out if a pointer is NULL. That way you can send an error or warning and spot easily a bug or the root of undesired behavior. By making it through some kind of assertion, it wont hit performance at release compilation.
That's a GCC extension and not portable
This subreddit is for the C programming language. You're going to have more luck at /r/CSharpHomework, or /r/csharp 
Sweet, thanks
Have you attempted to code this yourself? Most people are gonna tell you to do it yourself. You have no code to show...
I have some of it done. I was just going to see if anyone would post any pieces of the puzzle to help me out. But yes, I figured that I'd get a lot of crap when I posted this.
Huh. For a minute I thought this was /r/ProgrammerHumor 
If it runs it runs lol
C is used today on implementations with memory sizes that very by more than six orders of magnitude. An allocator that would be appropriate for a multi-gig monster is going to be very different from one that would be suitable for use on a micro with 8K or 16K of RAM. Besides, tweak the example to have the used and free blocks be of roughly similar size, but request a block that's slightly bigger, and the same principle will apply unless one forces all allocation sizes to be powers of two, which will waste a lot of storage with internal fragmentation.
The string type is just a typedef (alias) of char *. You can use the strcmp function (or one of the strcmp family) to compare it to user input using a simple if statement. 
-pedantic gang
It would be really nice to post formatted code, use [https://pastebin.com/](https://pastebin.com/) or the "Code Block" of this editor
Looks like the code is in header file. If you include this file in 2 source files you will get linker err or warns about duplicates.
Wrong sub mate.
After you type the character, you hit return - which puts a '\n' in the input stream - which your second call to `scanf` reads. Try using a leading space in your format string, e.g. `" %c"` Read up, in detail, on `scanf` to see why this works.
Ok, thanks
Thanks, I will split implementation into .cpp and .h files
Can I get the format please?
&gt; C is used today on implementations with memory sizes that very by more than six orders of magnitude. Sure. But the issues you raise about cache line aliasing etc. do not apply to low-memory embedded systems, most of which barely even have any cache at all.
Thank you ! &amp;#x200B; This worked and my program is now complete. One last thing though, how does the line of code you gave me work? It works, but I don't know why. Can you give a quick explanation?
C# is off topic in this subreddit. Please try /r/learncsharp instead.
Congrats dude , I will try to PR for more features 
Do I need to know extensive usage of pointers to contribute 
The list includes MinGW as an IDE? I use MinGW/MSYS2 but I'm not aware of a built in IDE as part of the distribution. If you search for IDE and MinGW it takes you to a page that mentions Code::Blocks and dev c++. What IDE is the article referring to?
I've made stuff with nginx - you don't have to link dynamically. maybe that's a new thing, that i don't know about. But when i did it it wasn't hard - you just build the whole thing with your module in it. Nginx then can reload itself, while running. So that's not a big issue for me at least. 
Not really. And if you do, I am more than happy to help any time.
Thank you!
NP üòÑüôè
Yup sure Thanks 
If you want some formal instruction, I can thoroughly recommend the Galway University. They have a distance learning program that teaches programming in C and is incredibly comprehensive. You need an undergrad degree though (doesn't have to be in Comp Sci though). &amp;#x200B; [http://www.nuigalway.ie/courses/adult-and-continuing-education-courses/softwareengineering.html/#course\_outline](http://www.nuigalway.ie/courses/adult-and-continuing-education-courses/softwareengineering.html/#course_outline) &amp;#x200B; Alternatively, Edx have a nice series on using C programming: &amp;#x200B; [https://www.edx.org/professional-certificate/dartmouth-imtx-c-programming-with-linux](https://www.edx.org/professional-certificate/dartmouth-imtx-c-programming-with-linux) &amp;#x200B; You can do it without paying for it, or if you want a piece of paper, you can pay for the course (it's not overly expensive). 
Visual Studio??? It's a pain in the ass to write C on visual studio, as you have to download the C++ packages for VS 2015 or VS 2017, then create a new C++ project, change an option to say you want to run the code as C instead of C++ , save that as a template and then remember to use that template any time you want to write some C. Okay, it's not an impossible task by any means, but the lack of native C support in VS Pro, considering it's still used in industry and a lot of MS products get built with C/C++ is pretty shocking. You shouldn't have to hack something together on a large (expensive) IDE to get it to run some C code. &amp;#x200B; Also I think X Code would or CLions would do a better job than some of those other "IDEs", and I'm not entirely sure as oldprogrammer said why MinGW is on the list of IDEs. &amp;#x200B; Not sure this is a helpful article at all really. &amp;#x200B;
Thanks for the reply! Do you have any recommended resources for extending Nginx? I've only looked a couple which seem ok'ish. From the little bit I have research, the libraries included with Nginx seem pretty nice to work with.
So true. I was really, like \*reallly\* surprised to see that cstring thing with embedded pointers. It's just imitating C++ \*syntax\* in C in the worst way possible, with no understanding of price of things... C is not Python, not C++ and not Java. OOP is not about syntax, it's way to think about data and data operation grouping, and I wish people understood the point. All those books on OOPs with stupid rhetorical hand-waving are not help here!
ohhh boi OHHHH OBIIIII ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§
Add `-pedantic` too. 
sure, you [here](https://nutrun.com/weblog/2009/08/15/hello-world-nginx-module.html) is a quickstart hello world module. And when you have that running - there's a in depth guide [here](http://www.evanmiller.org/nginx-modules-guide.html)
The problems with keeping information about allocated blocks in the space immediately preceding them also do not apply to such systems, and yet your earlier post says information about block size is "almost never there" [just before an allocated block]. My intended point was that it may be true that systems with multiple gigs of heap almost never keep information about allocated blocks in the space immediately preceding them, but that is hardly true of all systems, especially those where one might be interested in dealing with memory at a lower level. Further, I would expect that most of the factors that would make it advantageous to keep information about free-form allocated blocks in a region of storage separate from the blocks themselves would generally also apply to free blocks unless one has an arena which is dedicated solely to blocks of a particular exact size or, at minimum, uses a different free list for each size of block (so that code won't bother examining any free-list entry for any block that isn't going to satisfy its requirements). Perhaps it's common for implementations to maintain a separate free list for each size of block. I suppose that if the number of sizes is kept reasonable, that could work out pretty well. In any case, my intended original point was that many practical allocators on smaller systems do store information about used blocks in the space which precedes them, so saying such information is "almost never there" is only applicable to certain kinds of C implementations. 
Sounds like homework
Hey, we aren't here to do your homework for you. First off you're going to need to find an algorithm that does what you require, or better yet, come up with your own from scratch. If you're stuck on the actual code, feel free to come back and ask for some help!
Let me rewrite it to be a bit more understandable: int c = getchar(); while ( c != '\n' ) c = getchar(); `getchar` reads one character from the input. If that character isn't a newline, it reads another ... repeating this until it is a newline. The effect is to clear out all the bad input from the last line the user put in. It might seem a bit strange that I declared `c` to be an `int` instead of `char`, but that's on purpose. `getchar` actually returns an `int`, because it needs to return a special value (`EOF`) to indicate that the read failed because it read all the way to the end of the file. That's why there's a second condition in the original version, to check for that condition as well.
My university and also the public library both offered free subscriptions to [Lynda.com](https://Lynda.com). I started with the C Essentials course by Dan Gookin and that got me on my way with ZERO experience with a "C-like language." If you don't have access to [Lynda.com](https://Lynda.com) or LinkedIn Learning (they are the same thing now) or if you'd just prefer a book, I found "Head First C" to be helpful. I haven't read "C for Dummies" but IIRC Gookin (see above) is the author of that book. I hope this helps. Good luck!
I've found that `clang -Weverything` will warn about padding in structures, and if you specify packed structures, it will warn about no padding. On the plus side, `-Weverything` does what it says on the tin, but on the other hand, it's annoying and contradictory. 
I'm not sure how this is relevant. The warning I refer to is enabled by default, even if you do not turn any extra warnings.
I'm surprised OP didn't just drop a link to a PDF of his assignment instead 
&gt; I am only allowed to use arrays. What exactly are you not allowed to use? This description is very vague.
Without having a proof, I think the optimal solution is to sort both vectors. If you are not allowed to permute the second vector, then first sort the first vector and then permute it according to the inverse permutation needed to sort the second vector. In APL that would be {(‚çã‚ç∫)[(‚çã‚çµ)‚ç≥‚ç≥‚ç¥‚çµ]} I think.
Thank you so much! I really appreciate the links!
Does it need to be efficient? Since the description doesn't specify, I assume not. If I were you, I'd just generate all permutations, and keep track of the best so far. When the algorithm is done, you'll have the best one. &amp;#x200B; You can use this algorithm. [https://www.geeksforgeeks.org/write-a-c-program-to-print-all-permutations-of-a-given-string/](https://www.geeksforgeeks.org/write-a-c-program-to-print-all-permutations-of-a-given-string/)
There n! permutations of the vector elements. This is not going to terminate before the heat death of the universe for the demanded 100 elements.
Arrays, functions, if and while loops. &amp;#x200B;
So you are allowed to use arrays but also not allowed to use arrays?
Just asking for a starter help. I don't even have a idea of how to start the algorithm of comparing the vectors and how to permute them, not asking you to do my homework but just a little ignition to the problem would be nice.
\*challenge question. &amp;#x200B;
what no!!! I am allowed to use arrays. what i tried is i stored the first vector in array1 and second vector in array2. After this i am confused how to approach the permutation part. and btw have i posted somewhere which specifies i cannot use arrays then please tell i'll edit it.
Hmm. Yes. I missed that. I guess that the naive approach won't work. A good exercise for OP's google-fu.
My question to you was: &gt; What exactly are you not allowed to use? to which you answered &gt; Arrays, functions, if and while loops. Perhaps you misunderstood my question. I ask this question because it is impossible to solve this question with just arrays. You will need other things like variables, expressions, assignments, comparisons, integer constants, statements, scalar types, and more. I do not like to answer questions with unclear restrictions as to what can and what cannot be used since these lists tend to suddenly have new entries once I wrote an answer.
The `%d` specifier reads a decimal number, not a decimal digit. You get an `8` because `y` is never actually scanned and thus its value is undefined. To fix these issues, you can use `%1d` to scan a single digit.
This doesn't work since leading whitespace do not count towards the field with. Try with double result; str_to_double(" 12", 2, &amp;result); to observe the issue.
I think scanf is only meant to handle char\* as inputs: &amp;#x200B; [https://www.tutorialspoint.com/c\_standard\_library/c\_function\_scanf.htm](https://www.tutorialspoint.com/c_standard_library/c_function_scanf.htm)
That worked, but this is the first time I've seen this problem come up with %d. Anyway, thanks for your help!
That is not the case. The link you included in fact states otherwise.
s/PDF/artifact-laden JPEG/
I apologize for not clarifying these in the questions. Just getting use to discussion forums, my bad. The basic C operators are allowed like you mentioned expressions, assignments, comparisons, integer constants, statements, scalar types (int, floats and doubles), Boolean expressions and stuff.
Please tell me what exactly is not allowed.
Are you supposed to do this a digit at a time? &amp;#x200B; scanf("%2d", &amp;v); printf("%d\\n", v%10 + v / 10); &amp;#x200B; &amp;#x200B;
yes, scan two digits separately and reverse them &amp;#x200B;
"%d" is used to scan integer numbers. For decimal or real numbers you use float and you scan it with "%f". &amp;#x200B;
Well in that case, go with: printf("%c%c", getchar(), getchar()); And just claim that the unspecified behavior will work with some compiler, probably.
`%d` scans decimal integers as oposed to `%o` for octals and `%x` for hexadecimal integers.
There's no such thing (objectively) as "the basics". No one can make any assumptions about what your particular curriculum emphasizes or covers. If you want help, you need to stop with the vagueness about the requirements, and show what work you've done so far. https://idownvotedbecau.se/noattempt/
That‚Äôs a pretty smart joke, sad to see you downvoted!
I don't get the joke, is this a sarcasm sub?
What type of system (embedded/PC)? Where's the value coming from? Do you want it to calculate a new average only when X changes or at some fixed sampling interval?
I guess you could have a 5 element array somewhere and store the last five elements in it (update it every time it changes) and just get the average from the values in the array by adding them up and dividing by 5. You could even make it do that every time you change X and store the average in another variable so it's always there. Depends a little on how often you need it. Good luck!
This. A Circular buffer is what you want.
If it's ok to use floating point arithmetic you could a simple IIR Filter double avg = 0.9 * avg + 0.1 * x; If you want qucker response you can change the coefficients to something like 0.7 and 0.3. Make sure the sum of the coefficients equals one or the filter will become unstable.
Create an array of ints, add to the array when you get a new sample while keeping track of how many samples you've recorded. Sorry if formatting is messed. psuedocode: #define MAX_SAMPLES 50 int my_values[MAX_SAMPLES ]; int num_samples = 0; void addSample(int val) { // This will keep wrapping around and writing over the array my_values[num_samples % MAX_SAMPLES ] = val; num_samples++; } int getAverage() { int end_count = num_samples; if (num_samples &gt;= MAX_SAMPLES ) end_count= AVG_SAMPLES; int sum = 0; for (int i = 0; i &lt; end_count; i++) { sum += my_values[i]; } return (sum / end_count); } &amp;#x200B;
TiL what a circular buffer is. Thanks man! This is a lot more in-depth than I was thinking but it's probably the right answer. https://en.wikipedia.org/wiki/Circular_buffer?wprov=sfla1
If it's a fixed number of say 5. Keep a circular buffer of the entries. Update the average with (Newest Value - Oldest Value) / 5. Note, this could accumulate floating point errors.
Be aware that `num_samples` increases continually and might overflow. With a rate of 1/s we're talking about timeframe of 68 years and it's unlikely to give problems. But a couple of situation can change this: higher rate (i.e. a million times per second) or (embedded) systems where an int is defined as 16-bit. It might be better to wrap num_samples manually to avoid overflows.
You can implement something called a circular buffer. You store the last n values for your variable in an array or a linked list (if the linked list, you point the tail to the head) and cycle to the front when you reach the end. This allows you to go back and look at the last n values and use them however you wish.
&gt; a simple IIR Filter In this case, aka an [exponential moving average](https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average), which can help for determining properties/constants. Very different from a simple average over the last few samples, but doesn't require a buffer.
Yeah it's not a normal average. Essentially it's a crappy low-pass filter. But still, it's a nice quick'n'dirty way to smooth out jitter in a measurement.
No it's just full of C programmers.
Yes, I avoided mentioning overflows as I figured that was more advanced than he needed. To take care of that I'd add 'num_samples %= MAX_SAMPLES' after the increment.
That's okay, they often get the best of us, and thank you! I wish the book a lot of success, and thanks for your hard work...
Inline assembly is where you have actual blocks of assembly code embedded into your C source. This is available through a variety of compiler extensions. Alternatively you can write a raw assembly binary and build it with an assembler, then link it to a C program or do whatever you want with it.
Yes, the larger a function is (larger as in the number of registers and addresses used to keep track of the program state) the worse function call overhead is when called from inside the large function's scope . I'm not sure what O notation to use but eg. calling a function from within one that only uses two unsigned short variables and returning to it is going to be much faster than one called from one that keeps up with 200 local variables spread in 100KB. Each call of a function, the entire local state must be dumped to ram and the registers cleared so the called routine cam use them and after it returns the same process happens again, in reverse. You can imagine why that would be a bad idea to do from inside a tight loop of your big function. Its also 's why function inlining isn't necessarily better. Each new auto variable needed grows the stack frame which affects every function call the function makes. At first glance you'd think that since it's probably just a memory copy operations it shouldn't be so expensive but for some reason that isn't strictly true. This is pure speculation but the cost probably comed from the allocator memory for the stack which would suffer the same as malloc does whereby the difficulty of finding a free block of memory increases nonlinearly with the size of the requested block. All that being said, while I think people commonly underestimate the cost of function call overhead they are usually right that are other things that would provide a larger benefit if optimize. Compilers are actually really good at keeping the stack size as small as possible so even if it looks like a function is massive - using dozens or hundreds of variables - the chances are good only a handful actually need to be kept track of in a stack frame. https://godbolt.org can be great for checking the assembly
Dennis Ritchie [boostrapping](https://www.reddit.com/r/explainlikeimfive/comments/3u4h3z) from the B language. You starting by writing a compiler for a new language in a preexisting language, then you can re-write the same compiler in that new language. The Java compiler *was* written in C, but is now written in Java.
Is there an offline tool to take snapshots of the amount of RAM used by your program over the course of its execution? The more I read about stack frames the more concerned I am that I structured my little ascii/terminal game in a bad way. I use stack frames like scenes, basically. It runs great and I don't think any PC even remotely modern would have trouble with it but I doubt it's the best way to do things. 
https://www.bell-labs.com/usr/dmr/www/chist.html
Straight from (half of) the source: [Dennis Ritchie](https://www.bell-labs.com/usr/dmr/www/chist.html) If you want it summed up into a quote: &gt; In 1971 I began to extend the B language by adding a character type and also rewrote its compiler to generate PDP-11 machine instructions instead of threaded code. Thus the transition from B to C was contemporaneous with the creation of a compiler capable of producing programs fast and small enough to compete with assembly language. I called the slightly-extended language NB, for `new B.' There's more to it than that, but if you read the whole page it's pretty interesting. Basically by extending B into a new language "new B", which was developed into and re-named C.
It's not really a joke -- the function arguments can be evaluated in any order. Therefore, they may be evaluated from last to first. In that case, it would reverse the two characters.
Check out [https://en.wikipedia.org/wiki/Bootstrapping\_(compilers)](https://en.wikipedia.org/wiki/Bootstrapping_(compilers))
What does he mean by threaded code? I can't imagine he means threads in the modern sense given it's contrasted against machine instructions.
https://en.wikipedia.org/wiki/Threaded_code explains the idea.
On the page itself there is a footnote about that exact point. [See here](http://home.iae.nl/users/mhx/Forth_Bell.pdf)
If you need to average over a longer period and it becomes prohibitive to average the whole array each time a new sample comes in... make a circular buffer.. keep track of the sum as you add new elements, then when the buffer is full, start subtracting the first element of the buffer from your sum, and adding the new one to the sum.. then take that sum / number of samples in the buffer. This way it takes constant time to track the average no matter how long an interval you're averaging. Each step is just 1 add, 1 subtract, and 1 divide.
If you want from the last `n` elements you should use a circular buffer as others have mentioned. If you want from all elements just update the mean in-place: for (i = 1; i &lt; end; i++) { x = foo(); sleep(1); gt += x; avg = gt / i; }
Can you imagine writing a compiler in machine code. Wtf xD 
For a basic, extremely limited form of ASM? Yes. For anything, literally *anything* else? Absolutely not. Torture.
ALU
Damn, that's cool.
Call strtol https://en.cppreference.com/w/c/string/byte/strtol
Read the input as a string, then check to make sure that the string only contains characters that are digits. If it is valid, convert it to a int.
That's a no from me...
I'm new to C programming, but this might be due to Two's Complement. Normally, 1 is denoted as 00000001 If you flip it, you get 1111110 Add 1 to that value and you get 11111111 &amp;#x200B; Two's Complement is really popular in computer architecture.
Because the left most signed bit is -128, every bit after it adds onto it. The first 7 bits add up to 127, add that to -128 and you get -1. The reason that binary isn't done like that is because it would create a negative zero. For example 10000000 is -128, using the idea you are thinking of it would be negative zero. In math you can't have a negative zero for it doesn't have a value. The current system is that it is impossible to have negative zero.
you take two's complement by inverted all bits and adding 1. &amp;#x200B; 0000 0001 in two's complement, which is how negative numbers are stored, would be 1111 1110 + 0000 0001, which is 1111 1111. the leftmost bit is the sign bit. 
It makes it easier to do math, the CPU can use the same addition instruction for negative numbers as it would for positive numbers. `3 + (-1)` gives the same result as `3 + 255`. 
What do you mean, compare the entire string? How is that different from comparing each character in turn?
You can compare them using a hash of each, but then you‚Äôre vulnerable to collisions and the performance is probably only better for very long strings unless you compare often with cached hashes. You‚Äôd have to do a benchmark to see if it‚Äôs even worth pursuing. 
So basically i‚Äôm entering multiple inputs as C-Strings into a variable, lets call it ‚Äúnames‚Äù. and i have another variable called ‚Äúkey‚Äù. I wanna count the amount of times my ‚Äúkey‚Äù occurs in the ‚Äúnames‚Äù C-string. Sorry in advance, i suck at explaining this looool
Because of what happens when you add 1 to it. You get 0 carry the 1 in the rightmost digit, 0 carry the 1 in the next digit and so on until there are no more digits remaining, leaving you with 0, which is the answer you want. 
A function that might be useful to you is: char *strstr(const char *str1, const char *str2); It returns a pointer to the first occurrence of `str2` in `str1`, if present. You can probably write some kind of loop containing this function, that counts the number of occurrences.
Thanks a bunch! Lemme try this out
In my computer architecture class in college, our professor had us learn machine language before assembly so that we would, "appreciate assembly"
There's probably a better description for this, but the easiest way that I remember it is: -128 64 32 16 8 4 2 1 Is that unsigned chars have positive 128 as the most significant bit, and that signed chars have negative 128 as the most significant bit. So -128 is ```1 0000000``` and then -1 is -128 + 127 or ```1 1111111```.
This is the best and most intuitive answer.
&gt;but why isn't this stored as 10000001 instead? With that scheme, think about what number 10000000 would represent.
One of my favorite professors in college had a cool trick to manually do twos complement in one step. Starting from right to left copy every binary number until you encounter the first 1 and afterwards toggle every value until the end. 
Other people have mentioned that it's two's compliment. Not quite all processors use it, and due to that spectre of "undefined behaviour" you probably shouldn't assume it'll work as you'd expect in C, especially with higher optimization levels. Fun two's compliment tidbit: Take the sum of all the powers of two. S = 1 + 2 + 4 + 8 + ... Then, S = 1 + 2*(1 + 2 + 4 + 8 + ...) So clearly S = 1 + 2*S Solving for S S - 2*S = -S = 1 So clearly 1 + 2 + 4 + ... + 2^n + ... = -1, and Two's Compliment is just a reflection of that mathematical fact. (Yes, I know, this is wrong, in that the infinite sum doesn't converge, and hence doesn't "equal" anything)
Did it work? 
This is the correct answer.
This is a C forum, but I think there's not a real difference between C and C++ in your example: &amp;#x200B; look into for() loops to set the start and end. Example to count from ten to zero: int i; // variable 4 byte integer for (i = 10; i != 0; i--) { // sets i to 10, i - 1 each loop, stops at i == 0 printf("%i\n", i); // output } &amp;#x200B;
forgot to post my current code. int hold; int N; int dice; cout &lt;&lt; "What value should we hold at? "; cin &gt;&gt; hold; cout &lt;&lt; endl; cout &lt;&lt; "Hold-at-N turn simulations?"; cin &gt;&gt; N; cout &lt;&lt; endl; cout &lt;&lt; "Score\\t" &lt;&lt; "Estimated Probability" &lt;&lt; endl; for (int score = hold; score &lt;= hold + 6; score++) { /\*if(score == hold) { score = 0; } for (score = hold; score &gt;= hold; score -= hold) { cout &lt;&lt; score &lt;&lt; endl; break; }\*/ cout &lt;&lt; score &lt;&lt; endl; }
It makes arithmetics easier but an interesting case is the representation of 0. 0 is represented by 00000000 but -0=0 so with your representation of negative numbers 10000000 == 00000000. All in all that's not impossible to make happen, you could add a check for that case to make sure that the CPU understands that different sequences of bits are actually the same number. It could also be an invalid value, floating point numbers have lots of those. All of these edge cases also make conversion between signed and unsigned numbers difficult: 127 signed is 0fffffff, convert to unsigned it's still 0fffffff, add 1 it's 10000000 == 128 (unsigned), convert to signed it's...invalid? 0? All of this can be check for, but every check takes CPU time. The minimum and maximum values for a byte in your representation are -127 and 127. But we're using two representations for the same number (0) so we could actually represent a whole new number: traditionnal representation goes from -128 to 127 since every number is represented only once. So in summary the case of 0 shows well why naively setting the first bit to 1 isn't the best option to deal with unsigned numbers. It causes edge cases, makes arithmetics and conversions harder, can represent less numbers and would generally be less performant because of these limitations.
This is 16 minutes well spent: https://www.youtube.com/watch?v=lKTsv6iVxV4
`1 + (-1) = 0` `0001 + 1111 = 10000`, truncate: `0000` therefore, that's good enough
Important: 1. Please format your code 2. C++ has a lot of concepts, which we don't want/use/have in the C language (cin and cout for example), perhaps it's better to go into a C++ subreddit like [https://www.reddit.com/r/cpp/](https://www.reddit.com/r/cpp/) &amp;#x200B; &gt; I am trying to write a program where i type a number and it will print out the number plus the following six numbers, but the first number needs to be set to 0 and i can't seem to figure out how to do that. Any help is appreciated. Is a bit tricky to understand, you want to have a number by userinput: #include &lt;stdio.h&gt; int main() { int hold; scanf("%i", &amp;hold); // I think that's like cin &gt;&gt; hold &lt;&lt; endl;? for (int i = hold; hold &lt;= i + 6; hold++) printf("%i\n", hold); // like cout &lt;&lt; hold &lt;&lt; endl;? return 0; } Output: ./test7 // programm 100 // input 100 // &lt;- start of output 101 102 103 104 105 106 I don't understand what you mean with the set to zero part
How do you define an integer ? Is googol an integer ?
Clip the audio sample to be between -1.0 and 1.0, multiply it by 32767, and then round to the nearest integer.
You don't need a buffer, you can calculate an accumulated average See this https://math.stackexchange.com/questions/106313/regular-average-calculated-accumulatively The gist is that you can take your previous average, multiply it by n/(n+1) where n is the number of elements, and add your new value divided by (n+1)
Do they they really tho? 
We had to rewrite a whole lot of pascal functions and procedures to m68k assembler. I think even to this day this is probably a very good approach to learn. Same goes for implementing some of the higher level language constructs in use these days in c, that way you'll also 'appreciate' ;) the constructs but also know what overhead it takes and where to look for problems. Back when 8bit homecomputers where common it was very common to write in assembler (but there were already some with macro capabilities!) and compilers where no exception. What i find highly educational is the series of writing a forth system, this takes only a small bit of assembly but creates a very high level language :) https://github.com/nornagon/jonesforth/blob/master/jonesforth.S 
Maybe wrong, still cool. Never thought of it like that.
The funny idea is while everyone is talking abiout how to properly to the scanf, this solution does everything in a one liner, with the added bit that it will work on only some of the compilers. #include &lt;stdio.h&gt; int main( int argc, char **argv ) { return argc = getchar(), printf( "%c%c\n", getchar(), argc )-3; } 
With bit you mean byte? double should have 8 byte on 64bit architectures and 16 byte are \_\_int128 #include &lt;stdio.h&gt; int main() { double b = 12.123456; printf("%lu\n", sizeof(b)); // size of b in byte printf("%f\n", b); __int128 c = *((__int128 *) &amp;b); // casting b to fit into c printf("%lu\n", sizeof(c)); // size of c in byte printf("%f\n", *((double *) &amp;c)); // casting c as a double return 0; } Output: 8 12.123456 16 12.123456 I converted the 8 byte double into a 16 byte \_\_int128. I never used 16 byte integers, so I don't really know how to print them correctly. &amp;#x200B; Does this help or is this practically usefull at all?
Check out stage0... that shit is black magic
No blog spam please.
There is nothing impossible about negative zero. IEEE 754 floating-point numbers use a separate sign bit and have distinct representations of positive and negative zero.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
I switched from perl (basic scripting) directly to C: [https://www.youtube.com/user/CalebTheVideoMaker2/videos](https://www.youtube.com/user/CalebTheVideoMaker2/videos) helped me to understand the fundamentals. He has a lot of C guides, some C++, Java, Javascript, Python, ... &amp;#x200B; The basics are really easy, the real problem is the memory management, debugging and understanding the compiler.... Watch the guide -&gt; try and error for a week -&gt; read a book &amp;#x200B; Understanding how pointers work (casting them correctly and so on) needs some practice and experience, you won't learn that out of a book or guide.
&gt; Read the input as a string That's not very helpful... `argv[1]` is already a string, and the rest of your answer simply restates the question.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/devsjunky] [What do C arrays actually do under the hood? : C\_Programming](https://www.reddit.com/r/DevsJunky/comments/b3asod/what_do_c_arrays_actually_do_under_the_hood_c/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/devsjunky] [Building Win16 GUI Applications in C : C\_Programming](https://www.reddit.com/r/DevsJunky/comments/b3ax42/building_win16_gui_applications_in_c_c_programming/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I think you can show it going along these lines. (x1-y1)^2 + (x2-y2)^2 - ((x1-y2)^2 + (x2-y1)^2) = (x1-x2)(y2-y1) If x1&gt;x2 and y1&gt;y2 then the right hand side is negative and therefore the norm obtained by pairing up x1 and y1 is less then by pairing up x1 and y2. 
 #include &lt;stdio.h&gt; void print_int128(__int128); int main() { double b = 12.123456; printf("%lu\n", sizeof(b)); printf("%f\n", b); __int128 c = *((__int128 *) &amp;b); printf("%lu\n", sizeof(c)); printf("%f\n", *((double *) &amp;c)); printf("Printing it as (long) cast:\n"); printf("%lu\n", (long) c); printf("Printing it as __int128:\n"); print_int128(c); return 0; } // https://stackoverflow.com/a/17237254 // didn't know how to do it void print_int128(__int128 n) { if (n == 0) { return; } print_int128(n/10); putchar(n%10+0x30); } Output: 8 12.123456 16 12.123456 Printing it as (long) cast: 4623014517045263725 Printing it as __int128: 4623014517045263725 Seems to work
This is not the C-sharp subreddit. Try /r/learncsharp, /r/csharp or /r/dotnet.
on a slight side note that you might find interesting - a language is said to be self hosting when it can compile itself, so if the next version of Z (a made up language for the sake of example) was written entirely in Z then Z would be a self hosting language.... [https://en.wikipedia.org/wiki/Self-hosting](https://en.wikipedia.org/wiki/Self-hosting) some would no doubt argue that a language hasn't come of age till it reaches that mile post.... myself I'm not so sure, there are hybrid languages for example... 
As others have said, it's because of two's complement encoding. If you note that zero is `0000_0000` when you susbtract one and toss away the borrow you get `1111_1111`. This does mean there is a wrap around in the plainest sense, but many processors will set some sort of flag for this.
although decades ago I learnt 2'comp I watched this just to see if it would be good enough to pass onto someone who later asked my a similar question, all I can say is his students are lucky enough to have a great teacher.... AND he explained overflow detection !
Coming of age? Sure, it's a good challenge. Good choice for the long term? I'd lean to probably not because of all the reinventing the wheel one would do, especially when you look at all the good stuff to come from LLVM. Why would I want to even attempt reinventing a ton of the stuff in there?
Correct!
Yup. It also prevents having a positive and negative 0 (i.e. 10000000, 00000000)
In your first code, you declared terms such as X, Y etc. So system gives garbage values to them. That‚Äôs why declared terms such as ‚Äúsum‚Äù have garbage value. However, in your second code, even tho system attach garbage values to the X and Y, you attach values with scanf to X and Y. Because of that ‚Äúsum‚Äù have true value. The point here is that when something declared, system attach then garbage value. 
something i don't think anyone else has said - although this is generally (almost universally) true, the [C standard only specifies](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0907r1.html#c-sign) that it has to be 1 or 2's complement. so it's not necessarily true in all C programs (ie on all hardware).
scanf assigns the user input to variables x &amp; y. When you use these variables before the scanf statement, any value that is in the memory location of x and y is used. Thus, you get garbage values. Only after scanf is executed, the x and y memory locations will have the values that the user entered.
note that this isn't [yet](https://twitter.com/jfbastien/status/989242576598327296?lang=en) standard in C - in theory it can be anything.
The code is executed one line at a time, from top to bottom; it doesn't go back and retroactively change variables. The variables you declared to be floats are not assigned values at the time you take their sum, difference, etc. When you say: float x; /* its value is whatever is already in that memory spot*/ So, float x; /*holding garbage value*/ float y; /*holding some other garbage value*/ float sum = x + y; /*adds both garbage values together*/ scanf(...) /* Gets actual value */ print(...) /* Prints garbage value in sum because its value was never changed.*/
Everyone else here is right and is giving you a good rundown on two's complement; I just want to point out that the scheme you mentioned is called a *sign‚Äìmagnitude* representation (for hopefully obvious reasons), and while not ubiquitous, it is occasionally seen in hardware, and the C and C++ standards even have explicit allowance for it! There is another common representation called *ones' complement*, where negative numbers are simply the bitwise inverse of positive numbers. Each integer representation has interesting properties, but two's complement is by far the easiest to work with (in hardware and software), which is why it dominates the industry.
Thank you.
That link looks incredibly interesting. Thanks so much for posting it :)
Negative 0, which is a perfectly acceptable number in IEE 754
But that's not a sliding average, which is what OP is asking for. For that, you need a circular buffer.
What they're saying is, come back when you have an actual C question. What you have now is a math question.
Your answer is the correct one: *twos-complement*. However, the single biggest value to *twos-complement* is that it guarantees that `zero` will always have only one value. 
I should have made my answer a little clearer. What I was trying to say is to check if the argument is a integer, loop over the string and check that each character is a digit. If any none digit characters are found, the string is not valid. If it is valid, convert the string to a int. So something like the following: Int main(int argc, char *argv[]) { int len = 0; int i = 0; if(argv[1][0] == '-') { i++; } while(argv[1][i] != '\0') { If(argv[0][i] &lt; '0' || argv[0][i] &gt; '9') { printf("invalid input\n"); return -1; } i++; len++; } // valid input convert string to int return 0; } 
Or, you know, `strtol()`.
If one subtracts 1 from a positive number whose last 5 bits are 0, what will be the last 5 bits of the result? If one subtracts 1 from a positive number whose last 50 bits are 0, what will be the last 50 bits of the result? If one subtracts 1 from a positive number whose last N bits are 0, what will be the last N bits of the result? Two's-complement arithmetic simply generalizes this principle so it doesn't care whether the number started out positive. Think of the leftmost bit of a two's-complement representation not as having a negative weight, but rather as representing the state of an infinite string of bits to the left. Overflow occurs if there would be bits to the left of a number's representation that don't match its leftmost bit. Note that while the C Standard allows for the possibility of machines performing arithmetic in such a way that the result of lower-bit computations can be affected by the values of upper bits, no modern machines perform integer math that way. Unsigned computations larger than a machine's word size will require the ability to perform lower-bit computations without regard for a number's higher bits, and if one has the ability to perform such computations, doing so for signed and unsigned math alike will be easier than treating signed math differently. Incidentally, the authors of the Standard have said that they expected that most implementations would treat most signed and unsigned operations identically without regard for whether the Standard required them to do so (the authors of the Standard listed the exceptions). There was no need to have a rule to mandate that `uint1 = ushort1*ushort2;` be processed in arithmetically-correct fashion for product values in the range INT_MAX+1u to UINT_MAX, because they expected that implementations would behave that way--with or without a mandate--except in rare cases where some other behavior might better serve their customers. I don't think they foresaw the fact that compiler writers might use the fact that the Standard doesn't require such behavior as a judgment that compilers shouldn't generally be expected to behave in such fashion, but the above assignment will in fact cause gcc to generate code which is only reliable for product values up to INT_MAX,. 
It‚Äôs two‚Äôs compliment, not simple sign bit. 1. Prevents having two zeroes 2. More importantly: You don‚Äôt have to split it and work with the number and sign separately in the ALU, you can work with it like normal and it implicitly works correctly. It‚Äôs really clever when you look into it.
Might be worth it to point out that different languages behave differently. C is what's called an "imperative" language. That means that the code you write expresses a sequence of operations that have an explicit ordering. Execution starts at one point and proceeds forward one step at a time. The state of the program changes as that happens. Hence, your code that computes sum, product, etc. on x and y has to come after you initialize x and y with data from the user (the scanf call). There are also languages that are "declarative" in nature. They don't specify an explicit order. They just specify operations that can occur, and it's up to the evaluation engine to determine the order. Excellent example of this is Prolog. Both of these categories have subsets. For example, under imperative languages, there are "procedural" languages and "object-oriented" languages. C is procedural. C++ is a mix of procedural and object-oriented.
Some machines did store it as 10000001, others did weirder things like ones complement. 
Are you certain that ffmpeg would allow that kind of input and be able to successfully convert it into a vorbis file? 
Operators are not objects and you cannot store them in variables. What you can do is make a function to wrap the operator and store a pointer to that function. To make a variable that stores a character, use a variable of type `char`: char c = 'x';
Some computers actually do it the way you suggest, although I don't think anything modern does it that way. Doing it that way requires the computer make decisions when doing simple arithmetic. "Ok, that was an add instruction, but one of the numbers has the sign bit set, so do a subtract instead". What we use today is known as "two's complement". Using that system, the computer just throws the two numbers into the adder circuit and it all just comes out right. Say, for instance, you want to add 5 and -3. In binary, you get: 00000101 +11111101 -------- 00000010 And Bj√∂rn's your uncle. This technique is actually historical. If you read some older textbooks or use older calculators, you'll see that if you subtract 1 from 0, they'll often write it as 999999. As long as you eventually add something into your sum that causes it to overflow back to a positive number, it all works out in the end. And if you wind up with something starting with a bunch of 9's when you're done, that's when you actually convert to -1 notation.
I think you may have misinterpreted, I do a whole bunch of calculations, and then I print the result to the screen by multiplying the doubles by 127 and then storing the result in a char which I putc. This is fine for a bit depth of 8 bits, but if I wanted a bit depth of 16 I'd have to print 2 chars, and that's where things get confusing. I have to say, that's pretty neat though. I didn't know you could do that.
&gt; you take two's complement by inverting all bits and adding 1. On the old PDP-8 computer, the "negate" operation was called "complement and increment", opcode CAI
Oh yeah my bad. I didn't see the last part of his question
/r/somewhatinteresting
Twos compliment makes it possible to both add and subtract using the same half-adder circuitry in the CPU. Go check out the Wikipedia on that, it's really novel and means you don't need separate subtract instructions (though most do) or subtraction circuits. Note this is implementation defined in C. You can't both rely on this behavior and guarantee portability between compilers or architectures (though you're likely to be very lucky almost 100% of the time).
'x' isn't an operator, do you mean ' * ' (multiplication)? Regardless, operators are among the language's tokens (punctuator since C99), which is to say they are among the basic building blocks that the language uses to translate your source code into the actual running program during compilation. Normally, I would like to point to a specific part of the standard that says why you can, cannot, or should not (undefined behavior) do such a thing. Reading through it though, I cannot find an actual specific statement about what you're asking. I suspect that this is because it is actually just a by-definition programming thing. If you directly treat an operator as a variable, there is no "smaller" unit that the machine can use to differentiate the variable version from the token version. tl;dr -- to my knowledge no, because it's the basic building block of a programming language and the machine couldn't parse it correctly. I, however, cannot think of a specific source to point to to justify this, so I'd appreciate it if someone else has one or can correct me.
Output the integer as two characters, the first made from the lower 8 bits and the second made from the upper 8 bits. I think ffmpeg supports this format as pcm_s16le.
Because two's compliment.
You're exactly right. The thing is, I didn't know exactly how to do that. I've found a stackoverflow post that explains it though. Thanks for the help!
Thank you so much dude im in a Logic design class this will definitely help
Yes it surprised me a lot when i found out just how small the ammount of assembler was for such a system. The inventor of the language made it as a portable toolbox since he needed to program on different cpu's. It's a bit of a weird language but also very powerful, as you've probably seen lots of constructs like if while etc. can be implemented on a higher level. I can imagine if one has to bootstrap from nothing implementing this as a first step can be very helpful.
There used to be one's compliment computers. They would use the extra zero value for various purposes. I recall that you could differentiate between a numeric field read as a textual zero as 0 and one read with all spaces as -0 on a CDC one's compliment machine. One's compliment has no real advantages, though. &amp;#x200B;
You Sir made the special effort .. love it. Just wanted someone somewhere to say thank you and to tip a hat in your direction. The interent still works because of good people like you. Also "Bj√∂rn's your uncle" may be C++ related but it is cool anyways and I will use that expression today. 
I was afraid that someone could have a actual usecase for things like that
&gt; "Bj√∂rn's your uncle" may be C++ related Heh; I didn't even think of that. It's from one of Terry Pratchett's *Diskworld* novels. The conversation is between one of the night watch and Carrot, who was raised by dwarves: "[yadayada blah blah something something] and Bob's your uncle". "But ‚Ä¶ surely Bj√∂rn Stronginghtearm is my uncle". It's explained to Carrot that it's just an expression, and afterwards, Carrot uses the expression "Bj√∂rn's your uncle"
Yes, I know there is a library function - which someone else had already posted. I was showing OP another approach that is also a useful approach to input validation in general as well as demonstrating some basic string processing techniques in C.
Although there were some implementations of C89 that used ones'-complement platforms, C99 added additional requirements for unsigned type, such as a requirement that there be a 64-bit or longer unsigned type with a straight binary representation, that made it impractical to support on such platforms. Unless or until those other requirements are waived, there will almost certainly never be *any* C99-or-later implementations which do not use two's-complement math. 
Not directly, but if you add function wrappers you can get pretty close: int add(int a, int b) { return a + b; } int multiply(int a, int b) { return a * b; } void whatever(int (*func)(int, int)) { int result = func(1, 2); ... } whatever(add); whatever(multiply); 
If one wanted to attach sets of e.g. red and green blinkenlights attached to registers, with positive numbers using green lights and negative as red, the amount of circuitry that would have to be added to registers to display ones'-complement values in such fashion would be much less than two's-complement. Displaying a 36-bit ones'-complement register using 35 pairs of light bulbs, for example, would require 70 small transistors and two big ones. The amount of circuitry needed to display negative two's-complement values of some size (so -5 would light up bits 0 and 2) would be greater than the amount needed to implement a register of that size. Ones'-complement could thus have considerable advantage if one wants to show values directly on blinkenlights without having to use formatting code to make them human-readable first. Such advantages aren't very meaningful, however, on machines without blinkenlights. 
Ironically, there have been many times I've found it easier to work out the sequence of bytes needed to represent a few instructions than to figure out the assembly code necessary to do so. The need for assembly language or other build-system-specific hackery in many projects could be reduced if there were a standard syntax equivalent to one in Borland's Turbo C which would generate a function whose executable code would simply contain a given sequence of bytes, and if there were a standard syntax to force symbols to be placed at particular addresses. Adding those two features to the Standard would allow many freestanding projects to be accomplished wholly using Standard C syntax for everything (the effect of trying to run some sequence of bytes would depend on the target processor, of course, but shouldn't depend on the compiler that processes the code). 
...and then you get to the hardware level and learn about memory re-ordering, and that all of those things that we think of as happening in order, in fact don't, and the reordering of memory accesses/operations screws things up in multi-threaded contexts.... ...I'M LOOKING AT YOU, PETERSON'S ALGORITHM. ;)
&gt; it is occasionally seen in hardware IEEE-758 floating-point basically uses sign-magnitude, although the magnitude field is broken up into exponent and mantissa, and there are special NaN and ¬±‚àû values.
Haven't ever used those formats, but I saw f64le, floatle and such formats in ffmpeg and mplayer manpages. I guess not universal like s16le.
* Instead of representing the player with a `char`, consider making an `enum`. * You have several global variables. `grid` and `grid_size` are understandable, at least (though I wouldn't make them globals anyway). `counter` is questionable, and there's better ways of doing that job. `letter` should just be a local variable. * Variables don't have to be declared first thing in a function. On the contrary, many prefer variables to only be declared in the smallest scope possible. * `valid_choice` is effectively unused. `move` is unused * You have a local `gridsize` variable as well, along with nonsense code like `grid_size = gridsize`. * Your main loop has a very confusing structure. Don't write that loop like that, keep it simple and straightforward. * The code for getting the move for player 1 and player 2 is duplicated, which means you should put it into a function. * I would put the code for a tie game after the loop, not inside it. * `player_won` proposes returning `true` and `false`, but it actually returns an `int`. You've already included `&lt;stdbool.h&gt;`, so there's no excuse not to make this `bool`. * The parameter validation in `init_grid` is redundant, but it's not called anyway (and `draw_grid` does the initialization, surprisingly). I would make the default value for an unused cell 0, which makes initialization much easier, and then add logic to print what you want based on the value in the cell. * `draw_grid` only works once, for initialization. You then repeat the code for drawing in `update_grid`. You should write a single function that does the drawing and can be used generically. * I'm not sure your logic in `player_won` conforms to the efficiency requirements in your comment. There's certainly cleaner ways to write the code. Regarding replaying feature. For this, the very first thing you need to do is keep track of all the moves that have happened in the game. To replay, you need to reset the game board to its initial state and then go back through the history, move by move. If done right, all you need to do is call `update_grid` and everything should work how you want.
Yeah the bootstrapping process is the main point. In theory it start from machine code as assembly isn't exactly a language. Then you can start writing a text processor in assembly to parse the high level language to assembly. The interesting part is when you can write a compiler that compile itself to what it was. That's the bootstrapping moment. After that you can continue compiling your compiler from the exisint bootstrapped binary. 
1. use an array for the board and create a method that prints whole board use array and newline 2. global vars for booleans 3. structs overcomplicates your code 4. ask user for number to put x or o and put it in corresponding element if board char array offset by 1
I would probably touch on the following: 1. Major software development projects that largely use C, in use today (the Linux kernel, Apache web server, basically anything OS level). 2. How the language itself has evolved - check out the specs for the various C flavors and standards over the years (K&amp;R C, ANSI and ISO C, C99, C11, C18, etc). 3. How C inspired countless other derivatives. Look at those derivatives (C++, C#, Java, ObjC, ad infinitum). You could probably find some good material on each and how they took the best bits of C, improved (or not) on them. Sorry I don't have any good links off the top of my head, but that should give you a good starting point for what to search for in your research. Have fun!
If you add 1 to your **11111111**, it will overflow to 00000000 which is, of course the binary of zero.
&gt; C-- is not related to C, as some may be lead to be believed. yeah what could possibly lead them to believe that?
Another good teaching example of "threaded code" is in CPython's bytecode interpreter. They also make use of GCC's computed `goto`, sometimes called [labels as values](https://gcc.gnu.org/onlinedocs/gcc/Labels-as-Values.html). The code has a long-winded but really helpful comment [explaining the trick](https://github.com/python/cpython/blob/master/Python/ceval.c#L661).
Unisys ClearPath 2200 series computers still use one‚Äôs complement arithmetic, I believe. Sperry Univac 1100 backwards compatibility.
&gt;Is there a reliable way to build a binary that will run on OSs with an older glibc? Have you tried Docker? [https://hub.docker.com/\_/centos](https://hub.docker.com/_/centos)
Look at [Bjarne Stroustrup's website](http://www.stroustrup.com) for writing on how C++ evolved from C. Especially check out The Design and Evolution of C++ ([http://www.stroustrup.com/dne.html](http://www.stroustrup.com/dne.html)) for some really great insights into how he slowly built the features of C++ and kept compatibility with C. 
Yes, only Holy Build Box, but I found it annoying when I had to install external dependencies that depended on a newer version of flex or bison then what was available. 
You should check the return value of `scanf`. As it stands, the program will cause undefined behaviour if they enter letters instead of 1, 2 or 3. 
A lot of people have mentioned why 2s-complement is great, but a couple of days ago I found a rather niche but spectacularly brilliant reason/use case for two‚Äôs complement: How many trailing zeros are in a 64 bit integer? Say you have a 64 bit integer, x: 001011000100000....000 and you want to find how many zeros there are at the end. Calculate (x&amp;-x)*0x7edd5e59a4e28c2&gt;&gt;58 ‚Äò-‚Äò is two‚Äôs complement, the number 0x7... is just a number (in hexadecimal), &amp; is bitwise AND, and &gt;&gt; is a bitshift. This gives you a number between 0 and 63 unique depending on how many leading zeros there are! Then just populate an array that maps these numbers between 0-63 to your answer. This is the most efficient way to calculate how many zeros there are at the end of a binary number.
This is not a critique of the code itself, but... Player O, Choose location (x,y): 0,2 (0,2): 0 1 2 0 . . O 1 . X . 2 . . . Typically, x is used as the horizontal axis and y is the vertical axis, so I was not expecting it to show up in `2,0` when I typed `0,2`
gnu compiler collection (gcc) has everything you need
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
This is difficult to get right. Static linking often works though.
If scanf always returns -1 if it unsuccessful, then what should be used instead? I knew something was going wrong with it as my program ends up in an infinite loop with chars, like you mentioned.
&gt;godbolt.org here it is as a link for mobile users [godbolt.org](https://godbolt.org) :)
Thanks, good advice.
How would I go about changing code like `grid_size = gridsize` ? I removed the global variable and amended but then when I run my unit tests I run into a seg fault. The unit tests pass otherwise.
You should be passing the grid and the size as parameters to your functions.
I second gcc!
I love discrete math, but I always found myself using OpenGL for those sorts of things, because I want to see the results. There is a C++ OpenGL library, and if you decide not to use "new" and classes and a few other things, it'll be close enough to C to keep you happy, I expect.
How are you going to output an image?
&gt;If scanf always returns -1 if it unsuccessful, Not true, check the documentation! You can continue to use scanf but you need to take some appropriate course of action if the input was incorrect. One approach would be to clear the rest of the input (by calling `getchar()` until it either gives `\n` or `EOF`) and then go back to another scanf call.
You get bonus points for making me laugh! I know it's a crazy way of doing things, but it's incredibly simple and most audio programs can actually read and understand it. This workflow makes way more sense on Unix-like systems of course. 
While not a C based book, Sedgewick's "Computer Science" contains a lot of exercises concerning discrete math. Most of their Java code can probably be converted to C if it doesn't use their "standard drawing".
I‚Äôve been working on learning OpenGL, but there‚Äôs many gripes I have with it, so Last night I but the bullet and started working on trying Vulcan and getting over the ‚Äúfirst 800 lines of code‚Äù. Also I‚Äôm trying to move do more non graphical stuff cuz it feels like all I do üòÖ. Regardless, do you have any specific projects that you do in OpenGL? It makes sense that it would be a good sandbox for that, but I‚Äôd love specific ideas if you have them üòä. Thanks! 
I will check it out! Thank you 
&gt; I'm just wondering if there's a commonly accepted "best" implementation. Meet the following &gt; putting function pointers in structs which does seem easier especially if I end up needing more hardware specific functions. It's how everyone does it. The reason for that is that it decouples the hardware from the code by the means of a generic interface.
Thank you.
Thank you.
Thank you.
put all your function pointers into a struct. then, use the preprocessor to initialize one, and use its members anywhere you would call these functions. for most applications, you probably just want to have one of these structs as a static constant, but if your program grows more complex, you may write functions which take such a struct as an argument and call its member function pointers. at that point, you've rolled your own dynamic dispatch.
The format specifier for reading a single character with scanf is %c, not %char. Fixing that should fix your issue. As an aside, I've always found scanf to be unintuitive and clunky, so I'd definitely explore other options for reading input. The standard library has plenty of alternatives. 
In your if statements you are using the wrong operator. It needs to be if (t == a). What you are doing is assigning a to t with a single =. You should always compile with -Wall. The compiler would have warned you of this. Also why not compare directly? (t == '+') would be a lot more readable yet you obfuscate your code when you make variable names that have no meaning. I know that this is a basic example but proper naming of variables is important.
Nice, so many modern tui apps seem to be built with python these days.
Undefined behavior: You calculate with x and y which didn't get a value before! &amp;#x200B; The upper code works in the wrong order, scanf() needs to come before the calculations
"simple"
[https://www.geeksforgeeks.org/graph-and-its-representations/](https://www.geeksforgeeks.org/graph-and-its-representations/)
I see 'strtol()' was recommended several time. But in case of non numeric string it returns 0 (zero). I do not think it is right way to check. I'd recommend to use 'isdigit()' in loop to check each characted in argv\[1\]. If negative int is expected as input - first letter should be checked against '-'. another edge case: positive number goes with '+'. 
nice
Its just a style comment but I really dislike reading type definitions like this. This really calls for a typedef: typedef void (\*LED\_ON\_CALLBACK)(void) Then you define and initialize your device specific strucs with these. Similarly with function arguments. void set\_led\_func(LED\_ON\_CALLBACK on, LED\_OFF\_CALLBACK off) { }
`nnn` is in C. It uses the ncursesw library.
Ive seen a website, but I couldn't understand well. Here it is: http://csharphelper.com/blog/2017/02/draw-a-golden-spiral-in-c/
That's not C, it's C-sharp. Try asking a question in /r/learncsharp.
#include &lt;stdio.h&gt; int main() { float a, b; char p='+', q='-', m='*', z='/'; char t=''; scanf("%f %c %f", &amp;a, &amp;t, &amp;b); //I'm not sure if it is &amp;t or just t , try both; if(t=='+') printf("%f", a+b); else if(t=='-') printf("%f", a-b); else if(t=='*') printf("%f", a*b); else if(t=='/' &amp;&amp; b!=0) printf("%f", a/b); else printf("Error!!"); return 0; }
Please only post jobs offers and similar that are specifically asking for C programmers as this is a subreddit on C only. Merely trying to reach an audience of C programmers is insufficient to make your post on topic.
What's the part you don't understand?
I think you're asking about the difference between 'declaring' a variable and 'defining' a variable. If you search for those two terms you'll find a lot of info online.
malloc() is a function that, given a number of bytes of memory, will tell the operating system to give your program a chunk of memory of that size. You want a chunk of memory big enough to hold a `struct stack`, so you first work out how many bytes that will take, and then you ask the operating system for that many bytes.
I don't think you understand how pointers or malloc work A pointer is just the location of something in memory, it's not the thing itself. When you allocate a single pointer to your struct and then pass that to your function you have not passed a thing for it to operate on, just a random address to nowhere. Your function then tries to operate on the thing at the address you gave it, finds out that it's out of bounds, and it crashes.
It's just like any other memory management in C. You can allocate memory on the stack or on the heap. Using malloc gets you a block of memory allocated on the heap. If you want to allocate a struct on the stack, you declare your struct and set it's values, either manually or you can use initializer syntax: struct stack s = { 0, 0 }; The reason you are getting a seg fault is because this: struct stack *s; Is declaring an unallocated pointer, not actually allocating your struct. 
What others said... when you declare a "struct stack \*s", it is just a pointer.. what is it pointing to?? by default nothing... and when you try to use it in an operation you will obviously get segfaults. Hence you create a block of memory, large enough to hold the structure, and point the pointer to it. and then you will not get an error when you try to access or modify the pointer.. &amp;#x200B; Which is precisely what you have done in the example code above...
I've never liked how hard OpenGL makes it to extract yourself cleanly from the main loop. I had it down to a science at one point, but that's still my main gripe. Maybe Vulcan has patched that up a little, but I wouldn't know. You could do something like implement the [Held‚ÄìKarp algorithm](https://en.wikipedia.org/wiki/Held%E2%80%93Karp_algorithm). Tackles some graph theory and so-called "dynamic" programming, and if you get stuck there's plenty of implementations out there to crib off of....
Anything involving cryptography: big numbers, discrete math, modular arithmetic...
...XOR
Let's talk about one specific line of code, since your question is pretty specific: &lt;pre&gt;&lt;code&gt;struct stack *s = (struct stack*) malloc(sizeof(struct stack)); // If I do struct stack *s; //(segmentation fault) &lt;/code&gt;&lt;/pre&gt;
This is called a &gt;!https://en.wikipedia.org/wiki/XOR_linked_list!&lt;, and its use would be hard to justify.
This is just a variation on the common question of swapping two values in place. To encode two values in one variable and then retrieve either of them you can use an operation of your choice (XOR, mult/division, add/subtract) to get an intermediate value from which you can recover the original values if you know at least one of them. So, in theory, you could treat your pointer addresses like integers and XOR the next and previous addresses together and then store that intermediate. To go from the head to the next pointer you'd simply re-XOR head's link pointer with the head pointer to recover the "next" pointer. If you were allowed to use something besides NULL/0 for the end links, you could also use arithmetic operations. E.g. head's link pointer would be the result of END*(head-&gt;next). To move from head to 'next' you'd subtract the END pointer from head's link to recover the 'next' pointer. The main problem with all of these is that you're not permitted to perform binary operations on addresses/pointers (i.e. XORing pointers) and your compiler will complain. I suppose you could store them all in an array and instead of storing the actual pointer in the node store the array index of the pointer and then perform your operations described above on those indices. Then you'd have to have re-size operations and stuff for the array during array creation etc. but it would work I believe.
Technically speaking, it's also not portable for two reasons: * `uintptr_t` is the only integer type that can safely round trip a pointer, and it's optional. * An implementation is [permitted to have](https://nullprogram.com/blog/2016/05/30/) this behavior: void *p = malloc(1); uintptr_t a = (uintptr_t)p; uintptr_t b = (uintptr_t)p; assert(a != b); // integers allowed to differ assert((void *)a == (void *)b); // but must cast to equal pointers 
It's not intended to be used.... 
My tactic is to cast the pointers as a char*, then dereference to do the conversion byte by byte for `sizeof(struct node*)` bytes.
Learn this lesson well, OP: developers are miserable people, doubly so on the internet. I mean, here you are - you've learned of a novel solution, and you want to celebrate it with others! I mean it's perfectly fair, the XOR list *is* genius, and it is obscure because while awesome, a bit impractical. So you come out and say it, you're talking about it because it's cool, you want to remind everyone we do cool things on the occasion, and your point is making it a thinking challenge for funzies. Enter the look-how-smart-I-am old dogs who have heard of this trick before. What do they do? They rag on your shit, like you need to be told, like you couldn't read the Wikipedia on the subject yourself. It's almost like they think they're doing you a favor educating you, but really they're just calling you an idiot, and telling you this is stupid.
I liked that. Sum also works, does any 1 to 1 arithmetic op ?
Indeed... I mean... we could just go back to talking about `scanf` errors?
Imagine a simplified definition for malloc/free: ``` char system_memory[536870912]; // 512 MB buffer of "system" memory void free_memory_offset = 0; // How much memory has been handed out void *malloc2(int size) { void *ret = &amp;system_memory[free_memory_offset]; free_memory_offset += size; return ret; } void free2(void *value) { // Ensure we are freeing something in the system memory assert(value &gt; &amp;system_memory[0]) // Recalculate the offset; we free everything after value here, which is // not how free works in the real world, but good for this example free_memory_offset = value - &amp;system_memory[0]; } ``` When you call malloc2, it will return a location in the system memory for you to store your data structure. It needs to know how much space the structure needs to ensure that it doesn't hand that memory out again the next time malloc2 is called. An example, using our malloc2 above: ``` struct pair { int x, y; } int main() { struct pair *p1, *p2, p3; char *hello; p1 = malloc2(sizeof(struct pair)); // p1 now points to &amp;system_memory[0] p2 = malloc2(sizeof(struct triple)); // p2 now points to &amp;system_memory[sizeof(struct pair)] p3 = malloc2(sizeof(struct pair)); // p3 now points to &amp;system_memory[sizeof(struct pair) + sizeof(struct pair)] free2(p3) // p3 still points to something in system_memory, but that location might // be given to something else, say hello. You can no longer rely on that pointer hello = malloc2(strlen("Hello world!")); strcpy(hello, "Hello world!"); } ``` Before people scream, this isn't how malloc actually works. Maybe look at something like (https://stackoverflow.com/questions/1119134/how-do-malloc-and-free-work) for a more complete answer than I provided here.
It looks pretty good for the most part. Generally we only expose function definitions in header files, the actual implementation should be in a .c file. This only really becomes an issue when your project grows to more than a few compilation units. The formatting and indentation are a bit strange at some points, but that has no effect on the end result, and is completely your choice. As long as you stay consistent in your formatting choices, it‚Äôs all good.
Thanks, that's what I ended up doing except not static as it's used by different files. The struct is initialised in `main.c` (which has access to the hardware specific functions), and used in `driver.c`. Reading about the `extern` keyword everyone seems to put it in header files, however no other file outside those two is ever going to need access to this struct, while other files might include `driver.h`. Is there a reason not to use `extern` in a .c file?
i cant help with Criticism, because im new to C. but just wanted to say i enjoyed reading your code. it was easy to understand whats going on and learn from it. thank you
That was the first thing I noticed reading it. Really no need to declare your functions as extern. If they're in a header, they're pretty much implicitly extern. Specifying it kinda just clutters up the code. But as said, overall it looks pretty good. 
Struct list is undefined.
Sum and subtract seem to work, and each has its own quirks. I like XOR because it's instantly reversible in any direction, and has the extra feature that a node's address XOR'd with itself yields NULL, which can be a convenient base case to test for.
Do not put function definitions into header files. Definitions go into source files, only declarations go into header files. When you are more experienced, you can start to break these rules for inline functions, but right now it's a good idea to stick to the basic rule. If you otherwise put function definitions into header files, you will eventually get weird linking errors when including the same header from multiple source files.
Ah yes, `tree` is supposed to be `list`. That's what I get for hastily putting together a post on my phone over breakfast (while having spent too just time working on other data structures). Thanks for pointing it out.
Discrete and Combinatorial Mathematics by R. Grimaldi is a wondrful book. Check it out
Hi OP, &amp;#x200B; Like the other user said, you're getting some flack because grumpy. It's nothing new to me either, but I like cycling up old topics, and you've jived my thinking. It'd be cool to have a C\_Challenges subreddit. I'd team up with you on that if you want. &amp;#x200B; Ciao
Thanks 1000 times ü§óü§ó
Thanks 1000 times ü§óü§ó
Thanks 1000 times ü§óü§ó. I will stick to the advice
Also, while implementing linked list data structures in C: struct node { int value; struct node\* nerxt; }; Why does this next poitner have to be of type struct? It just stores the value of next data right? Why can't it be of type int?
Also, while implementing linked list data structures in C: struct node { int value; struct node\* nerxt; }; Why does this next poitner have to be of type struct? It just stores the value of next data right? Why can't it be of type int?
The whole idea of a linked list is that you have a link from node to node. The pointer is the link, and each node in the list is of type `struct node` so it needs to be a pointer to `struct node`
I believe there is a bug in your example. In the blog, ptr\_a and ptr\_b could have different values even if they compare equal to same value when cast to void ptr. In your example they can't. "a" must equal to "b" unless the compiler is buggy.
A couple of things: * Some of the macros in definitions.h look like they probably should've been functions and not macros. Especially the FREE macro, which just frees the data in whatever happens to be the local variable named `contacts` wherever it happens to be invoked looks weird. Maybe have a `phonebook_free(struct PHONEBOOK_t *contacts)` function instead? * Make sure to never use a variable after you've freed it. The FREE macro does `free(contacts);`, and then `contacts-&gt;firstName = NULL;` etc after `contacts` is already freed, which is undefined behavior. To detect other memory-related issues, compile your program with `-g -fsanitize=address` and then run it. * This is sort of pedantic, but user types generally shouldn't end in `_t`, because POSIX reserves that for system library related types. A lot of libraries don't follow that rule though.
The fact that repeated attempts to convert a pointer to an integer are not guaranteed to yield the same integer would not generally be a problem unless taking the xor of two `uintptr_t` representations of the same pointer, and xoring that with the representation of another pointer, would yield a value that cannot be converted to a pointer. A more serious problem is that it's possible for pointers to compare equal without being equivalent, and without either pointer being able to access any storage that is reachable from the other. For example, given `int a,b,*pa=&amp;a,pa1=pa+1,&amp;pb=&amp;b;`, the expression `pa1[-1]` would be usable to access `a`, and `pb[0]` would be usable to access `b`, but even if `pa1` and `pb` happen to compare equal (something that would be possible, and on some implementations likely, but which few implementations would guarantee), that would not imply that `pa1[0]` could be used to access `b`, nor that `pb[-1]` could be used to access `a`. The Standard guarantees that if type `uintptr_t` exists, `(int*)(uintptr_t)pa1` would yield a pointer that compares equal to `pa1`, and that `(int*)(uintptr_t)pb` would yield a pointer that compares equal to `pb`, but it doesn't say that the first pointer would be *equivalent* to `pa1`, nor that the second would be *equivalent* to `pb`. A capricious implementation could treat `(int*)(uintptr_t)pa1` as yielding `pb` and `(int*)(uintptr_t)pb` as yielding `pa1`. Although compilers would in most cases process integer-to-pointer conversions in useful fashion, there is no guarantee that they will do so. If the computation of `uintptr_t up` involves `(uintptr_t)&amp;a` and some other things the compiler doesn't doesn't understand, the compiler wouldn't be required to handle the possibility of an access to `*(int*)up` affecting anything other than `a`, even if the expression was actually something like `(uintptr_t)&amp;a - (uintptr_t)&amp;a + (uintptr_t)&amp;b`. Personally, I question the value of having a compiler support `uintptr_t` without guaranteeing that if `up == (uintptr_t)p`, then `(int*)up` may be used to access anything that would be accessible via `p`, but the Standard would allow implementations to define `uintptr_t` without supporting any particularly useful semantics. 
Why would you ever want a language that uses both curly braces and colon whitespace for code blocks?
In my example here, sure, it's very unlikely that the casts would result in different integers since they came so directly from the same pointer. I can't imagine a *practical* reason that what I described might happen, but it's still allowed to work out this way. Imagine an impractical, crazy implementation that randomly flips some unused pointer bits when making these casts, merely because the standard allows for it. In the article the example had the pointers arrive as separate arguments to allow for the more practical possibility that the values took different paths through the program and wound up with a different underlying representations. For example, suppose, as discussed in the article, unused pointer bits were used to track boundary information, but one of the pointers passed through an external library function and the boundary information was lost. 
 extern void listContacts(struct PHONEBOOK_t * contacts) { ... if ( ! contacts-&gt;nextContact ) { PRINT_PHONE_BOOK(contacts); return; } while ( contacts-&gt;nextContact ) { PRINT_PHONE_BOOK(contacts); contacts = contacts-&gt;nextContact; } PRINT_PHONE_BOOK(contacts); return; }; could be written as void listContacts(struct PHONEBOOK_t *contacts) { ... for (struct PHONEBOOK_t *p = contacts; p != NULL; p = p-&gt;nextContact) { PRINT_PHONE_BOOK(p); } } 
Looks interesting. Thanks for the recco - need a quick refresher in DM a decade out of university!
Engine can be found here: https://github.com/EvilPudding/candle
Sounds like a "mini shell". Google finds lots of examples.
It can be type of int(if you have a 32bit binary). There is nothing holding you off to do that. The reason why we write "struct node* next" is that its easier to see that this variable is a pointer to a struct node. Also the compiler can give you some errors. If you just had "int", you wouldnt know if that variable had a value or a pointer
Okay , thank you: I am having hard time implementing linked lists: Why is this program printing a 0 instead of 52? #include &lt;stdlib.h&gt; #include &lt;stdio.h&gt; struct node { int data; struct node *next; }; struct node* push (struct node *my_list, int value) { struct node * newnode; newnode = (struct node*) malloc(sizeof(struct node)); if (newnode == NULL) { printf("Error\n"); return my_list; } newnode -&gt; data = value; newnode -&gt; next = my_list; return newnode; } int main() { struct node *a; a = (struct node*) malloc(sizeof(struct node)); push(a,52); printf("%d\n",a -&gt;data); return 0; } &amp;#x200B;
Well there's a reason to learn SDL.
What do you mean?
In your github link it says you used SDL2. That's inspiring stuff and makes me want to learn the library.
SDL is mostly used for the OpenGL context initialization, there's a lot of other libraries for that.
If you had to make a short list of essential skills to learn in order to make that engine, what would they be? It looks really good.
What are you trying to achieve? When you call push you get a pointer to a new node, but you are ignoring the return value(a still points to the first node). If you did "a = push(a, 52)" then it would print 52
Go ahead and give us a line by line of what you think the code does right now. Describe to us what a race condition is and how you believe semaphores work. Don't forget to use `formatting` to make the code easier to read.
For some reason, I imagine a soft jazz saxophone playing to this. 
It's not about the language, it's about the implementation; i thought others might be interested in reading over a pretty decent project like this one. I found this project after browsing Github...
General data structures and algorithms. Vector mathematics. Trying to be aware of what techniques are being used, read blogs and such on how a game does something specific. The most important part is managing to make the core small but extendable. When you have a large project, it tends to grow into a monster, then you don't want to touch it. This means trying to keep features compartmentalized, trying to make them the least dependent on each other as possible. This is easy to say, but hard to do, it's almost impossible to get it well the first time around.
I'm really impressed with your organization. The makefile alone is way beyond anything I've tried to do. Can you recommend any resources for learning how to break a large C project into multiple files? So far I've been limiting myself to one .c and one .h file, even when the .c file runs to thousands of lines. 
Not OP, but basically my strategy goes like this: "anything that does or assists in the same job and may need to share 'private' (static) data structures between each other all go in the same file". Rendering in one file, Input handler in another file, basic, shared-by-all-game-objects logic in yet another... etc etc etc. Anything that you can categorize as a 'subsystem' or similar is a good candidate to have live in its own file.
Looks cool but it's just extremely bizarre to see both syntaxes together.
Even with a `#pragma once` or include guard?
There are many ways to do it. I have two rules, the first, which applies to most of the code, is where I divide sources based on the structure they are deal with. For example, the game engine contains meshes, a mesh is a data structure that requires it's specific functions to interact with, so all those functions go in the `mesh.c` file. Just so things are organized, I prefix all those functions with `mesh_`, and their first argument is always the pointer to a mesh. Most source code falls under rule 1, but there's some code that doesn't need any structure, for those functions, I try to group them by their general purpose, for functions that are too miscellaneous and can't be grouped by purpose, I shove them into a general utility source.
In your method push() you can operate on my_list directly, i.e. you don't have to create a new node struct. You can do my_list-&gt;data = value; instead. Obviously for that to work you need to ensure that my_list is actuallt pointing to something. And that's exactly what your malloc() call in main() does. (Sorry I'm on mobile so can't get that fancy format)
Well, it would save on memory usage; with the modification of using an integer index instead of a pointer then it could be used in a memory restricted environment.
I can't possibly imagine why.
&gt; So I have a 2D array of characters that I am using to print a grid. At every index of the array it is "---" where the dashes are spaces. Then later in the code I ask the user for a row and a column number and then at that point in the array it chages to "-O-". It looks like you're making Tic-Tac-Toe. A classic beginner's assignment. &gt; So my issue is that I keep getting an error called segmentation fault (core dumped), and I have figured out that I need to use poiters. Can anyone help me understand how to create pointers for the pieces of the array. Segmentation faults can be caused by so many things, and you can't fix this by thinking "Oh, I should be using pointers." We'll need to see your actual code to be of any help here.
Very nice! I wish I had the time to explore your project.
Knowing what exec does can be easily searched on google or using the man pages (if you‚Äôre using a posix system). 
Yes. The problem is that code for the function is going to be generated in multiple object files because the definition is visible in multiple object files. Functions may only be defined in a single object file.
As it seems like you will modify such particular string at specific row/column later, so what we need to do is ensure there's an enough space to hold string for each slot inside 2d array. &gt; I will go verbose as much as possible. So if for some details you already knew, please don't mind my verbose text of explanation. Problem you're facing is mostly because you're trying to access memory outside of the area of your 2d array, so it violates and gives you such error. There're 2 ways to form 2d array in this case. 1. Fixed-size for each string 2. Variable and dynamic size for each string (we can adjust the size later, but we need to put some more effort to manually free such memory space later when we're done) Assume you want 3 x 4 (row x col) array to hold string. # For 1, you can form 2d array like this ```c #include &lt;stdio.h&gt; ... char ss[3][4][255]; for (int row=0; row&lt;3; ++row) { for (int col=0; col&lt;4; ++col) { snprintf(ss[row][col], 255, "-%d-%d-", row, col); } } ``` You can try to insert `printf()` after such `snprintf()` to see the result. What it does is it defined 2d array of string as 3 x 4 with each slot has 255 bytes (thus 254 characters + 1 for null-terminated character). This means you can input at maximum of 254 characters for each slot. If you want maximum at 255, you change such number to 256 as we need to take care of allocate 1 more bytes to hold string. The focus here is `snprintf()`. It will do the work of copying format string as shown for you, then it will automatically insert `\0` (null-terminated character) for you at the end provided that you assign string to it less than 255 characters. `ss[i][j]` is to locate such slot in 2d array. This will give back the array of char with 255 bytes waiting to be filled. It will return the address of array into such function. Array in C is always passing by reference. # For 2, you can form 2d array like this ```c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; ... char* ss[3][4]; for (int row=0; row&lt;3; ++row) { for (int col=0; col&lt;4; ++col) { ss[row][col] = calloc(1, sizeof(char) * 255); snprintf(ss[row][col], 255, "-%d-%d", row, col); } } ``` The declaration and one more function are added; slightly different from 1. `char* ss[3][4]` can be read in human way via the [clockwise-spiral rule](http://c-faq.com/decl/spiral.anderson.html) as "ss is array of 3 by 4 of pointer to character" in which pointer to character here is string. You call `calloc()` to allocate 1 object with size of 255 bytes. `sizeof(char)` will return 1 but as always we explicitly define like this to play safe with compiler and platform the program will run on. Then it goes the same for `snprintf()`. Lastly we have another work to do which is to free memory space as dynamically allocated. ``` for (int row=0; row&lt;3; ++row) { for (int col=0; col&lt;4; ++col) { free(ss[row][col]); ss[row][col] = NULL; } } ``` After `free()` we mark such slot as empty by setting `NULL` to array of 255 characters which is pointer. Play safe.
&gt;but it's still allowed to work out this way. Consider an impractical, crazy implementation that randomly flips some unused pointer bits when making these casts merely because the standard allows for it. &amp;#x200B; Seriously, you should be writing programming horror stories. I'm terrified over this very thought and I fear that I may lose sleep. I can't even imagine the ways the compiler can torment and hurt us if this is true. I hope no one will experience this kind of sadness. :( &amp;#x200B; &gt;In the article the example had the pointers arrive as separate arguments to allow for the more practical possibility that the values took different paths through the program and wound up with a different underlying representations. For example, suppose, as discussed in the article, unused pointer bits were used to track boundary information, but one of the pointers passed through an external library function and the boundary information was lost. &amp;#x200B; Yeah, that makes sense to me. &amp;#x200B; As for your earlier example, I'm just going to reject your reality and substitute my own where this is not possible or allowed! I need sleep!
sounds like you've got it figured out; good job. when i said "static", i was using it the way rust does - force of habit. i mean as a constant in your program's rodata. it sounds like, based on your description, you should *declare* the struct in `driver.h` as `extern`, like: extern const dispatch_table_t the_dispatch_table; and then *define* the constant in `main.c` (or whichever the platform-specific file is), like: const dispatch_table_t the_dispatch_table = { .first_method = &amp;first_method_for_my_platform; .second_method = &amp;second_method_for_my_platform; };
Base on my previous comment, here is for pure pointer to achieve the same thing. ``` char* ss2; ss2 = calloc(1, sizeof(char) * 3 * 4 * 255); for (int row=0; row&lt;3; ++row) { for (int col=0; col&lt;4; ++col) { snprintf((ss2 + row*4) + col*255, 255, "-%d-%d-", row, col); printf("%s ", (ss2 + row*4) + col*255); } printf("\n"); } ``` It's easier to think the whole memory space as only 1D array. We allocate the whole enough memory space for all slots as you can see here for 3x4 array with each slot of 255 bytes, we will have 3 * 4 * 255 (as well multiply by size of char). The only matter here is to do math to give us correct location for certain slot. We locate row first by using `row*4` as we know each row has 4 columns thus we multiply by 4 i.e. if we are at 2nd row (row 1) we should have progressed through 4 slots already. Now for accessing column, a little bit tricky as each slot also has fixed size. So we need to do the same, step by 255 for each column. We jump one by one of whole string. I'm still think it's also possible to do this with double pointers. If I come up with such solution I'll post back another comment.
We used this in a real project once. There had a node structure that could not be made larger, so we used this trick. It never shipped, because we changed algorithms to only need a single linked list. But I lived with this data structure for several months. Incidentally, debugging was a bitch. 
Continued from previous 2 solutions in my previous comment, here is for pure pointer to achieve the same thing. &amp;#x200B; 3. With a single pointer &amp;#x200B; \`\`\` char\* ss2; ss2 = calloc(1, sizeof(char) \* 3 \* 4 \* 255); for (int row=0; row&lt;3; ++row) { for (int col=0; col&lt;4; ++col) { snprintf((ss2 + row\*4\*255) + col\*255, 255, "-%d-%d-", row, col); printf("%s ", (ss2 + row\*4\*255) + col\*255); } printf("\\n"); } \`\`\` &amp;#x200B; It's easier to think the whole memory space as only 1D array. We allocate the whole enough memory space for all slots as you can see here for 3x4 array with each slot of 255 bytes, we will have \`3 \* 4 \* 255\` (as well multiply by size of char). The only matter here is to do math to give us correct location for certain slot. We locate row first by using \`row\*4\*255\` as we know each row has 4 columns and each column has 255 bytes in size i.e. if we are at 2nd row (row 1) we should have progressed through 4 slots already which is 4\*255 bytes. Similar goes for column. &amp;#x200B; Finally, free it as follows &amp;#x200B; \`\`\`c free(ss2); ss2 = NULL; \`\`\` &amp;#x200B; 4. With double pointer &amp;#x200B; The concept here is we allocate per row-basis first, then in each row we allocate actual string for all columns. So each row will contain 4 of \`char\*\`. Calculating location to access particular slot is similar to 3. &amp;#x200B; I included calling to \`printf()\` for this case as it will make it easier to understand. &amp;#x200B; \`\`\` char\*\* ss3; ss3 = calloc(1, sizeof(char\*) \* 3); for (int row=0; row&lt;3; ++row) { \*(ss3 + row) = calloc(1, sizeof(char) \* 4 \* 255); &amp;#x200B; // set strings snprintf((\*(ss3 + row) + 0), 255, "-%d-%d-", row, 0); snprintf((\*(ss3 + row) + 1\*255), 255, "-%d-%d-", row, 1); snprintf((\*(ss3 + row) + 2\*255), 255, "-%d-%d-", row, 2); snprintf((\*(ss3 + row) + 3\*255), 255, "-%d-%d-", row, 3); &amp;#x200B; printf("%s %s %s %s\\n", \*(ss3 + row), \*(ss3 + row) + 1\*255, \*(ss3 + row) + 2\*255, \*(ss3 + row) + 3\*255); } &amp;#x200B; ... &amp;#x200B; // free strings for (int row=0; row&lt;3; ++row) { free(ss3\[row\]); ss3\[row\] = NULL; } free(ss3); ss3 = NULL; &amp;#x200B; \`\`\`
You might find more interest in this over in r/ProgrammingLanguages.
What about...? union { struct node* ptr; uintptr_t val; };
I am new to C and do the same thing as well. It seems to help chunk up the program into more digestible chunks. I too am curious what the more seasoned programmers think.. Great question!
Yes for very short snippets it is a bad habit I'd say. General rule of thumb (i.e. people can argue endlessly over) is unless you're using a short (arguable definition) bit of code more than twice you don't have to put it in a function. Also functions don't have to return a value, if you're just printing from a function then declare it void. I'd focus on language fundamentals like that before particularly worrying about coding style.
OK :) Thanks for your advice. 
You should think of functions as free! Use them as much as you feel like using them.
OK thanks! I think I worried too much.
Yeah, you did. Just program as you like in this regard. As you get better, you are going to develop a feeling for good programming style.
Other than the obvious benefit of code reuse, functions also help declutter the code, keep the focus on the primary (in scope) logic, and isolate logic. For very small programs, a `print_test_result` function is likely overkill (unless you think it might grow). 
Ok really helped me! And that was just simple fast examples. There's more in those functions. Thanks again!
Your code is not going to cut it for the project, as you did not create a function that performs the desired behavior. (Instead, you coded the behavior to run *once* in your main function). The point of "by reference" is that you are creating a function that outputs 3 things, but a function can only return 1 thing.... So... how do you do this? Well, you pass by reference, which means that you define memory locations *outside* of your function, and then you set those values from *inside* your function. To accomplish this, your function signature should require 4 arguments, namely 1. the input parameter, 2,3,4 :pointers to the location to write the number of 50s, 20s, &amp; 10s. As an aside, this is the basically the way that `scanf` works -- ie. scanf can read multiple tokens, so rather than *returning* a scanned token, it takes pointers to where it should write the token. That's about as much as I can give you without giving away the answer. The bottom line: you need to put the conversion logic in a function *outside* your main function, then call that function from main, and print the values from main.
 fscanf(input, "%s", lastAndFirst This reads a string into the buffer that `lastAndFirst` points at. `lastAndFirst` is uninitialised.
Hmm, I have in my notes that fscanf has the prototype `int fscanf(FILE* stream, const char *format, ...)`. Is that incorrect? I thought the stream went first.
That's not incorrect. But that's not what's wrong. lastAndFirst is uninitialised ... where is the string going to go?
Even if I initialize it, it still segfaults. [Here's the code now](https://pastebin.com/ArLipMhU) Thanks for the help by the way, I appreciate it! 
"hello" is string literal and must not be written to. And even if it could, it is too short to hold Mary Jane
Ahh rats, I forgot that array names are constant pointers. If I make the declaration into `char lastAndFirst[500]` though, it still segfaults. What's wrong with that?
&gt; However,I do not understand what the exec command does. [execv(3)](https://linux.die.net/man/3/execv)
You will find a middle ground. If it aids in readability without making the codebase too confusing to work through, go for it. If you're doing it for repeatability, until you get a feel for it, there's a half-decent guideline you can use as a rule of thumb: turn a set of logic into a helper function the third time you need to use/reuse. The reasoning behind this is that the first time you write something, it's novel -- ie. you don't gain anything (other than maybe readability) by standardizing the function. The second time you need to use that code -- copy/paste it, and keep developing. The workflow efficiency of just moving on (compared taking some time to do a minor refactor) is worth holding off a bit. On top of that, the copy/paste allows you to modify the logic as needed (rather than forcing a one-size-fits-all solution). The third time you need to use that code -- it's now worthwhile to standardize. If you're using it 3 times, you're probably using it more than 3 times, so the extra overhead right now is worth it. On top of that, you've now seen three separate contexts for this particular logic usage, and therefore you now have a better sense about how flexible your function(s) need(s) to be designed to be. If you had naively writen the function the first time, all of the logic updates (and function signature updates!) would detract from the efficiency you gained by standardizing. In a nutshell: yes, you are obsessed with functions, but that's a feature, not a bug.
Wow thanks for your reply. I learned a lot from these words. Thanks!
lastAndFirst must be an array. Not pointer. Memory is not allocated, fscanf writes to some random memory.
I will try to solve it for you
Not exactly correct. If it's initiated with NULL it still will be default. Pointer must point to some memory, writable memory. So, initialising with some string will also not work. Either array or allocate with *alloc().
Does candle engine support dynamic shadows?
This sub is about C, not C#
Well, there's no point in hiding a single printf call in another abstraction level; on the other hand, `int main(){` `do_something();` `printf("Test Complete! Good to go!\n");` `return 0;` `}` looks like a violation of the SLA principle to me. I'd make those procedures inline. Also, you don't need to return an int from every procedure.
OP appears to be a youtube clickfarmer
Yes, it's in the video, thou right now they're updating every frame, which is bad. I used to only iodate them when an object moved, but after some refactoring that doesn't work anymore.
&gt;If I don't create a new node in push then how will the list grow? I can only store one element right?
You're right, I read your code wrong. Now you are creating two new elements, one in main() and one in push(). If you decide to use push(a, 52) with "a" being the structure created in main(), you should use that parameter within push() and not create a new struct. Hope that makes a bit of sense.
The programming language doesn't really matter. You'll have to either find a description of the file format or reverse engineer it.
fscanf(input, " %[^\n]", firstandlast);
More to the point, curly braces but no statement separator. Although I guess you could do if (1) { do_this } if (1) { then_this } if (1) { then_that } to chain multiple statements on one line...
The other problem is that you can't implement insertion or deletion without walking the entire list. So it's not really the same data structure; it doesn't support the same operations, or at least not with the same complexity.
That doesn't make it any more portable... you should just use `uintptr_t`, which will work on every platform you're likely to care about.
I probably could have clarified this better. I have googled the command. I found the man page, and I see what it does. I don‚Äôt understand how it‚Äôs used (like I can‚Äôt find a sample usage of it). 
Now with that point out of the way, what does SVT mean? Shadow Volume Tracing? I've never heard of SVT, but I might be stuck in the 90s regarding CGI. 
how I tend to do this is to write a chunk of code, and then think might I need to do this more than once? can I make this more generic? what parameters would make it more generic (general purpose) ? If I can see a way I can drive this chunk of code with parameters it's a function.... if I see a group of more than 3-4 functions they quickly end up going into a separate unit of compilation (new source file and header) this means my main code gets smaller and less complex looking and frequently functions I don't need to change often end up not even getting loaded into my text editor.... less code to look through, cleaner looking main.....
Sparse Virtual Texturing. I talk about it in the r/gamedev post.
&gt; taking the xor of two `uintptr_t` representations of the same pointer, and xoring that with the representation of another pointer, would yield a value that cannot be converted to a pointer That's also permitted by the standard. I believe [CHERI](https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/) would give you a hard time with this. 
Wicked stuff, thanks! 
A memory-restricted environment is likely to have small integers and small pointers. For instance, a DOS .COM executable would normally only use 16-bit pointers (as opposed to .EXE, which would use a mix of 16-bit and 32-bit pointers).
&gt; They rag on your shit I don't see anybody ‚Äúragging on OP's shit‚Äù. I see people pointing out that a) it's not novel and b) it has flaws ranging from ‚Äúdisallowed by the standard‚Äù to ‚Äúnot fully equivalent to a doubly-linked list‚Äù.
&gt; `struct stack *s = (struct stack*) malloc(sizeof(struct stack));` That's bad practice. First, the cast is unnecessary and can hide bugs. Second, you repeat the same information (the type of `s`) three times, which makes it harder to change. The recommended idiom is: type_of_s *s = malloc(sizeof(*s)); or, if you're allocating an array: type_of_s = malloc(number * sizeof(*s)); 
In addition to the `=` vs `==` problem that others pointed out, your program will not be able to read its input correctly, because first, `scanf("%char", &amp;t)` means ‚Äúinput any character followed by *exactly* `har`‚Äù; and second, you don't allow for whitespace between the input elements. The only input your program will accept is &lt;num1&gt;&lt;c&gt;har&lt;num1&gt; where `&lt;num1&gt;` and `&lt;num2&gt;` are arbitrary numbers and `&lt;c&gt;` is an arbitrary character (including a single whitespace character). What you should do instead is: scanf(" %f ", &amp;x); scanf(" %c ", &amp;t); scanf(" %f ", &amp;y); or, as someone else suggested: scanf("%f %c %f", &amp;a, &amp;t, &amp;b); although this does not consume leading or trailing whitespace, so you may want to use this instead: scanf(" %f %c %f ", &amp;a, &amp;t, &amp;b); 
Because it is? I mean, it *intentionally* uses a C-like syntax, its semantics are *intentionally* similar to C's semantics, albeit greatly simplified, and its name was *intentionally* chosen to indicate that it is a reduced form of C. But more importantly, it was never intended to be written by humans.
If your program has a lot of dependencies that won't build on older Linux distributions, what is the point of trying to build it with a version of glibc that is only used by those distributions?
Well, what graphics toolkit are you using?
He‚Äôs just plain wrong, unless you‚Äôre using some outdated compiler that just sucks. Perhaps he wrote the original software and had problems getting things to work right because he didn‚Äôt know what he was doing. I‚Äôve worked on safety critical systems, and we used optimizations and functions everywhere. If you hadn‚Äôt realized it before this, you‚Äôre learning something important: global variables can make your program a mess. I wish you the best on your project.
Without seeing any code or knowing much, this feels very weird and messy. Global variables do get used, but to use them to circumvent any calling convention (ARM normally tries to use some registers) is bizarre, and setting up a codebase where you mutate state as frequently as you say seems concerning. &amp;#x200B; As for optimizations breaking the program, given a good compiler (and assuming Xilinx it probably is a good one, I think they use gcc??), it's not the compiler breaking the program but rather the compiler exploiting probably some undefined behavior that was not exposed at another optimization level (ie, the code is buggy, the compiler doesn't *break* things normally). &amp;#x200B; Given the way TAs are selected normally, he probably knows the pains of the project, but he may not understand the guts of the code. I'd expect he cargo coded the project the way he's advised you to based on what his TA said.
Okay, I see my mistake. But if pass a as a reference to push and change the declaration of push to void push (struct node\*\*, int data) then the program works but I am not sure why? Can you please explain :)
I'd recommend you look at a few C gtk tutorials, gtk has a nice C api, and there is also a gui designer gui.... if you're used to python you can also spin up quick prototypes using pygtk, get it all working then "port" it to C - can help rule out and specific gtk issues....
Yes, the optimiser does reorder code. However, the optimisier may only do so in ways that are invisible, i.e. do not affect the meaning of the program. If the optimiser changes the meaning of your program, then your program likely exhibits undefined behaviour and was wrong in the first place.
Optimisers can break your code - if your code does not adhere to the C Standard. If you write correct code that adheres to Standard C, then you are absolutely fine. 
He's wrong. Or is used to bad code being broken by the a (possibly) broken compiler. For embedded stuff with memory-mapped peripherals, if the variable isn't marked as volatile, the compiler can optimize away checks to direct memory by stashing the value in a register. "reordering code" is kind of a gross misrepresentation too. That makes it sound like the optimizer does stuff like changing a = 3; b = 4; b += a; b *= 2 into a = 3; b = 4; b *= 2; b += a; There are things like loop unrolling where rather than using a variable in a for loop, it'll just embed the code. Also, while yes, there is a "price" to calling functions, really small functions will likely automatically be in-lined or you can explicitly inline them. So if the TA is speaking from personal experience, he wrote bad code and never learned how to fix it. Yeah, (mis)using functions and then not using optimization will probably result in code with poor performance. That is not to say that you can't use functions properly and get good or better performance.
As some are saying, turning on the optimizer can introduce some headaches if you didn‚Äôt properly structure your code, eg, using the volatile keyword in the correct spots. Since I doubt that your team has a grasp on the pros and cons of the structure choices, you might just want to heed his advice to avoid potential potential pit falls and get an ‚Äú I told you so‚Äù from him.
Even MISRA C:2012 states that optimization is fine, as long as you use common sense.
I haven't really used an optimizer, though we did use really old compilers. There was a project that I did attempt turning it on, but I didn't look too much into exactly what broke because we didn't have the performance need. I want to say it had to do with accessing special purpose registers. But on most processors, adding parameters to a function call vs global means adding like 2-4 instructions per parameter to pack and unpack the data. As long as you follow the general rules of don't add ridiculous amounts of parameters or copy large structures, you should be fine. The only processor I've have issues with functions was a microprocessor that had a 7 bit of address space per stack frame. So if your parameters + local variables exceeded 127 bytes, it had to bank switch the stack frame. 
So in short. Live your dream. If you can get it to work with clean code, do it. 
Wait, you don't have tests that you can run with all optimisations on/off, and see for yourself where the branch bugs/cache-assumpetions are happening? The fact is, its true: if you don't know what the optimiser is going to do to your code, why are you using it? Wanna know more? Write tests. Tests will give you the only real answer. Don't have tests? You're both a couple of glib dilettantes then. Safety-critical shit 101, yo. 
"Huge performance problems" may be an exaggeration, but when working with the embedded world those kind of dirty tricks are used to try to squeeze every ounce of performance out of a resource constrained processor with critical realtime deadlines. It takes RAM and CPU cycles to create the stackframe for the function, and if you are frequently calling a lot of small functions that are doing trivial things (like providing access to the latest sample sensor data you use a lot) that can add up. This is especially true in interrupt context where you've essentially put the entire rest of the system on pause so you can finish your time critical thing. That said, the Arm Cortex A9 seems like a massively beefy processor to be worrying about such things. You're sacrificing readability and good coding practices in exchange for CPU cycles on a processor that's probably running near a GHz? This isn't some tiny PIC with a few k of RAM running at a few MHz, it's a proper modern processor with gobs of resources. I can't speak to the kind of chrono constraints you have when you're controlling a drone but to optimize at that level seems aggressive. As far as the optimizer goes, they're generally safe to use. It will reorder your code in ways a human would never think of, but it should not change the behavior of the program in doing so. There are sometimes bugs in optimizers but they're very few and far between, it's far more common for the code itself to have an issue that only manifests when running at higher optimization levels. 
This is just a picture if your programming assignment. You said you need help? What have you done so far and what are you stuck on?
&gt; Enter the look-how-smart-I-am old dogs Old?
Sounds exactly like the class I'm in now except we're making a toy car instead. My instructor swears up and down that we should follow his programming advice which includes wonderful exerpts such as "I don't subscribe to the idea of declaring globals using the static keyword in functions" or to "not use GCC since it's free. Have your company buy a real compiler". It's a real shame since many students have never written a larger scale C project before. They're coming in and learning this mess and thinking it's acceptable. Very upsetting.
This is using Vivado? &amp;#x200B; Thetre's a good chance he's right. If this is trying to compile C into VHDL into an FPGA, there are lots of things that simply can't be done that translate well into FPGA code.
My guess is that the existing code OP was given to work with is full of undefined behavior that "works" when no optimizer is used but breaks when turning on optimization. This is not a problem with using optimization. It's a problem with the given code, which is poorly written and highly buggy. Since OP is forced to work with that code, he may be forced to forgo use of optimization for this particular project, unless he's somehow willing to rewrite it all. How much the TA knows/doesn't know about this, not sure I can tell from what OP wrote. The TA either is naive and doesn't know what he's talking about, or he does know and is just bad at explaining it.
C does not have exceptions.
&gt; "I don't subscribe to the idea of declaring globals using the static keyword in functions" or to "not use GCC since it's free. Have your company buy a real compiler". Holy shit. Wow that's awful.
I used to do work in scientific computing. I will tell you this is very tricky issue. It can be true and false. The ordering of events do matter, unless you have say something like an ODE and you can control the error. Ideally you want order to not matter at all but sometimes this is not possible, say like in a real time system. So in this case, the best you can do is try to make sure reordering, although breaks reproducibility is within tolerance. That's just my opinion. Given that, you cant blindly blame the compiler or even say machine error. This is a very dangerous practice. I had a program that had the ordering issue that I knew was a potential problem however it also had a memory leak which pops up very infrequently, which of course is affected by optimization as well. It was small enough to be buried but I can't guranteed it say between compilers. The reason I found the leak was because the next generation of compiler gave me a crashed program even without optimization which told me I had a serious problem. As a rule, the argument about using global only is bad policy. It is more important to have a correct rather than optimized program. Modern compiler will take care of any optimization automatically. You can design your code to try to take advantage of parallelization but that can be done avoiding globals, just takes some planning.
that's the problem i've never used any graphics stuff and i don't know any graphics library or somthing like that!
Just googled *"c execv example"* and one of the first hits is a github page with a complete example and even compiling steps... [https://gist.github.com/apoorvingle/5e9a0280f1e6f6af46076c60a78bdbd2](https://gist.github.com/apoorvingle/5e9a0280f1e6f6af46076c60a78bdbd2) Don't forget to change the defines!
thanks mate
+1 for GTK. You can find the hello world tutorial here: https://developer.gnome.org/gtk3/stable/gtk-getting-started.html And a couple examples with different widgets here: https://developer.gnome.org/gnome-devel-demos/stable/c.html.en 
1. No effort. 2. We're not doing to do your homework for you. 3. cpp is not C
Is this a joke? You've posted a screenshot with no code and no further information. How can we possibly help you with the scarce information you've provided?
Need help with writing titles, too. :)
void main() { for (int i = 1; i &lt; 11; i++) { for (int j = 1; j &lt; 11; j++) { printf("%-2d ", i\*j); } printf("\\n"); } }
Open the file in a text editor. Look at it. See if it's human-readable. If it is, try to figure out what language it is. If it's not, you're SOL.
Am I missing something? The output looks identical. Also, what have you tried so far?
This sounds like your TA is from the 70s. Function calls can be inlined, if the compilers not junk optimization should be guaranteed to not break your program. Could be changes for floating point stuff if you specifically enable some of those but if you know what youre doing shouldnt be a problem. If theres already undefined behavior that could be a problem, which sounds likely given how shitty the code you describe is.
Probably just coincidence, but what university do you go to? I had a extremely similar question like that last year
Recursion learn it use it love it!
The only difference is in the last column where you can see there are 2 spaces instead of 1 and then there‚Äôs a difference with the 90 above the 100. I thought about making a if and then it could fix it but it won‚Äôt be so efficient 
A good compiler will break your program when you enable optimisations if and only if your code contains bugs. I would suggest that you follow your TA's advice for the sake of completing the project but as soon as you finish it forget everything that you were told by the TA.
Not sure how I didn‚Äôt find this. Thank you so much. 
I solve it by using functions but icant without it
You have a 3-digit value in the last row. If you want the other rows to match up with it, you'll need to use a 3-digit-wide format specifier like "%3d".
The optimizer will probably reorder or even delete your code. Whether this is a problem or not depends on what you're doing, how you're doing it and how the compiler optimizes. The compiler is going to make _a lot_ of assumptions about your code, assumptions that it's allowed to make because of the C standard. If you and the compiler aren't on the same page, problems are likely to happen. For example, optimizers are prone to insane reasoning such as "signed integer overflow is undefined so it can't possibly ever happen, might as well delete the useless checks the programmer wrote". There are posts all over the Linux kernel mailing list discussing adverse effects of optimization. [Here's an example:][gcc-insane] &gt; I know for a _fact_ that gcc would re-order write accesses &gt; that were clearly to (statically) the same address. &gt; Gcc would suddenly think that &gt; unsigned long a; &gt; a = 5; &gt; *(unsigned short *)&amp;a = 4; &gt; could be re-ordered to set it to 4 first (because clearly they don't alias &gt; - by reading the standard), and then because now the assignment of 'a=5' &gt; was later, the assignment of 4 could be elided entirely! [gcc-insane]: https://lkml.org/lkml/2009/1/12/369
One of the reasons C was successful in the 1980s is that many constructs were defined as having meaningful behavior on some kinds of machines, whether or not they would have meaningful behavior on all kinds of machines. According to the published Rationale, the authors of the Standard recognized that C may be legitimately be used for "non-portable programs", and they did not wish to impede programmers "from doing what needs to be done". The authors of the Standard deliberately refrained from requiring that all implementations be suitable for low-level programming (or any other particular purpose, for that matter), but implementations that *are* suitable for low-level programming will process various actions in ways that are characteristic of the environment without regard for whether the Standard requires them to do so. Perhaps there are practical execution environments where (int*)((uintptr_t)p1 ^ (uintptr_t)p2 ^ (uintptr_t)p2)` could yield a bit pattern which differs from that of `p1` in a way that would yield a trap representation. If such environments exist, then xor-based linked lists would be problematic on them. The likelihood of running into such environments, however, seems lower than the likelihood of encountering implementations that aggressively assume that programs won't use low-level semantics beyond those the Standard would require, even when targeting environments where such semantics would be useful. The possibility that xoring the integer representations of pointers might yield a trap representation is far less of a problem than the fact that even in cases where one can guarantee that the integer that's cast to the pointer is numerically equal to one produced by a pointer-to-integer cast, that still wouldn't guarantee that one could index or dereference it as one could the original. Incidentally, if the latter problem were solved, one could work around the former by converting every node's address to a `uintptr_t` as soon as it is created, and identifying nodes solely using `uintptr_t` values, so every node's address would get converted to a `uintptr_t` exactly once. Given: int *p=..., *q=...; uintptr_t upp = (uintptr_t) p; uintptr_t upq = (uintptr_t) q, upq1 = upq, upq2 = upq; int *q1 = (int*)upq, *q2 = (int*)((upp ^ upq1) ^ upq2) the Standard would guarantee that `q2` would be a valid pointer that would compare equal to `q` and `q1`, but would not guarantee that `q1` nor `q2` could be indexed or dereferenced even if `q` could be. 
I tried that but still it doesn‚Äôt work
I'm trying to add a screenshot but dont know how Im new here
Egyptian university
coincidence then do you know how to use recursion?
I'm assuming you use functions for the power and factorial operations. Do this in two steps. 1. write your own functions, and use them instead of whatever math library you're using. In these formulas, all the arguments are integers, so this should be relatively easy. 2. Essentially copy the code from the functions (this is essentially [Function Inlining](https://en.wikipedia.org/wiki/Inline_expansion)). You will have to make the returns assignments from the return expression to the variable you stored the functions return into. Example, below is a simple program where I've written my own modulus operator (its not important what it is). #include &lt;stdio.h&gt; #include &lt;assert.h&gt; int mod( int x, int k ){ while( x &gt;= k ){ x -= k; } return x; } int main(){ for( int k = 2; k &lt;= 10; k++ ){ for( int x = 0; x &lt;= 20; x++ ){ int check = mod(x,k); int actual = (x%k) assert( check == actual ); } } printf("done!\n"); } To remove the function, I can copy the code from the function and simulate a function call. BEWARE! YOU MIGHT NEED TO MAKE VARIABLE NAME CHANGES! What I've done is made a variable for each of mods function arguments, prefixed with \`mod\_\` and changed all the variable names in the function body. Then I removed the return statement, and used the expression (with the variable name changes) in the original return statement in the assignment. #include &lt;stdio.h&gt; #include &lt;assert.h&gt; int main(){ for( int k = 2; k &lt;= 10; k++ ){ for( int x = 0; x &lt;= 20; x++ ){ // simulate mod int mod_x = x; int mod_k = k; { while( mod_x &gt;= mod_k ){ mod_x -= mod_k; } // no return! } // use expression from return statement (x, or mod_x here) in assignment to check! int check = mod_x; int actual = (x%k); assert( check == actual ); } } printf("done!"); } Does that help? &amp;#x200B;
Well... avoiding having statics scattered all around your code (instead of all being defined in a block at the top of the module) *can* be useful. If you are trying to keep track of how much statically allocated memory your program needs, for example. That‚Äôs a coding style thing. gcc is definitely a ‚Äúreal compiler‚Äù, whatever *that* means.
All you need is + - * and / to solve this. Most of that already stands there in plain sight. solving the factorial is really not a big issue at all. 
The volatile registers is one of my first thoughts as well, and the other comments on undefined behavior make sense as well.
What have you tried so far? 
A (not broken) optimizer is not supposed to reorder execution of code in a way that affects the outcome of the program. If your code relies on some kind of implementation-defined or undefined behavior that changes when optimization is enabled, that might cause your program to ‚Äúbreak‚Äù. But really you should generally not depend on things like that, because they also might change because something about the platform changed, or the compiler got updated. Also worth noting that C/C++ compilers *assume your code is executing single threaded* and that you have taken any precautions needed for dealing with external actions where needed (disabling interrupts, memory barriers/fences, mutexes, tagging things `volatile`, etc.). If your code has not actually taken the correct precautions, it is possible that turning on optimization will ‚Äúbreak‚Äù things. But then the problem is that your program is buggy and just luckily happens to work with optimization off due to timing being different or interrupts not working quite the same way, or optimization being off mimicing what the `volatile` keyword does. So it‚Äôs possible that the framework you‚Äôre using falls into one of those categories. If this is the case you could potentially enable optimization only for the modules that contain your code and leave it off for the framework ones being given to you. In terms of performance... function calls (unless *completely* inlined by the compiler) aren‚Äôt free. At the very least you have to do some copying of parameters and results to and from registers. If the variables won‚Äôt fit in registers or you are passing/returning structs then things have to be pushed/popped from the stack. In embedded systems with limited processing power (or when trying to write really really efficient code in general) this can be significant. You also might not have much space on your stack, so you have to be careful about not allocating too many stack variables or calling recursive functions. But ‚Äúdon‚Äôt use functions at all and make literally everything global‚Äù feels like premature optimization to me.
There are several places where optimization can give you grief: *If* the compiler is broken, it's entirely possible that the optimizer will break things that would have been ok otherwise. When I worked on Solaris 7 at Sun Microsystems, the kernel was built with a broken compiler that sometimes didn't reserve enough space on the stack for the local variables. Believe me, a bug like that is a right bastard to track down. Once we realized this could happen, any time we encountered a mysterious kernel bug, the first thing we tried was turning off optimization for the module that was failing. Second, in an environment where memory locations are being shared between threads or processes, or device registers are being accessed, and you haven't declared things volatile that should be, then optimized code can fail where non-optimized code might not. In general, the optimizer can expose bugs in your code that you might have gotten away with in non-optimized code. The optimizer *does* re-arrange code. That's one of the things that exposes bugs in your code. Knowing when to use volatile, or memory barriers can be a dark art, and the optimizer makes it more important that you get it right. Finally, because the optimizer re-arranges things, it can be harder to understand what's going on when you run it under the debugger. This can be especially true if it inlines code you didn't tell it to inline. That can make stack traces really confusing until you realize it's happening. But in general, unless the compiler is actually broken, which is extremely rare, the only time you don't want to use optimization is if your code is broken. So when you test your software, make sure you build it with the same compiler and same compiler settings that you'll use for production.
Fair.
&gt; a) it's not novel Ragging. &gt; b) it has flaws Everything comes with a compromise. Literally everyone in this discussion has acknowledged that. But that was never the point, which is lost on you.
This would usually be the correct answer (in an fpga sub) but this is explicitly dealing with the zynq-7000 which has a hard core arm a9 processor that can be programmed alongside the fpga portion of the soc.
Which struck me as well -- (I've actually been coding against the 7000 for the past 18 months or so). My issue is the "Vivado as a complier". For the SoC arm core portion, you can use any standard gcc/clang compiler. &amp;#x200B; This makes me wonder if the class is working up towards porting the code to the FPGA, but starting with a less-performant version on the SoC.
Are you a student a KU Leuven? It sounds a lot like the eagle project
Fair enough, that did strike me as weird too. I just assumed that op neglected to list his entire toolchain. Now that you point that idea out explicitly that could actually be a pretty cool set of labs! And would also explain why the TA is telling them to use a sort of subset of c. 
He might be right about the optimizations because of hidden hardware dependent race conditions. It's probably a combination of bad code and bad hardware.
The first column should be left-justified. OP‚Äôs is right-justified.
What's really bad is that GCC and Clang are likely a million times better than any proprietary compiler. I didn't even know there were still paid for compilers considering GCC and Clang are so widespread.
I think this is probably a case of turning a kernel of truth into a whole mythology. The truth here is optimization can change program timing - in fact if it doesn't, then it is not a very good optimizer. And in real-time systems like flight control, having the right timing is critical. In a well structured program, running faster should not cause problems, but it sounds like this particular program is not that. If it is relying on X happening before Y without strictly controlling for it, then making the code path leading to Y much faster can break things. The ideal solution to a real-time control problem is a rigorous analysis of the timing constraints, followed by creating a processor time budget for the various tasks and interrupts. If your goal is simply to get things moving, I would take the TA's advice. Introduce changes slowly while you convince yourself the system is stable. As a real life example of the underlying truth here, I had a working motor control program break because I added 3 'reserved for future expansion' variables. I didn't ever access them, but the program started acting strangely. It turns out that the declaration caused the memory map to change, shifting the word alignment of certain critical structures. This caused the compiler to issue a slightly slower sequence of fetch instructions, which exposed a timing dependency we had missed. 
That's the only thing I would think too, try different values in the %d. When I had to print stuff to be aligned that's what I did and it worked !
[Here](https://hackspire.org/index.php/TNS_File_Format) you can find a little more info on the file format. You can convert it into a standard zip file as it seems, which would help you with understanding and editing it.
Thanks for expressing what's in my mind with about 50 less insults. I guess PTSD was about to get hold of me.
Unless it's some speciality thing, and even then. Yes, Intel's compiler produces better binaries for intel processors, and TI's compiler for MSP430 produces better, more efficient binaries for MSP430 chips, but GCC (and all its features and all its extensions) works well on both. You can't simply discount GCC out of hand.
I've experienced this first hand. I wrote some code for an MSP430. It mostly worked. I turned on optimizations. It broke. "Well that's not right." Spent 2 days troubleshooting before I realized I was specifying the wrong microcontroller model to the linker.
Sedgewick wrote a C version. It's older, but worth tracking down. It strikes a good balance between the mathematical concepts and code examples. My only nitpick was some butt ugly coding style (by today's standards), but the prose compensates for that. 
https://www.amazon.com/Algorithms-Parts-1-4-Fundamentals-Structures/dp/0201314525 It's worth the labor. Sedgewick knows his stuff. 
How are you compiling the program? LIke, what is your command or commands? I can compile what you've got here, albeit with some warnings about some of your type casts.
More likely, the code relies upon some of the myriad "popular extensions" which are alluded to in the published Rationale for the Standard, many of which used to be universally and usefully supported on general-purpose implementations for common platforms until compiler writers started viewing cases where the Standard didn't require that implementations behave usefully, but they did anyway, as "missed optimizations". 
I am compiling the project on code blocks (created the project as a console application). I‚Äôm assuming that must be the problem?
CodeBlocks might be throwing errors on warnings? 
It must have something to do with how the project is being compiled on code blocks. How are you compiling the program where it just throws warnings but still compiles?
How are you compiling the program so just warnings are thrown? (It might just be something with code blocks).
C++ is off-topic for this board.
thank u so much
gcc -Wall testfile.c -o testfile where "testfile.c" is your code as presented above.
The authors of the Standard did not want to mandate that every implementation support all of the semantics that would be needed to accomplish every single task. Instead, they expected that implementations intended for various tasks would support the semantics required to accomplish those tasks without regard for whether or not the Standard required them to do so. When the Standard lists one of the effects of Undefined Behavior as "behaving during translation or program execution in a documented manner characteristic of the environment" that wasn't just some hypothetical thing they thought some implementations might do by happenstance. Rather, they recognized it as a form of "popular extension" which some implementations should support and others shouldn't, and they recognized that the question of whether an implementation intended for some particular kinds of tasks on some particular execution environment should support such an "extension" should be left to people familiar with those tasks and the environment in question. &amp;#x200B; Unfortunately, there has never been any kind of "official" standard for the language one would get if one took the Standard and augmented it with "In cases where some parts of the Standard and the documentation of an implementation and execution environment would describe the behavior of some construct, but another part says it invokes Undefined Behavior, treat it as described by the former parts without regard for whether that is actually required". Such a behavioral description would actually be less ambiguous than the actual Standard in many cases, and matches the behavior of most past and present compilers when optimizations are disabled. Further, the dialects described thereby are vastly more powerful than the one described by the Standard, and allows programmers to efficiently perform many tasks that would be impractical or impossible using only the language defined by the Standard. &amp;#x200B; If people seeking to produce a quality non-commodity \*anything\* which is covered by a standard can be expected to serve customer needs when practical in cases where the standard would allow them to do so, without regard for whether the standard requires them to do so, and if it would be obvious that customers of certain objects would need certain features, then there should be no need for the standard to mandate such features, since the producers would support them anyway. Customers who demand unusual features from what would otherwise be commodity items will need to coordinate with a supplier to produce them on a non-commodity basis, but given the wide range of application purposes and target platforms, the C Standard was never intended to describe a commodity item. &amp;#x200B;
Any idea why not ‚ÄìO3?
Would that problem go away by declaring \`a\` as \`volatile\`?
&gt;This sounds like your TA is from the 70s. Born in the 90s, still livin' in the 70s.
They may be better for that tiny fraction of usage cases where either: 1. A program will never be called upon to process data from malicious sources 2. Nothing that a program would be in a position to do, even if it were malicious, could cause an unacceptable level of damage to anything. For the much more common scenario where a program is subject to the requirements: 1. When given valid data, produce valid results. 2. When given invalid data, don't worry about producing any specific results, but refrain from doing anything particularly damaging. compilers that offer behavioral guarantees beyond those mandated by the Standard, fed programs that exploit those guarantees, may be able to produce more efficient code than would be possible for any implementation given programs that don't exploit those guarantees. 
I've used platforms where the cost of calling a function that takes no arguments, or takes a single character-type argument, is significantly less than the cost of calling a function that takes anything beyond that. I've also used platforms where functions that don't need a stack frame are much faster than functions that do, and where accessing static objects is much faster than accessing automatic ones. ARM-family processors, however, are not such platforms. On the ARM, static-duration objects are slower to access than automatic-duration objects, and the first four word-sized arguments passed to a function are very cheap. Recognizing that certain constructs are outrageously expensive on certain processors is useful, but the workarounds necessary to achieve good performance on those processors should only be employed with code that will be called upon to run on them. 
I think even Intel‚Äôs using Clang now‚ÄîAFAICT they‚Äôve merged at least some of the stuff only IntelC used to do into LLVM, like optimizing inside `__asm__` statements.
Not strictly if-and-only-if‚Äîcompiler bugs do exist, although 99% of the time unless you‚Äôre beating the hell out of corner cases it‚Äôs the programmer‚Äôs fault.
Maybe in practice, but `volatile` doesn‚Äôt get you around alias analysis. The compiler may still get rid of `volatile` accesses it can tell ‚Äúcan‚Äôt‚Äù happen, or which aren‚Äôt ‚Äúnecessary,‚Äù as well. E.g., marking a variable that‚Äôs not visible outside its scope as `volatile` might not make a difference unless the variable‚Äôs address escapes somehow. For something like the above, `memcpy` is your best bet, or `union` if you‚Äôre guaranteed the compiler supports ‚â•C99, which is IIRC when they tightened down the `union` rules so you could switch between otherwise-incompatible representations.
MSVC will assume (by default for x86, and by configuration when processing an ARM) that writing a `volatile` object may trigger actions in the outside world which might observe any data written earlier in the current thread, and that reading a `volatile` object implies an interest in outside-world actions that may have affected objects that the current thread will be interested in. Thus, if one writes: volatile extern char *datptr; volatile extern uint32_t datsize; int buff[256]; buff[0] = 1; buff[0]++; datptr = buff; datsize = 1; while(datsize) ; buff[0]=3; datsize = 1; while(datsize) ; MSVC will guarantee that any action on `buff` which precedes the volatile write to `datptr` will not get reordered past that write, actions which occur between the first `while` and the next volatile `write` will not get reordered across either, and actions which follow the last `while` will not get reordered across that. Such behavior is appropriate when targeting platforms where `volatile` writes might trigger such effects, and performing tasks that might require such actions. The authors of the Standard said the semantics of `volatile` were Implementation-Defined to allow for compiler writers to judge what semantics would be appropriate given the platforms and intended kinds of tasks they were intended to support. The notion that compilers should be expected to require compiler-specific syntax in addition to `volatile` to achieve the semantics necessary to "do what needs to be done" would seem contrary to the purpose of having a standard `volatile` syntax. 
If you write code that uses only behaviors mandated by the Standard, you will only be able to perform a tiny fraction of the things that can be done in the language invented by Dennis Ritchie. 
The pointer `(unsigned short *)&amp;a` is formed from `a`, and it will never be addressed or accessed after either: 1. the next time the storage is addressed or accessed via other means, nor 2. the next time code enters a function or bona fide loop wherein the storage is accessed or accessed by other means. In other words, it doesn't *alias* `a`. If the code had been: int a; unsigned short *p = (unsigned short*)&amp;a; a=5; *p = 2; then in that situation `p` *would* alias `a`, because the last use of `p` to access storage would occur after that storage had been used via means not involving `p`. Unfortunately, compiler writers like to use N1570 6.5p7 as an excuse to limit how storage can be accessed even in cases that don't involve aliasing. 
Really? Wow, great! I love my opensource tool chains.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
Dependencies get statically linked into my program, so I only need them to build on my machine, then I can simply distribute my binary.
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead. 
Presumably this is for some class? Presumably there‚Äôs some specific subject matter for this class that you could apply to your homework so total strangers don‚Äôt have to do all of it for you, thus negating any potential usefulness for the assignment? Presumably the assignment gives you more details than things like ‚ÄúRead a .txt file‚Äù‚Äîcomparable in specificity to ‚ÄúPerform a calculation,‚Äù ‚ÄúCook some food,‚Äù or ‚ÄúFind that thing I wanted‚Äù‚Äîwhich you might be able to use in figuring out what to do?
The Effective Type rules are just as broken for `memcpy` as for everything else. Compilers don't yet exploit it to full advantage, but a significant plurality of code that uses `memcpy` to get around the limitations of 6.5p7 could be broken by a more sophisticated compiler. The remedy is to recognize that the language defined by the Standard isn't suitable for all the same purposes as the one invented by Dennis Ritchie, and there should thus be multiple recognized dialects: 1. One which defines all operations as loads and stores, without regard for types or aliasing. 2. One in which compilers may assume that no storage which has been used to hold any type will ever be used within its lifetime to hold any other. 3. One in which compilers may assume that objects of different types won't *alias*, but compilers must recognize, at minimum, freshly-formed relationships between objects and pointers that can be seen by independently examining the code for each function in source-code order. A compiler could satisfy this while still performing most useful aliasing-related optimizations, by applying two principles: (a) When a pointer is based on an object, don't defer any previous actions on the object past that point; (b) within a function where a U* has been formed from a T, ensure any pending operations involving a `U*` get resolved before any operation involving a `T`. If code enters a nested function or loop wherein a `T` is accessed, the latter requirement may be satisfied by resolving any pending operations before entering that function or loop. Personally, I would think dialect #3 would be most useful, and the level of compiler complexity necessary to support it would be far less than the level of complexity necessary to e.g. identify all the combinations of character-type accesses that may be replaced by the 32-bit load or store the programmer may have wanted to write in the first place. 
C does not support exception, but you can use another methods such as return specific value, update global or local(reference by address) error variable and so on.
Honestly I‚Äôd settle quite happily for a few different types of compiler/optimizer fence, which could be mashed onto the current language without any other major changes. Something that can force the compiler to spill all non-`register` things cached in registers, something that can affect spilling/killing/filling of specific variables or objects, something that can prevent the compiler looking through conditional branches, something to forcibly mark code as live or dead and variables/values as used or unused, stuff like that. Most of these would be implementable without any alterations to existing compilers (at least for GNU-compatible things; MS may be harder), although there‚Äôd need to be guarantees that those techniques would continue working in the future, or they‚Äôd have to be wrapped up properly so the programmer doesn‚Äôt have to deal with changes. But IMO that‚Äôd be the easiest, quickest approach for fixing most of the weird nitty-gritty sorts of problems; the Standards can keep their strict-aliasing and undefined behavior, and the programmers have some shit to throw at the wall that stands some chance of sticking when they need to get out around the rules.
A problem with the `volatile` keyword is that the authors of the Standard relied upon implementations to recognize the ways in which the effects of `volatile` accesses on the environment might interact with program state. Given something like: char buffer[64]; extern char volatile *volatile storageOwnedByEnvironment; generateBuffer(buffer); // Some function that expects an "ordinary" pointer storageOwnedByEnvironment = buffer; while(storageOwnedByEnvironment) {} useBufferSomehow(buffer); // Some function that expects an "ordinary" pointer there may be some environments that may observe or modify `*storageOwnedByEnvironment` at arbitrary times when that pointer isn't null, but would guarantee that if `storageOwnedByEnvironment` is null, they will treat the storage as owned by the application and will refrain from observing or modifying it unless or until `storageOwnedByEnvironment` is written. If `generateBuffer` and `useBufferSomehow` are called only when `storageOwnedByenvironment` is null, they should be able to treat `buffer` as ordinary storage. They shouldn't need to know or care about the fact that it might be modified by the underlying system at times when they're not being called. Unfortunately, the authors of the Standard failed to note that many tasks may require `volatile` semantics beyond the bare minimums described by the Standard--probably because they thought it obvious. Unfortunately, rather than being interpreted as "compilers need not support volatile acquire/release semantics in cases where their customers don't need them", the Standard has been interpreted as "Programmers have no legitimate reason to need volatile acquire/release semantics". 
Here's an example of a case where code had a bug that only showed up with -O3: https://github.com/samtools/htslib/issues/400 Also, -O3 can make your executable code larger, which you might not want. 
I am also interested in this.
Unfortunately, many people are strongly invested in the notion that there has ever been any particular "sensible" way for code that invokes UB to behave, even in cases where parts of the Standard and the documentation for an implementation and environment would fully describe its behavior in the absence of some other part of the Standard that says it invokes UB. If any programs that rely upon such code behaving a certain way have ever worked usefully, it was only by happenstance. Adding an "optimization-blocking" directive would make it hard to deny that that if a source text would have defined behavior if the directive were included everyplace it was required, there would be one useful meaning it could have in the absence of the directive. It would also be hard to deny that being able to process source texts which predate the directive and process them with the same semantics as though the directive were included whenever required is something that would has for decades improved the usefulness of compilers that have provided it, and impaired the usefulness of those that haven't. 
* *Programming with POSIX Threads* by David R. Butenhof * [*The Little Book of Semaphores*](https://greenteapress.com/wp/semaphores/) by Allen B. Downey (free): It's not explicitly C, but everything in it is easily applied to C. 
I don't happen to have a C standard right here. But says: &gt;Every access (both read and write) made through an lvalue expression of volatile-qualified type is considered an observable side effect for the purpose of optimization and is evaluated strictly according to the rules of the abstract machine (that is, all writes are completed at some time before the next sequence point). This means that within a single thread of execution, a volatile access cannot be optimized out or reordered relative to another visible side effect that is separated by a sequence point from the volatile access. The semantics of `volatile` can go above and beyond that depending on the platform (for instance, a platform might insert instructions to flush cache buffers before reading or after writing a volatile value), but it should always prevent instruction reordering (at least relative to other volatile values!) and eliding of reads/writes.
Well, threads weren't introduced into C until C11. So if you're using an older version of C, you'll probably want [pthreads](http://man7.org/linux/man-pages/man7/pthreads.7.html). 
The TA may have also tried stepping through optimized code with a debugger, which *will* give the appearance of jumping all over the place sometimes.
if anyone else is curious - http://www.keil.com/support/man/docs/armclang_ref/armclang_ref_chr1383738546439.htm https://stackoverflow.com/questions/2053029/how-exactly-does-attribute-constructor-work
&gt; Also any idea how can i show another text while the user's writing something in the fields To do this you will typically setup an event handler for key press events. When the user types in the field, each key press will generate an event that can be used to call a event handler. In that event handler you would have code to change the input character to the character you want. For Gtk+, you can find info about do this [here](https://developer.gnome.org/gdk3/stable/gdk3-Event-Structures.html#GdkEventKey).
thank u !
I've always liked this one: https://computing.llnl.gov/tutorials/pthreads/
You want pthreads regardless. And you probably want C99, too. 
Probably, check this article out first [https://www.cs.auckland.ac.nz/\~paul/C/Mac/](https://www.cs.auckland.ac.nz/~paul/C/Mac/) &amp;#x200B; Also, if you are having issues compiling, you can check out [https://stackoverflow.com/questions/52509602/cant-compile-c-program-on-a-mac-after-upgrade-to-mojave](https://stackoverflow.com/questions/52509602/cant-compile-c-program-on-a-mac-after-upgrade-to-mojave) &amp;#x200B; I searched "compile C code on Mac Mojave" on Google to get these results. Hopefully, that helps you search something on your end. 
&gt; Intel's compiler produces better binaries for intel processors Intel's `ICC` hasn't enoyed an advantage over open-source compilers for a decade or more. Probably one reason is that [Intel's compiler was found to be "over-pessimizing" for AMD targets](https://www.agner.org/optimize/blog/read.php?i=49#49) and that caused users to lose confidence in ICC. 
&gt; "not use GCC since it's free. Have your company buy a real compiler" This made me laugh until I remembered that my company bought a "real compiler" at some insane price and it is a total turd compared to the GNU toolchain. :-( 
&gt; Intel's compiler produces better binaries for intel processors As someone who uses icc and ifort daily, I can assert that Intel's compilers _cannot_ produce better anything - not even better error messages. They are literally the worst compilers I've ever used.
&gt; Does the TA know what he's talking about, and should we stick with the given coding style, and compile without optimizations, or is he just plain wrong? I'm not familiar with Vivado. However, I have two issues with what the TA has said; First, all of the advice for "hand optimizing" the code is actually _horrible_ advice that would never pass a code inspection on a _real_ software engineering team. Even embedded devices these days are performant enough that the cost of a function call is so much insanely cheaper than the cost of dealing with shit code crammed into a handful of massive routines. And secondly, if the optimizer is causing you problems it means either your compiler is turd or your code is turd - usually it is your code that is turd.
With these changes it should still print 0. can you show me the full code?
Implying C99, C11, etc. don't exist...
In many cases, a guarantee that certain operations won't be ordered by the compiler will be necessary and sufficient to ensure proper semantics. When using a platform like the ARM, it may be possible to divide tasks among cores in such a way that any tasks that would need to share things without memory barriers will use the same core. If one is using an operating system that doesn't allow control over such things, that may not be possible, but if one is writing the code that *creates* the execution environment, many more options will be possible. And if there *is* only one core, issues about memory barriers may be moot if compilers treat `volatile` as having acquire/release semantics. The performance impact of treating `volatile` accesses that way would seem like a non-issue compared with giving `volatile` semantics so weak as to be useless. Besides, C has yet to define any kind of memory barrier that can work with ordinary objects, so the choice is between implementations requiring the use of special syntax to achieve required semantics or being extending the semantics of the otherwise-useless `volatile` to achieve them.
I know absolutely nothing about this, but when I read your question I thought of a [semantic tree](https://www.sciencedirect.com/science/article/abs/pii/0306457383900195). Hopefully someone who actually knows something about this pipes in. Until then, this could be a place to start.
For embedded systems, Green Hills and the compiler suite from ARM directly are still well respected.
How many words are we talking? What type of user experience are you thinking of for the word association game? -- I'm trying to get a better sense of what you have in mind...
the lesson i learned was that, when academic rigor is the goal, you should run regression tests on every opt level 0 through 3, &amp; publish binaries built with `-O2`. it's not an official standard, but both `gcc` and `clang` seem to have adopted the convention that `-O2` runs every optimization pass that will (or at least are supposed to) strictly improve the performance and preserve the behavior of any conforming program, and that optimizations beyond `-O2` tend to be situational, buggy, dangerous, or cause bloated binaries.
There are great reasons for all those optimizations, and people really want them in there. The compiler engineers don't put them in for no reason. The most common one that hits embedded programming is considering 0 an invalid address. Your compiler can probably turn that off. For everything else, there's UBSan.
Those error messages aren't even Intel's. The frontend is licensed from another compiler (EDG). I still have some c++ code that'll crash it.
Note that "critical realtime deadlines" aren't the same as "has to be unreasonably fast" - it means it has to be predictable. So you'll probably still benefit from writing your code in a clean way that can be unit tested.
That code only works that way on a little-endian machine, I assume? 
According to the authors of the Standard, the Spirit of C includes the principles "Trust the programmer" and "Don't prevent the programmer from doing what needs to be done". C is used for many purposes, which require many different capabilities. If the most efficient way to accomplish task X would be to do Y, but many other tasks don't require doing Y, and the latter tasks could be handled more efficiently by assuming they won't do Y, then implementations that aren't intended for X should be allowed to benefit by assuming programs won't do Y, but would be less suitable for X than implementations that don't make such an assumption. The authors of the Standard did not expect to be experts on everything programmers might need to do, but expected people writing compilers for various platforms and purposes would be more familiar with programmers' needs than the Committee could possibly hope to be. For awhile, that worked, until some compiler writers started focusing solely on the Standard while ignoring the published Rationale documents. If portions of the Standard along with the documentation for an implementation and/or the execution environment would describe a behavior, but some other part of the Standard characterizes an overlapping category of behavior as defined, optimizations based upon the latter characterization may be useful if nothing a program needs to do would coincide with the former behavior. If, however, the former behavior would coincide exactly with what a program needs to accomplish, requiring that the programmer jump through hoops to achieve the same effect some other way isn't likely to make things more efficient. It may give a compiler writer to show off how "clever" he is for being able to turn a big nasty mess of code into the same machine instructions as the author of the program wanted to express more directly in the first place. 
You have created the "undefined behavior coding methodology", you're welcome.
Prior to the publication of C89, most C programs had behavior described by a combination of *The C Programming Language* and the documentation for the implementation and/or execution environment. The behaviors of many actions were characterized in K&amp;R as "machine-dependent", with some machines defining useful behaviors and others not. The authors of the Standard recognized that one of the great strengths of C was the fact that on many implementations, things could be done using non-portable code that would be less efficient if not impossible using portable code. They expressly stated that they did not wish to preclude the use of such techniques. Nonetheless, they thought that the marketplace should be better able than the committee to judge the costs and benefits of supporting various machine-specific features and guarantees. It's interesting to note, however, that the authors of the Standard described how most then-current implementations would process something like: unsigned mul(unsigned short x, unsigned short y) { return x*y; } in situations where the mathematical product exceeded `INT_MAX`, and gave no hint that they expected future implementations to behave differently. Any idea on what basis the authors of the Standard would have had for such expectation if the behavior was never defined? 
I've always been a big fan of just spawning a bunch of worker threads, depending on the number of detected logical cores, and then creating a simple system for passing bundled function/data pointers to as a 'job'. Then the threads just idle with a sleep of a few dozen milliseconds between attempts to pop a job off the bottom of a ring buffer within a mutex. This has made it super easy to parallelize a bunch of aspects of software I've developed that is computationally intensive, allowing it to scale to the capacity of the system, so that users' hardware is properly leveraged by whatever hardware they happen to be running on. Anything other than a threaded job system like that I imagine could never possibly get near the efficiency or CPU utilization, and I shake my head at the thought of anybody messing around with using threads for anything else in performance-critical applications because there's just no way to utilize cores in a more effective way... provided that your job granularity isn't chunkalicious or so fine that just the overhead of switching between jobs incurs a significant overhead unto itself.
Why? Also, why?
Thank you.
Thank you :)
Thank you :)
Thank you :)
pthreads are far more flexible in their usage from what I understand, though neither pthreads or the standard threads library work with msvc and pthreads doesn't fully work with other windows compilers, (not entirely sure how other compilers fare with std threads). &amp;#x200B; C99 is mostly supported by all major compiler vendors (msvc is still missing certain features like variable length arrays) whereas C11 is just recently being fully implemented by GCC and Clang if I remember correctly, so C99 is the safer/more portable choice.
I've been messing around with C for so long now, that I don't really remember a time when I didn't know it. The most complex thing I did is making a small OCR routine for single digits, using Markov chains and data learning. I did everything form scratch and was pretty proud of the result. But a few months back I read "Modern C" by Jens Gustedt, and then I understood that I actually didn't know anything about C... Btw, picturing how you would explain a concept (i.e. pointers, chained list, etc.) to someone else is a great way to reinforce your own understanding of that concept, and often it highlights the flaws in your mental constructions. Also, knowing every single function from the STD by heart is, imo, not really a sign of mastery. Looking things up when you need to is a skill in and of itself :)
I've never even heard of chained lists, so I guess I have something else to research now. Bit shifting is also something I can't seem to wrap my head around.
Well it feels good, GCC doesn't complain your complex programs work etc
Dialect 2 is non conforming because it can't support unions.
Bit shifting is simply, well, shifting the bits left or right. Say I have `char c = 21`. In memory it's gonna be `00010101`. If I shift it to the left by one bit using `c &lt;&lt; 1`, every bit is gonna be move one "rank" to the left. The result will be `0000101010`, which is equal to 42, because shifting to the left is equivalent to multiplying by 2 in base 10, and shifting to the right is the same as dividing by two.
Thanks for this üòÅüòÅüòÄ
took me a while, but basically after i "relearned" it at university. At that point i went from just memorizing things to really understanding things. So it basically took 10 years from learning it the first time to understanding. But i'd say the thing that changed most is me, growing up from a script kid to a real programmer/engineer. Developing your own coding styles is something i try to avoid, another thing i learned growing up is that sticking to conventions and rules makes working in a team and on big projects a lot easier. 
What's some practical uses for this? I see this in people's code but it just makes it unreadable to me. Do people do it to look cool or something?
Okay cool, that helps a lot. I'll run mine with clang -Weverything but turn off vla because everyone basically says to ignore it anyway.
Okay, yeah, it's the understanding computer concepts of it is where I struggle a bit. I don't have a CS degree and never took any classes, just teaching stuff on my own. So sometimes I have a hard time understanding the whys -- like why passing by reference would make sense or not in some situations.
Honestly, I've never used it practical code. I do use other bitwise operators like `|` or `&amp;` which are useful for flags. It's used by some RNG implementations, like PCG for example. AFAI, to get a "better randomness" it's sometimes good to keep only the first/last bits and throw away the rest. Shifting is an easy (and extremely fast) way to do that.
Would you mind elaborating on the | and &amp; stuff for me, or give me some good links to know more about it? I've been having a hard time understanding that one as well. I'm guessing I just don't write a lot of advanced code. :)
When I fully embraced the C mindset I guess.
I always try to not have any warnings or errors
So, I have some code that uses them a lot. &amp;#x200B; Specifically, I have a byte stream of data that is coming from an embedded device. The device sends out 32-bits at a time, and we have had to define what each bit means. So, for example, the first 8 bits are a header, and in that header, the first bit indicates channel, the second bit indicates falling or rising edge, the third bit indicates the type of internal algorithm being applied, etc. &amp;#x200B; So, when I get this data, I need to handle it based on what each bit is. Let's assume that I can get the header byte via a union (or a straight cast to a struct). (And, of course, endianness is dealt with as well). &amp;#x200B; uint8 header; &amp;#x200B; Now, how do I get the bits out of that byte? &amp;#x200B; uint8 CHANNEL_SELECTOR = 1 &lt;&lt; 0; uint8 EDGE_SELECTOR = 1 &lt;&lt; 1; uint8 ALGORITHM_SELECTOR = 1 &lt;&lt; 2; Which lets me do things like: &amp;#x200B; if ( header &amp; EDGE_SELECTOR ) { ... do stuff for channel selector bit being set... I've simplified this real world use case for purposes of this discussion, but hopefully it gets the point across. &amp;#x200B;
I'd say confident is a better word than "good", I'm confident I can usually right code that won't explode nor leak, but I don't think there will ever be a time where I know more than I don't.... to be honest though if you find you have a good grounding on pointers and memory allocation, it probably won't be too long before you get some confidence... and as for remembering stuff.... well that's what the internet or my own code archive is for!
any time I see different behaviour with the debugger and without, I immediately think memory corruption, check that you're not somehow going out of bounds with a string of something similar
Okay, I had to read that multiple times, and I'm not sure if I completely understand it, but here's my interpretation of it, tell me if this is wrong or not ... You're kind of using a byte to contain multiple values mapped to different variables. Like, say, in bash 35 would be a 35, but in C it'd be 0001011010 or whatever it is. Then you'd do bit shifting to say like "what's the 4th number in that sequence". Is that right?
basically use NULL to signal nothing, ie the pointer isn't pointing at anything to start head should point to null, then head points to fist then first.next will be null when second is added first.next will point to second and second.next well you get the idea......
I think both. 
I think both. 
`&amp;` means AND. It's used between two numbers and will give a result that combines them bit by bit, following these rules: * If at least one of the two bits is 0, then the result is zero * Else (if both are equal to 1), the result is 1. So basically the resulting bit is equal to 1 only if the first AND second bits are (hence the name of the operator). *Example:* `14 &amp; 9` will be equal to 8, because 14 is `00001110` and 9 is `00001001`, so the only bit equal to 1 that both numbers have in common is the fourth, resulting in `00001000` which is 8. &amp;#x200B; `|` means OR. It works the same, with slightly different rules: * If at least one bit is equal to 1, then the result is 1 * Else (if both are equal to 0), the result is 0. So the resulting bit is equal to 1 if the first OR second bits are. *Example:* `14 &amp; 9` is equal to 15. You should figure out why :) &amp;#x200B; In practice, the only time I've used those is for flags. Flags are like multiple options that you can pass to a function, but in a single argument. Say I've got a function that can take eight different yes/no options (it has to be yes or no, you can't do that with arguments that take any number). I could do it like this: \`\`\`\` void my\_function(int opt1, int op2, int opt3, int opt4, int opt5, int opt6, int opt7, int opt8) { if (opt1) { /\* do something \*/ } if (opt2) { /\* do something \*/ } /\* etc. \*/ } \`\`\`\` And my calls would look like a mess: \`\`\`\` my\_function(1, 0, 0, 1, 0, 1, 0, 1); my\_function(0, 0, 0, 0, 0, 1, 1, 1); \`\`\`\` Good luck trying to understand that kind of thing when you see, even in your own code. But if you've noticed, all those zeros and one look like... a binary number! So instead of sending eight numbers, we send just one. We'll use \`|\` to add bits to it (each bit corresponding to a particular option, or flag) and \`&amp;\` to check which bits are active. \`\`\`\` /\* Define some flags \*/ \#define OPT\_1 1 /\* 00000001 \*/ \#define OPT\_2 2 /\* 00000010 \*/ \#define OPT\_3 4 /\* 00000100 \*/ /\* etc. \*/ \#define OPT\_8 128 /\* 10000000 \*/ &amp;#x200B; /\* Define the function using only one argument \*/ void my\_func(char flags) { /\* Check if OPT\_1 is enabled \*/ if (flags &amp; OPT\_1 != 0) { /\* do something \*/ } /\* etc. \*/ } &amp;#x200B; /\* Call the function \*/ my\_func(OPT\_1 | OPT\_6); /\* will send: 00100001 \*/ my\_func(OPT\_3 | OPT\_4 | OPT\_8); /\* will send: 10001100 \*/ \`\`\`\`
Okay, I like that reframing. I can write C code to get to do exactly what I want with my projects, and that definitely gives me a lot of confidence. I'm looking at it from a "good" point of view, or quality, because since my apps are mostly done, now I go back and want to see if its optimized, uses best practices, etc. Like for example I didn't know str(n)dup was a thing, and in all my functions I'd use snprintf inside to write to the one passed into the function (if that made any sense).
What do you mean by memory corruption? If I was accessing memory that is not allocated to me wouldn't that return some kind of error?
I think I got it ... you started describing it and I thought to myself, this sounds a lot like XOR. It is. :) That's the only part I understand so far. It's late so I'm off to bed, but I'm gonna come back and study it some more. Thanks for going into so much detail, I'm learning a ton on this thread.
Yeah, same. It kind of drives me crazy when it'll compile fine with one with no warnings, but not with another. Porting stuff to other platforms is super fun as well, though. I feel like it forces me to write better code.
[removed]
[Feynman Technique](https://fs.blog/2012/04/feynman-technique/)
I always write for linux and Windows 
There isn‚Äôt a word limit within the task 2, and words that are related i.e. user says dog AI says Cat etc Not too sure what you mean by user experience, but it‚Äôs just a console window applications, I‚Äôve made a menu system and I think I‚Äôve created the network sockets and connections for task 3 too
Let‚Äôs say you have two buffers allocated next to each other - A which is size N, then B which is size M immediately after it. If, for whatever reason, you would end up writing to A[N], this would overwrite the first element of B (remember that arrays are zero indexed). The memory is still allocated to you so this won‚Äôt produce a segfault, but you have potentially corrupted the data in B which could change the execution path of your program. If you look up buffer overflow attacks you will find that you can overwrite all kinds of important things (such as the current function‚Äôs return address) if you overflow a buffer on the stack, though modern systems put protections in to mitigate these attacks.
You should read [Code: The Hidden Language of Computer Hardware and Software](http://www.charlespetzold.com/code/)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/devsjunky] [When did you first start feel like you were good at writing C?](https://www.reddit.com/r/DevsJunky/comments/b4huk2/when_did_you_first_start_feel_like_you_were_good/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
never. I never programmed professionally with C, but in my first and last semesters in university, I did program in C and whenever I tried I found new things and it always amazed me how you could use C in ways you couldn't use other languages. Have experience in Java, PHP, JS
I literally just put it away to skim through Reddit. Awesome read.
Try solving simple algorithms, it helped for me
&gt; solve a simple problem If that problem is simple enough to be visualized on paper, then solve it on paper, and then write your program in C. Ofcourse this won't handle all the edge cases, trivial bugs etc, but now you got a working program then improve it further. This worked for me.
The pointer to the head of the list is NULL. 
That was the case for some time, O3 is now perfectly okay.
Its used in wireless systems (4G, 5G etc) and DSP (Digital Signal Processing) all the time.
So why don't you link glibc statically as well?
If you've created your first node, then the head pointer should point to that node. Or at least that's the way it'd make sense to me.
Well, this is quite normal I'd say. When I was in high school, I used to suck at programming, so I know the feeling. The main thing you should do is just relax, C may be quite a difficult language to master, but you, like you said, are new to programming, so for a beginner level, C won't be a hassle to learn, the pain comes when you get advanced. After building your basics, you may make your way through with some exercises or simple challenges to hone your skills. Keep in mind, the only true way to get better at programming after you've done the basics, is just keep programming, get to obstacles and overcome them. Most of the advanced stuff is learned by practice, also your brain will keep that information well preserved, since it has a purpose. And of course, as you get stuck, try and search google for answers (googling, believe or not, is quite a skill for a programmer). And when you can't really find a way out, just don't be afraid and ask. It's that simple, there is no real shortcut. Also, as a beginner, you might have not developed the right "programmer M.O. ". Remember a fundamental rule: writing the code is the easiest part, the hard part is thinking of a way for your code to work. First, make sure you have an algorithm laid down, some logical way for your program to work. If it works on paper, then try with code. If you jump on coding without having settled on a certain way to solve your problem, it's obvious your brain will shut down. Plus, if you say you are good at maths, that is a real plus, believe it or not. I suck at maths, so sometimes I have difficulties figuring out some things quickly. Websites like [http://www.learntosolveit.com/cprogramming/](http://www.learntosolveit.com/cprogramming/) have quite a lot of exercises you might want to take a look at. &amp;#x200B;
The first ten years were the worst.
The strings of argv live in commandFromUser\[\]. It's local to shellCommands() and will get corrupted when the function returns. Make the buffer static or strdup() each string. if (process\_id == 0){ ... looks like the child process could, in some cases, fail to exit where it should. Add an \_exit() to prevent that.
What is ‚Äúthe pointer of the head?‚Äù
It's generally not recommended to link glibc statically. I believe it violates the lgpl license if you don't distribute your source code when statically linking glibc. It also greatly increases the size of your binary. I found crosstools-ng which makes it pretty easy to setup a toolchain that will link against an older version of glibc. Alternatively I plan to build a static version using musl for when glibc is not usable.
20+ years writing C here. I think that there are two stages: The first is thoroughly understanding C itself. That for me probably took at least 2 years. I remember thinking I had mastery and then I read some shipping code from another group, and there was much there I was bewildered by (sorry don't remember the details). The second is mastery of programming itself, independent of language. This is something that even some veteran programmers seem to fail at -- a global perspective on the project design, and implementing a well architected, easy-to-follow design that is bug-resistant and maintainable. In the current world of multiple cores and multiple threads this is no trivial task. As far as remembering details about library functions, I don't think that's relevant. I open man pages for library functions frequently. However, I'll point out that string functions don't add a "null pointer", they add a null value, so you still have a ways to go on correctly describing what's going on. You will need to be able to do that if you get employed writing C. I hope I'm not sounding too discouraging. I still love programming after all this time, and I wish you the best of luck. 
Thanks for the reply. I'll try the exercises and be patient. I'm going to study for a few hours per day and I hope I'll become better. :) 
Yes. The idea being that fundamentally, all a computer does is manipulate but patterns, and humans are responsible for assigning meaning to the patterns. (Relevant xkcd: https://xkcd.com/722/ ) In most cases, we are fine using the "standard interpretations", where we say some patterns are integers, some are floats, some are characters. Sometimes we use certain libraries where we call very large sets of bits things like "images", or "videos". And sometimes we need to assign a meaning to a set of bits that hasn't been predefined for us. In that case, setting and checking each bit is the job of the programmer. And that's what bit manipulation is for. 
Create a node with a null pointer for next node. When you want to use the linked list (like searching, traversing, inserting) then create a pointer to this head node and use it to find the next node. 
Just be patient with yourself and play a lot with things. Make just small programs that serve one purpose, like function pointer usage or pointers in general. Play with a debugger to test your assertions about things. See to it that you completely and fully understand, and can explain, a topic like pointers. It takes some time, but conquer the fundamentals one by one, not all at once, and really get great at one thing at a time. By the way, programmers who claim they're very good should be able to help you on any level. At the very least by explaining the difficult topics with examples you can relate to. And also by the way, many programmers (myself included) are afflicted with crippling self doubt at times, where you think you actually know nothing and the things you know are so easy anyone else knows them and you're basically worthless just nobody has found out yet. Don't let that get you, it's quite normal.
Start out slow and simple, learn what operators you have available `+ - * / %`, those are for arithmetic. the `%` is modulo, for example `12 % 5` would equal to 2, since the remainder from 12 divided by 5 is 2. 12 - (2 * 5) = 2. Modulo is only for integer numbers, normal division is a bit different, 12/5 would be 2. But why? Because its strictly an integer division, the part after the period is simply cut off in integer division and it is not rounded! If you wanted to calculate 12.0/5.0, you would get 2.4 as the result, when using floating points. That leads to the different variable types you can use in C: `float`(32-bit) and `double`(64-bit) for floating point numbers and for integers you have `char` (8-bit), `int` (16-bit), `long` (32-bit), `long long` (64-bit). For integer types you are also having two prefixes. For example an `unsigned char` would be using the 8 bits for its full range from 0 to 255, not using a bit for the sign. A `signed char` would use one bit for the sign and lead to a ranger from -127 to 127. The same applies to the other types. This leaves it completely up to you what kind of math you want to use. But it also leads to some mistakes for beginners. Those things will be getting a lot better over time as you get more comfortable with the language. Another simple thing you should be messing around would be arrays. An array can only be of a single type. You can not mix different types in the same array: For example a `char string[12]` would be an array of 12 chars, and the variable is named string. Char arrays are used a lot in C, since all the text strings will fit into that data type. For example if you have some values and you wanna calculate the average of them, it would look something like that. float values[5] = {1.0f, 2.0f, 3.0f, 4.0f, 5.0f}; float sum = 0.0f; float average = 0.0f; for (unsigned char i = 0; i &lt; 5; i++) { sum = sum + values[i]; // sum += values[i]; would do exactly the same thing } average = sum / 5; 
The versions I'm using will randomly crash with a generic internal error every once in a while for seemingly no reason. I've only had gcc do that when I had a bad memory module.
If you think about it, this technique is quite similar to rubber-duck debugging.
Around 1987, I think. 
That's patently wrong. I work with ICC on my job and its vectoriser is just lightyears ahead of what LLVM and gcc provide. For scientific code, no compilercan currently hold a candle to ICC.
Thanks. I do feel bad when I can't solve an exercise sometimes. I'll try to change my view of things. 
I have no idea what you mean by "task 2" and "task 3", but I assume they're part of your assignment (that you haven't yet mentioned) Anyways... Re: "not a word limit" what I'm trying to understand is how many words the AI knows. Ie there needs to be some type of word list for the AI to ingest (otherwise it needs to do all of its learning from user inputs, which is a bit much). Either way, the way I would probably go about this is with some type of dense, non-directed, weighted graph. Each node represents a word, and each edge represents an association with a weight representing the amount of association between each word. I'd then write a training mode which randomly selects a word, then gives the user two other random words to pick from which the user thinks is most associated with the given word. You could then use this user input to update the weight of that particular edge. (Higher values indicate no association, lower values indicate high association). Maybe then, I'd write an AI mode that takes a user input, looks for the word, and gives you the word in its edge list that has the best weight. Maybe after testing that naive approach, I'd more carefully consider an algorithm that experiments a bit more by following multiple edges. Maybe the AI mode would have some type of user validation so it can continue to learn. Anyways, this is why I asked about the size of the word list -- a dense graph has N^2 edges, so if you go this route, you need to consider algorithm efficiency as well as storage efficiency. Someone with more experience will probably note why my approach is horribad, but without more information (or constraints) -- this is how I would start brainstorming the assignment. Either way -- I went into a lot here -- probably a lot more than I should have. If you want more advice you really need to show some of your efforts to think through the problem.
&gt;practical uses Bit shifting is a very efficient way to do multiplication and division. Each shift to the left or right is a multiplication/division by the equivalent number of powers of two
During the final two months of the three-semester long C++ (yes, C++) course I finally had some confidence that I was able to be mindful of most of the plethora of things you have to keep in mind while writing in C. Now, a year after the course was finished, this confidence has significantly waned because I did not program with C on a daily basis in the meantime. 
Accurate
use what your comfortable with unless you have a pressing need for speed, you could say sprintf and for that matter strndup could be done faster yourself (maybe) but then the fist priority (for me) is to get something working that's not buggy, you can always refactor and finesse later (just backup first in case you finesse really breaks something!) what counts for elegant and what your proud of will develop as you gain more experience...