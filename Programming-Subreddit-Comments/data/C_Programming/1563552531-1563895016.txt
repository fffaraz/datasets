This seems like a really backwards to way to learn this. Why not start with a working example provided by the microcontroller vendor and figure out how it works? GPIOs are usually controlled by hardware registers mapped into your MCU's memory space. Either way, you'll need the reference manual for your microcontroller, which describes the peripherals and their registers and how to configure/use them. Here's a small example showing the basic idea: #include "stdint.h" // get fixed size types // note that hardware registers typically need to be declared volatile // to prevent the compiler from optimizing out writes/reads to them // you can make a macro you can use to refer to the register this way // you cast the memory address of the register to a volatile 32bit unsigned int, and the macro dereferences it #define GPIO_DIR (*((volatile uint32_t*)0x40000200UL)) #define GPIO_VALUE (*((volatile uint32_t*)0x40000204UL)) // alternatively, define a struct that lays out the registers in the peripheral, and define a macro that casts its base address to a pointer to the struct // be wary that the compiler will quietly insert padding to keep types aligned on their natural memory boundaries typedef struct gpio_periph { volatile uint32_t dir; volatile uint32_t outvalue; } gpio_periph; #define GPIO_PERIPHERAL ((gpio_periph *) 0x40000200UL) // and you can access the registers as follows: void test() { // let's say the reference manual says that to set our LED pin high, // we need to configure the direction of the pin and its output value by setting // bit 4 high in these two registers; we can do it this way: GPIO_PERIPHERAL-&gt;dir |= (1 &lt;&lt; 4); GPIO_PERIPHERAL-&gt;outvalue |= (1 &lt;&lt; 4); // you'll probably need to brush up on your bitwise operations if you're working with hw registers }
Christ. Format your code, dude. #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;time.h&gt; #define SIZE 100000 //#define SIZE 250000 //#define SIZE 500000 int main(void) { const char filename[] = "new_name.txt"; FILE *myfile = fopen (filename, "r"); //char names[SIZE][15]; //char line[SIZE]; char c; if (myfile == NULL) { printf("Cannot open file \n"); exit(0); } c = fgetc(myfile); while (c!= EOF) { printf("%c", c); c = fgetc(myfile); } fclose(myfile); return 0; }
Posting it removed my formatting chill out lol
Simply rewinding pos on mismatch creates an additional problem, for example: searching *abc* from *ababc*.
Keep in mind that you'll navigate around compiler optimizations on sites like Godbolt
The Macintosh did indeed allow locking of handles; the issue is that it allowed code to access the master pointers of handles *without* locking them. The .NET framework and JVM take a rather interesting alternative approach--one I wouldn't have thought was feasible but they pull it off. Object references in those frameworks are direct data pointers, but any code which uses them must have associated metadata indicating all of the places where they are kept in registers on the stack, or else a copy of a reference and an indication that other copies may exist. When it's necessary to relocate objects, all code that might be using them will be frozen while the GC not only relocates the objects, but "simultaneously" updates every pointer that exists to them, everywhere in the universe, to point to the new locations. I'd say that in languages with pass-by-reference semantics, the main use of pointers to pointers is for handles, but in C the main use is to simulate the ability to pass pointers by reference. As for manual memory management, that was possible in most if not all dialects of the language the Standard was written to describe, but because C is used for many purposes which don't require manual memory management, the Standard makes no effort to require that all implementations support it, which has led to the maintainers of gcc and clang not only pushing dialects that don't, but demeaning any code that doesn't work in their dialects (despite the fact that the authors of the Standard have explicitly said it was *not* intended to demean code that was non-portable but nonetheless useful).
This is a c subreddit, please post your question at either /cpp or /cppquestions
```close (listener)``` This will not terminate any connections which have been previously made through the listener.
That won't make the socket go away, just cause network clients a long timeout.
A listener socket is still a file descriptor. `close()` the socket like any other, and the underlying file descriptor will be shut down.
Slow down there satan, let the guy keep his will to live for now.
What about a macro version? #define toupper(ch)\ ( ((ch) &gt;= 'a' &amp;&amp; (ch) &lt;= 'z') ? (ch)-('a'-'A') : (ch) ) Or just use the expression itself if they are that ridiculously stupid.
Okay, I only found this sub. I will cancel my subscription and move to /cpp and /cppquestions
Problem is, accept is a blocking call, so i cant get from here to there unless someone tries to connect.
yeah this sounds like what Im looking for. Might you know where some examples may be?
Poll and only accept connections when the FD is "readable." You can poll in a loop on a tomeout of a second or two and optionally execute the cleanup condition in between pollings.
I cant because the accept() call is blocking, and runs in a loop. I need a way to signal the loop to stop listening, and avoid accept from blocking.
ok yes, this seems like where i want to go. Ill look around for examples.
Every operating system has its own recommended polling method (select, epoll, kpoll, ...). If you type "c polling &lt;your_operating_system_name&gt;" in Google, you will find resources and examples most suitable for your environment.
thanks!
Do not call ```accept``` until either ```poll``` or ```select``` tell you that there is a connection request on the line. Both these functions take a time-out, so you can control how long they block for, or no blocking at all.
Yes, I know. But, it wasn't clear what behavior OP was looking for... he said "stop listening". If there's a specific client behavior one was looking for that wouldn't involve a long timeout, of course you're right.
Leave things as they are (many users actually enjoy answering them). If you want to raise the quality of the questions, you can write a guide on how to ask questions. I'm happy to put it on the wiki and link it as the official guide.
Sounds like you're looking for a way to use select/poll. You could do this directly - e.g. [https://www.geeksforgeeks.org/tcp-and-udp-server-using-select/](https://www.geeksforgeeks.org/tcp-and-udp-server-using-select/), but a better (more portable, more robust, more reliable) way to do this is to adopt an event based programming model using something like libevent. e.g. [http://www.wangafu.net/\~nickm/libevent-book/](http://www.wangafu.net/~nickm/libevent-book/) Working with your code this way will move it leaps and bounds forward.
The design of C makes it very difficult for compilers to provide any sort of consistent bounds checking without a huge performance hit. Further, it often makes it needlessly difficult for programmers to provide any sort of consistent bounds checking. If a programmer wants to compute \`foo\*10000 &gt; bar\` in cases where \`foo &lt;= INT\_MAX/100\`, and if the only situations where \`foo\` could exceed \`INT\_MAX/10000\` would be those where it wouldn't matter whether the expression yielded 0 or 1, having a compiler use the existence of such a comparison to optimize out a comparison elsewhere in a construct like \`if (foo &lt; 500000) theArray\[foo\] = 123;\` would not exactly be helpful.
Without functions? #include &lt;stdio.h&gt; int main(int argc, char * const argv[]) { char *pos, *pos_h, *pos_n, *haystack, *needle, low_h, low_n; if ( argc != 3 ) { fprintf(stderr, "Usage: %s HAYSTACK NEEDLE\n", argv[0]); return 1; } else { haystack = argv[1]; needle = argv[2]; } for ( pos = haystack; *pos != '\0'; pos++ ) { for ( pos_n = needle, pos_h = pos; *pos_n != '\0' &amp;&amp; *pos_h != '\0'; (void)(pos_n++ &amp;&amp; pos_h++) ) { low_h = *pos_h &lt;= 90 &amp;&amp; *pos_h &gt;= 65 ? *pos_h + 32 : *pos_h; low_n = *pos_n &lt;= 90 &amp;&amp; *pos_n &gt;= 65 ? *pos_n + 32 : *pos_n; if ( low_n != low_h ) break; } if ( *pos_n == '\0' ) printf("Found at %zi\n", pos - haystack); } return 0; } I love pointers... :D
Bounds checking in C costs exactly as much as in any other language. Believe me I have taken both compiler and optimizing compiler courses.
Usually what happens is that things like (floating-point) `pow` are re-jiggered to be based on `exp`, and things like `log`/`lg` are re-jiggered to be based on `ln`. Those have nice series that (e.g., Taylor, MacLauren, ye olde Calculus knowledge I haven‚Äôt had to use) you can use a few iterations of to come up with an answer. For integer pows and logs, you usually end up either doing it via some lite brute-forcing or using binary-based (instead of e-based/‚Äúnatural‚Äù) algorithms.
In most languages, a compiler given a reference to an array object can determine the size of that array, even if it was determined at run-time. The only way a compiler could do that in C would be to pass around "fat" pointers, increasing the cost of code that passes around references to arrays whether or not the code ends up accessing the arrays in question.
 static const char IS_UPPER[256] = { ['A' ... 'Z'] = 1 }; Assuming you‚Äôre allowed to use C99 (or else just autogen that shit), that‚Äôs the quickest/safest way to do an ASCII-only case check (wouldn‚Äôt work for something like √Ä or √ë), which you‚Äôd need rather more support to handle properly. Go with lowercasing uppercase things for case-folding rather than the other way around; theoretically there might be some things like √ü that don‚Äôt have an uppercase form in your locale. (Newer unicode does have ·∫û, of course, but you might be using ISO-8859-1 or something.)
Array size in C has to be known at compile time. And in most other languages as compiler knows length because it is passed around in a variable, which means you are paying cost of "fat pointer". C gives you possibility to skip bounds checking when you don't need it, or implement it easily in your code (or library code) if you need it. There is no magic. The cost is exactly the same. And you would be surprised how few times you actually need bounds checking.
Functions that accept parameters of pointer-to-array type are rare in C. Instead, functions generally accept a pointer to an element that may or may not be at the start of an array; a compiler has no way of knowing which. Some other languages store the size of each array in memory preceding the data thereof, and require that code only pass pointers to the start of an array. Given such a pointer, a compiler can easily retrieve the array's size. An array within a structure must either have the size stored before it, or only be passed to a function that is expecting an array of that exact size, but in either case a compiler would be able to perform bounds checking given just an array pointer. Further, if one wants to reduce the cost of safety checks without compromising safety, one should recognize that most programs are subject to the following requirements: 1. Given correct data, produce correct results. 2. Don't do anything bad other producing meaningless results, even when given maliciously-crafted data. The C Standard deliberately allows implementations that are used for applications that don't need to meet those requirements to behave in ways that would be inappropriate for those that do, but allowing programmers to demand stronger guarantees in cases where the Standard presently imposes no requirements would eliminate the amount of code necessary to meet the second requirement.
Without the memcpy, attempting to read an element of indices[] which had not previously been written would be Undefined Behavior. And what? You are still reading from uninitialized memory, so how is that defined? memcpy(destination, source, number_bytes) Your indices is uninitialized, so you have anything there, 0s, 1s, any possible number. Your dat is uninitiated as well so you are copying some random value from your indices array into index. It equals to write index = indices[item]. Try it and see. Function call to copy those two bytes does not change nature of what you are doing. You are still copying two undefined bytes into your indices. Which way you decide to implement it is not interesting at all. Furthermore you are still missing the point you got in very first comment: if you malloc uninitialized memory in context where its content matters don't . You don't look for duplicate numbers in a block of uninitialized memory. Only thing you should be interested in when you have uninitialized memory is to initialize it to something that matters to your program.
&gt; But for some reason, it stops at 127(delete key). 127 is the maximum value of your `char` type.
and so that's why it does display all the characters of the ACSII table from 'z' to the end: http://www.asciitable.com/ it won't display the extended set because they go past the maximum value of a signed char, so you will need a second char byte to store them in utf8.
Oh... it was that simple... thank you. It explains why when I ran the second code the numbers after 128 were in reverse order
No idea how do you believe bounds checking is implemented in other languages, but if you believe there is something like free lunch, I can assure you there is not. If you want bounds checking then implement it in your code. Think about std::vector (not C, but good illustration). You have bounds checking with at() function because length is stored. In C if you want you are free to create your implementation of array/vector with bounds check. You will pay exactly same cost for those bounds checks in terms of ram and cpu time as you are paying for those checks in say Java or some other language. In "other languages" compiler pretty much does that behind your back on your behalf. That is what I meant when I ment the cost in C for bounds checks is same as in other languages. You can obviously not pass in raw pointers for the reasons you seem to understand yourself. I just thought it was self evident when I said you can implement bounds checking yourself in C.
Note that the behavior is due to your compiler using signed char. This is implementation dependant.
Take a quick look at this [ASCII table](http://www.asciitable.com/index/asciifull.gif). The first ASCII standard (which is 8 bits in size) can only represent 128 characters, so it starts at position 0 and ends at position 127. There is an extended ASCII table which is 16 bits in size, but the programming language must be set to this standard. As far as I remember, C is not. &amp;#x200B; Regarding the second 'for' loop, I don't understand what it's meant to do. At a first glance I thought the loops were meant to print all the letters from a to z and then do it again from z to a, but that doesn't seem to be the case here. &amp;#x200B; If the code is meant to just print a to z, the second for loop is not necessary.
As far as I'm concerned, there is no way to add custom content to the sidebar in the redesign.
Why does that happen?
Thanks heaps
The code has undefined behavior because char can either be signed or unsigned. The first loop can be replaced by `c = 'z';`. You can rewrite the second one just like a for loop while (c &gt; 'a') { printf("%c -&gt; %d\n", c, c); c++; }
I see what you're trying to say about the ASCII table; but it's a bit confusing, stated that way. Better to say that the first 128 chars are all that can be represented in the first 7 bits of the char; that's all that was in the original standard. The second 128 characters are yielded by setting the high order (eighth) bit on each of the first 128. Those are the IBM "extended character set" they devised for their PCs. That's how you get 256 characters out of 8 bits. :)
Lol
You‚Äôre right! I‚Äôll edit my post because now it‚Äôs spreading misinformation. I counted the powers of 2 in my head and got them wrong. Thanks for the clarification.
Reading &amp; interpreting the standard should also be a skill.
Error handling using ADT is not fool proof. Without pattern matching, or if you choose not to match, you‚Äôll get a non-recoverable error. Plus ADTs also have an overhead. You can try implementing a tagged union with a dummy error field and throw it in a hot path and see for yourself. Now add descriptive error messages to that error. This might not be important for some functional languages, however it is extremely important for C. In that regard, exceptions work better since you don‚Äôt get a perf hit if you never throw. It‚Äôs true there is no ‚Äústandard way‚Äù of error handling in C. Errno is helpful for system errors while return values are helpful for other functions that might fail. Pointers can be used like an optional type for functions returning pointers. But you can‚Äôt use it as a general error handling mechanism since not all functions return pointers, and when you do need to return a pointer from a function, you need to heap allocate it so the reference lives beyond the function‚Äôs boundary. Also globals aren‚Äôt bad, just to be used in moderation.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/linux] [Need help patching patch potential CVE](https://www.reddit.com/r/linux/comments/cfgwl8/need_help_patching_patch_potential_cve/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt;And for the while loop, I'm not really sure you should compare c != '\\0'. This is the null terminator, which goes at the end of strings (I'm guessing now is not the time for you to worry about strings in C). Yeah I wasn't sure what to use since in the first code there wasn't exactly a limit in the loop. The first code is kinda weird but it is complete, and is what the teacher put in the test. From my understanding, the first "for" is useless since it just makes c='z', and the second "for" prints the ASCII code for all characters starting from 'z'
&gt; because usually you always want to use -Wpedantic, but not -Wextra because it gives a lot of false positives. That's not been my observation with C89, where `-Wpedantic` chastises for not initializing variables at the top of a function, but I'll keep an open mind about it.
Have you considered working with a mentor? I am looking for programmers to try out a text editor I wrote, which runs on macOS and Linux platforms. In exchange, I would be willing to mentor you in C. We could work on projects that use more advanced C coding and concepts. Send me a private message if you're interested and we can discuss it. Maybe we can help each other out.
Are you sure there isn‚Äôt a typo in the problem and the second for loop is supposed to be c‚Äî?
&gt; Operations with unspecified behavior on invalid input (free) All functions exhibit undefined behaviour when presented with invalid pointers. Why should `free` be an exception? How do you expect `free` to detect that a pointer it receives is invalid? That's very difficult to do in general. &gt; Operations that use global variables (fopen) I.e. operations that use `errno` for error handling. &gt; Operations involving both return values and errno for error handling (fflush) `fflush` handles errors the same way `malloc` and most POSIX functions handle them: an error condition results in a special return value and an error code in `errno`. Do you mean the edge case where `fflush` tries to write to a file but the file ends early and cannot be expanded (e.g. because it's a tape or disk)?
No blog spam please.
There are a few terminal based C game on Github here: https://github.com/stillmotion/terminal-games.
Also try asking on /r/roguelikedev.
https://en.cppreference.com/w/c/links/libs Here is a list of Good C libraries you can select from and do some projects.
At every step, i increments. When c != a mismatch happens, cl rewinds to a and s steps to the 2nd b.
I did this when I started my new position. I hadn‚Äôt written C since college and I wasn‚Äôt working on anything at the time. I had three weeks to kill because no one would install software on my pc because IT lent me a laptop until my engineering spec one arrived. So I said fuck it. I need to brush up. I‚Äôll make a text game. So I made a dungeon crawler with classes abilities and enemies with abilities. A map n by n matrix of square brackets and randomly generated start/end. Item drops and inventory system with a backpack and equip slots. Menus etc. It‚Äôs a matter of weaving in your discoveries. Try implementing something with an array then try the next thing to implement a linked list. Sharing a variable to contain some map state? We‚Äôll make t a pointer to a static defined place in memory with malloc(). Try double pointers like I did in my inventory system and spawn only one instance of the item object but have everyone point to it/must play.
Understood, thank you.
I will check them out once I get home, thank you.
I‚Äôll check that out too. I didn‚Äôt know such a useful list exists. Thanks
Thank you for sharing your experience. I don‚Äôt understand everything you said, but I guess I‚Äôll figure it out. Now that you mentioned what you did with your game, I‚Äôm kind of more excited to get started. I‚Äôll try out your advice. Thank you again
I tried setsockopt SO\_RCVTIMEO to 1 second, and while it succeeded on a listening socket, it did NOT end a blocking accept. Not that this would be something to rely on, I was just curious.
I would look into the curses library. It's very good at terminal "graphics." I used it make a chess game at my work. I used a shared mmap file to make the game work between two instances so two people could play against each other. mmap is a great tool to learn regardless.
Take a look to [raylib](https://www.raylib.com/). üòâ
I use these literally all the time for "lists", i.e., arrays I don't know the size of. I treat these like strings in that the final entry must be null so they are convenient to iterate over. Is this not common? I rarely have issues with this.
I've created one before as well. I'd use ncurses draw the rendering of the ASCII characters. You'd be able to implement path finding algorithms to make the monsters find the player, use data structures to implement a turn-based queue, and possibly create a mini-parser (and lexer) to create config files. Outside of that, this is a great exercise and it's really fun to play it when it's done.
I had luck with [lazyfoo](http://www.lazyfoo.net/tutorials/SDL/index.php). You could also could try to pull down the SDL source. There may be some examples in there. I am curious why you don't want to use any resources from the SDL website?
But mixing declarations and code (this is what you mean?) *is* forbidden by C89. Either you want to limit yourself to C89 for some reason, then you should not mix declarations and code, and -Wpedantic is correct to generate a warning. Or you want to write modern C where you can mix declarations and code, then you should select a more recent C standard version, and -Wpedantic won't complain.
That would make more sense, but my teacher is the kinda guy who isn't very fond of logic
Check out the 7-day roguelike challenges as well to get an idea of the appropriate scope for a small roguelike project. Many of the most popular roguelikes(i.e. Angband, DCSS, Nethack, etc) are open source and written in C. See: http://www.roguebasin.com/index.php?title=C
I'm guessing he's talking about this [list of tutorials](http://wiki.libsdl.org/Tutorials) on their site. Most of them seem to be focused on C++. There is this list of [OpenGL 3 examples](http://www.g-truc.net/post-0204.html), or [some basic tutorials here](http://www.sdltutorials.com/tutorials), but I haven't checked if that's C or C++. So far this is the only [strictly C SDL2 tutorial I've found](https://www.parallelrealities.co.uk/tutorials/#shooter), there are tutorials for a top down shooter and a platformer.
Why would you need malloc for a pointer to static a memory?
DCSS is written in C++.
I though Git was ++ now?
/S P A C E M A C S/ - It's got style - It's got everything you will ever need and some more - Still very light on resources - Very portable / runs on anything
No. No idea where you got that from. https://github.com/git/git
You wouldn‚Äôt. I wrote that wrong. Thanks for catch!
What about Leptonica?
Haven't heard about that one. Is it another SDL resource?
It's library for processing image.
&gt; And what? You are still reading from uninitialized memory, so how is that defined? As filling the destination with an unspecified bit pattern. Because `uint16_t` is specified as having 16 data bits and no padding bits nor trap representations, every possible bit pattern is a number from 0 to 65535. It's impossible to reliably predict *which* value, but for purposes of this code that wouldn't matter. &gt; Your dat is uninitiated as well so you are copying some random value from your indices array into index. If the caller initializes the storage from `dat[0..length-1]`, which would typically be the case, then that storage would be initialized. I'm not sure why you're assuming the caller wouldn't write values in `dat` before calling the function. If the caller sets the first four values of some array to 10, 20, 30, and 20, respectively, then reading copying `indices[10]` to `index` would yield a value which is not less than zero, so code would set `indices[10]` to 0. Next, `indices[20]` would either yield a value that was not less than 1, or else it would yield the index of an element of `dat` holding 10 [which isn't equal to 20], so `indices[20]` would be set to 1. Then `indices[30]` would yield a value that was not less than 2, or would yield the index of an element of `dat` that's equal to either 10 or 20, and thus not equal to 30, so `indices[30]` would be set to 2. Finally, `indices[20]` would yield 1, and since `dat[1]` equals 20, the function would return 3, indicating that `dat[3]` is a duplicate of an earlier element.
[this](https://www.parallelrealities.co.uk/tutorials/) is the one I am using; it's in C. Maybe go through lazyfoo's to clear the basic concepts of SDL first.
[https://en.wikipedia.org/wiki/List\_of\_compilers#C\_compilers](https://en.wikipedia.org/wiki/List_of_compilers#C_compilers)
means all c compilers are suitable for C18?
No, if you look at the compliance list in that table many aren't even C11 compliant
https://en.m.wikipedia.org/wiki/ANSI_C https://en.m.wikipedia.org/wiki/C99 https://en.m.wikipedia.org/wiki/C11_(C_standard_revision) https://en.m.wikipedia.org/wiki/C18_(C_standard_revision)
**ANSI C** ANSI C, ISO C and Standard C refer to the successive standards for the C programming language published by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Historically, the names referred specifically to the original and best-supported version of the standard (known as C89 or C90). Software developers writing in C are encouraged to conform to the standards, as doing so helps portability between compilers. *** **C99** C99 (previously known as C9X) is an informal name for ISO/IEC 9899:1999, a past version of the C programming language standard. It extends the previous version (C90) with new features for the language and the standard library, and helps implementations make better use of available computer hardware, such as IEEE 754-1985 floating-point arithmetic, and compiler technology. The C11 version of the C programming language standard, published in 2011, replaces C99. *** **C11 (C standard revision)** C11 (formerly C1X) is an informal name for ISO/IEC 9899:2011, a past standard for the C programming language. It replaced C99 (standard ISO/IEC 9899:1999) and has been superseded by C18 (standard ISO/IEC 9899:2018). C11 mainly standardizes features already supported by common contemporary compilers, and includes a detailed memory model to better support multiple threads of execution. Due to delayed availability of conforming C99 implementations, C11 makes certain features optional, to make it easier to comply with the core language standard.The final draft, N1570, was published in April 2011. *** **C18 (C standard revision)** C18 is the informal name for ISO/IEC 9899:2018, the most recent standard for the C programming language, published in June 2018. It replaced C11 (standard ISO/IEC 9899:2011). It has been informally named as C17 too. GCC 8.1.0 and LLVM Clang 7.0.0 support C18. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/C_Programming/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
No. (Look at the C89 and C99 support.) &amp;#x200B; But once you've answered question 3, you can use this list to help you find the answers to question 4. You'll need to do some extra research, but it's a starting point.
What a waste of time. Caller should not initialized "dat", it was all about uninitialized memory and you are constantly speaking as if content of memory had meaning. It does not. Until you initialize it. Sorry my friend, but I believe you are bit confused here.
I'm building a rougelike right now using C and the ncurses library for writing to the terminal. I'm doing this on linux. I have a fair amount of experience with C, though I wouldn't claim I'm an expert. My project is not very far along yet. &amp;#x200B; The ncurses library can be a bit challenging, since it's basically working with terminal types built in the 60's. So it's fairly arcane in spots. I still think it's a good way to get your feet wet. You can always start with drawing out screens in text each time a key is pressed using basic printfs to start with while you gain some experience and level up. Then jump into the ncurses stuff.
gcc compilers are ANSI C compliant.
Yes, but it's much more difficult. There are lots of C graphics libraries, but none of them are easy to use. SDL and OpenGL are the most versatile and powerful, but not easy for beginners. I have found that Raylib is an easy-ish library and the developer u/raysan5 is very active.
Check out the SDL library.
GTK
Thanks I'll check it out
Ok thanks
Thanks
Oh wow, I didn't realize there weren't very good tutorials. I picked up the basics from lazyfoo back in ~2005ish? and then made do with the SDL API documentation. Then SDL2.0 came out and I just had to learn the few relevant changes/differences, but most stuff remained the same, so if you can find SDL1.2 tutorials you like then start with those and migrate to 2.0 later once you feel comfortable.. Good luck!
They can be configured to be conforming. Their maintainers, however, have expressed in support forums an attitude that if the Committee specified behavior in a corner case that would be hard to support, that's likely a mistake and need not be supported. I could see arguments for that view, except that any time the Committee fail to mandate behavior in cases they thought would be recognized as obvious, that's a deliberate judgment that any code relying upon such behavior should be regarded as "broken". To be sure, the One Program Rule means that there's almost nothing an implementation could do with most programs that would render it non-conforming, but that's really the only sense in which the optimized gcc dialects should be recognized as conforming, given that they uphold neither the letter of the Standard nor the Spirit of C described in the published Rationale documents (google "C99 rationale").
Put a printf() inside your while loop, and a printf inside your if() &amp;#x200B; What's happening at the first record, Alex is recorded in stu, and stu is assigned to head. &amp;#x200B; For the rest of the records, you don't touch head, but you're overwriting stu. Because head points to stu, when you look at the end, you see the last thing you overwrote stu with.
Wrong place to get c++ help
At least he can spell it.
why is that
look at the name of this subreddit....
Your problem is likely linked to points and memory management. Have you tried adding a print statement to your while loop specifically where you are creating a new student and before your if statement for checking head. Print both head and stu. I have limited c experience but it could be that your are changing head when creating a new stu or causing head to be null after creating it. A print statement would allow you to see whats going on as it runs.
shit!! don't mind me i'm new
How far have you gotten? Have you installed the development libraries and figured out how to compile a test program yet?
Even if i do something like if(head == NULL ){ head = createStudent(list,name, num); } head will still continue to be the last person in the list.
Aha, I think it's actually name and num. &amp;#x200B; You're using the same storage for the name and number each time. &amp;#x200B; stu-&gt;name is a pointer to char. &amp;#x200B; name\[20\] is a char array. &amp;#x200B; stu-&gt;name points to name\[20\], so each time you overwrite name\[20\], stu-&gt;name changes too. &amp;#x200B; You need to allocate separate storage for name and number inside each struct student. &amp;#x200B; Even though you're only calling createStudent once, you're still overwriting name\[20\] for every record as you read the lines.
Wouldnt Student *stud = (Student *)malloc(sizeof(Student)); take care of that though?
No (I think) because that creates storage for 3 pointers. Whereas you need storage to 2 arrays and one pointer. Right now you're creating the storage for the name and number in main with char name\[20\]; char num\[20\]; &amp;#x200B; And when you call createStudent() you just point your new pointers to these two arrays that you're overwriting in your main loop. &amp;#x200B; If you try passing different arguments to createStudent(), you should notice the difference. &amp;#x200B; (I haven't tried this)
wrong sub
for a first project, i would start with something easier like an ascii based sokoban or boulder dash.
C# is off topic in this subreddit. Please post C# questions to /r/learncsharp instead.
Check out the `scanf` function. Use it to read numbers from the user. Then check if the numbers are each between 0 and 9.
is c89, c99 and c11 are all ansi?
Seconding the SDL recommendation. GTK is nice, but it's mostly a ui library, for making desktop applications. Not so useful for making games. Raylib is also decent, but SDL is the 'standard'.
cool thanks
Your assignment sheet should have all the information you need. Read it carefully and think back to your lecture.
[GCC](https://en.m.wikipedia.org/wiki/GNU_Compiler_Collection) 8.1.0[[3]](https://en.m.wikipedia.org/wiki/C18_(C_standard_revision\)#cite_note-3) and [LLVM](https://en.m.wikipedia.org/wiki/LLVM) [Clang](https://en.m.wikipedia.org/wiki/Clang) 7.0.0[[4]](https://en.m.wikipedia.org/wiki/C18_(C_standard_revision\)#cite_note-4) support C18.
It's also known as C17, so use that as a search term .
You have to do a check on their input anyway, not just to see if it's a number from 0 to 9, but to see that the user doesn't troll you with letters, as well. What happens if they put in a B somewhere? Whoops, there goes your program, unless you catch it first.
Accurate
Dangerous yes, bad yes. But also terrifying to push into production? Also yes. Is my code a risk to your operating system? Yes. But can I make anything I want, yes. Freedom is worth the risk.
Don't use it if you don't like it &gt;.&gt;
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions. Also, the answer to your question is: to avoid forgetting C++, write programs in C++.
There's only one very minor user facing change, and that's the deprecation of ATOMIC_VAR_INIT
I guy I used to work with did a bunch of woodworking. One day he sawed his thumb right off. Never once did I hear him blame the saw.
thanks guys &lt;&lt;3
The C standard has the wrong operator precedence `x &amp; 0x777 == 0x777` but it isn't fixed due to backwards compatibility concerns. Your case for a consistent error handling interface and dropping the semicolon may have merit, but it doesn't matter. There are billions of lines of source code which rely on C being C. Any breaking change has to be weighed against the value of all this existing code, I can't imagine any breaking change ever being worth it.
Linux. Postgres. Postfix, etc I disagree with your opinion.
Linux and that other stuff is older than me.
And yet it still works.
C is like a cockroach - it's small, ugly, adaptable, and will probably be around long after whatever flavor-of-the-week language the kids are learning in 2019 is just code you can't hire anyone to maintain. It's not the right tool for many things, but it's a perfectly useful tool for the problem domain it was created for.
I‚Äôm going to repost this comment on /g/ tomorrow to cause hurt feelings.
That‚Äôs a pretty poor attitude to safety. Programming languages and tooling should make it harder to make mistakes. C makes it very easy.
Those have had plenty of memory safety issues.
C programmers don't think about you when you're not around.
c is not for kids.
If C programmers thought about anyone else at all they wouldn‚Äôt be programming in C.
le hardcore hackerman lives le dangerously
What is *recreational software*?
Thanks for stopping by to troll. Good night.
Well, there are saws that can detect whether they are cutting wood or the human. So there are safer saws just like there are safer languages.
&gt;‚Äî *You‚Äôre saying it‚Äôs logical if you have a language embedded in C to make it with C-like syntax. But if you have a C-embedded language, I assume you have C programmers who want the code to be in C and not some other language, which looks like C, but isn‚Äôt C. So Lua users were never supposed to use C daily? Why?* &gt;‚Äî Who uses C every day? &gt;‚Äî *System programmers.* &gt;‚Äî Exactly. That‚Äôs the problem, too many people use C, but should not be allowed to use it. Programmers ought to be certified to use C. Why is software so broken? All those hacks invading the world, all those security problems. At least half of them is because of C. It is really hard to program in C. &gt;‚Äî *But Lua is in C.* &gt;‚Äî Yes, and that‚Äôs how we learned how hard it is to program in C. You have buffer overflows, you have integer overflows that cause buffer overflows‚Ä¶ Just get a single C program that you can be sure that no arithmetic goes wrong if people put any number anywhere and everything is checked. Then again, real portability issues ‚Äî maybe sometimes in one CPU it works, but then it gets to the other CPU‚Ä¶ It‚Äôs crazy. From [an interview with Roberto Ierusalimschy](https://habr.com/en/company/mailru/blog/459466/) (the author of Lua)
How would you post the code aswell? Im on vacation now, but once i get back home im planning on releasing this on github, i could link the github link when its uploaded
Then let's change the example to a butcher cutting meat instead of wood, where that saw is probably not useable. Likewise, I probably can't write an interrupt handler in Python. But I agree that nobody *wants* severed digits, automobile accidents, or buffer overflows. We try to mitigate hazards with SawStop, automatic braking, and complier warnings, but we don't stop using power tools, driving cars, or using less-than-perfect languages. Sometimes we decide to accept the risk, or we'll never get anything done.
Get fucked.
&gt; Then let's change the example to a butcher cutting meat instead of wood, where that saw is probably not useable. [BladeStop](https://www.scottautomation.com/bladestop/) still works. &gt; Sometimes we decide to accept the risk, or we'll never get anything done. I think the cases where C is the better alternative to C++/Rust/Go have become increasingly rare in the past ten years or so.
IMHO if you can afford the [C Programming: A modern Approach (2nd Edition](https://www.amazon.com/C-Programming-Modern-Approach-2nd/dp/0393979504)) , then go for it by all means. Read the customers reviews to see why.
C++, sure, but it shares C's safety issues. IMO Rust or Go still have miles to go before they're a suitable replacement for C or C++ for many things these languages are used for. I think it's kinda like x86 - it's an old, ugly, not-very-good instruction set architecture and many people have thought they could do better (including Intel themselves), but in the real world, it turned out that many of the things academics thought were major pain points weren't *really* that crippling, and that compatibility, legacy code, established base, etc etc, mattered a lot more.
&gt; [‚Ä¶] compatibility, legacy code, established base, etc etc, mattered a lot more. That's the reason why we can't have nice things and instead are stuck with fossil powered cars, IPv4 and capitalism.
Great power involves great responsibilities. Programming in C is like being root on unix systems.
char c; while((c = getchar()) != EOF) { if ('0' &lt;= c &amp;&amp; c &lt;= '9') {‚Ä¶} }
thanks
&gt; I think the cases where C is the better alternative to C++/Rust/Go have become increasingly rare in the past ten years or so. I somewhat agree. In the long run, I think C will join assembly language, and be used in only extremely specific, unusual cases. Of course, in the long run we are all dead.
&gt;How far have you gotten? Have you installed the development libraries and figured out how to compile a test program yet? Wtf, I'm not noob. It's my first time to work with graphich at low-level
Funny how often this same question has been asked recently.
I'm still trying to solve this üòÖ
Way to go offside, well played.
The first thing you need to do is find out the difference between C# and C and realize they have nothing to do with each other.
Don‚Äôt work close to the metal if you can‚Äôt handle it. Languages exist with feature sets; you select what you need for the job. Don‚Äôt want to use C. Don‚Äôt. But the language isn‚Äôt bad or dangerous.
I hate to be that guy, but: # THIS IS A SUBREDDIT FOR [THE C PROGRAMMING LANGUAGE](https://en.wikipedia.org/wiki/C_(programming_language)) The [C#](https://en.wikipedia.org/wiki/C_Sharp_(programming_language)) subreddit is at r/csharp.
I believe you‚Äôre triggering your conditional to flip fightyes to false no matter your input. It‚Äôs a series of ors, so if any of them is true, fight yes is gonna be false. You input ‚Äúyes‚Äù which clears one condition, but it‚Äôs triggering the other 3 as true and setting fightyes to false
Redditors are stupid and lame.
Thank you [NoYoureCorrect](https://www.reddit.com/user/NoYoureCorrect/) and sorry guys.
C doesn't make a bad reddit programmer any worse. Reddit programmers will make the same stupid mistakes in any language.
And a lot smarter, too.
Software he writes while he masturbates.
Leetcode.
Will check it out !does it have tutorials for me learn something?
Introduction to Algorithms by Thomas Cormen and leetcode
Well its mostly questions about algorithms? I haven't seen it used it myself but I've seen it recommended a lot whenever anyone needs help with algorithms.
MIT Data-structures and algos open course: [https://www.youtube.com/watch?v=HtSuA80QTyo&amp;list=PLUl4u3cNGP61Oq3tWYp6V\_F-5jb5L2iHb](https://www.youtube.com/watch?v=HtSuA80QTyo&amp;list=PLUl4u3cNGP61Oq3tWYp6V_F-5jb5L2iHb)
Hackerrank, acmp.ru, codeforces
You literally cannot make a dangling pointer in javascript. You literally cannot dereference a null reference in C++, etc etc. Some mistakes are inherently easier or harder in different languages; that is undeniable.
C# is off topic in this subreddit. Please post C# questions to /r/learncsharp instead.
And that has nothing to do with anything I said. There are tools to catch things for you in C. With JavaScript there is a lot of "you can't". With C, you can do anything you want but any knowledgeable programmer knows to watch and test for such things.
Do not spam.
Check out my cmd emulator. It's written using linked list, stacks and trees. &amp;#x200B; [https://github.com/iivanu/Command\_prompt](https://github.com/iivanu/Command_prompt)
People do push the damnedest things to Github. The "dangerous" part is overstated. Otherwise -if you don't like C, don't use it.
What command are you using to compile this?
gcc main.c (random libraries)
In main.c, you are including file1.c and file2.c. This effectively pastes the contents of those files into main.c. The result is that main.c ends up containing two definitions of the same function.
Ah, I see. Instead should I compile them like "gcc file1.c file2.c main.c"?
It worked, thanks :)
Yes, or compile them separately and then link together into a final executable.
IAR compiler supports C18. They recently added support for it.
&gt; The C standard has the wrong operator precedence x &amp; 0x777 == 0x777 but it isn't fixed due to backwards compatibility concerns. I would think it would be possible (and desirable) to deprecate the use of certain constructs where operator precedence would affect the way code is parsed, with the intention that compilers warn about such constructs, and such constructs would be changed on an as-practical basis, to use sufficient parentheses to eliminate the dependence on operator precedence. I'd likewise like to see the Standard specify a means by which code can indicate what it's expecting as a minimum size of `int`, and recognize situations where certain aspects of promotion would or would not affected by the choice of `int` type beyond that, and deprecate cases where they would. For example, given something like: uint16_t u16a, u16b, u16c; uint32_t u32a; ... u16a = u16b * u16c; u32a = u16b * u16c; if (u16a - u16b &gt; u16c) doSomething(); the computation of `u16a` should be defined in machine-independent fashion, even on platforms where `int` is 24 or 32 bits; the computation of `u32a` should be defined in machine-dependent fashion on machines where `int` is 32 bits or more but deprecated on platforms where `int` is smaller, and in favor of either `u32a = (uint16_t)(u16b*u16c)` or `u32a = ((uint32_t)a * b);` (depending upon what action is required).
It's like an RV. All the pain and misery of both a car and a house with none of the benefits of either.
My point was that the ability to safely read potentially-uninitialized elements of \`indices\` can facilitate the task of finding duplicates within an array of caller-supplied values (which the caller would presumably initialize). I'm not claiming one should expect computations that depend upon nothing but meaningless data to be meaningful, but rather that it is sometimes useful to have a computation process a mixture of meaningful and meaningless data, without having to know in advance which data are meaningful.
I tried to format the code but it wont change.
No. It can not. You also constantly make implicit assumptions about meaning of uninitialized memory, such as your "potentially uninitialized indices".
What I ask is that the standard library offer new, more consistent error handling signatures. All this involves is new function names, deprecating the old and removing the old after a reasonable amount of time, such as ten years. This could be done with the syntax as well, phasing out old, risky syntax with new, more predictable syntax over some years. C is going to be around for some time, so we might as well make the most of it.
https://github.com/Lukas713/dataStructuresAndAlgorithms
lua is good for allowing an end user to mod their C written programs.
I‚Äôve looked at many languages and used almost just as many. If I had to choose a c replacement it would me Mozilla‚Äôs rust. Personally I love python for many different cases but for me can‚Äôt replace c in many cases. C can be bad. C can be dangerous. I just don‚Äôt think of it as inherently bad or dangerous .
C++ is not C.
I've decided that for now, Python 3 is the only programming language that I'm going to use for original work.
It works for c and c++ ! Actually there are almost no difference between the two if you want to use color.
Do you know about the "Mehlhorn-Sanders Algorithm Toolbox" ?!? Although a bit old, the theory is solid. [Mehlhorn &amp; sanders Algorithm Toolbox](https://people.mpi-inf.mpg.de/~mehlhorn/ftp/Mehlhorn-Sanders-Toolbox.pdf)
Advantage of this over escape codes?
&gt;And that has nothing to do with anything I said Sure it does. You said ‚Äòreddit programmers will make the same stupid mistakes‚Äô, so I gave some examples of how you can‚Äôt make the same mistakes in other languages. &gt;Any knowledgeable programmer knows to watch and test for such things as you mention Well, judging by the CVE database, I guess the world is full of non-knowledgeable programmers.
This project already uses escape codes on Linux, it has simply more conditions to it. You can't use escape code on Windows as example. Can you remember what color this is : "\\e\[0;31m" ? I don't. If you suggest the use of macro like #define red "\\e\[0;31m" well you miss the "remember previous color" stuff. It's also a huge pain to remove / comment out every color in case you don't want them anymore. A simple define in my project allow to remove every color. &amp;#x200B; On top of that, the code become more readable in my opinion. Every color is grouped in the same bracket.
Hi, sorry for this post. I have found out that I was not using pthread\_cond\_broadcast() after setting the value of member "order" inside "foo". After broadcasting to all other threads I was able to get out of the deadlock.
Data Structures and Algorithm Analysis in C by Mark Allen Weiss is a good book focusing more on the side of DS, has pretty good explanation of algorithm analysis and the code is in C.
I read snake.c and it looks pretty good. void free_state(struct state *s) { free(s-&gt;segments); } s-&gt;segments is now a pointer to memory you can't use. In a larger project that could be a source of bugs. IMO settings pointers to NULL after you free them is a good habit to get into. [https://stackoverflow.com/questions/1879550/should-one-really-set-pointers-to-null-after-freeing-them](https://stackoverflow.com/questions/1879550/should-one-really-set-pointers-to-null-after-freeing-them) &amp;#x200B; There were a few places I thought the code could be more readable. This is even more opinion based: s-&gt;segments-&gt;x = DEFAULT_X, s-&gt;segments-&gt;y = DEFAULT_Y; I would avoid using the comma operator almost completely. Splitting onto separate lines is easier to read, for me. case EAST: case SOUTH: I would prefer one case label per line for readability. &amp;#x200B; int dir_value(int dir) { switch (dir) { case EAST: case SOUTH: return 1; case WEST: case NORTH: return -1; } return 0; } void move_head(struct state *s) { if (s-&gt;direction == EAST || s-&gt;direction == WEST) head(s)-&gt;x += dir_value(s-&gt;direction); else head(s)-&gt;y += dir_value(s-&gt;direction); I think something like this would be more readable: void move_head(struct state *s) { switch(s-&gt;direction) { case NORTH: head(s)-&gt;y -= 1 break; case SOUTH: head(s)-&gt; += 1 break; // etc. } &amp;#x200B; if (ticks++ % speed == 0) { last_state = update(&amp;game, c); c = '\0'; } I found this broke my flow of reading because I had to stop and think about the operator precedence of ++ and %, and double check that there weren't any hidden tricks inside the condition. ticks++; if (ticks % speed == 0) { last_state = update(&amp;game, c); c = '\0'; } This uses an extra line, obviously, but I think it's a little easier to read.
I don't feel easy doing your homework for you, but in hanoi.c:main the variable ```c``` gets used in an indeterminate state, the first time through the loop. Hope you get a good mark for your assignment.
thanks for that stackoverflow link, i didn't even think to do that, and thank you for looking through my code! the `ticks` section rearranging is a good call! i arranged it like that so that the update would get called when `ticks` is 0, but i didn't even think about the interaction between ++ and %
ah good catch, i forgot to set c's initial value after turning the loop from a `while` to a `do {} while`. thanks, but this is a personal project, with it being the summer holidays and all.
Yeah, I noticed that the github thing was bullshit when I read it earlier and I forgot to update my comment.
Glad you figured it out, have you considered the case where a thread doesn't get to call pthread_cond_wait before the other thread(s) broadcast? Remember you have to be waiting on a condition variable when it is signaled in order to receive it.
I think it works as intended, but for me I had to sort of triple-check that I wasn't misinterpreting it. So instead of reading two lines once each, I was reading one line three times (say).
For a new library with different function names, come up with your own. There is nothing special about the standard library that can't be reproduced. If it is widely used it will be brought into the standard, like several of the Boost libraries have been incorporated into the C++ standard. The C standard tends to be a reflection of current practice, mostly by the big compilers, rather than driving change itself.
How would you write a function to determine if a sequence of consecutively-stored 16-bit values contains any duplicates, with time proportional to the number of items preceding the first duplicate and minimal setup time?
It depends if you want to find IF there is any duplicate, or if you want to find how many duplicates, in which places etc.
&gt; I'd likewise like to see the Standard specify a means by which code can indicate what it's expecting as a minimum size of int, and recognize situations where certain aspects of promotion would or would not affected by the choice of int type beyond that, and deprecate cases where they would. Have you tried #if INT_MAX &lt; 0x7fffffff # error need 32 bit int #endif Alternatively, have you tried `uint32_least_t`? This is a solved problem.
&gt; removing the old after a reasonable amount of time, such as ten years. You're kidding, right? Do you have an idea how much software in use today is more than 30 years old?
I agree with most of your notes. Setting the pointer to NULL is imo not something you should worry about. Not saying you should assume that your code is perfect will never use-after-free; but simply that you shouldn't be thinking about nulling together with every free. I have seen some people use a `FREE` macro, like `#define FREE(x) free(x); (x) = NULL`, which is not a bad idea, but you might be overlooking someone else who has a reference to `x`. If you want to ensure no memory errors, run through valgrind or a sanitizer.
Neither IPv4 nor capitalism have even halfway-decent replacements yet.
For C,Data Structures using C by Reema Thareja is a great book.The concepts are easy to grasp.
For C,Data Structures using C by Reema Thareja is a great book.The concepts are easy to grasp.
Data Structures Using C by Reema Thareja is a great book.The concepts are easy to grasp.
My point was that the Standard should deprecate situations in which code would be required to have different meaning on different platforms. Given e.g. \`uint16\_t a=1,b=2;\`, some implementations would be required to process \`a-b &gt; 5\` in a way that yields 1, while others would be required to process it in a way that yields 0. The Standard should either deprecate such expressions altogether, or else deprecate them in situations where their meaning would not match a particular implementation-independent meaning.
&gt; My point was that the Standard should deprecate situations in which code would be required to have different meaning on different platforms. That doesn't make a lot of sense. The standard allows for freedom in type sizes because different platforms have different requirements for the sizes of their types. Deprecating such situations would be deprecating the flexibility of the language to be adapted to new platforms.
frank denis is what i want to be when i grow up
I wish I was this good
Rather be a Chad C developer, than a filthy python virgin
 #include &lt;stdio.h&gt; int main(){ int day, month, year scanf("%i", &amp;day); scanf("%i", &amp;month); scanf("%i", &amp;year); enum months{Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec}; int days_in_months[12] = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31}; if (!(year % 4)) days_in_months[Feb] = 29; int total_days = 0; int counter = 0 while(counter &lt; month) total_days += days_in_months[counter]; total_days += day printf("total days: %i/n", total_days); return 0; }
C is a tool just like any other language. It is optimized for writing operating systems and for embedded systems. If you are using C as the back-end for a web service or for accounting software, you are not taking advantage of the available tools. &amp;#x200B; C is a beautiful language because of its technical simplicity.
[https://medium.com/better-programming/object-oriented-programming-the-trillion-dollar-disaster-%EF%B8%8F-92a4b666c7c7](https://medium.com/better-programming/object-oriented-programming-the-trillion-dollar-disaster-%EF%B8%8F-92a4b666c7c7) (yes I know medium is a horrid site - but the article need reading with an open mind) a language usually isn't bad, generally its the codes
Thank you!
How does this compare to WireGuard?
&gt; Never ever: &gt; Any feature request mentioning systemd. why tho?
Wireguard = udp. dsvpn = tcp.
Nice if you to do OPs homework assignment
why would it not just handle ipv6 if it connects to its own server?
\- Use stdint.h; \- I would typedef my types and have them in a .h; \- use a typedef enum for your return values to make sure that your functions return a valid code. Also, enums with no "=" ensure the uniqueness of each symbol. \- No comments. Comment everything and always specify the "why" and not "what are you doing". \- Declare each resource on a separate line. \- "c" and "s" are not proper variable names. \- for the function "handle\_key", it seems that the argument "c" is only used as an input. If an argument is only an input (all pass by value arguments) then make it const. \- when defining preprocessor constants, use parenthesis and define the expected type: `#define ONE (1u)`
Great article.
Not like you couldn't just build a service that runs it. Not exactly rocket surgery.
More compact solution, but unfortunately, wrong. The original had the 100 and 400 year rules correctly, at least.
Perhaps I should clarify what I meant: at present, there are two main "categories" of C programs--those which will run identically on all C implementations where they do not exceed translation limits, and those which will run on one C implementation. C99 expanded the first category to allow some C programs which may be rejected by some implementations, but will run identically on all implementations that would not be required to reject them, but that category was expanded only to accommodate optional features that didn't exist before such as the `uint16_t` type. IMHO, the Standard should define a category of implementation that generates code for a specified environment, and a category of programs which will--at the language level--either behave identically, or behave in ways that vary deliberately according to the implementation, on all implementations that accept them. When I say "at the language level", what I mean is that a construct like `*(uint32_t volatile *)0x12345678 = 0x87654321;` should have its meaning defined as "Synchronize the state of the abstract machine and the target environment, use the environment's natural means of writing 0x87654321 to address 0x12345678 *with whatever consequences result*, and then synchronize the state of the abstract machine with the target environment." Whether writing a particular value to a particular address would have any predictable or useful effect should not be a concern of the language nor implementation. My beef with C is that while types like `uint16_t` are supposed to facilitate implementation-independent code, an expression like `uint16a-uint16b &gt; uint16c` can have two very different meanings at the *language* level even though the types involved are *supposed* to be system-independent. Which of the following situations would most often apply in cases where a programmer subtracts two uin16_t values, and where promotion to a signed integer type would affect the behavior: 1. The programmer needs the subtraction to be performed mod 65536 on all platforms where the code will be used. 2. The programmer needs the subtraction to be performed with a signed arithmetic that has a range of at least -65535..+65535 on all platforms where the code will be used. 3. The programmer needs the subtraction to be performed with a signed arithmetic on all platforms where the code will be used, but a range of -32768..+32767 would suffice. 4. The programmer will need the subtraction to be performed with signed arithmetic on platforms where `int` is larger than type of the values being subtracted, and with unsigned arithmetic on platforms where it isn't. Do you think #4 is anywhere near as common as the other possibilities? Do you think it makes sense to have the shortest way of writing such an expression yield meaning #4?
&gt; IMHO, the Standard should define a category of implementation that generates code for a specified environment, and a category of programs which will--at the language level--either behave identically, or behave in ways that vary deliberately according to the implementation, on all implementations that accept them. POSIX defines [such environments](http://pubs.opengroup.org/onlinepubs/9699919799/utilities/c99.html#tag_20_11_13_04) (though likely less strict than you desire). Note that there are multiple environments given because no single environment admits an effective implementation on all interesting targets. &gt; Do you think #4 is anywhere near as common as the other possibilities? Do you think it makes sense to have the shortest way of writing such an expression yield meaning #4? Interpretation #4 is chosen because most architectures do not have the capability to perform arithmetic on types narrower than an `int`. Enforcing that arithmetic must be performed at a narrower width would just make all computations where such is not strictly needed a lot slower. And it's easy enough to remember the extra cast or extra masking around `uint16a-uint16b &gt; uint16c` when you do this sort of comparison, though this situation appears rarely anyway. This is by the way one of the reasons why I'm not a huge fan of fixed-width types: they give you the false confidence that arithmetic is truly performed modulo the bit width when that is not generally true. Most programmers would avoid this sort of error if they were forced to perform explicit masking if they desired such semantics.
what is a mern stack?
My main interest is embedded systems. At present, the Standard defines the behavior of roughly 0% of programs for freestanding implementations, but one wouldn't have to add much to the Standard to allow the majority of tasks for such implementations to be processed in a way that would be 100% defined at the *language* level. &gt; Enforcing that arithmetic must be performed at a narrower width would just make all computations where such is not strictly needed a lot slower. If processing some particular piece of code in such fashion would yield a program that slowly yields correct behavior, and promoting values would yield a program that quickly yields incorrect behavior, I'd say that the former would be a more useful way of processing that program. Personally, I'd like to see standard directives to specify what size(s) of `int` and `long` a piece of code is prepared to accommodate, with the proviso that implementations would be free to either use the specified types or reject the program, but recognizing accepting the program but processing it inefficiently may be more useful than rejecting it altogether. &gt; This is by the way one of the reasons why I'm not a huge fan of fixed-width types: they give you the false confidence that arithmetic is truly performed modulo the bit width when that is not generally true. Most programmers would avoid this sort of error if they were forced to perform explicit masking if they desired such semantics. Personally, if I were in charge of the Standard, I would add fixed-size-and-semantics types which would not promote, and would generally cause a program to be rejected in cases that would require promotion. To avoid chicken-and-egg issues, I would allow implementations to promote such types when balancing larger operands, but specify that quality implementations should issue diagnostics in such cases and quality programs should include explicit casts [this concession would allow 32-bit implementations to e.g. support `wrap32_t` as a synonym for `uint32_t`]. I'd also add a means of specifying integer formats explicitly (e.g. 32 bits, stored with eight bits per byte in little-endian format, with padding bits ignored on reads and zeroed on writes). Processing code that uses such types on a platform with e.g. 9-bit bytes would be slow, but if code only uses such types when needed, and uses native types otherwise, processing such code would likely be less slow than processing all the user-code masks and shifts necessary to achieve the same semantics. BTW, what do you think the authors of the Standard would have thought about the quality of a compiler that targets quiet-wraparound two's-complement hardware, but will not behave in reliably-predictable fashion if a function like: unsigned mul_mod_65536(unsingned short x, unsigned short y) { return (x*y) &amp; 0xFFFF; } is invoked when `x` exceeds `0x7FFFFFFF/y`?
Fantastic news. I'll never have to deal with you working in embedded.
This subreddit is about programming in C. Web shit is off topic here.
That depends whether which of the following languages one is talking about: 1. The language one would have if, whenever parts of the Standard and an implementation's together define the behavior of an action, but some other part of the Standard says it's undefined, implementations can be expected to process the action as described absent a compelling documented reason for doing otherwise. 2. The language one would have if, whenever parts of the Standard and an implementation's together define the behavior of an action, but some other part of the Standard says it's undefined, programmers must avoid the action at all costs. The first language is beautiful. The second not so much. I don't think the authors of the Standard expected anyone to be interested in the second, but it's the preferred choice of some compiler maintainers.
&gt; You can't use escape code on Windows as example. [Actually, you can](https://docs.microsoft.com/en-us/windows/console/console-virtual-terminal-sequences), but it was introduced in some Windows 10 update.
I don't have W10 and didn't know that. I tought it only worked with WSL. You still can force AINSI sequence anyways with a simple define if you refuse to use the windows color version.
people don't like systemd
for example, when it sends the number 200, why does the function give me another meaningless number?
give all the code. There is stuff not shown. You are starting at the index 1. Dont know if you are wanting to do that.
Please post the entire file. The error comes from the way you call the function, not the function itself. You're probably reading from outside of your array. Also note that malloc function provides you area of memory that is filled with random values. To get zeroed array use calloc instead. That might also be the cause of the error. Also if you're going to work with c you should probably invest your time into learning gdb or other debugger.
I share full code pls help
 #include&lt;stdio.h&gt; #define MIKTAR 10 void KomisyonFiyati( int dizi[], size_t a); int main(void){ size_t i;//Diziye deƒüer atama sayacƒ± int satis[MIKTAR]; for( i=0; i &lt; MIKTAR; ++i ){ printf( "Satis miktari giriniz(10 tane): " ); scanf("%d",&amp;satis[i]); } puts("Elemanlara verilecek para: "); KomisyonFiyati( satis,MIKTAR ); } void KomisyonFiyati( int dizi[], size_t a){ size_t k; for( k=1; k &lt; MIKTAR; ++k ){ dizi[k] = (dizi[k]*9/100)+200; } for( k=1; k &lt;MIKTAR; ++k){ printf("%u Elemanƒ±n alacagƒ± para: %d\n",k, dizi[k]); } return; }
What input are you giving? What output are you expecting? What output are you getting? %u may be the wrong specifier for size_t
&gt;POSIX defines &gt; &gt;such environments &gt; &gt; (though likely less strict than you desire). Note that there are multiple environments given because no single environment admits an effective implementation on all interesting targets. BTW, one thing that's long bugged me about Unix is that its design makes it awkward to have different programs use different sizes of `int` and `long`. One could easily have the same Windows installation run some programs that expect `long` to be 32 bits (as it should be for most purposes) and others that expect `long` to be 64 bits (useful for a few purposes), without having to do anything special because all interactions between the application and the environment are performed using types that are independent of the `int` and `long` types chosen by a C implementation. If one doesn't need to pass va_args pointers across ABI boundaries, there's no need an ABI should need to care about what types an implementation chooses for `int` and `long`, since an implementation should be able to bundle a standard-library implementation that works with whatever sizes of `int` and `long` it's using.
That was our textbook in CSC-101 way back in... 2001, I think?
If you indent all the code another 4 spaces, all the code will be in a nice code block.
This book got my feet on the ground and moving a lot easier than K&amp;R2 did. I took its guide on style to heart, but it's really interesting to me when reviewing modern source, that hardly anyone follows the conventions taught in this book. I still see plenty of abbreviated, cryptically-named variables in other people's source for example. I don't know if it's because they're trying to save keystrokes, but I think it has more to do with people wanting to make code aesthetically pleasing, or revel in their ability to be more efficient and concise. I always found that lends itself even more to being cryptic. People want to save a line or two of code, and it really becomes a matter of patting yourself on the back as a programmer, rather than writing clear code that's easy to understand. In my opinion, your code can be beautifully concise and very compact and clean, but that might not really help people read it more clearly, and it kind of ignores how broad the scope of potential readers may be. The whole idea of writing code as if you were an artist seems to be more about some kind of competition among other coders and programmers, rather than about good software engineering. Trying to avoid clearly-worded comments by "expressing yourself in code" seems to fall into that vein as well. It seems to me that the more *practical* approach is to write code clearly enough that someone who isn't even familiar with the programming language you used, can open up source files, modify and compile it according to their needs. Some code is easier to understand for end users and sysadmins for example; I've had to modify a few packages to get them operational, and it's a lot nicer when the sources is easy to follow, whereas more 'concise code written to impress other programmers might have just left me waiting for the development team to fix the bug in their next release. But I will say that the "comment, comment, comment" ideology does create some problems too. The more comments you have laced throughout, the more you have to pay attention to updating the comments along with the code. I'm the type to write some utility and then not come back to it for years ( literally ) so it's helpful to have comments to easily remember what I was doing, especially because as a I learn more as a programmer, I'm probably not going to keep writing code in the same style. I might look back on something I wrote years ago and say, "Wtf was I doing here?" but with comments it's a lot more obvious. On the other hand, if it's something that I'm working on frequently, and updating frequently, then every time I make a change to a program, having to make changes to the comments to reflect that creates more maintenance work. Basically you end up with as much cruft in comments as you do in actual lines of code, but it becomes much trickier because you don't really have to update the comments for the code to compile and run correctly; you might end up with a function that you've updated several times, but ignoring the comments, and then end up with a lot of comments to clarify how the code *use to* work. Anyway, cool review. It's nice to see someone mentioning this book, as it's basically *the* book that made C digestible enough for me to begin writing useful programs.
First step is admitting you got roasted.
Nice work. I will try it out! Thanks! Sorry for the annoying question but how does it compare to tinc? (My plex server wouldn‚Äôt be possible without it!)
 struct Diceroll d; snprintf( d.name, 50, "Dan" ); d.roll = 4; d.roll_counter = 2;
I get that, but this means I need to create all the variables in advance. How can I just store everything as I go? Is struct a bad way to do this?
That's usually how it's done. If there's a known number of players, you can define an array of structs and keep everything together.
You can use malloc() to dynamically allocate memory as needed if you don't want to create all variables ahead of time.
 struct Diceroll { char name[50]; int roll; int roll_counter; }; typedef struct Diceroll diceroll; struct game { diceroll d[5]; }; typedef struct game game; /* somewhere in main */ game my_game; char temp_name[50]; for ( int i = 0; i &lt; 5; i++ ) { printf ( "Enter name: " ); scanf ( "%s", name ); snprintf ( my_game.d[ i ].name, 50, "%s", temp_name ); /* other variables here */ }
Well Im not the best in C but why not great a binary file that stores data per each individual entry and gives you the option to remove it as well?
I'm really gonna have to analyze this lol. Thanks though, this looks really good.
I'm pretty new to c so I haven't done any of that stuff, but I'll get to that. Thank you for the response.
I didn't know you can make an array of structs lol
I don't know what that means lol I'm pretty new to this. But thanks anyways
Uh well it'll create an external file which your program will keep referencing each time you need to pull something you store in them.
And it's called a binary file?
I believe so.
Looked it up and it's very interesting. I'll check it out more. Thanks
First not my project but I do recommend you check out the author's other projects - they're usually of excellent quality. Looks less featureful than tinc. For example, it's only meant for a single use point to point tunnel to a linux server, but client can be *bsd/linux/macos. Only uses symmetric cipher primitives - specifically xoodoo by joan daemen which has received less cryptanalysis. This means you cannot get perfect forward secrecy - but may not be too important. Works over TCP and potentially solves the [TCP-in-TCP problem](http://sites.inka.de/bigred/devel/tcp-tcp.html) by using TCP_NOTSENT_LOWAT socket option which prevents writes to a socket if the buffer is at a "low water mark." Also since it uses BBR congestion control algorithm, performance might be better than your regular ip over tcp tunnels.
Wrong sub, you might be looking for /r/csharp :)
Alright thx
Cool! Thanks for the detailed response.
Get to it soon, it's a fundamental concept in C.
I wouldn't recommend storing this sort of data in a binary file, unless you want it to persist across runs of your program. When you read it out of the binary file you would still need to allocate memory for the structs, access struct elements etc so this just complicates things needlessly.
I know, I've heard it's what makes C so powerful. If you know of any good resources it would be much appreciated
When is a good time to use a binary file?
Can also use calloc if you want to initialize the entries to zero.
Create a file if you want the data to be in a file. Which generally means that your program is creating the file intentionally as part of its work (e.g. it's a compiler and it is creating the output binary) or it wants to store data that it will be able to read back the next time it runs. Data that just lasts for the duration of your program should be stored in memory.
You can make an array of any type, even functions if you had a valid reason to.
&gt;No external dependencies. Yeah, no. Sorry, but I'm not going to trust unproven encryption code.
Fair stance, just a nitpick, virtually all encryption schemes are unproven, because to prove their security would mean P != NP. But yes, cryptanalysis for now is what i stills trust.
C++ is off topic in this subreddit. The same applies to posts in languages other than English. Please post this to /r/cpp_questions or to /r/programacion/
C++ is off topic in this subreddit. Please post C++ questions to /r/cpp_questions instead.
solo quiero ense√±ar lo que se pero para que me ayuden a prender m√°s
No hablas Espa√±ol.
si hablo espa√±ol
because later on ill be adding code to display flags/opcode to console etc. and ill be adding code to those if statements
So it's like struct Person[10] ?
I see, thanks
I mean, you can do it the way you do with bitsets, it's just going to be really inefficient. Learn some bitwise arithmetic and your code is going to be a lot better.
I don't know what that means but thanks, will look into it
you are forgetting to do &gt; dizi[k] = (dizi[k]*9/100)+200; on the first element. Check the for loop initial value 200 doesn't give a meaningless number for me
I get what your saying, but i cant write the debugger for individual bits if i just do it the way you did, id have to just test the bits in the main loop. i need to test, each, individual, bit. for F, and A.
calloc is a function that does the same basic task of malloc, but initializes all allocated memory to zero. For example: char* buf = malloc(512); Allocates 512 bytes of memory that I can use like I'm accessing an array (or in other ways. You can really do almost anything you want). However, I access the data without making an assignment first, the result is not guaranteed to be anything in particular. Example: printf("%s, buf); Will print whatever was stored at that memory location before I was given access to it. It may not even print anything at all. However if I use calloc: char* buf = calloc(512, sizeof(char)); It is guaranteed to not print anything at all, because all 512 bytes are initializes to 0. Hope this helps.
&gt; I get what your saying, but i cant write the debugger for individual bits if i just do it the way you did, id have to just test the bits in the main loop. i need to test, each, individual, bit. for F, and A. Yeah, that's what people generally do: if (flags &amp; FLAG_F) printf("F flag set"); if (flags &amp; FLAG_A) printf("A flag set"); It's not really any harder than what you do, but it's a lot more efficient since you are also able to treat the flag set as an integer where it makes sense. &gt; either way, i need bitset for the debugger. You know that setting bit `i` in a datum `x` is just x | 1 &lt;&lt; i There is nothing difficult about this.
In C, it would look like struct Person array[10];
You need to actually create a struct to put any values in it. A struct is just a custom sized memory chunk that you can declare for organizational and efficiency purposes. In order to be able to actually add information to the struct you need to malloc() a pointer to said struct (look up malloc and the syntax that goes along with it). After that you should have a pointer to your struct that you can use to add information to it
&gt;It seems to me that the more *practical* approach is to write code clearly enough that someone who isn't even familiar with the programming language you used, can open up source files, modify and compile it according to their needs. Great point. Code should be easy to read and understand. You do that by using clear variable and function names, rather than abbreviations. This book indeed encourages writing clear code. &gt;so it's helpful to have comments to easily remember what I was doing, especially because as a I learn more as a programmer Yes, comments have their place and use. However the 'comment, comment, comment' approach is overkill and bad practice in my opinion. &gt;It's nice to see someone mentioning this book, as it's basically *the* book that made C digestible enough for me to begin writing useful programs. Thanks for your reply. It's nice to read that others also studies this book and benefited from it. I was wondering in which year you read this book and what books or sources you then studied. And do you still (mainly) program in C? Professionally or as a hobby?
That only applies to structs allocated on the heap (dynamically). OP does not "need to malloc()" anything.
If he wants to pass that struct through any other functions he likely should. He doesn‚Äôt need to if he wants to run it solely in a main function but he gives no mention of context
I'm a bit in the same boat as you. My plan is to just try code a little every now and then. Contributing to a free software by mid 2020 sounds like an awesome goal :) I might try to go for that myself actually. But why wait with contributing til 2020? I know I read an article a couple of years ago that said a lot of projects do have "first time contributer"-tags on some of their issues. The worst thing that can happen if you contribute is getting bad or none feedback. But you should be able to still learn a thing or two :) The hard thing would be to find good projects to start with I guess. &amp;#x200B; I can't find the article anymore, but I found this [https://github.com/topics/first-timers?l=c](https://github.com/topics/first-timers?l=c)
 #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;stdlib.h&gt; struct node { int counter; char roll; char *name; struct node *next; }; int main(void) { struct node *head, *current; head = current = malloc(sizeof(struct node)); char buffer[256] = {0}; char c = '1'; for (int i = 0; c != '0'; i++) { head-&gt;counter = i + 1; printf("Name:\n"); fgets(buffer, 256, stdin); head-&gt;roll = rand() % 6 + 1; head-&gt;name = malloc(strlen(buffer) + 1); snprintf(head-&gt;name, strlen(buffer) + 1, "%s", buffer); printf("Press any key but 0 to continue"); c = getchar(); head-&gt;next = malloc(sizeof(struct node)); head = head-&gt;next; } head-&gt;next = NULL; while (current-&gt;next) { printf("[ %02i ]\t-&gt;\t%i\t-&gt;\t%s\n", current-&gt;counter, current-&gt;roll, current-&gt;name); head = current; current = current-&gt;next; free(head-&gt;name); free(head); } return 0; } Something like that should do it, the middle part is a bit fucked with the out-/input &amp;#x200B; That's how you'd do it with structs
In my opinion, either something is missing alongside your code or I didn't understand it correctly, but from what I see here when you've got a message sent by either device A or B you don't actually convert anything: - When the message is sent by the B device, its 'command' field is first converted as a DA_CMD_X, and then immediatly after it is converted back to DB_CMD_X, before the translation was used anywhere - When the message is sent by the A device, you don't translate anything and you use the fields of the structure as they are
Thanks mate.
The translation is only used to select the correct case statement in the message handler switch statement. I added a couple of functions (do\_function\_1(); and do\_function\_2();) to clarify. Note these are independent of the command value so if it happens before or after the conversion it doesn't matter.
Okay, so instead of converting 'msg.command' in the first 'if', can't you use the 'command' variable to store the value, so you don't have to convert something back ?
You are forming definite statements ("need to", "have to", "should"), based on far reaching assumptions. Nobody said anything about functions and nothing in the code example tells us they will be needed. Also, you don't have to pass a struct by pointer. Function will work just fine with a copy. Even when you are passing struct by pointer, you are not forced to actually allocate the structure on the heap.
I'm not certain about Cairo rendering natively to OpenGL, but there's nothing stopping you rendering to a pixel buffer with Cairo, then uploading that to an OpenGL texture and rendering that way.
You're probably unaware of that, but dividing two integer values gives you result truncated to whole numbers. So you change change: `dizi[k] = (dizi[k]*9/100)+200;` to `dizi[k] = ((float)(dizi[k]*9)/100)+200;` to get proper result.
Balls. I've realised that my problem is slightly different to what I wrote above. I need to send any messages from DEVICE\_A to DEVICE\_B, and vice versa. Thus a conversion one way or another must always take place. I've updated the OP
You want to separate your wire representation as much as possible from your business logic. I work, among other things, with a wire protocol, that exists in two different version, which for all practical purposes is your setup. We strive to keep the frame data as isolated from the rest of the system as possible, so we code roughly looking like this: switch (rxframe.cmd) { case CMD_FOO: if (protver(rxframe.src) == 2) { do_FOO(rxframe.data &amp;&amp; FOO2_mask_frobnitz, rxframe.data &amp;&amp; FOO2_mask_moonphase &gt;&gt; FOO2_moonphase_shift); } else { /* We will never get anything else than version 3 otherwise*/ do_FOO(rxframe.data &amp;&amp; FOO3_mask_frobnitz, WAXING) /* Version 3 standardized to one cauldron for all phases. */ } } ....
üö® üëÆ‚Äç‚ôÄÔ∏è stop right there sir this is the C police. Did you give a suggestion on how to do something and I DISAGREE? Now I must waste everyone‚Äôs time by showing my üìö i m m e n s e k n o w l e d g e üìñ
Dear C police, please read my comments. I pointed out that solution provided in a comment applies only to structures allocated dynamically, where comment suggested it's the only way to create a structure, which is not true. My corespondent then clarified, that it is needed when structure has to be passed to a function, which is also not true, because OP can pass an address of a stack-allocated structure (like `function(&amp;structure)`). Dynamic allocation is a **possibility**, not requirement. That is all.
I made [this post](https://www.reddit.com/r/C_Programming/comments/cep9zl/c_skill_tree_visual_guide_for_c_resources/) for a map of suggestions of where to go in C. The [first post](https://www.reddit.com/r/C_Programming/comments/cep9zl/c_skill_tree_visual_guide_for_c_resources/eu426vf/) got buried, but it contains some suggestions and resources for where to go after finishing the basics. You can also try reading the replies to see if there are any tips there.
Thank you!
Edit: changed need to could üëç
Now it's OK :)
ü§ù
&gt; How much hours daily should I set aside for learning? Rather than measuring in hours, measure in progress. Go through a section of The C Programming Language and do the exercises from the book. Try to understand why the code does what it does, and turn to Google/DuckDuckGo if you have to. Do that until you understand the content. Obviously if you're still not understanding it after a couple of hours, take a break and return to it the next day. Maybe find a different resource for the topic and then return to the original from a new perspective. You won't always get everything instantly, but if you focus on learning the material rather than filling a time quota you'll do a lot better.
Translation via a table \[2\]\[NUM\_CMD\] for each physical command and maybe another to map incoming message to logical command?
No, we will not. For the reasons given in the comments. Your question is up for closure and that will, hopefully, occur quickly.
I'm doing the same thing. I'm at an intermediate level interns of language proficiency. My goal is to become a contributor at VLC by the end of 2019. The VLC codebase is huge and I'm trying to learn it bit by bit, solving issues along the way. Currently I'm practicing my C skills by coding shells, and working with Linux API. If you want, we could stay in touch and help each other on our goals. :)
https://github.com/0pb/macroColor/blob/master/macroColor.h#L45 Don't name this function "test" And you can just use a scope, thus `hConsole` could be defined more than once in the same function. I feel uncomfortable with your "colorAbove" thing, what's the purpose ? Rememberthe previous color ? Why only one ?
My goal is Linux kernel, it was when I started 4 years ago. I am not sure if I can understand even a bit of it by mid 2020. Maybe I should try VLC.
Thanks mate!