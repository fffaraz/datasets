(:
@beerdude26 another great idea! Thank you! how familiar are you with Docker containers and Haskell? 
@hallbrett Let's talk about this, maybe we can help you out somehow to finish it and then making it into a tutorial. 
/u/bss03 convinced me that I really don't want to try that at this time. I still feel like there might be better ways of conveying this stuff, but I certainly wouldn't try publishing something that doesn't elicit consensus from both experts and novices that it's actually an improvement over existing material. 
I found P.Wadler's "The essence of functional programming" paper http://homepages.inf.ed.ac.uk/wadler/topics/monads.html to be a most effective read. No metaphors, no burritos, no bulls++t, just gradual buildup of understanding using a concrete, recurring example.
Physician drink your own medicine. GP intuits correctly that the blog post is written from a math-saturated perspective, however much it attempts to shed its erudition and level with the reader. It's no secret that Dan Piponi has a Ph.D. in math. And it shows. There is ample space for other narratives, and GP has provided one that'll help even more people understand the concept. There is ample room for people to pitch in the effort to make haskell for all. 
I recently dipped my feet in Haskell. Naturally, I ran into the "What on earth is a Monad" problem pretty quickly as this word keeps popping up all over the place. And seems to be something you need to understand to be able to write Haskell programs. I have recently been told that's not really the case though... still working on it. To understand Monads you need to understand Functors (which are like Lists?!? but what's the difference?!?). So I came across this picture-based explanation of those two concepts. The one you linked above. In all honesty, as someone with *no* background in Mathematics, this post actually made it *worse* for me. After reading it, I think that - so far - all of my understanding is completely off. And it did not help. I would *love* to see an article explaining Monads using hands-on examples. Things I can *try* in ghci.
Let's see. Acid State (the library, not the concept) is pretty unique and I don't recall seeing any data store that makes quite the same engineering tradeoffs. HLean, as I understand it, can do certain important important statistical and machine learning operations much, much faster than the competition by exposing certain mathematical properties in the API and the Haskell web frameworks have type safe links which are quite funky. But you seem to be interested in gamedev? Honestly, Haskell might not be the right tool for the job there at least for the graphics (maybe Rust for that kind of low level programming?) Although for game logic and game state management, especially across a network, Haskell may well be interesting. A common and very difficult to debug problem in multilayer environments desync bugs. If you wrote your game logic in Haskell you'd be able write it in such as way that it's provably completely deterministic, encapsulated (using, say the ST Monad), and independently testable. 
It is such a fun learning experience. It's like learning to program again except this time without the self loathing : P
[PS: It might help to see these things in more familiar syntax](https://blog.jcoglan.com/2011/03/05/translation-from-haskell-to-javascript-of-selected-portions-of-the-best-introduction-to-monads-ive-ever-read/). But honestly, the best, best way is to study some examples. Try using the &gt;&gt; and &gt;&gt;= operators on some Mabye values in ghci and write some IO code with do notation (then try with &gt;&gt; and &gt;&gt;=).
Absolutely zilch (Docker containers, that is). That's why I'm very interested in an example :)
&gt; PS: It might help to see these things in more familiar syntax. Bookmarked! (So many bookmarks...) &gt; But honestly, the best, best way is to study some examples. Yes. 
Perfect, that is exactly how it should be. Thanks for the update.
Ah, thanks for the clarification!
I use spaces to indent so my code is aligned, if character size changes then the number of spaces needed to indent changes for each function, therefore things that were aligned using my previous indentation are now not aligned eg in my example if the character of 'a' in this new font is wider than the space character (which is not unusual) then it means my old indentation would now lead to unaligned code. Is that clearer :)
All language is metaphor, but what a monad 'is' is what it does. More helpful, perhaps to trace the uses and interconnections than to imagine a hidden essence ? Get them by their morphisms and their objects will follow ? 
&gt; You can see that even by considering plain-old fmap vs map: it's harder to read "fmap f . fmap g" than "map f . map g" because with the former you're having to manually search for more information about what Functor is being used in each case. What? The precise reason for using Functor is that I *don't* have to worry about what the exact data structure is. I'm even in favor of renaming fmap to map, which is much more radical than the FTP proposal. This is what's done in Idris (you can type ":t map" in the repl and see it has type "Prelude.Functor.map : Functor f =&gt; (a -&gt; b) -&gt; f a -&gt; f b"), and I find it immensely more ergonomic. It just makes so much more mathematical sense. I think Haskell messed up by not doing it the Idris way originally (to be fair, Idris had the extreme advantage of hindsight). FTP is just a step in the right direction.
As the author of the tutorial in question, I absolutely agree. It's not a good standalone tutorial for beginners (and arguably not a tutorial at all). It doesn't provide motivation for monads, and it doesn't provide sample usage of the monadic interface. I might have thought that it was a good standalone tutorial for beginners when I wrote it. I certainly don't now. It's really more of an intermediate resource for solidifying existing intuitions with a more precise understanding of what the Monad abstraction is.
&gt; and '.' is a great starting point Pun intended? :-)
`flatMap`gives a wrong intuition (value in the box) which doesn't work well for continuations or parsers etc. Even worse, if you have: data Triple a = Triple { t1 :: a, t2 :: a, t3 :: a } instance Monad Triple where return x = Triple x x x Triple x y z &gt;&gt;= f = Triple (t1 $ f x) (t2 $ f y) (t3 $ f z) `flatMap` give even totally wrong intuition. (`Triple` is computing three values in parallel, a bit like `ZipList`).
Heh; no. (: But that reminds me of the day when one of my high school math teachers introduced the notion of function composition; he wrote on the chalk board: f(g(x)) == f ○ g (x) ... and then said, "puts you in a bit of a fog." I guess we could say that &gt;&gt;= might put your brain in a bit of a bind. (:
`forM_` with `Maybe a` is occasionally useful.
This just increases my dislike for `Foldable`.
&gt; This cannot be a good thing. Why is that? Sure, there are some examples that compile and have unexpected behavior, but they don't seem to me as particulary practical. Also the same could be said for many other type classes. Is there some evidence for easy-to-do-wrong cases which are likely to occur in practice? As it stands, the argument sounds more like an emotional reaction.
The part I like about the proposal, is that instead of remembering a lot of similar concepts (i.e. mapList, mapTree, ...) I can just remember one abstract concept, which also has lesser rules to remember. If I add a new data type which satisfies the rules I get a lot of stuff for free. On the other hand, this means that it is harder to get a good intuition about the concept in terms of examples, because it applies to much more things, as it can be seen in the case of `concat`. Also as you've already mentioned, one expresses in less detail (or rather less locally), what the code should do, unless one adds explicit type ascriptions, i.e. `(fmap :: (a -&gt; b) -&gt; [a] -&gt; [b]) f xs`, which at least in this example have a too heavy syntactic overhead for me to be practical. So I'm still undecided, whether I like the overall effects of the proposal or not. I also haven't thought enough about how a better module system could improve the situation and maybe make another direction even more attractive. edit: Maybe some sort of syntactic sugar to fix type class instances with type ascriptions might be useful, i.e. `(fmap :: f = [])` or even `fmap^[]` instead of the before mentioned `(fmap :: (a -&gt; b) -&gt; [a] -&gt; [b])`. This would of course not fix the problem with `concat` since `concat^(,)` would still behave the same. But maybe the problem here is that `concat` is not the perfect name for the list concatenation generalized via `Foldable` or that the tuple type can be interpreted as either a value with context (writer applicative), for which the function's semantics actually makes sense, or as an ordinary tuple, for which they do not.
Wow, both of those are surprisingly ridiculous. What is even going on there? Both of these are rejected by the Idris repl. I wonder what they're doing differently?
Plain and simple: more code would compile, most with completely WTF result. And all those WTFs you'd have to learn by heart. Maybe someone will love it, but I'd rather not go there.
`(,) a` has a `Foldable` instance, that is the single `b` in `(a, b)` is considered "a list of `b` that `(a, b)` contains". Thus `length ([1,2], False) = 1` (there's exactly one `False`) and `concat ([1,2],[3,4]) = [3, 4]` (the result of "concatenating" the singleton second component).
This is rather an example of a "bad" instance of a type-class rather than overall bad thing about generic functions. For me, another example of such a bad thing is a Monoid instance of a HashMap, which, upon collision, takes an element from first hashmap (and drops one in second). I had lots of bugs because of this, while this has nothing to do with FTP. I'd just say that some instances of type-classes are bad and harmful, and there's rather a need to be able to disable these somehow, at least I'd use a feature like that.
&gt; most with completely WTF result What evidence do you have to justify the "most" here?
`Control.Lens` is a much more principled approach in my opinion. It doesn't pretend there is a single distinguished fold or traversal for any give datatype. These days I never use `Foldable` or `Traversable`. import Control.Lens traverseOf _Just :: Control.Applicative.Applicative f =&gt; (a -&gt; f b) -&gt; Maybe a -&gt; f (Maybe b) traverseOf _Right :: Control.Applicative.Applicative f =&gt; (a -&gt; f b) -&gt; Either c a -&gt; f (Either c b) forOf_ _Just :: Control.Applicative.Applicative f =&gt; Maybe a -&gt; (a -&gt; f r) -&gt; f () forOf_ _Right :: Control.Applicative.Applicative f =&gt; Either c a -&gt; (a -&gt; f r) -&gt; f ()
Sometimes a good paper is better than a tutorial. hardly surprising, but always worth mentioning.
Strange concept of "Working programmer". Some people learn best by examples, some by understanding the structure. Every of those group has a big intersection with professional programmers.
Are there any links for the two papers mentioned?
&gt; This is rather an example of a "bad" instance of a type-class rather than overall bad thing about generic functions. Do you think the `Traversable` instance for `(,) a` is bad too?
Not to be down on you, OP, but... how did you get this far in haskell (or programming in general) and not discover this? To me, a basic understanding of lambda calculus seems almost like a prereq for having a strong grasp on haskell. It's definitely possible that, since I'm already aware of this, it seems more obvious to me. Just curious.
Another big danger is that you may realise that now some of the more specialised combinators/functions on `Either`/`Maybe` like `maybeToList` (or a couple of others you may have been missing, such as `whenJust` or `whenRight`) can be expressed by `Foldable`/`Traversable`-verbs... I'm also quite happy about `Data.Bifunctor` having been moved into `base` allowing for even more of such cases to be covered by the standard vocabulary provided by `base` instead of having to learn and memorise yet another set of redundant functions.
While I too consider the `HashMap`-instance a bad idea, the `(,)` instance, however, seems consistent with the `Functor (,) a` instance... or is that a bad one too?
To add to this, a type-signature `:: Functor f =&gt; f X -&gt; f Y` for a function gives you more information than one with `:: [X] -&gt; [Y]` in some way: when applied to e.g. a value of type `[X]`, the `Functor`-generalised operation will preserve the length of `[X]` for the new value of type `[Y]`.
Fwiw, there's also `GHC.List` which existed already before `base-4.8`. So you can in theory write code that works w/o CPP unless you happen to need a list-specialised version of `{min,max}imumBy`, `find`, `mapAccum{L,R}` (as those aren't exported list-specialised currently via `GHC.List` nor `Data.List`)
On a side note, are you aware of pointfree style? A lot of your code can be written more succinctly (IMO). {-# LANGUAGE RankNTypes #-} type WFull a b = (a -&gt; b) -&gt; b type WSame a = WFull a a type W a = forall b . (a -&gt; b) -&gt; b wrap :: a -&gt; WFull a b wrap = flip ($) --because wrap x = flip ($) x = \y -&gt; y $ x = ($ x) unwrap :: WSame a -&gt; a unwrap = wrap id --because unwrap x = wrap id x = flip ($) id x = x $ id = x id apply :: WSame a -&gt; (a -&gt; b) -&gt; WFull b c apply = (wrap .) . wrap . unwrap --this one is harder to explain. --((wrap .) . wrap . unwrap) f x = ((wrap .) . wrap . unwrap f) x = ((wrap .) . wrap (f id)) x --((wrap .) . wrap (f id)) x = ((wrap .) ($ (f id))) x = (wrap . ($ (f id))) x = wrap . ($ (f id)) x --wrap . ($ (f id)) x = wrap . (x $ (f id)) = ($ (x (f id))) = wrap $ x (unwrap f) composeArgs :: (a -&gt; b) -&gt; (b -&gt; c) -&gt; a -&gt; c composeArgs = flip (.) --because flip (.) x y = (.) y x = y.x composeFunc :: WSame (b -&gt; c) -&gt; WSame (a -&gt; b) -&gt; WFull (a -&gt; c) d composeFunc f g = wrap $ (unwrap f).(unwrap g) --I can't think of a nice pointfree version.
&gt; To me, a basic understanding of lambda calculus seems almost like a prereq for having a strong grasp on haskell. You can learn hask from programing it and looking at examples like any programming language. I think it is a little easier with haskell even since haskell follows a more mathematical structure than most programming languages. So it seems likely if you learn haskell first you would pick up on the concepts of lambda calculus but not know what they are called.
That definitely is a big danger. `maybeToList` clearly explains to readers of my code (human or machine) exactly what the intermediate types are in my expression, and strongly hints of *why* I'm doing it. I would never want to replace `maybeToList` by a generic combinator. Type-specialized `maybeToList` is one of the most powerful tools for writing clear, maintainable, bug-free code. That's the power of Haskell - the ability to use types for razor-sharp semantic preciseness. Why are we weakening that?
Which is why a change like this needs to be done more gradually, with a chance to try it out first, and only finalize after achieving a broad consensus in the community.
Yes, it's bad too IMHO. We have newtypes for this kind of thing (see Sum and Product instances of Monoid).
&gt; instead of remembering a lot of similar concepts (i.e. mapList, mapTree, ...) I can just remember one abstract concept, which also has lesser rules to remember. No. First of all, it's not a *lot* of concepts - just a few, for the most fundamental types that represent fundamental semantic concepts. Second, the concepts are not the same. Each combinator expresses something different. The fact that each is a specialization of a common more general combinator only shows that they have *something* in common, with that something usually not all that important or interesting. The potential generalization is only interesting if you really think that this same code will need to be shared at different types, which at least in application code is quite rare.
The way I see it, /u/0wx has already written a blog post's worth of comments with strong opinions about the right way to write a monad tutorial. At that point /u/0wx might as well write the very specific tutorial they have in mind.
In compiled code, GHC optimizes `product` and it runs in constant space. That may or may not happen for more complicated uses of `foldl` though.
&gt; `(,)` a has a `Foldable` instance That's the real problem. I understand why it's there. I understand that it is the only possible instance, or close to it. However, it turns programmer mistakes that should be type errors into runtime value errors. That's one of the near-universal risks of generalization. However, with the way tuples are dealt with in several other mainstream languages, this mistake will be quite common in the current environment and should probably be given enhanced consideration. I think it would be better for this instance to be moved to a newtype wrapper (or similar) in a base or platform library. I recently used this functor and called it `Annotated`, but I also didn't search for existing names it might be under.
&gt; sometimes it really helps comprehension to do know the exact type. Yes, and isn't that what type annotations are for? Why have different names for specialized forms of generic operations to indicate what type they operate on when the language has a way to say directly "this is the type of that thing"?
Link is dead for me.
I think the most compelling argument from the post is that type classes without laws are hard to reason about. If I write code like: length = Data.Foldable.foldl' (+) 0 ... I don't really know what that does without inspecting the instance of the type I apply it to. I cannot reason abstractly about how `length` works and interacts with other functions. However, I don't mind generalizing something like `map` to `Functor` because the laws for `Functor` succinctly capture all the necessary properties that `map` should obey in an abstract instance-independent way. In reality, `Foldable` may have some useful laws, but I think the gist of the post still stands if you generalize it to lawless type classes.
It is just the Writer monad. 
This morning I re-listened To ekmett talk about lens on the Haskell Podcast, and I think he provided a good answer to why he chose Haskell. After about 15 years of programming and trying to solve problems he found that Haskell had better answers to all of the questions he was trying to solve. That to me is the reason -- Haskell has better answers to programming abstractions than other languages out there. It is also a gateway to some more interesting concepts in Dependent Types, but also has a great power to weight ratio. For me, Haskell gets to the essence of programming and because of that it is a great language to learn even if you will never use it in the real world (even though you can!).
OK, maybe your ideal post is what you get by removing the first paragraph from "You could have invented monads"...
&gt; This makes me think that I still don't understand it enough Do you understand the Monad instance for `(-&gt;) e` or the `Cont` Monad? At the bottom, you have to use pattern-matching for any sum type. In Haskell, you also have to use it for newtype wrappers. I generally think of `(&gt;&gt;=)` implemented in term of other functions, not pattern-matching directly, but maybe that is just hiding the pattern-matching. It is interesting to think about `(&gt;&gt;=)` in a case when pattern matching isn't allowed at all `(-&gt;) e`.
Because that's quite possibly one of the reasons this survey came to be. If someone has a strong case why FTP is not good in the current state and only got involved during this survey, that case can change the outcome.
Not quite. It doesn't have the Monoid constraint, so it can't be make into a (law-abiding) Monad. I *specifically* chose not to use the Writer monad, because I wanted the (implicit) monoid to be free. So, I used the free monad transformer for that annotated functor.
Spack has the recursive dependency versioning that you'd need to get nix-ish package management. One thing it needs at the moment is a more general notion of a build dependency. It has this for c/c++/fortran compilers but it could stand to be extended to support Haskell. Easybuild also sort of has recursive versioning but it requires an easyconfig per combination, so composing packages in new ways requires a lot of hacking.
So you think the post makes a compelling argument to remove `Num` from the Prelude? ;]
Your question is best answered by yourself given that only you can determine how to best use your time. 
I think Num should be replaced with Semiring
[The `formatting` package](https://hackage.haskell.org/package/formatting) makes excellent use of this trick to implement type-safe string formatting.
A couple of months ago I came to `#haskell` to ask why I couldn't mapM_ over a `Maybe` and was then promptly pointed to `Data.Foldable`. Considering myself a noobie, it definitely felt natural to me.
Oh, I would *love* to see the community reaction to a concrete proposal for doing that. Not that I disagree with you, mind.
[Remove the trailing slash.](https://blog.jcoglan.com/2011/03/05/translation-from-haskell-to-javascript-of-selected-portions-of-the-best-introduction-to-monads-ive-ever-read) Weirdly it adds the slash back when I hit that link. Edit: double weird. Maybe it's just refreshing? :|
How broad of a consensus do you think we need? 80%? 90%? 99?
There is always a tension between concretions (which are easier to perceive) and abstractions (which are easier to reason about because the problem is distilled to its essential parts). Haskell is already not at the top of anyone's list for being easiest to pick up.
:)
&gt; vl lenses To me that sounds like a topic that is quite far into Haskell.
No. As far as I can tell it was a comment saying that beginners to Haskell will also ask those other questions. I guess the argument is that beginners will be asking about pure functions and they are obviously a Good Thing tm. So just because this proposal steepens the learning curve of Haskell doesn't mean it's bad. It was worded in a pretty facetious manner really and I don't think the argument really holds. Just because some of the things beginners get stumped by are there for good reasons doesn't mean all are.
As far as I know the order of the import list does not matter in Haskell until this point. Do we really want to give this up for the mere convenience of not having to list symbols? Not to mention the havoc this could wreak if anyone added symbols to a module's export list if it is imported in this way (and consequently the inability to even add new symbols in changes that try not to break existing code).
As soon as you have a type error you have to worry about it and then you need to try to do the type inference in your head to figure out the intermediate types so you can fix your error.
Type annotations are very clumsy to use in `.` pipelines. You will often have to specify the type of more things than you want and you will have to bracket the expression awkwardly with parentheses.
That's pretty verbose though (`forOf_ _Right` instead of `forM_`). If that's the way, then I might prefer the specialized functions the author of the blog post prefers (`whenJust`, `whenRight`)... I fear that this kind of style makes code pretty hard to read, since it obscures what's really going on with 'type annotations' (`_Just` etc).
You probably want to use `:seti -XFoo` rather than `:set -XFoo` in your `.ghci` (the former only affects what you enter at the interactive prompt, while the latter also affects files that you load into ghci, like running `ghc -XFoo` on them would).
The `Foldable` instance alone is pretty stupid, yes. The `Traversable` instance less so, since it expresses a relationship between two `Functor`s. I am opposed on general principle to leaving out canonical instances for types and classes coming from the same package because some people will (legitimately) want them to exist. Orphan instances are bad enough when they're a necessary evil to preserve sane package dependencies, choosing between that or using a gratuitous newtype in order to define the one sensible instance is very irritating. And all of that goes double for `base`.
Even if it is, the user who typed that code (perhaps in error) didn't necessarily intend for it to be the writer monad.
One sad thing is that there is a paucity of showing how real word code would be affected for better or worse by the proposal :(
Oh, yeah, why the heck isn't the Wikibook in the sidebar here‽ EDIT: It's on the sidebar now!
Thanks! I never noticed that option.
Why do you need it to be fast? How fast? What's your application? You might want to look into /u/tekmo's [Morte](http://www.haskellforall.com/2014/09/morte-intermediate-language-for-super.html) or some of the dependently typed languages ([agda](http://wiki.portal.chalmers.se/agda/pmwiki.php), [idris](http://www.idris-lang.org/)), which (sometimes) need to fully reduce their proof terms.
[Philip Wadler, Comprehending Monads](http://ncatlab.org/nlab/files/WadlerMonads.pdf) [Mark Jones and Luc Duponcheel, Composing Monads](http://web.cecs.pdx.edu/~mpj/pubs/RR-1004.pdf) 
I think after you've covered higher-kinded types and type-classes (Applicative, Monad, Traversable), VL lenses are already possible.
And nor would I. But, if the explanation for why a screwdriver would work better had begun with a discussion of how the strength of materials arises from quantum mechanical effects I wouldn't be in the least surprised that it wasn't effective.
Are you arguing that `for_` and friends are terrible for readability? We use it at work a lot, and have never encountered problems. For example: maybeUser &lt;- lookupUser uId for_ maybeUser $ \u -&gt; sendEmail u passwordReminder or whatever (that's a fake example, but representative of what we do).
I wonder how many were disappointed when they realised that blog-post wasn't about security flaws in the file-transfer protocol... ;-)
I'm surprised no one posted http://dev.stephendiehl.com/hask/#monads
I wouldn't be surprised, either. But if someone is building things professionally, I *do* expect more from them than to wait around passively absorbing explanations. And if they're still pounding away with a hammer a year later I'm going to have a very low opinion of their skill as a professional, regardless of how bad the explanations they received were. To leave the land of hammer analogies, obviously making the jump to something like Haskell is a much bigger deal and a less obvious benefit. But there's still the fact that, for example, there are alleged professionals who defend the existence of null references in mainstream languages without being laughed out of the industry. So my opinion of mainstream software development is about as low as it can get even without Haskell being in the picture.
It's fine of course as long as `maybeUser` really is a `Maybe User`, but now you're relying on an unchecked property of your program (that the human-readable type in the name of the variable matches the type the compiler thinks the variable has). If you had a bug where all of your users were getting password reminder emails simultaneously, how sure would you be that this code was not the culprit? That kind of readability is important too.
I see your point, but I must admit I am rather puzzled: are there criteria for determining when using generic combinators is acceptable and when it is not?
For things you have to be creative to consider collections, yes.
Still 404 for me. :(
Depends on how flexible you are with the meaning of "flattening". I think the intuition that it is meant to build is that no elements are lost, and that's not true with the Monad instance above.
&gt; The fact is that a number of leading members of the community were totally unaware that this was going to be pushed through in such a disruptive way. That is their own fault. I'm a mere hobbyist and it's *not* difficult to keep up if you just use a decent mail reader or GMANE + your preferred NNTP reader. It's insane that some members of the core libraries committee weren't aware of this. What the hell were they doing on the committee if they weren't prepared to keep up with community goings-on? I'm sure that the committee itself could stand to improve internal communication if such a (relatively) big thing went unnoticed by at least one member, but in the end people are responsible for their own actions (or lack of actions). Coming in after the fact and calling a new vote is a violation of the trust that was originally put in the very committee that they were supposedly serving on. &gt; In my opinion, the best would be if it were possible to turn FTP on or off in 7.10.0. That way it can be delayed for a time without bitrotting the work that has already been done. No. That's just incrementing "n" in the 2^n number of ecosystems out there. That would *not* be helping. (Yes, this comment is perhaps overly harsh, but goddammit this kind of politicking pisses me off no end.)
I like this approach for things that can't be made Traversable, because they're monomorphic etc. However I think for types that can be Traversable, the instance is always quite intuitive. 
&gt; for types that can be Traversable, the instance is always quite intuitive What should the instance be for data Tree a = Node a | Branch (Tree a) (Tree a) Why is that more intuitive than its reverse?
You can be more verbose without also becoming more explicit. This needless verbosity should be avoided. But, anytime you are more explicit you will become more verbose; it's unavoidable. Is this needless verbosity? Can you `traverseOf _Nothing` or `forOf_ _Left`? If not, I think there is some needless verbosity.
Other than the fact that a 301 (moved permanently) is produced when the page is requested with no slash, and both work with wget I have no clue what is going on.
If someone had they could have posted it on the list before we even got to this stage. 
&gt; it's a label for what's there not a description of what it will become You see this a lot in DSLs, too. I think mostly it's an "abuse" of syntax to make code "easier to read". I still like `pure` better than `return`, but that's because I expect `return` to adjust control flow.
Sort of. I'm not sure that traverseMaybe f m is so much clearer than traverse f m :: Maybe _
I agree that I doubt I'd ever *want* the `Foldable` instance for `(,) a` specifically, only in relation to `Functor` and/or `Traversable`. Then again, that's mostly true of `Foldable` as a whole. As far as I know it's just for pairs. Arguably every tuple type should have similar instances, since `(a,b,c)` is not equivalent to `((a,b),c)`, but eh. Larger heterogeneous tuples are rarely what you want anyway.
Now imagine `maybeUser` is actually some long list due to an error.
I appreciate your nuance. As I've said in other places I think forOf_ _Just $ \u -&gt; ... strikes an excellent balance betwen genericity and specificity.
The problem is there is no path that gets us there that doesn't silently change the semantics of a very large amount of code. Also, `Monoid v` is still wrong constraint there as well. you only need a `Semigroup`, the unit is never employed.
So you think type classes without properly formalized laws but with great intuition are not worth it? I still think vaguely reasoning about code is a bigger win when writing software in Haskell than exact reasoning and having strong formalized guarantees.
I guess I'm naturally creative then... considering `Maybe` (or `Either whatever`) as a box that either has something in or doesn't isn't particularly creative to me. But maybe I've just been doing this for so long.
My favourite is 3d) use type application to say what you want: type List a = [a] fmap@List f
Maybe it's just me, but I found javascript's syntax distracting with respect to understanding the core concept. Even in not knowing Haskell (previously), I found the tutorials explaining various type classes (including Monad) *in* haskell much clearer than the transliterated ones (I've seen them in Python, Javscript, and CSharp for example).
The problem one quickly runs into here is what happens when there is more than one type variable involved. (In fact, even the type of `fmap` contains three type variables `f`, `a` and `b`, though in this case `f` can be distinguished from `a` and `b` by its kind.) If I write `for_@[]`, is `[]` the `Foldable` variable or the `Applicative` variable?
Yes, `&gt;&gt;=` is not a composition operator, it’s an application operator.
Type application has all sorts of unfortunate effects. Once you apply two terms the order of the type variables in the result is pretty much a jumbled mess. You need to be aware of deep internal properties of the typechecker which are in constant turmoil to know which one becomes the next argument. Consequently, I remain skeptical of the ultimate effectiveness of the explicit type application work that is underway, but I would love to be wrong about that.
In Scala, `Either` is not a functor-ish or monad-ish. It has, however, two projections for left and right bias. That makes sense. As you said, MaybeWithError is much more honest and the bind action makes sense. A general two-tuple? No way. As /u/zarazek said above, Sum and Product newtype which instance Monoid makes much more sense.
I'm liking lenses more and more. Does this work for things that are Foldable but not Traversable though?
Being from Ulster, yet another interpretation of the initials naturally predominates in my mind.
Users are hit with the same issue the first time they `fmap` over a tuple and get an unexpected result. Then they chase the result through the types and learn it does the only thing it ever can. The `Traversable` instance for `(,) e` does the only thing it can. It is completely determined for the same reason the `Functor` instance is completely determined. The `Foldable` instance follows suit. Haskell's typeclasses form a good set of questions you can ask about a given data type. If I sit down and write a data type down, the first thing I ask myself before I even consider their full ramifications is "is this an instance of Functor? Applicative? Monad? Foldable? Traversable? Alternative? MonadPlus? Comonad? Category? Arrow?" etc. If so, is it such in more than one way? By the time I'm done, I know my data type pretty well, and I'm ready to write down combinators for any of the things not entirely encapsulated by these standard classes and the available out-of-the-box vocabulary. _Not_ having the `(,) e` instances is asking for users to provide orphans whose behavior is completely determined. Every such orphan will be exactly the same code. It makes a value judgment out of a thing whose behavior is completely determined, and which is needed for certain situations. It ensures that users who _do_ find the need for this abstraction are then stuck making orphans that needlessly collide with the orphans from other users who need the abstraction. It denies a teaching opportunity to learn something about the nature of `Foldable`, it makes people think that `(,) e` is somehow different. In both of your examples the user stands to learn something about the nature of `Foldable`, about type signatures and about the laws at hand, just as when the user tries to `fmap` to change out the contents of both sides of a pair.
I thought (source being Edwin Brady on a podcast?) that Idris typeclasses had no laws because there was too much pain in proving them. which negates the benefits of dependent types. is this true? maybe it was just for monads. I should take another look at Idris.
Foldable needs an argument of kind `*-&gt;*`, so the natural choice for `(,)` is `Foldable ((,) r)` similar to both `Reader` and `Either`. You can flip the order of the parameters to get the equivalent instance for the first parameter, but this is usually newtyped. In other words, `(,)` is a type function with kind `* -&gt; * -&gt; *` and the natural way to get something of kind `* -&gt; *` is to apply the first argument. This is consistent with the way function application works at the term level.
Maybe this doesn't directly answer your question, but I thought I'd weigh in as someone who also started out in C/C++, Java and Python. For me, the gap between, say, C++ and Java was *much* smaller than the gap between C++ or Java and Haskell. Sure, C++ and Java are very different languages, have different memory management approaches, different syntax, etc., but many of the same concepts and high-level methods are portable directly between them. Haskell was like something completely new, and required a substantial re-think in terms of how I approached writing code. Only in retrospect can I really conceptually unify Haskell with other languages. Basically, learning Haskell will probably teach you to structure your code and mindset toward a problem far better than you otherwise would. If you haven't seriously looked at FP before, I would expect that the effort (and benefits) of learning Haskell are far greater than just exploring a new framework in a language you already know. Take the Red Pill!
Perhaps this? composeFunc = wrap .: (. unwrap) . (.) . unwrap Using `(.:) = (.) . (.)`. It’s in a library somewhere, but Hoogle is being unhelpful. 
True, but I was mostly trying to illustrate the point of what I meant by the wishy-washy term "special". The functor-y thing that (a, b) really cries out to be an instance of is a bifunctor. The functor instance seems like an instance of "just because you can, doesn't mean you should." But well, this is just my opinion.
I think /u/eoz is getting at the definition: x &gt;&gt;= f = join $ fmap f x `join` definitely acts as a flattening operation (`join :: Monad m =&gt; m (m a) -&gt; m a`), and it's in that sense the name `flatMap` makes sense.
They have both for both [algebraic](https://github.com/idris-lang/Idris-dev/blob/master/libs/prelude/Prelude/Algebra.idr#L37) and [categorical](https://github.com/idris-lang/Idris-dev/blob/master/libs/prelude/Prelude/Monad.idr) structures. In general, I think they recommend using the not Verified- versions unless you are going to use the proof terms directly.
Could someone comment on what would be reasonable prerequisites, to get anything useful out of this? I have a B.A. minor in Computer Science, and beyond that, many years of programming in a variety of languages, but formally I am mostly an auto-didact. Let's say I can understand the _very_ basics of lambda calculus, category theory, and automata now, have taught myself some Haskell and some Lisp and Scheme and some related languages, read some programming language papers for fun, but haven't had formal mathematics training beyond calculus, and that was many years ago. Would I be hopeless at this? Even floundering, would I get anything useful out of it?
SPJ's [Tackling the Awkward Squad: monadic input/output, concurrency, exceptions, and foreign-language calls in Haskell](http://research.microsoft.com/en-us/um/people/simonpj/papers/marktoberdorf/mark.pdf) is another classic you can add to that list. Its a bit more practically minded and gives a nice historical perspective as well.
.. and simultaneously there is a convention that would make picking any one of them other than the left to right reading quite surprising to users, and very few instances out there that take advantage of that flexibility, all of which are clearly signposted.
I'm not signing up to lead the charge on getting `lens` into Prelude. The Foldable/Traversable changes alone have already taken enough years off my lifespan. ;)
After discussion, the https://github.com/bgamari/monoidal-containers was born thanks to Ben Gamari
Not really. Most of the replies making actual constructive points tend to talk about ideas that go much, much further than the current proposal and are in no way hindered by it. Things like more powerful alternatives to Foldable or new language extensions hardly supply an answer to the 'How do we make Prelude more powerful without breaking existing code?' question the whole issue is actually about.
It's relatively new, so usage is expected to be limited. Also (I think) it solves a minor pain point. The holey monoid trick is very elegant though.
The impetus to try to actually finally make Applicative a superclass of Monad actually spun out of the BBP thread. David's proposal was put forth a week later, after Wren posted the fairly inflammatory initial burning bridges proposal and the Applicative changes mentioned in it were seen to have particularly wide support.
Yeah, I try to avoid type classes without properly formalized laws. One issue I have with them is that when they "fail" (meaning that they diverge from your intuition) they do so in an unpleasant way: failing at run-time with an unexpected result. I prefer mistakes to be caught at compile-time as much as possible.
Having the Foldable/Traversable instance for fundamental things like `(,) a` is quite useful when you want to consider the properties of more interesting data types that just happen to be built with them. data Free f a = Free (f (Free f a)) | Pure a gives us instance Functor f =&gt; Functor (Free f) instance Functor f =&gt; Applicative (Free f) instance Functor f =&gt; Monad (Free f) but it also gives us instance Foldable f =&gt; Foldable (Free f) instance Traversable f =&gt; Traversable (Free f) Now we can explore what this data type means when we plug in all sorts of standard data types. Free Identity a is a monad where we can count 'levels'. It is a partiality monad, folding or traversing walks through the levels and gets down to the single element inside. (Edit: I accidentally said `Free Maybe` at first.) Free [] a gives us a rose tree, folding or traversing now walks the tree's leaves in order. Free ((,) e)) a gives me a structure where I have a list of 'e's terminated by an `a`. Looking at the types you can easily see that the only thing that `traverse` will traverse is the final `a`, not the `e` elements. Free (Const x) a recovers `Either x a`, folding and traversing necessarily just touches the 'a' if it is present. etc. All of these do the only sensible thing when you go to fold them or `traverse` them, and they borrow that behavior from these simpler, obvious, universally-determined instances. Randomly removing instances just makes achieving insight into what such structures "are" vastly more difficult, and makes code that chooses to use them a rats' nest full of orphan instances or specialized one-off names.
This seems a bit mean spirited. Robbie is an excellent Haskell programmer, and I don’t really see how a basic understanding of lambda calculus trivially leads to this technique.
&gt; ... and simultaneously there is a restriction that would make picking any one of them ... literally prevent *any* user from picking a different one. 
&gt; I prefer mistakes to be caught at compile-time as much as possible. Of course, everyone does. The point is the alternative to type classes without properly formalized laws most of the time are not type classes with properly formalized laws. Rather the alternative is not using a type class, but concrete functions that can have arbitrary implementations as well and might do weird stuff. I'm not going to stop using Foldable because someone might potentially give a non-intuitive instance.
Again, no offense intended. I'm just curious is all. Unless I'm misunderstanding something big, the discovery here was the fundamental concept of lambda calculus.
Scenarios like that are why I wrote `lens`, and why the `lens` vocabulary largely mirrors the simpler common `Data.Foldable`/`Data.Traversable` vocabulary. On the other hand I also make regular use of the power of `traverse` and `foldMap` to _not_ know about the particular choice of `a` or `b` I'm using. The ratio of times the common sense default is exactly what I need is largely similar to what the ratio of times I can get away without making up a `newtype` to get any other particular odd instance behavior I need in the moment. There is often no particular reason to choose one `Ord` instance over the reverse as well. Should we remove `Ord`? It also actively prevents any users from picking a different ordering.
For almost every container, the only thing someone _has_ to write to make a Foldable instance is the `foldMap` definition. To make their code fast, and avoid blowing up the stack as a pragmatic concern for particularly big containers, however, a small percentage of those instances offer specialized versions of the other members. We do not currently know how to get to a world where `foldMap` is the only inhabitant of `Foldable`. Getting there requires an a generation of compiler magic we don't know how to write or where we've gone in other directions (Rob Ennals' thesis actually handles some of the cases quite well, like naïve `sum`), or just accepting that the stack should be unbounded, etc. There is no roadmap to make those things happen, and it isn't clear that they can. I'd love to get there. Show me how. =)
And many people now consider this to be a mistake, as borne out by a lot of accumulated experience teaching things the monomorphic way.
Oh that's much better than the form I had it in, thanks! But you're right, this is close to the point where pointfree style becomes too convoluted to be helpful. Definitely personal preference.
Can't we look to all the packages on hackage that have been updated to support 7.10?
The "something in common" is a massive advantage when reasoning about code. I know the upper bound of power used in an implementation.
Y'know, there was actually a thread on the libraries mailing list [a while back](https://www.haskell.org/pipermail/libraries/2013-May/thread.html) about `for_` vs. adding a `whenJust` function. The very interesting discussion that followed might have some relevant to the current broad topic. ;]
I just... fail to see how this isn't the uncurry function. The insight from the example, as far as I understand, is the idea that I can compose a fancy function in one spot, and compose some arguments totally independent of that function somewhere else, and then (provided they type check) stick that function and those arguments together at a later point. Please correct me if I misunderstand. But this is just the uncurry function! I can compose as many arguments as I want with (arg1,arg2,arg3) etc., and build a function the same way with uncurry. The original example, "uncomposed", is this: ((*).(+2)) 3 4 And the "composed" version (arguments and function built separately) is this: uncurry ((*).(+2)) (3,4) Provided I didn't misunderstand something, that is isomorphic to what OP has done. EDIT: And the relation to the lambda calculus is that multi-argument functions and single-argument functions are interchangeable, via currying and uncurrying.
Thanks, I see what you're getting at now.
Ahh, I see. Thanks for the clarification. If I understood your reference to the lambda calculus correctly, then you are saying that he implemented uncurrying using the [Church encoding for pairs](https://en.wikipedia.org/wiki/Lambda_calculus#Pairs). In this case I agree, this indeed seems very similar.
The key is that you can't mutate a variable. So instead just make a new variable and set it to (resdNum:numbersList). Honestly, I think you should go back and learn the basics of doing things functionally, before you're messing around with IO. The whole idea of "create a new list and add to it" is very imperative. If you want to loop adding numbers into a list, you want to use a fold which keeps building bigger and bigger lists. 
Use recursion. Here's your code with some changes -- it asks the user for numbers repeatedly until they enter zero, then it displays the list at the end. Hopefully this will help you take your next steps: import System.Environment prompt :: String -&gt; IO String prompt x = do putStrLn x number &lt;- getLine return number accumulateNumbers :: [Int] -&gt; IO () accumulateNumbers currentList = do rawNum &lt;- (prompt "Please enter a number: ") let num = read rawNum :: Int in if num /= 0 then do --valid number print ("ok! enter another or press 0 to stop.") accumulateNumbers (num : currentList) else do print ("nice! here's your list: " ++ (show currentList)) main :: IO () main = accumulateNumbers [] 
Everything is controversial. Even doing nothing is a highly controversial position. In matters like this you'll always get stuff like a person who objects to everything because it doesn't fit into their preferred coding style that noone else uses or the person who learned Haskell 10 years ago, liked it, and wants nothing to ever change after that. Yes, there was a general majority consensus reached. That doesn't mean anyone actually *changed their mind* at any point. Especially the two or three people with lots of stubbornness but little in the way of persuasive arguments. But yes, pretty much the entire current discussion is foreshadowed in that thread if not repeated in full.
Basically trying to take a list and determine which are prime Correct me if I'm wrong anywhere in the following as this is all making sense so far. ------------------------------------------- import System.Environment prompt :: String -&gt; IO String prompt x = do putStrLn x number &lt;- getLine return number accumulateNumbers :: [Int] -&gt; IO () --passing in a list of ints accumulateNumbers currentList = do rawNum &lt;- (prompt "Please enter a number: ") let num = read rawNum :: Int in --read the passed in number as an Int if num /= 0 then do --valid number print ("ok! enter another or press 0 to stop.") accumulateNumbers (num : currentList) --concatenating the new number before recursion else do print ("nice! here's your list: " ++ (show currentList)) main :: IO () main = accumulateNumbers [] --pass in an empty list to begin ----------------------------- Now if we were to manipulate the passed in numbers in the main would it be like main = do Let newList = [] accumulateNumbers newList print ("the list " ++ (show newList)) Or is it not by reference so the newList would still be empty. From there I have created a function to determine if a number is prime (going from 2 to the sqrt(x)). So next step would be stepping through the list and passing each value of the list into the isPrime function.
The newList would still be empty. You only need a small change though to make it work, change the type signature of `accumulateNumbers` to `[Int] -&gt; IO [Int]` and in the else clause put: print ... return currentList Then main looks like: main = do newList &lt;- accumulateNumbers [] print ... `return` is something of a misnomer. The last line in a do-block gets returned implicitly[1], but it has to have the type `IO whatever`, which return accomplishes (it's type is `a -&gt; IO a`). [1] The if clause doesn't need to be changed for that reason.
The point remains that I can't see ever wanting to apply functions from `Foldable` to something that will always be a tuple. :P As far as I'm concerned, "It's canonical, please don't *encourage* orphan instances" is 100% sufficient reason to include the instance.
Basically. Sometimes I've heard an `IO a` being described as an action that yields an `a` when executed (to distinguish it from a function that returns a value). I'd caution against taking the metaphor too far though.
&gt; "Cochoice Yoder Lemmings" I didn't giggled about a programming joke that much recently
I'm very happy that the other thread introduced me to `Control.Lens.forOf`.
If I know it is a tuple, I'm reaching for 'snd' and doing something with it. If I don't, I'm reaching for a combinator based on whatever properties I have at hand.
&gt; […] that is pleasing to the eye and unchallenging to the intellect. Obviously, the best way to resolve any debate is to imply that your opponent only believes something because they're dumb. Look, you can still think that someone is wrong without being a condescending jerk to them. This is mean-spirited and divisive. It's trying to insult and shame people into agreeing, instead of showing them the advantages of your ideas. I think the Haskell community should aspire to better than this. (And it's technically wrong, to boot! Even if people were arguing in favor of removing typeclasses entirely—which *nobody is actually arguing*—the combination of parametric polymorphism and higher-order functions enables manual dictionary-passing, which means nobody needs to resort to `m4` to write parametric code.)
Ouch. =/ I really do think we could stand to do better than to hurl insults at the other side of the debate. Picking a fight just ensures that any rift caused by the Foldable/Traversable Proposal becomes harder to heal. We all want the best for the language, there are just legitimate differences in opinion about what that might mean.
I'm still not exactly thrilled with this post. Please don't run the "joke" into the ground unless you want me to change my mind about removing it.
It's amazing to see the same points being made over and over and over... I was not aware of this thread but it has the same points as the reddit thread. The big difference is that [GHC 7.10 Prelude: we need your opinion](http://www.reddit.com/r/haskell/comments/2vfczx/ghc_710_prelude_we_need_your_opinion/) is much more concrete showing how much progress in understanding the matter has been achieved on the implementation side (which includes work on lenses) and how little progress on the opposing arguments such as "ease of teaching" and "beginners will suffer" etc. And here we are: AMP is the reality, hopefully BBP will become the reality as well. 
Is it April already?
Actually I was able to piece it all together using what I've learned/from a tutorial site. Everything's working except one value. Basically passing in a list of (1,2,3,4,5,6,7,8,9,10) brings back (1,2,3,5,7). The 2 is still there and I am unsure if it has to do with my casting or sqrting. --isPrime() method determines if a number is prime isPrime :: Int -&gt; Bool isPrime k = null [ x | x &lt;- [2..(floor (sqrt (fromIntegral k)))], k`mod`x == 0] --return a new list of only the prime numbers of a list determinePrimes :: [Int] -&gt; IO[Int] determinePrimes currentList = do return [ x | x &lt;- currentList, isPrime(x)]
[Coincidence? I think not.](https://twitter.com/HaskellCEO/status/565752362388963328)
Right, forgot to consider 2 as its own.
Exactly! There was a debate, people disagreed, but a large majority was apparent in the poll at the time. A committee specifically formed to do these things did an *amazingly* thorough job investigating design options, and then helped a large swath of the entire hackage ecosystem make fixes. There was debate, there was voting, there was a committee. Many people received help adopting the necessary minor changes. That some folks managed to miss all of that is a shame, but I'm still impressed with how well what will have been a two year long process went.
You can make an analogy to GOTO vs. structured programming. Structured programming is strictly less powerful than GOTO, yet structured programming won because it's easier for programmers to read and reason about. Similarly, I expect functional languages to win in the long run for the exact same reason: they are easier to read and reason about.
This makes me so happy.
I think of it as lifting the type into the monad, but they decided to use `lift` for functions.
Great example of free monad usage!
Is there a better example of problem code for this? Because this *specific* example sounds a lot like "the compiler won't save you from making incredibly bad decisions".
I mainly use the _Just or _Left/_Right traversals to make my intention explicit
You are correct sir. I dashed that off of the top of my head. The `Free Maybe` version is one that can either succeed or fail but does so after a number of steps.
You need to use a fixed width font if you want to line things up other than at the start of each line. 
Would it be possible to create a new "ByteString" and/or "Text" class that *would* play nice with fmap, etc. without losing speed?
I don't normally write blog posts on a Friday (since I'm not able to participate in discussions very much), but I thought this sentiment deserved to be expressed, and didn't feel like waiting till next week.
In general in a learning environment you need to hide parts of the real Prelude so you can write the actual definitions of a Prelude type to explain it (e.g. to explain Maybe you might want data Maybe a = Nothing | Just a in there).
It isn't a speed concern, so much as a 'leaking all the intermediate data types used' concern. Packages like `lens` or `mono-traversable` provide tools for working with those data types. e.g. with `lens` you can use a `Traversal` for both `ByteString` and `Text` that specializes it down to working with the `Word8`s or `Char`s inside respectively. The `lens` approach is the best way I know of to get a single common vocabulary that can be used across path the polymorphic and the monomorphic cases. We have combinators that accept a `Traversal` and then their normal arguments, and `traverse` from `Traversable` is a `Traversal`, suitable for passing. Much of the nomenclature it uses derives from the `Foldable` and `Traversable` classes and their associated combinators. e.g. if you wanted to use an analogue of `sum` for a given `Fold` you'd call `sumOf myFold`, etc. However, it is **considerably** heavier weight machinery.
Ah, thanks for that information! I was just wondering whether someone has already implemented something similar or is in the process of implementing it. Could you give a quick example to illustrate what you mean by term application leading to type variable shuffling?
Well, [I got close](http://lpaste.net/120426). As I mentioned in the comments, the two things I couldn't figure out were: 1. textBaseLine 2. stroking text That said, if the size of the generated output isn't a concern, the number of lines of haskell to produce morally equivalent output is identical. I suspect that static-canvas might be simpler in that you only need to worry about the CanvasFree and Style abstractions, where as with haste you have to worry about Picture, Shape, Canvas, and (briefly) Element.
&gt; I could play that game with just about every line of my code And how is that good? &gt; that's just as much of a "could go wrong" as "what if you accidentally delete the user instead of search for them?" It you could endorse that easily in the types, would you? With that maybeUser you can. 
I really don't see where this is coming from. To me, seeing `Maybe` as a container with 0 or 1 elements makes a lot of sense, and so using functions generic over the container is very natural. Do you also use specialized versions of `fmap`, or even `(&gt;&gt;=)`?
 &gt; I also consider the proposal to be a pretty big thing. I am not sure that all people who are affected are aware of this discussion, especially since it happens under the subject "add whenJust". 
You get that functionality with the partial type signatures proposal (but the syntax is less neat). forM_ :: Maybe _ -&gt; _ forM_ :: Maybe _ -&gt; _ -&gt; IO _ forM_ :: Maybe Int -&gt; _ -&gt; IO _ forM_ :: Maybe _ -&gt; _ -&gt; IO Int 
&gt; we now have a clear path forward: a feedback form I'm sorry to read that. Because the poll initiated the war (ok, the last round of it.) And I have to admit that silly MonoHaskell website discontinued the war. Edit: s/flame war/war/g
Ah, I see. Thanks for the comprehensive answer. I agree, there seems quite some complexity involved to solve the problem entirely and pretty. Maybe a somewhat practical subset would be to allow fixing type class instances in the order they appear in the constraints. This might at least give good intution when used for functions having an explicit type signature. But the problem with functional dependencies of course still exists. Maybe some sort of placeholder, i.e. `_`, could help to leave those to the compiler's imagination.
OK, the word is wrong. I still think it was a war.
I think I do. As I understood it, if a typeclass describes a sort of "behaviour" for a class. So a class which can be converted to a string representation has the typeclass "Show". Right?
Polymorphism gives you theorems for free. It's far easier to reason about.
I probably have a different definition of the term "war" ... but how do you define "war"?
When teaching students fold, it's probably better to implement it yourself.
Right. I know why the poll was started. But the community was already divided, starting a poll was bad idea in such situation because it divided us even more. Edit: typo
Gets the job done :)
I don't think this is a metaphor but a precise description of `IO a`. Can you elaborate on what you mean by taking it too far?
I disagree. The people interested in this topic are now aware that their voices have been heard. It is ok (and inevitable) for a group of people to disagree on some topics. It is however important that the group responsible for the final decision shows that every points has been taken into consideration.
So each time there is more then one haskeller involved there is a war? :)
Wow, is that coming? I tried to implement that during my master's and got pretty far along, but didn't finish it, sadly.
&gt;That said, I honestly haven't seen such statements myself. It seems to mainly be a twitter thing, fortunately. There are a few people on there who seem to think their opinion is undeniable fact. It puts me off contributing and offering my opinion in case I just get shouted down by these people. &gt;I'm certain you could provide links to demonstrate that behavior, but I think it would be better not to call people out so directly. I agree. 
That would explain it, I only occasionally read my Twitter feed. Please don't let that kind of attitude prevent you from getting involved. I'm fairly certain most people in the community are able to ignore that kind of negativity and still have a meaningful discussion with you.
I have not seen those sentiments expressed here, nor on the libraries@ mailing list. Quite the contrary.
"Nothing else has stopped." I think that's the key point. In the last few weeks I've been talking with people on "the other-side" about deploying Hoogle 5, using Shake to test all packages on Hackage, maintaining the Win32 library, drinking beer and dinosaurs - everywhere from private email, to twitter, to Facebook. This isn't two armies going into battle, this is a single group who have slightly different color preferences.
We should adopt this for convention naming. 
In the case we're talking about here, the type signatures have been written explicitly. One can easily write type parameters explicitly also, thereby avoiding the issue you mention.
Yes, but the "burning bridges" discussion fragmented into new threads with multiple topics several times, and generated an unusual amount of traffic for that mailing list. Everyone who reads the libraries mailing list would have been aware, but I guess more people ignore it than I expected.
I don't know about you but the poll forced me to read about the proposal and more carefully consider my opinions. If anything, I feel *less* disconnected from the plan I'm opposing now. I see now how both plans are rational and quite well thought out.
&gt;Not that it excuses anything, but it's also somewhat tangential to the debate. Unfortunately the quality of debate is lowered by this kind of thing
&gt; If you want a ~~Reader~~, just use a ~~Reader~~. I think you meant "Writer". FTFY.
Made my day.. Shit this is funny!
We had a conference call with 7 of us, including Simon Peyton Jones and Simon Marlow, with 3:4 split on what to do. None of us had an argument that was convincing. None of us thought polls were good ways to decide technical things, but none of us had a better idea. The poll is the way to force the issue, put it to bed, and move on.
[Link](https://twitter.com/HaskellCEO)
The tweets are fun, but I'm put off by the vulgarity.
Yeah, @HaskellCEO is quite abrasive
imagine this spoken by cave johnson over the intercom...
I find GHC news to be very useful for GHC outsiders. It highlights some major points/events but it started long after the FTP was under way, I suppose.
I think this account is extremely unfortunate. The Haskell community online already has a deservedly bad reputation because it fails to respond coherently to trolls and wannabe members who are consistently rude and non-constructive. The number of such people is small, but they're unfortunately very energetic and drag Haskell further into disrepute with each new [stupid stunt](http://monohaskell.com). Furthermore, if you're on the outside, you're going to have no idea that this is a very clumsy parody, and are likely to be further put off. So by all means find it funny if you wish, but I won't be laughing with you. It's puerile.
Yeah, he's trying to use swearing instead of telling actual jokes. Sometimes strategic swearing can be funny, but it got old real quick.
Foldable is not meant to be universal. It is meant as a method for presenting a single list-like view of a structure. For foldable instances to be universal, the part of the structure you are folding over would need to be isomorphic to a list. However, we want to be able to collapse some extra structure to present a Foldable instance. For example, you would like to be able to have Foldable instances for tree-like structures, but there is no way to go back and forth between depth-first and breadth-first traversals. This is the reason that similar proposals have only tried to reason about the membership of toList, not the order.
I get that, hence my asking if thinking of them as contexts or containers even makes sense. They seem to behave more like values. But I could envision a `Text' a` where a could be Word8, Word16 or Char, with a map function able to take one and return a different one. But I guess it couldn't work as there would have to be a constraint on what a and b could be.
`#trust` `#leadership` `#applicative`!
Precisely! See my comment!
`traverse` doesn't have the problem you mention. You can rule out that definition by showing that it violates the laws. Jeremy Gibbons' original paper feared it might be possible, but it has since shown to be ruled out just by the normal `Traversable` laws. This was a subject of a later paper by Mauro Jaskelioff and Rypacek, and I also derived a proof with Russell O'Connor independently. See section 4.2 of http://arxiv.org/pdf/1202.2919.pdf
It is.
As noted elsewhere on this thread, your proposal is too strong. Consider for example data Huh a = Huh Bool [a] instance Foldable Huh where toList (Huh _ xs) = xs g :: Huh a -&gt; [a] g (Huh b xs) = if b then xs else reverse xs So you cannot construct a `k` satisfying your condition, since the Bool has necessarily been thrown away. I have an alternate version of the law I proposed that /u/stere0id links to, which captures the idea of initiality more overtly but shows how functions such as `g` "split" in some sense: forall (g :: forall a. f a -&gt; [a]). exists (h :: forall a b. f a -&gt; [b] -&gt; [b]). forall. (x :: f a). g x === h x (toList x) I think it is equivalent in power (modulo potential size issues at infinities) to the law I proposed in that thread. Also, as /u/tomejaguar notes, the traverse instance you give is unlawful. I find a very clear explanation of the power of traverse laws is given in http://www.cs.ox.ac.uk/jeremy.gibbons/publications/uitbaf.pdf
This question is more about the underlying technology than the Haskell side. What does Canvas give you in a static context that SVG doesn't?
Thanks very much for implementing this. Now that the bytestring builder has been available for long enough it's clear that we eventually need to standardise on that one and gain the befits of multiple libraries using a common type for composing output. We're also planning to move the binary package's builder monoid to be the one from the bytestring package.
Too much profanity. However, I can imagine Mr. Torgue screaming all those tweets. Especially after reading the point-free one.
I'm really excited about developments like these. &gt; When I looked at distributed-process, it was clear that it was offering exactly this kind of supervision and much, much more. The problem is the library is certainly geared towards Cloud Haskell and the idea of the distributed closures, therefore if you want to use it, you have to buy the full package. This is exactly how I feel. There's lots of single computer robustness value to grab which doesn't require pulling off the entirety of the closure passing effort.
I kind of wish it was more Cave Johnson surreal than merely angry, but the voice is right on! 
Thanks dude!
Exactly :)
It’d be great to beef up image display to support resizing and zooming. For plots, it would be fantastic if the axes were scaled when zooming so you can locate points in the coordinate system of the axes, but this would require interaction across several components. 
It seems a shame that SVG can’t be scaled given the V. I’m under no illusions that any of these are easy features to implement, but perhaps they do suggest that pulling in something like D3 is worth it if it provides answers to so many requests.
&gt; The Haskell community online already has a deservedly bad reputation Maybe my view is too small to see enough outside perception, but I've always felt that the Haskell community has a great reputation for being extremely beginner-friendly and dealing with trolls well. There's the classic troll-handling episode that happened awhile back in #haskell where a vitriolic troll was thoroughly quelled in about 100 lines of IRC comments. That in my mind is the epitome of exemplary troll-handling. Now maybe the goodness has been diluted somewhat as the community has grown, but that's unavoidable. This doesn't mean that I disagree with you that these things can tarnish the image of the Haskell community when viewed devoid of context. But at the same time I think it's important for communities to be able to poke fun at themselves. If it wasn't for a few condescending bits, I think the aforementioned "stupid stunt" was actually close to being brilliant parody/satire.
Total agreement. It's a definite tradeoff. My belief is actually that there's some amount of research to be done in the space of "what's the right way to pull off OTP in Haskell" semantically and how to implement it around Haskell's threading/exception model. This research could be conducted in parallel with the research in the distributed-process space. So the duplication of effort is painful, but I believe there's good chance it'll be helpful.
Well mostly I mean it's not terribly precise when you stop talking about IO and start talking about monads in general. YYMV
I think the MonoHaskell site went too far, was fairly tone deaf and did not help further the debate. That said, I'm just going to leave this here: http://www.nytimes.com/2015/02/15/magazine/how-one-stupid-tweet-ruined-justine-saccos-life.html
That is a great article. Thanks for sharing. Are you implying it's directly related to this @HaskellCEO or just making note of the dangers of public shaming?
Thanks for sharing that, an amazing article. I also liked: http://nymag.com/daily/intelligencer/2015/01/not-a-very-pc-thing-to-say.html which touches on similar issues.
A vaguely representative list of packages that need to be bumped for this blaze-builder upgrade are [here](https://github.com/fpco/stackage/issues/442), but it should just be a case of bumping the version. I'm very happy about this, it means soonish I'll be able to switch to bytestring-builder in lucid and people using it with packages that depend on blaze-builder will have a smooth upgrade path.
I think the Haskell *Twitter* community has a bad reputation, but Reddit and the mailing lists still seem find and helpful to me, as does what I see of IRC (not that I'm on it much). I think people who "discuss" 140 characters at a time are setting themselves up for a bad ride.
Twitter ¯\\\_(ツ)_/¯ 
Ahh, that could be...I don't use Twitter. I prefer more than 140 characters as well.
&gt; StackOverflow SO has a great [haskell] community, which has perhaps a more generous concept of "on-topic" than the rest of SO, but my feeling is that hypothetical or language-design questions, e.g. relating to FTP, would be off-topic there. Also keep in mind that SO *comments* are subject to deletion both by their authors and by moderators. (This is consistent with your point, /u/camccann.) 
We just need to create a secondary market for synthetic beer derivative forwards, and no beer will ever have to be purchased directly or consumed at all!
After I got my bronze monad badge I have to admit I sort of lost interest :-) I note we now have just over 1,200 unanswered questions. I'd like to see some volunteers chip in to get that to under 1,000 or better yet 800 at least.
I think that the reason the AMP was more widely known was that ghc has been flagging it up in warnings. Nothing like getting the most popular compiler to tell everyone about future changes. 
I don't disagree with your statement, but I can't particularly agree with it, either. Worth noting that for those of us who are there, we're a little stuck when we come against these remarks - I can't tell you "no, that's wrong", but obviously *something* is keeping me there. So I would say I find it a fun and fast paced community, and it fits with me. It has its warts, but so does every communication forum. The limitation in post length can manifest itself as possibly overly-polarised opinions, and it helps to keep that in mind.
It is necessary to point out that the notorious episode led to a bad spate of people coming in deliberately to test troll-friendliness/conversion. For that reason many of us don't like to continue to go on about it.
I think OTP is misguided, so I'm happy that cloud haskell hasn't gone full OTP. What is missing are good libraries for distributed state machines such as an implementation of raft etc. Supervisor trees just does not give anywhere near the guarantees that we need for modern distributed systems. Supervisor trees were developed before people internalized paxos and distributed state machines as the solution for distributed systems.
And with that comment, the last three tweets have been profanity free. The fact they listen to feedback proves it's not a real CEO :P
I'm not sure it was meant as a dig at OCaml. It was more meant to say that if we stick to monomorphic types in Haskell rather than using typeclasses we may as well just use a different language anyway. IE, Haskell just ends up being OCaml.
Talk about hasty generalizations. Sure, the twitter community seems prone to this, but that doesn't mean we have to take "someone thought someone said something offensive" as the death of the entire Haskell community, either. I still remember the rage over "Functional Programming is Morally Correct" as a talk title.
Actively highlighting how painful monad transformers have been to use in the scala community has since translated into concrete improvements in the situation. * First folks figured out they can use `Unapply` tricks to enable us to at least get out of this situation for the simple `StateT` examples. These have been integrated into `scalaz`. * Then Erik Osheim's work on [kind-projector](http://github.com/non/kind-projector/) made the more complicated versions easier to state. * Since then [Jed Wesley-Smith has integrated that into `scalaz`](http://jwesleysmith.bitbucket.org/types-kinds.pdf) and removed the use of explicit type lambdas entirely. Things still aren't perfect, but the state of affairs is a hell of a lot better than it was a year ago. I can equally well say that Haskell is bad at dealing with deep accurate class hierarchies, because we don't get to employ properties of a subclass in defining our super-class members -- well, probably not in the confines of a tweet. ;) In many cases the first step to fixing a problem is acknowledging you have a problem.
The problem is, the OP has effectively called them out, but only to people-in-the-know. The rest of us are left scratching our heads wondering what on earth people are talking about. That said, I understand not wanting to call them out directly (and drawing attention to such people generally backfires). But if it's going to be brought up in the context of a discussion on the GP, it would be nice if everyone reading this thread could at least follow along with what is being referenced. EDIT: I missed that /u/jonsterling was the OP and /u/conklech was merely commenting on it.
Edward, this is all very interesting, and I don't mean to be dismissive (in fact it's relevant to some of my Rust work), but the point of my comment isn't about the technical content of that tweet. It's about the context in which the message is being delivered and the tone that it sets. I have a very hard time seeing non-haskeller's "learning" something from this style of presentation. The whole thing is like this echo chamber, Haskellers high-fiving and patting themselves on the back, and then wondering why outsiders are so put off by the language and its supporters.
i guess thats one way to make #haskell feel better about itself...though guess it doesn't say much at that point :P 
I've started trying to field the Japanese questions on the topic. I'll leave the crazy Americans to you. ;)
&gt; I note we now have just over 1,200 unanswered questions. I get frustrated with that list. Because, most of the questions are answered, just *in the comments*. It does very little, if any, good to rewrite someone else's comment into an answer. :/
Yeah, I think the right approach is to just *be there*. It won't stop bad things from happening, but it will let some good things happen, too.
darn
they're unique up to a unique isomorphism, right?
I prefer this article on the subject of political correctness: https://aggslanguage.wordpress.com/the-impact-of-political-correctness-on-language-change/
But if it's not universal, how can we ever write functions polymorphic over Foldable and predict how they behave :'(
Think of it like maths. In maths, if you write `x = 1`, you know that everywhere you can see `x`, you can replace it with `1`. So when you write let newList = [] then you know that `newList` will always equal `[]`, so later, this print ("the list " ++ (show newList)) is exactly equal to print ("the list " ++ (show []))
Heck, why do you think I'm campaigning so hard for the FTP? I mean, with Marlow having fallen into bos' clutches, success is dangerously close at hand.
Thanks for the drive-by judgment. I'll go back to twitter now where people are complaining about reddit. 
That's nice, but what does that have to do with convincing me you're not just here to stir shit up?
Haha, Haskell sweat shops. Yup, that's what we're striving for. 
Clearly Haskell is a perfect sweatshop language, since programmers like to slack off and no other language provides built-in tools for removing laziness!
I sincerely hope this doesn't come across as condescending or pretentious - that is not my intention at all. I merely wanted to move an observation I've had into a wider light. Thanks!
Oops, sounds like I just fell prey to exactly the kind of tendency I'm railing against. On internet forums it's very easy to make frustrated off-the-cuff remarks that are not supposed to be offensive but do end up offending. (I think on Twitter this is an even bigger problem because of the message length limit.) So, I apologise if you felt I was saying you are a frustrated person or you are being destructed by Twitter. I do actually read several people's Twitter feeds and find them interesting! 
You're right, my tone was too abrasive, sorry. You are one of the people whose Twitter feeds I do actually read, as you probably know! So my statement was made more out of frustration than due consideration.
Huh, you answer Haskell questions *in Japanese*? Sounds harder than learning all the lens operators.
It's done wonders for the PHP community: https://twitter.com/php_ceo
Nah, I know it was an innocent remark. I commented for ironic posterity and because there literally was the converse conversation happening on twitter at that very minute. People are people everywhere.
Thanks. Funny enough, Google's cache shows the "I've removed everything page", but the page has been restored meanwhile.
Just a quick library I threw together when I realized something like this could be done. Currently it's restricted to specific forms of types of kind (* -&gt; *) -&gt; *, but I'm hoping that with some thought this constraint could be gotten rid of. Let me know if you have any suggestions!
Just trying to get good ideas for new lens combinator names. Japanese combinators are a remarkably underutilized portion of the Haskell namespace.
If you have two lists `ps` and `qs`, you could do `sqrt $ sum $ map (^2) $ zipWith (-) ps qs` or you could do `sqrt $ sum $ zipWith (\p q -&gt; (q - p) ^ 2) ps qs`. Look at this with regards to recursion: distance as bs = sqrt (dist as bs) where dist [] _ = [] dist _ [] = [] dist (p:ps) (q:qs) = (q - p) ^ 2 + dist ps qs 
it's parody. and like most parody, there is some truth to it.
There are at least a couple on the "big four" posts under discussion at the moment. Not many though.
Very much agreed.
Have you even *used* OCaml? I have no idea where you would have got the idea that OCaml is somehow predominantly monomorphic. 
It's a novelty twitter account - hardly a spokesperson for the entire community. I think you might be taking this a bit too seriously.
No suggestions as I have a lot to learn from this library, just wanted to thank you for putting it out there!
yeh, been searching for a tutorial. of the 3 examples in the github distro, i could only get the latency example to work, not the chat one, the build instructions are unclear. i tried to hack it (sendfile must be changed to sendFile and given a directory as an additional argument, there is some __directory or something you can use...) but yeh, the examples come with js node servers to put the index to the browser when it calls localhost:port... its such a mess!! would love to see a simple code snippet of someone using this to talk to js. i think i might end up writing it... doh, with no info to go off, i guess there has to be a first. but seriously, if anyone has a working hello world example of passing some data from haskell to a js node server, it would be super great, even tips would be helpful... cant get in touch with oliver!
That `distance` I wrote should work, I think? Look at that `dist` helper function in there. It builds the inner part of the euclidean distance formula by working on the heads of the two lists, then uses itself on the tails of the lists. That's how you'd write it if you want to do the recursion yourself. There's btw. a different subreddit named /r/haskellquestions that might be better, has more people that are there to answer questions like this.
yeah, we're fine with it. It's the price we pay for having logical type class hierarchies. 
Stay awesome.
Frankly, the only person my efforts have been towards protecting and justifying in any sense in the past period has been you, when I've urged moderation on the part of others in the face of your abrasive and destructive behavior. I did so in the hope that you would learn to tone it down and act as a productive contributor, as you have shown you have the capacity to do, if you wanted to. Whatever hope I had has rapidly dwindled in the past period, and I'm tired of dealing with this. If you don't want to listen to friendly advice, freely offered, and in fact actively reject it, then, welp, I tried.
Keep in mind that comments which are wildly off-topic and/or add negative value to the conversation are likely to be removed by the moderators. I appreciate the idealism of /u/ocharles about reddiquette but I find that even a healthy garden benefits from occasional weeding. :P
I'm not going to try to prove a case about anybody. If you want to come to your own conclusions based on their history, you're welcome to. I'm asking for people to chill out and be friendly. This is apparently an unpopular idea in some parts. And I think dragging in world politics to the issue of basic human decency is a big stretch. I would suggest that you are scrapping for a fight far more than I am.
Sorry, I was not aware of the existence of /r/haskellquestions 
Other members of the Haskell.org committee have characterized Adam Foltzer's conduct as starting a lynch mob *multiple times*. People are scared because of his abusive conduct, I'm not going to let it pass in silence. Don't talk to me about counter-productive when acfoltzer's behavior has gone uncorrected and unapologized for.
At the risk of interjecting where my opinion is not welcome, I would just like to say that he's characterizing it thusly because there have been many comments on Twitter to the effect that people want him *removed from the commuity.* I think it's gone beyond mere criticism at that point, and is suggesting something anyway that is almost certainly impossible anyway, which strikes me as *deeply counter-productive* in its own right. But YMMV of course.
Ahhhhh it stings.
Replace the word "class" with "type" and you're more correct. Haskell doesn't have a "class" notion, distinct from "type class".
Welcome to Haskell dude
Oh, for fuck's sake. Is this *really* the hill you want to die on? You can do better than this. The MonoHaskell thing is mildly amusing at best and doesn't really add anything to the FTP discussion. Please let it drop. Look, no offense but you really are pretty abrasive on a semi-regular basis. If you were worse in the past then frankly I can't say I'm surprised that people hold a grduge. You also do a lot of good stuff, particularly where teaching Haskell is concerned. But in case you hadn't noticed, the MonoHaskell thing got negative reactions even from a lot of people who normally have no real problem with you. If you really care about Haskell and its community, *please* don't use the FTP discussion as a proxy battle for your personal war. It's petty and destructive and it turns what should be a technical, practical, and aesthetic question into a choice between "outspoken and abrasive jackassery" and "passive-aggressive faux-polite bile" that happens to have positions on the technical question along for the ride.
That's right, but the peek and poke is a little iffy, so I have some sympathy for this proposal. The whole breaking all code everywhere aspect is still slightly problematic, but it would be a better world if we could make this kind of change.
What gives you the impression I'm defending anything? All I'm saying is that if you want to see the FTP stuff go smoothly, please don't hitch your issues with acfoltzer or anyone else to it. I would also prefer that you not use /r/haskell as a battleground, mostly because I think reddit is a very bad environment for that sort of thing. And unfortunately, it kind of *is* about you, because you're making yourself into a lightning rod for the attention of people who aren't really interested in contributing anything constructive to the FTP issue itself.
People were bad-mouthing me and the others that help out in #haskell-beginners in this thread and the other one before I ever showed up. 11 hours: http://www.reddit.com/r/haskell/comments/2vrfix/whoever_created_the_haskellceo_account_on_twitter/cokdk1q 9 hours: http://www.reddit.com/r/haskell/comments/2vquuv/the_awesome_haskell_community/coki830 My first comment was 2 hours ago. ~~It's telling that you're not asking bos or jonsterling to stop pulling in off-topic, fractious conversations like MonoHaskell into this thread or that one.~~ Mea culpa: you did call out jonsterling here http://www.reddit.com/r/haskell/comments/2vquuv/the_awesome_haskell_community/coki830 But not bos who started the fire here.
Yeah, me too. I don't delete tweets often, either, so sometimes I have to go back and look at my own feed and wonder at how badly I phrased something.
This.
Thanks for the response. My bad, I meant "supervisor trees", not OTP. I have no idea how I short-circuited into OTP. Apologies.
(I don't want to make it sound like anyone's opinion is unwelcome!) I certainly can imagine that being in that predicament would be difficult. But MobOfOne isn't just taking issue with comments on Twitter—he's using _very_ loaded language, with phrases like 'lynch mob' and 'power-play', and being actively accusatory against several groups of people. All this is happening while passions are already running high due to an unrelated social/technical debate among the community of which all these people are a part. This is to say: the language he's using is defensive, fighting language, not meant to mediate a conflict but to _precipitate_ one. In light of the situation as you've described it, that's understandable! But it being _understandable_ doesn't make it a good idea: at the very _best_, it brings up bitterness and resolves nothing, and at _worst_, it turns an extant conflict into a _much worse_ conflict. That's what my comment was meant to convey.
&gt; What is your position on the Charlie Hebdo publications Since you're asking, [let's set the record straight on that matter](http://posthypnotic.randomstatic.net/charliehebdo/Charlie_Hebdo_article%2011.htm).
Monomorphic in this context means not ad-hoc polymorphic, right? I was under the impression that the heaviness of the module system discouraged ad hoc polymorphism, has that changed? 
Oh, perhaps I just misunderstood; I have never heard "monomorphic" being used to mean "possibly polymorphic but not ad hoc polymorphic".
I have. And I have no idea how you thought I got that idea based on what I said. All that was implied was that OCaml is not Haskell. Edit: actually, looking over the wording a second time, I can see how it could have been taken that way. I did not intend it that way, sorry.
Is there any point in splitting fail out into a new typeclass? It seems like when you use `fail` in a context that doesn't support it, you still end up with the "correct" semantics as your program blows up, just like it would if you failed a pattern match or gave the wrong input to a partial function in pure code. `fail` actually seems like a reasonable enough method for `Monad` inside of the Haskell design space.
Strange, your name doesn't sound Scandinavian at all.
I don't want to jump in the crossfire and generally avoid drama, but as far as I can tell after spending 10~ minutes going through this thread and old twitter posts (and heavily paraphrased): 1. Guy who teaches Haskell also posted something personal about him helping a cute girl at a gym. 2. Other guy immediately said "whoa this guys a predator" 3. Large group of people joined in on the bashing. While the "this guy is a predator" claim could have been true, there was really no way of knowing without more context. I find it generally more constructive to give people the benefit of the doubt, aka trust but verify.
It's Scottish, which I think makes up the difference.
This comes up every now and then, [quite recently on HN](https://news.ycombinator.com/item?id=8906167), and I'd echo the concerns voiced there: Is this really more accessible than just doing it with the usual symbols? Has anyone actually tried teaching lambda calculus with this?
Oh, I'm aware of both the Burning Bridges/FTP acrimony and a lot of the personal back history that's going on here. You are correct that he isn't just responding to comments on Twitter; then again, neither is anyone at this point. I would not have believed that a thread about a parody Twitter account could ever devolve into such hostility as is in this thread--and not just from MobOfOne. The hostility in this particular thread seemed to me to start with bos who felt it necessary to insult the maturity of anyone who enjoys the parody and also make it about Mob and also somehow make it about the entire "community" reputation. That was depressing and unnecessary. And things have just escalated from there. So, you think Mob's tone is making a bad situation worse. It is not a tone I would personally take, I grant you, but I understand why he's defensive and angry at some of the things that have been tossed at him. I do *not* understand why every single thing (n.b. slight hyperbole) that a Haskeller ever says on Twitter has to become a big drama about "what will people think of the community?" I'm a relative outsider and at this point, I have *very* mixed feelings about this community. On the one hand, nearly all the Haskellers I have personally interacted with on Twitter and IRL have been extremely kind, enthusiastic, and helpful. On the other hand, the "community" seems to blow up with irrational anger on a pretty regular basis, and people make incredibly derisive comments about their colleagues. Does being implicitly called immature by an author of Real World Haskell make me feel welcome to join the community? Do I want to join a community that ostracizes people because they can't seem to just ignore them on Twitter? Eh. Ehhhhhh. This entire thread is (allegedly) about a *parody Twitter account* that some think is funny and some do not, and in not thinking it funny they have chosen to make it about "the community" thereby starting a battle when they could have just said, well, to each her own. As I said, I think there's plenty of blame to go around if we want to engage in that. For my part, I tend to think dons had it right at the beginning and everyone should (lighten up and) go write some code. :)
Please tell me this was supposed to be in character as @HaskellCEO. Please. 
I am not really familiar with what reddit can do, but is it possible to move entries from one subreddit to another? As you're probably aware stackexchange allows this and I always thought that it is graceful way to handle these situations without stepping on the questioners feet. OTOH you are right, (beginner) programming questions are rare. But they pop up once in a while and I always have the feeling that /r/Haskell is the wrong place for them.
["Haskell is not not ML"](http://research.microsoft.com/en-us/um/people/simonpj/papers/not-not-ml/not-not-ml.pdf), so if "Ocaml is not Haskell", then "Ocaml is not not not ML". By the devil's bargain, which takes triple negation to single negation, even if we're trying to be constructive -- which I realize this comment is not -- then we can at last conclude that Ocaml is not ML. I think both communities would agree on that statement.
http://www.mail-archive.com/haskell@haskell.org/msg03002.html ^-- this is the actual discussion that lead to the status quo.
Damn it, my intuition says: vote it up. But does it add enought content? ;) Well at least now I can vote it up, since it is a demonstration on the meta level. So either way it should fit. It is definitly interesting and reassuring to see how many people agree, but should it be at the top of comments? Maybe we need two pairs of buttons: one for agree/disagree, the other for important/unimportant.
Ideally any comment that contributes to the discussion, even if you disagree, should be upvoted. Often the less popular opinions will hover around 0, 1 and 2 points whilst the prevailing opinion or the opinion of a well known member of the community will be at 20, 30, or 40 points 
...which points to the same post my 2^nd link referred to :-)
When the person who created it is someone who was very active in the FTP discussion, and not always in a good way, it's difficult to take it in good faith.
Personally, I would like to see anyone who wants to contribute to Haskell be able to so. That website was clearly inflammatory and was meant to demean the anti-FTP camp. That not only lowers the quality of discussion around FTP but it may also put people off from contributing. Why would you bother putting your side across if someone is going to write a sarcy web page about you and shout you down? And what does anyone lose by being careful how they argue and debate? Occasionally we might all miss out on something that was funny or even insightful because it was marred by a mean-spirited tone or whatever. That doesn't seem like too large a price to pay. TLDR: By not trying to rub people the wrong way the community loses very little but potentially gains quite a lot.
&gt;The hostility in this particular thread seemed to me to start with bos who felt it necessary to insult the maturity of anyone who enjoys the parody That's stretching it slightly, I think. He called it puerile but I didn't see him calling people who enjoyed it anything of the sort. &gt;I do not understand why every single thing (n.b. slight hyperbole) that a Haskeller ever says on Twitter has to become a big drama about "what will people think of the community?" In my opinion, communities can make or break a language. Without a good community, less people will learn the language and less code will be written in it. Debates may become one sided more easily. Traditionally, Haskell was known for having a really excellent community. I'm thinking of the IRC logs when that troll appeared. I'm thinking of #haskell in general, which is (used to be? I haven't been on for years) a friendly place for beginners and experts alike. The reason why this has turned into a "battle" is because it's very easy to alienate people with the language that has been thrown around recently. Ideally, we don't want to alienate anyone.
I don't think that's too bad. Ideally no one would take easy shots at other languages but it's clearly a parody account and it's not an account that just takes the piss out of other languages and their users. That's not to say that doesn't happen in the Haskell community. It annoys me when I see tweets that are saying how terrible dynamically typed languages are. I think the MonoHaskell thing is worse. It's pushing an agenda and using insults as a means of doing so. The HaskellCEO strikes me more of a "hahahaha. Isn't this exaggerated FP related thing funny?" whereas MonoHaskell is more of "hahahaha. People who disagree with me are wrong".
Big four?
&gt;I still remember the rage over "Functional Programming is Morally Correct" as a talk title. There was barely a "rage" about that. Someone posted some tweets saying that a title of a talk could be read in a condescending way. Someone then wrote quite a long blog post about how Haskell people actually aren't condescending at all and people who think that the talk could be seen as condescending are anti-intellectual and lazy. Then there was a rage about it. &gt;Talk about hasty generalizations. Sure, the twitter community seems prone to this, but that doesn't mean we have to take "someone thought someone said something offensive" as the death of the entire Haskell community, either. I don't think HaskellCEO is that bad, but calling criticism of people's behaviour a "rage" and then dismissing it is a dangerous path to go down. People generally don't just get outraged at any old thing and this kind of criticism should be listened to, not written off as anti-intellectual. That kind of mindset will put people off learning Haskell. To me that seems like a crying shame and if we can do some relatively simple things - try our best to be respectful, don't insult each other or another language, don't treat Haskell or static types or FP as the One True Way tm - to stop that then we should. 
These are really effective for me.
Can't wait for the next book "Real World Haskell Community: No Fun Allowed"
After rereading I feel like I should elaborate. I agree with you if you don't have a "canonical" instance. So that your domain types are not instances of `FromJSON` unless the domain is serialization. E.g. you have a `newtype` specifically for serialization. So if you keep responsibilities separated, then I don't mind how exactly you do that :)
When I was new to haskell I was confused when something like this didn't work as expected: clip = do x &lt;- blah when (x &gt; 3) (return 3) return x In retrospect, there was probably a warning like "use _ &lt;- to disregard non-() bind" or something. But the name return was actually harmful to my learning instead of the opposite.
Better memory usage, mostly. SVG turns every primitive graphical element into a full DOM node, which is very expensive.
The owners need to set it up.
Hey, that's not a problem, I didn't perceive yours as not constructive, as you were pointing out what you think are deficiency in my code, which is totally fine! :) Since now I'm in front of a proper keyboard and not from an iPad, let's see if I can address your concerns by point: 1. True enough, but if I have got the spirit behind Erlang OTP, this is what is solved by [other](http://www.erlang.org/doc/man/supervisor.html#type-restart), not-implemented `RestartStrategy`(s). If I'm not mistaken you can even specify things like throttling. So the lack of sophistication in `threads-supervisor` it's just due to the fact I implemented the OTP bits I needed. 2) True, good catch! I will try to whip up a patch during the w/e (put PR are welcome, of course!). OTOH though, if you shutdown your supervisor as part of a more general shutdown routine (e.g. you are stopping your webserver altogether) this is hardly a concern, since you will kill that orphan thread anyway :)
Yes, this is for opaque structures. And for creating space for arrays of them. I've seen it come up in C++ often in roughly the following form: 1. a foreign function that hands you back a pointer to some blob you don't care about, 2. on the Haskell side you've built up a bunch of these pointers from repeated calls to that function, 3. You need to turn all these pointers into a contiguous array so you can pass it along to another foreign function. A good compromise might be to additionally provide in Foreign.Marshal.Array, allocation functions that dropped the `Storable` requirement and took a additional size and alignment parameter that told them how far to push the pointer as it's filling up the array.
Apart from the actual answer please consider to post questions like these in /r/haskellquestions or (IMHO preferably) on StackOverflow which is a community better suited for this kind of questions. Tagging the question as Haskell *and* opengl related there would have addressed both communities. Metanote: if anyone opposes to me posting these kind of answers to programming questions in /r/Haskell feel free to tell me to stop.
Based on your question all I can do is to take a wild guess: do you draw several things on the same plane? Like the white grid on top of a black square for the background? Then you may have a problem with Z-fighting. Maybe you can post a screenshot?
Ok, will do next time. I promise =)
Looks about right ... Those lines do intersect, but I'd guess that it is not the actual intersection points that are flickering? Maybe check that you have depth buffering (GL_DEPTH) enabled? Still guessing here.
I'd be in favour of this.
You can use `mallocBytes` for this purpose today. Note, however, that the `Storable` `malloc` combinators do not actually listen to `alignment`, and the alignment they do supply will not be good enough for, say, the SSE instructions on your machine to be perfectly happy. To do so they'd have to use `posix_memalign` rather than `malloc` and then you run into the issue that that isn't available on every platform, and the way to `free` memory with larger alignments can vary considerably across other platforms. https://ghc.haskell.org/trac/ghc/ticket/9806
Agreed. I think that downvoting creates a very negative culture. It makes people afraid to express unpopular or contentious opinions, and also at least in my experience and others I've spoken to, it makes people censor themselves to pander to the crowd in a way that creates more resentment than just plain-speaking. Frankly I wish we could disable it on this subreddit, or in the least re-name it to "Mark as spam" or something. So I tend to pretend the downvoting feature doesn't exist. I ignore comments that I don't approve of. I tend to just upvote things that only have one point to show that someone read it and thought it was worth reading, and don't bother upvoting anything else really. Although I often find myself upvoting comments I don't agree with just to offset the unfair downvotes on it. Is there anything the mods can do about it? In some subreddits I've seen the downvote either hidden, or with a hover pop-up that asks the user to carefully re-consider. 
...who said anything about 7.10? :-)
I share your belief, and I think we're fine here because this is a focused, self-selected community, but looking at how large subreddits work vs how image boards work, I think voting is a failed model. You get the bad content either way, but voting also removes all niche content.
&gt; THE BALKANIZATION OF OUR WEBSITE INTO MULTIPLE NATIVE APPS WILL CONTINUE UNTIL REVENUE IMPROVES &gt; SOME OF YOU HAVE SENT ME YOUR PASSWORDS ON TWITTER THIS IS NOT SECURE!!! PLEASE ONLY USE EMAIL!!! &gt; OR FTP!!! &gt; I GET THAT WE'RE AGILE NOW BUT WE'RE NOT MOVING FAST ENOUGH &gt; WE SHOULD REDUCE AGILITY AND INCREASE SPEED BY CUTTING OFF THE LONG TAIL &gt;PREDICTION: 2015 WILL BE THE YEAR I FINALLY BREAK YOU &gt;HAHA JUST KIDDING YOU'VE BEEN BROKEN FOR YEARS OR YOU WOULDN'T STILL BE HERE &gt;DO YOU LIKE WORKING ON REALLY HARD PROBLEMS? &gt;JOIN US AND TRY FIGURING OUT HOW TO MAKE THIS TEN YEAR OLD HEAP OF SHIT APP RUN IN THE CLOUD Yup sounds exactly like RL
I guess he is talking about the four posts on the /r/haskell front page with the most comments.
&gt;Tic-Tac-Toe game with an unbeatable AI Are you in Graham Hutton's Advanced Functonal Programming class by any chance?
Nope. Don't know who that is. :) The full story is I wanted to make an AI for the board game Pentago several weeks ago. This was the first project I attempted in Haskell since it would allow me to explore Haskells parallelism and speed. I had previously build an AI in Python, but as you might guess, it was relatively slow. This project was too ambitious at the time, and I got bogged down and abandoned the project, did some more studying, and recently completed this Tic-Tac-Toe game. Now I think I'm ready to attempt the Pentago AI again.
I put together a [CSS snippet](https://gist.github.com/spinda/98200f6ba07f9d175a8b) that adds this in. Preview [here](https://i.imgur.com/6bRpOrG.png).
Yeah, got that enabled. I found a rogue *flush* somewhere in my code and removing it made the flickering a little bit more bearable. Still far from perfect tho.
The more polymorphic the type is, the _more razor sharp_ it is. That's the essence of parametricity.
I've tried gtk2hs (with gtk3), hsqml and having a webserver and launching a browser client. All three approaches are workable for linux+windows, my gtk2hs project failed though because you can't use -threaded with gtk2hs on windows. the web browser approach is workable but you need a haskell-&gt;JS compilation if you want an all-haskell project, and the client-server communication complicates things. I think if you don't know QML and because of hsqml's use of advanced haskell, hsqml has the steepest learning curve, but it would be my first choice now.
Learning lambda calculus as is would be much easier than this.
Looks good to me, please [notify the moderators](http://www.reddit.com/message/compose?to=%2Fr%2Fhaskell), so they can figure out what they think about implementing it. I should add that while I like these things in general, I'll highlight what [snoyberg said](http://www.yesodweb.com/blog/2015/02/awesome-haskell-community) — this community is great and needs these things less than others. However, that also may mean this community is happy to embrace every tool that makes us even better!
Then I hope I'll be there this year.
If you'd like to give my [FLTK](https://github.com/deech/fltkhs) bindings a spin, I'd love to hear your feedback. It seems to meet your needs. There are a number of demos that should work on Linux and Mac. It's almost nearing a release, except for a couple of demos and Windows support.
There are three big ones for pure subsets of haskell: fay, haste and ghcjs. there are elm and purescript for haskell-like. I used fay on my project when I did a localhost web GUI and I would not again: it doesn't have typeclasses, which was a pain for me (difficult to use monads, you need the RebindableSyntax extension or monomorphic binds for each monad you want to use). I would look into haste or ghcjs.
&gt;That's stretching it slightly, I think. He called it puerile but I didn't see him calling people who enjoyed it anything of the sort. Fair enough. I thought his comment was unnecessarily broadly worded and grumpy given the subject matter. &gt;In my opinion, communities can make or break a language. That seems likely. It doesn't address my larger point that perhaps the frequent, overserious, and emotional hand-wringing about the current reputation of Haskell's community does not serve the purpose of actually building a strong community. &gt; Ideally, we don't want to alienate anyone I think Haskell still has a great community around it. I don't think that Haskell has to have only one community, though (it doesn't anyway; there are already at least a couple subcultures, and I don't think that has to be problematic). While something has to be done about the foldable/traversable proposal that will affect the community as a whole, we should recognize that people don't all react to situations in the same way. Not all people will enjoy all humor, etc. But this is trivial. Some feelings and reactions are idiosyncratic and say nothing about the community. For my part, just as there are Haskell IRC channels where I would never go and people I don't follow on Twitter, I think I will stop reading these types of threads here and stick to the more technical stuff (to the extent I can understand it). This kind of infighting I find extremely alienating, and I enjoy Haskell and would rather not be alienated. I don't mean your comment at all, just the larger thread. Cheers.
I think I understand the untyped lambda calculus less after reading that. maybe it works with children, as the article says? I don't know what they'd be learning though.
Man, I can't even edit submission titles to fix a typo. 20k rep (and thus "trusted user" privileges) on Stack Overflow gives me a broader range of moderation tools than being an actual subreddit mod here.
Gleb, Simon, Johan and Alexander, thanks for organising a new ZuriHac! I'm looking forward to it.
Target the browser. I'm having fun with web sockets + d3.js + jmacro + lucid. The very nice thing about jmacro is you can cut/paste js directly in to haskell files. Starting from d3.js examples, I soon found I could tuck raw js chunks away and forget it was javascript. Ditto for html and lucid.
These look great! It's a really wonderful family of packages you're producing here. 
Done!
It's just designed as a Q&amp;A platform... Whereas reddit is better suited for announcements and general discussions. 
Implemented and Upvoted. Thanks!
&gt;Guy who teaches Haskell also posted something personal about him helping a cute girl at a gym. Relevantly, a *private* gym. I scarcely make eye contact in public gyms with other people unless they're trying to get my attention. This was my neighbor and her friend. Their squat form was injuriously bad and I've been lifting for ~half a decade - that's the only reason I said anything. I would've been happy to focus on what I was doing otherwise.
It's not intuitively obvious why it would be harder to indent Haskell than, um, Common Lisp. Either way, I'm really curious what the answers are. It's not really helpful to suggest three different indentation modes on the intro wiki.
As for hindent, please file bugs for where it adds whitespace you don't want it to. You can file issues [here](https://github.com/chrisdone/hindent/issues) and if you tag them with `@gibiansky` I'll see them. I'm fairly satisfied with the style as it is but it is meant to respect user-provided whitespace in many places (especially line breaks), and am happy to see examples of where you think the code is incorrectly or unpleasingly formatted.
So excited! ZuriHac last year was one of my fav. events :) If anyone is interested in sharing an Airbnb or something with me, drop me a line.
Just like the lambda calculus won't make any sense after the students finish learning it this way! Which is exactly what we'd expect, since it's exactly what the green alligator ate!
Awesome! Appreciated /u/jfredett and /u/spindakin.
In Lisp it's trivial to indent because you just count parentheses. In Python it's easy because the indentation is always previous-line-starting-column + offset (e.g. 4). It's hard in Haskell because it has few such obvious cues for the editor to use other than implementing a full parser. The two big indentation modes in haskell-mode are complicated beasts that nobody wants to hack on, but they're useful so they are included in the wiki. The simple indent mode is short, dumb and predictable, so that is also included. There isn't a clear winner, so they're all listed.
My concern with the "upvote-only" thing is that, last I checked, it's purely a cosmetic change and doesn't prevent downvotes from being submitted. I'd be fine with "nobody can downvote", but not so much with "only people who know how to circumvent it can downvote".
Yah, but adding barrier to entry does reduce the rate of downvotes (at least, it seems to, re: other subs that do it). I just sent out the modmail, I figure we figure out whats going on / what (if anything) we want to change, then put up a post for some peer review, then implement the changes based on that feedback
Fair enough. I don't really visit any other subreddits often and I like the "upvote-only" thing in principle, so if everyone thinks it'll work I won't object.
Indeed, it doesn't seem possible to disable downvoting properly. The cosmetic hiding of the down button only gives more power to savvy users control over content sorting.
I dunno if you're active on Stack Overflow &amp;c., but that actually is how it works there. But SO is specifically designed to *not* be a discussion forum, so I dunno how well it would translate to something like reddit.
I use structured haskell mode together with hindent using chris-done's style.
One thing I've always wanted is Haskell syntax highlighting for code blocks, for example: * Go to [this example page](http://www.reddit.com/r/haskell/comments/2vp9yh/adding_to_a_list/cojq83f). * Hit Ctrl-Shift-J in Chrome. * Run the following in the console: $('head').append('&lt;link rel="stylesheet" href="http://chrisdone.com/highlight.haskell.css"&gt;&lt;script src="http://chrisdone.com/highlight.haskell.js"&gt;&lt;/script&gt;'); * Then run (you need to run the first in a separate step to let the JS load): $('pre &gt; code,p &gt; code').each(function(i, block) { $(this).addClass('haskell').parent().addClass('hljs-block'); hljs.highlightBlock(block); }); * Yay, pretty colours! (Copied from lpaste.net) Obviously for inclusion in the subreddit you would clone the .js and .css files (I'm not proposing you serve anything from my domain). On non-Haskell source, like the example above, it doesn't really have an effect.
Ah, I guess that makes sense from a security perspective. Seems so odd for reddit having so many programming forums and yet no code fence support in its markdown!
I would like to start by saying that I am **very new** to Play and Scala in general. My friend literally asked me "Hey, we had discussed this before and I'm really busy this month, so I was wondering if you would like to join me on a project?" which means I'm basically learning Scala(And AngularJS, and bootstrap, and Slick and Play) by doing. However.. Play seems pretty decent, and Scala seems to let it do some nifty stuff, and even though I haven't even had time to look into how these features actually work(or *what* they're even called for some of them) I can see how they're being used in code and I can appreciate how they make stuff easier. I like just being able to add a new route in conf/routes, then adding the corresponding class/method. I also like having a type-safe, ORM-ish(please don't hate me for calling it that) interface to our database. Using sbt to automatically recompile the the project upon changes to the backend is very convenient and gives me a decently(see below) tight feedback loop. There are some things I dislike. I can't really say much about Scala as a language as I am still incredibly incompetent, but as I understood from my friend, Scala "case classes"(which I understand are somewhat analogous to Haskell's ADTs) have the limitation that they cannot contain more than 20-something "fields" .. this means, for example, that we are forced to use heterogenous lists, both for "projection"(specifying which members we actually wish to access/modify in the database) as well as the data we are adding/updating in the database.. in the same order. This is only true for one table, however, and we could definitely be using nested case classes to solve this, and the only reason we are living with it is because of 1. time constraints 2. the database interface was auto-generated, I believe. On top of that, while sbt is mostly cool, it seems to eat up progressively more RAM when I use it, and it is nigh unusable on my meager laptop. I am unsure if this is just the JRE or something specific to Scala, sbt or both. I need to kill it every now and then, it seems. All in all, however, I am pretty pleased to be working with something like Scala as opposed to, say, PHP, this being my first arguably 'real' job with real corporate customers.
This here was posted to /r/haskell a few days ago: https://www.youtube.com/watch?v=2-JFkv9-JOQ Perhaps watch that for inspiration. Something that's interesting for you shows up at some point in the presentation, might help with what you're wondering about "making types" and how limiting it'll be. I don't know if code is shared somewhere. The reddit post for the video is here: https://www.reddit.com/r/haskell/comments/2vdnn1/compose_conference_robots_on_haskell/
To tack one on, there's also /r/haskellgamedev
I'm not sure exactly what you mean by flickering in this case, so this could be way off; but are you using floats anywhere that might affect placement or scaling of the grid lines? I've seen all sorts of weird visual artifacts from rounding and truncation.
Unfortunately it's not possible; see [this thread](https://www.reddit.com/r/redditdev/comments/16esdb/language_specific_syntax_highlighting_in_code/) from a while back. Some subreddits do line numbers, though, via a code snippet that's been passed around and hacked up over the years. /r/python's is nice because it supports RES night mode properly. You can find the source by searching for "Code Block Line Numbers START" on /r/python/about/stylesheet.
Thanks, I see... but... "generalized Prelude", you mean...?
It's really not very remarkable. I've given some consideration to cleaning it up and publishing it more widely (an outdated version is on my github, but it's far from even building successfully right now) but that'd be kidna pointless now until I see how the FTP stuff resolves. I've occasionally tinkered with more drastic Prelude replacements and concluded that it's just not worth the hassle. Anything really interesting ended up with `RebindableSyntax` and major incompatibility with basically everything else.
Omg you won't answer what I want and I'm boiling of curiosity haha but okay, thank you!
Great, congratulations to everybody involved! I guess the copyright notice "© 2014 haskell.org" should be updated though, eh?
The website redesign is great from a new programmer's perspective. I just started learning Haskell a week ago, and I wish this was the first thing I saw. Looks wonderful. Cheers!
not a major issue, but i think the "try it" section should at least have explanatory text when cookies are disabled, like "you need to enable cookies to use this because X". i honestly don't know why it requires cookies, but i imagine i'm not the only one who uses a cookies whitelist.
True, no need to be snarky.
Thanks for the report! It used to point to a haskell book, we promise :-) Choices of what haskell books and resources to recommend are very partial still. If you have suggestions, please feel free to open a ticket or just make them here and we will take it into account.
Can you open an issue about that? I don't remember why it requires cookies but on tryhaskell.org we put a wee notice about it. 
Actually what I was irritated by was the "blessed" top section which included Real World Haskell (2007) and Learn You A Haskell (2011) and the not blessed "older" section which included Hutton's book (2007) and Simon Thompson's (2011). That and the the ommision of Paul Hudak's intriguing [Haskell School of Expression] (http://www.cs.yale.edu/homes/hudak/SOE/) which *is* older (he has a newer work in progress).
Thanks! Technically all the layout and content was produced in 2014 with only minor tweaks this year so the claim is accurate, but we changed it to 2014-2015 for good measure.
I suspect that saying "maybe you should check your work" when pointing out a fault always comes across badly. 
That's sloppy, absolutely. We'll try to get it fixed up soon.
Fixed it. Thanks. By the way, people thinking of criticizing that example please also read [this issue](https://github.com/haskell-infra/hl/issues/46) which includes the motivations behind it and what would be expected for an alternative example.
The plan now is a link at the bottom of the page. We can further bikeshed later. What I'd love is someone to tackle redesigning the wiki frontpage to highlight its wealth of content instead of serve as a "Hello, welcome to Haskell".
Ysangkok: Thanks for publishing it here I have to say that this title is much better than the current one
Desire, sure. Active plans, not yet. If you want to do this, or know somebody that might want to take that on, then it would be very welcome!
Thanks for that link. I was about to criticize it because of its extremely poor performance, but I understand why it's used as a code example now.
Nice. Do you have a benchmark comparing these lenses with TH-generated ones?
There seems to be a layout problem in the news section: http://i.imgur.com/F7oqtdf.png. (I'm using Chrome on a Mac.)
There doesn’t seem to be any prominent mention of the Haskell Platform — e.g. no mention of it on the main “downloads” page, and so on. Is it being deliberately deprecated for some reason, or was it seen as unnecessary, or what? (Generally agreed with others, though, that the new site seems great!)
Much better! Good job on the new site.
Install-page for Ubuntu shows one problem: https://www.haskell.org/downloads/linux GHC and Cabal suggested are somewhat old already. So, my question is, would it be normal to ask hvr to build some "current" or "stable" version-synonym?
You can use haste and hplayground. This is a demo site (sorry for the lack of styles): http://tryplayg.herokuapp.com/ 
This is #1 now on HN https://news.ycombinator.com/item?id=9052129 There may be valuable comments from the outside world. *Edit* … which are downvoted as always.
Shouldn't the download page at least *mention* the Haskell Platform? Also, the Windows download page has [this](https://a.pomf.se/hoisli.png) saying "more information", where those words aren't clickable or anything, so I don't know why it's there.
Sometimes you can extract the AST from a function using type-classes. This great article explains the method: http://queue.acm.org/detail.cfm?id=2617811 The relevant part is "How to Extract a Deep Embedding from a Function". The idea is that you have a type for expressions and write an instance of a type-class (say Num) that instead of evaluating a number builds up an AST. You can then "run" ordinary Haskell functions that use Num with your new type-class instance and get an AST back! The arguments you give to the Haskell functions should be AST nodes with unique names (say variables). Anyway, here is some code that demonstrates how you can capture the implementation of the "subtract" function: https://gist.github.com/raek/be13f53d0292c4f0f3e5
Another one of these anger accounts, 4 comments and all are downvoted... Come on, learn some better mechanisms to cope with your anger and then write a constructive comment instead of being condescending and putting fuel into fires. I understand that frustration can easily lead to such actions, but they are hardly ever useful to anybody except as a vent for oneself.
Great job, congratulations! I think it's the first time I see a newly designed site that *properly* reneders in a 800px wide window ;) And has the right information, in the right order. Trying to look at it as a newcomer, I'd suggest a few adjustments: * Give an answer to the question "Does is run on my platform?". Say that it compilers into native code on x, y, and z, that in-browser javasctipt target is worked on, JVM backend not supported, this sort of stuff. * Give an answer to the question "You got me, how do I proceed?". Make a section with pointers to entry-level tutorials and books. * Perhaps de-emphasize the "community effort" section. It's a bit noisy and not very helpful for a newcomer.
I recently talked to someone about free monads. I like them and find the abstraction they provide very useful. But my dialog partner insisted that free monads do not deliver good performance. I couldn't agree nor could I object, because I simply didn't (and still don't) know. I've googled a bit, but found almost nothing. So, you're probably better off benchmarking your free monad abstraction then. Can somebody share some insight on this performance issue?
&gt; The downside of free monad approach -- it is very polymorphic, and you can't make it less polymorphic I'm not sure I understand your point. If you use a free monad transformer, you can mix in io easily.
The only section I don't like from a design perspective is "An open source community effort for over 20 years". It feels devoid of real content -- and I really enjoy watching Haskell talks, so I think that linking to videos is a great idea. I think the content of the talks should be featured (title/summary/speaker) rather than the market-y visual of a blurry photo with thumbnails from videos which say nothing about them. [edit: and I know I can hover for the tooltip, but that's bad design IMO as it is crucial information.]
Do you think it might be possible to have a website which is both modern and informative? Is there is a specific subset of the information which was on the old website but not on the new one which you found particularly valuable? Can you tell us more about the reasons why you would have left the page so quickly?
[Mine](http://github.com/deech/fltkhs) installs pretty clean on a Mac. And you can write your GUI's completely in Haskell.
My attempt, using the List monad http://lpaste.net/120537
This is exactly the niche that I'm trying to fill with [threepenny-gui][1]. It's a GUI library that uses the web browser as a display, but you only ever write Haskell code. It also has some FRP built-in. [1]: https://wiki.haskell.org/Threepenny-gui
Luv the new homepage : )
That's the wrong place, few reach the bottom of the page, that's where legal boilerplate and seldom used links go. 
I made a PR for the Platform on the Windows page: https://github.com/haskell-infra/hl/pull/64/files 
Perhaps it's slow without the [codensity stuff I don't understand anyway](http://comonad.com/reader/2011/free-monads-for-less/) ?
By the way, given that it does not attract much attention, what do you think about the article?
I agree that this is a problem. First thing I tried was something like λ xs = [1, 2, 3] &lt;hint&gt;:1:4: parse error on input `=' λ let xs = [1, 2, 3] not an expression: `let xs = [1, 2, 3]' This was frustrating. As an experienced Haskeller, I understand what these messages mean, and I can figure out that I need to do something like let xs = [1, 2, 3] in map (+ 4) xs But the audience here is beginners. Can this be made to work more like ghci, allowing things like `let x = 2` on a line by itself, and ideally also multi-line expressions? (I like the idea of a free editing space with a Run or Evaluate button.) This small quibble aside, I like the new site a lot! 
That's a very nice idea. Now that the wiki only has to be a wiki it can really sell itself that way and grow without worries about sounding official. A front page full of topics/highlights sounds neat. You have access to make those changes?
It's clear that we need to have a community discussion about where Haskell Platform goes from here. Since changes to the Platform and its process, like changes to the Prelude, are effectively changes to Haskell itself, it is very important that we not repeat the mistake. Let's make sure that the discussion is extremely well publicized. But in the meantime, please make sure that all download pages on haskell.org link to the Haskell Platform.
There're 30 or so people actively engaging the tutorial presently. mueval wasn't built for this kind of load. We discussed doing some optimizations if there was time for it, but in the end thought we'd bite the bullet as this kind of traffic only happens once for a day during the launch and then it'll go back to 2 or 3 users active. 
There is one issue with the page, which is that there is no clear call to action for what the user should do next. They try out some things in the REPL and then what? Maybe the page should mention some resources like books or social networks (like Reddit, Google+, IRC, Twitter, mailing lists) so that the user has some concrete steps for what to do next if they are interested in learning the language. Edit: Oops! I just saw the "Learn more" link in the middle part. Maybe it's just a matter of making that link more visible.
I'd like to put some decent beginner videos in there like "A Taste of Haskell" and things like that. These videos come from the mockup stage but weren't that harmful so they stayed for now. The idea of this section is to show "look, real human beings are using this thing, who meet up and have conferences and give talks, etc.!" The photo is blurry because I didn't have it in high-res form, as I cribbed it from Google. :-P But maybe the Haskeller who took it can give us a higher res one.
&gt; While this new one is shiny, this century and all that, at the end it's mostly useless. If I was again the guy, kindof interested but undecided, I was around 2006, I would leave this page in about 10 seconds, and never look back. Sorry, but I don't think that's a step forward. That may be the case. Fortunately, while I obviously disagree, we can be scientific about it: We have some years worth of analytics data for the old wiki home page, we can see: * What the bounce rate is * Which links people click, and where they go next * Which links people ignore * How many repeat visitors there are versus newbies Once the new homepage has settled (and this initial launch heat has passed), we'll have measurable data on the efficacy of the home page compared to the last.
you did it with signals? or is there another way?
From my recent experience with both Haskell Platform and MinGHC on Windows, I have to say that MinGHC is way easier to actually use, since by itself it's already able to build things like the `network` package.
Awesome! Thank you :)
Tekmo, sorry again... I've noticed you are doing just string substitution when beta reducing (the "subst" function) so that isn't really much different from what I'm doing and might suffer from the same speed problems for large programs. But, I guess (and I'm not sure if you have a proof) this is the fastest way to do it anyway, correct? Great job, by the way.
If you want to integrate a Hoogle search box or anything else more deeply integrated let me know - happy to provide whatever you think would work best. 
yeah, i like the idea of the section a lot. for me personally watching a practitioner give a talk about a language they love is inspiring and gets me interested more than anything else. maybe there could be more context for the videos too, two tabs, "beginner/introduction" and "advanced"? default to beginner?
As I mentioned, we still have the old wiki. My hope is that its frontpage can be redone to highlight still more content and still less form, and more experienced Haskellers can just retrain themselves to go there by default. (Now, as Adorno has written, "form is sedimented content," but in this context I'm afraid I'm unable to do anything interesting with that aphorism.)
Where are you guys based on? Meaning where do you meet?
Due to lots of issues with the GHC schedule and related things, it does not feature nearly as current things as we would like. The Platform has many fans still. (including me -- I still run it whenever I setup a new Haskell environment). I also think you're right that more discussions about how the platform relates to other services should be conducted. See for example the only semi-baked idea here: http://www.ozonehouse.com/mark/platform/GPS-Haskell-HIW2014.pdf In the meantime, we absolutely need to put the platform right there on the downloads page. This is really just an oversight.
Not a fan of these "fork" links. There are many reasons to go to a GitHub site for a project, and forking is one of the rarer ones. 
It seems like the wiki links from the News page are broken. They just redirect to the top level of the new wiki instead of to the pages themselves.
Oh, I agree it should be on the download page, I was mostly just speculating on why other installers might be there instead of the HP. Edit: Is there any particular reason why the HP is still using 7.8.3 instead of 7.8.4 considering it was just a bugfix release as far as I recall?
Thanks for the feedback. What other frameworks do you mean? The only one that I know for parallelization in Async, which is compared in the article. Anyway transient is unique in his goal which is aimed to confront a flaw in software design that has existed for decades and is now confronted perhaps only in the Scala community. Yesod is a web framework. It has nothing in common with transient. But I imagine that you mean an example using Yesod. The article is in draft state. For that reason I did not publish it in reddit. This library has a lot to be done. I detail that in the conclusions. Beyond my bad marketing, Honestly I think that it is revolutionary. I´m still editing it. I promise to improve it!
How about bringing Yi up to par with emacs + haskell-mode ? It's a project that would benefit all haskell devs and all of you. And it is entirely in haskell unlike haskell-mode which is in elisp. 
Do we have analytics to track things like "conversions" or whatever actions we want visitors to take?
Thank you so much, Daniel Santa Cruz, for all your work keeping the HWN going -- I know it can't have been easy doing so while moving cross-country, and dealing with a new baby in the family. Thank you, Kim-Ee Yeoh, for stepping into the void.
Oh I haven't looked at Contol.Category but that seems like a useful generalization (based on the small amount of Category Theory they taught us in Algebra). Presumably that generalization would call for another Prelude and now I do see how things would start to get bloated and re-export issues would pop up.
That's a good point. I can also see issues with merging together "Prelude branches". I supposed the number of Preludes would have to be kept to an absolute minimum. 
Apart from the laugh at HIPster, one of the things that really resonated with me was Purely functional (whatever that meant at the time)! I honestly do not remember what I first thought of that and what it meant.
This is a very introductory talk about Haskell. At the beginning of the year the number of attendees at Boston Haskell skyrocketed from ~20 to ~60 when we became more proactive in doing outreach. I wish to offer my apologies for the video quality on this one. This talk was recorded before Greg Hale stepped up and started cutting together the amazingly crisp videos that we've had lately.
haskell cocos2d library for game development
Unfortunately OpenGL profiles don't appear to be configurable from the FLTK side. But it does [support](http://www.fltk.org/doc-1.3/opengl.html) drawing with OpenGL by overriding the `draw` method of `Fl_Gl_Window`. The Haskell binding allows you to override that method with a Haskell function. You can see this in action in the `cube` demo. I haven't ported it to Haskell yet simply because I haven't gotten around to it, but it is ported to C. To build it: 1. install FLTK 1.3.3 2. clone the repo 3. cd into repo. 4. `./configure; make`. This will build and link just the C binding and place it in `./c-lib`. 5. `cd ./c-examples` 6. `make cube`. This will build an executable called `cube` and place it in the `../executables`. 7. `../executables/cube`.
Thanks! 
Without the ability to set up a specific OpenGL context, this basically locks you in the stone age, graphically.
mssql-simple, just like postgresql-simple but for mssql.
I don't know much about OpenGL so I didn't even consider this a problem when I started the project. I can only say that there is a [patch](https://groups.google.com/forum/#!msg/fltkcoredev/ogdzbBSBZmI/MDHStt2s_AMJ) that *might* make it into the main branch. So maybe the next version will support this ...
&gt; Is there a general consensus on which one sucks least or is that not even clear? No. Whenever this topic comes up people comment on their preferred one but have little to no comment to say about the others. I don't use any of them.
Here are some [benchmark results](https://ro-che.info/articles/2014-06-14-extensible-effects-failed). The main cost of free monads is that they work by building and interpreting an explicit AST data structure; they're essentially interpreted embedded languages in Haskell, which yields a slowdown at least as bad as a switch from Haskell to a scripting language. However, the overhead often doesn't matter, especially with EDSL-s that translate to expensive external calls, like in Haxl. 
can you link me to any good resources about it? I google it once a month and nothing seems to "stick". whenever I install it (on OS X) it doesn't build with some error or another. and I am wary of any editor that doesn't have all the thousand things emacs does. but writing editor plugins in haskell just sounds amazing. I did write a light table plugin, but then went back to emacs soon enough. so I might be willing to work on it if there were good tutorials / architectural diagrams etc. and if I had a sense of who the developers were and what its status was light table's UI is btw based on html/css/js, and written in clojurescript. if we could write client/server plugins all in haskell, with ghcjs or something, that sounds even more amazing. also, maybe I'm in the minority, but I don't know other ui technology (besides browser stuff, like "gtk"?), which have always been a pain whenever I tried learning them. /end brain vomit
Yep, and this is very much like replacing [] with Seq.
That's an excellent design! I particularly love that the Try Haskell online interpreter is *right there* on the homepage, encouraging newbies to *try haskell*.
yes please
At most hackathons, some folks show up with projects they want to work on or talk to others about, others show up looking to pitch in, and things generally sort themselves out.
+1
Fixed. Lemma 2 is now Lemma 1, etc.
We were [talking about this in #haskell](http://ircbrowse.net/selection/haskell?title=fmap laws&amp;events=19931638,19931641,19931643,19931644,19931645,19931647,19931653,19931662,19931663,19931665,19931667,19931669,19931672,19931674,19931680,19931683,19931684,19931689,19931692,19931694,19931696,19931697,19931699,19931700,19931703,19931705,19931708,19931710,19931711,19931713,19931715,19931716,19931718,19931719,19931720,19931722,19931724,19931726,19931730,19931732,19931733,19931735,19931736,19931737,19931746,19931747,19931751,19931752,19931753,19931754,19931756,19931757,19931758,19931761,19931763,19931766,19931770,19931773,19931779,19931780,19931782,19931784,19931787,19931788,19931792,19931801,19931806,19931808,19931811,19931812,19931813,19931816,19931817,19931818,19931819,19931825,19931826,19931827,19931828,19931829,19931830,19931832,19931833,19931835,19931836,19931838,19931840,19931842,19931844,19931850,19931852,19931853,19931855,19931856,19931857,19931859,19931860,19931861,19931863,19931868) last month. I also didn't know *why* this came for free (though I'd seen it claimed and taken it as read) but after that, admittedly muddled, conversation it clicked. 
Note that you only get a bunch of left-associated binds if you use `forM`/`mapM`/`replicateM` or pretty much anything implementable in terms of `sequence`. However, those functions are already bad for performance even for other monads.
I think the `put` in the free monad example was supposed to be `put'`, but I still loved the post!
In practice, when using `Deferred` in functions, something like a thunk would be created, and all of the functions that use the value of the promise would wait until the async operation was done. But that would all be behind the scenes, on implementation level.
Could you please explain `$map` a little bit?
Yes, it's trivial to determine the indentation level but there are conventions about how things like, say, (unwind-protect...) or giant (ecase...) statements get formatted that aren't necessarily related to their nesting levels. But Lisp was probably a bad choice to bring up here, point taken.
&gt; There're 30 or so people . . . this kind of traffic only happens once for a day You sound so... optimistic. (I've considered a few "avoid success at all costs" jokes, but they're all awful. I give up, sorry)
South India 
I think the lemma 2 above that should also be lemma 1.
In the spirit of constructive feedback: This post is very confusing. You use a lot of terms slightly incorrectly, or perhaps with a different meaning than we expect; for instance your explanation of "polymorphic" in another post doesn't seem to correspond to what we usually call polymorphism. When I write /r/haskell comments, I try to say *one* thing, and I usually re-write it several times to make sure it makes sense. People around here expect ideas to be stated very clearly.
Fixed.
`Putline` and overzealous use of `error` in suspected problem functions.
It might not be as cool as making a complete project yourselves, but documenting an existing library might be a good project. It's possible to do at many skill levels and is easily parallelizable (you can split the modules up among people, or work on multiple existing projects). It's doable in very small chunks; even if you document only a few functions that's worthy of a pull request. And it'd be a good contribution; lots of Haskell libraries lack API documentation and examples. 
I go to great lengths to make the type system enforce data invariants. At a minimum this often requires smart constructors and abstract data types. Better though is to represent the invariants in such a way that I don't need to make any of the data types abstract. Sometimes it's helpful to write parametric functions rather than functions that operate on concrete types; parametricity ensures that the functions can't do certain things. Once I do all that I can hammer functions with QuickCheck tests. Using the type system to enforce invariants, and having a bunch of types that are not abstract, means that it's easy to write generators. If tests fail, I break bigger functions into smaller ones and test the smaller bits so I can isolate the failure point. Most functions aren't longer than about ten lines. For complicated functions, even ten lines is way too long. Sometimes for brain-dead boilerplate longer functions are needed. Sometimes this means writing some tedious types, which is fine. For instance I've got a big pile of code that represents any date (well, any Gregorian date from the year 0 to 9999) entirely using static types, even leap days. That was tedious to write, but then the type system enforces the invariants. I have no faith in myself to enforce those things. After all that, I never need to trace anything, and in fact I could barely debug anything in ghci.
hi2 is my favorite. It just makes it super easy to deal with all the indentation level options.
&gt; For instance I've got a big pile of code that represents any date (well, any Gregorian date from the year 0 to 9999) entirely using static types, even leap days. That was tedious to write, but then the type system enforces the invariants. Is this public or in a library somewhere? People have asking for better/safer/nicer datetime handling in Haskell for awhile.
? How is that supposed to work. &gt; let fib 0 = 1 ; fib 1 = error ":(" ; fib n = fib (n-1) + fib (n-2) &gt; :trace fib 4 Stopped at &lt;exception thrown&gt; _exception :: e = _ &gt; :history Empty history. Perhaps you forgot to use :trace? I can poke the exception with `:print` and `:force`, but I can't really see anything that resembles a stack trace.
I insert foo x | trace ("foo " ++ show x) False = undefined as the first line of a function definition to trace calls to that function.
I also cultivate my own debugging functions which are all based on "Debug.Trace.trace". However I have realized over the past few years that if I am relying on this method too often, this is usually because I have written a program that is too procedural in style, and not enough functional in style. * spare no effort in making all computation pure * write smaller functions that can more easily be hand tested for correctness in GHCi * try doing all IO through well-designed, lazy, Traversable data types using "Data.Traversable.traverse" Sticking to these design guidelines, it is much easier to debug programs with one or two "trace" functions and "error" functions.
I'm still holding out for a debugger...
Really, `(&amp;)`? That seems like a recipe for confusion!
Sorry I can't help more now, but from my experience and a short glance at your errors wxcore is probably expecting a different version of C++ compiler.
Why? It's quite an established convention thanks to the popular [`lens`](http://hackage.haskell.org/package/lens) expansion pack for Haskell
I have had a similar experience with `haskell-indentation-mode`. It does not even respect the `haskell indentation space` variable (I have this problem with all indentation mode including `hi2`). It is problably related to the fact that I am using emacs 24.4. I have found [this issue](https://github.com/haskell/haskell-mode/issues/377) but it does not solve the problem for me. I haven't submit an issue yet because it might well be my configuration that is wrong somehow ...
TDD, specifically quickcheck.
I usually also use `trace` to find out in which area of the program the bug lies. When I've found that, one technique to isolate the bug is to just write QuickCheck tests for the involved functions, testing the invariants that you think should be true. This also gets you a reduced counterexample. 
big improvement :)
Support the [IHaskell] (http://gibiansky.github.io/IHaskell/) . I am not affiliated with the project, but my guess is that they are in need of some additional display adapters. From the top of my head a nice project would be to write a display module for gloss... Although that probably doesn't involve much Haskell. 
There is also the [FPComplete Hoogle](https://www.fpcomplete.com/hoogle) which searches through a lot more packages by default.
What's not concrete about the type `Day`? Its internal representation is not directly Gregorian, true, but the functions `fromGregorian` and `toGregorian` are completely concrete functions involving only `Int`, `Integer`, `Day`, and tuples. What problem are you trying to solve?
Can you list explicitly what you would want to add or change in the GHCi debugger?
I like this: foo x y z | trace (" foo called with " ++ show x) False = undefined foo x y z = ... -- normal function It's almost as good as a stacktrace.
We always keep "constraints: network installed" in cabal.config. That's not so hard to explain to newcomers, but it should be the default on Windows. Or should *have* been. If MinGHC solves the problem going forward, so much the better.
ghci includes a debugger. no one (including you, evidently) uses it.
I have a feeling that the covariance of `$map` follows from the existence of our candidate `fmap :: (a-&gt;b) -&gt; (f a -&gt; f b)`. I don't think you can have, at the same time, this `fmap` and the synthesized `$map` that would go in the opposite direction `(b-&gt;a) -&gt; (f a -&gt; f b)`. 
This can work for exporting different sets of functions by default, but it doesn't work for typeclass hierarchy changes like the AMP. If instead of changing the Prelude to add Applicative f =&gt; Monad f we just made a new version of the Prelude named differently with that change, then you could not use any other module that still uses the old prelude without also importing the old Monad class with all it's functions, ... (because those modules do not provide instances for the new monad class)
Could the packages be compiled at the time they're uploaded to Hackage or wherever, to determine their exports/imports, with these exports/imports then uploaded to Hackage, and downloaded by any cabal install that requires that package?
That does sound like it's a frustration, since "uninstall what they have and start again with GHC and cabal" is wrong advice. It's possible - and easy - to work with Haskell Platform. There are a few issues that do come up that are trivial to work around; why not just help them with that?
Just to clear up some misconceptions: * You can use the latest version of cabal-install with Haskell Platform. * You can install any up-to-date packages that you want with Haskell Platform. With HP on Windows, you do need to make sure that the network package doesn't get updated by using a "network installed" constraint in your cabal.config. And that, in turn, does limit some package versions. If the MinGHC installation solves that problem - I haven't tried it yet - then great.
luite's project ghcjs is full-blown GHC (lightweight threads, STM, all extensions, javascript FFI and soon even TH support) that compiles to javascript (browser and/or node.js).
Not yet, though if it were it still only handles conversions from a YYYY-MM-DD Gregorian string to a Data.Time.Day, so it doesn't do anything else (like date arithmetic.)
I don't quite see how you would use this. When/how would you introduce `Deferred`? How would you resolve it later?
I'm aware you can't shuffle core desuraging typeclasses this way, but only one chanhe (AMP) needs that. Things like FTP are just as you say "shuffling things around".
yes. every installs now come with rootkit. it creates invisible partition, so you have to wipe out. 
`network` is not the only thing that fails to build though, this was just an example.
You make a good point. I think it's good to keep both sides of the argument in mind. However, I might point out that it's pretty hard to substantiate the "save an enormous amount of time" part of your point. Part of me wants to argue that while debuggers can save some time in some situations, if one is using the good practices demanded by the situations where debuggers can't be used, the amount of time saved won't be as enormous as you claim. When I think about all the Haskell development I've done in the past few years, I can't think of any problems that seem like they would have significantly benefitted from having a debugger. On the other hand when I think back to my pre-Haskell days, I can think of some situations where the debugger seemed like it was a big help. So I've been in both camps at various times and when I was in each camp, I thought that camp was the best. But I can't really make a definitive statement either way.
Because you can’t. I encourage you to join the effort at setting newcomers up so you can see all this first hand rather than speculate. For a long time, the HP shipped with a very old GHC. This included bugs and incompatibilities with newer packages people wanted to try because they’d read about them. This problem is thankfully in the past, but was due to a lack of automation in putting the platform together. Not just building a file for folks to download, but also the kind of CI that Stackage has now brought to the table. Okay, so lets say you don’t want a recent GHC. If you’re on Windows, you install the HP and think you’ve got a working environment, but then cabal suggests you update it, and you can’t build network. Okay, set aside Windows and wanting a recent GHC. The HP has historically used the global package database which meant that if you want to install something exciting from hackage like yesod or lens, you would probably break an already installed package. We have sandboxes that largely solve this problem but HP has not worked well with them due to the aforementioned package db issues. The HP concept is great, but the execution has struggled to keep up with the ecosystem. Thankfully there are lots of people out there beyond just me who notice these problems, which is why we now have a great new download for Windows, a great new download for OS X, Stackage and Stackage CI, Docker images, Halcyon, and an increasing investment in Nix. All of these efforts are wonderfully positive responses to the less than ideal state of the HP and should be pushed in the headlines rather than pretending that the old option is still the best option.
You might want to consider using real sandboxing setup on a server. For http://paste.hskll.org I use [restricted-workers](https://github.com/co-dan/interactive-diagrams/wiki/Restricted-Workers) library that uses SELinux, chroot, and rlimits. Together with the [interface to GHC API](https://github.com/co-dan/interactive-diagrams/blob/master/eval-api/src/Diagrams/Interactive/Eval/EvalWorker.hs) it shows better performance and security than mueval, because it does not actually try to start a new GHCi process every time, but keeps a small pool of processes that it accesses. In theory, you can even move workers to separate machines, although I haven't tried it and I am not sure if the latency is worth it. 
Take a look at https://github.com/time-cube/time-cube but note it's a work in progress.
Because nobody has done the work yet. A couple people started on this idea, and we even had a GSoC proposal for it (but it didn't get funded). This idea is covered breifly in my [blog post on Cabal Hell](http://www.well-typed.com/blog/99/) that explains how the different problems and solutions relate to each other. The idea you're talking about is referred to there as "Package interface compatibility tools".
I took the time to enumerate several specific problems with the HP. If you know how to address them, please, please do rather than just say you know how to. Install the HP, then install yesod. This is what new users do. I don’t know to make that an easy process, if you do please write it up somewhere so we can point people to that resource.
&gt; Could the packages be compiled [somewhere else], to determine their exports/imports Nope. The availablility of CPP / Setup.hs allows essentially any part of the build environment to change any part of the exports/imports. 
It's not at odds. There is basically one goal: preserve as much symbol information as is reasonable. Compiling with symbols enabled should have no impact on the program performance when optimizations are enabled, unless there is a bug in the compiler.
Notice the dash. It's entirely new research ;-)
If stack trace are built by following the stack pointer backwards, both function inlining and tail-call optimization will change the stack trace. There very much is a tension between optimization and debugging.
In that case, do you have any particular advice for using this style of debugging in Haskell, in pure code, for performance/non-termination bugs? My lab is currently using a wrapper around hslogger heavily relying on `unsafePerformIO` and on somewhat on TemplateHaskell.
Did you check https://hackage.haskell.org/package/bound ? It offers an efficient and very generic representation for binders/variables, and there are some example of evaluators of lambda terms to normal form or whnf. If you benchmark it, please publish the results.
How does Agda handle multiple libraries/packages declaring overlapping/conflicting builtins? Is there some kind of conflict-resolution?
You may also compile with -rtsopts and then run with ./program +RTS -s which gives a summary over memory-allocation, cpu-time and gc-time (i often use https://wiki.haskell.org/ThreadScope for having a look at multi-processor-performance - but i think this does not apply to your problems .. yet :) )
$30 is incredibly steep for such a paltry amount of content, not to mention how limited the scope is. You'll likely learn more from LYAH for free. Edit: /u/josuf107 reminded me about correct word usage and such.
downvoting is not hating. don't take it personally.
You can use debuggers for purposes other than actually debugging. In my Java days, I was using the debugger extensively to track the program execution and understand the code base. I find a function that I'd like to track, to understand how and when it's called. Nowadays high-quality IDEs can generate a stack trace statically for you(basically a graph of callers) but lots of time it's just not enough because 1) sometimes you need to see the concrete values and actual stack trace 2) if you're using reflection(for dynamic dependency injection purposes, for example) debugger is your only hope. In Haskell I think this is still a useful approach, because: 1. We don't have IDEs that generate a caller graph. 2. Even if you can grep/ack/ag your code base to find usages, you can't easily track the function call between different (third-party) packages. 3. With the presence of XMonad style modules, you may have to track things in runtime. (as in the dynamic dependency injection case above) 
I think you mean "paltry," unless I am really confused about what this book is about.
You actually can, but only in the case where 'a' does not occur in `f` at all, this is the phantom case above. But in that case you can derive both `fmap` and `contramap`.
I try to hit a lot of conferences and hackathons each year. Between them, hackathons are probably my preferred venue: I get to meet a lot of faces that are newer to the community and wander around and help people with projects that I never knew existed.
An entire book on Maybe, about the simplest data type in the Haskell Prelude after the traditional ones available in most languages?
I think the biggest problem is that these are not actually well specified, even for a single package version. Options can change what's built, CPP can rewrite imports, TH can do arbitary IO, and it's sometimes possible to write code that works with multiple versions of the same function without any external mechanisms. I strongly agree that it would be great to catch these things earlier, but unfortunately it's complicated.
*Now* I know what halcyon is. Great post, thanks! Halcyon looks very interesting.
Thanks for this, Ollie! I'm giving you a vote on a comment on voting on comments.
The motivation seems interesting to me: &gt; This book won’t teach you Haskell. It will teach you just enough Haskell, in a short amount of time, that you can understand its explanation of some cool, pragmatic functional stuff. You might even take these concepts back to your object-oriented language. &gt; Hopefully you’ll be motivated to make the time to actually learn Haskell from another resource after reading Maybe Haskell. I have a hard time putting myself in the shoes of the target audience, but I'm willing to believe it exists, and I like the idea of reaching out in that basic a way!
It's uncertain until we have a post-mortem, but I'd hazard saying that the sarcasm is unwarranted. The original context of that comment was people being worried about targeted MITM attacks, and I'd say that that's less likely in this instance than just an automated exploit randomly tagging an unpatched server.
This seems to be missing all of the concurrency machinery necessary to make it go.
I'm guessing they're trying to give people something where they can be productive as soon as possible with the absolute minimum information needed.
&gt; just 
I've used it some, it works pretty well as far as I can remember.
We should hold off on being negative about people willing to share what they know with the wider world before we've seen the content. I've noticed new people wanting to make `Maybe` values "go away" either because they thought them inconvenient or because they weren't comfortable with the use of Functor/Applicative/Monad. This book could help with that frequent source of awkwardness. I've had to steer a *lot* of people away from using `fromJust`. Edit: It occurred to me that there are slightly more awesome methods for managing `Maybe` values floating around in your data with `lens` and `Traversable` but it seems unlikely this book will go that far. Fingers crossed.
I go back here for reference all the time.
&gt; One more idea, you could pretty easily set up an HTTP proxy or stunnel on your own machine and point cabal-install at it, such that it upgrades the connection to TLS. That encrypts the traffic between yourself and the proxy, but not between the proxy and hackage, so you're no better off. 
Yes, "just". Unless you think a drive-by exploit is as worrisome as a targeted attack?
GCC/Clang both support compiling with debugging symbols and optimization flags simultaneously. Of course, the symbols are not quite as accurate because of inlining etc but it's still way more useful than seeing pure address numbers. The debugging symbols should have no impact on the optimizations at all.
Have you looked at [Minimal GHC](http://neilmitchell.blogspot.com/2014/12/beta-testing-windows-minimal-ghc.html) yet? Back in November I would've agreed with you, but now that we have something that won't curse god and die when it needs a different/newer version of `network` I'm pointing Windows users to that installer instead.
It's also an established *very different* convention in every other language, like, ever. Expanding the community was a goal, last I checked. But, spilled milk at this point I suppose.
Almost seems that "Haskell Platform considered harmful" may be the case?
Looks like a nice option, thanks!
I've found myself in plenty of situations debugging Haskell where a working debugger would have been very useful. Also note that the good practices themselves can be quite expensive to adhere to.
On OS X, in my experience it is way easier to set up Haskell without HP than with, fwiw. I don't think it was always this way, but it has been for at least a year.
This used to be true before MinGHC. But with every GHC upgrade the platform caused me a lot of pain because everybody updated their packages on Hackage causing me to fight back using upper bounds... Instead of providing stability, by pegging versions, the platform was wreaking havoc instead. 
Hmm from reading the package I doubt it offers an asymptotic advantage, but guess it is worth the try... I'll report if anything. Thank you! 
 For the record, the hosted files were daily builds of HEAD. Despite the domain name, these packages did not have "official status" anywhere and were not distributed outside of that site to our knowledge. In fact there are very few users that we know of -- to the point that when the site went down, there were no reports filed or complaints made. That said, when the service gets up and running again, the key will indeed need to be replaced.
Hoogle is now linked, hopefully to your satisfaction. In the future, some sort of "omnisearch" box would be great -- but those are significant engineering effort to get right.
I wish this would be taken care of as soon as possible. It completely deterred me from learning Haskell and choosing it for my project, which is a shame since Haskell has so many nice things going for it.
The timeit library is a minimal thing to get the rough sort of thing that you're doing now: http://hackage.haskell.org/package/timeit
"Install the Haskell Platform" from a single link is a simple way to get a reasonable haskell environment on many machines, and the package list sets a minimum standard for a distro or OS to be measured against. Asking a new user to choose between half a dozen more or less supported build tools and systems still seems like a path to confusion. You need to demonstrate a viable alternative to the community, that all the distros and OS teams can support. So far I don't see that.
&gt; Asking a new user to choose between half a dozen more or less supported build tools and systems still seems like a path to confusion. &gt; &gt; You need to demonstrate a viable alternative to the community, that all the distros and OS teams can support. This is an important point. Is there a way to achieve the goals mentioned here w/o Haskell Platform?
Totally. What you get (easy, reliable unit tests) is more important than how you build it. :)
&gt; I've found myself in plenty of situations debugging Haskell where a working debugger would have been very useful. Oh, I'm certainly not going to argue against having a debugger! I might, however, argue that they might not be such a huge time saver for someone comfortable with other debugging styles, and that if one relies on them too heavily they might find themselves at a loss for what to do when confronted with less debuggerable problems. &gt; Also note that the good practices themselves can be quite expensive to adhere to. Yes, but you don't have to go full-up best practice logging. Print statements are quick and easy to instrument. My point in mentioning the large scale production best practices was to point out that this isn't just some backwards idea promulgated by those who refuse to adopt modern debugger technology. It's very common if not essential in certain domains, which means that debugger-free debugging skills can have significant value.
Good to know.
What this is is just an *abstract* implementation - in that this is what the user-level functions would **feel** like. Similar to IO, which can do all sorts of cool stuff, but the nastiness of implementation is hidden from us.
I know a couple people that would like it if there were more libraries in `base`, but I've heard sound objections too.
Using `(&amp;)` for anything conventional isn't really an option here because `|` has syntactic meaning, and being half-conventional is worse than doing something entirely different.
Stunnel can be operated in either fashion. Stunnel also has a client mode that accepts unencrypted connections and then turns them into encrypted connections. HTTP proxies can do any combination of HTTP to HTTP, HTTP to HTTPS, HTTPS to HTTP, or HTTPS to HTTPS. So if you run an appropriate proxy either on your local machine where the client is located, or at the very least a local area network that you have 100% control over, then yes, you are better off.
It would be great if private cache had a local LAN network share option in addition to S3. 
What exactly? GHC also ships major portions of mingw. Do we just need more of it? Raise it with GHC and/or the Windows Haskell Platform trackers. In principle there's no reason why a minimal windows ghc installer, and a maxi windows ghc installer ought to do better/worse on this issue of "can I install packages that need to run ./configure".
That’s certainly doable, but it hasn’t been a priority. Please note it’s called [“private *storage*”](https://halcyon.sh/reference/#private-storage-options), as opposed to [“cache”](https://halcyon.sh/reference/#cache-options). Now, I haven’t tried it, but apparently [Eucalyptus](https://github.com/eucalyptus/eucalyptus) is an attempt at an open-source version of AWS. Perhaps you could set up an instance on your LAN, and point [`HALCYON_S3_BUCKET`](https://halcyon.sh/reference/#halcyon_s3_bucket) to it?
[Here is a quick example](https://www.youtube.com/watch?v=iGY3BBqUqH0&amp;t=33s) of haskell-mode integration of GHCi's debugger, by setting a breakpoint on the haskell homepage.
You can certainly use Halcyon without setting up private storage. One benefit is, you’ll be able to install any supported [GHC version](https://halcyon.sh/reference/#halcyon_ghc_version) (including the unlisted 7.10.1-rc2) in 5-10 seconds. Another benefit, only briefly mentioned in the article, is the ability to declare `build-tools` such as _alex_ and _happy_ to be automatically installed in your sandbox. Building your projects will also work, but won’t be ideal. Currently, switching between projects will clear your cache, so you’ll be rebuilding a sandbox on every switch. To avoid this, [set up private storage](https://halcyon.sh/tutorial/#set-up-private-storage) and let Halcyon archive and upload your sandboxes.
This is not for everyone, but for those who might want or need to use the Haskell Platform exclusively, an approach to consider is to forcibly peg your projects to the packages installed with the Haskell Platform. I have found it useful for my personal projects. Since I help build the HP for Windows, it doubly serves as feedback for issues. I exclusively use a sandbox, I never install anything globally or per-user, and I use a cabal.config file in each projects' directory which has one line per HP-installed package specifying a constraint to use the installed version (e.g., "constraints: process installed"). This way, I never get any HP packages re-installed, even in the sandbox. True, this is only useful for a certain style of use, is external to the tool chain with manual steps (and thus ugly and hacky), and does not eliminate all reasons the user might get tripped up when installing dependencies. For me, it has reduced the hugely tangled messes that can arise if installing a dependency would update a commonly used package (e.g., mtl, network, text, etc.).
Is there a transcript?
Yeah, a true `Promise` implementation would have a mechanism for updating the value in place. In Haskell, the standard solution would use an `MVar` for this purpose.
The one thing that Edward seems to avoid discussing is that hedge union and similar problems are solved by ML-style functors. It does become a bit awkward to express some things, but it's certainly another solution to this problem. Essentially, a functor parameterised by an ordering module will produce _different types_ for _different orderings_. So your union operation will only work on sets with the same ordering.
~~To be a bit more precise, this is only true for generative functors.~~ Edit: I made a silly mistake. This comment is wrong.
I talk about it a bit later on in the talk and I point out that the `Set` example is not particularly compelling for this very reason, that you can lift the choice of ordering up into the module itself. However, when you start talking about things like the `Compose` example, or monad transformers, it gets uglier, because now you need to rely on the discipline to lift all the definitions consistently and either lose confluence or you lose the ability to use standard classes to put in and take out those particular members. These basically are the same issues as the 'tagging' approach I advertised elsewhere in the talk. https://www.youtube.com/watch?v=hIZxTQP1ifo&amp;feature=youtu.be&amp;t=1h11m30s all of the issues with swapping 'tags' is relevant, as is https://www.youtube.com/watch?v=hIZxTQP1ifo&amp;feature=youtu.be&amp;t=1h18m30s
Greg Hale did all the work to cut together the audio and various video sources, I just stood up in front of a room and rambled for a couple of hours. ;)
Multiple MonadReader instances means that code doesn't just infer the right meaning. It means that you now have to write manual signatures for _everything_ you write and are reduced to type checking rather than type inference, or manual instance plumbing. I find this to be a terrible state of affairs for end users. If they don't know the end type of their function, they can't just ask. By way of contrast the `(MonadReader e m, HasFoo e, HasBar e, MonadState s m, HasQuux s, HasQuaffle s) =&gt; ...` pattern infers perfectly. Your mileage may vary. You are also welcome to your opinion on the topic of refactoring ML code, I just happen to disagree. I find the things that I have to plumb by hand in a module oriented world to be tedious, and better relegated to the type checker as it is all code that I throw away and rebuild when I refactor the code to a new design anyways, and I'd rather waste the compilers' efforts than mine. Sure, there are **many** places where I'd really love to have ML modules, and not just typeclasses, but I'd not give up typeclasses to get them.
I rely on a rather large amount of such instances to be "magically overloaded" in my code. It adds up. Even a little fragment of lens like `traverse.traverse._2 +~ 1` is asking for 4 such instances to be selected. That is 4 things I don't have to care about naming, which I don't have to make up and clutter that code with.
I approve. It has a bulge, but a smaller one than the current logo.
Sure, and if you only have one instance around, you can do that in something like OCaml too. You only have to choose names when there is ambiguity.
Sure, and in that situation there, the two Traversable instances are ambiguous. I tend to write very small combinators, so the cost of setting up and tearing down all the arguments in question is quite high. Most of my instances are derived from other instances. I lift a Functor and get a Monad for the free monad, etc. At that point almost by definition I'm dealing with multiple instances for the same class at the same time. I can readily accept that you deem it an acceptable cost, but please consider the notion that I do not. 
Ah, yeah, that's a fair argument.
&gt; network, HTTP, OpenGL, etc. can be quite tricky to install, especially for users on Windows. FWIW, this simply isn't the case in my experience. The thing that *can* be tricky to install is MSYS; but once that's working, anything that doesn't have a foreign library dependency falls right in line. And anything that *does* depend on a foreign library is certainly no easier with Platform. (And let's not even talk about profiling.) Today, MinGHC installs working MSYS painlessly and Stackage pretty much covers all the other benefits you raised. I really don't see a case for Platform anymore.
Oh no, that's not what I meant. Yes, you have multiple traversable instances, but it's unambiguous from the types which traversable you meant. With something like OCaml's new implicit module parameters, the same thing can be achieved with modules. Similarly, Agda's instance arguments now support recursive search, so you can do the same thing there.
...without the coherence properties to make it all safe. I can sit down with Coq or Agda and make classes. I get no guarantee that the ways I walk from one definition to its superclasses or other implied results are coherent and have no good way to even talk about such coherence the moment there is any diamond in the graph.
The other problems I ran into (I am on Windows and I downloaded MinGHC): 1. "cabal update" suggests that I update cabal-install, but then it failed at the linking, although that does not affect the cabal that came with the package it is the first "out-of-box" impression one gets; (also while poking around to resolve other problems I found out the config file points the global install path to the default suggested install directory -- not the directory I actually installed Haskell in; and install --global does not work any way due to some permission issues); 2. "cabal install ghc-mod" failed initially. It turned out that even though I did "cabal install alex happy" it still defaulted to using the version that came with the initial install. And the stock "happy" hard coded path to templates to (I guess) the maintainer's directories that don't exist on my machine. cabal/bin is in the PATH but comes after the global install path! Playing the the PATH setting fixed this. 3. In Emacs ghc-mod seems to not like SHM for code insertion as it looks for the indentation that came with haskell-mode. No big deal as I don't need code insertion anyway, but SHM is giving me a hard time with indentation as well. I guess I need to spend more time learning the best way to use it. Okay the IDE does feel advanced when it works, such as company-ghc and the flagging of syntax errors, although I have to say the error messages are on the terse side. Before I figured out that white spaces are significant imagine my frustration when the IDE told me that it couldn't parse all those perfect looking code -- I had to curse out loud a few times! 
I don't think such a reasoning burden is too onerous, but I guess we'll have to agree to disagree.
I could see a few fundamental packages like `text` or `bytestring` (or parts of them) being merged into `base`, as they'd have good chances of becoming part of a future Haskell Report, but I'm not sure if their APIs have finalised enough for that by now... I wouldn't bother merging packages which aren't recommended or aren't used by at least 90% of programs into `base`
I guess the post itself isn't doing well because people are familiar with the report :-) That said, this sort of "first time user experience" is very useful and appreciated. Thanks!
How do you handle actions that commute with each other?
Well, everybody has to choose what to do with their time. Usually, people will want to spend their time with things that earn them money — like writing a new book instead of contributing to an existing free one.
Isn't there a combinator to abstract over the explicit recursion? As in, take an IO action and execute it a number of times (or until it returns Nothing or whatever instead of an Int)
Hi, I co-wrote MinGHC, and sclv pointed this post out. Note that MinGHC is pretty new, so we're still working on it. To answer your problems: 1. We ideally want to ship a binary upstream Cabal unmodified, and that doesn't exist precompiled for the latest Windows version. Unfortunately, the latest one isn't avialable for Windows. https://github.com/fpco/minghc/issues/16. 2. The Happy/Alex precompiled on the web are broken, we're thinking about how to fix them: https://github.com/fpco/minghc/issues/24 3. No idea, not sure if this is anything to do with MinGHC or not.
This reminds me of elm's [response](http://package.elm-lang.org/packages/elm-lang/core/1.1.0/Http). In the elm case, the value is wrapped in a Signal.
I use [Haskell Platform](https://www.haskell.org/platform/) on Windows and it works smooth. Concerning IDE, I think you should [take a look at a previous post](https://www.reddit.com/r/haskell/comments/2sh4b3/haskell_idetext_editor_for_windows/). I use [Sublime Text](http://www.sublimetext.com/) with [SublimeHaskell (hsdev tree)](https://github.com/SublimeHaskell/SublimeHaskell/tree/hsdev) and [SublimeREPL](https://packagecontrol.io/packages/SublimeREPL) and it is totally OK for me, even better than Eclipse was in my Java days.
We definitely *do* need something that does what the Haskell Platform is *supposed* to do. The problem is that we don't really have that right now - HP itself in its current state isn't a great solution anymore. HP is not just a way to install GHC and some libraries. We always had lots of ways to do that, and now we have many more better ways. HP should not replace those - instead, it should leverage them. HP is supposed to supply the following: * A simple, clear web site that provides a simple default install. For every major platform. For people who don't want to research options. * A reasonable default set of libraries that allow you to "just do stuff" for people who don't want to research what libraries to use or learn a whole new programming paradigm. The original model for this is Python's "batteries included", although our choices don't need to be the same. * Libraries that are known to work together well - not just build together like on Stackage (although building together is obviously a prerequisite). Work together well means both that they actually work, and that they make sense together conceptually at least loosely. * Libraries that are mature, proven, and well maintained. So definitely not bleeding edge. * For people who then want to try other things - other paradigms, closer to the bleeding edge - don't get in the way. Maybe even be helpful :). But make sure not to force people who just want to work simply to face confusing choices. Every major programming language provides something like this. It's what people expect. What is the best way to provide this? EDIT: Also: Kept reasonably up-to-date. So some significant automation is needed, to allow agility in releasing new versions.
Another idea: Automatic release-time semantic versioning for Cabal packages ala [elm-package](https://github.com/elm-lang/elm-package).
Indeed! Let's also give credit to /u/ndmitchell, who was a big collaborator on this.
How does that field access interact with polymorphism?
Small formatting issue near the end, in the paragraph: "PrimState is an associated type giving the type of the state token. For IO, that's RealWorld, and for ST s, it's s. primitive gives a way to lift the internal implementation of both IO and ST` to the monad under question."
As far as I know, this... record.foo ...desugars into... .foo record ...so that the syntax is just sugar. But Elm does have extensible records / structural typing so that .foo has this type: { b | foo : a } -&gt; a 
What kind of problems are you talking about? Are you talking about the so-called "time leaks" that have plagued FRP libraries in the past? If so, that is unrelated to laziness, or more accurately, solvable with additional laziness.
The package `monad-loops` provides a [wide variety of such combinators](http://hackage.haskell.org/package/monad-loops-0.4.2.1/docs/Control-Monad-Loops.html). I'm not aware of anything along those lines in the standard libraries, though.
tl;dr - The report isn't a GHC User's guide. There are better resources for that. Please pardon Haskell's seemingly large barrier to entry, the tooling is better than it seems on first encounter (though not as good as it can be). While I certainly empathize with your frustrations in trying to get started with Haskell, I'm struggling to understand how any of your complaints directly relate to the Haskell 2010 Language Report. Indeed, they all seem to stem from your use of a particular implementation of that standard. Especially considering the "Great Debate" currently, some of what is in that report will surely become irrelevant (or might not be covered at all). I think the [Haskell website's documentation section](https://www.haskell.org/documentation) (recently revamped) has some great material for learning Haskell. [Stephen Diehl's guide](http://dev.stephendiehl.com/hask/#cabal) is especially useful with respect to addressing some of the stumbling blocks you seem to have tripped over. 
There is this problem, yes. But in my practice it is very rare. The type of your computation is `(Num a, MonadReader a m) =&gt; m a`, or, if you specialize it, it could be `MonadReader Integer m =&gt; m Integer`. Even in the absence of the inference problem, neither of these MonadReader constraints is descriptive. If `MonadReader Integer m` pops up in your code, you wouldn't know how you should satisfy it. So I always newtype the things that go into these classes. I could say newtype Score = Score Integer myComputation :: MonadState Score m =&gt; m () -- could be inferred myComputation = do Score score &lt;- get ...
Is this primitive *Haskell* or primitive *GHC*? Most of the article seems to indicate that we are talking about GHC, but the intro sounds like we might be talking about more than that. I imagine the idea of primops is pretty universal, but other than that I don't know what of this article is also valid in JHC or UHC, if anything.
Unioning two sets that were constructed with different orderings is not even a well defined operation because one equality may remove duplicates that the other one does not. Therefore unioning sets with two different orderings should clearly just be impossible. That is the case in Haskell because you only have one ordering per type, but it's also impossible with the module approach because unioning two sets with different order is a type error. So it seems that for the Set case, modules+implicits are superior to type classes. Rather than relying on coherence to ensure that two dictionaries that come from different places are equal it's much better to have only one dictionary associated with the `Set t` module in the first place (an instance of the general rule that it's better to make invalid states unrepresentable than to rule invalid states out by some separate mechanism). In the video you mention that there are other examples that are better than Set, such as Compose. Can you expand on what concretely is the problem with implicits for that, and why a similar solution as for Set would not work?
It sounds like the general material is intended to be Haskell but this part is certainly GHC. 
Yep It works just fine. You just need Rank-2 Types.
You do that. The vast majority of others do not. I'm rejecting it because the path you are calling for leads to incredibly higher levels of breakage to transition, an end state where the world remains divided indefinitely, requires greater use of qualified imports not less, and requires a language extension to boot. So it has a worse transition cost, and an end-state that requires more noise for more users for all time. That is a lot of strikes.
The next HP for Windows needs to be built on MinGHC.
&gt; We have a ReactJS-based approach with GHCJS, similar to Om &gt;...we haven't published it yet. :( 
Adam visited Boston Haskell over the summer and gave a talk. (OK, he wandered down the street. He's over at MIT these days.) While this isn't technically a Haskell talk, the content of the talk is -- I think -- quite interesting to the average Haskeller. It showcases how a powerful kind/record system lets Ur/Web do all sorts of interesting things for the very pragmatic goal of making a nice language for designing web applications.
&gt; I would love to see an article explaining Monads using hands-on examples. Things I can try in ghci. http://blog.sigfpe.com/2007/04/trivial-monad.html
What are the examples of this for other languages. I've never seen the analogue for any other language. Could you enumerate some examples please? 
I tend to prefer to make my code as polymorphic as possible to reduce the number of places where I can accidentally be depending on accidental details of the data types in question. It encourages me to reason by laws and has the benefit of helping type inference to boot. I don't think either one of us is going to change the other's viewpoint at this time, however. =)
=) Those kinds of captions are why I went nuts trying to manually caption the lens talk. Oof. Tedium.
are there any static call graph analyzers for haskell?
Well I would imagine you could prove the coherences too :-P
Not only as kqr notes are cabal sandboxes new, but "maintained and working minimal installers" for windows and os x are relatively new as well. Additionally, a consistent set of core packages that all work together is important, and platform was an important effort to put that together and ensure such packages were available on all platforms. Now that we have other CI systems such as stackage as well, how all this stuff relates becomes a more open question. Some prefer to stick to platform as their "base universe", some prefer to CI against stackage head, others want something more like stackage LTS, and some even just want "all the latest stuff on hackage".
Copied from wiki "There is no universal agreement about whether to include zero in the set of natural numbers." But that's off topic :) 
s/MinGW/MSYS/. GHC already comes with MinGW. &gt; Can you point out where I should raise this https://github.com/haskell/haskell-platform/issues
I'd adopt a different approach there. Throwing a ton of type variables at this encoding of the problem without any attempt at factoring it to make good use of existing abstractions makes it a mess, but lets take it apart and rebuild it in a form that can: `StackSet i l a sid sd` has 5 type variables, but only uses them in 3 distinct parts. `Screen i l a sid sd`, and `a`, `Workspace i l a` Also, `Screen i l a sid sd` also references `Workspace i l a` So we could deconstruct the design of `Workspace`, but that requires deconstructing properties of `Stack` first. The `Stack` that serves as the real work-horse, can be made an instance of `Functor`, `Foldable`, `Traversable`, `Comonad`... After that `integrate` becomes `toList`, `focus` is just `extract`, etc. Now up to `Workspace`: The `i` and `l` parameters are just sort of bolted on `Workspace` in an unvariegated manner and could for the most part be fused away. data Workspace b a = Workspace { tagLayout :: b, stack :: Maybe (Stack a) } `Workspace` is now a `Bifunctor`, and is meaningfully `Foldable`, `Traversable`, etc. Now we can work our way up to `Screen`. `screen` and `screenDetail` are passed together all over, so if we fuse those as above, and parameterize on the workspace notion we get: data Screen f sd a = Screen { screen :: sd, workspace :: f a } which is kind of boring, but it can also be a nice `Bifunctor`, `Foldable`, `Traversable`, etc. since `f` isn't going to be a `Monad`, the argument order is better served the other way around to enable the `Bifunctor` rather than monad transformer pattern. Now we can get to `StackSet` data StackSet f s a = StackSet { current, visible :: Screen f s a , hidden :: [f a] , floating :: Map a RationalRect } Now, I'd probably carry on and explore whether i wanted 'a's in both positive position and in key position for a `Map`, which is more or less spiritually a negative position argument, but that would be how I'd start. In the end we shed type variables, and limit the number of concerns at any given point in time. In exchange to get back the current `StackSet` behavior you're working with a slightly more complicated type, `StackSet (Workspace il)` or so, but in far fewer situations, and along the way you can take advantage of not having to name a ton of things, and most of the time it is clear you don't care what the properties of `Workspace` are.
The current implementation of reflection can be written in well-typed core, but requires trickery to build through the surface language, which is designed to forbid precisely what it achieves.
Note: During the talk I take care to point out that it is the generativity of the type in question that makes this safe. The support we're talking about would basically just be GHC taking the 2 combinators and typeclass under its wing and ensuring they don't break. (It actually works on both ghc and hugs today using the fast code path, and on every legal Haskell compiler with MPTCs/FDs using the slow path.)
You should just bring a stenographer to your talks. Joking aside, Mirabai Knight of the open-source [Plover](http://plover.stenoknight.com/) project has been trying to get more young folks into stenography, as it's kind of a dying art, and the machines are prohibitively expensive for hobbyists. I was thinking that if the low-cost things she's trying to bring about take off at all, there's a whole world of videos out there for new stenographers to practice on, and the practical upshot is that everyone gets free transcriptions, and it helps people who can't hear, or who want to watch videos silently in class. Win/win.
I dug up this old comment. http://reddit.com/r/haskell/comments/vfkf5/the_trouble_with_frp_and_laziness/c549efm
I responded with a comment on space leaks in FRP, but acknowledge that it may not actually be about time leaks. I don't quite remember the details, now. 
Back at the 2012 HIW, Mark gave a good overview of the sorts of things we were looking for parity with: http://youtu.be/st22QE-g0uo?t=3m47s The entire talk is a nice summary of the motivation behind the platform and process.
Type Providers are, essentially, a way to get type information from dynamic sources at compile time (or even at "develop-time" in an IDE), so as to provide type-safe bindings to external data sources that can vary based on the columns in a database table, etc. This talk, very neatly, not only shows how they are implemented in Idris, but on top of that a _great_ technique for how to use metaprogramming to "intercept" ugly type errors given by type-level programming, and dynamically rewrite them to a nice, DSL-specific human-readable form. I would _love_ to leverage that technique in GHC, and it seems very doable!
Good point, thank you. I've added the following paragraph: &gt; While this chapter is called "Primitive Haskell," the topics are very much GHC-specific. I avoided calling it "Primitive GHC" for fear of people assuming it was about the internals of GHC itself. To be clear: these topics apply to anyone compiling their Haskell code using the GHC compiler.
Both correct, good catches. Thanks!
I think that section is a very valuable dive.
Some pretty cool papers on the topic: * http://verse.aasemoon.com/images/7/76/Quantum_Lambda_Calculus.pdf * http://arxiv.org/pdf/1406.4481.pdf
Such a lucid explication. Just wow! Other writings look great too but I have not got around to them yet.
It is about compiler techniques but you made a good point. I agree it is not the same as realizing that Python object is a wrap around a dictionary. OTOH can one presume a high degree of probability that a typical Haskell user would enjoy reading up on underlying language theories? Or is this already common knowledge among proficient Haskell users?
Oh really cool, Leuven is closer to me than the Ghent FPG (and actually my next job, starting in 3 weeks, will be in Leuven and I hope to bring Haskell there) ! Thanks for posting this here, I didn't know about it. Is there a Twitter account to follow for next events ?
This does not solve my problem, I have solve it already. My question is about hGetLine and hPutStrLn, not about the simple getLine and putStrLn, they are different. I just want to ask does the two function memory the position they have read and when they called next time, these functions find the position and read the next line in the file, you do not understand my question. But I have solve it. ?!?!?!?!?! 
I guess the greatest challenge will be to get enough people who are gifted with explaining/writing skills to contribute to this as well as get this into a reasonably coherent presentation... I hope this project will succeed!
Why not a wiki, and why not just encourage more work on [Wikibooks Haskell](http://en.wikibooks.org/wiki/Haskell)? Not that wikis are perfect, but since the wikibook already has a lot of intermediate topics (GADTs, laziness, etc.) why not start there? Also saves you from setting up all the infrastructure.
To me Wikibooks Haskell was one of the most useful resources for learning Haskell. But I think we can do even better. E.g. active snippets can be very useful. FP Complete already has an amazing system, where you can run any example by yourself and play with it. It's all in the browser, so a user doesn't even have to set up anything. Everything is one click away. They will even run a webserver for you. I think in long run, building that new infrastructure will prove to be beneficial.
I dug up this old comment. http://reddit.com/r/haskell/comments/vfkf5/the_trouble_with_frp_and_laziness/c549efm
Upvoting is also a form of censorship.
I think in long run, building that new infrastructure will prove to be beneficial. My only problem is that that the proposal seems to be to build a highly centralized system that will have authorities which will decide whether your content is worth publishing or not. It has its benefits, but it also has its negatives as well. Imagine you want to write a new blog post on some subject. If we make an analogy with starting a new project, it will be like starting a github repository for your new project under somebody else's github profile. I hate to raise that subject. Nobody likes to talk about materialistic motivations, but let's face it, we still live in capitalism. In the same manner as starting a new personal github project under your github profile, you might want to publish content on your own site / github page. There might be many reasons for it. E.g. as a freelancer you want to build your credibility, while sharing free content with other people. Even if we don't consider the material side of it, building great content takes time and dedication. Sometimes you want your content to be as you want it. You don't want to be at complete mercy of the publisher, who will have the ultimate power over your content. You want to be able to share your version of the content as well, without depending on the publisher. If somebody wants, they can fork, modify your content and share their version of it. IMO, that's is what open source is about. If system is going to be too centralized and/or depend on a central authority, it will be no good. That being said, for discoverability there should be a central place. E.g., an outline or a mindmap of the content would be nice. But, IMO, there should be an option to have the content itself decentralized. Besides, there is ALREADY plenty of great content out there. It just need to be discoverable or searchable. I good example is pyvideo.org. Videos can be hosted anywhere by anybody, but there is a central place where they are discoverable. But I think it can be done much better. For blogs, perhaps users can submit content they found and pages can be crawled with a bot and added to a database. Then whenever somebody wants to use a library, then can search all blog posts or pages, which mention that library or that function.
Thank you, as a beginner this was great to read such an in-depth explanation into a few "simple" functions. 
In the proposal, I said: &gt; Commit rights to this repository will be granting very liberally. This will be "centralized" in the sense that there will be a central, primary Github-based repo. It will be decentralized in the senses that: * Git is a fully decentralized system, so anyone is free to fork the content and host it elsewhere. * The plan is explicitly to have a wide base of people who are able to edit the content.
When you compose many things into a single module like you propose now the properties of the module in question depend intricately on the properties of the parameters you've put on the data type. It requires more information locally at the use site to switch instances. It requires you to know about properties that may not have existed when you defined the data type and combinators in question. Claiming we can capture the constraints about the parameter in the object using constraint kinds is similar to using the GADT solution mentioned early on when I was discussing the `V2` example. You now need another parameter to talk about "what we know about the argument `a`", and now you need a whole new vocabulary for swapping in and out a's, `fmap` and `traverse` and the existing Haskell vocabulary won't do, you get one-off combinators everywhere. It also doesn't help that it isn't easy to talk about entailment with constraint kinds. the `constraints` package gets you some of the way there, but given constraints that can be upgraded there isn't a nice way to get the type checker to give me a `Constraint` that reflects `Foo a :- Bar a` to the constraint system. I have tricks that render the constraint system cartesian closed, which I use in `hask`, but the type checker isn't smart enough to take advantage of that fact automatically. What I meant by #2 is new classes can be made easily in Haskell and instances can be assigned for existing data types. So trying to capture all of the properties for all of the instances you know of in tags is a rather Sisyphian task. We have an open world assumption inherent in the design, trying to capture all the properties in _one_ tag runs into other problems mentioned above, and trying to "curry that information out" and lift it to the module itself runs into many of the same issues as tagging.
It should be noted that the sieve implemented here is equivalent to trial division and is not actually the Sieve of Eratosthenes in the sense that it has asymptotically worse time complexity. An in depth explanation of why this is and how to implement the Sieve of Eratosthenes with the correct time complexity can be found in the paper [The Genuine Sieve of Eratosthenes](http://www.cs.tufts.edu/~nr/cs257/archive/melissa-oneill/Sieve-JFP.pdf)
Since you worked for a document company in the past, I'm a little surprised that you try to make the claim that two different authoring formats are essentially equivalent because of the existence of a program that claims to translate from one to the other. Nevertheless, even if we strike that one, markdown on github is the clear winner over wikibooks. Here's a different way that the existence of pandoc adds another point for markdown: it is easier to publish to multiple formats and media types.
From a cursory glance it just requires to understand some basic Ocaml syntax, which should be pretty similar to what you have in Haskell. I would be more worried if it required you to know about Ocaml's module system.
You're right of course, it's a bit unfair to imply that there's a perfect mapping of all constructs or that we have a lossless roundtripping. I just meant that it's not unreasonable that the content from the Wikibook could be imported, or if desired, vice-versa. So yes, the presence of documentation in the Wikibook is a point in its favor, and one worth considering, but it's not a monumental undertaking to export it to a different place. And, now that I think of it, it's probably also possible to host Mediawiki content on Github as well.
You can always use the cabal flag `--allow-newer` as a last resort. But usually you can fix these kinds of things with at most one or two `--constraint` options (or entries in `constraints:` in your local `cabal.config`.)
(I assume parent was suggesting MediaWiki in general, not necessarily Wikibooks). &gt;The amount of effort required to get a Github repo to the level of functionality of Wikibooks is essentially 0; publish a Markdown file and you're done. But it's easy to extend with further features which we have no ability to do on Wikibooks Seriously? A Git repo can barely do a fraction of what MediaWiki can. There are dozens of extensions for various purposes. Moreover, the syntax is extensible, so features can be added if needed. You can't say that about Markdown on GitHub. &gt;From a content creation standpoint: it can be surprisingly difficult to get people to contribute content to a highly structured document set, simply by virtue of not knowing where to put it. Having a very free-form "drop a Markdown file wherever you want" and leaving the hierarchy issues up to a curator will hopefully knock down a barrier to entry. Again, there are extensions for that.
https://github.com/bitemyapp/learnhaskell
Learn You a Haskell is probably the best way to start. It has a light tone but it doesn't shy away from the more abstract parts of Haskell. Parallel and Concurrent Programming in Haskell is also a great book. Not exactly a follow-up to LYAH but it's a really great read.
Try this tutorial, which is very comprehensive and self-contained: http://www.stephendiehl.com/what/
Yeah, I agree. Without the ability to provide more context right up front, my comment was a mistake. The others who engaged with me on it happened to share that context, but I now wish I'd instead written something longer in a gist or whatnot so that people not in the know wouldn't just see it as a bizarre pile-on out of nowhere.
Nice tutorial! &gt; This is quite clever really - it is only considered a hole if it would otherwise be a scope error, so if for some misbegotten reason you decide to name a parameter to a function “_foo”, it will remain a normal variable. There is another valid reason to have variables prefixed with an underscore: it suppresses warnings generated by `-fwarn-unused-binds`. So, not so misbegotten :)
sure, but if you're always ignoring a parameter something is at least a little fishy.
Just FYI, if you're on Debian a far superior way of installing Haskell is using the excellent [Debian Alternatives](https://github.com/byrongibson/scripts/blob/master/install/haskell/README.md) system. Compile/Make to /opt and DA soft links to system directories, add new versions side-by-side, and upgrade or rollback harmlessly with a single cmd line, etc.
Here's another fine summary of how to use cabal sandboxes with OS X: http://www.davesquared.net/2014/05/platformless-haskell.html
There will be a new easyconfig format where you can have multiple versions in a single file, which should resolve that particular issue :)
Wow, this looks like it covers a lot indeed! Thanks for the suggestion.
You're welcome!
I couldn't recommend Parallel and Concurrent Programming in Haskell more. It is very no-nonsense but remains accessible. Loads of working code that is explained in detail. (edit: de-acronymized from PCPH)
How well does D-A work when you have packages installed in your user cabal directory? Especially when they're binaries (since the lib/ directory seems to be segregated by compiler version)?
Yes, we can copy it, and as this thread shows there are multiple libraries that are being worked on. [blaze-react](https://github.com/meiersi/blaze-react) is the library that /u/asayers and me are working on. Having a pure and possibly even serializable state opens up some cool possibilities. In this [demo](https://meiersi.github.io/blaze-react/#1) ([source code](https://github.com/meiersi/blaze-react/blob/master/todomvc/todo-main.hs)), we showcase for example combinators for tabbing between apps, inspection and rollback of their states with a time-machine, and a dynamic instantiation of apps on a per-user basis. We also demonstrate how to handle asynchronous actions by implementing a simple clock. The master branch of the blaze-react repo provides a solid proof-of-concept. As far as I know, /u/bas_van_dijk is even using it in production. /u/asayers and me are currently working on a partial rewrite that generalizes the types such that the state-machines with async requests can be written in a platform-independent way, and only the rendering functions are (partially) platform specific. The main goal is to replicate the development experience demonstrated by [Christopher Chedeau](https://github.com/vjeux) in his [talk on ReactNative](http://youtu.be/7rDsRXj9-cU?t=24m36s).
I suppose it's true that something is a little fishy if you have a usage of an underscored variable name. The only usecase I can think for that is if you're using conditional CPP, and one of the cases uses the variable while the other does not. In order to always have no warnings, you'd need to prefix with `_`. I have parameters prefixed with `_` all the time. Code can be easier to read when all of the bindings have explanatory names, even if they're unused.
What is PCPH short for?
I was mostly thinking about people already struggling with (comparatively) basic concepts like type classes when learning Haskell. An article requiring even basic Ocaml knowledge in addition to the Haskell knowledge would probably not suitable for that target audience. Basically despite the title this article is not for people mystified by type classes.
Indeed! Let's consolidate... Maybe it is a good idea to make a list of existing resources (links to blogs, wiki pages, papers) to be possibly incorporated. We could then reach out for the authors to permit re-use (re-license) and/or simply copy them over if the license is allowing us.
IMO, the only really unintuitive bit in the OCamel code is the pattern matching on records. If they used the more traditional "dot syntax" as in `d.show` then I don't think its too complicated.
&gt; So is there any reason I would want to use http://ghcformacosx.github.io/[1] instead of just using homebrew to install cabal-install? It doesn't appear that there is, is this right? My understanding is that the Homebrew formulas aren't maintained by anyone familiar with the moderate weirdness of packaging GHC and Cabal libraries up. I use GHC for Mac OS X because it's pretty painless, and I don't end up with a bunch of cruft in my /usr/local. It's also way easier to upgrade (just drop the new app in /Applications and change your path). Trying to upgrade brewed GHC is a nightmare, in my experience. &gt; I have in the past had this in my ~/.ghc/ghci.conf: &lt;snip&gt; I have a setup like this: .haskellbin/ ├── basics ├── dev-tools └── ghc-mod Each directory under `.haskellbin` is a sandbox. Then, in my PATH, I have a line (`fish` syntax, but you'll get the idea) like set -x PATH $HOME/.haskellbin/**/.cabal-sandbox/bin $PATH
&gt; Besides the presence of content on Wikibooks already (which, as I mentioned, could be copied to a new system), what advantages does that format for hosting provide? The github solution looks really awkward? Github's markdown display was intended for documentation, not a wiki. Github doesn't properly color Haskell anymore either.
The issue I ran into with this is anything using libgmp with the homebrew cabal dies at not being able to link it. I gave up trying to fix it and just use the haskell platform but am testing out using nix on osx right now.
What I Wish I Knew When Learning Haskell 2.2 ( Stephen Diehl ) http://dev.stephendiehl.com/hask/
&gt; I certainly don't see active snippets as a big enough win to justify scattering documentation around the web and dissipating effort in this way Scattering documentation around the web is actually a good thing, counterintuitively. It improves discoverability and increases the perceived social proof of the Haskell language. In fact, this is a common theme I notice where good programming practice is very often bad documentation practice. I believe this is the reason why many programmers are so bad at documentation. For example, as programmers we prefer to centralize things and avoid duplication, but in documentation repetition is a good thing because it helps reinforce the concept. Similarly, we consider it a code smell if we have lots of similar variations on some function, but in documentation having many variations on teaching the same topic is a good thing because sometimes you only understand something if you see it from many different angles. 
No. The problem ado notation is trying to solve is that people want to get the (potential) benefits from using the `Applicative` interface without needing to know a different syntax. Just use do notation for everything - it'll use the `Applicative` interface where possible, and the `Monad` interface when necessary.
Also the part about sequencing the effects in a different order from the function's arguments, without having to have some `(\a b c d -&gt; f d b a c) &lt;$&gt; ...` business, ~~doesn't apply to~~ isn't helped by applicative brackets either.
This sounds great, I'll do my best to contribute. How about including some exercises with accompanying tests? 
I don't think being used to something is a good reason to avoid seeking alternatives though. I'm also perfectly used to and comfortable with these operators (and their friends), but I'm starting to question whether I should be.
Define intermediate Haskell
Since this comes up a lot - Spring '13 is recommended on purpose. The newer cis194 courses got weird and stopped being appropriate for beginners learning Haskell. Could be because UPenn added a prerequisite to taking cis194 so some of what was covered got shifted around, but I don't really know. I didn't want to bother them about it.
Is it really a tutorial? It's so dense with information, I previously thought of it as a reference.
There is an important difference between wikis and github. Most wikis are oddly horrible for discussing content, so they actually don't scale well beyond 1 contributor per page (Wikipedia is a total disaster in this regard, but worse is better). Pull requests are much easier to work with than most wiki systems. They make it clear that people are notified about changes and contributions are discussed (with line comments) before being committed.
Copying my reply to this thread below. --- Adding context from what brought me to start thinking about using idioms: * I'm tired of writing (and reading) the awkward `f &lt;$&gt; z &lt;*&gt; y &lt;*&gt;` z pattern. * It's a pain with editor support and pretty printing (which is a solvable problem, but not the kind of problem I'd like to solve). * It feels like using `&gt;&gt;` and `&gt;&gt;=` for monads instead of do-notation. * The `[i|…|]` idiom quasi-quoter seems like it can solve these issues for me. So I've started trying it out on future codebases. Naturally I added support in SHM and hindent which reduces this pattern down to basic function application, which is great for editing and reading. The more function arguments, the more of a saving this is. Here's a fair comparison of before/after on my ace package's parser: https://github.com/chrisdone/ace/commit/36767780ca356db75468f803b0c91388186c0441 I say it's fair because this example involves mostly a low number of arguments, but a couple larger ones with obvious savings. (But I'm the kinda guy who writes `do x; y` instead of `x &gt;&gt; y`.) The more pathological examples come from e.g. writing JSON/Binary instances or formlets or optparse-applicative things, which regularly have &gt;5 arguments. Pros for the template-haskell-based quasi-quoter: * It doesn't seem to add any noticeable compiling overhead to this large module (see commit message for timings). Cons: * Nesting is not supported by quasi-quoters. * Currently it lacks the Alternative support as proposed by Conor. That would look like this: [i|TopicalizedSentenceExistential existentialTopic (optional (try sentenceCoord)) |TopicalizedSentenceUniversal universalTopic sentenceCoord |TopicalizedSentenceComposite compositeSentence|] Given that nobody is maintaining the applicative-quoter, I might go and add support for this extension too. That would also substantially improve the Parser.hs example above. It's quite similar to the parallel list comprehension notation. One nice thing is how trivial it is to move to and from pure to monadic/applicative code with this. Comparatively, I've never used arrows ever and yet GHC has built-in support for it. Meanwhile Applicatives have wide application (hehe) and we're stuck writing this clunky stuff. But I figured I'd play with the quasi-quoter and see how it feels, and see if other people get onboard with it. 
Does anyone know why isn't snd recommended as a relevant binding? Why should hoogle be necessary for that? 
You could always use `zipWith (+) [1,2,3] [4,5,6]`.
Fair. I rescind my snark :)
Agreed!
I haven't noticed any problem with that, seems to work ok so far, but can't claim any extensive test coverage.
I think the relevant bindings are just the local ones - it has no way of picking snd out of the visible stuff from the Prelude as somehow more relevant than the rest.
I like that the particular instance is mentioned, because of all the list-y instances there are (zippy, "nondet", diagonal and so on) I don’t really favour any of them over the others. If there was a way to mimic `ala Sum foldmap` to remove the redundancy and mention the particular instance exactly once I’d be quite happy though.
I don't agree, this article made me understand type classes back when I had barely heard of Haskell or OCaml. The only hurdle is a bit of syntax.
That was basically my experience. I learned most of Haskell by *writing code to implement my own ideas* while referencing wikis, docs, blogs. The books (RWH + Wikibook) were somewhat helpful for getting started but once knew the basic syntax I found it more fun to actually write programs. One of my first projects was to write a simple turn-based Pokemon-like game. I never finished the project however, yet the learning experience was extremely valuable. It taught me a lot about how to keep track of state in a pure language – this was before I understood what a state monad is.
As someone who started learning haskell not too long ago, I definitely recommend LYAH. It's just the best starting point, hands down. After that, as many people have said, Stephen Diehl's reference is a good place to expand your knowledge. All the other links are also great, although I can't attest to all of them personally. You should keep in mind that RWH is pretty out of date now. When I was trying to learn haskell, it was very unhelpful for that reason.
Well first you must understand what a monad is. Monads are like plantains in that they are like bananas but not really. Now that you understand what monads are, you can go ahead and read the other comments for the rest of haskell. 
It decreases the syntactic burden as you increase the number of parameters. It's also 1 character shorter with 2 arguments.
This could probably be added pretty easily.
Not all the way down, but [here](https://gist.github.com/rpglover64/1cee031f249ead059970) getZipList [i| (+) (pure 7) [4,5,6] |] I don't know if it's enough to be useful.
I seem to still get syntax highlighting, e.g.: https://gist.github.com/snoyberg/ad3342fbd4bc57039876
I discussed this a little bit in a [NY Haskell Meetup talk](https://vimeo.com/59215336) awhile back. I don't know if it will completely answer your question, but it should be a decent start. TL;DR - Whether JQuery et al are monads or not (though they certainly have some patterns in common), Haskell's purity and type system allows it to get a lot more value out of monads than other languages.
I'm not sure where compiler phases come into it - can you explain what you mean by that? In any case, I'm perfectly willing to grant that `Q` is a monad in which `IO` effects are included, and that it's thus normal `IO`. I see the two ways of thinking as being largely equivalent, because `Q` imposes the right sequencing anyway, but yours is less ugly :-) In Idris, on the other hand, the type providers feature is very much a matter of being in like `unsafePerformIO`: it runs an `IO` computation at compile time, extracts the resulting value from `IO`, and uses it as the RHS of a definition.
Having a "fluent interface" is not the definition of a monad, nor is it a sufficient condition. There must be an identity element that is preserved under return and bind.
deb.haskell.org served daily builds of HEAD. It was never a particularly good way for end-users to install ghc, unless they liked having the untested buggy bleeding edge :-)
JQuery is not a monad. It _almost_ is a list monad, but it isn't equipped with a proper fmap -- instead it sort of "smashes" together the fmap and bind operations. So, it _could_ be, but it isn't. But then a list gives a monad, so the idea that "a listlike thing" could give a monad is not so shocking or farfetched :-) Fluent interfaces in general are too general a concept to be a monad. LINQ workflows _do_ give a monad, along with a bunch of other methods, and they were designed to do so by people who knew what monads were and what that structure was a good fit. In fact, they were directly inspired by the use of monads in haskell. A monad is, as you note, a mathematical construction, given by a category and some operations with regards to it. In that broad sense, you certainly can have things derived from that definition in languages other than Haskell, and even languages without powerful type systems (though there you have to reason your way to those operations much more carefully due to the many ways the laws can be broken if you are not very restrictive). However, if you find a claim that something "is a monad" or "forms a monad" that does not in some way directly explain the relationship to that set of operations, and that does not attempt to show that the operations provided obey the laws we would expect, then that claim is almost certainly lacking.
I don't know if I am correct, but it seems that: &gt; $("#p1").css("color", "red").slideUp(2000).slideDown(2000); Each cal to a method , .css, .slideUp, ... is setting a DOM element value and returning a JQuery container with a reference to the dom element #p1 which the id is 'p1'. Can it be called a Monad ?? the $('#p1") is the constructor ( Haskell - return) or the function unit :: a -&gt; M a and the container is the Monad. Each method chaining seems to be a 'bind' ( &gt;&gt;= ), since: bind :: M a -&gt; ( a -&gt; Mb) -&gt; M b .css :: Ma [this in JS] -&gt; Mb (returns a new JS container) with different or equal value inside the container. I found no sources or papers explaining how method chaining is related to Monads, the majority of sources only did the claim that method chaining is equivalent to Monad in a OO or Mixed language like F#, JS and C#. 
A function that takes an argument of a given type and returns an argument of that same type (i.e. where the domain coincides with the range) is an _endomorphism_, and the general method chaining pattern you're talking about is just related to composition of endomorphisms, which is not really best understood by trying to relate that to monads. In any case, what you have here with the types you suggest is different from a monad for a number of reasons. For one. `return :: a -&gt; m a` Your use of `$` there is actually of "type" `String -&gt; [Dom]`. (where I use the type `Dom` to refer to objects referencing dom elements). So, not the same type. Now, if you only use `$()` to wrap elements of `Dom`, you get closer... Similarly ".css" as a method is of type `[Dom] -&gt; String -&gt; [Dom]` -- so not the same type. There _is_ a function sort of like "bind" for JQuery, because in some contexts it acts correctly. `.map :: [Dom] -&gt; (a -&gt; [b]) -&gt; [b]` However, as the name indicates, while acts as a "flatMap" or "bind" on methods returning lists, it does not act uniformly on methods _not_ returning lists, where its signature reads as `.map :: [Dom] -&gt; (Dom -&gt; b) -&gt; [b]`. Which is rather the proper type for `fmap`. This is why aspects of JQuery can actually feel slightly monadic -- because it comes close. Method chaining isn't in general related to monads, and my sense is you're just starting to get used to monads at the moment. My advice is to just stick to learning how to use them in Haskell for a while, and then at that point you'll be better equipped to make analogies elsewhere. If you start by looking for "monad things" that don't fully relate, then that will disrupt your intuitions before you can properly build them up. (nb to others -- you might find I've played too fast and loose here even, because we can only "return" things that are `Dom` really -- true enough, but there's got to be some sense in which we can say it is a "monad over the category whose objects are Dom objects, and lists of Dom objects, and whose morphisms are functions between them," and it will make some categorical sense, even if it still further removed from `Monad` as a typeclass in Haskell. )
Humans like to see patterns, even when they aren't really there. $("#p1") isn't a unit. The 'a' in the type of unit is important, in _both_ of its positions. `a -&gt; m a`. $ isn't a unit for a whole lot of reasons: First, $ doesn't take an argument of any type "naturally" from `a` to `M a`. It takes a string that represents a css selector, or a couple of other things that jQuery has hardcoded like particular dom objects. There is nothing natural about this selection process. When you feed it a string for a css selector it doesn't give you an `M String` it gives you a jquery-wrapped way to walk a bunch of dom-elements with a fluent interface. Next, even ignoring that, it fails the very first monad law: return a &gt;&gt;= f = f a There is no bind-like operation `???` for which no matter what `a` you give me, `$(a).???(f) = f(a)`. It fails the second law. You can't bind _to_ it. That same non-existant ??? operation would have to satisfy: m.???($) = m $ engages in too much magic for this to hold. Making (???) magic enough to make this work would fail naturality by doubling down on the case-wise ad hoc reasoning that cost us the first law. Next, The method chaining isn't bind. bind is an operation that takes a value and a function, it isn't that you call a bunch of methods on the resulting 'm'. bind itself is an operation that behaves more like `map` than every single operation on some object. I should be able to give you any function, not just a particular jquery combinator. The fluent behavior acts _a bit_ like a list monad/cont-like binding behavior by convention for many particular fluent combinators, but not every one. It is defined with the binding hand-fused into the individual combinator preventing you from abstracting over this behavior. jQuery is a wonderfully useful combinator library that has almost nothing to do with the notion of a monad. The third monad law even breaks down because we don't even have a "real" bind that takes a function. You can't even write the "other" association mentioned in the law for much the same reason you can't write the two forms of bind above. Fluent interfaces are not monads. They are a pragmatic design suitable to chaining together lots of different kinds of selector-like behavior while avoiding naming a bunch of awkward intermediate results. Monads can sometimes achieve this as well, but while chaining, that combinator can capture whatever information it wants, because it can be _any_ function you wrote, not a handful of things folks envisioned and blessed when writing jquery or some jquery plugin that happen to most of the time allow you to continue with a fluent interface, but only by convention. jQuery is not a Monad. jQuery is not Applicative. jQuery is not even a Functor, let alone these stronger things. If you are feeling really generous you might be able to come up with a way to say that it 'feels kinda like' a Monad for dom objects, but given the caveats above, I feel that even saying that brings more bad intuitions than good.
C# does have at least one monad (`IEnumerable&lt;T&gt;`), tools to implement new ones and syntactic sugar to use them. Unfortunately, monad methods usually aren't implemented for built-in types that could be monads like `Nullable` (aka `Maybe`), `Task` (aka `Future`), `List`etc. Though you can implement these methods using a mechanism called "extension methods" and have all the monadic goodness. [TestMethod] public void TestFilterNone() { var mx = Option.Some(2); var inc = from x in mx where x &gt; 10 select x + 1; Assert.IsFalse(inc.HasValue); } [TestMethod] public void TestLinqSome() { var mx = Option.Some(1); var my = Option.Some(2); var sum = from x in mx from y in my select x + y; Assert.AreEqual(3, sum.Value); }
&gt; and have all the monadic goodness. Now try to write a combinator that is parameterized in the choice of Monad. Even abstracting over Linq and Rx breaks down, despite them trying to supply the same API they do it in a way you can't abstract over. F# lets you fake it right up until it becomes recursive, then you are lost beyond hope of recovery. "Traversable" is a thought you can't think.
I've set up a Google Group for this purpose, a Twitter account might follow in the future! Here's the link: http://groups.google.com/d/forum/leuven-haskell
&gt; It's also 1 character shorter with 2 arguments. This kind of argument has been used far too often in the past to introduce syntactic (e.g. optional parentheses on empty argument lists) or semantic (e.g. implict conversions) abominations in various languages that I think we really need different arguments to make a significant change to Haskell.
&gt; Here's a fair comparison of before/after on my ace package's parser: https://github.com/chrisdone/ace/commit/36767780ca356db75468f803b0c91388186c0441 How do you find it in practice? If your example is indicative I don't think I would find any benefit in idiom brackets. The applicative combinator version looks equally easy to read.
You should also check the video lectures given by Erik Meijer on Microsoft's Channel 9(http://www.cs.nott.ac.uk/~gmh/book.html , http://channel9.msdn.com/Series/C9-Lectures-Erik-Meijer-Functional-Programming-Fundamentals). They cover every chapter from the Programming in Haskell book and I think they are a nice place to start + LYAH. Also you should practice writing some code: https://www.hackerrank.com/domains/fp/intro https://www.hackerrank.com/contests/projecteuler/challenges
Yep, I use that, and am in fact considering a `liftN` Template Haskell splice in the mean time to get around the fact that it's only defined for a finite number of parameters.
I believe we could get it down to getZipList (| [1, 2, 3] + [4, 5, 6] |) if we had idiom brackets, and if `ZipList` played with the `OverloadedLists` extension.
In JQuery you could say that `each()` is `fmap`, since `fmap = map` for the list monad. EDIT: But nevertheless, I agree with Ed that JQuery isn't a monad. It implements `concatMap` and `map`, which in Haskell happen to come from the Monad instance for lists. And it implements `&gt;&gt;= f` for a whole bunch of functions `f`. But it implements all of that for Javascript arrays that contain one concrete type. The whole idea of a monad is a generic type that gives a certain kind of common interface for all base types.
&gt; F# lets you fake it right up until it becomes recursive, then you are lost beyond hope of recovery. "Traversable" is a thought you can't think. Does that mean then that the same is true for ML?
That's a fair point. 
Would it possible to solve by making the (implicit) juxtaposition operator polymorphic in some manner? i.e you could overload juxtaposition for applicatives to get `pure f x y` instead of `pure f &lt;*&gt; x &lt;*&gt; y` or `f &lt;$&gt; x &lt;*&gt; y`. For (-&gt;), juxtaposition would be function application.
ML module signatures can talk about parameterized abstract data types. e.g. `type ’a stack`, F# lacks that portion of the vocabulary. They get by by checking some code's type only after inlining it if you ask. let add a b = a + b;; would infer the type add :: int -&gt; int -&gt; int but let inline add a b = a + b;; makes 'add' a function, but the type of 'add' isn't really fixed up front. When you invoke `add` inside the body of a function, it gets elaborated out to its body, then the types of all the variables get picked by surrounding context. This lets `+` do its limited overloading and try to pick the right `+`, so you could apply it to doubles, etc. However, `inline` doesn't work with recursive calls, and you have no vocabulary for talking about type constructors except when applied. So it is really an F#'ism causing the pain here, not an ML'ism per se. 
&gt; By the definition of Monads they are: &gt; &gt; A type that wraps a value or in other words, encapsulates an value &gt; &gt; ... This is a very Haskell-centric definition. See https://ro-che.info/articles/2012-12-26-monads-in-dynamic-languages
In real life - especially if it were more complex than this - I would probably do something like this: pureFunction &lt;$&gt; fetchWith some params &lt;*&gt; fetchMore withOthers &lt;*&gt; fetchYetMore withStillOthers And with the idiom brackets: (| pureFunction (fetchWith some params) (fetchMore withOthers) (fetchYetMore withStillOthers) |) I guess it's a matter of taste how much of an improvement that is.
It's new syntax in an extension, I'm not asking for Haskell itself to be redefined. Not sure if I made that clear in the original email...
I think the real purpose of `ado` is when you have *n* effectful computations but you want to return *m &lt; n* values back out. That, or you want to run the effects but produce values in a different order. Copying from my reply on the Cafe: do a &lt;- x b &lt;- y c &lt;- z pure (b, a) That is somewhere that you'd want `ApplicativeDo`, not `IdiomBrackets`.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**I know it when I see it**](https://en.wikipedia.org/wiki/I%20know%20it%20when%20I%20see%20it): [](#sfw) --- &gt;The [phrase](https://en.wikipedia.org/wiki/Phrase) "__I know it when I see it__" is a [colloquial](https://en.wikipedia.org/wiki/Colloquial) [expression](https://en.wikipedia.org/wiki/Expression_(language\)) by which a speaker attempts to categorize an observable fact or event, although the category is subjective or lacks clearly defined parameters. The phrase was famously used in 1964 by [United States Supreme Court](https://en.wikipedia.org/wiki/United_States_Supreme_Court) Justice [Potter Stewart](https://en.wikipedia.org/wiki/Potter_Stewart) to describe his threshold test for [obscenity](https://en.wikipedia.org/wiki/Obscenity) in *[Jacobellis v. Ohio](https://en.wikipedia.org/wiki/Jacobellis_v._Ohio)*. In explaining why the material at issue in the case was not [obscene](https://en.wikipedia.org/wiki/Obscenity) under the [Roth test](https://en.wikipedia.org/wiki/Roth_test), and therefore was [protected speech](https://en.wikipedia.org/wiki/Freedom_of_speech) that could not be censored, Stewart wrote: &gt;==== &gt;[**Image**](https://i.imgur.com/27fAEGm.png) [^(i)](https://commons.wikimedia.org/wiki/File:Seal_of_the_United_States_Supreme_Court.svg) - *Seal of the Supreme Court of the United States of America* --- ^Interesting: [^Jacobellis ^v. ^Ohio](https://en.wikipedia.org/wiki/Jacobellis_v._Ohio) ^| [^Duck ^test](https://en.wikipedia.org/wiki/Duck_test) ^| [^Billie ^Lawless](https://en.wikipedia.org/wiki/Billie_Lawless) ^| [^Index ^of ^epistemology ^articles](https://en.wikipedia.org/wiki/Index_of_epistemology_articles) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+coq8nho) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+coq8nho)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
`pure f x y z` is equivalent to `(pure f) x y z`. I don't see the type problem. `pure f` would return an applicative, just like it does now, but applicative would implement some sort of "applyable" class (or possibly... "applicative") which would declare "juxtaposition" as an operator. The problem I see there is that everything would have to be in the Id applicative for standard function application to work and you'll have a loop of types or something like that. There are people here vastly smarter than me that may find a way to do this which doesn't require special desugaring or break the type system.
Yup. That's why I'm giving it a test run in TH form.
To be clear, *I* am not making that argumnet. It's about the redundancy and editing overhead of chaining operators. x &gt;&gt; y &gt;&gt;= \p -&gt; z &gt;&gt; x do x; y; p &lt;- z; x Saves a few characters here and there. But that's not primarily why do-notation is better.
Is IEnumerable actually a monad? There's fmap and bind, sure. But I don't think that return is there, anywhere.
I almost died from boredom when reading it.
I've only ever really used Scotty for server side web stuff. For me it's always done the job very well. It's got a similar philosophy to libraries like Flask or Sinatra, if you've heard of either of those. http://hackage.haskell.org/package/scotty
I also did not mean to use character count as part of the main point. It was more an observation that savings occur quite soon.
...and function composition is `&lt;&lt;` (and `&gt;&gt;`) so using the `.` doesn't interfere with that like it would in Haskell.
`OverloadedStrings` and `OverloadedLists` I can get behind. `OverloadedApplication`... worries me. But it does at least sound interesting: let f' = pure f in let apply = (&lt;*&gt;) in f' x y
Ooh. I just got an arduino for christmas, so this will give me a reason to take it out of the box and do something with it! Thanks for sharing!
This is great. I always thought of functional programming as direct mapping to digital circuits design, as it maps more naturally to the way circuits are designed. 
Snap doesn't usually get labeled as minimalist, but if you use only the snap-core package (the majority of the API defined [here](http://hackage.haskell.org/package/snap-core-0.9.6.4/docs/Snap-Core.html)), then it's roughly the same level of abstraction as Scotty. The advantage here is that if your app grows, you can start using Snap's higher level features later with no problem. A number of things have been written that give a more detailed comparison. There's this [StackOverflow question](http://stackoverflow.com/questions/5645168/comparing-haskells-snap-and-yesod-web-frameworks/) from awhile back. Also, I wrote a more [historical comparison](http://softwaresimply.blogspot.com/2012/04/hopefully-fair-and-useful-comparison-of.html) blog post as well as a simplistic [comparison matrix](http://softwaresimply.blogspot.com/2012/12/haskell-web-framework-matrix_20.html) that might serve as a useful generalization.
I don't think the method exists, but it's simple to implement a return method with yield, or just to create an array and call .AsEnumerable()
Don't see an improvement at all. Even worse, now i have to keep in mind the context because explicit operators are gone. 
&gt; Speaking of WAI: this is what I use right now. It's not a framework, just a library for web server connectivity. This is my favourite stack.
Think I implemented something myself... it's not that difficult after all, and gives me complete freedom over where and how to persist sessions. It's really nice, for example, to have type-safe sessions instead of a stringly-typed bag of key:value pairs.
&gt; automatic generation of server-side and client-side code. *Nice.*
I agree entirely with this sentiment. Even if I might disagree with the book itself, which I have no real qualms over, I think anyone investing the time to write a book at least deserves input. I bought it just because I wanted to find out what it was like. A quick run through a few chapters and I have to admit, I wish I had this kind of book earlier to nudge me into the right directions in Haskell land. Thats a 15 minute quick read however. Will read more tonight.
or in another world la3 f x y z
I am the maintainer of Happstack. It is active, though stable at the moment. Much of the recent work has focused on things outside the core, such as working an a major overhaul of the new stripe-haskell library, and a rewrite of the happstack-authenticate library. Also in the works is a completely new backend, hyperdrive, which is similar to warp (but different in important ways). I should also note that the type-safe features of Yesod such as type safe routes, type safe forms, etc, already existed in Happstack (and still do) before Yesod was released. 
For a clinical lab management project, I have Happstack + postgresql-simple on the server side. Client-side, it's Semantic UI. Edit: server-side, there's also Aeson + Blaze's HTML5 modules. How could I forget about the nicest libraries I've seen?
It should also be pointed out that idiom brackets can be implemented without template haskell nor ghc support. https://gist.github.com/mpickering/99d62ccdb73f49840220
Cool
For me it wasn't like that. I liked Haskell, didn't love it, didn't hate it either, but it was as much of a pain in the ass as C (and I really love C, not C++, not C#, plain C), although not as much as Java (damn exceptions).
That's very interesting. Mainly I wanted to know if there is someone who uses it in their every-day job. Thank you.
In this case, naming the subexpressions (as in ApplicativeDo notation) would seem to be a perfectly viable solution.
"even though you can!" I heard that from my professor and he didn't know exactly what to tell me, but at least he was honest and said he'll do some research. I've never been much of a fan of abstractization, be it in math, physics, art of programming. For me, it seems as you're not discovering any answer, only more questions and then you die not acomplishing what you desire...
If you know ahead of time which packages are the offenders, you can use the `--constraint` flag during `cabal install` to prevent it from selecting other packages
I was thinking turn the implicit applicative structure into an actual Applicative instance via a newtype. But admittedly, I don't get the subtleties of the word.
The article is informative and well written but I think I might have found a missing definition in the Ocaml translation. When I paste the examples into [Try Ocaml](http://try.ocamlpro.com/) I'm getting an `Unbound value num_int` error in the definition of `print_incr_int`. Is `num_int` missing from the examples?
wasn't that due to issues with ARM support or something like that?
The prologue was hard to read on a phone (tiny font size in code snippets) but from the little I could read, that sounds absolutely amazing. If they have a way of dealing with authorization I might just drop the Clojure framework I've been enjoying a lot so far.
Your ideal approach is also my preferred approach: - **[Servant](http://haskell-servant.github.io/)** on the back-end. A minimalist framework, built on WAI, and intended to let you create type-safe, RESTful web services. Allows functions for querying these services to be automatically derived. - **[React](http://facebook.github.io/react/)** on the front-end. A breath of fresh air in the wasteland of JavaScript frameworks, brought to you by people who actually use it to build their own products, as opposed to Angular. - **[PureScript](http://www.purescript.org/)** to further improve your quality of life at the front-end. A Haskell-inspired language, with strict evaluation, JavaScript semantics, a powerful FFI, and a type system featuring extensible effects. It’s not Haskell, but it quacks like Haskell, and doesn’t require you to deal with megabytes of generated code. - **[`servant-purescript`](https://github.com/anchor/servant-purescript)** to derive functions for querying Servant services from PureScript. - **[`purescript-thermite`](https://github.com/paf31/purescript-thermite)** as a PureScript wrapper for React. See [`purescript-thermite-todomvc`](https://github.com/paf31/purescript-thermite-todomvc) for a usage example. Finally, to toot my own horn a little bit — I wrote **[Halcyon](https://halcyon.sh/)** specifically in order to improve the process of building Haskell web services. The [Halcyon tutorial](https://halcyon.sh/tutorial/) is a tiny Servant web app, and the [Halcyon shootout](https://halcyon.sh/shootout/) shows how to write a “Hello, world!” web service in a dozen ways, each using a different Haskell web framework. The focus is on build speed, because building Haskell programs quickly is what Halcyon does. Think of Halcyon as an improved version of _cabal-install_, able to install things from pre-built archives — such as GHC, _cabal-install_, sandboxes, and all types of Haskell programs, including web apps. Halcyon makes it simple to build things on one machine and install them on another, which in turn makes **[Haskell on Heroku](https://haskellonheroku.com/)** possible. For a great intro to both Halcyon and Haskell on Heroku, check out the recent [thoughtbot](http://thoughtbot.com/) article, **[“Building Haskell Projects with Halcyon”](http://robots.thoughtbot.com/building-haskell-projects-with-halcyon/)**.
you can track the progress of the 3 active projects on OpenHub: * [HaskForce](https://www.openhub.net/p/haskforce) * [Haskell IDEA plugin](https://www.openhub.net/p/haskell-idea-plugin) * [Intellij Haskell](https://www.openhub.net/p/intellij-haskell)
I recomment Scotty for the server side, since it is the simplest Haskell framework. Use whatever but Angular in the client side if you are not committed to Angular. Try any other JS framwork, for example React, if you are fluent with Javascript. But if you want to experiment the beautiful composability of the standard Haskell combinators in the client side, try Haste+hplayground. Haste is the haskell-to-Javascript compiler that produce the shorter and most efficient code. hplayground is the only library in any language with which you can create true composable widgets. editSave= do r&lt;- textArea "Enter your Text" ! atr "rows" "5" ! atr "cols" "80" &lt;* inputSubmit "Save" `fire` OnClick mr &lt;- ajax POST "/sendtext" [("content",r)] case mr of Just _ -&gt; do wprint $ r ++ "Saved" return $ Just r e -&gt; do wprint $ "some error:" ++ show (e :: Maybe String) return Nothing This example creates the `editSave` widget, that can be combined with anything else, for example main= runBody $ do wraw $ h1 "Editor" wraw $ div ! id "header" $ noHtml mr &lt;- editSave when (isJust mr) $ at "header" Append . wraw . p $ fromJust mr This program save the text box content with AJAX and append the content above the text box. EDITED: This is the site for playing with it: http://tryplayg.herokuapp.com/ Of course this example need a server that understand POST request `/sendtext`
Scala's futures have bind aka flatMap, so as far as I'm concerned they are monads. C# futures suck though.
The speaker mentioned in passing that delta and sigma respectively pi were adjoint functors. What are the monads that they induce?
Given a schema mapping `F : S -&gt; T`, we get three related functors between the categories of S-instances and T-instances. Sigma_F :: S-instances -&gt; T-instances Delta_F :: T-instances -&gt; S-instances Pi_F :: S-instances -&gt; T-instances such that we have the adjunction chain Sigma_F -| Delta_F -| Pi_F which gives rise to two monads `Pi_F . Delta_F` and `Delta_F . Sigma_F` dropping the subscript F for now, lets call these `PiDelta` and `DeltaSigma`. * PiDelta is a monad on T-instances. * DeltaSigma is a monad on S-instances. I worked out the properties of these at one point. But, let's see if we can do it now quickly: Like all monads it has 'closure-like' characteristics. These basically incorporate information from the mapping F into the existing instance. PiDelta would 'join then project'. This would cleanse members that weren't present on "the other side of the join" which is idempotent, as we'd expect. DeltaSigma always felt weird to me, allowing Sigma to work on things that don't have compatible signatures by bolting in the null members feels rather wrong. When I last gave this any serious thought, I wondered whether or not Sigma needed a stronger conditions than it is given here to exist. So I have no real intuition there, but I've not spent nearly as long staring at this stuff as Ryan and David have.
&gt; It just doesn't feel like that's something I should be doing in a modern language. You don't have to, but the type of the resulting function isn't simple (think about it for a bit if this isn't clear to you). It's been demonstrated many times how to do polyvariadic functions in Haskell ([[1]](http://okmij.org/ftp/Haskell/polyvariadic.html#polyvar-fn), [[2]](http://hackage.haskell.org/package/formatting-6.2.0/docs/Formatting.html)), but just for fun I gave it a go as well. See below for the code. The basic idea is to have a type class for applying `(&lt;*&gt;)` branching on the result type. If it's `f a`, we do nothing. If it's `f a -&gt; b` we apply one `(&lt;*&gt;)` and recurse on the `b`. We wrap everything up by lifting the input function initially. Type families `F` and `I` compute the functor and the input type from the result type, respectively. (Note that the code requires GHC 7.8+) {-# LANGUAGE MultiParamTypeClasses , FlexibleInstances , TypeFamilies , FlexibleContexts , OverlappingInstances #-} import Control.Applicative type family F o :: * -&gt; * where F (f a -&gt; b) = f F (f a ) = f type family I o :: * where I (f a -&gt; b) = a -&gt; I b I (f a ) = a class Lift r where lift' :: Applicative (F r) =&gt; (F r) (I r) -&gt; r instance (F r (I r) ~ r) =&gt; Lift r where lift' = id instance (Lift r, F r ~ f) =&gt; Lift (f a -&gt; r) where lift' fab fa = lift' (fab &lt;*&gt; fa) lift :: (Applicative (F r), Lift r) =&gt; I r -&gt; r lift f = lift' (pure f) a :: Maybe Int a = lift (+) (Just 1) (Just 2) b :: IO (String, String, String) b = lift (,,) getLine getLine getLine 
Snap is definitely not dead. I would submit that a better gauge of activity would be looking at the last updated dates on hackage or maybe the [github commit history](https://github.com/snapframework/snap/graphs/contributors). All of the [main](http://hackage.haskell.org/package/snap-core) [four](http://hackage.haskell.org/package/snap-server) [snap](http://hackage.haskell.org/package/snap) [packages](http://hackage.haskell.org/package/heist) have been updated within the last two months. Snap serves mission critical apps in at least three or four companies that I know of. At my company we use it in a number of applications, one of which serves well over a million hits per day (probably getting closer to two million now). Oh, and requests to ladygaga.com even get information from a Snap server behind the scenes. Given all this heavy production usage, Snap isn't going anywhere. Snap has always had a more methodical development style with a significant emphasis on backwards compatibility, robustness, [high](http://buildbot.snapframework.io/job/io-streams/ghc_ver=7.6.3/Test_coverage/) [test](http://buildbot.snapframework.io/job/snap-core/ghc_ver=7.6.3/Test_coverage/) [coverage](http://buildbot.snapframework.io/job/snap-server/ghc_ver=7.8.3,variant=default/Test_coverage/), etc. That said, we're finishing up a complete overhaul of the web server that included development of a new streaming library, [io-streams](http://hackage.haskell.org/package/io-streams), which will be released as Snap 1.0. While the core Snap packages have been pretty stable for awhile, most of the activity in the Snap ecosystem has been in [surrounding packages](http://hackage.haskell.org/packages/#cat:Snap). Things like Silk's [rest-snap](http://hackage.haskell.org/package/rest-snap) package, Daniel Patterson's [hspec-snap](http://hackage.haskell.org/package/hspec-snap), Luke Hoersten's [snaplet-stripe](http://hackage.haskell.org/package/snaplet-stripe), the [io-streams ecosystem](http://packdeps.haskellers.com/reverse/io-streams), etc. In short, we're busy using Snap to build real products, and as best practices emerge we will gradually incorporate them back into the framework.
&gt; it looks exactly like all the rest of lots-of-hype-zero-information software-related webpages which as so trendy these days, which is a big warning in my eyes. I see! Like, bad tech projects need to dress up their homepages because they don't have very convincing content in the first place, so they focus on the form instead? If that's the case, maybe having a dry homepage could act like a peacock tail: we'd be demonstrating that Haskell is so good that we can afford to do something which would otherwise be deleterious, namely to have a homepage which look boring. But then again, aren't there also many uninteresting technologies which have a boring website because their fanbase is so small that they don't have any proponent who also happens to know how to make a pretty webpage? We'd need something which we can only do if our language is as good as we claim. Like, I don't know, proving that our language really is good at concurrency by having an interactive shell on the homepage which would work with many concurrent users at the same time :) I like the idea of a [shibboleet](http://xkcd.com/806/), a secret way for us to reveal that we know what we're talking about. Having a dry but information-rich homepage may or may not be that secret way, I'm not convinced yet. Do you have examples of other worthwhile projects which use that approach?
Indeed; I am willing to sacrifice quite a lot of shortcuts for the ultimate minimalism and freedom that this approach gives me...
[Image](http://imgs.xkcd.com/comics/tech_support.png) **Title:** Tech Support **Title-text:** I recently had someone ask me to go get a computer and turn it on so I could restart it. He refused to move further in the script until I said I had done that. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/806#Explanation) **Stats:** This comic has been referenced 112 times, representing 0.2134% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_coqs0t8)
Well that's the problem, there are dozens of libraries, but most are just _here's a session store, though you have to implement X and Y and Z parts yourself_. I don't have anything against that approach, but I'd rather use a complete package that I can just plug in and be sure that it works, rather than spending a month trying to figure out which encryption I should use :) I haven't tried Spock though.
Okay, I now see that I have some reading to do about how Haskell's / GHC's type system actually works because honestly I have no idea how passing implicit parameters like this could blow up in my face. (I guess it was a sarcastic "enjoy"?)
I use Debian Stable right now with `ghc-7.4` and compile everything just fine. I wouldn't call it worthless.
Nice! Maybe you should package it up since this basically gives the idiom bracket, without template Haskell or special GHC support.
IMHO I think /u/ocharles the 24 days of GHC extensions was one of the best things in recent "intermediate documentation" in the style of: "stuff you might want to use to solve problems".
Nice, got to the same conclusion a couple of minutes ago. Maybe we are on to something. Maybe we should put /u/ocharles in charge of defining intermediate Haskell
There are so many devices and sensors... not sure how the boil-the-world approach will work unless there's some kind of FFI or at least a good understanding how to extend the support.
Why not use haskforce?
At the cost of honking unintuitive error messages. I can do many weird things with enough type hacks, but I don't think they are much more than that - hacks. They are great for exploring a concept to see if they are worth spending time with, but I don't think they are practical outside that (e.g., exposing in other libraries or using at work).
The whole keeping the context-in-mind thing is a battle I'm not going to be able to win. It's exactly the same argument as `fmap` not telling you *what* you're `fmap`ing - and some of us are fine with that. Personally, I don't care about what effect that is right there - the rest of the context or the names of the functions is generally explanation enough. If not, my editor should be able to tell me ("what's the type of this expression?") Of course, you don't have to turn this possible extension on, either :)
I use it all the time. So my answers are: 1) YES! 2) Me U {x | Person(x) /\ HPIsUsefulFor(x)} U {x | LearningHaskell(x)} :-) 3) Hopefully keeping more up-to-date with latest.
I've been using Snap for a webapp in my faculty used by 300+ students per semester (including during exams). I've been very pleased with the reliabily and performance of the server - it's been maintenance free except when I want to add new features. My only difficulties were in the initial understanding of the documentation and worked examples. But this may be my shortcomming as I'm not experienced with other web frameworks.
Do you know when Happstack based on pipes in going to be released? 
Two reasons: 1) I've been using vim almost full-time for 4 or 5 years now and I'm not comfortable with anything less than fully-features vim. 2) I don't feel like I need an IDE for Haskell, cabal repl works fine for most purposes.
Interestingly enough, your comment is sort of like a joke but not really at all. Now maybe you can go ahead and write more constructive things in the future, or at least more funny ones.
I do not know when it will be released. But I do plan to start blogging about it in the March. I need to finish hashing out the scheduler design and then there will be enough done to start talking about it. I plan to blog early because it will help me realize stupid design choices as I try to write about them. Also, getting early feedback for others is good too. 
Thank You, I am looking forward to it. 
xmonad, darcs, pandoc, and the gitit wiki are some of the more well-known open source projects. Haskell doesn't have a great GUI story, so there are comparatively fewer open source apps around built with haskell GUIs -- one that I know of, and that is pretty neat is hoodle: http://ianwookim.org/hoodle/ There is also a fair amount of interest in game development in Haskell, though some of the links here are outdated: https://wiki.haskell.org/Game_Development One recent effort was nikki and the robots: http://code.joyridelabs.de/nikki/ -- the studio unfortunately shut down, but you can see the game in action on youtube, and the code is open sourced.
`h` stands for `handle`, not `position`. `getLine` and `putStrLn` use standard handles.
git-annex is another good open source "real world" example https://git-annex.branchable.com/
Edward Kmett has a real-time ray-tracer called "quine" on his github.
Previous discussion: https://www.reddit.com/r/haskell/search?q=url%3A2-JFkv9-JOQ&amp;restrict_sr=on&amp;sort=relevance&amp;t=all
It's about a type system feature implemented in a type inference engine for JavaScript, written in Haskell. I think that qualifies... Care to explain what I have muddled up?
it's hard to consider a ray-tracer as real-world application
[Opaleye](https://github.com/tomjaguarpaw/haskell-opaleye)'s code generator could be improved, firstly to make queries easier for humans to read and secondly to provide optimizations. That could be an interesting project for someone. I'm also working on an idea for a *in memory* relational algebra and data processing API based on Opaleye's if anyone's interested in that.
Have you seen [Opaleye](https://github.com/tomjaguarpaw/haskell-opaleye)? Could you give a comparison between Opaleye and Beam in terms of the aims of both libraries? I would be interested to know why you consider Template Haskell not type safe. The following line makes me think that you can't have more than one table of a given type in a database. Is that right? &gt; inBeamTxn beam $ queryList (all_ (of_ :: Simple TodoList))
This looks pretty cool. I agree with your sentiment to not use TH, and I like that you have kept the types reasonably simple.
I think your friend is wrong that Haskell is too slow, and from my experience hiring Haskellers also isn't a problem. The biggest issue I see is you mentioning GUI development. If this means a native GUI, and particularly a cross platform one, I have not yet found a Haskell solution that works well. Lower lever graphics libraries tend to work well, but e.g. gtk2hs is hard to get to work on a Mac (haven't tried Windows) and the same goes for many other GUI libraries: they're either small and not that pretty and full featured, or they're hard to install on some platforms. It can be done of course, but it will require some extra work by you compared to other languages. If you're talking about a web GUI, on the other hand, I'd say go for it. 
I don't know about gtk2hs, but gtk in general has a lot of problems on Windows. Last time I tried it, font rendering didn't work properly, so all the text was difficult to read (in addition to often being partially cut by the containing widgets).
(one of the authors of servant here) - Regarding `EitherT (Int, String) IO a`, that's only a first and simple shot. We've been thinking about this and may converge to a better solution soon, given the feedback and needs of our users. This will definitely change at some point in the future. - Regarding the routing performance, it's really not bad without having put any effort into optimizing it. See [this benchmark](https://github.com/haskell-servant/servant-benchmarks/blob/master/routes.md) (the routes are randomly generated) - Regarding your last comment about `QuickCheck`, could you expand? We've been thinking about how to automatically derive tests for a webservice, that should be possible but it's a long term plan we keep thinking about -- it definitely requires quite some time to get right. I'm however not sure this is what you meant, since you mention doc generation and what I've just talked about isn't really related to that. 
Looks very nice! What is the reason for making the `id` row implicit though? 
Recently OCaml got a tool to generate pattern from type information: [merlin's destruct command](http://the-lambda-church.github.io/merlin/destruct.ogv). I know that some other languages possess this kind of tool (Idris, Agda? not sure). Having this available in ghc-mod (or somewhere else) would be a _HUGE_ helper when writing Haskell code. I cannot state enough how the day to day use of this feature is pleasant and usefull.
Not a student, but do you have some details on it? I was pondering making a textbox/button/label GUI test above reactive-banana, and I'm interested in other project.
Thanks! I need to play with concrete examples.
It is nice for expressions with operators. One can write `[| a + b |]` instead of `(+) &lt;$&gt; a &lt;*&gt; b`.
Few of the usually mentioned examples are XMonad a tiling window manager for linux and Pandoc a swiss army knife for document formatting
Sure, if you look at a digital circuit design application, ICs would be function composition. Regarding clock and other interactions with the outside world, the similarities would come from reactive and dataflow programming. 
This makes much more sense to me now. Thanks for the expansion!
You could pick a part of your project that don't require a GUI and that could be accessed by the rest of your project by a networked API. Then you could implement it both in Haskell and Java and compare the two. For the GUI, you might consider using a web interface: there are plenty of web-related libraries and framework to choose from in Haskell.
That sounds super interesting actually. I know someone who would love that sort of thing (I'll tell him to take a look).
haskell: http://serras-haskell-gsoc.blogspot.ru/2014/08/summer-of-code-on-emacs.html?m=1 f#: http://fsprojects.github.io/VisualFSharpPowerTools/unionpatternmatchcasegeneration.html
Agreed. We fed 3 slots into ghcjs last year.
thats the idea
I think you missed the fact that it is (supposed to be) real-time. That significantly expands the potential practical uses.
We did, but I couldn't find anything that seemed to provide enough of an improvement to outweigh the cost of more difficult debugging and other friction caused by going against the grain. However, if I were starting a new project now, I would probably use GHCJS. It has matured incredibly fast over the last couple of years. I've helped out in one small way by creating [ghcjs-setup](https://github.com/ryantrinkle/ghcjs-setup), which uses Nix to make it easy to get ghcjs and ghcjs-based packages installed.
Yes! Now you can produce demoscene animations _real fast_
Especially QT. A focused student project would be to create enough solid Haskell bindings so that you could use Haskell to test drive your C++ QT code. More generally, a solid Haskell replacement for Google Test. 
I have seen Esqueleto, and I think that it's a great library! One of the things that I really wanted to go for with beam was **composability** of queries. Esqueleto is not very composable. For example, suppose you had two Esqueleto queries: one which returned articles and one which returned all comments written by Bob. articlesQ :: SqlQuery Article commentsByBobQ :: SqlQuery Comment Now, suppose you wanted to query which joined these two relations together. In Esqueleto, this would not be possible, because joins need to be specified in the from clause. In Beam, on the other hand, if you have the queries articlesQ :: Query (Entity Article Column) commentsByBobQ :: Query (Entity Comment Column) you can easily join them together. articlesAndCommentsByBobQ :: Query (Entity Article Column :|: Entity Comment Column) articlesAndCommentsByBobQ = articlesQ `join_` commentsByBobQ `where_` (\(Entity (PK articleId) _ :|: Entity _ comment) -&gt; field_ articleId ==# (columnValue . tableId . reference . commentArticle $ comment)) Unlike in Esqueleto, in Beam, the two queries are composable, and can freely be joined, filtered, projected, etc. This can result in arbitrarily complex (but type-safe) queries that are just-in-time converted into SQL before they get sent to the database. Beam will automatically handle the creation of any sub-selects, and will even simplify some of the query if the composed queries were redundant. As far as I know, with esqueleto, you'd have to write a whole other query or re-arrange your current implementation
I was about to start a similar project. May I join yours instead?
Maybe you could consider a set of helper functions that work with 'id' implicitly and leave the main library free of that stuff. The 'id' helper functions would also be an explicit statement that 'id' is just one of many possibilities.
I always say it's a good thinking language. 
Looking at the Basic tutorial in the Opaleye repository, it seems the idealized SQL and the generated SQL are very different, and the generated SQL has a lot of subqueries. For example, [this query](https://github.com/tomjaguarpaw/haskell-opaleye/blob/master/Doc/Tutorial/TutorialBasic.lhs#L135) which should be a simple select seems to generate two nested selects. Once I saw the queries generated in the tutorial, I figured that Opaleye did not currently simplify queries in the same way, but maybe the tutorials aren't up-to-date? Great work on Opaleye BTW!
I haven't had the chance to use Haskell at work, but I can definitely say that it has made my code in other languages clearer and more concise. Learning Haskell may hurt, but you'll learn a lot!
Would you mind to share your code? I never heard of lucid and would like to see it in action.
Link for the lazy ones: https://github.com/chrisdone/lucid
At Soostone we use Haskell heavily for all our major products. Here are a few anecdotes that may be of support for your argument: - Our analytics platform (written entirely in Haskell) for real-time predictive optimization receives millions of queries a day, performs 50+ concurrent (with a non-trivial dependency graph) database operations (dynamodb, cassandra, redis, postgres) to pull together relevant information, makes a decision for each and responds back - all typically within 200ms. It's deployed on several of our clients' websites, many with very high volume. Haskell has been quite fantastic in managing the complexity as we add sophistication with each iteration. Lately, we have also been using Purescript (which is really quite close to Haskell) for an isolated component that will live purely on the browser. - Our interactive data exploration/mining/collaboration product (to be publicly released on a future date) started with a Haskell backend and an EmberJS GUI front-end. The complexity on the GUI escalated way faster than we were willing to stomach and we rewrote the front-end to work on top of Haste inside of 2-3 weeks by one person. The result worked very well and has allowed us to add non-trivial features for much cheaper. However, the ecosystem is certainly less developed than the pure JS world and requires a willingness/ability to build one's own abstractions. We are currently evaluating GHCJS as our final home for the GUI along with a more structured GUI framework. - We maintain an ever-growing list of libraries and tools that are written on Haskell that support our products and analytics work. Self-contained algorithms, CLI executables, scripts, DB DSLs, etc - you name it. The experience has been great. Haskell makes it really enjoyable to leave a series of highly reusable, small-to-medium components in your wake.
&gt; Well Done Chris Pun intended? On a serious note, I appreciate lucid's principled approach. Blaze is great, but because it's really using a Monoid in disguise, I constantly found myself shooting myself in the foot.
You may find Chris' [blog posts](http://chrisdone.com/posts/lucid2) on the library an interesting read. In addition to explaining why he wrote it, he gives plenty of examples on how to use it, as well as compares it to equivalent blaze-html code.
&gt; import Data.Map (Map) qualified as M Can we also steal Scala's import syntax? import Prelude (fromIntegral =&gt; fi, (.) =&gt; _, id =&gt; _, _) would be so nice.
I would be delighted! It would good to collaborate. I haven't got anything quite fit for public consumption yet but let me work on something during the weekend and get back to you. I'll give you a quick summary of the high-level API behind my idea. * A widget has some value of type `s` representing its current state * The behaviour of the widget is controlled by a value of type `s -&gt; Doc e s g` * When the widget state is fed to this function * it produces an element of type `g` which is intended to be displayed on the screen * the `g` can raise an event of type `e` * any event that the `g` produces can be handled to return a new widget state of type `s` * We feed the new widget state back into the function to continue the loop As you might expect `Doc` is a `Bifunctor` (meaning you can fmap over the `s` and `g` parameters) and indeed a `Biapplicative`. The latter means that you can combine widgets Doc e s g -&gt; Doc e s' g' -&gt; Doc e (s, s') (g, g') Here's an explicit example, fairly close to the reactive-banana CRUD example: http://apfelmus.nfshost.com/blog/2012/03/29-frp-three-principles-bidirectional-gui/Reactive-banana-CRUD1.png This is actually code for a React-like HTML/Javascript target, but the WX Widgets target would be exactly the same. We store the state of our crud app in the `Filter` type. It contains the data of what names are available to be selected in `fAvailable`. The filter text box state is in `fFilter` and the text editing and selecting widget state is combined in `fTextSelect`. data Filter = Filter { _fAvailable :: R.Radio DT.Text DT.Text , _fFilter :: T.TextEntry , _fTextSelect :: TS.TextSelect Int } deriving Show $(L.makeLenses ''Filter) We also have a type for the events the filter can raise. data FilterEvent = FilterEvent T.TextEntryEvent | EditorEvent T.TextEntryEvent | SelectEvent (S.SelectEvent Int) $(L.makePrisms ''FilterEvent) `filterA` is an example of how to create a widget. We make our filter widget out of a "static" value that is not displayed ("static" is maybe not the best name for this term. It can change, but it cannot emit events) a text entry widget for the filter text box (that emits `FilterEvent`s) and a combined text box/selection widget (that emits either `EditorEvent`s or `SelectEvent`s). filterA :: Filter -&gt; Doc FilterEvent Filter [H.Element] filterA (Filter available textFilter textSelect) = ((Filter, \_ -&gt; (++)) `contains` (static available `emitting` absurd) `also` (T.textEntryC textFilter `emitting` FilterEvent) `also` (TS.textSelectC textSelect `emitting` either EditorEvent SelectEvent)) Because the underlying state is explicit we can manipulate it in response to events very easily. When we received an `EditorEvent` we update the "available" state to what the text field was edited to. When we receive a `FilterEvent` we update the selection to contain only elements that meet the filter criteria. When we receive a `SelectEvent` we update the "available" state to reflect the selection. (This example uses some nice lens syntax, but it doesn't have to if you are allergic.) filterC :: Filter -&gt; Doc FilterEvent Filter [H.Element] filterC = handle _EditorEvent (\_ -&gt; do c &lt;- L.use (fTextSelect.TS.tsText.T.tText) fAvailable.R.chosen .= c) . handle _FilterEvent (\_ -&gt; do f &lt;- L.use fFilter a &lt;- L.use fAvailable fTextSelect.TS.tsSelect .= availableForSelection f a) . handle (_SelectEvent.S.cEvent) (\i -&gt; fAvailable %= R.chooseIndex i) . filterA 
How dare you slander my friend `\x0955\t\t@%%`, they have done great things for the Haskell community!
It does, what is more interesting is that with attention you can notice yourself is that most of the time you approach understanding new concepts in terms of things that you already understand. 
The link to haskell.org in the first paragraph is broken. Missing http://?
I've applied haskell/functionally inspired ideas at work to great effect, even if it is in javascript. FRP via bacon.js has been a huge hit with my colleagues.
[Here](https://github.com/aleator/LambdaLuento/blob/master/LambdaLuento.hs). This was done in a hurry so don't expect sane code.
Thankyou for this. I'm still a beginner, and couldn't figure out an elegant way of expressing it monadically. I've read up on MonadPlus and guard now. I might have a go in the future at writing up a sequel post explaining this technique.
I like this trick of parameterizing the type on some higher-kinded type constructor and then deriving `Generic`. It's very similar to the trick used by `generic-lens` and I think it's very tasteful. Edit: I just realized that both posts were by the same author. That makes sense! :)
Those are bad for performance for other monads? In what sense? What are the alternatives? 
Improving error messages of the elm compiler might be a fun subject. 
They are bad for performance in the sense that they will materialize the entire list in memory instead of streaming the result. They also tend to be very inefficient, too, with bad constant factors. The alternative would be any `ListT` implementation (other than the one in `transformers`)
&gt; More generally, a solid Haskell replacement for Google Test. What does Google Test have that HUnit, QuickCheck, SmallCheck, hspec,... do not have (other than things that make no sense without OOP)?
I've applied lazy evaluation in a R library that reads HDF5 that are more than a gig in size. I know R is sometimes lazy but it seems to be strict at the worse times. It was a huge hit with my boss.
.
Check out my [FLTK](http://github.com/deech/fltkhs) and let me know what you think. It's meant to address the exact problem of getting a no-fuss install library for traditional native apps in pure Haskell across. It currently works smoothly on Linux and Mac. There are currently almost 60 widgets ported and I'm one away from making an official release. There are also a (growing) number of demos. The only reason Windows support is not there yet is that I don't have a Windows box and don't know the Windows tool chain, otherwise the code should be portable. Any help here is appreciated. See [here](http://hackage.haskell.org/package/fltkhs-0.1.0.0/candidate/docs/Graphics-UI-FLTK-LowLevel-FLTKHS.html) for more why this project exists and more documentation.
Haskell didn’t really *change* the way I think. It gave me a lot of tools that I knew I was lacking in C++, back when that was my primary language. In particular: control over side effects, type inference, easy composition and factoring, easy concurrency, and being able to encode (to some extent) which code can be reordered and which cannot. But at the end of the day, I basically think of program architecture in Haskell the same way as I do in C—it’s just data types and functions.
Hmm, I had only tested it compiled when using gnuplot. You are right, it is much faster compiled than in GHCi. I guess I don't have a problem anymore, but is the way I'm doing the recursion fine? By that I mean, is it the most Haskell way of doing it? And thanks!
It completely changed my way of programming. Now I want to use Haskell features in other languages too, Maybe, higher order functions, lazy evaluation ... monads and less classes, less side effects. Functional programming beats all GOF Gang of Four patterns. 
You evaluate `num (t - dt)` twice recursively, and therefore (without optimization) your algorithm runs in exponential time, not linear time. The difference is likely whether the compiler is smart enough to perform this optimization. You can simply say `let value = num (t - dt) in value - dt / tau * value` and this issue would be corrected. A better way would be to use algebra, since `num (t - dt) - dt / tau * num (t - dt) == (1 - dt / tau) * num (t - dt)`
You are recursing twice in each step, resulting in an exponential number of calls to `num`. I guess when compiled GHC is smart enough to recognize the common subexpression. This gets it down to linear time even in GHCi: num t | t &gt; 0 = let t' = num (t - dt) in t' - dt / tau * t' | otherwise = n0 This way, `num (t - dt)` is evalulated once and shared between both uses of `t'`.
Silly me. Thank you for pointing that out!
I can't recommend this enough for PL students and industrial pros. I'd say "go as early as possible", but it's probably wise to have a few PLT courses under your belt. I had an amazing time. I went near the end of my PhD and wished I had gone much sooner. It clarified so many things. And the lecturers and students are always a very fun bunch after a long day of study!
I took a small look at the code, but I'm not a Haskell expert. One personal problem I have with it is the use of IORefs, but thats not really a problem with your code but a problem with WYAS itself. I didn't look too deeply but I didn't really like the nested chains of if and case statements like [in here](https://github.com/hellerve/R5RS/blob/49414775ae837ddc5c9ce559d27abaea39d12f82/src/macro.hs#L104) and [here](https://github.com/hellerve/R5RS/blob/49414775ae837ddc5c9ce559d27abaea39d12f82/src/macro.hs#L197). You seem to have *really big* functions that seem to have no documentation what so ever so you don't really know what they do. One big example is [transformRule](https://github.com/hellerve/R5RS/blob/49414775ae837ddc5c9ce559d27abaea39d12f82/src/macro.hs#L142), I mean this function is almost 70 lines long and I haven't the clue of what it does. You should split up your functions more and instead of using if/case statements you should rely more on pattern matching in separate functions. Also more documentation should help people understand how your code works.
&gt; I didn't look too deeply but I didn't really like the nested chains of if and case statements like in here[1] and here[2] At first glance these nested chains remind me of the transformation in the [Haskell Wikibook chapter "Understanding Monads"](http://en.wikibooks.org/wiki/Haskell/Understanding_monads): bothGrandfathers :: Person -&gt; Maybe (Person, Person) bothGrandfathers p = case father p of Nothing -&gt; Nothing Just dad -&gt; case father dad of Nothing -&gt; Nothing Just gf1 -&gt; -- found first grandfather case mother p of Nothing -&gt; Nothing Just mom -&gt; case father mom of Nothing -&gt; Nothing Just gf2 -&gt; -- found second grandfather Just (gf1, gf2) And the transformation... bothGrandfathers p = do dad &lt;- father p gf1 &lt;- father dad mom &lt;- mother p gf2 &lt;- father mom return (gf1, gf2)
You can't actually do type inference in simply typed lambda calculus: it's ambiguous in the general case. If we completely elide type annotations, then the term λx. x could be assigned the type unit → unit (unit → unit) → (unit → unit) ... to solve this, we have to annotate lambda arguments to lambdas with a type. So our language is something like data Type = Arr Type Type | Unit deriving Eq data Exp = App Exp Exp | Lam Type Exp | Var Int | TT Here I'm using what's called "DeBruijn indices" to notate variables. This means that each variable is actually just an integer that tells us how far away it is from its binder. If there are no lambdas in between where a variable was bound and where it was used, it would be notated `Var 0`. If there was 1, then it would be `Var 1` and so on and so on. Type inference is just infer :: [Type] {- The context, the ith elem is the type of (Var i) -} -&gt; Term -&gt; Type infer cxt (Var i) = cxt !! i infer cxt TT = Unit infer cxt (Lam ty body) = Arr ty (infer (ty : cxt) body) infer cxt (App l r) = case infer cxt l of Arr tyl tyr -&gt; if infer cxt r == tyl then tyr else error "Type mismatch" _ -&gt; error "Applied a nonfunction" So if we have a variable we look it up. If we see a lambda, we note the argument type and infer the body, returning a arrow from the argument type to the body type. If we see an application, we assert that the left side is a function type and that it matches the argument, if it does then we return the return of that function. Exercises left to the reader: 1. Implement proper error handling 2. Add some more base types and their corresponding elim forms 3. Extend this with `fix` or recursion over natural numbers (PCF or Godel's T) If you didn't want STLC but instead wanted something closer to System F (the original basis for Haskell and ML) then you might be interested in my [tiny type inferencer](http://github.com/jozefg/hm). It's written precisely for explaining type inference but alas the explanation isn't completely done (what github project is?). It's in SML but should be legible to most Haskellers, the syntax is very similar. Hope that made sense. Cheers.
[Raincat](http://bysusanlin.com/raincat/) is quite entertaining. 
Does it really need to be a do monad though? Why not just define those intermediate values in the "where" section of a function?
How would that help anything? You'd still have to nest and nest. The pattern of case Nothing -&gt; Nothing forever and forever is a telltale sign that you could use monad syntax to make your code clearer. 
It's like `IO a` vs `a`. But with a more fine-grained hierarchy of side-effects. From that hierarchy we are interested in (interactively) reading the user's input in this case. The issue is distinguishing commands that would require interaction with the user vs those that simply print the result. Purity would not allow to hide side-effects in the internals, but rather bring them up to the top-level type of the command, and it would be expected from the environment that it handles each `IO`-like type properly. Simpler commands should have simpler types in the hierarchy of side-effects, those that require interaction would have a more complex type. (Not all commands the same, most general type, i.e, `IO`.) The environment (shell) would choose how handle each command based on its type (like GHCi does for `IO a` vs `a`). ----- If it weren't purely functional, then there would be no need to bring the side-effects to the toplevel type of a command. And no guarantees that a command handled in the lightweight way by the shell (no interaction), wouldn't break because of hidden interaction. Isn't this not sensible about "purity"?
Sorry to revisit this old thread, but I may be giving my talk again some time and I read your post again to refresh on some ideas. It seems I can't find when list2 could be set to all 0s since list1 is never touched, and list2's changed entries start at 1 and don't go back. Not sure what I'm missing... Of course, that's part of the point, but it's really bothering me.
The example I gave was of aliasing. When you pass in two references to the same list, all bets are off. Part of the contract of calling the function is that you pass references to two distinct lists in memory.
Yes, I can understand that. So far, I have put my mind on adding features and making things work, now I should start transforming it into beautiful, idiomatic code. I know the project is not documented yet, so thank you very much for looking into it nontheless.
Thanks, what you're describing is exactly what Typesafe did with their flagship query DSL, [Slick](https://github.com/slick/slick); not everyone is convinced that this was a sensible choice given the additional boilerplate foisted on the end user (particularly wrt to grouping, sorting, and aggregation). At any rate, it is possible to base a query dsl on a relational algebra using monadic comprehensions because, well it's [already been done](https://github.com/slick/slick/blob/master/slick/src/main/scala/slick/lifted/Query.scala#L21) in Slick and its predecessor, ScalaQuery. Also, Wadler et al recently published some research on an [improved LINQ to SQL](http://homepages.inf.ed.ac.uk/jcheney/publications/cheney13icfp.pdf) that is, I believe, based on monadic comprehensions. At any rate, I think more what I'm getting at is the sheer amount of typing one has to do in order to construct a query. For Haskellers perhaps this is par for the course/extremely readable code; however, for outsiders such as myself there appears to be several extraneous references that, given table mappings, would not require having to specify, for example, `Entity` or `PK` in the query body since the compiler should be able to infer the Entity-ness and PK-ness of Query elements. Obviously were one able to create a Haskell query dsl based on relational algebra, *and* have it be as concise as sql itself, it would have already been done ;-) Not to take anything away from your fledgling work, I'm sure as it matures things will evolve accordingly on all fronts (and likely suits many Haskellers already based on this thread's activity).. And of course it's great to see so many query options sprouting up in Haskell land, can only imagine how things will look a few years from now, you guys/gals are trail blazing.
A board game in Haskell looks like exactly what I'm looking for.
Having stopped and started learning Haskell a few times, I've gotten some good momentum going this time by writing small, focused applications. I've written one for fetching email over IMAP, one for uploading files to S3, I've started one for pub/sub over redis, and I plan to write a small project using acid-state, and another using either STM or CHP for concurrency. 
As a suggestion for site search, there is [Hunt](https://github.com/hunt-framework/hunt ), A lightweight search-framework written in Haskell. It is used in Hayoo. I will discuss a first release with the original auhtors next Wednesday. There is Elasticsearch for one, but having a Haskell-page-search written in Haskell sounds awesome.
Intuition is different for everybody and comes with experience, is unfortunately the best answer I can give. What's intuitive for me (space burritos, for example) might not be for you.
You are right, the docs are sparse. I spent my time on API coverage and demos, which while useful, don't make up for good docs. I'm working on it and I hope that since this an initial release people will understand. Thanks for the feedback!
[Write Yourself a Scheme in 48 Hours](http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours)
You can think about type classes in a similar way as you think about OOP interfaces: the only way to use the type is with the functions specified in the interface. The difference is that the v-table for type classes flows along with the type, rather than along with the values as is the case with OOP. For specific type classes like Functor and Monad it can indeed be hard to get intuition about operations since the abstraction is so general. For Functor it may help to think in terms of interaction. If you have some generic type `F a` you may be able to interact with it in many ways, but in the end there is only two things that can happen with values of type `a`: you can put values of type `a` into `F a`, or you can get values of type `a` out of `F a`. For example if you have the type `F a = List a`, then you can get values of type `a` out of the list. If you have the type `F a = a -&gt; Bool` you can't get a's out of it but you can put values into it. If you have `F a = (a, Bool) -&gt; (a, Int)` you can put values into it and get values out of it. A type `F a` is a Functor if you can only get values out of it, and not put values into it. So List is a functor but `a -&gt; Bool` is not. What `fmap` does is it puts a kind of post-processing step after a value. Given a function `a -&gt; b` and a value `F a`, it produces an `F b`. Whenever you want to get a value out of the `F b`, it takes the corresponding value out of the `F a`, then applies the function `a -&gt; b` to it to get a `b`. This is a covariant functor (the Functor type class in Haskell). Dually you also have contravariant functors (the Contravariant type class in Haskell). They are types where you can only put values into them, and not get values out of them, like `a -&gt; Bool`. The `contramap` of a contravariant functor does a pre-processing step instead of a post-processing step. When you have a value of type `F b`, and a function of type `a -&gt; b` then it creates a value of type `F a` by using the `a -&gt; b` as a pre-processor: every time you put a value of type `a` into it, it first converts it into type `b`, then puts it into the value of type `F b`. If a type `F a` has both inputs of type `a` and outputs of type `a`, like `(a, Bool) -&gt; (a, Int)`, then it cannot be a covariant functor and it cannot be a contravariant functor either, but it can be a bifunctor. A bifunctor does both pre-processing and post processing with the bimap operation: `f a -&gt; (a -&gt; b, b -&gt; a) -&gt; f b`. It uses the `a -&gt; b` to do post-processing and the `b -&gt; a` to do pre-processing. *Every* type is a bifunctor. In summary: you can think of fmap as a kind of generalized post-processing, and contramap as generalized pre-processing, and bimap combines the two. There's more than one way to think about functors in general, this is just how I think about them. Monads are a bit more difficult to think about in general terms. One way to think about them is in terms of the continuation monad. The continuation monad is in a sense the most general monad, and any other monad is a special case of it. So if you want to know what a monadic piece of code does you can mentally substitute the continuation monad, and any other monad is going to have more restrictive behavior than that.
https://bitbucket.org/chemist/viewer do it for my self go-to-definition by tag demo was in my home server, unfortunately it does not work now. 
Deliberative practice. Always be reaching for something just slightly out of your reach. Haskell can tempt you a bit to jump too far ahead with the "good" stuff, but be patient. It will come. 
Your understanding is mostly correct, apart from one point: When /u/julesjacobs says that you cannot extract a value from a `Functor`, they mean that you cannot do so _using only functions from the Functor class_. You can, however, define _other_ functions on your data type which enable you to do so. What this means is that if you talk about functions that work on _every_ functor (rather than only one specific instance), none of these functions can extract the 'content' of their arguments, because in order to do so, they would have to know which specific `Functor` instance they are working with. From these observations, you can for example deduce that no function with the following type signature can be implemented: (Functor f) =&gt; f a -&gt; a (This only holds if you don't use `undefined`, `error`, `unsafePerformIO` or similar shenanigans.) Similarly for the signature (Functor f) =&gt; (a -&gt; f b) -&gt; f a -&gt; f b although the argument is a bit trickier here. Incidentally, this is the type of `=&lt;&lt;` if you replace `Functor` by `Monad`, which is an indication that `Monad` is, in a sense, stronger than `Functor`.
[Functional education](http://bitemyapp.com/posts/2014-12-31-functional-education.html) blog post focuses on many sources for learning Haskell and highlights pros and cons of each one, you might be interested to check it out.
I've got 3 ideas, that would be worth to work on: 1. Better Cabal - Cabal is great and Cabal is pure love, but sometimes Cabal can be pain in the * when working with complex dependencies. Allowing installing sub-packages in different versions would be a life-saver 2. Better OpenGL support. Currently OpenGL support is very poor. On top of a good binding we could create complex interfaces and even a haskell based GUI library. I would personally love to contribute / create such library also - but the OpenGL support is crutial. 3. There is a new flow-based language allowing advanced visual programming - based on Haskell and it's called Luna. It's made by an startup I'm working in (flowbox.io) and is used to create special effects for movies. I think if its development would gain some external attention, we would open-source it :)
First fifty problems from [https://projecteuler.net/archives](https://projecteuler.net/archives) are fairly easy. What about Sudoku solver for instance? ([problem 96](https://projecteuler.net/problem=96) in Euler) You can try solution based on lists, then arrays (immutable, mutable) and you can pack fields into bit fields to learn about binary operations in Haskell.
Or event don't use do syntax but make use of '&gt;&gt;=' directly bothGrandfathers p = father p &gt;&gt;= father &gt;&gt;= \gf1 -&gt; mother p &gt;&gt;= father &gt;&gt;= \gf2 -&gt; return (gf1, gf2) 
Just finding examples of functors and writing their implementations helped me a lot (moreso for their monad instances). Keep in mind the fact that the type can only be a functor in its rightmost parameter (or a bifunctor in its two rightmost parameters) is just a result of Haskell's type system, not anything fundamental. If you write `newtype Sum a b = Pair (Either b a)` to swap the arguments of an Either suddenly it's a functor in its other argument.
As kwef said, the dual to "row polymorphism" is indeed "polymorphic variants". Row polymorphism allows you to add subtypes to a record type after the fact, and polymorphic variants allow you to add supertypes to a variant type after the fact. As far as I know, Haskell doesn't have those, but OCaml does. They are pretty important, for example, the most natural solution to the [Expression Problem](http://en.wikipedia.org/wiki/Expression_problem) that I know of is [Garrigue's solution](http://www.math.nagoya-u.ac.jp/~garrigue/papers/fose2000.html) with polymorphic variants.
&gt; When /u/julesjacobs says that you cannot extract a value from a Functor, they mean that you cannot do so using only functions from the Functor class. That's not really what I meant. A type constructor can be made an instance of Functor if and only if it is covariant, and moreover the Functor instance is unique (Monad is different in that sense: the type does not uniquely determine the monad instance). The input/output or covariant/contravariant distinction is a property of the type constructor itself, not of the `fmap` function. For example neither a function `(Functor f) =&gt; a -&gt; f a` nor a function `(Functor f) =&gt; f a -&gt; a` exists, so that does not really capture the input/output or covariant/contravariant distinction. I see that my explanation is not clear though. I believe that the term to google is "game semantics"; perhaps there is a good explanation already out there.
The type inference approach you want to see for starters is Hindley Milner, because it is beautifully straightforward once you understand it. I actually think the wikipedia page is pretty good in this case: http://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system
I think the point is that [ x: Bool | y: Bool | p ] would match any sum type who at least had two constructors which took a Bool. That is, the function f would work for any of these types: data Foo = Bar Bool | Baz Bool Data Fizz = Buzz Bool | Fazz Bool | Fezz Int
"open sum types" and "polymorphic variants" are actually different things. Open sum types are exactly like sum types except you can add variants after the definition. This means you never know all the variants of the type. There is no subtyping involved. The most natural representant of such a type is the "exception" type in most languages (in OCaml in particular). polymorphic variants are based on a subtyping between sum types, just like you do with row polymorphism.
Actually looking for just haddock with annotation as you have shown, that would be pretty useful, it seems haddock doesn't support that.
I see; apologies for the confusion then. Seems like I skipped a few things when trying to relate your original post to my modest previous knowledge. ;)
Wouldn't you need to make a lot of types with name clashes on their constructors to use this in practice? I see that as a major downside compared to e.g. a type class or a record of functions all returning the same type passed in as a parameter.
That's a good alternative if you are trying to avoid do syntax.
I've read that row polymorphism is different than subtyping between records, which is why I tried not to mention it in the OP
That might be the reason why neither of them is very common.
It would be interesting to read that discussion. I've been always thinking of designing a flexible tool for processing languages with implicit type-lifting (perhaps, something like preprocessor generating Haskell). To explore various possible designs of languages with implicit lifting (or languages living entirely on a higher level like the level of an Applicative), and use them in practice. I know about the existence of "she" tool. It has some fixed rules of translating expressions; probably, not all possible designs I've been thinking about are covered by "she". It's an area that is interesting for me to explore.
My main concern is how difficult it would be to explain to people who use my type checker: javascript programmers (ok, not average ones: even very good ones). Something like `a = String|Number` is dead simple (but doesn't scale), but I think also `HasPlus a =&gt; a -&gt; a -&gt; a` is reasonable. Lenses? Not sure...
By the way, I forgot to mention pervasive mutability as a strongly interacting language feature. It makes the idea of lenses and ix/at a bit less useful.
That looks very interesting indeed! I haven't considered these as a possible solution. Thanks!
It is different. Polymorphic variants look like [`A | `B | `C] which means a type which is exactly made from one of those three variants. You can also write this as mere bounds [&lt; `A | `B &gt; `A] which reads as "some variant larger than just `A` and smaller than `A | B`.
Thanks, very nice! Looks pretty sane to me. But where do `Slides` and `TreeToHtml` come from? Those look intiguing.
Regarding #2, I would happily work with a student who wanted to improve the new [gl](http://hackage.haskell.org/package/gl) package. At a lower level of abstraction, but flashier level of visibility, I also actually had a student approach me about working on an editor for [quine](http://github.com/ekmett/quine), which might be another way to help boost visibility of Haskell, by showing we can do "real" realtime gaming and graphics.
do other languages' build tools have this? I guess elm.
I can't find it in my comment history. And, reexamining /u/Soul-Burn's post, I think the original discussion was advocating something more extreme, so the arguments might not apply anyway. Changing juxtaposition from being `($) :: (a -&gt; b) -&gt; a -&gt; b` to being `(&lt;$&gt;) :: Functor f =&gt; f (a -&gt; b) -&gt; a -&gt; f b` (At least sometimes) would still require explicit calls to `pure` so there's no/less ambiguity around that. It seems like the Functor instance for `(-&gt;) e` could make things... confiusing. Like, sometimes a binary function would take it's arguments in either order! For example: ltn :: Int -&gt; [c] -&gt; [c] ltn = (concat .) . replicate Currently, `ltn 3 "Wow"` type-checks (a ~ Int, [c] ~ b, c ~ Char) and `ltn "Wow" 3` fails to type-check (a ~ Int, Int /~ [c]). But, with `instance Functor ((-&gt;) e` available and your change, the second *does* type-check (f ~ (-&gt;) e, e ~ Int, a ~ [c], b ~ [c], c ~ Char) and evaluates to "WowWowWow" (as expected?). That's weird, but I'm not sure it's a problem.
Great talk! I find it extremely interesting what dependently typed programming can do for these kinds of "practical programming" problems. (In terms of natural type support for this kind of thing.) On the other hand, most of this problem goes away if you just embed a little code-generation step into your build process. Granted it's not quite as elegant, but is the added complexity of Type Providers worth it? (How often do API endpoints *actually* change in practice?) I know it was a silly example, but just following along with the example, I could trivially build an "ask-the-user-about-their-age" step into any build process pretty trivially. (Same goes for generating schemas, etc.) EDIT: Perhaps it's just a question of me being extremely skeptical of the idea of Type Providers in general.
Integrating that with haddock seems like a great GSOC proposal btw!
Thanks for the reply! I'll need to think about it.
Those were actually generated with a modified haddock that I wrote a while back -- couldn't be merged into regular haddock because of an unfortunate dependency on syb, which would probably be trivial to remove with GHC generics I think... https://twitter.com/ranjitjhala/status/318071163668541441 
Look at [vinyl](http://hackage.haskell.org/package/vinyl)
Understanding [weak head normal form](http://stackoverflow.com/questions/6872898/haskell-what-is-weak-head-normal-form) is a huge part of predicting Haskell evaluation.
I implemented this (with only `TypeFamilies`, `FlexibleInstances` and `FlexibleContexts` btw) and the major disadvantage I could find is that you can't nest calls to `lift`. b :: IO (String, String, String) b = lift (,,) getLine getLine (lift id getLine) With the multi-param typeclass version I was playing around with, you can. Any idea why this is? I thought that type families were at least as powerful as functional dependencies so we should be able to get the same behaviour?
Thank you! I'd heard them used interchangeably in casual discussions, but hadn't (yet) dug up the literature to understand their relation to one another.
[Halcyon](https://halcyon.sh/) now supports 32-bit platforms, including Debian 7.
&gt; -- foldr instead of foldl' &gt; sum = foldr (+) 0 This won't help you much but there is another way to define `sum` which is: sum :: (Foldable t, Num a) =&gt; t a -&gt; a sum = getSum . foldMap Sum (https://ghc.haskell.org/trac/ghc/wiki/Prelude710/FTP) I still don't see when the latter would perform better than `foldl'` but it works for every t.
I understand the "weird" example, but if I did an extension in this direction, I wouldn't allow to mix (without special delimiters) expressions written in the language of the Functor, Applicative, (Monad) and plain Haskell. In `ltn "Wow" 3` the first juxtaposition is from the higher-level language and the second is "unfunctoring": going back from the Functor to plain Haskell, which shouldn't be allowed to be mixed in a single expression. It's also weird because it's like allowing to explicitly pass a world-argument (`3`) to an IO-action. On our level, we don't have direct access to worlds. (My plans were more for, like, automatic `join` for "powerful operators", or viewed from the other side: for automatic `pure`/`return` for "weak" values and automatic `lift` for pure "weak" functions. And some other things...)
Go big or go home (I'm just having fun now) import Control.Lens bothGrandfathers = sequenceOf both . liftM2 (,) (father &lt;=&lt; father) (father &lt;=&lt; mother)
That other way of defining sum doesn't really fix anything. It might be efficient in some context, but certainly not for lists without optimizations enabled. $ ghci GHCi, version 7.8.4: http://www.haskell.org/ghc/ :? for help Loading package ghc-prim ... linking ... done. Loading package integer-gmp ... linking ... done. Loading package base ... linking ... done. λ&gt; :set +s λ&gt; import Data.Foldable (0.00 secs, 2224376 bytes) λ&gt; import Data.Monoid (0.01 secs, 6988832 bytes) λ&gt; foldl' (+) 0 [1..10000000] 50000005000000 (0.30 secs, 972658088 bytes) λ&gt; (getSum . foldMap Sum) [1..10000000] 50000005000000 (3.68 secs, 2023367656 bytes) 
Thank you. I have updated C version prototype.
&gt; which is quite different from having to look up the documentation in a separate area. Who says binding generators can't also generate good documentation? (For example, most XML binding generators for Java include all the documentation from relevant XSD elements.) Granted, it's not even close to perfect, but I stick by my assertion that APIs are *mostly* static, and thus can be reasonably documented out-of-band and will remain relatively consant across a project's lifetime :). &gt; Code generation, at least the kind where you spit out source files as a step in a Makefile, doesn't do much for guaranteeing the well-typedness of the generated code, for instance. They're a bit more sophisticated these days, but... "doesn't do much for guaranteeing the well-typedness of the generated code, for instance" is a weird claim. Obviously, I'm going to have my compiler check/compile the generated code, so... yes, it's going to be type safe, by definition. I might as well raise an objection to Type Providers saying that "well, maybe the Type Provider actually doesn't *really* know what the XSD/... says, so it's not going to be type safe." At the end of the day, you're going to have to communicate with a SOAP/REST service and whatever it says at *run time* is going to determine if you succeed or not. All that Type Providers *actually* do is to move a build-time step to compile-time. It may be great for ergonomics, but it is *not* revolutionary (for anything other than rapid development). EDIT: Oh, I should say: Having such things integrated in the language is obviously a nice perk, but again this is mostly about ergonomics.)
I agree, but would also suggest that it should ideally be explained *before* the actual term "weak head normal form" is introduced. It's an arcane phrase for a dead-simple concept; that sort of thing has a nasty tendency to make people doubt their understanding on the assumption that it just *couldn't* be that simple.
Yes. You may want to look into a language like MLPolyR where these things are first class. http://people.cs.uchicago.edu/~blume/classes/spr2005/cmsc22620/docs/langspec.pdf http://lambda-the-ultimate.org/node/4631
Why don't you learn Erlang, Elixir, FSharp along with Haskell? FP is still hipster, but there are more and more jobs available every day. There is a slew of Elixir jobs on twitter.
I would love to learn as much as I can. Honestly though I feel overwhelmed by the amount of things everyone recommends. Over the last couple of years I've given quite a few ( by my lame standards) languages a spin - javascript, scala, clojure, groovy, racket, a little bit of Golang and now Haskell. Im willing to try anything but to be employable/dangerous in anything seems to need more than a tad bit of expertise (breadth first is easy but depth is harder) The one thing I find is that claims are taller than the reality. Most new hip languages start with the promise of ease, succinctness, parallel computing ease etc and become unwieldy soon enough. The only exceptions I found so far are Lisp and Haskell.... Haskell more so than lisp. Anyway i will give your suggestions a try. Thanks so much for replying. 
I don't think its admitting defeat at all to keep at coding in Java for a day job for a whole, or just taking a more modest step to Clojure or Scala, while you keep working on learning Haskell. I don't think it has to be all or nothing -- and finding the time to do a little of what you're interested in each day, and finding a way to bring that back to the code you're working on, even if it is in another language where functional idioms don't come quite as readily -- that's a fine incremental step. There are _lots_ of scala and clojure opportunities at the moment, and lots of the folks doing them are interested in functional concepts too, and could even be open to doing smaller projects in Haskell as they acquire more developers with the capacity to do so.
For what it's worth, I followed a similar path, but ended up in Javascript instead of your prospective choice of Python. Despite Javascript's reputation, it is a very interesting place to work. There are a lot of very smart, principled people creating libraries and tools. I think Facebook's React library is a great example. I became a different, better programmer from learning Javascript, just as I would from learning any language. In the end I was even enjoying it. (Well, sort of.) The field is ridiculous. There can be a path through the wilderness, however. Sometimes we have to balance ideals with pragmatism, but who knows what new ideals that may introduce you to?
Be glad you are not a want-to-haskell-developer who ends up doing VB6. (The pay is good, but..)
You are hereby encouraged. :) Come hang out in #haskell. I'm chreekat. (Er, I guess that's obvious.) I'm also in #snowdrift, the channel for the project I'm working on right now. We/I am happy to answer questions, chat about the weather, whatever. Haskell jobs are a pain to find, but community is everywhere. Every different job and different language opens new opportunities. Good luck!
That's very interesting. I wanted to do JS too but I'd imagined front end work as both rewarding yet as also limiting ( because of my server side background). Perhaps I should give it a serious look again. 
Sounds like you're soul searching. If you understand technology you have nothing to worry about.
&gt; I think my example still stands as a decent reason not to "overload" juxtaposition as both fmap/&lt;$&gt; and it's current use/$. Yes.
Klasse!
I'll second this - OPLSS really clarified a lot of things for me, and I met a lot of great people who I still correspond with to this day.
Yeah, thats a good point. I think it is alright to start with the term 'normal form' though simply because it is the form programmers think of an expression being in with most procedural languages.
Have you considered shifting to C# for the short-term employment angle? It's close enough to Java that it should be a breeze for you to translate your existing expertise, but IMO it's considerably less tedious; and more to the point, numerous language features in the last few revisions have been directly inspired by Haskell. Enough to get some practice with a few core FP concepts while working in a more familiar environment.
An installation of the official SDK binaries can be quite large because it can include the IDE, multiple different versions of the libraries, example programs, etc. The minimal set of libraries and headers for building with MinGW is only ~200 Mb and that doesn't require the Visual Studio CRT libraries. As /u/TJSomething pointed out [in this post](http://www.reddit.com/r/haskell/comments/2vehoo/crosscompiling_gui_libraries_from_linux_to_windows/), the worst case set of Qt libraries required for distributing an [HsQML](http://www.gekkou.co.uk/software/hsqml/) application binary weighs in at 50 Mb and there are several avenues for reducing that.
1. Slick was referring to Qt (and QML more specifically)'s appearance, not the size of installation. I apologize for using such ambiguous phrasing. 2. GHC on Arch linux takes up 787MB for install (which I believe also includes base). Do you consider GHC bloatware as well? 3. The [offline installers](http://www.qt.io/download-open-source/#) weigh in as little as 625MB. If you're concerned about install size of the SDK, perhaps try one of those. 4. Qt Doesn't require Visual Studio libs. I was able to use MinGW (both the version included with the installation, as well as a standalone installation of it). 5. No one is twisting your arm asking you to use Qt. I didn't even suggest that people use Qt rather than FLTK. I was merely noting why I generally choose Qt over FLTK. In fact, I'd not have mentioned this at all if the OP hadn't, in the documentation, mentioned Qt himself (in the form of hsQML). 6. Please do your homework next time, and try not to sound so bitter. I'm aware that my comments aren't as tactful as they perhaps could be, but your comment rubbed me the wrong way /u/SkoomaMudcrab 
Summary: The free monoid in Haskell is something that is ~~infinite at both ends~~ doubly infinite at all internal points. `[]` is not free because it is only infinite to the right. I still don't quite understand though. What is the unique monoid homomorphism `FM Bool -&gt; C2` extending `True -&gt; 0`, `False -&gt; 1`, where `C2` is addition of integers modulo 2? EDIT: I guess it is `_|_` on "infinite" elements of `FM Bool`. This is more subtle than I thought.
It's quite possible that in other contexts these names are used differently, but in the context of Haskell code and packages, what you refer to as bifunctors, I've only previously encountered under the name [invariant functors][invariant]. Whereas I've only ever seen [bifunctors][bifunctors] used to refer to types which are functors in two of their type arguments (`Either`, `(,)`), occasionally also including those where one or both are contravariant (in which case a [profunctor](http://hackage.haskell.org/package/profunctors) is also a kind of bifunctor). [bifunctors]: http://hackage.haskell.org/package/bifunctors [invariant]: http://hackage.haskell.org/package/invariant
Wow... the most interesting part for me was the rearranging from foldMap :: (Foldable f, Monoid m) =&gt; (a -&gt; m) -&gt; f a -&gt; m to toFreeMonoid :: Foldable f =&gt; f a -&gt; (forall m. Monoid m =&gt; (a -&gt; m) -&gt; m) ...and the realisation that the [free monoid](http://en.wikipedia.org/wiki/Free_monoid) can be expressed as existential type(?) in Haskell
First I was a little surprised to read a German title and thought it was some misleading autocorrect. Danke für den Beitrag, klingt interessant. :)
You're right, I mixed up the names. Thanks!
I am currently using Haskell to write AI programs. I find it a great language to work in for such tasks. Due to my contract I can't share code, but I would be happy to answer questions. I found LYAH quite helpful as I was learning (not that we ever stop learning) I find working on small self allocated projects the best way to learn. That and Caltech lectures.
Not only that, but you can try F# without having to rewrite everything
There's a [repo](https://github.com/chris-taylor/aima-haskell) I've stumbled upon some time ago, never checked it out thoroughly but it seems to show that you can do the AI algorithms successfully in haskell. Seems that the goal of the author was to implement all of the algorithms from the Norvig's book AI: A Modern Approach.
Cheers, I had a go at using your slides structure for a talk i'm giving tomorrow and they look great. Thanks to Chris Done too :) 
I assumed that diffing wasn't semantically important because my understanding of diffing comes from [the React docs](http://facebook.github.io/react/docs/reconciliation.html) where it is written &gt; ... the reconciliation algorithm is an implementation detail. React could re-render the whole app on every action; the end result would be the same. Losing data that's typed into a text field is certainly a non-issue. I don't do diffing and I don't lose any text field data! "Flash and reflow of UI" is the performance issue I was talking about and will have to be dealt with. Scroll position is interesting because it's generally a completely implicit piece of state, but I don't see why it couldn't be handled by explicity by a "react-like" framework. (I'm not saying that the user would have to deal with scroll position, just that the framework could behind the scenes.) &gt; the view is holding state which isn't being reflected in our model Yes, that would be a problem. In practice I do actually keep all necessary state in the model. &gt; Is your design also compatible with existing GUI and FRP libraries? My design is compatible with existing GUI libraries as long as they provide enough primitives. I have an implementation in HTML/Javascript and another in WXWidgets. I suspect it would be viewed as an *alternative* to FRP though, rather than something that could take advantage of FRP. One might be able to use some FRP library alongside but I imagine it would not be very useful. I have two concerns about FRP in general. The first is the semantics of simultaneous events which always seemed to me to be problematic. The second is dynamically creating events. These issues simply don't arise in my framework. &gt; did you envision to build a monolithic, batteries-included framework which offers a fixed set of builtin widgets but can be used immediately, or a smaller, generic library on which many such frameworks could be built? Probably both. Batteries-included frameworks for many targets (WXWidgets, Gtk, Qt, HTML/Javascript, FLTK) built on the same underlying generic library.
Basically the monoid associativity laws say you can always reassociate any finite portions of the tree. The tricky thing is of course you can't know what is finite and what is infinite in a properly continuous manner.
http://stackoverflow.com/questions/19197339/haskell-data-constructor-meaning
Seems I missed this the first time around, and I have felt the blaze-html pain, so thanks for bringing this up. I wonder though, could it be made more type safe to avoid invalid html such as body_ . head_ ?
It's taken me around 3 years on and off to become proficient at Haskell, with a number of false starts on various subjects like folds and monads. Tbf, it was about the same time as it took me to really grok imperative programming (even if I were much younger). I stuck with it though and it has made me a much, much better developer. I now think functionally and apply this to my code in imperative languages to great effect.
Has anyone used lucid with yesod? That would be quite easy if lucid was built on blaze-markup; I wonder why it's not..
&gt; Losing data that's typed into a text field is certainly a non-issue. I don't do diffing and I don't lose any text field data! [...] Scroll position is interesting because it's generally a completely implicit piece of state, but I don't see why it couldn't be handled explicitly by a "react-like" framework. You might not lose the text itself, but what about the cursor position, the selection, which frame of the cursor blinking animation we're at? Widgets have a lot of state, and they don't expose all of it. The reason GUI libraries are tricky in Haskell is that there is a tension between two fundamentally opposed alternatives: either exposing imperative bindings to a major GUI library, or creating a purely functional API for a homemade GUI which will never reach the polish and feature-set of the major players. I'm interested in React's diff approach because it's a clever way to bridge between the two worlds. It may be an implementation detail to Facebook, but to me, it's fundamental and I want to explore it further. &gt; My design is compatible with existing GUI libraries as long as they provide enough primitives. Do you mean that you provide an abstract representation of a button, allowing the GUI frontend to be changed without changing the user's code? &gt; I have an implementation in HTML/Javascript and another in WXWidgets. Your implementation is much further along than I thought! It must be way too late to have these design discussions. &gt; I suspect it would be viewed as an alternative to FRP though, rather than something that could take advantage of FRP. Then I'm afraid our project goals might not be compatible after all. I was imagining that once I was done with my bridge, I'd be able to use funky purely functional abstractions such as FRP on one side, and an imperative GUI library on the other. &gt; I have two concerns about FRP in general. The first is the semantics of simultaneous events which always seemed to me to be problematic. Would you like to elaborate? The only reactive-banana primitive which cares about simultaneous events is [`calm`](http://hackage.haskell.org/package/reactive-banana-0.8.0.4/docs/Reactive-Banana-Combinators.html#v:calm), and I don't understand under which circumstances I would want to use it. And perhaps [`union`](http://hackage.haskell.org/package/reactive-banana-0.8.0.4/docs/Reactive-Banana-Combinators.html#v:union), which deals with simultaneous occurrences by ordering the left events before the right, which I find quite intuitive. &gt; The second is dynamically creating events. These issues simply don't arise in my framework. Do you mean things like [dynamic event switching](http://hackage.haskell.org/package/reactive-banana-0.8.0.4/docs/Reactive-Banana-Switch.html#g:3)? Since your framework encodes the possible events in the type, aren't you constrained to a fixed set of events? Or do you use polymorphic recursion somewhere?
Seconding C#. It's an absolute joy to work with. I used to think Java was tolerable, but after learning modern C#, I never want to write Java again.
I read several things in your post. Please allow me to take them apart and reflect on them separately. ### 1. You want to do programming work that inspires you, and makes you feels truly valuable to the end-result. This you can do in Java (or any lang)! And you should look at this issue separate for learning Haskell. Some ideas on how to achieve this: * working for smaller companies helps * working on a product may help * learning things in spare time that line up with the tech-needs of your job; which you can then apply at work may help (React.js, Play framework, Varnish, etc.) * shifting more into teaching others, or software architecture, or Scrum-master, or any role that is not specifically programming but helps to see the whole process better may help ### 2. You want to make a living. For this you are either on the labour market, or you are to start a company yourself. It seems you focus more on the first: then play that market the best way you can! Make sure to have a nice resume (have others read it, especially people who do interviews with programmers) and linkedin profile. Then do some interviews (or informal meetings at companies) sometimes; just to have an idea whats out there and to have companies know you are out there. ### 3. You love craft of software development, and you want to do it "the best way possible" -- for this attitude you have identified Haskell as a major step fwd, and thus are very interested in it. Great! I totally agree. Software dev't is interesting, and Haskell is one heck of an interesting way to do it. Also: very different from how you have programmed before! So you need time to switch. Take that time. Take it slow. You don't do this to make a living: you do this from your "love of the art". Do it in your own sweet time. Bit by bit. Litte project here'n'there. This will bring you eventually to a proficient level of Haskell dev't (it is not really hard; it is mostly verrrrry different). Then once you are proficient you maybe may find a job with it. But more likely you have applied many insights from your journey into Haskell into your job already! Use more functional style, work more with closures, prefer immutability, pick tools that are more on the functional side of life (for example React.js over Angular). It also to me a lot of time to get to a certain level with Haskell. ### Conclusion I may be wrong with my advice, please forgive me in that case and let me know. But I hope pulling you question into 3 might help you. Good luck! *EDIT:* Fixed headings. Also, in the context of both **1** and **2**, I want to note the importance of going to meetups (see meetup.com for a start), this really helps to get in touch with the better part of a local programmers community. Try also to contribute, if you can make a presentation you can move from consuming into producing for a local community -- that also helps. 
*universal, not existential
Nitpicks: Isn't WAI more akin to Ruby's [Rack](http://rack.github.io/)? I think your arguments would still hold, but I think that would at least be a more apples to apples comparison to draw from. If we are talking Sinatra, we should be looking at Scotty, Spock, et al, not WAI. Also, I don't think mentioning the use of three files is fair, since you could technically write a WAI app without using cabal. Also, the ruby analog would be Gem files (perhaps with [Bundler](http://bundler.io/gemfile.html) as the cabal analog). 
I work in an AI research lab. Haskell isn't popular at all. It's numerical/scientific computing abilities/ecosystem (which is what most of computational AI boils down to) isn't in the top-10 of languages. The dominant languages for modern vision/NLP research are C++, CUDA (for GPU programming), Python (for scripting, wrapping C++ via the CPython interface, etc). Frameworks like Caffe, CCN, etc exemplify this approach. A lot of AIMA is old, outdated, pre-AI-winter work, and isn't relevant at all to modern AI. There are much better books on ML nowdays.
Basically the `:` character counts as a (the only) "capitalized symbol" for following the capitalization convention —where type constructors and data constructors must be capitalized, and functions and variables must not.
&gt; However, two of those files are devoted to ensuring that our dependencies don't mess us around, which isn't actually possibly to achieve in Ruby. I don't understand this bit. Ruby's Bundler will let you specify version constraints in your Gemfile and track the exact versions you've installed in the Gemfile.lock.
Is the EasyChair link down for everyone or just me?
The Haskell job market isn't as grim as it can seem. No, there aren't as many many jobs as in some other languages, but neither are there as many candidates. Meanwhile there are more and more functional-friendly workplaces, where Haskell may not have made it into the codebase quite yet, but it's a strong plus on a resume---a sign that the candidate has the right attitude. Those can be great places to work, even if they're using a less exciting language for the moment. You're much more likely to find jobs like that if you're learning Haskell, going to Haskell events, hanging out in #haskell... On the tech side --- trouble with folds is often a sign that you haven't assimilated all the stuff you've learned. Folds have a lot moving parts, so they can stress your new Haskell skills to the breaking point, even if you generally get the basic idea. So ignore them for a while, and just write a bunch of code. Folds are great, but you don't actually need them: you can always achieve the the same result with explicit recursion, and when you're beginning, that's fine.
Even for sets (as the carrier), finite unassociated sequences are merely the least fixed point of the monoid laws. We can also consider the greatest fixed point[0] of the monoid laws, which is where these infinite sequences come from. Whenever infinite sequences arise, finite associativity is insufficient to nail everything down to a unique flat representation; which is the problem for taking cons-lists or snoc-lists to represent unassociated sequences. The big question is when is it that the least and greatest fixed points must in fact coincide? To answer this question we must look to where the monoid lives— not where the carrier lives. If we allow our sets to contain "infinite elements" then our notion of sets is big enough to drive these fixed points apart. So even saying that the monoid is (merely) a set is insufficient to avoid the problem. Moreover, Haskell's semantics require[1] that we have such "infinite elements", so we can't even try solving the problem by getting rid of them. [0] You may get an uncanny feeling here, if you think about why/how Dan encoded the free monoid by using an elimination form that allows us to universally eliminate into any monoid [1] The requirement comes from the fact that we are allowed to define infinite values at all; i.e., that `ones = 1 : ones` is a permissible and non-degenerate definition.
Ooh. I don't have anything to submit, so unfortunately can't offer relevant feedback.sorry.
Target audience? How much Haskell should one expect to know to get anything useful from this presentation? I do find the topic interesting, but fear it might be over my head. I don't think my lack of experience disqualifies this as a valid proposal, but I do think I'd be reluctant to sign up for this session without understanding how much I'm expected to know ahead of time I see the group intermediate, but I don't really know what that means when Haskell is concerned. I think there was a thread on what it meant to be a Haskell expert which ended with inconclusive results.
I wish Planet Haskell listed authors at the top rather than bottom of posts. In that feed, this is prominently labeled "Edward Kmett." Either way, I thought this was really illuminating.
Given how many libraries you've written, isn't that like saying "Oooh. Its nice to see hackage getting some use".? Not a rag. I appreciate your contributions to the Haskell ecosystem, even if I don't understand half of it.