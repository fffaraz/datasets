&gt; The only piece of code I have written used functions from Data.List and I was always frustrated at the types the functions would return since I would have no idea how to then use them in my own code. Data.List seems rather straightforward, all told. Did you have a particular example in mind?
When you have a specific problem, you should post it to haskell-beginner or haskell-cafe (mailing lists), there will be people to explain. Or in IRC.
Concurrency &amp; Parallelism, obvious example of clear &amp; concise code (rewriting wc, grep etc is often appreciated), and showing how the strong type system is of a great help. Another important thing is the community : many free books/tutorials here and there, a centralised library/application repository, the huge wiki with all the answers, ...
I'm not a planner either, but somehow I stuck with trying to understand Haskell. I'm far from being good, but at least I understand enough to code many usefull things. Hang on ! The more you do, the easier it becomes.
good list, but i havent done any parallelism work in haskell myself so that might make it worth my while (in doing the talk) to learn that stuff i was also thinking about having a local instance of lambdabot to show type and src queries
Seeing them as a restriction is a good thing, and it's that restriction that is a powerful tool : it prevents you from doing mistakes. It takes a while to get used to it, but eventually you'll get there.
A talk about Haskell wouldn't be complete without laziness. It blew my mind to learn that short-circuiting applies to pretty much everything in Haskell thanks to laziness. Now this might be more difficult, but you could skim over the surface of monads, and without going into the dense details of their internals, show how you can use them to do cool parsing a la Text.ParserCombinators.Parsec, and use Applicative to basically "OR" two operations. 
Pure vs. impure. Use STM to show the benefit of purity. Lazy vs. eager. Use laziness to show how it simplifies the logic for complex calculations. Consider tossing in some stuff on bang patterns and simple parallelism for performance (this one ties in with pure vs impure, too). Monads. Show how Maybe simplifies the logic of a sequence of calculations that require correctness at each stage.
&gt; It [Scala] allows you to gradually progress from a java-style OO language to a **functional** language with static types, ... You keep using that word. I do not think it means what you think it means. NB, from the definition: &gt; In computer science, **functional** programming is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids state and mutable data. 
Your question seems very familiar to the one SPJ [asked in 2007](http://www.haskell.org//pipermail/haskell-cafe/2007-April/024500.html)... And his answer was `[A Taste of Haskell](http://research.microsoft.com/en-us/um/people/simonpj/papers/haskell-tutorial/index.htm)'.
I was faced with the same decision for our St. Louis-based Lambda Lounge. I worked on a long slideshow, starting with major bullet points, then diving in to each (purity, laziness, pattern matching, etc.) and built a handout in parallel. Presentation and handout got too long. We had previously been working on modeling a vending machine in various languages, so I decided to switch gears, and after a couple slides of bullet points then I launched into in-depth explanation of the Haskell vending machine, block-by-block, line-by-line. I still ran over time somewhat, but I think this worked out better, giving people something concrete to look at and ask questions about. I intentionally glossed over monads, wanting to focus more on pure functional code and avoid people's eyes glazing over. Afterwards I still sent out my old handout on the mailing list, so it wasn't wasted effort. P.S. Looking at your title again I see your audience is working functional programmers. Our audience is primarily people who would LIKE to be working functional programmers, but instead use Java or something else in our day jobs.
I know Scala isn't pure. I'm just saying that Scala allows you to make a more gradual transition to a functional style before you switch to Haskell.
but f4hy, if you don't understand types and your program doesn't work, it won't work in a dynamically typed enviroment either! I don't understand what your piece of code was supposed to do... maybe because I don't remember which operator binds more tightly, if =&lt;&lt; or $, so I would put some parenthesis... nice thing 'bout types: if you forget a parenthesis, it comes out as a type error!
I think Wadler's Law was in effect because people in the list (it was about a mailing list) had a uniform view about semantics, so they argued about syntax :P
If you talk about Monads, make sure you push the fact that they're not essential or special and that the only language support we have for them is the do syntactic sugar. There are too many people out there who think "Haskell is about monads and if you don't understand them immediately, you can't do anything!" and I think that strange myth should be eradicated as much as we can. It's probably due in part to the ubiquity of monad tutorials everywhere.
I didn't know philly lambda existed! I've been tinkering with FP for a couple years now without really diving in. I've played with Standard ML a while back, and recently decided to try the "hard stuff" as Tim Bray put it. Hopefully I'll be able to attend. The subjects I'd like to hear about: concurrency and monads. I've always been confused by monads, and you can't really do much in haskell without them. The Real World Haskell book is helping, but it would be great to talk to a real live person about it.
3 hours seems a bit longer than what i was shooting for, but thanks for the tip
the material for the last meeting just consisted of code demonstrations in emacs and such, not really slides or anything the company that hosts this i think recently switched to clojure and ruby from java or something
Wouldn't a proper inverse, in addition to zip . unzip = id also mean unzip . zip = id ? That is, the given pair of inverses isn't bijective, as lists are truncated. I'm just nit-picking, though. Not truncating is certainly possible, but would introduce awkwardness in everyday programming, consider zip [a..z] [1..] = [(a,1), (b,2), ..., (undefined, 200), (undefined, 201), ...] ...and opens a can of worms and bikeshedding about whether to use ⫠ or have a tuple of sum types. Not to mention the behaviour of unzip [(a,1), (undefined, 2), (c, 3)]
No mention that I saw of the rules for what things can/can't/must/mustn't start with a uppercase/lowercase letter. (Yeah this was definitely worth a downmod. Fuckers.)
&gt; I've always been confused by monads, and you can't really do much in haskell without them. This is totally false.
So you'd say LISP, Scheme, SML, OCaml, Clojure, and F# aren't functional languages? Also, your (unsourced) "definition" is from Wikipedia, which is edited all the time by idiots. So citing it is really no better than just restating your opinion. And how does "avoids state" equate to "prohibits state"? And why don't Haskell's IORefs, STRefs, MVars, or TChans count? Basically what I'm saying is, never post again.
&gt; Also, your (unsourced) "definition" is from Wikipedia, which is edited all the time by idiots. So citing it is really no better than just restating your opinion It's also the definition used on the linked article. &gt; And how does "avoids state" equate to "prohibits state"? Who says it does? &gt; Basically what I'm saying is, never post again. Let me guess, you're a new Haskell programmer? No wonder it took you 5 paragraphs to say something simple.
Excellent... 
&gt; It's also the definition used on the linked article. Uh, no it's not. FTA: "The Wikipedia explanation [link] is fairly impenetrable.". Doesn't sound like an endorsement to me. &gt; Who says it does? You. Or on what other basis do you claim Scala is not functional? And you didn't answer my question about those other languages.
For me I went basically straight from C to Ruby to Haskell, I didn't need any gateway drug to realize the benefits of fp.
Author here. I wish I could answer you definitively but obviously I'm learning the basics from the book. I think what you're pointing out is that the exhaustive implementation of zip in the code truncates the lists where they aren't of the same length. As a result, swapping the composition is not equivalent to id as zip could change its input. unzip $ zip ([1,2,3], ['a','b']) \= id ([1,2,3], ['a','b']) ([1,2], ['a','b']) \= ([1,2,3], ['a','b']) Is that correct?
Which Qt bindings? Does it use qtHaskell or something else? I would like to see the source code in any case, cause I'm still evaluating GUI library for my next project.
Yep, I'm just unsure what properties an inverse is actually supposed to have.
&gt; You. Or on what other basis do you claim Scala is not functional? I *didn't* claim that. I mocked the idea that Scala "allows you to gradually progress from a java-style OO language to a functional language"; The very idea that Scala is training wheels for real programming is silly. &gt; And you didn't answer my question about those other languages. Largely because you didn't ask politely, and you do not seem to be a honest person. I'm not really interested in arguing about what a "functional programming language" actually means because you can make an argument that [C is a functional language](http://conal.net/blog/posts/the-c-language-is-purely-functional/), and you're not going to get anywhere.
&gt; you do not seem to be a honest person. Yeah, well, you smell bad.
Have a nice day.
I tried to prove this in agda, check it [out](http://www.reddit.com/r/programming/comments/9rh0p/agda_proof_of_unzip_zip_id_in_response_to/).
u2 is a little weird since (join . pure) = id
Howdy, /r/haskell! I've had so many people kindly help me throughout my ongoing journey in learning Haskell, that I thought I would try and show a little of that helpfulness to other learners. I hope someone finds it useful! Comment here with any... comments, but be gentle, as this is the first of my writing I've ever let strangers see :)
I've been going through "Learn You a Haskell", but wanted to know what $ did well before it's been introduced because I see it in a tonne of Xmonad configurations and it confuses me :). Searching Google for "haskell syntax $" is largely pointless; the first result doesn't explain it and the next two down weren't explanatory enough for a raw Haskell newcomer like me. Thanks though :), and while I use WebKit browsers I'll have a look at Hoogle :).
Impressive, relevant, and substantial! There's a real need for this kind of writing in Haskell. This brings to mind just how difficult it can be in write coherently about Haskell topics, as a process oriented explanation hardly ever goes far enough toward explaining what's going on in a particular piece of Haskell code. Something as seemingly simple as wrapping up a JSON Haskell type, involves mention of an abstract type, pattern matching on that type, and a related class, supporting actions for that type. It used to bother me that much of the code in Hackage, including the JSON package, comes with very little documentation apart from the minimal Haddock output generated from the source. I finally subjectively determined that the best approach to this would be for one to master the idioms of the type system combined with classes and everything else generally. Then the intention of the Haskell code is generally obvious throught the types and classes involved. However, this can be a hugh Catch-22 problem for beginners, who are unfamiliar with the mechanics of Haskell and need some code examples to work through, but struggle to make a coherence out of any substantial code for lack of not being able to approach it from all the required angles.
Not sure about the title ...
Ah, I hope you didn't find it offensive, dons. It originally stemmed from an idea I had about a RWH-style concept, but with example projects that were less practical but more akin to the silly stuff I like programming (like that roguelike I've yet to finish). Then I shifted gears, but kept the title as I felt it in some strange way paid hommage to RWH. 
Perhaps not "Fake World Haskell" but rather, "Real Life Haskell" -- someone using RWH in the RW... Great post though!
Oh, no, it's not offensive! It's a nice tribute, but I'm not sure it conveys the right message. "fake" is an awkward word for a title.
An overview of multicore programming in Haskell: http://donsbot.wordpress.com/2009/09/05/defun-2009-multicore-programming-in-haskell-now/
Crikey, what a bunch of whiners commenting on the blog.
I got the idea that this was going to be some kind of a sandbox environment where you can create and delete files without messing up your filesystem; hence the 'fuzzy blanket'.
Very cool, I'll take a look at this after work today!
"Another theme that will emerge in subsequent chapters is the user of inverses in program specification and synthesis." I hope that means I'll get more detail.
&gt; I'm just saying that Scala allows you to make a more gradual transition to a functional style before you switch to Haskell. That makes it sound like Scala is training wheels, and Haskell is the grown-up programming. &gt; I know Scala isn't pure. Neither is C, but you can use a functional style in it; functional programming cannot mean merely "can write functional programs in it" because it's just not a useful definition. The way you teach people to write using a functional style is to show them how productive they can be without lvalues, not by making the lvalues more attractive.
Maybe a different adjective might do? * Unreal World Haskell * Virtual World Haskell * Imaginary World Haskell * Artificial World Haskell * Parallel World Haskell * Alternate World Haskell * Toy World Haskell * Dummy World Haskell Now, if only the site would load for me.
Eh.. Parallelism and Concurrency discussions typically have to start with someone giving a definition before the discussion even makes sense due to the muddying of the waters.
Dreaming Haskell?
Sorry, poor server isn't used to the attention. Should be back up
I'm not dons but I'm not sure I don't find the title offensive, both on the blog and here on reddit. I am an experienced programmer (20 years+) and I'm interested in Haskell, and I do want a resource like this, and this looks pretty good. But...'newbie' is a derogatory term. No doubt the Fortran I did 20 years ago won't much help me understand Haskell although I expect that the Scheme I've done since then might, but no...I'm merely a 'newbie'. (BTW: 'new to Haskell' != 'knows nothing about programming with functions and immutable values') 'Fuzzy blanket' isn't great either. Who needs a fuzzy blanket? Poor 'ickle childrens. Probably afraid of the monster under the bed. As for 'fake', that's a slap in the face. Can't take the real stuff, eh? Well, here's some faked up pretend Haskell for you, junior. Titles matter a lot. They invite the reader to make a lot of inferences about how the author views their subject matter and their readers. There is a word for what you have done with _Real World Haskell_—the word is 'exegesis' Try that out. Exegesis is a difficult and noble thing, and creates a resource of great value for intelligent students. Call this thing _An Exegesis on Real World Haskell_ and you are paying everyone involved a complement.
A variety of ICFP participants giving a short introduction to their talk or research area, with links to papers and videos. Many thanks to Vidiowiki and Phil Wadler for arranging this!
Well, it's certain I'm going to change the title for future installations. As to what exactly, I haven't decided, but rest assured it will be something more neutral. It honestly didn't occur to me that people would feel so strongly about the title, but I apologize. Again, I don't have any experience with this whole public blog deal.
oh ya? Your programs don't need to do any input or output? Because I'm under the impression that you need to use monads to do any input or output in Haskell. Please disabuse me of that notion if I'm wrong.
As a some-time amateur musician, it brought to my mind the analogy of a [Fake Book](http://en.wikipedia.org/wiki/Fake_book). &gt; A fake book is a collection of musical lead sheets intended to help a performer quickly learn new songs. Each song in a fake book contains the melody line, basic chords, and lyrics - the minimal information needed by a musician to make an impromptu arrangement of a song, or "fake it." &gt; &gt; The fake book is a central part of the culture of playing music in public, particularly in jazz, where improvisation is especially valued. Not a perfect metaphor for what nefigah is doing, but evocative.
First of all, you can learn most of the concepts in Haskell by writing pure functions and evaluating them in an interactive shell like `GHCi`. Even for a complicated stand-alone program, it's highly misleading to say that you "can't do much" without monads. Most computation-heavy programs will involve a thin IO "shell" around a pure computational core. A simple example of such a "shell" is [interact](http://www.haskell.org/ghc/docs/latest/html/libraries/base/System-IO.html#v%3Ainteract), which will turn an arbitrary `String -&gt; String` function into a UNIX-style filter program from standard input to standard output. There are a lot of nontrivial programs you can write that way, as any UNIX user will tell you. Even when you're writing your own IO code it will often be a small percentage of the total coding effort. Once you want to write your own IO code, there are two approaches to take as a beginner: 1. You just want to do IO? Just write the code. Treat the `do` notation as an imperative mini-language and don't worry too much about this whole business of "monads". To be fair it's not a perfect match (the meaning of `return` is misleading, for example), but you can get pretty far this way. 2. You're ready to understand what monads actually are? Don't even think about IO. Learn one of the simple monads like `Maybe`. Learn how to use it with `do`, then how that translates into monad operators, and finally implement your own `Maybe` monad by defining those operators. (This takes 4 lines of code.) The `IO` monad is a weird, special-case monad, and you'll get a lot of false intuition about monads in general if you start there. (By "pure computational core" I mean that you don't use IO, not that you don't use monads at all. There's nothing "impure" about monads in general. They're both a way to describe side effects *and* a powerful way to structure non-side-effecting code. But, when starting out, there's quite a bit you can do without *any* monadic code.)
And uninformed too. I love the big ranty one near the top especially.
It's cool. Probe, analyse, respond. I hope you do continue the series (whatever its called).
Using interact is a good suggestion. Since I came across it in Real World Haskell I've been able to make some real progress, where I was stuck before. However, its only fair to point out that function is in the IO monad. So its not "totally false" that you need to use monads to do anything useful. (where "useful" means process any input or emit any kind of output) Its just that its possible to use monads indirectly. Even the "do" notation, as I understand it, is syntactic sugar for a monad. I also agree that trying to understand monads vis-a-vis IO is a bad idea, and I've been mightily confused by various tutorials that tried to explain it that way. 
&gt; So its not "totally false" that you need to use monads to do anything useful. Again, you can use GHCi. And I don't think that writing main = interact f counts as "using monads" in the sense you care about, because you need zero knowledge of monads to do that. But that's a minor point.
When you make an categorical claim that something is "totally false", you're begging to be quibbled with. 
[Tackling the Awkward Squad](http://research.microsoft.com/en-us/um/people/simonpj/Papers/marktoberdorf/) is a classic, covering concurrency as a subtopic of FP in the large. For a rather different take on concurrency, check out [A Poor Man's Concurrency Monad](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.8039) and [The Essence of Multitasking](http://www.cs.missouri.edu/~harrisonwl/papers/amast06.pdf).
Yeah. I'd also talk about the distinction between [concurrency and parallelism](http://ghcmutterings.wordpress.com/2009/10/06/parallelism-concurrency/).
I've just finished reading the tutorial and I found it to be a wonderful, clear explanation of some of the fundamentals! It's definitely a very nice contribution to the Haskell community - keep up the good work! Haskell is definitely not an easy language to learn because it's fundamentally different from most traditional and popular languages out there (C++, C#, etc.), so it's always nice to have a concise, yet informative tutorial like this one! 
good catch. I was playing with the identity (=&lt;&lt;) f mx = join . (f &lt;$&gt;) $ mx but I did it wrong. Should have been u2 els = join . ((pure . (&lt;$&gt;) (* 3)) &lt;$&gt;) $ els correcting on blog...
Any of the papers discussed here: http://lambda-the-ultimate.org/
Is there a transcript/equivalent text representation of this talk somewhere?
Sadly, the god of "doing more than one thing at a time" has only granted us poor Neanderthals two words to describe the complex set of problems in the space of "doing more than one thing at a time". The god of "doing more than one thing at a time" has forbidden us to use the lexicon of mathematics to better understand and describe our problems and solutions. So we beat on each other with the words "concurrent" and "parallel" because we have no other words to use. I think we need a different god. *ugh*
Someone buy the guy a microphone. It's hard enough to understand his brogue.
Or do it again without using the letter 's' :)
I spent a bit of time looking into this for my own purposes, when investigating how to do efficient operations over lists where the data elements were inlined into the nodes a few cache lines at a time. The biggest worry that I can think of is alignment. GHC at last check pretty much assumes the stack and heap are 4 byte aligned throughout. For access to most SIMD operations you need 16 byte alignment today, and 32 byte alignment in the future for Larrabee, etc. This comes with a price tag. Stuff that doesn't use this feature gets bigger, and your data cache gets full faster. That isn't to say it is not worth the cost, but it is at least a consideration to be fully aware of and one which needs to have its impact profiled. Adding proper support for these is more than just adding a couple of primops. Avoiding taking a global performance hit and following the Kent Dybvig 'pay as you go' principle would require some sort scheme where frames and thunks that use these features would be responsible for taking a different allocation path. This would be terrible invasive, also affects how you walk the stack for GC, and the extra overhead there may kill much of the win from having access to these features. The cynic in me says that by the time you finished the patch it'd be too big and too invasive for them to want to integrate into mainline GHC anyways. It is hard to figure out how to 'hill climb' from the current GHC to a GHC that supports those operations.
It's not every day you see a computer professional in a kilt. Here's hoping that it doesn't become Haskell fashion... my legs aren't sexy enough.
I wonder how long until Haskell gets banned as a performance-enhancing drug.
&gt; That makes it sound like Scala is training wheels, and Haskell is the grown-up programming. A fairly apt analogy. ;) Actually, I just figure I'm not pedantic enough to program in Scala. The notation is too busy and makes my eyes hurt. I think I burned out my love for shoe-horning every feature you can into a language with Perl.
There's no official release announcement yet, and it isn't a backend as such, but the jmacro package provides a very nice functional, haskell-ish dsl within haskell for javascript generation: http://hackage.haskell.org/package/jmacro Not very well documented, but feel free to email, etc. with questions.
So one of the things we, we found were to do... So I was using, working with Steve Blotts, er Steve Blott, now he produced a PhD on type classes, he was Phil Wadler's PhD student, and Steve worked with Phil doing a lot of the original theory of type classes; I read this up in the paper on ad-hoc polymorphism from about that time. So, type classes, fantastic idea, if we didn't have type classes we wouldn't really have Haskell, we would have one of the languages of the period where you'd have strange coercions happening behind the scenes. But, again, there are some interesting little quirks to this. And one of the things I studied one day, is that when I put in my standard Fibonacci definition, and I named it and I used it in two different places in the local definition, I could actually have this coming out as being of two different types, so at that time we allowed full overloading in local definitions. So, [???] define your Fibonacci definition, you could have `n` and say this is coming out as `Num a` for some `a`, and then we could use it as maybe an `Int`, maybe as a `Float` in different places in your definition. And of course, in order to do that, the implementation had to recompute the Fibonacci function, which is a bit expensive, to put it mildly. So I went to show John this, John Hughes this, one day, and John again was absolutely horrified discovering this, and said we can't possibly do this — if we do this, we're going to be crucified, because you know, a programming language where you have exponential cost for executing your functions when you've got something which has the same name is really not going to win us, again, too many friends. We've got to do something about that. And the quick fix at the time was to introduce the monomorphism restriction. So a lot of people come to us and they complain about the monomorphism restriction, and it's because of this — it's because of this realization that if you have a named value, you'd expect it to only have one value, not to have multiple values, not to be recomputed all the time. So that's the rationale for it, and I know a lot of people have been bitten by this over the years, so for that, our apologies.
I can't remember where I saw it, probably here, but the Moscow HUG has this: http://vir.mskhug.ru/
Someday, somehow... the monomorphism restriction will be turned into a warning. Like it should have been from the very beginning. And then, someday, somehow... that warning will be dropped from the list of default warnings, and you will have to explicitly request it.
As these are introductory lectures (and, allegedly, not about Haskell but FP in general), shouldn't they go into the proggit?
barsoap, these are based on the Haskell book by Hutton. They're meant to be very introductory. 
I can't check that out, how can I get it to work?
`bos` has turned into some kind of Haskell machine! Seriously nice work there, if only I had a use for it! :-)
We need an overhaul of the I/O libraries so you can e.g. have a version of readLine that returns Text. Then I can use Data.Text for most of my text manipulation needs.
If in doubt, add more type classes...
What's the difference from DList?
Are there parsers that consume this "Text" data type?
I'll be adding I/O support to the text package shortly, and it will fit in with Simon Marlow's rework of the I/O subsystem in GHC 6.12.
Not yet, but it would be easy to get e.g. Parsec3 working with it. Something that I want to do is use criterion to compare the performance of Parsec3 with Parsec2, since questions about that seem to be preventing a lot of people from making the switch.
Clearly you don't live in Silicon Valley :-\
Blogspot needs easy TeX embedding.
I frequently run into a situation where I have to write something quick and though i think in pure functional terms, I cant cough up some thing in Haskell and end up having to resort to shell or python. If i had a proficient Haskeller as a colleague, it would be easy to get tips and over time accomplishing every day computing tasks in Haskell would become easy and natural. My hope is that /r/EnHaskell can serve as a meeting place for " How Can I do X" or probably a bit more complex tasks and knowledgeable people who can provide tips and directions. Do you think it will be useful? Please let me know if you want to join as a mod on that sub reddit too 
I'm a mod here, I'll be happy to help there too.
If a parser can't parse your data, it's the parser's fault: Not matching on (:) but using an Uncons class is its choice, and it's a straight-forward extension. As bos said, Parsec3 supports exactly that. Something along the lines of instance Uncons T.Text where uncons t = (T.head t, T.tail t) ...probably the cleaner choice would be to make FingerTree's viewL and viewR type classes and use them throughout for such tasks.
Part of the problem with teaching category theory to programmers who know no mathematics is that your only source of examples is functional programming and then it all seems to be a big pile of pointless complexity. With all respect to Edward, I'm not sure his package succeeds in dispelling that impression. I've never seen a non-horrible textbook treatment of category theory for even a mathematically sophisticated audience. Particularly the yoga of diagrams is very hard to grasp from reading and self study. I'm reminded of van der Waerden's verdict on the loss of the classical tradition in geometry: "An oral explanation makes it possible to indicate the line segments with the fingers; one can emphasize essentials and point out how the proof was found. All of this disappears in the written formulation of the strictly classical style. The proofs are logically sound, but they are not suggestive. One feels caught in a logical mousetrap, but one fails to see the guiding line of thought. As long as there were no interruption, as long as each generation could hand over its method to the next, everything went well and science flourished. But as soon as some external cause brought about an interruption in the oral tradition, and only books remained, it became extremely difficult to assimilate the work of the great precursors and next to impossible to pass beyond it."
I'm going to disagree slightly and say that Mac Lane's tome is an incredibly good book if you already know about as much math as a beginning phd student in pure math. Other than that...
I agree it's the least horrible book. Its main strength is in the range of examples. But the manner of exposition, especially in the proofs, is as horrible as most other books on the subject. It's a truism that the only way to really understand any mathematical proof is to deconstruct it and then reconstruct it according to your own way of thinking. But usually seeing someone's proof at least puts you on the path to rediscovery and understanding. With category theory and homological algebra I find this is very rarely the case. You have to prove everything from scratch yourself; another's proof is more likely to confuse than enlighten. With that in mind, the purpose of a good textbook on category theory should be to convey ways of thinking and doing; when you get that, the proofs usually write themselves, as suggested by the infamous exercise in the old edition of Lang's Algebra ("Take any book on homological algebra and prove all its theorems without looking at the proofs."). On that score all the textbooks I know of, even the better ones like Mac Lane, fail miserably. Anyway, that's my take.
Awodey's text is really approachable and fairly self contained. At least, it should be a great deal more comfortable for computer scientists than MacLane.
What do you think of Awodey's text?
Last time I had easy access to a university library it was not yet published, so I haven't read it. I'll check it out when I have a chance. By the way, I should point out that nCatLab is another excellent resource once you have a feel for the basics. Maybe not as useful for computer scientists.
This is a great thing to try, and you should definitely keep at it. These days, I write almost all of my throw-away code in Haskell.
&gt; Sharpen your lambdas and threaten any category theorist you come across until he writes in a style that's easy to understand. Bah, humbug. We have to meet them halfway; you must do problems for a few months before you dare to complain.
I have heard good things about **Category Theory for Computing Sciences** (by Barr &amp; Wells) but I've not been able to find a copy. (I have emailed the publishers and not gotten a reply.) Have you seen it? 
I found _Conceptual Mathematics: A First Introduction to Categories_ by Lawvere and Schanuel to be interesting and approachable; I think it was designed for an advanced High School-level class. I can't claim to have mastered the whole book but it kept me entertained and I felt like I was able to make progress in the topic.
I'm not a huge fan of it. I'm teaching a course on category theory this term and I'm changing the organization a good bit from that book - for example, they use adjoints in ch 3 but don't define them until ch 13.
Thanks a lot! I'll add you right away :)
Personally, I'm not very interested in proofs: I'm interested in category theory because it provides a powerful and generic way of abstraction, not because I want to prove that such-and-such thing that I happened to come across is this and that kind of category, but because I want to tune my filters to spot more opportunities to abstract, to better manage my code. Category theory, for me, is a means to a means to an end. If you're not acquainted to a particular abstraction (and an author of a textbook should assume that its audience isn't), jumping from "A monoid is a thingy with an identity and a binary relation to itself" to "The natural numbers under+ with identity 0 form a monoid, as do they under * with identity 1" is much, much harder than just starting out with those examples, identifying the common parts, and finally formalizing the abstraction. Especially if the abstraction is more advanced than monoids. That, and cluttering both examples and the abstraction itself with alien notation and modes of thought that, while penetrable, distract from the task at hand. So, please don't worry about proofs. I do them: Informally, in the back of my head. I notice whether they were correct by noticing whether applying a certain abstraction works in practice: First of all, I care about the correctness of a particular specialisation of an abstraction, not the laws that make it correct in the general case. It's nice to have them mentioned, but don't dwell on them or even bother giving exercises: I'm interested in slurping knowledge in the hope that it might be useful some time later, not learning for an exam. I think Byorgey's typeclassopedia comes with exactly one exercise: Writing bind in terms of &lt;*&gt; and join. I would be smarter if I knew why that's actually an enticing one.
I'm coding software for more than 10 years and consider myself quite advanced, I tend to grok concepts that make others run away in horror (have a look at the continuation section of "Advanced Programming Language Design"), but my math education stopped at integrals. I never did formal proofs, and my logic is boolean. So, when I don't need any maths to grok that continuations can easily express lists, why am I supposed to get into maths to be given the chance to read something about some category?
There's no "Category Theory for Hackers", is there?
http://pleac.sourceforge.net/pleac_haskell/index.html
cratylus, thanks! if there could be a sticky thread we could add links like these at the top. For now i'll add them in the descritpion.
&gt; I'm interested in slurping knowledge in the hope that it might be useful some time later, not learning for an exam. This is a very strange conception of proofs. Knowledge is justified true belief. The point of a proof, a good one anyway, is to provide justification and understanding; the point is not to satisfy some ivory tower pedant.
Is there documentation available (I'm talking user manual, not so much Haddocks...) for parsec3? Also, is it backwards compatible with P2 parsers? Or am I going to have to hack at it for a while to get it to work? Speed is less an issue for me than how much work I'm going to have to put in re-learning how to make stuff work...
The problem is that without understanding proofs, you will always have a very superficial knowledge of the subject. It doesn't suffice to say: That sounds about right (only in *really* obvious cases), because often many statements are more subtle then it appears. If you ever want to build on abstractions, you have to fully understand them first.
I am surprised no one mentioned them: There is a [youtube channel](http://www.youtube.com/user/TheCatsters) about category theory (they don't start at zero and haven't posted in over a year but they give an reasonable introduction to many fundamental definitions, with some examples). The style of exposition is really brilliant and introduces you to shorthand notations that explained in books are just awkward to learn. And they even use Lists to explain Monads :).
I think another part of the problem is that a lot of the concepts or examples are introduced/proven non-constructively, so that it's hard to see how (or even if) they can apply directly to programming.
Really? I admit I never encountered that as an impediment. Do you have any examples in mind?
not off the top of my head :) But the kind of thing I had in mind was an existence proof that a certain something exists in a particular category, derived by contradiction; so the proof gives no way to compute that object, nor any indication whether there indeed *is* a way to compute the object, or whether you need extra conditions and properties to be able to compute it, etc.
The moment I begin to fully understand a theorem is when I'm trying to prove it from scratch and fail miserably.
Well for me it helps to prove simpler consequences, for which nevertheless you have to understand the original proof. But if I were to prove the Inverse Function theorem from scratch for example, I would most certainly fail.
I had exactly the Inverse Function Theorem in mind when writing this. :-D I still don't quite understand it (Why on earth does the proof use the Banach fixed point theorem?) but trying to prove it from scratch helped a great deal. Also, I recommend comparing one proof of it with the one in Lang's "Real and Functional Analysis" who keeps the fuss to a minimum.
Sorry about the late submission. I managed to figure out how to submit it on my own. It just took me a while.
I have a decent maths background, but still struggle with the concepts in category theory until I can see them being *useful abstractions* in categories that I'm comfortable working in ('Hask' being the main example these days). So (because of Hask) I'm fine with products/sums, exponentials, functors, natural transformations, monads even... but haven't properly gotten to grips yet with some of the further abstractions like limits/colimits. I can follow the proofs mechanically, but need the motivation for it to really 'stick'. I'd probably need someone to show me how a colimit can be a useful abstraction when doing functional programming (for Hask), or linear algebra (for Vec), or perhaps an interesting logic (for its category of propositions/proofs). Seems like category theory's good for (at least) a couple of thing: * Talking about structural connections between different areas of maths/physics/comp sci. So unless you're familiar with two different areas where there are enlightening structural connections to talk about and get to grips with, this isn't so useful. * Discovering useful abstractions and structural language within an individual area in which you work (functional programming say). And with this, it proves useful up to a point, but beyond that point descends into abstraction for the sake of abstraction. Where that point lies probably depends on the field in question. It seems quite a few academic mathematicians view category theorists in the same way programmers view architecture astronauts/design patterns obsessives...
Get where you're coming from there. With category theory being more about structure than content (or so it seems, at least at the more basic level), often the proofs just amount to checking that the definitions are fit for purpose. So most of all we want good motivation for what that purpose is, afterwards the proofs will tend to fall out. If you've not done much of this kind of definition-checking proof before though it's worth doing some of them. Also, it's possible to develop wrong ideas in category theory, where you unwittingly assume that every category behaves the same way your pet category (and source of intuition) does. Going through the proof in the abstract setting helps you avoid that.
I think barsoap wants to: * Slurp up structural concepts to the extent required to spot them in the wild * Only prove properties of them when they're essential to the motivation for their definition / to getting an intuition for the concept * Then wait until you've spotted (or been shown) some useful examples "in the wild" and feel like you might get some use out of the abstraction in this case, before investigating further. Which is pretty much where I'm coming from too. Think you need to do at least some proofs to get that intuition though.
I haven't tried it. I just remembered seeing it somewhere. As it turns out it was here: http://www.reddit.com/r/haskell/comments/9lpu8/ghcs_javascript_backend/
Why should there be? It's a theoretical tool, hackers aren't theorists.
the haddock documentation for parsec3 is a lot better than parsec 2's
I'm afraid I don't believe a word you say about the usefulness of proofs. You see, back in the days my English teacher scolded me for not learning my vocabulary. It seemed to me that shoving endless lists of words into my mind without any surrounding usage context just won't make it stick. Instead, I read English books. That practice doesn't seem to have hurt my language skill, quite the contrary: Sometimes, I'm even able to produce English that's idiomatic. The same appears to be true for proofs: In my mind, they float in an abstract space, surrounded by void. You might prove that friction produces heat but still be unable to light a fire. I rather leave out the proof and learn how to light a fire. The insight that friction produces heat iff the wood isn't wet tends to stick better. Proofs may be all that mathematicians crave for, but I very much doubt them to be the conclusion of all didactic wisdom. It might be that I undervalue them, but then it's because they're overvalued (in the didactic and practical, not formal sense) by those that specialize in them.
Without theorists, there'd be no lambda calculus. Without hackers, there'd be no lisp. Ergo, it's useful for hackers to learn lambda calculus. Generalising, it's useful for hackers to learn about theoretical tools so they can be abused for practical ends. Q.E.D.
Knowledge is reliable association popping up upon encountering something. I rather stick with Kant than with a definition that fails to include measures for "justified" and "true". I know my mind and its tendency to wallow in local optima too well to rely on such a definition that defines a term in terms of further definitions, but doesn't induce an original thought on its own. That is, I'm interested in thinking of the right things at the right time, not about the metaphysics of truth, though I don't mind them popping up as a result of thinking the right thing at the right time.
Well I just expressed my personal opinion. I speak from (albeit limited) experience however, that a rigorous mathematical formulation and the knowledge of the usual proof structure can help a lot to differentiate between essential and problem specific properties in physics. (For example it might be nice for the professor to prove the Cauchy-Schwarz inequality in the QM formulation, with fancy bra and ket notation, but it would be equally valid to just refer to it)
&gt; Which is pretty much where I'm coming from too. Think you need to do at least some proofs to get that intuition though. Well, yes. Once upon a time, I went to my sister, complaining that that funky formula my math teacher told us about doesn't make any sense: A = ( b * h ) / 2 She went out drawing a rectangle with a diagonal, saying that the area of one of those single triangles is obviously half the area of both triangles, which happens to coincidence with the area of the rectangle b and h describes. Then she drew the mirror image of those two triangles right next to it. I never bothered to tediously work out all the special cases, I just noticed that you can reduce any triangle to right triangles and lived happily ever after, never remembering the formula, but being able to infer it in the blink of an eye. And no, I never wrote a proof for it. I'm quite sure there's a proof, but I just don't care.
Certainly a lot of mathematicians view category theorists ...unkindly. But I think you've missed one of the biggest things that CT is good for: parametricity. In CT, the discussion is always firmly about functions/morphisms, and this allows us to get away from stupid details about the particular innards of objects. Contrast this with set theory which is obsessed with the innards and never seems to move much beyond them. The parametric nature or "ungrounded"-ness of CT is very much like the ungroundedness of type theory (HM type inference doesn't give one whit what the values of a type look like, it just assumes there are types and goes from there). And this ungroundedness is very important. Other disciplines are obsessed with grounding, which is why they despair of CT, but that's also part of the reason IMO why they always get hung up on abstruse problems that don't generalize to other domains.
Damnit, this should have been issue 135. The post itself is fixed, but I can't update the title here... :/
psychotic, can you point to an intro to category theory online? e.g what do you think of the wikipedia entry for [Category Theory](http://en.wikipedia.org/wiki/Category_theory) (wikipedia is often surprisingly good for maths stuff); or the explanations in Wolfram's Mathworld (for Mathematica) for [Category](http://mathworld.wolfram.com/Category.html) (and links). Mathworld often seems quite deep and very practical to me, a non-mathematician. I like the "general abstract nonsense" term; and I note that since it's a meta-mathematical theory, it's probably only understandable in terms of other mathematics (like that least-horrible textbook you mentioned).
Not a very good drawing. Where's the purity?
I always thought [this](http://en.wikipedia.org/wiki/Haskell_Curry) was haskell personified
 instance Monad ChastityBelt where (&gt;&gt;=) = turn_key_in_lock
After learning some more from an external source: http://en.wikiversity.org/wiki/Introduction_to_Category_Theory/Sets_and_Functions Its clear that the second example unzip . zip is in fact surjective. Not particularly useful, but for anyone stumbling here who wants more info on the conversation, see that link.
What's the message with the prominently featured turned A's? All who partake are satisfied?
I guess the artist is quite fond of [existentially quantified types](http://en.wikibooks.org/wiki/Haskell/Existentially_quantified_types)
&gt; However, we never actually want to declare such a general instance as the one above, because it rules out instances which aren’t implemented via Applicative Why is that a bad thing? What's wrong with guaranteeing all Applicatives containing Num behave consistently that way?
Because there may be a significantly more efficient implementation which is extensionally equal to it.
I think the same problem can be solved by the simpler extension of allowing default methods for superclasses in a class declaration. 
That's person linguified.
awesome !
Aren't we All.
The problem when you do that is that you also get locked inside. It's kind of like Lemarchand's box.
Sounds useful. Don't forget about #haskell as a more interactive, though less visual, place for that.
I haven't seen a unified treatment that I much liked, either online or offline. You can find good explanations of some individual concepts and ideas on sigfpe's blog. 
My intention was not to get into a scholastic argument on epistemology. My aim was entirely practical. For me, a good proof (or a sketch thereof) is something that accomplishes everything you stated as a desideratum, and more. I admit most texts on mathematics have remarkably bad proofs as measured by this yardstick.
ummm, isn't the inner product also invariant under rotation?
Needs an update for the new logo.
Seems paradoxical that you can only bind to another ChastityBelt. How does that work, is that like shopping carts?
&gt; * Talking about structural connections between different areas of maths/physics/comp sci. So unless you're familiar with two different areas where there are enlightening structural connections to talk about and get to grips with, this isn't so useful. &gt; &gt; * Discovering useful abstractions and structural language within an individual area in which you work (functional programming say). And with this, it proves useful up to a point, but beyond that point descends into abstraction for the sake of abstraction. Where that point lies probably depends on the field in question. It seems to me that the first bullet point is about half of what category theory was originally designed to do, and not necessarily the most interesting half. I believe (but am no math historian, so could be wrong) that category theory was originally designed to make precise the vague notion that this proof over here in, say, group theory, really looks, in a structural sense, an awful lot like that proof over there in, say, topology, and we shouldn't *have* to prove it twice just because the names are different.
Any problems building this on Snow Leopard?
Is there no longer an extralibs tarball? The README still says there is.
It will build on SL, but ghci doesn't work and there may be problems with linking. Also some functionality relying on the interpreter (like Template Haskell and annotations are buggy).
Would it not be better keeping the submissons in thios subreddit? Sounds like you might jusr diffuse the haskell audience
Nice.
Well, think of a project you might try in Python/Java/Ruby/whatever else you know. Then try it in haskell! Some project ideas I've had/worked on (the latter are marked with +'s before them) * +Hackmail Getmail/Procmail Replacement * Mailhack Mail viewer/sender + sendmail wrapper * +HCard A library for implementing playing cards, decks thereof, etc. * +HWN2 A rewrite of the old HWN software, which is used for aggregating community news and formatting it into the HWN newsletter * +hsemail-ns A nonstandard parser for emails, forked from hsemail, -ns uses template haskell and some other tools to make the hsemail parser a little cleaner and nicer. * piirc (πIRC, pronounced "Percy") A scriptable IRC client which would have a EDSL for interacting with IRC. Ideally this would take the form of a combinator API + some basic primitives. The idea is that -- given a very basic IRC client, the user would use the EDSL to do most of the actual IRC interaction. * 1/parsec (one-per-parsec, or "persec" for short). An "inverse" parser, something which would have a parsec-like combinator library, but instead of generating a parser, it would generate a function which generates samples which conform to the parser. Specifically, it would generate some number of unit-tests which simply run the parser on the sample generated. This could then be added to a testcase so that when changes to the parser are made that are supposed to be backwards compatible, you have a test harness already in place. -------------- Feel free to take any of those ideas and put them to good use! (Attribution is appreciated but not required. :) ) I also happily accept patches for any of the ones I've actually started working on (like HWN or w/e) -- if you're interested in helping, I can come up with a TODO list (as of right now I'm just flying by the seat of my pants and a vague roadmap.
thanks
Also talked about here: http://www.reddit.com/r/haskell/comments/8hbgu/an_adaptive_state_monad_40_faster_than_our_best/ http://hpaste.org/fastcgi/hpaste.fcgi/view?id=4458 
.I'm presenting a short talk and position paper at the "Workshop on Non-Traditional Programming Models" (in relation to high performance computing). I'm arguing that EDSLs are a good way to tackle new kinds of hardware, and help domain experts get their code running. The 1 page position paper is here: http://galois.com/~dons/tmp/paper.pdf I'd love feedback!
Edit: off topic.
 instance Monad ChastityBelt where return = put_on_belt does returning the woman into our ChastityBelt make more sense? The first was meant to read "bind by turning the key in the lock" :D 
[release notes](http://darcs.haskell.org/ghc/docs/users_guide/6.12.1-notes.xml) ...I didn't find a built html version, so that's the raw xml.
The release notes say it's been superseded by the platform.
Well I guess those aren't the ones I count as proofs while busy demeaning proofs, as they don't creep me out. You know, all generalisations are false.
this SR is a general umbrella for all things Haskell. It gets difficult to filter certain types of posts and also get and retain attention of experts. The other indirect advantage i see is that having a specific subreddit by itself might attract people to make more of such posts over time. hopefully eventually there will be enough posts to be a good starting point for most newbies to Haskell[ might i say even those with some level of expertise] to start applying Haskell for their task at hand. /r/EnHaskell is for "(This is the problem, This is a solution in Haskell) threads, so by discussion and by just presenting it, more problems and tasks that Haskell can be and is used for will get some air time.
Just to clarify, if your program doesn't use split and doesn't call newStdGen repeatedly, it won't be affected by this issue. For instance, the example program could easily be rewritten to use randomRIO or randomRs, and would work fine in either case.
This doesn't just rule out other instances for Applicatives containing Num; it rules out other instances for anything of the shape (f a), even if f isn't Applicative and a isn't Num.
[Formatted release notes](http://www.haskell.org/ghc/dist/current/docs/html/users_guide/release-6-12-1.html)
That's a because instance selection ignores context :-( Is there a consensus that instance selection should ignore context, or was it done as a temporary simplification?
I'm not sure what the issue is? Haskell handles mutual recursion just fine. Also pretty off topic.
A toy programming language is a good way to learn stuff.
Lava probably deserves mention too, since it's probably the oldest EDSL in Haskell?
Then you can implement another language in your language so you can implement a language in it
I'm on a campaign to kill off all the IO functions in System.Random, except for the one that gives you a new RNG from the OS (ie /dev/(u)random). There should not be a "global" RNG at all. For one thing, you can't even implement it in Haskell. That should be a good indication that it's not a good API.
Then you can't really call it a toy =p
parsec3 includes a compatibility layer that works almost all of the time. It is possible to write code which works in parsec2 but won't compile in parsec3, but it is unlikely.
I have a few half-baked forks of parsec3 written for performance and getting benchmarks has always been a pain. After that, I just need to write a set of correctness tests. Funny story - I once left one of my forks of parsec installed and couldn't download packages with caball-install, because network couldn't parse URLs anymore.
I once wrote a library where I wanted to use 'newStdGen', but the existence of 'setStdGen' scared me off - I can't be assured that a consumer of my library isn't also using a second library which games the random generator.
Btu that's the point of newStdGen. It gives you a StdGen that is independent of the global one. It is unaffected by subsequent calls to setStdGen.
Do you mean the extension described [here](http://www.haskell.org/haskellwiki/Superclass_defaults)? So, you would solve the problem as -- in some library class (Num a, Applicative f, Num (f a)) =&gt; AppNum f a where -- The type signature to show which superclass we are overriding (+) :: f a -&gt; f a -&gt; f a = liftA2 (+) ... -- in user code instance (Num (MyApplicative MyNum), AppNum MyApplicative MyNum) where {} I hadn't thought of that encoding.
at the expense of &lt; i dont know what to put here&gt;, may i suggest you take a look every now and then at /r/EnHaskell and see if any of the problems [ or a combination of them] interests you. there are already two unsolved problems there :) 
Another issue is that if you get a random integer in a range, the library currently generates it by returning the remainder of a random number from some fixed range when divided by the requested range. This gives some quite non-uniform distributions for unfortunate choices of the range.
But it is affected by prior calls to setStdGen.
I usually write ray tracers when learning a new language. They're fun, there's loads of variation you can play with, and it's good "bang for buck" complexity wise (cool shiny spheres only take a few lines!)
So the following code, designed to produce a lazy list of shuffled packs of cards (from a program to calculate poker stats) would be affected: shuffle _ [] = [] shuffle rng cs = head b : shuffle g' (a ++ tail b) where (a,b) = splitAt r cs (r,g') = randomR (0, length cs - 1) rng shuffles rng cs = shuffle g cs : shuffles g' cs where (g,g') = split rng but changing the latter definition to shuffles rng cs = shuffle (mkStdGen s1) cs : shuffles (mkStdGen s2) cs where (s1,g) = random rng (s2,_) = random g would be OK?
I appreciate the nod. =) I need to go back through and refactor category-extras into several smaller packages. ;) Right now it is a kitchen-sink of every category theoretic idea I had that I could put a type to, and so it attempts to serve several masters at present. 1. Providing monads/comonads/functors and transformers based on Kan extensions (yoneda, codensity, etc) 2. Usable comonads and comonad transformers. 3. Providing a full suite of extensions for Control.Category to cover the middle ground between a Category and Arrow. 4. Providing a more category theoretic notion of functors and monads, where the categories can be something other than the category of Haskell types, although still not in full generality. 5. Providing a comprehensive overview of the different constructive algorithmic control structures (Control.Morphism.*). Some of those need to be modified (in particular my definitions for Erwig style metamorphisms is wrong, because the definition for a Bialgebra in category-extras is too simplistic) 6. Providing a place to get a usable notion of the various notions of parameterized/indexed monads that have been bandied about. 7. Provides a canonical set of bifunctor and functor combinators that can be used to build up arbitrarily shaped bifunctors. Unfortunately, these muddle the exposition of the rest, and are made up to match Haskeller intuition, and don't reflect any deeper naming convention from higher mathematics. 8. A few of the abstractions are overly simplified because I wanted to avoid defining a concept, a lax version and the opposite lax version, and so sometimes the terminology suffers. 9. Almost every non-traditional category theoretic idea I've bothered to blog about over the last few years, somehow wound up encoded in the library. ;) A lot of people avoid using category-extras because it has an enormous (and aging) dependency list, so refactoring it into more streamline packages might improve adoption. It is just a fairly daunting task, because of the complicated web of interdependencies. Most of the individual pieces should be quite accessible in isolation, however.
You may also appreciate his Ph.D dissertation, which I linked to here, and which is referenced in the text you provided. http://comonad.com/reader/2008/just-fokkinga-abide/ The Bird/Meertens "SQUIGGOL" school of thought used in those may be a bit hard for folks to read these days though, and is more about a particular sub-problem in programming (recursion and so-called "constructive algorithmics") than about category theory in general. A lot of people find that notation off-putting, and go to read that, the Bananas, Lenses and Barbed Wire paper, or Erik Meijer's Calculating Compilers dissertation and write off all this strange category-theory nonsense as being too terse and pointless er... pointfree. ;)
You could call it an Exhibit though.
And you get to make pretty pictures, pretty pictures are _always_ worth making.
I completely agree. But unfortunately, there is a *lot* of code out there that uses those functions. So there would have to be a careful deprecation process. Probably very few uses of getStdGen rely on it returning the same value more than once, but I think it would be hard to find that out. We certainly should be using /dev/urandom (and the corresponding Windows thing) instead of the system time for newStdGen and the initialization of getStdGen. That change could be made right now. 
That's exactly what I had in mind. 
Also, you can leave off 'where {}'. 
I don't think the first program is affected, but it would be if you changed the definition of shuffles to shuffles rng cs = shuffle g cs : shuffles g' cs where (g',g) = split rng More precisely, if you called shuffles with a StdGen created by mkStdGen, and you told me the top cards of the first k decks, I could (in theory) predict the top card of the next deck with much more than 1/52 probability. (Same for the second cards, etc.) The first program, as you wrote it, doesn't have this problem because you are effectively iterating snd . split, not fst . split, in the shuffles recursion--this matters due to the specifics of the mkStdGen/split interaction. Neither program is really OK in that there is no theoretical basis for their randomness--they might be predictable in ways we haven't thought of yet. It's better (from the point of view of theoretical justification) to avoid splitting in any way; in this case, that's not too hard to do by returning the final rng state from shuffle: shuffle rng [] = ([], rng) shuffle rng cs = first (head b :) $ shuffle g' (a ++ tail b) where -- etc. and threading the rng state through shuffles. Unfortunately, I believe this can lead to space leaks if, for instance, you only use the first 5 elements of each shuffle result.
If instance selection did not ignore context, but instead backtracked until an instance whose context instance constraints were met was found, then simply adding a new instance declaration could change the meaning of an existing, compiling program. IMHO that would be highly undesirable.
Accept no fakes! :) Newly christened, but with the same flavor you've grown to love... or something. Hope you like it!
Slightly off-topic: does CHP currently have any support for running across multiple machines? Can you, or do you still have to, use PVM for that (not that I want to use PVM)?
&gt; Why on earth does the proof use the Banach fixed point theorem? For people like me who dislike hard analysis (lots of estimates and inequalities) it's nice to isolate the nasty analytical plumbing in few high-powered black boxes like the contraction mapping theorem. All analytical questions of existence should be settled with topological fixed points theorems! I have a very good direct intuition for why contraction mappings on complete metric spaces must have a fixed point with quadratic convergence, but when I see a page of meaningless estimates, I stop paying attention. Did you know you can prove a weaker version of the inverse function theorem using Newton-Raphson iteration? It comes down to the process converging in some neighborhood of every point with nonzero derivative, assuming a certain second-order condition. Like iterated contraction mappings, Newton-Raphson iteration also has quadratic convergence. This is not an accident! Once you have a gut understanding of how the Newton-Raphson-based proof works, it should be obvious how you can use the contraction mapping theorem to strengthen the theorem. This is probably my favorite way of introducing someone to the proof of the inverse function theorem, since Newton-Raphson iteration has a very intuitive geometric-kinematic interpretation, and the proof of the stronger theorem based on iterated contraction is a very straightforward conceptual generalization. You still have to do a bit of analysis but it is more directly motivated and geometric in its origins.
&gt;The first program, as you wrote it, doesn't have this problem because you are effectively iterating snd . split, not fst . split, in the shuffles recursion--this matters due to the specifics of the mkStdGen/split interaction. Ah, yes. Thanks: that's greatly clarified the situation for me. &gt;Neither program is really OK in that there is no theoretical basis for their randomness Yeah, I read the disclaimers, but was prepared to live with the uncertainty. I'm not betting my life savings on the output, and had trusted informal scrutiny by others to ensure it was random enough. This article, therefore, came as a bit of a surprise. &gt;threading the rng state through shuffles Yes, not too hard, but so much less *clean*. Still, I may give it a go if I get time. (Re space leaks, I was using typically 15 cards of each of 100,000s of shuffles.)
Can't overlapping instances already cause that?
http://blog.desudesudesu.org/wp-content/uploads/2009/02/27dcd29da9440ccf385d601ad5ea6ae0c9033f4a.jpg &lt;-- This is the original. Thanks to the nice folks at #japanese (I'd like to say cale, but he was outmatched), I got a translation for the text. However, the resulting picture may not have the best possible description of haskell. ..so you can visit http://brage.info/~svein/haskell.xcf to get a version that lets you replace the text, without re-drawing the underlying symbols *again*.
&gt; instance (Num (MyApplicative MyNum), AppNum MyApplicative MyNum) I don't understand what this syntax means.
Sticking to your continuation-based example: Because then you can easily see that translating into continuation passing style is just the use of a particular kind of right Kan extension (and if you study topology, that it is a codensity monad) and reason by analogy to find that the other right Kan extensions give you other interesting control structures and optimizations (map fusion, etc.). What I like about category theory is that people working on category theory have had more than 50 years to come up with every non-obvious consequence that they can think of, and since the framework is so general, they can think of a lot of stuff. And nicely, since the lambda calculus is effectively the language of a closed Cartesian category, it is all disturbingly applicable to programming in general. 
tutorial.happstack.com it's not as good as I want it to be, but if you can slog your way through you have a functioning web 2.0 app for "beating the averages with" with your next startup. http://www.paulgraham.com/avg.html Ok, take that with a grain of salt... but take it :)
The functions toKeyValuePairs and toValues have an unnecessary and, in my opinion, confusing special case for the empty list. I think it's wrong to teach people to start mechanically with a special case for the empty list whenever they write a function that operates on lists. First, write the regular case that does the real work and gives meaning to the function. Then, think about whether there are some special cases that we haven't covered or that need special treatment for some reason. In fact, both of these particular functions can be written even more clearly and naturally in points-free form. And you are more likely to notice that if you use the "regular case first" way of thinking. But you probably can't use even the simplest points-free yet at this point in the exposition.
In my browser (Safari), your indentation does not line up correctly in every code example that has a "where" clause.
As I recall, this isn't really what it claims to be (i.e. genuine backwards-mode ad with the efficiency that provides). 
No -- network support is on my to-do list, but unfortunately it's not yet implemented. But that would be running several instances of a CHP program on different machines, communicating with serialised data via sockets (so no sending functions over the network, but that's not too surprising). What is PVM?
Thanks for the reply. PVM is [Parallel Virtual Machine](http://www.csm.ornl.gov/pvm/). Some previous implementations of parallelism in Haskell have relied on it to achieve distribution across machines, including "Glasgow Parallel Haskell". I thought that CHP did too, but apparently not. &gt; But that would be running several instances of a CHP program on different machines, communicating with serialised data via sockets Yes, that's pretty much exactly what I'm looking for. 
Ah, thanks. Haven't tested in Safari; will give it a shot when I get home.
I like your point about the special cases coming later. Here, I was following RWH's code order, and really I think both ways have merit. Though all programmers are familiar with the concept of functions choking on bad input, Haskell's particular brand of "non-exhaustive patterns" can be something that takes getting used to, and as such it's not a horrible thing if a new Haskeller gets in the mindset of always covering his bases with regard to the empty list. Thank you for your input! I also agree with the point-free style remark, and I love reading and writing code in that style myself. But as you correctly gathered, I think it's a bit too early to jump into that just yet.
Yes, they can--one reason I avoid them. (The other reason is that I don't understand exactly what they do, which admittedly is a bit circular.) I don't know if I would say that there is consensus that overlapping instances are bad, but it seems to be a pretty common opinion.
I agree fully as well, but I just want to note that this issue is not specific to newStdGen and the global RNG model. It would also affect a program using a State StdGen monad if it updated the state using the first component of split, for instance, so that it could pass the second component to randoms. (The MonadRandom library happens to use the second component to update the state, presumably because State is defined as s -&gt; (a, s) and not s -&gt; (s, a).)
Thanks guys. I'm doing two Haskell talks this week, to two different non-Haskell audiences. * LACSS, [Non-Traditional Programming Models](http://www.galois.com/blog/2009/10/13/domain-specific-languages-for-domain-specific-problems/), tomorrow in Santa Fe. Then a 60 minute talk on multicore and parallelism at UIUC for the Reflections|Projections series. I'll have the slides and notes up afterwards.
It is the syntax proposed [here](http://www.haskell.org/haskellwiki/Superclass_defaults), and is the method for declaring instances when some classes provide method defaults for other classes. It means something like, "simultaneously declare the instances 'Num (MyApplicative MyNum)' and 'AppNum MyApplicative MyNum' such that the AppNum may provide default method implementations for the Num".
No, it's not really backwards AD.
There'll be video right?
A good project for you here: http://www.reddit.com/r/EnHaskell/comments/9tej1/tool_to_help_traverse_uses_of_deprecated_api/c0ee6n5 I can help clear the requirements and act as a customer if you want :)
Have Galois talks been recorded in the past? If so, where may we find them?
We've just started experimenting with video. We'll let you know if it is to be recorded.
I seem to remember Don or somebody saying they had just gotten the equipment and were going to record them going forward.
that looks really cool. I'm totally going to go use that, thanks.
&gt; Because then you can easily see that translating into continuation passing style is just the use of a particular kind of right Kan extension (and if you study topology, that it is a codensity monad) and reason by analogy to find that the other right Kan extensions give you other interesting control structures and optimizations (map fusion, etc.). Wouldn't CPS'ing Scheme not fit into the codensity monad, because of the use of call/cc?
John McCarthy, who created Lisp, was at that time considered a mathematician, and Lisp was an attempt to explore Chuch's work using new tools. He is mostly thought of as a Computer Scientist now because of Lisp, so you're sort of putting the cart before the horse when you say "without hackers there'd be no Lisp." Lisp turned out to be tremendously elegant and evolved into a language people used to solve practical problems, much in the same way that Haskell is currently evolving -- but it was designed to satisfy the whims of a pie-in-the-sky academic, not to scratch the proverbial itch of a get-his-hands-dirty-to-solve-a-problem hacker. I don't disagree that it's useful for an application-minded person to develop a good grounding in the theoretical basis of his tools, but I think the way you poo-poo the notation and manner in which the theorists present these topics because they don't cater to your non-theoretical bent is a little bit arrogant. It's your responsibility to learn the topics you're interested in. Category theory as practiced in mathematics diverges greatly from functional programming, and with good reason -- it's an attempt to provide a means to translate similar concepts across widely disparate branches the discipline (originally between algebra and topology) so that the machinery built in one place (group theory, say) could be used to solve problems in another (topology). It is by its nature a terribly general sort of math. Learning category theory with the intent only to learn about one category -- Hask, in this case, the category of Haskell types -- is of course going to be confusing, and it's of debatable use if practicality is your emphasis and aim. If you aren't intending to do math for its own sake, and all you want to do is functional programming, category theory is a useless abstraction. The reason you hear about it so much from Haskell-types is because unlike you, they enjoy seeing how you can talk about type theory in the same language you can use to talk about algebra, or topology, or even analysis and geometry. If you don't understand algebra or topology or analysis or geometry, and don't care to learn these things, what exactly is category theory even good for? Let it go, and go back to practical matters. You can continue to roll your eyes at people who care about proofs. Eventually, if the concepts are practical enough, someone will dumb them down for you whether you make a "call to arms" or not.
Please do something about the redundant code for the empty list. It's terrible style. 
You can cover call/cc by viewing CPS as a codensity monad of a constant functor. That is how you dodge the universal quantification. I have a package on hackage called monad-ran that does this.
Agreed! While we're at it, there should be an introductory example on how to use the library. It's a recurring issue for Haskell beginners on the mailing list.
Just curious, are there any Linux kernel modules being developed in Haskell right now?
You describe what I shouldn't do and justify it in terms of practicability. Yet, I find that other theoretical constructs not truly at home in what's now called Computer Science have invaluable practical applications (which, as a rule of thumb, don't use dynamic scope, any more. I think because lisp as we know it doesn't obey the whims of its creator, any more). What you fail to give is a metric by which I could judge whether or not I'm too hands-on to get my fingers dirty by learning a specific theoretical concept. I think CT is a wonderful tool for that. Consider what Edward noted: That CPS-transformation is a particular kind of right Kan extension. With the knowledge about a) why it's just particular one and b) CPS transformation I can go out and scan other fields for Kan extensions, not to prove anything equivalent, but to _get inspiration_ and _empty my design space of limiting assumptions_. All I argue is that it is possible to grok CT concepts without relying on traditional proofs, and, additionally, that that style of proof is, usually, far from being the didactically optimal way to convey a concept. I didn't yet get around to dig into Fokkinga's thesis, but his computational style could very well be way closer to what I'd like to see. In the meantime, I don't care for being accused of polemic. I wholeheartedly confess, and have found an elegant proof for its value in discussions. A reddit comment is to narrow to contain that proof, though. Traditional proofs consist solely of the cruft they accumulated for ages. I judge this in the same way as cruft in a program: It sticks out. You don't have to understand code in detail to see that it's in utter need of a rewrite.
I have a ricoh mmc driver - direct translation from the C version - written in Haskell. It hasn't been tested but I'm as confident as I've ever been, prior to testing, that the code will work. This is partly because it is far from an impressive driver - just some bit fiddling really.
Clever name.
I'm looking for folks who want to hack on an automotive physics sim...
Again, that part comes straight out of RWH. Though I agree with you, I can also see why it was done, and with the goal of these articles being what it is, I really think it's okay this early on. A good approach, however, would have been to use an example where the empty list really did need to be matched. In retrospect, perhaps I punted by using RWH's examples here. I'll keep that in mind for the future.
Dealing with "interesting" structures (maps, lists, etc.) always seemed to be where the first-class labels technique started to run into problems. I am curious how this turns out; I don't think I would have solved it in this way!
*shooot har*
From the title at least, sounds a lot like my [AVar](http://hackage.haskell.org/package/AVar) package on hackage.
When I don't need to update the innards of a map, I put \k -&gt; Map.lookup k . Map.fromList $ ... into the record. Your solution just rocks.
This is surprising news! I thought this was almost certain to be the Australian area of _New_ South Wales.
Nothing stops you from improving the code from RWH. You can do it as a closing remark. 
But you need to implement lemma, lemma2, and lemma3 or it doesn't work.
mhhh. It looks so easy. Maybe I should try to compile code before posting, next time.
It's still awesome. I think you can probably pretty easily make lemma and lemma2 members of the Tuple typeclasss. lemma3 is a little harder because of the Append constraint.
but I think you can implement this without the lemmas. Here's one way to do it: http://hpaste.org/fastcgi/hpaste.fcgi/view?id=10774#a10774 (I've simplified the original problem a bit by representing references as de Bruijn vars rather than de Bruijn levels)
&gt; Did you know you can prove a weaker version of the inverse function theorem using Newton-Raphson iteration? [...] assuming a certain second-order condition. Ah, nice to know! Tried to reproduce it from scratch today and it seems to work. With the assumption that the function has a continuous second derivative |F''(y)|&lt;=C, the Newton method makes the goal quadratically small |F(y)-0| &lt;= C|y_{n+1}-y_n|^2 which then guarantees that the step lengths |y_{n+1}-y_n| ~ |F(y_n)| will decrease rapidly. &gt; All analytical questions of existence should be settled with topological fixed points theorems! Yes! And that's why I think that both the Newton method and the Banach fixed point theorem are overkill. After all, the implicit function theorem just asserts that a function behaves like its derivative (and hence is invertible) when viewed through a magnifying glass. Somehow, the fixed point iterations happen on a scale that should be infinitesimal in the first place. 
I'm seeing "type family" and "type instance" all over the place. I've never seen this before in Haskell code, does anyone know some documentation about this?
http://haskell.org/haskellwiki/GHC/Type_families
Well, we knew that splittable PRNGs were an potential problem. I seem to recall that being mentioned right in the documentation. Kind of embarassing to see it so cleanly laid out though. Time to switch to [Control.Comonad.Supply](http://hackage.haskell.org/packages/archive/category-extras/0.53.5/doc/html/Control-Comonad-Supply.html). ;)
Can anybody put some references about what he is trying to accomplish and maybe some "weekend readings" for the Haskell Noobs? I'm guessing there's some context around this. 
You might also want to look at my library `HCard` (on hackage) for some _very_ simple applications of associated types, which are related to type families. Also, on SPJ's page on the haskellwiki, there is a paper about Type functions which he did with a couple others (I think Oleg and someone else who's name escapes me) which is quite readable.
This function got removed from the fclabels package with the newer version because I thought it might have been to confusing, but the fmapL function might be useful: fmapL :: (a :-&gt; b) -&gt; f a :-&gt; f b Like the fmap, but not for functions but for labels. Something like this is now possible: person :: String -&gt; Map String Person :-&gt; Maybe Person age :: Person :-&gt; Int personAge :: String -&gt; Map String Person :-&gt; Maybe Int personAge name = fmapL age . person name 
Does anyone know if it is possible in GHC to overload do-notation to also work with indexed monads?
"Brian's Purely Functional Brain" is certainly better than the precursor to the fictional Douglas Adams "Deep Thought": "Deep Thunk" who's only contribution to intellectual discourse was memory leaks.
What IDE is that running in [the background](http://willdonnelly.files.wordpress.com/2009/10/best-screen.png)?
vim?
Nice! I was messing around with these sorts of ca the other day in Scheme (Ikarus and Ypsilon). Here's Brian's Brain in 6 lines of Scheme: http://github.com/dharmatech/agave/blob/master/demos/ca-brians-brain.scm given this engine: http://github.com/dharmatech/agave/blob/master/demos/ca-gen.sls ;-) There's a bunch more here: (the ca-*.scm files): http://github.com/dharmatech/agave/tree/master/demos You do win on the line count though. :-) Ed
It's vim with the [wombat](http://dengmao.wordpress.com/2007/01/22/vim-color-scheme-wombat/) color scheme running under [xmonad](http://xmonad.org/).
By the way, the S/B/C are from the notation described here: http://www.mirekw.com/ca/rullex_gene.html So the ca-gen library implements the "Generations" family of ca described there. Ed
In newer versions, -XNoImplicitPrelude is all you need: GHC uses whatever &gt;&gt;=, &gt;&gt; etc is in scope. That won't interoperate well with vanilla monads, but then there's [ixdopp](http://hackage.haskell.org/package/ixdopp).
Awesome, thanks!
Thanks, I'll take a look at that. I think I found the article here: http://haskell.org/haskellwiki/Simonpj/Talk:FunWithTypeFuns The last person is Ken Shan :).
Yah, thats the paper. It's really very good...
Maybe dump your structures into JSON or YAML; there are libs for each of these on Hackage.
Maybe it is possible to make use of parser via compiling it to shared library and then bridging with python via C-coded python module?
actual link: http://channel9.msdn.com/shows/Going+Deep/C9-Lectures-Dr-Erik-Meijer-Functional-Programming-Fundamentals-Chapter-3-of-13/ What is wrong with some people. Why use bit.ly when there is no reason to do so. 
Nothing much interesting with this link : it links to hackage, the homepage is equally uninformative and the haddock documentation is inexistent. Hopefully a promising future library
http://www.vim.org/ Check it out, you will need to follow some sort of tutorial to get started though. http://blog.interlinked.org/tutorials/vim_tutorial.html
Sorry to further the off-topicness, but what are you using to get transparency in xmonad? I've tried xcompmgr in the past, but it made everything slow enough that I had to ditch it (on my newish ATI card).
I can't speak for Will, but I'm using cairo-cmpmgr with xmonad and only experiencing a mild amount of oddness (menus are sometimes improperly obscured). 
You replied to the wrong person :)
So one thing that is often useful is mutable references. If you can "encapsulate" your mutable reference in some way, you can even make it [callable from pure code](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.50.3299). The method described in that paper is effectively to encapsulate "unsafePerformIO" with a quantified type variable; this ensures that references never escape from the pure code. Here's a simple implementation of ST: -- do not export constructors/accessors for these types newtype ST s a = MkST { unST :: IO a } newtype STRef s a = MkSTRef { unSTRef :: IORef a } newSTRef :: a -&gt; ST s (STRef s a) newSTRef a = MkST (fmap MkSTRef (newIORef a)) readSTRef :: STRef s a -&gt; ST s a readSTRef r = MkST (readIORef (unSTRef r)) writeSTRef :: STRef s a -&gt; a -&gt; ST s () writeSTRef r a = MkST (writeIORef (unSTRef r) a) runST :: (forall s. ST s a) -&gt; a runST a = unsafePerformIO (unST a) Philosophically, the phantom type "s" represents the heap state used by the computation; since runST requires your computation to work for any starting heap state, the computation must not rely on any variables created outside of it. Similarily, runST (newSTRef ()) doesn't type check because the "s" escapes from the forall. This code is attempting to encode the "heap" state used *directly* into the type; IxST s1 s2 a represents a stateful computation which starts from heap state s1, ends in heap state s2, and returns a value of type a. The heap is just represented as a typed list; a heap with variables of types Int, Bool, and String looks like: (Int, (Bool, (String, ()))) The advantage of this approach is that you end up not needing to run to unsafePerformIO under the hood; you can run entirely in pure code which means you don't need to rely on the "runST" trick. In fact, runIxST has the type (IxST () s a -&gt; a), with no higher-rank types in sight. It says that the computation has to start with an empty heap, and can end in any state whatsoever. It can even return a reference from that heap (which isn't unsafe, because the reference can only be used to access its own heap type!)
&gt;menus are sometimes improperly obscured In Java apps?
Not generally. It only happens when a menu tries to overlap another program's window. For example the menus from gnome-panel sometimes are obscured behind my other windows. 
I'm using xcompmgr too. I'm running it on a laptop with some puny Intel integrated graphics chipset. I have yet to ever see a problem from it.
I'd second this. JSON comes built into Python as well (as of 2.6/I assume 3.0), so it can natively read the objects. I use JSON for pretty much all my object serialization these days :).
Hmm, alright. I have no doubt it was shaky ATI drivers. 
Most awesome lectures ever! Thanks for sharing! I just submitted this to [/r/lectures](http://www.reddit.com/r/lectures) - lectures subreddit!!!
Thanks! I would love to upvote you twice :-)
I'd third this, and suggest looking at the Python JSON library's `object_hook` functionality. Whatever it is you are doing, you almost certainly will want actual Python objects (not just dicts), and with that you can write something very simple that will go from JSON -&gt; Python objects without much fuss. I use something very like that in another context to use a distinguished attribute on a JSON object to indicate the class. If you do not have the distinguished attribute, you're just a normal Perl hash. (Alas, I'm in perl.)
I would like to echo that I'm running a similar setup and not experiencing problems.
I had no idea about object_hook, but that's fantastic, thankyou!
I actually thought you were asking what vim was.
I wrote something like this a ways back, experimenting with type-safe ways to implement ST. However, this way of structuring things is strictly less flexible, because your use of references needs to be statically determined. So, for instance, you can't write a loop that creates a number of references based on a runtime value without somehow reflecting that value into the type system. That isn't impossible, but it gets increasingly inconvenient the more complex the value is. I'd probably be hard pressed to come up with code that needs to come up with new mutable references like that, except that arrays are an example (of course, array sizes aren't actually hard to reflect into the type system), although I don't imagine you'd want to use a mutable-style array that's backed by an immutable, inductive tuple 'heap' anyway.
Finally :). Some people are really ambitious these days.
"rock! " * 10000
The real thing: http://www.bcl.hamilton.ie/~barak/papers/toplas-reverse.pdf Alas, it doesn't seem to be readily implementable directly in Haskell -- I spent a couple of weeks trying last year.
Katamari damacy people, I've said it before, I'll say it again. Haskell is the Katamari Damacy of programming languages.
Oh. No, I was just answering his question.
I don't know; Poplog has been around for quite some time, and it includes ML, Prolog, Pop-11 and Common Lisp. PLT has quite a few languages for DrScheme now as well. That's not to say that Haskell *isn't* the Katamari Damacy of programming languages, just that it's one of many... Still, I can recall Atom, Timber, Curry, Disciple &amp; Cayene off the top of my head... *Edit*: Department of Redundancy Department has openings...
So... we just need to Katamari Damafy Poplog and the gang. :) Mostly it's just a reference to how often someone write ASTs/Interpreters/etc in or as EDSLs in Haskell. Viz, this, Hubris, the Erlang AST, augustss' C and BASIC EDSLs, etc.
Sure, Functional &amp; (most)Stack based languages make it dead simple to quickly wire up a DSL or even a full language. Maybe there should be a KD school of Polyglot programming :D
Sooo.. is this only a parser for now? What is the status? Should I abandon my own plans for the same? :)
I like it. [Hope programmer's blog](http://programming-tidbits.blogspot.com/) * August: Implement Quicksort in Haskell * October: Implement Python in Haskell Edit: Just for comparison, I started learning Haskell in August and I'm almost ready to try Quicksort. :)
Should start with Language.Python http://hackage.haskell.org/package/language-python
Soon you'll be ready for Python yourself!
Is there a series of tutorials on getting useful results from CT in really mundane contexts? Applying Category Theory for Dummies?
I played with this at the time too, but took a different approach: import qualified Data.Vector as V compose = foldl' (flip (.)) id zipBoardsWith = V.zipWith . V.zipWith neighbors b = let rotate v = V.tail v `V.snoc` V.head v rotate' v = V.last v `V.cons` V.init v lb = V.map rotate b rb = V.map rotate' b in compose (map (zipBoardsWith (:)) ( map rotate [lb, b, rb] ++ [lb, rb] ++ map rotate' [lb, b, rb])) ((V.map . V.map) (const []) b) step b = zipBoardsWith rule b (neighbors b) I have no idea how performance compares and I didn't finish it up with a GUI... I just like the idea of doing this without any explicit indexing.
I assume a video will be available eventually to go with the slides?
Thank you! I sometimes think it would be beneficial to print out the whole Hackage index and read it - just to know what's there.
The pain of reading Comic Sans text is almost unbearable.
concat . replicate 10000 $ "rock! "
http://maude.cs.uiuc.edu/primer/maude-primer.pdf "Maude is simple. Its semantics is based on the fundamentals of category theory, which is pretty intuitive and straightforward until a mathematician tries to describe it formally with symbols and Greek letters." +1 true
I think you mean "An implementation of a fragment of a python parser, for Haskell". This is I guess less than 1% of the work of a python implementation, and none of the hard bits.
I, for one, would categorize them as "awesome."
Have you seen [this](http://obvioushints.blogspot.com/2009/09/running-haskell-ghc-on-snow-leopard.html) What is the contents of your /usr/bin/ghc file? Mine is as follows... #!/bin/sh exec /Library/Frameworks/GHC.framework/Versions/610/usr/lib/ghc-6.10.4/ghc -B/Library/Frameworks/GHC.framework/Versions/610/usr/lib/ghc-6.10.4/. -optc-m32 -opta-m32 -optl-m32 -dynload wrapped ${1+"$@"}
Thank you, kindly. My /usr/bin/ghc file looked similar to that, but I had it in a different order with the compile flags for 32bit.
Looking more and more like I won't make it. :/ Oh well, next time!
Damn, there's a Scott Aaronson talk the same day that I want to go to. Decisions Decisions!
wrong
Speaking of Leksah, anyone know why there hasn't been a release since July 21st?
SPJ has a patch that reimplements inlining for class methods completely. It does use rewrite rules instead of inlining in a manner that essentially boils down to what you describe with the advantage that it's all perfectly safe. (It also uses a new generic form of rules —that's only available internally— to do the job with much fewer rules than you would need when using conventional rules.) The patch isn't in the HEAD yet (mainly to avoid destabilising before the 6.12 branch), but should land fairly soon. We already use it for a while for DPH, where we use an enormous amount of overloading and want very highly optimised code.
Everyone's a co-median.
generally I suggest stackoverflow as imho a better place than reddit for tech support. reddit is better for emotional support. 
I would have, but I can't stand stackoverflow for a variety of reasons. Also, I have no emotions, so /r/haskell (being away from the filth that constitutes the majority of the site) defaults to my tech support since I don't have to wade through Glenn Beck shit.
I smiled upon seeing the "type error". To nitpick though, I wouldn't say &gt; equality only makes sense on a bounded set of types It doesn't make sense on *all* types, but there is an unbounded number of types it *does* make sense for, in particular all tuple types over Eq types.
In which a .Net user walks into 30 years ago.
The Anti-if campaign makes me snicker. Congrats, guys, you have pattern matching on one implicit non-assignable field.
I've found the second part very interesting to read, the Haskell equivalents of classic ".toString()" is something that interested me for quite a while; unfortunately, can't find the time to actually follow through the entire tutorial at the moment, but I'll definitely put this knowledge to work once I get a little less busy! Thanks a lot for another nice tutorial on Haskell! :)
I think the simplest problem is trying to derive the type of their nonlocal AD operator. (J-with-arrow, or whatever it is called) 
No. This is the first time I've ever seen it down for a long enough length of time for me to notice.
While the server is online, the file system holding the hackage website is out to lunch. We expect it'll be sorted out some time after Monday morning US west coast time when the admin gets in.
Nobody dislikes Linux either. Right? Right? If you are in school or in a language design research program, you probably are interested in the features of Haskell. If Haskell becomes more popular, then I am sure people will take issue with some of the language features. I have seen some people take issue with Haskell's lazy evaluation.
Log into the Ruby on Rails irc channel and start trolling about how Haskell is the shit.
I actually dislike linux... I've taken issue with Haskell's lazy evaluation at times too, and I've also had some problems debugging IO intensive code in the past with Haskell as it appears some things are running ahead of sequence points that should be impossible to get ahead of :-) However, that said, I typically find more positives than negatives wrt Haskell when it comes to being able to build up an expressive set of functions (or EDSL) for solving problems.
It's not that I don't like Haskell, but for some reason I've a really hard time grasping the concept of functional programming. So far I've only used it to solve a few problems on Project Euler, but besides that I never found a practical use for it. That doesn't mean the language sucks, it's just probably not my cup of tea.
Time to start looking at mirrored solutions?
&gt; Is Haskell just flawless? No. My only issue so far is that I think monad transformers are overly complicated to use. I am sure it will get better with practice, but at the moment I find creating my own monads out of simpler ones a pain. Also, when learning the basics, it is easier to understand a language with *more* restrictive syntax rules than *less*. You can rewrite the same code in many ways, which increases the learning curve a bit. I'm not about to complain about this, but I can see how it could be frustrating to others.
as stroustrup noted, there are two kinds of programming languages, the kind that everyone complains about and the kind that no one uses :) (more seriously, no one is forced to use haskell; if they don't like it they just don't use it)
I think a lot of people get the feeling that "if I don't like this thing in Haskell, then it's because I'm stupid or haven't given it enough thought". I haven't written much Haskell, but I have some issues with: monads spreading to engulf my program (STRefs, ST monad, STUArray), (IORefs, IO monad, IOUArray), Hard to predict space/time characteristics (some naive/pure functional code performing well, others not, not easy to tell the difference) Hard to predict Monad Transformer Stack characteristics. (and hard to wrap your head around) Nearly impossible to work with ST Arrays of different types Hard to adapt to the fact that you have to send everything into a function where an imperative/object oriented language would let you grab the contents of a global variable. (you may send the stuff in by putting it in a suitable monad - see previous points) Hard to get a full environment up and running (I want recent ghc, gtk2hs on a MacOSX 10.6, other packages like databases etc shouldn't take half a day to get working) All of this can easily be attributed to me being too dim for this ;-) 
considering how dependent the community is on hackage, a backup server, even if just a static mirror thats updated once a week would be pretty valuable. easy for me to say considering i have no intention of doing it.. not ragging on the haskell.org or hackage team at all, tons of respect for them, just my two cents.
I bitch about it a lot, but don't have a blog. I don't think the issues with it are fundamental, but they're frustrating nonetheless. Check back on the recent thread in proggit about things you hate about your favorite programming language for lots of haskell complaints :)
I love me some Haskell, but it definitely isn't flawless. The record system sucks, GC still has problems with mutable arrays (meaning no efficient hash table implementation), you have to be careful about thunks building up causing space leaks, library &amp; tools situation still pretty immature, etc..
I have an always-on box on a university network (i.e., effectively unrestricted transfer) that I could use to mirror it.
The difficulty here is that people aren't ever forced to use Haskell, which means that the people who take the time to become proficient programmers in it are people who like it. The people who download GHC, go through half a tutorial and decide they hate it (and there are many of these) aren't worth listening to because they haven't gotten good enough at the language to really have an informed opinion about it. More mainstream languages, like Java, C++, or even Python, are in a bit of a different boat. Many programmers have been forced to learn these for work, and know the ins and outs and edge cases very well -- and not surprisingly, since learning these languages wasn't their choice, some of them like them and some don't. It's easy to find very well thought out critiques of C++, for example (and well-thought out rebuttals of those critiques, and well-thought out rebuttals of those rebuttals, etc). That's because, for many people, becoming really good at C++ wasn't a choice. They write code in C++ (or Java, or whatever) all day long for work. Haskell hasn't reached this level of maturity yet. Most people who don't like Haskell don't actually know how to use it, which makes their opinion suspect, to say the least. At some point in the future, Haskell or a language like it will probably be quite mainstream -- and when that happens, I'm sure there will be lots of people who really know what they're talking about that have gripes with it. Right now those people aren't so common. For what it's worth, though, Oleg, who is possibly one of the most knowledgeable CS folks around, did post a detailed comment on Lambda the Ultimate [on some of the drawbacks of monadic frameworks and monad transformers in particular](http://lambda-the-ultimate.org/node/2749#comment-41078). That's not Haskell-specific, but Haskell is the most mainstream language that depends on monads to encapsulate side-effects (along with other things). Having said that, Oleg loves Haskell. So he's not a hater -- he just understands the theory and practice well enough to identify some weak points. I'm sure there are many others like him in academia, which is why Haskell remains a work in progress.
We're aware of the problem and working on it. 
&gt; Yes! And that's why I think that both the Newton method and the Banach fixed point theorem are overkill. After all, the implicit function theorem just asserts that a function behaves like its derivative (and hence is invertible) when viewed through a magnifying glass. Somehow, the fixed point iterations happen on a scale that should be infinitesimal in the first place. Well, one of the lessons of the theorem is that a purely differentiable function _doesn't_ generally behave locally in the same qualitative way as its derivative. You usually need to add some other regularity conditions. In the case of the implicit function theorem, it's that the derivative does not merely exist but is continuous. You're passing from the infinitesimal to the locally finite, so you usually need to keep the function under more control to make that jump. A more elementary example is the mean value theorem. It does not require a continuous derivative by itself but most of its interesting applications do require it; in the fundamental theorem of calculus you need continuity so you can prevent the derivative from varying too much from the mean by choosing a small enough interval. A less elementary example is in the theory of differential equations. Do you remember how you prove the existence of smooth local flows for ODEs? The contraction mapping theorem again. In fact, there's a sense in which the the local inverse constructed by the inverse function theorem is a kind of integration, so the connection is not too surprising. Would you say the contraction mapping theorem also seems overkill for the theorem on smooth local flows?
gasdmf,nasdfjhl-records... they make me want to die...
Functional Programming is a brain-breaker, thats for sure. I encourage you to keep trying, when you get to the point where it "clicks" you'll understand why we (the haskell lunatics) are all stark raving for the notion. Particularly, I don't know if you're familiar with fuzzy logic for game AIs, but there was a post recently about an implementation in Haskell that was derived (well, built as response too is more like it) a C++ implementation from a book on Game AI. The results were _stunning_ -- the code read easily, I didn't even need to know the API to understand what was happening, it was simply beautiful. Link is [here](http://article.gmane.org/gmane.comp.lang.haskell.cafe/64860) If you've seen fuzzy-logic AI frameworks elsewhere, you'll understand what I mean. It's simply fantastic. 
I always found Ruby people to be quite nice (not just because I tell them I think their language is better than Python, either) -- is that not the case with RoR people?
This clever trick makes me cry, but I might try it (at least until SPJ's patch that chak has already mentioned finds its way into my GHC).
I don't think it is flawless, but it does very well what it set out to do i.e. being a pure lazy statically-typed functional language. People that hate Haskell probably hate the pure FP paradigm and the strong (but complex) type system, more than they hate things like the syntax of the language itself. From a theoretical point of view, it is one of the best languages. You can do some very powerful and abstract computations, in very few lines of code. From a practical point of view, I can see that people that want to get into it quickly for their pet project often run into problems. It's not a language that you can learn very quickly like python or ruby. It is a deep language and it is very unforgiving to a certain type of programming called ["programming by coincidence"](http://www.pragprog.com/the-pragmatic-programmer/extracts/coincidence). There are no coincidences in Haskell, and the type system is there to remind you every step of the way. So like C++, you have to know what you are doing, unlike C++, the compiler is there to remind you when you don't know what you are doing. And often, if you don't know what you are doing, the compiler errors won't mean much to you. So there is definitely a barrier to entry. 
Oh there's much, much wrong in e.g. the standard typeclass hierarchy (that is, something that can be fixed on library level... but still breaking legacy code). There's much cool stuff that would make Haskell that much cooler but isn't really there, yet (e.g. closed type funs, data kinds, totality checking). We lack a single FRP library that's both mindboggingly elegant, like reactive _and_ blazingly fast, like elerea. Idiomatic Haskell GUI toolkits are bitrotted and/or were never intended for production usage, and the rest of the lot makes your code look like glorified C. But, in the end, these are gripes other languages can only dream of.
I love haskell but people hacking it have gone infix insane which makes the code hard to read and is very offputing to newcomers.
Any estimates?
Wow. I *haven't* seen't fuzzy-logic AI frameworks before… at least not since I looked at Quake. I'm still learning about higher order functions and only barely beginning to get the basics of monads, and I can understand a lot of that code. It's really elegant. It's short, and even that short code could be abstracted away, but I wouldn't want to do that. It's really nice.
Personally, I wish Haskell had more of the dependently typed features such as the ability to treat types more like first class values. But I don't know if that's a constructive criticism, since Haskell's typesystem really doesn't work well with deptypes.
Would your university be happy with the level (or the spikes) in bandwidth, though? (I once submitted an amateur film-making group's film to Slashdot - it was hosted on a university server in Germany - and the Slashdot effect caused it to be taken down.)
&gt; Nobody dislikes Linux either. I hope you're being sarcastic, because I know several people that don't like Linux, and I work in a computer science department.
Exactly. I wasn't being sarcastic, but honestly asking whether the community has grown now to the size where we need to start looking at distributed, high availability solutions and soliciting volunteers to host and update cabal to redirect.
Next few hours.
&gt; "if I don't like this thing in Haskell, then it's because I'm stupid or haven't given it enough thought" It's this kind of thinking which has held back open source software in general, especially GNU/Linux. Please, people, don't be shy to ask for help or report a bug if something is unusable for you.
In my experience, there's typically not that many infix operators or "infixified" functions used in the body of any given function (partly because function bodies are often quite short).
Overall, I quite like Haskell but things that I've found a little annoying: * Real World Haskell is the exception, most haskell tutorials etc. are impenetrable by those without the appropriate mathematical background * Most haddock documentation isn't (look mum, pointfree : ) * Why can't recursing through directories just be easy? Ok, perhaps I should just install MissingH * You can't just decide to add a logging statement... no... definitely not... That said, it is a wonder of a language. Full of beautiful surprises. And populated by some of the most helpful people in the programming world so it's deficiencies look pretty pale in comparison.
"Right? Right?" Yea, you missed that part. On, reddit you get a lot of people that love Haskell, love Linux and other various technologies. But, when you ask anyone that actually is a CIO, CTO or technical lead at a company that makes money. Most people can't tell you anything about it, let alone give an opinion. 
That's because CIOs and CTOs get their information from trade magazines, ads and promos, not by talking to coders. ;)
Depends on the company but yea.
They seem pretty liberal about letting people use large amounts of it, but I would probably ask a sysadmin just to make sure, if people did want it.
Screw that, I hate the syntax. Every library seems to define their own &lt;||_||&gt; crap that is totally impenetrable. I don't want to count to see if it's ||| or |||| in the code. (exaggerating, but it's seriously a pain).
There are many minor issues that Haskell users complain about (many highlighted in a recent thread, e.g. accessors, if-then-else syntax, module system, etc.), and others here have made good points here. I'd also add that, in a way, the difficulty many have penetrating the more academic side of Haskell is actually like an extreme version of how people complain about, say, templates "cluttering up" C++. Some C++ features can be tricky to use, or even understand, so people complain about them. The same thing would exist in Haskell, but many examples of their usage are accompanied by papers or academic references with extremely high barriers to entry. These feature descriptions can be so intimidating that most don't even bother to complain that the existence of such a technique makes the language ugly. People complain about features and techniques in C++ when they feel like they would just do it another, easier, way. People read the abstract of a Haskell paper and aren't even sure what they'd be complaining about. Real World Haskell is likely a real watershed event in Haskell usage, and has likely kicked off a long future of griping by practitioners. :)
Ouch, that's evil. One problem with this approach though is that it requires the -O flag to make sure that ghc uses the rules. Compiling without any extra flags will result in crashes.
the common answer I got when I made this gripe was try fc-labels. honestly, they look quite promising, though I haven't really started using htem in a serious way I probably will soon,.
&gt; [...], the derivative does not merely exist but is continuous. You're passing from the infinitesimal to the locally finite, so you usually need to keep the function under more control to make that jump. Yes, of course, and the proof has to use that. However, that doesn't mean make that the proof with Banach is the only one who can do that, there could be another, "better" proof. :-) &gt; Would you say the contraction mapping theorem also seems overkill for the theorem on smooth local flows? Yes. While the Picard-Lindelöf theorem establishes both existence and uniqueness of a solution to an ODE, I prefer the proof of Peano's theorem for its use of Arzelà-Ascoli's compactness argument, even though it only proves existence. It's not really intuitive either, but it seems much more "direct" to me. &gt; There's a sense in which the the local inverse constructed by the inverse function theorem is a kind of integration Just out of curiosity, is there a precise formulation?
I think the solution to monad transformers being overly complicated is just not to use them. ;) They're really only suitable for writing certain types of library. Of course, the line between "library" and "application" is often blurry, but if you can't clearly separate out what you're doing with the monad transformer and hide the fact that you're using it behind a newtype, chances are it doesn't fit well in your program. The only exceptions to this that I've found are tiny one-liners where you realise that the function you're writing is the unwrapped version of one of the standard monad operations (like sequence or mapM or something) in a particularly transformed monad. For instance, nest :: [(r -&gt; b) -&gt; b] -&gt; ([r] -&gt; b) -&gt; b nest = runCont . sequence . map Cont This happened to be just the thing for getting hold of a bunch of resources from some with* style functions all at once (that is, the usual CPS trick for resource management). Edit: Oops, that was a poor example, since it doesn't actually involve a monad transformer, only the type of lifting that I meant. ;) Well, off the top of my head, I can only think of the following fun way of doing permutations: select :: [a] -&gt; [(a,[a])] select [] = [] select (x:xs) = (x,xs) : [(y,x:ys) | (y,ys) &lt;- select xs] select' :: StateT [a] [] a select' = StateT select permutations xs = evalStateT (mapM (const select') xs) xs Of course, a bunch of related functions are made easy to write from that perspective. pick k = evalStateT (replicateM k select') Note that what these have in common is that I'm applying the constructor for the monad/transformer explicitly to something, and then using a bit of standard Control.Monad machinery before immediately running the monad/transformer to unwrap again.
You can't just decide to add logging to a pure function, but for debugging [Debug.Trace](http://www.haskell.org/ghc/docs/latest/html/libraries/base/Debug-Trace.html) works pretty well.
But that's not syntax. Or maybe it is insofar as Haskell allowing library writer to define arbitrary operators. But the issue here is more that the community considers new operators ok (if not a good thing) than Haskell's syntax. It's not like haskell *forces* anyone to create unreadable ascii-mangle.
I don't like Haskell because: * You can't use GHC to link your code against libraries compiled with another version of GHC. That means that I need to either use the same version of GHC for both production work and exploratory work, or maintain two separate development environments. * The solution to most real world problems involves Monad transformers but they are implemented so inconsistently that you cannot be sure which implementation of a transformer function is being called. * The FFI is so simple that library implementers phone it in, rarely considering the failure paths demanded by common usage. e.g. In gtk2hs, treeModelGetValue requires a TreeModel, but most calls will be preceeded by treeViewGetModel, which can fail, but the failure isn't propagated via the Maybe monad. treeViewGetModel :: TreeViewClass self =&gt; self -&gt; IO (Maybe TreeModel) treeModelGetValue :: TreeModelClass self =&gt; self -&gt; TreeIter -&gt; Int -&gt; IO GenericValue * The community only cares about cutting edge. Once a new version of GHC is released, library maintainers don't care about users of previous GHC releases. The same is true about version dependencies between libraries. This is likely related to the first point. The Haskell Platform has good goals, but its development is far too slow, with serious bugs persisting between releases. Furthermore, the advice from #haskell usually requires deviating from the platform. * The community is in love with the idea of combinators. Combinators are great for building libraries without losing customizability. However most Haskell libraries are just the combinators, which cannot be easily used to solve more than example problems because [humans just can't keep such a large number of combinators in their head](http://en.wikipedia.org/wiki/Short-term_memory). * The arrows in type signatures don't mesh well with the composition operator; you can't write out the type signatures above the composition to make sure you have the types right. I'm not sure that writing the type signatures backward is an improvement. I just don't like reading long function compositions either way. Haskell did make me take functional programming more seriously. However I've found Clojure much more tolerable.
It is back up now, Mon 9pm GMT
At http://osdir.com/ml/haskell-cafe@haskell.org/2009-10/msg00197.html I griped that the lack of Data-Derivable time values was causing me headache in happstack. In the proposed cabal package http://patch-tag.com/r/tphyahoo/systemtimetypeable/snapshot/current/content/pretty/systemtimetypeable.cabal I submit a workaround that, while probably not the ideal thing, has proved helpful to me. Basically, I use the type MyTime, which is data-deriveable, when working with Macid in happstack; and convert from System.Time and/or Data.Time with the accompanying utility functions when necessary. Perhaps the utility functions are useful on their own as well. I found it surprisingly hard to get from Data.Time values to System.Time values. Anyways, I am interested in what others think and, of course, patches and suggestions welcome. thomas.
you can define oooooooooooo and oooooooooooo methods in java. that is so much better!
I hate bottoms (insert snappy comment here) and I'd prefer total core of haskell. I also don't like monads ([] and Cont are ok, but most of the time, monads are used to model exceptions and state and type systems with effects are much better with this)
Thanks. It's something that I wonder about, though, in terms of the stability of an overall design i.e. if you decide that you need something like logging 8 nested calls away from IO do you end up refactoring everything in between?
And actually, using `trace` and friends is arguably better than trying to thread IO into your programs, and not just because it's much more convenient -- it doesn't interfere with Haskell's lazy evaluation strategy, which can help give you a sense of when things actually get executed. If you're new to Haskell, you may find that things happen at decidedly unexpected times. `trace` can help you develop an intuition for how laziness works.
Well, as you get more familiar with Haskell you're probably less likely to paint yourself into a corner like that. I mainly write network servers, and I've ended up putting most stuff in a Error/State/IO monad stack, and that in most cases is sufficient for my needs.
Correct, it's not syntax, it's meta-syntax that actually maps to functions. But yeah, it's the community's approach to how they're defined. But it's extremely common.
To each his own; I don't find this to be a problem. I have to look up the documentation or definition for a symbol to know what it means anyway, and a short symbol is usually easy to remember. Of course, poor usage of symbols will be hard to read, but alphabetic names suffer from the same problem.
Broken hackage packages.
A few frustrations: * Not all Monads are Functors/Applicatives. So when writing one you need to create more instances, and when using one you can't use Applicative style etc. * All the MonadState, MonadReader type-classes etc, which make monad transformers more usable, require code length that is quadratic to the amount of Monad transformers. When you create a new Monad transformer it generally should implement an instance for each and every one of these type classes and create a new type class so next time there's one more to implement. * More deriving required. It would be nice for record syntax to derive setters and modifiers, and not just getters. I would really like to have "inMyType f = MyType . f . runMyType" generated for newtypes, as well as inMyType2 etc 
I hate Haskell, I just hate every other language more. Haskell is so close to being what I would consider "good" that it pisses me off.
There is probably a framework in which what she did counts as a proof ;-)
If only you could actually **read** the blackboard!
News to me!
I don't think it's really applicable to MS Word, if that's what you're looking for ...
I haven't noticed this happen very much. Sometimes you just need to add a bit of temporary debugging, and Debug.Trace is great, but a pure function doesn't often grow to need IO output. The things that need IO are usually in some monad transformer stack that already has it, so it's no big deal, as long as you've set things up right.
Those are the same function!
Send patches.
&gt; to most real world problems involves Monad transformers I don't think that's true at all. Some subset, perhaps, but no where near "most". I'm looking at Galois codebase. &gt; The Haskell Platform has good goals, but its development is far too slow, with serious bugs persisting between releases That's useful. We're trying to keep it stable, rather than having lots of releases. I think there is a real tension here. *Personally, I think Clojure is a toy at this early stage. I just have zero evidence of performance, scaling, robustness, .... Whereas you can bet your company on Haskell. Actually, I take that back. People use all sorts of languages, and they all kinda work. I just think Haskell is the devil we really really know, while Clojure is pretty much unknown. That's a good reason to use Haskell*
Why not patch the time package?
&gt; Just out of curiosity, is there a precise formulation? Yes, there's a proof of the implicit function theorem using the ODE existence and uniqueness theorem. If F(x,y) = C and dy/dx is nonzero at some point then we may locally expand y in terms of x, and differentiating gives dF/dx + dF/dy dy/dx = 0. This is an exact ODE, so you can transfer local statements about its solutions to local statements about implicit functions y(x). Unfortunately this only works for the two-variables version of the theorem. You can prove the general version using the theory of PDEs, but that is less elementary. This connection also suggests why the implicit and inverse function theorems are not completely obvious. Even if the derivative at a point is nice, it's possible that when trying to pass from the infinitesimal to the finite you would run into integrability obstructions, as you do with more general kinds of differential systems. Of course, the fact that the parts of the differential data were not independently specified but indeed came from a function makes this scenario not play out. By the way, there's another simple proof of the inverse function theorem for complex-analytic functions using Lagrange's inversion theorem. This theorem has a combinatorial and an analytical component. The combinatorial component is straightforward manipulation of formal power series. The analytical component is estimation of the remainder term, which may easily be done with the calculus of residues. Yet another proof for analytic functions, real or complex, uses the Cauchy-Kowalewsky theorem on existence and uniqueness for PDEs with analytic data, traditionally proved using the method of majorization. It's an easy theorem as PDE theory goes, certainly compared to the more general proof for non-analytic functions using PDE theory that I mentioned above. 
The subset of real world problems that require monad transformers includes at least CGI and GUI code. Would you mind linking to some Galois GUI or CGI code that doesn't use monad transformers and doesn't have an ugly UI? I can hear you say *"It's more important to be correct than pretty"*. Galois' list of customers on their website is mostly the military, so I can understand why you could think that. However you would be wrong in my situation. It's more important to be pretty than correct when your users are internal, you can give them a bugfix release in minutes, and you sit 20 feet from them, so it's easy for them to complain about the UI. &gt; That's useful. We're trying to keep it stable, rather than having lots of releases. I think there is a real tension here. There is a real tension there, but critical errors cannot be retained just because you would *like* to have few releases. e.g. 2009.2.0.2 cannot be installed on Linux if you install GHC from the generic Linux binaries because GHC installs some libraries that are included in the platform, causing the platform's install.sh to fail. There was a patch for this on haskell-cafe back in August, but there still hasn't been another release. 
You hate bottom? The only way to avoid it is to... prove that your program will terminate. That's a tall task for a type checker. That's a tall task for a few CS grad students with a year to waste. It doesn't matter what language you use.
No. I am not asking anyone to fix them; it's just the way it is.
Every single commenter on his blog seems to have more or less missed the point so far. &gt; These exist in all Cartesian closed categories (CCC). So our original function definition, despite apparently referring to elements, can be mechanically turned into a definition valid for any CCC. We can now reinterpret the meaning of x, y and z in the original definition as not referring to elements at all, but as labels indicating how a bunch of fairly general categorically defined primitives are to be assembled together. A closely analogous example from homological algebra is how you can mechanically translate element-chasing proofs in concrete categories of modules into diagram-chasing proofs that work for any abelian categories. Mac Lane has a sketch of this. If you have read Koch's work on synthetic differential structures, you'll know that for expository reasons he usually writes as if he were working over a concrete smooth category, with the knowledge that everything can be turned into element-free definitions, theorems and proofs that work for arbitrary smooth categories. In play are the doctrines of cartesian-closed categories, abelian categories and smooth categories. The common feature is that all of them have an internal language modeled on concrete generic categories, namely lambda calculi, modules and smooth spaces, respectively. "Concrete" meaning that you can treat these models as sets with extra structure and hence work with elements. "Generic" meaning that anything proved for the models holds generally for categories of their respective doctrine. Anyway, that's what seems to be happening. 
&gt; The subset of real world problems that require monad transformers includes at least CGI and GUI code Why? They might all be in the GUI monad or the CGI monad. I don't see why anything about GUIs or CGI *requires* monad transformers. gtk2hs is all in the IO monad, after all. &gt; There was a patch for this on haskell-cafe back in August, but there still hasn't been another release. Indeed. Thanks for the constructive input.
You should send patches to the maintainer. That's what I do. It works.
you can use only proven subset of general programming techniques (no general recursion). it also doesn't matter how many grad students have how much time to waste, they won't succeed.
but you had to count 'o's, didn't you?
Okay I'm going to say it one more time before I start being rude: I do not want to fix broken packages. That will be the third time. Do not beat me around the head with insistence because I do not love Haskell as deeply as you do.
I'm not a fan personally. I've given it a go but it still reads like utter line noise. However, that's because I've not dedicated enough time to it. My real issue with it is that I started because of all the chatter about it allowing fantastically stable programs, but the only non-toy examples I've used crashed far more often than even my own hastily coded research c++ apps. XMonad died relatively infrequently, but since it's a window manager I want something that pretty much never dies (wmii seems to be fitting this bill extremely well). The other one that springs to mind is ProteinVis. I could crash that in two maybe three clicks. &gt; I'd really like to know what you think of this. Is Haskell just flawless? Nope, but it might be the right tool for the job. It depends on what you want to do, but try to ignore the hype (for any language). Based on the kinds of programs I want to make, I use erlang. It's certainly not my perfect language, but it does what I need extremely well.
I've noticed that the license is GPL. Have you considered BSD3 instead?
Have you considered using GHC's [standalone deriving](http://www.haskell.org/ghc/docs/latest/html/users_guide/deriving.html#stand-alone-deriving)? That might solve your problem.
I didn't like that phrasing either but figured Don must have meant "bounded" in the sense of "bounded polymorphism". A type class constraint plays the role of a lower bound on the qualified type.
Bottoms are a perfect way to model exceptions in a lazily evaluated program.
You can easily make a Monad instances of Functor and Applicative by writing this boilerplate code: instance Functor &lt;m&gt; where fmap f p = p &gt;&gt;= return . f instance Applicative &lt;m&gt; where pure = return (&lt;*&gt;) = ap where `&lt;m&gt;` is an instance of Monad.
Yes. I agree with you. Stable Haskell codes are rare (not that I'm saying that there are very few quality Haskell codes--quality does not necessarily mean stable).
I feel its best to introduce Haskell to a person who has no prior programming experience so that he is saved from all the messy details of the imperative world and really focus on the solution. Also he has an added advantage of not knowing any other imperative language.
Asking "Is Haskell awesome?" on reddit is like asking the pope "Was Jesus Christ a good person?".
I am teaching a couple of my siblings how to program right now, and I wrestled with this problem. In my opinion, the choice isn't about using an 'imperative' or 'functional' language, but rather what language is well suited to expressing a variety of programming paradigms to a beginner. In the end I decided to go with Scheme instead of Haskell as a first language, b/c I felt that Scheme was an easier language to use for pedagogical purposes. That choice was largely based on the fact that Scheme is a dynamic language, and there is a lot of ground that I would like to cover before I start talking about type systems. In addition, it was much easier to explain how to set up an environment that they could use to evaluate and debug in, since Dr Scheme is geared to that. I would love to hear what other people have to say about this.
Yes, if they were Mathematicians.
This is an interesting educational pearl on the subject: [The Risks and Benefits of Teaching Purely Functional Programming in First Year](http://www.cse.unsw.edu.au/~chak/papers/CK02a.html)
&gt; I don't see why anything about GUIs or CGI requires monad transformers. gtk2hs is all in the IO monad, after all. [runCGI](http://hackage.haskell.org/packages/archive/cgi/3001.1.7.1/doc/html/src/Network-CGI.html#runCGI) expects a CGIT. So many gtk2hs calls can fail that whenever I ask in #haskell about how to make my code look like Haskell instead of ugly C, the chorus of suggestions is MaybeT, which isn't in the standard library, not searchable on Hoogle, and wasn't in the haskell platform the last time I checked. This is similar to my original point about libraries not offering good failure modes.
Read the new book "Coders at Work" for perspectives on coders coming of age, including our SPJ. I was astounded at how many old gheezers like me were affected by using APL. Now, only Haskell gets back that old feeling. We have to dispel this myth that people will "mother goose" on their first programming language, emotionally crippling themselves so they'll never see another language as different. This is a trait of some people, not some languages. If every lover looks just like their first lover, they'll probably make bad scientists; this isn't specific to programming. Pair programming with mathematicians, I always choose Haskell. They recognize it as a native tongue, with plenty of help. For my brother, a speech pathologist who wants to munge foreign language texts, I sent him my Python books. Obvious choice. I'll defer to the commentary in "Coders on Work" on C++. They say it with far more authority.
In my uni course. The first language we are taught is Haskell, about half the people on the course had never done programming before. And I think most are coping with it ok. Some need a bit of help, but thats due a bit to them not having as much time as they need to do the work at their pace. So I'd recommend it to a beginner
&gt; before I start being rude ... I do not want to fix broken packages This is not how open source works. 
I think you've hit on the salient points regarding Dr Scheme's advantages for education. It's an IDE, which gives the user an application in which to "do Scheme" but without too many knobs and buttons to scare anyone off. The standard library means you can immediately dive into most kinds of application programming, while the teaching languages strip away a whole lot of potential stumbling blocks for first time programmers. I really appreciate that I can tell someone to download DrScheme and be confident that it will be available for their platform, will easily install and run on their platform, and that they likely won't need to manually install any libraries to run any code that I give them (between the standard library and PLaneT's auto-download ability).
I would more readily recommend Haskell to beginners than to experienced programmers, if only there was good material targetting that audience.
&gt; That choice was largely based on the fact that Scheme is a dynamic language, and there is a lot of ground that I would like to cover before I start talking about type systems. In addition, it was much easier to explain how to set up an environment that they could use to evaluate and debug in, since Dr Scheme is geared to that. I would love to hear what other people have to say about this. This is exactly why I chose Scheme to teach to a young person. I couldn't imagine bogging them down with a type system out of the gate. Let them encounter concrete types on their own (by trying to apply a map function to a an atom, for example, and then building towards a more complex type like they do with rational numbers in SICP) rather than require them to learn types as an abstraction before they can program anything at all. Then there's the side effects issue. Scheme allows for them and Scheme IO is much easier than having to teach monads before having any IO. Conrad Barski really hit the nail on the head on that one with the Lisp/Haskell comic; it makes me laugh every time I see it (I can resist clicking when yet another person links to it).
The first language I was taught was Haskell. I think that worked out fine.
Haskell is pretty close to my ideal language. Issues: * FFI is pretty abysmal. Trying to talk to any large scale modern C++ library is an exercise in frustration management. * There is no path for retroactively adding a superclass in the type system that doesn't modify all instances. This is actually worse in Haskell than in C++ because in C++ I can refactor code into a new superclass without regard to its descendants. This tends to act as a sticking point for library evolution. Witness the lack of Functor or Applicative as a superclass of Monad. * The numerical tower is a compromise that satisfies no one. Num is meaningless mathematically, and contains spurious Eq and Show requirements that preclude useful instances. * Typeclasses with newtype noise can implement all of the things a module system can and vice versa, but occasionally it is useful to have ML style functors (parameterized modules) if only because it would allow you to avoid large scale refactoring of your code when you decide that you want to parameterize it. As it stands now, the choice of whether or not to make something a parameter of a typeclass/data type is an art. You need to know if you are likely to extend on that axis in the future. Gamble wrong and you have a lot of refactoring ahead of you. * Laziness occasionally makes it hard to reason about space performance. Naively written code often contains space leaks. It is hard not to write naive code. Robert Ennals' dissertation on speculative evaluation did wonders for space leaks in naive code, but was too big of a change to make it back into the GHC mainline. * No story for how to handle orphan instances/library interaction. When defining a new library you can make instances of your new classes for data types from other libraries. The problem is that you have three options that all suck: 1. You can make the smallest library that can contain your class - in which case you encourage other people to depend on your class. 2. You can make a large library that extends all the data types you can think of with instances for your class. 3. You can make a small core library, and a bunch of small extension libraries that describe how you extend each of the other libraries in turn. The problem here is that you are forced to use orphan instances which may not be seen or may be linked in an inconsistent manner by accident. * Beyond those the rest of my issues are largely academic. No polymorphic kinding means you can't talk about a category of small categories as a category or easily code type level metaprogramming combinators, typeclasses mean constraints on certain forms of type functions, all of which require a careful balancing act in the type system.
I also have some bits of code where I want to thread some state over IO, and there's no reason to newtype a StateT that's used essentially only in a single, if lengthy, where clause.
Great. But what does it do? I assume it improves GHC's inlineing features, but in which way? Is this something we user should care about or will things just speed up without any effort?
Yes, unequivocally.
&gt; just speed up without any effort Yep :)
The first course taught at my cs dept. is "Functional Programming using SML", which I think works out pretty well. The course teaches basic recursion, use of algebraic data types, higher order functions, I/O and structures/modules. I think Haskell would be a barrier for some, especially people who are new to programming. For instance, you have to know about type classes even to do basic arithmetics (Num, Fractional), and everything that involves IO will seem overly complicated. And last, I'm not sure if the lazy semantics are that intuitive for a beginner. Even though SML is far from being as elegant as Haskell, I think languages like this may be better for teaching the basics of programming. As long as the language is a functional, statically typed language of course :). Now, I haven't actually tried teaching Haskell to someone who has never tried programming before, so I don't know if my assumptions are correct.
Great news! I'm try some of my troublesome programs again.
I always do it, except I use fmap = liftM but it still sucks that I have to do it. And then my second point was that if I'm writing code that should work for Monads, I can't use Applicative's (&lt;$&gt;) and (&lt;*&gt;). 
What comic is that? I haven't been able to find the one you must be referring to.
Were your type signatures correct? Did you wrote them like this? ... :: (Monad m, Functor m, Applicative m) =&gt; ... 
It might be [this April 1st comic](http://www.lisperati.com/landoflisp/).
Hee hee, it gives me great pleasure to pass this along: [Land of Lisp](http://lisperati.com/landoflisp/). It carries the name of his forthcoming book on learning lisp, I think it was the product of an earlier idea for a book on lisp under the same title, he seems to have changed directions into a "learning" book.
I did some tutoring in college, helping people in CS, and was amazed at some of the trouble some people had with what struck me as fairly basic concepts. Could be I was a crappy tutor, but my sense was that some people just don't take to programming. The pint here is that when you see people having trouble for $LANGUAGE as a first language, it could be that the language is hard, but ti could be that those people would have trouble with almost any non-trivial language. One big problem I've had in learning programming languages is having to block out habits and preconceptions picked up from previous languages. Same goes for Haskell. It seems weird and hard if you've a head full of imperative programming and mutable state.
Which, category theory is a theoretical tool, or are you a hacker and a theorist? If the latter, biologists aren't car-mechanics, but obviously, someone could be both.
Which is decidedly different from asking the pope about Haskell and reddit about Jesus.
Will this cause rewrite rules to fire more often or anything of that sort? Oh, and will this make it into the 6.12.1 release (doubtful, I suspect)?
"Structure and Interpretation of Computer Programs" by Sussman. Yes it's all written around LISP. But it's a great functional introduction to programming.
I don't think it really introduces the necessary things to learn Haskell proper, though.
This sprint will run in parallel to the one hosted in Vienna. RSVP today!
Boy, was that ever a plot twist!
Of course if I add Applicative to the context I could use (&lt;$&gt;) and (&lt;*&gt;). But this has some significant downsides: * Larger context is less readable and takes more effort to write * Extending the context makes my function less useful. It requires the context of Applicative to spread to all functions that use it and all functions that use those functions etc. 
Yes. It's ironic that Haskell promotes high level abstraction and cutting down source code length. The type system seems like a double-edged sword. Sometimes it's warm/fuzzy but sometimes it's too delicate. In the mean time you can always replace `&lt;$&gt;` with `liftM` and `&lt;*&gt;` with `ap`.
I think Scheme is a better language for people with no programming experience. It fits well with a lot of the same functional techniques that are used in Haskell, its syntax is brilliantly simple (I think the importance of this for a beginning programmer cannot be overstated), and it has some [wonderful, free literature](http://mitpress.mit.edu/sicp/) to go with it.
Unfortunately that was an April 1st post... meaning *is he being serious!?!?* has to be asked. :-)
how was your experience learning C after learning Haskell as your first language ?
Yeah, okay Mr. Aspie Kid. I have and will continue to contribute the odd patch when OSS blows up in my face. However, if I do so it is because I am feeling generous. Telling me to fix things myself is a lame answer to a question that wasn't even asked by my original post. I do not like fixing broken packages, and no amount of you insisting that I submit patches will change that. Does it make you happy to make the rest of Haskell-land look stupid with your overzealous love for Haskell? You are just the flip-side of bonch and the other Haskell haters.
You mean, ididntRTFM-overflow? amidoinitrite?
then how do I write some code and be sure it doesn't throw any exceptions?
Usually I've found that when the piece of code is sufficiently small, it doesn't hurt much to just pass the parameters manually, though I can imagine that it sometimes occurs. Particularly over IO where you already have unbounded amounts of state via IORefs and IOArrays. Mainly I'm just worried that people sometimes jump into using complicated stacks of monad transformers without considering how the code might look if written in a more straightforward fashion. There are certainly use cases where monad transformers do wonders, but I've also seen a lot of code where they're just making things more complicated.
Have you read it? It introduces the fundamental concepts of functional programming in a methodical manner aimed at beginners. If the examples were reworked in Haskell it would be simply awesome.
I'm trying to offer constructive steps you can make as an individual to improve things. At the very least, mail the error log to the maintainer of the package. What are you trying to achieve by this rant?
I agree with you greenrd, with the caveat that *sometimes* the problem *really is* that the complainer has not given it very much thought. But that's not a license to be mean to newbies -- quite the opposite, in fact.
I was hoping you would stop badgering anyone who isn't 100% satisfied with hackage to "submit a patch". I guess it's a lost cause. Do you think I don't know that fixing the package will fix the package? What do you hope to accomplish by pointing out that "constructive step"? Not everyone has time to piss about fixing other peoples' broken work.
Your anger is inappropriate.
You set the rules for this reddit, but in wider society obnoxious behaviour like you're displaying begets angry responses. The only reason I'm even responding to this hogwash is that I'm quite certain you're perfectly sincere, and around here you're something of an ambassador for Haskell. The only reason it got heated is because you kept throwing dumb "THATS NOT THE TRUE OSS WAY" lines at me when I had made it clear that I didn't expect anyone to fix anything for me. If I had come on here attacking Haskell or expecting people to fix things for me then I would understand your insistence. I simply don't like it when hackage packages are broken. End of story. There is no rebuttal for this position, because it is pure personal preference, and you know it. Stop trying to insist that I should turn it into a "positive" by fixing things. If I want to fix things, then I will do so of my own volition.
I have read it. It's good stuff, but it doesn't talk about a lot of things I would consider essential for effective Haskell programming.
Be a good programmer. [HLint](http://community.haskell.org/~ndm/hlint/) may be your friend. It's not a question of whether the programmer makes sure his code does not throw exceptions. Bad programmers produces incorrect programs, good ones makes less. Exceptions are not a bad thing per se. It's a question of how you render *run-time* errors in Haskell or what the program should return when it can't figure out how to execute an otherwise correctly typed instruction. `1 / 0` and `[] !! 0` are completely type safe operations. There's no way the compiler is going to completely detect these errors and it certainly is not responsible for any of them.
My impression thus far of most haskell code is that infixs are used too often. &lt;|&gt; does not represent its underlying functionality well... Just an opinion though.
Anyone have benchmarks?
I think Haskell is probably easier to learn as a first language than after imperative programming.
Where do you go to school? Don't answer if you don't want to.
Isn't that the purpose of [lyhgg](http://learnyouahaskell.com/chapters)? I haven't read all of it, so I don't know how good it is, but I've heard really good things and what I did read seemed really good for someone who had never programmed before.
It doesn't directly affect user-supplied rewrite rules. It may help in cases, where lack of inlining has prevented rules from firing in the past. It will definitely not go into 6.12.1. In fact, a main reason for the patch not making it in earlier was to wait until 6.12.1 is out of the way.
After taking a class in Haskell as an absolute beginner, my only complaint was that there weren't enough resources to help me learn things on my own that weren't geared towards people who already had some programming experience. There is far more beginner stuff for Python. I hated Haskell when I was learning it but it's not so bad. I think the resource problem will be solved when more people start learning it. 
On the Haskell subreddit, no less. My answer to the question is absolutely not, for a number of reasons, but I really don't feel like disputing the unequivocal awesomeness of Haskell here.
Great question! Prior to the Real World Haskell, I'd say *hell no*. Even with RWH, you'd really need to create a lot of curriculum and maybe a framework so that you could teach the most basic principals without stepping into topics that are too advanced. You need a BASIC DSL so that they can spend lots of time doing real stuff (say web mashups), but only messing with functions, variables, etc. There is a lot of plumbing to hide.
As one of the authors of that article, let me add the following. I have literally taught thousands of students Haskell. In my experience, the group that struggles the most are mediocre programmers with previous experience in an imperative language. This group tends to be very attached to syntax and, as they are not very confident at programming, they are very reluctant to change paradigms and risk losing the little confidence they have. Both the upper, say, 20% of students with previous experience and the absolute beginners usually get used to the language fairly quickly. For the absolute beginners, it is the usual uphill battle of learning a programming language as well as algorithmic thinking at the same time, but they clearly benefit from the high level of abstraction and are more quickly able to solve more complicated programming problems than in other languages. That's a big benefit as it enables me to set more interesting programming exercises, which in turn keeps the students motivated. As an aside, I just started to introduce my 6.5 year old son to expression evaluation in ghci. He is actually quite excited about simple arithmetic and list manipulations. Expression-oriented programming is easy to grasp, even for small children.
This is a horrible idea. I spent 10 months and worked through SICP which was awesome, but... It requires heavy domain knowledge of math and other topics that are totally irrelevant to learning programming. All of the SICP exercises would need to be updated to do iPhone, Facebook, or general web app development.
It was just copy pasted. That said, I'll probably do as dons suggested rather than uploading to hackage.
I wonder how far you could get with Type inference and a really restrictive framework or sandbox. Only when the student outgrew the confines would they be ready to learn about type signatures or creating new types.
I think that for "abstract operations" is better to use an operator. Naming those is difficult. When I have used &lt;|&gt; I think about BNF. where you use "|" for the alternatives: digit:= 0 | 1 | ... So in some sense it represents the underlying functionality IMHO. Or maybe I'm brainwashed :-)
Well, there are two issues here: one is that you can convert any arbitrary into infix form, which can result in a substantial readability benefit, and the other is the usage of symbols to define operators, which can definitely be overdone, but can greatly increase the conciseness of code and when used effectively, can reveal meaning. Hoogle helps a lot.
That sounds okay. But can i still take credit for the speedup in my code?
I'm not sure whether you're objecting to infix operators (such as &lt;|&gt; or mplus-enclosed-in-backticks (I give up, reddit!)) or identifiers made up of punctuation rather than letters. I suspect that nearly all uses of mplus in real code (besides things like "foldr mplus") are in infix form anyways, so the name (&lt;|&gt;) saves us from having to use the ` key a lot. Giving descriptive names to class functions is hard, especially functions which originate in abstract algebra and don't necessarily have a fixed interpretation. For instance I don't like the name "mappend" because it doesn't suggest an operation which could be as general as multiplication of complex numbers or juxtaposition of images. (Plus it's too long!) I will grant though that people sometimes go overboard with names that are punctuation, e.g., =~ to match a string against a regular expression, which can only be justified by reference to Perl (or maybe an older language).
&gt; The first language I was taught was Haskell. I think that worked out fine. Is the first language that you learned also the first language that you were taught?
I hadn't thought about this view of Haskell until your post, so I really appreciate it! Doctrine is a good word but there still isn't any universal definition. It's the usual higher category theory problem of striking the balance between weakness and strictness.
Ah :) No. I'd learned Basic (and Modula-2 to some extent) prior.
Agreed. The only problem is the lack of resources. After 4 years of maths I found that Haskell fitted my existing way of thinking a lot better than any other language I'd dabbled with. For me, this made it worth persevering with. I wouldn't say it was the first language I learnt, but I would say it was the first I learnt where I got further than being an absolute beginner
Couldn't help but notice this line: M ./compiler/stranal/StrictAnal.lhs -1
University of Edinburgh, in my first year there
&gt; Be a good programmer. I'm not. &gt; There's no way the compiler is going to completely detect these errors and it certainly is not responsible for any of them. I disagree. compiler didn't stop me from producing code that can fail. how is that different from dereferencing null in C?
&gt; I disagree. compiler didn't stop me from producing code that can fail. Have you ever heard of Turing's halting problem? Some things just aren't decidable. Saying that a compiler must not produce a program that can fail is like saying that a car must not allow its driver to crash. &gt; how is that different from dereferencing null in C? Interesting question. I never programmed in C, so I'm not sure on how to answer that.
Nofib results are in the file attached to SPJ's email.
Ah, it was a .obj which confused me.
Some people [didn't like it](http://hackage.haskell.org/trac/ghc/ticket/3056)
I can for most of the time.
For those who might be put off by the abstract, this article actually argues strongly in favor of using a pure FP language in first year programming courses. Nice article.
&gt; Some things just aren't decidable. so? there are nulls in almost every language and it's not possible for a compiler to prove that there won't be any null dereferencing (it's undecidable) so how come there are no NullPointerExceptions in haskell? because we worked around the problem of nulls and use only safe subset of operations that makes it easy to prove that there won't be any NPE. same thing can be applied to halting (if you stick with structural/walther recursion you WILL halt). I want to use language+libraries that make it impossible to use their api in a wrong way.
In order to get a backtick, use \\\`
Ah, that would make sense. Enjoy being smarter than most programmers.
I know this is bit off topic, but am I the only one who is incredibly annoyed by the lopsided backtick+apostrophe quotes used throughout the Haskell wiki and GHC itself? Every time I see it, it's confusing and wrong. The only time it ever even [looks remotely correct](http://www.cl.cam.ac.uk/~mgk25/ucs/quotes.html) is if you're using default XFree86 fonts from before 2004. Even then, it's just an illusion, and is logically incorrect. * `` `` ``Wrong'' and `wrong' `` (Even reddit is too confused to let me do this) * "Right" and 'right' * “More correct” and ‘more correct’
Didn't work for me... the problem seems to be getting two backticks on the same line.
I guess you get pretty used to the backtick-singlequote style from reading and writing a lot of Latex. Technically they should be auto-converted to opening and closing quotes by the wiki engine.
Weren't we discussing about bottom? Bottom and null pointers are completely different things. Yes, we did solve the NPE problem. But we did not (and it's proven that no one can) solve the halting problem. &gt; if you stick with structural/walther recursion you WILL halt Says who? *Any* Turing-complete language can be used to write a program that does not halt. 
It depends on what you use to write latex. I use AUCTeX, so I can use either quote style to write and they're automatically rendered as proper curly quotes. If they're ever wrong I use the backtick (which is then rendered curly) or explicitly use curly quotes. So, what I'm saying is that I never *read* backticked quotes, although I sometimes write them.
Hi Wouter, not sure which problem you mean, and are you taling about time from System.time or Data.Time? That said, there appear to be other solutions with newer ghc libs (see parent thread).
That may be the case but it only takes one &lt;|&gt; to completely ruin the readability of a functions code
this is likely not to be a problem with newer ghc libs (see parent).
I think its possible but I would be worried about the frustration you might feel with the language and lack of material. Picking up something like ruby or python will net you some near-term gratification which will hopefully provide motivation. Haskell is where I went after feeling confident with object oriented design because I wanted to learn a new paradigm.
not sure what you mean by that. also, update: http://groups.google.com/group/haskell-cafe/msg/d04808b0988464dd 
:) I actually noticed the same problem when composing my post, but it didn't occur to me that you'd had the exact same issue.
I'd like to read this, but I don't have a PS viewer here at work, and cannot download one due to IT restrictions. Can someone post a PDF? And before anyone flames me, I actually prefer ps.gz to PDF for this sort of thing.
Types, for example.
&gt;It requires heavy domain knowledge of math and other topics that are totally irrelevant to learning programming. This word, "irrelevant" -- I do not think it means what you think it means. &gt;All of the SICP exercises would need to be updated to do iPhone, Facebook, or general web app development. Ugh. Show me someone who has worked through SICP that can't figure out how to do these things in a day.
&gt; Bottom and null pointers are completely different things wow, really? do you remember self-contradicting construction of the program from the proof of undecidability of halting problem? switch "loops" with "throws NPE" and what do you get? but we solved it! OH SHI... &gt; Says who? Any Turing-complete language can be used to write a program that does not halt. languages that forbid general recursion and only allow you to use structural/walther recursion aren't turing complete.
Or write backtick-backtick-space-expr-space-backtick-backtick.
There could be legal problems with that. Is there an off-site machine that you can log into and do the PS to PDF conversion there? You may want to try an [online PS to PDF converter](http://ps2pdf.com/convert.cgi). A document of this size might be too big for one of those online converters though. If so, you can easily divide up the PS by pages into several PS documents using your favorite text editor. Look for the %%Pages line, and the %%Page lines.
This is a very good point. Quite frankly (and probably due to my lack of education), names like "mappend" and "mplus" mean about zilch to me, especially considering that associating the "plus" I'm familiar with with "mplus" is not only wrong, but misleading (like `mplus (Just 1) (Just 2)`). It may as well be represented by an ASCII penis or something; at least that would make it self-evident that no assumptions can be made about the functionality from the name. 
Yes. When you are cool enough to choose a language that has a cool compiler that gives you cool speedups for free every version or two, you are free to pat yourself on the back!
Thanks... I'll just read it at home, I think. Less hassle.
Ok, I should've added "[Humor]" in the title. 
With MetaGene you can do your template metaprogramming in OCaml and it will spit out the ugly C++ for you: http://www.lrde.epita.fr/cgi-bin/twiki/view/Projects/MetaGeneIntro
Q: "What Does Haskell Have to Do with C++? " A: It has to mop the floor with C++ in more real world bench marks and in adoption numbers :) /me ducks under the desk
Wow, you effectively added nothing to the discussion.
I like the comment at the end of the article: &gt;“…some familiarity with Haskell may be really helpful in understanding and designing templates in C++” &gt; &gt;I agree, however, a little more familiarity than that may result in the desire never to see another line of C++ again, so you have to be careful. 
Aw, now now. Haskell has some brilliant minds driving it, and it's at least safe to say that interest and adoption are on a clear rise. Can't ask for more than that!
Yeah, but isn't the humor evident in the post?
Is this C++ template metaprogramming language lazy? Can one translate fibs = 0 : 1 : zipWith (+) fibs (tail fibs)?
let me just say.. I'm on my 4th or 5th week cleaning up someone's mess because they didn't understand templates. THis shit never should have compiled.. ever!!!!
I think yes.
I guess Dijkstra was wrong.
No, the compiler's just *really* fast.
Too bad it is still GPL
Great!
The C++ template metaprogramming language is fun and expressive, if somewhat obfuscated, however once you start trying to do something non-trivial, you realise that you can't, because the compile-time language in the compiler is not garbage collected (and you can't free things manually)! Everything accumulates, until ... boom!
It's not lazy by default, but you can build a framework that supports it which was what [boost::mpl](http://www.boost.org/doc/libs/1_40_0/libs/mpl/doc/index.html) gives you (check lazy sequences). The added bonus of lazy template instantiation is that compile-times are reduced, sometimes significantly depending on the compiler.
Seems that no action is required, should be solved shortly within libraries: http://groups.google.com/group/haskell-cafe/browse_thread/thread/6e6112610aeb3e12/d04808b0988464dd?lnk=gst&amp;q=tphyahoo#d04808b0988464dd
http://pleac.sourceforge.net/pleac_haskell/index.html it's far from being complete, though
Very interesting, thanks!
http://www.haskell.org/haskellwiki/Cookbook but it's still rudimentary.
....no it isn't. &gt; Copyright 2009 David Harley. All rights reserved. &gt; &gt; Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: ..... 
I understand that the 'pleac' project follows the 'Perl Cookbook', but the section in 'pleac' on hashes isn't about hashes. It's about applying search algorithms that are association lists or trees, not hashes. No effort is made to clarify this fact, 'pleac' just blindly follows along. So be aware that if you choose to use 'pleac' as your guide, there may be significant differences in approach with Haskell that are not apples to apples with Perl. This is not the fault of 'pleac', but rather that Haskell is not an imperative programming language and must therefore find different (sometimes greatly so) algorithmic solutions to the Cookbook problems.
I think he means the actual QT library is GPL unless you want to pay for a proprietary one. However, QT is also released LGPL for the benefit of our closed-source loving friends.
You may want to poke around in [/r/EnHaskell](http://reddit.com/r/Enhaskell)[1] We've got quite a few simple examples there since `fpisfun` started the place. [1] The "En" is as in "En passant" -- the connotation is that we make a clever (Haskelly) move to solve (take) a problem (pawn). 
Documentation is inconsistent. From: http://qthaskell.berlios.de/doc/userGuide/license.html &gt; Copyright 2008, David Harley. All rights reserved. &gt; The Current and previous releases of qtHaskell are preview versions and are released under the terms of the GPL. This policy will be revised at such time as full releases of qtHaskell become available I would expect the 2009 copyright to be more relevant for this release but it would be nice to see that page updated to match.
Your message appears twice....
Thanks, fixed. My internet is being choppy today.
Beautiful slide show.
it slaughters all other languages?
I found [Real World Haskell](http://www.realworldhaskell.org) quite useful. 
code clarity: Haskell is the winner. scalability: draw. constant factor: C is the winner. Hopefully new GHC optimizations will improve the constant factor part.
Isn't there some combinator library to build SQL queries, rather than using strings susceptible to SQL injection?
[HaskellDB](http://hackage.haskell.org/package/haskelldb). It's even been updated *somewhat* recently (within the year) so that it supports all the databases supported by HDBC and HSQL. However, it badly needs tutorials and documentation. The Haddock is not bad if you're already rather comfortable with Haskell, but the type-level hackery used to work around the fact that GHC doesn't have polymorphic extensible records is enough to make it hard to recommend to beginners without some extensive tutorials.
HDBC has query replacements : query = "SELECT id FROM users WHERE name = ?" [toSql name]
Announce them, promote them, make it easy to contribute.
Also, promote them in such a way that it appears I either: * Want to use them because they may be useful to my own project(s). * Want to use them because they may be useful to a future project of mine. * Want to use them because they are _really freaking cool_ (Viz, DPH, STM, Dyre, Just about anything Conal Elliot comes up with, etc). That, combined with what dons said, (especially making it _easy_ to contribute) is probably the best way. For my part, I've got too much on my plate... Someday I'll help other people! ... Someday...
Documentation. Or at least simplify and format your source code for readability so that people can figure out the objective of each code snippet and spot mistakes.
I agree. You need excellent documentation. Nothing worse than wanting to contribute, but fighting to understand what has been done so far.
Real World Haskell was the one for me too. I also found learnyouahaskell.com very helpful.
Keep a blog with status updates and goals of the project, throwing in commentary about stuff you are learning and challenges you're overcoming... and challenges you aren't able to figure out. The former stuff helps broaden people's knowledge of your project, the latter gets people involved. Oh, and make some friends on IRC :)
Cabalize and release it on [HackageDB](http://hackage.haskell.org/packages/archive/pkg-list.html) to make it more visible.
Pizza. We need a fund to finance pizza for people and get the delivery service to slide it under their door.
For large scale collaboration, use type classes with detailed semantics to protect interfaces, so you can farm out implementations.
Promise that it ends with them being published in an academic journal.
This isn't actually a bad idea
I like this as an example of how to use reader monad, but intend to use takusen for real world db work if the need arises. (I was advised to do this because less surprising lazy/strict io behavior.) 
It's almost like building constructors for arbitrary values. I imagine this potentially be useful for building "safe" constructors. I'll have to read more of the library to really get a sense for how that might work though.
I would not characterize Apache's configuration capabilities as "limited". You can definitely handle custom authentication and set environment variables for CGI scripts. Apache is your best bet.
Just skimming over the code, I was extremely happy to see that its very readable. The heaviest function is something like 10 lines, which I've found to be rare in the haskell world. 
It's not good enough. I have to plug my *own* authentication handler (database backed, written in a language of my choice), and I don't want to write a module in C.
happstack. Yes, it may be over engineered. But it's a nice group of folks that will be happy if you can help them split things out and make the web server more streamlined / independent. I can't remember where, but there was a discussion that the end game for happstack is for it to blend into the background, and have it be a bunch of loosely coupled modules that worked well together but could also be used independently. Perhaps you could help this happen.
This is a case of over-specificity; I'm sure there's something out of the box that would provide equivalent functionality. That said, it sounds like there is enough complexity in your idea that you should build it into your script. Also, if it's going to get enough use to make this worthwhile, you should think about FastCGI instead of CGI. You'd be able to do a lot more in that case because the application could maintain state.
Wow. Never expected to hear someone admitting Happstack's shortcomings. I really want them to succeed. But I guess you're right on the over-engineering bit. The whole thing needs to be redesigned.
&gt; That said, it sounds like there is enough complexity in your idea that you should build it into your script. Apache strips several headers, including ones related to HTTP's authentication mechanism, before calling CGI. Anyways, noted.
The whole thing? Or just the part of the thing that applies to your particular need? If it's the latter, maybe you should give it a chance. Roll your own is tempting, but communities have value imperfect as they are. 
happstack-server is widely used. I've found hyena usable.
&gt; Hack: API offers no way to know the IP address of the originating request. For happstack backend: Is it even possible with Happstack-server? If not, I can't just create a remote ip out of thin air. The backend handler is written a few months ago. If it is possible, please let me know, I'll just add it into the http env; For cgi backend: Check the (http + hackHeaders) var for (remote\_host / remote\_address) after mapping to lowercase for some generality. if it's not there, it's not in the cgi environment. How to get remote_host in wsgi / rack? Look up the env hash, same with hack.
&gt; Is it even possible with Happstack-server? I believe you can query that from the request object with `rqPeer`. 
Thanks, but seems still broken on mac, just tried
Looks possibly useful for constraint-based programming?
There are a handful of Haskell enthusiasts at the University of Waterloo, myself included, who might be able to make an occasional Toronto-area meetup. We might be able to score free meetup space at UW, alternatively.
I just tried Hyena, and like you my first "Hello world" ended up in an infinite loop. Turns out I hadn't set the content length properly, do that and it seems to work fine... I'm not sure what the expected behaviour should be if the content length isn't set...
Welcoming instructive commentary on this! Wazzit for?
This could be readily used for templates.
Neat. I had actually wished for this feature without realizing it was already available.
Sure. I'm another Haskell programmer from UW.
I quite like Hyena, but I've never used it out-of-the-box, I always end up hacking it to do what I want. It's small enough that that's easy to do. Not right for anything production-level, though.
what's up with galois blog link?
Holey Monoids Batman!
Not sure, the .wiki file has it in there w/o issue, I'll look into it. 
That looks pretty interesting. Can't wait to dive into it.
Personally I prefer "Teach Yourself Programming in Ten Years" http://norvig.com/21-days.html
For additional reading, [10 years of FP at Galois](http://www.scribd.com/doc/19502765/Engineering-Large-Projects-in-Haskell-A-Decade-of-FP-at-Galois).
I don't get the idea that this book is intended to do anything more than serve as an introduction to the scope of programming languages and paradigms that exist. I can't imagine the author or anyone else thinks you could become an expert user of any of the languages in a week.
"I’m most excited about Erlang, and a little nervous about Haskell. It’s going to be hard to do it justice in a chapter." -- we can help here.
Or do a better job than the various intros already available for these languages. What are the chances that the required gross simplification will give readers a false impression about more than one of these languages?
gross oversimplification... there lies the problem.
At the moment, if you turn on documentation without having haddock installed, installation simply fails. It would be nice if cabal could manage tool dependencies. It doesn't.
My main attraction for reading this is to see the quotes - and no, not just my own. :P Sometimes this leads me to find interesting things. Like Cereal. I shall now use it.
I don't necessarily disagree with you. My concern is that this may become a "pick your instrument based on hearing one note" scenario.
In a few years Galios will break out in pimples and behave rebelliously.
Congratulations! Hope we will be moving in close by... :-)
I hear if you wrap your pillow in a towel...
The book should build a single application using all of them.
How can someone know just what to include in a compressed description of a language without first being fully immersed in it and learning what is essential and what is superficial? Would you trust someone who spent a week in Europe to tell you the good and bad points? It's tech tourism. 
In 12 years it will die in a duel. 
Man, if Galois and Abel had lived longer... it makes you wonder, doesn't it?
Galois. Even our birthday cake was misspelled.
I prefer the [Holy Monad](http://www.seekersoftruth.org/online/holy_monad.htm).
On that note, today is Galois' 198th birthday.
&gt; How can someone know just what to include in a compressed description of a language without first being fully immersed in it and learning what is essential and what is superficial? ask people who are "fully immersed in it".
Terrible thing that!
I think this is a great idea, as long as the focus of the book is on the "weird" elements of each language and not on giving an overview of the language. Those are two different things. Seven EigenLanguages in Seven Weeks. As for how to do it, I'd pick at least one adviser from each language community, there's just no other way to do it. Mind you, picking the "interesting stuff" out of Haskell is still a challenge, since of all those languages Haskell is the one going out of its way to be "interesting". Might need some extra space for Haskell; for a book like this, it's going to legitimately have more to say than Ruby, which is not really that unconventional when you get down to it.
There are auth modules for most databases out there. See e.g. [mod\_auth_mysql](http://modauthmysql.sourceforge.net/)
Either a is a monad, but you have to import its instance from Control.Monad.Error
Looking forward to see some actual code.
Let me know when there's actually something to see. It seems a bit premature to even take note of this. Do we know anything about this? Is it based on CGI monad, Hack, Hyena? Is it using HDBC, haskelldb or something else? More concrete details on the website would be appreciated.
I'm glad that someone in the Haskell community is working on better error handling. It looks like wrapFailure can only handle one type of failure. Having exceptions derived from more abstract exceptions is one of the more valuable attributes of exceptions in other languages. Is there a way to handle more than one type of error at the same location?
If you're dealing with an Attempt object, you can easily do that directly (eg, pattern match on Failure). As far as an arbitrary MonadAttempt, I suppose your best bet would be to do something like: myWrap ma = do inside &lt;- runAttemptT ma -- assuming it's an AttemptT let inside' = myWrapHelper inside -- however you want to do the wrapping return $ AttemptT inside' If you have a concrete example of something you'd like to do, I can try to either make wrapFailure more general or add a new function which will perform what you need.
And get into ugliness with orphan instances and conflicting instances between the mtl and monads-fd packages...
In the mtl package, it's been moved into Control.Monad.Error.Class. So that if you want, you can avoid importing the classes and instances.
It says it uses Happstack.
Upvoted for reading ;). Actually, I misread that the first time to just be the critique of Happstack, not that they were actually *using* Happstack.
I filed [a GHC bug](http://hackage.haskell.org/trac/ghc/ticket/3610) about the hard-coded /usr/bin/strip issue. I'm not sure what needs to be done about packages overriding extra-lib-dirs and extra-include-dirs in their cabal files. I discussed this issue with dcoutts on #haskell. It seems that there are two separate issues that might be involved: one is that these directives in the .cabal/config *append* their paths to the ones in the package cabal file; do you require the ability to *prepend* in this situation? The other is that sometimes packages have their own configure scripts that do not respect the paths specified in cabal. So we need more information about what exactly you needed to do and what went wrong. Then we can file tickets if needed. There seems to be some problem with the FileManip package. Perhaps it is a version issue. Please be in touch with the package author (bos) about this. His email address is on the hackage page. As for Dreamhost's fidgety memory limits - I'm afraid I don't see much we can do to help with that.
Does anyone know what you need to do to get the Actions.SpawnOn to work? It's really annoying having firefox pop up in the middle of a workspace I didn't open it on
Michael, I posted an [answer](http://pepeiborra.posterous.com/control-monad-exception-and-the-long-type-sig) to your blog. There is some controversy but definitely room for collaboration too! It would be great if you would use the MonadThrow class in your safe library.
As yitz says, we need a proper bug report about the extra-lib/include-dirs issue with details about which package, what paths etc.
Show me some code, no matter how immature, or it doesn't exist.
I ran into the inclusion issue with HsOpenSSL-0.6.5 not being able to find my cbits headers directory. As a work-around, I added ~/prefix/include to the Include-Dirs section of the cabal file, but it would be nice to have that taken from the cabal config. I will contact bos about FileManip too. Thanks for looking into these issues! This was more a proof-of-concept than anything, so I expected to run into lots of problems, but didn't hit anything that was insurmountable.
&gt; whereas control-monad-exception' exceptions are explicit and checked by the type system a la java and .NET .Net ? anyway, I think you're arguing the wrong way (but I agree with checked exceptions with all my heart). since exceptions form hierarchy, you can always cast your function to something of type Either MasterException a, it can be done with one function/constructor. regular people get crappy function that fails when (maybe) documentation says it will and we (the pure and righteous people) can still omit that wrapper and know what can go wrong.
why did you put ghc on that server? why not just compile it on your own machine and only upload binaries? that's the beauty of compiled languages, you don't have to put interpreter/vm on your server.
/me hands you a sock.
I don't know yet but this is the first thing I'm going to try out. I really really hope this works as advertised.
a valuable experience report -- thanks. nice happstack on dreamhost would be quite a coup. Seems the usual practice for now is root on linode/slicehost, which is only a few bucks more. 
Is this because your host already has the OpenSSL C headers installed but you wanted to use your own versions (ie you installed a different version of OpenSSL into a local directory), or are you saying it could not find them at all, even when you used the extra-include-dirs setting? We need more details for a proper bug report. Otherwise we don't know which bit needs fixing.
+1 for a good blog post. Just to be clear (and I'll respond properly in your blog), I don't mean to dismiss your library, it simply isn't the right fit for a number of use cases that I have. I like your collaboration ideas, I'll try to get back to you in a few hours.
http://www.n-sch.de/hdocs/xmonad-contrib/XMonad-Actions-SpawnOn.html Note that if you're still using dmenu, you should probably switch to using XMonad.Prompt.Shell
Sorry for being vague! The problem is exactly to do with the installer not being able to find gmp.h, which I have in my ~/prefix/include, which is specified under extra-include-dirs in ~/.cabal/config. Here is exactly the problem: substack@cannons : HsOpenSSL-0.6.5 $ ./Setup.hs configure --user Configuring HsOpenSSL-0.6.5... substack@cannons : HsOpenSSL-0.6.5 $ ./Setup.hs build Preprocessing library HsOpenSSL-0.6.5... Building HsOpenSSL-0.6.5... [ 1 of 29] Compiling OpenSSL.Stack ( dist/build/OpenSSL/Stack.hs, dist/build/OpenSSL/Stack.o ) [ 2 of 29] Compiling OpenSSL.SSL ( dist/build/OpenSSL/SSL.hs, dist/build/OpenSSL/SSL.o ) [ 3 of 29] Compiling OpenSSL.Objects ( dist/build/OpenSSL/Objects.hs, dist/build/OpenSSL/Objects.o ) In file included from dist/build/OpenSSL/Objects_stub.c:2:0: /home/substack/prefix/lib/ghc-6.10.4/include/Rts.h:186:17: error: gmp.h: No such file or directory In file included from dist/build/OpenSSL/Objects_stub.c:2:0: /home/substack/prefix/lib/ghc-6.10.4/include/Rts.h:215:0: error: expected ‘)’ before ‘*’ token /home/substack/prefix/lib/ghc-6.10.4/include/Rts.h:216:0: error: expected ‘)’ before ‘*’ token substack@cannons : HsOpenSSL-0.6.5 $ ls ~/prefix/include ansidecl.h bfd.h bfdlink.h dis-asm.h gmp.h sqlite3.h sqlite3ext.h symcat.h substack@cannons : HsOpenSSL-0.6.5 $ grep include ~/.cabal/config extra-include-dirs: /home/substack/prefix/include
This looks neat; I've always been a bit confused by Haskell error handling. (One teeny tiny request: could you change the CSS for code highlighting to not use that bright aqua on white background for things like parens? It's a bit hard to read)
(I'm sure this gets asked a lot, but) since Galois has been going strong for 10 years with Haskell, why don't more places do the same?
I originally had this idea, but I have a 32-bit laptop and the target host is 64-bit, and from what I gathered, cross compiling with ghc is pretty [non-trivial](http://www.mail-archive.com/cvs-all@haskell.org/msg29192.html). Plus, the binaries are pretty big (about 13M), so doing a git pull and recompile on the remote end is much faster than re-uploading it when I make changes.
Not sure why this got downvotes. I'd never played with &gt;=&gt; or &gt;&gt;&gt;, but now they don't seem as scary.
Ohhh. You're confused about the relationship between the 'cabal' program and the `Setup.hs` scripts. The `Setup.hs` scripts are rather like `./configure` scripts and have no global config file, they just depend on command line parameters and the environment ($PATH etc). Then the 'cabal' program is a bit like a simple package manager. It's got a global per-user config file. So if you used cabal configure then it'd work since it'd pick up the setting from your `~/.cabal/config`. Alternatively you can use: runghc Setup.hs configure --user --extra-include-dirs=/home/substack/prefix/include Make sense? Generally I stick to the 'cabal' program and don't bother running the raw `Setup.hs` directly. Mixing the two often leads to confusion.
have you tried stripping them? or using dynamically linked libraries? don't you have another 64bit machine for compilations?
Returning whether a word was in the trie unnecessarily sequentializes your program. If you really do need this information, it will probably be difficult to parallelize efficiently. However, if we can rephrase the problem a bit such that order and disposition of insertions doesn't matter, the problem is pretty straightforward: import Control.Parallel data Tree = Bs Bool -- ^ is an empty word inserted here? (Maybe Tree) -- ^ '0' subtree (Maybe Tree) -- ^ '1' subtree deriving Show insertMany :: [[Bool]] -&gt; Maybe Tree insertMany [] = Nothing insertMany xss = hasEnd `par` fs `par` ts `pseq` Just (Bs hasEnd fs ts) where hasEnd = any null xss fs = insertMany [ xs | False : xs &lt;- xss] ts = insertMany [ xs | True : xs &lt;- xss] I don't have multiple cores at the moment, so I can't test this, but it should scale well. We've basically got a parallel radix sort in just a few lines -- not too shabby!
hmm this got out the gate a little sooner then I was planning. I'm still working on the base of this project and hope to have some code to release to the world sooner then later. 
No objections? No screaming bloody murder about the impurity of it all? Nobody saying "hey, here's a better way to do it"? I've been looking for something like this... now's your chance to tell me why this isn't right before I start doing it.
This technique is actually given more support in languages like Agda and Epigram. They don't even have 'undefined', but you can write code with holes in it like (in the Agda case): foo x y z = bar ? y (x ?) z and run the type checker. The question marks fill the space of a term of any type. If checking with the hole succeeds, your code will look like: foo x y z = bar { }0 y (x { }1) z and the environment will tell you what type of thing you need to fill into hole 0 and hole 1. And you can even enter things like: foo x y z = bar { baz ? }0 y (x { }1) z and run a command that will check to see if `baz ?` has a permissible type, and if so, you'll be rewarded with the code: foo x y z = bar (baz { }2) y (x { }1) z Of course, if `baz ?` doesn't have the right type, it'll just tell you so. It's quite nice, and, in the case of complicated proof-carrying code, almost a necessity for working with those languages (it's even more of a necessity for Epigram, since the holes take care of the 2-dimensional syntax to some degree, which is a serious pain to type by hand).
You should configure your robots.txt to keep dons away ;).
You maybe want to have a look to the [attempt](http://hackage.haskell.org/package/attempt) package on hackage
That's all fine, but... please, please don't use a monospaced font for prose paragraphs. The user's default setting for text is just fine. Thank you.
Oh, error is just as good a debugging tool as Debug.Trace. Refreshing deserts in an oasis of purity.
Perhaps to eliminate some of the par-thrashing near the leaves, you might want to write instead: insertMany :: [[Bool]] -&gt; Maybe Tree insertMany [] = Nothing insertMany [xs] = foldr oneBranch oneLeaf xs where oneLeaf = Just (Bs True Nothing Nothing) oneBranch False x = x `seq` Just (Bs False x Nothing) oneBranch True x = x `seq` Just (Bs False Nothing x) insertMany xss = hasEnd `par` fs `par` ts `pseq` Just (Bs hasEnd fs ts) where hasEnd = any null xss fs = insertMany [ xs | False : xs &lt;- xss] ts = insertMany [ xs | True : xs &lt;- xss] 
This is great! You've succeeded in posting to your blog - now how about posting to hackage?
This version is a little bit buggy. I've uploaded newer version of *ffmpeg* (0.3.4), could be found on [hackage](http://hackage.haskell.org/package/hs-ffmpeg). The problem was in supporting stable *ffmpeg* releases for different platform. My older code used **0.53.0** version of *avcodec* and *avformat*, but many users use slightly older versions (my Ubuntu distro depends on **0.51.0* version), so now I added support for this version into main package. By the way, the SVN version will still fork fine :) 
Great stuff. I look forward to seeing this on Hackage soon enough!
That's what I get for using a WordPress theme that uses 'web unsafe' fonts like 'Trebuchet MS'. I've changed to a theme with safer fonts.
Note that pandoc directly supports literate Haskell: pandoc -f markdown+lhs -t html+lhs -s will convert bird-style literate Haskell to HTML with highlighted Haskell source code. The Haskell source will be highlighted using highlighting-kate, not hscolour. But it shouldn't be too hard to modify pandoc to use hscolour instead of highlighting kate for literate Haskell. Would people be interested in that? 
I would. I wonder if it would make sense to be able to control highlighting somehow via the WriterOptions type? I.e. enable/disable it or provide custom highlighting?
Well, honestly, when you say "research problem" what exactly do you mean? Do you want to investigate some particular open problems in category theory? Are you looking for some application of category theory to computer science?
Lucky bastard, none of my math profs. are CT people... It can't hurt to show an interest, set up independent studies w/ them in algebra (assuming you have already taken all the "normal" abs. alg courses and stuff). I imagine your probably a CS guy, so you may need to take a few math courses before they'll consider doing an ISP with you. Research in CT might be a little too high level for undergrad work, but you might be able to get something out of a good ISP, and it's really nice on the resume...
Wow, pandoc is amazing! And there's even a vim syntax file! Where can I send the author money?
All of the above :) I'm just wondering if this is a worth while path to pursue.. The 1000ft view I have so far is that a few ideas from CT have been pulled down into the programming world, but that a thorough understanding of the discipline isn't really worth while to most projects.. But I might be mistaken, thus the post..
Actually, it's a 2-year college, so I probably won't be doing an ISP.. And I haven't taken any algebra courses yet. So this is all just speculation based on my own desire to pursue these ideas in future :) I guess I was just asking if I should start down this path now (reading up in my spare time), or just keep that door open for the future..
So, any reasons for being downmodded? Or is offering a counterpoint too hard?
Thomas Hartman: Thanks a ton for working over the weekend and making this happen. How to get it: * install [haskell-platform](http://haskell.org/platform) 2009.2.0.2 * cabal update * cabal install happs-tutorial * ???? * Enjoy :) Edit: added version 
Definitely start now! Never to early to start learning stuff. I can recommend some books that will be good, and a general outline of my path to CT, so I will. 1. I started with the basics, Number Theory, Dis. Math, Geometry, etc. Helps you to get a handle on proof-writing and how to think logically, you can skip this if you already feel comfortable with proofs, but Geometry (esp. non-euclidean geometry) is awesome, good books include Martin Jay Greenberg's _Euclidean and Non-Euclidean geometry_ and just about any number theory book will do, I have Strayer's _Elementary Number Theory_ which is very nice. 2. Get a handle on Analysis and Algebra. Analysis will lead naturally into topology, which is where CT comes from. Algebra teaches you about how to reason about the _structure_ of things, There are many good opinions on Analysis books, I used Bartle and Sherbert's _Introduction to Real Analysis_ to start, you won't need much past derivatives an integrals to be able to do Topo, I didn't particularly care for Analysis (I prefer Algebra) so I didn't do much after that. YMMV. For Algebra I can recommend Gallian's _Contemporary and Abstract Algebra_ or Hungerford's _Undergraduate Algebra_ (**not** the grad text, they have virtually the same title, but the grad text assumes basically everything that's in the UG text...). Make sure you understand up through Ideals and Basic Group Theory. Those concepts, while not critical to category theory, do help you to reason _very_ abstractly (Ideals can be a bitch...), which _will_ help with CT. aside, you're pretty likely to prefer Algebra or Analysis, you may or may not like both. It's okay, if you like one more than the other, just get through the basics on the one you don't like, make sure you understand up through the above recommendations, and then don't bother, if you _really_ like one or the other, do extra! It can only help. 3. Topology. I'm using a couple of books, there are lots of good ones. The point is to make sure you like the questions. I'm in the midst of doing an ISP in this (and advanced Algebra) so I can't give a solid recc. but my Prof (who is advising the ISP) says to "Make sure you understand the three C's of Point-Set Topology, namely Connectedness, Compactness, Completeness, and also Subspaces, Bases, and Homeomorphisms[1]. And work through some Algebraic Topology, eg Homotopy results, etc. CT comes in around homeomorphisms, from what I can tell, it helps to describe relationships between Topo. Spaces. Further, make sure you actually do all the stuff about Metric spaces and sequences. It may _look_ like Analysis, and in most cases it is, but it's different. Hope that helps a bit. CT is way awesome, as is all the math leading up to it! Good luck!
this is fantastic!
Err I meant to say it installs. I still have to run and test it out thoroughly. the head line should be .. installing happstack tutorial now works on windows too!! PS: how can i edit the submission title?
Odd, why do a few of your haskell snippets not appear with &gt; at the start of the line? But... great work. I'll have to try it out and consider using it in the future. A hackage package would be much recommended :-)
???? = regex-posix-0.72.0.3 failed during the configure step. The exception was: sh: runGenProcess: does not exist (No such file or directory)
The 'bird-style' haskell (&gt; lines) is part of the module being written before your very eyes. The non-bird-style haskell is example code, not part of the 'BlogLiterately' module. You should be able to cut and paste the post into an editor, save it (with a .lhs extension!) and compile it, and just the bird-style code would be compiled, the rest would be treated as commentary. I've verified this works, at least for me.
what's the output of ghc --version cabal --version
did you install the haskell platform?
The issues he raises appear valid. With regards to layering StateTs or other monad transformers... the solution I've found is to simply not do it. Abstract away what state you need into a datatype so that you can easily tack stuff in there later. But then you bump into the rather inadequate syntax for updating record fields. Luckily, this sort of thing hasn't been too much of an issue so far. I can't vouch for some of the stuff he goes on towards the end because I lack the background, but having used monad transformers, I can certainly say they are restricting at times. They certainly force your code to be clean, but I'd definitely believe that monad transformers are less powerful than type and effect systems. Finally, I don't feel certain that the difficult in learning Monads makes them a bad choice for representing computation, because it may just be that people haven't gotten their heads wrapped around the idea yet. It feels pretty natural once you *are* used to it.
The Glorious Glasgow Haskell Compilation System, version 6.10.3
This is because regex-posix uses a ./configure script which requires sh.exe (eg from MSYS/mingw). BTW, there's an open ticket on improving the error message if someone would like to do that. Though as fpisfun says, if you've got the platform then you've already got regex-posix and do not need to fight with ./configure scripts.
This is cool. I'd also like to see someone formalize the notion that applicative parsers recognize context-free languages and monadic ones can do arbitrary context-sensitive ones (or if not, what restrictions there are).
Yep. Pretty much. And your point was...?
I did install Haskell Platform 2009.2.0.1, I guess I need a later one.
I love the slides showing the rewrite rules and optimizations kicking in. I would **really** love to be able to see this happening inside my code editor...
The authors says "MY parser combinators are as expressive as possible"; how confident are you in your editorialisation?
I don't think there is anything controversial about the choice of combinators, however: * empty * a particular token * a or b * a followed by b You might argue that "a particular token" should be generalized to "a token that satisfies this predicate function", but, as long as the alphabet is finite, they are equivalent.
If I recall correctly STM code can still effectively deadlock, though you do have to try much harder than with standard locking code.
It can livelock -- threads can keep being denied access to the tvars due to contention.
Is this a problem in practice? Do you have to actively keep trying to avoid it?
Nope, its a design consideration earlier in development -- "is the granularity of my transactions likely to be unbalanced?" (based on the amount of work they're doing in each atomic section. Easy to decide upfront.
i installed 2009.2.0.2. If you try it, Could you please let me know if that works for you too?
Is there a simple concrete example? recently i saw news about ICC supporting STM, but couldn't get my head around the examples they gave.
Infinite production rules might be controversial. For instance, for `f(l) = true`, this grammar looks something like: ε | true (ε | true (ε | true ... | false ...) | false ...) | false (...) And for some more interesting f, you just replace some of the ε terms with ∅. But, parser combinators don't necessarily parse by recursive descent. They might build up a grammar representation for use by some other algorithm (or for some sort of optimization), and that might not be happy with an infinite grammar.
This company has turned up a couple of times in the past few weeks.. Looking at [their](http://www.galois.com/company/) website, it seems like the kind of place I'd like to work at.. But I wonder how much of a market there is for those kinds of services, what with all the business people who can hardly describe what they want, let alone give a formal specification of it.
Not exactly, the grammar for f(l) = true could be: g = ε | (true . # g) | (false . # g) It is true that the "construct a grammar from this function" function builds an infinite grammar, but that isn't saying anything about the parser combinators themselves. Keep in mind that due to referential transparency, my "g" is equivalent to your infinite description. Just because we can't automatically generate the optimal grammar for a function (this seems hard), doesn't mean that the combinators can't express that optimal grammar.
The sharing cannot be observed from within the language, so no matter how you define it, a circular, coinductively defined grammar like that will appear infinite to any function manipulating it. A library that attempts to do some sort of static analysis by analyzing the whole grammar may not be able to work with such an object; it may need an inductively defined grammar. For instance, one could write a set of combinators to parse regular languages and only regular languages (for whatever reason). Those would necessarily be unable to express some functions of type `List Bool -&gt; Bool`. However, no combinator in the article is off the list, is it? if r and s are regular, then r | s is regular if r and s are regular, then rs is regular if t is a token, then the language accepting just that token is regular the empty language is regular the language {ε} is regular Of course, my `f(l) = true` example is the language `(true|false)*`, which is also regular, but not all `f` need define a regular language. So, what's the problem? I think the answer is that regular languages can be parsed with finite state automata, whereas with a coinductive grammar, one is working with an infinite state automaton. The construction in the article constructs something analogous to a machine that looks like: ----------ε---------- | | --0---- ----1-- | | | | 00 01 10 11 / \ / \ / \ / \ ... ... ... ... ... ... where each node is named with the string that's seen so far, and is designated either accept or reject based on `f`. Such a machine can be represented using codata, and the representation can be incrementally consumed by an LL(1) parser to parse any language that the host language can recognize (of course all the difficulty of recognizing has been moved into `f` in this case, which gets used once at each state), but that doesn't necessarily mean that any set of parser combinators will work with such a grammar, even if it allows the five building blocks above.
Now that is actually rather good. The hello world example is indeed "pointless", and actually works! The second example also works, but I have no idea what it's doing: fix$(&lt;$&gt;)&lt;$&gt;(:)&lt;*&gt;((&lt;$&gt;((:[{- OH MY GOD IT'S A COMMENT!!! -}])&lt;$&gt;))(=&lt;&lt;)&lt;$&gt;(*)&lt;$&gt;(*2))$1 appears to produce a list of powers of 2.
I'd guess that Galois do a lot of work for government and military agencies, in my (very limited) experience such customers tend to value correctness of operation quite highly. Sadly (for me anyway), they're looking for people who can hold a US security clearance, which I understand isn't possible for non-US citizens. :-/
Something like this perhaps. Run these two in different threads with the same TVar, and the first one will constantly commit, invalidating the second one (which takes much longer to run). foo x = do atomic $ do xval &lt;- readTVar x writeTVar x (xval+1) foo x bar x = do atomic $ do xval &lt;- readTVar x writeTVar x (slowFunction xval) bar x
This article has absolutely no respect for my lambdas. :'(
On a quick glance, those (&lt;$&gt;) work on Functor ((-&gt;)a), which means that you can just replace them with (.) (allegedly making the program easier to understand....). Not sure about the first four, though, and whether (=&lt;&lt;) works on Monad [a] or Monad ((-&gt;)a) (evil) remains to be seen. Zetabot and @unpl might help.
 fix$(&lt;$&gt;)&lt;$&gt;(:)&lt;*&gt;((&lt;$&gt;((:[{- OH MY GOD IT'S A COMMENT!!! -}])&lt;$&gt;))(=&lt;&lt;)&lt;$&gt;(*)&lt;$&gt;(*2))$1 -- Remove the comment. fix$(&lt;$&gt;)&lt;$&gt;(:)&lt;*&gt;((&lt;$&gt;((:[])&lt;$&gt;))(=&lt;&lt;)&lt;$&gt;(*)&lt;$&gt;(*2))$1 -- f &lt;$&gt; g &lt;*&gt; h = liftM2 f g h fix $ liftM2 (&lt;$&gt;) (:) ((&lt;$&gt;((:[])&lt;$&gt;))(=&lt;&lt;)&lt;$&gt;(*)&lt;$&gt;(*2)) $ 1 -- (&lt;$&gt;) = (.) in the (e -&gt;) functor. It's verifiable that all these -- (&lt;$&gt;) are in the (e -&gt;) monad by checking the type signature. (&lt;$&gt;((:[])&lt;$&gt;))(=&lt;&lt;)&lt;$&gt;(*)&lt;$&gt;(*2) ((=&lt;&lt;) . ((:[]) .))&lt;$&gt;(*)&lt;$&gt;(*2) ((=&lt;&lt;) . ((:[]) .)) . (*) . (*2) fix $ liftM2 (&lt;$&gt;) (:) (((=&lt;&lt;) . ((:[]) .)).(*).(*2)) $ 1 -- liftM2 f g h x = f (g x) (h x) fix $ (&lt;$&gt;) (1:) (((=&lt;&lt;) . ((:[]) .)).(*).(*2) $ 1) fix $ (1:) &lt;$&gt; (((=&lt;&lt;) . ((:[]) .)).(*).(*2) $ 1) -- Apply (*2) to 1 fix $ (1:) &lt;$&gt; (((=&lt;&lt;) . ((:[]) .)).(*) $ 2) -- (=&lt;&lt;) is concatMap in the list monad. fix $ (1:) &lt;$&gt; ((concatMap . ((:[]) .)).(*) $ 2) -- Apply (*) to 2. (f . g $ x = f $ g x) fix $ (1:) &lt;$&gt; (concatMap . ((:[]) .)) (2*) -- (concatMap . ((:[]) .)) = map fix $ (1:) &lt;$&gt; (concatMap . ((:[]) .)) (2*) fix $ (1:) &lt;$&gt; map (2*) fix $ (1:) . map (2*) -- The pointful form of fix. let xs = 1 : map (2*) xs in xs Equational reasoning is cool.
&gt; they're looking for people who can hold a US security clearance, That's not actually true, if you read the job description.
And why is it useful?
well if you care about code size and you're unlucky with ghc's default O2, then you need this.
Wouldn't this just build up an infinite list of thunks that never get evaluated, though? What here is forcing the evaluation of `slowFunction`? It seems as though the unevaluated thunk would just get passed from thread to thread, building up a non-deterministic sequence of `(+1)` and `slowFunction` compositions thanks to laziness. Unless `writeTVar` is strict? I haven't played with this much myself, but I seem to remember someone talking once about using concurrency in a multiple cores/CPUs scenario to farm evaluation of expensive thunks off to other threads, but in his example he didn't use any sort of explicit evaluation strategy, and so the thunk he passed off to the other thread (presumably running on another core) was actually passed back to his control thread without being evaluated. Someone else pointed this out and then the thread got very interesting. I think it was a few years back on proggit before proggit started to suck. Laziness by itself doesn't phase me much, but mixing it with concurrency sometimes makes me feel like I'm standing in a fog.
You're my hero :)
This was hilarious. I enjoyed it muchly. Unfortunately that bonch guy on proggit seems to think it's accurate.
Dead link?
This works - http://channel9.msdn.com/
[C9 page of video](http://channel9.msdn.com/shows/Going+Deep/C9-Lectures-Dr-Erik-Meijer-Functional-Programming-Fundamentals-Chapter-5-of-13/) [WMV direct download link](http://ecn.channel9.msdn.com/o9/ch9/8/1/9/8/9/4/C9LecturesMeijerFPC5_2MB_ch9.wmv)
Seems rather ad-hoc though. Presumably needed for DPH for some reason. I wonder why it isn't a PRAGMA? Are GHC planning on moving towards using annotations for everything, perhaps?
When is it likely to be a good idea to try this?
PRAGMAs are used for the whole file/module, with annotations you get finer granularity
Quite likely not at all, at least at the moment. I implemented it to make experimenting with DPH optimisations a bit easier.
Yes, I think you'd want to use strict concurrency primitives/application like: writeTVar x $! slowFunction xval to make sure that `slowFunction` is evaluated in the relevant thread before writing it to the `TVar`. Then you'd get the desired livelocking behavior. :)
Very nice! It'd be nice to see more dtrace love in haskell land :)
I'll try to remember that in the future. Unfortunately, it's not CSS, it's the evil font tag (default output from HsColour).
We do have some more plans for dtrace'ing of parallel Haskell programs.
See you there, erlang represent ! :)
The difference between "I have "+number+" pieces of "+fruit+" at $"+unit_cost+" apiece" and "I have #{number} pieces of #{fruit} at $#{unit_cost} apiece" is tiny. Why would anyone spend any effort on supporting the second version? 
If you write it once, it makes it a small amount better for everyone who uses it. Syntactic noise is especially deterring to new programmers coming from the scripting community.
You might want to have a look at HStringTemplate.
AWESOME! Please make this work for zsh soon =)
All of my friends from Amazon are still zsh users, so I'm sure someone will do it soon. Patches welcome!
Actually, this is fairly well known in the literature. In general arbitrary attribute grammars with both synthesized and inherited attributes can be modeled with higher order synthesized attributes in a functional language. Then an alternative grammar is just a (codata) context-free attribute grammar with a synthesized (potentially higher order) attribute. &lt;*&gt; is juxtaposition of two nonterminals, &lt;|&gt; is a choice of nonterminals. pure creates an epsilon, empty matches no terminal. You do however, need a combinator added for recognizing a symbol, over and above a pure alternative. I say coCFG above because the CFG you generate may be infinite, and hence codata, not data.
Ruby string interpolation automatically converts expressions to strings. So you can also say: "1 + 1 = #{1+1}" as opposed to "1 + 1 = "+(1+1).toString() or what-have-you.
The latter gives you an opportunity to add correct encoding to your string. For instance, in many cases both of those are going to go out on the web, where that's a XSS waiting to happen. Sure, all three of those are numbers and of course they'll never be anything but numbers... but you should still HTML encode them for the cases where you are wrong and arbitrary user input popped out anyhow. Oh, wait, you say no language you use actually has that capability? Yeah, that's true, and it's no small part of why we have so many XSS vulnerabilities on the web.
That's why we should not be constructing strings and instead be using html pretty-printing libs that do the right escaping automatically (and types to prevent you doing it wrong).
yes, absolutely. This is a really bad technique for constructing structured data like HTML, with a pretty printing library you can guarantee all kinds of nice features like static well-formedness. There are still places where a more ad-hoc approach to templating is useful, though.
I did check it out first, but it doesn't quite do what I wanted - you still need to pass the attributes in as a dictionary, which adds a bit of syntactic noise.
good work. I was pretty impressed by the documentation at blog and github.
The poster made the classic new-to-monads mistake of: foo &lt;- return bar Gah..
how does it differ from [hdbus](http://neugierig.org/software/hdbus/)?
I think a couple of differences are that hdbus is a wrapper round the dbus c library whereas dbus-core and dbus-client are pure haskell, and that hdbus isn't on hackage
Dude, why wouldn't you write: main = do x &lt;- getLine let x1 = reverse x putStrLn x1 Or even better (if you still want to use do notation): main = do x &lt;- fmap reverse getLine putStrLn x1 ??? You seem to have gone off on a completely different tangent to what my point was, which is that wrapping pure computations in monad chains uselessly is bad haskell style.
My dream library allows me to use the concision inherent in the interpolation syntax, but to do it type- and encoding-safe. Not sure how it would all work, though I suspect Haskell could do it if I tried....
Cool. Maybe it's time to write an ivman replacement in Haskell? I'd like a nicer automounter.
Accepted papers with a relation to Haskell: * Clone Detection and Elimination for Haskell (Christopher Brown and Simon Thompson) * I/O Guided Detection of List Catamorphisms - Towards Problem Specific Use of Program Templates in IP (Martin Hofmann and Emanuel Kitzelmann) * Making "Stricterness" More Relevant (Stefan Holdermans and Jurriaan Hage) * Optimizing Generics Is Easy! (José Pedro Magalhães, Stefan Holdermans, Johan Jeuring, and Andres Löh) * Optimizing relational algebra operations using generic equivalence discriminators and lazy products (Fritz Henglein) * From Higher-Order Logic to Haskell: there and back again (Florian Haftmann) * IgorII - an Analytical Inductive Functional Programming System (Martin Hofmann) * The SourceGraph Program (Ivan Lazar Miljenovic) **And the other papers are great, too!** 
Python version is so much cleaner! SCNR
That was my first reaction too. And I don't think it's a symptom of it being a Python to Haskell translation: the Python code was written in a functional style in the first place, and if I wrote a Haskell program from scratch to carry out the same algorithm, it would probably look like this. I really like writing Haskell code, and I'm not a Python expert, but Python does come across as being much more programmer-friendly.
&gt; much more programmer-friendly Could you say more specifically on what aspects of the language and toolchain make it more friendly?
I didn't really get that reaction. I thought the Haskell version stood up quite well, which is impressive considering the translation was from a dynamic language. 
A few examples from the spell corrector program: "if b" vs "not $ null b", to see if a string is empty; accessing lists and sets works the same way; and the technique of using 'or' in the correct function, to find the first non-empty set. Without much prior Python experience, these points made me do a double-take, but because I guessed correctly what the syntax does without having to look it up. Having said that, these are all points in favour of Python as a language that makes sense the first time you look at it. I've always thought that Haskell has a steep bump at the start of the learning curve, but it's one that's well worth getting past. 
Man, I was so excited about that guy working on EcpliseFP for GSoC. I was so disappointed when he quit so soon. :|
For `if b` vs `not $ null b`, would the following equivalent list comprehension suit you? deletes = [ a ++ b | (a, _:b) &lt;- s ] In general, I've found pattern-matching almost always negates the need for a `null`-check at all.
That's much neater. And I could probably tidy up some of the head/tail/drop expressions that way, too.
&gt; I don't think it's a symptom of it being a Python to Haskell translation I disagree. The Python code leverages Python idioms; there many small ways in which those idioms create clutter in Haskell, and they add up. For example, here is a better port of the function edits1: edits1 word = Set.fromList $ concat [deletes, transposes, replaces, inserts] where s = zip (inits word) (tails word) deletes = [a ++ b | (a, _:b) &lt;- s] transposes = [a ++ y:x:b | (a, x:y:b) &lt;- s] replaces = [a ++ x:b | (a, _:b) &lt;- s, x &lt;- alphabet] inserts = [a ++ x:b | (a, b) &lt;- s, x &lt;- alphabet] All of a sudden - the Haskell looks clearer than the Python, doesn't it?
Excellent. I wish there many more postings about the practicalities of doing stuff in Haskell like this one and and many fewer trying to make me a better person through Monadology.
&gt; readNWORDS is a I/O monad that ... readNWORDS is an IO *value*, not a monad. I mention this distinction, because there's so much confusion about Monad and about IO and unnecessary linking of these two independent concepts. 
For more on this see [The view from the left](http://strictlypositive.org/view-Dec6.ps.gz) (the left being where pattern matching takes place).
 Requirements include the Scion IDE library which , on Ubuntu at least, needs to be built form source. I end up with this error: Linking dist/build/scion-server/scion-server ... /usr/bin/ld: cannot find -ledit collect2: ld returned 1 exit status Any hints on getting this to build on Ubuntu 8.04? As best I can tell, I have libedit2 installed.
&gt; It’s surprisingly expensive to try to eliminate the duplicates in Haskell, but having them present has no effect on correctness, as far as I can tell. Is it expensive to use a Data.Set?
Yes, i have the same problem with libgmp. I think I have some success with this on Ubuntu 9.10, and will try to add some info in the post soon.
Thanks for all the improvements -- mainly because of pattern matching inside the list comprehensions, [the Haskell version is now definitely clearer than the Python original](http://www.partario.com/blog/2009/11/an-improved-spelling-corrector-in-haskell.html).
Based on the [hdbus documentation](http://neugierig.org/software/hdbus/doc/), it's just a quick-and-dirty binding to the libdbus C library. It's aimed at making method calls to other clients, but isn't well suited for receiving or handling them itself. For example, there's no way to introspect or unpack `Variant`, no `Error` or `MethodReturn` message type, and no way to receive messages. It'll do for sending method calls to another client without looking for a reply, but can't handle anything more complicated. It's also not seen any significant development in over three years.
I had to downgrade to 2.4* from 2.5, because tab stopped working like it used to. is there A New Way of doing tabs or something?
What's your estimate of the market for IDEs for mainstream programming languages? By what rate do you think is Haskell development less common? What do you get if you multiply both numbers?
Credit Suisse has in the past paid for some IDE development for Haskell. The market is not zero.
i would buy it if it was good and open source. easy as that. i am picky about my editor, though. if it comes with a really simple text editor like most IDEs do, i don't think i would be interested.
That said, I can see a market for ready-to-use refactoring tools. And other tools to support commercial developers. The IHG shows there's a market for Haskell support.
If it was a Visual Studio IDE I think you could find more of a market than a standalone one.
Make it easy for beginners to use, make a website for it, and sell it to schools. Kids can then begin learning Haskell....perfect.
I'm not Windows fan, but I know that at work we'd mostly be interested in paying for a VS plugin for Haskell, because VS is what most people are used to. And I have to admit that VS is pretty good. 
does that mean its in ubuntu 9.10 or will that be later on?
And is this the [Platform Effect](http://qa.debian.org/popcon-graph.php?packages=xmonad,ghc6,darcs,hpodder,pandoc&amp;show_installed=on&amp;want_legend=on&amp;want_ticks=on&amp;from_date=&amp;to_date=&amp;hlght_date=&amp;date_fmt=%25Y-%25m&amp;beenhere=1) ??
Most people don't buy open source products though, do they? (RHEL excepted, and you can even argue about that one)
It is not in Ubuntu. Someone on Ubuntu has to port the package across
yay!
why not TH? 
I'll buy if its good. 
There is a very primitive TH combinator too, but it is more tedious to use. The preprocessor is just more convenient. By the way, patches are welcome!
Yes. Yes, there is. Haskell-mode has a number of optional modules, none of which are on by default (now!). One of them is indentation, which *used* to be on by default when there were only two, one of which was clearly awful and not to be used. So, download 2.6.1, then turn on haskell-indentation. It's not the mode you're used to; it's better.
You mean something like this: [A type-based solution to the strings problem: a fitting end to XSS attacks?](http://blog.moertel.com/articles/2006/10/18/a-type-based-solution-to-the-strings-problem)
Yes, I would pay somewhere on the order of $50 for a simple Visual Studio extension. Visual Studio shell is free so you could use it without visual studio, but it would be neat if I could just use the IDE I (and most windows devs, I'm guessing) use. If you integrate debugging (with watch windows, break points etc.) I'd probably go higher on the price. Maybe $75 or so. And that's just for personal use, but I think you'd probably want to target individuals initially (not too many Haskell companies around) .
I personally think you may have more to gain by contributing to an open source effort (which is why I have spent time helping on Leksah). There are several different efforts currently in progress and they all could use more help. A quick list of projects I think you should consider * Leksah (IDE written in Haskell that integrates Haskell tools using GTK UI) * Yi (Editor written from the ground up in Haskell) * EclipseFP * Scion (IDE support library) * Andy Stewart is working on what I guess would be an IE (IDE but not for just development) * Along with various Emacs and Vim support tools * More I probably missed Commercial Haskell projects will be easier for us all to sell if the tools meet the expectations of commercial users. In some ways open source tools are easier to sell. I did some work for a company that used "SQL IDE Pro" for putting our SQL in version control, the company that made it was bought out by Toad and it did not work out well for us at all (development and support of SQL IDE Pro stopped and Toad lacked the only feature we really wanted). I would be hesitant to recommend a closed source tool that did not have a very large user base. If Haskell becomes more popular in the commercial world there will hopefully be a market for support and adding features, or at the vary least there will be a market for the skills you used.
This means we'll be writing apps in 6.8.2 era Haskell for the next ten years `:(`
If you do decide to do this, please repost at some point.. It would be interesting to know how it turns out..
Very close, yes. Closest I've seen. I'd still like to see something that can further verify that your fragment is correct (that is, block `$(q "&lt;a href=\"#{r url}&gt;#{=content}&lt;/a&gt;")`, note the missing terminating double-quote on the first attribute), but... well, like I said, I'm talking about my _dream_ library, not complaining about yours. Compared to the mess I usually have to deal with that's still much safer.
I don't see what's wrong with Emacs, works fine for me on Windows. If the author/maintainer of haskell-mode wanted users to support it through some small contribution, I would be willing to do that. I don't even expect much from it, I've barely read M-x describe-mode more than once.
Thanks!
Dream come true. I've been spending years apologising to users for hairy install procedure and promising that things will get easier with time. Now (well, maybe after 2010 April as these are Ubuntu-ites) I can just tell them sudo aptitude install haskell-platform cabal install my-program Now if only the re-cabalised wxHaskell work would just get pushed through...
I believe this is not true - It does not need porting to Ubuntu. Someone from the project said so on a recent video: Ubuntu will pick up all Debian packages automatically in 3 months. I just tried, and the Debian .deb files work fine on Ubuntu 9.10.
I'm a small business owner and much of the work I do is dependent on Haskell (nothing fancy, just procedural XML generation). My tool of choice is Eclipse on Mac OS X. Can your product save me enough time to make it worth my while? I purchased [oXygen](http://www.oxygenxml.com), an XML editor, for $180 or so and have paid for several maintenance extensions over the years at $80 each. I have found this product to be invaluable when working with XML. If you can provide something of great value for Haskell, it's likely that I would be willing to pay a significant sum ($200+, depending on functionality). If you provide something of moderate value, I will pay much less ($25 to $50) or be unwilling to purchase it. I would prefer an Eclipse plug-in but standalone would be acceptable if it is good enough.
&gt; I don't see what's wrong with Emacs... You need to learn Emacs.
People are said to have bought Macs in order to use the text editor "TextMate" (Haskell is to Lisp as TextMate is to Emacs) for Ruby on Rails development. I already use Macs, and I gladly pay for TextMate, which is my IDE axe for any edit-compile loop, whether it be Haskell, or TeX scientific word processing. Single purpose IDEs usually represent language flaws. One shouldn't ask someone to learn a new editor for a single purpose, just like one shouldn't ask someone to learn a new language for a single purpose. Whatever strengths a tightly fitting IDE offer should be presented in a general purpose programmable editor.
Precisely. It will be moved into Ubuntu 10.4 automatically. Usually the freeze for moving packages happens somewhere around 2-3 months before a release, so late January is the current window I would guess. 
There was a plugin a few years back: [Visual Haskell](http://www.haskell.org/visualhaskell/). It sort of died on the vine, but it shouldn't be too hard for someone *ahem* influential in the community *cough, cough* to resuscitate it. :)
Yes, because the average nine year-old's grasp of category theory should make Monads simple for their little minds to grasp. &lt;/irony&gt;
Shove it down their throats.
I will say that at this point you are probably not poised to tackle open problems in the area of category theory. Don't take that wrong, most PhD mathematicians are also not poised to tackle open problems in category theory. They mostly emerge in the murkier waters of 2-category theory or higher, where you spend more and more of your time clarifying what particular variation on the theme of a 2-category you are working -- because there are a bunch of variations on the notion of equivalence and a combinatorial explosion of 'lax' notions when there is more than one thing to relax! -- and you get to spend less time actually describing and tackling interesting problems. Applying what is known to category theorists and is already there to problems in programming is probably quite viable, however! Viewing _Hask_ as a category (through sufficiently fuzzy lenses, ignoring bottoms and liftings as needed, SIGFPE has a nice post on the topic) provides you with a lot of tools, and a very nice mostly-concrete category to work with to gain intuition for the concepts in category theory. It also helps that there aren't a lot of us applying category theory to computer science, so there is still low hanging fruit. One starting point might be to look at the category-extras package on hackage. Another great resource is the #haskell IRC channel on freenode. More people speak category theory there than on the #math channel.
People don't, but corporations do. What they're really interested in buying though is the support contract rather than the software -- if something doesn't work they don't want to have to fix it. So if you hack something together and forget about it once you've shipped it, you're not going to be able to sell it to anyone. Furthermore, if something ever goes wrong with your software and you're not available 24/7 to fix it, you can forget about it.
Yes, the point of the library was to do something about security and errors while acknowledging that the way most programmers write web software is by manipulating strings. If we can't move the masses to use type-safe combinator libraries, maybe we can bring the 80% of the safety to them by making string interpolation safer.
If someone has told you that you need any mathematical or categorical background to understand monads as Haskell uses them, you've been grossly led astray.
I got this: Server error: : hPutChar: hardware fault (Input/output error) Very funny. I used to have a cherrypy server running on webfaction. That was a fun project. Imagine web programming with not HTML and javascript, only python. The setup was very easy. I hope the point of this was that they are offering something similar with haskell. 
possibly a better link than the headline http://blog.wrwills.webfactional.com/ 
I'd say Emacs is easier to learn than VS. On the other hand, most people are forced to learn VS for work, so I suppose that learning curve is a sunk cost for Windows devs.
Unfortunately, Haskell newbies are told ad nauseum that there's something difficult about monads. As a result, when the concept clicks, a large percentage of them feel the need to share their epiphany with the world. Still, I'm not sure it's necessarily so bad -- when I first started with Haskell the only references to monads there were on line were either in research papers or from people complaining about how hard they are. Now a cursory search on the web reveals a lot of people saying, "Hey, it's not so hard after all," which I think goes a long way to combat the myth that monads are difficult, which is sadly self-perpetuating.
sorry, I was just curious, I've never used TH nor other pre-processors.
I'm pretty sure that I understand monads. I've written enough Scheme functions that take "the world" as an argument and return a new one, and I've written enough DCG predicates in Prolog that do that too but hide it well. However, I find the descriptions of the pre-cooked monads in the libraries largely impenetrable. 
That's not what a monad is, just so you know. A monad essentially provides a framework for a kind of overloaded function composition. The newbie desire to learn I/O first means that most people are introduced to the `IO` monad very early on, which (while understandable) is I think responsible for most of the muddying of the waters when it comes to monads. The monad you just described is specifically the state monad (taking state and interleaving it through function compositions) and is one of the hairier monads out there. Thinking of it as the canonical monad will greatly, greatly complicate monads conceptually for you. A much better thing to think of as your basic monad is `Maybe`. It's very simple, easy to understand, and isolates the concept very well in my opinion, without forcing you to wrap your head around currying. Also, for the record, there's no particular reason that the `IO` monad needs to be implemented as a state monad (although that's how GHC does it). It's a black box -- you're best off not trying to think about its implementation too much, because by design you're not allowed to see it.
Aha, now the Farnsworthian headline makes more sense: ""Good news, everyone! We'll be writing apps in 6.8.2 era Haskell for the next ten years!"
Thanks for slapping me down.
Thanks for the advice.. I may or may not actually pursue open problems in CT. I guess my question was a big too forward thinking. But I will most definitely try and maintain an open dialogue with my instructors and ask for suggestions on new and existing materials to study. While they're not exactly computer scientists, perhaps I can describe some of the applications of categories in an interesting way and get some decent feedback, and perhaps get some suggestions from a different perspective.
Besides budget, the difficulty with selling to programmers is the mindset. They live for problems and don't want them to be hidden in a box. But once the box is opened up, it is thought to be harder to charge. This problem is similar to the music industry. People do pay for matlab and mathematica, but the customers consider themselves to be "users" more than programmers. They are happy to have Cholesky decomposition in a box. Even so there are open source competitors around. People pay for VS mainly because they are users of the .Net libraries, which are much easier to navigate with this tool. In general people pay to make problems go away. What problem do I have with Haskell that I wish would just go away? Learning it! Your IDE should focus on this aspect of development and take advantage of increasing interest in Haskell. I tried leksah and liked some features very much. First it forced (enabled) me to set up write my code as a cabal package, which I wanted to learn at some point. Second it let me navigate the libraries and documentation so I could see the code I was invoking from others' libraries, but had not written. Somehow I haven't learned how to do tis in emacs yet. Unfortunately the editor is buggy at the moment so I am on hold with leksah. I hope development proceeds. All leksah would have to do is charge $20 a download instead of asking for a donation. I wouldn't bother to evade it though others might. Just like I leave a tip at a restaurant though even though I don't have to. 
Hah. Trust me -- just forget about `IO` for now. I mean, use it (you don't need to understand monads to do I/O) but don't try to understand it. To really understand monads, forget about the word monad entirely and look at specific instances. Do them in this order: `Maybe`, `Either`, `Writer`, `Reader`, `State`, and then maybe `Cont` if you want something *really* messy. Look carefully at the definitions of `&gt;&gt;=` and `return` for each, and don't move on to the next one until you understand the one before. Eschew `do` notation -- it's very nice if you understand what's going on, but it will confuse you royally if there are any questions. Just forget about it for now. If you're into symbolic manipulation, proving the monad laws might be fun, and instructive. It's not important, though. It's very easy to do for `Maybe` so maybe try that. Ultimately a monad is a design pattern -- people didn't come up with monads first, they came up with types like `Maybe` and `Writer` first, and then discovered that some pretty basic and obvious functions were similar between the two. So it's pretty silly really to encourage people to try to understand what a monad is abstractly first. I think this really trips people up. Sigh, this thread devolved into monadology, didn't it? Anyway, take care.
would you mind writing a few using-emacs-for-haskell blog posts? I've been using haskell-mode only for syntax highlighting, indentation and sending input to ghci and frankly, all those things are buggy. Would be nice to learn about experience of other people.
&gt;Sigh, this thread devolved into monadology, didn't it? Yep. Although your particular combination of trying to show me the road to enlightenment while simultaneously leaving me in no doubt that I'm personally and specifically an idiot, am furthermore a member of a broad class of idiot and that our idiocy is amply demonstrated by the fact that in learning about a subject we ask idiot questions and this is our fault for being idiots is relatively novel. I'm sure that this approach will pay great dividends in raising the profile of Haskell amongst programmers at large. You actual advice looks sound. Trouble is, people are disinclined to take even the best advice when it's given by someone publicly contemptuous of them. Have you thought about an academic career? 
Once I've gotten rid of the bugs, sure. For the time being, any time I get to spend on haskell-mode will be used to squash them, not document them. ;)
Wait, were you insulted? I'm having some trouble gauging your tone from text, sorry if I'm misunderstanding something here.
This is the kind of getting stuff working code that Haskell needs more of! Seeing this blog post makes this MonadLoc stuff much more tractable; I hope to use it in my code in the future.
Yes, I felt insulted. &gt;That's not what a monad is, just so you know. Think about the attitude towards my thoughts that this statement invites me to infer. &gt;The newbie desire to learn I/O first means [...] So it's the fault of "newbies" that those writing all those monad tutorials and Haskell introductions chose to use i/o as their model? I find newbie to be a derogatory term: dismissive and condescending. I find it doubly condescending that the difficulties that those new to a technology have are blamed on them. 
Ah. Well, I don't have much to say to that other than to assure you that that's not the way it was intended. Firstly I encourage you not to take the term "newbie" derogatorily -- everyone was a newbie once, and all of us are newbies in whatever new knowledge we're currently attempting to acquire (for example, I am a newbie in Agda, which I find quite confusing). While it was a long time ago, I remember clearly being confused by monads when I first encountered them, something I attribute largely to the way they were presented to me: as something stateful, which I later learned to be a terrible way to think about them. I sensed you were making the same mistake I did, and I was eager to share the knowledge I've gleaned having already traveled down the way you're apparently heading. To help you, you see. If I thought you were an idiot, I wouldn't even talk to you. I understand that it can be very frustrating to be a Haskell newbie. From talking to you I don't doubt you are a very competent programmer and are used to being treated as such, and maybe even resent a stranger who probably isn't even as competent an imperative programmer as you are giving you advice like you're only just starting out. Unfortunately I think you'll find that your experience with Scheme or C++ or Python or Java or whatever will not help you very much with Haskell, and you'll just need to accept that others may know more than you about that particular subject gracefully. And for the record, I'm not a Haskell evangelist -- I'm no dons. Whether you decide to continue on your Haskell journey or not is ultimately of no consequence to me. I'm trying to offer help in passing; telling me that I'm turning people away from Haskell by not working on being more sensitive in my delivery isn't going to have much effect. People who desire knowledge take it from where they can get it, to my mind. If your desire for knowledge is limited to only knowledge that is carefully worded to avoid offending your sensibilities, well, what can I tell you? Hopefully you find success, either way.
One day Oleg's going to prove that all GHC extensions are actually valid '98.
Let me try to offer you some help in passing—no matter how much powerful intellects would like to believe otherwise, effective communication is pleasant communication. It's that simple. If you do want to communicate effectively (and if you don't, what are you doing here?) then you should bear in mind that it's more effective to do so with a care for the sensibilities of your audience. This is a well established fact about people. You will do better at communicating your ideas if you express them with grace. If you do not intend to communicate well, then do what you will.
Fair enough.
This is great as long as hackage gets a proper home too. 
control-monad-exception 0.5 is available now in Hackage, with support for monadic stack traces via a preprocessor.
Oleg's reasoning abilities scare the hell out of me, man. Dude's almost an overman.
Can/does it generate Deterministic Automatons for parsing?
Newest in the no-longer-fake-world-haskell series. Please leave your feedback in comments here; I'm curious if this installation is understandable, as the material is a bit more complicated than previously.
Visual Haskell was a great start, but as you say, it died. :(
Tokyo Drift... You brilliant bastard... *EDIT After Reading*: Well, skimming more than reading. It looks good. You might want to peek at the various pretty printing libraries too (I don't know if you did and I just missed it, but for pedagogical purposes...). Keep up the good work!
It is not possible (in general) to generate a DFA that parses a CFG. Not all context-free grammars define a regular language.
There's an [old Oleg post](http://okmij.org/ftp/Computation/monads.html#fair-bt-stream) on fair backtracking where he does what amounts to diagonalization. The Earley top-down parsing algorithm for context-free grammars also uses a work queue for pending states, which I think of conceptually as round-robin thread scheduling. Using a queue as opposed to a stack ensures that you don't get stuck in unproductive left-recursive cycles. That's also a kind of diagonalization.
The "stack" automatons that do parse CFG are not considered DFA's? 
but, what about the list monad? 
Very interesting and enlightening! Congratulations on another successful part of the intro to Haskell. I like how the parts are united by the same goal and how each part develops a certain specific area of Haskell that is required to achieve the goal. Good job indeed! :)
Those are not DFAs but DPAs (P for pushdown). A DFA cannot perform unbounded counting. You need this to recognize languages like the one defined by this CFG: x ::= epsilon | '(' x ')'
EclipseFP is stilll being maintained, though. All bug reports and feature requests are welcomed!
I feel like a lot of newbies wonder what the benefit of a monad interface to list is when they can use list comprehensions and `concatMap`. It's only later, when they begin to appreciate the monad as an abstraction, that the list monad really clicks. But maybe I'm projecting. It's certainly not a complicated monad to understand. The `&gt;&gt;=` operation on the `Maybe` type, though, is immediately obviously useful in and of itself to anyone that's worked much with `Maybe`. That's part of why I think it's a good motivating example. You can sit down and write code with `&gt;&gt;=` and `Maybe` to greater clarity without understanding what monads are generically.
I have an idea, get someone to host Hackage who can actually keep the damn thing up :p
Or better, just get mirrors.
Sorry, you're right, of course. I just inserted the "F" in there because it's the first thing that came to mind. Still, not all CFG's are recognizable by deterministic (pushdown) automata -- and the class of CFG's that are recognizable in this way is actually interesting and a little bit strange. =)
Oh, I didn't know anyone picked up development after Tomas quit.
Despite this new channel, I vote for allowing hackagebot to continue to announce on #haskell as well.
After 5 years up, the disks are starting to fail.
Awesome. I was wondering what the relationship between GHC, HP, and the individual libraries were. As a maintainer of a small library in HP, the decoupling makes things easier.
Ericsson? Didn't they have some other language too? Something for parallel stuff... We're taking over. :)
Very cool, any word about whats on the list for GHC 6.14? Seems like just yesterday it was 6.6...
I completely agree, the channel isn't supposed to replace hackagebot, or -café/the libraries mailing list (there is one right?), but as a place for discussion about hackage and using hackage.
The work that's (slowly) being done on rewriting hackage using happstack should make it easier to mirror I believe.
See also: [Control.Monad.Fix](http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Monad-Fix.html), which is used to desugar recursive do blocks, and [the recursive do notation entry in the latest GHC manual](http://www.haskell.org/ghc/dist/current/docs/html/users_guide/syntax-extns.html#mdo-notation), which details the new syntax that replaces the `mdo` described in the linked paper (with `rec`, which does seem to be superior.) The motivating example in the paper is quite interesting and easy to follow, worth a read if you're an intermediate Haskell developer (or a motivated beginner).
Probably. For example, I replaced my source installation of GHC and use GHC and platform packages since Friday.
Oh, and an addendum: if you're not intimidated by equational reasoning and proofs, the discussion regarding the appropriate definition of `mfix` for the state monad (section 4.4) is very, very interesting.
Saying it was recently deprecated is a bit misleading isn't it? GHC just added new syntax for recursive do, and also deprecated the old syntax.
I always thought the name of the `mdo` keyword was a little odd. The footnote on page 16 says: &gt; The closest we can get to μ`do` using ASCII. (We would have used `dorec`, but that is just too long.) Note that the use of Haskell-like syntax is just for convenience. We could have used Moggi’s `let` T x ⇐ e `in` e notation and the keyword `letrec` T as well. 
Yeah, I should have somehow indicated that the syntax was changed and that sugar for `mfix` is still part of GHC, but the various wordings I came up with were all either too long for a summary line or a bit ambiguous.
I thought that haskell-indentation was the new mode, and that for old behaviour you need either haskell-indent or haskell-simple-indent? Anyway, just read the README: it tells you what you need.
Another UW Haskell hacker here.
Sorry about posting so many times in the comments to my own submission, but so much of what's in this paper is just so interesting. So in section 5 he conjectures that there is no definition of `mfix` for the continuation monad. This in and of itself is very interesting. But in section 5.3, it goes into blow your mind territory. To get an idea of how continuations play with recursion in a language without restricted effects, he takes a look at Scheme. If you grok Scheme, you'll appreciate this. Here's a taste. He defines (define (test1) (letrec ((x (call-with-current-continuation (lambda (c) (list #T c))))) (if (car x) ((cadr x) (list #F (lambda () x))) (eq? x ((cadr x)))))) and (define (test2) (let ((x (call-with-current-continuation (lambda (c) (list #T c))))) (if (car x) ((cadr x) (list #F (lambda () x))) (eq? x ((cadr x)))))) which you can see differ only between the upper's use of `let` versus the lower's use of `letrec`. But in Scheme, thanks to first class continuations, these evaluate differently! See if you can see why -- and if not, check out the section in question. Totally blew me away. Who knew there was so much to think about!
I seem to recall seeing somewhere, when someone mentioned something like the above, a reply that `letrec` needn't be implemented in the way the specified, with an underlying `set!`, and that you only get back `set!` if the implementation chooses to implement `letrec` that way. Which, I suppose, might mean that the behavior of the first expression (or something related) is implementation dependent. Of course, I may be remembering incorrectly, as if my above vagueness isn't bad enough. In any case, this is a pretty bizarre area of the Scheme semantics.
Hm, maybe so -- I don't know enough about the guts of Scheme to comment, but in the paper FWIW he does have this snippet from personal correspondence with one Andrzej Filinski: &gt;...as far as I know, the only popular functional language that allows such de finitions is Scheme; and I believe that allowing them was a mistake. The extra generality is virtually never used, but it disallows some useful optimizations by unnecessarily constraining the implementation. It is well known that in the presence of call/cc, one can expose the imperative nature of letrec and use it to define a general mutable cell; any RnRS-conforming system must support this behavior no matter how it implements recursion... I've been trying to find the original post in comp.lang.scheme that he references (Alan Bawden, "letrec and callcc implement references", apparently from 1988) but nowhere in [Google Groups' archive of the newsgroup](http://groups.google.com/group/comp.lang.scheme/about) is the post to be found. Still, there are quite a few references to the phenomenon, indicating that within the Scheme community the behavior is relatively well-known. I'm no Scheme guru, unfortunately -- I just know enough to hurt myself. :) EDIT: I think I've found the post in question. It's actually from March of 1989 and the posting title was *LETREC + CALL/CC = SET! even in a limited setting*. I do believe it is the same post that the author of the submitted paper was referring to, because it contains the code in question, and it ends with Alan Bawden wondering whether or not any Scheme implementations incorrectly perform a `letrec` to `let` optimization in the presence of `call/cc`, something that the paper mentions. Anyway, [here's the link](http://groups.google.com/group/comp.lang.scheme/tree/browse_frm/month/1989-03/367ac22c681623fd?rnum=1&amp;_done=%2Fgroup%2Fcomp.lang.scheme%2Fbrowse_frm%2Fmonth%2F1989-03%3F#doc_063a514aa6933180). It's a fairly interesting post.
But without that twist in the headline I wouldn't be reading this all :-) Thanks for the pointer!
Why is he even bothering compiling GHC himself? Does his OS not have a binary package manager?
That was answered in the second paragraph.
Is GHC not in the Ubuntu repository, or some third-party repository? If not, he needs to get a better distro.
Pretty soon he'll discover that GHC 0.0.9 requires him to first compile a chicken, which requires an egg, which as we know requires a chicken, and then he'll regret being so strict in his evaluation.
i wish more people tried to build it themselves, i recently went through the pain again while building the 6.10.4 package for VectorLinux. VL requires that all packages be re buildable, and GHC requires a binary installation to build a package from source. it was not fun at all
Was there any particular reason for the syntax switch? (I seem to have missed any discussion on it...)
why call it Tokyo Drift? 
SPJ discusses it [here](http://www.haskell.org//pipermail/glasgow-haskell-users/2009-October/017904.html). The significant benefit seems to be that it works with rebindable syntax.
Wow, that's complicated. Is there something clever to add to GHC that would make this better?
Perhaps GHC could inline a function when the argument is known to lead into a non-recursive branch of the function? Done repeatedly this would evaluate this expression completely at compile time. In the real world we might need some way to determine if an inlining would constitute a "simplification" or a "bloatification"...
Additionally, I have noticed that gcc will happily inline recursive functions such as fib with favorable results, so there is probably no technical reason it can't be done.
 Oops... Trac detected an internal error: If you think this really should work and you can reproduce it. Then you should consider to report this problem to the Trac team. Go to http://trac.edgewall.org/ and create a new ticket where you describe the problem, how to reproduce it. Don't forget to include the python traceback found below. TracGuide — The Trac User and Administration Guide Python traceback Traceback (most recent call last): File "/var/lib/python-support/python2.4/trac/web/main.py", line 387, in dispatch_request dispatcher.dispatch(req) File "/var/lib/python-support/python2.4/trac/web/main.py", line 239, in dispatch template, content_type = self._post_process_request(req, File "/var/lib/python-support/python2.4/trac/web/main.py", line 269, in _post_process_request content_type) File "build/bdist.linux-i686/egg/hidevalsigloo/filter.py", line 35, in post_process_request IOError: [Errno 28] No space left on device 
Seeing the title, I'd hoped this was going to be a "how to" instead of a "you can't". :(
In my understanding, it's not quite that simple. I think you'll find that provided all the GUI operations take place in one thread, then this won't be a problem - check gtk2hs-users mail archives for more discussion. The upshot is that you can use extra threads for long-running tasks, etc. but need to explicitly communicate between threads using threadsafe queues or actors or whatever, and have all the GUI updates, etc. occur in the main thread. Caveat: I haven't actually done this with gtk2hs (so far I use wx), and may have misunderstood, but I was looking into it a couple of months ago and this was the state of play then, IIRC. 
I like `mdo`. :( While maybe unwieldy for precise control of the recursion, it makes easier syntax for things like the [frisby parser combinator](http://repetae.net/computer/frisby/#v%3AnewRule). The code example would have to be written additive = do rec additive &lt;- newRule $ multitive &lt;&gt; char '+' -&gt;&gt; additive ## uncurry (+) // multitive multitive &lt;- newRule $ primary &lt;&gt; char '*' -&gt;&gt; multitive ## uncurry (*) // primary primary &lt;- newRule $ char '(' -&gt;&gt; additive &lt;&lt;- char ')' // decimal decimal &lt;- newRule $ many1 (oneOf ['0' .. '9']) ## read return additive
 import sys lines = (line for line in sys.stdin) print lines.next().strip(), for line in lines: if line[0] != ' ': print print line.strip(),
I always liked Lisp's way of solving that particular problem (e.g. http://www.gnu.org/software/emacs/manual/html_node/cl/Time-of-Evaluation.html ). Why force the programmer to write the program completely differently when they want it to be executed at compile time when you can just provide a language construct to specify evaluation time explicitly.
You are describing supercompilation.
Does it require that for gcc too?
made a mistake and sent to general reddit - gonna take some flak for that
I'm the author (though I didn't submit it here, it wasn't really news worthy :-) I'm creating a binary for a host over which I have no control (i.e. shared web host), so using a better distro is not an answer. It's running CentOS 4.5, and the only binaries I've found for that are for GHC 6.4. That is how I managed to bootstrap the whole process, but it's quite painful from there on in.
Silly humor. This article is part 3 in the series, and Tokyo Drift was part 3 in the Fast and the Furious movies. The juxtaposition seemed uniquely inappropriate.
404 :( any other mirror for this? 
gcc comes with the distro as part of a development package along with the whole enchilada tool chain. and i would venture a guess that the gnu tool chain is considered a basic necessity to build all the others[ in VL/slackware].
Direct URL: http://ecn.channel9.msdn.com/o9/ch9/6/6/0/9/9/4/C9LecturesErikMeijerFPC6_ch9.wmv All others: * http://ecn.channel9.msdn.com/o9/ch9/7/9/3/4/9/4/C9LecturesMeijerFunctionalChapter1_ch9.wmv * http://ecn.channel9.msdn.com/o9/ch9/8/9/3/4/9/4/C9LecturesMeijerFPC2_ch9.wmv * http://ecn.channel9.msdn.com/o9/ch9/6/1/7/5/9/4/C9LecturesMeijerFPC3_ch9.wmv * http://ecn.channel9.msdn.com/o9/ch9/7/1/9/8/9/4/C9LecturesMeijerFPC4_ch9.wmv * http://ecn.channel9.msdn.com/o9/ch9/8/1/9/8/9/4/C9LecturesMeijerFPC5_ch9.wmv
I like that he refers to 2 great papers ("Why functional programming matters" and "Why calculating is better than scheming") in this talk. I can't wait to see the next talk (higher order functions) where things will get a little more interesting. 
It isn't particularly clear to me what exactly those annotations do. However, the point of the article isn't just to have the compiler evaluate an expression that the programmer knows to be wholly statically computable during compilation (which sounds like what's happening with the Lisp annotations, but I'm not sure). That can be done with template haskell, something like: foo = $(quote (sumT term)) The point of the article is to trick GHC into doing as much partial evaluation of a function as is possible at compile time, even for values where only a portion of its structure is statically known. For instance, if one writes: foo x = [1..10] ++ [x] bar x = sum (foo x) It should turn into something like: foo x = 1:2:3:4:5:6:7:8:9:10:x:[] bar x = 55 + x Is that what those lisp annotations accomplish?
Good luck with empty lines.
Generally the idea of writing a tail recursive algorithm is to eliminate O(N) space behaviour (stack frames) and enable your algorithm to process very large or infinite lists. The tail recursive version presented here doesn't have any advantages over the first version. Each time the function recurses, it extends the closure which gets called at the end with another tree generation function. In the end, you've just transferred the O(N) behaviour from the activation records (which are heap allocated in Haskell) onto the heap.
A subset of supercompilation perhaps.
They accomplish what you assumed they do, i.e. the programmer explicitly specifies when to evaluate a given (sub-)expression. Of course compiler optimizations like the one you describe are best but it would be nice to have a simple, explicit, readable way of instructing the compiler to behave one way or the other too for the cases that are too complex for the compiler to figure out.
This has been a great series so far. Looks to be getting even better.
Not to mention that we have guarded recursion here (obfuscated by the record syntax). It'd take very special circumstances to make it worth giving up guarded recursion just to make something into a tail call. In general it'd just enforce excessive strictness.
There's a video on the site, but there's also a (pretty poorly transcribed, unfortunately) transcript. I'd generally rather read the transcript than watch the video, but the site is *terribly* designed. To that end, here's the transcript in two parts: *I'm Sadek Drobi, I'm here with John Hughes, at Erlang Factory. John, can you tell us a bit about yourself and what you've been busy with?* I'm at heart an academic, I've been a professor for many years and I got interested in functional programming way back in the mid '70s. I've been working with it throughout my career, both with the design of Haskell and more recently, when the functional programming has become to make a move into industry, then I've been working with Erlang. So, I'm very much a fanatic of technology - I love it and very much enjoying seeing that it's finally bearing fruits. In industry, what I've been doing most recently is working with my testing tool, QuickCheck and spending a lot of time with my company that is marketing that. *From Haskell to Erlang, what made the move?* We had a customer! Some of the Erlang users at Ericsson, especially ... were interested in using a version of QuickCheck, so I made a version in Erlang. At that time, certainly there weren't very many or perhaps hardly any Haskell users in the commercial world. So, if we wanted customers, then Erlang was a much better choice. *Do you miss laziness from Haskell?* Yes, absolutely. I have Macros in Erlang that simulate it and I use them all the time. *And types?* Yes, of course. What I miss, when I think of type error, is not immediately discovered and that's very useful, no doubt about that and I do spend some time looking for errors that the Haskell type checker would tell me about immediately. But what that means, is that I have to find my type errors by thorough testing. Oh, wait a minute, I'm working with a testing tool! I actually find that the type errors are found very quickly by QuickCheck tests, so I need to write QuickCheck properties for testing, anyway, so that it's not as big a problem as I might have expected not to have the type checker. *What attracts you most in Erlang in contrast to Haskell?* There are advantages than not having type checker, namely generic programming. If you do generic programming in Haskell, you can write a paper about it. If you do generic programming in Erlang, it's 4 lines - one for lists, one for tuples, one for basic values. Maybe they are only 3 lines! But it's very easy to do generic programming and I do that a lot in the Erlang version of QuickCheck. I've been able to make what the user has to write, to write QuickCheck specifications simpler and more elegant, thanks to the lack of a type system in Erlang. Erlang is very good for meta programming. It's not something that is a lot harder to do in Haskell. *QuickCheck you designed in the beginning in Haskell, right? And then you did a version for Erlang and now you are using it to test race conditions. Can you tell us more about this?* This is some recent work we've been doing as part of the Protest project, which is a project that the EU Framework Program is financing and what we are doing is running current Erlang programs under control of our own scheduler. We define a scheduler as an Erlang process and we instrument the code under test, so that all of the other processes talk to our scheduler and they say "Isn’t it my turn yet?" Then, the scheduler says "Now it's your turn". That lets us randomize the execution and makes it much more likely that we'll provoke race conditions. That's a fairly standard approach, actually. What is more novel about what we are doing is that we are generating the parallel test cases using QuickCheck. We found that we are able to shrink parallel test cases and produce the same kind of minimal examples that make sequential bugs easy to find. We can produce some of those that provoke race conditions. That's very interesting! *Higher order programming with Haskell is easy because of types. Don't you think that types are enablers for higher order programming?* Yes. When you do higher order programming, you have to know what the types of your functions are. I do higher order programming all the time in Erlang and I know what the types of my functions are. They are a very valuable intellectual tool for understanding the complexity of higher order programs, whether or not you have a type checker that checks them. In Erlang I don't have a type checker that checks them, but that doesn't bother me so much. *Both Haskell and Erlang inspire the industry or mainstream in some way or another. Can you tell a bit about what are your favorite features from both languages that are getting mainstream in some way?* In Erlang's case it must be the concurrency and the very nice error handling and features for fault tolerance. In the case of Haskell, I guess it is perhaps Haskell’s ability to capture domain specific languages very elegantly, this having a lot of impact. There are several features in the language that make Haskell so good for that. One is the type system which is very flexible, another is support for higher order programming, which is really essential for defining many domain specific languages, but also lazy evaluation. Lazy evaluation is quite critical for defining the interface of a domain specific language. In Erlang I have to use macros to get the same effect, because you want to be able to define constructions like conditionals that don't evaluate over their branches and lazy evaluation makes that easy to do. Some of my favorite Haskell applications are things like the financial combinators that Lennart Augustsson is working with, where you write Haskell code or what looks like a domain specific language, but is actually Haskell code that then generates Excel interfaces to the computing engines that perform these heavy financial computations - I think that kind of thing is really cool. *With Haskell you've been always thinking it's side effect free, right? Writing a function is side effect free. In Erlang just the fact of passing a message is a side effect. Don't you find it a bit of a problem or a difficulty when programming with Erlang?* Most of my Erlang programming is side effect free. I think I probably write very unusual Erlang programs that look a lot like Haskell ones. Now and then, I do write side effecting code. For example, when I use the random number generation libraries that comes with Erlang, it has a side effecting interface. It's very tempting when you are building something on top of the library with a stateful interface to build code on top of that that also has a stateful interface. That's what I did the first time I tried to use it. That has caused me so much trouble. I think every single bug that I spent hours trying to track down has been caused by a side effect. In a way, I've been programming Haskell for so many years, that I'd forgotten just how devastating side effects are and just how difficult they make debugging. I've learnt that lesson again and nowadays, if I want to use a stateful library, I usually build a side effect free interface on top of it, so that I can then use it safely in the rest of my code. 
Continued ... *Scala is a programming language that got inspired from different other programming languages including Haskell and Erlang, because it has actor model as a library and it has a pretty powerful type system. What do you think of this mixing of features? The same thing with F# which is trying to mix several paradigms, several things like dynamic and static typing in the same language for example. What do you think of this mixing?* I think it's great. My view of functional programming is always been that it gives us new useful tools. That's what I care about, rather than that it stops us doing bad things. You can always choose not to do bad things. I think, if integrating good ideas from several different languages makes an appealing combination, that's all to the good. I'm not a very purist about forbidding side effects absolutely, I simply choose not to use them. *Convention over obligation, right?* Yes, I guess so. *The QuickCheck framework got implemented in several languages. Are you aware of all the implementations?* There have been many clones, more or less complete. It's a nice idea. *For people that don't know about it, can you introduce it a bit to contrast it to unit testing?* When you write QuickCheck tests, what you write is a property and the properties of the form for all test cases in some set, some general property should be true. The difference from unit testing is that you specify a property of a whole set of test cases and then, when QuickCheck runs a test, what it does is it generates an element of that set. Your test cases are generated rather than being prescribed by the programmer. The property then has to determine whether an arbitrary test in this set has passed or not and that forces you to think more generally about the behavior or your code. It's not enough to think "If I put in an A, I should get out a B". You have to think of a general property that will always be true. What you are writing is essentially a part of the form specification that can be more or less complete and the tool then generates as many tests as you like and checks the property of all of those cases. When a test fails, then the generated test case is often not very easy to understand. The reason for that is that we are using random generation. Random generation of anything produces a lot of noise. Somewhere in that test case, which can often be very large, there is some feature that causes the test to fail and we think of that as the signal. The other thing that QuickCheck does is once we find a failing test that we know contains some feature that provokes a bug, we start systematically simplifying it and usually that works very well and we boil the test case down until we get a minimal example normally that provokes a failure. That automates a very familiar part of debugging where you start off with some complex case that has failed and often you would manually start trying to remove parts of it and simplify it and boil it down to a simple case that you can then understand and diagnose. We automate that process and I think that's what people like most about the tool. *For some time, Java was the language of the mainstream. Now we are hearing about lot of other languages, like Erlang, Haskell, F#. Do you think that there will be a next big language or we will be using a lot of languages for doing what we want to do?* Do you mean if there is going to be a winner? I suppose there will be maybe a small number of winners. If you look at Haskell, for example, there are certain kinds of programming that Haskell is truly excellent for and other kinds of programming, where it's entirely unsuitable. I don't think that Haskell will entirely replace C, for example. But, I suppose, in the long term, it's likely that perhaps one language of each kind will attract adherence, end up with better libraries, and in the end become the natural language of choice if you want to do that kind of programming. I don't know which languages that will be. Erlang seems to be doing very well at the moment for its particular niche. *Are you still involved in the Haskell community?* Yes, but I'm pretty focused at the moment, I'm only part time at the university, part time at the company and we have this EU research project that is closely related to the Erlang work I'm doing at the company, so for natural reasons, just at the moment, that's where virtually all my time is being spent. *More than side effect free, are there other concepts from functional programming that you are applying in Erlang, like maybe monads or other abstractions that we see a lot in Haskell and other functional programming languages?* What I'm doing in Erlang is providing a domain specific language for testing and just like the domain specific languages that are provided in Haskell, higher order programming is a very important part of that, lazy evaluation is an important part because we are searching a space for minimal test cases and search processes are very nicely expressed in lazy evaluation and actually using a monad as well. I'm probably one of the few Erlang programmers who is using a monad. I think that many people, when they think about monads, they think that they are a way of doing IO without losing referential transparency. Then, it's natural to think "Well, you can already do IO in Erlang, and without any need for monads, so why use one?" In fact, monads are useful both for capturing IO and as a program structuring concept. That I think is perhaps the more important use of monads and that's what I'm doing inside the Erlang code I'm writing. QuickCheck is based on a monad and it's not the same kind of monad that you do IO with. If you were, I wouldn't need it, but it enables me to structure the code of QuickCheck very nicely. *One thing we use often in Haskell for modeling is type classes. What about Erlang?* There is nothing corresponding to type classes. *Do you miss them?* I'm looking at a specific kind of application and in that application, then I don't think the lack of type class is really a big deal. One of the nice things about the Haskell version of QuickCheck is that we use type classes in order to generate test data of the right type and the programmer doesn't have to say anything, whereas, in the Erlang version, then you have to say "Generate me an integer" or "Generate me a list of integers" or "Generate me a protocol message" or whatever. You have to specify the generators, instead of getting them "for free". At first sight, that looks like a disadvantage, but in reality, when you move beyond very simple properties, then you almost always need to specify generators. Generation is more complex than just saying "Give me an int". Maybe you want to generate a list and then generate one of the elements from the list for example, so you have dependencies between the things that you are generating. As soon as you move beyond very simple properties, you have to write the generators in Haskell also. Then, the fact that you have to write them in the Erlang version it's not really a disadvantage. You have to do the same thing basically. *What do you see as a concept or a technology that will be very interesting for the future?* I think functional programming is a very interesting concept for the future and for the present indeed. One of the things I do wonder about though, is when I got interested in the field, the mainstream was probably Fortran and COBOL and even C was fairly new at that time. The functional programming pioneers spoke of an order of magnitude improvement in productivity and I think functional programming has delivered that. If you compare Haskell programs to C code or even C++ often, they are about an order of magnitude smaller and simpler. The same is for Erlang, those results are being validated in the industry. Where is the next order of magnitude coming from? I wish I had an answer to that question because it's hard to see almost. When you look at a beautiful Haskell program, how could this be 10 times shorter? But I think we need to be asking ourselves that kind of question. If I had a good idea there, I would spend the rest of my career working on it.
I think this has to do with the new parallel gc. (Guessing here) The gc will run an object's finalizer when the object is collected, and for gtk the finalizer will actually do non-trivial stuff. If multiple threads are all running finalizers at the same time, and the finalizers themselves are not synchronized, then badness occurs. Although I may be off here because I don't really see how this is news: I was bitten by this right after the parallel gc came out (like a year ago now?) and my reaction was "Wtf? Oh, right, finalizer is running in a different thread. Have to free that manually." and thought no more of it.
I'm not much of a Haskell programmer, but I know that values in Haskell are immutable. Doesn't that imply that any destructive operation on a data structure uses at least O(n) space? Or is Haskell internally keeping some sort of difference list?
Thanks for the posting the transcript in the comments. I'm on my phone and it was impossible to read it on the sight. 
If i remember correctly, in coders at work SPJ said he was expecting the feedback of J. Hughes about the differences of typing between erlang and haskell. Seems it's done now.
The pun with the english meaning of the word was intended, though, I think. Anyway, ssreflect for 8.2 has been out for a few months ( http://bit.ly/16Zo0Z ), and I have to mention, for the sake of completion, that Coq has a not-so-experimental, older implementation of typeclasses: http://bit.ly/1oi97M
As winterkoninkje pointed out, the form of recursion used here is a special form called guarded recursion, otherwise known in theoretical circles as corecursion. Haskell's semantics are non-strict, so that the evaluation of the recursion doesn't occur before the return. To evaluate the expression n {l = insert_ntr (l n) x} the implementation will place a thunk, a section of code which produces the value when called, into the place where the left tree lives. This thunk will insert the node into the left subtree. (The right tree and the value at this node are shared with the original tree.) For balanced trees, this means you're copying the path from the root to the leaf where you insert it, taking O(log N) space. Of course, if the original tree isn't referenced anywhere else, the path you've copied becomes a candidate for garbage collection so from that perspective it's a constant space operation. If you force these evaluations to occur, then you end up copying every node on the way down the tree. This is the problem with the new tail recursive version, and is what winterkoninkje means by enforcing excessive strictness: in order to evaluate just the first node in the tree, the entire insertion is performed.
You'll need to specify what you mean by "destructive operation" in a Haskell context. Because everything in Haskell is immutable, a destructive operation in the classic sense (an operation that discards the previous structure in favor of the newly created one) cannot actually happen in Haskell unless the compiler can prove that no references to the previous version of the structure remain (this is typically accomplished with a monad like `ST` or `IO`). Instead in Haskell we favor persistent data structures. As a simple example, suppose you have a list called `xs`, which you are using in your code. Somewhere in your code, a function using `xs` constructs an updated version, `ys`, defined as `ys = 1 : xs`. This update is not destructive, because `ys` and `xs` share values -- the tail of `ys` is actually `xs`. This is a persistent data structure. However, suppose we wanted to put `1` at the end of `xs` instead of the beginning. We then say `ys = xs ++ [1]`. Ignoring lazy semantics for a moment (because actually, at the point of assignment, no concatenation is actually performed in Haskell) it is clear that `xs` and `ys` cannot share any cons cells here. In order to append to `xs`, you incur an O(n) penalty with `n` the length of the list -- each cell must be copied (unless you can prove that no reference to the original `xs` still exists, which does not happen automatically). Contrast this to a language based on mutable values, where a dynamic list typically lives on the heap where it may have been allocated more space than it actually needs. If an allocation does not need to be performed, appending to a list is O(1). On the other hand, the data structure is not persistent -- if anyone else has a reference to your list, changing it in one place will change it everywhere. Particularly in a concurrent scenario, this creates a need for thread synchronization, which as you probably know can get very hairy very quickly. But on a large list, O(n) append is a pretty big penalty, right? That's why functional programmers emphasize data structures so much more than imperative programmers do. If you need amortized O(1) affix to both the head and tail of the data structure, then internally a linked list is not the appropriate data structure, and you shouldn't be using a list, but rather a kind of tree. If you use the right kind of data structure, you can usually match the time complexity of a mutable operation *and* keep persistence. The catch of course are the constant factors... but if you're dealing with large `n`, these nearly never matter. In the particular case of append to a list, laziness means that in practice the O(n) penalty is incurred during list consumption, which is going to be O(n) anyway.
This is seriously impressive for a bachelor degree project
bad ass
Is the code available somewhere? 
Very cool. LLVM is the cool low-level toy, these days.
sounds great, but he should proof-read it. twice. seriously, he accidentally 3-line long sentence without a verb.
[chak](http://reddit.com/user/chak) says "scheduled for inclusion to the main repo, but needs some more love before that"
Oh, I see. In that case: eek. :-)
Very nice, want to play around with it.
I agree about the proof-reading, but if I had managed anything so cool for an undergrad project I would probably feel proof-reading was beneath me too :-) Or maybe the acknowledgement of his friends maybe reading it one day was a sly dig towards people who promise to proof-read but never get back to you...
&gt; scheduled for inclusion to the main repo Great! &gt; needs some more love I'd love to help. I work with LLVM on my day job.
Does that mean, now that we got a VM backend, that we're going to get true metacircularity? instance Show ((-&gt;) a) doing a fully lazy reduction and showing me what's left of my code after currying?
Every data structure is different. But, as with any other language, unless you tell Haskell to do something it won't. In imperative languages which allow destructive updates (or actually: with ephemeral data structures), not doing anything you don't tell them to means that multiple sources can hold a pointer to the same instance in memory and they can all make changes that the other sources can see. When this is not the desired behavior, we're forced to clone the entire instance whenever we want to allow multiple sources to make changes to a "local copy". In a pure functional language (or actually: with persistent data structures) no destructive changes are allowed. This is good because it means we can safely have many sources point to the same instance in memory without worrying that any "changes" will be globally visible. So then how to we make changes? Rather than destructively altering the contents of memory, we make a new instance in memory. Here, not doing anything we don't tell it to means that we can reuse chunks of the old value whenever we want to keep something without changing it. Thus, for tree-like data structures if we alter some value at a leaf, we will allocate a new spine covering the path from the root to that leaf, but all the rest of the tree can be shared between the old value and the new one. Similarly for if we change a value at an internal node, except now we can share any subtrees below that internal node as well. So, for updating trees, an ephemeral representation requires us to allocate a new O(n) copy ---where n is the number of nodes in the tree--- whereas an ephemeral representation only requires us to allocate a new O(d) spine ---where d is the depth of the node, which is typically O(log n) or similar. Also, unless you're pulling copy-on-write tricks, the O(n) cost must be paid up front whenever there's aliasing that could result in changes, whereas the O(d) is only required when changes are actually made.
Untested, but how about: munge ('\n' : x : xs) | isSpace x &amp;&amp; x /= '\n' = ' ' : munge (dropWhile isSpace xs) munge (x : xs) = x : munge xs munge [] = [] main = interact munge I will happily admit that this is a little bit more difficult to understand.
Here's a Haskell points-free one-liner for "unwrap": unwrap = map(concat.intersperse" ".map(dropWhile isSpace)).groupBy(const$not.null.takeWhile isSpace) It differs slightly from the one in the blog, because it will also strip leading spaces from the first line. To get the original behavior, you can modify "main": main = interact $ tail . unlines . unwrap . lines . ('X' :)
THINK BEFORE YOU CODE.
This works fine with empty lines. $ cat &gt; foo.py import sys lines = (line for line in sys.stdin) print lines.next().strip(), for line in lines: if line[0] != ' ': print print line.strip(), $ cat &gt; header This is a normal line. This is a slightly longer line that wraps with two spaces. A short line. Another example of a long line that wraps with tabs (not just once, but twice. Final line. $ cat header | python foo.py This is a normal line. This is a slightly longer line that wraps with two spaces. A short line. Another example of a long line that wraps with tabs (not just once, but twice. Final line. 
I didn't say this in the post, but this was part of a larger program that needed to do more processing after unwrap, so that's why I don't use print and instead have a function that produces an array of lines. If the Haskell program were just printing, it might look like this: import Data.List main = fmap lines getContents &gt;&gt;= mapM_ go go (c : cs) | isSpace c = putStr (' ' : dropWhile isSpace cs) go s = putStr ('\n' : s) 
*(Repeated from Liam's blog, which ate my paragraph breaks.)* Hi Liam. I like the clarity and down-to-earth nature of your presentation. One suggestion: I'd avoid any statements about what's "obvious" (or "clear"), which I hear as "in my blind spot" or "compatible with my unquestioned assumptions". If you really know something is so, then just say it. If you're uneasy, then rethink your claim and/or admit your uneasiness. A pet peeve of mine. More at *[Fostering creativity by relinquishing the obvious](http://conal.net/blog/posts/fostering-creativity-by-relinquishing-the-obvious/)*. In particular, please reconsider your remark &gt; We use [Int] type because QuickCheck can't generate test cases for type [a] for obvious reasons. I have two problems with this remark. First, the reasons you can't may become less obvious if you think about them a lot more deeply. Second, while you've said (perhaps incorrectly) why you cannot test for the general case, you haven't said why testing only a single type-specialized case is even nearly adequate. You're not satisfied with testing with a single list, and yet you are satisfied with a single type. There is indeed a justification, but I doubt it'd be obvious until you've wrestled with the question for a long time and hit a deep insight. My hunch is that the word "obvious" makes issues like these two harder for people to notice and point out. A sort of Emperor's New Clothes phenomenon. Regards, - Conal
So I'm getting down modded for not meeting a requirement you didn't list? Clearly you could simply replace sys.stdin with a StringIO and each print statement with a string concatenation in my code and this code works directly. The algorithm is the interesting part, not which function is called to retrieve or emit a string.
I intend to explain that remark perhaps a bit more, this isn't just slides for people to read, I'll be talking too and explaining quickcheck generators and so on.
Liam, this is an excellent presentation. If I need to present Haskell to people in industry any time in the near future, I'll consider using it.
Thanks! Feel free.
You're probably being downmodded because GHC won't compile your program :-)
I am afraid not.
Site's down for me.
And as Jean-Philippe Bernardy has shown recently, you can generate test cases for the type [a], and they are in fact quite simple. 
Oh, do you have a link or something? Happy to correct it if you can find some more information.
Still working for me, and I didn't do anything?
http://www.cse.chalmers.se/%7Ebernardy/PolyTest.pdf
The last time this was linked in reddit was [over a year ago](http://www.reddit.com/r/haskell/comments/7buik/a_djangoinspired_haskell_web_framework_ella/), and a lot has been added since then. In particular, the first Ella-based web app - a [blog](http://lukeplant.me.uk/blog/posts/haskell-blog-software/) - is now live. Ella provides a CGI-wrapper with tools for crafting the URL structure of a web app. It does not provide a data store or a templating facility; the author uses HDBC and HStringTemplate, respectively, for those. It also apparently does not yet provide an admin facility.
This is good stuff. Partial evaluation has huge potential but not enough people have looked at the application to ML-style languages. Historically the partial evaluation researches mainly concentrated on the untyped lisp-style languages (or extending into imperative languages). There's no reason for that anymore, since we noticed that the cogen style works perfectly well in typed languages.
This was also mentioned in the [ByteString](http://www.cse.unsw.edu.au/~dons/papers/CSL06.html) paper, section 3.6
"Connecting to liamoc.net...." forever, at home and at work.
This is probably the same trick as redundant binary numbers? Basically, the number is written in binary, but the digits allowed are 0, 1 and 2. This way, both increment and decrement take O(1) amortized time. inc (2222) = (11111) dec (11111) = (11110) 
Another thing you can do (which seems simpler to me) is the 2D analogue to loose octtrees. Basically you still subdivide like a quad tree, putting each object into the cell of its center point if the object is smaller than the cell size. This means objects may extend beyond the bounding area of the cell. However, it can only expand by at most half the the cell size since we require that the object must be smaller than the cell size. So then we can just loosen up the bounding area of each cell to extend 50% into the neighbours whenever we test anything against it (this guarantees that we won't miss any objects). So you decouple the subdivision for the purposes of construction with the bounding edges used for the purposes of intersection, where the latter is slightly looser to allow for objects extending past their cell boundaries.
Sure, the purpose is slightly different, but it's the same number system and even the same `inc` / `dec` effect, I think. (Maybe in "reverse") Namely, an object crossing a boundary is equivalent to adding 2^(-k) to its position and the redundant representation prevents this from bubbling up all the way to the top. The digits -1, 0 and 1 make the connection apparent: the interval [-1,1] = { 0.a1a2a3... | ak in {-1,0,1} } is the union of [-1,0] = { 0.(-1)a2a3a4... | ak in {-1,0,1} } [-1/2,1/2] = { 0.0a2a3a4... | ak in {-1,0,1} } [0,1] = { 0.1a2a3a4... | ak in {-1,0,1} } and that's the tree structure that Luke is using. 
I love xmonad, and been using it for over a year now, and have never looked back. However everything I read about xmonad bothers me. It seems it is all propaganda or something. If /r/xmonad will have useful things for an xmonad user, like configuration tips and advice, or discussions about how xmonad works or what new features are on the horizon I am all for it. Looking at it right now, it just looks like a bunch of blogs about people stating how awesome xmonad is and how your stupid for using anything else. edit: I take it back, only half of the links appear to have this issue, the rest are great, subscribed.
I'd pay if it were good, even if it were free and had a large "DONATE" button. /me goes seeking for the DONATE button for Leksah
I really would like to see something like Dr. Haskell...
Don, you should be paid for all this reddit work.
I am reminded very very loosely of Burkhard-Keller Trees, if only because you merely get a reduction of the number of leaves you have to descend down to rather than an exact search. http://blog.notdot.net/2007/4/Damn-Cool-Algorithms-Part-1-BK-Trees What prevents the applicability of an R-Tree/GiST to this particular domain though? A GiST using nested circles with a key-merge function of finding the smallest circle containing both should work reasonably well, though I suspect he might need a different balance of update performance to read performance.
The comment this post responds to... &gt; Since static type checking can't cover all possibilities, you will need automated testing. Once you have automated testing, static type checking is redundant. ...is completely inane. That makes as much sense as saying, "Hey, I brush my teeth, why should I wear a seat belt?"
There are lots of places it makes sense. For example, take a non-trivial mathematical function that takes numerical inputs, combines them somehow, with a single flow of control, and returns some value. Let's say we write some tests for it, and they pass. We know now that we didn't make any silly type errors, like trying to add together a list and an integer. If we had static type checks for the same thing, they would be adding nothing that our unit tests didn't already check *regarding the implementation of that function*. That's what the author of that comment meant by the static type checking being redundant. 
If your non-trivial mathematical function deals with objects of many different types, and is sufficiently non-trivial (many branches, etc), there may well be pathological edge cases your testing framework fails to uncover. If your compiler can deduce those cases trivially and automatically, why would you want it not to?
Cut him some slack! BSc theses are done in 2x 12 weeks at UNSW, while having other coursework obligations at the same time. Do what David has done in that time, write the thesis and find time for lots of proof reading, and we'll talk again.
Let's say you wrote your own fancy "sin" function. You then wrote your unit tests to check that sin(0) = 0, sin(pi/2) = 1, etc. Awesome, you now know it probably works like you expect it would. That's great, but the problem is that these tests only test how it acts with numeric inputs, and only the inputs you tested. You could use quickcheck to check how it responds to a bunch of different inputs. Now what happens when someone sneaks a non-integer character into your form field that gets passed to your sine function, and internally your sine function converts that to the ASCII equivalent. That output would be quite confusing. What type-checks do is provide a sort of contract between different parts of the code. You can test a lot, but types guarantee that you will never get input that isn't what you expect it to be. You can be absolutely certain that this would never happen unless you're following very bad coding practices. They're really two different things. They're like layers in the code-correctness cake. Better type systems mean you can get away with fewer tests (like not having to worry that everything fails gracefully on NULL pointers) but they are not equivalent.
The author of that quote uses Python, which is strongly-typed. sin("1") would result in an exception, probably a `TypeError`, not some random garbage value. You'd need a weakly-typed language such as C or JavaScript for that.
Feel free to ask questions too... that said, by a large margin online comments on xmonad are positiive. The downsides cited are usually the dependency on the GHC toolchain, and the use of Haskell as the root configuration language.
I completely agree. I was just defending the quotation in the context where the function *doesn't* deal with many different types of objects, and *doesn't* have many branches etc. 
Err, yes. The same goes for Sequences. The more fun questions, though, are what it means to fold a Sierpinski triangle, a Hex grid, some other strange lattice or even graphs as well as how we can harness associativity and commutativity to figure out how to best fold over a structure.
Curiously, the comment you quoted makes a lot of sense if you swap the places of "automated testing" and "static type checking", with the obvious limitation that static type checking only addresses certain kinds of problem (albeit often very common ones).
If your function operates on `[a]`, it should operate on lists of bottom... lists of `undefined` of various lengths would be a good proxy.
&gt; ...is completely inane. I agree. With static checking, you need only those automated tests that aren't covered by type checking. That's a significant reduction from automated tests for everything.
&gt; That's what the author of that comment meant by the static type checking being redundant. Yes, but no one using static typing writes tests to do what the type checker does. It's meaningless to do so: int addInts(int a, int b) { return a + b; } void testAddIntsTakesInts() { addInts("one", "two"); } That won't even compile (of course), so there's no reason or even possible *way* to write tests to check against it. At the same time, no one presumes that static typing can cover *everything* tests can do.
Yeah, it's rather short sighted. For instance, suppose we're representing the syntax of the lambda calculus (after all, isn't that pretty much all anyone ever does?). We'll use a locally nameless representation (bound variables are De Bruijn indices, and free variables are strings, or whatever), because that's nice. Now, in a Haskell attempt, I might write (for the untyped lambda calculus): data Term = App Term Term | Bound Integer | Free String | Lam Term And that works. But, the nice thing about a locally nameless representation is that you're expected to only work with well-scoped lambda terms. So, when you peel off a `Lam`, you're expected to replace all corresponding indices with free variables. If you don't work with well-scoped terms, then you have to make sure you do arithmetic on the indices during substitution, otherwise you get variable capture problems just like using all strings for names (only there, instead of arithmetic, you do alpha renaming). So, we need to make sure, through tests presumably, that all our operations preserve well-scoping, and that we never accidentally introduce non-well-scoped terms anywhere. But, what if we instead represent our syntax as something like: data Term' : ℕ → Set where _·_ : ∀{n} → Term' n → Term' n → Term' n bound : ∀{n} → Fin n → Term' n free : ∀{n} → String → Term' n Λ_ : ∀{n} → Term' (suc n) → Term' n So, we keep track of how many bound variables are in scope in the type of the lambda term. Then we can start working with the following types: Term : Set Term = ∀{n} → Term' n Scope : Set Scope = ∀{n} → Term' (suc n) A `Term` must, necessarily, be a well-scoped term, because we could instantiate `n` to `0`, and there are no values in the finite set of size 0, so there's no way for the term to contain `bound i` unless it's enclosed by a lambda. Similarly, a `Scope` has one dangling variable, and we can write operations that convert between `Term` and `Scope` properly, and use them, confident that we aren't mixing things up, and moreover, have the type system *prove* that various values are well-scoped. For instance, here's a function that replaces the dangling variables in a `Scope` with a well-scoped `Term` (`ix-test` figures out whether we should substitute for an index, returning `nothing` if so, or `just k` where `k` is the new index we should use if not; this arithmetic should be unnecessary, too, but I just whipped this up in a few minutes): instantiate : Term → Scope → Term instantiate t s {n} = push zero (s {n}) where push : ∀{n} → (j : Fin (suc n)) → Term' (suc n) → Term' n push j (f · x) = push j f · push j x push j (bound i) with ix-test i j ... | just k = bound k ... | nothing = t push j (free s) = free s push j (Λ e) = Λ push (suc j) e As a fun side note, if you accidentally type: push j (Λ e) = Λ push j e for that last case, the type checker will immediately tell you you're wrong. Anyhow, the important point for that function is that when we decide we're supposed to do a substitution (the `... | nothing = t` case), we can just insert the term, because we know, statically, that it's well-scoped, and thus is not subject to any variable capture issues. To conclude, while I'm using Agda to write this, you can actually enforce the above invariant using a mere nested type in Haskell: data Term' n = App (Term' n) (Term' n) | Bound n | Free String | Lam (Term' (Maybe n)) type Term = forall n. Term' n type Scope = forall n. Term' (Maybe n) So you don't even necessarily need to wait until far in the future to statically ensure nice invariants of your programs.
But that error will occur at run time, whereas in Haskell it can't occur at all. The real problem of course arises not when the code literally has `sin("1")`, but when a string wanders in from the other end of the program through three layers of indirection and you have no idea how it got there.
Yes, but periodic was implying that passing a value with an unexpected type could produce an erroneous result. It actually would just raise an exception. Python, unlike Haskell, has a working stack trace mechanism. If a procedure received an invalid parameter, the exception's stack trace would indicate where the value came from. I've used both Python and Haskell, Python for years and Haskell for a few months, and I *do* like Haskell's type system better. But passing a value of the wrong type to a procedure is such a rare error that, if it occurs, it's a big red flag about the quality of the code. It's equivalent to seeing `Prelude: undefined` show up when evaluating a Haskell function.
Agreed, but I can't live without it at this point. So I had to install GHC on my netbook just so I could use xmonad. Thanks for the subreddit though. I would ask questions but really xmonad does everything I need. I have done very minimal configurations and I am sure I could make it more awesome by customizing it, but it already does everything I want.
How are you liking Agda? I've been meaning to learn it.
Thank you all for the responses - very informative. I do understand the immutable list example, which makes perfect sense. I'm still wondering how efficient an operation like delete on a balance binary search tree is in terms of space. I guess I could be reading Okasaki instead of browsing reddit :) I am constantly impressed by how clever Haskellers are. I've implemented a few easy algorithms in Haskell like A* search, and my code is tragically bad. (Although usually fine in terms of asymptotic behaviour.) The first language I ever learned rigorously was C++, and I fear I'll never escape the brain damage it has caused me. 
It's great for experimenting with dependently typed programming. I'm not sure how well one would fare trying to write actual applications in it, and it lacks some features that the more straight theorem provers have, but it gives a good preview (at the least) of what actual programming with type systems beyond those like Haskell's would be like.
There really is no such thing as a single 'best' way to fold over a structure, it depends on the function being folded. Is the function strict? is it more efficient when applied on the left like cons, or when on the right, like snoc, or in a tree pattern? And more interestingly, is there a way to automatically use the best fold?
&gt;You will do better at communicating your ideas if you express them with grace. If you do not intend to communicate well, then do what you will. Irony in juxtaposition. 
Giving rise to the same topology, alright. :-D
The only reason this is in /r/haskell is that it's written by Luke Palmer. The solution is in C#.
Not for me and evidently others :/
If there are any happstackers (or curious) in L.A. I am giving a presentation on using happstack in a hands on way, for the LAFTP monthly meeting, this evening. Already announced via lafp but in case others are interested... :) 4760 Boelter Hall on the UCLA campus. At 19:00 
Okasaki is definitely the go-to guy on persistent data structures. In particular, a lot of what he focuses on is the interplay between lazy and strict evaluation in order to get optimal space and time complexity. Don't worry about your code being bad, everyone's is to a greater or lesser extent, right? There's always someone better than you to lament about, so just focus on enjoying yourself and good code will come. I'm sure you didn't write elegant and bug free code in C++ when you first started, either :)
&gt;I'm not sure how well one would fare trying to write actual applications in it On the other hand, people used to say that about Haskell in the 90s, right? You never know... Anyway, thanks for the nice motivating example.
This link doesn't have any code in it at all. The only reference to C# in the whole article is the following line: &gt;The algorithm seems to work well — I am able to support 5,000 densely packed circles in C# without optimizations. To me, this makes this article a generic computer science article. You're right that it's not particularly related to Haskell, but the general Programming and Compsci reddits are hit and miss enough quality-wise that I don't even subscribe to them.
That said, I'm still glad it was in here, as I probably wouldn't have seen it otherwise. And it lead to an interesting apfelmus/sigfpe exchange. :-)
Is there going to be a video, or are you trying to get overseas developers to take a plane?